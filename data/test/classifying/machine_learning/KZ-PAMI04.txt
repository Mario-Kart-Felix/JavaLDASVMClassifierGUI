What Energy Functions Can Be Minimized
via Graph Cuts?
Vladimir Kolmogorov, Member, IEEE, and Ramin Zabih, Member, IEEE
Abstract—In the last few years, several new algorithms based on graph cuts have been developed to solve energy minimization
problems in computer vision. Each of these techniques constructs a graph such that the minimum cut on the graph also minimizes the
energy. Yet, because these graph constructions are complex and highly specific to a particular energy function, graph cuts have seen
limited application to date. In this paper, we give a characterization of the energy functions that can be minimized by graph cuts. Our
results are restricted to functions of binary variables. However, our work generalizes many previous constructions and is easily
applicable to vision problems that involve large numbers of labels, such as stereo, motion, image restoration, and scene reconstruction.
We give a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be
written as a sumof terms containing three or fewer binary variables.We also provide a general-purpose construction tominimize such an
energy function. Finally, we give a necessary condition for any energy function of binary variables to be minimized by graph cuts.
Researchers who are considering the use of graph cuts to optimize a particular energy function can use our results to determine if this is
possible and then follow our construction to create the appropriate graph. A software implementation is freely available.
Index Terms—Energy minimization, optimization, graph algorithms, minimum cut, maximum flow, Markov Random Fields.

1 INTRODUCTION AND OVERVIEW
MANY of the problems that arise in early vision can benaturally expressed in terms of energy minimization.
The computational task of minimizing the energy is usually
quite difficult as it generally requires minimizing a
nonconvex function in a space with thousands of dimen-
sions. If the functions have a very restricted form, they can
be solved efficiently using dynamic programming [2].
However, researchers typically have needed to rely on
general purpose optimization techniques such as simulated
annealing [3], [16], which requires exponential time in
theory and is extremely slow in practice.
In the last few years, however, a new approach has been
developed based on graph cuts. The basic technique is to
construct a specialized graph for the energy function to be
minimized such that the minimum cut on the graph also
minimizes the energy (either globally or locally). The
minimum cut, in turn, can be computed very efficiently
by max flow algorithms. These methods have been
successfully used for a wide variety of vision problems,
including image restoration [9], [10], [18], [21], stereo and
motion [4], [9], [10], [20], [24], [27], [32], [35], [36], image
synthesis [29], image segmentation [8], voxel occupancy
[39], multicamera scene reconstruction [28], and medical
imaging [5], [6], [25], [26]. The output of these algorithms is
generally a solution with some interesting theoretical
quality guarantee. In some cases [9], [18], [20], [21], [35], it
is the global minimum, in other cases, a local minimum in a
strong sense [10] that is within a known factor of the global
minimum. The experimental results produced by these
algorithms are also quite good. For example, two recent
evaluations of stereo algorithms using real imagery with
dense ground truth [37], [41] found that the best overall
performance was due to algorithms based on graph cuts.
Minimizing an energy function via graph cuts, however,
remains a technically difficult problem. Each paper con-
structs its own graph specifically for its individual energy
functionand, in someof these cases (especially [10], [27], [28]),
the construction is fairly complex. One consequence is that
researchers sometimes use heuristic methods for optimiza-
tion, even in situations where the exact global minimum can
be computed via graph cuts. The goal of this paper is to
precisely characterize the class of energy functions that canbe
minimized via graph cuts and to give a general-purpose
graphconstruction thatminimizesanyenergy function in this
class. Our results play a key role in [28], provide a significant
generalization of the energy minimization methods used in
[4], [5], [6], [10], [18], [26], [32], [39], and show how to
minimize an interesting new class of energy functions.
In this paper, we only consider energy functions
involving binary-valued variables. At first glance, this
restriction seems severe since most work with graph cuts
considers energy functions with variables that have many
possible values. For example, the algorithms presented in
[10] use graph cuts to address the standard pixel labeling
problem that arises in early vision, including stereo, motion,
and image restoration. In the pixel-labeling problem, the
variables represent individual pixels and the possible
values for an individual variable represent, e.g., its possible
displacements or intensities. However, as we discuss in
Section 2, many of the graph cut methods that handle
multiple possible values work by repeatedly minimizing an
energy function involving only binary variables. As we will
see, our results generalize many graph cut algorithms [4],
[5], [6], [10], [18], [26], [39] and can be easily applied to
IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 26, NO. 2, FEBRUARY 2004 147
. The authors are with the Computer Science Department, Cornell
University, Ithaca, NY 14853. E-mail: {vnk, rdz}@cs.cornell.edu.
Manuscript received 2 May 2002; revised 17 Mar. 2003; accepted 16 June
2003.
Recommended for acceptance by M.A.T. Figueiredo, E.R. Hancock, M. Pelillo,
and J. Zerubia.
For information on obtaining reprints of this article, please send e-mail to:
tpami@computer.org, and reference IEEECS Log Number 118731.
0162-8828/04/$20.00  2004 IEEE Published by the IEEE Computer Society
problems like pixel labeling, even though the pixels have
many possible labels.
1.1 Summary of Our Results
In this paper,we focus on two classes of energy functions. Let
fx1; . . . ; xng, xi 2 f0; 1g be a set of binary-valued variables.
We define the classF 2 to be functions that can bewritten as a
sum of functions of up to two binary variables at a time,
Eðx1; . . . ; xnÞ ¼
X
i
EiðxiÞ þ
X
i<j
Ei;jðxi; xjÞ: ð1Þ
We define the class F 3 to be functions that can be written as
a sum of functions of up to three binary variables at a time,
Eðx1; . . . ; xnÞ ¼
X
i
EiðxiÞ þ
X
i<j
Ei;jðxi; xjÞ
þ
X
i<j<k
Ei;j;kðxi; xj; xkÞ:
ð2Þ
Obviously, the class F 2 is a strict subset of the class F 3.
However, to simplify the discussion, we will begin by
focusing on F 2. Note that there is no restriction on the signs
of the energy functions or of the individual terms.
The main results in this paper are:
. A precise characterization of the class of functions in
F 3 that can be minimized using graph cuts.
. A general-purpose graph construction for minimiz-
ing any function in this class.
. A necessary condition for any function of binary
variables to be minimized via graph cuts.
Therestof thepaper isorganizedasfollows: InSection2,we
describe how graph cuts can be used to minimize energy
functionsanddiscuss the importanceofenergyfunctionswith
binary variables in the context of two example vision
problems, namely, stereo andmulticamera scene reconstruc-
tion. In Section 3, we formalize the relationship between
graphs and energy functions and provide a precise definition
of the problem that we wish to solve. Section 4 contains our
main theoremfor theclassof functionsF 2 andshowshowthis
result can be used for both stereo and multicamera scene
reconstruction. Section5givesour results for thebroaderclass
F 3 and shows how this result can be used for multicamera
scene reconstruction. A necessary condition for an arbitrary
function of binary variables to beminimized via graph cuts is
presented in Section 6. We discuss some related work in the
theory of submodular functions in Section 7 and give a
summaryofourgraphconstructions inSection8.Softwarecan
be downloaded from http://www.cs.cornell.edu/~rdz/
graphcuts.html that automatically constructs the appropriate
graphandminimizestheenergy.AnNP-hardnessresultanda
proof of one of our theorems are deferred to the Appendix.
2 MINIMIZING ENERGY FUNCTIONS VIA
GRAPH CUTS
Many vision problems, especially in early vision, can
naturally be formulated in terms of energy minimization.
Energy minimization has a long history in computer vision
(see [34] for several examples). The classical use of energy
minimization is to solve the pixel-labeling problem, which
is a generalization of such problems as stereo, motion, and
image restoration. The input is a set of pixels P and a set of
labels L. The goal is to find a labeling f (i.e., a mapping
from P to L) which minimizes some energy function.
A standard form of the energy function is
EðfÞ ¼
X
p2P
DpðfpÞ þ
X
p;q2N
Vp;qðfp; fqÞ; ð3Þ
where N  P  P is a neighborhood system on pixels.1
DpðfpÞ is a function derived from the observed data that
measures the cost of assigning the label fp to the pixel p.
Vp;qðfp; fqÞ measures the cost of assigning the labels fp; fq to
the adjacent pixels p; q and is used to impose spatial
smoothness. At the borders of objects, adjacent pixels should
often have very different labels and it is important thatE not
overpenalize such labelings. This requires that V be a
nonconvex function of jfp  fqj. Such an energy function is
called discontinuity-preserving. Energy functions of the form
(3) can be justified on Bayesian grounds using the well-
knownMarkov Random Fields (MRF) formulation [16], [31].
Energy functions like E are extremely difficult to
minimize, however, as they are nonconvex functions in a
space with many thousands of dimensions. They have
traditionally been minimized with general-purpose optimi-
zation techniques (such as simulated annealing) that can
minimize an arbitrary energy function. As a consequence of
their generality, however, such techniques require expo-
nential time and are extremely slow in practice. In the last
few years, however, efficient algorithms have been devel-
oped for these problems based on graph cuts.2
2.1 Graph Cuts
Suppose G ¼ ðV; EÞ is a directed graph with nonnegative
edge weights that has two special vertices (terminals),
namely, the source s and the sink t. An s-t-cut (which we
will refer to informally as a cut) C ¼ S; T is a partition of the
vertices in V into two disjoint sets S and T such that s 2 S
and t 2 T . The cost of the cut is the sum of costs of all edges
that go from S to T :
cðS; T Þ ¼
X
u2S;v2T;ðu;vÞ2E
cðu; vÞ:
The minimum s-t-cut problem is to find a cut C with the
smallest cost. Due to the theorem of Ford and Fulkerson [14],
this is equivalent to computing the maximum flow from the
source to sink. There are many algorithms that solve this
problem in polynomial timewith small constants [1], [7], [17].
It is convenient to note a cut C ¼ S; T by a labeling f
mapping from the set of the vertices V  fs; tg to f0; 1g,
where fðvÞ ¼ 0 means that v 2 S and fðvÞ ¼ 1 means that
v 2 T . We will use this notation later.
Note that a cut is a binary partition of a graph viewed as a
labeling; it is a binary-valued labeling. While there are
generalizations of the minimum s-t-cut problem that
involve more than two terminals (such as the multiway
cut problem [12]), such generalizations are NP-hard.
148 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 26, NO. 2, FEBRUARY 2004
1. Without loss of generality, we can assume that N contains only
ordered pairs p; q for which p < q since we can combine two terms Vp;q and
Vq;p into one term.
2. It is interesting to note that some similar techniques have been
developed by algorithms researchers working on the task assignment
problem [30], [33], [40].
2.2 Energy Minimization Using Graph Cuts
In order to minimizeE using graph cuts, a specialized graph
is created such that the minimum cut on the graph also
minimizesE (either globally or locally). The formof thegraph
depends on the exact form of V and on the number of labels.
In certain restricted situations, it is possible to efficiently
compute theglobalminimum. If there areonly two labels, [18]
showed how to compute the global minimum of E. This is
also possible for an arbitrary number of labels as long as the
labels are consecutive integers and V is the L1 distance. The
construction is due to [20] and is a modified version of [36].
This construction has been further generalized to handle an
arbitrary convex V [22].
However, a convex V is not discontinuity preserving and
optimizing an energy function with such a V leads to
oversmoothing at the borders of objects. The ability to find
the global minimum efficiently, while theoretically of great
value, does not overcome this drawback. This is clearly
visible in the relatively poor performance of such algo-
rithms on the stereo benchmarks described in [37].
Moreover, efficient global energy minimization algo-
rithms for even the simplest class of discontinuity-preserving
energy functions almost certainly do not exist. Consider
V ðfp; fqÞ ¼ T ½fp 6¼ fq, where the indicator function T ½ is 1 if
its argument is true and otherwise 0. This smoothness term,
sometimes called the Potts model, is clearly discontinuity-
preserving. Yet, it is known to be NP-hard to minimize [10].
However, graph cut algorithms have been developed
that compute a local minimum in a strong sense [10]. As we
shall see, these methods minimize an energy function with
nonbinary variables by repeatedly minimizing an energy
function with binary variables.3
2.3 The Expansion Move Algorithm
One of the most effective algorithms for minimizing
discontinuity-preserving energy functions is the expansion
move algorithm, which was introduced in [10]. This
algorithm can be used whenever V is a metric on the space
of labels; this includes several important discontinuity-
preserving energy functions (see [10] for more details).
Consider a labeling f and a particular label . Another
labeling f 0 is defined to be an -expansion move from f if
f 0p 6¼  implies f 0p ¼ fp. This means that the set of pixels
assigned the label  has increased when going from f to
f 0. An example of an expansion move is shown in Fig. 1.
The expansionmove algorithm cycles through the labels
in some order (fixed or random) and finds the lowest energy
-expansionmove from the current labeling. If this expansion
move has lower energy than the current labeling, then it
becomes the current labeling. The algorithm terminates with
a labeling that is a localminimumof theenergywith respect to
expansion moves; more precisely, there is no -expansion
move, for any label , with lower energy. It is also possible to
prove that such a local minimum lies within a multiplicative
factor of the global minimum [10] (the factor is at least 2 and
depends only on V ).
2.3.1 Applications of the Expansion Move Algorithm
Energy functions like that of (3) arise commonly in early
vision, so it is straightforward to apply the expansion move
algorithm to many vision problems. For example, the
expansion move algorithm can be used for the standard
2-camera stereo problem, as well as for multicamera scene
reconstruction.
Stereo. For the stereo problem, the labels are disparities
and the data term DpðfpÞ is some function of the intensity
difference between the pixel p in the primary image and the
pixelpþ fp in thesecondary image.Onthestereoproblem, the
expansion move algorithm and other closely related energy
minimization algorithms give very strong empirical perfor-
mance.Theyhavebeenusedasa critical componentof several
algorithms [4], [27], [28], [32], including the top two algo-
rithms (and five of the top six) according to a recent published
survey [37] that used real data with dense ground truth.
Multicamera scene reconstruction. It is also possible to
use the expansion move algorithm for multicamera scene
reconstruction, as reported in [28]. In their problem formula-
tion, the energy function consists entirely of terms with two
arguments (in other words, Dp does not exist). The set of
pixels P includes all pixels from all cameras and the labels
correspond to planes. Thus, a pair hp; fpi specifies a 3D point
anda labeling f gives thenearest scene elementvisible in each
pixel in each camera.
The expansion move algorithm can be straightforwardly
applied to this problem as long as the energy is of the right
form. Note that an -expansion move increases the set of
pixels labeled  in all cameras at once, rather than in a
single preferred image.
The actual energy function consists of three terms. All the
termsare in the same formasV in that theydependonpairs of
labels fp; fq. One term enforces the visibility constraint.While
this constraint is very important, it has no analogue in the
simple pixel labeling problem formulation and we will not
discuss it here. The other terms are analogous to the standard
stereo data term and smoothness term.
In themulticamera scene reconstruction problem, the data
term enforces photoconsistency. Let I be a set of pairs of
“nearby” 3D points. These points will come from different
cameras, but they will share the same depth (i.e., the points
are of the form hp; fpi; hq; fqiwhere fp ¼ fq and p; q are pixels
from different cameras). Then, the data term is
X
fhðp;lÞi;hðq;lÞi2Ig
Dp;q;lðfp; fqÞ; ð4Þ
where
Dp;q;lðfp; fqÞ ¼ Dðp; qÞ  T ½fp ¼ fq ¼ l:
We have rewritten each term in the sum as a function of
fp; fq (since p; q do not depend on f). The function D will be
KOLMOGOROV AND ZABIH: WHAT ENERGY FUNCTIONS CAN BE MINIMIZED VIA GRAPH CUTS? 149
3. This is somewhat analogous to the ZM algorithm [13], although that
method produces a global minimum of a function with nonbinary variables
by repeatedly minimizing a function with binary variables.
Fig. 1. An example of an expansion move. The labeling on the right is a
white-expansion move from the labeling on the left.
some function of the intensity difference between p and q,
typically, a monotonically increasing function.
The smoothness term, on the other hand, involves a
single camera at a time. It is defined to be
X
fp;qg2N
Vp;qðfp; fqÞ; ð5Þ
where N is a neighborhood system on pixels in a single
camera.
2.4 Energy Functions of Binary Variables
The key subproblem in the expansion move algorithm is to
compute the lowest energy labeling within a single
-expansion of f . This subproblem is solved efficiently with
a single graph cut [10], using a somewhat intricate graph
construction.
It is important to note that this subproblem is an energy
minimizationproblemoverbinaryvariables, even though the
overall problem that the expansionmove algorithm is solving
involves nonbinary variables. This is because each pixel will
either keep its old value under f or acquire the new label .
Formally, any labeling f 0 within a single -expansion of
the initial labeling f can be encoded by a binary vector
x ¼ fxpjp 2 Pg, where f 0ðpÞ ¼ fðpÞ if xp ¼ 0 and f 0ðpÞ ¼ 
if xp ¼ 1. Let us denote the labeling defined by a binary
vector x as fx. Since the energy function E is defined over
all labelings, it is obviously also defined over labelings
specified by binary vectors. The key step in the expansion
move algorithm is therefore to find the minimum of EðfxÞ
over all binary vectors x.
The importance of energy functions of binary variables
does not arise simply from the expansion move algorithm.
Instead, it results from the fact that a graph cut effectively
assigns one of twopossible values to each vertex of the graph.
So, in a certain sense, any energy minimization construction
based on graph cuts relies on intermediate binary variables.
It is, of course, possible to use graph cuts in such amanner
that variables in the original problem do not correspond in a
one-to-one manner with vertices in the graph. This kind of
complex transformation lies at the heart of the graph cut
algorithms that compute a global minimum [20], [22].
However, the NP-hardness result given in [10] shows that
(unless P = NP) such result cannot be achieved for even the
simplest discontinuity-preserving energy function.
3 REPRESENTING ENERGY FUNCTIONS
WITH GRAPHS
Let us consider a graphG ¼ ðV; EÞwith terminals s and t, thus
V ¼ fv1; . . . ; vn; s; tg. Each cut on G has some cost; therefore, G
represents the energy function mapping from all cuts on G to
the set of nonnegative real numbers.Any cut canbedescribed
byn binary variables x1; . . . ; xn corresponding to vertices in G
(excluding the source and the sink): xi ¼ 0 when vi 2 S and
xi ¼ 1when vi 2 T . Therefore, the energyE that G represents
canbeviewedasa functionofnbinaryvariables:Eðx1; . . . ; xnÞ
is equal to the cost of the cut defined by the configuration
x1; . . . ; xn (xi 2 f0; 1g). Note that the configuration that
minimizesEwill not change if we add a constant toE.
WecanefficientlyminimizeE bycomputing theminimum
s-t-cut on G. This naturally leads to the question: What is the
classof energy functionsE forwhichwecanconstruct agraph
that represents E? We can also generalize our construction.
Above, we used each vertex (except the source and the sink)
for encoding one binary variable. Instead, we can specify a
subset V0 ¼ fv1; . . . ; vkg  V  fs; tg and introduce variables
only for thevertices in this set. Then, theremaybe several cuts
corresponding to a configuration x1; . . . ; xk. If we define the
energy Eðx1; . . . ; xkÞ as the minimum among the costs of all
such cuts, then the minimum s-t-cut on Gwill again yield the
configuration which minimizes E.
We will summarize the graph constructions that we
allow in the following definition.
Definition 3.1. A functionE ofn binary variables is calledgraph-
representable if there exists a graph G ¼ ðV; EÞwith terminals
s and t and a subset of vertices V0 ¼ fv1; . . . ; vng  V  fs; tg
such that, for any configuration x1; . . . ; xn, the value of the
energy Eðx1; . . . ; xnÞ is equal to a constant plus the cost of the
minimum s-t-cut among all cuts C ¼ S; T in which vi 2 S, if
xi ¼ 0, and vi 2 T , if xi ¼ 1 (1  i  n). We say that E is
exactly represented by G, V0 if this constant is zero.
The following lemma is an obvious consequence of this
definition.
Lemma 3.2. Suppose the energy functionE is graph-representable
by a graph G and a subset V0. Then, it is possible to find the exact
minimum of E in polynomial time by computing the minimum
s-t-cut on G.
In this paper, we will give a complete characterization of
the classes F 2 and F 3 in terms of graph representability and
show how to construct graphs for minimizing graph-
representable energies within these classes. Moreover, we
will give a necessary condition for all other classes that must
bemet for a function to be graph-representable. Obviously, it
would be sufficient to consider only the class F 3 since
F 2  F 3. However, the condition forF 2 is simpler, sowewill
consider it separately.
Note that the energy functions we consider can be
negative, as can the individual terms in the energy functions.
However, the graphs that we construct must have nonnega-
tive edgeweights. All previouswork that used graph cuts for
energy minimization dealt with nonnegative energy func-
tions and terms.
4 THE CLASS F 2
Our main result for the class F 2 is the following theorem.
Theorem 4.1 (F 2 Theorem). Let E be a function of n binary
variables from the class F 2, i.e.,
Eðx1; . . . ; xnÞ ¼
X
i
EiðxiÞ þ
X
i<j
Ei;jðxi; xjÞ: ð6Þ
Then, E is graph-representable if and only if each term Ei;j
satisfies the inequality
Ei;jð0; 0Þ þ Ei;jð1; 1Þ  Ei;jð0; 1Þ þ Ei;jð1; 0Þ: ð7Þ
We will call functions satisfying the condition of (7)
regular.4 This theorem thus states that regularity is a
necessary and sufficient condition for graph-representabil-
ity, at least in F 2.
150 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 26, NO. 2, FEBRUARY 2004
4. The representation of a function E as a sum in (6) is not unique.
However, we will show in Section 5 that the definition of regularity does
not depend on this representation.
In this section, we will give a constructive proof that
regularity isasufficientconditionbydescribinghowtobuilda
graph that represents an arbitrary regular function inF 2. The
otherhalf of the theorem isproven inmuchmoregenerality in
Section 6, where we show that a regularity is a necessary
condition for any function to be graph-representable.
Regularity is thus an extremely important property as it
allows energy functions to be minimized using graph cuts.
Moreover, without the regularity constraint, the problem
becomes intractable. Our next theorem shows that mini-
mizing an arbitrary nonregular function is NP-hard, even if
we restrict our attention to F 2.
Theorem 4.2 (NP-Hardness). Let E2 be a nonregular function
of two variables. Then, minimizing functions of the form
Eðx1; . . . ; xnÞ ¼
X
i
EiðxiÞ þ
X
ði;jÞ2N
E2ðxi; xjÞ;
where Ei are arbitrary functions of one variable and
N  fði; jÞj1  i < j  ng, is NP-hard.
The proof of this theorem is deferred to the Appendix.
Note that this theorem implies the intractability of mini-
mizing the entire class of nonregular functions in F 2. It thus
allows for the existence of nonregular functions in F 2 that
can be minimized efficiently.5
4.1 Graph Construction for F 2
In this section, we will prove the constructive part of the
F 2 theorem. Let E be a regular function of the form given in
the theorem. We will construct a graph for each term
separately and then “merge” all graphs together. This is
justified by the additivity theorem, which is given in the
Appendix.
The graphwill containnþ 2 vertices: V ¼ fs; t; v1; . . . ; vng.
Each nonterminal vertex vi will encode the binary variable xi.
For each term of E, we will add one or more edges that we
describe next.
First, consider a term Ei depending on one variable xi. If
Eið0Þ < Eið1Þ, then we add the edge ðs; viÞ with the weight
Eið1Þ  Eið0Þ (Fig. 2a).Otherwise,weadd theedge ðvi; tÞwith
the weight Eið0Þ  Eið1Þ (Fig. 2b). It easy to see that, in both
cases, the constructed graph represents the function Ei (but
with different constants:Eið0Þ in the former case andEið1Þ in
the latter).
Now, consider a term Ei;j depending on two variables xi,
xj. It is convenient to represent it in Table 1. We can rewrite
it as it is expressed in Table 2. The first term is a constant
function, so we don’t need to add any edges for it. The
second and the third terms depend only on one variable xi
and xj, respectively. Therefore, we can use the construction
given above. To represent the last term, we add an edge
ðvi; vjÞ with the weight Bþ C AD (Fig. 2c). Note that
this weight is nonnegative due to the regularity of E.
A complete graph for Ei;j will contain three edges. One
possible case (C A > 0 and D C < 0) is illustrated in
Fig. 2d.
Note that we did not introduce any additional vertices
for representing binary interactions of binary variables. This
is in contrast to the construction in [10] which added
auxiliary vertices for representing energies that we just
considered. Our construction yields a smaller graph and,
thus, the minimum cut can potentially be computed faster.
4.2 Example: Applying Our Results for Stereo and
Multicamera Scene Reconstruction
Our results give a generalization of a number of previous
algorithms [4], [5], [6], [10], [18], [26], [32], [39] in the following
sense. Each of thesemethods used a graph cut algorithm that
was specifically constructed to minimize a certain form of
energy function. The class of energy functions that we show
how to minimize is much larger and includes the techniques
used in all of these methods as special cases.
To illustrate the power of our results, we return to the use
of the expansionmove algorithm for stereo andmulticamera
scene reconstruction described in Section 2.3.1. Recall that the
key subproblem is to find the minimum energy labeling
within a single -expansion of f , which is equivalent to
minimizing the energy over binary variables xi.
KOLMOGOROV AND ZABIH: WHAT ENERGY FUNCTIONS CAN BE MINIMIZED VIA GRAPH CUTS? 151
Fig. 2. Graphs that represent some functions in F 2. (a) Graph for Ei,
where Eið0Þ > Eið1Þ. (b) Graph for Ei, where Eið0Þ 6> Eið0Þ. (c) Third
edge for Ei;j. (d) Complete graph for Ei;j if C > A and C > D.
5. Gortler et al. have investigated a particularly simple example, namely,
functions that can be made regular by interchanging the senses of 0 and 1
for some set of variables.
TABLE 1
TABLE 2
4.2.1 Stereo
The paper that proposed the expansion move algorithm [10]
showed how to solve the key subproblem with graph cuts
as long as Dp is nonnegative and V is a metric on the space
of labels. This involved an elaborate graph construction and
several associated theorems.
Using our results, we can recreate the proof that such an
energy function can be solved in just a few lines. All that we
need is to prove that E is regular if Dp is nonnegative and V
is a metric. Obviously, the form of Dp doesn’t matter; we
simply have to show that if V is a metric the individual
terms satisfy the inequality in (7). Table 3 considers two
neighboring pixels p; q, with associated binary variables i; j.
If V is a metric, by definition, for any labels ; ;  V ð; Þ ¼
0 and V ð; Þ þ V ð; Þ  V ð; Þ. This gives the inequality
of (7) and shows that E can be minimized using graph cuts.
4.2.2 Multicamera Scene Reconstruction
We can also show that the expansion move algorithm can be
used for a different energy function, namely, the one
proposed for multicamera scene reconstruction in [28]. We
need to show that the smoothness (5) and the data (4) energy
functions are regular. The argument for the smoothness term
is identical to the one we just gave for stereo because the
smoothness term is regular.
The data term for multicamera scene reconstruction is
perhaps the best demonstration of the utility of our results.
The function in the data term is clearly not a metric on the
space of labels (for example, it is entirely possible that
Dp;q;lð; Þ 6¼ 0 for some label ). Prior to our results, the only
way to use the expansion move algorithm for this energy
function would be to create an elaborate graph construction
that is specific to thisparticular energy function.Worse, itwas
not a priori obvious that such a construction existed.
Usingour results, it is simple to showthat thedata termcan
be made regular and the expansion move algorithm can be
applied. Let us write out the sum in (4) and consider a single
termDðp; qÞ  T ½fp ¼ fq ¼ l,which imposesapenalty ifpandq
both have the label l. Recall that we are seeking the lowest
energy labelingwithin a single-expansion of f .Wewill have
two binary variables which are 0 if the associated pixel keeps
its original label in f and 1 if it acquires the new label .
There are twocases thatmustbeanalyzedseparately: l 6¼ 
and l ¼ . Consider the case l 6¼ . If fp 6¼ l or fq 6¼ l, then the
term is zero for any values of the binary variables. If
fp ¼ fq ¼ l, then the penalty is only imposedwhen the binary
variables are both 0. We can graphically show this in Table 4.
If l ¼ , then, if either fp or fq are , the penalty imposed is
independent of one of the binary variables and it is easy to see
that this is regular. If l ¼  andneither fp nor fq are, then the
penalty is only imposedwhen the binary variables are both 1.
Graphically, this can be shown in Table 5. Overall, the energy
function is regular ifDðp; qÞ is nonpositive. Recall thatDðp; qÞ
is a photoconsistency term. It is typically a monotonically
increasing function of the intensity difference between p and
q. By simply subtractinga large constant,wecanensure thatD
is nonpositive and, thus, apply our construction.
5 THE CLASS F 3
Before stating our theorem for the class F 3, we will extend
the definition of regularity to arbitrary functions of binary
variables. This requires a notion of projections.
Suppose we have a function E of n binary variables. If
we fixm of these variables, then we get a new function E0 of
nm binary variables; we will call this function a projection
of E. The notation for projections is as follows:
Definition 5.1. Let Eðx1; . . . ; xnÞ be a function of n binary
variables and let I, J be a disjoint partition of the set of indices
f1; . . . ; ng: I ¼ fið1Þ; . . . ; iðmÞg, J ¼ fjð1Þ; . . . ; jðnmÞg.
Let ið1Þ; . . . ; iðmÞ be binary constants. A projection E
0 ¼
E½xið1Þ ¼ ið1Þ; . . . ; xiðmÞ ¼ iðmÞ is a function of nm
variables defined by
E0ðxjð1Þ; . . . ; xjðnmÞÞ ¼ Eðx1; . . . ; xnÞ;
where xi ¼ i for i 2 I. We say that we fix the variables
xið1Þ, . . . , xiðmÞ.
Now, we can give a generalized definition of regularity.
Definition 5.2.
. All functions of one variable are regular.
. A function E of two variables is called regular if
Eð0; 0Þ þEð1; 1Þ  Eð0; 1Þ þEð1; 0Þ.
. A function E of more than two variables is called
regular if all projections of E of two variables are
regular.
For the class F 2, this definition is equivalent to the previous
one. A proof of this fact is given in Section 5.3.
Now, we are ready to formulate our main theorem forF 3.
Theorem 5.3 (F 3 Theorem). Let E be a function of n binary
variables from F 3, i.e.,
Eðx1; . . . ; xnÞ ¼
X
i
EiðxiÞ þ
X
i<j
Ei;jðxi; xjÞ
þ
X
i<j<k
Ei;j;kðxi; xj; xkÞ:
ð8Þ
Then, E is graph-representable if and only if E is regular.
152 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 26, NO. 2, FEBRUARY 2004
TABLE 3
TABLE 4
TABLE 5
5.1 Graph Construction for F 3
Consider a regular function E of the form given in (8). The
regularity ofE doesnotnecessarily imply that each term in (8)
is regular. However, wewill give an algorithm for converting
any regular function in F 3 to the form (8) where each term is
regular (see the regrouping theorem in the next section).Note
that this was not necessary for the class F 2 since, for any
representation of a regular function in the form (6), each term
in the sum is regular.
Here, we will give graph construction for a regular
function E of the form as in the F 3 theorem assuming that
each term of E is regular. The graph will contain
nþ 2 vertices: V ¼ fs; t; v1; . . . ; vng as well as some addi-
tional vertices described below. Each nonterminal vertex vi
will encode the binary variable xi. For each term of E, we
will add one or more edges and, possibly, an additional
(unique) vertex that we describe next. Again, our construc-
tion is justified by the additivity theorem given in the
Appendix.
Terms depending on one and two variables were
considered in the previous section, so we will concentrate
on a term Ei;j;k depending on three variables xi, xj, xk. It
is convenient to represent it in Table 6.
Let us denote P ¼ ðAþDþ F þGÞ  ðBþ C þ E þHÞ.
We consider two cases:
Case 1.P >¼ 0.Ei;j;k can be rewritten as shown in Table 7,
where P1 ¼ F B, P2 ¼ G E, P3 ¼ D C, P23 ¼ Bþ C 
A D, P31 ¼ BþE A F , P12 ¼ C þ E AG. Ei;j;k is
regular, therefore, by considering projections Ei;j;k½x1 ¼ 0,
Ei;j;k½x2 ¼ 0, Ei;j;k½x3 ¼ 0, we conclude that P23, P31, P12 are
nonnegative.
Thefirst termisaconstant function, sowedon’tneedtoadd
any edges for it. The next three terms depend only on one
variable (xi, xj, xk, respectively), so we can use the construc-
tion given in the previous section. The next three terms
depend on two variables; the nonnegativity of P23, P31, P12
implies that they are all regular. Therefore, we can again use
the construction of the previous section. (Three edges will be
added: ðvj; vkÞ, ðvk; viÞ, ðvi; vjÞ with weights P23, P31, P12,
respectively).
To represent the last term, we will add an auxiliary vertex
uijk andfouredges ðvi; uijkÞ, ðvj; uijkÞ, ðvk; uijkÞ, ðuijk; tÞwith the
weight P . This is shown in Fig. 3a. Let us prove these four
edges exactly represent the function shown in Table 8. If
xi ¼ xj ¼ xk ¼ 1, then the cost of the minimum cut is 0 (the
minimum cut is S ¼ fsg, T ¼ fvi; vj; vk; uijk; tg. Suppose at
least one of the variables xi, xj, xk is 0; without loss of
generality, we can assume that xi ¼ 0, i.e., vi 2 S. If uijk 2 S,
then the edge ðuijk; tÞ is cut; if uijk 2 T , the edge ðvi; uijkÞ is cut
yielding the cost P . Hence, the cost of the minimum cut is at
leastP . However, ifuijk 2 S, the cost of the cut is exactlyP , no
matterwhere theverticesvi,vj,vk are.Therefore, thecostof the
minimumcutwill be 0 if xi ¼ xj ¼ xk ¼ 1 andP otherwise, as
desired.
Case 2. P < 0. This case is similar to the Case 1. Ei;j;k can
be rewritten as shown in Table 9, where P1 ¼ C G,
P2 ¼ BD, P3 ¼ E  F , P32 ¼ F þGE H, P13 ¼ Dþ
G C H, P21 ¼ Dþ F BH. By considering projec-
tions Ei;j;k½x1 ¼ 1, Ei;j;k½x2 ¼ 1, Ei;j;k½x3 ¼ 1, we conclude
that P32, P13, P21 are nonnegative.
As in theprevious case, all terms except the last are regular
and depend on at most two variables, so we can use the
construction of the previous section. We will have, for
example, edges ðvk; vjÞ, ðvi; vkÞ, ðvj; viÞ with weights P32, P13,
P21, respectively.
To represent the last term, we will add an auxiliary
vertex uijk and four edges ðuijk; viÞ, ðuijk; vjÞ, ðuijk; vkÞ,
ðs; uijkÞ with the weight P . This is shown in Fig. 3b.
KOLMOGOROV AND ZABIH: WHAT ENERGY FUNCTIONS CAN BE MINIMIZED VIA GRAPH CUTS? 153
TABLE 6
Fig. 3. Graphs for functions in F 3. (a) Edge weights are all P . (b) Edge
weights are all P .
TABLE 7
TABLE 8
Note that, in both cases, we added an auxiliary vertex
uijk. It is easy to see that this is necessary since graphs
without auxiliary vertices can only represent functions in
F 2. Each edge represents a function of at most two
variables, so the whole graph represents a function that is
a sum of terms of at most two variables.
5.2 Constructive Proof of the Regrouping Theorem
Now, we will show how to convert a regular function in F 3
to the form given in (8) where each term is regular.
Theorem 5.4 (regrouping). Any regular function E from the
class F 3 can be rewritten as a sum of terms such that each term
is regular and depends on at most three variables.
We will assume E given as
Eðx1; . . . ; xnÞ ¼
X
i<j<k
Ei;j;kðxi; xj; xkÞ;
where i, j, k are indices from the set f1; . . . ; ng (we omitted
terms involving functions of one and two variables since
they can be viewed as functions of three variables).
We begin by giving a definition.
Definition 5.5. The functional  will be a mapping from the set
of all functions (of binary variables) to the set of real numbers
which is defined as follows. For a function Eðx1; . . . ; xnÞ
ðEÞ ¼
X
x12f0;1g;...;xn2f0;1g
ni¼1ð1Þ
xi
 
Eðx1; . . . ; xnÞ:
For example, for a function E of two variables ðEÞ ¼
Eð0; 0Þ  Eð0; 1Þ  Eð1; 0Þ þEð1; 1Þ. Note that a function E
of two variables is regular if and only if ðEÞ  0.
It is trivial to check the following lemma.
Lemma 5.6. The functional  has the following properties.
.  is linear, i.e., for a scalar c and two functions E0,
E00 of n variables ðE0 þ E00Þ ¼ ðE0Þ þ ðE00Þ and
ðc  E0Þ ¼ c  ðE0Þ.
. If E is a function of n variables that does not depend on
at least one of the variables, then ðEÞ ¼ 0.
We will prove the theorem using the following lemma
and a trivial induction argument.
Definition 5.7. Let Ei;j;k be a function of three variables. The
functional NðEi;j;kÞ is defined as the number of projections of
two variables of Ei;j;k with positive values of the functional .
Note that NðEi;j;kÞ ¼ 0 exactly when Ei;j;k is regular.
Lemma 5.8. Suppose the function E of n variables can be
written as
Eðx1; . . . ; xnÞ ¼
X
i<j<k
Ei;j;kðxi; xj; xkÞ;
where some of the terms are not regular. Then, it can be
written as
Eðx1; . . . ; xnÞ ¼
X
i<j<k
~Ei;j;kðxi; xj; xkÞ;
where
X
i<j<k
N ~Ei;j;k
 
<
X
i<j<k
N Ei;j;k
 
:
Proof. For simplicity of notation, let us assume that the
term E1;2;3 is not regular and ðE1;2;3½x3 ¼ 0Þ > 0 or
ðE1;2;3½x3 ¼ 1Þ > 0 (we can ensure this by renaming
indices). Let
Ck ¼ max
k2f0;1g
ðE1;2;k½xk ¼ kÞ k 2 f4; . . . ; ng
C3 ¼ 
Xn
k¼4
Ck:
Now, we will modify the terms E1;2;3, . . . , E1;2;n as
follows:
~E1;2;k  E1;2;k R½Ck k 2 f3; . . . ; ng;
where R½C is the function of two variables x1 and x2
defined by Table 10 (other terms are unchanged:
~Ei;j;k  Ei;j;k, ði; jÞ 6¼ ð1; 2Þ). We have
Eðx1; . . . ; xnÞ ¼
X
i<j<k
~Ei;j;kðxi; xj; xkÞ
since
Pn
k¼3 Ck ¼ 0 and
Pn
k¼3 R½Ck  0.
If we considerR½C as a function of n variables and take
a projection of two variables where the two variables that
are not fixed are xi and xj (i < j), then the functional will
be C, if ði; jÞ ¼ ð1; 2Þ, and 0 otherwise (since, in the latter
case, a projection actually depends on, at most, one
variable). Hence, the only projections of two variables that
could have changed their value of the functional  are
~E1;2;k½x3 ¼ 3; . . . ; xn ¼ n,k 2 f3; . . . ; ng, ifwe treat ~E1;2;k
as functions of n variables, or ~E1;2;k½xk ¼ k, if we treat
~E1;2;k as functions of three variables.
154 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 26, NO. 2, FEBRUARY 2004
TABLE 9
TABLE 10
First, let us consider terms with k 2 f4; . . . ; ng. We
have ðE1;2;k½xk ¼ kÞ  Ck, thus
ð ~E1;2;k½xk ¼ kÞ ¼ðE1;2;k½xk ¼ kÞ
 ðR½Ck½xk ¼ kÞ  Ck  Ck ¼ 0:
Therefore, we did not introduce any nonregular projec-
tions for these terms.
Now, let us consider the term ð ~E1;2;3½x3 ¼ 3Þ. We
can write
ð ~E1;2;3½x3 ¼ 3Þ ¼ ðE1;2;3½x3 ¼ 3Þ  ðR½C3½x3 ¼ 3Þ
¼ ðE1;2;3½x3 ¼ 3Þ  ð
Xn
k¼4
CkÞ ¼
Xn
k¼3
ðE1;2;k½xk ¼ kÞ;
where k ¼ argmax2f0;1g ðE1;2;k½xk ¼ Þ, k 2 f4; . . . ; ng.
The last expression is just ðE½x3 ¼ 3; . . . ; xn ¼ nÞ and
is nonpositive since E is regular by assumption. Hence,
values ð ~E1;2;3½x3 ¼ 0Þ and ð ~E1;2;3½x3 ¼ 1Þ are both
nonpositive and, therefore, the number of nonregular
projections has decreased. tu
The complexity of a single step is OðnÞ since it involves
modifying at most n terms. Therefore, the complexity of the
whole algorithm is OðmnÞ, where m is the number of terms
in (8) since, in the beginning,
P
i<j<k NðEi;j;kÞ is at most 6m
and each step decreases it by at least one.
5.3 The Two Definitions of Regularity
Are Equivalent
We now prove that the definition of regularity 5.2 is
equivalent to the previous definition of regularity for the
class F 2. Note that the latter one is formulated not only as a
property of the function E but also as a property of its
representation as a sum in (6). We will show equivalence for
an arbitrary representation, which will imply that the
definition of regularity for the class F 2 depends only on E
but not on the representation.
Let us consider a graph-representable function E from
the class F 2:
Eðx1; . . . ; xnÞ ¼
X
i
EiðxiÞ þ
X
i<j
Ei;jðxi; xjÞ:
Consider a projection where the two variables that are not
fixed are xi and xj. By Lemma 5.6, the value of the
functional  of this projection is equal to ðEi;jÞ (all other
terms yield zero). Therefore, this projection is regular if and
only if Ei;jð0; 0Þ þ Ei;jð1; 1Þ  Ei;jð0; 1Þ þ Ei;jð1; 0Þ, which
means that the two definitions are equivalent.
5.4 Example: Multicamera Scene Reconstruction
We now show an example of function from the class F 3 that
is potentially useful in vision. Consider the multicamera
scene reconstruction problem described earlier. Similar to
the data term depending on pairs of pixels, we can define a
term depending on triples of pixels.6 Let I3 be a set of triples
of “nearby” 3D points. These points will come from three
different cameras, but they will share the same depth (i.e.,
the points are of the form hp; fqi; hq; fqi; hr; fri, where fp ¼
fq ¼ fr and p; q; r are pixels from different cameras). The
new data term will be
X
fhp;li;hq;li;hr;li2I3g
Dp;q;r;lðfp; fq; frÞ; ð9Þ
where
Dp;q;r;lðfp; fq; frÞ ¼ Dðp; q; rÞ  T ½fp ¼ fq ¼ fr ¼ l:
This term can be motivated as follows: If three pixels have
similar intensities, then it ismore likely that they see the same
scene element than if only two pixels have similar intensities.
We now show the expansion move algorithm can be
used for minimizing this new term, i.e., that the resulting
energy function is regular. The proof proceeds similarly to
the proof in Section 4.2.2. Consider a single term
Dðp; q; rÞ  T ½fp ¼ fq ¼ fr ¼ l, which imposes a penalty if p,
q, and r have the label l. We will have three binary variables
which are 0 if the associated pixel keeps its original label in
f and 1 if it acquires the new label .
Again, there are two cases that must be analyzed
separately: l 6¼  and l ¼ . Consider the case l 6¼ . If at least
one of labels fp; fq; fr is not l, then the term is zero for any
valuesof binaryvariables. If fp ¼ fq ¼ fr ¼ l, then thepenalty
is only imposed when the binary variables are all 0.
Graphically, we show this in Table 11. Now, consider the
case l ¼ . If at least one of the labels fp; fq; fr is  then the
penalty imposed is independent of one of the binary
variables; therefore, this case reduces to a data term
dependingon twovariables,whichhasbeenanalyzed earlier.
Suppose that all labels fp; fq; fr are different from. Then, the
penalty is only imposed when the binary variables are all 1,
which is written graphically in Table 12. We get the result
similar to the previous one: The energy function is regular if
Dðp; q; rÞ is nonpositive.
6 MORE GENERAL CLASSES OF ENERGY
FUNCTIONS
Finally, we give a necessary condition for graph represent-
ability for arbitrary functions of binary variables.
KOLMOGOROV AND ZABIH: WHAT ENERGY FUNCTIONS CAN BE MINIMIZED VIA GRAPH CUTS? 155
TABLE 11 TABLE 12
6. We thank Rick Szeliski for discussions that have led to the
development of this term.
Theorem 6.1 (regularity). Let E be a function of binary
variables. If E is not regular, thenE is not graph-representable.
This theorem will imply the corresponding directions of
the F 2 and F 3 theorems (Theorems 4.1 and 5.3).
Definition 6.2. Let G ¼ ðV; EÞ be a graph, v1; . . . ; vk be a subset
of vertices V, and 1; . . . ; k be binary constants whose values
are from f0; 1g. We will define the graph G½x1 ¼ 1; . . . ; xk ¼
k as follows: Its vertices will be the same as in G and its edges
will be all edges of G plus additional edges corresponding to
vertices v1; . . . ; vk: for a vertex vi, we add the edge ðs; viÞ if
i ¼ 0 or ðvi; tÞ if i ¼ 1, with an infinite capacity.
It should be obvious that these edges enforce con-
straints fðv1Þ ¼ 1, . . . , fðvkÞ ¼ k in the minimum cut on
G½x1 ¼ 1; . . . ; xk ¼ k, i.e., if i ¼ 0, then vi 2 S and if
i ¼ 1, then vi 2 T . (If, for example, i ¼ 0 and vi 2 T ,
then the edge ðs; viÞ must be cut yielding an infinite cost,
so it would not the minimum cut.)
Now, we can give a definition of graph representability
which is equivalent to Definition 3.1. This new definition
will be more convenient for the proof.
Definition 6.3. We say that the function E of n binary variables
is exactly represented by the graph G ¼ ðV; EÞ and the set
V0  V if for any configuration 1; . . . ; n the cost of the
minimum cut on G½x1 ¼ 1; . . . ; xk ¼ k is Eð1; . . . ; nÞ.
Lemma 6.4. Any projection of a graph-representable function is
graph-representable.
Proof. LetE be a graph-representable function of n variables
and the graph G ¼ ðV; EÞ and the set V0 represents E.
Suppose that we fix variables xið1Þ; . . . ; xiðmÞ. It is straight-
forward to check that the graph G½xið1Þ ¼ ið1Þ; . . . ; xiðmÞ ¼
iðmÞ and the set V00 ¼ V0  fvið1Þ; . . . ; viðmÞg represents the
function E0 ¼ E½xið1Þ ¼ ið1Þ; . . . ; xiðmÞ ¼ iðmÞ. tu
This lemma implies that it suffices to prove Theorem 3.1
only for energy functions of two variables.
Let Eðx1; x2Þ be a graph-representable function of two
variables. Let usprove that E is regular, i.e., thatA  0,where
A¼ ð EÞ¼ Eð0; 0Þþ Eð1; 1Þ  Eð0; 1Þ Eð1; 0Þ. Suppose this
is not true:A > 0.
In Table 13, all the functions on the right side are graph-
representable, therefore, by the additivity theorem (see the
Appendix), the function E is graph-representable as well,
where, in Table 14, consider a graph G and a set V0 ¼ fv1; v2g
representingE. Thismeans that there isa constantK such that
G, V0 exactly representE0ðx1; x2Þ ¼ Eðx1; x2Þ þK (Table 15).
The cost of theminimum s-t-cut onG isK (since this cost is
just theminimumentry inthetableforE0);hence,K  0.Thus,
thevalueofthemaximumflowfroms to t inG isK.LetG0bethe
residual graph obtained from G after pushing the flowK. Let
E0ðx1; x2Þ be the function exactly represented by G0;V0.
By the definition of graph representability, E0ð1; 2Þ is
equal to the value of the minimum cut (or maximum flow)
on the graph G½x1 ¼ 1; x2 ¼ 2. The following sequence of
operations shows one possible way to push the maximum
flow through this graph.
. First,we take theoriginalgraphGandpush the flowK;
thenweget the residualgraphG0. (This is equivalent to
pushing flow through G½x1 ¼ 1; x2 ¼ 2, where we
donotuseedges corresponding to the constraintsx1 ¼
1 and x2 ¼ 2).
. Then, we add edges corresponding to these con-
straints; we get the graph G0½x1 ¼ 1; x2 ¼ 2.
. Finally, we push the maximum flow possible
through the graph G0½x1 ¼ 1; x2 ¼ 2; the amount
of this flow is E0ð1; 2Þ according to the definition
of graph representability.
The total amount of flow pushed during all steps is
K þ E0ð1; 2Þ; thus,
E0ð1; 2Þ ¼ K þ E0ð1; 2Þ
or
Eð1; 2Þ ¼ E0ð1; 2Þ:
We have proven that E is exactly represented by G0, V0.
The value of the minimum cut/maximum flow on G0 is 0
(it is the minimum entry in the table for E); thus, there is no
augmenting path from s to t in G0. However, if we add the
edges ðv1; tÞ and ðv2; tÞ, then there will be an augmenting
path from s to t in G0½x1 ¼ 1; x2 ¼ 2 since Eð1; 1Þ ¼ A > 0.
Hence, this augmenting path will contain at least one of
these edges and, therefore, either v1 or v2 will be in the path.
Let P be the part of this path going from the source until v1
or v2 is first encountered. Without loss of generality, we can
assume that it will be v1. Thus, P is an augmenting path
from s to v1 which does not contain edges that we added,
namely, ðv1; tÞ and ðv2; tÞ.
Finally, let us consider the graph G0½x1 ¼ 1; x2 ¼ 0 which
is obtained from G0 by adding edges ðv1; tÞ and ðs; v2Þ with
infinite capacities. There is an augmenting path fP; ðv1; tÞg
from the source to the sink in this graph; hence, the
minimum cut/maximum flow on it is greater than zero or
Eð1; 0Þ > 0. We get a contradiction.
156 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 26, NO. 2, FEBRUARY 2004
TABLE 13
TABLE 14 TABLE 15
7 RELATED WORK
There is an interesting relationship between regular func-
tions and submodular functions.7 Let S be a finite set and
g : 2S ! R be a real-valued function defined on the set of all
subsets of S. g is called submodular if for any X;Y  S
gðXÞ þ gðY Þ  gðX [ Y Þ þ gðX \ Y Þ:
See [15], for example, for a discussion of submodular
functions. An equivalent definition of submodular functions
is that g is called submodular if, for any X  S and
i; j 2 S X,
gðX [ fjgÞ  gðXÞ  gðX [ fi; jgÞ  gðX [ figÞ:
Obviously, functions of subsetsX of S ¼ f1; . . . ; ng can be
viewed as functions of n binary variables ðx1; . . . ; xnÞ; the
indicator variable xi is 1 if i is included inX and 0 otherwise.
Then, it is easy to see that the second definition of
submodularity reduces to the definition of regularity. Thus,
submodular functions and regular functions are essentially
the same. We use different names to emphasize a technical
distinction between them: Submodular functions are func-
tions of subsets of S while regular functions are functions of
binary variables. From our experience, the second point of
view is much more convenient for vision applications.
Submodular functions have received significant attention
in the combinatorial optimization literature. A remarkable
fact about submodular functions is that they can be
minimized in polynomial time [19], [23], [38]. A function g
is assumed to be given as a value oracle, i.e., a “black box”
which, for any input subset X returns the value gðXÞ.
Unfortunately, algorithms for minimizing arbitrary sub-
modular functions are extremely slow. For example, the
algorithm of [23] runs in Oðn5 minflognM;n2 logngÞ time,
where M is an upper bound on jgðXÞj among X 2 2S . Thus,
our work can be viewed as identifying an important
subclass of submodular functions for which much faster
algorithm can be used.
In addition, a relation between submodular functions and
certain graph-representable functions called cut functions is
already known. Using our terminology, cut functions can be
defined as functions that can be represented by a graph
without the source and the sink and without auxiliary
vertices. It is well-known that cut functions are submodular.
Cunningham [11] characterizes cut functions and gives a
general-purpose graph construction for them.
It can be shown that the set of cut functions is a strict
subset of F 2. We allow a more general graph construction;
as a result, we can minimize a larger class of functions,
namely, regular functions in F 3.
8 SUMMARY OF GRAPH CONSTRUCTIONS
Wenow summarize the graph constructions used for regular
functions. Software can be downloaded from http://
www.cs.cornell.edu/~rdz/graphcuts.html that takes an en-
ergy function as input and automatically constructs the
appropriate graph, then minimizes the energy.
Recall that, for a function Eðx1; . . . ; xnÞ, we define
ðEÞ ¼
X
x12f0;1g;...;xn2f0;1g
ni¼1ð1Þ
xi
 
Eðx1; . . . ; xnÞ:
The notation edgeðv; cÞ will mean that we add an edge
ðs; vÞ with the weight c if c > 0 or an edge ðv; tÞ with the
weight c if c < 0.
8.1 Regular Functions of One Binary Variable
Recall that all functions of one variable are regular. For a
function Eðx1Þ, we construct a graph G with three vertices
V ¼ fv1; s; tg. There is a single edge edgeðv1; Eð1Þ  Eð0ÞÞ.
8.2 Regular Functions of Two Binary Variables
We now show how to construct a graph G for a regular
function Eðx1; x2Þ of two variables. It will contain four
vertices: V ¼ fv1; v2; s; tg. The edges E are given below:
. edgeðv1; Eð1; 0Þ Eð0; 0ÞÞ;
. edgeðv2; Eð1; 1Þ Eð1; 0ÞÞ;
. ðv1; v2Þ with the weight ðEÞ.
8.3 Regular Functions of Three Binary Vvariables
We next show how to construct a graph G for a regular
function Eðx1; x2; x3Þ of three variables. It will contain five
vertices: V ¼ fv1; v2; v3; u; s; tg. If ðEÞ  0, then the edges are
. edgeðv1; Eð1; 0; 1Þ  Eð0; 0; 1ÞÞ;
. edgeðv2; Eð1; 1; 0Þ  Eð1; 0; 0ÞÞ;
. edgeðv3; Eð0; 1; 1Þ  Eð0; 1; 0ÞÞ;
. ðv2; v3Þ with the weight ðE½x1 ¼ 0Þ;
. ðv3; v1Þ with the weight ðE½x2 ¼ 0Þ;
. ðv1; v2Þ with the weight ðE½x3 ¼ 0Þ;
. ðv1; uÞ, ðv2; uÞ, ðv3; uÞ, ðu; tÞ with the weight ðEÞ.
If ðEÞ < 0, then the edges are
. edgeðv1; Eð1; 1; 0Þ  Eð0; 1; 0ÞÞ;
. edgeðv2; Eð0; 1; 1Þ  Eð0; 0; 1ÞÞ;
. edgeðv3; Eð1; 0; 1Þ  Eð1; 0; 0ÞÞ;
. ðv3; v2Þ with the weight ðE½x1 ¼ 1Þ;
. ðv1; v3Þ with the weight ðE½x2 ¼ 1Þ;
. ðv2; v1Þ with the weight ðE½x3 ¼ 1Þ;
. ðu; v1Þ, ðu; v2Þ, ðu; v3Þ, ðs; uÞ with the weight ðEÞ.
APPENDIX A
PROOF OF THE NP-HARDNESS THEOREM
We now give a proof of the NP-hardness theorem
(Theorem 4.2), which shows that, without the regularity
constraint, it is intractable to minimize energy functions
in F 2.
Proof. Adding functions of one variable does not change the
class of functions that we are considering. Thus, we can
assumewithout loss of generality thatE2 has the form that
is shown in Table 16. (We can transform an arbitrary
function of two variables to this form as follows: We
subtract a constant fromthe first row tomake theupper left
element zero, then we subtract a constant from the second
row to make the bottom left element zero, and, finally, we
subtract a constant from the second column to make the
upper right element zero.)
These transformations preserve the functional , so E2
is nonregular, which means that A > 0.
KOLMOGOROV AND ZABIH: WHAT ENERGY FUNCTIONS CAN BE MINIMIZED VIA GRAPH CUTS? 157
7. We thank Yuri Boykov and Howard Karloff for pointing this out.
We will prove the theorem by reducing the maximum
independent set problem, which is known to be NP-hard,
to our energy minimization problem.
Let an undirected graph G ¼ ðV; EÞ be the input to the
maximumindependentsetproblem.AsubsetU  V is said
to be independent if, for any two vertices u; v 2 U, the edge
ðu; vÞ is not in E. The goal is to find an independent subset
U	  V ofmaximum cardinality. We construct an instance
of the energyminimization problem as follows: There will
be n ¼ jVj binary variables x1; . . . ; xn corresponding to the
vertices v1; . . . ; vn of V. Let us consider the energy
Eðx1; . . . ; xnÞ ¼
X
i
EiðxiÞ þ
X
ði;jÞ2N
E2ðxi; xjÞ;
where EiðxiÞ ¼  A2n  xi and N ¼ fði; jÞ j ðvi; vjÞ 2 Eg.
There is a one-to-one correspondence between all
configurations ðx1; . . . ; xnÞ and subsets U  V: A vertex vi
is in U if and only if xi ¼ 1. Moreover, the first term of
Eðx1; . . . ; xnÞ is  A2n times the cardinality of U (which
cannot be less than  A2 ) and the second term is 0 if U is
independent and at least A otherwise. Thus, minimizing
the energy yields the independent subset of maximum
cardinality. tu
APPENDIX B
THE ADDITIVITY THEOREM
We now prove the additivity theorem, which plays an
important role in our constructions.
Theorem (additivity). The sum of two graph-representable
functions is graph-representable.
It is important to note that the proof of this theorem is
constructive. The construction has a particularly simple
form if the graphs representing the two functions are
defined on the same set of vertices (i.e., they differ only in
their edge weights). In this case, by simply adding the edge
weights together, we obtain a graph that represents the sum
of the two functions. If one of the graphs has no edge
between two vertices, we can add an edge with weight 0.
Proof. Let us assume for simplicity of notation that E0 and
E00 are functions of all n variables: E0 ¼ E0ðx1; . . . ; xnÞ,
E00 ¼ E00ðx1; . . . ; xnÞ. By the definition of graph repre-
sentability, there exist constants K0, K00, graphs
G0 ¼ ðV0; E0Þ, G00 ¼ ðV00; E00Þ, and the set V0 ¼ fv1; . . . ; vng,
V0  V0  fs; tg, V0  V00  fs; tg such that E0 þK0 is
exactly represented by G0, V0 and E00 þK00 is exactly
represented by G00, V0. We can assume that the only
common vertices of G0 and G00 are V0 [ fs; tg. Let us
construct the graph G ¼ ðV; EÞ as the combined graph of
G0 and G00: V ¼ V0 [ V00, E ¼ E0 [ E00.
Let ~E be the function that G, V0 exactly represents. Let
us prove that ~E  E þ ðK0 þK00Þ (and, therefore, E is
graph-representable).
Consider a configuration x1; . . . ; xn. Let C
0 ¼ S0; T 0 be
the cut on G0 with the smallest cost among all cuts for
which vi 2 S0 if xi ¼ 0 and vi 2 T 0 if xi ¼ 1 (1  i  n).
According to the definition of graph representability,
E0ðx1; . . . ; xnÞ þK0 ¼
X
u2S0;v2T 0;ðu;vÞ2E0
cðu; vÞ:
Let C00 ¼ S00; T 00 be the cut on G00 with the smallest cost
among all cuts for which vi 2 S00 if xi ¼ 0, and vi 2 T 00 if
xi ¼ 1 (1  i  n). Similarly,
E00ðx1; . . . ; xnÞ þK00 ¼
X
u2S0 0;v2T 0 0;ðu;vÞ2E00
cðu; vÞ:
Let S ¼ S0 [ S00, T ¼ T 0 [ T 00. It is easy to check that
C ¼ S; T is a cut on G. Thus,
~Eðx1; . . . ; xnÞ 
X
u2S;v2T;ðu;vÞ2E
cðu; vÞ
¼
X
u2S0;v2T 0;ðu;vÞ2E0
cðu; vÞ þ
X
u2S0 0;v2T 0 0;ðu;vÞ2E00
cðu; vÞ
¼ ðE0ðx1; . . . ; xnÞ þK0Þ þ ðE00ðx1; . . . ; xnÞ þK00Þ
¼ Eðx1; . . . ; xnÞ þ ðK0 þK00Þ:
Now, let C ¼ S; T be the cut on Gwith the smallest cost
amongall cuts forwhich vi 2 S ifxi ¼ 0 and vi 2 T ifxi ¼ 1
(1  i  n) and let S0 ¼ S \ V0, T 0 ¼ T \ V0, S00 ¼ S \ V00,
T 00 ¼ T \ V0. It is easy to see that C0 ¼ S0; T 0, and C00 ¼
S00; T 00 are cuts on G0 and G00, respectively. According to the
definition of graph representability,
Eðx1; . . . ; xnÞ þ ðK0 þK00Þ ¼ ðE0ðx1; . . . ; xnÞ þK0Þ
þ ðE00ðx1; . . . ; xnÞ þK00Þ 
X
u2S0;v2T 0;ðu;vÞ2E0
cðu; vÞ
þ
X
u2S0 0;v2T 0 0;ðu;vÞ2E00
cðu; vÞ
¼
X
u2S;v2T;ðu;vÞ2E0
cðu; vÞ ¼ ~Eðx1; . . . ; xnÞ:
ut
ACKNOWLEDGMENTS
The authors are grateful to Olga Veksler and Yuri Boykov
for their careful reading of this paper and for valuable
comments that greatly improved its readability. They
would like to thank Jon Kleinberg and Eva Tardos for
helping them understand the relationship between their
work and submodular function minimization. They would
also like to thank Ian Jermyn and several anonymous
reviewers for helping them clarify the paper’s presentation.
This research was supported by US National Science
Foundation grants IIS-9900115 and CCR-0113371 and by a
grant from Microsoft Research. A preliminary version of
this paper appeared in the Proceedings of the European
Conference on Computer Vision, May 2002.
158 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 26, NO. 2, FEBRUARY 2004
TABLE 16
REFERENCES
[1] R.K. Ahuja, T.L. Magnanti, and J.B. Orlin, Network Flows: Theory,
Algorithms, and Applications. Prentice Hall, 1993.
[2] A. Amini, T. Weymouth, and R. Jain, “Using Dynamic Program-
ming for Solving Variational Problems in Vision,” IEEE Trans.
Pattern Analysis and Machine Intelligence, vol. 12, no. 9, pp. 855-867,
Sept. 1990.
[3] S. Barnard, “Stochastic Stereo Matching Over Scale,” Int’l J.
Computer Vision, vol. 3, no. 1, pp. 17-32, 1989.
[4] S. Birchfield and C. Tomasi, “Multiway Cut for Stereo and Motion
with Slanted Surfaces,” Proc. Int’l Conf. Computer Vision, pp. 489-
495, 1999.
[5] Y. Boykov and M.-P. Jolly, “Interactive Organ Segmentation Using
Graph Cuts,” Proc. Medical Image Computing and Computer-Assisted
Intervention, pp. 276-286, 2000.
[6] Y. Boykov and M.-P. Jolly, “Interactive Graph Cuts for Optimal
Boundary and Region Segmentation of Objects in N-D Images,”
Proc. Int’l Conf. Computer Vision, pp. 105-112, 2001.
[7] Y. Boykov and V. Kolmogorov, “An Experimental Comparison of
Min-Cut/Max-Flow Algorithms for Energy Minimization in
Computer Vision,” Proc. Int’l Workshop Energy Minimization
Methods in Computer Vision and Pattern Recognition, Lecture Notes
in Computer Science, pp. 359-374, Springer-Verlag, Sept. 2001.
[8] Y. Boykov and V. Kolmogorov, “Computing Geodesics and
Minimal Surfaces via Graph Cuts,” Proc. Int’l Conf. Computer
Vision, pp. 26-33, 2003.
[9] Y. Boykov, O. Veksler, and R. Zabih, “Markov Random Fields
with Efficient Approximations,” Proc. IEEE Conf. Computer Vision
and Pattern Recognition, pp. 648-655, 1998.
[10] Y. Boykov, O. Veksler, and R. Zabih, “Fast Approximate Energy
Minimization via Graph Cuts,” Proc. IEEE Trans. Pattern Analysis
and Machine Intelligence, vol. 23, no. 11, pp. 1222-1239, Nov. 2001.
[11] W.H. Cunningham, “Minimum Cuts, Modular Functions, and
Matroid Polyhedra,” Networks, vol. 15, pp. 205-215, 1985.
[12] E. Dahlhaus, D.S. Johnson, C.H. Papadimitriou, P.D. Seymour,
and M. Yannakakis, “The Complexity of Multiway Cuts,” Proc.
ACM Symp. Theory of Computing, pp. 241-251, 1992.
[13] J. Dias and J. Leitao, “The ZM Algorithm: A Method for
Interferometric Image Reconstruction in SAR/SAS” IEEE Trans.
Image Processing, vol. 11, no. 4, pp. 408-422, Apr. 2002.
[14] L. Ford and D. Fulkerson, Flows in Networks. Princeton Univ.
Press, 1962.
[15] S. Fujishige, “ Submodular Functions and Optimization,” vol. 47,
Annals of Discrete Math., North Holland, 1990.
[16] S. Geman and D. Geman, “Stochastic Relaxation, Gibbs Distribu-
tions, and the Bayesian Restoration of Images,” IEEE Trans. Pattern
Analysis and Machine Intelligence, vol. 6, pp. 721-741, 1984.
[17] A. Goldberg and R. Tarjan, “A New Approach to the Maximum
Flow Problem,” J. ACM, vol. 35, no. 4, pp. 921-940, Oct. 1988.
[18] D. Greig, B. Porteous, and A. Seheult, “Exact Maximum
A Posteriori Estimation for Binary Images,” J. Royal Statistical
Soc., Series B, vol. 51, no. 2, pp. 271-279, 1989.
[19] M. Grötschel, L. Lovasz, and A. Schrijver, Geometric Algorithms and
Combinatorial Optimization. Springer-Verlag, 1988.
[20] H. Ishikawa and D. Geiger, “Occlusions, Discontinuities, and
Epipolar Lines in Stereo,” Proc. European Conf. Computer Vision,
pp. 232-248, 1998.
[21] H. Ishikawa and D. Geiger, “Segmentation by Grouping Junc-
tions,” Proc. IEEE Conf. Computer Vision and Pattern Recognition,
pp. 125-131, 1998.
[22] H. Ishikawa, “Exact Optimization for Markov Random Fields with
Convex Priors,” IEEE Trans. Pattern Analysis and Machine
Intelligence, vol. 25, no. 10, pp. 1333-1336, Oct. 2003.
[23] S. Iwata, L. Fleischer, and S. Fujishige, “A Combinatorial, Strongly
Polynomial Algorithm for Minimizing Submodular Functions,”
J. ACM, vol. 48, no. 4, pp. 761-777, July 2001.
[24] J. Kim, V. Kolmogorov, and R. Zabih, “Visual Correspondence
Using Energy Minimization and Mutual Information,” Proc. Int’l
Conf. Computer Vision, pp. 1033-1040, 2003.
[25] J. Kim and R. Zabih, “Automatic Segmentation of Contrast-
Enhanced Image Sequences,” Proc. Int’l Conf. Computer Vision,
pp. 502-509, 2003.
[26] J. Kim, J. Fisher, A. Tsai, C. Wible, A. Willsky, and W. Wells,
“Incorporating Spatial Priors into an Information Theoretic
Approach for FMRI Data Analysis,” Proc. Medical Image Computing
and Computer-Assisted Intervention, pp. 62-71, 2000.
[27] V. Kolmogorov and R. Zabih, “Visual Correspondence with
Occlusions Using Graph Cuts,” Proc. Int’l Conf. Computer Vision,
pp. 508-515, 2001.
[28] V. Kolmogorov and R. Zabih, “Multi-Camera Scene Reconstruc-
tion via Graph Cuts,” Proc. European Conf. Computer Vision, vol. 3,
pp. 82-96, 2002.
[29] V. Kwatra, A. Schödl, I. Essa, G. Turk, and A. Bobick, “Graphcut
Textures: Image and Video Synthesis Using Graph Cuts,” ACM
Trans. Graphics, Proc. SIGGRAPH 2003, July 2003.
[30] C.-H. Lee, D. Lee, and M. Kim, “Optimal Task Assignment in
Linear Array Networks,” IEEE Trans. Computers, vol. 41, no. 7,
pp. 877-880, July 1992.
[31] S. Li, Markov Random Field Modeling in Computer Vision. Springer-
Verlag, 1995.
[32] M.H. Lin, “Surfaces with Occlusions from Layered Stereo,” PhD
thesis, Stanford Univ., Dec. 2002.
[33] I. Milis, “Task Assignment in Distributed Systems Using Network
Flow Methods,” Proc. Combinatorics and Computer Science, Lecture
Notes in Computer Science, pp. 396-405, Springer-Verlag, 1996.
[34] T. Poggio, V. Torre, and C. Koch, “Computational Vision and
Regularization Theory,” Nature, vol. 317, pp. 314-319, 1985.
[35] S. Roy, “Stereo without Epipolar Lines: A Maximum Flow
Formulation,” Int’l J. Computer Vision, vol. 1, no. 2, pp. 1-15, 1999.
[36] S. Roy and I. Cox, “A Maximum-Flow Formulation of the
n-Camera Stereo Correspondence Problem,” Proc. Int’l Conf.
Computer Vision, 1998.
[37] D. Scharstein and R. Szeliski, “A Taxonomy and Evaluation of
Dense Two-Frame Stereo Correspondence Algorithms,” Int’l J.
Computer Vision, vol. 47, pp. 7-42, Apr. 2002.
[38] A. Schrijver, “A Combinatorial Algorithm Minimizing Submod-
ular Functions in Strongly Polynomial Time,” J. Combinatorial
Theory, vol. B 80, pp. 346-355, 2000.
[39] D. Snow, P. Viola, and R. Zabih, “Exact Voxel Occupancy with
Graph Cuts,” Proc. IEEE Conf. Computer Vision and Pattern
Recognition, pp. 345-352, 2000.
[40] H.S. Stone, “Multiprocessor Scheduling with the Aid of Network
Flow Algorithms,” IEEE Trans. Software Eng., pp. 85-93, 1977.
[41] R. Szeliski and R. Zabih, “An Experimental Comparison of Stereo
Algorithms,” Proc. Vision Algorithms: Theory and Practice, Lecture
Notes inComputer Science, B. Triggs,A. Zisserman, andR. Szeliski,
eds.,vol. 1883, pp. 1-19, Springer-Verlag, Sept. 1999.
Vladimir Kolmogorov received the MS degree
from the Moscow Institute of Physics and
Technology in applied mathematics and physics
in 1999 and the PhD degree in computer science
from Cornell University in January 2004. He is
currently a postdoctoral researcher at Microsoft
Research, Cambridge, United Kingdom. His
research interests are graph algorithms, stereo
correspondence, image segmentation, para-
meter estimation, and mutual information. Two
of his papers (written with Ramin Zabih) received a best paper award at
the European Conference on Computer Vision, 2002. He is a member of
the IEEE and the IEEE Computer Society.
Ramin Zabih attended the Massachusetts
Institute of Technology as an undergraduate,
where he received BS degrees in computer
science and mathematics and the MSc degree in
computer science. After earning the PhD degree
in computer science from Stanford University in
1994, he joined the faculty at Cornell University,
where he is currently an associate professor of
computer science. Since 2001, he has held a
joint appointment as an associate professor of
radiology at Cornell Medical School. His research interests lie in early
vision and its applications, especially in medicine. He has served on
numerous program committees, including the International Conference
on Computer Vision (ICCV) in 1999, 2001, and 2003, and the IEEE
Conference on Computer Vision and Pattern Recognition (CVPR) in
1997, 2000, 2001, and 2003. He coedited a special issue of the IEEE
Transactions on Pattern Analysis and Machine Intelligence in October
2001. He is a member of the IEEE and the IEEE Computer Society.
KOLMOGOROV AND ZABIH: WHAT ENERGY FUNCTIONS CAN BE MINIMIZED VIA GRAPH CUTS? 159

