Controlling Overload in Networks of SIP ServersVolker Hilt and Indra WidjajaBell Labs, AlcatelLucentHolmdel, NJ 07733, USABell Labs, AlcatelLucentMurray Hill, NJ 07974, USAAbstractThe Session Initiation Protocol SIP is rapidly beingadopted as the signaling protocol for establishing, modifyingand terminating multimedia sessions. With the increasing useof SIP in large deployments, it is now becoming apparent thatthe current SIP design does not easily scale up to large networksizes and SIP servers are not well equipped to handle overloadconditions. When a SIP server is operating close to or above itscapacity limit, message retransmissions by various SIP timerscan cause the network to be severely overloaded and result inan extremely low goodput. In this paper, we first provide adetailed analysis of the behavior of SIP servers under overload.We show that SIP servers are often unable to recover fromcongestion collapse once it has occurred and that overload canspread throughout a network of SIP servers. We then discussmechanisms and algorithms for controlling overload in theseservers. We found that performing overload control locally ata server provides a simple remedy for light cases of overloadhowever, it is ineffective in handling higher amounts of load.Finally, we investigate distributed overload control mechanismsfor SIP and show that they are effective in controlling overloadof SIP servers.I. INTRODUCTIONThe Session Initiation Protocol SIP 16 has been verysuccessful in recent years and has become the main signaling protocol for multimedia sessions in the Internet andIP telephony. It serves as a foundation for many of todaysInternetbased communication services including VoiceoverIP, instant messaging and presence. The SIP protocol has alsobeen adopted by 3GPP 1 as the basis for its IMS architectureand many telephony service providers are starting to use or arein the process of deploying SIPbased networks.Despite its popularity and rapidly growing deployments,overload control for the SIP protocol is still little understood. While the SIP protocol has a basic overload controlmechanism 16, this mechanism has proven to be ineffectivein practice and often cannot prevent SIP server overload.This problem is now becoming increasingly apparent as SIPdeployments are reaching large scales and serve a quicklygrowing number of users.Overload of a SIP server occurs if the message arrivalrate to the server exceeds its message processing capacity.Under overload, the throughput of a SIP server can dropsignificantly and can reach zero or a small fraction of theservers original capacity. In this case, the server enters into acongestion collapse. In addition to the messages a SIP serverreceives from external sources, it also generates messagesinternally, for example, to retransmit a request if a responsehas not been received in time. These internal messages addto the overall message arrival rate of the server. A servercan therefore be overloaded even at times when the externalmessage arrival rate is less than its processing capacity. Thisaspect is important as overload in one server, which willbecome significantly less responsive, can lead to overload inits neighbors. This way, overload can spread in a network ofSIP servers and eventually bring down the entire network.Overload in a network of SIP servers can be triggered byvarious reasons. It can be the result of many users trying toinitiate a SIP call around the same time, for example, whenvoting for a TV show or in an emergency situation. Anothercommon reason for overload is the failure of a componentin a SIP server farm, which degrades the overall processingcapacity and requires the remaining servers to keep up withthe incoming load. Yet another reason for overload is whenmany endpoints recover from a failure at the same time andsimultaneously register to the network, for example, aftera large power outage or a misconfiguration by the serviceprovider 15. Overload can occur even if a service providerhas carefully dimensioned its SIP servers to user demandssince the amount of signaling messages generated by SIPendpoints can exceed the average load by orders of magnitude6. As for Web servers and existing telephony networks, itis not economical and often not possible to dimension SIPservers for the worst case.Since overload in SIP servers cannot fully be avoided, itis crucial to equip the SIP protocol with a mechanism thatcan effectively manage overload 15. To achieve this goal,it is important to fully understand the behavior of a networkof SIP servers under overload. In this paper, we investigatethe effects of SIP server overload. Our results reveal thatthe current mechanisms provided by the SIP protocol cannotprevent congestion collapse. Furthermore, congestion collapsein one server can spread throughout a network and a SIPserver in state of congestion collapse cannot easily recover.We show that local overload control techniques can alleviatethe problem of overload only in light cases of overload. Wepropose distributed overload control mechanisms for SIP andshow that they are effective in preventing congestion collapse.After the introduction in Section I and the discussion onrelated work in Section II, we introduce key aspects of SIP inSection III. Section IV describes our simulation model, Section V provides a detailed performance evaluation of the SIPprotocol, and Section VI evaluates the performance of local14244250750820.00 2008 IEEE 832overload control. We investigate mechanisms for distributedoverload control in Section VII, and conclude the paper inSection VIII.II. RELATED WORKThe general topic of overload control in communicationnetworks has received a lot of attention in the past. Forexample, analysis of overload control based on MM1 queuingsystems has been studied in 4, 12 and Chapter 11 of 18.In the early 1990s, researchers were also attracted to overloadcontrol in telecommunications networks and the SignalingSystem SS7 e.g., 20, 10 and 17.A large body of work exist on congestion control for theTCP protocol, including 2, 13, 7 and 14. While TCPcongestion control aims at controlling a flow of many packetsfrom a single sender to a receiver, SIP overload control isfocused on individual requests sent from many senders tomany receivers through a set of intermediary SIP servers. Sinceeach sender only contributes single requests, endtoend flowcontrol is limited in its effectiveness. SIP also uses a differentretransmission mechanism than TCP. Overload control has alsobeen investigated for HTTP servers, e.g., in 21 and 22 witha focus on including additional servers to offload traffic duringperiods of overload and local overload control mechanisms.We investigate local overload control for SIP in Section VI.Overload control for the SIP protocol has received littleattention so far. The SIP specification provides a limitedoverload control mechanism, which we analyze in detail inSection V. The use of this mechanism with a bangbangcontrol algorithm is described in 11. Ejzak et al. 5 articulate the need for overload control in SIP and discussqualitative similarities and differences between ISUPSS7 andSIP networks. However, they do not provide quantitativeresults of how overload would affect SIP performance orpropose specific approaches on how to handle overload in SIPnetworks.GOCAP 6 takes a different approach by defining anabstract, protocolindependent framework for overload control.Even though it is argued that GOCAP can be applied to SIP, amapping has not yet been defined. Since GOCAP is protocolindependent, it uses a single overload control algorithm andits own control feedback loop that is applied to all controlledprotocols.III. SIP BACKGROUNDA. SIP Protocol OverviewSIP is a requestresponsebased protocol. End users arerepresented by user agents UAs, which take the role of auser agent client UAC or user agent server UAS for arequestresponse pair. A UAC creates a SIP request and sendsit to a UAS. On its way, a SIP request typically traversesone or more SIP servers, also called SIP proxies. The mainpurpose of a SIP server is to route a request one hop closer toits destination. Responses trace back the path the request hastaken.INVITE INVITEINVITE100 Trying100 TryingUAC Proxy A Proxy B UAS180 Ringing180 Ringing180 Ringing200 OK200 OK200 OKACK ACKACKBYE BYEBYE200 OK200 OK200 OKSession DataFig. 1. Example INVITEBYE call flow.To set up a SIP session, the UAC sends an INVITE requestto the UAS, as shown in Figure 1. Each server on the pathconfirms the reception of this request by returning a 100Trying response to the previous hop. Instead of forwarding arequest, a SIP server can reject it if it is unwilling or unable toforward the request. Once the request is received by the UAS,it typically responds with a 180 Ringing response to indicatethat the called user is being alerted and a 200 OK responsewhen the user has accepted the session. After the 200 OK isreceived by the UAC, it sends an ACK request to complete thethree way handshake of an INVITE transaction. The INVITErequest is the only SIP request that uses a three way handshake.Sessions can be terminated at any time by sending a BYErequest, which is confirmed with a 200 OK response. TheSIP protocol defines other methods besides the ones describedabove. Since setting up and terminating a session is one of thekey usages of SIP, we focus on the call flow for this scenario.We expect the qualitative results to be the same if the othermethods are used more frequently in the traffic mix and leave adetailed investigation of the impact of traffic mixes on overloadcontrol for further study.The SIP protocol provides a basic overload control mechanism through the 503 Service Unavailable response code. SIPservers that are unable to forward a request due to temporaryoverload can reject the request with a 503 response. Theoverloaded server can insert a RetryAfter header into the 503response, which defines the number of seconds during whichthis server does not want to receive any further request fromthe upstream neighbor. A server that receives a 503 responsefrom a downstream neighbor stops forwarding requests to thisneighbor for the specified amount of time and starts again afterthis time is over. Without a RetryAfter header, a 503 responseonly affects the current request and all other requests can stillbe forwarded to this downstream neighbor. A server that hasreceived a 503 response can try to resend the request to analternate server, if one is available. A server does not forward503 responses towards the UAC and converts them to 500Server Internal Error responses instead.The SIP protocol can operate over reliable e.g., TCP andunreliable transport protocols e.g., UDP. If it runs over anunreliable transport, SIP uses retransmission timers with an14244250750820.00 2008 IEEE 843DBACa Server  ServerEDb UA  ServerabczFig. 2. SIP server topologies.exponential back off to compensate for lost messages. SIPdifferentiates between two types of transactions INVITE andnonINVITE transactions. The two transaction types differ inthe way requests are retransmitted and confirmed. Each time aSIP entity sends a request over an unreliable transport protocolto the next hop, it starts a retransmission timer with a defaultvalue of 500ms. This timer is called timer A for INVITEand timer E for nonINVITE transactions. When this timerexpires, the request is retransmitted and the timer is reset withits value doubled. For nonINVITE transactions, the value oftimer E is capped and is not raised above a given maximumthe default is 4s. Retransmissions cease when a response isreceived or the request timeout timer fires, which has a defaultvalue of 32s. The request timeout timer is called timer B forINVITE and timer F for nonINVITE transactions and is usedindependent of the transport type. For INVITE transactions,the UAS retransmits the 200 OK response until it receives anACK using the capped exponential back off mechanism as intimer A and a request timeout as in timer B. 200 OK responsesare retransmitted independent of the transport protocol in use.With these retransmission schemes, a SIP message can betransmitted up to seven times without a cap for timer AEand eleven times when the doubling of timer AE is capped.B. SIP Server TopologiesThe topology of SIP servers impacts overload control inSIP. Figure 2 a depicts a serverserver configuration inwhich a SIP server D receives traffic from multiple upstreamneighbors. Each of the upstream servers forwards potentiallymany requests to the downstream server. In this topology, anoverload control mechanism can notify each upstream serverto reduce the load forwarded. An upstream server can havean alternative downstream server it can forward a request toif the first server is unavailable. The UAserver scenario isdepicted in Figure 2 b. Here, a SIP server receives requestsfrom a large population of UAs. Each user agent typicallyonly generates a small number of requests, which are oftenrelated to the same call. Hence, asking user agents to lowerthe number of requests has little impact on the load of serverD. However, since INVITE transactions consist of multiplerequests, rejecting an INVITE can still lower the offered loadof server D. In this paper, we focus on serverserver overloadcontrol and use local overload control in our simulations forUAserver configurations if needed.CPUOutgoingReset timerTimer startsmessagesTimer bufferMessage buffermessagesExternalTimer expiresfiresTimerPrio 3 Prio 1Prio 2Fig. 3. Queuing model for a stateful server.IV. SIMULATION MODELWe have implemented a discreteevent simulator to evaluatethe behavior of SIP servers under overload. Our simulatorimplements the full SIP transaction layer and key elements ofa transaction user for INVITE and nonINVITE transactionsaccording to the SIP RFC 3261 16. This simulation modelprovides us the flexibility to evaluate the impact of differentSIP server topologies, server processing capacities, overloadcontrol algorithms and internal message processing techniquessuch as the stateless rejection of SIP requests. Our simulatorhas been carefully evaluated and verified in the design team forSIP overload control, which was formed by the IETF SIPPINGworking group. We also verified the results of our simulatorfor Network Topology 1 see below with the goodput of a SIPproxy implementation, the SIP Express Router SER 19, inthe same configuration.A. Model for SIP ServersWhen a SIP entity sends new request, it instantiates aclient transaction, which is governed by a finitestate machineFSM. Similarly, when a SIP entity receives a request, itinstantiates a server transaction that is again governed bya finitestate machine. In addition to the client or servertransaction, a SIP entity also instantiates an INVITE or nonINVITE transaction user. Four types of FSMs are defineddepending on whether the transaction is at the client orserver, and whether the transaction is triggered by an INVITEor nonINVITE message. A description of these four FSMscan be found in Section 17 of 16. The SIP servers areset to operate in transaction stateful mode. UAs and SIPservers can transmit messages either via UDP or TCP. IfUDP is used, retransmission timers are used as defined bySIP. Servers are set to record route, which causes all SIPmessages exchanged between two UAs to traverse throughthese servers. This includes the ACK request and the BYEtransaction, which would otherwise be exchanged directlybetween UAs. Since the initial INVITE request and responsesand their retransmissions always traverse SIP servers, the useof recordroute does not qualitatively change the results.The structure of the queuing system for a SIP server isshown in Figure 3. External messages i.e., requests andresponses and timer messages contexts are queued in amessage buffer, which implements a nonpreemptive priorityqueuing discipline with priority i having a higher precedenceover priority j if i  j. Messages of the same priority14244250750820.00 2008 IEEE 854are queued in a FIFO manner. The processor CPU servesthe message at the head of the priority queue by executingthe necessary FSM, sending a message to the next hop, andpossibly starting a timer. Timers are placed in a priority queuesorted according to their firing times. When a timer fires andthus exits the timer buffer, its associated context is queued intothe message buffer if required by the FSM, and a new timerwith a subsequent firing time is enqueued in the timer bufferif needed. A timer that expires simply leaves the system.Generally, timer messages are assigned priority 1 while external messages are assigned priority 2. Priority 3 is needed forlocal overload control and is discussed in Section VI. Becausesome timer messages need to be processed to ensure that theassociated transactions are properly cleaned, we assume thatthe space for timer messages is unlimited. External messagescan be queued up to B messages, and new external messagesare dropped if its space is full.We assume the following parameters for the base server.The external message service time at the processor is 1ms andthe timer message service time is 0.5ms. This implies that theretransmission of a SIP message takes half the time of theinitial transmission. A server with a given processing capacitycan be defined in the simulator by scaling updown the valuesgiven in the base server. We assume that message service timeis deterministic. Our experiment with exponential messageservice time does not show qualitative differences. Note thatwhile packet service time in a router typically depends onpayload length and not on header processing, SIP messageservice time is mainly determined by header processing ratherthan payload length.All associated timer firing intervals use the default valuesspecified in RFC 3261. Throughout this paper, we assume thatB  1000, and if high watermark Bh and low watermark Blare used, the values are 800 and 600, respectively.B. Model for UAsOur model uses an infinite number of UAs and each new INVITE request is generated by a new UA instance. INVITE requests are created with an aggregate rate of  requestssecondaccording to a Poisson process. Because other messages aregenerated based on events e.g., timer firing or receiving amessage and the state of the FSM, their arrival processes isgoverned by the dynamics of interacting SIP transactions. Ifa call is not established 10 seconds after the INVITE requestwas sent it is assumed that a user will abandon the call andthe INVITE transaction is cancelled. The holding time for anestablished call is assumed to be exponentially distributed withparameter 1ETh, where ETh is the average holding time.We assume ETh  100 secs. Finally, a UA sends a BYErequest to terminate its session. The offered load is the totalnumber of calls new INVITEs per second initiated by UAs.The goodput is the total number of calls per second terminatedby UAs.3456128UAsUAsUAsUAsEdgesCore 2Core 1 UAsUAsGateway 2Gateway 17Fig. 4. Network topology 2.21CoreEdge73456UAsUAsUAsUAsUAsFig. 5. Network topology 3.C. Network TopologiesThe simplest topology Network Topology 1 we have usedin our experiments is a single server serving all the UAs thatis, each pair of UAs are communicating via a single server.This simple star topology is useful to study the behavior of aSIP server in isolation.The next network topology is depicted in Figure 4. Itconsists of M edge servers M  4 for example servingUAs that are interested in communicating with users servedby one of two gateway servers. Each edge server has to selectone of the core servers to reach the respective gateway server.This configuration can be used, for example, to connect SIPUAs to PSTN gateways.Figure 5 shows a topology with M edge servers, whichsend traffic through one of N core servers. The edge serversbalance load across the core servers. Edge servers forwardtraffic from the UAs to the core servers and vice versa. EachUA is connected to one edge server. Edge servers can exchangemessages with all core servers. This topology is typicallyused for UAs that communicate within a SIP service providerdomain.An extension of the preceding topology is one where coreservers in one domain forward messages to core servers inanother domain, as shown in Figure 6. The above networktopologies are representations of topologies proposed in stan14244250750820.00 2008 IEEE 865UAsUAsUAsUAsb1a2a5UAsb6b5b4b3a1a6a3a4b2Domain bDomain aCores CoresEdgesEdges UAsUAsUAsFig. 6. Network topology 4.dards, e.g., in the IMS architecture 1 and are used by SIPservice providers.SIP servers communicate via an underlying IP network. TheIP network may drop packets and introduce packet delay dueto queuing. We do not consider the effects of the underlyingnetwork in order to isolate the performance behavior due toSIP. We also assume that propagation delay in the network isnegligible.V. SIP PERFORMANCE EVALUATIONIn this section, we explore the performance of SIPbasednetworks without additional overload control mechanisms.A. Congestion Collapse and Recovery from Congestion CollapseWe first begin with the simplest topology, Network Topology 1, in which all UAs are communicating via a single server.We assume that this server simply discards arriving messageswhen its buffer is full. With the parameters set to those of thebase server described in the previous section and the call flowdepicted in Figure 1, the server has a capacity of about 160calls per second cps.Figure 7a shows a sample path of the goodput as a functionof time when the offered load to the server is varied. After adelay that is due to the call holding time the goodput initiallytracks the offered load at about 150 cps. As the offered loadexceeds the server capacity at t  1000s, the system collapsesand the goodput drops significantly. At this point, the serverstarts to drop messages which are in turn retransmitted by thesender. These retransmissions amplify the offered load, whicheventually leads to a congestion collapse. Interestingly, whenthe offered load is reduced back to 150 cps i.e., below theserver capacity at t  2000s, the congestion collapse persistsand the goodput remains low.Figure 7b depicts the timer firing rate over time. Althoughthe rate of new call arrivals has been reduced after t  2000s,internal as well as external message arrivals due to timerretransmissions remain high and contribute to load that keepsthe server under stress. Since timer B and F fire at a muchlower rate than timer A and E, their arrival rate remains at the 0 50 100 150 200 250 0  1000  2000  3000  4000  5000Calls per secondTime sec.a GoodputOffered loadGoodput 0 100 200 300 400 0  1000  2000  3000  4000  5000Message RateTime sec.b Timer firing ratetimer Atimer Btimer Etimer F 0 0.2 0.4 0.6 0.8 1 0  1000  2000  3000  4000  5000UtilizationTime sec.c Server utilizationFig. 7. SIP server performance over time as the offered is varied a thecall goodput drops when the offered load exceeds the capacity of the serverand does not recover easily, as b message retransmissions due to timer firingexacerbate the overload and c result in very high server utilization.bottom of Figure 7b. This is also corroborated in Figure 7cwhere the server utilization remains close to 1 even afterreduction of the call arrival rate. Only after the offered loadis reduced sufficiently at t  3000s the timer retransmissionsare cleared. At this point, the server recovers from congestioncollapse.B. Cascading EffectsWe now investigate how a congestion collapse at a particularserver in a network affects other servers. We use NetworkTopology 2 to illustrate the interactions among differentservers in a network. We assume that all edge servers and coreserver 1 each have a capacity of 80 cps, while the gatewaysand core server 2 each have a capacity of 160 cps. Trafficis sent from UAs connected to the gateways to the UAsconnected to the edge servers and vice versa. All traffic isuniformly distributed among the four edge servers. The trafficbetween the edge servers and gateway 1 is routed throughcore server 1. Traffic between the edge servers and gateway2 is routed through core server 2. Denote the overall offeredload exchanged between the edge servers and the gateway iby i i  1, 2.Figure 8a plots the offered loads and the correspondinggoodputs for both traffic streams. Initially at t  0, 1 65 cps and 2  80 cps. Calls are successfully set up asboth core servers have ample capacities to process the traffic.Note in Figure 8c that core server 1 already operates at ahigh utilization while the other servers are moderately loaded.14244250750820.00 2008 IEEE 876 0 20 40 60 80 100 0  1000  2000  3000  4000Calls per secondTime sec.a GoodputOffered load 1Goodput 1Offered load 2Goodput 2 0 50 100 150 200 250 300 0  1000  2000  3000  4000Message RateTime sec.b Timer A firing ratecore 1edgecore 2 0 0.2 0.4 0.6 0.8 1 0  1000  2000  3000  4000Server UtilizationTime sec.c Server utilizationcore1core2edgegateway1gateway2Fig. 8. Effect of one SIP server on other servers a when offered load1 exceeds the capacity of a server, goodput 2 for another path can beimpacted, b confirmed by message retransmissions at different servers, andc utilizations at different servers.At time t  1000s, 1 is increased slightly above 80 cps,which causes core server 1 to be overloaded. 2 remains at80 cps. Because core server 1 is experiencing a congestioncollapse, each of the edge servers will start to retransmit manyof its messages, as can be seen in Figure 8b. This leads toa congestion collapse at the edge servers. Subsequently, asthe edge servers become unresponsive, core server 2 starts toperform retransmissions for requests and responses sent andeventually goes into congestion collapse. As can be seen aftert  2000s, even after the offered load 1 is reduced, theservers remain in a state of congestion collapse.C. Controlling Overload with the 503 Response CodeThe use of the 503 response code with a RetryAfter headergenerates an onoff traffic pattern since a SIP server alternatesbetween not forwarding requests and forwarding all requests.The onoff pattern of 503 responses with RetryAfter leads toinstability in the offered load and can be expected not to offera satisfactory performance. During periods in which trafficcannot be forwarded, a SIP server can reject requests witha 500 Server Internal Error response or retry them at analternate server. Retrying at alternate servers can cause trafficoscillation among the servers.To demonstrate the effects of using the 503 response codewith RetryAfter for overload control, we use Network Topology 3. We assume that a server receiving a 503 response froma downstream neighbor will retry the request at an alternateserver, if possible. Calls are rejected with a 500 Server 0 50 100 150 200 250 300 0  1000  2000  3000Calls per secondTime sec.a GoodputOffered loadGoodput 0 0.2 0.4 0.6 0.8 1 0  1000  2000  3000Server UtilizationTime sec.b Server utilizationu core1u core2Fig. 9. Use of 503 responses to control overload a goodput dropssignificantly during overload, and b servers may oscillate.Internal Error response code if they are unsuccessful at alldownstream servers. We set the capacity of core server 1 to120 cps and core server 2 to 160 cps. Each of the edge servershas a capacity of 480 cps to ensure that only core servers areoverloaded. Edge servers are set to balance load across thetwo core servers. A server starts to send 503 responses to itsupstream neighbor if the servers queue length has reached thehighwatermark level. A server stops sending 503 responsesafter the queue length has decreased below the lowwatermarklevel. Figure 9a plots the total goodput and offered load usingRetryAfter value of 10s. We use 10s since it allows us tobetter examine the traffic oscillations that occur. The observedeffects are, however, the same even with the shortest possiblevalue of 1s. As can be seen, this technique results in congestioncollapse during overload. Figure 9b shows the utilization ateach core server. It reveals that core server 2 is oscillatingat a period of about 10s. Core server 1, which is slower, isexperiencing a severe overload and is unable to recover fromthe overload condition during the RetryAfter timeout periods.It still needs to process responses as well as internal messagesduring these times. Oscillation is generally a bad behavior as itleads to poor performance and provides inconsistent servicesto the end users. We investigate the use 503 responses withouta RetryAfter header in the context of local overload control.D. Impact of Transport Protocols on SIP PerformanceSince SIP can use a reliable e.g., TCP or unreliablee.g., UDP transport protocol, it is of interest to evaluateSIP performance under different transport protocols and, inparticular, TCP versus UDP. Many of the SIP retransmissiontimers are only activated if SIP is used over an unreliabletransport protocol. Therefore, we expect that the goodput ofa SIP server under overload will be higher if TCP is usedinstead of UDP. To confirm our expectation, we compare threescenarios. In the first scenario, we assume that all SIP entitiesalong the path of a request are using TCP. In the secondscenario, we exploit the fact that the SIP protocol allows14244250750820.00 2008 IEEE 887 0 50 100 150 200 250 300 0  100  200  300  400  500  600  700  800Goodput calls per secondOffered load calls per secondUDPMixedTCPFig. 10. Goodput comparison for different transport protocols.the use of a different transport protocol on each hop. Here,UAs use UDP to reach a SIP server while the servertoservercommunication uses TCP this scenario is labeled the mixedmodel. In the third scenario, we only use UDP.Figure 10 illustrates the goodput versus offered load forthe three different scenarios using Network Topology 3. It isassumed that each server has a capacity of 160 cps. Traffic isuniformly distributed across the core servers and edge servers.As expected, the goodput performance progresses as more andmore TCP links are used. Notice that even with TCP, we stillsee a significant drop in goodput once the server capacity isreached. This can be attributed in part to the fact that a UASretransmits 200 OK responses with an exponential back offirrespective of the transport in use. Another reason is related tothe way TCP is used. During overload, a SIP server can eitherkeep reading from a TCP socket and discard some of the SIPmessages it receives or it can stop reading SIP messages fromthe TCP socket altogether. We have used the former methodas it decouples network congestion from overload control.It enables the SIP server to continue to process incomingmessages such as responses, ACK and BYE requests and onlydiscard new INVITE requests. This method is used in manySIP proxy implementations. The latter method implicitly usesTCP as a feedback mechanism for overload control that affectsall messages from a server. We leave this method for furtherstudy.While there are many considerations that determine thechoice of a transport protocol, our studies confirm that using areliable transport provides a better performance under overloadfor a SIP server.VI. LOCAL OVERLOAD CONTROLA mechanism that is frequently used to improve performance of a SIP server under overload is local overload control.A. OverviewThe basic idea of local overload control is that a SIP server,which is getting close to its capacity limit, starts to rejectSIP requests locally with 503 responses without RetryAfterheader instead of dropping messages or using 503 responseswith RetryAfter. The 503 response code with no RetryAfterheader only affects the rejected request. Unlike the two othermethods, rejecting requests and sending 503 responses upstream consumes processing resources. Nevertheless, rejectinga request can be made to consume far less resources thanfully processing it. Even if rejecting requests consumes lessprocessing resources, an overloaded SIP server with localoverload control will eventually spend most of its processingresources on rejecting requests if the offered load is very high,which leads to a poor goodput.The rationale behind local overload control is that it isbeneficial to avoid that upstream servers retransmit copies ofmessages that have been dropped and thereby amplify the offered load. Instead of dropping these messages, local overloadcontrol suppresses retransmissions by rejecting them. Furthermore, since a server can reject each request individually, it canfreely choose the fraction of requests it wants to reject. Thisenables a smooth control of the requests to be processed. Localoverload control does not require cooperation between servers.This characteristic is important since it enables the use of localoverload control even if upstream servers are noncooperative.To speed up the rejection process for local overload control,we do not use a transactionlayer FSM in SIP servers whenrejecting these requests with 503 responses without RetryAfter. In other words, a SIP server rejects requests for localoverload control in a stateless mode, which avoids that stateneeds to be looked up or created.We noted that the stateless generation of 503 responses cancreate a race condition between a 200 success and 503 failureresponse for the same request, which eventually causes theaffected call to fail. To further investigate the impact of thesecall failures on the overall performance, we also performedsimulation runs using the standard stateful generation of 503responses. We found that stateless 503 response generationcan provide a marginal performance improvement but therewas no qualitative difference in the performance of the twomethods.Another important aspect of the rejection process is whetherrequests are selected for rejection due to overload early,i.e., before enqueuing them in the input message buffer orlate, i.e., when they are dequeued. To explore the firstalternative, we have configured our queuing model describedin Section IVA by assigning priority 1 for timers, priority2 for requests selected for rejection and priority 3 for allother messages. Thus, only requests that are admitted bylocal overload control are enqueued in the input messagebuffer all other requests are scheduled to be rejected. Forlate rejections we use our standard queuing model with 2priorities. We found that a combination of early rejectionsand stateless rejections provides the best performance givenall other parameters remain the same and we use those twomessage processing techniques in our evaluation describedbelow.14244250750820.00 2008 IEEE 898B. Algorithms for Local Overload ControlA key component of local overload control is the algorithmthat determines the amount of requests a SIP server shouldaccept. We compare the use of two algorithms for localoverload control other possible algorithms are described, forexample, in 9. The first algorithm is a simple bangbangcontrol BBC algorithm that is also described in 11. Here, aserver has two states 1 overload and 2 underload. A serverin underload state turns to overload state when its messagequeue length exceeds a high watermark value Bh. Similarly, aserver in overload state turns to underload state when the queuelength falls below a low watermark value Bl. In underloadstate, all messages are accepted whereas in overload state, allincoming INVITE requests are rejected.The second algorithm is called the occupancy OCC algorithm 3, where incoming INVITE requests are acceptedwith probability f or rejected with probability 1  f . TheOCC algorithm is based on processor occupancy utilization. It has the objective of dynamically adjusting f to maintaina utilization at or below a given target utilization targ. Theutilization, , is periodically updated at every  seconds. Ineach tth epoch, the processor utilization t is updated andcompared with the target utilization targ. If desired, theutilization can be smoothed with a moving average filter. Thebasic idea of OCC is to increase f if   targ, and to decreaseit otherwise. Let ft1 denote the newly updated f in the nextepoch t  1, while ft denote f in the current epoch t. Thealgorithm that updates f in each epoch is described as follows.ft1 fmin, if t ft  fmin1, if t ft  1t ft, otherwise,1where fmin represents the threshold for the minimum fractionof traffic accepted. The multiplicative increasedecrease factort is given byt  mintargt, max, 2where max defines the maximum possible multiplicativeincrease in f from one epoch to the next.C. Performance ComparisonIn this section, we compare four different cases Case 1 The base case where no overload control isemployed. Case 2 Local overload control with BBC. Case 3 Same as Case 2, except that an upstream serverwill retry a rejected request at an alternate server, ifpossible. Case 4 Local overload control with OCC.We use Network Topology 3 and set the capacity of eachserver to 160 cps. Each call to an ingress edge server isuniformly distributed to an egress edge server. Edge serversdistribute calls equally across the core servers. We assume thatan early reject incurs a processing time of 0.16666ms. For theOCC algorithm, fmin  0.02, max  5, targ  0.9, and tis updated every second. 0 50 100 150 200 250 300 0  100  200  300  400  500  600  700  800Goodput calls per secondOffered load calls per secondCase 1Case 2Case 3Case 4Fig. 11. Goodput comparison based on topology 3. Case 1 no overloadcontrol Case 2 BBC without alternate server Case 3 BBC with alternateserver Case 4 OCC without alternate server. 0.01 0.1 1 10 0  100  200  300  400  500  600  700  800Delay secondsOffered load calls per secondCase 1Case 2Case 3Case 4Fig. 12. Delay comparison based on topology 3. Case 1 no overload controlCase 2 BBC without alternate server Case 3 BBC with alternate server Case4 OCC without alternate server.As can be seen in Figure 11, the goodput with Case 1increases up to the network capacity and then rapidly dropsto zero with a severe congestion collapse at around 300 cps.The corresponding mean setup delay the difference betweenthe time an INVITE is sent by a UAC and the time an ACKis received by a UAS is depicted in Figure 12. Note that forCase 1 the delay is plotted only up to about 300 cps as nocalls can get through beyond it.Case 2 in Figure 11 depicts the goodput provided bythe BBC algorithm without retrying rejected requests at analternate server. The goodput reaches close to the serversprocessing capacity at first since in BBC a server does notbegin to reject requests until the buffer has reached the highwatermark and the server turns into overload state, which isnear its capacity. Once a server enters overload state, it startsto reject all INVITE requests, resulting in a rather sudden dropin goodput. Another reason for the overall poor performanceof BBC is that the processor is allowed to reach a very high14244250750820.00 2008 IEEE 909utilization. With local overload control the processor needsto have enough capacity to reject requests, which may not beavailable in BBC at the time the buffer occupancy is at the highwatermark. It is also interesting to note that the correspondingsetup delay in Figure 12 increases near the capacity limit as theutilization approaches 1, but levels off due to finite buffering.In the previous cases, edge servers were programmed toreject all requests for which they have received a 503 responsefrom a core server with a 500 response. In Case 3, edge serverswill retry all rejected requests at the second core server. Onlyif a request is rejected there as well, a 500 response will bereturned back to the UAC. This behavior is suggested in theSIP specification.The graphs labeled Case 3 in Figure 11 and Figure 12 plotthe goodput and delay if rerouting is allowed. Contrary tothe initial intuition, retrying decreases goodput and increasesdelay during overload here. This can be explained by the factthat retrying rejected requests at alternate servers increases theload on these servers. Each server receives all requests thatwere rejected by the other server. The more alternate serversare available, the worse is this effect is since a request is sendto all servers before it is cleared from the system.Retrying requests can be beneficial when one SIP serveris highly loaded while the alternate server has plenty ofcapacity. However, in many cases the performance of such aconfiguration can be improved by adjusting the distributionof load across servers instead of retrying requests duringoverload.Case 4 in Figure 11 plots the goodput of the OCC algorithm.Note that the goodput degrades approximately linearly asthe load increases. This is because OCC increasingly rejectsINVITE requests as the offered load increases. The OCCalgorithm does not fully reach the capacity limit of the serversince it starts to reduce the number of requests processed when reaches 0.9. The delay shown in Figure 12 indicates thatOCC is able to maintain a low delay for the calls that areprocessed as long as the load stays below the rejection rateof the server. Thus, while an increasing number of calls arerejected, the ones that are processed do not see a significantincrease in setup delay. However, when the load increasesbeyond the rejection capacity, the delay starts to increasesignificantly. This can be explained by the fact that the serverstarts to drop requests at this point and enters into a congestioncollapse.Interestingly, the goodput of OCC, as well as of all othercontrol algorithms, does not drop to zero when the offered loadreaches the rejection capacity of a server. This can be attributedto the Poisson distribution of call arrivals. Even under a highload, there are periods which the offered load is low enough toallow the server to process a few incoming INVITE requests.Summing up, we find that local overload control is capableof extending the range under which a server can operatewithout dropping requests. In particular, if an appropriatecontrol algorithm is used, local overload control outperforms asystem without overload control and enables a server to copewith light cases of overload. However, local overload controli jj1j2a Hopbyhopi jj2b Endtoendj1Fig. 13. Hopbyhop vs. endtoend overload control.does not prevent a congestion collapse and therefore is notsuitable as the sole overload control mechanism.VII. DISTRIBUTED OVERLOAD CONTROLDistributed overload control allows an overloaded server tooffload the task of rejecting requests to other servers.A. Hopbyhop Vs. EndtoEndIn distributed overload control, SIP servers are enabled toprovide overload control feedback to servers that are furtherupstream in a SIP server network. This feedback can beused by the upstream servers to reduce load to an amountthat does not cause downstream servers to be overloaded.Overload control feedback can, for example, be conveyed in aSIP response header 8. The overload control feedback loopcan be applied to the path of a SIP request hopbyhop, i.e.,individually between each pair of SIP servers, or endtoendas a single control loop that stretches across the entire pathfrom UAC to UAS. Figure 13 depicts the two alternatives.In the hopbyhop mechanism, a separate overload control loop is instantiated between each pair of neighboringSIP servers on the path of a SIP request. For example inFigure 13a a separate overload control loop is establishedbetween servers j1j, j2j, and ji. Each SIP server providesfeedback to its direct upstream neighbors, which then adjustthe amount of traffic they are forwarding to this SIP server. Theupstream neighbors do not forward the received informationupstream. An upstream neighbor uses a separate overloadcontrol loop with its own upstream neighbors. In this model,overload is always resolved by the direct upstream neighborsof an overloaded server without the need to involve entitiesthat are located multiple SIP hops away.In our experiment, each SIP server j independently reportsits current acceptance probability f j value to its upstreamneighbors in SIP responses1. An upstream neighbor of jsimply accepts new INVITES that are to be forwarded toj using the reported probability f j or rejects them withprobability 1f j2. If an upstream neighbor i is at the networkedge, it will instead use minf i, f j, where f i is its owncomputed value. Note that if the set of direct downstreamneighbors of a server is j1, j2,    , jL, the server only has to1In general, a server can report a rate cap instead of acceptance probabilityor even raw load information such as utilization and queue length.2In practice, a server needs to be able to handle upstream neighbors thatdo not support overload control. This is not addressed in this paper.14244250750820.00 2008 IEEE 9110maintain a list of f j1 , f j2 ,    , f jL values. Thus, the hopbyhop mechanism scales well to networks with many SIPentities.The endtoend overload control mechanism on the otherhand implements an overload control loop along the path ofa SIP request. When a SIP server receives the first requestfrom its upstream neighbor, it knows the downstream neighborto forward the message to, but not the entire path towardthe destination. Our endtoend mechanism makes use of thisfact. As there are different sets of downstream neighbors fordifferent target servers those that are onehop away from theUASs, each server needs to keep track of its downstreamneighbors information on a pertarget basis. Specifically,for a given target server d, a server j maintains a list off j1d, f j2d,    , f jLd values if its corresponding downstream neighbors for target d are j1d, j2d,    , jLd,where f jld is the f value the server receives from its downstream neighbor jl for target d. If server j with the precedingdownstream neighbors reports the feedback information toits upstream neighbor, it will only report the summarizedinformation f id  minf j1d, f j2d,    , f jLd, f i. Thefeedback information for each target is eventually propagatedto all ingress servers. An ingress server i makes the decision onaccepting new INVITES for target d based on the smaller of f ivalue or the value received from its downstream neighbor. Theendtoend mechanism is in particular suitable for networkswith fixed call routing policies. The main disadvantage of theendtoend mechanism is its greater complexity compared tohopbyhop mechanism.B. Performance ComparisonWe use Network Topology 4 to compare local, hopbyhopand endtoend overloadcontrol mechanisms. For each case,the OCC algorithm is used. We assume that each server has acapacity of 160 cps. The offered load among all edge servers isuniformly distributed with routing to each core server equallylikely.Figure 14 compares the goodput performance for the different overloadcontrol mechanisms. As expected, hopbyhopsignificantly outperforms local overloadcontrol. Nevertheless,the hopbyhop mechanism still experiences some loss ofgoodput as the offered becomes very high. On the other hand,the endtoend mechanism maintains high goodput throughout.It is intuitively clear that endtoend mechanism will not offer aperformance advantage over the hopbyhop mechanism whenan overloaded server is only onehop away from an ingressserver, as in Network Topology 3. At the other extreme, theperformance of the hopbyhop mechanism can expected tobe lower if an overloaded server occurs in the middle of along path whereas the endtoend mechanism maintains highgoodput as long as the ingress servers are not overloaded.VIII. CONCLUSIONIn this paper, we have investigated the performance ofa network of SIP servers under overload. The motivationbehind our work is that, the servers using the current SIP 0 50 100 150 200 250 300 0  100  200  300  400  500  600  700  800Goodput calls per secondOffered load calls per secondLocalHopbyhopEndtoendFig. 14. Comparisons among different overloadcontrol mechanisms.protocol are vulnerable to overload and congestion collapse.This shortcoming is now becoming apparent as SIP networksare deployed in different domains on a large scale. To the bestof our knowledge, our work provides the first comprehensivestudy of SIP overload which reveals problems such as spreading of overload and slow recovery of SIP servers. Our workalso provides a sidebyside comparison of different overloadcontrol algorithms BBC without alternate servers, BBC withalternate servers, OCC and overload control paradigms local,hopbyhop and endtoend overload control.We have shown that the current overload control mechanismof SIP is unable to prevent congestion collapse and may, infact, worsen an overload condition. Due to message retransmissions triggered by various SIP timers, overload may spreadthroughout a network of SIP servers and SIP servers cannoteasily recover from overload once it has occurred. Our resultshave shown that using local overload control techniques canprovide a simple remedy for light cases of overload however,it is ineffective to treat higher amounts of load. Finally, wehave investigated distributed overload control mechanisms,which are able to prevent congestion collapse in a networkof SIP servers under a wide range of overload. Based on ourresults we argue that an extension of the SIP protocol foroverload management is necessary and feasible.REFERENCES1 3rd Generation Partnership Project, httpwww.3gpp.org.2 M. Allman, V. Paxson and W. Stevens, TCP Congestion Control, IETF,RFC 2581, April 1999.3 B. L. Cyr, J. S. Kaufman and P. T. Lee, Load balancing and overloadcontrol in a distributed processing telecommunication systems, UnitedStates Patent No. 4,974,256, 1990.4 B. T. Doshi and H. Heffes, Overload performance of several processorqueueing disciplines for the MM1 queue, IEEE Transactions onCommunications, vol. 34, no. 6, pp. 538546, Jun. 1986.5 R. P. Ejzak, C. K. Florkey and R. W. Hemmeter, Network overload andcongestion a comparison of ISUP and SIP, Bell Labs Technical Journal,vol. 9, no. 3, pp. 173182, 2004.6 ETSI, Architecture for Control of Processing Overload, ETSI,DTRTISPAN02026NGN, 2006.7 S. Floyd, T. Henderson and A. Gurtov, The NewReno Modification toTCPs Fast Recovery Algorithm, IETF, RFC 3782, April 2004.14244250750820.00 2008 IEEE 92118 V. Hilt, I. Widjaja and H. Schulzrinne, Session Initiation ProtocolSIP Overload Control, IETF, InternetDraft, drafthiltsippingoverload,2008.9 S. Kasera, J. Pinheiro, C. Loader, M. Karaul, A. Hari and T. LaPorta,Fast and robust signaling overload control, International Conferenceon Network Protocols, Riverside, CA, November 2001.10 D. R. Manfield, G. K. Millsteed and M. Zukerman, Performanceanalysis of SS7 congestion controls under sustained overload, IEEEJournal on Selected Aread in Communications, vol. 12, no. 3, pp. 405414, Apr. 1994.11 M. Ohta, Overload Control in a SIP Signaling Network, EnformatikaTransactions in Engineering, Computing and Technology, Mar. 2006.12 R. R. Pillai, A distributed overload control algorithm for delayboundedcall setup, IEEE Transactions on Networking, vol. 9, no. 6, pp. 780789,Dec. 2001.13 K. Ramakrishnan, S. Floyd and D. Black, The Addition of ExplicitCongestion Notification ECN to IP, IETF, RFC 3168, September 2001.14 I. Rhee and L. Xu, CUBIC A New TCPFriendly HighSpeed TCPVariants, PFLDnet, Lyon, France, 2005.15 J. Rosenberg, Requirements for Management of Overload in the SessionInitiation Protocol, IETF, InternetDraft, draftietfsippingoverloadreqs,2008.16 J. Rosenberg, H. Schulzrinne, G. Camarillo, A. Johnston, J. Peterson,R. Sparks, M. Handley, E. Schooler, SIP Session Initiation Protocol,IETF, RFC 3261, June 2002.17 M. Rumsewicz, On the efficacy of using the transferredcontrolledprocedure during periods of STP processor overload in SS7 networks,IEEE Journal on Selected Aread in Communications, vol. 12, no. 3,pp. 415423, Apr. 1994.18 M. Schwartz, Telecommunication networks, AddisonWesley, Reading, MA, 1987.19 SIP Express Router, httpwww.iptel.orgser20 D. Tow, Network ManagementRecent Advances and Future Trends,IEEE Journal on Selected Areas in Communications, vol. 6, no. 4, May1988.21 M. Welsh and D. Culler, Adaptive Overload Control for Busy InternetServers, USENIX Symposium on Internet Technologies and Systems,Seattle, WA, 2003.22 W. Zhao and H. Schulzrinne, Enabling Ondemand Query ResultCaching in DotSlash for Handling Web Hotspots Effectively, IEEEWorkshop on Hot Topics in Web Systems and Technologies, Boston,Massachusetts, November 2006.14244250750820.00 2008 IEEE 93
