Ant Algorithms for DiscreteOptimizationMarco DorigoGianni Di CaroIRIDIA CP 1946Universite Libre de BruxellesAvenue Franklin Roosevelt 50B1050 BrusselsBelgiummdorigoulb.ac.begdicaroiridia.ulb.ac.beLuca M. GambardellaIDSIACorso Elvezia 36CH6900 LuganoSwitzerlandlucaidsia.chKeywordsant algorithms, ant colony optimization, swarm intelligence, metaheuristics, natural computationAbstract This article presents an overview of recent workon ant algorithms, that is, algorithms for discrete optimizationthat took inspiration from the observation of ant coloniesforaging behavior, and introduces the ant colony optimizationACO metaheuristic. In the first part of the article the basicbiological findings on real ants are reviewed and theirartificial counterparts as well as the ACO metaheuristic aredefined. In the second part of the article a number ofapplications of ACO algorithms to combinatorial optimizationand routing in communications networks are described. Weconclude with a discussion of related work and of some ofthe most important aspects of the ACO metaheuristic.1 IntroductionAnt algorithms were first proposed by Dorigo and colleagues 33, 40 as a multiagentapproach to difficult combinatorial optimization problems such as the traveling salesman problem TSP and the quadratic assignment problem QAP. There is currentlymuch ongoing activity in the scientific community to extend and apply antbased algorithms to many different discrete optimization problems 5, 21. Recent applicationscover problems such as vehicle routing, sequential ordering, graph coloring, routing incommunications networks, and so on.Ant algorithms were inspired by the observation of real ant colonies. Ants are socialinsects, that is, insects that live in colonies and whose behavior is directed more to thesurvival of the colony as a whole than to that of a single individual component of thecolony. Social insects have captured the attention of many scientists because of thehigh structuration level their colonies can achieve, especially when compared to therelative simplicity of the colonys individuals. An important and interesting behavior ofant colonies is their foraging behavior, and, in particular, how ants can find the shortestpaths between food sources and their nest.While walking from food sources to the nest and vice versa, ants deposit on theground a substance called pheromone, forming in this way a pheromone trail. Ants cansmell pheromone, and when choosing their way, they tend to choose, in probability,paths marked by strong pheromone concentrations. The pheromone trail allows theants to find their way back to the food source or to the nest. Also, it can be used byother ants to find the location of the food sources found by their nestmates.It has been shown experimentally that this pheromone trail following behavior cangive rise, once employed by a colony of ants, to the emergence of shortest paths. Thatis, when more paths are available from the nest to a food source, a colony of antsmay be able to exploit the pheromone trails left by the individual ants to discover theshortest path from the nest to the food source and back.c 1999 Massachusetts Institute of Technology Artificial Life 5 137172 1999M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimization15 cmNest FoodUpper BranchLower Brancha02550751000 5 10 15 20 25 30Time minutes Passages upper branch  Passages lower branchbFigure 1. Single bridge experiment. a Experimental setup. b Results for a typical single trial, showing thepercentage of passages on each of the two branches per unit of time as a function of time. Eventually, after an initialshort transitory phase, the upper branch becomes the most used. After Deneubourg et al., 1990 25.To study in controlled conditions the ants foraging behavior, the binary bridge experiment has been set up by Deneubourg et al. 25 see Figure 1a. The nest of a colonyof ants of the species Linepithema humile and a food source have been separated bya double bridge in which each branch has the same length. Ants are then left free tomove between the nest and the food source and the percentage of ants that chooseone or the other of the two branches is observed over time. The result see Figure 1bis that after an initial transitory phase in which some oscillations can appear, ants tendto converge on a same path.In the above experiment initially there is no pheromone on the two branches, whichare therefore selected by the ants with the same probability. Nevertheless, randomfluctuations, after an initial transitory phase, cause a few more ants to select one branchrandomly, the upper one in the experiment shown in Figure 1a, over the other. Becauseants deposit pheromone while walking, the greater number of ants on the upper branchdetermines a greater amount of pheromone on it, which in turn stimulates more antsto choose it, and so on. The probabilistic model that describes this phenomenon,which closely matches the experimental observations, is the following 60. We firstmake the assumption that the amount of pheromone on a branch is proportional tothe number of ants that used the branch in the past. This assumption implies thatpheromone evaporation is not taken into account. Given that an experiment typicallylasts approximately one hour, it is plausible to assume that the amount of pheromoneevaporated in this time period is negligible. In the model, the probability of choosinga branch at a certain time depends on the total amount of pheromone on the branch,which in turn is proportional to the number of ants that used the branch until that time.More precisely, let Um and Lm be the numbers of ants that have used the upper andlower branch after m ants have crossed the bridge, with Um Lm  m. The probabilityPU m with which the m  1th ant chooses the upper branch isPU m  Um  khUm  kh  Lm  kh 1while the probability PLm that it chooses the lower branch is PLm  1  PU m.This functional form of the probability of choosing one branch over the other wasobtained from experiments on trail following 83 the parameters h and k allow us tofit the model to experimental data. The ant choice dynamics follows from the above138 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete OptimizationForaging areaNestaForaging areaNestb0 20 40 60 80 10002020404060608080100 of experimentscFigure 2. Double bridge experiment. a Ants start exploring the double bridge. b Eventually most of the antschoose the shortest path. c Distribution of the percentage of ants that selected the shorter path. After Goss etal. 1989 60.equation Um1  Um  1, if   PU ,Um1  Um otherwise, where  is a randomvariable uniformly distributed over the interval 0,1.Monte Carlo simulations were run to test the correspondence between this modeland the real data Results of simulations were in agreement with the experiments withreal ants when parameters were set to k  20 and h  2 83.It is easy to modify the experiment above to the case in which the bridges branchesare of different length 60, and to extend the model of Equation 1 so that it can describethis new situation. In this case, because of the same pheromonelaying mechanism asin the previous situation, the shortest branch is most often selected The first ants toarrive at the food source are those that took the two shortest branches, so that, whenthese ants start their return trip, more pheromone is present on the short branch thanon the long branch, stimulating successive ants to choose the short branch. In thiscase, the importance of initial random fluctuations is much reduced, and the stochasticpheromone trail following behavior of the ants coupled to differential branch lengthis the main mechanism at work. In Figure 2 are shown the experimental apparatusand the typical result of an experiment with a double bridge with branches of differentlengths.It is clear that what is going on in the abovedescribed process is a kind of distributedoptimization mechanism to which each single ant gives only a very small contribution.It is interesting that, although a single ant is in principle capable of building a solutioni.e., of finding a path between nest and food reservoir, it is only the ensemble of ants,that is, the ant colony, that presents the shortest pathfinding behavior.1 In a sense,this behavior is an emergent property of the ant colony. It is also interesting to note thatants can perform this specific behavior using a simple form of indirect communicationmediated by pheromone laying, known as stigmergy 62.1 The abovedescribed experiments have been run in strongly constrained conditions. A formal proof of the pheromonedrivenshortest pathfinding behavior in the general case is missing. Bruckstein et al. 9, 10 consider the shortest pathfinding problemin absence of obstacles for ants driven by visual clues and not by pheromones and prove the convergence of the ants path to thestraight line.Artificial Life Volume 5, Number 2 139M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete OptimizationAs defined by Grasse in his work on Bellicositermes Natalensis and Cubitermes62, stigmergy is the stimulation of the workers by the very performances they haveachieved p. 79.2In fact, Grasse 61 observed that insects are capable of responding to socalledsignificant stimuli that activate a genetically encoded reaction. In social insects, ofwhich termites and ants are some of the best known examples, the effects of thesereactions can act as new significant stimuli for both the insect that produced themand for other insects in the colony. The production of a new significant stimulus as aconsequence of the reaction to a significant stimulus determines a form of coordinationof the activities and can be interpreted as a form of indirect communication. Forexample, Grasse 62 observed that Bellicositermes Natalensis as well as Cubitermes,when building a new nest, start by a random, noncoordinated activity of earth pelletdepositing. But once the earth pellets reach a certain density in a restricted area theybecome a new significant stimulus that causes more termites to add earth pellets sothat pillar and arches, and eventually the whole nest, are built.What characterizes stigmergy from other means of communication is a the physicalnature of the information released by the communicating insects, which corresponds toa modification of physical environmental states visited by the insects, and b the localnature of the released information, which can only be accessed by insects that visit thestate in which it was released or some neighborhood of that state.Accordingly, in this article we take the stance that it is possible to talk of stigmergetic communication whenever there is an indirect communication mediated byphysical modifications of environmental states which are only locally accessible by thecommunicating agents.One of the main tenets of this article is that the stigmergetic model of communication in general, and the one inspired by ants foraging behavior in particular, is aninteresting model for artificial multiagent systems applied to the solution of difficultoptimization problems. In fact, the abovementioned characteristics of stigmergy caneasily be extended to artificial agents by a associating with problem states appropriatestate variables, and b giving the artificial agents only local access to these variablesvalues.For example, in the abovedescribed foraging behavior of ants, stigmergetic communication is at work via the pheromone that ants deposit on the ground while walking.Correspondingly, our artificial ants will simulate pheromone laying by modifying appropriate pheromone variables associated with problem states they visit while buildingsolutions to the optimization problem to which they are applied. Also, according tothe stigmergetic communication model, our artificial ants will have only local access tothese pheromone variables.Another important aspect of real ants foraging behavior that is exploited by artificialants is the coupling between the autocatalytic positive feedback mechanism 40 andthe implicit evaluation of solutions. By implicit solution evaluation we mean the factthat shorter paths which correspond to lower cost solutions in artificial ants will becompleted earlier than longer ones, and therefore they will receive pheromone reinforcement more quickly. Implicit solution evaluation coupled with autocatalysis canbe very effective The shorter the path, the sooner the pheromone is deposited by theants, the more the ants that use the shorter path. If appropriately used, autocatalysiscan be a powerful mechanism in populationbased optimization algorithms e.g., inevolutionary computation algorithms 45, 66, 85, 91 autocatalysis is implemented bythe selectionreproduction mechanism. In fact, it quickly favors the best individuals,2 Workers are one of the castes in termite colonies. Although Grasse introduced the term stigmergy to explain the behavior oftermite societies, the same term has been used to describe indirect communication mediated by modifications of the environmentthat can also be observed in other social insects.140 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimizationso that they can direct the search process. When using autocatalysis some care mustbe taken to avoid premature convergence stagnation, that is, the situation in whichsome not very good individual takes over the population just because of a contingentsituation e.g., because of a local optimum, or just because of initial random fluctuations that caused a not very good individual to be much better than all the otherindividuals in the population impeding further exploration of the search space. Wewill see that pheromone trail evaporation and stochastic state transitions are the neededcomplements to autocatalysis drawbacks.In the remainder of this article we discuss a number of ant algorithms based onthe above ideas. We start by defining, in Section 2, the characterizing aspects of antalgorithms and the ant colony optimization ACO metaheuristic.3 Section 3 is anoverview of most of the applications of ACO algorithms. In Section 4 we briefly discussrelated work, and in Section 5 we discuss some of the characteristics of implementedACO algorithms. Finally, we draw some conclusions in Section 6.2 The Ant Colony Optimization ApproachIn the ant colony optimization ACO metaheuristic a colony of artificial ants cooperatesin finding good solutions to difficult discrete optimization problems. Cooperation is akey design component of ACO algorithms The choice is to allocate the computationalresources to a set of relatively simple agents artificial ants that communicate indirectlyby stigmergy. Good solutions are an emergent property of the agents cooperativeinteraction.Artificial ants have a double nature. On the one hand, they are an abstraction of thosebehavioral traits of real ants that seemed to be at the heart of the shortest pathfindingbehavior observed in real ant colonies. On the other hand, they have been enrichedwith some capabilities that do not find a natural counterpart. In fact, we want antcolony optimization to be an engineering approach to the design and implementationof software systems for the solution of difficult optimization problems. It is thereforereasonable to give artificial ants some capabilities that, although not corresponding toany capacity of their real ant counterparts, make them more effective and efficient. Inthe following we discuss first the natureinspired characteristics of artificial ants, andthen how they differ from real ants.2.1 Similarities and Differences with Real AntsMost of the ideas of ACO stem from real ants. In particular, the use of a a colony ofcooperating individuals, b an artificial pheromone trail for local stigmergetic communication, c a sequence of local moves to find shortest paths, and d a stochasticdecision policy using local information and no lookahead.Colony of cooperating individuals. As real ant colonies, ant algorithms are composedof a population, or colony, of concurrent and asynchronous entities globally cooperating to find a good solution to the task under consideration. Although the complexityof each artificial ant is such that it can build a feasible solution as a real ant can somehow find a path between the nest and the food, high quality solutions are the result ofthe cooperation among the individuals of the whole colony. Ants cooperate by meansof the information they concurrently readwrite on the problems states they visit, asexplained in the next item.3 It is important here to clarify briefly the terminology used. We talk of ACO metaheuristic to refer to the general procedurepresented in Section 2. The term ACO algorithm will be used to indicate any generic instantiation of the ACO metaheuristic.Alternatively, we will also talk more informally of ant algorithms to indicate any algorithm that, while following the generalguidelines set above, does not necessarily follow all the aspects of the ACO metaheuristic. Therefore, all ACO algorithms are alsoant algorithms, though the converse is not true e.g., we will see that HASQAP is an ant, but not strictly an ACO algorithm.Artificial Life Volume 5, Number 2 141M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete OptimizationPheromone trail and stigmergy. Artificial ants modify some aspects of their environment as the real ants do. While real ants deposit on the worlds state they visit achemical substance, the pheromone, artificial ants change some numeric informationlocally stored in the problems state they visit. This information takes into accountthe ants current history or performance and can be readwritten by any ant accessing the state. By analogy, we call this numeric information artificial pheromone trail,pheromone trail for short in the following. In ACO algorithms local pheromone trailsare the only communication channels among the ants. This stigmergetic form of communication plays a major role in the utilization of collective knowledge. Its main effectis to change the way the environment the problem landscape is locally perceived bythe ants as a function of all the past history of the whole ant colony. Usually, in ACOalgorithms an evaporation mechanism, similar to real pheromone evaporation, modifies pheromone information over time. Pheromone evaporation allows the ant colonyslowly to forget its past history so that it can direct its search toward new directionswithout being overconstrained by past decisions.Shortest path searching and local moves. Artificial and real ants share a commontask to find a shortest minimum cost path joining an origin nest to destinationfood sites. Real ants do not jump they just walk through adjacent terrains states, andso do artificial ants, moving stepbystep through adjacent states of the problem. Ofcourse, exact definitions of state and adjacency are problem specific.Stochastic and myopic state transition policy. Artificial ants, as real ones, build solutions applying a probabilistic decision policy to move through adjacent states. As forreal ants, the artificial ants policy makes use of local information only and it does notmake use of lookahead to predict future states. Therefore, the applied policy is completely local, in space and time. The policy is a function of both the a priori informationrepresented by the problem specifications equivalent to the terrains structure for realants, and of the local modifications in the environment pheromone trails induced bypast ants.As we said, artificial ants also have some characteristics that do not find their counterpart in real ants. Artificial ants live in a discrete world and their moves consist of transitions fromdiscrete states to discrete states. Artificial ants have an internal state. This private state contains the memory of theants past actions. Artificial ants deposit an amount of pheromone that is a function of the quality ofthe solution found.4 Artificial ants timing in pheromone laying is problem dependent and often doesnot reflect real ants behavior. For example, in many cases artificial ants updatepheromone trails only after having generated a solution. To improve overall system efficiency, ACO algorithms can be enriched with extracapabilities such as lookahead, local optimization, backtracking, and so on thatcannot be found in real ants. In many implementations ants have been hybridizedwith local optimization procedures see, e.g., 38, 51, 98, while, so far, only Micheland Middendorf 78 have used a simple onestep lookahead function and there areno examples of backtracking procedures added to the basic ant capabilities, exceptfor simple recovery procedures used by Di Caro and Dorigo 26, 29.54 In reality, some real ants have a similar behavior They deposit more pheromone in case of richer food sources.5 Usually, backtracking strategies are suitable to solve constraint satisfaction problems, e.g., nqueens and lookahead is very useful142 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete OptimizationIn the following section we will show how artificial ants can be put to work inan algorithmic framework so that they can be applied to discrete optimizationproblems.2.2 The ACO MetaheuristicIn ACO algorithms a finitesize colony of artificial ants with the abovedescribed characteristics collectively searches for goodquality solutions to the optimization problem under consideration. Each ant builds a solution, or a component of it,6 startingfrom an initial state selected according to some problemdependent criteria. Whilebuilding its own solution, each ant collects information on the problem characteristics and on its own performance and uses this information to modify the representation of the problem, as seen by the other ants. Ants can act concurrently andindependently, showing a cooperative behavior. They do not use direct communication It is the stigmergy paradigm that governs the information exchange among theants.An incremental constructive approach is used by the ants to search for a feasible solution. A solution is expressed as a minimum cost shortest path throughthe states of the problem in accordance with the problems constraints. The complexity of each ant is such that even a single ant is able to find a probably poorquality solution. Highquality solutions are only found as the emergent result of theglobal cooperation among all the agents of the colony concurrently building differentsolutions.According to the assigned notion of neighborhood problemdependent, each antbuilds a solution by moving through a finite sequence of neighbor states. Movesare selected by applying a stochastic local search policy directed a by ant privateinformation the ant internal state, or memory and b by publicly available pheromonetrails and a priori problemspecific local information.The ants internal state stores information about the ant past history. It can beused to carry useful information to compute the valuegoodness of the generated solution andor the contribution of each executed move. Moreover it can play a fundamental role to manage the feasibility of the solutions. In some problems, in fact,typically in combinatorial optimization, some of the moves available to an ant in astate can take the ant to an infeasible state. This can be avoided by exploiting theants memory. Ants therefore can build feasible solutions using only knowledge aboutthe local state and about the effects of actions that can be performed in the localstate.The local, public information comprises both some problemspecific heuristic information and the knowledge, coded in the pheromone trails, accumulated by all the antsfrom the beginning of the search process. This timeglobal pheromone knowledge builtup by the ants is a shared local longterm memory that influences the ants decisions.The decisions about when the ants should release pheromone on the environmentand how much pheromone should be deposited depend on the characteristics of theproblem and on the design of the implementation. Ants can release pheromone whilebuilding the solution online stepbystep, or after a solution has been built, movingback to all the visited states online delayed, or both. As we said, autocatalysis playswhen the cost of making a local prediction about the effect of future moves is much lower than the cost of the real execution ofthe move sequence e.g., mobile robotics. To our knowledge, until now ACO algorithms have not been applied to these classesof problems.6 To make more intuitive what we mean by component of a solution, we can consider, as an example, a transportation routingproblem Given a set of n cities, ci, i  1, . . . , n, and a network of interconnection roads, we want to find all the shortest pathssij connecting each city pair cicj . In this case, a complete solution is represented by the set of all the nn 1 shortest path pairs,while a component of a solution is a single path sij .Artificial Life Volume 5, Number 2 143M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimizationan important role in ACO algorithms functioning The more ants choose a move, themore the move is rewarded by adding pheromone and the more interesting it becomes for the next ants. In general, the amount of pheromone deposited is madeproportional to the goodness of the solution an ant has built or is building. In thisway, if a move contributed to generating a highquality solution its goodness will beincreased proportionally to its contribution.A functional composition of the locally available pheromone and heuristic valuesdefines antdecision tables, that is, probabilistic tables used by the ants decision policyto direct their search toward the most interesting regions of the search space. Thestochastic component of the move choice decision policy and the previously discussed pheromone evaporation mechanism prevent a rapid drift of all the ants toward the same part of the search space. Of course, the level of stochasticity in thepolicy and the strength of the updates in the pheromone trail determine the balance between the exploration of new points in the state space and the exploitationof accumulated knowledge. If necessary and feasible, the ants decision policy canbe enriched with problemspecific components such as backtracking procedures orlookahead. Once an ant has accomplished its task, consisting of building a solutionand depositing pheromone information, the ant dies, that is, it is deleted from thesystem.The overall ACO metaheuristic, besides the two abovedescribed components actingfrom a local perspective i.e., ants generation and activity, and pheromone evaporation, can also comprise some extra components that use global information and thatgo under the name of daemon actions in the algorithm reported in Figure 3. Forexample, a daemon can be allowed to observe the ants behavior and to collect usefulglobal information to deposit additional pheromone information, biasing, in this way,the ant search process from a nonlocal perspective. Or, it could, on the basis of theobservation of all the solutions generated by the ants, apply problemspecific local optimization procedures and deposit additional pheromone offline with respect to thepheromone the ants deposited online.The three main activities of an ACO algorithm ant generation and activity, pheromoneevaporation, and daemon actions may need some kind of synchronization, performedby the schedule activities construct of Figure 3. In general, a strictly sequentialscheduling of the activities is particularly suitable for nondistributed problems, wherethe global knowledge is easily accessible at any instant and the operations can beconveniently synchronized. On the contrary, some form of parallelism can be easilyand efficiently exploited in distributed problems such as routing in telecommunicationsnetworks, as will be discussed in Section 3.2.In Figure 3, a highlevel description of the ACO metaheuristic is reported in pseudocode. As pointed out above, some described components and behaviors are optional,such as daemon activities, or strictly implementation dependent, such as when and howthe pheromone is deposited. In general, the online stepbystep pheromone updateand the online delayed pheromone update components respectively, lines 2427 and3034 in the new active ant procedure are mutually exclusive and only in a fewcases are they both present or both absent when both components are absent, thepheromone is deposited by the daemon.ACO algorithms, as a consequence of their concurrent and adaptive nature, areparticularly suitable for distributed stochastic problems where the presence of exogenous sources determines a nonstationarity in the problem representation in terms ofcosts andor environment. For example, many problems related to communicationsor transportation networks are intrinsically distributed and nonstationary and it is oftennot possible to have an exact model of the underlying variability. On the contrary,because stigmergy is both the only interant communication method and it is spatially144 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimization1 procedure ACO Meta heuristic2 while termination criterion not satisfied3 schedule activities4 ants generation and activity5 pheromone evaporation6 daemon actions foptionalg7 end schedule activities8 end while9 end procedure10 procedure ants generation and activity11 while available resources12 schedule the creation of a new ant13 new active ant14 end while15 end procedure16 procedure new active ant fant lifecycleg17 initialize ant18 M  update ant memory19 while current state 6 target state20 A  read local antrouting table21 P  compute transition probabilitiesAM problem constraints22 next state  apply ant decision policyP problem constraints23 move to next statenext state24 if online stepbystep pheromone update25 deposit pheromone on the visited arc26 update antrouting table27 end if28 M  update internal state29 end while30 if online delayed pheromone update31 evaluate solution32 deposit pheromone on all visited arcs33 update antrouting table34 end if35 die36 end procedureFigure 3. The ACO metaheuristic in pseudocode. Comments are enclosed in braces. All the procedures at the firstlevel of indentation in the statement in parallel are executed concurrently. The procedure daemon actionsat line 6 is optional and refers to centralized actions executed by a daemon possessing global knowledge. Thetarget state line 19 refers to a complete solution, or to a component of a complete solution, built by theant. The stepbystep and delayed pheromone updating procedures at lines 2427 and 3034 are often mutuallyexclusive. When both of them are absent the pheromone is deposited by the daemon.localized, ACO algorithms could perform not at their best in problems where each statehas a largesized neighborhood. In fact, an ant that visits a state with a largesizedneighborhood has a huge number of possible moves among which to choose. Therefore, the probability that many ants visit the same state is very small, and consequentlythere is little, if any, difference between using or not using pheromone trails. A moreformal definition of the ACO metaheuristic, as well as of the class of problems to whichit can be applied, can be found in 35.Artificial Life Volume 5, Number 2 145M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimization3 Applications of ACO AlgorithmsThere are now available numerous successful implementations of the ACO metaheuristic Figure 3 applied to a number of different combinatorial optimization problems.Looking at these implementations it is possible to distinguish among two classes of applications those to static combinatorial optimization problems, and those to dynamicones.Static problems are those in which the characteristics of the problem are given onceand for all when the problem is defined and do not change while the problem is beingsolved. A paradigmatic example of such problems is the classic traveling salesmanproblem 67, 71, 86, in which city locations and their relative distances are part of theproblem definition and do not change at run time. On the contrary, dynamic problemsare defined as a function of some quantities whose value is set by the dynamics ofan underlying system. The problem changes therefore at run time and the optimization algorithm must be capable of adapting online to the changing environment. Theparadigmatic example discussed in the remainder of this section is network routing.Topological modifications e.g., adding or removing a node, which are not considered by the above classification, can be seen as transitions between problems belongingto the same class.Tables 1 and 2 list the available implementations of ACO algorithms. The maincharacteristics of the listed algorithms are discussed in the following two subsections.We then conclude with a brief review of existing parallel implementations of ACOalgorithms.3.1 Applications of ACO Algorithms to Static Combinatorial OptimizationProblemsThe application of the ACO metaheuristic to a static combinatorial optimization problemis relatively straightforward, once a mapping of the problem that allows the incrementalconstruction of a solution, a neighborhood structure, and a stochastic state transitionrule to be locally used to direct the constructive procedure is defined.A strictly implementationdependent aspect of the ACO metaheuristic regards thetiming of pheromone updates lines 2427 and 3034 of the algorithm in Figure 3. InACO algorithms for static combinatorial optimization the way ants update pheromonetrails changes across algorithms Any combination of online stepbystep pheromoneupdates and online delayed pheromone updates is possible.Another important implementationdependent aspect concerns the daemonactions component of the ACO metaheuristic line 6 of the algorithm in Figure 3.Daemon actions implement actions that require some kind of global knowledge aboutthe problem. Examples are offline pheromone updates and local optimization of solutions built by ants.Most of the ACO algorithms presented in this subsection are strongly inspired byAnt System AS, the first work on ant colony optimization 33, 40. Many of thesuccessive applications of the original idea are relatively straightforward applicationsof AS to the specific problem under consideration. We therefore start the descriptionof ACO algorithms with AS. Following AS, for each ACO algorithm listed in Table 1we give a short description of the algorithms main characteristics and of the resultsobtained.3.1.1 Traveling Salesman ProblemThe first application of an ant colony optimization algorithm was done using the traveling salesman problem as a test problem. The main reasons why the TSP, one of themost studied NPhard 71, 86 problems in combinatorial optimization, was chosen are146 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete OptimizationTable 1. List of applications of ACO algorithms to static combinatorial optimization problems. Classification byapplication and chronologically ordered.Problem Authors Year Main Algorithmname references nameTraveling Dorigo, Maniezzo,  Colorni 1991 33, 40, 41 ASsalesman Gambardella  Dorigo 1995 49 AntQDorigo  Gambardella 1996 37, 38, 50 ACS ACS3optStutzle  Hoos 1997 98, 97 MMASBullnheimer, Hartl,  Strauss 1997 12 ASrankQuadratic Maniezzo, Colorni,  Dorigo 1994 77 ASQAPassignment Gambardella, Taillard,  Dorigo 1997 53, 54 HASQAPaStutzle  Hoos 1998 99 MMASQAPManiezzo  Colorni 1998 76 ASQAPbManiezzo 1998 75 ANTSQAPJobshop Colorni, Dorigo,  Maniezzo 1994 20 ASJSPschedulingVehicle Bullnheimer, Hartl,  Strauss 1996 15, 11, 13 ASVRProuting Gambardella, Taillard,  Agazzi 1999 52 HASVRPSequential Gambardella  Dorigo 1997 51 HASSOPorderingGraph Costa  Hertz 1997 22 ANTCOLcoloringShortest common Michel  Middendorf 1998 78, 79 ASSCSsupersequencea HASQAP is an ant algorithm that does not follow all the aspects of the ACOmetaheuristic.b This is a variant of the original ASQAP.Table 2. List of applications of ACO algorithms to dynamic combinatorial optimization problems. Classification byapplication and chronologically ordered.Problem name Authors Year Main Algorithmreferences nameConnectionoriented Schoonderwoerd, Holland, 1996 90, 89 ABCnetwork routing Bruten,  RothkrantzWhite, Pagurek,  Oppacher 1998 105 ASGADi Caro  Dorigo 1998 30 AntNetFSBonabeau, Henaux, Guerin, 1998 6 ABCsmartSnyers, Kuntz,  Theraulaz antsConnectionless Di Caro  Dorigo 1997 26, 29, 32 AntNet network routing AntNetFASubramanian, Druschel, 1997 100 Regular ants ChenHeusse, Guerin, Snyers, 1998 64 CAF Kuntzvan der Put  Rothkrantz 1998 102, 103 ABCbackwardArtificial Life Volume 5, Number 2 147M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimizationthat it is a shortest path problem to which the ant colony metaphor is easily adaptedand that it is a didactic problem i.e., it is very easy to understand and explanations ofthe algorithm behavior are not obscured by too many technicalities.A general definition of the traveling salesman problem is the following. Consider aset N of nodes, representing cities, and a set E of arcs fully connecting the nodes N .Let dij be the length of the arc i, j  E , that is, the distance between cities i and j ,with i, j  N . The TSP is the problem of finding a minimal length Hamiltonian circuiton the graph G  N , E , where a Hamiltonian circuit of graph G is a closed tourvisiting once and only once all the n  N  nodes of G , and its length is given by thesum of the lengths of all the arcs of which it is composed.7In the following we will briefly overview the ACO algorithms that have been proposed for the TSP, starting with Ant System. A more complete overview can be foundin 96.Ant System AS. Ant System was the first 1991 33, 40 ACO algorithm. Its importance resides mainly in being the prototype of a number of ant algorithms that havefound many interesting and successful applications.In AS, artificial ants build solutions tours of the TSP by moving on the problemgraph from one city to another. The algorithm executes tmax iterations, in the followingindexed by t . During each iteration m ants build a tour executing n steps in whicha probabilistic decision state transition rule is applied. In practice, when in node ithe ant chooses the node j to move to, and the arc i, j is added to the tour underconstruction. This step is repeated until the ant has completed its tour.Three AS algorithms have been defined 19, 33, 40, 41 that differ by the waypheromone trails are updated. These algorithms are called antdensity, antquantity,and antcycle. In antdensity and antquantity ants deposit pheromone while buildinga solution,8 while in antcycle ants deposit pheromone after they have built a completetour.Preliminary experiments run on a set of benchmark problems 33, 40, 41 haveshown that antcycles performance was much better than that of the other two algorithms. Consequently, research on AS was directed toward a better understandingof the characteristics of antcycle, which is now known as Ant System, while the othertwo algorithms were abandoned.As we said, in AS after ants have built their tours, each ant deposits pheromone onpheromone trail variables associated to the visited arcs to make the visited arcs becomemore desirable for future ants i.e., online delayed pheromone update is at work.Then the ants die. In AS no daemon activities are performed, while the pheromoneevaporation procedure, which happens just before ants start to deposit pheromone, isinterleaved with the ants activity.The amount of pheromone trail ij t associated to arc i, j is intended to representthe learned desirability of choosing city j when in city i which also corresponds to thedesirability that the arc i, j belongs to the tour built by an ant. The pheromone trailinformation is changed during problem solution to reflect the experience acquired byants during problem solving. Ants deposit an amount of pheromone proportional tothe quality of the solutions they produced The shorter the tour generated by an ant,the greater the amount of pheromone it deposits on the arcs that it used to generatethe tour. This choice helps to direct search toward good solutions. The main role ofpheromone evaporation is to avoid stagnation, that is, the situation in which all antsend up doing the same tour.7 Note that distances need not be symmetric In an asymmetric TSP ATSP dij 6 dji . Also, the graph need not be fully connected.If it is not, it suffices to add the missing arcs, giving them a very high length.8 These two algorithms differ by the amount of pheromone ants deposit at each step In antdensity ants deposit a constant amountof pheromone, while in antquantity they deposit an amount of pheromone inversely proportional to the length of the chosen arc.148 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete OptimizationThe memory or internal state of each ant contains the already visited cities and iscalled tabu list in the following we will continue to use the term tabu list9 to indicatethe ants memory. The memory is used to define, for each ant k, the set of cities thatan ant located on city i still has to visit. By exploiting the memory, therefore, an ant kcan build feasible solutions by an implicit statespace graph generation in the TSP thiscorresponds to visiting a city exactly once. Also, memory allows the ant to cover thesame path to deposit online delayed pheromone on the visited arcs.The antdecision table Ai  aij tNi  of node i is obtained by the composition ofthe local pheromone trail values with the local heuristic values as followsaij t ij t ij lNiil t il  j  Ni 2where ij t is the amount of pheromone trail on arc i, j at time t , ij  1dij is theheuristic value of moving from node i to node j , Ni is the set of neighbors of nodei, and  and  are two parameters that control the relative weight of pheromone trailand heuristic value.The probability with which an ant k chooses to go from city i to city j  N ki whilebuilding its tour at the tth algorithm iteration ispkij t aij tlN kiail t3where N ki  Ni is the set of nodes in the neighborhood of node i that ant k hasnot visited yet nodes in N ki are selected from those in Ni by using the ant privatememoryMk.The role of the parameters  and  is the following. If   0, the closest cities aremore likely to be selected This corresponds to a classical stochastic greedy algorithmwith multiple starting points since ants are initially randomly distributed on the nodes.If, on the contrary,   0, only pheromone amplification is at work This method willlead to the rapid emergence of a stagnation situation with the corresponding generationof tours that, in general, are strongly suboptimal 41. A tradeoff between heuristicvalue and trail intensity therefore appears to be necessary.After all ants have completed their tour, pheromone evaporation on all arcs is triggered, and then each ant k deposits a quantity of pheromone 1 kij t on each arc thatit has used1 kij t 1Lkt if i, j  T kt0 if i, j  T kt 4where T kt is the tour done by ant k at iteration t , and Lkt is its length. Note thatin the symmetric TSP arcs are considered to be bidirectional so that arcs i, j and j, i are always updated contemporaneously in fact, they are the same arc. Differentis the case of the asymmetric TSP, where arcs have a directionality, and for which thepheromone trail level on the arcs i, j and  j, i can be different. In this case, therefore,when an ant moves from node i to node j only arc i, j, and not  j, i, is updated.9 The term tabu list is used here to indicate a simple memory that contains the set of already visited cities and has no relation withtabu search 57, 58.Artificial Life Volume 5, Number 2 149M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete OptimizationIt is clear from Equation 4 that the value 1 kij t depends on how well the ant hasperformed The shorter the tour done, the greater the amount of pheromone deposited.In practice, the addition of new pheromone by ants and pheromone evaporation areimplemented by the following rule applied to all the arcsij t 1 ij t1ij t 5where 1ij t mk11kij t, m is the number of ants at each iteration maintainedconstant, and   0, 1 is the pheromone trail decay coefficient. The initial amountof pheromone ij 0 is set to a same small positive constant value 0 on all arcs, andthe total number of ants is set to m  n, while , , and  are respectively set to1, 5, and 0.5 these values were experimentally found to be good by Dorigo 33.Dorigo et al. 40 introduced also elitist ants, that is, a daemon action by which the arcsused by the ant that generated the best tour from the beginning of the trial get extrapheromone.Ant System was compared with other general purpose heuristics on some relativelysmall TSP problems these were problems ranging from 30 to 75 cities. The results40, 41 were very interesting and disappointing at the same time. AS was able to findand improve the best solution found by a genetic algorithm for Oliver30 106, a 30cityproblem, and it had a performance similar or better than that of some generalpurposeheuristics with which it was compared. Unfortunately, for problems of growing dimensions AS never reached the bestknown solutions within the allowed 3,000 iterations,although it exhibited quick convergence to good solutions. These encouraging, although not exceptional, results stimulated a number of researchers to study further theACO approach to optimization. These efforts have resulted in numerous successfulapplications, listed in the following sections.Others ASlike approaches. Stutzle and Hoos 98, 97 have introduced MaxMin ASMMAS, which is the same as AS, but a pheromone trails are only updated offlineby the daemon the arcs that were used by the best ant in the current iteration receive additional pheromone, b pheromone trail values are restricted to an intervalmin, max, and c trails are initialized to their maximum value max.Putting explicit limits on the trail strength restricts the range of possible values forthe probability of choosing a specific arc according to Equation 3. This helps avoidstagnation, which was one of the reasons why AS performed poorly when an elitiststrategy, such as allowing only the best ant to update pheromone trails, was used.To avoid stagnation, which may occur when some pheromone trails are close to maxwhile most others are close to min, Stutzle and Hoos have added what they call a trailsmoothing mechanism that is, pheromone trails are updated using a proportionalmechanism 1ij  max  ij t. In this way the relative difference between thetrail strengths gets smaller, which obviously favors the exploration of new paths. Theyfound that, when applied to the TSP, MMAS finds significantly better tours than AS,although comparable to those obtained with ACS. ACS is an extension of AS discussedin the next subsection.Bullnheimer, Hartl, and Strauss 12 proposed yet another modification of AS, calledASrank. In ASrank, as was the case in MMAS, the only pheromone updates are performed by the daemon, which implements the following activities a the m antsare ranked by tour length L1t, L2t, . . . , Lmt and the arcs that were visited byone of the first   1 ants in the ranking receive an amount of pheromone proportional to the visiting ant rank, and b the arcs used by the ant that generated thebest tour from the beginning of the trial also receive additional pheromone this isequivalent to ASs elitist ants pheromone updating. These are both forms of offline pheromone update. In their implementation the contribution of the best tour so150 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimizationfar was multiplied by  . The dynamics of the amount of pheromone ij t is givenbyij t 1 ij t 1ij t1 rij t 6where 1ij t  1Lt, L being the length of the best solution from beginning ofthe trial, and 1 rij t 111ij t, with 1ij t    1Lt if the ant withrank  has used arc i, j in its tour and 1ij t  0 otherwise. Lt is the length ofthe tour performed by the ant with rank  at iteration t . Equation 6 is applied to allarcs and implements therefore both pheromone evaporation and offline pheromoneupdating. They found that this new procedure improves significantly the quality of theresults obtained with AS.Ant Colony System ACS, ACS3opt, and AntQ. The Ant Colony System ACSalgorithm has been introduced by Dorigo and Gambardella 37, 38, 50 to improve theperformance of AS, which was able to find good solutions within a reasonable timeonly for small problems. ACS is based on AS but presents some important differences.First, the daemon updates pheromone trails offline At the end of an iteration of thealgorithm, once all the ants have built a solution, pheromone trail is added to the arcsused by the ant that found the best tour from the beginning of the trial. In ACS3optthe daemon first activates a local search procedure based on a variant of the 3opt localsearch procedure 73 to improve the solutions generated by the ants and then performsoffline pheromone trail update. The offline pheromone trail update rule isij t 1 ij t 1ij t 7where   0, 1 is a parameter governing pheromone decay, 1ij t  1L, and Lis the length of T , the best tour since the beginning of the trial. Equation 7 is appliedonly to the arcs i, j belonging to T .Second, ants use a different decision rule, called pseudorandomproportional rule,in which an ant k on city i chooses the city j  N ki to move to as follows. LetAi  aij tNi  be the antdecision tableaij t ij tij lNi il til  j  Ni 8Let q be a random variable uniformly distributed over 0, 1, and q0  0, 1 be atunable parameter. The pseudorandomproportional rule, used by ant k located innode i to choose the next node j  N ki , is the following If q  q0 thenpkij t 1 if j  arg max aij0 otherwise9otherwise, when q  q0pkij t aij tlN ki ail t10This decision rule has a double function When q  q0 the decision rule exploits theknowledge available about the problem, that is, the heuristic knowledge about distancesbetween cities and the learned knowledge memorized in the form of pheromone trails,Artificial Life Volume 5, Number 2 151M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimizationwhile when q  q0 it operates a biased exploration equivalent to ASs Equation 3. Tuning q0 allows us to modulate the degree of exploration and to choose whether to concentrate the activity of the system on the best solutions or to explore the search space.Third, in ACS, ants perform only online stepbystep pheromone updates. Theseupdates are performed to favor the emergence of other solutions than the best so far.The pheromone updates are performed by applying the ruleij t 1 ij t 0 11where 0    1.Equation 11 says that an ant moving from city i to city j  N ki updates the pheromonetrail on arc i, j. The value 0 is the same as the initial value of pheromone trails andit was experimentally found that setting 0  nLnn1, where n is the number ofcities and Lnn is the length of a tour produced by the nearest neighbor heuristic 56,produces good results. When an ant moves from city i to city j , the application of thelocal update rule makes the corresponding pheromone trail ij decrease. The rationalefor decreasing the pheromone trail on the path an ant is using to build a solution is thefollowing. Consider an ant k2 starting in city 2 and moving to city 3, 4, and so on, andan ant k1 starting in city 1 and choosing city 2 as the first city to move to. Then, thereare good chances that ant k1 will follow ant k2 with one step delay. The traildecreasingeffect obtained by applying the local update rule reduces the risk of such a situation.In other words, ACSs local update rule has the effect of making the visited arcs lessand less attractive as they are visited by ants, indirectly favoring the exploration ofnotyetvisited arcs. As a consequence, ants tend not to converge to a common path.This fact, which was observed experimentally 38, is a desirable property given thatif ants explore different paths, then there is a higher probability that one of them willfind an improving solution than in the case when they all converge to the same tourwhich would make the use of m ants pointless.Last, ACS exploits a data structure called candidate list, which provides additionallocal heuristic information. A candidate list is a list of preferred cities to be visited froma given city. In ACS when an ant is in city i, instead of examining all the unvisitedneighbors of i, it chooses the city to move to among those in the candidate list only ifno city in candidate list has unvisited status are other cities examined. The candidate listof a city contains cl cities ordered by increasing distance cl is a parameter, and the listis scanned sequentially and according to the ant tabu list to avoid already visited cities.ACS was tested see 37, 38 for detailed results on standard problems, both symmetric and asymmetric, of various sizes and compared with many other metaheuristics.In all cases, its performance, both in terms of quality of the solutions generated and ofCPU time required to generate them, was the best one.ACS3opts performance was compared to that of the genetic algorithm with localoptimization 47, 48 that won the First International Contest on Evolutionary Optimization 2. The two algorithms showed similar performance with the genetic algorithmbehaving slightly better on symmetric problems and ACS3opt on asymmetric ones.To conclude, we mention that ACS was the direct successor of AntQ 36, 49, analgorithm that tried to merge AS and Qlearning 104 properties. In fact, AntQ differsfrom ACS only in the value 0 used by ants to perform online stepbystep pheromoneupdates. The idea was to update pheromone trails with a value that was a predictionof the value of the next state. In AntQ, an ant k implements online stepbysteppheromone updates by the following equation, which replaces Equation 11ij t 1 ij t  maxlN kjj l 12152 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete OptimizationUnfortunately, it was later found that setting the complicate prediction term to a smallconstant value, as it is done in ACS, resulted in approximately the same performance.Therefore, although having a good performance, AntQ was abandoned for the equallygood but simpler ACS.Also, other versions of ACS were studied that differ from the one described abovebecause of a the way online stepbystep pheromone updates were implemented in38 experiments were run disabling it, or by setting the update term in Equation 11to the value 0  0, b the way the decision rule was implemented in 49 thepseudorandomproportional rule of Equations 9 and 10 was compared to the randomproportional rule of Ant System, and to a pseudorandom rule that differs from thepseudorandomproportional rule because random choices are done uniformly randomly, and c the type of solution used by the daemon to update the pheromonetrails in 38 the use of the best solution found in the current iteration was comparedwith ACSs use of the best solution found from the beginning of the trial. ACS asdescribed above is the best performing of all the algorithms obtained by combinationsof the abovementioned choices.3.1.2 Quadratic Assignment ProblemThe quadratic assignment problem is the problem of assigning n facilities to n locationsso that the cost of the assignment, which is a function of the way facilities have beenassigned to locations, is minimized 69. The QAP was, after the TSP, the first problemto be attacked by an ASlike algorithm. This was a reasonable choice, since the QAPis a generalization of the TSP.10 Maniezzo, Colorni, and Dorigo 77 applied exactlythe same algorithm as AS using the QAPspecific minmax heuristic to compute the values used in Equation 3. The resulting algorithm, ASQAP, was tested on a set ofstandard problems and turned out to be of the same quality as metaheuristic approachessuch as simulated annealing and evolutionary computation. More recently, Maniezzoand Colorni 76 and Maniezzo 75 developed two variants of ASQAP and added tothem a local optimizer. The resulting algorithms were compared with some of the bestheuristics available for the QAP with very good results Their versions of ASQAP gavethe best results on all the tested problems.Similar results were obtained by Stutzle and Hoos with theirMMASQAP algorithm99 MMASQAP is a straightforward application ofMMAS, see Section 3.1.1, to theQAP, and by Gambardella, Taillard, and Dorigo 53 with their HASQAP.11 MMASQAP and HASQAP were compared with some of the best heuristics available for theQAP on two classes of QAP problems random and structured QAPs, where structuredQAPs are instances of problems taken from realworld applications. These ant algorithms were found to be the best performing on structured problems 53, 54. A detailedoverview of applications of ACO algorithms to the QAP can be found in 95.3.1.3 JobShop Scheduling ProblemColorni, Dorigo, and Maniezzo 1994 20 applied AS to the jobshop scheduling problem JSP, which is formulated as follows. Given a set M of machines and a set Jof jobs consisting of an ordered sequence of operations to be executed on these machines, the jobshop scheduling problem is that of assigning operations to machinesso that the maximum of the completion times of all operations is minimized and notwo jobs are processed at the same time on the same machine. JSP is NPhard 55.10 In fact, the TSP can be seen as the problem of assigning to each of n cities a different number chosen between 1 and n. QAP, asthe TSP, is NPhard 92.11 HASQAP is an ant algorithm that, although initially inspired by AS, does not strictly belong to the ACO metaheuristic becauseof some peculiarities, such as ants that modify solutions as opposed to build them, and pheromone trail used to guide solutionmodifications and not as an aid to direct their construction.Artificial Life Volume 5, Number 2 153M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete OptimizationThe basic algorithm they applied was exactly the same as AS, where the  heuristicvalue was computed using the longest remaining processing time heuristic. Due tothe different nature of the constraints with respect to the TSP they also defined a newway of building the ants tabu list. ASJSP was applied to problems of dimensions upto 15 machines and 15 jobs always finding solutions within 10 of the optimal value20, 41. These results, although not exceptional, are encouraging and suggest that further work could lead to a workable system. Also, a comparison with other approachesis necessary.3.1.4 Vehicle Routing ProblemThere are many types of vehicle routing problems VRPs. Bullnheimer, Hartl, andStrauss 11, 13, 15 applied an ASlike algorithm to the following instance. Let G N ,A,d be a complete weighted directed graph, where N  n0, . . . ,nn is the set ofnodes, A  i, j i 6 j is the set of arcs, and each arc i, j has an associated weightdij  0 that represents the distance between ni and nj . Node n0 represents a depot,where M vehicles are located, each one of capacity D, while the other nodes representcustomers locations. A demand di  0 and a service time i  0 are associated to eachcustomer ni d0  0 and 0  0. The objective is to find minimum cost vehicle routessuch that a every customer is visited exactly once by exactly one vehicle, b forevery vehicle the total demand does not exceed the vehicle capacity D, c the totaltour length of each vehicle does not exceed a bound L, and d every vehicle startsand ends its tour in the depot.12 ASVRP, the algorithm defined by Bullnheimer, Hartl,and Strauss for the above problem, is a direct extension of AS based on their ASrankalgorithm discussed in Section 3.1.1. They used various standard heuristics for the VRP18, 82 and added a simple local optimizer based on the 2opt heuristic 24. They alsoadapted the way the tabu list is built by taking into consideration the constraints on themaximum total tour length L of a vehicle and its maximum capacity D. Comparisonson a set of standard problems showed that ASVRP performance is at least interestingIt outperforms simulated annealing and neural networks, while it has a slightly lowerperformance than tabu search.Gambardella, Taillard, and Agazzi 52 have also attacked the VRP by means of anACO algorithm. They first reformulate the problem by adding to the city set M  1depots, where M is the number of vehicles. Using this formulation, the VRP problembecomes a TSP with additional constraints. Therefore they can define an algorithm,called HASVRP, which is inspired by ACS Each ant builds a complete tour withoutviolating vehicle capacity constraints each vehicle has associated a maximum transportable weight. A complete tour comprises many subtours connecting depots, andeach subtour corresponds to the tour associated to one of the vehicles. Pheromonetrail updates are done offline as in ACS. Also, a local optimization procedure basedon edge exchanges is applied by the daemon. Results obtained with this approachare competitive with those of the bestknown algorithms and new upper bounds havebeen computed for wellknown problem instances. They also study the vehicle routingproblem with time windows VRPTW, which extends the VRP by introducing a timewindow bi, ei  within which a customer i must be served. Therefore, a vehicle visitingcustomer i before time bi will have to wait. In the literature the VRPTW is solvedconsidering two objectives functions The first one is to minimize the number of vehicles and the second one is to minimize the total travel time. A solution with a lowernumber of vehicles is always preferred to a solution with a higher number of vehiclesbut lower travel time. To optimize both objectives simultaneously, a twocolony ant12 Also in this case it can be easily seen that the VRP is closely related to the TSP A VRP consists of the solution of many TSPs withcommon start and end cities. As such, VRP is an NPhard problem.154 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimizationalgorithm has been designed. The first colony tries to minimize the number of vehicles,while the other one uses V vehicles, where V is the number of vehicles computed bythe first colony, to minimize travel time. The two colonies work using different sets ofpheromone trails, but the best ants are allowed to update the pheromone trails of theother colony. This approach has been proved to be competitive with the bestknownmethods in the literature.3.1.5 Shortest Common Supersequence ProblemGiven a set L of strings over an alphabet 6, find a string of minimal length that is asupersequence of each string in L, where a string S is a supersequence of a string Aif S can be obtained from A by inserting in A zero or more characters.13 This is theproblem known as the shortest common supersequence problem SCS that Michel andMiddendorf 78, 79 attacked by means of ASSCS. ASSCS differs from AS in that it usesa lookahead function that takes into account the influence of the choice of the nextsymbol to append at the next iteration. The value returned by the lookahead functiontakes the place of the heuristic value  in the probabilistic decision rule Equation 3.Also, in ASSCS the value returned by a simple heuristic called LM 7 is factorized in thepheromone trail term. Michel and Middendorf 78,79 further improved their algorithmby the use of an island model of computation i.e., different colonies of ants work onthe same problem concurrently using private pheromone trail distributions every fixednumber of iterations they exchange the best solution found.ASSCSLM i.e., ASSCS with LM heuristic, lookahead, and island model of computation was compared in 78 with the MM 46 and LM heuristics, as well as with a recentlyproposed genetic algorithm specialized for the SCS problem. On the great majority ofthe test problems ASSCSLM turned out to be the bestperforming algorithm.3.1.6 GraphColoring ProblemCosta and Hertz 22 have proposed the ASATP algorithm for assignment type problems.14 The ASATP algorithm they define is basically the same as AS except that antsneed to make two choices First they choose an item, then they choose a resourceto assign to the previously chosen item. These two choices are made by means oftwo probabilistic rule functions of two distinct pheromone trails 1 and 2 and of twoappropriate heuristic values 1 and 2. In fact, the use of two pheromone trails isthe main novelty introduced by ASATP. They exemplify their approach by means ofan application to the graphcoloring problem GCP. Given a graph G  N , E , aqcoloring of G is a mapping c N  1, . . . , q such that ci  c j if i, j  E . TheGCP is the problem of finding a coloring of the graph G so that the number q of colorsused is minimum. The algorithm they propose, called ANTCOL, makes use of wellknown graphcoloring heuristics such as recursive large first RLF 72 and DSATUR8. Costa and Hertz tested ANTCOL on a set of random graphs and compared it withsome of the best available heuristics. Results have shown that ANTCOL performanceis comparable to that obtained by the other heuristics On 20 randomly generatedgraphs of 100 nodes with any two nodes connected with probability 0.5 the averagenumber of colors used by ANTCOL was 15.05, whereas the best known result 23, 44is 14.95. More research will be necessary to establish whether the proposed use of twopheromone trails can be a useful addition to ACO algorithms.13 Consider for example the set L  bcab, bccb, baab, acca. The string baccab is a shortest supersequence. The shortest commonsupersequence SCS problem is NPhard even for an alphabet of cardinality two 84.14 Examples of assignment type problems are the QAP, the TSP, graph coloring, set covering, and so on.Artificial Life Volume 5, Number 2 155M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimization3.1.7 Sequential Ordering ProblemThe sequential ordering problem SOP 42 consists of finding a minimum weightHamiltonian path on a directed graph with weights on the arcs and on the nodes,subject to precedence constraints among nodes. It is very similar to an asymmetric TSPin which the end city is not directly connected to the start city. The SOP, which is NPhard, models realworld problems such as singlevehicle routing problems with pickupand delivery constraints, production planning, and transportation problems in flexiblemanufacturing systems and is therefore an important problem from an applicationspoint of view.Gambardella and Dorigo 51 attacked the SOP by HASSOP, an extension of ACS.In fact, HASSOP is the same as ACS except for the set of feasible nodes, which isbuilt taking into consideration the additional precedence constraints, and for the localoptimizer, which was a specifically designed variant of the wellknown 3opt procedure. Results obtained with HASSOP are excellent. Tests were run on a great numberof standard problems15 and comparisons were done with the best available heuristicmethods. In all cases HASSOP was the bestperforming method in terms of solutionquality and of computing time. Also, on the set of problems tested it improved manyof the best known results.3.2 Applications of ACO Algorithms to Dynamic Combinatorial OptimizationProblemsResearch on the applications of ACO algorithms to dynamic combinatorial optimizationproblems has focused on communications networks. This is mainly because networkoptimization problems have characteristics, such as inherent information and computation distribution, nonstationary stochastic dynamics, and asynchronous evolution ofthe network status, that well match those of the ACO metaheuristic. In particular, theACO approach has been applied to routing problems.Routing is one of the most critical components of network control and concernsthe networkwide distributed activity of building and using routing tables to directdata traffic. The routing table of a generic node i is a data structure that tells datapackets entering node i which should be the next node to move to among the set Niof neighbors of i. In the applications presented in this section routing tables for datapackets are obtained by some functional transformation of antdecision tables.Let G  N ,A be a directed weighted graph, where each node in the set N represents a network node with processingqueuing and forwarding capabilities, and eachoriented arc in A is a transmission system link with an associated weight definedby its physical properties. Network applications generate data flows from source todestination nodes. For each node in the network, the local routing component usesthe local routing table to choose the best outgoing link to direct incoming data towardtheir destination nodes.The generic routing problem can be informally stated as the problem of buildingrouting tables so that some measure of network performance is maximized.16Most of the ACO implementations for routing problems well match the general guidelines of the metaheuristic shown in Figure 3. Ants are launched from each networknode toward heuristically selected destination nodes launching follows some randomor problemspecific schedule. Ants, like data packets, travel across the network and15 In fact, on all the problems registered in the TSPLIB, a wellknown repository for TSPrelated benchmark problems available onthe Internet at httpwww.iwr.uniheidelberg.deiwrcomoptsoftTSPLIB95TSPLIB.html.16 The choice of what particular measure of network performance to use depends on the type of network considered and on whichaspects of the provided services are most interesting. For example, in a telephone network, performance can be measured by thepercentage of accepted calls and by the mean waiting time to setup or refuse a call, while in an Internetlike network, performancecan be scored by the amount of correctly delivered bits per time unit throughput, and by the distribution of data packet delays.156 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimizationbuild paths from source to destination nodes by applying a probabilistic transition rulethat makes use of information maintained in pheromone trail variables associated tolinks and, in some cases, of additional local information. Algorithmspecific heuristicsand information structures are used to score the discovered paths and to set the amountof pheromone ants deposit.A common characteristic of ACO algorithms for routing is that the role of the daemonline 6 of the ACO metaheuristic of Figure 3 is much reduced In the majority of theimplementations it simply does not perform any actions.ACO implementations for communications networks are grouped in two classes,those for connectionoriented and those for connectionless networks. In connectionoriented networks all the packets of a same session follow a common path selected bya preliminary setup phase. On the contrary, in connectionless, or datagram, networksdata packets of a same session can follow different paths. At each intermediate nodealong the route from the source to the destination node a packetspecific forwardingdecision is taken by the local routing component. In both types of networks besteffort routing, that is, routing without any explicit network resource reservation, can bedelivered. Moreover, in connectionoriented networks an explicit reservation softwareor hardware of the resources can be done. In this way, services requiring specificcharacteristics in terms of bandwidth, delay, etc. can be delivered.173.2.1 ConnectionOriented Network RoutingThe work by Schoonderwoerd, Holland, Bruten, and Rothkrantz 89, 90 has been, toour knowledge, the first attempt to apply an ACO algorithm to a routing problem. Theiralgorithm, called antbased control ABC, was applied to a model of the British TelecomBT telephone network. The network is modeled by a graph G  N ,A, whereeach node i has the same functionalities as a crossbar switch with limited connectivitycapacity and links have infinite capacity i.e., they can carry a potentially infinitenumber of connections. Each node i has a set Ni of neighbors and is characterizedby a total capacity Ci , and a spare capacity Si . Ci represents the maximum number ofconnections node i can establish, while Si represents the percentage of capacity thatis still available for new connections. Each link i, j connecting node i to node jhas an associated vector of pheromone trail values ijd ,d  1, . . . , i  1, i  1, . . . ,N .The value ijd represents a measure of the desirability of choosing link i, j when thedestination node is d .Because the algorithm does not make use of any additional local heuristics, onlypheromone values are used to define the antdecision table values aind t  ind t.The ant stochastic decision policy uses the pheromone values as follows ind t givesthe probability that a given ant, the destination of which is node d , be routed at timet from node i to neighbor node n. An exploration mechanism is added to the antsdecision policy With some low probability ants can choose the neighbor to move tofollowing a uniformly random scheme over all the current neighbors. The ant internalstate keeps track only of the ant source node and launching time. No memory aboutthe visited nodes is maintained to avoid ant cycles. Routing tables for calls are obtainedusing antdecision tables in a deterministic way At setup time a route from node s tonode d is built by choosing sequentially and deterministically, starting from node s, theneighbor node with the highest probability value until node d is reached. Once thecall is set up in this way, the spare capacity Si of each node i on the selected route isdecreased by a fixed amount. If at call setup time any of the nodes along the routeunder construction has no spare capacity left, then the call is rejected. When a call17 For example, telephone calls need connectionoriented networks able to guarantee the necessary bandwidth during the entire calltime.Artificial Life Volume 5, Number 2 157M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimizationterminates, the corresponding reserved capacity of nodes on its route is made availableagain for other calls. Ants are launched at regular temporal intervals from all the nodestoward destination nodes selected in a uniformly random way. Ants deposit pheromoneonly online, stepbystep, on the links they visit they do not deposit pheromone afterthe path has been built, that is, they do not implement the procedure of lines 3034 ofthe ACO metaheuristic of Figure 3. An ant k originated in node s and arriving at time tin node j from node i adds an amount 1 kt of pheromone to the value j ist storedon link  j, i. The updated value j ist, which represents the desirability to go fromnode j to destination node s via node i, will be used by ants moving in the oppositedirection of the updating ant. This updating strategy can be applied when the networkis approximately cost symmetric, that is, when it is reasonable to use an estimate ofthe cost from node i to node j as an estimate of the cost from node j to node i. Inthe network model used by Schoonderwoerd et al. 89, 90 cost symmetry is a directconsequence of the assumptions made on the switches and transmission link structure.The pheromone trail update formula isj ist j ist1 kt 13After the visited entry has been updated, the pheromone value of all the entries relativeto the destination s decays. Pheromone decay, as usual, corresponds to the evaporationof real pheromone.18 In this case the decay factor is set to 11  1 kt so that itoperates a normalization of the pheromone values, which continue therefore to beusable as probabilitiesinst inst11 kt , n  Ni 14The value 1 kt is a function of the ants age. Ants move over a control networkisomorphic to the real one. They grow older after each node hop and they are virtuallydelayed in nodes as a function of the node spare capacity. By this simple mechanism,the amount of pheromone deposited by an ant is made inversely proportional to thelength and to the degree of congestion of the selected path. Therefore, the overalleffect of ants on pheromone trail values is such that routes that are visited frequentlyand by young ants will be favored when building paths to route new calls.In ABC no daemon actions are included in the algorithm. Each new call is acceptedor rejected on the basis of a setup packet that looks for a path with spare capacity byprobing the deterministically best path as indicated by the routing tables.ABC has been tested on the abovedescribed model of the British Telecom telephone network 30 nodes using a sequential discrete time simulator and compared,in terms of percentage of accepted calls, to an agentbased algorithm developed by BTresearchers. Results were encouraging19 ABC always performed significantly betterthan its competitor on a variety of different traffic situations.White, Pagurek, and Oppacher 105 use an ACO algorithm for routing in connectionoriented pointtopoint and pointtomultipoint networks. The algorithm follows ascheme very similar to AS see Section 3.1.1 The antdecision table has the sameform as ASs Equation 2 and the decision rule Equation 3 is identical. The heuristicinformation  is locally estimated by link costs. From the source node of each incomingconnection, a group of ants is launched to search for a path. At the beginning of the18 Schoonderwoerd et al. 89, 90 developed ABC independently from previous ant colony optimization work. Therefore, they donot explicitly speak of pheromone evaporation, even if their probability renormalization mechanism plays the same role.19 In the following we use the word encouraging whenever interesting results were obtained but the algorithm was compared onlyon simple problems, or with no stateoftheart algorithms, or under limited experimental conditions.158 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimizationtrip each ant k sets to 0 a cost variable Ck associated to its path, and after each linkcrossing the path cost is incremented by the link cost lij  Ck  Ck lij . When arrived attheir destination, ants move backward to their source node and at each node they usea simple additive rule to deposit pheromone on the visited links. The amount of deposited pheromone is a function of the whole cost Ck of the path, and only this onlinestepbystep updating is used to update pheromone. When all the spooled ants arriveback at the source node, a simple local daemon algorithm decides whether to allocatea path, based on the percentage of ants that followed a same path. Moreover, duringall the connection lifetime, the local daemon launches and coordinates exploring antsto reroute the connection paths in case of network congestion or failures. A geneticalgorithm 59, 66 is used online to evolve the parameters  and  of the transition ruleformula, which determine the relative weight of pheromone and link costs because ofthis mechanism the algorithm is called ASGA, ant system plus genetic algorithm. Somepreliminary results were obtained testing the algorithm on several networks and usingseveral link cost functions. Results are promising The algorithm is able to computeshortest paths and the genetic adaptation of the rule parameters considerably improvesthe algorithms performance.Bonabeau, Henaux, Guerin, Snyers, Kuntz, and Theraulaz 6 improved the ABCalgorithm by the introduction of a dynamic programming mechanism. They updatethe pheromone trail values of all the links on an ant path not only with respect to theants origin node, but also with respect to all the intermediate nodes on the subpathbetween the origin and the ants current node.Di Caro and Dorigo 30 are currently investigating the use of AntNetFS to managefairshare besteffort routing in highspeed connectionoriented networks. AntNetFS isa derivation of AntNet, an algorithm for besteffort routing in connectionless networksthe same authors developed. Therefore, we postpone the description of AntNetFS tothe next subsubsection, where AntNet and its extensions are described in detail.3.2.2 Connectionless Network RoutingSeveral ACO algorithms have been developed for routing in connectionless networkstaking inspiration both from AS Section 3.1.1 in general and from ABC Section 3.2.1in particular.Di Caro and Dorigo 2629, 31 developed several versions of AntNet, an ACO algorithm for distributed adaptive routing in besteffort connectionless Internetlike datanetworks. The main differences between ABC and AntNet are that a in AntNet realtrip times experienced by ants ants move over the same, real network as data packets and local statistical models are used to evaluate paths goodness, b pheromoneis deposited once a complete path is built this is a choice dictated by a more generalassumption of cost asymmetry made on the network, and c the ant decision rulemakes use of local heuristic information  about the current traffic status.In AntNet the antdecision table Ai  aind tNi ,N 1 of node i is obtained bythe composition of the local pheromone trail values with the local heuristic values asfollowsaind t  ind t 1 nt  1 Ni   1 15where Ni is the set of neighbors of node i, n  Ni , d is the destination node, n isa 0,1normalized heuristic value inversely proportional to the length of the local linkqueue toward neighbor n,   0, 1 is a weighting factor and the denominator is anormalization term. The decision rule of the ant located at node i and directed towarddestination node d at time t uses the entry aind t of the antdecision table as followsArtificial Life Volume 5, Number 2 159M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimizationaind t is simply the probability of choosing neighbor n. This probabilistic selection isapplied over all the notyetvisited neighbors by the ant, or over all the neighbors ifall the neighbors have already been visited by the ant. While building the path to thedestination, ants move using the same link queues as data. In this way, ants experiencethe same delays as data packets and the time Tsd elapsed while moving from the sourcenode s to the destination node d can be used as a measure of the path quality. Theoverall goodness of a path is evaluated by a heuristic function of the trip time Tsdand of local adaptive statistical models. In fact, paths need to be evaluated relative tothe network status because a trip time T judged of low quality under low congestionconditions could be an excellent one under high traffic load. Once a path has beencompleted ants deposit on the visited nodes an amount of pheromone proportional tothe goodness of the path they built. AntNets ants use only this online delayed wayto update pheromone, different from ABC, which uses only the online stepbystepstrategy lines 3034 and 2427, respectively, of the ACO metaheuristic of Figure 3.To this purpose, after reaching their destination nodes, ants move back to their sourcenodes along the same path but backward and using highpriority queues, to allow afast propagation of the collected information in AntNet the term forward ant is usedfor ants moving from source to destination nodes, and the term backward ant forants going back to their source nodes. During the backward path, the pheromonevalue of each visited link is updated with a rule similar to ABCs. AntNet differs fromABC also in a number of minor details, the most important of which are a ants arelaunched from each node toward destinations chosen to match probabilistically thetraffic patterns, b all the pheromone values on an ant path are updated with respectto all the successor nodes of the forward path as is done also in 6, c cycles areremoved online from the ants paths,20 and d data packets are routed probabilisticallyusing routing tables obtained by means of a simple functional transformation of theantdecision tables. AntNet was tested using a continuous time discrete events networksimulator, on a wide variety of different spatial and temporal traffic conditions, andon several real and randomly generated network configurations ranging from 8 to150 nodes. Stateoftheart static and adaptive routing algorithms have been used forcomparison. Results were excellent AntNet showed striking superior performance interms of both throughput and packet delays. Moreover, it appears to be very robust tothe ant production rate and its impact on network resources is almost negligible.Di Caro and Dorigo 27, 30 recently developed an enhanced version of AntNet,called AntNetFA.21 AntNetFA is the same as AntNet except for the following twoaspects. First, forward ants are substituted by socalled flying ants While buildinga path from source to destination node, flying ants make use of highpriority queuesand do not store the trip times T . Second, each node maintains a simple local modelof the local link queue depletion process. By using this model, rough estimates of themissing forward ant trip times are built. Backward ants read these estimates onlineand use them to evaluate the path quality and consequently to compute the amountof pheromone to deposit. AntNetFA appears to be more reactive the informationcollected by ants is more uptodate and is propagated faster than in the original AntNet.AntNetFA has been observed to perform much better than the original AntNet in besteffort connectionless networks 32.Starting from AntNetFA, Di Caro and Dorigo 30 are currently developing AntNetFS,a routing and flow control system to manage multipath adaptive fairshare routing inconnectionoriented highspeed networks. In AntNetFS, some ants have some extra20 This is a simple form of backtracking.21 In the original paper 32 the same algorithm was called AntNetCO, because the algorithm was developed in the perspectiveof connectionoriented routing, while here and in the future the authors choose to use the name AntNetFA, to emphasize theflying ant nature of forward ants.160 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimizationfunctionalities to support the search and allocation of multipaths for each new incominguser session. Forward setup ants fork to search for convenient multipaths virtualcircuits to allocate the session. A daemon component local to the session endpointsdecides whether or not to accept the virtual circuits discovered by the forward setupants. Accepted virtual circuits are allocated by the backward setup ants, reserving atthe same time the sessions bandwidth in a fairshare 74 fashion over the circuit nodes.The allocated bandwidth is dynamically redistributed and adapted after the arrival ofa new session or the departure of an old one. The AntNetFS approach looks verypromising for highspeed networks such as ATM, but needs more testing.Subramanian, Druschel, and Chen 100 proposed the regular ants algorithm, whichessentially is an application of Schoonderwoerd et al.s ABC algorithm 89, 90 to packetswitched networks, where the only difference is the use of link costs instead of antsage. The way their ants use link costs requires the network to be approximately costsymmetric. They also propose uniform ants, that is, ants without a precise destination,which live for a fixed amount of time in the network and explore it by using a uniformprobability scheme over the node neighbors. Uniform ants do not use the autocatalyticmechanism that characterizes all ACO algorithms and therefore do not belong to theACO metaheuristic.Heusse, Guerin, Snyers, and Kuntz 64 developed a new algorithm for general costasymmetric networks, called Cooperative Asymmetric Forward CAF. In CAF, eachdata packet, after going from node i to node j , releases on node j the informationcij about the sum of the experienced waiting and crossing times from node i. Thisinformation is used as an estimate of the time distance to go from i to j and is read bythe ants traveling in the opposite direction to perform online stepbystep pheromoneupdating no online delayed pheromone updating is used in this case. The algorithmsauthors tested CAF under some static and dynamic conditions, using the average number of packets waiting in the queues and the average packet delay as performancemeasures. They compared CAF to an algorithm very similar to an earlier version ofAntNet. Results were encouraging under all the test situations CAF performed betterthan its competitors.Van der Put and Rothkrantz 102, 103 designed ABCbackward, an extension of theABC algorithm applicable to costasymmetric networks. They use the same forwardbackward ant mechanism as in AntNet Forward ants, while moving from the source tothe destination node, collect information on the status of the network, and backwardants use this information to update the pheromone trails of the visited links during theirjourney back from the destination to the source node. In ABCbackward, backward antsupdate the pheromone trails using an updating formula identical to that used in ABC,except for the fact that the ants age is replaced by the trip times experienced by the antsin their forward journey. Van der Put and Rothkrantz have shown experimentally thatABCbackward has a better performance than ABC on both costsymmetricbecausebackward ants can avoid depositing pheromone on cyclesand costasymmetric networks. They apply ABCbackward to a fax distribution problem proposed by the largestDutch telephone company KPN Telecom.3.3 Parallel ImplementationsThe very nature of ACO algorithms lends them to be naturally parallelized in the dataor population domains. In particular, many parallel models used in other populationbased algorithms can be easily adapted to the ACO structure e.g., migration and diffusion models adopted in the field of parallel genetic algorithms see, for example,reviews in 16, 39.Early experiments with parallel versions of AS for the TSP on the Connection MachineCM2 65 adopted the approach of attributing a single processing unit to each ant 4.Artificial Life Volume 5, Number 2 161M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete OptimizationExperimental results showed that communication overhead can be a major problemwith this approach on finegrained parallel machines, since ants end up spending mostof their time communicating to other ants the modifications they made to pheromonetrails. In fact, the algorithms behavior was not impressive and scaled up very badlywhen increasing the problem dimensions. Better results were obtained on a coarsegrained parallel network of 16 transputers 4, 34. The idea here was to divide the colonyinto p subcolonies, where p is the number of available processors. Each subcolonyacts as a complete colony and therefore implements a standard AS algorithm. Aftereach subcolony has completed an iteration of the algorithm, a hierarchical broadcastcommunication process collects the information about the tours of all the ants in allthe subcolonies and then broadcasts this information to all the p processors so thata concurrent update of the pheromone trails can be done. In this case the speedupwas nearly linear when increasing the number of processors, and this behavior did notchange significatively for increasing problem dimensions.More recently, Bullnheimer, Kotsis, and Strauss 14 proposed two coarsegrainedparallel versions of AS. The first one, called Synchronous Parallel Implementation SPI,is basically the same as the one implemented by Bolondi and Bondanza 4, while thesecond one, called Partially Asynchronous Parallel Implementation PAPI, exchangespheromone information among subcolonies every fixed number of iterations done byeach subcolony. The two algorithms have been evaluated by simulation. The findingsshow that the reduced communication due to the less frequent exchange of pheromonetrail information among subcolonies determines a better performance of the PAPI approach with respect to running time and speedup. More experimentation is necessaryto compare the quality of the results produced by the SPI and the PAPI implementations.Kruger, Merkle, and Middendorf 70 investigated which pheromone trail information should be exchanged between the m subcolonies and how this information shouldbe used to update the subcolonys trail information. They compared an exchange ofa the global best solution every subcolony uses the global best solution to choosewhere to add pheromone trail, b the local best solutions every subcolony receivesthe local best solution from all other subcolonies and updates pheromone trail on thecorresponding arcs, and c the total trail information every colony computes the average over the trail information of all colonies that is, if  l   lij  is the trail informationof subcolony l , 1  l  m then every colony l sends  l to the other colonies andafterward computes  lij mh1 hij , 1  i, j  n. The results indicate that methods aand b are faster and give better solutions than method c, but further investigationsare necessary.Last, Stutzle 94 presents computational results for the execution of parallel independent runs on up to 10 processors of hisMMAS algorithm 98, 97. The executionof parallel independent runs is the easiest way to obtain a parallel algorithm and, obviously, it is a reasonable approach only if the underlying algorithm, as is the case withACO algorithms, is randomized. Stutzles results show that the performance ofMMASgrows with the number of processors.4 Related WorkACO algorithms show similarities with some optimization, learning, and simulationapproaches such as heuristic graph search, Monte Carlo simulation, neural networks,and evolutionary computation. These similarities are now briefly discussed.Heuristic graph search. In ACO algorithms each ant performs a heuristic graph searchin the space of the components of a solution Ants take biased probabilistic decisions tochoose the next component to move to, where the bias is given by a heuristic evaluationfunction that favors components that are perceived as more promising. It is interesting162 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimizationto note that this is different from what happens, for example, in stochastic hillclimbers81 or in simulated annealing 68, where a an acceptance criteria is defined andonly those randomly generated moves that satisfy the criteria are executed, and b thesearch is usually performed in the space of the solutions.Monte Carlo simulation. ACO algorithms can be interpreted as parallel replicatedMonte Carlo systems 93. Monte Carlo systems 87 are general stochastic simulationsystems, that is, techniques performing repeated sampling experiments on the modelof the system under consideration by making use of a stochastic component in the statesampling andor transition rules. Experiment results are used to update some statisticalknowledge about the problem, as well as the estimate of the variables the researcher isinterested in. In turn, this knowledge can also be iteratively used to reduce the variancein the estimation of the desired variables, directing the simulation process toward themost interesting regions of the state space. Analogously, in ACO algorithms the antssample the problems solution space by repeatedly applying a stochastic decision policyuntil a feasible solution of the considered problem is built. The sampling is realizedconcurrently by a collection of differently instantiated replicas of the same ant type.Each ant experiment allows adaptive modification of the local statistical knowledgeon the problem structure i.e., the pheromone trails. The recursive transmission ofsuch knowledge by means of stigmergy determines a reduction in the variance of thewhole search process The sofar most interesting explored transitions probabilisticallybias future search, preventing ants from wasting resources in unpromising regions ofthe search space.Neural networks. Ant colonies, being composed of numerous concurrently and locallyinteracting units, can be seen as connectionist systems 43, the most famous examplesof which are neural networks 3, 63, 88. From a structural point of view, the parallelbetween the ACO metaheuristic and a generic neural network is obtained by puttingeach state i visited by ants in correspondence with a neuron i, and the problemspecific neighborhood structure of state i in correspondence with the set of synapticlikelinks exiting neuron i. The ants themselves can be seen as input signals concurrentlypropagating through the neural network and modifying the strength of the synapticlikeinterneuron connections. Signals ants are locally propagated by means of a stochastictransfer function and the more a synapse is used, the more the connection betweenits two end neurons is reinforced. The ACOsynaptic learning rule can be interpretedas an a posteriori rule Signals related to good examples, that is, ants that discovereda good quality solution, reinforce the synaptic connections they traverse more thansignals related to poor examples. It is interesting to note that the ACOneural networkalgorithm does not correspond to any existing neural network model.The ACOneural network is also reminiscent of networks solving reinforcementlearning problems 101. In reinforcement learning the only feedback available to thelearner is a numeric signal the reinforcement that scores the result of actions. This isalso the case in the ACO metaheuristic The signals ants fed into the network can beseen as input examples with an associated approximate score measure. The strengthof pheromone updates and the level of stochasticity in signal propagation play the roleof a learning rate, controlling the balance between exploration and exploitation.Finally, it is worth making a reference to the work of Chen 17, who proposed aneural network approach to TSP that bears important similarities with the ACO approach. Like in ACO algorithms, Chen builds a tour in an incremental way, accordingto synaptic strengths. It also makes use of candidate lists and 2opt local optimization.The strengths of the synapses of the current tour and of all previous tours are updatedaccording to a Boltzmannlike rule and a learning rate playing the role of an evaporation coefficient. Although there are some differences, the common features are, in thiscase, striking.Artificial Life Volume 5, Number 2 163M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete OptimizationEvolutionary computation. There are some general similarities between the ACOmetaheuristic and evolutionary computation EC 45. Both approaches use a population of individuals that represent problem solutions, and in both approaches theknowledge about the problem collected by the population is used to generate stochastically a new population of individuals. A main difference is that in EC algorithms allthe knowledge about the problem is contained in the current population, while in ACOa memory of past performance is maintained under the form of pheromone trails.An EC algorithm that is very similar to ACO algorithms in general and to AS inparticular is Baluja and Caruanas Population Based Incremental Learning PBIL 1.PBIL maintains a vector of real numbers, the generating vector, which plays a rolesimilar to that of the population in genetic algorithms 59, 66. Starting from this vector,a population of binary strings is randomly generated Each string in the populationwill have the ith bit set to 1 with a probability that is a function of the ith value in thegenerating vector. Once a population of solutions is created, the generated solutionsare evaluated and this evaluation is used to increase or decrease the probabilitiesof each separate component in the generating vector so that good bad solutions inthe future generations will be produced with higher lower probability. It is clearthat in ACO algorithms the pheromone trail values play a role similar to Baluja andCaruanas generating vector, and pheromone updating has the same goal as updatingthe probabilities in the generating vector. A main difference between ACO algorithmsand PBIL consists in the fact that in PBIL all the probability vector components areevaluated independently, making the approach work well only when the solution isseparable into its components.The 1,  evolution strategy is another EC algorithm that is related to ACO algorithms,and in particular to ACS. In fact, in the 1,  evolution strategy the following steps areiteratively repeated a a population of  solutions ants is initially generated, thenb the best individual of the population is saved for the next generation, while allthe other solutions are discarded, and c starting from the best individual,   1 newsolutions are stochastically generated by mutation, and finally d the process is iteratedgoing back to step b. The similitude with ACS is striking.Stochastic learning automata. This is one of the oldest approaches to machine learning see 80 for a review. An automaton is defined by a set of possible actions and avector of associated probabilities, a continuous set of inputs and a learning algorithmto learn inputoutput associations. Automata are connected in a feedback configuration with the environment, and a set of penalty signals from the environment to theactions is defined. The similarity of stochastic learning automata and ACO approachescan be made clear as follows. The set of pheromone trails available on each arclinkis seen as a set of concurrent stochastic learning automata. Ants play the role ofthe environment signals, while the pheromone update rule is the automaton learningrule. The main difference lies in the fact that in ACO the environment signals i.e.,the ants are stochastically biased, by means of their probabilistic transition rule, todirect the learning process toward the most interesting regions of the search space.That is, the whole environment plays a key, active role in learning good stateactionpairs.5 DiscussionThe ACO metaheuristic was defined a posteriori, that is, it is the result of a synthesiseffort effectuated on a set of algorithms inspired by a common natural process. Such asynthesis can be very useful because a it is a first attempt to characterize this new classof algorithms, and b it can be used as a reference to design new instances of ACOalgorithms. On the other hand, the a posteriori character of the synthesis determines a164 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimizationgreat variety in the way some aspects of the metaheuristic are implemented, as discussedin the following.Role of the local heuristic. Most of the ACO algorithms presented combine pheromonetrails with local heuristic values to obtain antdecision tables. An exception are theSchoonderwoerd et al. 89, 90 ABC algorithm and all the derived algorithms ABCsmart ants, ABCbackward, regular ants, and CAF in which antdecision tables areobtained using only pheromone trail values. Current wisdom indicates that the use ofa heuristic value, whenever possible, improves ACO performance considerably. Thenature of the heuristic information differs between static and dynamic problems. In allstatic problems attacked by ACO a simple heuristic value directly obtainable from theproblem definition was used. On the contrary, in dynamic problems the heuristic valuemust be estimated by local statistical sampling of the dynamic system.Stepbystep versus delayed online solution evaluation. In dynamic combinatorialoptimization problems some of the proposed ACO algorithms use stepbystep onlinesolution evaluation ABC, ABCsmart, and regular ants, which take advantage of thecostsymmetric nature of the network model, and CAF, which, although applied to acostasymmetric network, can apply a stepbystep solution evaluation by exploitinginformation deposited on nodes by data packets traveling in the opposite directionof ants. The other algorithms applied to costasymmetric networks, AntNet and ABCbackward, use delayed online solution evaluation. For the static optimization problemsconsidered, the use of a stepbystep online solution evaluation would be misleadingbecause problem constraints make the quality of partial solutions not a good estimateof the quality of complete solutions.Pheromone trail directionality. The pheromone trail can have directional properties.This is true for all dynamic optimization problems considered. Differently, in all theapplications to static problems Section 3.1 pheromone trail is not directional An antusing arc i, j will see the same pheromone trail values independent of the node it iscoming from. It is the decision policy that can take into consideration the node, orthe series of nodes, the ant is coming from.Implicit solution evaluation. One of the interesting aspects of real ants shortest pathfinding behavior is that they exploit implicit solution evaluation If an ant takes ashorter path it will arrive at the destination before any other ant that took a longerpath. Therefore, shorter paths will receive pheromone earlier and they start to attractnew ants before longer paths. This implicit solution evaluation property is exploited bythe ACO algorithms applied to routing, and not by those applied to static optimizationproblems. The reason for this is that implicit solution evaluation is obtained for freewhenever the speed with which ants move on the problem representation is inverselyproportional to the cost of each state transition during solution construction. Whilethis is the most natural way to implement artificial ants for network applications, it isnot an efficient choice for the considered static problems. In fact, in this case it wouldbe necessary to implement an extra algorithm component to manage each ants speed,which would require extra computation resources without any guarantee of improvedperformance.6 ConclusionsIn this article we have introduced the ant colony optimization ACO metaheuristic andwe have given an overview of ACO algorithms. ACO is a novel and very promisingresearch field situated at the crossing between artificial life and operations research. Theant colony optimization metaheuristic belongs to the relatively new wave of stochasticmetaheuristics such as evolutionary computation 45, simulated annealing 68, tabusearch 57, 58, neural computation 3, 63, 88, and so on, which are built around someArtificial Life Volume 5, Number 2 165M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimizationbasic principles taken from the observation of a particular natural phenomenon. Asis very common in the practical usage of these heuristics, ACO algorithms often endup at some distance from their inspiring natural metaphor. Often ACO algorithms areenriched with capacities that do not find a counterpart in real ants, such as local searchand globalknowledgebased actions, so that they can compete with more applicationspecific approaches. ACO algorithms so enriched are very competitive and in someapplications they have reached worldclass performance. For example, on structuredquadratic assignment problems ASQAP, HASQAP, andMMASQAP are currently thebest available heuristics. Other very successful applications are those to the sequentialordering problem, for which HASSOP is by far the best available heuristic, and to datanetwork routing, where AntNet resulted in being superior to a whole set of stateoftheart algorithms.Within the artificial life field, ant algorithms represent one of the most successfulapplications of swarm intelligence.22 One of the most characterizing aspects of swarmintelligent algorithms, shared by ACO algorithms, is the use of the stigmergetic modelof communication. We have seen that this form of indirect distributed communicationplays an important role in making ACO algorithms successful. There are, however,examples of applications of stigmergy based on social insect behaviors other than antsforaging behavior. For example, the stigmergymediated allocation of work in antcolonies has inspired models of task allocation in a distributed mail retrieval systemdead body aggregation and brood sorting, again in ant colonies, have inspired a dataclustering algorithm and models of collective transport by ants have inspired transportcontrol strategies for groups of robot.23In conclusion, we hope this paper has achieved its goal To convince the reader thatACO, and more generally the stigmergetic model of communication, are worth furtherresearch.AcknowledgmentsWe are grateful to Nick Bradshaw, Bernd Bullnheimer, Martin Heusse, Owen Holland,Vittorio Maniezzo, Martin Middendorf, Ruud Schoonderwoerd, and Dominique Snyersfor critical reading of a draft version of this article. We also wish to thank Eric Bonabeauand the two referees for their valuable comments. Marco Dorigo acknowledges support from the Belgian FNRS, of which he is a Research Associate. This work wassupported by a Marie Curie Fellowship awarded to Gianni Di Caro CECTMR ContractN. ERBFMBICT 961153.References1. Baluja, S.,  Caruana, R. 1995. Removing the genetics from the standard geneticalgorithm. In A. Prieditis  S. Russell Eds., Proceedings of the Twelfth InternationalConference on Machine Learning, ML95 pp. 3846. Palo Alto, CA Morgan Kaufmann.2. Bersini, H., Dorigo, M., Langerman, S., Seront, G.,  Gambardella, L. M. 1996. Results ofthe first international contest on evolutionary optimisation 1st ICEO. In Proceedings ofIEEE International Conference on Evolutionary Computation, IEEEEC 96 pp. 611615.Piscataway, NJ IEEE Press.3. Bishop, C. M. 1995. Neural networks for pattern recognition. Oxford Oxford UniversityPress.22 Swarm intelligence can be defined as the field that covers any attempt to design algorithms or distributed problemsolving devicesinspired by the collective behavior of social insect colonies and other animal societies 5, p. 7.23 These and other examples of the possible applications of stigmergetic systems are discussed in detail by Bonabeau, Dorigo, andTheraulaz 5.166 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimization4. Bolondi, M.,  Bondanza, M. 1993. Parallelizzazione di un algoritmo per la risoluzionedel problema del commesso viaggiatore. Unpublished masters thesis, Dipartimento diElettronica e Informazione, Politecnico di Milano, Italy.5. Bonabeau, E., Dorigo, M.,  Theraulaz, G. 1999. From natural to artificial swarmintelligence. New York Oxford University Press.6. Bonabeau, E., Henaux, F., Guerin, S., Snyers, D., Kuntz, P.,  Theraulaz, G. 1998.Routing in telecommunications networks with smart antlike agents. In S. Albayrak F. J. Garijo Eds., Proceedings of IATA 98, Second International Workshop on IntelligentAgents for Telecommunication Applications pp. 6071. Lecture Notes in AI vol. 1437,SpringerVerlag.7. Branke, J., Middendorf, M.,  Schneider, F. 1998. Improved heuristics and a geneticalgorithm for finding short supersequences. ORSpektrum, 20, 3946.8. Brelaz, D. 1979. New methods to color vertices of a graph. Communications of the ACM,22, 251256.9. Bruckstein, A. M. 1993. Why the ant trails look so straight and nice. The MathematicalIntelligencer, 152, 5962.10. Bruckstein, A. M., Mallows, C. L.,  Wagner, I. A. 1997. Probabilistic pursuits on the grid.American Mathematical Monthly, 1044, 323343.11. Bullnheimer, B., Hartl, R. F.,  Strauss, C. 1997. An improved Ant System algorithm forthe vehicle routing problem. Tech. Rep. POM1097. Vienna, Austria University ofVienna, Institute of Management Science. To appear in Dawid, Feichtinger,  Hartl Eds.,Annals of Operations Research Nonlinear Economic Dynamics and Control.12. Bullnheimer, B., Hartl, R. F.,  Strauss, C. 1997. A new rankbased version of the AntSystem A computational study. Tech. Rep. POM0397. Vienna, Austria University ofVienna, Institute of Management Science. Also available in 1999. Central EuropeanJournal for Operations Research and Economics, 7 1, 2538.13. Bullnheimer, B., Hartl, R. F.,  Strauss, C. 1998. Applying the Ant System to the vehiclerouting problem. In S. Voss., S. Martello, I. H. Osman,  C. Roucairol Eds.,Metaheuristics Advances and trends in local search paradigms for optimizationpp. 109120. Boston Kluwer.14. Bullnheimer, B., Kotsis, G.,  Strauss, C. 1997. Parallelization strategies for the AntSystem. Tech. Rep. POM997. Vienna, Austria University of Vienna, Institute ofManagement Science. Also available in 1998. R. De Leone, A. Murli, P. Pardalos, G. Toraldo Eds., High performance algorithms and software in nonlinear optimizationpp. 87100. Series Applied Optimization, vol. 24. Dordrecht Kluwer.15. Bullnheimer, B.,  Strauss, C. 1996. Tourenplanung mit dem Ant System. Tech. Rep. 6.Vienna, Austria Instituts fur Betriebwirtschaftslehre, Universitat Wien.16. Campanini, R., Di Caro, G., Villani, M., DAntone, I.,  Giusti, G. 1994. Parallelarchitectures and intrinsically parallel algorithms Genetic algorithms. InternationalJournal of Modern Physics C, 51, 95112.17. Chen, K. 1997. A simple learning algorithm for the traveling salesman problem. PhysicalReview E, 55, 78097812.18. Clarke, G.,  Wright, J. W. 1964. Scheduling of vehicles from a central depot to anumber of delivery points. Operations Research, 12, 568581.19. Colorni, A., Dorigo, M.,  Maniezzo, V. 1992. Distributed optimization by ant colonies.In F. J. Varela  P. Bourgina Eds., Proceedings of the First European Conference onArtificial Life pp. 134142. Cambridge, MA MIT PressBradford Books.20. Colorni, A., Dorigo, M., Maniezzo, V.,  Trubian, M. 1994. Ant System for jobshopscheduling. Belgian Journal of Operations Research, Statistics and Computer ScienceJORBEL, 34, 3953.21. Corne, D., Dorigo, M.,  Glover, F. Eds.. 1999. New ideas in optimization.Maidenhead, UK McGrawHill.Artificial Life Volume 5, Number 2 167M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimization22. Costa, D.,  Hertz, A. 1997. Ants can colour graphs. Journal of the Operational ResearchSociety, 48, 295305.23. Costa, D., Hertz, A.,  Dubuis, O. 1995. Embedding of a sequential algorithm within anevolutionary algorithm for coloring problems in graphs. Journal of Heuristics, 1, 105128.24. Croes, G. A. 1958. A method for solving traveling salesman problems. OperationsResearch, 6, 791812.25. Deneubourg, J.L., Aron, S., Goss, S.,  Pasteels, J.M. 1990. The selforganizingexploratory pattern of the argentine ant. Journal of Insect Behavior, 3, 159168.26. Di Caro, G.,  Dorigo, M. 1997. AntNet  A mobile agents approach to adaptive routing.Tech. Rep. 9712. Universite Libre de Bruxelles, IRIDIA.27. Di Caro, G.,  Dorigo, M. 1998. An adaptive multiagent routing algorithm inspired byants behavior. In Proceedings of PART98Fifth Annual Australasian Conference onParallel and RealTime Systems pp. 261272. SpringerVerlag.28. Di Caro, G.,  Dorigo, M. 1998. Ant colonies for adaptive routing in packetswitchedcommunications networks. In A. E. Eiben, T. Back, M. Schoenauer,  H.P. SchwefelEds., Proceedings of PPSNV, Fifth International Conference on Parallel Problem Solvingfrom Nature pp. 673682. Berlin SpringerVerlag.29. Di Caro, G.,  Dorigo, M. 1998. AntNet Distributed stigmergetic control forcommunications networks. Journal of Artificial Intelligence Research JAIR, 9, 317365.Available at httpwww.jair.orgabstractsdicaro98a.html.30. Di Caro, G.,  Dorigo, M. 1998. Extending AntNet for besteffort QualityofServicerouting. Unpublished presentation at ANTS 98From Ant Colonies to Artificial Ants FirstInternational Workshop on Ant Colony Optimization.httpiridia.ulb.ac.beants98ants98.html.31. Di Caro, G.,  Dorigo, M. 1998. Mobile agents for adaptive routing. In H. ElRewiniEd., Proceedings of the 31st International Conference on System Sciences HICSS31Vol. 7, pp. 7483. Los Alamitos, CA IEEE Computer Society Press.32. Di Caro, G.,  Dorigo, M. 1998. Two ant colony algorithms for besteffort routing indatagram networks. In Proceedings of the Tenth IASTED International Conference onParallel and Distributed Computing and Systems PDCS 98 pp. 541546.IASTEDACTA Press.33. Dorigo, M. 1992. Optimization, learning and natural algorithms in Italian.Unpublished doctoral dissertation, Politecnico di Milano, Dipartimento di Elettronica, Italy.34. Dorigo, M. 1993. Parallel Ant System An experimental study. Unpublished manuscript.35. Dorigo, M.,  Di Caro, G. 1999. The ant colony optimization metaheuristic. In D. Corne,M. Dorigo,  F. Glover Eds., New ideas in optimization. Maidenhead, UK McGrawHill.36. Dorigo, M.,  Gambardella, L. M. 1996. A study of some properties of AntQ. InH.M. Voight, W. Ebeling, I. Rechenberg,  H.P. Schwefel Eds., Proceedings of PPSNIV,Fourth International Conference on Parallel Problem Solving from Nature pp. 656665.Berlin SpringerVerlag.37. Dorigo, M.,  Gambardella, L. M. 1997. Ant colonies for the traveling salesman problem.BioSystems, 43, 7381.38. Dorigo, M.,  Gambardella, L. M. 1997. Ant Colony System A cooperative learningapproach to the traveling salesman problem. IEEE Transactions on EvolutionaryComputation, 11, 5366.39. Dorigo, M.,  Maniezzo, V. 1993. Parallel genetic algorithms Introduction and overviewof the current research. In J. Stender Ed., Parallel genetic algorithms Theory applications pp. 542. Amsterdam IOS Press.40. Dorigo, M., Maniezzo, V.,  Colorni, A. 1991. Positive feedback as a search strategy.Tech. Rep. 91016. Milan, Italy Politecnico di Milano, Dipartimento di Elettronica.168 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimization41. Dorigo, M., Maniezzo, V.,  Colorni, A. 1996. The Ant System Optimization by a colonyof cooperating agents. IEEE Transactions on Systems, Man, and CyberneticsPart B,26 1, 2941.42. Escudero, L. F. 1988. An inexact algorithm for the sequential ordering problem.European Journal of Operations Research, 37, 232253.43. Feldman, J. A.,  Ballard, D. H. 1982. Connectionist models and their properties.Cognitive Science, 6, 205254.44. Fleurent, C.,  Ferland, J. 1996. Genetic and hybrid algorithms for graph coloring.Annals of Operations Research, 63, 437461.45. Fogel, D. B. 1995. Evolutionary computation. Piscataway, NJ IEEE Press.46. Foulser, D. E., Li, M.,  Yang, Q. 1992. Theory and algorithms for plan merging.Artificial Intelligence, 57, 143181.47. Freisleben, B.,  Merz, P. 1996. Genetic local search algorithms for solving symmetricand asymmetric traveling salesman problems. In Proceedings of IEEE InternationalConference on Evolutionary Computation, IEEEEC 96 pp. 616621. Piscataway, NJIEEE Press.48. Freisleben, B.,  Merz, P. 1996. New genetic local search operators for the travelingsalesman problem. In H.M. Voigt, W. Ebeling, I. Rechenberg,  H.P. Schwefel Eds.,Proceedings of PPSNIV, Fourth International Conference on Parallel Problem Solvingfrom Nature pp. 890899. Berlin SpringerVerlag.49. Gambardella, L. M.,  Dorigo, M. 1995. AntQ A reinforcement learning approach to thetraveling salesman problem. In A. Prieditis  S. Russell Eds., Proceedings of the TwelfthInternational Conference on Machine Learning, ML95 pp. 252260. Palo Alto, CAMorgan Kauffman.50. Gambardella, L. M.,  Dorigo, M. 1996. Solving symmetric and asymmetric TSPs by antcolonies. In Proceedings of the IEEE International Conference on EvolutionaryComputation, ICEC 96 pp. 622627. Piscataway, NJ IEEE Press.51. Gambardella, L. M.,  Dorigo, M. 1997. HASSOP An hybrid ant system for thesequential ordering problem. Tech. Rep. 1197. Lugano, Switzerland IDSIA.52. Gambardella, L. M., Taillard, E.,  Agazzi, G. 1999. MACSVRPTW A multiple AntColony System for vehicle routing problems with time windows. In D. Corne, M. Dorigo, F. Glover Eds., New ideas in optimization. Maidenhead, UK McGrawHill.53. Gambardella, L. M., Taillard, E. D.,  Dorigo, M. 1997. Ant colonies for the QAP. Tech.Rep. 497. Lugano, Switzerland IDSIA.54. Gambardella, L. M., Taillard, E. D.,  Dorigo, M. 1999. Ant colonies for the quadraticassignment problem. Journal of the Operational Research Society, 502, 167176.55. Garey, M. R., Johnson, D. S.,  Sethi, R. 1976. The complexity of flowshop and jobshopscheduling. Mathematics of Operations Research, 22, 117129.56. Gavett, J. 1965. Three heuristic rules for sequencing jobs to a single production facility.Management Science, 11, 166176.57. Glover, F. 1989. Tabu search, part I. ORSA Journal on Computing, 1, 190206.58. Glover, F. 1989. Tabu search, part II. ORSA Journal on Computing, 2, 432.59. Goldberg, D. E. 1989. Genetic algorithms in search, optimization and machine learning.Reading, MA AddisonWesley.60. Goss, S., Aron, S., Deneubourg, J. L.,  Pasteels, J. M. 1989. Selforganized shortcuts inthe Argentine ant. Naturwissenschaften, 76, 579581.61. Grasse, P. P. 1946. Les insects dans leur univers. Paris Editions du Palais de ladecouverte.Artificial Life Volume 5, Number 2 169M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimization62. Grasse, P. P. 1959. La reconstruction du nid et les coordinations interindividuelles chezBellicositermes natalensis et Cubitermes sp. La theorie de la stigmergie Essaidinterpretation du comportement des termites constructeurs. Insectes Sociaux, 6, 4181.63. Hertz, J., Krogh, A.,  Palmer, R. G. 1991. Introduction to the theory of neuralcomputation. Redwood City, CA AddisonWesley.64. Heusse, M., Guerin, S., Snyers, D.,  Kuntz, P. 1998. Adaptive agentdriven routing andload balancing in communication networks. Advances in Complex Systems, 1, 237254.65. Hillis, W. D. 1982. The connection machine. Cambridge, MA MIT Press.66. Holland, J. 1975. Adaptation in natural and artificial systems. Ann Arbor University ofMichigan Press.67. Johnson, D. S.,  McGeoch, L. A. 1997. The traveling salesman problem A case study.In E. H. Aarts  J. K. Lenstra Eds., Local search in combinatorial optimizationpp. 215310. Chichester, UK Wiley.68. Kirkpatrick, S., Gelatt, C. D.,  Vecchi, M. P. 1983. Optimization by simulated annealing.Science, 2204598, 671680.69. Koopmans, T. C.,  Beckmann, M. J. 1957. Assignment problems and the location ofecononomic activities. Econometrica, 25, 5376.70. Kruger, F., Merkle, D.,  Middendorf, M. 1998. Studies on a parallel Ant System for theBSP model. Unpublished manuscript.71. Lawler, E. L., Lenstra, J. K., RinnooyKan, A. H. G.,  Shmoys, D. B. Eds.. 1985. Thetravelling salesman problem. Chichester, UK Wiley.72. Leighton, F. 1979. A graph coloring algorithm for large scheduling problems. Journal ofResearch of the National Bureau of Standards, 84, 489505.73. Lin, S. 1965. Computer solutions of the traveling salesman problem. Bell SystemsJournal, 44, 22452269.74. Ma, Q., Steenkiste, P.,  Zhang, H. 1996. Routing in highbandwidth traffic in maxminfair share networks. ACM Computer Communication Review SIGCOMM 96 , 26 4,206217.75. Maniezzo, V. 1998. Exact and approximate nondeterministic treesearch procedures forthe quadratic assignment problem. Tech. Rep. CSR 981. In Scienze dellInformazione,Universita di Bologna, sede di Cesena, Italy.76. Maniezzo, V.,  Colorni, A. in press. The Ant System applied to the quadraticassignment problem. IEEE Transactions on Knowledge and Data Engineering.77. Maniezzo, V., Colorni, A.,  Dorigo, M. 1994. The Ant System applied to the quadraticassignment problem. Tech. Rep. IRIDIA9428. Belgium Universite Libre de Bruxelles.78. Michel, R.,  Middendorf, M. 1998. An island model based Ant System with lookaheadfor the shortest supersequence problem. In A. E. Eiben, T. Back, M. Schoenauer, H.P. Schwefel Eds., Proceedings of PPSNV, Fifth International Conference on ParallelProblem Solving from Nature pp. 692701. Berlin SpringerVerlag.79. Michel, R.,  Middendorf, M. 1999. An ACO algorithm for the shortest commonsupersequence problem. In D. Corne, M. Dorigo,  F. Glover Eds., New ideas inoptimization. Maidenhead, UK McGrawHill.80. Narendra, K.,  Thathachar, M. 1989. Learning automata An introduction.PrenticeHall.81. Nilsson, N. J. 1998. Artificial intelligence A new synthesis. Morgan Kaufmann.82. Paessens, H. 1988. The savings algorithm for the vehicle routing problem. EuropeanJournal of Operational Research, 34, 336344.83. Pasteels, J. M., Deneubourg, J.L.,  Goss, S. 1987. Selforganization mechanisms in antsocieties i Trail recruitment to newly discovered food sources. ExperientiaSupplementum, 54, 155175.170 Artificial Life Volume 5, Number 2M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimization84. Raiha, K.J.,  Ukkonen, E. 1981. The shortest common supersequence problem overbinary alphabet is NPcomplete. Theoretical Computer Science, 16, 187198.85. Rechenberg, R. I. 1973. Evolutionsstrategie Optimierung technischer Systeme nachPrinzipien der biologischen Evolution. Stuttgart, Germany FrommannHolzboog.86. Reinelt, G. 1994. The traveling salesman problem Computational solutions for TSPapplications. Berlin SpringerVerlag.87. Rubinstein, R. Y. 1981. Simulation and the Monte Carlo method. New York Wiley.88. Rumelhart, D. E., McClelland, J. L.,  the PDP Research Group Eds.. 1986. Paralleldistributed processing. Cambridge, MA MIT Press.89. Schoonderwoerd, R., Holland, O.,  Bruten, J. 1997. Antlike agents for load balancingin telecommunications networks. In J. Muller Ed., Proceedings of the First InternationalConference on Autonomous Agents pp. 209216. ACM Press.90. Schoonderwoerd, R., Holland, O., Bruten, J.,  Rothkrantz, L. 1996. Antbased loadbalancing in telecommunications networks. Adaptive Behavior, 52, 169207.91. Schwefel, H.P. 1977. Numerische Optimierung von ComputerModellen mittels derEvolutionsstrategie. Basel, Switzerland Birkauser.92. Shani, S.,  Gonzales, T. 1976. Pcomplete approximation problems. Journal of ACM,23, 555565.93. Streltsov, S.,  Vakili, P. 1996. Variance reduction algorithms for parallel replicatedsimulation of uniformized Markov chains. Discrete Event Dynamic Systems Theory andApplications, 6, 159180.94. Stutzle, T. 1998. Parallelization strategies for ant colony optimization. In A. E. Eiben,T. Back, M. Schoenauer,  H.P. Schwefel Eds., Proceedings of PPSNV, FifthInternational Conference on Parallel Problem Solving from Nature pp. 722731. BerlinSpringerVerlag.95. Stutzle, T.,  Dorigo, M. 1999. ACO algorithms for the quadratic assignment problem. InD. Corne, M. Dorigo,  F. Glover Eds., New ideas in optimization. Maidenhead, UKMcGrawHill.96. Stutzle, T.,  Dorigo, M. 1999. ACO algorithms for the traveling salesman problem. InK. Miettinen, M. M. Makela, P. Neittaanmaki,  J. Periaux Eds., Evolutionary algorithmsin engineering and computer science. Chichester, UK Wiley.97. Stutzle, T.,  Hoos, H. 1997. Improvements on the Ant System IntroducingMAX MIN ant system. In Proceedings of the International Conference on ArtificialNeural Networks and Genetic Algorithms pp. 245249. SpringerVerlag.98. Stutzle, T.,  Hoos, H. 1997. TheMAX MIN Ant System and local search for thetraveling salesman problem. In T. Back, Z. Michalewicz,  X. Yao Eds., Proceedings ofIEEEICECEPS 97, IEEE International Conference on Evolutionary Computation andEvolutionary Programming Conference pp. 309314. Piscataway, NJ IEEE Press.99. Stutzle, T.,  Hoos, H. 1998.MAX MIN Ant System and local search forcombinatorial optimization problems. In S. Voss, S. Martello, I. H. Osman,  C. RoucairolEds., Metaheuristics Advances and trends in local search paradigms for optimizationpp. 137154.100. Subramanian, D., Druschel, P.,  Chen, J. 1997. Ants and reinforcement learning A casestudy in routing in dynamic networks. In Proceedings of IJCAI97, International JointConference on Artifical Intelligence pp. 832838. Palo Alto, CA Morgan Kauffman.101. Sutton, R. S.,  Barto, A. G. 1998. Reinforcement learning An introduction. Cambridge,MA MIT Press.102. van der Put, R. 1998. Routing in the faxfactory using mobile agents. Tech. Rep.RDSV98276. Leidschendam, The Netherlands KPN Research.103. van der Put, R.,  Rothkrantz, L. in press. Routing in packet switched networks usingagents. Simulation Practice and Theory.Artificial Life Volume 5, Number 2 171M. Dorigo, G. Di Caro, and L. M. Gambardella Ant Algorithms for Discrete Optimization104. Watkins, C. J. 1989. Learning with delayed rewards. Unpublished doctoral dissertation,Psychology Department, University of Cambridge, UK.105. White, T., Pagurek, B.,  Oppacher, F. 1998. Connection management using adaptivemobile agents. In H. R. Arabnia Ed., Proceedings of the International Conference onParallel and Distributed Processing Techniques and Applications PDPTA 98pp. 802809. Athens, GA CSREA Press.106. Whitley, D., Starkweather, T.,  Fuquay, D. 1989. Scheduling problems and travellingsalesman The genetic edge recombination operator. In J. D. Schaffer Ed., Proceedingsof the Third International Conference on Genetic Algorithms pp. 133140. Palo Alto, CAMorgan Kaufmann.172 Artificial Life Volume 5, Number 2
