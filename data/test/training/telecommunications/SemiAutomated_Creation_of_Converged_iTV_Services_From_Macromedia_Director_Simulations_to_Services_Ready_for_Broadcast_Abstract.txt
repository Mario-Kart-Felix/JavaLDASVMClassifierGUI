Journal of Virtual Reality and Broadcasting, Volume 42007, no. 17JVRB EuroITV 2006 Special, no. 7SemiAutomated Creation of Converged iTV ServicesFrom Macromedia Director Simulations to Services Ready forBroadcastEmmanuel Tsekleves and John CosmasBrunel UniversitySchool of Engineering  DesignUxbridge UB8 3PH, UKphone, email Emmanuel.Tseklevesbrunel.ac.uk,John.Cosmasbrunel.ac.ukAbstractWhile sound and video may capture viewers attention, interaction can captivate them. This has not beenavailable prior to the advent of Digital Television. Infact, what lies at the heart of the Digital Television revolution is this new type of interactive content, offeredin the form of interactive Television iTV services.On top of that, the new world of converged networks has created a demand for a new type of converged services on a range of mobile terminals TabletPCs, PDAs and mobile phones. This paper aims atpresenting a new approach to service creation that allows for the semiautomatic translation of simulationsand rapid prototypes created in the accessible desktopmultimedia authoring package Macromedia Directorinto services ready for broadcast. This is achieved bya series of tools that deskill and speedup the processof creating digital TV user interfaces UI and applications for mobile terminals.Digital Peer Publishing LicenceAny party may pass on this Work by electronicmeans and make it available for download underthe terms and conditions of the current versionof the Digital Peer Publishing Licence DPPL.The text of the licence may be accessed andretrieved via Internet athttpwww.dipp.nrw.de.First presented at the 4th European InteractiveTV Conference EuroITV 2006, extended and revisedfor JVRBThe benefits of rapid prototyping are essential forthe production of these new types of services, andare therefore discussed in the first section of this paper. In the following sections, an overview of theoperation of content, service, creation and management subsystems is presented, which illustrates whythese tools compose an important and integral part of asystem responsible of creating, delivering and managing converged broadcast and telecommunications services. The next section examines a number of metadata languages candidates for describing the iTV services user interface and the schema language adoptedin this project. A detailed description of the operationof the two tools is provided to offer an insight of howthey can be used to deskill and speedup the processof creating digital TV user interfaces and applicationsfor mobile terminals. Finally, representative broadcastoriented and telecommunication oriented convergedservice components are also introduced, demonstrating how these tools have been used to generate different types of services.Keywords Interactive Television, Mobile Terminals, User Interfaces, iTV Services, Macromedia Director1 MotivationThe next generation multimedia mobile services willprovide a variety of multimedia content such as moving pictures, movies, images and Internet pages delivered via converged broadcast DVBT, DVBH,DAB, cellular UMTS, GPRS, and wireless WLAN,urnnbnde0009610862, ISSN 18602037Journal of Virtual Reality and Broadcasting, Volume 42007, no. 17JVRB EuroITV 2006 Special, no. 7BRAN etc. networks targeted to a range of differentenduser terminal hosting operating systems, Application Program Interfaces APIs e.g. Java MHP, JavaMIDP etc. and player resources MPEG2, MPEG4, H.263, H.264, HTML browser etc.. These services are wanted by consumers to access content inmobile environments and needed by network providersto generate new sources of revenues to support investments in their new networks. It is therefore necessarythat crisp and clear user requirements be drawn upfor the development team in order for them to createthe services. Currently this service creation processutilises an iterative software development cycle whereonce requirements are captured a software based prototype is iteratively developed and validated. This process is expensive because it requires a full softwareprototype to be developed at the end of each iterativestep until a final solution is created. To reduce this costa new service development methodology has been developed that allows the efficient creation of servicesthrough the application of rapid prototyping, simulations and semiautomatic fast application developmentSE03, Kra96. This service development methodology is more efficient because it removes the need fora softwarebased prototype to be developed in the traditional approach. Alternatively the designer createsand simulates rapid prototypes using graphical design tools. These rapid prototypes are then used as atemplate for attaching preimplemented functions in asemiautomatic manner thus creating the final serviceapplication.The purpose of service scenarios is to derive crispand clear user requirements by describing in detailand storyboarding the service components, their technical specifications, the situation where they will beconsumed and the target audience for each of our distinct service operatorscustomers. Once the servicescenario has been defined, the rapid prototypes can bedeveloped.The purpose of rapid prototyping of multimedia services is to demonstrate the viability and validity ofservice proposals without going through the huge effort of building delivery systems and enduser terminals and deploying services. This is a very importantstep towards service development because, first, it allows service designers to visualise how their proposals would look like on an enduser terminal to obtaina common understanding of the service concept and,second, it enables service designers to test the usefulness of their ideas on relevant user groups well before the completion of any delivery system and enduser terminal technology. A rapid prototype of a scenario can also serve as a testing medium, by involving the user in the earlier stages of the design cycleto establish user acceptance and therefore be modifiedaccordingly. This methodological approach is knownas scenariobased requirements gathering. Scenariobased requirements gathering techniques have beenused in Human Computer Interaction research as aneffective way to capture, analyse and communicateusers needs for technology CR92, Car00. Three scenarios have been tested with real users in order to ensure that the selected services really correspond withuser needs PRS02, SDP04.The purpose of semiautomatically generating applications is to reduce development times for creating the first and updated versions of the applicationsfor a range of different enduser terminals hostingdifferent operating systems, APIs, network interfacesand player resources. This is very important becausethe introduction of new services is increasingly becoming a very complex logistical exercise due to theproliferation of different mobile terminal types being introduced into the market with a new model being introduced almost every week from a single terminal manufacturer Ind06 and due to the proliferation of different service providers, including broadcasters, telecommunication operators and independentproviders. Even though the motivations and type ofservices of these providers are quite different, the toolsused to develop the services should be the same.This paper describes a Rapid Prototyping and Semiautomated Application Generation tools set, which canproduce applications very fast from a rapid prototypesimulation for all classes of service providers.2 Service Provision ArchitectureOverviewThis section describes the overview of a service provisioning architecture, which is shown in Figure reffigure01 at subsystem and component level. It consists of the Content Creation, Service Creation andService Management subsystems. This overview provides an insight on how the Rapid Prototyping andSemiautomated Generation tools can be incorporatedwithin a typical provisioning architecture.More precisely, this system architecture has beendesigned and developed to provide content for servicesurnnbnde0009610862, ISSN 18602037Journal of Virtual Reality and Broadcasting, Volume 42007, no. 17JVRB EuroITV 2006 Special, no. 7Figure 1 Overall System Architecture  subsystem and component levelin a single base format and generating the graphicalcomponents of the enduser terminals Graphical UserInterface GUI for delivery into a number of converged DVBHT, UMTS, GPRS enduser terminalsTablet PC, PDA, Mobile Phone. The audio visualbase format employed in the INSTINCT project wasMPEG2 ISO95 and the GUI base format was XMLwith JPEGPNG. The process of integrating contentwas achieved using a simulation tool that allows a fastprototype of the service to be generated for testingwith the organization commissioning the service andwith potential consumers.More precisely, the Content Creation subsystemconsists of the Content Processing, Content Annotation and Content Integration components. The Content Processing component tool provides access toand processing of MPEG encoders, transraters andtranscoders MPEG2 to MPEG4. This transratingis being made for the delivery of audio visual contentto lowpowered terminals such as mobile phones. TheContent Integration component aggregates all the UserInterface UI elements graphics and buttons andcontent elements videoaudio clips, Internet linksthat comprise the services content and user interfacelookandfeel. A desktop publishing tool Macromedia Director was used to prototype services quicklyand iteratively construct and test them on organizations and their customers who were commissioning theservice.The Content Annotation component consists of aService description tool that generates imports andmaintains content descriptions and basic service descriptions. It imports an XML file generated by theApplication Generation tool that describes the basic services, contents and associate content and enables the addition of more content service descriptions which are stored into the common database thatis shared with Service Description tool.The Service Creation subsystem consists of theUser Interface Generation, Application Generation,Service Description, Content Packaging and Interactive Services components. Once the user interface design process is completed then the UI Generation software component is used to parse the desktoppublishing tool file and generate a XML descriptionof the user interface with its graphical components.The XML description could be further translated toHTML, WML and several other formats, dependingon the navigation engine resident on the targeted enduser terminals. In order to add functionality to theurnnbnde0009610862, ISSN 18602037Journal of Virtual Reality and Broadcasting, Volume 42007, no. 17JVRB EuroITV 2006 Special, no. 7user interface graphical widgets, the semiautomaticApplication Generation software component, which isshown in Fig. 4, is used to map terminal functions,depicted on the right hand side of the tool, onto UIgraphical widgets, depicted on the left hand side ofthe tool as either a DOM tree or on the centre ofa tool as a graphical widget. The different terminalprofiles take into account aspects such as operatingsystem Linux, Windows Mobile, middleware APIMHP, MIDP, JSR272 RW07 and device Tablet PC,PDA, Mobile Phone. The Service Description software component generates scalable service descriptions, which include the session, the schedule, the coding format attributes, and the network area descriptions and delivers these descriptions as a package tothe Push Broadcast Portal in the Service Managementsubsystem ACC07.One or more Service Creation subsystems deliverservice descriptions to a single Service Managementsubsystem which collates all of them and deliversthem as an Electronic Service Guide ESG to enduserterminals activating the Content Packaging servers atthe appropriate time. The Service Management component is used for setting up contracts between thebusiness entities and then managing them by monitoring the Quality of Service QoS for the deliveredservices. The User Management component is usedto establish subscription and ondemand services withendusers and to provide the enduser with a pulledversion of the ESG.3 Metadata Language ComparisonToday it is possible to access information via a widerange of mobile computing devices. Despite the importance these communication devices have gained,too much time is spent in designing UIs for each newdevice, since there is not a unified standard language.Instead the design of the UI is restricted to specific programming languages, varying from one device to theother e.g. J2ME for PDAs, Wireless Markup Language for mobile phones, etc. Since our researchaims at encompassing several portable devices, fromset top boxes to PDAs, tablet PCs and smart phones, ageneric language for creating deviceindependent userinterface must be sought.In addition, a significant aim for a broadcastingrelated metadata language is the use of a language,which can be economically broadcasted along with thematerial and media UI description and graphics it describes. More precisely, the user interface descriptionlanguage should qualify all of the following criteria Consistency should be consistent amongst different systems. Platform Independency the user interface shouldbe designed in a generic way without worryingabout the system on which the UI will be employed. Extensibility when extra functionality needs tobe incorporated the author should be allowedto apply modifications without starting fromscratch. Prototyping designers should be able to involvethe user in the initial design stages and conductearly usertrials. Usability the language should be fairly easy touse by nonspecialists, minimizing the learningcurve. Open Standard it should be a nonproprietarylanguage recognised and supported by an international body or consortium.The major user interface description language candidates for the user interface generation tool are UserInterface Markup Language UIML, Scalable VectorGraphics SVG, Portable Content Format PCF andExtensible Markup Language XML. Let us take andexamine each one of them separately.The UIML is an XML language that allows designers to describe the UI in generic terms and then usea style description to map the UI to various operating systems. In particular, the UIML describes theUI with five different sections description, structure,data, style and events APB99. Despite the factthat it allows a fairly device independent descriptionof a UI, its main shortcoming is that it must providea target specific renderer that will convert the UIMLmetadata generating the user interface An02. Thefact that the renderers support Java, HTML, WML andVoiceXML, means that the user interface will workonly for platformspecific devices. It should be alsonoted that the company has developed a UIML toolLiquidUI in which the Java renderer is currently onlycompatible with JDK 1.3 Har04, not taking into account the effort one should put in writing these renderers for every device. In addition it takes quite someurnnbnde0009610862, ISSN 18602037Journal of Virtual Reality and Broadcasting, Volume 42007, no. 17JVRB EuroITV 2006 Special, no. 7time to learn it, becoming even more complicated bythe usage of the different sections description, data,events, etc..Scalable Vector Graphics SVG composes anothercandidate technology for using in our tool. More precisely SVG is an XMLbased language for describingtwodimensional graphics and graphical applicationsin XML. It is a W3C standard W3C03 and composesa platform and device independent solution to graphicdesign and display. Being an XML language it integrates with other W3C standards as the DocumentObject Model DOM and XSL. Although SVG seemsas a good candidate for the metadata language since itis extensible, consistent, platform independent and anopen standard, it was unfortunately not supported bythe DVBMHP when this research project started itswork.The Portable Content Format PCF is a standardspecified by the DVB project to describe interactivedigital television services. PCF is intended to provide the industry with a platformindependent format for the transfer of interactive content betweendifferent open and proprietary middleware platformsBCH06. A description captured using the PCF,however is not intended for actual transmission in adigital television network. Rather, it is an intermediateform that will need to be converted to some platformspecific representation prior to transmission. There aretwo main modes of implementing PCF on the terminalsidea with delivery of the output either directly to thetarget platforms engine execution or presentation,b or possibly via clientserver model using a smallmicro browser application sitting on top of anexecution engine.PCF still requires that the party or parties handling the conversion will have to implement appropriate conversion infrastructure and software Pro05.Furthermore PCF is mainly focused on data exchangebetween set top box middleware solutions and notmiddleware platforms for smaller lowpower processing terminals such as PDAs and mobile phones. BothSVG and PCF form good solutions that provide addedfunctionality and benefits. They both complement thefunctionality of our existing tool and is planned to beintegrated in a following phase.Last but not least, XML constitutes a platform independent language created by the W3C Consortiumhas also developed HTML, with its main strengththe separation of content and presentation. As faras consistency, this can be achieved through the usage of Document Type Definition DTD. Furthermorethrough the usage of eXtensible Stylesheet LanguageXSL and XSLT W3C04 it can be published in different formats. Particularly, in terms of user interfacedesign of iTV services, it can assist in the achievementof a generic UI transformed into the different formatsthat each device and platform requires quickly, allowing rapid prototyping of the UI design though the creation of a new customized schema.4 User Interface XML LanguageSchemaThe User Interface XML Schema language was developed for the sole purpose of providing XML descriptions of the User Interface produced by the User Interface Generation Tool.In general the following functionality is provided User Interface  The root of the schema is comprised by the  UI  element, which has oneattribute Device see Figure 2. The Deviceattribute holds information about the screen resolution of the terminal where the UI is presented.i.e. 1024x768 for a Tablet PC, 260x320 for amobile phone, etc The  Node  element represents the differentnodespages of the User Interface. For example aUser Interface with 12 pages has 12  Node elements each one of them distinguished by aunique ID attribute. The  Node  element,in turn, can contain a number of combinations ofthe following child elements Button, Graphics,TextArea, TextField, Video and Audio. Button  The  Button  element is dividedinto four categories according to the button typeused Graphic Button, Radio Button, Check Button and Push Button. This element holds information about the button components screencoordinates xCord, yCord, image size Width,Height and many other parameters. The mostimportant of those are the ActionID, which isempty but this is responsible for capturing the information that will be filled by the ApplicationGeneration Tool that will hold information regarding the functionalityaction that takes placeurnnbnde0009610862, ISSN 18602037Journal of Virtual Reality and Broadcasting, Volume 42007, no. 17JVRB EuroITV 2006 Special, no. 7in the backend when the user clicks on the button. For instance a button component mappedwith a link to the video decoder and player APIsto decode and play a video clip, e.g.  Action VideoPlayer, Play, Filename  Action .The  Functionality  element holds the number of the Node the next page the user navigatesto. Graphics  The  Graphics  element lists theimages that compose the User Interface layoutand any pictures that are part of the content. TextArea  the  TextArea  element holdspure textual information that can be displayedanywhere on the UI. Furthermore like the Button  element the  TextArea  element can hold functionality information, whichenables the user, when the  TextArea  component is clicked, to navigate to a different page.see figure 2 TextField  the  TextF ield  holds textual information that are displayed only in a FieldTextField component. Video  The  V ideo  element holds video cliprelated information, such as duration, screen coordinates of the video clip. Audio  The  Audio  element holds audioclip related information such as sample rate e.g.22.050 kHz, bit depth e.g. 16 bits and duration5 User Interface Generation ToolSo far the task of developing applications and user interfaces was part of software engineers job description, who was given the arduous task of handwritingall the code for the service applications on top of theirunderlying user interfaces in the Multimedia HomePlatform MHP Pro03 for more powerful terminalsTablet PCs, PDAs, Set top boxes and Mobile Information Device Profile MIDP Mic06 for mobilephones.Previous approaches have been to create digitalTV applications and their UIs using the Multimedia and Hypermedia Experts Group MHEG or MHPstandard. In case of the former, it is part of theISOIEC 135225 Multimedia and Hypermedia Experts Group MHEG Gro03 international standardused for Digital Teletext in UK digital terrestrialtelevision. It is a language for describing multimedia presentations as a collection of objects. More precisely, UIs in the MHEG have to be described as Multimedia presentations using a non XMLbased predefined scripting language, thus forcing programmers todeal with the UI as well the coding aspects of the digital TV applications as well. Additionally since it wasmainly developed for designing Digital Teletext it isonly able to produce UIs that are very limited from adesign of interactive TV services point of view. Furthermore, employing a non xmlbased solution meansthat the UI cannot be transformed to other formats andbe ported over different type of terminalsplatforms,other than Settop boxes. This is further restrictedby the user navigation methods defined in the MHEG,which account only for a remote control based modeof user input and interaction Gro03.Compared to existing solutions, such as the MHEG,MHP is a second generation system with a significantstep forward in functionality, enabling a much greatervariety of interactive applications, services and thusinteractivity.Previous approaches to create UIs using MHP haveused its Java Abstract Window Toolkit AWT orHome Audio Video interoperability HAVi components HAV04. This approach however is very effortand time demanding, since Java components such asthese must be to handcoded in Java by the programmer, which is not an easy task, especially when youattempt to reproduce attractive and complex user interfaces that require complicated layouts and components. Furthermore, the produced UIs look and feeloffers an inflexible, uncreative and unexciting user experience since AWT and HAVi are constrained in creating anything other than simple and fixed shaped UIcomponents. On top of that, building a UI is a highlyiterative process, meaning that the code for the UI hasto be rewritten many times. The shortcomings of UIsproduced in this manner may be less obvious for services delivered to big TV sets via settop boxes but arenot in any way suitable for smaller screens where thelean forward versus lean backwards mode of interaction and viewing applies.Moreover and following the previous discussion it isimportant to create tools to enable graphics designers,interaction designers and software engineers to workwithin their own area of expertise. However it is extremely difficult and rare to find a good designer whois also an experienced programmer and vice versa.This is particularly the case for Digital TV that reurnnbnde0009610862, ISSN 18602037Journal of Virtual Reality and Broadcasting, Volume 42007, no. 17JVRB EuroITV 2006 Special, no. 7Figure 2 The User Interface XML Schema Languagequires people to work with the Java languages of theMHP and MIDP respectively.Tools such as Director are very useful and userfriendly since they use graphical means to expressgraphical concepts draganddrop user interface.Also the addition of an eventbased scripting languageLingo and custom preprogrammed modules makesDirector an ideal tool to employ for the design offast iTV prototypes, since it maps well to the directmanipulation graphical user interface style. Therefore by moving some aspects of the user interfaceimplementation from conventional code into an easytouse multimedia graphic authoring package, theseaspects of user interface design implementation aremade available to those who are not conventional programmers.Despite its easeofuse and usefulness in providingfast prototypes and simulations of iTV services, Director forms a proprietary tool that does not interface withthe open standard solutions of MHP and MIDP employed today in displaying GUIs in Tablet PCs, settopboxes and mobile devices respectively. Consequentlythere is a demand for the development of a tool thatwill create that interface by employing an opensourcestandard such as XML. This tool should be responsible for converting and outputting the user interfacecreated in Director into a format that is compliant withthe MHP specification and can be used in conjunctionwith MHP Xlets as well as other middleware solutionssuch as MIDP.The proposed user interface Generation Tool is partof a threestage UI production process, where the userinterface is divided into a twotier solution, in whichthe graphical part of the UI frontend is produced independently from the actual applications that lie behind the UI backend.In particular, in the first stage the designer createsthe graphical elements components of the UI usingany commercial graphical design tool. These graphical components are then exported as bitmap graphics in one of the graphic formats currently supportedby the MHP GIF, JPG and PNG. In the next stagethese graphics are imported into Macromedias Director Sys06 authoring package to create and simulatethe user interface layout, content text, internet pagesand snippets of audio and video. These two stages areentirely concerned with the graphical components ofthe user interface and therefore are responsible for theurnnbnde0009610862, ISSN 18602037Journal of Virtual Reality and Broadcasting, Volume 42007, no. 17JVRB EuroITV 2006 Special, no. 7frontend.More precisely, the new tool composes a fully automated package for parsing the different nodespagesof the UI created in Director that automatically exports the full XML description of the user interface.The tool works by scanning Directors score, a timeline where the author places the graphical components,both horizontically in terms of frames and verticallyin terms of channels, so that all the graphics of everyUI nodepage are identified and automatically outputto the target XML file. It is also records the functionsused in Directors scripting language Lingo to interlink the different pagesnodes.All this information is exported in a single XML fileusing a descriptive schema see Figure 2, categorisedand built in such a way that can be then transformedinto different formats, such as HTML.The tool is also responsible for automatically copying all the graphic files and content used in the UI intoa folder, thus speedingup the production and distribution process.Figure 3 The User Interface XML Schema LanguageTherefore, instead of creating a new tool fromscratch to perform this task and invest time in trainingdesigners to learn how to use it, an already existingsuccessful commercial multimedia authoring packageis employed and enhanced.Last but not least, without having to write a singleline of Java code or XML metadata, designers can easily, effectively and quickly produce a graphical userinterface frontend in a standard format XML thatcan be then manipulated by MHP and MIDP to render the UI on the enduser terminal. Therefore, thisapproach serves as a User Interface simulator wherewhat you see is what you get. This approach can beused to rapid prototype and simulate enduser terminaluser interfaces and services where human factors specialists and interaction experts can conduct user trialswith endusers, utilising the trials feedback to iteratively create an aesthetically pleasant and userfriendlydesign.In the last and more important step, the User Interface Generator Tool semiautomatically performs themost complex task accounts for the backend, whichis discussed in the next section.The benefits gained by using this service development methodology increases with relation to the complexity of the service application.5.1 LimitationsDirector is a very versatile package with numeroususes not limited to just building user interfaces. Theuser interface generation tool accounts for only a smallsubset of the potential applications of Director, specific to developing user interfaces. In addition, thetesting performed on the user interface generation hasrevealed that parsing of the Director file will fail unless specific set of design and authoring rules are followed prior to the import of the file in the user interface generation tool. Therefore the designerauthor ofthe Director file must ensure his design follows somerequirements and guidelines.More precisely, Director does not distinguish whichcomponents are simple graphics and which function asbuttons. Thus this needs to be manually specified bythe author. This can be done either when the graphicalcomponent is being designed in a graphic design package e.g. Photoshop by appending the word Buttonto the filename of the component or inside Directorby appending the word Button to the name of thecast member e.g. the name of the graphic cast memberClickOk will become ClickOkButton.Furthermore, MHP supports only three graphictypes GIF, JPG and PNG. So the UI graphical components should be exported in one of the above formats. PNG 24bit is recommended since it supportstransparency and it is good at retaining vectorbasedgraphics.Lastly, the tool has been programmed to recordsome functionality. Namely it records the change ofa leaf node e.g. jumping from one page to another.Supported functions are as followsurnnbnde0009610862, ISSN 18602037Journal of Virtual Reality and Broadcasting, Volume 42007, no. 17JVRB EuroITV 2006 Special, no. 7go to frame 45  goes to the leaf node specified bythe frame nogo to startMarker  goes to the leaf node specifiedby the marker namego startMarker  goes to the leaf node specifiedby the marker namegoToNetPage www.instinct.org  opens the webpage in a browser6 Application Generation ToolAfter the UI is generated frontend, it is necessaryto code the logic of the application itself backendand then pack the application to be broadcasted anddelivered to the terminal.The Application Generation tool comprises a headend solution that is responsible for semiautomaticallydeveloping MHP for Laptop PCs, Tablet PCs, PDAsand MIDP for mobile phones applications for Digital TV. Since MHP and MIDP are different standardswith different sets of Java APIs, different sets of applications have to be created.On the terminal side lies a rendering subsystem thatdisplays the frontend and permits Xlet navigation viahttp links.The Application Generation tool functions by importing the XML Description of the generated UI seeFigure 4 and presenting it in a hierarchical node bynode page by page manner both as a XML DOM treeand as a graphical layout left and centre panel of thescreenshot window of Figure 4. The user is also ableto further manipulate the Java DOM tree by removing, modifying and adding new components onto theUI without having to revert to the Director simulationand the User Interface Generation tool.The tool incorporates a number of device profilese.g. Tablet PC, PDA with relevant functional modules, MHP and MIDP in this case for different platforms e.g. Linux, Windows that the user can import as plugins right panel of Figure 4, This includesplaying media files, storing and retrieving media content to storage devices, loading and executing applications and several others. Although only MHP andMIDP functional modules have been written so far,additional middleware solutions based on other Javaand C APIs can be added very easily, increasing thespectrum of platforms and terminals on which the applications can be consumed.These functional modules commands are classesand methods that are written by the software engineersand imported on to the tool. From this list the designeris able to select the profile for the specified type ofdevice and platform and then, in a drag and drop manner, map the relevant functionality to the particular leafnode of the UI. For instance, a button component canbe mapped with a link to call the player APIs and playa particular video clip. For this reason a protocol aspecially defined String has been defined linking thefrontend UI components to a specific functionalitybackend. This protocol is created when a functionalmodule is draganddropped onto a user interface component and is stored on the XML file that describes theUI under the  ActionID  element. This is thenparsed by the resident application on the terminal thatperforms a search to see if there is a method that corresponds to the contents of this protocol.For instance if the functional module commandthat has been assigned to a button is responsible forplaying an MPEG4 video clip named BBC Newsnight on a MHP enabled terminal such as a settopbox or Tablet PC in a 640x480px resolution then theprotocol will be formed asmhpplayVideoClipBBC Newsnight.mp4640x480   API name methodclass parameter1 parameter2Based on this protocol one can device and writea number of other related functional modules. Thefollowing list provides some of these that have beenimplemented and tested throughout the INSTINCTproject Tune Channel tunes to a TV channel. Oneparameter that specifies whether to tune tonext 1 or previous 1 channel or specificchannel if number is known e.g. 6 i.e.mhpTuneChannel1 Launch Xlet launches a specific Xlet application. Parameter name of Xlet i.e.mhplaunchAppmyXlet Play video or audio clip plays a specified video clip. Parameters audiovideoclip filename, video clips resolution. i.e.mhpplayAudioClipradioOne.mp3 Display HTML launches an Internet browser thatdisplays the specified URL of an HTML page i.e.mhplaunchHTMLhttpnews.bbc.co.ukurnnbnde0009610862, ISSN 18602037Journal of Virtual Reality and Broadcasting, Volume 42007, no. 17JVRB EuroITV 2006 Special, no. 7Figure 4 INSTINCT User Interface  Application Generation ModelOnce all the required functional modules are linkedinto the specified UI components, the tool stores thesecompleted strings in the protocol defined above underthe  ActionID  element. Then by performinga scan of the assigned commands from these tags itcopies the corresponding classes to a number of Javafiles files with .java extension in order to build anXlet MHP application or a Midlet MIDP application that will run these commands when run in theenduser terminal.When the mapping is finished the UI descriptionstored in the XML file can be transformed into HTMLusing the W3C XSLT language. This transformationserves as a simulation and visualisation of the XMLfile and evaluation tool of the UI in enduser terminals,which do not have the processing power to run Director for the user trials. In addition such transformations permit the usage of different rendering subsystems on the terminal side, such as an HTML browserbased rendering subsystem as well as using a traditional graphics processing and XML parser to renderthe UI.This tool allows services to be simulated on targetenduser terminals that have the same lookandfeel asthe final service without going through the expensiveprocess of commissioning the service on the broadcastand cellular network delivery platforms.In addition this approach reinforces platform independency, since it allows the delivery of a commonUI with terminal specific functionality. For example the same UI frontend can be used on settopboxes running supporting different middleware solutions e.g. MHP Pro03, OpenTV Cor05, OCAPMSC05 etc. and running on different operating systems e.g. Windows, Linux.Thus, by reusing code in an easytouse, time andcodeefficient manner the Application Generation toolcan semiautomate the process of writing applicationsurnnbnde0009610862, ISSN 18602037Journal of Virtual Reality and Broadcasting, Volume 42007, no. 17JVRB EuroITV 2006 Special, no. 7for a range of terminals and platforms.7 Design  Application Generationof Prototype and Simulated ServicesThe user interface generation tool and the applicationgeneration tools were used to create both broadcastand telecommunications Telco service provider oriented services and applications for a wide range of terminal types during the INSTINCT project and thesewere demonstrated in the International Broadcast Exhibition IBC in 2005 IBC07.Figure 5 provides screenshots of the Telcoorientedservices. These are GUI prototypes that have been created and simulated in Macromedia Director and thenemploying the UI and application generation tool havebeen converted to MIDP applications that run on a mobile phone terminal.Since the type of terminals mobile phone, PDA,tablet PC that can be used for consuming mobile services have a wide range of screen sizes their user interface designs can be quite different. The limited screensize available for mobile phone means that the ESG isdesigned exclusively onto a separate page, as shownin figure 5a, whereas the more extensive screen sizeavailable on a tablet PC means that the ESG can bepresented simultaneously with the media services, asshown in figure 6a.These different designs were made available by theUser Interface Generation tool, which provides all thegraphics and an XML description of the UI requiredby the Application Xlet to dynamically construct thefrontend.For terminals that have limited resident storage capacity such as mobile phones, the ESG can be interpreted and presented onto the terminal by applicationscreated by the application generation tool that are embedded within the terminal e.g. ESG manager, serviceapplications. Alternatively for terminals that have alarge amount of resident storage capacity, the ESG canbe interpreted and presented onto the terminal by applications created by the application generation toolthat have been downloaded onto the terminal. Figure 5a shows a typical telecom operators ESG presented on a mobile phone whilst Figure 6a shows atypical broadcast operators ESG presented on a tabletPC at the same time as service content because thereis sufficient space on the screen.a Telecom serviceproviders ESGb TV AV Program ona mobile phonec AV Service on amobile phoned Image Service on amobile phoneFigure 5 Telco Scenario Service Screenshotsurnnbnde0009610862, ISSN 18602037Journal of Virtual Reality and Broadcasting, Volume 42007, no. 17JVRB EuroITV 2006 Special, no. 7All terminal types have the capability of playingaudiovisual content that has been downloaded ontothe terminals or streamed either across the DVBTHbroadcast IP network or through the cellular radio mobile phone unicast IP network. The telecommunication service scenario is motivated to streaming audiovisual services on the IP over DVBH network,since there is not sufficient storage space on mobilephones or efficient IP multicasting capabilities overcellular radio networks or sufficient space for a largeenough battery within the mobile phone to supportcontinuous DVBT transmissions. A TV programmulticast on IP over DVBH is shown in Figure 5b anda streamed AV service on IP over DVBH is shown inFigure 5c.The broadcaster service scenario is motivated tocontinue to stream TV programs on the stream sectionsover DVBT whilst offering additional audiovisual ortext based services complementing the traditionalstreamed DVBTH broadcast services. These additional services combine downloading or streaming onthe IP over DVBTH with using the unicast cellularradio network as an interactive return and deliverychannel. A TV programme broadcast on the DVBT stream section is shown in Figure 6b while an additional audiovisual service streamed on IP over theunicast cellular network is shown in Figure 6c. TVprogrammes cannot be observed at the same time asadditional services because user validation has shownthat viewers find this disturbing. The application generation tool specifies the classes that play this AV content whereas the URI is specified on the ESG.All terminal types have the capability of pullingadditional Internet, image or graphical content overthe cellular radio mobile phone unicast IP network.The telecommunication service scenario is motivatedto pulling content snippets since it does not have theprocessing power and storage capability to support afull Internet browser. An image service pulled over theIP unicast cellular network is shown in Figure 5d. Thebroadcast service scenario pushes basic content via theDVB network and uses the IP cellular network to pullspecial types of content according to users individualwishesinterests. Figure 6f and Figure 6d shows Textand Internet page services pushed over the IP unicastcellular networks on which there is hypertext URLs toaccess further media over the unicast network. Againthe application generation tool specifies the class thataccess the web browser.8 ConclusionIt is clear that with the introduction of a wide range ofbroadband networks within the mobile domain therewill be a large demand for high quality interactiveservices to wide range of different terminal architectures. The construction and maintenance of such services require significant service provider resources ifthe services are developed using traditional methods.This paper has proposed a new service developmentmethodology that encompasses a number of tools thataim to reduce this cost by rapid prototyping and semiautomatically generating the applications from a service scenario. In particular, the semiautomatic application generation tool provides a means to cope thelogistics of managing the huge variety of screen sizes,applications, middleware APIs, operating systems andnetwork interfaces that are within todays mobile terminals. Furthermore, it has illustrated how these toolsare placed within the context of a service provisioning architecture to develop a vast range of differentservices. Therefore, we believe that these tools represent a significant cost saving in the development ofapplicationsservices for consumer converged broadcast and Telco mobile terminals. A second phase isbeing planned to further enhance the tool by making itDVBCMBS ESG compliant as well as increasing theterminalplatform range by implementing an SVG andPCF output that will complement the functionality ofthe existing tool.9 AcknowledgementsThe authors gratefully acknowledge the support forthis work that is funded by the EU under the IST program as the project INSTINCT IPbased Networks,Services and Terminals for Converging systems, IST2003507014. The author Emmanuel Tsekleves gratefully acknowledges the financial support offered by thePublic Benefit Foundation Alexander. S.Onassis forhis PhD programme.ReferencesACC07 Fabio Allamandri, Sebastien Campion,Angelo Centonza, Alex Chernilov, John P.Cosmas, Annette Duffy, David Garrec,Michel Guiraudou, Kannan Krishnapillai, Thierry Levesque, Bertrand Mazieres,Ronald Mies, Thomas Owens, Michele Re,urnnbnde0009610862, ISSN 18602037Journal of Virtual Reality and Broadcasting, Volume 42007, no. 17JVRB EuroITV 2006 Special, no. 7Emmanuel Tsekleves, and Lizhi Zheng,Service Platform for Converged InteractiveBroadband Broadcast and Cellular Wireless, IEEE Transactions on Broadcasting 532007, 200211, ISSN 00189316.An02 Mir Farooq Ali and Manuel A. PerezQuinones, Using task models to generate multiplatform user interfaces while ensuring usability, Proceedings of ACM CHI 2002Conference on Human Factors in Computing Systems, 2002, ISBN 1581134541,pp. 670671.APB99 Marc Abrams, Constantinos Phanouriou,Alan L. Batongbacal, Stephen M. Williams,and Jonathan E. Shuster, UIML AnApplianceIndependent XML User Interface Language, Proceedings of the EighthInternational WorldWide Web Conference,1999, www8.orgw8papers5bhypertextmediauimluiml.html, last visited July20th, 2007.BCH06 R. Bradbury, R. Cartwright, J. Hunter,S. Perrott, and J. E. Rosser, Portablecontent format a standard for describingan interactive digital television service,RD White Paper WHP 134, BritishBroadcasting Corporation, may 2006,www.bbc.co.ukrdpubswhpwhppdffilesWHP134.pdf, last visited July 20th,2007.Car00 John Millar Carroll, Making use  scenariobased design of humancomputer interactions, MIT Press, Cambridge, Mass., 2000,ISBN 0262032791.Cor05 OpenTV Corp., Open tv, www.opentv.com,2005, last visited July 20th, 2007.CR92 John M. Carroll and Mary Beth Rosson,Getting Around the TaskArtifact CycleHow to Make Claims and Design by Scenario, ACM Transactions on InformationSystems 10 1992, no. 2, 181212, ISSN10468188.Gro03 Digital TV Group, Digital Terrestrial Television MHEG5 specification, version 1.0.6,www.dtg.org.uk, 2003, last visited July20th, 2007.Har04 Harmonia, LiquidUI tool,www.harmonia.com, 2004, last visitedNovember 7th, 2005.HAV04 HAVi, Home Audio Video interoperability,www.havi.org, 2004, last visited July 20th,2007.IBC07 IBC, Ibc 2007 conference and exbihition,www.ibc.org, 2007, last visited July 20th,2007.Ind06 IndiaTimes, Nokia plans 40 new models thisyear, httpinfotech.indiatimes.com, 2006,last visited July 20th, 2007.ISO95 ISOIEC, Information Technology  GenericCoding of Moving Pictures and AssociatedAudio Part 2  Video, ISOIEC 138182 1995 E Recommendation ITUT H.2621995 E, 1995.Kra96 C. J. Kraal, Developing for interactive services in digital TV, International Broadcasting Convention, Conference Publication No. 428, 1996, ISBN 0852966636,pp. 230235.Mic06 Sun Microsystems, MIDP Mobile information device profile, java.sun.com, 2006, lastvisited July 20th, 2007.MSC05 Steven Morris and Anthony SmithChaigneau, Interactive TV standards a guide to MHP, OCAP, and JavaTV,Elsevier, Amsterdam, 2005, ISBN 0240806662.Pro03 MHP Project, MHP the multimedia homeplatform, httpwww.mhp.org, 2003, lastvisited July 20th, 2007.Pro05 DVB Project, A090  DVB portable contentformat PCF commercial requirements,www.dvb.org, 2005, last visited July 20th,2007.PRS02 Jennifer Preece, Yvonne Rogers, and Helen Sharp, Interaction Design BeyondHuman Computer Intraction, ch. Chapter8 Design, Prototyping and Construction,pp. 239278, Wiley, New York, NY, 2002,ISBN 0471492787.urnnbnde0009610862, ISSN 18602037Journal of Virtual Reality and Broadcasting, Volume 42007, no. 17JVRB EuroITV 2006 Special, no. 7RW07 Antti Rantalahti and Ivan Wong, Jsr 272Mobile broadcast service api for handheldterminals, Tech. report, Java CommunityProcess, 2007, jcp.orgenjsrdetailid272,last visited July 20th, 2007.SDP04 JeanLuc Sicre, Annette Duffy,Raquel Navarro Prieto, Marcello Otte,John Cosmas, Emmanuel Tsekleves,Michele Re, Veronique Leturcq, andRonald Mies, Three user scenarios on thejoint usage of mobile telco and TV servicesfor customers on the move, 12th WirelessWorld Research Forum Conference WWRFToronto, Canada, 2004.SE03 Jon Sigurdson and Peter Ericsson, Newservices in 3G new business models forstreaming and video, International Journalof Mobile Communications 1 2003, no. 12, 1534, ISSN 17415217.Sys06 Adobe Systems, Macromedia director mx,www.macromedia.comsoftwaredirector,2006, last visited July 20th, 2007.W3C03 W3C, Scalable vector graphics,www.w3c.org, 2003, last visited July20th, 2007.W3C04 W3C, The extensible stylesheet languagefamily xsl, www.w3.orgStyleXSL,2004, last visited July 20th, 2007.CitationEmmanuel Tsekleves and John Cosmas, SemiAutomated Creation of Converged iTV ServicesFrom Macromedia Director Simulations to,Services Ready for Broadcast, Journal of VirtualReality and Broadcasting, 42007, no. 17,September 2006, urnnbnde0009610862,ISSN 18602037.a Broadcaster service providers ESGb TV AV Program on a tablet PCc AV Service on a tablet PCd Video  text content on a tablet PCFigure 6 Appendixurnnbnde0009610862, ISSN 18602037
