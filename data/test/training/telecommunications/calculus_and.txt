Probability gradient estimation by setvaluedcalculus and applications in network designGeorg Ch. Pflug 1 and Heinz Weisshaupt 2Abstract. Let  7 P  be a setvalued mapping from Rd into the family of closedcompact polyhedra in Rs. Let  be a Rs valued random variable. Many stochastic optimization problems in computer networking, system reliability, transportation, telecommunication, finance etc. can be formulated as a problem to minimize or maximize theprobability P  P  under some constraints on the decision variable . For a practical solution of such a problem, one has to approximate the objective function and itsderivative by Monte Carlo simulation, since a closed analytical expression is only availablein rare cases. In this paper, we present a new method of approximating the gradient ofP  P  w.r.t  by sampling, which is based on the concept of setwise derivative.Quite surprisingly, it turns out that it is typically easier to approximate the derivativethan the objective itself.1 IntroductionIn many applications in computer networking, systems reliability, transportation, telecommunication, insurance and financial optimization, the objective is to minimize the probability of a failure or network breakdown, ruin, financial distress under some appropriateconstraints. These problems are stochastic optimization problems with a specific type ofobjective the probability of an event depending on the decision parameter. They areclosely related to chance constrained stochastic optimization problems, in which probabilities of unwanted events appear as constraints see for instance 7, 4.In this article, we concentrate on the essential part of a stochastic optimization problemwith probability objective To find the gradients of the objective w.r.t. the decisionparameter. Once an accurate estimate of the gradient is found, any numerical algorithmfor optimization, e.g. gradient projection may be applied.The setup of our problem is as follows Assume that  7 P  is a setvalued mappingfrom Rd into the family of closed compact polyhedra in Rs. Let  be a Rs valued randomvariable with distribution  and continuous density g. Let p  P   P  P .If P  is more complicated than a box or a disjoint union of boxes, then the only practical1Department of Statistics and Decision Support Systems, University of Vienna, Austria, A1010 Wien,Universitatsstrasse 52Department of Statistics, University of Dusseldorf1method to calculate p is by Monte Carlo simulation. Tricky ways to include P  in aunion of boxes andor to use importance sampling are well known. Even more complicatedis to calculate the gradient p of p w.r.t .Gradient estimation procedures based on sampling are known under the names of perturbation analysis 2, the score function method 10 and the method of weak derivatives6. Perturbation analysis does not work here. The pushout score function method depends on finding an appropriate reparameterization, which transforms the parameters ofthe polyhedron into parameters of the probability distribution, which works only in specific cases. We will present here a weak derivative method. Notice that differentiationformulas as integrals over the surface measure appear already in Raik 9, compare alsothe work of Uryasev 12.This paper is organized as follows Section 2 is devoted to a motivating example,in section 3 we present the algorithms. A numerical example is contained in section 4.Sections 5 an 6 are devoted to the elaboration of the setvalued weak derivative method infull mathematical strength. In section 7, we generalize the motivating problem and showhow also the generalization may be treated. Some auxiliary results are collected in theAppendix.Throughout the paper, we use the following notation If C is a convex body in Rs,then C denotes its surface the topological boundary and oC the surface area measuresee Proposition 2 in the Appendix.2 A motivating exampleWe consider the well known problem of designing a communication network with randomdemand in an optimal way see e.g. 8, 5. Assume that the topology of the network isgiven, the decision is to be made about the optimal capacities of the links of the networkunder a budget constraint. The objective is to maximize the reliability, i.e. minimize thebreakdown probability. A breakdown occurs, if the demand cannot be satisfied with theavailable capacities. The example was motivated by a project with the Austrian Telekomcompany.The nodes of the network are denoted by N  1, . . . N. The potential links are pairsof nodes k, , 1  k  N, 1    N. Every link has a nonnegative capacity k,. Azero capacity k,  0 means that the link k,  does not exist.The demand is given by a collection of random variables m,n indicating the trafficoriginating in node m and ending in node n, for every origindestination OD relationm  n. This demand is mapped onto the links through a routing system R.We assume first that the routing is fixed. This assumption is relaxed in section 7.The proportion of traffic from m to n flowing through link k,  is denoted by rm,n,k,. Arouting must satisfyrm,n,m,  1 for all m,nrm,n,,k rm,n,k, for k 6 m,n2rm,n,,n  1 for all m,nThe total flow on link k,  ism,n m,nrm,n,k,. The capacity constraint reads thatm,nm,nrm,n,k,  k,. 1The network is reliable, if all capacity constraints are fulfilled.In a compact matrix notation after a new indexing of links and OD relationships bysingle indices the constraint 1 readsR  .Denote by P  the reliable polyhedronP   y  0  R y  .The optimal network design problem isMaximize P  P  2hT   BHere h is a cost vector and B is the available budget The constraints may be morecomplicated and nonlinear as well. The main challenge in solving 2 algorithmically is tocalculate p  P  P  and, even more importantly the gradient P  P  p1, . . . , pd.In the next section, we present algorithms to estimate this gradient.3 The main theorem and the algorithmsLet   Rd and let aiiI be rowvectors in Rs, depending on . Let biiI be realnumbers the right hand sides. Let P  be the polyhedronP   y  Rs  yTai  bi i  I. 3We suppose that ai and bi are differentiable functions in  and that the convexpolyhedron P  is compact and has nonempty interior for   , an open subset of Rd.Let  be a probability measure on Rs with continuous density g with respect toLebesgue measure  such thatP  P   P  P gu du.Denote by DP  the directional derivative from the right of P  w.r.t. thedirection  , i.e.DP   limh01hP   h P .3Introduce in a similar manner the directional derivatives Dai and Dbi.It may happen that for the fixed  under consideration, two hyperplanes x  ai1x bi1 and x  ai2x  bi2 coincide but are not identical for all . For this reason,we introduce the equivalence classesi  j  I  aj  jai, bj  jbi for some j  0, J  i  i  I,Hi  x  aix  bi and Hi  HiOur main theorem represents the desired directional derivative D P  by an integral w.r.t. the surface area measure oP  on P .Main Theorem.Under the given assumptions,DP  4P gx  jJ1P Hj minij 1ai Dbi xT Dai doP x.The proof of this theorem will be given in section 5.Based on this theorem, the following algorithm implements a sampling method forgetting an unbiased derivative estimate.Algorithm 1 Construct a random variable  with probability distributionproportional to g. oP . Sample x from  Calculate fi  1aiDbi xT Daifor all i with x  Hi andfind f  min fi. The derivative estimate is f  P  gu doP uBy virtue of our main Theorem, this algorithm produces an unbiased estimate ofthe derivative. The algorithm needs the construction of the random variable . Theconstruction of  is not easy in general. The problem is that we have to sample from adistribution on the boundary of P . We replace now this sampling on the boundary bysampling and if necessary discarding points on the hyperplanes Hi. Algorithm 2 worksonly if the integralsHjgx doHjx are finite.4Algorithm 2 Construct for all j  J random variables j withprobability distributions proportional to goHj. Sample xj from j. if xj  P then Calculate fi 1aiDbi xTjDaifor all i  I and findfor all j  J the value fj  minij fi. else set fj  0 The derivative estimate isjJfj Hjgu doHjuThis algorithm needs the construction of random variables j, i.e. sampling from aconditional distribution on hyperplanes, rather than from the distribution  itself. We willillustrate the method for the important case of  being a multivariate normal distribution,because then also the conditional distributions are multivariate normal and easy to sample.Assuming that  is multivariate normal,   Nm, , recall that it may be transformed by a linear mapping to a standard normal distribution. For a positive definite ,let be any matrix satisfyingT  .The algorithm specialized for multivariate normal reads5Algorithm 3 Transform the problem so that the original distribution Nm, becomes the standard normal distribution N0, I on Rs Let Anew  A   and let bnew  b A m. Change the notation to A  Anew and b  bnew. Let zj  Hj be the point in Hj with minimal norm, i.e.zj biaiaTi ai, i  j. Sample x from a standard normal distribution on Rs. Calculate for all j  J the orthogonal projectionxj  x aTi xbiaTi aiai, i  j, of x onto Hj. if xj  P  then Calculate fi 1aiDbi xTjDaifor all i  I and findfor all j  J the value fj  minij fi. else set fj  0 The derivative estimate isjJfj Hju doHju jJfj  12ezj22 .Here  is the density of the standard normal distribution in Rs.4 A numerical exampleWe return to the network reliability problem discussed in section 2. Consider the networkshown in Figure 1.The set of nodes isN  1, 2, 3, 4, 5, 6.The set of links isL  l1  1, 2 l2  1, 6 l3  2, 3 l4  2, 4 l5  2, 6 l6  3, 4l7  3, 5 l8  4, 5 l9  5, 6The set of origindestinations relations isOD  1, 2 1, 3 1, 4 1, 5 1, 6 2, 3 2, 4 2, 5 2, 6 3, 4 3, 53, 6 4, 5 4, 6 5, 66123456Figure 1 A network exampleFor simplicity, the traffic is considered undirected in this example. With the very samemethod, one could also treat the links as directed and thus double their number as wellas the number of ODrelations.The routing matrix is the fixed 9  15 matrix R given below. The ordering of therows is according to the ordering of links in L and the ordering of the columns is accordingto the ordering of the ODrelations above.R 1.0 1.0 1.0 0 0 0 0 0 0 0 0 0 0 0 00 0 0 1.0 1.0 0 0 0 0 0 0 0 0 0 00 1.0 0 0 0 1.0 0 0 0 0 0 0.5 0 0 00 0 1.0 0 0 0 1.0 0.5 0 0 0 0 0 0 00 0 0 0 0 0 0 0.5 1.0 0 0 0.5 0 0 00 0 0 0 0 0 0 0 0 1.0 0 0 0 0 00 0 0 0 0 0 0 0 0 0 1.0 0.5 0 0 00 0 0 0 0 0 0 0.5 0 0 0 0 1.0 1.0 00 0 0 1.0 0 0 0 0.5 0 0 0 0.5 0 1.0 1.0We assume that the demand vector  follows a 15dimensional normal distribution withmean valueE  100 200 1500 300 80 200 1500 300 80 3000 600 160 4500 1200 240and covariance matrix  1 2where71 2.5 1.5 11.25 2.25 0.6 1.5 11.251.5 10.0 22.5 4.5 1.2 3.0 7.511.25 22.5 562.5 33.75 9.0 7.5 168.752.25 4.5 33.75 22.5 1.8 1.5 11.250.6 1.2 9.0 1.8 1.6 0.4 3.01.5 3.0 7.5 1.5 0.4 10.0 22.511.25 7.5 168.75 11.25 3.0 22.5 562.52.25 1.5 11.25 6.75 0.6 4.5 33.750.6 0.4 3.0 0.6 0.48 1.2 9.07.5 45.0 337.5 22.5 6.0 45.0 337.51.5 9.0 22.5 13.5 1.2 9.0 22.50.4 2.4 6.0 1.2 0.96 2.4 6.011.25 22.5 506.25 101.25 9.0 22.5 506.253.0 6.0 135.0 9.0 7.2 6.0 135.00.6 1.2 9.0 5.4 1.44 1.2 9.02 2.25 0.6 7.5 1.5 0.4 11.25 3.0 0.61.5 0.4 45.0 9.0 2.4 22.5 6.0 1.211.25 3.0 337.5 22.5 6.0 506.25 135.0 9.06.75 0.6 22.5 13.5 1.2 101.25 9.0 5.40.6 0.48 6.0 1.2 0.96 9.0 7.2 1.444.5 1.2 45.0 9.0 2.4 22.5 6.0 1.233.75 9.0 337.5 22.5 6.0 506.25 135.0 9.022.5 1.8 22.5 13.5 1.2 101.25 9.0 5.41.8 1.6 6.0 1.2 0.96 9.0 7.2 1.4422.5 6.0 2250.0 135.0 36.0 1012.5 270.0 18.013.5 1.2 135.0 90.0 7.2 202.5 18.0 10.81.2 0.96 36.0 7.2 6.4 18.0 14.4 2.88101.25 9.0 1012.5 202.5 18.0 5062.5 405.0 81.09.0 7.2 270.0 18.0 14.4 405.0 360.0 21.65.4 1.44 18.0 10.8 2.88 81.0 21.6 14.4In this special case, the matrix A equals the routing matrix R not depending on. The right hand side is equal to , i.e., bi  . Further the directions of thevectors ai are all different and so all hyperplanes of the form x  aTi x   are different.Thus the equivalence classes i contain just the element i and the conditions concerningthe formation of minimum in the different algorithms become vacuous. The derivativeestimate in the direction ei of the ith coordinateaxis thus becomes in the special case ofour example1Ri, 12ezi222 if x  Hi  P0 otherwiseHere Ri, is the ith row of the transformed routing matrix R.8gradient estimate5000 iterations 50000 iterations1 0.0281  103 0.0282  1032 0.0538  103 0.0538  1033 0.1394  103 0.1388  1034 0.0013  103 0.0013  1035 0.0000  103 0.0000  1036 0.0556  103 0.0557  1037 0.0784  103 0.0786  1038 0.0040  103 0.0040  1039 0.0009  103 0.0009  103Table 1 The values of the estimated gradient vectorAlgorithm 3 was applied to this example to estimate P  P  at the point  1890 400 500 3310 330 3150 715 6150 2070. The column vectors of estimates ofthe partial derivatives for a sample size of 5000 and 50000 are shown in Table 1.We compare this result with the result obtained by estimating the gradient by analgorithm Algorithm 4 below, which calculates an estimate of the directional derivativeby calculating PP eiP .This algorithm is based on Monte Carlo simulation. Instead of sampling from thedistribution of  it uses importance sampling from different distributions for each unitdirection ei. This distributions are chosen to improve the performance of this simplealgorithm and to allow a fair comparison of our Algorithm 3 based on weak derivativeswith this simple method.9standard deviationAlgorithm 3 Algorithm 41 0.0627  104 0.3158  1032 0.0940  104 0.2319  1033 0.3196  104 0.6393  1034 0.0106  104 0.0236  1035 0.0000  104 0.0000  1036 0.0732  104 0.8478  1037 0.1520  104 0.5134  1038 0.0086  104 0.0850  1039 0.0038  104 0.0104  103Table 2 A comparison of the componentwise standard deviationsAlgorithm 4 Transform the problem so that the original distribution Nm, becomes the standard normal distribution N0, I on Rs Let Anew  A   and let bnew  b A m. Change the notation to A  Anew and b  bnew. Let zj  Hj be the point in Hj with minimal norm, i.e. zj biaiaTi ai, i  j. Sample xi from a normal distribution on Rs with meanvector zi andcovariance matrix the identity. if xi  P     P  then let fi  1 else set fi  0. The estimate of the ith directional derivative isfi exTixixiziT xizi2The vectors of estimated standard deviations of Algorithm 3 and Algorithm 4 for  0.5 are displayed in Table 2.Considering these standard deviations we see that about only 0.25 percent of the samplesize is needed in our algorithm to obtain an equally stable estimate compared to the directAlgorithm 4. Moreover, the estimate obtained by the direct algorithm is biased, while the10gradient estimateAlgorithm 3 with5  104 iterationsAlgorithm 4 with5  105 iterationsand   0.51 0.0281  103 0.0270  1032 0.0538  103 0.0447  1033 0.1394  103 0.1191  1034 0.0013  103 0.0014  1035 0.0000  103 0.0000  1036 0.0556  103 0.0537  1037 0.0784  103 0.0712  1038 0.0040  103 0.0040  1039 0.0009  103 0.0009  103Table 3 A comparison of the estimated gradient vectorsestimate based on the new algorithm is unbiased.5 Weak derivatives of setvalued mappingsIn this section, we discuss the notion of derivatives of setvalued mappings and give someproperties. The concept will be introduced for general convex bodies and not only forconvex polyhedra.Let   Rd be open and let  7 C be a setvalued mapping defined on  such thatthe values C are convex bodies convex compact sets with nonempty interior in Rs.We call such mappings for short convexvalued mappings. Let  be a probability measureon Rs which possesses a continuous density g with respect to Lebesgue measure .We denote by C the boundary of the convex set C and by oC the surface areameasure on C see Appendix.Given a measure  we denote by  A its restriction to S, i.e.  A B  A B.We define now the important concept of the weak derivative of a set valued mapping 7 C in direction   Rd with respect to a measure  on Rs.Definition 1. See also 6 and 13 We say that a convexvalued mapping  7 Cis weakly differentiable from the right at  in direction  with respect to a measure  ifthere exists a possibly signed measure D C such that for all continuous functionswith compact support   Rs 7 R we have dD C  limh01h1C h  1Cd.The signed measure D C is called the weak derivative.11From the definition of the weak derivative we get in the special case that   1 on aneighborhood of C thatD C CdD C. 5Suppose that D C  oC. This implies for continuous g  dd that D C oC and thatD CdoCx  gx  dD CdoCx a.s. doC. 6Sufficient condition SC. If the derivative D C exists, then a sufficient conditionfor D C  oC is as can be easily derived from Definition 2 and Proposition 2 ofthe Appendix, that  7 C fulfills a Lipschitz condition with respect to the Hausdorffdistance Haus i.e.HausC, C  s  c  sfor some constant c and sufficiently small s.In the following, we will always assume that the sufficient condition SC is fulfilled. Wewill treat the case of Lebesgue measure  in Rs, since all other cases can be brought tothis case by simple density correction. For short, we call a function  7 C which fulfills Definition 1 for the Lebesgue measure a WDDCV weakly directionally differentiableconvex valued function.There is a calculus for WDDCV functions. The following Lemma shows two properties.Lemma 1.i Let  7 C1 be WDDCV function and let C2 be a compact convex set such thatoC1C2  0. Then  7 C1  C2 is a WDDCV function with derivativeD C1 C2 .ii Let  7 Cj for j  J , a finite index set, be WDDCV functions. Suppose that forall j1 6 j2 j1, j2  Jlimh01h Cj1  h  Cj1  Cj2  h  Cj2  0 7where  denotes the symmetric difference. Then  7 jJ Cj is a WDDCVfunction with derivativejJ D Cj iJ Ci.Proof. i. For all continuous functions  with compact support dD C1  limh01h1C1 h  1C1d.This implies that the same property holds for all functions , for which the set of discontinuities has zero measure w.r.t the limiting measure D C see Billingsley 1. Sincelimh01h1C1 hC2  1C1C2d  limh01h1C21C1 h  1C1d,12setting    1C2 and noticing that the assumption implies that the set of discontinuitiesof  have limiting measure zero, because they are contained in C2, this implies theassertion.ii. We prove first the result for J  1, 2. Using i, the assertion ii is shown if weestablish that for all continuous  with compact support, bounded by 1,limh01hxIx dx  0 8whereIx  1C1hC2hx 1C1C2x 1C1hC2x 1C1C2x1C1C2hx 1C1C2xi.e. the difference is equivalent to the sum of the cases when C1 is treated as constant andC2 is treated as constant  a form of a product rule of differentiation. The integral in 8is bounded by1h C1  h  C1  C1  h  C1 ,which by assumption 7 converges to zero.For the general case one proceeds by induction. Suppose that the proof is establishedfor J  1, 2, . . . , k  1. The condition needed to extend it for another index k is thatlimh01hjJCj  h  jJCj  Ck  h  Ck  0.This condition follows from the fact thatjJCj  h  jJCj  Ck  h  Ck jJCj  h  Cj  Ck  h  Ckand the application of condition 7 for each of the setsCj  h  Cj  Ck  h  Ck.26 The proof of the main theoremLet C be a convex body as in section 4. Later, we will specialize C  P , whereP is the polyhedron defined in 3. From 5 and 6 we obtain13DC CgxdD CdoCx doCx 9Formula 9 entails the main formula 4, if we show that for the convex polyhedron PdD P doCx jJ1P Hj minij 1ai Dbi xT Dai.We will first prove the Main Theorem in the special case that P  is a half space,i.e. that for all indices i  I, the halfspaces coincide for some fixed , but are possiblydifferent for all other values of . Having done this case, an application of Lemma 1 willprovide the final proof.In the following, we will alternatively use the notations xT y or x, y for the innerproduct in Rs, whatever notation seems more appropriate.Lemma 2. Let I be a finite index set and let for i  Iai  Rs and bi  Rwith  7 ai,  7 bi differentiable. LetP  iIy  ai, y  biand suppose that for some fixed    the halfspaces y  ai, y  bi are allidentical. Then P  is itself a halfspace H, the function  7 P   RB is weaklydirectional differentiable from the right at  and its directional derivative in direction  isgiven by f  o with o the surface area measure on H RB and f  H 7 R given byf y  miniI1aiDbi yT Dai.Proof. Let u  aiai denote the outward unit normal vector on H, which  byassumption  is independent of i.Introduce the half spaces Hih asHih  x  x, ai  h    bi  h  .By assumption, H  Hi0 is independent of i and can be written asHi0  x  x, a  b  y  u    0 y, a  bwhere a  ai, b  b1. Alternatively, we may writeHih  y  u    i,hy y, a  bwhere i,hy for y  H is chosen such thaty  i,hyu, ai  h  bi  h.14Now iIHih  y  u    minii,hy y, a  b.It is easy to show that in the definition of the weak derivative, the set of continuousfunctions with compact support may be replaced by any other dense set, for instance theset of Lipschitz continuous functions with compact support.Let  be a Lipschitz continuous function with compact support. We have to show thatlimh01hx1iI Hihx 1H0x dx yf y doHy 10where H is the hyperplane H  H. A change of integration variables gives1hx1iI Hihx 1H0x dx1hHRy  u1iI Hihy  u 1H0y  u d doHy1hHRy  O10mini i,hy  1mini i,hy0 d doHyHRy1hminii,hy doHy  O 1hminii,hy2 doHyHRy1hminii,hy doHy  o1as h  0. Here we have used the Landau symbols O and o. An easy calculation showsthatlimh0i,hyh1aiDbi yT Daiand thereforelimh0minii,hyh mini1aiDbi yT Dai f y.Finally, by dominated convergence theoremlimh01hx1iI Hih  1H0 dx yf y doHy.2We remark here that a similar result holds if bi  R.The proof of the Main TheoremConsider a ball RB sufficiently big such that P   intRB. Propositions 4 and 5of the Appendix ensure that  7 P  is Lipschitz in the Hausdorff sense and that thesufficient condition is fulfilled. Moreover, for halfspaces the condition 7 is fulfilled. Thuswe get by Lemma 2 withCj  RB ijx  ai, x  bi15and Lemma 1 ii applied to the index set J  j thatdD P doCx jJ1P Hj minij 1ai Dbi xDai.Inserting this in equation 9 we obtain equation 4, i.e., the Main Theorem has beenproved.7 Adaptive routingIn this section we show that adaptive routing is included in the type of problems studiedalready. In the adaptive routing situation, the flows are calculated through an assignmentproblem of its own.Let zm,n,k, be the traffic form origin m to destination n, which flows over the link k, .These flows must satisfyzm,n,m,  m,n for all m,nzm,n,,k zm,n,k, for k 6 m,nzm,n,,n  n,m for all n,m 11The capacity constraints arem,nzm,n,k,  k, 12We say that  is admissible if there is a z  0 such that all equations 11 and theinequality 12 is fulfilled.By introducing appropriate indices for links and ODrelations, introducing the appropriate matrices A and M , one gets a system of the following form is admissible, if z  0 such thatAz  , Bz  0,Mz  .The admissible polyhedron isP     z  0  Az  , Bz  0,Mz  .This representation is not in the desired explicit form 3. Lets rewrite it asP     z  0  Az  , Bz  0,Mz     z, y  0  Az  , Bz  0,Mz  y     x  0  Wx 016Here we have set x zyand W A 0B 0M I.The set d  x  0  Wx  d is identical with the set d  dT ei  0, where ei arethe extremal rays of the polyhedral cone u  W T u  0. Let ui, vi, wi, i  I be theextremal rays of the polyhedral cone u, v, w  AT u  BT v  MT w  0, w  0.We see that the polyhedron P  has the representationP     T ui  T wi, i  1, . . . I,which is of the required form 3.How can one calculate the extremal rays of a polyhedral cone Let W be a n  mmatrix of rank d. This matrix describes a linear mapping from Rm onto a ddimensionalsubspace of Rn. Let k be the dimension of the kernel of W . We have that d  m  k.The cone u  Wu  0 is the set of all us whose image lies in the positive quadrant.We may find a basis b1, . . . , bm of Rm such that b1, . . . , bk is a basis of the kernel andbk1, . . . , bm is orthogonal to it. It is sufficient to intersect the linear combinations ofthe images of bk1, . . . , bm with the facets of the positive orthant. The dimension ofthe image is m  k, thus more n  m  k linear conditions are needed. We solve thehomogeneous equationmik1 ibi  r, where r is zero for n  m  k indices and freeelsewhere. If the solution is nonnegative, an extremal ray has been found. We have to testat mostnnmkequations. Notice that the extremal rays are independent of  and canbe stored and kept once they were found.AppendixWe denote by S the unit sphere and by B the unit ball in Rs.Proposition 1. Let C be a convex body and let for h  0Ch  C  C  hB and Ch  C  hB  intC.Then there exists a measure oC the surface area measure such that in weak senselimh01h Ch limh01h Ch oC .Definition 2. The Hausdorff distance Haus of two convex bodies C,D is defined byHausC,D  inf  0  D  C  B and C  D  B.Proposition 2.i If HausC, D  , then C D  D  B and D  C  C  B.ii HausC, D  HausC, D.17iii If HausC,D  , then CD  C2B. Here  denotes the symmetric difference.Proof. i follows directly from the definition. ii Let   HausC,D and letx  C. We have to find a y  D such that x  y  . If x  D, then there is ay  D such that x  y   by assumption. If x  D, then find a point y  D, suchthat the convex projection of y onto C is x. For this point,   infy  v  v  C y  x and the assertion is shown.iii follows from i and ii D  C  C  B andC D  D  B  C  B B  C  2B. 2Definition 3. For a convex body C with the property that 0  intC, define forx  S the radial functionCx  sup  x  C.The radial distance between two convex bodies C, D with 0  intC, 0  intD isradC, D  supxSCx Dx.Proposition 3. If C,D are two convex bodies with rB  C, D  RB, then rRradC,D HausC,D  radC, D. Thus rad and Haus are equivalent on the space of convex bodies C with rB  C  RB.Proof. The inequality HausC, D  radC, D is obvious. Thus we show thatrRradC, D  HausC,D. Let p  C and q  D be points such that p  q radC, D, such that p and q lie on a ray originating at 0 and suppose without loss ofgenerality that p  D and q 6 C. Let v  C be sucht that v  q  minwC w  q.Then HausC,D  v  q. Let now t  rS the point on the ray from 0 in directionq v. We have t  r. Notice that p, q, v, t lie in one hyperplane. Let u the point wherethe line between 0 and q intersects the line between t ans v. Notice that u q  p qby the convexity of C. SoHausC, Dr v  qt u qu p qRradC, DR2Notice that the radial functions satisfy Ci  mini Ci and therefore the next proposition is an easy consequence of Proposition 3.Proposition 4. Let Cii1,...,l and Dii1,...l be convex sets withrB  C, D  RB for all i  1, . . . , l. 13ThenHausli1Ci,li1Di  Rrmaxi1,...,lHausCi, Di.Notice that the condition 13 can be weakened to the requirement that it is fulfilledfor a certain translation of the sets Ci, Di.18Proposition 5. Let   Rd and let a    Rs and b    R be differentiablefunctions with a 6 0 for all   . Let H  x  Rs  aT x  b and supposethat H  RB 6 0 for all   . Then, for all R  0, there exists a c  0 such that forsufficiently small h  0HausH RB, H  h   RB  c  hi.e. the sufficient condition SC is fulfilled.References1 Billingsley P. 1968. Convergence of probability measures. J. Wiley and Sons, NewYork.2 Glasserman P. 1991. Gradient Estimation via Perturbation Analysis. Kluwer Academic Publishers, Norwell, USA.3 Lieber, D. Nemirovksi, A. Rubinstein, R.Y. 1996 A fast Monte Carlo Method forEvaluation of Reliability Indices, IEEE Transactions of on Reliability Systems, Vol.48, No 3, 256261, 1999.4 Kibzun A. I., Kan Yu. S. 2000. Stochastic Programming problems with Probabilityand Quantile Functions. J. Wiley and Sons, New York5 Krivulin N. 1993. An analysis of gradient estimates in stochastic network optimization problems. In Modeloriented data analysis Petrodvorets, 1992, Physica, Heidelberg, pp. 227240, 1993.6 Pflug G. Ch. 1996. Optimization of Stochastic Models The Interface Between Simulation and Optimization, Kluwer Academic Publishers.7 Prekopa A. Stochastic Programming. Mathematics and its Applications Volume 324,Kluwer Academic Publishers, 1995.8 Prekopa, A. Network planning using twostage programming under uncertainty. Recentresults in stochastic programming Proc. Meeting, Oberwolfach, 1979, pp. 215237,Lecture Notes in Econom. and Math. Systems, 179, Springer, BerlinNew York, 1980.90C159 Raik, E. 1975. The differentiability in the parameter of the probability function andoptimization via the stochastic pseudogradient method. Izvestiya Akad. Nauk Est.SSR, Phis. Math. 24 1, 3  6 in Russian.10 Rubinstein, R.Y., Shapiro A. 1992. Discrete Event Systems Sensitivity Analysisand Stochastic Optimization by the Score Function Method. John Wiley  Sons, NewYork.1911 Rubinstein R.Y. 1992. Sensitivity Analysis of Discrete Event Systems by the PushOut Method. Ann. Oper. Res. 39, 229  250.12 Uryasev S. 1995. Derivatives of probability functions and integrals over sets givenby inequalities. J. Computational and Applied Mathematics Vol. 56.13 Weisshaupt H. A measurevalued approach to convex setvalued dynamics. SetValuedAnal. 9 2001, no. 4, 337373.20
