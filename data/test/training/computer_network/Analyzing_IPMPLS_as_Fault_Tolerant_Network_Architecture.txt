Institutionen för Systemteknik
Department of Electrical Engineering
Examensarbete

Analyzing IP/MPLS as Fault Tolerant Network Architecture

Examensarbete utfört i Informationskodning
vid Tekniska Högskolan i Linköping
av
Muhammad Roohan Kebria
LiTH-ISY-EX--12/4551--SE
Linköping 2012



TEKNISKA HÖGSKOLAN
LINKÖPINGS UNIVERSITET

Department of Electrical Engineering
Linköping University
SE-581 83 Linköping, Sweden
Institutionen för Systemteknik
Linköpings Tekniska Högskola
SE-581 83 Linköping, Sverige

Analyzing IP/MPLS as Fault Tolerant Network Architecture
2





Analyzing IP/MPLS as Fault Tolerant Network Architecture


Examensarbete utfört i Elektroniksystem
vid Tekniska högskolan i Linköping
av

Muhammad Roohan Kebria
LiTH-ISY-EX--12/4551--SE





Handledare:  Muhammad Ajmal
ISY, Linköpings Universitet

Examinator:  Robert Forchheimer
ISY, Linköpings Universitet

Linköping, March 2012
Analyzing IP/MPLS as Fault Tolerant Network Architecture
3
Presentation Date
March 26, 2012
_______________________
Publishing Date (Electronic version)

_______________________

Department and Division

Division of Information Coding
Department of Electrical Engineering
Linköping University
SE-581 83 Linköping, Sweden




URL, Electronic Version
http://www.ep.liu.se


Publication Title
Analyzing IP/MPLS as Fault Tolerant Network Architecture


Author
Muhammad Roohan Kebria [muhke224@student.liu.se]


Abstract
MPLS is a widely used technology in the service providers and enterprise networks across the globe. MPLS-enabled
infrastructure has the ability to transport any type of payload (ATM, Frame Relay and Ethernet) over it, subsequently
providing a multipurpose architecture. An incoming packet is classified only once as it enters into the MPLS domain and
gets assigned label information; thereafter all decision processes along a specified path is based upon the attached label
rather than destination IP addresses. As network applications are becoming mission critical, the requirements for fault
tolerant networks are increasing, as a basic requirement for carrying sensitive traffic. Fault tolerance mechanisms as
provided by an IP/MPLS network helps in providing end to end “Quality of Service” within a domain, by better handling
blackouts and brownouts. This thesis work reflects how MPLS increases the capability of deployed IP infrastructure to
transport traffic in-between end devices with unexpected failures in place. It also focuses on how MPLS converts a packet
switched network into a circuit switched network, while retaining the characteristics of packet switched technology. A new
mechanism for MPLS fault tolerance is proposed.


Keywords
Fault Tolerance, IP, MPLS, Network, Routing, Switching











Language

X English
Other (specify below)

__________________
Number of Pages

______108_________

Type of Publication

Licentiate thesis
X Degree thesis
Thesis C-level
Thesis D-level
Report
Other (specify below)

ISBN (Licentiate thesis)

ISRN:  LiTH-ISY-EX--12/4551--SE

Title of series (Licentiate thesis)


Series number/ISSN (Licentiate thesis)
Analyzing IP/MPLS as Fault Tolerant Network Architecture
4
Upphovsrätt
Detta dokument hålls tillgängligt på Internet - eller dess framtida ersättare - från
publiceringsdatum under förutsättning att inga extraordinära omständigheter uppstår.
Tillgång till dokumentet innebär tillstånd för var och en att läsa, ladda ner, skriva ut
enstaka kopior för enskilt bruk och att använda det oförändrat för ickekommersiell forskning
och för undervisning. Överföring av upphovsrätten vid en senare tidpunkt kan inte upphäva
detta tillstånd. All annan användning av dokumentet kräver upphovsmannens medgivande.
För att garantera äktheten, säkerheten och tillgängligheten finns lösningar av teknisk och
administrativ art.
Upphovsmannens ideella rätt innefattar rätt att bli nämnd som upphovsman i den
omfattning som god sed kräver vid användning av dokumentet på ovan beskrivna sätt samt
skydd mot att dokumentet ändras eller presenteras i sådan form eller i sådant sammanhang
som är kränkande för upphovsmannens litterära eller konstnärliga anseende eller egenart.
För ytterligare information om Linköping University Electronic Press se förlagets
hemsida http://www.ep.liu.se/


Copyright
The publishers will keep this document online on the Internet  –  or its possible replacement
from the date of publication barring exceptional circumstances.
The online availability of the document implies permanent permission for anyone to
read, to download, or to print out single copies for his/hers own use and to use it unchanged
for non-commercial research and educational purpose. Subsequent transfers of copyright
cannot revoke this permission. All other uses of the  document are conditional upon the
consent of the copyright owner. The publisher has taken technical and administrative
measures to assure authenticity, security and accessibility.
According to intellectual property law the author has the right to be mentioned when
his work is accessed as described above and to be protected against infringement.
For additional information about the Linköping University Electronic Press and its
procedures for publication and for assurance of document integrity, please refer to its www
home page: http://www.ep.liu.se/









© Muhammad Roohan Kebria



Analyzing IP/MPLS as Fault Tolerant Network Architecture
5









Abstract

MPLS is a widely used technology in the service providers and enterprise networks across the globe.
MPLS-enabled infrastructure has the ability to transport any type of payload (ATM, Frame Relay and
Ethernet) over it, subsequently providing a multipurpose architecture. An incoming packet is classified
only once as it enters into the MPLS domain and gets assigned label information; thereafter all decision
processes along a specified path is based upon the attached label rather than destination IP addresses.
As network applications are becoming mission critical, the requirements for fault tolerant networks are
increasing, as a basic requirement for carrying sensitive traffic. Fault tolerance mechanisms as provided
by an IP/MPLS network helps in providing end to end “Quality of Service” within a domain, by better
handling blackouts and brownouts. This thesis work reflects how MPLS increases the capability of
deployed IP infrastructure to transport traffic in-between end devices with unexpected failures in place.
It also focuses on how MPLS converts a packet switched network into a circuit switched network, while
retaining the characteristics of packet switched technology. A new mechanism for MPLS fault tolerance
is proposed.








Keywords: LDP, IP, IP-DiffServ, MPLS, MPLS-DiffServ, MPLS-DiffServ-TE, MPLS-FRR, QoS, RSVP.

Analyzing IP/MPLS as Fault Tolerant Network Architecture
6





Acknowledgement

All praise to ALLAH, the most Beneficent and most Merciful

My first and foremost compliments to Almighty ALLAH, Who gave me strength to accomplish my tasks
until now including this thesis work. Without His blessings it is impossible to achieve any success in life.

I would like to thank my parents and siblings, who always encouraged me during whole course of my
study duration. Without their pray everything is unattainable for me.

I am grateful to my thesis examiner Mr. Robert Forchheimer for providing me such a great opportunity
to work under his esteem supervision.

I appreciate Mr. Muhammad Ajmal, who has been the supervisor of this thesis. He supported and
guided me with his knowledge in a friendly manner.

Lastly, I would like to thank all my friends from Linköping University, whose love and support
provided me such a friendly and peaceful environment to work with. I also like to say best wishes for all
of you.




Muhammad Roohan Kebria
Analyzing IP/MPLS as Fault Tolerant Network Architecture
7
Abbreviations

CSPF – Constraint Shortest Path First
CR-LDP – Constraint based Label Routing Protocol
FEC – Forward Equivalence Class
FRR – Fast Re-Route
IP – Internet Protocol
ISIS – Intermediate System to Intermediate System
LDP – Label Distribution Protocol
LER – Label Edge Router
LFIB – Label Forwarding Information Base
LFA – Loop Free Alternative
LSA – Link State Advertisement
LSDB – Link State Database
LSP – Label Switch Path
LSR – Label Switch Router
MPLS – Multi Protocol Label Switching
OPNET – Optimized Network Engineering Tool
OSPF – Open Shortest Path First
PHB – Per Hob Behavior
PHP – Penultimate Hop Pop
PLR – Point of Local Repair
QoS – Quality of Service
RSVP – Resource Reservation Protocol
SPF – Shortest Path First
SPT – Shortest Path Tree
TCP – Transmission Control Protocol
TE – Traffic Engineering
TED – Traffic Engineering Database
TLV – Type Length Value
UDP – User Datagram Protocol

Analyzing IP/MPLS as Fault Tolerant Network Architecture
8
List of Figure
2.1 – MPLS Planes---------------------------------------------------------------------------------------------------------------18
2.2 – MPLS Label----------------------------------------------------------------------------------------------------------------18
2.3 – MPLS Label Swapping-------------------------------------------------------------------------------------------------19
2.4 – LFIB Table-----------------------------------------------------------------------------------------------------------------20
2.5 – MPLS PHP Operation--------------------------------------------------------------------------------------------------22
2.6 - LDP PDU-------------------------------------------------------------------------------------------------------------------23
2.7 – LDP Session Protection-------------------------------------------------------------------------------------------------25
2.8 – LDP message exchange across MPLS domain--------------------------------------------------------------------28
3.1 – Fish Problem--------------------------------------------------------------------------------------------------------------30
3.2 – CR-LDP Message Flow-------------------------------------------------------------------------------------------------35
3.3 – RSVP Message Exchange----------------------------------------------------------------------------------------------36
4.1 – MPLS Path Protection--------------------------------------------------------------------------------------------------43
4.2 – MPLS Local Protection-------------------------------------------------------------------------------------------------45
4.3 – MPLS Link Protection--------------------------------------------------------------------------------------------------46
4.4 - MPLS Node Protection--------------------------------------------------------------------------------------------------48
4.5 – MAM Model--------------------------------------------------------------------------------------------------------------50
4.6 – Russian Doll Model-----------------------------------------------------------------------------------------------------50
4.7 – LDP Fast Re route--------------------------------------------------------------------------------------------------------52
5.1 – OPNET FTP Traffic Specification------------------------------------------------------------------------------------58
5.2 – OPNET HTTP Traffic Specification---------------------------------------------------------------------------------58
5.3 – OPNET Email Traffic Specification----------------------------------------------------------------------------------59
5.4 – OPNET Voice Traffic Specification----------------------------------------------------------------------------------59
5.5 – OPNET Video Conferencing Traffic Specification---------------------------------------------------------------60
5.6 – OPNET IP network Base Scenario snapshoot---------------------------------------------------------------------61
6.1 – Failure Simulation OPNET Object Configuration----------------------------------------------------------------71
6.2 – Link Background Utilization OPNET Configuration------------------------------------------------------------75
6.3 – MPLS Traffic Engineered LSP Configuration in OPNET ------------------------------------------------------88
6.4 – MPLS Weighted Load Balancing for Traffic Engineered LSP-------------------------------------------------90
6.5 – MPLS Traffic Engineered LSP Configuration for Weighted Load Balancing------------------------------90
6.6 – MPLS Traffic Engineered LSP Configuration for Voice Traffic-----------------------------------------------92
Analyzing IP/MPLS as Fault Tolerant Network Architecture
9
Table of Contents
1 Introduction------------------------------------------------------------------------------------------------------------------10
1.1 Motivation--------------------------------------------------------------------------------------------------------11
1.2 Background-------------------------------------------------------------------------------------------------------12
1.3 Aims and Objective---------------------------------------------------------------------------------------------14
1.4 Scope---------------------------------------------------------------------------------------------------------------15
1.5 Methodology-----------------------------------------------------------------------------------------------------16
1.6 Thesis Structure--------------------------------------------------------------------------------------------------16
2 MPLS Basics-----------------------------------------------------------------------------------------------------------------17
2.1 MPLS Forwarding Plane--------------------------------------------------------------------------------------18
2.2 MPLS Control Plane--------------------------------------------------------------------------------------------22
2.2.1 LDP-----------------------------------------------------------------------------------------------------23
3 MPLS Traffic Engineering-----------------------------------------------------------------------------------------------29
3.1 CR-LDP------------------------------------------------------------------------------------------------------------31
3.2 RSVP-TE-----------------------------------------------------------------------------------------------------------35
4 Fault Tolerances with IP/MPLS-TE------------------------------------------------------------------------------------40
4.1 Failure Detection---------------------------------------------------------------------------------------------------41
4.2 MPLS-TE Protection Mechanisms-----------------------------------------------------------------------------42
4.2.1 Path Protection---------------------------------------------------------------------------------------43
4.2.2 Local Protection-------------------------------------------------------------------------------------44
4.2.3 Bandwidth Protection------------------------------------------------------------------------------48
4.3 LDP Fast Reroute--------------------------------------------------------------------------------------------------51
5 Network Model and Simulation---------------------------------------------------------------------------------------53
5.1 Assumption---------------------------------------------------------------------------------------------------------54
5.2 OPNET Model Configuration----------------------------------------------------------------------------------54
5.3 OPNET Simulated Application Traffic-----------------------------------------------------------------------58
5.4 OPNET Simulated Network------------------------------------------------------------------------------------61
5.5 OPNET Simulated Scenarios------------------------------------------------------------------------------------62
6 Simulation Results and Evaluations----------------------------------------------------------------------------------63
7 Conclusions and Future Work------------------------------------------------------------------------------------------105
Bibliography-------------------------------------------------------------------------------------------------------------------108
Analyzing IP/MPLS as Fault Tolerant Network Architecture
10
Chapter 1
Introduction
Internet Protocol (i.e. IP) has now become the de-facto standard for communication across local area and
wide area networks. Although the next version for IP known as IPv6 has come into action, IPv4 provides
the basis for this new release, and there is not much difference in forwarding plane of IPv4 or IPv6
routing architecture. Both, IPv4 and IPv6 inherit connectionless (no connection establish between
adjacent IP nodes before sending an IP packet) best effort delivery (no guarantee that a sent packet will
be received correctly at destination) based on the principle of destination based shortest path (minimal
resources involved) routing [1], [2]. Upon packet arrival each node along the path consults a pre
computed routing table to decide which interface to exit this packet. Routing tables are built using
routing protocols or through manual configuration.

With traditional IP routing, it is impossible to provide a mechanism for load balancing across unequal
cost path (with the only exception of Cisco proprietary EIGRP), because there is always a single best
path towards a destination, while taking into account multiple path metrics. All packets from source to
destination adopt the best path through independent table look up at each intermediate node. In
extreme situations, the best path has to carry a large volume of traffic, so that packets may get drops or
inherit a certain level of latency, whereas the bandwidth along the not-so best paths remains idle. Policy
based routing (PBR) can influence the default destination based mechanism used by the routers to
forward a packet [2]. PBR once configured on a device allows it to make forwarding decisions based on
information other than destination IP address, but still all the nodes along the path need to lookup each
incoming packet’s IP header information for forwarding decision about exit interface. This limitation for
repeated lookup makes pure IP network not a scalable solution as it requires distributed processing (at
each switching node) for each packet treatment.

Moreover, failure occurrence inside an IP network is a common scenario. A failure can have many
reasons, it can be software failure inside a router’s control, forwarding plane or it can be a hardware
failure that leads to a network resource (link or node) being down. The question is how to handle these
unexpected situations within a network or domain. There must be some mechanism which ensures that
Analyzing IP/MPLS as Fault Tolerant Network Architecture
11
an IP network is able to provide a defined service quality to its end users running diverse applications.
A resource failure inside an IP network degrades the service, because of the fact that IP is only
responsible for the routing related function and provides unreliable transport for applications data. TCP
(Transmission Control Protocol) therefore is used in conjunction with IP technology, because it takes
care of reliable information delivery, hence resulting in the TCP/IP suit [2]. TCP puts burden on the end
system applications to handle failure scenarios that results in retransmission or reordering. This
reliability mechanism results in increased resource utilization in terms of processing at the end node for
packet re-ordering or bandwidth consumption along the path in-case of packet retransmission. TCP is
not the only option for end systems with real time application like voice, video and some times data
(like online transactions). For applications, running over UDP (User Datagram Protocol) and relying
only on underlying IP infrastructure this cannot be an optimal solution. An IP network should help
alleviate such worst scenarios, where end applications are running over UDP.

1.1 Motivation
MPLS (Multi Protocol Label Switching) is renowned in the service provider’s network as one of the core
protocols providing reliable, fast and efficient packet switching across a domain. It comes into play with
increasing demand by customers for high service quality regarding their application requirements. The
service providers consequently implement this cutting edge technology in their network domain to
utilize and manage the resources in a cost effective flexible way, with a surety to stay in business for
long time. MPLS provides its functionality in a way that the intermediate devices need not to re-process
the network layer information, attached with each packet traversing the MPLS network. Despite label
lookup at each node, the intermediate nodes do forwarding decisions by just using the MPLS Label
(more specifically the MPLS Header) attached to the labeled packet. This single piece of information
(label) is easily implemented in hardware (as compared to network layer header information). MPLS
brings the routing down to hardware level in a smooth fashion and below the network layer, thus acting
as double edge sword lowering the latency inherited by packets across a domain [2].

The customers to a service provider network have no concern about the implemented technologies; they
just desire guaranteed services through a provider’s network. MPLS take this factor into account by
reusing IP quality of service architecture for the applications running over it. More and more features
are added to make the MPLS network architecture with the passage of time, making it a fault tolerant
architecture to rely on. The main focus of this thesis work is to study and analyze the fault tolerance
Analyzing IP/MPLS as Fault Tolerant Network Architecture
12
mechanism inside IP and MPLS networks. It is likely that a reader of this thesis will be able to figure out
the operation of next generation networks and basis for the standards currently under development (like
MPLS-TP) at IETF for convergence of data and voice/video over IP, using MPLS as underlying
technology.

1.2 Background
The IP protocol itself is a routed protocol, carrying payload across IP domains toward a specific
destination. The destination prefix and next-hop should be known ahead of time along each node across
the most likely path to be taken by the network traffic. Within an organizational domain, populating
routing table at each node is the responsibility of routing protocols like, Interior Gateway routing
Protocol (IGP) or it can be done in conjunction with an Exterior Gateway routing Protocol (EGP).
Routing protocols use IP as underlying communication protocol to exchange control plane information
dynamically among different nodes for proper path setup. Routing protocols have their own transport
layer mechanism to handle reliable transmission of their control messages.

Whenever network statistics change, control information is exchanged among routing processes running
at each intermediate node that are working in a coordinated fashion. Variable network statistics is one of
the reasons for unordered packet delivery of IP packets to an end system or in severe situation lead to
packet drop [2]. The reason behind these intricate situations is that different IP packets sharing a
common source and destination may be forwarded along different paths. Network states might change
as a result of link statistics update, or failure scenario. In both situations, nodes connected to affected
interfaces first update this information in their database tables (which might not be the routing table)
and advertise it to other neighbors participating in building up a snapshot of domain topology. Hence, it
is the responsibility of each and every node to keep its database updated, so that an incoming IP packet
may route in an optimal way. A topological information update requires a number of advertisements to
be exchanged among participating nodes. In case of Distance Vector Routing Protocols (DVRP) like RIP
(Routing Information Protocol) and EIGRP (Enhanced Interior Gateway Routing Protocol) the updated
information is exchanged between the connected neighbors and they advertise only the known best
paths reachable through them, resulting in distributed route calculation [2]. In Link State Routing
Protocols (LSRP) like ISIS and OSPF an updated information is exchanged with each and every LSRP
capable router [2] or a single designated router (centralized calculation), with the exception that ISIS
exchange whole of its link states information updates in Link State Advertisements (LSA) while OSPF
Analyzing IP/MPLS as Fault Tolerant Network Architecture
13
only advertise the local link information that is changed [6], [7]. Thus, different sizes of update
advertisements need to be processed by a node running a specific or multiple routing protocols.

In an IP network running LSRP, each IP capable node maintains LSDB (Link State Data Base) of all
received LSA. Dijkstra’s Shortest Path First (SPF) [7] is the algorithm used by the LSRP to calculate the
cost of reaching a remote destination with minimal resources involved along the path. The LSDB must
be synchronized among participating nodes. Every node has a consistent view of the network topology
with synchronized LSDB. This synchronized LSDB is given as an input for the SPF calculation. Each
node starts SPF algorithm by first considering itself as root node of a tree and then computes a cost to
reach different nodes by populating the leafs, hence making the Shortest Path Tree. SPT once built at
each participating nodes ultimately populates routing table also known as Routing Information Base
(RIB). This SPF algorithm then runs on new incoming Link State Advertisement (LSA). A disadvantage
of SPF calculation is that it’s processing increases with the number of nodes involved in the routing
process. To overcome this calculation load, the LSA updates are localized within small network
portions. An LSRP domain is thus divided into different areas and mostly LSA is restricted within a
defined area boundary. A summary of steps performed by different LSRP nodes to compute a common
snapshot of topology in IP domain is provided by [4]:
IGP Convergence = D + O + F + SPT + RIB + DD

Where D is the link state update detection time, O is the time to originate LSA, F is the complete
flooding time from node detecting the failure, SPT is shortest path tree computation time, RIB is the
time to update Routing Information Base as result of SPT computation and DD is the time to distribute
the FIB (Forwarding Information Base) update.

The FIB is a topology driven database implemented in hardware. An entry in FIB corresponds to a RIB
entry. FIB keeps an update copy of RIB entries in its cache to decrease lookup delay and increases device
packet processing throughput. An LSA update triggers SPF calculation among the nodes and often
results in traffic drop for the amount of time elapsed during link state topology convergence among
participating nodes. This amount of elapsed time is critical for traffic with real time applications.

Multi Protocol Label Switching (MPLS) has been standardized in RFC-3031 [3]. This technology changes
the way traditional internet works and these changes are below the IP layer [6]. Enabling MPLS inside a
Analyzing IP/MPLS as Fault Tolerant Network Architecture
14
network not only benefits in terms of fast reroute along the corrupted resources, but also helps an
organization to better reuse deployed resources using MPLS Traffic Engineering (TE) [5] ,[7]. MPLS Fast
Re-route (FRR) enhances a domain capability in response to failure situations. Within the MPLS domain,
only the head end, i.e. source router decides the path to be taken by an incoming packet through routing
table lookup (implementing source routing) and packets generated by same/different application are
sent along different paths towards the same destination. MPLS deployment pushes IP routing
capabilities to the edge of the MPLS domain. MPLS core is usually unaware of IP routes and do not
perform any lookup based on IP layer information. This deployment benefits in terms of performance as
the core routers no longer carry a global routing table and the single MPLS domain provides overlay
network architecture for multiple applications traffic to be carried over it [2], [8].

With MPLS each edge router adds an MPLS header to an incoming IP packet. The MPLS header may
contain more than one label. The label information attached to each packet determines the path to be
taken by the packet and the differentiated treatment received to this labeled packet from the MPLS core,
even though the IP parameters (source or destination) are the same [3]. Source routing is one of the most
powerful properties of MPLS-TE [8]. Each node in the MPLS domain forwards a labeled packet with no
independent forwarding decision. This is in contrast to the IP routing which is susceptible to routing
changes, and performs independent forwarding decisions by locating longest prefix match from routing
table at each hop along the path. The MPLS-TE path is calculated only once by the head end regardless
of route changes along a network. This thesis work will cover the capabilities of MPLS networks in
providing services like circuit switching, as TE and fast reroute. Further it also explains how MPLS
enhance functionality of an IP network in terms of better resource utilization with optimal flow and
guaranteed quality of services. The factors of MPLS network that result in converged backbone over
IP/MPLS technology for voice, video and data are investigated. The main focus is to find some
mechanism that could lead to an optimal solution within MPLS fault tolerance domain.

1.3 Aims and Objective
The main goal of this thesis work is to evaluate the IP network resilience to a failure situation inside an
internet realm. Network resource failure leads to traffic drops in worst condition and results in initiating
new calculation (say SPF) around a failed resource. This thesis will analyze IP network capabilities in
handling such failure situation in accordance with the MPLS network architecture. OPNET Modeler is
Analyzing IP/MPLS as Fault Tolerant Network Architecture
15
used as a benchmark tool to simulate the network scenarios and to analyze the results. The objectives of
this thesis include:
 Literature study about IP, MPLS network with regard to real time traffic characteristics
 Study the interaction of IP and MPLS, that results in IP/MPLS network architecture
 Study with focus on the Quality of Service and MPLS fault tolerance mechanism
 Method taken into account to detect a failure in timely manner inside an IP environment
 The schemes provided by IP framework to cope with network resource failure
 Comparing the available varieties for tolerance mechanism inside MPLS network
 How MPLS turns a packet switched network into circuit switched like network.
 Why MPLS still depends upon the IP for its specific functionalities.
 The degree of resilience provided upon failure over core resources (node or link).
 How traffic engineering ensures quality of service along the alternate path.
 Effect of certain Quality of service techniques in providing end-to-end resilience
 Understand how to configure network and network attributes in OPNET Modeler
 Investigating the behavior of network traffic under various situations using OPNET
 Apply mutation testing over the simulated network to study the behavior of network state
 Analyze the results achieved through matching with other potential results
 Verify how to minimize the effect of traffic congestion and drops
 Understanding different application statistics such as packet drop, end to end delay, jitter,
network responsiveness and throughput over the simulated IP/MPLS network
 Try to find out a possible mechanism for IP/MPLS fault tolerance

1.4 Scope
This thesis will cover mostly the MPLS section of the converged architecture. Which protocols are
potential drivers of this fault tolerance technology? At which extend the IP/MPLS is guaranteed to
provide better service quality? In short, this work presents the performance of different applications
using IP/MPLS as underlying transport architecture in a compact manner and it may provide help for
further research in fault tolerance mechanisms in today’s IP network.



Analyzing IP/MPLS as Fault Tolerant Network Architecture
16
1.5 Methodology
This work involves in-depth literature studies. Most of the information is taken from the well-known
books; IETF RFC’s and highly recognized research papers. Further, implementation of different network
scenarios to gain a better knowledge about the characteristics of diverse applications is also part of this
thesis. Evaluation methods are chosen based on different matrices as mentioned in “aims and objective
section”. The theoretical knowledge gained is implemented in the OPNET research simulator. In
addition, the section-5 will reflect the steps involved in implementation.

1.6 Thesis Structure
Section 1: This covers the introduction, background, aims and objective, scope of thesis, methodology as
discussed above.

Section 2: This covers the basics of MPLS network architecture, the terminologies and concepts related
to MPLS architecture. How MPLS converts packet switching network to label swapping network
through MPLS control plane protocol(s).

Section 3: Traffic engineering concepts related to IP and MPLS network is discussed in this chapter,
with the procedure how to convert a best effort network into a traffic engineered network.

Section 4: How IP/MPLS provides resilience within a deployed architecture is discussed. Several failure
detection and protection mechanisms besides MPLS fault tolerance flavors.

Section 5: The main steps and procedures taken to simulate different network architectures in OPNET,
as IP/MPLS-DiffServ-TE, with and without mutation testing are presented in this chapter.

Section 6: This section will cover achieved results that are shown in the form of graphs to evaluate
different scenarios.

Section 7: Conclusions and proposal for future work are presented in this section.


Analyzing IP/MPLS as Fault Tolerant Network Architecture
17
Chapter 2
MPLS Basics
MPLS is a tunneling mechanism [8], with the capability that only the edge devices are aware of the
tunneled payload type. The core of the network is unaware of the payload to be carried over them.
Routers at core (backbone) just maintain minimal information required to treat an incoming packet and
pass it on to an adjacent node. An MPLS network consists of a number of MPLS capable devices as Label
Switch Routers (LSR) [9]. An LSR typically have all interfaces enabled for the MPLS protocol. An edge
router (ingress or egress) known as Label Edge Router (LER) is connected outside the MPLS domain; it
has specific interfaces enabled for MPLS. LER lies on the border in between the IP and the MPLS
domain. A unidirectional path taken by a labeled packet in MPLS domain is established between the
LER and is called Label Switch Path (LSP). When a packet (of any protocol type ATM, FR, Ethernet,
IPv6) enters the MPLS network, it gets classified under a FEC (Forward Equivalence Class). A FEC is a
set of packets towards the same destination requesting the same kind of treatment from MPLS domain.
An Ingress LER labels an incoming packet according to the FEC it belongs. An LSR keeps the label
binding information for a particular FEC in Label Forwarding Information Base (LFIB), which is the
forwarding table for MPLS domain as IP domain has the routing table (RIB) [9].

With the advent of modern IP routing technique (RIB and FIB), MPLS switching is also divided into the
Forwarding plane and Control plane [10].  This separation results in building two separate databases on
each router, the LIB and the LFIB. The LIB is Label Information Base and resides in control plane. LIB
manages all locally assigned labels and received label information from other nodes, which could
possibly be used to forward a labeled packet. LFIB is constructed based on information in LIB and RIB.
LFIB contains the best label to a particular prefix, just as RIB contains the best routes to a prefix. The
Forwarding/Data plane is related only with forwarding a packet from source to destination, while the
control plane is related to all actions carried out by each intermediate node in the MPLS domain to treat
incoming packet in a way that optimize the forwarding plane mechanisms. The control plane is the core
for MPLS forwarding engine, all the forwarding decisions are based upon control information [8].
Analyzing IP/MPLS as Fault Tolerant Network Architecture
18








Figure 2.1 – MPLS Planes [13].

2.1 MPLS Forwarding Plane
All the decisions for a packet to route over a network are decided solely based upon the PDU (Protocol
Data Unit) attached to it. In case of IP layer the PDU attached is called IP header, which provides
routing table lookup functionality across intermediate nodes and decides how to forward a packet along
correct path. Despite IP, an MPLS enabled network adds its own fixed sized 4 byte of header
information known as MPLS header[9] or Shim header [8] [10] [11]. The shim header is inserted in
between the IP header information and the Data link header information, as MPLS technology lies in
between layer2 and layer3 known as layer2.5 protocol [11]. An MPLS header has local significance, each
intermediate LSR has to exchange a header with new header information.



Figure 2.2 – MPLS Label [11].

Thus, MPLS introduces a new field that is used for forwarding a packet along the MPLS domain.
Although the labels are locally significant they are advertised to directly reachable peers. If somehow
this label information was introduced in already deployed IP protocols, than there would be lot of
upgrades in every IP related protocol to make it label capable. To avoid such situation new protocol
Analyzing IP/MPLS as Fault Tolerant Network Architecture
19
architecture was developed at IETF for carrying labeled information which can run with any underlying
protocol infrastructure.

Label bits are used to assign label information, but often the MPLS header is known as the MPLS label
[8]. The MPLS label has no structure as it changes at each hop. Label information identifies a next hop
for a MPLS packet. The experimental (EXP) bits are used to grade a service quality inside MPLS domain.
The EXP specifies PHB (Per-Hop-Behavior) in the MPLS domain as the IP Differentiated Service Code
Point (DSCP) which is used to provide quality of service in IP domain inside DiffServ (Differentiated
Services) architecture [12]. The stack bit identifies either it’s the only label attached to the packet or there
is other label present. A stack value allows an LSR to recognize the last MPLS header before the IP
header begins, mostly an ingress router to the MPLS domain while attaching first label setting this stack
bit to “1”. The TTL (Time-to-Live) has the same function as the TTL field in the IP protocol, to prevent
forever looping of a packet. The TTL value is copied from IP packet upon entering MPLS domain (at the
Ingress LER) and is copied back to IP header at the egress LER [9].







Figure 2.3 – MPLS Label Swapping [11].

Interestingly enough there is no CRC or FCS in the MPLS header. This is due to the fact that the modern
layer2 architectures (SDH/SONET) trust the underlying medium used. MPLS is mainly a service
provider technology and backbone links are deployed with minimal error conditions during
transmission. If somehow there are errors introduced in labeled payload, egress router will discard the
affected packet and generate an ICMP message back to the source. This also reduces burden from the
core of an MPLS domain to calculate checksum at each intermediate nodes. Further as MPLS is known
to be multi protocol it can carry any type of payload across the backbone MPLS domain, while nodes in
backbone are unaware of a specific protocol technology. The core network is only doing the process of
swapping incoming label with outgoing label and rapid forwarding.
Analyzing IP/MPLS as Fault Tolerant Network Architecture
20
A forwarding mechanism for MPLS domain is provided in [11] as shown in the figure below, along with
a sample LFIB table at LSR W. An attachment of MPLS header is done to an IP packet as it enters an
MPLS domain by the Ingress LER (LSR-V) which forwards the packet out to a specific interface towards
the next MPLS capable route. The router changes the layer-2 Ethernet protocol identifier value to specify
that the payload starts with a label and is followed by an IP header.





Figure 2.4 – LFIB Table [11].

An intermediate node in an MPLS domain has no information regarding payload or IP header; it just
looks at the label information, swaps the incoming label with an outgoing label and forwards the labeled
packet towards the next hop. This process continues until the label packet reaches the Egress LER LSR
X) which removes the label information, gets the IP packet and forwards the packet based on attached IP
information (perform IP lookup).  Certain terminologies related with the forwarding plane include:
Push Label: The process of adding label information to an IP packet or already labeled packet, often
done at the ingress edge.
Swap Label: The process of exchanging an incoming label with a pre-determined outgoing label.
Pop Label: The process of removing the MPLS domain specific information from a labeled packet.
FIB:  A database at the ingress edge and used for incoming unlabelled packets.
LFIB: A database at each MPLS enabled router used for incoming labeled packets.
Label Stack: The process of attaching more than one label to an IP or labeled packet resulting in nested
LSP. The intermediate LSR only process packets based on the top label, the bottom label is understood
only at the egress LSR, who assigns it and advertise this information towards the ingress LSR.

Each MPLS label corresponds to a service. Only the top label identifies how to reach the next hop for a
particular destination and another attached label (in case of label stack) identifies an extra treatment at
the egress LER or intermediate node (MPLS-FRR). Each MPLS header is four (4) bytes of information
and attaching a new header to IP packet or adding another MPLS label to an already labeled packet
might result in fragmentation, whenever the data link layer MTU is exceeded across certain links in the
Analyzing IP/MPLS as Fault Tolerant Network Architecture
21
MPLS domain. When a situation like this occur the LSR pop all labels makes a record of this label
information, fragments the tunneled IP payload into multiple chunks if “Don’t Fragment bit” is OFF,
and attach label information with each fragmented chunks and pass multiple labeled packet towards the
egress [13]. The egress will do care about other functions either merging multiple packets into one big
packet that conform data link MTU size or make more fragmentation. This leads to the results that the
LSR (lies inside the MPLS domain) are IP capable [8] and perform IP layer functionalities, besides full
routing through the IP header information. To better handle this analysis of MPLS domain can result in
better solution, as data link may support Baby Giant Frames, which are slightly bigger than the link
MTU size. MPLS MTU size known as MPLS Maximum Receive Unit (MRU) [13] needs to be pre
configured on such susceptible links. The MPLS MRU information corresponds to an outgoing link and
label information will reside in the LFIB [13], and a single LFIB lookup reveals certain information for a
particular incoming and outgoing label and interface characteristics.

But what will happen if the Don’t Fragment bit is SET for a packet exceeding MTU or the TTL value
expired along the path towards the egress LER. The core of the MPLS domain is unaware of the source
of a labeled packet. LSR only label information on how to swap labels and forward labeled packets.
Although an LSR can access the IP information beneath the MPLS label, it has no information how to
reach the source. A likewise scenario is discussed in [13]. If such situation arises in the core of the
network, an LSR will simply drop this label packet, make a new packet with only IP header information
of the dropped packet and ICMP message, label it with corresponding LFIB information as usual and
forward the packet towards the egress edge. As the egress edge gets this information about the packet
treatment at the core it will generate the ICMP message back to the source.

As a label packet reaches an egress LER, this edge router has to perform two lookups [14] to forward an
incoming labeled packet out to a specific interface as an IP packet. First it has to perform an LFIB lookup
to find the outgoing label, as it is LER it has no outgoing label installed in LFIB database. It will pop the
label, read the IP header information and perform an IP lookup in the routing table or Routing
information Base (RIB) to get the exit interface. This last LFIB lookup can be avoided if the arriving
packet at the egress edge is an IP packet and not a labeled packet. For this purpose while advertising
label information, the egress edge (LSR-Z) for a particular prefix advertises an “Implicit NULL” label of
value “3” for IP to neighbor router (LSR-Y) [13]. An implicit Null label is advertised by LER, for a prefix
it does not want to assign a label. The previous receiving router (LSR-Y) upon receiving an incoming
Analyzing IP/MPLS as Fault Tolerant Network Architecture
22
label packet destined for LER, it pops label information and forwards an IP packet towards the egress
edge (LSR-Z). LER performs a single IP lookup in RIB and forward the packet accordingly. This
capability is know as “Penultimate Hop Popping” (PHP) [9] in MPLS domain. PHP router (LSR-Y) is the
last router that reads the label information in MPLS domain just before the MPLS egress edge router.









Figure 2.5 – MPLS PHP Operation [11].

A drawback of this PHP operation is that the DSCP value used for quality of service for a label packet
within MPLS domain is lost. The LER has no way to treat a plain IP packet in a preferred way. To get
DSCP value at LER, the egress edge LSR-Z is configured to advertise an “Explicit Null” label of value
“0”, towards PHP router (say LSR-Y). The LSR-Y will now send labeled packets towards LER. This
solution with the use of explicit null provides opportunity for end to end DSCP propagation inside
MPLS domain [8] [13]. This mechanism is required while implementing MPLS-DiffServ-TE.

2.2 MPLS Control Plane
Building LIB across each of the MPLS enabled nodes in MPLS domain is the function of the control
plane. The bindings between labels and FEC need to be distributed throughout the network. Manual
configuration is tedious and puts burden on the operators. The MPLS signaling protocols are like IP
routing protocols, used to build label forwarding table across each MPLS node. As a label has local
significance upon a link, no LSR provide label information of its received label to adjacent neighbors,
rather advertise a newly locally assigned label for a received label. Hence an LSR has no information
about the packet path ahead of its neighbors, where as in IP routing, a router can build the path from
itself to any other destination as it has information about the LSRP topology.

Analyzing IP/MPLS as Fault Tolerant Network Architecture
23
To dynamically advertise label information there are two options [8], either invent a new signaling
protocol or enhance an existing signaling protocol to carry label information. For MPLS, both of these
options are taken into account resulting in a new protocol called Label Distribution Protocol (LDP) and
enhancing two existing protocols Resource Reservation (RSVP) and Border Gateway Protocol (BGP).
The upgraded flavors used piggybacking mechanism to carry label information. Upgraded versions are
known as RSVP-TE (Traffic Engineered RSVP) and MP-BGP (Multi Protocol BGP).

2.2.1 LDP
The fundamental approach to distribute labels across an MPLS domain is accomplished through the
Label Distribution Protocol (LDP). It is standardized in RFC-3026, published in 2001 by IEFT and
updated in 2007 by RFC-5036. LDP was designed specifically for label distribution in MPLS domain [10].
LDP do not provide any routing related functions and depends upon the IGP for its routing related
decisions [8], this means that LDP path is along the IGP shortest path.  As a protocol, the LDP
functionality is divided into four categories [11]:
 Discovery of adjacent LDP capable LSR
 Establishment of control conversation in between LSR and negotiate capabilities
 Advertisement of labels
 Withdrawal of labels

Every LDP PDU begins with a header indicating the length of the whole PDU and followed by one or
more messages to be exchanged in between the LSRs. Each message is itself made up of header that
indicates the length of message followed by contents of message [11]. LDP was designed while keeping
extensibility in mind, the LDP messages are in TLV (Type Length Value) format [8].
Type, Specify which information is being exchanged.
Length, Specify total length of value field.
Value, Contains actual information being exchanged.




Figure 2.6 - LDP PDU [14].

Analyzing IP/MPLS as Fault Tolerant Network Architecture
24
Adding new capabilities in LDP is accomplished simply by adding new TLV field in LDP message and
the LDP capable LSR that does not understand extended fields may ignore specified amount of data as
mentioned in Length field [8] of respective TLV. LDP neighbor is discovered using Hello messages
mentioning features and mode of operation over UDP port 646 at IP multicast address “224.0.0.2”,
referring to all routers on this segment. The LDP enabled LSR willing for neighbor-ship replies with the
Hello protocol over the UDP port. Once an LDP peer is discovered over the UDP port using multicast
address, the TCP session is established with the discovered peer over TCP port 646 to exchange label
binding with particular FEC. The higher LDP id router (LSR with higher IP address) initiates the TCP
connection with the other end. The use of TCP ensures reliable delivery of the information and allows
incremental updates (using TCP sequence numbering), rather than periodic updates. Keep-alive
messages are used in absence of any new information [8].

LDP operation is initiated by message exchange in between the LDP peers. A neighbor-ship can be
formed either on point-to-point link for directly connected peers or through LDP targeted Hello for
remote peers. LDP Targeted Hello is established though unicast Hello request at specific IP address,
rather multicast. The Targeted LDP peers help implementing LDP Session Protection. LDP relies on IGP
which has several implications [8]:
 LDP established LSP will always follow IGP shortest path. As IGP topology change LDP LSP
also change, resulting in a new LSP.
 The scope of LDP- established LSP is limited to the scope of IGP. Thus LDP LSP can not traverse
autonomous system (AS) boundary.
 IGP converge leads to LDP convergence time and during convergence the traffic can be black
holed or looped.
 IGP and LDP need to be synchronized to use a particular link in MPLS domain, resulting in IGP
LDP synchronization.

Beside the LDP drawback on relying on IGP, a certain benefit for LDP from this reliance is “LDP Session
Protection” [8, 13] by avoiding sub optimal path during link flap [8]. As there are a number of links in
between two LDP peers within IGP area, a peer can be reachable through either a direct link or through
some IGP path. A LDP Hello neighbor-ship maintains only one LDP session in case both direct and
targeted Hello are configured in between them. As direct LDP session breaks due to link failure between
LSR A and LSR C, the LDP peer can still be reachable through the LDP targeted session between them as
Analyzing IP/MPLS as Fault Tolerant Network Architecture
25
far as there is an IGP path that stays in between two LDP peers through LSR B and LSR D as being the
intermediate nodes.  Another benefit for LDP LSP relying on IGP is load balancing [13]. IGP by default
do load balancing across the Equal Cost Multiple Path (ECMP), so LDP also performs load balancing
across ECMP links.







Figure 2.7 – LDP Session Protection [8].

An issue related to LDP dependence over IGP results when an IGP advertise a summary route for a
particular destination. Aggregation in IP network has severe effect over MPLS capable routers.
Aggregation is a method to summarize many subnets in a single subnet and advertise it to other peers.
Aggregation may hide subnet failure inside a summarized address and suppress unwanted updates,
this leads to a stable IP network design. But once aggregation is used inside the MPLS design it breaks
the MPLS LSP tunnel. Performing aggregation at an LSR results in advertising a single label for a range
of prefix. As a result LSR advertise label corresponds to an aggregate prefix. As a packet arrives
requiring to be forwarded along one of the aggregate label information, an LSR pops all labels, performs
an IP lookup to determine the next-hop and assigns corresponding label before forwarding. Thus
aggregation breaks the LSP tunnel into multiple LSP, one ended at the aggregator LSR and another
starts from the aggregator towards the egress edge [13].

Label Allocation/Distribution Schemes
Before advertising label information to its peers, an LSR assigns a label for a network prefix or FEC,
which is reachable through it and keep this information in LFIB [14]. This assigned label to a particular
FEC is advertised to adjacent routers, which save the advertised label as the outgoing label for a specific
FEC. Before going into the different modes of label allocation, traffic flow is an important concept to be
cleared beforehand [14]. The flow of traffic is always from the upstream node towards the downstream
Analyzing IP/MPLS as Fault Tolerant Network Architecture
26
node for a particular destination [15]. An upstream node is close to the source and downstream node is
close to the destination.
1. Unsolicited Downstream:  The downstream node assigns a label to a FEC and distribute this
information to all other upstream neighbors in an unsolicited way either they need it or not.
2. Downstream On demand:  The downstream node assigns label to a FEC and provide this label
binding to an upstream LSR upon request.
3. Upstream Label Allocation:  The upstream router itself assigns a label for a FEC and advertises it
to the LSR downstream in MPLS domain. Used in some special scenarios like MPLS-multicast.

Label Retention Mode
In an LDP enabled network an LSR only keeps a label binding in LFIB correspond to a FEC which
arrives from the downstream LDP peer, along the IGP shortest path towards the destination and discard
or either retain other label depends upon the mode the LSR is working in. There are two modes for an
LSR to be in to make decision which label to keep [8]:
1. Liberal Retention Mode: Keeping the entire labels from the downstream LSR, either they are
along the shortest path towards destination or not. But LFIB is populated with only the label to be
used for forwarding. This is due to the fact that LDP relies on IGP and IGP topology is vulnerable
being changed time to time. So, keeping a label from all the neighbors increase efficiency in case
some other neighbor became the next hop for a particular destination along IGP shortest path.
2. Conservation Retention Mode: An LDP enabled LSR only keeps the label corresponds to the
routing table entries (along shortest path) and discard any other label. The labels used to forward
the traffic along the next hop is kept in the LFIB, all other label information is discarded. So,
whenever an LSR do not have a label for a specific incoming label, it issues a Downstream on
Demand label request to its downstream peer.








Analyzing IP/MPLS as Fault Tolerant Network Architecture
27
Label Control Mode
Control mode specifies who has the control over the LSP setup.
1.   Ordered LSP control: An LSR only keeps a label which arrives along IGP shortest path towards
destination [8].  Hence the label assignment starts from the egress edge (close to destination) and
moves upward in an ordered fashion.
2.   Independent LSP control: An LSR can advertise label information as far as it is along a path
towards a destination. It no longer waits for an incoming label from its downstream LSR. An
obvious drawback with this technique is that the ingress edge might get the label binding before
the end to end LSP is established [13] and traffic entering is vulnerable being lost.

As topology change occur inside an IGP area, affected LSR removes forwarding state from LFIB and
new label has to reach an LSR, to perform forwarding decision. For the time during label unavailability,
traffic is black holed. A solution to such silent failure problem found at [8], by increasing the IGP link
metric, if LDP is not fully operational over a link. This can be achieved through configuring IGP and
LDP synchronization.

LDP Label Space
MPLS Label is a 20-bit field inside the MPLS header. A label has local significance across the link
between two LDP peers. Label space is the set of all the labels to be assigned for a prefix by a particular
LSR. Some labels are reserved for specific purposes.
1. Per-Platform Label Space: A set of labels shared by all interfaces on a platform. Used mostly in
broadcast medium, like Ethernet. An incoming label packet can use any interface to get into the
platform (LSR).
2. Per-Interface Label Space: Specific interfaces use specified labels, and an incoming labeled packet
is inspected either it arrive from a correct interface or not. Used mostly in non-broadcast medium,
like ATM, Frame Relay.

Per-platform label space is mostly used, and we will see how this helps us in MPLS FRR
implementation.


Analyzing IP/MPLS as Fault Tolerant Network Architecture
28
LDP Messages
Message is a way of communication among different nodes sharing common infrastructure. LDP
exchange certain messages with peer to create, maintain and teardown an LSP, these include [11]:
1. Label Request Message:  An LSR ask from its neighbor a label binding for a particular prefix.
2. Label Mapping Message: An LSR provides with the label binding information for a prefix.
3. Label Withdraw Message: An LSR is no more along the IGP shortest path for a particular prefix.
4.  Label Released Message: A notification for releasing label information corresponds to a prefix
mentioned in withdrawn message.

Figure 2.8 - LDP message exchange across MPLS domain [11].



Analyzing IP/MPLS as Fault Tolerant Network Architecture
29
Chapter 3
MPLS Traffic Engineering
The true benefit of deploying MPLS inside a network lies in traffic engineering. Traffic engineering (TE)
is the process to steer traffic around a network, while maintaining requirement that the path taken will
be an optimal path for the network traffic that belongs to a particular class. This optimal path is not
along the IGP shortest path for all time. Strictly speaking traffic engineering (TE) is a form of congestion
avoidance mechanism, to avoid congestion from occurring along the best path (shortest path) which
carries all traffic. TE is used as the congestion may results by inefficient mapping of traffic streams onto
network resources. TE used to avoid long term congestion; it has nothing to do with short term
congestion caused by busty traffic. TE is a process in its own, used to measure, analyze network
behavior and be applied to traffic pattern to achieve certain goals. In data communication world, TE
provides an integrated approach to engineer traffic at layer 3 of OSI. TE hence controls the path along
which data flows.

TE using MPLS integrates label swapping framework with network layer routing. Incoming IP packet
gets classified at the ingress and is assigned a label corresponding to a destination. TE label is assigned
to this labeled packet to further define the circuit to be taken for labeled packet across the network. TE
thus provides benefits similar to overlay model but without separate layer-2 network architecture as
provided by ATM or Frame Relay. MPLS-TE further enhances the IP-DiffServ architecture, as it is not
mostly preferred to send different applications traffic, having diverse characteristics along the same path
and treated in the same way. Such TE is not possible in IP network with flexibility like this, as it is
provided by MPLS enabled network. IP routing is destination based and each node along the path
independently follows the least cost principle to get traffic around network as quickly as possible. The
only possibility with IP traffic engineered network is to manipulate the link cost so that a specific link
lies along the least cost path for a specific traffic. But, manipulation is not a solution for larger networks
as topology changes more often. Manipulation may result in suboptimal routing across a network
domain, and besides getting more from a network the operators are paying more for using metric
manipulation.

Analyzing IP/MPLS as Fault Tolerant Network Architecture
30

The difference between network engineering and traffic engineering is [13]:
Network Engineering: The process of manipulating network to suit for a traffic requirement, results in
installing new infrastructure as required depending upon traffic flows.
Traffic Engineering: The process of manipulating traffic to better utilize deployed network resources.

MPLS TE, attempts to take the best of connection oriented traffic approach and merge it with IP routing.
[RFC-2702] layouts the requirement for traffic engineering but gives rise to the so called “Fish Problem”
[8, 13], shown in figure 3.1. Consider all links being equal cost for IP routing traffic flowing from source
A or B will always take the path C-G-D There is no way to utilized the C-E-F-D path unless the link
metric along that path is manipulated and makes ECMP or better than primary link. This is partial
solution for network traffic originating from A or B, what if traffic is also originated from E or G; this
leads to suboptimal scenario using IP capabilities in providing true TE. MPLS switching follows source
based path. In MPLS network, head end has the capability to decide a path through the network for a
particular FEC. For specific application traffic, head-end C decides either to use LSP along the path CG
D or LSP along the path C-E-F-D. MPLS-TE decouples the routing and forwarding [16].







Figure 3.1 - Fish Problem [8].

The building block for MPLS-TE involves RSVP-TE and CR-LDP [8] [11] [14]. CR-LDP stands for
Constraint Routing LDP, i.e. the original LDP protocol with new constraints across the network links, to
be taken into account while calculating the path for an LSP. RSVP-TE is tweaked version of RSVP
signaling protocol. A brief description of TE mechanism is provided below.


Analyzing IP/MPLS as Fault Tolerant Network Architecture
31
3.1 CR-LDP
A disadvantage of LDP is the reliance on IGP for its routing related functionality while building an LSP.
For LDP an LSP is setup based on routing information in IP routing table and in turn results in a single
IGP shortest path. CR-LDP is the signaling protocol for MPLS-TE, based on LDP. CR-LDP enhanced
LDP, and is able to compute an explicit LSP along an arbitrary calculated sequence of LSR. The source
computed LSP route and than signaled to other nodes along the specified path. The CR-LSP is also
unidirectional and able to perform load balancing along different cost paths, despite LDP which only
performs load balancing along ECMP due to its reliance over IGP. Source based routing enhances the
QoS criterion inside MPLS network [14].

Constraint based Routing
The Constraint based Routing (CBR) is a set of protocols and algorithms that compute at a certain
source, an optimal path towards a final destination with regard to certain constraints. This leads to a set
of requirements [15] to enable CBR:
 All links in the domain should be characterized with traffic engineered attributes
 The configured attributes must be advertised to all routers in the IGP area
 A constraint path calculation mechanism to be implemented at each node

There is obviously a need of routing protocol and possibly the link state algorithm to convey link
attributes among nodes. Rather than developing a new routing protocol specific for this purpose,
existing link state protocols are extended to support CBR, hence results in ISIS-TE and OSPF-TE. The set
of newly added attributes include [8] [13]:
 Traffic Engineered (TE) metric, other than IGP metric to be configured upon the links
 Maximum Bandwidth, the TE link capacity
 Maximum Reserve Bandwidth, how much bandwidth on a link can be reserved (TE pool)
 Unreserved Bandwidth, still available bandwidth on a link from TE pool
 Administrative Group

TE metric: is a value assigned at a specific link for TE calculation, if TE metric is not configured across
the links then by default IGP-TE takes into account IGP metric at that link [13]. It is also considered to be
TE administrative weight over the TE capable links.
Analyzing IP/MPLS as Fault Tolerant Network Architecture
32
Maximum bandwidth: A static value configured by operator at each link. A configurable value across a
link can be greater than the actual link capacity resulted in over provisioning the links, while keeping in
mind the constraint that not all the circuits passing through an over provisioned link should be active at
the same time.
Unreserved bandwidth: This value changes on every TE-LSP setup/tear down and the updated
information is sent across the domain. Flooding the value upon every change, results in number of
Traffic Engineered Link State Advertisements (TE-LSA) to be sent per unit time, and TE network is
susceptible to being unstable. Link state protocol calculation is distributed mostly; each node requires
full information regarding network statistics. To better alleviate such situation, thresholds [8], [13] are
often configured across the network links. Whenever a bandwidth crosses this threshold value in Up or
Down direction, a TE-LSA is flooded. This stability inside a TE network is achieved at the cost of the
tradeoff between TE database accuracy and TE information processing [8]. TE-LSA populates the Traffic
Engineered Databases (TED) [15] at the head end. TED gets updated, once a threshold reaches at specific
threshold across network and resulted in TE-LSA generation at that LSR. TED thus sometimes is not
reflecting an exact picture about network statistics and the TE-LSP calculation at the head end may often
results in a failure [13], [16]; this situation is discussed in the coming section on RSVP.
Administrative group: A 32-bit value used as a flexibility mechanism across TE links. Each
administrative group bit can be used to specify different parameters of a TE link. Link can be marked
optionally with different values (or colors) which can be understood generally in terms of a tag on the
link. Each color/value corresponds to a specific property as latency, delay, packet loss. Thus, it provides
interfaces statistics using attribute names expressed in strings [8].

The head end computes an optimal path based on TE-LSA, using a tweaked version of Dijkstra’s
shortest path first algorithm, known as Constrained Shortest Path First (CSPF). Each of the ingress LSR
has a complete picture of MPLS domain (links) attribute stored in their TED. The CSPF uses information
in TED, which is updated by IGP-TE and locally specified constraints upon link attributes. CSPF is an
SPF algorithm that runs multiple times upon the TED, and taking a single constraint (TE Attributes) into
account during each run [2]. Traditional SPF only calculates shortest path towards a destination with
minimal cost, a CSPF computes a path that meet certain requirements and prunes every other link from
the Constraint Shortest Path Tree (CSPT) [15].

Analyzing IP/MPLS as Fault Tolerant Network Architecture
33
The TE attributes assigned to the network links, representing the state of the network need to be
received at each head end to perform proper decision while setting up a TE-LSP circuit. Link attributes
once available to head end calculates the explicit path with requested bandwidth along the network.
Traffic patterns sharing a common characteristic (fall under single FEC), should be forwarded along the
same circuit or TE-LSP Tunnel. Head end LSR enabled for MPLS-TE, creates one or more explicit paths
with bandwidth assurance for each tunnel. LSP Tunnels need to be mapped over the underlying packet
switched network (mostly IP network). These LSP tunnels convert characteristics of the packet switched
networks into circuit switch network. Link attributes along the network are used to constrain the
routing of packets through specific LSP tunnel circuits, corresponding to different explicitly specified
network resources (intermediate routers). MPLS-TE thus has the ability to define trunks through a
network, each with an assured amount of bandwidth, thus augment the sensitive data to be passed over
those tunnels with guaranteed jitter and low packet loss. To distribute link attributes dynamically, there
is a need for a pure link state routing protocol that may distribute such information to all head ends in
MPLS domain. The main motive for using link state routing protocol for propagating TE parameters is
that, the link state routing enables a router to flood the incoming LSA to all other routers without its
own calculation over that LSA. This result in distributed calculation at each LSR, which is much faster
than individual (centralized) calculation and passing only the best path as distance vector protocols do.

OSPF Traffic Engineering Extension
OSPF is renowned as a link state algorithm to distribute routing updates. For scalability purposes OSPF
domain is broken down into multiple areas, with the constraint that all areas must be connected to the
backbone area (area 0). A reason to choose OSPF for TE is that this is a link state algorithm that better
handles link statistics that are required for traffic engineering solution within a network. A routing
device inside OSPF domain may belong to multiple OSPF areas [2]. OSPF routing protocol with traffic
engineering capabilities is knows as OSPF-TE. OSPF-TE introduces three new LSA to propagate TE link
information among the participating nodes. These new LSA have different flooding scope [7]:
LSA 9: Link Local TE LSA, stays on local link, exchanged among TE peer routers over a single link.
LSA 10: Area wide TE LSA, restricted by ABR (Area Border Router).
LSA 11: AS wide TE-LSA, ABR flood this LSA to other areas but ASBR (Autonomous System Border
Router) restricts this and not flood outside AS boundary.

Analyzing IP/MPLS as Fault Tolerant Network Architecture
34
These new LSA are known to be Opaque LSA in OSPF domain [13]. OSPF-TE is backward compatible
with OSPF, means any router which does not understand these opaque LSA may discard it. TE
capabilities are exchanged in between TE enabled LSR using “O bit” in OSPF option field while
exchanging HELLO packets [7].

ISIS Traffic Engineering Extension
ISIS is another choice of link state routing protocol that has the capability to distribute link related
information in a reliable manner. Instead of areas as in the OSPF routing domain, ISIS domain is divided
into multiple levels. A router inside an ISIS domain may belong only to single ISIS level [2]. ISIS routing
protocol with traffic engineering capabilities is knows as ISIS-TE. ISIS is also a LSRP, so it performs
almost like OSPF, as we have discussed, but for ISIS there is no area concept. ISIS relies on concept of
level to control the amount of flooded traffic as OSPF area do. ISIS uses TLV as its message format. An
ISIS metric could be any positive number within a valid range, for the purpose of MPLS-TE; the ISIS-TE
has extended metric values. ISIS-TE thus introduces new TLV to carry TE information [6]:
TLV 22:  ISIS-TE reach ability TLV, describes ISIS neighbor and TE cost to reach it. There is a sub-TLV
associated with TLV 22 containing TE information.
TLV 134: Traffic Engineered Router ID. Use to identify router inside TE domain. [2], [8].
TLV 135: Extended IP Reach-ability adds TE and wide metric capabilities. [2].

CR-LSP Setup
CR-LDP makes use of CBR. A scenario for CR-LDP is presented in [14]. Signaling across the explicitly
calculated path will be done using explicit route TLV (ER-TLV) [14]. This ER-TLV is carried within the
LDP label request message. Within an explicitly specified list, an intermediate hop can be strictly
connected or loose hop. In case of explicitly specified loose next hop, a receiving node calculates the
path to reach remote loose hop and generates a list of strict hops to be taken in order to reach loose hop
[13].  The traffic parameters TLV is used within the label request and label mapping messages, and is
used to describe the traffic parameters for a CR-LDP. The five traffic parameters – PDR, PBS, CDR, CBS
and EBS, are used to set different values for different service classes [14]. The output of the CBS is the
amount of traffic entering into the network, and is policed or shaped based on token bucket criteria. The
fields related to traffic characterization within TLV includes [14]:

Analyzing IP/MPLS as Fault Tolerant Network Architecture
35
Peak Data Rate (PDR): The maximum rate of traffic that can be sent to CR-LDP established LSP.
Peak Burst Size (PBS): The maximum packet size that can be sent to the CR-LDP established LSP.
Committed Data Rate (CDR): The policed traffic to be sent across the network.
Committed Burst Size (CBS): The maximum size of token bucket.
Excess Burst Size (EBS): Instructs what to do with violating packets (mark or drop).









Figure 3.2 – CR-LDP Message Flow [14].

Once the label message reaches the egress LSR along the TE shortest path, it checks the resources
availability. If it has the capacity to accommodate new LSP it assigns the label for this particular flow
and sends label mapping message. Each upstream node assigns specified resources in label mapping
message and provides labels towards upstream, this way the CR-LDP is setup across explicit specified
path [13].

3.2 RSVP-TE
RSVP-TE is another option used by head end LSR to signal the TE-LSP along the explicitly calculated
path. RSVP-TE is not a new protocol to carry signaling information, but it is an extension to the original
RSVP protocol. RSVP has been used to signal QoS information along the IGP path in IP IntServ
(Integrated Service) Architecture [17]. Within IntServ architecture, RSVP is deployed to create a session
in between end devices on per flow basis, resulting in a large number of RSVP states to be maintained at
each intermediate node [13]. While RSVP-TE has much less number of RSVP sessions by its inherit
aggregation mechanism, which allows traffic to be aggregated within single TE tunnel [8].  RSVP also
provides policy control and admission control along explicit path to be taken by the packets.

Analyzing IP/MPLS as Fault Tolerant Network Architecture
36
Another advantage of using RSVP-TE inside a network is independence from IGP. An RSVP-TE LSP no
longer follows the IGP shortest path, and LSP can be created along multiple IGP areas as required. The
basic flow of RSVP messages can be found at [11]. RSVP messages exchange between TE-LSR to setup a
TE-LSP include [8]:
 Path Message
 Resv Message
 PathTear Message (Terminate session and release resources)
 PathErr Message (Generated if LSP setup fails)
 ResvTear Message (Generated by Egress Edge)
 ResvErr (Generated whenever an LSP gets preempted)












Figure 3.3 – RSVP Message Exchange [8].

The creation of an RSVP-TE LSP is initiated by the ingress LSR (say LSR-A) by sending Path message.
The destination address of Path message is the Egress LSR (LSR-D). An RSVP-TE is going to pass set of
nodes which are no longer along the shortest path. To request an intermediate LSR for its participation,
the Path message has the “Router Alert option” turned On [8]. Router Alert option can alert an
intermediate LSR that a packet needs close inspection and make any necessary modification to it (in case
of loose next-hop or record its own address in RRO). The object contained in RSVP-TE Path message
includes [18]:

Analyzing IP/MPLS as Fault Tolerant Network Architecture
37
Label Request Object: Requests an MPLS label along the path.
Explicit Route Object (ERO): A specified list of next hop IP addresses (can be loose or strict).
Record Route Object (RRO): To verify path taken by Path message as specified path in Explicit Route
Object (ERO).
Sender TSpec: The traffic requirement for a particular flow as requested by ingress LSR.
Session Attribute: Contains priority values (for LSP setup, hold) and certain flags.

The Path message once reaching the egress LSR, the egress LSR checks for amount of resources required
for this circuit setup. If it has as much resources as specified in Sender TSpec, it assigns required
resources for the circuit to be established. In response to Path message the egress LSR generates Resv
message. The Resv message is sent towards the adjacent LSR upstream, rather than addressing directly
towards source LSR [8]. This ensures that Resv message follows the exact same path as taken by the Path
message. The RSVP-TE objects inside the Resv message include [18]:
Label Object: Contains the label used for this section of the LSP (Label has local significance)
Record Route Object: Recorded path taken by the Resv message, it should be consistent with the ERO.
Sender_TSpec: Copied from Path message into Resv message to reserve the hold resources for this LSP.

RRO can further help in detecting loops [8]. The RSVP PathTear message is generated by the source to
remove reservations along the TE-LSP path. The RSVP PathErr message is originated from the point of
failure towards headend LSR if requested resources are not available at particular LSR along explicitly
specified path and preempting an already setup LSP also does not provide required bandwidth
constraints. A PathErr message also initiates LSA of TE information from that particular node generated
PathErr message, as it believes that the head-end has no up to date information stored in its TED
regarding network statistics resulting in wrong computation [13].

IntServ is said to be hard QoS [16], as it reserves required resources along a path using RSVP signaling,
ahead of time for a particular flow. Whereas DiffServ, is a form of soft QoS [16], as it only differentiate
among type of traffic at each hop and performs QoS accordingly, without reserving particular resources
for each FEC. There is no guarantee in DiffServ domain that a particular traffic is able to get required
resources, along the path towards final destination. MPLS-TE takes advantage over both IntServ and
DiffServ architecture. Like IntServ, it reserve resources along the path using RSVP-TE signaling protocol
for a particular type of traffic flow and then perform PHB (Per-Hop-Behavior) at each intermediate LSR
Analyzing IP/MPLS as Fault Tolerant Network Architecture
38
to get the resources along the pool of reserved resources, like DiffServ approach. The PHB in MPLS
domain can be extracted from the EXP bits specifying packet precedence in MPLS domain. MPLS label
information itself can be used to specify PHB at an intermediate node. If an LSP uses EXP bits it is said
to be E-LSP [8]. If a PHB behavior deduces from both the label and EXP bits then the LSP is known as L
LSP [8]. In case of L-LSP, the MPLS label itself informs about traffic class precedence and EXP bits
specify the drop precedence within a label specified class [10].

Once the MPLS-TE LSP is established along the path, next step is to map the traffic to these LSP, so that
a particular flow requirement is fulfilled and to forward all traffic from a particular source towards a
destination. This can be done through static mapping [8] in its simplest form. PBR [13] can be used to
direct specific mission critical traffic towards a specific LSP. This mechanism extends ingress LSP
capability in providing admission control at head end. A benefit of MPLS-TE LSP is that it can be
advertised as a route in the routing updates inside an IGP area. Once advertised the MPLS-TE towards a
certain destination, the other IGP nodes takes into account this MPLS-TE for its link state calculation and
hence normal traffic can use TE-LSP to forward traffic towards a destination. TE LSP can be advertised
with a configured IGP metric and other LSR take care of this TE-LSP while calculating SPT [8] [13]. For
distance vector like RIP, MPLS-TE LSP is considered as a link in between two distinct nodes with hop
count value equals to 1 [11]. The LSR connected over the MPLS-TE LSP are considered as directly
connected neighbors. The TE LSP has to be advertised by both the source head-end and destination
tailed towards each other with equal IGP metric [13]. This is because an LSP is a unidirectional tunnel,
once both end advertise a unidirectional LSP, it acts like a normal link.

Re-optimization is also done upon the TE-LSP; as a new link with better metric comes up or head-end
found a better path to route traffic [13]. As TED gets update MPLS-TE performs such optimization using
make-before break rule. Make-Before-Break suggests reserving resources along the new path before
removing the existing LSP [8].  This may result in double booking of resources along some links, but
MPLS-SE (shared Explicit) [8] style helps alleviate such double bookings, only the highest bandwidth
requirement taken into account [13] across links is effected by double booking. SE style is signaled by
tunnel head-end using a flag in Session Attribute object inside RSVP Path message [16] mentioning that
there is already a tunnel active for this session.

Analyzing IP/MPLS as Fault Tolerant Network Architecture
39
RSVP runs over UDP and it requires periodic refreshment along the path. RSVP performs full fledge
state refreshment on hop-by-hop basis [13]. RSVP uses downstream on-demand label allocation scheme
with ordered control, as CR-LDP. RFC-2961 introduces a summary refresh extension to RSVP, known as
“Refresh Route Reduction” and it is used to refresh a number of LSP states per RSVP Path message.
RSVP also has optional node failure detection mechanism [8] using a periodic Hello exchanged in
between the RSVP neighbors. Without this mechanism failure detection is only caused by RSVP session
timeout, which is time consuming process. There is no concept of ECMP in RSVP, RSVP-TE only creates
a single TE path and traffic is traversed over that tunnel towards a destination. This greatly benefits the
packet order at destination as packets along a single path take exactly the same sequence as they sent
down the tunnel; this reduces the effort to be done by an end system application in reordering packets.
As mentioned, not every end system application is running over TCP for its reliability mechanism for
reordering or retransmission. Reordering issue is solved at this point across an explicitly specified single
path taken by all the packets, now it is time to avoid retransmissions by avoiding failure situation inside
a network or recover from failure with the minimal downtime without degrading network QoS.
Requirement to alleviate packet loss puts additional burden on underlying infrastructure to provide
such services as guaranteed. MPLS-TE takes care of this fact and provides these services in form of
MPLS-TE LSP and MPLS-FRR.
















Analyzing IP/MPLS as Fault Tolerant Network Architecture
40
Chapter 4
Fault Tolerance with IP/MPLS-TE
MPLS-TE section describes how MPLS network carries traffic with QoS guarantees while working as
overlay architecture across the IP network. Applications require guaranteed services not in period of
normal condition of a network, but also following a failure. As mentioned earlier, end system
applications are not always implemented over TCP for reliability to retransmit or reorder packets. Real
time applications like voice, video often use UDP as underlying protocol. UDP is connection less and IP
is only providing best effort delivery mechanism. IP has nothing to do with failure or packet loss, it
solely depends upon end system to cope with such situation. Further it is not likely feasible to construct
a stream that has been lost along the path. The number of packet lost during failure scenario or during
re-convergence period has severe effect over network service quality.

One way to provide fast recovery following a link failure is to provide protection at layer 1, as used by
SONET APS (Automatic Protection Switching) [10]. But SONET APS is only a hardware solution to this
problem, and requires extra hardware provisioning at both side of a link and bandwidth along standby
link remains idle until primary path goes down. This has limitations as a network is a combination of
different link types connected to different devices, and not all of them provide SONET connections.
MPLS-TE replies to such failure situations in term of Fast Reroute (FRR) mechanisms, which help
network operators within MPLS domain to provide strict QoS guaranteed for end system applications.
Before MPLS FRR capabilities TDM (Time Division Multiplex) systems was used to carry traffic with
tight SLA (Service Level Agreements) [13]. MPLS FRR provides ground towards convergence of all
services on the same core over IP/MPLS-TE [8].

MPLS FRR is not restricted to specific link types, requires no extra hardware and provides FRR in case
of link and node failure [8]. The switchover is a very fast process. APS provides 50millisecond [13]
switchover onto backup path. So, FRR should also provide such fast recovery in case of node and link
failure. No matter how fast the mechanism for moving traffic along the backup path around the point of
failure is, it is useless without fast failure detection. The amount of traffic lost during a failure depends
Analyzing IP/MPLS as Fault Tolerant Network Architecture
41
upon how fast the failure is detected [8]. Fast failure detection remains a core concern for FRR. There are
certain built-in and separate methods deployed for this purpose.

4.1 Failure Detection
The ability to detect failure in timely manner is considered as the first step towards recovery [8] and it
must be done closer to physical layer for efficiency purpose. Some transmission media provides
hardware indication upon connectivity loss and break in a transmission link is detected within
milliseconds at physical layer. But hardware detection mechanism is not available for most of the time.
This task can be accomplished through a higher layer protocol. The different choices include [8] [13]:
 IGP Failure Detection
 RSVP Hello Detection
 Bidirectional  Forwarding Detection (BFD)

IGP Failure Detection
IGP neighbors exchange Hello messages with each other across a link to ensure connectivity with each
other. When a Hello (as keep alive) stops arriving, a failure is assumed. Hello and Dead timers are
configurable entities in an IGP configuration and provide the minimum bound for failure to be detected.
[8, 13] present reasons why hello-based failure detection using IGP hello can not provide fast detection
times:
1. IGP neighbor can miss more than one Hello messages (depends upon configured Hold down
timer) without considering other end as dead. This failure detection is 3 seconds for OSPF and 1
second for ISIS in typical protocol configuration.
2. Handling IGP hellos is relatively complex and costly in term of CPU cycles. Hello packets need
to be processed by the central CPU and keep track of the Dead timer for a specific neighbor to be
considered dead. Dead timer is reset as Hello packet is received and processed by the central
CPU.
3. IGP failure detection initiates a series of steps (as: SPF calculation, Advertisements) to be
performed once a change inside a network occurs.



Analyzing IP/MPLS as Fault Tolerant Network Architecture
42
RSVP Hello Detection
As mentioned before, RSVP is a soft state protocol requiring periodic refreshment. RSVP Hello enables
RSVP nodes to detect when a neighbor node is not reachable. This is node to node link failure detection
[13]. RSVP hello configuration is needed at both side of a link. RSVP hello based detection is considered
sufficient for failure detection in local protection and its convergence is faster than plain IP or MPLS-TE
without FRR [16]. Large number of Hello messages in between two adjacent LSR results in high CPU
utilization and put strain on router resources. So RSVP Hello instance is only created once required and
deleted when no longer needed.
Active Hello Instance: This RSVP instance is used if an LSR is ready for fast reroute. It generates RSVP
Hello message periodically and expects Hello ACK in response.
Passive Hello Instance: It is created as a response to RSVP Hello message, by sending Hello ACK
message on an interface and deleted afterwards. It does not initiate RSVP Hello Request message and
does not cause an LSP to be fast rerouted. It does not keep track of the attached interface on its own;
rather it only works in response mode.

Bidirectional Forwarding Discovery
BFD is a lightweight generic protocol developed for fast detection by IETF [19]. It detects faults in
bidirectional paths between two forwarding engines in timely manner at uniform rate [16]. It can work
in echo mode, without causing the other end to participate in running BFD. BFD control packets are
used, to detect live-ness like Hello protocol but in more accelerated fashion. BFD informs forwarding
engine only once, as it detects failure to forwarding engine. BFD contributes in reducing the overall
network convergence time. BFD is able to detect failure in the range of 10s of milliseconds [8]. That is a
huge improvement over detection time in order of seconds. It can be enabled on per interface basis or
routing level. BFD is thus not related to any specific protocol.

4.2 MPLS-TE Protection Mechanisms
MPLS-TE LSP greatly benefits from BFD fast detection mechanism. The next step to fast failure recovery
is how to protect traffic loss over a logical resource like LSP from physical resource failure (Node or
Link). MPLS-TE capability provides diverse protection mechanisms to ensure guaranteed quality of
Analyzing IP/MPLS as Fault Tolerant Network Architecture
43
service in IP/MPLS network. Each mechanism has its own advantages and drawbacks inside an MPLS
TE domain. Protection mechanisms provided include:
 Path Protection
 Local Protection
 Link Protection
 Node Protection
 Bandwidth Protection

4.2.1 Path Protection
End to end full path protection is often desired. A common practice is to use a secondary path besides a
primary path for resiliency purpose. MPLS Path Protection is a response to such scenarios, when a
primary path is an LSP tunnel. With path protection, a secondary LSP is created in addition to a critical
primary LSP, that traverse set of LSR that are along another SRLG (Shared Risk Link Group) than
primary path SRLG . To get more out of this mechanism a secondary LSP should be signaled ahead of
time, in effect being in hot standby mode [8]. There is 1:1 relation between a primary and backup tunnel
[13], they can have same characteristics (bandwidth requirement).









Figure 4.1 – MPLS Path Protection [8].

SRLG is sequence of links affected by a single incident, hence a group of resources being affected by a
single failure situation. Once a failure is detected along the primary LSP, a RSVP PathErr message is
originated from the point of failure and forwarded towards head end [13]. Upon arrival of this error
message, the head end LSR shifts traffic over an already signaled secondary path. A problem with such
failure detection mechanism is that, an error message has to reach head-end which may consume
Analyzing IP/MPLS as Fault Tolerant Network Architecture
44
variable time and traffic lost for an amount of time along the broken LSP. A path protection may
provide unnecessary protection in case some links along a path protected by other mechanism (like
APS). Further, if there is a failure in secondary path then there is nothing to be done by the head end.

Enhanced path protection can be achieved using multiple backup paths [13] for a single critical LSP;
with a restriction that only one backup path can be signaled ahead of time. Path diversity (using
different SRLG) should be taken into account for multiple backup paths. With path protection one can
be sure about the exact path taken by traffic in case of failure, it is an important aspect to ensure
properties like low delay [8].

4.2.2 Local Protection
To minimize failure detection time at the head end during which traffic is lost, protection should be
applied as close to point of failure as possible [8]. Local protection attempts to fix issues inherit by path
protection by providing local protection, without involving the head-end LSR for rerouting the traffic.
Local protection achieves this through Fast Reroute (FRR) mechanism, by creating a Detour (bypass)
path [8] around a failed recourse. It has the advantage that not only the traffic will follow locally
repaired path, but also RSVP signaling will pass over it and the TE tunnel will remain signaled [13] for
the duration of FRR along a failed resource. MPLS FRR is a local decision, besides IGP convergence
which is a distributed operation and IGP capable nodes have to agree upon a common topology
(centralized computing) before traffic starts passing around a failed resource [16]. MPLS FRR is a local
repair method and PLR (point of local repair) has no complete view into the TED as head-end, so it is
possible to pick and choose which resource to protect. PLR merge a backup tunnel along primary path
just ahead of failed resource at the Merge Point (MP). Comparing with end-to-end path protection, FRR
benefits from speed of recovery and provides deterministic delay (in order of 10s of milliseconds with
BFD). Two protection schemes are available [8] [13] [16]:
 Link Protection
 Node Protection




Analyzing IP/MPLS as Fault Tolerant Network Architecture
45








Figure 4.2 – MPLS Local Protection [8].

The number of LSP protected by the protection tunnel can be either 1:1 or N:1. These are so called One
to-one backup” or “Facility backup”, respectively.
One-to-one backup: Upon failure, each FEC along the failed resource is backed up with a tunnel for
each FEC towards their destination.
Facility backup:  The next hop following a failed node/link is the merger point for all traffic passing
around a failed resource.

A protection schemes once combined with backup schemes, leads to a total of four different variants for
MPLS FRR [8]:
1. Link Protection with facility backup
2. Link Protection with one-to-one backup
3. Node Protection with facility backup
4. Node Protection with one-to-one backup

An LSP which requires local protection, the head-end sets “local protection desired flag” in RSVP
Session Attribute object and Fast Reroute object [8] for that LSP. This local protection flag is taken care of
by every LSR downstream. The downstream LSR which has protection available in form of backup path
replies to head end with the “Protection Available flag” [8].


Analyzing IP/MPLS as Fault Tolerant Network Architecture
46
Link Protection
With link protection FRR scheme, a single TE link along an LSP is protected. All traffic passing over that
link is protected by bypass tunnel (facility backup).  A complete link with all its TE LSP is backed up.
LSP is unidirectional, so it does a bypass tunnel. For two way communication, a backup tunnel is
required in each direction. The bypass tunnel, protecting a single link is called Next-Hop (NHOP)
bypass tunnel [20], because bypass tunnel merge at primary LSP at next hop following a failed link [8,
11]. A NHOP tunnel can cross many hops, but it is restricted to merge at next hop (MP) across a failed
link. RSVP-TE signaling is used to create this backup tunnel and provide a label to be used over NHOP
tunnel.









Figure 4.3 – MPLS Link Protection [8].

A single label is increased at PLR for NHOP bypass tunnel (A-C-D-B), so this must be taken care of in
advance by configuring MPLS MRU along all links carrying NHOP tunnel. The only difference at LSR-B
is that labeled packets arrive from another interface, but it has no effect as long as per-platform label
space is used [13]. LSR-D will become PHP router for this NHOP tunnel.

PLR carries traffic along NHOP tunnel temporarily. As failure is detected along a protected link, PLR
first repairs the tunnel locally and then propagates RSVP PathErr message towards head-end reporting
that the tunnel is “locally repaired” at some point downstream [13]. Upon receipt RSVP Path message
with local repaired flag turned-on within the Session Attribute object, the head-end does not mark this
tunnel as down, but instead keeps forwarding traffic over it and tries to compute a better path to reroute
failed LSP traffic. The PLR takes care of traffic and signaling messages (Path, Refresh message) along
failed link during the time FRR is active, by sending control messages and application traffic over to the
Analyzing IP/MPLS as Fault Tolerant Network Architecture
47
NHOP bypass tunnel. PLR is now the sender of RSVP Path message [8]. If head end LSR is unable to
find a better path for failed LSP to switchover, the PLR will keep forwarding traffic along backup path.
As tunnel is locally repaired by PLR, so ERO will be different from RRO in RSVP Path message [13].

IGP neighbors along either side of failed link also generate link state update upon failure detection. This
IGP updates reach every router in an IGP area and they try to calculate a path towards destination
ignoring the failed link. This IGP update has no effect over tunnel head end LSR, as it has already got
RSVP PathErr message with local repair flag SET. If somehow, head-end does not get RSVP PathErr
message, it will wait for RSVP PathErr and only mark the tunnel down upon receipt of RSVP PathErr
without local repair being active from a downstream node. IGP advertisement also reaches tail end LSR,
but as FRR link protection was desired along protected LSP, the tail-end also discards this update. The
new sender of RSVP Path message is now PLR, tail end knows that Path message is coming from a new
sender but it still belongs to same session (based on session id information) and it will never generate
ResvTear message [13].

At any time a number of LSP passing through the protected link will reserve a lot of bandwidth over the
link. Upon failure it might be possible that, not all bandwidth for each LSP is available along the NHOP
bypass tunnel and traffic might get dropped [8] in this case. Link protection takes advantage of being
temporary repair, once the head-end LSR establish a new path, traffic is shifted over new LSP and
resources reserve along failed LSP are released using PathTear message. If not enough bandwidth is
available along single NHOP bypass tunnel then multiple tunnels for each traversing LSP can be created
using 1:1 protection tunnel method[8] [13].

Node Protection
MPLS FRR local protection also provides a way to protect all traffic passing an adjacent node. Node
protection also covers link protection, because it is not sure for most of time what the immediate cause
of link failure is. Failure may be because of failure in link itself or the next hop LSR may be down. Link
protection alone does not cover this aspect of failure. The reason is that if both link and node protection
is configured at a PLR, then following a failure, PLR picks a node protection tunnel for forwarding
traffic. Node protection tunnel is called Next-Next Hop (NNHOP) bypass tunnel [20], as the MP for
NNHOP tunnel is not the immediate node following a link but one more hop away following a
protected node (facility backup).
Analyzing IP/MPLS as Fault Tolerant Network Architecture
48












Figure 4.4 - MPLS Node Protection [8].

NNHOP tunnel is avoiding a protected node during failure, but RSVP ERO still carries the IP address of
the protected failed LSR even when the LSR is bypassed [13]. There are some aspects to be taken care of
while using the NNHOP bypass tunnel. Looking at figure 4.4 provided at [8], one can see that LSR-A
needs to know about the incoming label used by main LSP at LSR-Z and IP address of LSR-Z.

Address of LSR-Z can be obtained from RRO or ERO in RSVP Path or Resv messages. To get the label
used as an incoming label at LSR-Z, RSVP Session Attribute object has been extended with “Label
Recording Desired” flag [8]. Upon receipt of this Session Attribute object at an intermediate LSR, it
records the assigned label for a particular prefix in RRO label sub object. So while using node protection,
label recording is required and it provides label information at the specific node.

4.2.3 Bandwidth Protection
Ability to guarantee that enough bandwidth is available along the protection path is referred as
bandwidth protection. It is often desirable to provide certain level of service quality for critical
applications during failure. With Node and Link protection, backup tunnels can be used to protect
bandwidth along backup path. The head-end informs the PLR about the amount of bandwidth required
per LSP going through PLR and backup bandwidth required in case of failure, using a new “Bandwidth
Protection” flag in Session Attribute and Fast Reroute Objects [8]. Once PathErr message with tunnel
Analyzing IP/MPLS as Fault Tolerant Network Architecture
49
local repair flag set is received by head-end it sends only that much amount of traffic into the locally
repaired tunnel as it requests following a failure from PLR. With large number of LSP requiring
guaranteed backup bandwidth, PLR has to take care about each LSP requirement and create a back LSP
for each protected LSP with guaranteed backup bandwidth towards NHOP or NNHOP. Bandwidth
protection also allows load balancing among the backup tunnels in case a single tunnel is unable to carry
such bandwidth constraints.

MPLS Differentiated Service aware Traffic Engineering (DS-TE) [13] allows per class TE capability across
an MPLS domain. DS-TE once integrated with MPLS-FRR, provides fast reroute mechanism on per-class
basis. It helps in controlling properties of traffic belonging to different classes on network links. DS-TE
acts as control plane mechanism, while IP DiffServ acts as forwarding plane mechanism [16]. DS-TE
reservation is only in control plane, not in the forwarding plane. DS-TE divides maximum reserve able
bandwidth (configured value) among the flows, whereas IP DiffServ divides link rate among the flows
[16]. There is no guarantee that the resources reserved across a link in MPLS-DS-TE can be available
once traffic reaches there, so it is the responsibility of head end to do proper admission control for a
particular LSP. Out of band traffic can be either marked or dropped, affecting the QoS [8]. A backup
tunnel without explicitly specified bandwidth can use unlimited bandwidth across the links [13].

LSP priority allows considering some LSP more important than others. In absence of priority values
assigned, a resource can be used by less important LSP. An LSP contains preemption priority value and
hold priority value [13]. These values are used to setup LSP and preempt already setup LSP if a LSP
with better hold value arrives [8]. For a stable design hold priority must be less (better) than setup
priority [8, 13]. MPLS-TE defines eight priority levels (0 through 7).

DS-TE uses the concept of Class Type (CT) for the purpose of link bandwidth allocation among different
traffic types. MPLS EXP field is a three bit value so a network can use up to 8 CT (CT0 – CT7) [8]. DS-TE
also supports the TE LSP preemption within CT or across CT [13].  CT is corresponds to IP DiffServ PHB
Scheduling Class (PSC), so flexible mapping between PSC (total 64) and CT (total 8) is possible. A DS-TE
class defines a combination of a CT value and corresponding preemption priority. DS-TE introduces
new “CLASSTYPE RSVP object” in RSVP Path message [16].

Analyzing IP/MPLS as Fault Tolerant Network Architecture
50
MPLS, Bandwidth Constraint (BC) models are responsible for allocating bandwidth among different
MPLS Class Type (CT). The percentage of bandwidth used by a particular CT or group of CT is called
BC [RFC: 3564]. Each link across the TE domain has a set of BC configured, while admitting a new TE
LSP on a DS-TE link, the node uses BC rules to update the amount of unreserved bandwidth for each
TE-Class being affected. With DS-TE, as PLR receives Path Message with Session Attribute object
mentioning the CT and backup bandwidth, it will only create a tunnel towards NHOP or NNHOP
which meet such criteria. MPLS BC models include [8]:

Maximum Allocation Model (MAM): The link bandwidth is divided among different CT and traffic
belonging to one CT can not use resources (bandwidth) of any other CT unused bandwidth configured
on that link. It maps one BC to one CT in 1:1 fashion.  A packet scheduler managing congestion in
forwarding plane typically guarantees bandwidth sharing [21].






Figure 4.5 – MAM Model [8].

Russian Dolls Model (RDM): It improves bandwidth efficiency over MAM by allowing bandwidth
sharing among different CT. Bandwidth reserved for CT0 (global pool) can be used by any other sub
pool CT (CT1 -  CT7) on demand. Each CT provides bandwidth sharing to higher CT values [8]. Figure
4.6 shows only three CT values for simplicity.







Figure 4.6 – Russian Doll Model [8].
Analyzing IP/MPLS as Fault Tolerant Network Architecture
51
Bandwidth demands change over time. The tunnel head-end configured for auto bandwidth [8],
monitors the traffic statistics and periodically adjust bandwidth requirement according to current flow
[13]. A new path can be calculated (LSP Re-optimization) based on new bandwidth requirements, using
“make-before-break” rule.

4.3 LDP Fast Reroute
The local protection schemes discussed so far applies with RSVP-TE signaling. Critical applications
running over LDP or specifically CR-LDP based MPLS-TE networks also require same resilience from
underlying architecture. The fundamental difference between CR-LDP signaled LSP and RSVP-TE
signaled LSP, is due to the fact that CR-LDP based CR-LSP always follow IGP-TE shortest path and IETF
restricts further work on any flavor of LDP [8]. Thus LDP is influenced by IGP convergence, but RSVP is
not. This is the reason to develop fast reroute mechanism in IP network, known as IP-FRR [8].

Tunnel based approach for LDP switchover provided in [8] can be a solution once LDP traffic reaches a
defined PLR and then PLR transmit traffic over to RSVP-TE signaled bypass tunnel towards NHOP or
NNHOP. An end-to-end LDP fast reroute LSP can be established by creating NHOP or NNHOP RSVP
TE tunnels across every node along an IGP shortest path and use LSP Stitching [8] mechanism to join
separate RSVP-TE tunnels together to make an end to end protection path.  LSP Stitching is mostly used
for establishing inter domain RSVP-TE tunnels, where each domain is responsible for routing traffic
through its own administrative domain. The stitched TE LSP across IGP path is susceptible to change as
IGP shortest path change over time, it is not a guarantee that traffic following LDP path will reach PLR
and pick up an RSVP-TE backup tunnel. This scenario can be useful for controlled environment where
IGP paths are not prone to change so often.

A general solution to this issue is an alternate path approach [8]. Alternate path relies on maintaining an
alternate path towards a destination and taking into account this path as failure is detected at PLR. IGP
routing protocols specialized for TE do not use the concept of alternate path. An IGP only considers
more than one path towards a destination, if there are ECMP and so there is a possibility for load
balancing across multiple paths. A new technique called IP LFA (Loop Free Alternative), adds a pre
signaled backup next hop into the forwarding plane. LFA provides consistent 50 millisecond IGP
convergence without adding additional burden on nodes. Introduction of LFA in IP network provides
automatic FRR capabilities inside LDP network.
Analyzing IP/MPLS as Fault Tolerant Network Architecture
52
Failure detection first occurs in forwarding plane, which signals this information to control plane. Upon
notification of failure, the routing protocol performs series of steps as mentioned earlier in the
Introduction section resulting in global repair. LFA enhances IP network capability to deliver loop free
rerouting without involving control plane after a failure. LFA performs local repair and an alternate
path is pre installed which gets locally activated once forwarding engine detects link failure. Local
repair path will stay active as long as global repair completes its task and IGP-TE area converged upon a
TED.









Figure 4.7 – LDP Fast Re route [8].

RFC-5286 [22] defines this process as forwarding traffic over Less Equal Cost Multiple Path (LECMP),
used specifically for connectivity restoration. As long as a LECMP can not create a loop it can be used as
an alternate path. LECMP that does not create forwarding loops is said to be a LFA. A LFA enabled
node performs calculation in advance to determine a backup path. RFC5268 [22] also specifies criteria to
be met, so that a LECMP can be considered as LFA for a particular destination:
Distance (N, D) < [Distance (N, S) + Distance (S, D)]

Where, S is source that requires LFA. N, is a Neighboring LSR. D is Destination to be reached through
LFA. If the above equation is satisfied then N is considered as LFA for Source S with respect to
destination D. This calculation can be done by any TE enabled node because LSRP share a common
topology database. Any node can compute cost to reach a specific destination with respect to some other
node.


Analyzing IP/MPLS as Fault Tolerant Network Architecture
53
Chapter 5
Network Model and Simulation
The methodology taken into account for this thesis work is described in this section. This chapter further
describes our intended model under study and how to implement it in OPNET Modeler [25]. The
version of OPNET used for this work is 14.5. OPNET is short for Optimized Network Engineering Tool
and it has its roots in study and research related to computer networks [25]. OPNET Modeler provides a
comprehensive development environment supporting the modeling of communication networks and
distributed systems. It helps the interested personals in collecting behavior and performance of OPNET
modeled network systems which can later be analyzed by performing discrete event simulations.
OPNET Modeler can be used as a platform to develop models of a wide range of systems that includes
[25]:
 Standard LAN/WAN performance modeling
 Internet work planning
 Resource sizing
 Research and development of advanced distributed network environment

We use OPNET as a simulation tool to model our network design being investigated while keeping in
mind our final goals. When the model is in a complete form, built in simulations are run to actually
study the system's behavior and performance. But, before running simulations, the user must consider
what information is to be obtained from the modeled environment. In the case of most simulations, a
large number of system variables and metrics are available for collection. Each OPNET module at the
node level, as well as link at the network level is the source of a significant number of built-in local
statistics, and in addition a simulation can generate large numbers of global and local user-defined
statistics. But in general, only a small subset of the available data is of particular interest [25].

For collecting the results OPNET works as an active network monitoring tool. The active network
monitoring tools sends the additional traffic into the network. Active monitoring is done through probes
that do not affect the network characteristics in anyway. Probes aim to emulate the actual network
traffic, and are sent among the active network agents (devices).  The agents measure the received
Analyzing IP/MPLS as Fault Tolerant Network Architecture
54
streams and typically keep a statistical analysis of measured results, which can be interrogated
periodically by the active monitoring device. The active network monitoring is in contrast to passive
network monitoring where each network device records statistics on actual network traffic result
passing through it as an indication of status at a particular network element. Periodic polling is typically
used to gather data residing at different nodes for reporting and analysis. Hence, passive monitoring
looks at each device in isolation and by looking at multiple devices an aggregated view of the status of
the network is deduced [21].

Once the simulation ends with the desired fields turned on, this corresponds to specific metrics.  The
next step is to analyze the results achieved through the Result Browser inside OPNET. The Results
Browser is used to display information in the form of graphs. A graph is the part of the result browser
that can contain statistics. With this understanding about the OPNET, the remaining section deals with
the simulated environment regarding this thesis work.

5.1 Assumption
The research aim is to find out which and how a network architecture feature is more reluctant to
network brownouts (congestion) and blackouts (failure) situations, there is a need to implement
multiple network scenarios based on a consistent physical network design. This can help in
understanding and in comparing different results achieved through a single model with different
scenarios. QoS consideration only comes into play when network gets congested which results in
increased packet jitter or drops. To better understand IP/MPLS technology in accordance with the QoS
and fault tolerance, the backbone network links provided here are smaller factor of the local links, which
helps in alleviating the bottle neck links outside the network being observed. This design visualize the
participation of different network application across the core links, and how the backbone nodes handle
different application traffic requirements as a prescribed bounded element.

5.2 OPNET Model Configuration
This section will describe which and how different network elements are placed to constitute a desired
network topology inside an OPNET. To study the characteristics of the intended work, the baseline
network topology will remain consistent. Only the configuration on the interacting nodes will differ,
Analyzing IP/MPLS as Fault Tolerant Network Architecture
55
according to study objectives. The network components as used in this thesis work from OPNET library
includes:
ethernet2_slip8_ler: “ler” stands for Label Edge Router. It has 2 Ethernet ports and 8 serial interfaces for
WAN PPP connections. It simulates a main component in MPLS domain, working at the edge of the
MPLS domain, to connect to other non-MPLS/MPLS networks. The same “ler” router can be used to
simulate an IP or MPLS domain end node; it is only the configuration that dictates how to work in a
respective configured environment. It provides the IP layer functionalities as routing and runs IP
routing protocols. Once enabled to MPLS, it works as a boundary router in MPLS domain and is able to
PUSH or POP label as required.

ethernet2_slip8_lsr: “lsr” stands for Label Swapping/Switching Router. It has 2 Ethernet ports and 8
serial interfaces for WAN PPP connections. It is simulated as a core MPLS network component. It
resides inside an MPLS domain and used specifically for the purpose of receiving an incoming labeled
packet, to swap the label and forward to the next hop along the LSP. Once enabled for MPLS and
working as lsr, it constructs the LFIB based on advertised labels and performs only label swapping
functionalities.

ppp_adv: Point-to-Point serial full-duplex link at the explicitly specified rate in bps and is used to
simulate the link in between the routers. For convenience, all core links are 5Mbps duplex links. The low
bandwidth serial links are used specifically to study the application characteristics at the network core.

ethernet_wkstn_adv: Ethernet workstation OPNET element is used to simulate the network users. It
consists of single Ethernet connection at a selected rate, directed by the underlying medium used to
connect to an Ethernet switch. Advanced station is chosen specifically for the reason to implement RSVP
in the simulated network. The destination preference is configured to reduce the service server
resolution time and traffic. This module is used to simulate single end user in our network design, using
different applications.

ethernet_server_adv: Ethernet server provided in OPNET is used to simulate the service server in the
network. It contains one Ethernet connection to the switch, facilitating that subnet.

Analyzing IP/MPLS as Fault Tolerant Network Architecture
56
ethernet16_switch: This OPNET module simulates the Ethernet switch with total 16 ethernet ports
available, on either side of the “ler”. The end devices, ethernet_server_adv and ethernet_server_adv are
connected to this module using different link types, as specified.

100BaseT:  This full duplex link is used to connect, ethernet_server_adv to the ethernet16_switch.

10BaseT: These links are used to connect ethernet_wkstn_adv to the ethernet16_switch.

10Gbps_Ethernet:  This high speed full duplex Ethernet link is used to connect “ler” to the associated
West switch, on both side of the network. High speed link is used specifically so that the application
inherits no congestion over the interfaces outside the simulated network core.

1000BaseX: This link is used to connect East switch to associated “ler”.

MPLS_E-LSP_DYNAMIC: As the network topology is configured for MPLS, the LSP are built
automatically inside the network. But those LSP follow the IP shortest path in between two nodes. To
develop an explicit LSP around the network, this OPNET element simulates the behavior of such
dynamic LSP. If not configured with explicit nodes along the LSP path, the dynamic LSP adjusts itself
with the changing network scenarios with guaranteed resources along the network. For most of time, an
LSP with explicitly specified route is used. A dynamic LSP is signaled using RSVP or CR-LDP, at the
simulation startup. CR-LDP makes use of the dynamic routing protocols to calculate the dynamic LSP
towards a certain destination, as mentioned in its explicit path [25].

MPLS_E-LSP_STATIC: Static LSP are not signaled during the startup. Static LSP allow more routing
control but fewer resiliencies to node or link failure [25].

Despite the fact that dynamic LSP behaves better following a failure, this thesis work takes into account
both options for MPLS LSP to better understand the network characteristics following a failure. Besides
the above mentioned OPNET network elements, there are certain OPNET control elements, used to
configure policies, network wide configurations and adjusting scenarios. The OPNET control objects
used in this thesis work, which includes:

Analyzing IP/MPLS as Fault Tolerant Network Architecture
57
Application Config: This element is used to tell OPNET which application is going to be modeled upon
the underlying network. A single Application Config. is used to instruct OPNET for multiple network
applications. Application parameters for different application types being observed are configured in
this element.

Profile Config: Profiles describe the activity patterns of a user or group of users in terms of the
applications used over a period of (simulation) time [25]. There can be several different profiles running
on a given network under observation. User profiles have diverse properties, so configuring a certain
profile with a specific application is done here. The configured profiles are then assigned to the network
users.

QoS Attribute Config: Different QoS criterion to be implemented in network topology that helps better
understand the traffic characteristics is configured here. This helps implementing network wide QoS at a
single place.

mpls_config_object: Configuring MPLS FEC and Traffic Trunk is done under this element
configuration. The configured specification is used at the Ingress Edge router to direct the traffic flows
and assign different LSP to different application traffic.

Failure Recovery: To study the simulated network model during/after failure, OPNET model has built
in an element called “Failure Recovery”. This covers link or node failure/recovery situations at
specifically configured simulation time.










Analyzing IP/MPLS as Fault Tolerant Network Architecture
58
5.3 OPNET Simulated Application Traffic
This thesis work takes into account five (5) different types of application traffic. The applications that
constitute this work are mentioned below with their subsequent details. Application traffic is
differentiated using TOS value as mentioned with each application flow; this will help inside the
DiffServ or IntServ domain.

FTP Traffic: FTP is short for File Transfer Protocol. It is used to generate traffic flow from the FTP server
towards the FTP client, thus simulating file downloading based upon the request from the client. The
FTP traffic characteristics are provided in a diagram table. The FTP is given the TOS equals Best Effort
(0). FTP makes use of TCP protocol.









Figure 5.1 – OPNET FTP Traffic Specification.

HTTP Traffic: Hyper Text Transfer Protocol is used to simulate web browsing scenario, inside our
network design. Below are the HTTP request/reply characteristics. HTTP is given the TOS equals
Standard (2). HTTP browsing makes use of TCP protocol.
Figure 5.2 – OPNET HTTP Traffic Specification.
Analyzing IP/MPLS as Fault Tolerant Network Architecture
59
Email Traffic: Email traffic is used in this thesis work to check the behavior of email service inside an
enterprise. The characteristics of Email are provided in a diagram table. Emails are considered to be
important, so given TOS value which equals Excellent Effort (3). Email service makes use of TCP
protocol.

To check network characteristic to some real time delay in tolerant traffic, video and voice traffic is
produced in the simulated network. This helps better understand network attributes in terms of delay
variation and packet loss.  For these reasons, the voice/video applications are initiated, below are the
characteristics of each of them separately. Both traffic flows make use of UDP transport mechanism.
Voice and Video constitutes the network major traffic share.









Figure 5.3 – OPNET Email Traffic Specification.

Voice Traffic:  The Voice traffic holds the mentioned characteristics. Voice application traffic is given
the highest application TOS which equals Interactive Voice (6).








Figure 5.4 – OPNET Voice Traffic Specification.
Analyzing IP/MPLS as Fault Tolerant Network Architecture
60
Video Conferencing Traffic:  The video conferencing inherits the mentioned characteristics. It is given a
TOS value which equals Interactive multimedia (5). The traffic generated by Video application per
seconds includes:
(128 x 120 bytes) (10 frames / sec) = 153.6 Kbytes/sec
= 1.2 Mbits/sec (approx.)








Figure 5.5 – OPNET Video Conferencing Traffic Specification.












Analyzing IP/MPLS as Fault Tolerant Network Architecture
61
5.4 OPNET Simulated Network
Up till now, the network modules and application to be run over the simulated network is provided.
The initial network model is provided below; different OPNET modules are added to this topology as
required.

Figure 5.6 – OPNET IP network Base Scenario snapshoot

Some core nodes constitute towards full mesh as they have more connectivity than others. The overall
network link connectivity is 3.75 links per core node, on average. Different network scenarios are
implemented over this baseline configuration, the next section will describe those scenarios. Each
network Scenario implements a capability in simulated network architecture, except the scenarios with
the mutation testing for a particular technology. Mutation testing will include failure of one/more links
Analyzing IP/MPLS as Fault Tolerant Network Architecture
62
at same/different simulation time, to check the behavior of network, following a failure. The source
nodes on one side and the destination nodes are provided on the other side of the network, so that a
small change in the network topology may affect all the application traffic, not only a single application.

5.5 OPNET Simulated Scenarios
For proper understanding of IP/MPLS network architecture with it’s inherit fault tolerant properties,
certain OPNET scenarios are implemented one by one. A single baseline network topology is deployed,
which is mentioned in previous sub section. Different extensions to that baseline network topology are
provided below to study network characteristics.

 IP ECMP configuration with Per-Packet / Per-Destination Load Balancing
 IP DiffServ configuration network
 IP ECMP Per-packet Load balancing configuration with Mutation Testing
 IP ECMP with Mutation Testing under Loaded Network configuration
 MPLS Baseline Network configuration
 MPLS network configuration with Mutation Testing
 MPLS with Mutation Testing under Loaded Network configuration
 MPLS Network with Traffic Engineering Capability configuration for FTP
 MPLS-TE Capability with Weighted Load balancing configuration for FTP
 MPLS-TE Capability for Voice Traffic using RSVP-TE
 MPLS-TE Capability for Voice Traffic using CR-LDP
 Mutation Testing for MPLS-TE network
 Mutation Testing for MPLS-RSVP-TE network with Global Repair
 Mutation Testing for MPLS-RSVP-TE network with Local Repair
 Mutation Testing for MPLS-CR-LDP-TE network with Local Repair







Analyzing IP/MPLS as Fault Tolerant Network Architecture
63
Chapter 6
Simulation Results and Evaluation
This section will evaluate different network scenarios based on the previously mentioned scenarios.
Each scenario is taken separately and in order, starting with discussion on the (first) baseline scenario.
All log results are time average representations of the collected results. First, the capabilities in pure IP
network will be taken under consideration and then MPLS configuration will be implemented to study
the IP/MPLS conjunction.

6.1 IP ECMP configuration with Per-Packet / Per-Destination Load Balancing
Provided in the network topology section, the baseline IP configuration is built using IP capabilities.
OSPF is taken as a routing protocol for the core and each core link is inside OSPF area 0. OSPF is chosen
specifically for the reason that it is a link state algorithm with TE capabilities. OSPF builds its shortest
path first table using Dijkstra’s algorithm. OSPF makes use of additive link bandwidth (or more
specifically link cost) as cost to reach a remote destination. Link bandwidth is configured upon the
ppp_adv link models. Each core link consists of 5Mbps of bandwidth. So for the initial scenario, there
might be multiple paths towards a specific destination. As situation like this occurs, the dynamic routing
protocols (as OSPF in our case) automatically provides Equal Cost Multi Path (ECMP), for the
destination accessible with same cost.

In our simulated network, the end to end bi-directional ECMP available includes:
 West-R3-R2-R1-East
 West-R6-R5-R4-East

Inside the core network, at each intermediate node there are ECMP route towards the other end of the
network, as:
 R3-R5-R1-East
 R3-R5-R4-East
 R2-R1-East
 R2-R4-East
Analyzing IP/MPLS as Fault Tolerant Network Architecture
64
 R6-R2-R1-East
 R6-R2-R4-East
 R5-R4-East
 R5-R1-East

ECMP is used to do load balancing across the network domain, by sending the traffic around multiple
network paths. ECMP thus helps decrease network congestion at the links, by distributing the loads.
Two types of load balancing options are available [2], either to perform per-destination load balancing
or to do per-packet load balancing. But, this perfect situation of ECMP is not available always inside a
network, because links are not of equal capacity. Further, not all different network application sources
and destinations are at equal cost or different network routing protocols like EIGRP are used, which
take into account the link load (at certain time) while calculating the route towards a destination. But
EIGRP is neither link state nor is it an IEFT standard. EIGRP is CISCO proprietary and used only with
CISCO interconnecting devices.

A certain benefit of per-packet load balancing includes load distribution across network links, but a
down side of per-packet load balancing is that different packets to the same destination follow different
paths, this leads to an increased re-ordering delay at the final destination [2]. A variant of per-packet
load balancing includes per-destination load balancing option. Per destination load balancing is done by
distributing load across the network based on the destination network address associated with an
incoming packet, thus preserving packet ordering (mostly). The more the destination networks are
available the more the link load balancing capability comes into play. Each interface keeps a table
associated with each destination address and then maps the incoming traffic to an associated exit
interface. With such load balancing, some traffic maps over a less utilized link, whereas some
application traffic is mapped over an already congested link. Below are the application characteristics
with implemented per-destination load-balancing.

For per-packet load balancing, each incoming packet is process switched [2, 13], by moving it to router
CPU buffer for close inspection. In the case for per-destination load balancing, the first packet needs to
be process switched and an exit interface is specified for the duration of the application flow, but later
on the incoming packets to the same destination follow same path, as the first packet. A route cache
entry at the incoming interface [2] is made for the per-destination load balancing, so that each packet
Analyzing IP/MPLS as Fault Tolerant Network Architecture
65
needs not to be process switched (separation between control and data plane). From now on, this work
will take into account the IP ECMP per-packet load balancing, because of its reliable network load
sharing across network links and there is no such constraint for this work to take into account any
specific load balancing options. Different application characteristics once run over the ECMP network
are provided below:


FTP Download Response Time    HTTP Object Response Time















HTTP Page Response Time     Email Download Response Time
Analyzing IP/MPLS as Fault Tolerant Network Architecture
66


Email Upload Response Time           Video Conferencing Packet Delay Variation




Video Packet End to End Delay      Voice Jitter

Analyzing IP/MPLS as Fault Tolerant Network Architecture
67

Voice Packet Delay Variation    Voice End to End Delay


6.2 IP DiffServ configuration network
Differentiated Service is a Quality of Service policy, implemented inside a core network. Using DiffServ
a core node can treat application traffic with higher TOS value as prioritize. This priority value is used to
queue up traffic flows into single or multiple queues, while providing priority treatment to the traffic
marked with higher QoS. IP DiffServ is considered to be soft QoS [2] [15] as opposed to the IP IntServ
QoS, which is treated as hard QoS [2]. IntServ makes us of RSVP protocol to reserve resources before the
traffic reaches a particular node in the network. The recourses are reserved within IntServ domain for
the duration of traffic flow and no one else can use that reserved resources. IntServ can be used to make
a circuit switch overlay network across the IP best effort delivery with guaranteed bandwidth and jitter,
with one drawback that RSVP requires periodic refreshment mechanism and each node maintains a set
of RSVP states which are proportional to the number of traffic flows passing through a node. Below are
IP DiffServ flavors with different queuing strategies.



Analyzing IP/MPLS as Fault Tolerant Network Architecture
68
OPNET model, named QoS Attribute Config, is used to configure network wide QoS. The three
scenarios used for IP DiffServ architectures include:
 IP ECMP per-packet Load Balancing with FIFO strategy
 IP ECMP per-packet Load Balancing with PQ strategy
 IP ECMP per-packet Load Balancing with WFQ strategy

First In First Out “FIFO” [15] uses same single queue to be used as a common mechanism to buffer
packets from different applications. There is no differentiation done once a packet comes into the queue,
it will be treated upon its turn and position in the queue. The first packet entering the queue suffers no
delay, while each proceeding packet suffers some delay. Delay is thus variable and it depends upon the
statistics how many packets are already queued up inside a single queue. There is no TOS field to be
checked while keeping the packet in a FIFO queue [15].

Priority queue “PQ” [15] goes a step further by taking into account multiple queues for different flows.
Incoming packets are classified according to their TOS field and then assigned a queue out of the
available queues. There can be different number of queues, but the traffic that goes inside the Priority
Queue is served before any other queue is to be served. There could be queues with Low, Normal,
Medium and High priority queues [15] [25]. Inside OPNET, the traffic with TOS value 0 and 1, ends up
being in low priority queues. These queues are configurable. By default, TOS value 2 and 3 traffic ends
up in normal priority queue. TOS value 4 and 5 goes inside Medium priority queue. The TOS value 6
and 7 traffic goes inside High Priority queue. The greater the TOS value, the lower the queuing delay on
average [15].

Priority queuing has a drawback that all higher priorities queues need to be empty, before transmitting
the packets from the lower priority queues. This leads to starvation, as packets inside a lower priority
queues wait and wait, while the packets from the higher priority queues are continuously treated. To
overcome starvation issue, Weighted Fair Queue is taken into account. With WFQ, each flow has
separate FIFO queue. Flow is made up using the TOS field value. Each queue is treated in Round-Robin
(RR) fashion [25]. There is a drawback associated with a WFQ that for each FTP packet a corresponding
single voice packet is being transmitted, whereas there is lot of difference in payload carried inside each
packet, despite the fact that voice traffic is more burst than FTP traffic. More advanced, queuing
strategies (like Deficit Weighted Round Robin or Modified Deficit Weighted Round Robin) are
Analyzing IP/MPLS as Fault Tolerant Network Architecture
69
developed [15], but WFQ provides the basis for this advanced queuing strategy. This work will only
consider the effect of above mentioned comparison, within a DiffServ domain. Below is the network
application performance under different queuing techniques.

FTP Download Response time     HTTP Object Response time















HTTP Page Response time     Email Download Response time
Analyzing IP/MPLS as Fault Tolerant Network Architecture
70















Email Upload Download Response Time  Video Conferencing Packet Delay Variation




Video Conferencing Packet Delay Variation               Voice Jitter

Analyzing IP/MPLS as Fault Tolerant Network Architecture
71














Voice Packet Delay Variation     Voice Packet End to End delay

6.3 IP ECMP Per-packet Load balancing configuration with Mutation Testing
Mutation testing will be done onto the IP ECMP with load balancing scenario. Three different network
links will be broken with the help of OPNET failure/recovery model, with respect to the simulation
timing. The timing taken into account for three different scenarios is:
 Simulation time 400sec link(s) will go down
 Simulation time 700sec link(s) will come up again
For brevity purpose, only the configuration for the three links failure/recovery is show below:










Figure 6.1 – Failure Simulation OPNET Object Configuration
Analyzing IP/MPLS as Fault Tolerant Network Architecture
72













FTP Download Response Time    HTTP Object Response Time
















HTTP Page Response Time     Email Download Response Time



Analyzing IP/MPLS as Fault Tolerant Network Architecture
73

Email Upload Response Time    Video Conferencing Packet Delay Variation



Video Packet End to End Delay      Voice Jitter

Analyzing IP/MPLS as Fault Tolerant Network Architecture
74

Voice Packet Delay Variation    Voice End to End Delay


TCP Delay     TCP Retransmission Count



Analyzing IP/MPLS as Fault Tolerant Network Architecture
75
6.4 IP ECMP with Mutation Testing under Loaded Network configuration
Network load also contributes towards network degradation. This scenario takes this affect into account.
Network load with failure scenario will help understand network statistics in a better way. We make
different failure scenarios and adjust the link bandwidth reserved to be 20% that is 1Mbps of core links.
The links are being filled with network traffic using built in OPNET capability, which makes links busy
in both directions. We use the same configuration to fill up all core links at 20%.





















Figure 6.2 – Link Background Utilization OPNET Configuration






Analyzing IP/MPLS as Fault Tolerant Network Architecture
76














FTP Download Response Time     HTTP Object Response Time

















HTTP Page Response Time     Email Download Response Time

Analyzing IP/MPLS as Fault Tolerant Network Architecture
77

Email Upload Response Time    Video Conferencing Packet Delay Variation




Video Packet End to End Delay      Voice Jitter

Analyzing IP/MPLS as Fault Tolerant Network Architecture
78















Voice Packet Delay Variation    Voice End to End Delay



TCP Delay      TCP Retransmission Count
Analyzing IP/MPLS as Fault Tolerant Network Architecture
79
6.5 MPLS Baseline Network configuration
As the baseline configuration for MPLS, we enabled MPLS at the core routers. Enabling MPLS upon the
routers constitutes an MPLS domain. Without any Traffic Engineered tunnel (TE-LSP), the path taken by
the labeled packets remains the same as IP shortest path. Hence, just by enabling MPLS in a network
without its TE ability pays less to the applications using it. MPLS dependence upon the routing
protocols provides it to do load balancing across ECMP [8], as mentioned in section 2.4.1. Given below
are the logs collected for different application traffic:
FTP Download Response Time     HTTP Object Response Time

HTTP Page Response Time     Email Download Response Time
Analyzing IP/MPLS as Fault Tolerant Network Architecture
80














Email Upload Response Time    Video Conferencing Packet Delay Variation

















Video Packet End to End Delay      Voice Jitter


Analyzing IP/MPLS as Fault Tolerant Network Architecture
81
Voice Packet Delay Variation     Voice End to End Delay


















TCP Delay      TCP Retransmission Count
Analyzing IP/MPLS as Fault Tolerant Network Architecture
82
6.6 MPLS network configuration with Mutation Testing
The mutation testing is done same as scenario “6.3. IP ECMP Per-packet Load balancing configuration
with Mutation Testing”.  The same failure/recovery OPNET element is used for MPLS enabled network
without TE capabilities.

FTP Download Response Time    Email Download Response Time

Email Upload Response Time    Video Conferencing Packet Delay Variation
Analyzing IP/MPLS as Fault Tolerant Network Architecture
83

Video Packet End to End Delay      Voice Jitter



Voice Packet Delay Variation     Voice Packet End to End Delay

Analyzing IP/MPLS as Fault Tolerant Network Architecture
84

TCP Delay      TCP Retransmission Count





















Analyzing IP/MPLS as Fault Tolerant Network Architecture
85
6.7 MPLS with Mutation Testing under Loaded Network configuration
We now configure the MPLS network for some load and check the network efficiency in response to
failure situation. The following results are achieved when the network load across all core links equals
20% of each link capacity, which is about 1Mbps. The failure and corresponding recovery inside the
MPLS results in a better network design.


FTP Download Response Time     Email Download Response Time

Email Upload Response Time    Video Conferencing Packet Delay Variation
Analyzing IP/MPLS as Fault Tolerant Network Architecture
86













Video Packet End to End Delay      Voice Jitter



Voice Packet Delay Variation     Voice End to End Delay




Analyzing IP/MPLS as Fault Tolerant Network Architecture
87
TCP Delay       TCP Retransmission Count




















Analyzing IP/MPLS as Fault Tolerant Network Architecture
88
6.8 MPLS Network with Traffic Engineering Capability configuration for FTP
As mentioned the true benefit of deploying MPLS inside a network domain lies in its Traffic
Engineering capabilities.  Using Traffic Engineering in the designed topology can benefit in terms of
delay variation and retransmissions. As discussed previously, TE is taken as congestion avoidance
mechanism. With MPLS TE capabilities, one is able to direct traffic along an explicitly specified path.
This path could be static or dynamic depending upon the type of LSP (dynamic or static) being used to
traverse the intermediate nodes. A static LSP requires mapping at each intermediate node along the
path, whereas the dynamic LSP is signaled once at the startup [25]. For MPLS-TE to work with our
MPLS network we need to configure RSVP protocol across all selected nodes and provide the RSVP
reserve-able values over each link in the core. The reserve-able in our case is 75percent of total link
bandwidth.

To understand MPLS – TE in a better way, the FTP traffic has been Traffic Engineered along the paths,
making a circuit dedicated specifically for the FTP traffic. As the file has to be downloaded from the FTP
Server an explicit path from West to the East is required and FTP traffic needs to be mapped at the West
node into corresponding LSP:
 West – R3 – R5 – R1 – East








Figure 6.3 – MPLS Traffic Engineered LSP Configuration in OPNET

The results achieved for FTP application and compared with IP and MPLS network scenarios are
presented below. For IP and MPLS scenario, the traffic was load balanced along different equal cost
path, but here all the FTP traffic is required to traverse a single path, which may lead to performance
degradation, as single circuit may get congested or vulnerable to failure. These issues are resolved
further ahead using MPLS-TE weighted load balancing and MPLS-TE with fast reroute capabilities.
Analyzing IP/MPLS as Fault Tolerant Network Architecture
89












b

FTP Download Response Time     FTP Traffic Received (bytes/sec)















Analyzing IP/MPLS as Fault Tolerant Network Architecture
90
6.9 MPLS-TE Capability with Weighted Load balancing configuration for FTP
As found previously, the MPLS-TE may lead to traffic degradation while providing control over the
traffic path to be taken by an application. MPLS-TE has the nice feature of providing Weighted Load
Balancing across as many LSP circuits as possible.  With weighted load balancing, a weight value needs
to be configured on every LSP being used to carry specified application traffic. Weight upon LSP is
taken into account while mapping traffic across multiple LSP. Weight across multiple LSP can be
considered as the traffic ratio, being carried over each LSP. Suppose the weight at LSP1 has the value 10,
while the weight at LSP2 has value 20. This means that for every 10 packets send into LSP, the 20
packets needs to be transmitted into LSP2. This mechanism provides an effective load balancing
solution, as each network does not have equal capacity. Weighted load balancing hence increases
utilization of low bandwidth links as compared to high bandwidth links.






Figure 6.4 – MPLS Weighted Load Balancing for Traffic Engineered LSP

For this scenario, the same weights have been configured across both LSP from West towards East. A
reason for configuring equal weight could be because both paths have the same link capacity. This
configuration provides ECMP load balancing across multiple LSP. Compared to IP, MPLS and MPLS-TE
without weighted load balancing is compared below for FTP traffic.







Figure 6.5 – MPLS Traffic Engineered LSP Configuration for Weighted Load Balancing
Analyzing IP/MPLS as Fault Tolerant Network Architecture
91

FTP Download Response time     FTP Traffic Received (bytes/sec)




LSP Traffic In      LSP Traffic Out



Analyzing IP/MPLS as Fault Tolerant Network Architecture
92
6.10 MPLS-TE Capability for Voice Traffic using RSVP-TE
In this OPNET topology scenario, the MPLS-RSVP-TE capability has been extended to the Voice
application traffic. This topology reuses the previous MPLS-TE topology for FTP with the weighted load
balancing scenario.  The path taken by the Voice traffic from East to West will go inside LSP path “East –
R4 – R5 – R6 – West”. Whereas the Voice traffic from West to East will go over the LSP circuit “West –
R3 – R2 – R1 – East”, as shown in the figure:







Figure 6.6 – MPLS Traffic Engineered LSP Configuration for Voice Traffic

The comparison of this scenario with the other scenarios like IP, MPLS, and MPLS-TE for FTP is
provided below. One can see that when implemented the MPLS-TE for FTP application traffic with
weighted load balancing the Voice packet delay variation increases. But, this is handled further while
implementing MPLS-TE capabilities for Voice application traffic.













Analyzing IP/MPLS as Fault Tolerant Network Architecture
93

Email Download Response Time    Email Upload Response Time


Video Packet End to End Delay       Video Jitter
Analyzing IP/MPLS as Fault Tolerant Network Architecture
94


Voice Packet Delay Variation     Voice Packet End to End Delay


FTP Download Response Time        Video Conferencing Packet Delay Variation
Analyzing IP/MPLS as Fault Tolerant Network Architecture
95
6.11 MPLS-TE Capability for Voice Traffic using CR-LDP
CR-LDP is another version to implement MPLS-TE inside a network. CR-LDP makes use of the traffic
engineered routing protocols to setup LSP in the network. This also requires update information to be
exchanged among the TE-routers in the MPLS-TE domain. The below mentioned logs compare the
above scenario with the CR-LDP.













Email Download Response Time   Email Upload Response Time

FTP Download Response Time    Video Conferencing Packet Delay Variation
Analyzing IP/MPLS as Fault Tolerant Network Architecture
96

Video Packet End to End Delay     Voice Jitter



Voice Packet Delay Variation      Voice End to End Delay
Analyzing IP/MPLS as Fault Tolerant Network Architecture
97
6.12 Mutation Testing for MPLS-TE network
In this scenario we are going to take links down at specific times and make a note of network statistics as
it changes over time. During a single link failure, such as the link between R2 and R1 it will fail at
simulation time 400sec and recover at 700sec. The voice LSP goes over this link, that will be disturbed
and the RSVP-TE and CR-LDP will take care to route traffic along a better path. Below are the statistics
taken for both CR-LDP and RSVP-TE.

Email Download Response Time    Email Upload Response Time

FTP Download Response Time    Video Conferencing Packet Delay Variation
Analyzing IP/MPLS as Fault Tolerant Network Architecture
98

Video Packet End to End Delay      Voice Jitter



Voice Packet Delay Variation     Voice End to End Delay



Analyzing IP/MPLS as Fault Tolerant Network Architecture
99
6.13 Mutation Testing for MPLS-RSVP-TE network with Global Repair
Global repair is the scheme where the central node that initializes an LSP along a set of nodes, takes care
of the failure inside the network and does decision accordingly. This is often done by using a pre
signaled backup along a set of nodes that may be more diverse than the main LSP, making both LSP in
separate SRLG “Shared Risk Link Group” [3]. A certain advantage of declaring SRLG is that the diverse
paths are easy to establish. SRLS is often done my marking the link using the link affinity and then
match for specific mask to be taken care of.

For our scenario for mutation testing, the link R1-R2 is vulnerable to being failure and so does the LSP
for voice from West-East that is passing though the failed link. Global repair works for the TE versions,
where the RSVP PathErr message has to reach the head end.  Upon the receipt of RSVP PathErr message
the head end makes use of its TED “Traffic Engineered Database” to find out a better way to pass the
LSP though it.

Email Download Response Time    Email Upload Response Time






Analyzing IP/MPLS as Fault Tolerant Network Architecture
100















FTP Download Response Time    Video Conferencing Packet Delay Variation





Video Packet End to End Delay      Voice Jitter
Analyzing IP/MPLS as Fault Tolerant Network Architecture
101

Voice Packet Delay Variation      Voice End to End Delay


6.13 Mutation Testing for MPLS-RSVP-TE network with Local Repair
The local repair is done as close to the point of failure as possible. This greatly reduces the time it takes
to reroute the traffic and also results in less traffic loss. Local repair mechanism is also known as Fast
Reroute (FRR). MPLS FRR is done using NHOP tunnels for link failures. Below are the network statistics
for MPLS-FRR when done closer to the faulty links. Only voice LSP is broken at specific simulation
intervals, so for brevity only the statistics for Voice is provided below, in comparison with other
faults/recovery solutions.
Analyzing IP/MPLS as Fault Tolerant Network Architecture
102
















Voice Packet Delay Variation

















Voice End to End Delay
Analyzing IP/MPLS as Fault Tolerant Network Architecture
103
6.14 Mutation Testing for MPLS-CR-LDP-TE network with Local Repair
CR-LDP provides a default local repair mechanism. CR-LDP is based upon the routing protocols being
enhanced for the traffic engineering purpose. As a fault occurs inside a network, the CR-LDP enabled
network tries to recover from fault locally as the network updates are propagated. CR-LDP LSP only
takes the FRR tunnels in case of failure if they are laid across the shortest IGP path towards the
destination. If FRR tunnels are not along the shortest path, the CR-LDP recalculation will result into
shortest path consideration around a failed node.

Email Download Response Time   Email Upload Response Time








Analyzing IP/MPLS as Fault Tolerant Network Architecture
104


FTP Download Response Time    Video Conferencing Packet Delay Variation


















Voice Packet Delay Variation     Video Packet End to End Delay
Analyzing IP/MPLS as Fault Tolerant Network Architecture
105
Chapter 7
Conclusions and Future Work
The thesis work has presented an in-depth study of the fault tolerance mechanism in today’s IP network
as well as the IP/MPLS network. Faults inside a network can be divided into two subcategories such as
hard and soft failures. Hard failures are caused by network physical resource (link or node) breakdown.
Soft failures combine all the other factors that degrade the network services and hence resulting in
application degradation as a whole. Soft failures include jitter, packet delay variation, congestion and
likewise soft factors. Hard failure results in network black out whereas the soft failures cause network
brown out. Brown out occurs more commonly inside a network as compared to network black out.

For a network to be fault tolerant, it must handle both the soft and hard failures in a consistent manner.
IP networks have the capability to handle frequently occurring soft failures, through IP Differentiated
services architecture. IP Differentiated services architecture implementation inside an IP network
provides resilience towards soft failure, but only to applications that fall under a specific class of service
(Higher TOS value). Different applications under different classes of service get different services based
upon their packet header values. But, when it comes to handle hard failures inside an IP network, the
only way to handle such situation is to build a secondary path and make use of it following a failure.
Handling hard failures inside the IP networks requires assistance of deployed routing protocols. A
disadvantage is that this mechanism depends upon the routing protocol recovery time and not all
routing protocols have the same calculation time while building a new SPF around a failed resource.
The shortcoming of IP networks in handling hard failures in a consistent way is handled using IP/MPLS
technology.

The MPLS technology has been renowned in service provider’s domain as a tool to handle both
congestion and failure situations. The MPLS header contains three EXP bits that can be used to provide
enhanced QoS inside an MPLS-TE network. MPLS-TE provides resilience towards network brownouts.
MPLS-TE domain provides opportunity to a network administrator to better manage resources and
constraints over the core resources. MPLS-TE capability converts a packet switch network into circuit
like technology. A circuit (mostly single path network) like architecture is more prone to being
Analyzing IP/MPLS as Fault Tolerant Network Architecture
106
congested and to fail. Congestion inside MPLS-TE is handled using weighted load balancing, whereas
recovery to a failure situation is handled in a consistent manner through MPLS fast reroute (FRR). MPLS
FRR is independent of the underlying deployed IP routing protocol hence providing constant failover
time. MPLS FRR provides NHOP and NNHOP tunnel to recover from immediate link or node failure,
therefore provides resilience towards network black outs. A disadvantage of MPLS FRR solution is that
only an adjacent resource can be survived per MPLS-FRR LSP tunnel, i.e. either a link or a node.

The result achieved by simulating the IP/MPLS network with it’s inheriting capabilities to handle hard
and soft failures show efficient recovery and protection schemes. In this thesis, we have implemented
different network scenarios in OPNET simulator and we found that MPLS-DiffServ-TE with FRR
provides almost constant failover time. Investigating MPLS fault tolerance leads to the result that
although it is a good solution some improvements can be made to make it more flexible. An obvious
solution could be to extend MPLS-FRR NHOP or NNHOP tunnels towards a certain value. For now
NHOP tunnel separately covers an immediate link, where as a NNHOP tunnel provides resilience to an
immediate node failure. Adding a flexibility value (x = 1, 2, 3… n) could enhance the MPLS fault
tolerance, by making fast-backup tunnels up to a pre-determined “x” number (links or nodes). This
xHOP (where “x” could be any value in the range) could possibly provide resilience towards a certain
link/node, once provided an IP address of the resource to be protected. This enhancement is a
combination of Global and Local repair solutions and could possibly provide resilience over multiple
resources failures. xHOP tunnels require new backup path calculation at the PLR, so it suits the CR-LDP
FRR protocol. It also combines the NHOP and NNHOP backup tunnels criteria once implemented to
save a particular IP address/neighbor. This mechanism may also decrease (on average) the total number
of required fault recovery/protection tunnels inside MPLS domain. In case of multiple equal paths
which are available to a protected resource “x” value away, an arbitrary tie-breaker is required. The tie
breaker could be a different metric for real time and non-real time traffic that could be distinguished by
the use of MPLS EXP or IP TOS field value.

A solution to brownout situation in TE environment could be the automatic adjustable TE
administrative weight value upon the TE capable links. A TE weight is a static entry configured
manually though configuration over the TE links within the MPLS domain. If no TE administrative
weight value is configured, the default IGP metric value for that link is taken into account for
calculation. Static TE weights have vulnerability by being fixed. For example, as the load across the link
Analyzing IP/MPLS as Fault Tolerant Network Architecture
107
increases so does the unreserved bandwidth changes. There should be direct interaction between the TE
weights over a network link and the TE parameters for that link. The TE weight value should change in
accordance with the TE parameters. The adjustment of TE weights should be locally done and
propagated within the TE domain. This could possibly simplify the calculation done for the sake of TE
path calculation, as only a single TE attribute requires to be investigated while calculating a CBR-TE
path with specific TE requirements.

When it comes to future work, one could possibly look into IETF new IP-FRR solution for CR-LDP. A
basic introduction is provided in section 4.3, “LDP fast reroute”. There is a new flavor of MPLS known
as; MPLS-TP “Transport Profile” which is considered as one of the layer2 technologies and comes into
action as network layer technology inside transport network (SDH, SONET). RFC-5654 provides a good
basis for MPLS-TP architecture. Interested persons can look inside its behaviors and try to figure out its
capabilities in various networks scenarios. One can also look inside the hybrid xHOP solution that is
provided in the above paragraph and check its credibility with different scenarios. Further, the option to
implement adjustable TE weight within MPLS domain is open to anyone interested. An OPNET
modeler can be used for the prospective research work.

















Analyzing IP/MPLS as Fault Tolerant Network Architecture
108
Bibliography
[1]. RFC781: Internet Protocol, IETF, September 1981
[2]. “Routing TCP IP” Volume 1, 2nd Edition, Cisco Press, October 2005
[3]. RFC: 3031 Multi Protocol Label Switching Architecture, IETF, January 2001
[4]. “Achieving sub-second IGP convergence”, Perre F., Clarence F., Oliver B., ACM, July 2005
[5]. “Fast Convergence Mechanisms and Features Deployment within Operator Backbone”, A. Ala, M. Essaaidi, D.E.
Oughiri, IEEE 2009
[6]. “The Unpublicized Sea Change in the Internet”, Spatscheck, O.,  Van der Merwe, J., AT&TLabs    Research,
IEEE Computer Society, Jan.-Feb. 2011 V.15, p.92 – 95
[7]. RFC: 3630 Traffic Engineering (TE) Extensions to OSPF Version 2, IETF, September 2003
[8]. “MPLS enabled applications: emerging developments and new technologies”, Ina Minei, Julian Lucek, 3rd
edition, Wiley, 2010
[9]. “The Illustrated Network”, Walter Goralski, Morgan Kaufmann, 2008
[10]. “MPLS: Next Steps”, Bruce S. Davie, Adrian Farrel, Morgan Kaufmann, 2008
[11]. “The Internet and Its Protocols - A Comparative Approach”, Adrian Farrel, Morgan Kaufmann, 2004
[12]. RFC: 2475 an Architecture for Differentiated Services, IETF, December 1998
[13]. “MPLS Fundamentals”, Luc De C., Cisco Press 2007
[14]. “Connection - oriented networks: SONET/SDH, ATM, MPLS, and Optical Networks”, Harry G. Perros, Wiley,
2005
[15]. “End-to-End QoS over Heterogeneous Networks”, Braun T., Diaz M., Gabeiras, Springer, 2008
[16]. “Traffic Engineering with MPLS”, Eric O., Ajay S., Cisco Press 2003
[17]. RFC: 1633 Integrated Services in the Internet Architecture: an Overview, June 1994
[18]. RFC:  3209 RSVP-TE: Extensions to RSVP for LSP Tunnels, December 2001
[19]. RFC: 5880 Bidirectional Forwarding Detection (BFD), IETF, June 2010
[20]. RFC: 4090 Fast Reroute Extensions to RSVP-TE for LSP Tunnels, IETF, May 2005
[21]. “Deploying QoS for Cisco IP and multi service networks”, J. Evans, C. Filsfils, Morgan Kaufmann, 2007
[22]. RFC: 5286 “Basic Specification for IP Fast Reroute: Loop-Free Alternates”, IETF, September 2008
[23]. RFC: 5793 “Virtual Router Redundancy Protocol (VRRP) Version 3 for IPv4 and IPv6”, IETF,   March
2010
[24]. RFC: 5303 IS-IS Extensions for Traffic Engineering, IETF, October 2008
[25]. Opnet Product Documentations, Version 14.5, OPNET Inc.

