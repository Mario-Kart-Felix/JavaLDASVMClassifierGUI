782 IEEEACM TRANSACTIONS ON NETWORKING, VOL. 11, NO. 5, OCTOBER 2003An Algebraic Approach to Network CodingRalf Koetter, Member, IEEE, and Muriel Mdard, Senior Member, IEEEAbstractWe take a new look at the issue of network capacity. Itis shown that network coding is an essential ingredient in achievingthe capacity of a network. Building on recent work by Li et al., whoexamined the network capacity of multicast networks, we extendthe network coding framework to arbitrary networks and robustnetworking. For networks which are restricted to using linear network codes, we find necessary and sufficient conditions for the feasibility of any given set of connections over a given network. Wealso consider the problem of network recovery for nonergodic linkfailures. For the multicast setup we prove that there exist codingstrategies that provide maximally robust networks and that do notrequire adaptation of the network interior to the failure pattern inquestion. The results are derived for both delayfree networks andnetworks with delays.Index TermsAlgebraic coding, network information theory,network robustness.I. INTRODUCTIONTHE ISSUE of network capacity has generally been considered in the context of networks of links exhibiting ergodicerror processes. Channel coding theorems and capacity regionscan be found for certain networks of this type, such as broadcastchannels 13, multiple access channels 4, 5, and relaychannels 68. Recently, some renewed attention has beenpaid to the capacity of errorfree networks. In particular, codingover errorfree networks for the purpose of transmitting multicast connections has been considered 911. For a further,recent discussion of network coding, refer to 12, ch. 11, 15.The work in 9 and 10 examined the network capacity ofmulticast networks and related capacity to cutsets. Capacity isachieved by coding over a network. We present a new surprisingly simple and effective framework for studying networks andtheir capacity. The framework is essentially algebraic and makesa straight connection between a given network information flowproblem and an algebraic variety over the closure of a finitefield. While the results of Li et al. 9 and Ahlswede et al. 10contain algebraic elements, i.e., linear coding 9 and a remarkpertaining to convolutional codes 10 the presented connectionto concepts from algebraic geometry opens up the opportunityto employ very powerful theorems in well developed mathematical disciplines. For networks which are restricted to using linearcodes later we make precise the meaning of linear codes, sincethese codes are not bitwise linear, we find necessary and suffiManuscript received May 14, 2002 revised January 25, 2003 approved byIEEEACM TRANSACTIONS ON NETWORKING Editor D. Lee. This work wassupported by the National Science Foundation under Awards CCR 9984515,CCR 0325673, and CCR0093349, and by the HP Wireless Center at MIT.R. Koetter is with the Coordinated Science Laboratory, University of Illinoisat UrbanaChampaign, Urbana, IL 61801 USA email koetteruiuc.edu.M. Mdard is with the Laboratory for Information and Decision SystemsLIDS, Massachusetts Institute of Technology, Cambridge, MA 02139 USAemail medardmit.edu.Digital Object Identifier 10.1109TNET.2003.818197Fig. 1. Networks with multicast from s to y and z.cient conditions for any given set of connections to be achievable over a given network. Using our framework, we show thatthe case of a multicast connection over a network exhibits a veryspecial structure, which makes its feasibility verifiable in polynomial time. Moreover, similar to results in 9, we show thatlinear codes over a network are sufficient to implement any feasible multicast connection.For networks where connections are not multicast, we showthat giving the necessary and sufficient conditions for the connections to be feasible is equivalent to the problem of finding apoint in an algebraic variety which, in general, is an NPcomplete problem. Moreover, while the cutset conditions are necessary and sufficient to establish the feasibility of a certain set ofconnections for multicast connections, the cutset conditions areonly necessary but provably not sufficient for the case of generalconnections, i.e., of some arbitrary collection of pointtopointconnections.The usefulness of coding over errorfree networks can beeasily viewed from an example. Consider Fig. 1 from 9 and10. Each link can transmit a single bit errorfree here,we donot consider delays. On the lefthand side network, the sourcemay easily transmit two bits, and , to receivers and ,by using switching at and broadcasting at and . On therighthand side network, a code is required, where must codeover the arc . The capacity of such networks is shown tobe the maximum flow from the source to each receiver in the network. This approach may be generalized from directed acyclicgraphs to general directed graphs as long as we consider delaysalong the links.Networks that do not experience ergodic error processesmay be reasonable models for networks that in reality are builtfrom links exhibiting ergodic failure processes. Appropriatecoding over the links in the network may render those linksin effect errorfree and network coding can then be used toachieve capacity or recovery over an errorfree network, withpossible delays due to coding. We do not explicitly consider inthis paper the relation between link coding for ergodic failuresand network coding. All links are assumed to be error freewhen they are operational. Links, however, are allowed to failaltogether.106366920317.00  2003 IEEEKOETTER AND MDARD ALGEBRAIC APPROACH TO NETWORK CODING 783Indeed, coding is not only applicable to networks in order toachieve capacity, but can also be used to recover from networkfailures. For an early work pointing into this direction, refer toAyanoglu et al. 14, where coding strategies for simple networks are suggested. Such failures are different from link errors, described by ergodic processes, which would be typicallydealt with by using channel coding. The failures we considerentail the permanent removal of an edge, such as would occurin a network if there were a longterm failure due to a link cut orother disconnection. We show that network coding can providemaximal robustness of a network against nonergodic link failures. Moreover, we prove that there exist coding strategies thatdo not require an adaptation to a specific link failure pattern.II. PROBLEM FORMULATIONA communication network is a collection of directed linksconnecting transmitters, switches, and receivers. It may be represented by a directed graph with a vertex set andan edge set . We will allow multiple edges between two vertices and hence, is a subset of , where the lastinteger enumerates edges between two vertices. Edges linksare denoted by round brackets and assumed to bedirected. If no confusion can arise, we also denote edges simplyas . The and of an edge is denoted by and .We define as the set of edges that end at a vertexand as the set of edges originating at . Formally, we haveThe indegree of is defined as , whilethe outdegree is defined as .A network is called cyclic if it contains directed cycles, i.e., ifthere exists a sequence of edgesin . A network is called acyclic if it does not contain directedcycles. To each link we associate a nonnegative number, called the capacity of .Let bea collection of discrete random processes that areobservable at node . We want to allow communicationbetween selected nodes in the network, i.e., we want toreplicate, by means of the network, a subset of the randomprocesses in at some different node . We define aas a triple ,where denotes the power set of . The rateof a connection is defined as, where is theentropy rate of a random process .Given a connection , we call aand a of , and write and .For notational convenience, we will always assume that.A node can send information through a linkoriginating at at a rate of at most bits per time unit.The random process transmitted through link is denoted by. In addition to the random processes in , node canobserve random processes for all in . In general,the random process transmitted through linkwill be a function of both and if is in.If is the sink of any connection , the collection ofrandom processes ,denotes the output at . A connectionis established successfully if a possibly delayed copy of is a subset of .Let a network be given together with a set of desired connections. We will make a number of simplifying assumptions.1 The capacity of any link in is a constant, e.g., bits pertime unit. This is an assumption that can be satisfied to anarbitrary degree of accuracy. If the capacity exceedsbits per time unit, we model this as parallel edges with unitcapacity. Fractional capacities can be well approximatedby choosing the time unit large enough.2 Each link in the communication network has the samedelay. We will allow for the case of zero delay, in whichcase we call the network delayfree. We will alwaysassume that delayfree networks are acyclic in order toavoid stability problems.3 Random processes , are independent and have a constant and integral entropy rateof, e.g., bits per unit time. The unit time is chosento equal the time unit in the definition of link capacity.This implies that the rate of any connectionis an integer equal to . Thisassumption can be satisfied with arbitrary accuracy byletting the time basis be large enough and by modelinga source of larger entropy rate as a number of parallelsources.4 The random processes are independent for different . This assumption reflects the nature of a communication network. In particular, information that is injected into the network at different locations is assumedindependent.In addition to the above constraints, we assume that communication in the network is performed by transmission of vectorssymbols of bits. The length of the vectors is equal in all transmissions and we assume that all links are synchronized withrespect to the symbol timing.Any binary vector of length can be interpreted as anelement in , the finite field with elements. The randomprocesses , , and can, hence, be modeledas discrete processes ,, and ,that consist of a sequence of symbols from .We have the following definition of a delayfree and hence,by assumption, acyclic linear communication network9.Definition 1 Let be a delayfree communicationnetwork. We say that is a linear network, if for all linksthe random process on a link satisfieswhere the coefficients and are elements of .784 IEEEACM TRANSACTIONS ON NETWORKING, VOL. 11, NO. 5, OCTOBER 2003Definition 1 is concerned with the formation of random processes that are transmitted on the links of the network. It is possible to consider timevarying coefficients and and wecall the network timeinvariant or timevarying, depending onthis choice.The output at any node is formed from the randomprocesses for . It will be sufficient for the purpose of this paper to restrict ourselves to the case thatare also linear combinations of the , i.e.,1where the coefficients are elements of . Indeed, wewill prove in Section IIIA that, for linear networks, it sufficesto consider the formation of the by linear functions offor . The concepts of Definition 1 are illustratedin the following example network.We emphasize that we can freely choose and the fieldcontaining the constants , , and . In particular, wefrequently choose to consider the algebraic closure of ,which is defined as the union of all possible algebraic extensionsof . Once we find suitable coefficients in , it is clear thatthese coefficients also lie in a finite extension of .For a given network and a given set of connections , weformally define a network coding problem as a pair . Theproblem is to give succinct algebraic conditions under whicha set of desired connections is feasible. This is equivalent tofinding elements , , and in a suitably chosen fieldsuch that all desired connections can be established successfully by the network. Such a set of numbers , , andwill be called a solution to the network coding problem. If a solution exists, the network coding problem will becalled solvable. The solution is timeinvariant timevarying ifthe , and are independent dependent of the time.We also consider the case of networks that suffer from linkfailure. Link failures are not assumed to be ergodic processesand we assume that a link either is working perfectly or is effectively removed from the network. A link failure pattern canbe identified with binary vectors of length such that eachposition in is associated with one edge in . If a link fails, weassume that the corresponding position in equals one, otherwise the entry in corresponding to the link equals zero.We say that a network is solvable under link failure patternif it is solvable once the links corresponding to the support ofhave been removed. While it is straightforward to investigate thesolvability for a given failure pattern, finding common solutionsfor classes of failure patterns is a much more interesting task. Wesay that a network solution is static under a set of link failurepattern, if there exists solutions for the network under any linkfailure pattern with the same elements . Staticsolutions are particularly desirable because1 no new solution has to be found and distributed in thenetwork if a failure pattern occurs2 the individual nodes in the interior network can be oblivious to the failure pattern, i.e., the basic operation performed at a node in the network is independent of the particular error pattern.The fundamental questions that we strive to answer in thispaper are the following.1 Under what conditions is a given linear network codingproblem solvable2 How can we efficiently find a solution to a given linearnetwork coding problem3 When does a static solution exist for a network that issubject to link failuresThe main tools we will use for answering the above questions involve concepts from algebraic geometry. In particular,we will relate the network coding problem to the problem offinding points on algebraic varieties, which is one of the centralquestions of algebraic geometry.In Section III, we introduce part of the algebraic framework.The goal of the section is to make the reader familiar with someof the employed concepts. The base theorem is an algebraic reformulation of the MinCut MaxFlow Theorem. We point outthe algebraic interpretation of this theorem in the context of theFordFulkerson algorithm.In Section IVA, we apply the algebraic framework to acyclicnetworks. We rapidly recover and extend the work of Li et al.9 and Ahlswede et al. 10. In particular, we are able to answer some of the problems left open by the authors 9. In Section IVB, we address the general network coding problem forcyclefree networks and we derive necessary and sufficient conditions to guarantee the solvability of a network coding problem.The case of robust networks that are subject to link failure istreated in Section V. The main surprising result is that robustmulticast can be achieved with static solutions to the networkcoding problem. Section VI extends the results to networks withdelay and networks with cycles.III. ALGEBRAIC FORMULATIONIn this section, we will develop some of the algebraic concepts used throughout this paper. For the readers convenience,we will follow a simple example of a pointtopoint connectionin the communication network given in Fig. 2a.Let be a communication network. A betweena node and is a partition of the vertex set of into twoclasses and of vertices such that containsand contains . The value of the cut is defined asKOETTER AND MDARD ALGEBRAIC APPROACH TO NETWORK CODING 785abFig. 2. a Pointtopoint connection in a simple network. b The samenetwork with nodes representing the random processes to be transmitted in thenetwork.The famous MinCut MaxFlow Theorem can be formulatedas follows.Theorem 1 MinCut MaxFlow Let a network with a singlesource and a single sink be given, i.e., the only desired connection is . The network problem is solvable ifand only if the rate of the connection is less than or equalto the minimum value of all cuts between and .Proof See 16 and 17.The FordFulkerson labeling algorithm 16 gives a way forfinding a solution for pointtopoint connections provided a network problem is solvable. The algorithm is graph theoretic bydesign and finds, under the assumptions made in Section II, asolution such that all parameters and in Definition 1are either zero or one.While the FordFulkerson labeling algorithm provides anelegant solution for pointtopoint connections, the technique isnot powerful enough to handle a more involved communicationsscenario. In the remainder of this section, we develop sometheory and notation necessary for more complex setups. We firstconsider a pointtopoint setup. Let node be the only sourcein the network. We letdenote the vector of input processes observed at . Similarly, let be the only sink node in a network. We letbe the vector ofoutput processes.The most important consequence of considering an linear network is that we can give a transfer matrix describingthe relationship between an input vector and an output vector. Let be the system transfer matrix of a network with inputand output , i.e., . For a fixed set of coefficients, , and , is a matrix whose coefficients areelements in the field In our case, we go a step further andconsider the coefficients as indeterminate variables. Hence, weconsider the elements of matrix as polynomials over thering of polynomials inthe variables , , and .Example 1 We consider the network of Fig. 2. The following set of equations governs the parameters , andand the random processes in the network.It is straightforward to compute the transfer matrix describingthe relationship between and . In particular, let matricesand be defined asThe system matrix is found to equalThe determinant of matrix equals. We can choose parameters in anextension field so that the determinant of is nonzeroover . Hence, we can choose as the identity matrix andso that the overall matrix is also an identity matrix. Onesuch solution found by the FordFulkerson algorithm wouldbe to let while all otherparameters of type are chosen to equal zero. Clearly, apointtopoint communication between and is possibleat a rate of three bits per unit time. We note that, over thealgebraic closure there exists an infinite number of solutionsto the posed networking problem, namely, all assignments toparameters which render a nonzero determinant of thetransfer matrix .Inspecting Example 1, we see that the crucial property of the network is that the equationadmitted a choiceof variables so that the polynomial did not evaluate to zero.The following simple lemma will be the foundation of manyexistence proofs given in this paper.Lemma 1 Let be the ring of polynomials over an infinite field in variables .For any nonzero element there existsan infinite set of tuples such that.786 IEEEACM TRANSACTIONS ON NETWORKING, VOL. 11, NO. 5, OCTOBER 2003Proof The proof follows by induction over the number ofvariables and the fact that is an infinite field.The following theorem makes the connection between thenetwork transfer matrix an algebraic quantity, and theMinCut MaxFlow Theorem a graphtheoretic tool.Theorem 2 Let a linear network be given with source node ,sink node , and a desired connection ofrate . The following three statements are equivalent.1 A pointtopoint connection is possible.2 The MinCut MaxFlow bound Theorem 1 is satisfiedbetween and for a rate .3 The determinant of thetransfer matrix is nonzero over the ring.Proof Most of the theorem is a direct consequence ofthe MinCut MaxFlow Theorem. In particular, 1 and 2 areequivalent by Theorem 3. In fact, the theorem only treatsthe singlesource singlesink case for a network with integerflows by assumption. The FordFulkerson algorithm thusyields edgedisjoint paths between source and sinknodes. We show the equivalence of 1 and 3. This in turnwill show the equivalence of 2 and 3. The FordFulkersonalgorithm implies that a solution to the linear network codingproblem exists. Choosing this solution for the parametersof the linear network coding problem yields a solution suchthat is the identity matrix and, hence, the determinant ofover does not vanishidentically. Conversely, if the determinant of is nonzeroover we can invert matrixby choosing parameters accordingly. From Lemma 1,we know that we can choose the parameters as to make thisdeterminant nonzero. Hence, 3 implies 1 and the equivalenceis shown.From Example 1, Lemma 1, and Theorem 2, we concludethat studying the feasibility of connections in a linear networkscenario is equivalent to studying the properties of solutions topolynomial equations over the field . The third statement ofTheorem 3 allows us to translate graphtheoretical propertiesof a network, like maxflow and connectivity, into an algebraiccondition. Powerful algebraic tools can then be employed to arrive at statements concerning the original network. It is worthwhile to point out that it is sufficient in Theorem 3 to considerexpressions over fields of fixed characteristic. In other words,if a solution to a pointtopoint network problem exists, therealso exists a solution restricted to the algebraic closure of the binary field . Hence, there is no need or advantage to considerfields of other characteristic. Nevertheless, it is not clear if linearcoding strategies are sufficient for a general network problem.In Section IIIA, we investigate the structure of general transfermatrices and the polynomial equations to which they give rise.A. Transfer MatricesIn a linear communication network of Definition 1, any nodetransmits, on an outgoing edge, a linear combination of thesymbols observed on the incoming edges. This relationship between edges in a linear communication network is the naturalFig. 3. Directed labeled line graph G corresponding to the network depictedin Fig. 2a.incidence structure for our problem. We say that any edgefeeds into edge if is equal to .We define the directed labeled line graph of aswith vertex set and edge set. Any edge is labeledwith the corresponding label . Fig. 3 shows the directed labeled line graph of the network in Fig. 2.We define the adjacency matrix of the graph with elements given asotherwise.Lemma 2 Let be the adjacency matrix of the labeled linegraph of a cyclefree network . The matrix  has a polynomial inverse with coefficients in .Proof Provided the original network is acyclic, thegraph is acyclic. Hence, we may assume that the vertices inare ordered according to an ancestral ordering. It followsthat is a strict uppertriangular matrix and, hence,  isinvertible in the field of definition of . The claim that the is invertible in the ring of polynomials rather than thecorresponding quotient field of rational functions follows froma direct backsubstitution algorithm.In order to consider the case that a network contains multiple sources and sinks, we consideras the vector of input processes on all vertices in .If a vertex in a network is not a source node, we set the corresponding parameter equal to zero.is a vector of length .Let the entries of a matrix be defined asotherwise.Similarly, letbethe vector of output processes. If is not a sink node of anyconnection, we let be equal to zero. is a vector of length. Let the entries of a matrix be definedasotherwise.Example 2 We consider the network depicted in Fig. 4a.The corresponding labeled line graph is depicted in Fig. 4b.KOETTER AND MDARD ALGEBRAIC APPROACH TO NETWORK CODING 787abFig. 4. a Network with two source and two sink nodes. b Correspondinglabeled line graph. Labels in b are omitted for clarity. The edge e does notfeed into any other edge and no edge feeds into e , which renders an isolatedvertex in the labeled line graph.We assume that the network is supposed to accommodate two connections , and. We fix an ordering of edges as, , . For thisordering, the adjacency matrix of the labeled line graph isfound to equal 2, shown at the bottom of the page.Also, matrices and are found to equal 3 and 4, respectively, also shown at the bottom of the page.From the definition of matrices , and , we can easilyfind the transfer matrix of the overall network.Theorem 3 Let a network be given with matrices , , and. The transfer matrix of the network is given aswhere is the identity matrix.Proof Matrices and do not substantially contribute tothe overall transfer matrix as they only perform a linear mixingof the input and output random processes. In order to find theimpulse response of the link between an input random processand an output , we have to add all gains alongall paths that the random process can take in order tocontribute to . It is straightforward to verify that the pathbetween nodes in the network are accounted for in the series. Matrix is nilpotent and eventuallythere will be a such that is the all zero matrix. Hence, wecan write . The theoremfollows.The transfer matrix is considered as a matrix over the ringof polynomials . In thesequel, we will use a vector to denote the set of variables, and, hence, we consider asa matrix with elements in . We will use the explicit form ofthe vector only if we want to make statements about a specificsolution of a particular network problem .We conclude this section with a remark that it is sufficientto form the output processes by a linear function ofthe processes . Indeed, provided a networkproblem is solvable, let the output process be equalto where is an arbitraryfunction and the edges are in . By Definition 1, the processes are a linear function of the input processes .Hence, provided that the output equals any particularinput, the function describes a vector space homomorphismfrom to for all and,hence, must be a linear function. This proves that the formof 1 is no restriction on the solvability of a network codingproblem.IV. DELAYFREE NETWORKSA. Multicast of InformationIn its simplest form, the multicast problem consists of the distribution of the information generated at a single source nodeto a set of sink nodes such that all sink nodesget all source bits. In other words, the set of desired connectionsis given by , .Clearly, each connection must satisfy the cutsetbound between and . Ahlswede et al. 10 showed that thiscondition is sufficient to guarantee the existence of a codingstrategy that ensures the feasibility of the desired connections.Li et al. 9 showed that linear coding strategies are sufficient to234788 IEEEACM TRANSACTIONS ON NETWORKING, VOL. 11, NO. 5, OCTOBER 2003achieve this goal. The following theorem recovers their result inthe algebraic framework developed in Section III.Theorem 4 Let a delayfree network and aset of desired connections ,be given. The networkproblem is solvable if and only if the MinCutMaxFlow bound is satisfied for all connections in .Proof We have a single source in the network and,hence, the system matrix is a matrix with dimensionMoreover, by assumption and Theorem 2,each submatrix corresponding to one connection has nonzero determinant over . We considerthe product of the determinants of thesubmatrices. This product is a nonzero polynomial .By Lemma 1, we can find an assignment for such thatand, hence, the determinants of all submatricesare simultaneously nonzero in . Matrix can be chosen asa block diagonal matrix which contains on the main diagonalthe inverse of the corresponding submatricesof . By choosing matrix in this way, we can guaranteethat is the fold repetition of the identitymatrix, which proves the theorem.The most important ingredient of Theorem 4 is the fact that allsink nodes get the same information. Moreover, all sink nodesreceive the entire data that is injected into the network. In otherwords, provided that the sink nodes know the part of the systemmatrix that describes their connection, there are no interferingsignals in the network. Another interesting aspect of this setupis that the sink nodes do not have to be aware of the topology ofthe network. Knowledge about the overall effects of all codingoccurring in the network is sufficient to resolve their connection.The construction of special codes for the multicast networkcoding problem is rather easy. From the proof of Theorem 4, itis clear that we are given a polynomial in the product of thedeterminants and we have to find a point that does not lieon the algebraic variety cut out by this polynomial. A simplegreedy algorithm will actually suffice to find such a solution.We formulate this algorithm as follows.Algorithm 1 Input A polynomial in indeterminates  integerIteration1 Find the maximal degree of inand let be the smallest number such that.2 Find an element in such thatand let .3 If then halt, else , goto2.Output .The determination of the coefficients renders a networksuch that all the transfer matrices between the single source andany sink node are invertible. Choosing the matrix so that allthese matrices are the identity matrix solves the multicast network problem. The following theorem proves the correctness ofAlgorithm 1 and provides a simple bound on the degree of theextension of that we will have to consider.Theorem 5 Let a delayfree communication network anda solvable multicast network problem be given with one sourceand receivers. Let be the product of the determinants ofthe transfer matrices for the individual connections and let bethe maximal degree of with respect to any variable . Thereexists a solution to the multicast network problem in , whereis the smallest number such that . Algorithm 1 findssuch a solution.Proof We only have to show that Algorithm 1 indeed terminates properly. Also, it suffices to show that we can find inas the rest of the proof follows by induction. We consideras a polynomial in with coefficients from .By the definition of , the coefficients of are not divisible byand, hence, there exists an element such thaton substituting for at least one of the coefficients evaluatesto a nonzero element of . Substituting for and repeatingthe procedure yields the desired solution.A simple general upper bound on the necessary degree ofthe extension field for the multicast problem is given in the following corollary.Corollary 1 Let a delayfree communication network anda solvable multicast network problem be given with one sourceand receivers. Let be the rate at which the source generates information. There exists a solution to the network codingproblem in a finite field withProof Each entry in the matrix has degree atmost one in any variable. Hence, the degree of each variable inthe determinant of a particular transfer matrix is at most . Itfollows that the relevant polynomial has degree at most inany variable.B. General Network Coding ProblemThe situation is much changed if we consider the general network coding problem, i.e., we are given a network and an arbitrary set of connections . This problem is considerably moredifficult than the multicast problem. Some progress on characterizing the achievable set of connections is found in 13 for thecase of arbitrary nonlinear coding strategies. The set of achievable connections is there bounded within Yeungs frameworkof information inequalities 12. Here, we focus on linear network coding, which allows us to make concise statements for anumber of network coding problems. In order to accommodatethe desired connections, we have to ensure that 1 the MinCutMaxFlow bound is satisfied for every single connection and2 there is no disturbing interference from other connections.The following example outlines the basic requirements for thegeneral case.Example 3 Let the network be given as depicted inFig. 5a. The corresponding labeled line graphis given in Fig. 5b. We assume that we want toaccommodate two connections in the network, i.e.,.Vectors and are given asandKOETTER AND MDARD ALGEBRAIC APPROACH TO NETWORK CODING 789abFig. 5. a Network with two source and two sink nodes. b Correspondinglabeled line graph.. It is straightforward to check that the systemmatrix is given asWe can write as a block matrixwhere denotes the transfer matrix betweenand , denotesthe transfer matrix between and, etc. It is easy to see that the networkproblem is solvable if and only if the determinants ofand are unequal to zero, while the matricesand are zero matrices. Note that the determinant ofand is nonzero over if and only if the MinCutMaxFlow bound is satisfied. Indeed, we haveandIt is interesting to note that the MinCut MaxFlow condition issatisfied for each connection individually and also for any cutbetween both sources and both sinks. This condition is guaranteed by edge . If edge is removed the determinant of thetransfer matrix would vanish identically, which indicates a violation of the MinCut MaxFlow condition applied to cuts separating and from and . In order to satisfy ,we have to choose which implies that equalszero. However, then, we cannot satisfy the requirements thatand simultaneously and, hence, thenetwork problem is not solvable. It is worthwhile to pointout that it can be verified that this nonsolvability of the networkcoding problem is pertinent to any coding strategy and is not ashortcoming of linear network coding.As before, let denote the vector of input processes and letdenote a vector of output processes. Following Example 3, weconsider the transfer matrix in a block form assuch that is the submatrix of describing the transfermatrix between the input processes at and the output processes at . The following theorem states a succinct conditionunder which a network problem is solvable.Theorem 6 Generalized MinCut MaxFlow Condition Let an acyclic delayfree linear network problembe given and let be the corresponding transfermatrix relating the set of input nodes to the set of output nodes.The network problem is solvable if and only if there exists anassignment of numbers to variables such that1 for all pairs of vertices such that2 if contains the connections ,, , thesubmatrix is a nonsingularmatrix.Proof Assume the conditions of the theorem are met andassume the network operates with the corresponding assignmentof numbers to . Condition 1 ensures that there is no disturbinginterference at the sink nodes. Also, any sink node can invertthe transfer matrix and, hence, recoverthe sent information.Conversely, assume that either of the conditions is not satisfied. If Condition 1 is not satisfied, then the collection ofrandom processes observed on the incoming edges of is a superposition of desired information and interference. Moreover,the sink node has no possibility of distinguishing interference from desired information and, hence, the desired processescannot be reliably reproduced at .Condition 2 is equivalent to a MinCut MaxFlow condition,which clearly has to be satisfied if the network problem is solvable.Theorem 6 gives a succinct condition for the satisfiability ofa network problem. However, checking the two conditions is atedious task as we have to find a solution, i.e., an assignmentto number that exhibits the desired properties. We will sketchan algebraic approach to this problem in the remainder of thissection.Let denote all the entries inthat have to evaluate to zero in order to satisfy the first790 IEEEACM TRANSACTIONS ON NETWORKING, VOL. 11, NO. 5, OCTOBER 2003condition of Theorem 6. We consider the ideal generated by and denote this ideal by. From the Hilbert Nullstellensatz 18, weknow that this ideal is a proper ideal of if and only ifwe can find an assignment of numbers for such that we cansatisfy the first condition of Theorem 6. In order to satisfy thesecond condition of the theorem, we letdenote the determinants of the matrices thathave to be nonzero. Next, we introduce a new variable andconsider the function . We call the idealthe ideal ofthe linear network problem denoted by . Thealgebraic variety associated with is denoted, given byTheorem 7 Let a linear network problem be given.The network problem is solvable if and only if isnonempty and, hence, the ideal is a proper idealof , i.e, .Proof Assume first that the ideal is aproper ideal of . The Hilbert Nullstellensatz impliesthat the variety of points where all elementsof vanish is nonempty. Hence, there exists anassignment to and such that Condition 1 of Theorem 6 issatisfied. Moreover, for all solutions in the varietywe have and as otherwise 1 is in thegenerating set of the ideal and, hence, would beidentified with . Hence, Condition 2 of Theorem 6 issatisfied and any element of is a solution of the linear networkproblem. Conversely, assume that .It follows that the variety is empty and there isno solution which satisfies the required conditions. Indeed,by choosing a proper value for any solution to the networkcoding problem would immediately give rise to a nonemptyvariety .Using Theorem 7, we have reduced the problem of decidingthe solvability of a linear network problem to the problemof deciding if a variety is empty or not. We can decide thisproblem using Buchbergers algorithm 19 to compute aGrbner basis for the ideal . It is well known 19that the Grbner basis of an ideal equals 1 if and only if thecorresponding variety is nonempty. The techniques involvingGrbner bases exceed the scope of the paper, and we referthe reader to Cox et al. 19 for a thorough treatment of thismaterial. We only note that it is well known that, in general, thecomplexity of Grbner basis computations is not polynomiallybounded in the number of variables. Nevertheless, mathematicssoftware routinely solves large Grbner basis computations.A careful study of the structure ofas obtained from network problems, as well as optimizing thecomputation of a Grbner basis for the ideal of a linear networkproblem, are important future tasks for deriving efficientalgorithms deciding a network problem.C. Some Special Network ProblemsIn a few cases, it is relatively straightforward to satisfy theconditions of Theorems 6 and 7. These approaches can be subsumed under the principle that the conditions of Theorem 6 canbe satisfied by means of linear algebra alone. The multicast scenario of Section IVA is the simplest example of this situation.We start with the case of multiple sources and multiple sinksin a network coding problem where all sources want to communicate all their information to all sinks. In other words, the setof desired connections between sources and sinks is givenas . Onecharacterization of this setup is, again, that it is interference freedue to the fact that all sinks are supposed to receive all the information. This interferencefree situation was also exploited in15, where a similar theorem was stated in the context of general, potentially nonlinear, coding strategies.Theorem 8 Let a linear acyclic delayfree network be given with a set of desired connections.The network problem is solvable if and only if theMinCut MaxFlow bound is satisfied for any cut between allsource nodes and any sink node .Proof We consider the transfer matrices between thesource nodes and any of the sink nodes individually. Eachmatrix, considered as matrix over , is nonsingular by assumption. Hence, we can find an assignment of numbers to thevariables such that the matrix evaluated at these points is nonsingular over . This holds for each relevant bymatrix. The sink nodes can obtain the desired information by choosing matrix appropriately.We note that Theorem 8 contains Theorem 4 as a special casefor . The situations are relatively similar and Theorem 8can be reduced to Theorem 4 by introducing a super node havingaccess to the entire information feeding information to the nodes.A surprising fact in solving a given set of connections in thesetup of Theorem 8 is that there is no encoding necessary atthe source nodes. This is also clear from the observation thatthis case is interference free. However, allowing for properencoding at the source node is crucial for the general networkingproblem. In a number of special cases, we can make use of theencoding opportunity at the sources to guarantee the existenceof a solution to a network coding problem. In the remainingtheorems of this section, we specialize to the case of one source,which gives us complete control over the encoding matrix .The specific type of network coding problem that is covered ineach of the subsequent theorems is specified in the set of desiredconnections.We say that the MinCut MaxFlow is satisfied between asource node and a set of sink nodes at ratesif it is satisfied for any cut seperating a setfrom at a rate .Theorem 9 Let a linear acyclic delayfree network be given with a set of desired connectionssuch that allcollections of random processes are mutually disjoint, i.e.,for . The network problem issolvable if and only if the MinCut MaxFlow bound is satisfiedKOETTER AND MDARD ALGEBRAIC APPROACH TO NETWORK CODING 791between and the set of sink nodes at rates.Proof We can assume, without loss of generality, that themutually disjoint random processes partition the set. Hence, the overall transfer matrix is a bysquare matrix that is nonsingular by assumption. Choosingmatrix at the source node properly, we can guarantee thatthe overall transfer matrix realizes the identity matrix and eachsink node receives the data stream intended for it. Conversely,assume that the MinCut MaxFlow is not satisfied for anysubset of the sink nodes. It follows that the correspondingsubmatrix of the transfer matrix contains linearly dependentcolumns and, hence, the overall transfer matrix cannot benonsingular.We note that the setup of Theorem 9 breaks down if we allowmore than one source node because this imposes a restrictionon the particular form of matrix . However, we can loosenthe restrictions on the disjointness of the information to be distributed to different nodes. In particular, we can augment theset of connections of Theorem 9 by a number of connectionsthat should receive the entireinformation injected into the network at node .Theorem 10 Let a linear acyclic delayfree network begiven with a set of desired connectionssuch that the collections of random processes ,are mutually disjoint for , i.e.,for , . The network problem issolvable if and only if the MinCut MaxFlow bound is satisfiedbetween and the set of sink nodes at ratesand between and , at a rate .Proof The proof is an extension of the proof of Theorem 9. The transfer matrix of this proof is augmented by anumber of by square matrices correspondingto the connections . The matrix that we chosein the proof of Theorem 9 is nonsingular and, hence, theproduct of and the square matrices corresponding to theconnections is nonsingular, too. These matricescan be inverted by a proper choice of matrix .Theorem 10 has an interesting corollary for the case of twosink nodes, which might be best described as twolevel multicast. The setup assumes two sinks such that one sink shouldreceive all the information , while a second sink receivesonly a subset of .Corollary 2 Let a linear acyclic delayfree network be given with a set of desired connections. The network problemis solvable if and only if the MinCut MaxFlow bound issatisfied between and at a rate and betweenand at a rate .There are a large number of special cases which can be treatedsimilarly to the results given in this section. The proofs of theabove theorems should be adaptable to these situations with onlyminor modifications.We now turn our attention to the problem of robust networks.V. ROBUST NETWORKSAn interesting challenge is added to the problem of networkcoding if we assume that links in a network may fail. The question then becomes, under which failure pattern a successful network usage is still guaranteed. Let be a failing link.We assume that any downstream sink node, i.e., any node thatcan be reached from via a directed path, can be notified ofthe failure of link . However, no other nodes are being notifiedof the link failure. Given a network and a link failure pattern, it is straightforward to consider the network that is obtained by deleting the failing links and applying the results ofSections IIIV to this setup. We are interested in static solutionswhere the network is oblivious to the particular failure pattern.The idea is that each node transmits on outgoing edges a function of the observed random processes, such that the functionsare independent of the current failure pattern. Here, we use theconvention that the constant 0 is observed on failing links. Wecan achieve the effect of a failing link by setting parametersand to zero for all and , which effectivelyanihilates the influence of any random process transmitted onedge . Let be the system matrix for a particular linearnetwork coding problem. Moreover, let the set of parametersthat are affected by a failing link , i.e., that correspond toand for all and , be denoted asFor any particular link failure pattern , we define asThe following lemma makes the connection between the network problem without and with a link failure pattern .Lemma 2 Let be the system matrix of a linear networkcoding problem with system matrix . Let be a particularlink failure pattern and let be the system matrix for thenetwork obtained by deleting the failing links. We have thefollowing relation between and .Proof The effect of a failed link can be modeled by thefact that no information about a random process is either fedinto a failed link or is fed from the failed link into another link.Setting the coefficients to zero is compliant with theassumption that a constant 0 is observed on failed nodes.Let be the set of failure patterns such that the network coding problem is solvable. For the multicastscenario, i.e., the case ,, we have the following surprising result.Theorem 11 Let a linear network and a set of connections ,be given. There exists a common static solution to the networkproblems for all .Proof Let be any particular failure pattern that renders asolvable network. Let be the determinant of the transfermatrix corresponding to connection . We considerthe product . By Lemma 1, we canfind an assignment of numbers to such that and, hence,every single determinant evaluates to a nonzero valuesimultaneously. It follows that regardless of error pattern in ,the basic multicast requirements are satisfied.792 IEEEACM TRANSACTIONS ON NETWORKING, VOL. 11, NO. 5, OCTOBER 2003Theorem 11 makes very robust multicast scenarios possiblein a sense, the multicast can be organized as robustlyas possible. It is also interesting to note that choosing thevalue of the variables at random from a large enough fieldyields a solution, which with high probability achieves maximum robustness of the network. We can give an equivalentto Theorem 5 and Corollary 1. In formulating the followingtheorem, the price we have to pay for this exceptional robustness becomes apparent.Theorem 12 Let a delayfree communication network anda solvable multicast network problem be given with one sourceand receivers. Moreover, let be a set of failurepatterns from which we want to recover. Let be the rate atwhich the source generates information. There exists a solution to the network coding problem in a finite field with.Proof Let be the product of the determinants of thetransfer matrices for the individual connections and let bethe maximal degree of with respect to any variable . Following the proof of Corollary 1, we know that is bounded by. Altogether, we have to consider the product of determinants. The theorem follows.The question arises if statements like Theorem 11 can be derived for a general network problem. The following exampleshows that simple network coding problems exist that do notallow a static solution for different failure patterns in .Example 4 We consider the network depicted inFig. 6. Let the capacity of all edges be one bit pertime unit and let the set of desired connections begiven as , with.The example is small enough that it is possible to verify directly that 1 the network coding problem is solvable for anysingle failure involving a single link and 2 there does not exista static solution for any linear or nonlinear coding strategy.We show how this observation is reflected in the algebraic setup of our approach. Let the input vector and theoutput vector be given as and. The transfer matrix is found toequalwhere account for the way the elements of are fedinto the network, while account for the linearmixing being performed at the sink nodes.The ideal of the network coding problemis generated by the polynomials ,and we can easily find a point in the corresponding variety.abFig. 6. a Communication network with two source nodes v  v  and twosink nodes u  u . b Corresponding labeled line graph.Next, we consider the case that link fails. According toLemma 2, we find the corresponding transfer matrix byletting all variables be zero. Hence,the ideal is generated by. Similarly,we consider the case that link fails in which case we findthat and is generated by.A necessary condition for the existence of a commonsolution to the network problems obtained if either orfails is that the smallest ideal containing andis a proper ideal of or, in otherwords, the intersection of the corresponding varieties is notempty.The ideal is generated by, and it can beseen that the condition that either of , or has to beequal to zero leads to a situation in which either the equationor cannot besatisfied. Hence, and and there does not exista static solution which allows for failure of the link or .VI. NETWORKS WITH DELAYSo far, we have dealt with delayfree and hence, by assumption, cyclefree networks. The extension to networks with delays is relatively straightforward while technical for the multicast scenario. The general scenario requires considerably moretechnical tools. The main problem in the treatment of the general setup is that the system matrix is a matrix over the polynomial ring whose coefficients are rational functions ina delay variable . Hence, the natural field of consideration isthe algebraic closure of the field of rational functions in .KOETTER AND MDARD ALGEBRAIC APPROACH TO NETWORK CODING 793Given an acyclic network with delay, we can either operatethe network in a continuous mode where information is continuously injected into the network or we can operate the network in a burstoriented mode. In the latter mode, each vertextransmits information on an outgoing node only if an input hasbeen observed on all incoming links. This approach, taken byLi et al. 9, leads to a situation where a network with delay canbe thought of as instantaneous and the results of Section IVAapply. The time fraction during which a particular link is idlecan be controlled by choosing the frame length large enough.Here, we treat the case of continuous operation of a networkwith delay. The problem arises that the same injected information can take different routes causing different delays throughthe network. This delay necessitates memory at the sink nodes.We now consider input random processes , outputrandom processes , and random processestransmitted on a link as power series in a delay parameter, i.e., ,and .Also, as before, given a particular orderingof sources and sinks we use the the notationand, todenote the vectors of random processes that are input andoutput of the system.In this paper, we restrict ourselves to interior network nodesthat operate in a memoryless fashion, which means that any internal node of the network can take linear combinations of thesymbols observed simultaneously on its incoming edges. However, this turns out to be too restrictive for the general linear network problem. Still, memoryless operation of the nodes is sufficient to treat a robust multicast scenario. Nevertheless, even forthis case, we will see that we have to allow for memory at thesink or source nodes. Formally, we have the following definition.Definition 2 Networks With Delay Let bea communication network with delay. We say that is alinear network if for all edges in the random processon a link satisfieswhere the coefficients and are elements of .The output at any node can be formed from the observed random processes at in any suitable fashion. However,it turns out that it is sufficient to consider linear operation at theoutput, i.e., we havewhere the coefficients and are elements of andaccounts for the memory required at sink node .The process of encoding information at the network nodesand feeding it into outgoing edges can again be captured in theadjacency matrix of the corresponding directed line graph.We distinguish the case of acyclic networks with delay from thecase of a network that contains cycles.Lemma 3 Let be the adjacency matrix of the labeled linegraph of a cyclefree network . The matrix has apolynomial inverse in the ring .Proof Using an ancestral ordering of the edges in the network, we see that can be written as an upper triangular matrix with entries from the ring .The claim follows by using a backsubstitution algorithm to givean explicit form of the inverse .Lemma 4 Let be the adjacency matrix of labeled linegraph of a network . The matrix has a inverse in thefield of rational functions .Proof The determinant of is nonzero, which canbe seen from letting be equal to zero. Hence, the matrix isinvertible over its field of definition which can be taken to be.As in the case of delayfree networks, we consider the systemmatrix . The entries of are defined as the rational functions, where is the response of thesystem to an excitation . The system matrix is again composed of the multiplication of three matrices , , anda matrix defined as in Section IIIA. However, nowmatrices and in general also contain rational functions in .In particular, the entries of a matrix are nowdefined asotherwise.Similarly, the entries of a matrix are defined asotherwise.We will call matrices constant, polynomial, and rational, depending on their domain of definition. Also, we call a rationalmatrix realizable if all entries in are realizable rationalfunctions, i.e., any entry in is defined when evaluated at .The following theorem gives the equivalent of Theorem 5 forthe case of networks with delay.Theorem 13 Let a communication network with delay begiven with rational matrices , . Let be the adjacency matrix of the corresponding labeled line graph . Thetransfer matrix of the network is given aswhere is the identity matrix.Proof The proof is essentially identical to the proof ofTheorem 3 and is, therefore, omitted.The base theorem underlying the development in Section IVis Theorem 2. The following reformulation applies to networkswith cycles.Theorem 14 Let a communication network be given. Thefollowing three statements are equivalent.794 IEEEACM TRANSACTIONS ON NETWORKING, VOL. 11, NO. 5, OCTOBER 20031 A pointtopoint connection is possible.2 The MinCut MaxFlow bound is satisfied for a rate .3 The determinant of the transfer matrix isnonzero over the fieldProof Again, most of the theorem is a direct consequenceof the MinCut MaxFlow Theorem, which also is true in thecase of cyclic networks. Statements 1 and 2 are equivalent bythis theorem. The FordFulkerson algorithm yields a solution tothe network problem that satisfies the requirements of a linearsolution. Hence, we can associate a system transfer matrix withthis solution which, consequently, has to have a nonzero determinant.Conversely, if the determinant of is nonzero, we can invertmatrix by choosing parameters and accordingly.From Lemma 1, we know that we can choose the parameters soas to make this determinant nonzero. Hence, 3 implies 1 andthe equivalence is shown.We are now in a position to state the main results concerningnetworks with cycles in a multicast and robust multicast setup.We start with a formulation of the multicast scenario.Theorem 15 Let a communication network and aset of connections , ,be given. The network problem issolvable if and only if the MinCut MaxFlow bound is satisfiedfor all connections in .Proof After changing the field of constants from to, the field of rational functions in , the proof is essentially the same as the proof of Theorem 4. The determinants ofthe relevant transfer matrices can be considered as the ratio ofpolynomials from the ring . By Lemma 1, we can findan assignment of such that all determinants are nonzero inand, hence, that all submatrices are invertible. Again,we can choose a realizable matrix , as a matrix with elements from such that is the fold repetition ofwhere is a large enough integer and is theunit matrix.Corollary 3 Let a linear network be given with a set ofdesired connections ,. The network problem is solvable if and only ifthe MinCut MaxFlow bound is satisfied for any cut betweenall source nodes and any sink node .Li et al. give a result for the multicast problem that concernsthe achievability of the MinCut MaxFlow bound in networkswith cycles. The codes employed in their setup are timevaryingand the question is raised if a timeinvariant multicast networkexists that satisfies the simultaneous MinCut MaxFlow bound.An important consequence of the proof of Theorem 15 is thefollowing corollary, which answers this question affirmatively.Corollary 4 Let a communications network and aset of connections , ,be given. The network problem has atimeinvariant solution if and only if the MinCut MaxFlowbound is satisfied for all connections in .Proof The proof follows from the proof of Theorem 15.In particular, the individual determinants can be made nonzeroby choosing the assignment of over rather than . Itshould be noted that while the operations performed at the interior nodes of the network are timeinvariant, the individual sinknodes have to implement rational functions involving memoryin order to output the possibly delayed input .The same arguments that lead to the derivation of robust networks and Theorem 11 can be extended to the case of networkswith delays allowing the sink nodes to implement rational functions in . In particular, following Corollary 4, such a robustsolution can be made timeinvariant.By now, it should be clear that all the particular network problems treated in Section IVC have an equivalent formulation fornetworks with cycles. For brevity, we will not reformulate thesetheorems.VII. CONCLUSIONWe have presented an algebraic framework for investigatingcapacity issues in networks using linear codes. The introducedtechnique makes a connection between certain systems of polynomial equations and the solutions to network problems. Theuse of algebra in this context is a significant and enabling tool,since it is possible to capitalize on powerful theorems in thiswellestablished field of mathematics.We see many roads opening up for further research. The investigation of network behavior under randomly chosen codesis an intriguing question in the context of selforganizing networks. Other avenues are a structured investigation of networkmanagement requirements for robust networks. In particular, relating a change in a network to the change in receiver functioncan give insight into the minimum number of bits required torespond to failure scenarios.Other issues involve the development of protocols that capitalize on the insights from network coding. More theoretical issues address questions about the sufficiency of network codingas well as a general separability of network coding and codingfor ergodic link failures.REFERENCES1 T. M. Cover, Comments on broadcast channels, IEEE Trans. Inform.Theory, vol. 44, pp. 25242530, Oct. 1998.2 , Broadcast channels, IEEE Trans. Inform. Theory, vol. IT18,pp. 214, Jan. 1972.3 , An achievable rate region for the broadcast channel, IEEETrans. Inform. Theory, vol. IT21, pp. 300404, July 1975.4 R. Ahlswede, Multiway communication channels, in Proc. 1971IEEE Int. Symp. Information Theory, pp. 2352.5 H. Liao, Multipleaccess channels, Ph.D. dissertation, Univ. Hawaii,1972.6 E. Van der Meulen, Threeterminal communication channels, Adv.Appl. Probabil., vol. 3, pp. 120154, 1971.7 T. Cover and A. El Gamal, Capacity theorems for the relay channel,IEEE Trans. Inform. Theory, vol. IT25, pp. 572584, Sept. 1979.8 B. Schein and R. Gallager, The Gaussian parallel relay network, inProc. 2000 IEEE Int. Symp. Information Theory, p. 22.9 S. Y. R. Li, R. W. Yeung, and N. Cai, Linear network coding, IEEETrans. Inform. Theory, vol. 49, p. 371, Feb. 2003.10 R. Ahlswede, N. Cai, S.Y. R. Li, and R. W. Yeung, Network information flow, IEEE Trans. Inform. Theory, vol. 46, pp. 12041216, July2000.11 S.Y. R. Li and R. W. Yeung, Network multicast flow via linear coding,in Proc. Int. Symp. Operations Research and its Applications, 1998, pp.197211.KOETTER AND MDARD ALGEBRAIC APPROACH TO NETWORK CODING 79512 R. W. Yeung, A First Course in Information Theory. Norwood, MAKluwer, 2002.13 R. W. Yeung and Z. Zhang, Distributed source coding for satellite communications, IEEE Trans. Inform. Theory, vol. 45, pp. 11111120, May1999.14 E. Ayanoglu, I. ChihLin, R. D. Gitlin, and J. D. Mazo, Diversitycoding Using error control for selfhealing in communication networks, in Proc. IEEE INFOCOM, vol. 1, 1990, pp. 95104.15 S.Y. R. Li and R. W. Yeung, Network information flowmultiplesources, in Proc. 2001 IEEE Int. Symp. Information Theory, p. 102.16 D. P. Bertsekas, Network Optimization Continuous and DiscreteModels. Belmont, MA Athena Scientific, 1998.17 P. Elias, A. Feinstein, and C. E. Shannon, A note on the maximum flowthrough a network, IEEE Trans. Info. Theory, vol. IT2, pp. 117119,Dec. 1956.18 W. Fulton, Algebraic Curves. New York Benjamin, 1969.19 D. Cox, J. Little, and D. OShea, Ideals, Varieties, and Algorithms AnIntroduction to Computational Algebraic Geometry and CommutativeAlgebra. New York Springer, 1992.Ralf Koetter S92M95 received the Diploma degree in electrical engineering from the Technical University Darmstadt, Darmstadt, Germany, in 1990 andthe Ph.D. degree from the Department of ElectricalEngineering, Linkping University, Sweden.From 1996 to 1997, he was a Visiting Scientist atthe IBM Almaden Research Laboratory, San Jose,CA. He was a Visiting Assistant Professor at theUniversity of Illinois at UrbanaChampaign, anda Visiting Scientist at CNRS, Sophia Antipolis,France, from 1997 to 1998. He joined the faculty ofthe University of Illinois at UrbanaChampaign in 1999, where he is currentlyan Assistant Professor with the Coordinated Science Laboratory. His researchinterests include coding and information theory and their application tocommunication systems.Dr. Koetter received an IBM Invention Achievement Award in 1997, aNational Science Foundation CAREER Award in 2000, and an IBM PartnershipAward in 2001. He served as Associate Editor for coding theory and techniquesfor the IEEE TRANSACTIONS ON COMMUNICATIONS from 1999 to 2001. In2000, he started a term as Associate Editor for coding theory of the IEEETRANSACTIONS ON INFORMATION THEORY.Muriel Mdard S91M95SM00 received B.S.degrees in electrical engineering and computer science and in mathematics in 1989, the B.S. degree inhumanities in 1990, the M.S. degree in electrical engineering in 1991, and the Sc.D. degree in electricalengineering in 1995, all from the Massachusetts Institute of Technology MIT, Cambridge.She is an Esther and Harold E. Edgerton Associate Professor in the Department of Electrical Engineering and Computer Science, MIT, and a memberof the Laboratory for Information and Decision Systems. She was previously an Assistant Professor in the Department of Electricaland Computer Engineering and a member of the Coordinated Science Laboratory of the University of Illinois at UrbanaChampaign. From 1995 to 1998, shewas a Staff Member of the MIT Lincoln Laboratory in the Optical Communications and the Advanced Networking Groups. Her research interests are in theareas of reliable communications, particularly for optical and wireless networks.Dr. Mdard received the IEEE Leon K. Kirchmayer Prize Paper Awardin 2002. She is an Associate Editor for the Optical Communicationsand Networking Series of the IEEE JOURNAL ON SELECTED AREAS INCOMMUNICATIONS, and has been a Guest Editor for the JOURNAL OFLIGHTWAVE TECHNOLOGY and an Associate Editor for the OSA Journal ofOptical Networking.
