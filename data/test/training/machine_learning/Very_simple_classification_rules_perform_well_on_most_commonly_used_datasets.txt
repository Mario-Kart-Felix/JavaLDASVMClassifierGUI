Very Simple Classification Rules Perform Wellon Most Commonly Used DatasetsRobert C. Holte holtecsi.uottawa.caComputer Science Department, University of Ottawa, Ottawa, Canada K1N 6N5The classification rules induced by machine learning systems are judged by two criteriatheir classification accuracy on an independent test set henceforth accuracy, and theircomplexity. The relationship between these two criteria is, of course, of keen interest tothe machine learning community.There are in the literature some indications that very simple rules may achievesurprisingly high accuracy on many datasets. For example, Rendell occasionally remarksthat many real world datasets have few peaks often just one and so are easy to learnRendell  Seshu, 1990, p.256. Similarly, Shavlik et al. 1991 report that, with certainqualifications, the accuracy of the perceptron is hardly distinguishable from the morecomplicated learning algorithms p.134. Further evidence is provided by studies ofpruning methods e.g. Buntine  Niblett, 1992 Clark  Niblett, 1989 Mingers, 1989,where accuracy is rarely seen to decrease as pruning becomes more severe for example,see Table 11. This is so even when rules are pruned to the extreme, as happened with theErrcomp pruning method in Mingers 1989. This method produced the most accuratedecision trees, and in four of the five domains studied these trees had only 2 or 3 leavesMingers, 1989, pp. 238239. Such small trees cannot test more than one or twoattributes. The most compelling initial indication that very simple rules often performwell occurs in Weiss et al., 1990. In 4 of the 5 datasets studied, classification rulesinvolving 2 or fewer attributes outperformed more complex rules.This paper reports the results of experiments measuring the performance of very simplerules on the datasets commonly used in machine learning research. The specific kind ofrules examined in this paper, called 1rules, are rules that classify an object on thebasis of a single attribute i.e. they are 1level decision trees. Section 2 describes asystem, called 1R, whose input is a set of training examples and whose output is a 1rule.In an experimental comparison involving 16 commonly used datasets, 1Rs rules are onlya few percentage points less accurate, on most of the datasets, than the decision treesproduced by C4 Quinlan, 1986. Section 3 examines possible improvements to 1Rscriterion for selecting rules. It defines an upper bound, called 1R, on the accuracy thatsuch improvements can produce. 1R turns out to be very similar to the accuracy of C4sdecision trees. This result has two implications. First, it indicates that simplemodifications to 1R might produce a system competitive with C4, although morefundamental modifications are required in order to outperform C4. Second, this resultsuggests that it may be possible to use the performance of 1rules to predict theperformance of the more complex hypotheses produced by standard learning systems.1 conditions under which pruning leads to a decrease in accuracy hav e been investigated by Schaffer1992 in press and Fisher  Schlimmer 1988.1 Machine Learning 116391, 1993TABLE 1. Results of a typical experimental study Buntine  Niblett, 1992. Foreach dataset the error rates of 4 systems are sorted in increasing order. Only 3 entriesviolate the rule that error rate increases as complexity leaf count increases these aremarked with an asterisk.Dataset Error Rates Corresponding Leaf CountsBC 27.2 28.5 28.7 29.7 6.0 9.3 10.2 25.4GL 39.6 40.5 50.6 53.2 8.1 8.5 8.9 21.8HY 0.95 1.01 1.27 7.44 4.8 5.0 5.8 34.0IR 4.9 5.0 5.5 14.2 3.5 3.5 3.4 12.1LY 24.0 24.3 24.4 32.3 7.5 7.7 8.2 15.5MU 1.44 1.44 7.31 8.77 12.4 12.4 23.3 48.7VO 4.5 4.6 11.8 15.6 5.1 5.2 12.4 22.9V1 12.8 13.0 15.1 15.6 8.9 9.4 13.0 22.9led 32.9 33.2 33.8 38.2 13.0 13.1 13.3 19.4pole 15.0 15.4 15.5 26.4 5.4 5.7 5.8 22.8tumor 60.9 61.6 62.7 67.9 19.6 17.6 22.5 32.8xd6 22.06 22.14 22.17 31.86 14.8 14.9 14.8 20.1Section 4 defines a practical prediction system based on 1rule accuracy, compares itspredictions to the accuracies of all learning systems reported in the literature, anddiscusses its uses. Section 5 considers the practical significance of these results, andsections 6 and 7 discuss the implications of the results for machine learning applicationsand research.1. 1R  a program that learns 1rules from examplesProgram 1R is ordinary in most respects. It ranks attributes according to error rate onthe training set, as opposed to the entropybased measures used in C4. It treats allnumericallyvalued attributes as continuous and uses a straightforward method to dividethe range of values into several disjoint intervals. It handles missing values by treatingmissing as a legitimate value. Appendix A giv es pseudocode for 1R.In datasets with continuouslyvalued attributes there is a risk of overfitting. In dividingthe continuous range of values into a finite number of intervals it is tempting to makeeach interval pure, i.e. contain examples that are all of the same class. But just asoverfitting may result from deepening a decision tree until all the leaves are pure, so toooverfitting may result from subdividing an interval until all the subintervals are pure. Toavoid this, 1R requires all intervals except the rightmost to contain more than apredefined number of examples in the same class. Based on the results in Holte et al.1989, the threshold was set at 6 for all datasets except for the datasets with fewestexamples LA,SO where the threshold was set at 3.2 Machine Learning 116391, 1993A similar difficulty sometimes arises with nominal attributes. For example, consider adataset in which there is a nominal attribute that uniquely identifies each example, such asthe name of a patient in a medical dataset. Using this attribute, one can build a 1rulethat classifies a given training set 100 correctly needless to say, the rule will notperform well on an independent test set. Although this problem is uncommon, it did arisein two of the datasets in this study GL,HO the problematic attributes have beenmanually deleted from the datasets.1.1 The Datasets Used for Experimental Comparison.Sixteen datasets were used to compare 1R with C4, a stateoftheart learning algorithm.Fourteen of the datasets were selected from the collection of datasets distributed by themachine learning group at the University of California at Irvine see Appendix B. Theselection includes many of the datasets most commonly used in machine learningresearch. In addition to these fourteen datasets, the study includes a 2class version ofGL G2, and, following Buntine  Niblett, 1992, a version of VO in which the bestattribute has been deleted V1.Table 2 gives a brief description of the datasets note that they exhibit a wide variety ofcharacteristics. Dataset gives the twoletter name used to refer to the dataset. If thereare more than 2 classes in a dataset, the number of classes is indicated in parenthesesTABLE 2. Datasets used in the experiments.blank entries represent 0sBaseline Missing Attributes ... number of distinct valuesAccuracy Values cont 2 3 4 5 6 6 TOTALDataset SizeBC 286 70.3 yes 3 2  1 1 2 9CH 3196 52.2 no 35 1 36GL 6 214 35.5 no 9 9G2 163 53.4 no 9 9HD 303 54.5 yes 5 3 3 2  13HE 155 79.4 yes 6 13 19HO 368 63.0 yes 7 2 5 5 2 1  22HY 3163 95.2 yes 7 18 25IR 3 150 33.3 no 4 4LA 57 64.9 yes 8 3 5 16LY 4 141 56.7 no 2 9 2 5  18MU 8124 51.8 yes 5 1 5 1 2  7 22SE 3163 90.7 yes 7 18 25SO 4 47 36.2 no 13 3 4  1 35VO 435 61.4 yes 16 16V1 435 61.4 yes 15 153 Machine Learning 116391, 1993after the name. Size gives the total number of examples in the dataset. BaselineAccuracy gives the percentage of examples in the most frequently occurring class in thedataset. Missing Values indicates whether there are any examples in the dataset forwhich the value of some attribute is unknown. The remaining columns indicate thenumber of attributes having a given number of values. To be counted, in Table 2, ascontinuous column entitled cont an attribute must have more than 6 numerical values.The total number of attributes in a dataset is given in the rightmost column. The total isthe sum of the other Attributes columns plus the number of attributes in the dataset forwhich all examples have the same value. For example, in the SO dataset there are 13attributes having 2 values, 3 attributes having 3 values, 4 attributes having values 4values, and 1 attribute having more than 6 nonnumeric values. This accounts for 21 ofthe 35 attributes in the dataset the other 14 attributes have the same value in everyexample.1.2 Experiment 1. Comparison of 1R and C4.The version of C4 used in these experiments is C4.5 as distributed in May 1990. Thedefault settings of all parameters were used, except that windowing was turned off. Theaccuracies of C4 and 1R on a dataset are computed in the usual way, namely1. randomly split the dataset into two parts, a training set 23 of the dataset and atest set.2. Using the training set alone, generate a rule.3. Measure the accuracy of the rule on the test set.4. Repeat 13 25 times and average the results.The results of this experiment are given in Table 3.TABLE 3. Results of Experiment 1  Classification Accuracy.1R  average accuracy on the test set of the 1rule produced by 1R.C4  average accuracy on the test set of the pruned tree produced by C4DatasetBC CH GL G2 HD HE HO HY1R 68.7 67.6 53.8 72.9 73.4 76.3 81.0 97.2C4 72.0 99.2 63.2 74.3 73.6 81.2 83.6 99.1DatasetIR LA LY MU SE SO VO V11R 93.5 71.5 70.7 98.4 95.0 81.0 95.2 86.8C4 93.8 77.2 77.5 100.0 97.7 97.5 95.6 89.44 Machine Learning 116391, 19931.3 Discussion of Experiment 1.On average 1Rs accuracy is 5.7 percentage points lower than C4s. However, thisav erage is quite misleading on 12 of the 16 datasets, the difference between 1Rsaccuracy and C4s is less than the average. This skewness is caused by the two datasetsCH,SO on which 1Rs accuracy is extremely poor compared to C4s. On the other 14datasets, 1Rs accuracy is an average of 3.1 percentage points lower than C4s. On halfthe datasets, 1Rs accuracy is within 2.6 percentage points of C4s. To summarize theseresults in general terms, one would say that on most of the datasets studied 1Rs accuracyis about 3 percentage points lower than C4s.These results raise two related questions1 why was C4s accuracy not much greater than 1Rs on most of the datasets 2 is there anything special about the CH and SO datasets that caused 1R to perform sopoorly Considering question 1, there is no evidence that C4 missed opportunities to exploitadditional complexity in order to improve its accuracy C4s pruned trees were the sameaccuracy as its unpruned ones not shown. It is possible that C4 is overfitting, i.e., thatslightly less complex decision trees might have been more accurate, but this possibilityhas been explored only partially. Experiments were run in which C4 was forced to build1rules. These 1rules were never more accurate than the pruned trees C4 wouldnormally have produced C4 is therefore correct in not pruning to the extreme. In fact, asurvey of the literature reveals that C4s performance on these datasets is better than mostlearning systems see Appendix C for details and section 4 for a discussion of thissurvey.If the answer to question 1 lies not in the C4 algorithm, it must lie in the datasetsthemselves. It may simply be a fact that on these particular datasets 1rules are almost asaccurate as more complex rules. For example, on 2 datasets BC,HE, few learningsystems have succeeded in finding rules of any kind whose accuracy exceeds the baselineaccuracy by more than 2 percentage points see Appendix C.2 On a few datasets IR, forexample C4 prunes its decision tree almost to a 1rule, a clear indication that, on thesedatasets, additional complexity does not improve accuracy. Section 6 examines in detailthe complexity of C4s rules.Turning to question 2, there is a characteristic of the CH and SO datasets that is apotential source of difficulty for a 1rule learner. In these datasets there is only oneattribute having more values than there are classes. In CH there are 2 classes, and there isone attribute having 3 values, and 35 attributes having 2 values. In SO there are 4 classes,and there is one attribute having 7 values, 4 attributes having 4 values, and 30 attributeshaving fewer than 4 values. By contrast, in almost all the other datasets there arecontinuous attributes which can be divided into as many intervals as necessary orseveral attributes having more values than there are classes.2 Clark  Boswell 1991 offers some discussion of this phenomenon.5 Machine Learning 116391, 1993To see why this characteristic can cause 1rules to have unusually low accuracies,consider an extreme example  the soybean dataset used in Michalski  Chilausky1980. In this dataset there are 15 classes, and there is one attribute having 10 values,3one attribute having 7 values, and 33 other attributes having 5 or fewer values. Assumingthe attribute with 10 values perfectly separates the examples in the 10 largest classes, a1rule based on this attribute would achieve 86 accuracy. This is 11 percentage pointslower than the accuracy of the complex rules reported in Michalski  Chilausky 1980.If this attribute turns out to be a poor classifier, the next best accuracy possible by a1rule is 76, which happens only if the 7valued attribute perfectly separates theexamples of the 7 largest classes. The accuracy of 1rules based on 5valued attributes is66 or less on this dataset. Of course, more complex rules can separate the examples inall of the classes, and one would expect them to clearly outperform 1rules on datasetssuch as this.This characteristic is thus an indication that 1rules might perform poorly. Howev er, onemust not conclude that 1rules will always perform poorly on datasets having thischaracteristic VO and V1 provide examples to the contrary. In fact, on half the datasets,the number of leaves in 1Rs rules is within 1 of the number of classes, as the followingtable shows.BC CH GL G2 HD HE HO HY IR LA LY MU SE SO VO V1 leaves 7  2 4 4  4 3 3  5 3 4  3 9 5 4 3 3 classes 2 2 6 2 2  2  2 2 3 2 4  2 2 4  2 2The numbers in this table include the leaf for missing providing it is nonempty. This isthe reason that there are 3 leaves for the VO dataset even though all the attributes have 2values. In the LY dataset two of the four classes have very few examples, so relativelyhigh accuracy can be achieved with fewer leaves than classes.If the poor performance of 1R on CH and SO is to be explained as a consequence of thedatasets having only one attribute with more values than there are classes, it is thennecessary to address the question, why did 1R perform well on several datasets alsohaving this property . The answer to this question, like the answer to question 1, maybe that it is simply a fact about these particular datasets that classes and the values ofsome attributes are almost in 11 correspondence.3 In the version of this dataset in the Irvine collection, this attribute has only 4 values.6 Machine Learning 116391, 19933. An Upper Bound on Improvements to 1Rs Selection CriterionGiven a dataset, 1R generates its output, a 1rule, in 2 steps. First it constructs arelatively small set of candidate rules one for each attribute and then it selects one ofthese rules. This 2step pattern is typical of many learning systems. For example, C4consists of two similar steps first it constructs a large decision tree, and then, in thepruning step, it selects one of the subtrees of the tree constructed in the first step.In any such 2step system it is straightforward to compute an upper bound on theaccuracy that can be achieved by optimizing the selection step. This is done by simplybypassing the selection step altogether and measuring the accuracy on the test set of allthe rules available for selection. The maximum of these accuracies is the accuracy thatwould be achieved by the optimal selection method. Of course, in practice one isconstrained to use selection methods that do not have access to the final test set, so it maynot be possible to achieve the optimal accuracy. Thus, the optimal accuracy is an upperbound on the accuracy that could be achieved by improving the selection step of thesystem being studied.There are at least two important uses of an upper bound computed in this way. First, ifthe systems current performance is close to the upper bound on all available datasets,then it will be impossible to experimentally detect improvements to the selection step.For example, before doing a largescale study of various pruning methods, such asMingers,1989, it would have been useful to compute the upper bound on accuracyachievable by any pruning method. Such a study may have indicated that there was littleroom for variation amongst all possible pruning methods on the datasets beingconsidered.The second important use of this upper bound is in comparing two systems. If the upperbound on accuracy of one system, S1, is less than the actual accuracy of another system,S2, then the only variations of S1 that can possibly outperform S2 are ones whose firststep is different than S1s. This is the use made of the upper bound in this section thefollowing experiment was undertaken to determine if modifications to 1Rs selection stepcould possibly result in 1R equalling or exceeding C4s performance.3.1 Experiment 2.An upper bound on the accuracy achievable by optimizing 1Rs selection step iscomputed as follows.1. randomly split the dataset into two parts, a training set and a test set.2. Using the training set alone, generate a set of rules.3. Measure the highest accuracy of all the generated rules on the test set.4. repeat 13 25 times and average the results.The same trainingtesting sets were used as in experiment 1. The results of thisexperiment are given in table 4. For ease of reference, the upper bound is given the name1R.7 Machine Learning 116391, 1993TABLE 4. Results of Experiment 2  Classification Accuracy.1R, C4  as in Table 3.1R  the highest accuracy on the test set of all the rules constructed by 1Rwith greater than baseline accuracy of the training set. This is an upper bound on the accuracy achievable by optimizing 1Rs selectionstep.DatasetBC CH GL G2 HD HE HO HY1R 68.7 67.6 53.8 72.9 73.4 76.3 81.0 97.21R 72.5 69.2 56.4 77.0 78.0 85.1 81.2 97.2C4 72.0 99.2 63.2 74.3 73.6 81.2 83.6 99.1DatasetIR LA LY MU SE SO VO V11R 93.5 71.5 70.7 98.4 95.0 81.0 95.2 86.81R 95.9 87.4 77.3 98.4 95.0 87.0 95.2 87.9C4 93.8 77.2 77.5 100.0 97.7 97.5 95.6 89.43.2 Discussion of Experiment 2.1Rs accuracy cannot exceed 1R because the rule selected by 1R is in the set of ruleswhose accuracies are used to compute 1R. On average, 1Rs accuracy is 3.6 percentagepoints lower than 1R. On 5 datasets the difference in accuracies is negligible and on afurther 5 datasets the difference is not large 3.8 percentage points or less. Bearing inmind that 1R is a rather optimistic upper bound, one may conclude that changes to 1Rsselection criterion will produce only modest improvement in accuracy on most of thedatasets in this study.The difference between C4s accuracy and 1R is not particularly large on most of thedatasets in this study. On twothirds 10 of the datasets the difference is 2.7 percentagepoints or less. On average, 1R is 2.1 percentage points less than C4s accuracy, and only0.28 less if the CH dataset is ignored. On half of the datasets, 1R is higher than ornegligibly lower than C4s accuracy. For these reasons, one may conclude that the mostaccurate 1rule constructed by 1R is, on almost all the datasets studied, about the sameaccuracy as C4s decision tree.This result has two main consequences. First, it shows that the accuracy of 1rules canbe used to predict the accuracy of C4s decision trees. Section 4 develops a fast predictor,based on 1rule accuracy, and discusses several different uses of such a predictor.Secondly, this result shows that 1R is failing to select the most accurate of the 1rules it isconstructng. With an improved selection criterion 1R might be competitive, as a learningsystem, with C4 except on datasets such as CH. On the other hand, it is certain that8 Machine Learning 116391, 1993however the selection criterion is improved, 1R will never significantly outperform C4. IfC4 is to be surpassed on most datasets by a 1rule learning system, changes of a morefundamental nature are required.4. Using 1rules to predict the accuracy of complex rules.An ideal predictor would be a system that made a single, rapid pass over the given datasetand produced an accuracy comparable to C4s on the dataset. A natural candidate is 1Ritself, using the whole dataset for both training and testing. 1Rw is defined to be theaccuracy computed in this way1. Run program 1R with the whole dataset as a training set to generate a rule calledthe Wrule.2. 1Rw is the accuracy of the Wrule on the whole dataset.Table 5 shows the value of 1Rw for the datasets in this study.A careful comparison of 1Rw with C4s accuracy inv olves two steps. The first step is touse a statistical test a twotailed ttest to evaluate the difference in accuracy on eachindividual dataset. This test computes the probability that the observed differencebetween 1Rw and C4s accuracy is due to sampling confidence is 1 minus thisprobability. Unless confidence is very high, one may conclude that there is no significantdifference between 1Rw and C4s accuracy on the dataset. If confidence is very high, oneproceeds with the second step of the comparison in which the magnitude of thedifferences is considered. This step is necessary because significance tests are notdirectly concerned with magnitudes very small differences can be highly significant. ForTABLE 5. 1Rw measured on the datasets.C4  as in Table 4.1Rw  highest accuracy of the 1rules produced when the whole dataset isused by 1R for both training and testing.DatasetBC CH GL G2 HD HE HO HYC4 72.0 99.2 63.2 74.3 73.6 81.2 83.6 99.11Rw 72.7 68.3 62.2 78.5 76.6 84.5 81.5 98.0DatasetIR LA LY MU SE SO VO V1C4 93.8 77.2 77.5 100.0 97.7 97.5 95.6 89.41Rw 96.0 84.2 75.7 98.5 95.0 87.2 95.6 87.49 Machine Learning 116391, 1993example, the difference between C4s accuracy and 1Rw on the MU dataset, although it isone of the smallest in magnitude, is much more significant than the difference on anyother dataset.The results of the ttests are as follows see appendix D for details. The differencesbetween C4s accuracy and 1Rw on the BC, GL, and VO datasets are not significant. Thedifference on the LY dataset is significant with 95 confidence. The differences on allother datasets are significant with greater than 99 confidence, i.e., the probability ofobserving differences of these magnitudes, if C4s accuracy is in fact equal to 1Rw, is lessthan .01.The difference between C4s accuracy and 1Rw, although statistically significant, is notparticularly large on most of the datasets in this study. On three quarters of the datasetsthe absolute difference is 3.3 percentage points or less. On average, 1Rw is 1.9percentage points less than C4s accuracy, and only 0.007 less if the CH dataset isignored. For these reasons, one may conclude that 1Rw is a good predictor of C4saccuracy on almost all the datasets studied.4.1 1Rw as a Predictor of Accuracy of Other Machine Learning Systems.In order to evaluate 1Rw as a predictor of the accuracy of machine learning systems ingeneral, the machine learning literature was scanned for results on the datasets used inthis study4. Appendix C lists the results that were found in ths survey. The G2, HO, andSO datasets do not appear in Appendix C because there are no reported resultsconcerning them. A detailed comparison of the results for each dataset is impossible,because the results were obtained under different experimental conditions. Nevertheless,a general assessment of 1Rw as a predictor of accuracy can be made by comparing it oneach dataset to the median of the accuracies for that dataset reported in the literature.1Rw is very highly correlated with the medians, having a correlation coefficient r of99 if CH is ignored, 77 if CH is included. By fitting a line to this medianvs1Rwdata, one obtains a simple means of predicting medians given 1Rw. If this is done, thepredicted value differs from the actual value by only 1.3 percentage points on average ifCH is ignored.4 It is not always possible to be certain that a dataset described in the literature is identical to thedataset with the same name on which 1Rw was measured. The survey includes all results for which there isno evidence that the datasets differ.10 Machine Learning 116391, 19934.2 Uses of 1RwPredictors of accuracy, such 1Rw, or of relative accuracy, such as Fishers measure ofattribute dependence Fisher 1987 Fisher  Schlimmer 1988 are informativemeasurements to make on a dataset they can be used in a variety of ways.The most obvious use of 1Rw is as a benchmark accuracy for learning systems, i.e., as astandard against which to compare new results. The current benchmark is baselineaccuracy, the percentage of examples in a dataset in the most frequently occurring class.For most datasets baseline accuracy is relatively low, and therefore not a usefulbenchmark. 1Rw is only slightly more expensive to compute and it is often a verychallenging benchmark.Alternatively, one can measure 1Rw before applying a learning algorithm to a dataset, inorder to obtain a quick estimate of the accuracy that learned rules will have. Thisestimate could be compared to the accuracy required in the given circumstances. Anestimated accuracy that is lower than the required accuracy is an indication that learningmight not produce a rule of the required accuracy. In this case, the dataset should beimproved by collecting or creating additional attributes for each example e.g. compareV1 and VO, or reducing the number of classes e.g. compare GL and G2, or in someother way changing the representation. In constructive induction systems Rendell Seshu, 1990 1Rw is a natural method for evaluating new attributes, or even whole newrepresentations Saxena, 1989.5. The Practical Significance of the Experimental ResultsThe preceding experiments show that most of the examples in most of the datasetsstudied can be classified correctly by very simple rules. The practical significance of thisobservation hinges on whether or not the procedures and datasets that have been used inthe experiments  which are the standard procedures and datasets in machine learning faithfully reflect the conditions that arise in practice. Of particular concern are thedatasets. One does not intuitively expect real classification problems to be solved byvery simple rules. Consequently, one may doubt if the datasets used in this study arerepresentative of the datasets that actually arise in practice.It is true that many of the classification problems that arise in practice do not have simplesolutions. Rendell  Seshu 1990 call such problems hard. The best known hardclassification problem is protein structure prediction, in which the secondary structure ofa protein must be predicted given a  description of the protein as an amino acid sequence.Another wellknown hard problem is the classification of a chess position as won or lost,given a description of the position in terms of low lev el features. The machine learningtechniques developed for easy classification problems are, by definition, of limited usefor hard classification problems the development of techniques appropriate to hardproblems is a challenging, and relatively new branch of machine learning.However, the fact that some real problems are hard does not imply that all real problemsare hard. A dataset faithfully represents a real problem providing it satisfies twoconditions. First, the dataset must have been drawn from a reallife domain, as opposed11 Machine Learning 116391, 1993to having been constructed artificially. All the datasets in this study satisfy thisrequirement. Secondly, the particular examples in the dataset and the attributes used todescribe them, must be typical of the examples and attributes that naturally arise in thedomain. That is, the datasets must not have been specially engineered by the machinelearning community to make them easy. The CH dataset does not satisfy thiscondition its attributes were engineered explicitly for ID3 by a chess expert working witha version of ID3 built specially for this purpose Shapiro, 1987, pp.7173. Indeed, thedevelopment of CH was a case study of one particular technique structured inductionfor transforming a hard classification problem into an easy one.Thus, the practical significance of the present study, and other studies based on thesedatasets, reduces to the question are the examples and attributes in these datasets naturalor have they been specially engineered by the machine community learning as in CH inorder to make induction easy  The evidence pertaining to this question varies fromdataset to dataset.For 6 datasets HY,LA,MU,SE,VO,V1 the process by which the dataset was createdfrom the raw data is sufficiently well documented5 that it can confidently be asserted thatthese datasets faithfully represent real problems. The only instance of data adaptationthat is mentioned is in connection with the congressional voting data VO, V1. In theoriginal form, there were 9 possible positions a congressman could take tow ards a givenbill. In the dataset, some of these possibilities are combined so that there are only threepossible values for each attribute. The grouping is a natural one, and not one speciallycontrived to improve the results of learning.For 3 datasets BC,HO,LY, the creation of the dataset involved some cleaning of theraw data. The nature of this cleaning is not described in detail, but there is nosuggestion that that it involves anything other than the normal activities involved inrendering a heterogeneous collection of records into a uniform structure suitable formachine learning experiments.6 Thus there is no reason to doubt that these datasetsfaithfully represent real classification problems.The preceding datasets are adaptations, involving minimal changes, of data that hadalready been collected for a purpose other than machine learning. The SO dataset isdifferent, in that it was created for the purpose of machine learning. The account given ofthe creation of this dataset pp.134136, Michalski  Chilausky, 1980 mentions twocriteria for selecting attributes 1 each attribute must be measurable by a layman, and2 the dataset must include the attributes used in the expert system that was developedfor comparison with the induced classification rules. The account suggests that thedevelopment of the expert system involved iterative refinement. Although this accountdoes not explicitly comment on the extent to which the attributes evolved during theexpert system development, it not unreasonable to suppose that the attributes in thisdataset have been engineered, or at least selected, to ensure that accurate classification is5 HY, SE Quinlan et al. 1986. LA Bergadano et al. 1992. MU, VO V1 Schlimmer 1987.6 HO McLeish  Cecile 1990. BC, LY Cestnik et al. 1987. For LY, some grouping of valueswas done, as in VO.12 Machine Learning 116391, 1993possible with relatively simple rules.On the creation of the remaining datasets GL, G2, HD, HE, IR there is no publishedinformation.In summary, only 2 of the datasets in this study may reasonably be judged to have beenspecially engineered by the machine learning community to be easy. Ironically, it isthese two datasets on which 1R performs most poorly. 9 of the datasets are known to be,or are very likely to be, representative of problems that naturally arise in practice.Although these datasets do not represent the entire range of real problems e.g. they donot represent hard problems, the number and diversity of the datasets indicates thatthey represent a class of problems that often arises. The next two sections examine therole of very simple classification rules in machine learning applications and researchwithin this class of problems.6. Accuracy versus Complexity in 1R and C4The preceding sections have established that there are a significant number of realisticdatasets on which 1rules are only slightly less accurate 3.1 percentage points than thecomplex rules created by C4 and other machine learning systems. In order to get insightinto the tradeoff between accuracy and complexity, the complexity of C4s trees wasmeasured in experiment 1. The results are given in the following table.BC CH GL G2 HD HE HO HY IR LA LY MU SE SO VO V1mx 4 13 12 9 7  7  4 7 4 3 5  6  9 3 5 7dc 0.9 4.5 5.1 3.7 2.7 2.2 1.6 1.2 1.9 1.4 2.2 1.6 1.5 2.0 1.4 2.22 2 59 87 80 58 26 18 6 24 5 36 8 13 18 6 30The mx row giv es the maximum depth of the pruned trees built by C4 on each dataset.Maximum depth corresponds to the number of attributes measured to classify an examplein the worst case. On average, the maximum depth of C4s trees is 6.6, compared to 1 for1rules. Maximum depth is usually regarded as an underestimate of the true complexityof a decision tree because it does not take into account the complexity due to the treesshape. For this reason, researchers normally define complexity as the number of leaves ornodes in a tree. By this measure, C4s trees are much more complex than 1rules.Maximum depth, or number of leaves, are measures of the static complexity of adecision tree. However, considerations such as the speed of classification, or cost ofmeasuring the attributes used during classification Tan  Schlimmer, 1990, are dynamicproperties of a tree which are not accurately reflected by static complexity. The dynamiccomplexity of a rule can be defined as the average number of attributes measured inclassifying an example. The dynamic complexity of C4s pruned trees is given in the13 Machine Learning 116391, 1993dc row of the table.7 On datasets where C4s trees involve continuous attributes GL,G2, and IR, for example, dynamic complexity is artificially high because C4 transformsthese into binary attributes instead of Nary attributes N  2. C4s dynamic complexity,av eraged over the 16 datasets, is 2.3, compared to 1 for 1rules. Furthermore, there isconsiderable variance in the number of attributes measured by C4s decision trees onsome datasets C4s dynamic complexity is considerably greater than 2.3, and in mostdatasets there are some examples, sometimes many, for which C4s decision treesmeasure more than 2.3 attributes. To illustrate the latter kind of variation, the third row inthe table 2 indicates the percentage of examples in each dataset for whichclassification by C4s decision trees involves measuring 3 or more attributes.Thus in 1R and C4 there is a perfect symmetry in the relationship between accuracy anddynamic complexity. 1Rs rules are always very simple, usually a little less accurate, andoccasionally much less accurate. C4s rules are more accurate, a little less simple onav erage, and occasionally much less simple.These differences between 1R and C4 have practical implications. In practice, differentapplications have different demands in terms of accuracy and static and dynamiccomplexity. Depending on these demands, either 1R or C4 will be the more appropriatelearning system for the application. For example, C4 is appropriate for applications thatdemand the highest possible accuracy, reg ardless of complexity8. And, 1R is appropriatefor applications in which static complexity is of paramount importance for example,applications in which the classification process is required to be comprehensible to theuser. In applications where simplicity and accuracy are equally important, the symmetrybetween 1R and C4 means that the two systems are equally appropriate.7. The Simplicity First Research MethodologyOne goal of machine learning research is to improve both the simplicity and accuracy ofthe rules produced by machine learning systems. In pursuit of this goal, the researchcommunity has historically followed a research methodology whose main premise is thata learning system should search in very large hypothesis spaces containing, among otherthings, very complex hypotheses. According to this traditional methodology, progressin machine learning occurs as researchers invent better heuristics for navigating in thesespaces towards simple, accurate hypotheses.The results of preceding sections do not lend support to the premise of the traditionalmethodology. Complex hypotheses need not be considered for datasets in which mostexamples can be classified correctly on the basis of 1 or 2 attributes. An alternative,simplicity first methodology begins with the opposite premise a learning system shouldsearch in a relatively small space containing only simple hypotheses. Because the spaceis small, navigating in it is not a major problem. In this methodology, progress occurs as7 The dynamic complexity of the BC dataset is less than 1 because C4 occasionally produces a decision tree that consists of nothing but a leaf all examples are classified the same without testing a single attribute.8 for example, the space shuttle application described in Catlett 1991a14 Machine Learning 116391, 1993researchers invent ways to expand the search space to include slightly more complexhypotheses that rectify specific deficiencies.The experiment with 1R nicely illustrates how a researcher proceeds according to thesimplicity first methodology. That experiment analyzed the potential for improving 1Rby optimizing its selection criterion. The results showed that modifications to 1Rsselection criterion would produce at best modest increases in accuracy. To achievegreater increases it is necessary to change the set of rules that 1R searches during itsconstruction step. For example, 1Rs method for partitioning the values of continuousattributes into a set of intervals does not consider all possible partitions. A method ofpartitioning that considered different partitions might construct 1rules that are moreaccurate than any of the 1rules constructed by the current version of 1R.9 Morefundamental changes might extend 1Rs search space to include slightly more complexrules, such as rules that measure 2 attributes or linear trees.The two methodologies have as their aim the same goal improving both the accuracy andthe simplicity of the rules produced by machine learning systems. But they providedifferent starting points, emphases, and styles of research towards this goal. The mainpractical differences in the methodologies are the following.1 Systems designed using the simplicity first methodology are guaranteed to producerules that are nearoptimal with respect to simplicity. If the accuracy of the rule isunsatisfactory, then there does not exist a satisfactory simple rule, so to improveaccuracy one must increase the complexity of the rules being considered. By contrast,systems designed using the traditional methodology may produce rules that aresignificantly suboptimal with respect to both simplicity and accuracy. For example,on the VO dataset Buntine  Niblett 1992 report a learning system that produces adecision tree having 12 leaves and an accuracy of 88.2. This rule is neither accuratenor simple.10 If this accuracy is unsatisfactory, there may exist a simpler rule that ismore accurate. Or there may not. In the traditional methodology one must simplyguess where to search for more accurate rules if an unsatisfactory rule is initiallyproduced.2 Analysis, such as formal learnability analysis, of simple hypothesis spaces and theassociated simple learning algorithms is easier than the corresponding analysis forcomplex hypothesis spaces. Iba  Langley 1992 give an initial analysis of 1rulelearning behaviour. In this regard, the simplicity first methodology for studying anddesigning learning systems parallels the normal methodology in mathematics ofproceeding from simple, easily understood problems through progressively moredifficult ones, with the solutions to later problems building upon the results, or usingthe methods, of the earlier ones. Because the methodologies are parallel, the theoryand practice of machine learning may progress together.9 A recursive partitioning algorithm similar to Catletts 1991b creates partitions that are differentthan 1Rs, and no less accurate.10 1R produces a rule having 3 leaves and an accuracy of 95.2.15 Machine Learning 116391, 19933 Simple hypothesis spaces are so much smaller that algorithms can be used whichwould be impractical in a larger space. For example, in an acceptably short amount oftime PVM Weiss et al., 1990 can search thoroughly although not exhaustivelythrough its relatively small hypothesis space. As a result, PVM is able to find rules ofmaximal accuracy, at least for their length.114 Finally, many of the same issues arise when using a simple hypothesis space as whenusing a complex one. For example, Weiss et al. 1990 address the issues of accuracyestimation and partitioning continuous attributes into intervals. Other issues that ariseequally with simple and complex hypothesis spaces are overfitting, tiebreakingchoosing between rules that score equally well on the training data, and the handlingof small disjuncts and missing values. Such issues are more easily studied in thesmaller, simpler context, and the knowledge derived in this way is, for the most part,transferable to the larger context.As these differences illustrate, the simplicity first methodology is a promisingalternative to the existing methodology.8. CONCLUSIONThis paper presented the results of an investigation into the classification accuracy of verysimple rules 1rules, or 1level decision trees ones which classify examples on thebasis of a single attribute. A program, called 1R, that learns 1rules from examples wascompared to C4 on 16 datasets commonly used in machine learning research.The main result of comparing 1R and C4 is insight into the tradeoff between simplicityand accuracy. 1Rs rules are only a little less accurate 3.1 percentage points than C4spruned decision trees on almost all of the datasets. C4s trees are considerably larger insize static complexity than 1rules, but not much larger in terms of the number ofattributes measured to classify the average example dynamic complexity.The fact that, on many datasets, 1rules are almost as accurate as more complex rules hasnumerous implications for machine learning research and applications. The firstimplication is that 1R can be used to predict the accuracy of the rules produced by moresophisticated machine learning systems. In research, this prediction can be used as abenchmark accuracy, giving a reasonable estimate of how one learning system wouldcompare with others. In applications, it can be used to determine if learning is likely toachieve the required accuracy.A more important implication is that simplerule learning systems are often a viablealternative to systems that learn more complex rules. If a complex rule is induced, itsadditional complexity must be justified by its being correspondingly more accurate than asimple rule. In research, this observation leads to an new research methodology that11 On two datasets Weiss et al. 1990 searched exhaustively through all rules up to a certain length 2in one case, 3 in the other. If longer, more accurate rules exist, no one has yet found them.16 Machine Learning 116391, 1993differs from the traditional methodology in significant ways. In applications, theaccuracy and complexity demands of each particular application dictate the choicebetween the two kinds of system.The practical significance of this research was assessed by examining whether or not thedatasets used in this study are representative of datasets that arise in practice. It wasfound that most of these datasets are typical of the data available in a commonlyoccurring class of real classification problems. Very simple rules can be expected toperform well on most datasets in this class.AcknowledgementsThis work was supported in part by an operating grant from the Natural Sciences andEngineering Research Council of Canada. I thank Ross Quinlan for providing the sourcefor C4.5 and David Aha for his work in creating and managing the UCI datasetcollection. I am greatly indebted to Doug Fisher, Peter Clark, Bruce Porter, and theexplanation group at the University of Texas at Austin Ray Mooney, Rich Mallory,Ken Murray, James Lester, and Liane Acker for the extensive comments they providedon drafts of this paper. Helpful feedback was also given by Wray Buntine and LarryWatanabe.ReferencesAha, D.W.  Kibler, D. 1989. NoiseTolerant Instancebased Learning Algorithms. Proceedings of theEleventh International Joint Conference on Artificial Intelligence pp.794799. MorganKaufmann.Bergadano, F., Matwin, S., Michalski, R.S.,  Zhang, J. 1992. Learning Twotiered Descriptions ofFlexible Concepts The Poseidon System. Machine Learning, 8, 544.Buntine, W. 1989. Learning Clasification Rules Using Bayes. In A. Segre Ed., Proceedings of the 6thInternational Workshop on Machine Learning pp.9498. Morgan Kaufmann.Buntine, W.,  Niblett, T. 1992. A Further Comparison of Splitting Rules for DecisionTree Induction.Machine Learning, 8, 7586.Catlett, J. 1991a. Megainduction a Test Flight. In L.A. Birnbaum  G.C. Collins Eds., Proceedings ofthe Eighth International Conference on Machine Learning pp.596599. Morgan Kaufmann.Catlett, J. 1991b. On Changing Continuous Attributes into Ordered Discrete Attributes. In Y. KodratoffEd., Machine Learning  EWSL91 pp.164178. SpringerVerlag.Cestnik, B.,  Bratko, I. 1991. On Estimating Probabilities in Tree Pruning. In Y. Kodratoff Ed.,Machine Learning  EWSL91 pp.138150. SpringerVerlag.17 Machine Learning 116391, 1993Cestnik, G., Konenenko, I.,  Bratko, I. 1987. Assistant86 A KnowledgeElicitation Tool forSophisticated Users. In I. Bratko  N. Lavrac Eds., Progress in Machine Learning pp.3145.Sigma Press.Clark, P.,  Boswell, R. 1991. Rule Induction with CN2 Some Recent Improvements. In Y. KodratoffEd., Machine Learning  EWSL91 pp.151163. SpringerVerlag.Clark, P.  Niblett, T. 1989. The CN2 Induction Algorithm. Machine Learning, 3, 261283.Clark, P.  Niblett, T. 1987. Induction in Noisy Domains. In I. Bratko  N. Lavrac Eds., Progress inMachine Learning pp.1130. Sigma Press.de la Maza, M. 1991. A Prototype Based Symbolic Concept Learning System. In L.A. Birnbaum  G.C.Collins Eds., Proceedings of the Eighth International Conference on Machine Learningpp.4145. Morgan Kaufmann.Diaconis, P.  Efron, B. 1983. ComputerIntensive Methods in Statistics. Scientific American, 248.Fisher, D.H. 1987. Knowledge Acquisition via incremental conceptual clustering. Machine Learning, 2,139172.Fisher, D.H.,  McKusick, K.B. 1989. An Empirical Comparison of ID3 and BackPropagation.Proceedings of the Eleventh International Joint Conference on Artificial Intelligence pp.788793.Morgan Kaufmann.Fisher, D.H.,  Schlimmer, J.C. 1988. Concept Simplification and Prediction Accuracy. In J. LairdEd., Proceedings of the Fifth International Conference on Machine Learning pp.2228. MorganKaufmann.Hirsh, H. 1990. Learning From Data with Bounded Inconsistency. In B.W. Porter  R.J. Mooney Eds.,Proceedings of the Seventh International Conference on Machine Learning pp.3239. MorganKaufmann.Holder Jr., L.B. 1991. Maintaining the Utility of Learned Knowledge Using ModelBased AdaptiveControl, Ph.D. thesis, Computer Science Department, University of Illinois at UrbanaChampaign.Holte, R.C., Acker, L.,  Porter, B.W. 1989. Concept Learning and the Problem of Small Disjuncts.Proceedings of the Eleventh International Joint Conference on Artificial Intelligence pp.813818.Morgan Kaufmann.Iba, W.F.  Langley, P. 1992. Induction of OneLevel Decision Trees. In D. Sleeman  P. EdwardsEds. Proceedings of the Ninth International Conference on Machine Learning pp.233240.Morgan Kaufmann.Iba, W., Wogulis, J.,  Langley, P. 1988. Trading off Simplicity and Coverage in Incremental ConceptLearning. In J. Laird Ed., Proceedings of the Fifth International Conference on Machine Learningpp.7379. Morgan Kaufmann.18 Machine Learning 116391, 1993Jensen, D. 1992. Induction with Randomization Testing Decisionoriented Analysis of Large Data Sets.Ph.D. thesis, Washington University, St. Louis, Missouri.Kibler, D.,  Aha, D.W. 1988. Comparing Instanceaveraging with InstanceFiltering LearningAlgorithms. In D. Sleeman Ed., EWSL88 Proceedings of the 3rd European Working Session onLearning pp.6369. Pitman.Lopez de Mantaras, R. 1991. A Distancebased Attribute Selection Measure for Decision Tree Induction.Machine Learning, 6, 8192.McLeish, M.  Cecile, M. 1990. Enhancing Medical Expert Systems With Knowledge Obtained FromStatistical Data. Annals of Mathematics and Artificial Intelligence, 2, 261276.Michalski, R.S. 1990. Learning Flexible Concepts Fundamental Ideas and a Method Based onTw oTiered Representation. In Y. Kodratoff   R.S. Michalski Eds., Machine Learning AnArtificial Intelligence Approach volume 3. Morgan Kaufmann.Michalski, R.S.,  Chilausky, R.L. 1980. Learning by Being Told and Learning from Examples AnExperimental Comparison of the Two Methods of Knowledge Acquisition in the Context ofDeveloping an Expert System for Soybean Disease Diagnosis. International Journal of PolicyAnalysis and Information Systems, 42, 125161.Michalski, R.S., Mozetic, I., Hong, J.,  Lavrac, N. 1986. The MultiPurpose Incremental LearningSystem AQ15 and its Testing Application to Three Medical Domains. Proceedings of the FifthNational Conference on Artificial Intelligence pp.10411045. Morgan Kaufmann.Mingers, J. 1989. An Empirical Comparison of Pruning Methods for Decision Tree Induction. MachineLearning, 42, 227243.Quinlan, J.R. 1989. Unknown Attribute Values in Induction. In A. Segre Ed., Proceedings of the 6thInternational Workshop on Machine Learning pp.164168. Morgan Kaufmann.Quinlan, J.R. 1987. Generating Production Rules from Decision Trees. Proceedings of the TenthInternational Joint Conference on Artificial Intelligence pp.304307. Morgan Kaufmann.Quinlan, J.R. 1986. Induction of Decision Trees. Machine Learning, 1, 81106.Quinlan, J.R., Compton, P.J., Horn, K.A.,  Lazurus, L. 1986. Inductive knowledge acquisition a casestudy. Proceedings of the Second Australian Conference on Applications of Expert Systems.Sydney, Australia.Rendell, L.  Seshu, R. 1990. Learning Hard Concepts Through Constructive Induction. ComputationalIntelligence, 6, 247270.Salzberg, S. 1991. A Nearest Hyperrectangle Learning Method. Machine Learning, 6, 251276.19 Machine Learning 116391, 1993Saxena, S. 1989. Evaluating Alternative Instance Representations. In A. Segre Ed., Proceedings of theSixth International Conference on Machine Learning pp.465468. Morgan Kaufmann.Schaffer, C. in press. Overfitting Avoidance as Bias. to appear in Machine Learning.Schaffer, C. 1992. Sparse data and the effect of overfitting avoidance in decision tree induction.Proceedings of AAAI92, the Tenth National Conference on Artifical Intelligence.Schlimmer, J.S. 1987. Concept Acquisition Through Representational Adjustment Technical Report8719. Ph.D. thesis, Department of Information and Computer Science, University of California,Irvine.Schoenauer, M.  Sebag, M. 1990. Incremental Learning of Rules and MetaRules. in B.W. Porter R.J. Mooney Eds., Proceedings of the Seventh International Conference on Machine Learningpp.4957. Morgan Kaufmann.Shapiro, A.D. 1987. Structured Induction of Expert Systems. AddisonWesley.Shavlik, J., Mooney, R.J.,  Towell, G. 1991. Symbolic and Neural Learning Algorithms AnExperimental Comparison. Machine Learning, 6, 111143.Tan, M.,  Eshelman, L. 1988. Using weighted networks to represent classification knowledge in noisydomains. In J. Laird Ed., Proceedings of the Fifth International Conference on Machine Learningpp.121134. Morgan Kaufmann.Tan, M.,  Schlimmer, J. 1990. Two Case Studies in CostSensitive Concept Acquisition. Proceedingsof AAAI90, the Eighth National Conference on Artifical Intelligence pp.854860. MIT Press.Utgoff, P.E.,  Bradley, C.E. 1990. An Incremental Method for Finding Multivariate Splits for DecisionTrees. In B.W. Porter  R.J. Mooney Eds., Proceedings of the Seventh International Conferenceon Machine Learning pp.5865. Morgan Kaufmann.Weiss, S.M., Galen, R.S.,  Tadepalli, P.V. 1990. Maximizing the Predictive Value of Production Rules.Artificial Intelligence, 45, 4771.Weiss, S.M.,  Kapouleas, I. 1989. An Empirical Comparison of Pattern Recognition, Neural Nets, andMachine Learning Classification Methods. Proceedings of the Eleventh International JointConference on Artificial Intelligence pp.781787. Morgan Kaufmann.Wirth, J.,  Catlett, J. 1988. Experiments on the Costs and Benefits of Windowing in ID3. In J. LairdEd., Proceedings of the Fifth International Conference on Machine Learning pp.8799. MorganKaufmann.Yeung, DY. 1991. A Neural Network Approach to Constructive Induction. In L.A. Birnbaum  G.C.Collins Eds., Proceedings of the Eighth International Conference on Machine Learningpp.228232. Morgan Kaufmann.20 Machine Learning 116391, 1993APPENDIX A. A brief description of the program 1R.1R and 1R are implemented in one program they are identical except for about 2 linesof code which, if executed, produces 1Routput in addition to 1Routput see step 5below. The user sets a flag to select 1R or 1R. The user also sets SMALL, the smalldisjunct threshold Holte et al., 1989.Toplevel pseudocode.1. In the training set count the number of examples in class C having value V for attributeA store this information in a 3d array, COUNTC,V,A.2. The default class is the one having the most examples in the training set. The accuracyof the default class is the number of training examples in the default class divided bythe total number of training examples.3. FOR EACH NUMERICAL ATTRIBUTE, A, create a nominal version of A bydefining a finite number of intervals of values. These intervals become the values ofthe nominal version of A. For example, if As numerical values are partitioned intothree intervals, the nominal version of A will have three values interval 1, interval2, and interval 3. COUNTC,V,A reflects this transformation COUNTC,intervalI,A is the sum of COUNTC,V,A for all V in interval I.definitionsClass C is optimal for attribute A, value V, if it maximizes COUNTC,V,A.Class C is optimal for attribute A, interval I, if it maximizesCOUNTC,interval I,A.Values are partitioned into intervals so that every interval satisfies the followingconstraintsa there is at least one class that is optimal for more than SMALL of the values inthe interval. This constraint does not apply to the rightmost interval.b If VI is the smallest value for attribute A in the training set that is larger than thevalues in interval I then there is no class C that is optimal both for VI and forinterval I.4. FOR EACH ATTRIBUTE, A, use the nominal version of numerical attributesa Construct a hypothesis involving attribute A by selecting, for each value V of Aand also for missing, an optimal class for V. If sev eral classes are optimal for avalue, choose among them randomly.b add the constructed hypothesis to a set called HYPOTHESES. This set willultimately contain one hypothesis for each attribute.5. 1R choose the rule from the set HYPOTHESES having the highest accuracy on thetraining set if there are several best rules, choose among them at random.1R choose all the rules from HYPOTHESES having an accuracy on the training setgreater than the accuracy of the default class.21 Machine Learning 116391, 1993APPENDIX B. Source of the Datasets Used in this Study.All datasets are from the collection distributed by the University of California at Irvinecurrent contact person Pat Murphy pmurphyics.uci.edu. Except as noted below, Iused the datasets exactly as they are found in the April 1990 distribution.Datasets BC and LY were originally collected at the University Medical Center, Instituteof Oncology, Ljubljana, Slovenia, by M. Soklic and M. Zwitter, and converted into easytouse experimental material by Igor Kononenko, Faculty of Electrical Engineering,Ljubljana University.BC breastcancerbreastcancer.dataCH chessendgameskingrookvskingpawnkrvskp.dataGL glassglass.data. First attribute deleted. This dataset is sometimes described ashaving 7 classes, but there are no examples of class 4.G2 GL with classes 1 and 3 combined and classes 4 through 7 deleted.HD heartdiseasecleve.mod. Last attribute deleted to give a 2class problem.HE hepatitishepatitis.dataHO undocumentedtaylorhorsecolic.data  horsecolic.testAttribute V24 is used as the class. Attributes V3, V25, V26, V27, V28 deleted.HY thyroiddiseasehypothyroid.dataIR irisiris.dataLA labornegotiations. The dataset in the April1990 distribution was in an unusableformat. I obtained a usable version  which I believe is now in the UCIcollection  from the original source Stan Matwin, University of Ottawa.LY  lymphographylymphography.dataMU mushroomagaricuslepiota.dataSE thyroiddiseasesickeuthyroid.dataSO soybeansoybeansmall.dataVO votingrecordshousevotes84.dataV1 VO with the physicianfeefreeze attribute deleted.22 Machine Learning 116391, 1993APPENDIX C. Survey of results for each dataset.The results included in this survey were produced under a very wide variety ofexperimental conditions and therefore it is impossible to compare them in any detailedmanner. Most of the results are averages over a number of runs, where each run involvessplitting the dataset into disjoint training and test sets and using the test set to estimate theaccuracy of the rule produced given the training set. But the number of runs variesconsiderably, as does the ratio of the sizes of the training and test set, and differentmethods of randomly splitting have sometimes been used e.g. crossvalidation,stratified sampling, and unstratified sampling. Furthermore, it is virtually certain thatsome papers reporting results on a dataset have used slightly different versions of thedataset than others, it being common practice to make small changes to a dataset for thepurposes of a particular experiment.Dataset BC62.0, B Schoenauer  Sebag, 199062.0, Assistant no pruning Clark  Niblett 1987,198965.0, Bayes Clark  Niblett 1987,198965.1, CN2 ordered,laplace Clark  Boswell, 199165.3, nearest neighbour Weiss  Kapouleas, 198965.6, Bayessecond order Weiss  Kapouleas, 198965.6, quadratic discriminant Weiss  Kapouleas, 198966.0, AQTT15 Michalski, 199066.3, ID unpruned Peter Clark, personal communication66.8, CN2 ordered Peter Clark, personal communication66.8, GR, Minerr Mingers, 198966.9, C4 unpruned Peter Clark, personal communication67.0, Assistant no pruning Michalski, 199067.4, Prob, Minerr Mingers, 198968.0, AQ1115 Tan  Eshelman, 198868.0, AQ15 Salzberg, 199168.0, AQTT15 biggest disjuncts Michalski, 199068.0, AQTT15 unique1 Michalski, 199068.0, Assistant pruning Clark  Niblett 1987,198968.3, Gstat, Minerr Mingers, 198968.7,  1R 68.7, Marsh, Minerr Mingers, 198969.0, CN2 ordered,entropy Clark  Boswell, 199169.2, Gain Ratio Lopez de Mantaras, 199169.3, GR, Critical Mingers, 198969.3, ID3 Tan  Eshelman, 198869.6, Gstat, Critical Mingers, 198969.7, GR, Errcomp Mingers, 198970.0, Assistant no pruning Cestnik et al., 198770.3,  BASELINE ACCURACY 70.4, random Buntine  Niblett, 199270.6, Distance Lopez de Mantaras, 1991continued next page23 Machine Learning 116391, 1993Dataset BC continued70.8, GR, reduce Mingers, 198971.0, CN299 Clark  Niblett 1987,198971.0, Prob, Critical Mingers, 198971.5, C4 pruned Peter Clark, personal communication71.5, EACH without feature adjustment Salzberg, 199171.5, Info Gain Buntine  Niblett, 199271.5, Prob, Errcomp Mingers, 198971.5, neural net Weiss  Kapouleas, 198971.6, GR, Pessim Mingers, 198971.6, linear discriminant Weiss  Kapouleas, 198971.8, Bayes Weiss  Kapouleas, 198971.9, Marsh, Pessim Mingers, 198971.9, Prob, Pessim Mingers, 198972.0, AQ15 Michalski et al., 198672.0, AQR Clark  Niblett 1987,198972.0, Assistant pruning Michalski, 199072.0, C4 pruned this paper72.0, Gstat, Errcomp Mingers, 198972.1, C4 Clark  Boswell, 199172.3, GINI Buntine  Niblett, 199272.3, Marsh, Critical Mingers, 198972.3, Marsh, Errcomp Mingers, 198972.5, Gstat, Pessim Mingers, 198972.7,  1Rw 72.8,  1R 72.8, Prob, Reduce Mingers, 198972.9, Gstat, Reduce Mingers, 198972.9, Marsh Buntine  Niblett, 199273.0, CN2 unordered,laplace Clark  Boswell, 199173.1, Marsh, Reduce Mingers, 198973.4, IWNaddor Tan  Eshelman, 198873.5, IWNmaxor Tan  Eshelman, 198874.3, ID3 pruned Buntine, 198975.0, C2 Schoenauer  Sebag, 199075.6, BayesN Buntine, 198976.1, Bayes Buntine, 198976.2, ID3 averaged Buntine, 198977.0, Assistant prepruning Cestnik et al., 198777.1, CART Weiss  Kapouleas, 198977.1, PVM Weiss  Kapouleas, 198977.6, EACH with feature adjustment Salzberg, 199178.0, D3 Schoenauer  Sebag, 199078.0, Assistant postpruning Cestnik et al., 198778.0, Bayes Cestnik et al., 198724 Machine Learning 116391, 1993Dataset CH67.6,  1R 68.3,  1Rw 69.2,  1R 85.4, Bayes Buntine, 198991.0, CN2 Holte et al., 198993.9, perceptron Shavlik et al., 199196.3, back propagation Shavlik et al., 199196.4, ID3 pruned Buntine, 198996.9, ID3 unpruned Buntine, 198997.0, ID3 Shavlik et al., 199199.2, C4 pruned this paperDataset GL45.5, NTgrowth de la Maza, 199146.8, random Buntine  Niblett, 199248.0, ProtoTO de la Maza, 199149.4, Info Gain Buntine  Niblett, 199253.8,  1R 56.3,  1R 59.5, Marsh Buntine  Niblett, 199260.0, GINI Buntine  Niblett, 199262.2,  1Rw 63.2, C4 pruned this paper65.5, C4 de la Maza, 1991Dataset HD60.5, perceptron Shavlik et al., 199170.5, growth Aha  Kibler, 198971.1, Knearest neighbour growth K3 Aha  Kibler, 198971.2, ID3 Shavlik et al., 199171.3, disjunctive spanning Aha  Kibler, 198971.4, growth Kibler  Aha, 198873.4,  1R 73.6, C4 pruned this paper74.8, C4 Kibler  Aha, 198875.4, C4 Aha  Kibler, 198976.2, proximity Aha  Kibler, 198976.4, IRT Jensen, 199276.6,  1Rw 77.0, NTgrowth Kibler  Aha, 198877.9, NTgrowth Aha  Kibler, 198978.0,  1R 78.7, NT disjunctive spanning Aha  Kibler, 198979.2, Knearest neighbour K3 Aha  Kibler, 198979.4, NT Knearest neighbour growth K3 Aha  Kibler, 198980.6, back propagation Shavlik et al., 199125 Machine Learning 116391, 1993Dataset HE38.7, NTgrowth de la Maza, 199171.3, CN2 ordered,entropy Clark  Boswell, 199176.3,  1R 77.6, CN2 ordered,laplace Clark  Boswell, 199177.8, ID unpruned Peter Clark, personal communication78.6, Gain Ratio Lopez de Mantaras, 199179.3, C4 Clark  Boswell, 199179.3, Distance Lopez de Mantaras, 199179.4,  BASELINE ACCURACY 79.8, C4 de la Maza, 199179.8, m0.0 Cestnik  Bratko, 199179.8, m0.01 Cestnik  Bratko, 199179.9, ProtoTO de la Maza, 199180.0, cited in the UCI files Diaconis  Efron, 198380.0, Assistant no pruning Cestnik et al., 198780.1, CN2 unordered,laplace Clark  Boswell, 199181.1, m1 Cestnik  Bratko, 199181.2, C4 pruned this paper81.5, m0.5 Cestnik  Bratko, 199182.0, Assistant postpruning Cestnik et al., 198782.1, laplace Cestnik  Bratko, 199182.1, m2 Cestnik  Bratko, 199183.0, Assistant prepruning Cestnik et al., 198783.6, m3 Cestnik  Bratko, 199183.8, m128 Cestnik  Bratko, 199183.8, m32 Cestnik  Bratko, 199183.8, m64 Cestnik  Bratko, 199183.8, m999 Cestnik  Bratko, 199184.0, Bayes Cestnik et al., 198784.0, m8 Cestnik  Bratko, 199184.5,  1Rw 84.5, m4 Cestnik  Bratko, 199185.5, m12 Cestnik  Bratko, 199185.5, m16 Cestnik  Bratko, 199185.8,  1R 26 Machine Learning 116391, 1993Dataset HY88.4, quadratic discriminant Weiss  Kapouleas, 198992.4, Bayessecond order Weiss  Kapouleas, 198992.6, random Buntine  Niblett, 199293.9, linear discriminant Weiss  Kapouleas, 198995.3, nearest neighbour Weiss  Kapouleas, 198996.1, Bayes Weiss  Kapouleas, 198997.1, growth Kibler  Aha, 198897.2,  1R 97.4,  1R 97.7, NTgrowth Kibler  Aha, 198898.0,  1Rw 98.2, C4 Kibler  Aha, 198898.5, neural net Weiss  Kapouleas, 198998.7, Marsh Buntine  Niblett, 199299.0, GINI Buntine  Niblett, 199299.1, C4 pruned this paper99.1, Info Gain Buntine  Niblett, 199299.1, PT2 Utgoff  Bradley, 199099.3, C4rules Quinlan, 198799.3, PVM Weiss  Kapouleas, 198999.4, C4 Quinlan, 198799.4, CART Weiss  Kapouleas, 198999.7, C4 Quinlan et al., 1986Dataset IR84.0, Bayessecond order, crossvalidation Weiss  Kapouleas, 198985.8, random Buntine  Niblett, 199289.3, Prob, Reduce Mingers, 198990.5, Prob, Errcomp Mingers, 198991.1, Marsh, Critical Mingers, 198991.2, Marsh, Pessim Mingers, 198991.3, Prob, Critical Mingers, 198992.2, Marsh, Minerr Mingers, 198992.3, NTgrowth de la Maza, 199192.4, Marsh, Errcomp Mingers, 198992.4, Marsh, Reduce Mingers, 198992.4, Prob, Pessim Mingers, 198992.4, growth Kibler  Aha, 198892.5, GR, Critical Mingers, 198992.5, GR, Errcomp Mingers, 198992.5, GR, Pessim Mingers, 198992.5, GR, reduce Mingers, 198992.6, EACH without feature adjustment Salzberg, 199192.8, Gstat, Critical Mingers, 198992.8, Gstat, Errcomp Mingers, 198992.8, Gstat, Minerr Mingers, 1989continued next page27 Machine Learning 116391, 1993Dataset IR continued92.8, Gstat, Pessim Mingers, 198992.8, Gstat, Reduce Mingers, 198993.0, CART Salzberg, 199193.2, GR, Minerr Mingers, 198993.3, Bayes, crossvalidation Weiss  Kapouleas, 198993.3, Prob, Minerr Mingers, 198993.5,  1R 93.8, C4 pruned this paper94.0, ID3 pruned Buntine, 198994.2, C4 de la Maza, 199194.2, ID3 Catlett, 1991a94.2, ID3 new version Catlett, 1991a94.4, C4 Kibler  Aha, 198894.4, ID3 averaged Buntine, 198994.5, Marsh Buntine  Niblett, 199294.7, Dasarathy Hirsh, 199095.0, GINI Buntine  Niblett, 199295.1, Info Gain Buntine  Niblett, 199295.3, CART, crossvalidation Weiss  Kapouleas, 198995.3, EACH with feature adjustment Salzberg, 199195.4, NTgrowth Kibler  Aha, 198895.5, Bayes Buntine, 198995.5, BayesN Buntine, 198995.9,  1R 96.0,  1Rw 96.0, PVM, crossvalidation Weiss  Kapouleas, 198996.0, ProtoTO de la Maza, 199196.0, nearest neighbour, crossvalidation Weiss  Kapouleas, 198996.7, IVSM, Hirsh, 199096.7, neural net, crossvalidation Weiss  Kapouleas, 198997.3, quadratic discriminant, crossvalidation Weiss  Kapouleas, 198998.0, linear discriminant, crossvalidation Weiss  Kapouleas, 1989Dataset LA71.5,  1R 77.0, 1nearest neighbour Bergadano et al., 199277.3, C4 pruned this paper80.0, 5nearest neighbour Bergadano et al., 199280.0, AQ15 strict or flexible matching Bergadano et al., 199283.0, 3nearest neighbour Bergadano et al., 199283.0, AQ15 top rule truncation Bergadano et al., 199283.0, AQ15 TRUNCSG,flexible matching Bergadano et al., 199284.2,  1Rw 86.0, Assistant with pruning Bergadano et al., 199287.4,  1R 90.0, AQ15 TRUNCSG,deductive matching Bergadano et al., 199228 Machine Learning 116391, 1993Dataset LY56.1, m999 Cestnik  Bratko, 199167.7, random Buntine  Niblett, 199269.1, m128 Cestnik  Bratko, 199170.7,  1R 71.5, CN2 ordered,entropy Clark  Boswell, 199174.8, m64 Cestnik  Bratko, 199175.0, m16 Cestnik  Bratko, 199175.6, GINI Buntine  Niblett, 199275.7,  1Rw 75.7, Marsh Buntine  Niblett, 199275.9, m12 Cestnik  Bratko, 199175.9, m32 Cestnik  Bratko, 199176.0, AQR Clark  Niblett 1987,198976.0, Assistant no pruning Cestnik et al., 198776.0, Assistant no pruning Michalski, 199076.0, Assistant postpruning Cestnik et al., 198776.0, Assistant prepruning Cestnik et al., 198776.0, Info Gain Buntine  Niblett, 199276.4, C4 Clark  Boswell, 199176.7, ID3 pruned Buntine, 198976.8, m8 Cestnik  Bratko, 199177.0, Assistant pruning Michalski, 199077.1, laplace Cestnik  Bratko, 199177.1, m4 Cestnik  Bratko, 199177.3,  1R 77.3, m0.01 Cestnik  Bratko, 199177.3, m0.5 Cestnik  Bratko, 199177.3, m1 Cestnik  Bratko, 199177.3, m2 Cestnik  Bratko, 199177.3, m3 Cestnik  Bratko, 199177.5, C4 pruned this paper77.5, m0.0 Cestnik  Bratko, 199178.0, Assistant pruning Clark  Niblett 1987,198978.4, ID3 averaged Buntine, 198979.0, Assistant no pruning Clark  Niblett 1987,198979.0, Bayes Cestnik et al., 198779.6, CN2 ordered,laplace Clark  Boswell, 199180.0, AQTT15 unique1 Michalski, 199081.0, AQTT15 Michalski, 199081.7, CN2 unordered,laplace Clark  Boswell, 199182.0, AQ15 Michalski et al., 198682.0, AQTT15 biggest disjuncts Michalski, 199082.0, BayesN Buntine, 198982.0, CN299 Clark  Niblett 1987,198983.0, Bayes Clark  Niblett 1987,198985.1, Bayes Buntine, 198929 Machine Learning 116391, 1993Dataset MU91.2, random Buntine  Niblett, 199292.7, Marsh Buntine  Niblett, 199295.0, HILLARY Iba et al., 198895.0, STAGGER Schlimmer, 198798.4,  1R 98.4,  1R 98.5,  1Rw 98.6, GINI Buntine  Niblett, 199298.6, Info Gain Buntine  Niblett, 199299.1, neural net Yeung, 199199.9, ID3 Wirth  Catlett, 1988100.0, C4 pruned this paperDataset SE91.8, growth Kibler  Aha, 198895.0,  1R 95.0,  1R 95.0,  1Rw 95.0, RAF Quinlan, 198995.2, RUU Quinlan, 198995.4, RSS Quinlan, 198995.9, NTgrowth Kibler  Aha, 198896.1, RPF Quinlan, 198996.2, RFF Quinlan, 198996.3, RIF Quinlan, 198996.8, RCF Quinlan, 198997.3, C4 Kibler  Aha, 198897.7, C4 pruned this paper99.2, C4 Quinlan et al., 1986Dataset VO84.0, 3nearest neighbour Bergadano et al., 199284.0, 5nearest neighbour Bergadano et al., 199284.6, random Buntine  Niblett, 199285.0, AQ15 top rule truncation Bergadano et al., 199285.2, NT Knearest neighbour growth K3 Aha  Kibler, 198986.0, 1nearest neighbour Bergadano et al., 199286.0, AQ15 strict or flexible matching Bergadano et al., 199286.0, Assistant with pruning Bergadano et al., 199286.2, Knearest neighbour K3 Aha  Kibler, 198986.4, Knearest neighbour growth K3 Aha  Kibler, 198988.2, Marsh Buntine  Niblett, 199290.4, ProtoTO de la Maza, 199190.6, NTgrowth de la Maza, 199190.7, growth Aha  Kibler, 198990.8, IWNaddor Tan  Eshelman, 1988continued next page30 Machine Learning 116391, 1993Dataset VO continued91.7, proximity. Aha  Kibler, 198991.9, NTgrowth Aha  Kibler, 198992.0, AQ15 TRUNCSG,deductive matching Bergadano et al., 199292.0, AQ15 TRUNCSG,flexible matching Bergadano et al., 199292.4, disjunctive spanning Aha  Kibler, 198992.9, NT disjunctive spanning Aha  Kibler, 198993.6, CN2 ordered,entropy Clark  Boswell, 199193.9, IWNmaxor Tan  Eshelman, 198894.0, ID3 Fisher  McKusick, 198994.3, IWNaddor Tan  Eshelman, 198894.5, C4 Aha  Kibler, 198994.8, CN2 ordered,laplace Clark  Boswell, 199194.8, CN2 unordered,laplace Clark  Boswell, 199195.0, IRT Jensen, 199295.0, STAGGER Schlimmer, 198795.2,  1R 95.2,  1R 95.3, C4 de la Maza, 199195.3, neural net Yeung, 199195.4, Info Gain Buntine  Niblett, 199295.5, GINI Buntine  Niblett, 199295.6,  1Rw 95.6, C4 Clark  Boswell, 199195.6, C4 pruned this paperDataset V184.4, random Buntine  Niblett, 199284.9, Marsh Buntine  Niblett, 199286.8,  1R 87.0, Info Gain Buntine  Niblett, 199287.2, GINI Buntine  Niblett, 199287.4,  1Rw 87.9,  1R 89.4, C4 pruned this paper31 Machine Learning 116391, 1993APPENDIX D. Data from the 25 runs on each dataset.1R C4 tvaluesmean std.dev. mean std.dev. C41R 1R1Rw C41RwDataset 1RwBC 72.46 4.23 71.96 4.36 72.7 0.82 0.27 0.83CH 69.24 0.95 99.19 0.27 68.3 134.7 4.85 571GL 56.44 5.06 63.16 5.71 62.2 4.98 5.53 0.86G2 77.02 3.88 74.26 6.61 78.5 1.93 1.90 3.17HD 78.00 2.68 73.62 4.44 76.57 5.18 2.62 3.26HE 85.14 6.23 81.23 5.12 84.5 2.69 0.51 3.13HO 81.18 1.95 83.61 3.41 81.5 4.05 0.86 3.01HY 97.20 0.67 99.13 0.27 98.0 13.44 5.88 20.59IR 95.92 1.55 93.76 2.96 96.0 3.61 0.25 3.71LA 87.37 4.48 77.25 5.89 84.2 7.11 3.47 5.78LY 77.28 3.75 77.52 4.46 75.7 0.21 2.07 2.00MU 98.44 0.20 100.0 0.0 98.5 37.47 1.44 SE 95.00 0.54 97.69 0.40 95.0 30.3 0.04 32.8SO 87.00 6.62 97.51 3.94 87.2 6.55 0.15 12.81VO 95.18 1.52 95.57 1.31 95.6 1.59 1.34 0.12V1 87.93 2.22 89.36 2.45 87.4 3.93 1.17 3.9232 Machine Learning 116391, 1993
