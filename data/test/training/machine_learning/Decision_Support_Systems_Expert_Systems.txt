Getting It Right at the Very Start  Building Project Modelswhere Data Is Expensive by Combining Human Expertise,Machine Learning and Information TheoryFrank D. FranconeRML Technologies, Inc.  Chalmers University of Technologyfrank.dfrancone.comLarry M. DeschaineScience Applications International Corporation, Inc.  Chalmers University of TechnologyLarry.M.Deschainealum.mit.eduKeywords Environmental Science, Geophysics,Information Theory, Underground Anomaly Detection,Machine Learning, Genetic Programming, IntegratedDecision Support Systems, Expert SystemsAbstractBuilding models using machine learning techniques requiresdata. For some projects, gathering data is very expensive. Inthis type of projectwhich we refer to as Incremental Learning Projectsthere are two significant costs to usingmachine learning techniques 1 Machine learning modelscannot even begin to make predictions until the project hasalready spent significant amounts of money gathering dataand 2 While the data is being gathered to train the machinelearning system, unnecessary costs are incurred in makinginefficient decisions.Engineers may address this type of problem efficientlywhen enough human expertise exists about the problemdomain to be modeled. This work proposes an approach tocombining human expertise, machine learning andinformation theory that makes efficient and effectivedecisions from the start of the project, in concert withproject data collection.INTRODUCTIONThis work describes an approach to creating integrateddecision support systems for certain types of projects, whichwe refer to as Incremental Learning Projects.Characteristics of Incremental Learning ProjectsProperlydesigned, decisionsupport systems can yieldsignificant cost savings and improved decision support forIncremental Learning Projects, which have the followingcharacteristics The project requires that engineers repeatedly makesimilar decisions based on relatively low costmeasurements of the domain in which the decisions areto be made Human experts can give a firstpass assessment for eachof these required repetitive decisions. From theirassessment, project engineers should be able todetermine how certain the human experts were of theirdecision The cost of acquiring actual groundtruth for thedecisions required by the project is relatively high One of the principal goals in the project is to avoidincurring the costs of acquiring actual groundtruth fora large number of the decision pointsthat is, it wouldbe desirable that a large number of the repetitive projectdecisions be made using only the information availablefrom theprojects lowcost, domain measurements and Finally, sufficient information exists in the lowcostmeasurements for machine learning systems alone or inconjunction with human experts to make betterjudgments than the human expert alone.We will sometimes refer to projects with thesecharacteristics as Incremental Learning Projects.Incremental Learning Project ExampleAn example of an Incremental Learning Project, whichwe will follow and expand upon throughout this paper, willmake our discussion more clear.Geophysicists frequently have to discriminate betweendifferent types of underground objects from readings madeby electromagnetic or other aboveground, nondestructive,sensors. 1 Each signal from the aboveground sensors isrelatively inexpensive to obtain. From these abovegroundmeasurements, geophysicists can make predictions aboutwhich signals represent target objects and which do not.But to get groundtruth, a hole must be dug atconsiderable expense. Not having to dig empty holes is aprimary objective of this type of project. 1 Adding amachine learning system to the mix can improve decisionaccuracy considerably. 2Obviously, this underground anomaly discriminationproject fits each of the criteria set forth above.The ChickenAndEgg Problem in Using MachineLearning in Incremental Learning ProjectsThe problem with applying machine learning systemsto Incremental Learning Projects is that groundtruth mustbe provided to machine learning systems for the purpose ofderiving predictive models. 3 This poses a chickenandegg problem.One technique to bypass the chickenandegg problemis described in 4. That work involved a physicsbasedsimulator that predicted the location of the fringe of anunderground, groundwatercontaminantplume. A Kalmanfilter system looked at randomly generated outputs from thesimulator to determine where to take the next ground sampleto optimally reduce the uncertainty of the simulator.Where physicsbased simulation models are notavailable, machinelearning techniques may be used todevelop them to help make better predictions and reducecosts. But building inductive models requires expensiveprocess information such as groundtruth to validate them.356This suggests that, at best, machine learning can onlybegin to contribute to project decisions after the project hasbeen ongoing for some time and has made enough mistakesto provide examples of goodand baddecisions to themachine learning algorithm.StepByStep Approach to Incremental LearningProjectsThis paper proposes a stepbystep approach toIncremental Learning Projects. This approach solves thechickenandegg problem. Our approach involves fiveSteps1. Make a preliminary expert assessment for each of therepetitive decisions. The decisions should be ranked byprobability. For example, for binary decisionmakingrequiring a classification of each decision into yesornocategories, each decision should be ranked by howprobable is it that this decision should be a yes decision. In our example project, each undergroundanomaly detected by the sensors would be labeled withthe expert assessment of the probability that it is atarget that should be dug up2. Using the expert probability rankings from Step 1 asgroundtruth, train the machine learning system toproduce predictions about the result of making each ofthe required repetitive decisions. In our exampleproject, the machine learning system would be trainedusing the experts predictions of groundtruth in lieu ofactual ground truth. The machine learning systemwould then generate predictions for each anomaly3. Using the predictions from the previous Step, for eachof the expected repetitive project decisions, do thefollowinga Determine the expected additional project cost ofacquiring groundtruth by making that decision andb Determine the information gain predicted byShannon as a result of making that decision.Then incur the expense of obtaining groundtruth digthe hole in the example project for the decision ordecisions that yields the highest expected amount ofnew information per netdollar expended obtaining theinformation4. Retrain the machine learning system using knowngroundtruth, including the new groundtruthinformation just acquired in Step 3. Where groundtruthis not available, use the most current expertbasedassessment for each decision in lieu of groundtruthand5. Repeat Steps 3 and 4 until the project ends.Improvement in Incremental Learning ProjectsDue to StepbyStep ApproachThe advantages of this stepbystep approach arestraightforward Problemsolving with machine learning techniques maybegin at the start of a project rather than having to waituntil sufficient data samples have been gathered onwhich to train the models Early use of machine learning may improve decisionmaking substantially and throughout the life of theproject and Improved decision making means lower cost and betterresults. This is particularly critical where the cost ofobtaining data is high. In such projects, minimizing thenumber of data points for which highcost measurementis required is often the largest costdeterminant.Information Theory and Incremental LearningProjectsInformation Theory suggests that the stepbystepapproach we propose should be the most efficient means ofgathering information for training a machine learningsystem in Incremental Learning Projects. Simply put,information theory suggests that more information isacquired about a physical system when one samples fromthe system and obtains an unexpected result than when theresult is expected. 7So long as the experts preliminary ranking of theprobable effect of decisions to be made is not random, thenthe most unexpected results should occur in the regionwhere the experts are most uncertain. Thus, by samplinggroundtruth in the region of maximum uncertainty, wegather additional information about the system as efficientlyas possible per sample.In addition to the information gain expected as a resultof acquiring new ground truth, there is another factor indetermining the optimal ordering of project decisionsthatis, which hole to dig next. That factor is the expectedadditional cost to the project of acquiring the groundtruthby digging any particular hole.When we consider added project cost in conjunctionwith Shannons definition of information gain, we concludethat the most efficient order of decisionmaking is, at anygiven time, to make that decision of which the predictivesystem is most confident and then feed the groundtruththereby acquired back into the machine learning system. Inother words, dig the next hole where the predictive systemhumanexpertbased or machinelearningbased is mostcertain there is a target.MACHINE LEARNING ALGORITHMSMachine Learning is a term that includes a number ofalgorithmic approaches. When we refer to machine learningsystems, we are actually referring to a subset of machinelearning caled supervised machine learning. 35Various and probably familiar machine learning techniquesinclude backpropagation and various other neural networkapproaches 8, decisiontree algorithms 35, and geneticprogramming, 391011The authors prefer linear genetic programming LGPfor the particularly difficult learning domains that aretypical of Incremental Learning Projects. 2 Thus, whileour discussion here will frequently refer to LGP, othersufficiently powerful machine learning tools may sometimesbe substituted for LGP in this technique.What all supervised machine learning techniques havein common is that the algorithm trains on known data withknown answers. In one way or another, the algorithmdevelops a mapping between the domain measurementsprovided to it by the project engineers and the knownansweror the groundtruth.Thus, and by way of example, LGP automaticallyproduces a C program that maps the domain measurementsprovided by the project engineers to groundtruth. 11 Witha properly trained and tested model in hand, the engineercan then apply the LGP model to inputs for which theanswer is not known and use the model as a predictive toolfor the remainder of the project. 311Our approach is related to, but different from otherwork we have done to improve process decisionmakingaccuracy. 2 In that work, we fused the information contentof humanderived models and machinebased models. Thisresulted in improved decisionquality accuracy beyond thatwhich was possible using either approach separately. In thatstudy, we assumed that groundtruth was available to trainthe machinelearning system from the start. By way ofcontrast, the present approach addresses quite a differentproblemhow to fuse expert analysis with machinelearning when there is no preexisting groundtruth.The purpose of this paper is to suggest that byappropriate stepbystep sampling of groundtruth, machinelearning may be integrated with human and traditionalcomputer simulation tools even in Incremental LearningProjects to produce a better, and more cost effective,approach to this type of project.DESCRIPTION OF INCREMENTALLEARNING PROJECTSWe briefly described Incremental Learning Projects inthe Introduction. The following observations flesh thatdiscussion outFirst Incremental Learning Projects involve similardecisions made overandover. It would be desirable tomake these decisions based on relatively lowcostmeasurements. But these lowcost measurements do notprovide experts enough information to make their decisionswith certainty.Although we have referred to human experts as havingmade the preliminary assessment, the nature of thepreliminary assessment is not so important here. Thisassessment may be grounded on one or more of thefollowing techniques, depending on the project Human experts using the lowcost measurements tomake preliminary decisions Statistical analysis of the low cost measurements A simulation model of the project using the lowcostmeasurements as inputs or A combination of the foregoing.Second This approach is suitable for projects for wheremachine learning can make better predictions out ofwhatever groundtruth information is available at any giventime than can the human experts or the existing simulationmodels.Surprisingly to some, this project requirement is nolonger uncommon for noisy, complex modeling problems.The underground objects example above is only one domainin which genetic programming outperforms human expertswhen looking at the same data. 212 Noisy domainswhere the physics of the problem are complex or poorlyunderstood frequently present situations where geneticprogramming or other machine learning techniquesoutperforms human experts and humandesigned rulesystems or simulators.Finally This approach is suitable only for projects inwhich the cost of obtaining groundtruth is high. If it is not,then the project engineer should gather the groundtruth atlow cost, of course and apply machine learning techniquesin a traditional manner.APPLICATION ISSUESOur stepbystep approach for applying machinelearning to Incremental Learning Projects is presented in theIntroduction. Those steps raise a number of interestingapplication issues, which we address in this section.Acquiring the Training Data for the MachineLearning AlgorithmThe essential ingredient of the approach outlined in thispaper is the manner in which the training examples arederived for the machine learning algorithm. The traditionalmachine learning approach would be to select trainingexamples containing both 1 lowcost measurements of thedomain and 2 the known groundtruth for thosemeasurements.Simulated Ground TruthFor Incremental Learning Projects, we suggest derivingthe groundtruth for the initial training examples in a nontraditional manner. In our approach, the training exampleswould be derived from two sources 1 If available, trainingexamples should be chosen using actual groundtruth. Asthe project proceeds, more and more of the examples wouldbe based on real groundtruth or 2 If actual groundtruthis not available, the training examples should be derivedfrom the best human, statistical, or simulator basedjudgment that may be derived from the lowcostmeasurements in lieu of groundtruth. Model developmentshould, of course, follow the Department of Defenseguidelines for verification, validation, accreditation andcredibility. 6To use the example above, suppose the decision thatmust be made in the project is whether to dig expensiveholes at particular spots where electromagnetic anomalieshave been detected by aboveground measurements. Ofcourse, the goal is to remove the target objects. An emptyhole represents a large and unnecessary expense.To do this, Geophysicists would examine the lowcostmeasurements and assess the probability of whether thesemeasurements reveal a target object that must be removed.Anomalies with an assessed probability in excess of aproject specific threshold would be labeled, for the purposeof training the machine learning algorithm, as TARGET. Those below the threshold would be labeled as NOTTARGET. That would provide groundtruth to themachine learning system in the absence of actual groundtruth.The Effect of Using Simulated Ground TruthThe effect of constructing training examples in thismanner is that machine learning may be integrated withhuman expertise in an almost riskfree manner. That is, aproperly trained and tested machine learning model wouldbegin making predictions at or above the level of the humanexperts, whose judgment it has effectively reverseengineered. Machine learning systems in particular lineargenetic programming have been quite successful in suchreverse engineering the experts type applications. 2The machine learning system typically starts by makingpredictions as good as those that would be made by the besthumanexperts or the best available simulators. As moregroundtruth is acquired during the course of the projectinthe above example, as more holes are dugthose actualexamples supplement andor replace the humanexpertisebased examples. Typically, a machine learning systems predictions will improve as it acquires moreand moreaccuratetraining data.Accordingly, we should expect such an approach to dono worse than the human experts. In reality, the machinelearning system, after training on the human expertpredictions, often immediately improves on the humanpredictions. What happens is that the machine learningsystem finds regions of the input space where the expertpredictions are inconsistent with expert predictionselsewhere. By identifying those inconsistencies ab initio,the machine learning system clarifies the experts domain knowledge for better predictions at the start. 2And, as the project moves forwardand more groundtruth is acquiredwe should expect such an approachfrequently to outperform the alternative approach whichuses only human, statistical or simulatorbased expertisethroughout the project. 2Choosing the Cost FunctionAl supervised machine learning systems require a cost function. In effect, a cost function tells the algorithm whena particular model is doing better, or worse, at solving theproblem at hand. The cost function is used by machinelearning algorithms to move thru the search space ofpossible models. 35In linear genetic programming, the cost function isreferred to as a fitness function. This nomenclature comes from LGPs history as an evolutionary algorithm. Evolutionary algorithms draw on analogies to Darwiniannatural selectionsurvival of the fittest. Thus, the geneticprogramming fitness function is used to determine whichmodels survive and reproduce during training.3In the above example, a simple fitness function wouldjust tally up how many anomalies a particular model hasclassified correctly as DIG or DONT DIG. Models that classify training examples more accurately would beassessed in the cost functionas more fit.But in this approach, all training examples are notequal. Offhand, at least three general categories of trainingexamples may be delineated1. Examples based on humanexpert evaluationsthat is,there is no known groundtruth for the exampleand inwhich the experts have low confidence in theirprediction.2. Examples based on humanexpert evaluationsthat is,there is no known groundtruth for the exampleand inwhich the experts have high confidence in theirprediction.3. Examples based on actual, measured groundtruth. Inalmost all cases, these examples should be regarded asthe examples in which we have the most confidence.1One important decision that project engineers mustmake is whether and how to weight these different cases inthe cost, or fitness function. Assigning different costs todifferent training examples is a frequently used technique inmachine learning 5 11 and it seems particularlyapplicable in this situation. Manifestly, an error by thealgorithm on a training example that involves known groundtruth seems more serious than an error on an example where1 The exception to this general rule would occur whereengineers determine there is a reason to suspect the lowcostmeasurements such as instrument error, calibrationproblems and the like.the training example is based on an experts lowconfidencejudgment.The details of using differential cost functions would bethe subject of a different, and much longer paper.Nevertheless it is important to note hereFirst, that the issue should be explicitly resolved byproject engineers based on the particulars of the project, andSecond, that effect of similar weighting schemes can bevery different depending on which machine learningalgorithm is used. For example, the authors experience with differential cost functions in evolutionary algorithms such asLGP suggests a very small weighting differential can havemuch more substantial effects than the same differentialapplied in decisiontree algorithms. 11Ordering the Acquisition of GroundTruth forOptimal Project PerformanceImprovements in machine learning predictions for theproject will depend on how much new information isacquired during the project. New information is acquired bylearning groundtruth. Thus, Shannons measure of the amount of information that may be acquired by choosing todig here instead of there is very useful.Shannon described the foundations of InformationTheory in 1948. 7 The information obtained by making anobservation that has an a priori probability, p, ofoccurring  pI is defined as1  pI  1 pLogp Using Equation 1, the remainder of this sectiondescribes two different approaches to integratinginformation theory into the project decisionmaking process.One approach seeks to maximize the amount of informationacquired per decision made. The later seeks to maximizethe information acquired per additional project dollarexpended obtaining that information.The Simple Information Theoretic Approach toOrdering the Samples to Obtain GroundTruthIn the above example, assume that the geophysicistshave made preliminary assessments of each of thegeophysical anomalies. In doing so, they have assignedprobabilities that each anomaly represents a target thatshould be dug up. In that case, it is trivial to show that themaximum Shannon information see Equation 1 would beobtained by digging the anomaly about which thegeophysicists are most uncertain about whether theirdecision is correct.Put another way, where the geophysicists assign aprobability of 0.50 that a particular anomaly is a target thatshould be dug up, their uncertainty is highest. Regardingthat anomaly, the expected value of the information to beobtained from digging it up is greater than or equal to theexpected information obtainable from any other anomaly inthe domain.2Thus, the strategy suggested by this simple informationtheoretic approach is to dig next, that anomaly for which theTARGET vs. NOT TARGET classification is mostuncertain.A More Sophisticated Information TheoreticApproach to Ordering Samples to Obtain GroundTruthIntegrating Project Costs and InformationTheoryA second measure by which project engineers couldorder the digging of anomalies would be to maximize theexpected amount of information acquired by digging a holeper dollar of expected additional projectcosts caused bydigging.The cost of digging a hole would be the simplest way tomeasure the cost of obtaining groundtruth for a particularanomaly. But that does not really represent the expenditureof additional monies for that anomaly if there is aprobability assessed to the anomaly that the anomaly is atarget. Rather, if ip represents the probability that the ithanomaly is a target, the expected incremental cost to theproject of digging that anomaly incCost is2 , iincCost  1 digCostip  where digCost is the expected cost of digging a hole.This may be illustrated by an example. Suppose theprobability that the ith anomaly is actually a target is 0.90.In that case, project engineers expect to dig that hole oneway or the other. So digging it now adds an additionalexpected cost to the project measured by the probability thatthe hole will be emptythat is, 0.10, as suggested byEquation 2.3 Thus, if it costs 200 to dig a hole, the2 Although we refer in the preceding paragraph togeophysicist based estimates of probability, such estimates will be made purely by the geophysicists only in the earlystages of the project. As the project continues, and themachine learning system begins to make predictions, thoseprobabilities would be assigned by the machine learningsystem alone or more likely by the machine learningsystem after review of its predictions by the geophysicists.3 Similar reasoning leads to the conclusion that projectengineers may ignore the cost of not digging until the veryend of the project. The decision not to dig imposes noadditional costs on the project until the decision becomesirrevocablethat is, at the end of the project. Until the endexpected additional cost to the project of digging thisanomaly to acquire information is only 20.The information gain per dollar of additional costexpected from digging up the ith anomaly may beformalized by combining Equations 1 and 2. The expectedinformation gain per dollar of added project cost fromdigging the ith anomaly , iI  is stated in Equation 3.3 , iI Costipipip11logIt is simple to demonstrate computationally that, asip increases from 0 to 1, , iI increases steadily, forall positive values of Cost Equation 3.We can therefore conclude as the anomaly diggingproject proceeds, engineers should, at any point, dig theanomaly that then has the highest probability of being atarget. By doing so, they can maximize the expectedinformation gain per dollar of added costs I .Furthermore, so long as project engineers can rank theanomalies in the project from most likely to least likely tobe targets, the same dig ordering holds, even if we cannotassign specific probability numbers. This follows from thefact that, if  jpip  , then , iI is greater than, jI see Equation 3.This leads to a somewhat different conclusion than thesimple application of Equation 1, discussed above. Insteadof digging up the most uncertain anomaly first, this analysissuggests that project engineers can minimize the cost ofacquiring information by, at each point in the project,digging up the anomaly that they are most certain is not afalse positive.Machine Learning as a Decision Support Tool inConcluding the ProjectAt some point in the project, the engineers have to stopdigging. Otherwise, the machine learning system saves nomoney. In this section, we propose a simple metric formaking that determination.The effectiveness in this metric depends on projectengineers adopting the second method of orderingacquisition of groundtruth proposed abovethat is,groundtruth is acquired by starting with the decision aboutwhich human or machine predictors are most certain. Thenthe next most certain. Then the next. And so forth.of the project, the hole can always be dug. So deciding notto dig it at an earlier point in the project adds no cost to theproject.That metric is also based on the project designersassigning a cost  fnCost to making a falsenegativedecision. In our example project,  fnCost represents thecost of a decision not to dig up an anomaly that turns out tobe a target. Our example project is over when engineersdecide not to dig up all anomalies remaining.At each step, the machine learning system has assigneda probability that the ith anomaly is a target, ip . Theincremental cost to the project of not digging the holendCost  is4 ndCost   fnCostip  .As long as ndCost is greater than digCost ,engineers should keep digging because the cost of diggingthe hole is less than the cost of a false negative.So, for example, if the cost of a false negative is 5,000and the cost of digging a hole is 200, engineers shouldkeep digging until ip  04.0 .CONCLUSIONIn this paper we have presented a novel approach tointegrating machine learning techniques with humanexpertise and humanbuilt simulators on projects with a highcost of obtaining data.Engineers with projects similar to those described inthis paper should consider utilizing the techniques describedherein to integrate machine learning capabilities into theirprojects.REFERENCES1 Ernesto R. Cespedes, September 2001. AdvancedUXO Detection  Discrimination TechnologyDemonstrationU.S. Army Jefferson Proving Ground,Madison, Indiana. US Army Corps of Engineers,Engineer Research and Development Center.2 Francone, F. D., Deschaine, Larry, M. 2004.Extending the Boundaries Of Design Optimization byIntegrating Fast Optimization Techniques withMachineCodeBased, Linear, Genetic Programming.In press Journal of Information Sciences, ElsevierPress.3 Banzhaf, W., Nordin, P., Keller, R, and Francone, F.1998 Genetic Programming, An Introduction, MorganKaufmann Publishers, Inc, Stanford CA.4 Deschaine, L. M., Simulation and Optimization ofLarge Scale Subsurface Environmental ImpactsInvestigations, Remedial Design and Long TermMonitoring. In press Journal of MathematicalMachines and Systems, National Academy of Sciencesof Ukraine, Kiev. In press. 2003.5 Langley, Pat. 1998 Elements of Machine Learning,Morgan Kaufmann Publishers, Inc, Stanford, CA.6 Department of Defense, DoD Defense Modeling andSimulation Guidelines for model verification,validation, accreditation and credibility available athttpswww.dmso.milpublictransitionvva7 Shannon, C. E., 1948, A Mathematical Theory ofCommunication, Bell System Technical Journal 27,379423.8 Masters, Timothy. 1995 Advanced Algorithms forNeural Networks, John Wiley  Sons, Inc. New York,New York.9 Koza, John. 1996 Genetic Programming, On theProgramming of Computers by means of NaturalSelection. MIT Press, Cambridge Massachusetts.10 Nordin, P., Banzhaf, W. and Francone, F. 1999Eficient Evolutionof Machine Code for CISCArchitecture Using Instruction Blocks and HomologousCrossover. In Advances in Genetic Programming,Volume III, edited by Spector, Lee et al. MIT Press,Cambridge MA, 275300.11 Francone, F., 2000Discipulus Owners Manual.Available at www.aimlearning.com.12 Koza, J., Bennett, F., Andre, D.,  Keane, M. 2001.Genetic Programming III Automatic Programmingand Automatic Circuit Synthesis. MIT Press,Cambridge, MA.
