Introduction to WordNet An Online Lexical DatabaseGeorge A. Miller, Richard Beckwith, Christiane Fellbaum,Derek Gross, and Katherine MillerRevised August 1993WordNet is an online lexical reference system whose design is inspired by currentpsycholinguistic theories of human lexical memory. English nouns, verbs, and adjectives areorganized into synonym sets, each representing one underlying lexical concept. Differentrelations link the synonym sets.Standard alphabetical procedures for organizing lexical information put togetherwords that are spelled alike and scatter words with similar or related meaningshaphazardly through the list. Unfortunately, there is no obvious alternative, no othersimple way for lexicographers to keep track of what has been done or for readers to findthe word they are looking for. But a frequent objection to this solution is that findingthings on an alphabetical list can be tedious and timeconsuming. Many people whowould like to refer to a dictionary decide not to bother with it because finding theinformation would interrupt their work and break their train of thought.In this age of computers, however, there is an answer to that complaint. Oneobvious reason to resort to online dictionarieslexical databases that can be read bycomputersis that computers can search such alphabetical lists much faster than peoplecan. A dictionary entry can be available as soon as the target word is selected or typedinto the keyboard. Moreover, since dictionaries are printed from tapes that are read bycomputers, it is a relatively simple matter to convert those tapes into the appropriate kindof lexical database. Putting conventional dictionaries on line seems a simple and naturalmarriage of the old and the new.Once computers are enlisted in the service of dictionary users, however, it quicklybecomes apparent that it is grossly inefficient to use these powerful machines as littlemore than rapid pageturners. The challenge is to think what further use to make ofthem. WordNet is a proposal for a more effective combination of traditionallexicographic information and modern highspeed computation.This, and the accompanying four papers, is a detailed report of the state of WordNetas of 1990. In order to reduce unnecessary repetition, the papers are written to be readconsecutively.PsycholexicologyMurrays Oxford English Dictionary 1928 was compiled on historicalprinciples and no one doubts the value of the OED in settling issues of word use orsense priority. By focusing on historical diachronic evidence, however, the OED, likeother standard dictionaries, neglected questions concerning the synchronic organizationof lexical knowledge. 2 It is now possible to envision ways in which that omission might be repaired. The20th Century has seen the emergence of psycholinguistics, an interdisciplinary field ofresearch concerned with the cognitive bases of linguistic competence. Both linguists andpsycholinguists have explored in considerable depth the factors determining thecontemporary synchronic structure of linguistic knowledge in general, and lexicalknowledge in particularMiller and JohnsonLaird 1976 have proposed that researchconcerned with the lexical component of language should be called psycholexicology.As linguistic theories evolved in recent decades, linguists became increasingly explicitabout the information a lexicon must contain in order for the phonological, syntactic, andlexical components to work together in the everyday production and comprehension oflinguistic messages, and those proposals have been incorporated into the work ofpsycholinguists. Beginning with word association studies at the turn of the century andcontinuing down to the sophisticated experimental tasks of the past twenty years,psycholinguists have discovered many synchronic properties of the mental lexicon thatcan be exploited in lexicography.In 1985 a group of psychologists and linguists at Princeton University undertook todevelop a lexical database along lines suggested by these investigations Miller, 1985.The initial idea was to provide an aid to use in searching dictionaries conceptually, ratherthan merely alphabeticallyit was to be used in close conjunction with an onlinedictionary of the conventional type. As the work proceeded, however, it demanded amore ambitious formulation of its own principles and goals. WordNet is the result.Inasmuch as it instantiates hypotheses based on results of psycholinguistic research,WordNet can be said to be a dictionary based on psycholinguistic principles.How the leading psycholinguistic theories should be exploited for this project wasnot always obvious. Unfortunately, most research of interest for psycholexicology hasdealt with relatively small samples of the English lexicon, often concentrating on nounsat the expense of other parts of speech. All too often, an interesting hypothesis is putforward, fifty or a hundred words illustrating it are considered, and extension to the restof the lexicon is left as an exercise for the reader. One motive for developing WordNetwas to expose such hypotheses to the full range of the common vocabulary. WordNetpresently contains approximately 95,600 different word forms 51,500 simple words and44,100 collocations organized into some 70,100 word meanings, or sets of synonyms,and only the most robust hypotheses have survived.The most obvious difference between WordNet and a standard dictionary is thatWordNet divides the lexicon into five categories nouns, verbs, adjectives, adverbs, andfunction words. Actually, WordNet contains only nouns, verbs, adjectives, and adverbs.1The relatively small set of English function words is omitted on the assumptionsupported by observations of the speech of aphasic patients Garrett, 1982 that they areprobably stored separately as part of the syntactic component of language. Therealization that syntactic categories differ in subjective organization emerged first fromstudies of word associations. Fillenbaum and Jones 1965, for example, asked English 1 A discussion of adverbs is not included in the present collection of papers. 3 speaking subjects to give the first word they thought of in response to highly familiarwords drawn from different syntactic categories. The modal response category was thesame as the category of the probe word noun probes elicited nouns responses 79 of thetime, adjectives elicited adjectives 65 of the time, and verbs elicited verbs 43 of thetime. Since grammatical speech requires a speaker to know at least implicitly thesyntactic privileges of different words, it is not surprising that such information would bereadily available. How it is learned, however, is more of a puzzle it is rare in connecteddiscourse for adjacent words to be from the same syntactic category, so Fillenbaum andJoness data cannot be explained as association by continguity.The price of imposing this syntactic categorization on WordNet is a certain amountof redundancy that conventional dictionaries avoidwords like back, for example, turnup in more than one category. But the advantage is that fundamental differences in thesemantic organization of these syntactic categories can be clearly seen and systematicallyexploited. As will become clear from the papers following this one, nouns are organizedin lexical memory as topical hierarchies, verbs are organized by a variety of entailmentrelations, and adjectives and adverbs are organized as Ndimensional hyperspaces. Eachof these lexical structures reflects a different way of categorizing experience attempts toimpose a single organizing principle on all syntactic categories would badly misrepresentthe psychological complexity of lexical knowledge.The most ambitious feature of WordNet, however, is its attempt to organize lexicalinformation in terms of word meanings, rather than word forms. In that respect,WordNet resembles a thesaurus more than a dictionary, and, in fact, Laurence Urdangsrevision of Rodales The Synonym Finder 1978 and Robert L. Chapmans revision ofRogets International Thesaurus 1977 have been helpful tools in putting WordNettogether. But neither of those excellent works is well suited to the printed form. Theproblem with an alphabetical thesaurus is redundant entries if word Wx and word Wy aresynonyms, the pair should be entered twice, once alphabetized under Wx and againalphabetized under Wy. The problem with a topical thesaurus is that two lookups arerequired, first on an alphabetical list and again in the thesaurus proper, thus doubling ausers search time. These are, of course, precisely the kinds of mechanical chores that acomputer can perform rapidly and efficiently.WordNet is not merely an online thesaurus, however. In order to appreciate whatmore has been attempted in WordNet, it is necessary to understand its basic designMiller and Fellbaum, 1991.The Lexical MatrixLexical semantics begins with a recognition that a word is a conventionalassociation between a lexicalized concept and an utterance that plays a syntactic role.This definition of word raises at least three classes of problems for research. First,what kinds of utterances enter into these lexical associations Second, what is the natureand organization of the lexicalized concepts that words can express Third, whatsyntactic roles do different words play Although it is impossible to ignore any of thesequestions while considering only one, the emphasis here will be on the second class of 4 problems, those dealing with the semantic structure of the English lexicon.Since the word word is commonly used to refer both to the utterance and to itsassociated concept, discussions of this lexical association are vulnerable toterminological confusion. In order to reduce ambiguity, therefore, word form will beused here to refer to the physical utterance or inscription and word meaning to refer tothe lexicalized concept that a form can be used to express. Then the starting point forlexical semantics can be said to be the mapping between forms and meanings Miller,1986. A conservative initial assumption is that different syntactic categories of wordsmay have different kinds of mappings.Table 1 is offered simply to make the notion of a lexical matrix concrete. Wordforms are imagined to be listed as headings for the columns word meanings as headingsfor the rows. An entry in a cell of the matrix implies that the form in that column can beused in an appropriate context to express the meaning in that row. Thus, entry E1,1implies that word form F1 can be used to express word meaning M1. If there are twoentries in the same column, the word form is polysemous if there are two entries in thesame row, the two word forms are synonyms relative to a context.Table 1Illustrating the Concept of a Lexical MatrixF1 and F2 are synonyms F2 is polysemousWord Word FormsMeanings F1 F2 F3 . . . FnM1 E1,1 E1,2M2 E2,2M3 E3,3. .. .. .Mm Em,nMappings between forms and meanings are manymanysome forms have severaldifferent meanings, and some meanings can be expressed by several different forms.Two difficult problems of lexicography, polysemy and synonymy, can be viewed ascomplementary aspects of this mapping. That is to say, polysemy and synonymy areproblems that arise in the course of gaining access to information in the mental lexicon alistener or reader who recognizes a form must cope with its polysemy a speaker or writerwho hopes to express a meaning must decide between synonyms.As a parenthetical comment, it should be noted that psycholinguists frequentlyrepresent their hypotheses about language processing by boxandarrow diagrams. Inthat notation, a lexical matrix could be represented by two boxes with arrows goingbetween them in both directions. One box would be labeled Word Meaning and theother Word Form arrows would indicate that a language user could start with ameaning and look for appropriate forms to express it, or could start with a form and 5 retrieve appropriate meanings. This boxandarrow representation makes clear thedifference between meaningmeaning relations in the Word Meaning box andwordword relations in the Word Form box. In its initial conception, WordNet wasconcerned solely with the pattern of semantic relations between lexicalized concepts thatis to say, it was to be a theory of the Word Meaning box. As work proceeded, however,it became increasingly clear that lexical relations in the Word Form box could not beignored. At present, WordNet distinguishes between semantic relations and lexicalrelations the emphasis is still on semantic relations between meanings, but relationsbetween words are also included.Although the boxandarrow representation respects the difference between thesetwo kinds of relations, it has the disadvantage that the intricate details of the manymanymapping between meanings and forms are slighted, which not only conceals thereciprocity of polysemy and synonymy, but also obscures the major device used inWordNet to represent meanings. For that reason, this description of WordNet has beenintroduced in terms of a lexical matrix, rather than as a boxandarrow diagram.How are word meanings represented in WordNet In order to simulate a lexicalmatrix it is necessary to have some way to represent both forms and meanings in acomputer. Inscriptions can provide a reasonably satisfactory solution for the forms, buthow meanings should be represented poses a critical question for any theory of lexicalsemantics. Lacking an adequate psychological theory, methods developed bylexicographers can provide an interim solution definitions can play the same role in asimulation that meanings play in the mind of a language user.How lexicalized concepts are to be represented by definitions in a theory of lexicalsemantics depends on whether the theory is intended to be constructive or merelydifferential. In a constructive theory, the representation should contain sufficientinformation to support an accurate construction of the concept by either a person or amachine. The requirements of a constructive theory are not easily met, and there issome reason to believe that the definitions found in most standard dictionaries do notmeet them Gross, Kegl, Gildea, and Miller, 1989 Miller and Gildea, 1987. In adifferential theory, on the other hand, meanings can be represented by any symbols thatenable a theorist to distinguish among them. The requirements for a differential theoryare more modest, yet suffice for the construction of the desired mappings. If the personwho reads the definition has already acquired the concept and needs merely to identify it,then a synonym or near synonym is often sufficient. In other words, the word meaningM1 in Table 1 can be represented by simply listing the word forms that can be used toexpress it F1, F2, . . . . Here and later, the curly brackets,  and , surround thesets of synonyms that serve as identifying definitions of lexicalized concepts. Forexample, someone who knows that board can signify either a piece of lumber or a groupof people assembled for some purpose will be able to pick out the intended sense with nomore help than plank or committee. The synonym sets, board, plank and board,committee can serve as unambiguous designators of these two meanings of board.These synonym sets synsets do not explain what the concepts are they merely signifythat the concepts exist. People who know English are assumed to have already acquired 6 the concepts, and are expected to recognize them from the words listed in the synset.A lexical matrix, therefore, can be represented for theoretical purposes by amapping between written words and synsets. Since English is rich in synonyms, synsetsare often sufficient for differential purposes. Sometimes, however, an appropriatesynonym is not available, in which case the polysemy can be resolved by a short gloss,e.g., board, a persons meals, provided regularly for money can serve to differentiatethis sense of board from the others it can be regarded as a synset with a single member.The gloss is not intended for use in constructing a new lexical concept by someone notalready familiar with it, and it differs from a synonym in that it is not used to gain accessto information stored in the mental lexicon. It fulfills its purpose if it enables the user ofWordNet, who is assumed to know English, to differentiate this sense from others withwhich it could be confused.Synonymy is, of course, a lexical relation between word forms, but because it isassigned this central role in WordNet, a notational distinction is made between wordsrelated by synonymy, which are enclosed in curly brackets,  and , and other lexicalrelations, which will be enclosed in square brackets,  and . Semantic relations areindicated by pointers.WordNet is organized by semantic relations. Since a semantic relation is a relationbetween meanings, and since meanings can be represented by synsets, it is natural tothink of semantic relations as pointers between synsets. It is characteristic of semanticrelations that they are reciprocated if there is a semantic relation R between meaning x,x, . . . and meaning y, y, . . ., then there is also a relation R between y, y, . . . andx, x, . . .. For the purposes of the present discussion, the names of the semanticrelations will serve a dual role if the relation between the meanings x, x, . . . and y,y, . . . is called R, then R will also be used to designate the relation between individualword forms belonging to those synsets. It might be logically tidier to introduce separateterms for the relation between meanings and for the relation between forms, but evengreater confusion might result from the introduction of so many new technical terms.The following examples illustrate but do not exhaust the kinds of relations used tocreate WordNet.SynonymyFrom what has already been said, it should be obvious that the most importantrelation for WordNet is similarity of meaning, since the ability to judge that relationbetween word forms is a prerequisite for the representation of meanings in a lexicalmatrix. According to one definition usually attributed to Leibniz two expressions aresynonymous if the substitution of one for the other never changes the truth value of asentence in which the substitution is made. By that definition, true synonyms are rare, ifthey exist at all. A weakened version of this definition would make synonymy relative toa context two expressions are synonymous in a linguistic context C if the substitution ofone for the other in C does not alter the truth value. For example, the substitution ofplank for board will seldom alter truth values in carpentry contexts, although there areother contexts of board where that substitution would be totally inappropriate. 7 Note that the definition of synonymy in terms of substitutability makes it necessaryto partition WordNet into nouns, verbs, adjectives, and adverbs. That is to say, ifconcepts are represented by synsets, and if synonyms must be interchangeable, thenwords in different syntactic categories cannot be synonyms cannot form synsetsbecause they are not interchangeable. Nouns express nominal concepts, verbs expressverbal concepts, and modifiers provide ways to qualify those concepts. In other words,the use of synsets to represent word meanings is consistent with psycholinguisticevidence that nouns, verbs, and modifiers are organized independently in semanticmemory. An argument might be made in favor of still further partitions some words inthe same syntactic category particularly verbs express very similar concepts, yet cannotbe interchanged without making the sentence ungrammatical.The definition of synonymy in terms of truth values seems to make synonymy adiscrete matter two words either are synonyms or they are not. But as somephilosophers have argued, and most psychologists accept without considering thealternative, synonymy is best thought of as one end of a continuum along whichsimilarity of meaning can be graded. It is probably the case that semantically similarwords can be interchanged in more contexts than can semantically dissimilar words. Butthe important point here is that theories of lexical semantics do not depend on truthfunctional conceptions of meaning semantic similarity is sufficient. It is convenient toassume that the relation is symmetric if x is similar to y, then y is equally similar to x.The gradability of semantic similarity is ubiquitous, but it is most important forunderstanding the organization of adjectival and adverbial meanings.AntonymyAnother familiar relation is antonymy, which turns out to be surprisingly difficult todefine. The antonym of a word x is sometimes notx, but not always. For example, richand poor are antonyms, but to say that someone is not rich does not imply that they mustbe poor many people consider themselves neither rich nor poor. Antonymy, whichseems to be a simple symmetric relation, is actually quite complex, yet speakers ofEnglish have little difficulty recognizing antonyms when they see them.Antonymy is a lexical relation between word forms, not a semantic relation betweenword meanings. For example, the meanings rise, ascend and fall, descend may beconceptual opposites, but they are not antonyms risefall are antonyms and so areascenddescend, but most people hesitate and look thoughtful when asked if rise anddescend, or ascend and fall, are antonyms. Such facts make apparent the need todistinguish between semantic relations between word forms and semantic relationsbetween word meanings. Antonymy provides a central organizing principle for theadjectives and adverbs in WordNet, and the complications that arise from the fact thatantonymy is a semantic relation between words are better discussed in that context. 8 HyponymyUnlike synonymy and antonymy, which are lexical relations between word forms,hyponymyhypernymy is a semantic relation between word meanings e.g., maple is ahyponym of tree, and tree is a hyponym of plant. Much attention has beendevoted to hyponymyhypernymy variously called subordinationsuperordination,subsetsuperset, or the ISA relation. A concept represented by the synset x, x, . . . issaid to be a hyponym of the concept represented by the synset y, y, . . . if nativespeakers of English accept sentences constructed from such frames as An x is a kind ofy. The relation can be represented by including in x, x, . . . a pointer to itssuperordinate, and including in y, y, . . . pointers to its hyponyms.Hyponymy is transitive and asymmetrical Lyons, 1977, vol. 1, and, since there isnormally a single superordinate, it generates a hierarchical semantic structure, in which ahyponym is said to be below its superordinate. Such hierarchical representations arewidely used in the construction of information retrieval systems, where they are calledinheritance systems Touretzky, 1986 a hyponym inherits all the features of the moregeneric concept and adds at least one feature that distinguishes it from its superordinateand from any other hyponyms of that superordinate. For example, maple inherits thefeatures of its superordinate, tree, but is distinguished from other trees by the hardness ofits wood, the shape of its leaves, the use of its sap for syrup, etc. This conventionprovides the central organizing principle for the nouns in WordNet.MeronymySynonymy, antonymy, and hyponymy are familiar relations. They apply widelythroughout the lexicon and people do not need special training in linguistics in order toappreciate them. Another relation sharing these advantagesa semantic relationis thepartwhole or HASA relation, known to lexical semanticists as meronymyholonymy. Aconcept represented by the synset x, x, . . . is a meronym of a concept represented bythe synset y, y, . . . if native speakers of English accept sentences constructed fromsuch frames as A y has an x as a part or An x is a part of y. The meronymic relation istransitive with qualifications and asymmetrical Cruse, 1986, and can be used toconstruct a part hierarchy with some reservations, since a meronym can have manyholonyms. It will be assumed that the concept of a part of a whole can be a part of aconcept of the whole, although it is recognized that the implications of this assumptiondeserve more discussion than they will receive here.These and other similar relations serve to organize the mental lexicon. They can berepresented in WordNet by parenthetical groupings or by pointers labeled arcs from onesynset to another. These relations represent associations that form a complex networkknowing where a word is situated in that network is an important part of knowing thewords meaning. It is not profitable to discuss these relations in the abstract, however,because they play different roles in organizing the lexical knowledge associated withdifferent syntactic categories. 9 Morphological RelationsAn important class of lexical relations are the morphological relations betweenword forms. Initially, interest was limited to semantic relations no plans were made toinclude morphological relations in WordNet. As work progressed, however, it becameincreasingly obvious that if WordNet was to be of any practical use to anyone, it wouldhave to deal with inflectional morphology. For example, if someone put the computerscursor on the word trees and clicked a request for information, WordNet should not replythat the word was not in the database. A program was needed to strip off the plural suffixand then to look up tree, which certainly is in the database. This need led to thedevelopment of a program for dealing with inflectional morphology.Although the inflectional morphology of English is relatively simple, writing acomputer program to deal with it proved to be a more complex task than had beenexpected. Verbs are the major problem, of course, since there are four forms and manyirregular verbs. But the software has been written and is presently available as part of theinterface between the lexical database and the user. In the course of this development itbecame obvious that programs dealing with derivational morphology would greatlyenhance the value of WordNet, but that more ambitious project has not yet beenundertaken.The three papers following this introduction have little to say about lexical relationsresulting from inflectional morphology, since those relations are incorporated in theinterface to WordNet, not in the central database. 10 Nouns in WordNet A Lexical Inheritance SystemGeorge A. MillerRevised August 1993Definitions of common nouns typically give a superordinate term plusdistinguishing features that information provides the basis for organizing nounfiles in WordNet. The superordinate relation hyponymy generates ahierarchical semantic organization that is duplicated in the noun files by theuse of labeled pointers between sets of synonyms synsets. The hierarchy islimited in depth, seldom exceeding more than a dozen levels. Distinguishingfeatures are entered in such a way as to create a lexical inheritance system, asystem in which each word inherits the distinguishing features of all itssuperordinates. Three types of distinguishing features are discussed attributesmodification, parts meronymy, and functions predication, but onlymeronymy is presently implemented in the noun files. Antonymy is also foundbetween nouns, but it is not a fundamental organizing principle for nouns.Coverage is partitioned into twentyfive topical files, each of which deals witha different primitive semantic component.As this is written, WordNet contains approximately 57,000 noun word formsorganized into approximately 48,800 word meanings synsets. The numbers areapproximate because WordNet continues to growone advantage of an online database.Many of these nouns are compounds, of course a few are artificial collocations inventedfor the convenience of categorization. No attempt has been made to include propernouns on the other hand, since many common nouns once were names, no seriousattempt has been made to exclude them. In terms of coverage, WordNets goals differlittle from those of a good standard handheld collegiatelevel dictionary. It is in theorganization of that information that WordNet aspires to innovation.If someone asks how to use a conventional dictionary, it is customary to explain thedifferent kinds of information packed into lexical entries spelling, pronunciation,inflected and derivative forms, etymology, part of speech, definitions and illustrative usesof alternative senses, synonyms and antonyms, special usage notes, occasional linedrawings or platesa good dictionary is a remarkable store of information. But ifsomeone asks how to improve a dictionary, it becomes necessary to consider what is notincluded. And when, as in the case of WordNet, improvements are intended to reflectpsycholinguistic principles, the focal concern becomes what is not included in thedefinitions.Examples offer the simplest way to characterize the omissions. Take one meaningof the noun tree, the sense having to do with trees as plants. Conventional dictionariesdefine this sense of tree by some such gloss as a plant that is large, woody, perennial,and has a distinct trunk. Of course, the actual wording is usually more felicitousalarge, woody, perennial plant with a distinct trunk, for examplebut the underlyinglogic is the same superordinate plus distinguishers. The point is that the prototypical 11 definition of a noun consists of its immediate superordinate plant, in this example,followed by a relative clause that describes how this instance differs from all otherinstances.What is missing from this definition Anyone educated to expect this kind of thingin a dictionary will not feel that anything is missing. But the definition is woefullyincomplete. It does not say, for example, that trees have roots, or that they consist ofcells having cellulose walls, or even that they are living organisms. Of course, if youlook up the superordinate term, plant, you may find that kind of informationunless, ofcourse, you make a mistake and choose the definition of plant that says it is a placewhere some product is manufactured. There is, after all, nothing in the definition of treethat specifies which sense of plant is the appropriate superordinate. That specification isomitted on the assumption that the reader is not an idiot, a Martian, or a computer. But itis instructive to note that, even though intelligent readers can supply it for themselves,important information about the superordinate term is missing from the definition.Second, this definition of tree contains no information about coordinate terms. Theexistence of other kinds of plants is a plausible conjecture, but no help is given in findingthem. A reader curious about coordinate terms has little alternative but to scan thedictionary from A to Z, noting along the way each occurrence of a definition with thesuperordinate term plant. Even this heroic strategy might not succeed if thelexicographers, not expecting such use of their work, did not maintain strict uniformity intheir choice of superordinate terms. Tree is probably an unfair example in this respect,since the distinction between trees and bushes is so unclearthe same plant that growsinto a tall tree in one location may be little more than a bush in a less favorable climate.Botanists have little use for the lay term treemany trees are gymnosperms, many othersangiosperms. Even for wellbehaved definitions, however, a conventional dictionaryleaves the discovery of coordinate terms as a challenging exercise for the reader.Third, a similar challenge faces a reader who is interested in knowing the differentkinds of trees. In addition to looking through the dictionary for such familiar trees aspine or maple or oak, a reader might wish to know which trees are deciduous, which arehardwoods, or how many different kinds of conifers there are. Dictionaries contain muchof this information, but only the most determined reader would try to dig it out. Theprototypical definition points upward, to a superordinate term, not sideways to coordinateterms or downward to hyponyms.Fourth, everyone knows a great deal about trees that lexicographers would notinclude in a definition of tree. For example, trees have bark and twigs, they grow fromseeds, adult trees are much taller than human beings, they manufacture their own food byphotosynthesis, they provide shade and protection from the wind, they grow wild inforests, their wood is used in construction and for fuel, and so on. Someone who wastotally innocent about trees would not be able to construct an accurate concept of them ifnothing more were available than the information required to define tree. A dictionarydefinition draws some important distinctions and serves to remind the reader ofsomething that is presumed to be familiar already it is not intended as a catalogue ofgeneral knowledge. There is a place for encyclopedias as well as dictionaries. 12 Note that much of the missing information is structural, rather than factual. That isto say, lexicographers make an effort to cover all of the factual information about themeanings of each word, but the organization of the conventional dictionary into discrete,alphabetized entries and the economic pressure to minimize redundancy make thereassembly of this scattered information a formidable chore.Lexical Inheritance SystemsIt has often been observed that lexicographers are caught in a web of words.Sometimes it is posed as a conundrum since words are used to define words, how canlexicography escape circularity Every dictionary probably contains a few vacuouscircles, instances where word Wa is used to define word Wb and Wb is also used to defineWa in such cases, presumably, the lexicographer inadvertently overlooked the need todefine one or the other of these synonyms in terms of something else. Circularity is theexception, not the rule.The fundamental design that lexicographers try to impose on the semantic memoryfor nouns is not a circle, but a tree in the sense of tree as a graphical representation. Itis a defining property of tree graphs that they branch from a single stem without formingcircular loops. The lexical tree can be reconstructed by following trails of superordinateterms oak  tree  plant  organism, for example, where  is thetransitive, asymmetric, semantic relation that can be read is a or is a kind of. Byconvention,  is said to point upward. This design creates a sequence of levels, ahierarchy, going from many specific terms at the lower levels to a few generic terms atthe top. Hierarchies provide conceptual skeletons for nouns information aboutindividual nouns is hung on this structure like ornaments on a Christmas tree.The semantic relation that is represented above by  has been called the ISArelation, or the hypernymic or superordinate relation since it points to a hypernym orsuperordinate term it goes from specific to generic and so is a generalization.Whenever it is the case that a noun Wh  a noun Ws, there is always an inverserelation, Ws  Wh. That is to say, if Ws is the superordinate of Wh, then Wh is thesubordinate or hyponym of Ws. The inverse semantic relation  goes from generic tospecific from superordinate to hyponym and so is a specialization.Since a noun usually has a single superordinate, dictionaries include thesuperordinate in the definition since a noun can have many hyponyms, Englishdictionaries do not list them the French dictionary Le Grand Robert is an exception.Even though the specialization relation is not made explicit in standard dictionaries ofEnglish, it is a logical derivative of the generalization relation. In WordNet,lexicographers code the generalization relation  explicitly with a labeled pointerbetween lexical concepts or senses. When the lexicographers files are convertedautomatically into the lexical database, one step in this process is to insert inversepointers for the specialization relation . Thus, the lexical database is a hierarchythat can be searched upward or downward with equal speed.Hierarchies of this sort are widely used by computer programmers to organize largedatabases Touretzky, 1986. They have the advantage that information common to 13 many items in the database need not be stored with every item. In other words, databaseexperts and lexicographers both resort to hierarchical structures for the same reason tosave space. Computer scientists call such hierarchies inheritance systems, becausethey think of specific items inheriting information from their generic superordinates.That is to say, all of the properties of the superordinate are assumed to be properties ofthe subordinate as well instead of listing those properties redundantly with both items,they are listed only with the superordinate and a pointer from the subordinate to thesuperordinate is understood to mean for additional properties, look here.Inheritance is most easily understood for names. If you hear that your friend hasacquired a collie named Rex, you do not need to ask whether Rex is an animal, whetherRex has hair, four legs, and a tail, or whether Rex shares any other properties known tocharacterize collies. Such questions would be distinctly odd. Since you have been toldthat Rex is a collie, you are expected to understand that Rex inherits all the propertiesthat define collie. And, implicitly, that collie inherits the properties of dog, whichinherits the properties of of canine, and so on.Clearly, an inheritance system is implicit in the prototypical lexicographic definitionof a noun. A lexicographer does not store the information that is common to tree andplant with both entries the lexicographer stores the redundant information only withplant, then writes the definition of tree in such a way that a reader will know where tofind it. With a printed dictionary, however, a user must look up repeated entries in orderto find information that can be instantly retrieved and displayed by a computer.WordNet is a lexical inheritance system a systematic effort has been made toconnect hyponyms with their superordinates and vice versa. In the WordNet database,an entry for tree contains a reference, or pointer , to an entry for plant the pointeris labeled superordinate by the arbitrary symbol . Thus, the synset for tree wouldlook something like tree, plant, conifer, alder, . . . where the . . . is filled with many more pointers to hyponyms. In the database, thepointer  to the superordinate plant will be reflected by an inverse pointer  to tree inthe synset for plant that pointer is labeled hyponym by the arbitrary symbol  plant, flora, organism, tree, . . . tree is not the only hyponym of plant, flora, of course others have been omittedhere in order not to obscure the reciprocity of  and . The computer is programmedto use these labeled pointers to construct whatever information a user requests thearbitrary symbols  and  are suppressed when the requested information isdisplayed. There is no need for special tags on tree or plant, to distinguish which sensesare intended because nouns denoting living plants are all in one file, whereas nounsdenoting graphical trees or manufacturing plants are elsewhere, as will be explainedbelow.It should be noted, at least parenthetically, that WordNet assumes that a distinctioncan always be drawn between synonymy and hyponymy. In practice, of course, thisdistinction is not always clear, but in a conventional dictionary that causes no problems.For example, a conventional dictionary can include in its entry for board the information 14 that this term can be used to refer to surf boards or to skate boards. That is to say, inaddition to the generic meaning of board, there are specific meanings of board that arehyponyms of the generic meaning. If the information were entered this way in WordNet,however, then a request for information about the superordinates of board would elicitthe same path twice, the only difference being that one path would be prefaced by surfboard, board  board. In WordNet, therefore, an effort has been made to avoidentries in which a term is its own hyponym. Thus, for example, cat is entered inWordNet as the superordinate of big cat and house cat, even though to most people theprimary sense of catthe meaning that comes first to mindis house cat, tabby, pussy,pussy cat, domesticated cat. WordNet does not make explicit the fact that cat isfrequently used to refer to pet cats, but relies on general linguistic knowledge that asuperordinate term can replace a more specific term whenever the context insures that noconfusion will result.What benefits follow from treating lexical knowledge as an inheritance system Inthe introduction to this paper, four examples of information missing from conventionaldefinitions were described. Of those four, the first three can be repaired by the judicioususe of labeled pointers with a computer it is as easy to move from superordinate tohyponyms as it is to move from hyponym to superordinate. The fourth omissionof allthe associated general knowledge about a referent that is not given in a termsdefinitionstands uncorrected in WordNet somewhere a line must be drawn betweenlexical concepts and general knowledge, and WordNet is designed on the assumption thatthe standard lexicographic line is probably as distinct as any could be.Psycholinguistic AssumptionsSince WordNet is supposed to be organized according to principles governinghuman lexical memory, the decision to organize the nouns as an inheritance systemreflects a psycholinguistic judgment about the mental lexicon. What kinds of evidenceprovide a basis for such decisionsThe isolation of nouns into a separate lexical subsystem receives some support fromclinical observations of patients with anomic aphasia. After a lefthemisphere stroke thataffects the ability to communicate linguistically, most patients are left with a deficit innaming ability Caramazza and Berndt, 1978. In anomic aphasia, there is a specificinability to name objects. When confronted with an apple, say, patients may be unable toutter apple, even though they will reject such suggestions as shoe or banana, and willrecognize that apple is correct when it is provided. They have similar difficulties innaming pictured objects, or in providing a name when given its definition, or in usingnouns in spontaneous speech. Nouns that occur frequently in everyday usage tend to bemore accessible than are rarely used nouns, but a patient with severe anomia looks for allthe world like someone whose semantic memory for nouns has become disconnectedfrom the rest of the lexicon. However, clinical symptoms are characterized by greatvariability from one patient to the next, so no great weight should be assigned to suchobservations. 15 Psycholinguistic evidence that knowledge of nouns is organized hierarchicallycomes from the ease with which people handle anaphoric nouns and comparativeconstructions. 1 Superordinate nouns can serve as anaphors referring back to theirhyponyms. For example, in such constructions as He owned a rifle, but the gun had notbeen fired, it is immediately understood that the gun is an anaphoric noun with a rifle asits antecedent. Moreover, 2 superordinates and their hyponyms cannot be comparedBever and Rosenbaum, 1970. For example, both A rifle is safer than a gun and A gun issafer than a rifle are immediately recognized as semantically anomalous. Suchjudgments demand an explanation in terms of hierarchical semantic relations.More to the point, however, is the question is there psycholinguistic evidence thatpeoples lexical memory for nouns forms an inheritance system The first person tomake this claim explicit seems to have been Quillian 1967, 1968. Experimental tests ofQuillians proposal were reported in a seminal paper by Collins and Quillian 1969, whoassumed that reaction times can be used to indicate the number of hierarchical levelsseparating two meanings. They observed, for example, that it takes less time to respondTrue to A canary can sing than to A canary can fly, and still more time is requiredto respond True to A canary has skin. In this example, it is assumed that can sing isstored as a feature of canary, can fly as a feature of bird, and has skin as a feature ofanimal. If all three features had been stored directly as features of canary, they could allhave been retrieved with equal speed. The reaction times are not equal becauseadditional time is required to retrieve can fly and has skin from the superordinateconcepts. Collins and Quillian concluded from such observations that genericinformation is not stored redundantly, but is retrieved when needed. In WordNet, thehierarchy is canary  finch  passerine  bird  vertebrate  animal,but these intervening levels do not affect the general argument that Collins and Quillianwere making.Most psycholinguists agree that English common nouns are organized hierarchicallyin semantic memory, but whether generic information is inherited or is storedredundantly is still moot Smith, 1978. The publication of Collins and Quillians 1969experiments stimulated considerable research, in the course of which a number ofproblems were raised. For example, according to Quillians theory, robin and ostrichshare the same kind of semantic link to the superordinate bird, yet A robin is a bird isconfirmed more rapidly than is An ostrich is a bird Wilkins, 1971. Or, again, canmove and has ears are both properties that people associate with animal, yet An animalcan move is confirmed more rapidly than is An animal has ears Conrad, 1972.From these and similar results, many psycholinguists concluded that Quillian was wrong,that semantic memory for nouns is not organized as an inheritance system.An alternative conclusionthe conclusion on which WordNet is basedis that theinheritance assumption is correct, but that reaction times do not measure what Collinsand Quillian, and other experimentalists assumed they did. Perhaps reaction timesindicate a pragmatic rather than a semantic distancea difference in word use, ratherthan a difference in word meaning Miller and Charles, 1991. 16 Semantic ComponentsOne way to construe the hierarchical principle is to assume that all nouns arecontained in a single hierarchy. If so, the topmost, or most generic level would besemantically empty. In principle, it is possible to put some vague abstraction designated,say, entity, at the top to make object, thing and idea its immediate hyponyms, andso to continue down to more specific meanings, thus pulling all nouns together into asingle hierarchical memory structure. In practice, however, these abstract genericconcepts carry little semantic information it is doubtful that people could even agree onappropriate words to express them.The alternative is to partition the nouns with a set of semantic primesto select arelatively small number of generic concepts and to treat each one as the uniquebeginner of a separate hierarchy. These multiple hierarchies correspond to relativelydistinct semantic fields, each with its own vocabulary. That is to say, since the featuresthat characterize a unique beginner are inherited by all of its hyponyms, a uniquebeginner can be regarded as a primitive semantic component of all words in itshierarchically structured semantic field. Partitioning the nouns also has practicaladvantages it reduces the size of the files that the lexicographers must work with, andmakes it possible to assign the writing and editing of different files to differentlexicographers.Table 1List of 25 unique beginners for WordNet nounsact, action, activity natural objectanimal, fauna natural phenomenonartifact person, human beingattribute, property plant, florabody, corpus possessioncognition, knowledge processcommunication quantity, amountevent, happening relationfeeling, emotion shapefood state, conditiongroup, collection substancelocation, place timemotiveThe problem, of course, is to decide what these primitive semantic componentsshould be. Different workers make different choices one important criterion is that,collectively, they should provide a place for every English noun. WordNet has adoptedthe set of twentyfive unique beginners that are listed in Table 1. These hierarchies varywidely in size and are not mutually exclusivesome crossreferencing is requiredbuton the whole they cover distinct conceptual and lexical domains. They were selected 17 after considering the possible adjectivenoun combinations that could be expected tooccur that analysis was carried out by Philip N. JohnsonLaird. The rationale will bediscussed below.Once the primitive semantic components had been chosen, however, some naturalgroupings among them were observed. Seven of the components, for example, wereconcerned with living or nonliving things they could be arranged hierarchically asdiagrammed in Figure 1. Accordingly, a small Tops file was created in order to includethese semantic relations in the system. However, the great bulk of WordNets nouns arecontained in the twentyfive component files.Figure 1. Diagrammatic representation of hyponymic relationsamong seven unique beginnersdenoting different kinds of tangible things.plant, floraliving thing, organism animal, faunaperson, human beingthing, entitynatural objectartifactnonliving thing, object substancefoodIt is of some interest that these files are relatively shallow. In principle, of course,there is no limit to the number of levels an inheritance system can have. Lexicalinheritance systems, however, seldom go more than ten levels deep, and the deepestexamples usually contain technical levels that are not part of the everyday vocabulary.For example, a Shetland pony is a pony, a horse, an equid, an oddtoed ungulate, aherbivore, a mammal, a vertebrate, and an animal pursuing it into the Tops file addsorganism and entity eleven levels, most of them technical. Some hierarchies are deeperthan others manmade artifacts sometimes go six or seven levels deep roadster  car motor vehicle  wheeled vehicle  vehicle  conveyance  artifact,whereas the hierarchy of persons runs about three or four one of the deepest istelevangelist  evangelist  preacher  clergyman  spiritual leader person. Advocates of redundant storage of the information associated with theseconcepts point out that the more generic information would be repeated over and over ina redundant system, so each additional level would put an increasingly severe burden onlexical memorya possible reason that the number of levels is limited.Distinguishing FeaturesThese hierarchies of nominal concepts are said to have a level, somewhere in themiddle, where most of the distinguishing features are attached. It is referred to as thebasic level, and the nominal concepts at this level are called basiclevel categories orgeneric concepts Berlin, Breedlove, and Raven, 1966, 1973. Rosch 1975 Rosch, 18 Mervis, Gray, Johnson, and BoyesBraem, 1976 extended this generalization forconcepts at the basic level, people can list many distinguishing features. Above the basiclevel, descriptions are brief and general. Below the base level, little is added to thefeatures that distinguish basic concepts. These observations have been made largely forthe names of concrete, tangible objects, but some psycholinguists have argued that a baseor primary level should be a feature of every lexical hierarchy Hoffman and Ziessler,1983.Although the overall structure of noun hierarchies is generated by the hyponymyrelation, details are given by the features that distinguish one concept from another. Forexample, a canary is a bird that is small, colorful, sings, and flies, so not only mustcanary be entered as a hyponym of bird, but the attributes of small size and bright colormust also be included, as well as the activities of singing and flying. Moreover, canarymust inherit from bird the fact that it has a beak and wings with feathers. In order tomake all of this information available when canary is activated, it must be possible toassociate canary appropriately with at least three different kinds of distinguishingfeatures Miller, in press1 Attributes small, yellow2 Parts beak, wings3 Functions sing, flyEach type of distinguishing feature must be treated differently.Note that attributes are given by adjectives, parts by nouns, and functions by verbs.If the association of canary with each of these features is to be represented in WordNetby labeled pointers, then pointers will be required from nouns to adjectives and fromnouns to verbs. As this is written, allowance has been made for including such pointersin WordNet, but the possibility has not yet been coded by the lexicographers only thepointers to parts, which go from nouns to nouns, have been implemented.When WordNet was first conceived, it was not intended to include informationabout distinguishing features. It was assumed that WordNet would be used in closeconjunction with some online dictionary, and that the distinguishing features of a lexicalconcept would be available from that source. As the coverage of WordNet increased, itbecame increasingly obvious that alternative senses of a word could not always beidentified by the use of synonyms. Rather late in the game, therefore, it was decided toinclude distinguishing features in the same way that conventional dictionaries do, byincluding short explanatory glosses as a part of synsets containing polysemous words.These are marked off from the rest of the synset by parentheses. For example, theartifact hierarchy in WordNet contains eight different senses of the highly polysemousnoun casecarton, case0, box, a box made of cardboard opens by flaps on the topcase1, bag, a portable bag for carrying small objectscase2, pillowcase, pillowslip, slip2, bed linen, a removable and washable coverfor a pillow 19 bag1, case3, grip, suitcase, traveling bag, a portable rectangular traveling bagfor carrying clothescabinet, case4, console, cupboard, a cupboard with doors and shelvescase5, container, a small portable metal containershell, shell plating, case6, casing1, outside surface, the outer covering orhousing of somethingcasing, case7, framework, the enclosing frame around a door or windowopeningThe parenthetical glosses serve to keep the several senses distinct, but a certainredundancy is apparent between the superordinate concepts, indicated by , and thehead words of the defining gloss. As more distinguishing features come to be indicatedby pointers, these glosses should become even more redundant. An imaginable test of thesystem would then be to write a computer program that would synthesize glosses fromthe information provided by the pointers.At the present time, however, attributive and functional features are not availablefor many words, and where they are available, it is in the form of defining glosses, notlabeled pointers to the appropriate adjectives or verbs. But partwhole relations areavailable in WordNet experience with these distinguishing features should provide abasis for the future implementation of crosspartofspeech pointers.Attributes and ModificationValues of attributes are expressed by adjectives. For example, size and color areattributes of canaries the size of canaries can be expressed by the adjective small, andthe usual color of canaries can be expressed by the adjective yellow. There is nosemantic relation comparable to synonymy or hyponymy that can serve this function,however. Instead, adjectives are said to modify nouns, or nouns are said to serve asarguments for attributes Sizecanary  small.Although the possibility has not yet been implemented in WordNet, the fact that acanary is small could be represented by a labeled pointer in much the same way as thefact that a canary is a bird is represented. Formally, the difference is that there would beno return pointer from small back to canary. That is to say, although people will listsmall when asked for the features of canaries, when asked to list small things they areunlikely to group together canaries, pygmies, ponies, and closets. The pointer fromcanary to small is interpreted with respect to the immediate superordinate of canary, i.e.,small for a bird, but that anchor to a head noun is lost when small is accessed alone.The semantic structure of adjectival concepts is discussed by Gross and Miller thisvolume. Here it is sufficient to point out that the attributes associated with a noun arereflected in the adjectives that can normally modify it. For example, a canary can behungry or satiated because hunger is a feature of animals and canaries are animals, but astingy canary or a generous canary could only be interpreted metaphorically, sincegenerosity is not a feature of animals in general, or of canaries in particular. Keil 1979,1983 has argued that children learn the hierarchical structure of nominal concepts by 20 observing what can and cannot be predicated at each level. For example, the importantsemantic distinction between animate and inanimate nouns derives from the fact that theadjectives dead and alive can be predicated of one class of nouns but not of the other.Although such selectional restrictions on adjectives are not represented explicitly inWordNet, they did motivate the partitioning of the nouns into the twentyfive semanticcomponents listed above.Parts and MeronymyThe partwhole relation between nouns is generally considered to be a semanticrelation, called meronymy from the Greek meros, part Cruse, 1986, comparable tosynonymy, antonymy, and hyponymy. The relation has an inverse if Wm is a meronymof Wh, then Wh is said to be a holonym of Wm.Meronyms are distinguishing features that hyponyms can inherit. Consequently,meronymy and hyponymy become intertwined in complex ways. For example, if beakand wing are meronyms of bird, and if canary is a hyponym of bird, then, by inheritance,beak and wing must also be meronyms of canary. Although the connections may appearcomplex when dissected in this manner, they are rapidly deployed in languagecomprehension. For example, most people do not even notice the inferences required toestablish a connection between the following sentences It was a canary. The beak wasinjured. Of course, after canary has inherited beak often enough, the fact that canarieshave beaks may come to be stored redundantly with the other features of canary, but thatpossibility does not mean that the general structure of peoples lexical knowledge is notorganized hierarchically.The connections between meronymy and hyponymy are further complicated by thefact that parts are hyponyms as well as meronyms. For example, beak, bill, neb is ahyponym of mouth, muzzle, which in turn is a meronym of face, countenance and ahyponym of orifice, opening. A frequent problem in establishing the proper relationbetween hyponymy and meronymy arises from a general tendency to attach features toohigh in the hierarchy. For example, if wheel is said to be a meronym of vehicle, thensleds will inherit wheels they should not have. Indeed, in WordNet a special synset wascreated for the concept, wheeled vehicle.It has been said that distinguishing features are introduced into noun hierarchiesprimarily at the level of basic concepts some claims have been made that meronymy isparticularly important for defining basic terms Tversky and Hemenway, 1984. Tests ofthese claims, however, have been concerned primarily with words denoting physicalobjects, which is where meronyms tend to occur most frequently. In WordNet,meronymy is found primarily in the body, corpus, artifact, and quantity, amounthierarchies. For concrete objects like bodies and artifacts, meronyms do indeed help todefine a basic level. No such level is apparent for terms denoting quantities, however,where small units of measurement are parts of larger units at every level of the hierarchy.Since attributes and functions have not yet been coded, no attempt has been made to seewhether a basic level can be defined for the more abstract hierarchies. 21 The part of relation is often compared to the kind of relation both areasymmetric and with reservations transitive, and can relate terms hierarchically Millerand JohnsonLaird, 1976. That is to say, parts can have parts a finger is a part of ahand, a hand is a part of an arm, an arm is a part of a body the term finger is a meronymof the term hand, hand is a meronym of arm, arm is a meronym of body. But the partof construction is not always a reliable test of meronymy. A basic problem withmeronymy is that people will accept the test frame, Wm is a part of Wh, for a variety ofpartwhole relations.In many instances transitivity seems to be limited. Lyons 1977, for example,notes that handle is a meronym of door and door is a meronym of house, yet it soundsodd to say The house has a handle or The handle is a part of the house. Winston,Chaffin, and Hermann 1987 take such failures of transitivity to indicate that differentpartwhole relations are involved in the two cases. For example, The branch is a part ofthe tree and The tree is a part of a forest do not imply that The branch is a part ofthe forest because the branchtree relation is not the same as the treeforest relation.For Lyons example, they suggest, following Cruse 1986, that part of is sometimesused where attached to would be more appropriate part of should be transitive,whereas attached to is clearly not. The house has a door handle is acceptablebecause it negates the implicit inference in The house has a handle that the handle isattached to the house.Such observations raise questions about how many different part of relationsthere are. Winston et al. 1987 differentiate six types of meronyms componentobjectbranchtree, membercollection treeforest, portionmass slicecake, stuffobjectaluminumairplane, featureactivity payingshopping, and placearea PrincetonNewJersey. Chaffin, Hermann, and Winston 1988 add a seventh phaseprocessadolescencegrowing up. Meronymy is obviously a complex semantic relationor setof relations. Only three of these types of meronymy are coded in WordNetWm p Wh indicates that Wm is a component part of WhWm m Wh indicates that Wm is a member of Wh andWm s Wh indicates that Wm is the stuff that Wh is made from.Of these three, the is a component of relation p is by far the most frequent.The stuffobject relation demonstrates the limits of folk theories of objectcomposition. With the help of modern science it is now possible to analyze stuff intosmaller and smaller components. At some point, this analysis loses all connection withthe object being analyzed. For example, since all concrete objects are composed ofatoms, having atoms as a part will not distinguish one category of concrete objects fromany other. Atom would be a meronym of every term denoting a concrete object.Something has gone wrong here. For commonsense purposes, the dissection of an objectterminates at the point where the parts no longer serve to distinguish this object fromothers with which it might be confused. Knowing where to stop requires commonsenseknowledge of the contrasts that need to be drawn. 22 This problem arises for many parts other than atoms, of course. Some componentscan serve as parts of many different things think of all the different objects that havegears. It is sometimes the case that an object can be two kinds of thing at the sametimea piano is both a kind of musical instrument and a kind of furniture, forexamplewhich results in what is sometimes called a tangled hierarchy Fahlman,1979. Tangled hierarchies are rare when hyponymy is the semantic relation. Inmeronymic hierarchies, on the other hand, it is common point, for example, is ameronym of arrow, awl, dagger, fishhook, harpoon, icepick, knife, needle, pencil, pin,sword, tine handle has an even greater variety of holonyms. Since the points andhandles involved are so different from one holonym to the next, it is remarkable that thissituation causes as little confusion as it does.Functions and PredicationThe term function has served many purposes, both in psychology and linguistics,so anyone who uses it is obligated to explain what sense they attach to it in this context.A functional feature of a nominal concept is intended to be a description of somethingthat instances of the concept normally do, or that is normally done with or to them. Thisusage feels more natural in some cases than in others. For example, it seems natural tosay that the function of a pencil is to write or the function of a knife is to cut, but to saythat the function of a canary is to fly or to sing seems a bit forced. What is reallyintended here are all the features of nominal concepts that are described by verbs or verbphrases. Nominal concepts can play various semantic roles as arguments of the verbsthat they cooccur with in a sentence instruments knifecut, materials woolknit,products holedig picturepaint, containers boxhold, etc.There does not seem to be an obvious term for this type of distinguishing feature.They resemble the functional utilities or action possibilities that Gibson 1979 calledaffordances. Gardner 1973, borrowing a term from Jean Piaget, spoke ofoperativity operative concepts are acquired by interaction and manipulation, whereasfigurative concepts are acquired visually, without interaction. Lacking a better term,function will serve, although the possibility should not be overlooked that a more preciseanalysis might distinguish several different kinds of functional features.The need for functional features is most apparent when attempting to characterize aconcept like ornament, decoration. An ornament can be any size or shape orcomposition parts and attributes fail to capture the meaning. But the function of anornament is clear it is to make something else appear more attractive. At least sinceDunker 1945 described functional fixedness, psychologists have been aware that theuses to which a thing is normally put are a central part of a persons conception of thatthing. To call something a box, for example, suggests that it should function as acontainer, which blocks the thought of using it for anything else.There are also linguistic reasons to assume that a things function is a feature of itsmeaning. Consider the problem of defining the adjective good. A good pencil is one thatwrites easily, a good knife is one that cuts well, a good paint job is one that coverscompletely, a good light is one that illuminates brightly, and so on. As the head noun 23 changes, good takes on a sequence of meanings writes easily, cuts well, coverscompletely, illuminates brightly, etc. It is unthinkable that all of these differentmeanings should be listed in a dictionary entry for good. How should this problem behandledOne solution is to define one sense of good as performs well the function that itshead noun is intended to perform Katz, 1964. A good pencil is one that performs wellthe function that pencils are intended to perform a good knife is one that performs wellthe function that knives are supposed to perform and so on. This solution puts theburden on the head noun. If an object has a normal function, the noun denoting it mustcontain information about what that function is. Then when the noun is modified bygood, the functional feature of the nouns meaning is marked  when it is modified bybad, the functional feature is marked . If an object has no normal function, then it isinappropriate to say it is good or bad a good electron is semantically anomalous. Ifsomething serves several functions, a speaker who says it is good or bad can bemisunderstood.A surprising consequence of this formulation is that an object that is not an X can besaid to be a good X if it performs well the function that Xs normally perform. Forexample, calling a box a chair does not make it one, yet a person who sits on a box cansay This box is a good chair and so indicate that the box is performing well thefunction that chairs are expected to perform. Such a sentence would be unintelligible ifthe function that a chair normally serves were not included as part of the meaning ofchair.In terms of the present approach to lexical semantics, functional information shouldbe included by pointers to verb concepts, just as attributes are included by pointers toadjective concepts. In many cases, however, there is no single verb that expresses thefunction. And in cases where there is a single verb, it can be circular. For example, ifthe noun hammer is defined by a pointer to the verb hammer, both concepts are left inneed of definition. More appropriately, the noun hammer should point to the verb pound,because it usually plays the semantic role of instrument and is used for pounding theverb hammer is a conflation of its superordinate hit and the instrument used to do it. Thesemantic role of nouns like hammer, wallpaper, or box tend to be the same wherever theyoccur in sentences, independent of their grammatical role. That is to say, in both John hitthe mugger with a hammer and The hammer hit him on the head, the semantic role ofhammer is that of an instrument. Similarly, wool is a semantic material in each of thefollowing sentences She knitted the wool into a scarf, She knitted a scarf out of the wool,and This wool knits well. This consistency in mapping onto the same semantic roleindependently of syntax is not a feature of all nominal concepts, however what is thefunction of apple or catAlthough functional pointers from nouns to verbs have not yet been implemented inWordNet, the hyponymic hierarchy itself reflects function strongly. For example, a termlike weapon demands a functional definition, yet hyponyms of weapongun, sword,club, etc.are specific kinds of things with familiar structures Wierzbicka, 1984.Indeed, many tangles in the noun hierarchy result from the competing demands of 24 structure and function. Particularly among the human artifacts there are things that havebeen created for a purpose they are defined both by structure and use, and consequentlyearn double superordinates. For example, ribbon, band is a strip of cloth on structuralgrounds, but an adornment on functional grounds balance wheel is structurally awheel, but functionally a regulator cairn is a pile of stones that functions as a markeretc. Functional pointers from these nominal concepts to the verbal concepts adorn,regulate, mark, etc. could eliminate many of these tangles. At this time it is notobvious which representation if not both has the greater psycholinguistic validity.The details are obviously complicated and it is hard to feel that a satisfactoryunderstanding of these functional attributes of nominal concepts has yet been achieved.If support for the continued development of WordNet is forthcoming, the exercise ofadding pointers from nouns to the verbs that express their functions should lead to deeperinsight into the problem.AntonymyThe strongest psycholinguistic indication that two words are antonyms is that eachis given on a word association test as the most common response to the other. Forexample, if people are asked for the first word they think of other than the probe worditself when they hear victory, most will respond defeat when they hear defeat,most will respond victory. Such oppositions are most common for deadjectivalnouns happiness and unhappiness are noun antonyms because they derive from theantonymous adjectives happy and unhappy.Semantic opposition is not a fundamental organizing relation between nouns, but itdoes exist and so merits its own representation in WordNet. For example, the synsets forman and woman would contain man, woman,, person, . . . a male person  woman, man,, person, . . . a female person where the symmetric relation of antonymy is represented by the  pointer, and squarebrackets indicate that antonymy is a lexical relation between words, rather than asemantic relation between concepts. This particular opposition echoes through the kinterms, being inherited by husbandwife, fathermother, sondaughter, uncleaunt,brothersister, nephewniece, and even beyond kingqueen, dukeduchess, actoractress,etc.When all three kinds of semantic relationshyponymy, meronymy, andantonymyare included, the result is a highly interconnected network of nouns. Agraphical representation of a fragment of the noun network is shown in Figure 2. Thereis enough structure to hold each lexical concept in its appropriate place relative to theothers, yet there is enough flexibility for the network to grow and change with learning. 25 Figure 2. Network representation of three semantic relationsamong an illustrative variety of lexical conceptsgroupfamilypersonrelativebrother sisternaturalobjectbodyarm legsubstanceorganicsubstanceflesh bonehyponymy antonymy meronymy 26 Adjectives in WordNetChristiane Fellbaum, Derek Gross, and Katherine MillerRevised August 1993WordNet divides adjectives into two major classes descriptive and relational. Decriptiveadjectives ascribe to their head nouns values of typically bipolar attributes and consequentlyare organized in terms of binary oppositions antonymy and similarity of meaningsynonymy. Descriptive adjectives that do not have direct antonyms are said to have indirectantonyms by virtue of their semantic similarity to adjectives that do have direct antonyms.WordNet contains pointers between descriptive adjectives expressing a value of an attributeand the noun by which that attribute is lexicalized. Referencemodifying adjectives havespecial syntactic properties that distinguish them from other descriptive adjectives. Relationaladjectives are assumed to be stylistic variants of modifying nouns and so are crossreferencedto the noun files. Chromatic color adjectives are regarded as a special case.All languages provide some means of modifying or elaborating the meanings ofnouns, although they differ in the syntactic form that such modification can assume.English syntax allows for a variety of ways to express the qualification of a noun.For example, if chair alone is not adequate to select the particular chair a speaker has inmind, a more specific designation can be produced with adjectives like large andcomfortable. Words belonging to other syntactic categories can function as adjectives,such as present and past participles of verbs the creaking chair the overstuffed chairand nouns armchair, barber chair. Phrasal modifiers are prepositional phrases chair bythe window, chair with green upholstery and noun phrases my grandfathers chair.Entire clauses can modify nouns, as in The chair that you bought at the auction.Prepositional phrases and clausal noun modifiers follow the noun genitive noun phrasesand single word modifiers precede it.Noun modification is primarily associated with the syntactic category adjective.Adjectives have as their sole function the modification of nouns, whereas modification isnot the primary function of noun, verb, and prepositional phrases. Adjectives haveparticular semantic properties that are not shared by other modifiers some of these arediscussed. The lexical organization of adjectives is unique to them, and differs from thatof the other major syntactic categories, noun and verb.The adjective synsets in WordNet contain mostly adjectives, although some nounsand prepositional phrases that function frequently as modifiers have been entered as well.The present discussion will be limited to adjectives.WordNet presently contains approximately 19,500 adjective word forms, organizedinto approximately 10,000 word meanings synsets.WordNet contains descriptive adjectives such as big, interesting, possible andrelational adjectives such as presidential and nuclear. A relatively small number ofadjectives including former and alleged constitute the closed class of referencemodifying adjectives. Each of these classes is distinguished by the particular semantic 27 and syntactic properties of its adjectives.Descriptive AdjectivesDescriptive adjectives are what one usually thinks of when adjectives arementioned. A descriptive adjective is one that ascribes a value of an attribute to a noun.That is to say, x is Adj presupposes that there is an attribute A such that Ax  Adj. Tosay The package is heavy presupposes that there is an attribute WEIGHT such thatWEIGHTpackage  heavy. Similarly, low and high are values for the attribute HEIGHT.WordNet contains pointers between descriptive adjectives and the noun synsets that referto the appropriate attributes.The semantic organization of descriptive adjectives is entirely different from that ofnouns. Nothing like the hyponymic relation that generates nominal hierarchies isavailable for adjectives it is not clear what it would mean to say that one adjective is akind of some other adjective. The semantic organization of adjectives is more naturallythought of as an abstract hyperspace of N dimensions rather than as a hierarchical tree.Antonymy The basic semantic relation among descriptive adjectives is antonymy.The importance of antonymy first became obvious from results obtained with wordassociation tests When the probe is a familiar adjective, the response commonly givenby adult speakers is its antonym. For example, to the probe good, the common responseis bad to bad, the response is good. This mutuality of association is a salient feature ofthe data for adjectives Deese, 1964, 1965. It seems to be acquired as a consequence ofthese pairs of words being used together in the same phrases and sentences Charles andMiller, 1989 Justeson and Katz, 1991a, 1991b.The importance of antonymy in the organization of descriptive adjectives isunderstandable when it is recognized that the function of these adjectives is to expressvalues of attributes, and that nearly all attributes are bipolar. Antonymous adjectivesexpress opposing values of an attribute. For example, the antonym of heavy is light,which expresses a value at the opposite pole of the WEIGHT attribute. In WordNet, thisbinary opposition is represented by reciprocal labeled pointers heavy  light and light heavy.This account suggests two closely related questions, which can serve to organize thefollowing discussion.1 When two adjectives have closely similar meanings, why do they not have the sameantonym For example, why do heavy and weighty, which are closely similar inmeaning, have different antonyms, light and weightless, respectively2 If antonymy is so important, why do many descriptive adjectives seem to have noantonym For example, continuing with WEIGHT, what is the antonym of ponderousTo the suggestion that light is the antonym of ponderous, the reply must be that theantonym of light in the appropriate sense is heavy. Is some different semanticrelation other than antonymy involved in the subjective organization of the rest ofthe adjectives 28 The first question caused serious problems for WordNet, which was initiallyconceived as using labeled pointers between synsets in order to represent semanticrelations between lexical concepts. But it is not appropriate to introduce antonymy bylabeled pointers between the synsets heavy, weighty, ponderous and light, weightless,airy. People who know English judge heavylight to be antonyms, and perhapsweightyweightless, but they pause and are puzzled when asked whether heavyweightlessor ponderousairy are antonyms. The concepts are opposed, but the word forms are notfamiliar antonym pairs.The problem here is that the antonymy relation between word forms is not the sameas the conceptual opposition between word meanings. Except for a handful of frequentlyused adjectives most of which are AngloSaxon, most antonyms of descriptiveadjectives are formed by a morphological rule that changes the polarity of the meaningby adding a negative prefix usually the AngloSaxon un or the Latinate in and itsallomorphs il, im, ir. Morphological rules apply to word forms, not to wordmeanings they generally have a semantic reflex, of course, and in the case of antonymythe semantic reflex is so striking that it deflects attention away from the underlyingmorphological process. But the important consequence of the morphological origin ofantonyms is that wordform antonymy is not a relation between meaningswhichprecludes the simple representation of antonymy by pointers between synsets.If the familiar semantic relation of antonymy holds only between selected pairs ofwords like heavylight and weightyweightless, then the second question arises what is tobe done with ponderous, massive, and airy, which seem to have no appropriateantonyms The simple answer seems to be to introduce a similarity pointer and use it toindicate that the adjectives lacking antonyms are similar in meaning to adjectives that dohave antonyms.Gross, Fischer, and Miller 1989 proposed that adjective synsets be regarded asclusters of adjectives associated by semantic similarity to a focal adjective that relates thecluster to a contrasting cluster at the opposite pole of the attribute. Thus, ponderous issimilar to heavy and heavy is the antonym of light, so a conceptual opposition ofponderouslight is mediated by heavy. Gross, Fischer, and Miller distinguish directantonyms like heavylight, which are conceptual opposites that are also lexical pairs,from indirect antonyms, like heavyweightless, which are conceptual opposites that arenot lexically paired. Under this formulation, all descriptive adjectives have antonymsthose lacking direct antonyms have indirect antonyms, i.e., are synonyms of adjectivesthat have direct antonyms.In WordNet, direct antonyms are represented by an antonymy pointer, indirect antonyms are inherited through similarity, which is indicated by the similaritypointer, . The configuration that results is illustrated in Figure 1 for the cluster ofadjectives around the direct antonyms, wetdry. For example, moist does not have a directantonym, but its indirect antonym can be found via the path, moist  wet  dry.This strategy has been successful with the great bulk of English adjectives, butparticular adjectives have posed some interesting problems. Among the few adjectivesthat have no satisfactory antonym, even in an un form, are some of the strongest and 29 wet drywaterydampsoggyhumidmoistparchedaridanhydrousseredriedupsimilarityantonymyFigure 1. Bipolar Adjective Structuremost colorful. Angry is an example. The attribute ANGER is gradable from no anger toextreme fury, but unlike most attributes it does not seem to be bipolar. Many terms aresimilar in meaning to angry enraged, irate, wrathful, incensed, furious. But none ofthem has a direct antonym, either. When adjectives are encountered that do not havedirect antonyms, the usual strategy is to search for a related antonym pair and to code theunopposed adjective as similar in meaning to one or the other member of that pair. In thecase of angry, the best related pair seems to be pleaseddispleased, but coding angry displeased seems to miss the essential meaning of angry. And amicablehostile is evenworse. In order to deal with this situation, a special cluster headed angrynot angry wascreated, with calm and placid which indicate absence of emotional disturbance codedas similar in meaning to the synthetic adjective not angry. The significance of suchexceptions is not obvious, but the recognition that there are exceptions is unavoidable.The construction of the antonym clusters is discussed in more detail later. Webelieve that the model presented heredividing adjectives into two major types,descriptive which enter into clusters based on antonymy and relational which aresimilar to nouns used as modifiersaccounts for the majority of English adjectives. Wedo not claim complete coverage.Gradation Most discussions of antonymy distinguish between contradictory andcontrary terms. This terminology originated in logic, where two propositions are said tobe contradictory if the truth of one implies the falsity of the other and are said to becontrary if only one proposition can be true but both can be false. Thus, alive and deadare said to be contradictory terms because the truth of Kennedy is dead implies the falsityof Kennedy is alive, and vice versa. And fat and thin are said to be contrary terms 30 because Kennedy is fat and Kennedy is thin cannot both be true, although both can befalse if Kennedy is of average weight. However, Lyons 1977, vol. 1 has pointed outthat this definition of contrary terms is not limited to opposites, but can be applied sobroadly as to be almost meaningless for example, Kennedy is a tree and Kennedy is adog cannot both be true, but both can be false, so dog and tree must be contraries. Lyonsargues that gradability, not truth functions, provides the better explanation of thesedifferences. Contraries are gradable adjectives, contradictories are not.Gradation, therefore, must also be considered as a semantic relation organizinglexical memory for adjectives Bierwisch, 1989. For some attributes gradation can beexpressed by ordered strings of adjectives, all of which point to the same attribute nounin WordNet. Table 1 illustrates lexicalized gradations for SIZE, WHITENESS, AGE, VIRTUE,VALUE, and WARMTH. The most difficult grade to find terms for is the neutral middle ofeach attributeextremes are extensively lexicalized.Table 1Examples of Some Graded AdjectivesSIZE WHITENESS AGE VIRTUE VALUE WARMTHastronomical snowy ancient saintly superb torridhuge white old good great hotlarge ashgray middleaged worthy good warmstandard gray mature ordinary mediocre tepidsmall charcoal adolescent unworthy bad cooltiny black young evil awful coldinfinitesimal pitchblack infantile fiendish atrocious frigidBut the grading in Table 1 is the exception, not the rule surprisingly little gradationis lexicalized in English. Most gradation is accomplished in other ways. A gradableadjective can be defined as one whose value can be multiplied by such adverbs of degreeas very, decidedly, intensely, rather, quite, somewhat, pretty, extremely Cliff, 1959.And most grading is done by morphological rules for the comparative and superlativedegrees, which can be extended if less and least are used to complement more and most.It would not be difficult to represent ordered relations by labeled pointers betweensynsets, but it was estimated that not more than 2 of the more than 2,500 adjectiveclusters could be organized in that way. Since the conceptually important relation ofgradation does not play a central role in the organization of adjectives, it has not beencoded in WordNet.Markedness Most attributes have an orientation. It is natural to think of them asdimensions in a hyperspace, where one end of each dimension is anchored at the point oforigin of the space. The point of origin is the expected or default value deviation from itmerits comment, and is called the marked value of the attribute.The antonyms longshort illustrate this general linguistic phenomenon known asmarkedness. In an important paper on German adjectives, Bierwisch 1967 noted that 31 only unmarked spatial adjectives can take measure phrases. For example, The road is tenmiles long is acceptable the measure phrase, ten miles, describes the LENGTH of the road.But when the antonym is used, as in The road is ten miles short, the result is notacceptable unless the road is short of some goal. Thus, the primary member, long, is theunmarked term the secondary member, short, is marked and does not take measurephrases except in special circumstances. Note that the unmarked member, long, lends itsname to the attribute, LENGTH.Measure phrases are inappropriate with many attributes, yet markedness is a generalphenomenon that characterizes nearly all direct antonyms. In nearly every case, onemember of a pair of antonyms is primary more customary, more frequently used, lessremarkable, or morphologically related to the name of the attribute. The primary term isthe default value of the attribute, the value that would be assumed in the absence ofinformation to the contrary. Markedness has not been coded in WordNet it has beenassumed that the marked member of the pair is obvious and so needs no explicitindicator. However, the noun that names the attributee.g., LENGTHand all theadjectives expressing values of that attribute in this case, long, short, lengthy, etc. arelinked in WordNet by a pointer. In a few cases e.g., wetdry, easydifficult it is arguablewhich term should be regarded as primary, but for the vast majority of pairs the marker ismorphologically explicit in the form of a negative prefix unpleasant, indecent,impatient, illegal, irresolute, for example.Polysemy and Selectional Preferences Justeson and Katz 1993 find that thedifferent senses of polysemous adjectives like old, right, and short occur with specificnouns or specific senses of polysemous nouns. For example, the sense of old meaningnot young frequently modifies nouns like man, whereas old meaning not new wasfound to frequently modify nouns like house. Justeson and Katz note that the nouncontext therefore often serves to disambiguate polysemous adjectives.An alternative view, put forth by Murphy and Andrew 1993, holds that adjectivesare monosemous but that they have different extensions Murphy and Andrew assert thatspeakers compute the appropriate meanings in combination with the meanings of thenouns that the adjectives modify. Murphy and Andrew further argue against the claimthat antonymy is a relation between two word forms on the basis of the fact that speakersgenerate different antonyms for an adjective like fresh depending on whether it modifiesshirt or bread. WordNet takes the position that these facts point to the polysemy ofadjectives like fresh this view is also adopted by Justeson and Katz 1993, who pointout that the different antonyms can serve to disambiguate polysemous adjectives.Adjectives are selective about the nouns they modify. The general rule is that if thereferent denoted by a noun does not have the attribute whose value is expressed by theadjective, then that adjectivenoun combination requires a figurative or idiomaticinterpretation. For example, a building or a person can be tall because buildings andpersons have HEIGHT as an attribute, but streets and stories do not have HEIGHT, so tallstreet or tall story do not admit literal readings. Nor do antonymy relations hold whennouns lack the pertinent attribute. Compare short story with tall story, or short orderwith tall order. It is really a comment on the semantics of nouns, therefore, when it is 32 said that adjectives vary widely in their breadth of application. Adjectives expressingevaluations goodbad, desirableundesirable can modify almost any noun thoseexpressing activity activepassive, fastslow or potency strongweak, bravecowardlyalso have wide ranges of applicability cf. Osgood, Suci, and Tannenbaum, 1957. Otheradjectives are strictly limited with respect to the range of their head nounsmownunmown dehiscentindehiscent.The semantic contribution of adjectives is secondary to, and dependent on, the headnouns that they modify. Edward Sapir 1944 seems to have been the first linguist topoint out explicitly that many adjectives take on different meanings when they modifydifferent nouns. Thus, tall denotes one range of heights for a building, another for a tree,and still another for a person. It appears that part of the meaning of each of the nounsbuilding, tree, and person is a range of expected values for the attribute HEIGHT. Tall isinterpreted relative to the expected height of objects of the kind denoted by the headnoun a tall person is someone who is tall for a person.Therefore, in addition to containing a mere list of its attributes, a nominal concept isusually assumed to contain information about the expected values of those attributes forexample, although both buildings and persons have the attribute of HEIGHT, the expectedheight of a building is much greater than the expected height of a person. The adjectivesimply modifies those values above or below their default values. The denotation of anadjectivenoun combination such as tall building cannot be the intersection of twoindependent sets, the set of tall things and the set of buildings, for then all buildingswould be included.How adjectival information modulates nominal information is not a question to besettled in terms of lexical representations. We assume that the interactions betweenadjectives and nouns are not prestored but are computed as needed by some onlineinterpretative process. As suggested by Miller and JohnsonLaird, The nominalinformation must be given priority the adjectival information is then evaluated withinthe range allowed by the nominal information Miller and JohnsonLaird, 1976, p. 358.The noun classes of WordNet have been organized in such a way as to make thestatement of an adjectives selectional preferences as simple as possible Miller, thisvolume, but as this account is being written those relations have not yet been coded inWordNet.Syntax Descriptive adjectives such as big and heavy are syntactically the freestthey can be used attributively in prenominal position or predicatively after be, become,remain, stay, and a few other linking verbs. Some identifying adjectives, such as bestand left, occur mostly attributively The best essay vs. The essay is best but in context,a sentence like The essay by Mary was best is acceptable. Referencemodifying andrelational adjectives, to be discussed below, are also restricted to attributive use.ReferenceModifying AdjectivesBolinger 1967 was the first to note the distinction between referencemodifyingand referentmodifying adjectives. He pointed out that in a phrase like the formerpresident, what is former is the presidenthood of the referent, not the referent himself 33 the person is former qua president. Only the reference to the person as president is beingqualified by former. The nouns modified by adjectives like former, present, alleged, andlikely generally denote a function or social relation. In the phrase my old friend, theadjective can be interpreted as referencemodifying, qualifying the friendship betweenthe speaker and the possibly young referent of the noun. Under the referentmodifyinginterpretation of that same adjective, the friend is old aged, but the friendship need notbe. Note that the two senses of this adjective have different antonyms the referencemodifying sense is opposed to the referencemodifying adjectives recent or new,whereas the referentmodifying adjective has young as its antonym. Referencemodifyingadjectives are a closed class comprising a few dozen adjectives. Many refer to thetemporal status of the noun former, present, last, past, late, recent, occasional othershave an epistemological flavor potential, reputed, alleged still others are intensifyingmere, sheer, virtual, actual. The adjectives express different values of attributes thatseem not to be lexicalized, such as degree of certainty. Only some of the adjectiveshave nominalizations likelihood, possibility, and a few others.The referencemodifying adjectives often function like adverbs My former teachermeans he was formerly my teacher the alleged killer states that she is allegedly a killeror she allegedly killed and a light eater is someone that eats lightly.Referencemodifying adjectives can occur only attributively, but not predicativelycompare The alleged burglar with The burglar is alleged. And the predicative use ofold as in My friend is old disambiguates that adjective, ruling out the longstandingreading in favor of the aged interpretation. In the current version of WordNet, mostreferencemodifying adjectives are marked as occurring prenominally only.Some referencemodifying adjectives resemble descriptive adjectives in that theyhave direct antonyms the possibleimpossible task the pastpresent director. Those thatdo not have direct antonyms usually have indirect antonyms.Color AdjectivesOne large and intensively studied class of adjectives is organized differently, anddeserves special comment.English color terms are exceptional in several ways. They can serve as either nounsor adjectives, yet they are not nominal adjectives they can be graded, nominalized, andconjoined with other descriptive adjectives. But the pattern of direct and indirectantonymy that is observed for other descriptive adjectives does not hold for coloradjectives.Only one color attribute is clearly described by direct antonyms LIGHTNESS, whosepolar values are expressed by lightdark. Students of color vision can produce evidenceof oppositions between red and green, and between yellow and blue, but those are nottreated as direct antonyms in lay speech. The organization of color terms is given by thedimensions of color perception lightness, hue, and saturation, which define the wellknown color solid. In WordNet, however, the opposition coloredcolorless crossreferenced to chromaticachromatic is used to introduce the names of colors. Hues arecoded as similar to colored, and the shades of gray from white to black are coded as 34 similar to grey, which is in a tripartite cluster with white and black, providing for agraded continuum.There is some reason to suspect that the elaborate color terminology available in thelanguages of industrialized countries is a consequence of technological progress and nota natural linguistic development. Speculation about the evolution of color terminologyBerlin and Kay, 1969 suggests that it begins with a single, conventional attribute,LIGHTNESS. Exotic languages are still spoken that have only two color terms to expressvalues of that attribute, and it has been shown that this lexical limitation is not aconsequence of perceptual deficits Heider, 1972 Heider and Olivier, 1972. Astechnology develops and makes possible the manipulation and control of color, the needfor greater terminological precision grows and more color terms appear in the language.They are always added along lines determined by innate mechanisms of color perceptionrather than by established patterns of linguistic modification.Relational AdjectivesAnother kind of adjective comprises the large and open class of relationaladjectives. These, too, can occur only in attributive position, although for someadjectives, this constraint is somewhat relaxed. Relational adjectives, which were firstdiscussed at length by by Levi 1978, mean something like of, relatingpertaining to, orassociated with some noun, and they play a role similar to that of a modifying noun.For example, fraternal, as in fraternal twins relates to brother, and dental, as indental hygiene, is related to tooth. Some head nouns can be modified by both therelational adjective and the noun from which it is derived both atomic bomb and atombomb are admissible.Some nouns give rise to two homonymous adjectives one relational adjectiverestricted to predicative use, the other descriptive. For example, musical has a differentmeaning in musical instrument and musical child the first noun phrase does not refer toan instrument that is musical but an instrument used in music. Similarly, the adjective incriminal law is not the same as in criminal behavior this is reflected in the fact that thesecond adjective, but not the first, is referentmodifying and can be used predicatively.Relational adjectives do not combine well with descriptive adjectives in modifying thesame head noun when the two adjectives are linked by a conjunction nervous and lifethreatening disease and musical but not extraordinary talent sound distinctly odd.Concatenations like lifethreatening nervous disease are fine, indicating that therelational adjective acts like a modifying noun. On the other hand, relational adjectivescan easily be conjoined with modifying nouns atom and nuclear bombs, the Korean andVietnam war.Relational adjectives are most often derived from Greek or Latin nouns, and lessoften from the appropriate AngloSaxon noun. The English lexicon frequently hasseveral synonymous adjectives derived from nouns in different languages that expressthe same concept Greekbased rhinal and AngloSaxon nasal both relate to nose therelational adjectives corresponding to word are verbal from Latin and lexical from theGreek. In many cases, these synonyms each pick out their own head nouns and are not 35 substitutable in a given context compare nasalrhinal passage and rhinalnasalsurgery.Conversely, a single relational adjective sometimes points to several nounschemical has senses corresponding to the two nouns chemical as in chemical fertilizerand chemistry as in chemical engineer.Some homonymous relational adjectives have a common origin but their meaningshave drifted apart over time consequently they point to two distinct noun synsets onesense of clerical points to clergy clerical leader another sense is linked to clerkclerical work.Some relational adjectives do not point to morphologically related English nounsthe Latin or Greek nouns that they are derived from have no exact English equivalents.For example, fictile relates to pottery, and comes from the Latin word fictilis, meaningmade or molded of clay there is no corresponding English noun expressing this concept.An adjective like rural connects to several related concepts country, as opposed to city,and farming. In such cases, several senses of the adjective have been entered withpointers to different nouns.WordNet also has a number of adjectives that are derived from other relationaladjectives via some prefix these adjectives, which include interstellar, extramural, andpremedical do not point to any noun but are linked instead to the unprefixed adjectivesstellar, mural, and medical, respectively, from which they are derived.Semantics Relational adjectives differ from descriptive adjectives in that they donot relate to an attribute there is no scale of criminality or musicality on which theadjectives in criminal law and musical training express a value. The adjective and therelated noun refer to the same concept, but they differ formally morphologically.Relational adjectives do not refer to a property of their head nouns. This can beseen from the absence of corresponding nominalizations the descriptive use of nervousin the nervous person admits such constructions as the persons nervousness, but itsrelational use in the nervous disorder does not. Relational adjectives, like nouns andunlike descriptive adjectives, are not gradable the extremely atomic bomb, like theextremely atom bomb or the very baseball game, are not acceptable. Relationaladjectives do not have direct antonyms although they can often be combined with non,such forms do not express the opposite value of an attribute but something likeeverything else these adjectives have a classifying function. In a few cases,relational adjectives enter into an opposition on the basis of their prefixes extracellularvs. intracellular. More frequently, relational adjectives enter into Nway oppositions incombination with a specific head noun e.g., civil opposes criminal in combination withlawyer, and mechanical, electrical, etc., in combination with engineering.Since relational adjectives do not have antonyms, they cannot be incorporated intothe clusters that characterize descriptive adjectives. And because their syntactic andsemantic properties are a mixture of those of adjectives and those of nouns used as nounmodifiers, rather than attempting to integrate them into either structure WordNetmaintains a separate file of relational adjectives with pointers to the corresponding nouns. 36 Some 1,700 relational adjective synsets containing over 3,000 individual lexemesare currently included in WordNet. Each synset consists of one or more relationaladjectives, followed by a pointer to the appropriate noun. For example, the entrystellar, astral, sidereal, noun.objectstar indicates that stellar, astral, sidereal relate tothe noun star.Syntax The semantic relation between a head noun and the noun from which theadjective is derived may differ with different head nouns. For example, musical eveningmeans an evening with music, whereas musical instrument is an instrument forproducing music. Bartning 1980 observes that when the head noun is deverbal,predication is often possible so long as the head noun denotes a state rather than anaction. For example, economic restructuring refers to an action, and predication ispossible The restructuring was economic. By contrast, economic slump is a state, andthe sentence the slump is economic is bad.Bartning 1980 observed further that if there is a tight, obvious grammaticalrelation, the adjective cannot be used predicatively however, when the relation betweenthe adjective and its headnoun is less obvious, predication is possible. Thus, in the nounphrase presidential election, president is the object of elect here, the grammaticalrelation between adjective and head noun is transparent, and predication is not possiblethe election is presidential. Similarly, the Pope is clearly the subject in the phrasepapal visit, and predication is bad The visit was papal. If, however, the relation is onewhere the base noun is an adjunct of the head noun, predication is more likely to beacceptable. Manual labor is labor WITHBY hand, and the phrase This labor ismostly manual is fine. The syntactic behavior of some relational adjectives thatdiffers with the semantic relation to the particular head noun cannot presently beaccounted for in WordNet. The relational adjectives are not provided with syntacticcodes.Predication is also possible when the relation between the noun and the base nounof the adjective is like Nixonian politics are politics reminiscent of those of a formerpresident a presidential speech is a speech that is like that of a president. Both allowpredication These politics are truly Nixonian His speech was rather presidential.Arguably, the meaning of presidential is not the same in presidential speech and inpresidential election where the adjective cannot be used predicatively. In WordNet,such distinctions have generally not been made, because there are too many semanticrelations between a relational adjective and its different head nouns to classify theadjectives into distinct senses.Virtually all relational adjectives can be used predicatively in contrastive contextsThese weapons are not chemical or biological, but nuclear They hired a criminal not acorporate lawyer. However, these cases arguably involve ellipsis of the head noun.CodingThe semantic organization of descriptive adjectives illustrated in Figure is 1 codedby organizing them into bipolar clusters. There are over 2,500 of these clusters, one foreach pair of antonyms they can be likened to the subject files for nouns and verbs. Each 37 bipolar cluster stands alone, and coding is restricted to withincluster relations.The cluster for wetdry, which define the attribute WETNESS or MOISTNESS,illustrates the basic coding devices used, and shows the variety and range of senses thatcan be represented within a cluster. WET1, DRY1, bedewed, boggy, clammy, damp, drenched,drizzling, hydrated, muggy, perspiring, saturated2,showery, tacky, tearful, watery2, WET2,  bedewed, dewy, wet1,  boggy, marshy, miry, mucky, muddy, quaggy, swampy, wet1,  clammy, dank, humid1, wet1,  damp, moist, wet1,  drenched, saturated1, soaked, soaking, soppy, soused, wet1,  drizzling, drizzly, misting, misty, wet1,  hydrated, hydrous, wet1, chem combined with water molecules  muggy, humid2, steamy, sticky1, sultry, wet1,  perspiring, sweaty, wet1,  saturated2, sodden, soggy, waterlogged, wet1,  showery, rainy, wet1,  sticky2, tacky, undried, wet1, wet varnish  tearful, teary, watery1, wet1,  watery2, wet1, filled with water watery soil  DRY1, WET1, anhydrous, arid, dehydrated, dried, driedup1,driedup2, DRY2, rainless, thirsty,  anhydrous, dry1, chem with all water removed  arid, waterless, dry1,  dehydrated, desiccated, parched, dry1,  dried, dry1, the ink is dry  driedup1, dry1, a dry water hole  driedup2, sere, shriveled, withered, wizened, dry1,used of vegetation  rainless, dry1,  thirsty, dry1, Each half of the cluster is headed by what is called a head synset. The first twoitems in each head synset are the antonymous pair that define the attribute representedhead words are coded as such by being capitalized. These head words are followed bypointers, one to each synset in the half cluster, each of which has a reciprocal pointerback to the head word. The numerals following certain items distinguish differentsubsenses or different privileges of occurrencefor example, the driedup1 of a waterhole in one synset and the driedup2 of autumn leaves or fruit in another. Each of thesecases, furthermore, contains parenthetical information designed to help distinguish theseparticular senses or indicate acceptable contexts.As already mentioned, many adjectives are limited as to the syntactic positions theycan occupy, and that limitation is usually coded in WordNet. Because it is a wordformlimitation, it is coded for individual adjectives rather than for synsets. Consider the 38 cluster awakeasleep, both of which are limited to predicate position. Although these arethe head words of the cluster, the limitation does not hold for all of the synonyms in thecluster. Therefore, the individual words so limited are all coded withp. AWAKEp, ASLEEP, ALERT, astirp, AWAREp, CONSCIOUS,insomniac, unsleeping,  astirp, outofbedp, upp, awake,  insomniac, sleepless, wakeful, awake,  unsleeping, wideawake, awake,  ASLEEPp, AWAKE, atrestp, benumbed, DEAD, dormant, drowsing,drowsy, unconscious, UNAWARE, UNCONSCIOUS,  atrestp, resting, asleep,  benumbed, insensible, numb, unfeeling, asleep, my foot is asleep  dormant, inactive, hibernating, torpid, asleep,  drowsing, dozing, napping, asleep,  drowsy, nodding, sleepy, slumberous, slumbrous, somnolent, asleep,  unconscious, asleep, For adjectives limited to prenominal attributive position, the code isa forexample, putativea, reputeda, supposeda, as in the putative father but not thefather is putative, and barea, merea, as in the bare minimum but not the minimum isbare. As already mentioned, former is used only prenominally, and so are several of itssynonyms, precedinga, previousa, priora,. When, however, previous is usedpredicatively the sense becomes premature, too soonp,, as in our condemnation ofhim was a bit previous.And, finally, for those few adjectives that can appear only immediately following anoun, the code isip for immediately postnominal galore as in gore galore, electas in president elect, and aforethought as in malice aforethought. In many cases theadjectives constitute part of what is essentially a frozen construction.In addition to the lowercase withincluster pointers, many head synsets containpointers to other, related clusters. In this AWAKEASLEEP cluster, the capitalized pointerALERT, points to the head word of the ALERTUNALERT cluster. These capitalizedpointers are planned to serve as see also crossreferences to related clusters, eventhough the present system software is not yet able to make use of them, being tightlyrestricted to withincluster coding.The restricted withincluster coding leads to a problem when closely relatedattributes are expressed by more than one pair of antonyms. In such cases, exactly thesame set of synsets can be related to two different antonymous pairs, some of which arepresently in different clusters. Consider largesmall and biglittle. Biglittle andlargesmall are equally salient as antonyms many synsets could just as well be coded assimilar to big as to large. Therefore, a single cluster has been created headed by bothpairs, thus avoiding unnecessary redundancy. In addition, a particular synset can becoded with two pointers, one to its own cluster head, the other to the head of an outsidecluster. 39 A final word about largesmall and biglittle although large is clearly opposed tolittle, the pair large and little are simply not accepted as antonyms. Overwhelmingly,association data and cooccurrence data indicate that big and little are considered a pairand so are large and small. These two pairs constitute a prime demonstration thatantonymy is as a semantic relation between words rather than between lexicalizedconcepts. 40 English Verbs as a Semantic NetChristiane FellbaumThis paper describes the semantic network of English verbs in WordNet. The semanticrelations used to build networks of nouns and adjectives cannot be applied withoutmodification, but have to be adapted to fit the semantics of verbs, which differ substantiallyfrom those of the other lexical categories. The nature of these relations is discussed, as is theirdistribution throughout different semantic groups of verbs, which determines certainidiosyncratic patterns of lexicalization. In addition, four variants of lexical entailment aredistinguished, which interact in systematic ways with the semantic relations. Finally, thelexical properties of the different verb groups are outlined.Verbs are arguably the most important lexical and syntactic category of a language.All English sentences must contain at least one verb, but, as grammatical sentences withdummy subjects like It is snowing show, they need not contain a referential noun.Many linguists have argued for a model of sentence meaning in which verbs occupy thecore position and function as the central organizers of sentences Chafe, 1970 Fillmore,1968 and others. The verb provides the relational and semantic framework for itssentence. Its predicateargument structure or subcategorization frame specifies thepossible syntactic structures of the sentences in which it can occur. The linking of nounarguments with thematic roles or cases, such as INSTRUMENT, determines the differentmeanings of the events or states denoted by the sentence, and the selectional restrictionsspecify the semantic properties of the noun classes that can flesh out the frame. Thissyntactic and semantic information is generally thought to be part of the verbs lexicalentry, that is to say, part of the information about the verb that is stored in a speakersmental lexicon. Because of the complexity of this information, verbs are probably thelexical category that is most difficult to study.PolysemyEven though grammatical English sentences require a verb though not necessarily anoun, the language has far fewer verbs than nouns. For example, the Collins EnglishDictionary lists 43,636 different nouns and 14,190 different verbs. Verbs are morepolysemous than nouns the nouns in Collins have on the average 1.74 senses, whereasverbs average 2.11 senses.2The higher polysemy of verbs suggests that verb meanings are more flexible thannoun meanings. Verbs can change their meanings depending on the kinds of nounarguments with which they cooccur, whereas the meanings of nouns tend to be morestable in the presence of different verbs. Gentner and France 1988 have demonstratedwhat they call the high mutability of verbs. They presented subjects with sentences 2 We are indebted to Richard Beckwith for computing these figures. 41 containing verbs in conjunction with nouns that violated the verbs selectionalrestrictions. When asked to paraphrase the sentences, subjects assigned novelinterpretations to the verbs, but did not modify the literal meanings of the nouns.Gentner and France concluded that verb meanings are more easily altered because theyare less cohesive than those of nounsa flexibility that makes a semantic analyis ofverbs an even more challenging task.The most frequently used verbs have, be, run, make, set, go, take, and others arealso the most polysemous, and their meanings often depend heavily on the nouns withwhich they cooccur. For example, dictionaries differentiate between the senses of havein sentences like I have a Mercedes and I have a headache. The difference is less due tothe polysemy of have, however, than to the concrete or abstract nature of its objects.In the case of such polysemous verbs as beat, meaning differences are determinedless by the semantics of the verbs arguments than by different elaborations of one or twocommon core components shared by most senses of beat. Different senses of beat occurin very different semantic domains beat, strike, hit is a contact verb beat, flatten isa verb of change beat, throb, pulse is a motion verb beat, defeat is a competitionverb beat, flog, punish and beat, circumvent the system are verbs in the domain ofsocial interaction beat, shape, do metalwork is a creation verb beat, baffle is acognition verb beat, stir, whisk belongs to the domain of cooking verbs and beat,mark is a kind of motion performed to indicate the counts in music. Although most ofthese verbs seem to share a semantic component of CONTACT or IMPACT, the differencesillustrate how flexible these core meanings can be.In order to reduce ambiguity in WordNet, verb synsets could contain crossreference pointers to the noun synsets that contain nouns selected for by the verbs. Forexample, one sense of the verb throw throw on a wheel always selects the noun potteryor its hyponyms as its object that selectional restriction could be represented by alabeled pointer. At the present time, however, this possibility has not been implementedin WordNet.The Organization of Verbs in WordNetCurrently, WordNet contains over 21,000 verb word forms of which over 13,000are unique strings and approximately 8,400 word meanings synsets. Included arephrasal verbs like look up and fall back.Verbs are divided into 15 files, largely on the basis of semantic criteria. All but oneof these files correspond to what linguists have called semantic domains verbs of bodilycare and functions, change, cognition, communication, competition, consumption,contact, creation, emotion, motion, perception, possession, social interaction, andweather verbs. Virtually all the verbs in these files denote events or actions. Another filecontains verbs referring to states, such as suffice, belong, and resemble, that could not beintegrated into the other files. The verbs in this latter group do not constitute a semanticdomain, and share no semantic properties other than that they refer to states. This file,whose organization resembles that of the adjectives in WordNet, consists of smallsemantic clusters. The division of verbs into 14 files corresponding to different semantic 42 domains, each containing event and action verbs, and one file containing semanticallydiverse stative verbs reflects the division between the major conceptual categories EVENTand STATE found in Jackendoffs 1983170 and Dowtys 1979 analyses. Theboundaries between the files are not rigid, and the particular classification was chosenlargely because it permits us to get a grasp on the organization of the verbs it has nofurther theoretical or psychological implications.Many of the files derive their names from the topmost verbs, or uniquebeginners, which head these semantically coherent lexical groups. These topmost verbsresemble the core components of Miller and JohnsonLaird 1976. They are theunelaborated concepts from which the verbs constituting the semantic field are derivedvia semantic relations.SynonymyFew truly synonymous verbs, such as shut and close, can be found in the lexiconthe number depends on how loose a definition of synonymy one adopts. The bestexamples are probably verb concepts that are represented by both an AngloSaxon and aGrecoLatinate word begincommence, endterminate, riseascend, blinknictate,beheaddecapitate, spitexpectorate. In general, the GrecoLatinate verbs are used inmore formal or technical speech registers buy vs. purchase, sweat vs. perspire, or shavevs. epilate. Cruse 1986268 points out that frequently only one member of such asynonym pair tends to be felicitous in a given context Where have you hidden Dadsslippers sounds more natural than Where have you concealed Dads slippers Andsubtle meaning differences can show up in different selectional restrictions. Forexample, rise and fall can select as an argument such abstract entities as the temperature,but their close synonyms ascend or descend cannot. Because many apparentlysynonymous verbs exhibit such differences, verb synsets in WordNet often containperiphrastic expressions, rather than lexicalized synonyms.These periphrases break down a synonymous verb into an entire verb phrase andthereby often reflect the way in which the verb has become lexicalized by showingconstituents that have been conflated in the verb. For example, a denominal verb such ashammer is listed with the parenthetical gloss hit with a hammer the conflated verbdenotes the function of the noun. The periphrases indicate the basic action and the roleof the noun material and instrument with which the action is performed. Thesynonymous expressions of deadjectival verbs often have the form make or become some adjective whiten, become white, enrich, make rich, etc. Thus they reflect thefact that these verbs are for the most part verbs of change. The synonymous expressionsof many verbs show that they are manner elaborations of a more basic verb swim,travel through water, mumble, talk indistinctly, saute, fry briefly, etc.Representing the meanings of verbs is difficult for any theory of lexical semantics,but especially so for WordNet, which differs from previous approaches in avoiding asemantic decomposition in favor of a relational analysis. 43 Decompositional vs. Relational Semantic AnalysisMost approaches to verb semantics have been attempts at decomposition in oneform or another. Early proponents of semantic decomposition Katz  Fodor, 1963Katz, 1972 Gruber, 1976 Lakoff, 1970 Jackendoff, 1972 Schank, 1972 Miller andJohnsonLaird, 1976 and others, whether in a generative or an interpretative framework,argued for the existence of a finite set of universal semanticconceptual components orprimes, or primitives, or atomic predicates, or, in the case of nouns, markers into whichall lexical items could be exhaustively decomposed. Among the examples one findsdiscussed in the literature, most have been English verbs. The best known example ofthe decomposition of a verb is probably McCawleys 1968 analysis of kill into CAUSETO BECOME NOT ALIVE, which has been much discussed and criticized Fodor, 1970Shibatani, 1972 and others.Although semantic decomposition has been judged by some to be an inadequatetheory of semantic representation Chomsky, 1972, and others, more recent approacheshave taken a similar path to semantic analysis. Both Jackendoff 1983 and Talmy1985 have proposed an anlysis of verbs in terms of such conceptual categories asEVENT, STATE, ACTION, PATH, MANNER, PLACE, etc. For example, Talmy analyzes theverb roll as being a lexicalized conflation of MOVE and MANNER. Both analyses sharethe assumption of a limited inventory including components or categories that can beexpressed not only by verbs, but also by nouns and by operators like NEG.Relational semantic analysis differs from semantic decomposition primarily intaking lexical items, rather than hypothetically irreducible meaning atoms, as thesmallest unit of analysis. Thus, relational analysis has the advantage that its units can bethought of as entries in speakers mental dictionaries. However, the relational analysisadopted in WordNet shares some aspects of decomposition. Although WordNet does notexplicitly recognize conceptual components, some components are reflected in the natureof the semantic relations linking verbs to each other. For example, one of generativesemantics important subpredicates, CAUSE, has the status of a semantic relation inWordNeta relation that links such verb pairs as teachlearn and showsee. Thisrelation also distinguishes systematically between the causative transitive and theanticausative intransitive senses of certain verb classes, including break, rot and move.Components like NEG and PATH do not play an overt role in WordNet. But NEG isclearly implicit in the opposition relation that holds between contradictory verbs like liveand die, or succeed and fail, and between gradables like like and dislike. And a semanticPATH component is clearly part of the manner relation that links verb concepts likemove, travel and soar. Other features, such as Talmys MANNER, are also part of thesemantics of WordNets manner relation troponymy linking basic verbs like eat andcommunicate to other verbs denoting particular elaborations of the base verb, such asgobble and telex.Proponents of semantic decomposition have also argued for the existence ofsubpredicates, corresponding to abstract verbal concepts, in many lexicalized verbs.Some abstract semantic predicates such as MOVE or GO are argued to be the basiccomponents of most verbs from a wide variety of different semantic fields Gruber, 1976 44 Jackendoff, 1972, 1976. Grubers Location Hypothesis argues that all events and statescan be analyzed as more or less abstract spatial locations and motions. Similarly, Dowty1979 analyzes all English verbs with the exception of statives as verbs of change, andposits as part of their meaning the semantic subpredicate CHANGE. Thus, Gruberanalyzes verbs of giving as an abstract motion undergone by the object that is givenDowty sees giving as a change of possession. Such decompositions of verb semanticsare defensible on an abstract plane, but it is not clear that they reflect the way in whichpeoples memory of verbs is structured there is no evidence that speakers store verbs ofgiving together with the concept of abstract motion or change of location. Pinker1989101 claims that speakers of English decompose verbs into such semanticsubpredicates as CAUSE, GO, BE, and PATH, which enables them to predict the verbsidiosyncratic syntactic behavior. Such an analysis may well be part of speakerslinguistic competence, but there is no indication that it serves to organize the mentallexicon. And there is no evidence that verbs with a complex composition take longer touse or understand.The subpredicates of lexical decomposition are accorded the same status as otherverbs in WordNet. Because verbs like move, go and change refer to very basicconcepts, they constitute the root verbs, or topmost unique beginners, heading twosemantic field. The verbs making up these fields are linked to the root verbs via semanticrelations. In other words, WordNet characterizes the verbs of change not by the presenceof a semantic component CHANGE, but rather by a semantic relation to the verb change.This distinction may appear subtle it hinges on the formulation of the semantic relationsthat are coded in WordNet.Componential analysis could be viewed in terms of entailment, in that a verb V1 thatis a component of another verb V2 must be entailed by V1. This idea forms the basis ofCarnaps 1947 theory of meaning postulates. Rather than attempting to provide anexhaustive breakdown of words into components, meaning postulates state inferentialrules between sentences based on the semantic composition of the words in thesesentences. A wellknown example is the relation between the sentence John is abachelor and the sentences John is a male  John is an adult  John is unmarried. Theseentailment relations reflect the fact that the lexical composition of bachelor includes thecomponents MALE, ADULT, and UNMARRIED. The meaning of bachelor can be expressedin terms of its position in a taxonomic hierarchy, that is, a bachelor is a kind of a man,which is a kind of a person. Bachelor, therefore, could be said to inherit all the semanticcomponents of its superordinates, such as HUMAN. Consequently, the sentence John is abachelor also entails the sentence John is human. Katz, 1972, expresses a similar ideaby postulating lexical redundancy rules concerning the cooccurrence of semanticcomponents. Carnaps meaning postulates also predict an entailment relation betweensuch verbs as kill and die. The entailment here reflects the fact that die and kill, which isdecomposed into CAUSE TO DIE, share the semantic component DIE.Although WordNet avoids semantic decomposition in favor of a relational analysis,the semantic relations among verbs in WordNet all interact with entailment. 45 Lexical EntailmentThe principle of lexical inheritance can be said to underlie the semantic relationsbetween nouns, and bipolar oppositions serve to organize the adjectives. Similarly, thedifferent relations that organize the verbs can be cast in terms of one overarchingprinciple, lexical entailment.In logic, entailment, or strict implication, is properly defined for propositions aproposition P entails a proposition Q if and only if there is no conceivable state of affairsthat could make P true and Q false. Entailment is a semantic relation because it involvesreference to the states of affairs that P and Q represent. The term will be generalizedhere to refer to the relation between two verbs V1 and V2 that holds when the sentenceSomeone V1 logically entails the sentence Someone V2 this use of entailment can becalled lexical entailment. Thus, for example, snore lexically entails sleep because thesentence He is snoring entails He is sleeping the second sentence necessarily holds if thethe first one does.Lexical entailment is a unilateral relation if a verb V1 entails another verb V2, thenit cannot be that case that V2 entails V1. The exception is that where two verbs can besaid to be mutually entailing, they must also be synonyms, that is, they must have thesame sense. For example, one might say both that The Germans beat the Argentiniansentails The Germans defeated the Argentinians, and that The Germans defeated theArgentinians entails The Germans beat the Argentinians. However, we find suchstatements rather unnatural. Negation reverses the direction of entailment not sleepingentails not snoring, but not snoring does not entail not sleeping. The converse ofentailment is contradiction If the sentence He is snoring entails He is sleeping, then Heis snoring also contradicts the sentence He is not sleeping Kempson, 1977.The entailment relation between verbs resembles meronymy between nouns, butmeronymy is better suited to nouns than to verbs. To begin with, in order for sentencesbased on the formula An x is a part of a y to be acceptable, both x and y must be nouns.It might seem that using the nominalizing gerundive form of the verbs would convertthem into nouns, and as nouns the HASA relation should apply. For example, Rips andConrad 1989 obtained consistent results when they asked subjects to judge questionslike Is thinking a part of planning vs. Is planning a part of thinking But this change insyntactic category does not overcome fundamental meaning differences between nounsand verbs. Fellbaum and Miller 1990 argue that, first, verbs cannot be taken apart inthe same way as nouns, because the parts of verbs are not analogous to the parts ofnouns. Most nouns and noun parts have distinct, delimited referents. The referents ofverbs, on the other hand, do not have the kind of distinct parts that characterize objects,groups, or substances. Componential analyses have shown that verbs cannot be brokenup into referents denoted solely by verbs. And, second, the relations among parts ofverbs differ from those found among noun parts. Any acceptable statement about partrelations among verbs always involves the temporal relation between the activities thatthe two verbs denote. One activity or event is part of another activity or event only whenit is part of, or a stage in, its temporal realization. 46 It is true that some activities can be broken down into sequentially orderedsubactivities. For the most part, these are complex activities that are said to be mentallyrepresented as scripts Schank and Abelson, 1977. They tend not to be lexicalized inEnglish eat at a restaurant, clean an engine, get a medical checkup, etc. The analysisinto lexicalized subactivities that is possible for these verb phrases is, however, notavailable for the majority of simple verbs in English. Yet people will also accept partwhole statements involving verb pairs like driveride and snoresleep. The reason lies inthe kinds of entailment that hold between the verbs.Consider the relation between the verbs ride and drive. Although neither activity isa discrete part of the other, the two are connected in that when you drive a vehicle, younecessarily also ride in it. The relation between the two activities denoted by these verbsis different from that holding between an activity like get a medical checkup and itstemporally sequential subactivities, like visit the doctor and undress. Riding anddriving are carried on simultaneously. Yet most people accept Riding is a part of drivingand reject Driving is a part of riding, even though neither activity can be considered asubactivity of the other.Consider also the relations among the activities denoted by the verbs snore, dream,and sleep. Snoring or dreaming can be a part of sleeping, in the sense that the twoactivities are, at least partially, temporally coextensive the time that you spend snoringor dreaming is a proper part of the time you spend sleeping. And it is true that when youstop sleeping you also necessarily stop snoring or dreaming.The differences between pairs like drive and ride and snore and sleep are due to thetemporal relations between the members of each pair. The activities can be simultaneousas with drive and ride or one can include the other as with snore and sleep. For bothpairs, engaging in one activity necessitates engaging in the other activity. Therefore, thefirst activity in each pair entails the second.The two semantic relations subsumed under lexical entailment that we haveconsidered so far share the feature of temporal inclusion. That is to say, the sets of verbsrelated by entailment have in common that one member temporally includes the other. Averb V1 will be said to include a verb V2 if there is some stretch of time during which theactivities denoted by the two verbs cooccur, but no time during which V2 occurs and V1does not. If there is a time during which V1 occurs but V2 does not, V1 will be said toproperly include V2.Temporal inclusion may go in either direction. Verb pairs like buy and pay differfrom those like snore and sleep in that whereas snore entails sleep and is properlyincluded by it, buy entails pay but properly includes it. That is to say, either the entailingor the entailed verb may properly include the other. In the case of snoresleep, it is theentailed verb sleep that properly includes the entailing verb snore, whereas in the pairbuypay, the entailing verb buy properly includes the entailed verb pay.Our analysis so far yields a simple generalization if V1 entails V2, and if a temporalinclusion relation holds between them, then people will accept a partwhole statementrelating V2 and V1. 47 Hyponymy Among VerbsThe sentence frame used to test hyponymy between nouns, An x is a y, is notsuitable for verbs, because it requires that x and y be nouns to amble is a kind of to walkis not a felicitous sentence. Even when this formula is used with verbs in the gerundiveform, there is a noticeable difference between nouns and verbs. Although people arequite comfortable with statements like A horse is an animal or A spade is a garden tool,they are likely to reject such statements as Ambling is walking or Mumbling is talking,where the superordinate is not accompanied by some qualification. The semanticdistinction between two verbs is different from the features that distinguish two nouns ina hyponymic relation.An examination of verb hyponyms and their superordinates shows thatlexicalization involves many kinds of semantic elaborations across different semanticfields. For example, Talmys 1985 analysis of motion verbs treats them as conflationsof move and such semantic components as MANNER and CAUSE, exemplified by slide andpull, respectively. To these components could be added SPEED encoded in run, stroll orthe CONVEYANCE of displacement bus, truck, bike. Similarly, English verbs denotingdifferent kinds of hitting express the DEGREE OF FORCE used by the agent chop, slam,whack, swat, rap, tap, peck, etc.. Some verbs refer to different degrees of INTENSITY ofthe action or state drowse, doze, sleep.Since the aim is to study relations between verbs, rather than between the buildingblocks that make them up, the many different kinds of elaborations that distinguish averb hyponym from its superordinate have been merged into a manner relation thatFellbaum and Miller 1990 have dubbed troponymy from the Greek tropos, manner orfashion. The troponymy relation between two verbs can be expressed by the formula ToV1 is to V2 in some particular manner. Manner is interpreted here more loosely than inTalmys work, for example, and troponyms can be related to their superordinates alongmany semantic dimensions. Subsets of particular kinds of manners tend to cluster withina given semantic field. Among competition verbs, for example, many troponyms areconflations of the basic verb fight with nouns denoting the occasion for, or form of, thefight battle, war, tourney, joust, duel, feud, etc. Troponyms of communication verbsoften encode the speakers INTENTION or motivation for communicating, as in examine,confess, or preach, or the MEDIUM of communication fax, email, phone, telex.Troponymy and EntailmentTroponymy is a particular kind of entailment, in that every troponym V1 of a moregeneral verb V2 also entails V2. Consider the pair limpwalk. The verbs in this pair arerelated by troponymy to limp is also to walk in a certain manner limp is a troponym ofwalk. The verbs are also in an entailment relation the statement He is limping entails Heis walking, and walking can be said to be a part of limping. Unlike the activitites denotedby snore and sleep, or buy and pay, the activities referred to by a troponym and its moregeneral superordinate are always temporally coextensive, in that one must necessarily bewalking every instant that one is limping. Troponymy therefore represents a special caseof entailment pairs that are always temporally coextensive and are related byentailment. 48 In contrast with pairs like limpwalk, a verb like snore entails and is included insleep, but is not a troponym of sleep get a medical checkup entails and includes visit thedoctor, but is not a troponym of visit the doctor and buy entails pay, but is not atroponym of pay. The verbs in these pairs are related only by entailment and propertemporal inclusion. The important generalization here is that verbs related by entailmentand proper temporal inclusion cannot be related by troponymy. For two verbs to berelated by troponymy, the activities they denote must be temporally coextensive. Onecan sleep before or after snoring, buying includes activities other than paying, andvisiting the doctor is not temporally coextensive with getting a medical checkup, sonone of these pairs are related by troponymy.The two categories of lexical entailment that have been distinguished so far arerelated diagrammatically in Figure 1.EntailmentTroponymyCoextensivenessTroponymyProper InclusionlimpwalklisptalksnoresleepbuypayFigure 1. Two kinds of entailment with temporal inclusionVerb TaxonomiesIn trying to construct verb taxonomies using the troponymy relation, it becameapparent that verbs cannot easily be arranged into the kind of tree structures onto whichnouns are mapped. First, within a single semantic field it is frequently the case that notall verbs can be grouped under a single unique beginner some semantic fields must berepresented by several independent trees. Motion verbs, for example, have two topnodes, move, make a movement, and move, travel. Verbs of possession can be tracedup to the three verbs give, transfer, take, receive, and have, hold for the mostpart, their troponyms encode ways in which society has ritualized the transfer ofpossessions bequeath, donate, inherit, usurp, own, stock, etc. The semantic fieldcontaining verbs of bodily care and functions consists of a number of independenthierarchies that form a coherent semantic field by virtue of the fact that most of the verbswash, comb, shampoo, make up ache, atrophy select for the same kinds of nounarguments body parts. The communication verbs are headed by the verb communicatebut immediately divide into verbs of verbal and nonverbal gestural communicationthe former divide further into actions denoting the communication of spoken vs. written 49 language.Verb hierarchies tend to have a more shallow, bushy structure than nouns in fewcases does the number of hierarchical levels exceed four. Moreover, virtually every verbtaxonomy shows what might be called a bulge, that is to say, a level far more richlylexicalized than the other levels in the same hierarchy. Call this layer L0, the layer aboveit L1, and the layer below L1. Certain parallels can be drawn between L0 and what hasbeen called the basic level in noun hierarchies Rosch et al., 1976. Not only do most ofthe verbs in a hierarchy cluster at L0, but the troponymy relation between these verbs andtheir superordinate is semantically richer than between verbs on other levels. Consider,for example, the taxonomy arising from the L1 verb walk the superordinate of walk, onlevel L2, is move, travel troponyms of walk, on level L0, are march, strut, traipse,amble, mosey, slouch, etc. Although a statement relating L1 to L2To walk is tomove in some manneris perfectly acceptable, statements relating L0 to L1Tomarchstruttraipseamble . . . is to walk in some mannerseem more felicitous theseverbs elaborate the concept of walking in distinct ways, yet the features of walking arestill clearly present. Walk, on the other hand, seems semantically more remote from itssuperordinate, move.An alternative way to think about verb taxonomiesone that reflects theprominence of the two levels, L1 and L0is in terms of a radial structure, or cluster,with unelaborated L1 verbs like walk, talk, hit, and fight in the center and theirtroponyms march, strut lisp, babble tap, slam battle, joust, etc., clustered around them.In most hierarchies, L1, the level below the most richly lexicalized one, has fewmembers. For the most part, they tend not to be independently lexicalized, but arecompounded from their superordinate verb and a noun or noun phrase. Examples aregoosestep, a troponym of march from the walk hierarchy and spoonfeed, forcefeed,bottlefeed, breastfeed, troponyms of feed, cause to eat from the ingest hierarchyamong the consumption verbs.As one descends in a verb hierarchy, the variety of nouns that the verbs on a givenlevel can take as potential arguments decreases. This seems to be a function of theincreasing elaboration and meaning specificity of the verb. Thus, walk can take a subjectreferring either to a person or an animal most troponyms of walk, however, are restrictedto human subjects. And goosestepping is usually, though not necessarily, done bysoldiers this verb rarely takes children or old people as arguments. On the other hand,move, travel can take not only person and animal subjects, but also vehicles, or objectsmoved by external forces. Similarly, figures or pictures can communicate and talk theycan even deceive or lie, but they cannot fib or perjure themselves, as only humanspeakers can. A piece of news may hit, touch or even grab you, but it cannot punch,stroke or collar you only people can be agents of these verbs.Opposition Relations between VerbsThere is evidence that opposition relations are psychologically salient not only foradjectives, but also for verbs. For example, in the course of teaching foreign languagesthe author has experienced that students, when given only one member of an antonymous 50 or opposed verb pair, will insist on being told the other member they believe that it iseasier to learn semantically opposed words together. Fellbaum and Chaffin 1990, in ananalogy task involving different semantic relations between verbs, asked subjects togenerate verbs whose relation to the stimulus matched that of a given pair they foundthat subjects were most successful in completing analogies that involved an oppositionrelation. Moreover, analogies based on opposition relations took the least time tocomplete. In building the database for verbs, it was found that after synonymy andtroponymy, opposition is the most frequently coded semantic relation.The semantics of opposition relations among verbs is complex. As in the case ofadjectives, much of the opposition among verbs is based on the morphologicalmarkedness of one member of an opposed pair, as in the pairs tieuntie andappeardisappearfR.Like the semantically similar adjective pairs weightyweightless and heavylight,there are pairs like fallrise and ascenddescend that seem identical in meaning, yet aredistinguished by the way their members pick out their direct antonyms risedescend andascendfall are conceptually opposed, but are not direct antonyms.Many deadjectival verbs formed with a suffix such as en or ify inherit oppositionrelations from their root adjectives lengthenshorten, strengthenweaken, prettifyuglify,for example. These are, for the most part, verbs of change and would decompose intoBECOME  adjective or MAKE  adjective. As in the case of the correspondingadjectives, these are direct antonyms. Synonyms of these verbs, when they exist, aregenerally of Latin or Greek origin and tend to be more constrained in the range of theirpotential arguments, that is to say, they are usually reserved for more specialized uses.Thus, fortify is a synonym of strengthen, but its opposition relation to weaken isconceptual fortifyweaken are indirect antonyms. In short, deadjectival verbs can berepresented by the same configuration that Gross and Miller this volume describe foradjectives.As in the case of adjectives, a variety of negative morphological markers attach toverbs to form their respective opposing members. Examples are tieuntie,approvedisapprove, and bonedebone. The semantics of these morphologicaloppositions is not simple negation. To untie is a kind of undoing, and the sense of thisverb is one of reversing an action it does not mean to not tie. A pair of verbs likeapprovedisapprove are gradables the two lexicalized terms are points on a scale ofapproval, in this case. Gradable verbs, like gradable adjectives, can be modified bydegree adverbs, such as quite, rather, etc. Perhaps the most striking example illustratingthat negative morphology is not simple negation is seen in such pairs as bonedebonewhere, despite the lexical opposition induced by the presence of a negative prefix, thereis no semantic opposition at allboth verbs refer to the same activity of removing thebones of an animal Horn, 1989. In some pairs, the marked member cannot be inferredsimply from the morphological marker because the opposition derives from the prefixesthemselves emigrateimmigrate, exhaleinhale, predatepostdate.Other pairs whose members seem to be direct antonyms are risefall and walkrun.Members of these pairs are associated with each other rather than with verbs that are 51 synonyms of their respective opposites and that express the same concept as thatopposite. These pairs are illustrative of an opposition relation that is found quitesystematically between cotroponyms troponyms of the same superordinate verb. Forexample, the motion verbs rise and fall both conflate the superordinate move with asemantic component denoting the direction of motion they constitute an opposing pairbecause the direction of motion, upward or downward, is opposed. Similarly, theopposition between walk and run, two cotroponyms of move, travel, is due to theopposing manners slow or fast, respectively that distinguish each troponym from itssuperordinate. And the opposition of nibble and gorge, cotroponyms of eat, derivesfrom the opposition between the quantities eaten. Similarly, breastfeed and bottlefeed areopposites because they refer to two opposite manners of feeding an infant.Still other pairs illustrate the variety and complexity of verb opposition. Somepairs, called converses, are opposites that are associated with no common superordinateor entailed verb givetake, buysell, lendborrow, teachlearn, etc. They have incommon that they occur within the same semantic field they refer to the same activity,but from the viewpoint of different participants. This fact would lead one to surmise thattheir strong lexical association is probably due to their frequent cooccurrence in usage.Most antonymous verbs are stative or changeofstate verbs that can be expressed interms of attributes. There are many opposition relations among stative verbs livedie,excludeinclude, differequal, wakesleep. Opposition relations are also frequent amongchange verbs. Virtually no other relation other than synonymy holds these verbstogether. Thus, the organization of this suburb of the lexicon is flat rather thanhierarchicalthere are no superordinates except the generic change and be or have,and virtually no troponyms. Change verbs and stative verbs thus have a structureresembling that of the adjectives, with only synonymy and opposition relations.Opposition and EntailmentMany verb pairs in an opposition relation also share an entailed verb. For example,both hit and miss entail aim, because one must necessarily aim in order to hit or miss. Incontrast to the kinds of entailment discussed earlier, these verbs are not related bytemporal inclusion. The activities denoted by hit or miss and aim occur in a sequentialorder in order to either hit or miss, one must have aimed first aiming is a preconditionfor both hitting and missing. The relation between the entailing and the entailed verbshere is one of backward presupposition, where the activity denoted by the entailed verbalways precedes the activity denoted by the entailing verb in time. Other examples arefail and succeed, which both entail try and win and lose, both entailing play or gamble.Entailment via backward presupposition also holds between certain verb pairsrelated by a result or purpose relation, such as fattenfeed.A verb V1 that is entailed by another verb V2 via backward presupposition cannot besaid to be a part of V2. Partwhole statements between verbs are possible only when atemporal inclusion relation holds between these verbs.The set of verbs related by entailment that we have considered so far can beclassified exhaustively into two mutually exclusive categories on the basis of temporal 52 inclusion see Fig.2.EntailmentTemporal Inclusion Temporal InclusionBackward PresuppositionsucceedtryuntietieTroponymyCoextensivenesslimpwalklisptalkTroponymyProper InclusionsnoresleepbuypayFigure 2. Three kinds of entailmentOpposing verbs like fail and succeed tend to be contradictories, and, likecontradictory adjectives, they do not tolerate degree adverbs. Some opposition relationsinteract with the entailment relation in a systematic way. Cruse 1986 distinguishes anopposition relation that holds between verb pairs like damage and repair, and removeand replace. One member of these pairs, Cruse states, constitutes a restitutive. Thiskind of opposition also always includes entailment, in that the restitutive verb alwayspresupposes what one might call the deconstructive one. Many reversive un or deverbs also presuppose their unprefixed, opposed member in order to untie or unscrewsomething, someone must have tied or screwed it first. Again, these accompanyingentailment relations are not marked in WordNet only the more salient oppositionrelation is entered.The Causal RelationThe causative relation picks out two verb concepts, one causative like give, theother what might be called the resultative like have. In contrast to the other relationscoded in WordNet, the subject of the causative verb usually has a referent that is distinctfrom the subject of the resultative the subject of the resultative must be an object of thecausative verb, which is therefore necessarily transitive. The causative member of thepair may have its own lexicalization, distinct from the resultative, as in the pair show andsee sometimes, the members of such a pair differ only by a small variation in theircommon stem, as in the case of fellfall and raiserise. Although many languages have ameans to express causation, not all languages lexicalize the causative member 53 independently causation is often marked by a morpheme reserved for this function.English does not have many lexicalized causativeresultative pairs, such as showsee ithas an analytic, or periphrastic, causative, formed with cause tomakelethaveget to, thatis used productively.It has frequently been pointed out that a periphrastic causative is not semanticallyequivalent to a lexicalized causative Fodor, 1970 Shibatani, 1972 and others, butrefers to a more indirect kind of causation than the direct, lexicalized form. Kill andcause to die usually cannot be used interchangeably to refer to the same action, and soare not strictly speaking synonymous expressions of the same concept. For example,Chomsky 1977 notes that you can cause someone to die by having him drive across thecountry with a pathological murderer, but your action could not properly be calledkilling. For the purposes of WordNet, such pragmatic considerations have beendisregarded.WordNet recognizes only lexicalized causativeresultative pairs. The synonyms ofthe members of such a pair inherit the Cause relation, indicating that this relation holdsbetween the entire concept rather than between individual word forms only thesynonyms teach, instruct, educate, for example, are all causatives of the conceptlearn, acquire knowledge. However, unlike entailment, the causation relation is notinherited by the troponyms of each of these concepts spoonfeed, indoctrinate, and tutordo not necessarily cause the student to cram, stuff, or memorize.Causative verbs have the sense of cause to bebecomehappenhave or cause to do.That is to say, they relate transitive verbs to either states or actions. For example, giveand teach are related via causation to the statives have and know raise and feed arerelated to the events or actions referred to by rise and eat. In both cases, causation can beseen as a kind of change. Many verbs clearly have the semantics of such a causativechange, but they do not have lexicalized resultatives. The amuse and annoy subgroup ofthe psych verbs all refer to causing the experiencer to have an emotion, but only one suchcausative concept, frighten, scare, has a lexicalized resultative, fear, dread.There are many verbs in English that have both a causative and an anticausativeusage. Most of them cluster in the file containing the verbs of change, where many verbsalternate between a transitive causative form and an intransitive anticausative orunaccusative, or inchoative form. Here, the surface form of the causative and theanticausative verbs are identical. Examples are the verbs whiten, grow, break, andshrink. Most anticausative verbs imply either an animate agent or an inanimate causeThe glass door brokeThe stormThe children broke the glass door. A few verbs arecompatible only with an inanimate cause Johnnies teeth rottedAll that candy rottedJohnnies teeth, is acceptable, but His mother rotted Johnnies teeth is not.The causative relation also shows up systematically among the motion verbsbounce, roll, blow, etc., alternate between a causative and an anticausative usage Sheblew a soap bubble in his face vs. The soap bubble blew in his face. While the causativevariants of these verbs usually require an inanimate object, some unergative verbs likerun, jump, gallop, walk, race, which select for an animate agent, can also have acausative reading, as in the sentences He raced the horse past the barn and The father 54 walked his son to school. See Levin, 1985, and Pinker, 1989, for a conceptual analysisof these verbs.Causation and EntailmentCarter 1976 notes that causation is a specific kind of entailment if V1 necessarilycauses V2, then V1 also entails V2. He cites the entailment relation between verb pairslike expel and leave, or bequeath and own, where the entailing verb denotes the causationof the state or activity referred to by the entailed verb. Like the backward presuppositionrelation that holds between verbs like failsucceed and try, the entailment between verbslike bequeath and own is characterized by the absence of temporal inclusion.The causation relation is unidirectional although giving something to somebodycauses the recipient to have it, for someone to have something does not entail that he wasgiven it. Similarly, feeding somebody causes that person to eat, but somebodys eatingdoes not entail that someone feeds the eater. Except that when the subject of eat is not apotentially independent agent, such as a baby or a confined animal, then eating doesentail the causative act of feeding. The direction of the entailment may therefore bereversed in such cases, depending on the semantic features of the verbs subject. Butbecause the entailment depends on specific features of the subject, it can no longer besaid to be lexical, that is, it is no longer a relation between two verbs only.We have now distinguished four different kinds of lexical entailment thatsystematically interact with the semantic relations we code in WordNet. These fourkinds of entailment are related in Figure 3.EntailmentTemporal Inclusion Temporal InclusionBackward PresuppositionsucceedtryuntietieCauseraiserisegivehaveTroponymyCoextensivenesslimpwalklisptalkTroponymyProper InclusionsnoresleepbuypayFigure 3. Four kinds of entailment relations among verbs 55 Syntactic Properties and Semantic RelationsIn recent years the lexicon has gained increasing attention from linguists. Verbs inparticular have been the subject of much research in pursuit of a theory of lexicalknowledge. The work of Levin 1985, 1989 and others has focused on properties ofverbs as lexical items that combine with noun arguments to form sentences. Thisresearch analyzes the constraints on verbs argumenttaking properties in terms of theirsemantic makeup, based on the assumption that the distinctive syntactic behavior ofverbs and verb classes arises from their semantic components. Pinker 1989 undertakesa finegrained semantic analysis of verbs that participate in syntactic alternations,claiming that children can discern subtle differences that enable them to distinguishsemanticallybased verb classes with certain syntactic properties. Gleitman 1990asserts that children exploit the syntacticsemantic regularities of verbs to infer theirmeanings on the basis of their syntactic properties.WordNet was designed to model lexical memory rather than represent lexicalknowledge, so it excludes much of a speakers knowledge about both semantic andsyntactic properties of verbs. There is no evidence that the syntactic behavior of verbsor any other lexical category serves to organize lexical memory. But there is asubstantial body of research cited in Levin, 1989 showing undeniable correlationsbetween a verbs semantic makeup and its syntax, and the possible implications forchildrens acquisition of lexical knowledge Pinker, 1989 Gleitman, 1990.To cover at least the most important syntactic aspects of verbs, therefore, WordNetincludes for each verb synset one or several sentence frames, which specify thesubcategorization features of the verbs in the synset by indicating the kinds of sentencesthey can occur in. This information permits one quickly to search among the verbs forthe kinds of semanticsyntactic regularities studied by Levin and others. One can eithersearch for all the synsets that share one or more sentence frames in common and comparetheir semantic properties or one can start with a number of semantically similar verbsynsets and see whether they exhibit the same syntactic properties. An exploration of thesyntactic properties of cotroponyms occasionally provides the basis for distinguishingsemantic subgroups of troponyms.As a case in point, consider verbs like fabricate and compose, which are membersof the creation verb class. Many creation verbs participate in a syntactic alternation thatLevin 1989 terms the MaterialProduct alternation, illustrated by the followingexamplesShe wove a rug from the black sheeps woolShe wove the black sheeps wool into a rugThey molded a head from the clayThey molded the clay into a headSome verbs, like fabricate and compose, which also share membership in the class ofcreation verbs, do not participate in this syntactic alternation, despite their semanticsimilarity to verbs like weave and mold 56 The reporter fabricated a story out of the girls accountThe reporter fabricated the girls account into a storyShe composed a quartet out of the old folk songShe composed the old folk song into a quartetIn discussing these verbs, Fellbaum and Kegl 1988 point out that the data suggest aneed for a finegrained subclassification of creation verbs that distinguishes a class ofverbs referring to acts of mental creation such as as fabricate and compose from verbsdenoting the creation from raw materials such as weave and mold. Such a distinctionwould account for the systematic difference among the verbs in most cases. Thus, Levin1989 distinguishes these verbs in terms of membership in one of two classes the BUILDclass, which comprises verbs like bake, and the CREATE class constituted by such verbsas compose and fabricate. However, English does not have a lexicalized generic verbdenoting the concepts of create from raw material and create mentally, which wouldmake it possible to capture this generalization by means of different superordinateswhose troponyms differ syntactically. But the observation can be formulated in terms ofdifferences in the manner relations that link verbs like mold on the one hand, and verbslike compose on the other hand, to their common superordinate create. This exampledemonstrates how syntactic differences between apparently similar verbs can be cast interms of the particular way that the meanings of words are represented in WordNet.Viewing verbs in terms of semantic relations can also provide clues to anunderstanding of the syntactic behavior of verbs. Fellbaum and Kegl 1989 studied aclass of English verbs that participate in the following transitiveintransitive alternationMary ate a bag of pretzelsMary atePrevious analyses of these verbs have explained the alternation in terms of discoursecontrol Fillmore, 1986 or aspect Mittwoch, 1982. However, an analysis of thetroponyms of the verb eat showed that they fall into two syntactic classes those thatmust always be used transitively, and those that are always intransitive. The first classincludes the verbs gobble, guzzle, gulp, and devour the second class includes verbs likedine, graze, nosh, and snack. Fellbaum and Kegl suggest that this syntactic difference isnot just a transitivity alternation characteristic of a single verb, but is semanticallymotivated. They show that English has two verbs eat, and that each verb occupies adifferent position in the network, that is to say, each verb is part of a different taxonomy.Intransitive eat has the sense of eat a meal. In some troponyms of this verb, such as thedenominals dine, breakfast, picnic, and feast, the verb eat has become conflated withhyponyms of the noun meal. These verbs are intransitive because they are alllexicalizations of the verb eat that means eat a meal. Other intransitive troponyms of thisverb are munch, nosh, and graze. Although these verbs are not conflations of eat and anoun, they are semantically related in that they refer to eating informal kinds of meals orrepasts. By contrast, the transitive verb eat has the sense of ingest in some manner, andits troponyms all refer to a specific manner of eating gobble, gulp, devour, etc.3 Thus, 3 Kenneth Hale personal communication informs us that two eat verbs having this semanticdistinction are found crosslinguistically. 57 the semantics of the troponyms in each case provide a classification in terms of twodistinct hierarchies matching the syntactic distinction between the two verb groups.SummaryDifferent semantic groups of verbs have distinct structures. Some parts can be castinto a taxonomic framework by means of the troponymy relation this is generally truefor verbs of creation, communication, competition, contact, motion, and consumption.The troponymy relation covers a number of different manner relations, one or more ofwhich tend to cluster in specific semantic domains. In some semantic domains, distinctpatterns of lexicalization can be discerned often a base verb conflates with nouns fromthe corresponding semantic domain. In such verb hierarchies, which tend to be muchflatter than noun hierarchies, one level can be distinguished that is more richlylexicalized than the other levels. Stative verbs and verbs of change exhibit an entirelydifferent structure they tend to be organized in terms of opposition and synonymyrelations and they can be mapped into the bipolar clusters that characterize the adjectives.Comments on Specific Verb ClustersThis section lists particular properties of the several verb files.1. Verbs of Bodily Functions and Care. This relatively small file of approximately275 synsets contains many verbs referring to actions or events that are not under thecontrol of the argument that functions as their subject sweat, shiver, faint, burp, ache,tire, sleep, freeze, etc.. For this reason these verbs, which are mostly intransitives, havebeen called unaccusatives, that is, their subjects are thought to be underlyingly objects.Some verbs, like snort and wink, that have a basic sense referring to an involuntaryaction, acquire a sense of communication when the action is intended and controlled bythe agent. A number of body verbs referring to grooming activities such as wash, anddress have a reflexive reading in their intransitive form, and are transitive when theaction is performed on someone other than the agent, or on a specific body part of theagent.2. Verbs of Change. The verbs of change constitute one of the largest verb files inWordNet about 750 synsets, owing in part to the fact that the concept of change isflexible enough to accommodate verbs whose semantic description makes them unfit forany other semantically coherent group. Dowty 1979 analyzes all verbs as ultimatelybeing composable as stative predicates, which, by means of aspectual connectives andoperators such as DO, yield other verb classes. With the exception of the statives, Dowtyadditionally assigns to all verbs the operator BECOME as part of their lexical makeup.His analysis shows that all nonstative verbs can be classified as verbs of change, eitheras intransitives stative predicates plus the operator BECOME or as transitives with theadditional operator DO. An analysis like Dowtys is based on the decomposition ofverbs, rather than on a relational analysis of the kind WordNet has undertaken, but itshows that, given the abstract concept of CHANGE, all verbs can be derived from it. InWordNet, this concept has been broken down into several superordinate verbs of changechange, alter, vary, modify, change1, change state, change2, change by reversal, 58 turn, revert, change integrity, change shape, and change3, adjust, conform,adapt. Most verbs in the change file are derived from these verbs via troponymy. Thus,WordNet characterizes the verbs of change not by the presence of a semantic componentCHANGE but by a semantic relation to one of these more specific concepts of change.The fact that the change file is so large is also due, in part, to the fact that Englishhas productive morphological rules deriving change verbs from adjectives or nouns viaaffixes such as ify and ize. The derived verbs, such as humidify and magnetize, generallyrefer to a state or attribute, and there is usually an opposite state or attribute valueexpressed by a verb that is identical except for a negative prefix dehumidify anddemagnetize. Many change verbs are also derived from adjectives via the en suffixthey tend to have an antonymic verb derived from the base adjectives antonymweakenstrengthen, shortenlengthen, etc.3. Verbs of Communication. The communication verbs, which comprise over 710synsets, include verbs of verbal and nonverbal communication gesturing the former arefurther divided into verbs of speaking and verbs of writing. Most communication verbsinvolving language, such as petition and hail, can be classified as troponyms of speechact verbs Austin, 1962. Verbs of verbal communciation are richly lexicalized inEnglish. They are elaborated in terms of manner of speaking lisp, stammer, babble orthe speakers intention beg, order, thank. The communication verb file is also rich indenominals mandate, appeal, quiz, and many more. Many subareas of lexicalizationshow where society values communication politics veto, inaugurate, law libel, plead,pardon, religion preach, proselytize, catechize, education teach, examine,telecommunciations denominals derived from the nouns denoting the medium ofcommunication, like fax, telex, and email, to name just a few. This file also containsverbs referring to animal noises neigh, moo, etc. and verbs of noise production anduttering that have an inanimate source and lack a communicative function creak,screech.4. Competition Verbs. These verbs, grouped into over 200 synsets, cover thesemantic areas of sports, games, and warfare. In this file, the L1 layer is relatively welllexicalized for many hierarchies, because there are many verbs referring to actions thatare specific to games or sports, and that are troponyms of verbs with more generalmeanings. We find many composite troponyms faceoff, runoff, counterstrike anddenominals referee, handicap, arm, team, campaign, chickenfight, duel. Many of theverbs can be used reciprocally, i.e., they can take a plural subject, and either a surface oran implicit each other referring to the two opposing sides fight, race, etc..5. Consumption Verbs. The consumption file includes, besides verbs of ingesting,verbs of using, exploiting, spending, and sharing, organized into approximately 130synsets. Many verbs are syntactic unergativesthat is to say, they are either strictlyintransitive or they select only cognate objects or their subordinates. For example, drink,when it is not used intransitively, takes as its object the cognate noun drink usually witha modifier or one of its subordinates water, beer, etc.. The analysis of transitive andintransitive verbs like eat Fellbaum  Kegl, 1989 described above shows howtransitivity patterns can serve to tease out semantic subgroups of verbs. The consumption 59 verb file contains other unergatives like eat, which can be analyzed in a similar fashion.6. Contact Verbs. This file is the largest verb file, consisting of over 820 synsets.Because most of its verbs are troponyms of very few base verbs, the largest treestructures are to be found in this file. The central verb concepts are fasten, attach,cover, cut, and touch. Many troponyms are derived via a manner relation encoding theforce, intensity, or iteration of the action. For example, the troponyms of rub denotedifferent degrees of force scrub, wipe, fray, chafe, scour, abrade, and others. There aremany verbs of holding grasp, squeeze, grab, pinch, grip, and others, and touching paw,finger, stroke, hit, jab, poke. Some of the base verbs require an instrument or materialCarter 1976 and Jackendoff 1983 refer to these as entailed or open arguments,respectively. These arguments are frequently conflated in troponyms together with thebase verb characterizing the action. Troponyms of cut encode the instrument knife,saw or the resultant shape cube, slice troponyms of cover express the material withwhich an object is covered paint, tar, feather troponyms of enclose encode thecontainer box, bag, crate, shroud. Verbs of removal refer to the removed stuff skin,bark, fleece or the resultant empty space furrow, hole, groove. Body part denominalsindicate what kind of contact action the body part is typically used for shouldersupport, carry elbow push finger, thumb touch, manipulate, and so on.7. Cognition Verbs. This file contains verbs denoting various cognitive actions andstates, such as reasoning, judging, learning, memorizing, understanding, and concluding.The organizing relation in this file is troponymy. Some troponyms express kinds ofreasoning deduce, induce or degrees of certainty infer, guess, assume, suppose. Thecognition verbs overlap to a large degree with the communication verbs one verb canrefer both to the mental activity of, say, reasoning and judging and to the action ofarticulating ones reasoning and judging.8. Creation Verbs. The creation verbs, organized into about 250 synsets, fall intoseveral subgroups that are both semantically and syntactically motivated, but whosesuperordinates, referring to manners of creation, are not lexicalized create by mental actinvent, conceive, etc. create by artistic means engrave, illuminate, print create fromraw material weave, sew, bake. Many of these verbs can appear either transitively,where the direct object refers to the creation, or intransitively, where the verb no longernecessarily has the create sense but refers only to a manipulation of some materialcompare He sewed and He sewed a shirt without implying the accomplishment of acreation. Other troponyms of creation verbs are such denominals as lithograph, fresco,and silkscreen, where the created object has been conflated with the verb.9. Motion Verbs. The motion verbs, grouped into over 500 synsets, derive fromtwo roots move, make a movement, and move, travel. The first sense, exemplifiedby shake and twist, is what Miller and JohnsonLaird 1976, p. 529 call motioninplace1976, p.529 and Pinker calls contained motion 1989 the second is theconcept of locomotion, as in run and crawl. Both senses of move can also have atransitive causative meaning this is not true for all of their troponyms, though.Troponyms encode the speed of locomotion gallop, race, the medium of transportationcanoe, taxi, and the medium in which the travel takes place fly, swim, as well as other 60 elaborations.10. Emotion or Psych Verbs. These verbs fall into two grammatically distinctclasses those whose subject is the animate Experiencer and whose object if there is oneis the Source fear, miss, adore, love, despise and those whose object is the animateExperiencer and whose subject is the Source amuse, charm, encourage, anger. In bothcases, the Source may be either animate or inanimate. If the Source is animate, it may beeither intentionally causing the emotion, i.e., it may an Agent, or it may be theunintentional Source of the emotion. This distinction is shown by the ambiguity of Theteacher frightened the children. Inanimates are of course always unintentional sourcesThe skeletonThe cry of the owl scared the children. Most of the verbs have beenstructured along the analysis given in JohnsonLaird and Oatley 1989 for nouns, wherefive basic emotions happiness, sadness, fear, anger, disgust are posited along with theirsubordinates most of these nouns have corresponding verbs. Besides being linked bytroponymy, some emotions enter into opposition relations lovehate, hopedespair.11. Stative Verbs. Stative verbs some 200 synsets are for the most part verbs ofbeing and having. Many stative verbs also have nonstative senses that have been placedinto other files. For example, verbs like surround, cross, and reach have both a stativesense referring to spatial relations, and a nonstative sense denoting verbs of motion.Many verbs have the meaning of be ADJECTIVE equal, suffice, necessitate, to namejust a few. Like adjectives, they usually have opposite terms differ, lack, obviate andsynonyms match, cover, require, but they rarely have superordinates, other than be orhave, feature, have as a feature. The stative verb file, therefore, consists of small,semantically independent clusters, and resembles the adjective file.12. Perception Verbs. The top nodes in this file of about 200 synsets are verbsreferring to perception by means of the five senses. Their troponyms encode differentelaborations. For example, the troponyms of the base verb see conflate the intention onthe part of the perceiver watch, spy, survey, the circumstances witness, discover, andmanner gaze, stare, ogle, glance. Verbs of smelling, for example, take as their subjecteither experiencer snuff, sniff, whiff or the source of the perception reek, stink smelland scent can be used in either frame. Verbs denoting both the causation and theperception of cutaneous irritation are particularly richly lexicalized ache, hurt, prickle,sting, prick, tingle, tickle, scratch, itch, bite, and others.13. Verbs of Possession. The verbs of possession, organized into almost 300synsets, are mostly derived from three basic concepts have, hold, own, give,transfer, and take, receive, which denote the change of possession and its prior orresultant state. Troponyms of these verbs refer to ways in which the transfer ofpossession takes place in our society by legal or illegal means, such as inheritancebequeath, will, inherit vs. theft rob, plagiarize, loot by formal or informal giftsbestow, confer, grant vs. beg, bribe, extort and by various business transactionspeddle, scalp, auction, retail, to name a few of the possible elaborations.14. Verbs of Social Interaction. This file contains well over 400 synsets with verbsfrom different areas of social life law, politics, economy, education, family, religion, etc.Many have a specialized meaning, restricted to a particular domain of social life, and 61 they tend to be monosemous impeach, courtmartial, moonlight, franchise,gerrymander, excommunicate, to name a few. Frequently, the verbs are denominalsconflating a basic verboften a communication or a cognition verband a noun fromone of the areas named above, for example, petition, quarrel, charm, or veto.15. Weather Verbs. Weather verbs constitute the smallest verb file 66 synsets, butthey are semantically and syntactically distinct. They include mostly verbs like rain andthunder, which are all intransitives except for such idiomatic expressions as It is rainingcats and dogs. They do not select for any arguments their subject is the semanticallyempty expletive, it. Many of these verbs are derived from their homonymous nounsrain, thunder, snow, hail, etc..ConclusionA relational analysis of English verbs has revealed some of the striking ways inwhich verbs differ from nouns and adjectives. The relations between verbs are distinctfrom those between words of other parts of speech in general, their semantics areconsiderably more complex. The predominance of different relations and differentlexicalization patterns in various semantic domains has been discussed. 62 Design and Implementation of the WordNet Lexical Databaseand Searching SoftwareRichard Beckwith, George A. Miller, and Randee TengiLexicographers must be concerned with the presentation as well as the content oftheir work, and this concern is heightened when presentation moves from the printedpage to the computer monitor. Printed dictionaries have become relatively standardizedthrough many years of publishing Vizetelly, 1915 expectations for electronic lexiconsare still up for grabs. Indeed, computer technology itself is evolving rapidly anindefinite variety of ways to present lexical information is possible with this newtechnology, and the advantages and disadvantages of many possible alternatives are stillmatters for experimentation and debate. Given this degree of uncertainty, manner ofpresentation must be a central concern for the electronic lexicographer.WordNet is a pioneering excursion into this new medium. Considerable attentionhas been devoted to making it useful and convenient, but the solutions described here areunlikely to be the final word on these matters. It is hoped that readers will not merelynote the shortcomings of this work, but will also be inspired to make improvements on it.Ones first impression of WordNet is likely to be that it is an online thesaurus. It istrue that sets of synonyms are basic building blocks, and with nothing more than thesesynonym sets the system would have all the power of a thesaurus. When short glossesare added to the synonym sets, it resembles an online dictionary that has beensupplemented with synonyms for cross referencing Calzolari, 1988. But WordNetincludes much more information than that. In an attempt to model the lexical knowledgeof a native speaker of English, WordNet has been given detailed information aboutrelations between word forms and synonym sets. How this relational structure should bepresented to a user raises questions that outrun the experience of conventionallexicography.In developing this online lexical database, it has been convenient to divide thework into two interdependent tasks which bear a vague similarity to the traditional tasksof writing and printing a dictionary. One task was to write the source files that containthe basic lexical data  the contents of those files are the lexical substance of WordNet.The second task was to create a set of computer programs that would accept the source  This is a revised version of Implementing a Lexical Network in CSL Report 43, preparedby Randee Tengi. UNIX is a registered trademark of UNIX System Laboratories, Inc. Sun, Sun 3and Sun 4 are trademarks of Sun Microsystems, Inc. Macintosh is a trademark of Macintosh Laboratory, Inc. licensed to Apple Computer, Inc. NeXT is a trademark of NeXT. Microsoft Windows is a trademark of Microsoft Corporation. IBM is a registered trademark of InternationalBusiness Machines Corporation. X Windows is a trademark of the Massachusetts Institute ofTechnology. DECstation is a trademark of Digital Equipment Corporation. 63 files and do all the work leading ultimately to the generation of a display for the user.The WordNet system falls naturally into four parts the WordNet lexicographerssource files the software to convert these files into the WordNet lexical database theWordNet lexical database and the suite of software tools used to access the database.The WordNet system is developed on a network of Sun4 workstations. The softwareprograms and tools are written using the C programming language, Unix utilities, andshell scripts. To date, WordNet has been ported to the following computer systemsSun3 DECstation NeXT IBM PC and PC clones Macintosh.The remainder of this paper discusses general features of the design andimplementation of WordNet. The WordNet Reference Manual is a set of manualpages that describe aspects of the WordNet system in detail, particularly the userinterfaces and file formats. Together the two provide a fairly comprehensive view of theWordNet system.Index of FamiliarityOne of the best known and most important psycholinguistic facts about the mentallexicon is that some words are much more familiar than others. The familiarity of a wordis known to influence a wide range of performance variables speed of reading, speed ofcomprehension, ease of recall, probability of use. The effects are so ubiquitous thatexperimenters who hope to study anything else must take great pains to equate the wordsthey use for familiarity. To ignore this variable in a lexical database that is supposed toreflect psycholinguistic principles would be unthinkable.In order to incorporate differences in familiarity into WordNet, a syntacticallytagged index of familiarity is associated with each word form. This index does notreflect all of the consequences of differences of familiarity  some theorists would askfor strength indices associated with each relation  but accurate information on all ofthe consequences is not easily obtained. The present index is a first step.Frequency of use is usually assumed to be the best indicator of familiarity. Theclosed class words that play an important syntactic role are the most frequently used, ofcourse, but even within the open classes of words there are large differences in frequencyof occurrence that are assumed to correlate with  or to explain  the large differencesin familiarity. The frequency data that are readily available in the technical literature,however, are inadequate for a database as extensive as WordNet. Thorndike and Lorge1944 published data based on a count of some 5,000,000 running words of text, butthey reported their results only for the 30,000 most frequent words. Moreover, theydefined a word as any string of letters between successive spaces, so their counts forhomographs are untrustworthy there is no way to tell, for example, how often leadoccurred as a noun and how often as a verb. Francis and Kucvera 1982 tag words fortheir syntactic category, but they report results for only 1,014,000 running words of text or 50,400 word types, including many proper names  which is not a large enoughsample to yield reliable counts for infrequently used words. A comfortable rate ofspeaking is about 120 wordsminute, so that 1,000,000 words corresponds to 140 hours,or about two weeks of normal exposure to language. 64 Fortunately, an alternative indicator of familiarity is available. It has been known atleast since Zipf 1945 that frequency of occurrence and polysemy are correlated. That isto say, on the average, the more frequently a word is used the more different meanings itwill have in a dictionary. An intriguing finding in psycholinguistics Jastrezembski,1981 is that polysemy seems to predict lexical access times as well as frequency does.Indeed, if the effect of frequency is controlled by choosing words of equivalentfrequencies, polysemy is still a significant predictor of lexical decision times.Instead of using frequency of occurrence as an index of familiarity, therefore,WordNet uses polysemy. This measure can be determined from an online dictionary. Ifan index value of 0 is assigned to words that do not appear in the dictionary, and if valuesof 1 or more are assigned according to the number of senses the word has, then an indexvalue can be made available for every word in every syntactic category. Associated withevery word form in WordNet, therefore, there is an integer that represents a count of theCollins Dictionary of the English Language of the number of senses that word form haswhen it is used as a noun, verb, adjective, or adverb.A simple example of how the familiarity index might be used is shown in Table 1.If, say, the superordinates of bronco are requested, WordNet can respond with thesequence of hypernyms shown in Table 1. Now, if all the terms with a familiarity indexpolysemy count of 0 or 1 are omitted, which are primarily technical terms, thehypernyms of bronco include simply bronco  pony  horse  animal organism  entity. This shortened chain is much closer to what a layman wouldexpect. The index of familiarity should be useful, therefore, when making suggestionsfor changes in wording. A user can search for a more familiar word by inspecting thepolysemy in the WordNet hierarchy.WordNet would be a better simulation of human semantic memory if a familiarityindex could be assigned to wordmeaning pairs rather than to word forms. The noun tie,for example, is used far more often with the meaning tie, necktie than with themeaning tie, tie beam, yet both are presently assigned the same index, 13.Lexicographers Source FilesWordNets source files are written by lexicographers. They are the product of adetailed relational analysis of lexical semantics a variety of lexical and semanticrelations are used to represent the organization of lexical knowledge. Two kinds ofbuilding blocks are distinguished in the source files word forms and word meanings.Word forms are represented in their familiar orthography word meanings are representedby synonym sets  lists of synonymous word forms that are interchangeable in somesyntax. Two kinds of relations are recognized lexical and semantic. Lexical relationshold between word forms semantic relations hold between word meanings.WordNet organizes nouns, verbs, adjectives and adverbs into synonym setssynsets, which are further arranged into a set of lexicographers source files by syntacticcategory and other organizational criteria. Adverbs are maintained in one file, whilenouns and verbs are grouped according to semantic fields. Adjectives are dividedbetween two files one for descriptive adjectives and one for relational adjectives. 65 Hypernyms of bronco and their index valuesWord Polysemy bronco 1 mustang 1 pony 5 horse 14 equine 0 oddtoed ungulate 0 placental mammal 0 mammal 1 vertebrate 1 chordate 1 animal 4 organism 2 entity 3Table 1Appendix A lists the names of the lexicographers source files.Each source file contains a list of synsets for one part of speech. Each synsetconsists of synonymous word forms, relational pointers, and other information. Therelations represented by these pointers include but are not limited tohypernymyhyponymy, antonymy, entailment, and meronymyholonymy. Polysemousword forms are those that appear in more than one synset, therefore representing morethan one concept. A lexicographer often enters a textual gloss in a synset, usually toprovide some insight into the semantics intended by the synonymous word forms andtheir usage. If present, the textual gloss is included in the database and can be displayedby retrieval software. Comments can be entered, outside of a synset, by enclosing thetext of the comment in parentheses, and are not included in the database.Descriptive adjectives are organized into clusters that represent the values, from oneextreme to the other, of some attribute. Thus each adjective cluster has two occasionallythree parts, each part headed by an antonymous pair of word forms called a head synset.Most head synsets are followed by one or more satellite synsets, each representing aconcept that is similar in meaning to the concept represented by the head synset. Oneway to think of the cluster organization is to visualize a wheel, with each head synset as ahub and its satellite synsets as the spokes. Two or more wheels are logically connectedvia antonymy, which can be thought of as an axle between wheels.The Grinder utility compiles the lexicographers files. It verifies the syntax of thefiles, resolves the relational pointers, then generates the WordNet database that is usedwith the retrieval software and other research tools. 66 Word FormsIn WordNet, a word form is represented as the orthographic representation of anindividual word or a string of individual words joined with underscore characters. Astring of words so joined is referred to as a collocation and represents a single concept,such as the noun collocation fountainpen.In the lexicographers files a word form may be augmented with additionalinformation, necessary for the correct processing and interpretation of the data. Aninteger sense number is added for sense disambiguation if the same word form appearsmore than once in a lexicographer file. A syntactic marker, enclosed in parentheses, isadded to any adjectival word form whose use is limited to a specific syntactic position inrelation to the noun that it modifies. Each word form in WordNet is known by itsorthographic representation, syntactic category, semantic field, and sense number.Together, these data make a key which uniquely identifies each word form in thedatabase.Relational PointersRelational pointers represent the relations between the word forms in a synset andother synsets, and are either lexical or semantic. Lexical relations exists betweenrelational adjectives and the nouns that they relate to, and between adverbs and theadjectives from which they are derived. The semantic relation between adjectives andthe nouns for which they express values are encoded as attributes. The semantic relationbetween noun attributes and the adjectives expressing their values are also encoded.Presently these are the only pointers that cross from one syntactic category to another.Antonyms are also lexically related. Synonymy of word forms is implicit by inclusion inthe same synset. Table 2 summarizes the relational pointers by syntactic category.Meronymy is further specified by appending one of the following characters to themeronymy pointer p to indicate a part of something s to indicate the substance ofsomething m to indicate a member of some group. Holonymy is specified in the samemanner, each pointer representing the semantic relation opposite to the correspondingmeronymy relation.Many pointers are reflexive, meaning that if a synset contains a pointer to anothersynset, the other synset should contain a corresponding reflexive pointer back to theoriginal synset. The Grinder automatically generates the relations for missing reflexivepointers of the types listed in Table 3.A relational pointer can be entered by the lexicographer in one of two ways. If apointer is to represent a relation between synsets  a semantic relation  it is enteredfollowing the list of word forms in the synset. Hypernymy always relates one synset toanother, and is an example of a semantic relation. The lexicographer can also enclose aword form and a list of pointers within square brackets ... to define a lexical relationbetween word forms. Relational adjectives are entered in this manner, showing thelexical relation between the adjective and the noun that it pertains to. 67 WordNet Relational PointersNoun Verb Adjective AdverbAntonym  Antonym  Antonym  Antonym Hyponym  Troponym  Similar  Derived from Hypernym  Hypernym  Relational Adj. Meronym  Entailment  Also See Holonym  Cause  Attribute Attribute  Also See Table 2Reflexive Pointers Pointer Reflect Antonym AntonymHyponym HypernymHypernym HyponymHolonym MeronymMeronym HolonymSimilar to Similar toAttribute Attribute Table 3Verb Sentence FramesEach verb synset contains a list of verb frames illustrating the types of simplesentences in which the verbs in the synset can be used. A list of verb frames can berestricted to a word form by using the square bracket syntax described above. SeeAppendix B for a list of the verb sentence frames.Synset SyntaxStrings in the source files that conform to the following syntactic rules are treated assynsets. Note that this is a brief description of the general synset syntax and is not aformal description of the source file format. A formal specification is found in themanual page wninput5 of the WordNet Reference Manual. 68 1 Each synset begins with a left curly bracket .2 Each synset is terminated with a right curly bracket .3 Each synset contains a list of one or more word forms, each followed by acomma.4 To code semantic relations, the list of word forms is followed by a list ofrelational pointers using the following syntax a word form optionally precededby filename to indicate a word form in a different lexicographer file followedby a comma, followed by a relational pointer symbol.5 For verb synsets, frames is followed by a comma separated list of applicableverb frames. The verb frames follow all relational pointers.6 To code lexical relations, a word form is followed by a list of elements from 4andor 5 inside square brackets ....7 To code adjective clusters, each part of a cluster a head synset, optionallyfollowed by satellite synsets is separated from other parts of a cluster by a linecontaining only hyphens. Each entire cluster is enclosed in square brackets.Archive SystemThe lexicographers source files are maintained in an archive system based on theUnix Revision Control System RCS for managing multiple revisions of text files. Thearchive system has been established for several reasons  to allow the reconstruction ofany version of the WordNet database, to keep a history of all the changes tolexicographers files, to prevent people from making conflicting changes to the same file,and to ensure that it is always possible to produce an uptodate version of the WordNetdatabase. The programs in the archive system are Unix shell scripts which envelop RCScommands in a manner that maintains the desired control over the lexicographers sourcefiles and provides a userfriendly interface for the lexicographers.The reserve command extracts from the archive the most recent revision of a givenfile or files and locks the file for as long as a user is working on it. The review commandextracts from the archive the most recent revision of a given file or files for the purposeof examination only, therefore the file is not locked. To discourage making changes,review files do not have write permission since any such changes could not beincorporated into the archive. The restore command verifies the integrity of a reservedfile and returns it to the archive system. The release command is used to break a lockplaced on a file with the reserve command. This is generally used if the lexicographerdecides that changes should not be returned to the archive. The whose command is usedto find out whether files are currently reserved, and if so, by whom.Grinder UtilityThe Grinder is a versatile utility with the primary purpose of compiling thelexicographers files into a database format that facilitates machine retrieval of theinformation in WordNet. The Grinder has several options that control its operation on aset of input files. To build a complete WordNet database, all of the lexicographers files 69 must be processed at the same time. The Grinder is also used as a verification tool toensure the syntactic integrity of the lexicographers files when they are returned to thearchive system with the restore command.ImplementationThe Grinder is a multipass compiler that is coded in C. The first pass uses a parser,written in yacc and lex, to verify that the syntax of the input files conforms to thespecification of the input grammar and lexical items, and builds an internal representationof the parsed synsets. Additional passes refer only to this internal representation of thelexicographic data. Pass one attempts to find as many syntactic and structural errors aspossible. Syntactic errors are those in which the input file fails to conform to the inputgrammars specification, and structural errors refer to relational pointers that cannot beresolved for some reason. Usually these errors occur because the lexicographer has madea typographical error, such as constructing a pointer to a nonexistent file, or fails tospecify a sense number when referring to an ambiguous word form. Pass one cannotdetermine structural errors in pointers to files that are not processed together. When usedas a verification tool, as from the restore command, only pass one is run.In its second pass, the Grinder resolves all of the semantic and lexical pointers. Todo this, the pointers that were specified in each synset are examined in turn, and thetarget of each pointer either a synset or a word form in a synset is found. The sourcepointer is then resolved by adding an entry to the internal data structure which notes thelocation of the target. In the case of reflexive pointers, the target pointers synset isthen searched for a corresponding reflexive pointer. If found, the data structurerepresenting the reflexive pointer is modified to note the location of its target, theoriginal source pointer. If a reflexive pointer is not found, the Grinder automaticallycreates one with all the pertinent information.A subsequent pass through the list of word forms assigns a polysemy index value, orsense count, to each word form found in the online dictionary. There is a separate sensecount for each syntactic category that the word form is found in. The Grinders final passgenerates the WordNet database.Internal RepresentationThe internal representation of the lexicographic data is a network of interrelatedlinked lists. A hash table of word forms is created as the lexicographers files are parsed.Lowercase strings are used as keys the original orthographic word form, if not inlowercase, is retained as part of the data structure for inclusion in the database files. Asthe parser processes an input file, it calls functions which create data structures for theword forms, pointers, and verb frames in a synset. Once an entire synset had beenparsed, a data structure is created for it which includes pointers to the various structuresrepresenting the word forms, pointers, and verb frames. All of the synsets from the inputfiles are maintained as a single linked list. The Grinders different passes access thestructures either through the linked list of synsets or the hash table of word forms. A listof synsets that specify each word form is maintained for the purposes of resolving 70 pointers and generating the databases index files.WordNet DatabaseFor each syntactic category, two files represent the WordNet database  index.posand data.pos, where pos is either noun, verb, adj or adv the actual file names may bedifferent on platforms other than Sun4. The database is in an ASCII format that ishuman and machinereadable, and is easily accessible to those who wish to use it withtheir own applications. Each index file is an alphabetized list of all of the word forms inWordNet for the corresponding syntactic category. Each data file contains all of thelexicographic data gathered from the lexicographers files for the corresponding syntacticcategory, with relational pointers resolved to addresses in data files.The index and data files are interrelated. Part of each entry in an index file is a listof one or more byte offsets, each indicating the starting address of a synset in a data file.The first step to the retrieval of synsets or other information is typically a search for aword form in one or more index files to obtain all data file addresses of the synsetscontaining the word form. Each address is the byte offset in the data file correspondingto the syntactic category of the index file at which the synsets information begins. Theinformation pertaining to a single synset is encoded as described in the Data Filessection below.One shortcoming of the databases structure is that although all the files are inASCII, and are therefore editable, and in theory extensible, in practice this is almostimpossible. One of the Grinders primary functions is the calculation of addresses for thesynsets in the data files. Editing any of the database files would most likely createincorrect byte offsets, and would thus derail many searching strategies. At the presenttime, building a WordNet database requires the use of the Grinder and the processing ofall lexicographers source files at the same time.The descriptions of the Index and Data files that follow are brief and are intended toprovide only a glimpse into the structure, syntax, and organization of the database. Moredetailed descriptions can be found in the manual page wndb5 included in theWordNet Reference Manual.Index FilesWord forms in an index file are in lower case regardless of how they were entered inthe lexicographers files. The files are sorted according to the ASCII character setcollating sequence and can be searched quickly with a binary search.Each index file begins with several lines containing a copyright notice, versionnumber and license agreement, followed by the data lines. Each line of data contains thefollowing information the sense count from the online dictionary a list of the relationalpointer types used in all synsets containing the word this is used by the retrievalsoftware to indicate to a user which searches are applicable a list of indices which arebyte offsets into the corresponding data file, one for each occurrence of the word form ina synset. Each data line is terminated with an endofline character. 71 Data FilesA data file contains information corresponding to the synsets that were defined inthe lexicographers files with pointers resolved to byte offsets in data.pos files.Each data file begins with several lines containing a copyright notice, versionnumber and license agreement. This is followed by a list of the names of all the inputfiles that were specified to the Grinder, in the order that they were given on the commandline, followed by the data lines. Each line of data contains an encoding of theinformation entered by the lexicographer for a synset, as well as additional informationprovided by the Grinder which is useful to the retrieval software and other programs.Each data line is terminated with an endofline character. In the data files, word formsin a synset match the orthographic representation entered in the lexicographers files.The first piece of information on each line is the byte offset, or address, of thesynset. This is slightly redundant, since almost any computer program that reads a synsetfrom a data file knows the byte offset that it read it from however this piece ofinformation is useful when using UNIX utilities like grep to trace synsets and pointerswithout the use of sophisticated software. It also provides a unique key for a synset,if a users application requires one. An integer, corresponding to the location in the listof file names of the file from which the synset originated, follows. This can be used byretrieval software to annotate the display of a synset with the name of the originating file,and can be helpful for distinguishing senses. A list of word forms, relational pointers,and verb frames follows. An optional textual gloss is the final component of a data line.Relational pointers are represented by several pieces of information. The symbolfor the pointer comes first, followed by the address of the target synset and its syntacticcategory necessary for pointers that cross over into a different syntactic category,followed by a field which differentiates lexical and semantic pointers. If a lexical pointeris being represented, this field indicates which word forms in the source and targetsynsets the pointer pertains to. For a semantic pointer, this field is 0.Retrieving Lexical InformationIn order to give a user access to information in the database, an interface is required.Interfaces enable end users to retrieve the lexical data and display it via a windowbasedtool or the command line. When considering the role of the interface, it is important torecognize the difference between a printed dictionary and a lexical database. WordNetsinterface software creates its responses to a users requests on the fly. Unlike an onlineversion of a printed dictionary, where information is stored in a fixed format anddisplayed on demand, WordNets information is stored in a format that would bemeaningless to an ordinary reader. The interface provides a user with a variety of waysto retrieve and display lexical information. Different interfaces can be created to servethe purposes of different users, but all of them will draw on the same underlying lexicaldatabase, and may use the same software functions that interface to the database files.User interfaces to WordNet can take on many forms. The standard interface is an XWindows application, which has been ported to several computer platforms. MicrosoftWindows and Macintosh interfaces have also been written. An alternative command line 72 interface allows the user to retrieve the same data, with exactly the same output as thewindowbased interfaces, although the specification of the retrieval criteria is morecumbersome, and the whole effect is less impressive. Nevertheless, the command lineinterface is useful because some users do not have access to windowing environments.Shell scripts and other programs can also be written around the command line interface.The search process is the same regardless of the type of search requested. The firststep is to retrieve the index entry located in the appropriate index file. This will contain alist of addresses of the synsets in the data file in which the word appears. Then each ofthe synsets in the data file is searched for the requested information, which is retrievedand formatted for output. Searching is complicated by the fact that each synsetcontaining the search word also contains pointers to other synsets in the data file that mayneed to be retrieved and displayed, depending on the search type. For example, eachsynset in the hypernymic pathway points to the next synset in the hierarchy. If a userrequests a recursive search on hypernyms a recursive retrieval process is repeated until asynset is encountered that contains no further pointers.The user interfaces to WordNet and other software tools rely upon a library offunctions that interface to the database files. A fairly comprehensive set of functions isprovided they perform searches and retrievals, morphology, and various other utilityfunctions. Appendix C contains a brief description of these functions. The structured,flexible design of the library provides a simple programming interface to the WordNetdatabase. Lowlevel, complex, and utility functions are included. The user interfacesoftware depends upon the more complex functions to perform the actual data retrievaland formatting of the search results for display to the user. Lowlevel functions providebasic access to the lexical data in the index and data files, while shielding theprogrammer from the details of opening files, reading files, and parsing a line of data.These functions return the requested information in a data structure that can beinterpreted and used as required by the application. Utility functions allow simplemanipulations of the search strings.The basic searching function, findtheinfo, receives as its input arguments a wordform, syntactic category, and search type findtheinfo calls a lowlevel function to findthe corresponding entry in the index file, and for each sense calls the appropriate functionto trace the pointer corresponding to the search type. Most traces are done with thefunction traceptrs, but specialized functions exist for search types which do notconform to the standard hierarchical search. As a synset is retrieved from the database, itis formatted as required by the search type into a large output buffer. The resultingbuffer, containing all of the formatted synsets for all of the senses of the search word, isreturned to the caller. The calling function simply has to print the buffer returned fromfindtheinfo.This general search and retrieval algorithm is used in several different ways toimplement the user interfaces to WordNet. Search types vary by syntactic category butcorrespond to the relational pointers listed in Table 2. Hierarchical searches may beperformed on all relational pointers except for antonyms and also see. In addition, acall to findtheinfo may retrieve polysemy information, verb sentence frames, or noun 73 coordinate terms those with the same hypernym as the search string.The searching function does not perform morphological operations therefore callsto findtheinfo are made from within a loop that calls morphstr to translate the searchstring into one or more base forms before calling the searching function.X Windows InterfaceAn attempt is made here to give the reader an idea of the look and feel of the XWindows interface to the WordNet database. The Microsoft Windows and Macintoshinterfaces are very similar. The command line interface provides the same functions, butthe user must specify the search string and search type, as well as other options, on thecommand line. The command line interface allows multiple searches on a search stringwith a single command, but a separate command line must be constructed for each searchword.The command xwn runs the xwordnet program in the background, freeing up thewindow from which it was started for other tasks. The xwordnet window provides fullaccess to the WordNet database. The standard X Windows mouse functions are used toopen and close the xwordnet window, move the window, and change its size. Help onthe general operation of xwordnet can be obtained by pressing the middle mouse buttonwith the cursor in the top part of the window.Searching the DatabaseThe top part of the xwordnet window provides a buffer for entering a search stringand buttons corresponding to syntactic categories and options. Below this area a statusline indicates which type of search is being displayed in the large buffer below.To search the WordNet database, a user moves the cursor into the large, horizontalbox below Enter Search Word and enters a search string, followed by a carriagereturn. A single word, hyphenated word, or collocation may be entered. A highlightedbutton indicates each syntactic category in the WordNet database that contains the searchstring. If the search string is not present exactly as typed except for case, which isignored, a morphological process is applied to the search string in an attempt toautomatically generate a form that is present in WordNet. See the section on Morphyfor a discussion of this process.Holding any mouse button on a highlighted partofspeech button reveals a pulldown menu of searches specific to that syntactic category. All of the searches availablefor the search string are highlighted. The user selects a search by scrolling down with themouse until the desired search type is in reverse video, then releasing the mouse button.The retrieval is then performed and the formatted results are displayed in the lowerwindow. The status line shows the type of search that was selected.Although most searches return very quickly, the WordNet hierarchies can be quitedeep and broad, and some retrievals can take a long time. While a search is running, themouse pointer displays as a watchface when the mouse is in the upper part of the windowabove the output buffer, and the message Searching... is displayed in the output buffer. 74 By default, all of the senses found in WordNet that match the selected search aredisplayed. The search may be restricted to one or more specific senses by entering acommaseparated list of sense numbers in the Sense Number box. These numbersare used for one search only, and the box is cleared after the search is completed.OptionsThe Options menu displays a list of options that are not directly associated withWordNet searches. The Help, Textual Gloss, and Log options are toggles. Help and Logare initially Off, and Textual Gloss is initially On. An option is toggled by highlightingthe option and releasing the mouse button. The following options are available1 The Help option is used to display information that is helpful in understandingthe search results. The help information is displayed in the output buffer beforethe search results.2 Many WordNet synsets have a textual gloss which often provides anexplanation of what the synset represents. The Textual Gloss option controlsthis display.3 In addition to being viewed in the output buffer, search results may be appendedto a file. When the Log option is On, search results are appended to the filenamed when the option is displayed. By default this file is wnoutput.log. If theWNLOG environment variable is set, the filename is the value of the variablewith .log appended.4 Display license allows a user to view the WordNet copyright notice, versionnumber, and license.5 Selecting Quit exits xwordnet.OutputThe output of a WordNet search is intended to be selfexplanatory, given that theuser knows what type of search was requested. Visual cues, such as indentation torepresent levels in retrieved hierarchies, are relied upon to aide a user in interpreting theformatted search results. The complex nature of the adjective structure, unfortunately,makes for less straightforward output of retrieved adjective synsets. In an attempt toclarify the display of adjectival information, direct antonyms, which are generallyrepresented only by head synsets, are always displayed together. This allows a user todistinguish head synsets from satellite synsets, as well as different senses of a headsynset.The output of a search is displayed in the large buffer below the status line. Bothhorizontal and vertical scroll bars are used to view data that exceeds the windowsborders. The output consists of an ordinal sense number simply indicating position inthe list of senses, followed by a line with the synset that the search string is in, followedby the search results. Each line of search output is preceded by a marker and the synsetcontaining the requested information. If a search traverses more than one level of thetree, then successive lines are indented by spaces corresponding to its level in the 75 hierarchy. If a search doesnt apply to all senses of the search string, the search resultsare headed by a string such as2 of 5 senses of tableWhen Sample sentences for verb  is selected, verb frames that areacceptable for all words in a synset are preceded by the string . If a frame isacceptable for the search string only, it is preceded by the string .When an adjective is printed, its direct antonym, if it has one, is also printed inparentheses. Since adjectives can be in either head synsets, satellite synsets, or both, anyhead synsets that the word appears in are printed first, followed by all of the satellitesynsets that the word appears in, with an indication of the head synset that the adjectiveis a satellite of. When the search string is in a head synset, all of the head synsetssatellites are also displayed. The position of an adjective in relation to the noun may berestricted to the prenominal, postnominal, or predicative position. Where present, theserestrictions are noted in parentheses.When an adverb is derived from an adjective, the specific adjectival sense on whichit is based is printed, along with the relevant adjective synset. If the adjective synsetindicated is a satellite synset, then the pertinent head synset is printed following thesatellite synset.MorphyMany dictionaries hang their information on uninflected headwords withoutseparate listings for inflectional or many derivational forms of the word. In a printeddictionary, that practice causes little trouble with a few highly irregular exceptions,morphologically related words are generally similar enough in spelling to the referenceform that the eye, aided by boldface type, quickly picks them up. In an electronicdictionary, on the other hand, when an inflected form is requested, the response is likelyto be a frustrating announcement that the word is not in the database users are requiredto know the reference form of every word they want to look up. In WordNet, only baseforms of words are generally represented. In order to spare users the trouble of affixstripping, and to assist with the creation of programs that use WordNet to automaticallyprocess natural language texts, the WordNet software suite includes functions that giveWordNet some intelligence about English morphology. At the present time nomorphological processes are performed on adverbs.The WordNet morphological processing functions, Morphy, handle a wide range ofmorphological transformations. Morphy uses two types of processes to try to convert aword form into a form that is found in the WordNet database. There are lists ofinflectional endings, based on syntactic category, that can be detached from individualwords in an attempt to find a form of the word that is in WordNet. There are alsoexception lists for each syntactic category in which a search for an inflected form may bedone. Morphy tries to use these two processes in an intelligent manner to translate theword form passed to the form found in WordNet. Morphy first checks for exceptions, 76 then uses the rules of detachment.The Morphy functions are part of the WordNet library and are used by the retrievalsoftware and various applications. The primary interface function is passed a string aword form or collocation and a syntactic category. Since some words, such as axes canhave more than one base form axe and axis, Morphy is set up to work in the followingmanner. The first time that Morphy is called with a specific string, it returns a base form.For each subsequent lookup of the same string, Morphy returns an alternative base form.Whenever Morphy cannot perform a transformation, NULL is returned.Exception ListsThere is one exception list for each syntactic category except adverbs. Theexception lists contain the morphological transformations for words that are not regularand therefore cannot be processed in an algorithmic manner. Each line of an exceptionlist contains an inflected form of a word, followed by one or more base forms of theword. The list is kept in alphabetical order and a binary search is used to find words inthese lists.Single WordsIn general, single words are relatively easy to process. Morphy first looks for theword form in the exception list. If it is found, then the first base form is returned.Subsequent lookups for the same word form return alternative base forms, if present. ANULL is returned when there are no more base forms of the word.If the word is not found in the exception list corresponding to the syntactic category,then an algorithmic process that looks for a matching suffix is applied. If a matchingsuffix is found, a corresponding ending is applied, if necessary, and WordNet is consultedto see if the resulting word is found in WordNet. Refer to Table 4 for a list of suffixesand endings for each syntactic category.CollocationsAs opposed to single words, collocations can be quite challenging to transform intoa base form that is present in WordNet. In general, only base forms of words, even thosecomprising collocations such as attorney general, are stored in WordNet. Transformingthe collocation attorneys general is then simply a matter of finding the base forms of theindividual words comprising the collocation. This usually works for nouns, thereforenonconforming nouns, such as customs duty are presently entered in the noun exceptionlist a transformation on each word results in the base form custom duty, which is not inWordNet.Verb collocations that have prepositions, such as stand in line, are more difficult.As with single words, the exception list is searched first. If the collocation is not found,special code in Morphy determines whether a verb collocation has a preposition in it. Ifit does, the following process is applied to try to find the base form. It is assumed thatthe first word in the collocation is a verb and that the last word is a noun. The algorithmthen builds a search string with the base forms of the verb and noun, leaving the 77 Morphy Suffixes and Endings Noun Verb Adjective                                                   Sufffix Ending Suffix Ending Suffix Ending s s erses s ies y estxes x es e er ezes z es est eches ch ed eshes sh eding eing Table 4remainder of the collocation usually just the preposition, but more words may beinvolved in the middle. For example, passed standing in lines, the database searchwould be performed with stand in line, which is found in WordNet, and thereforereturned from Morphy. If a verb collocation does not contain a preposition, then the baseform of each word in the collocation is found and WordNet is searched for the resultingstring.HyphenationHyphenation also presents special difficulties when searching WordNet. It is oftena subjective determination whether a word is hyphenated, is closed up, or is a collocationof several words, and which of the various forms are entered into WordNet. WhenMorphy breaks a string into words, it looks for both spaces and hyphens as delimiters.Future WorkSince many noun collocations contains prepositions, such as line of products, analgorithm similar to that used for verbs should be written for nouns. In the presentscheme, if Morphy is passed lines of products, the search string becomes line of product,which is not in WordNet. Morphy should also be able to work in both directions when passed a base form, it should be possible to obtain inflected forms of the word. 78 Appendix ALexicographers Filesnoun.Tops unique beginners for nounsnoun.act nouns denoting acts or actionsnoun.animal nouns denoting animalsnoun.artifact nouns denoting manmade objectsnoun.attribute nouns denoting attributes of people and objectsnoun.body nouns denoting body partsnoun.cognition nouns denoting cognitive processes and contentsnoun.communication nouns denoting communicative processes andcontentsnoun.event nouns denoting natural eventsnoun.feeling nouns denoting feelings and emotionsnoun.food nouns denoting foods and drinksnoun.group nouns denoting groupings of people or objectsnoun.location nouns denoting spatial positionnoun.motive nouns denoting goalsnoun.object nouns denoting natural objects not manmadenoun.person nouns denoting peoplenoun.phenomenon nouns denoting natural phenomenanoun.plant nouns denoting plantsnoun.possession nouns denoting possession and transfer of possessionnoun.process nouns denoting natural processesnoun.quantity nouns denoting quantities and units of measurenoun.relation nouns denoting relations between people or things orideasnoun.shape nouns denoting two and three dimensional shapesnoun.state nouns denoting stable states of affairsnoun.substance nouns denoting substancesnoun.time nouns denoting time and temporal relations 79 verb.body verbs of grooming, dressing and bodily careverb.change verbs of change of size, temperature, intensity, etc.verb.cognition verbs of thinking, judging, analyzing, doubting, etc.verb.communication verbs of telling, asking, ordering, singing, etc.verb.competition verbs of fighting, athletic activities, etc.verb.consumption verbs of eating and drinkingverb.contact verbs of touching, hitting, tying, digging, etc.verb.creation verbs of sewing, baking, painting, performing, etc.verb.emotion verbs of feelingverb.motion verbs of walking, flying, swimming, etc.verb.perception verbs of seeing, hearing, feeling, etc.verb.possession verbs of buying, selling, owning, and transferverb.social verbs of political and social activities and eventsverb.stative verbs of being, having, spatial relationsverb.weather verbs of raining, snowing, thawing, thundering, etc.adj.all all adjective clustersadj.pert relational adjectives pertainymsadv.all all adverbs 80 Appendix BVerb Sentence Frames1 Something s2 Somebody s3 It is ing4 Something is ing PP5 Something s something AdjectiveNoun6 Something s AdjectiveNoun7 Somebody s Adjective8 Somebody s something9 Somebody s somebody10 Something s somebody11 Something s something12 Something s to somebody13 Somebody s on something14 Somebody s somebody something15 Somebody s something to somebody16 Somebody s something from somebody17 Somebody s somebody with something18 Somebody s somebody of something19 Somebody s something on somebody20 Somebody s somebody PP21 Somebody s something PP22 Somebody s PP23 Somebodys body part s24 Somebody s somebody to INFINITIVE25 Somebody s somebody INFINITIVE26 Somebody s that CLAUSE27 Somebody s to somebody28 Somebody s to INFINITIVE29 Somebody s whether INFINITIVE30 Somebody s somebody into Ving something31 Somebody s something with something32 Somebody s INFINITIVE33 Somebody s VERBing34 It s that CLAUSE35 Something s INFINITIVE 81 Appendix CLibrary Functions Function Name Input Arguments Process Performed Information Returned findtheinfo word Search of database Formatted search resultsfindtheinfods syntactic category in buffer or data structuresearch typesense number traceptrs synset structure Trace pointer hierarchy and None or datatraceptrsds pointer type place formatted synsets in structuresyntactic category output buffer or datadepth structure                                                                                            tracecoords see traceptrs Trace coordinate terms None traceinherit see traceptrs Trace meronyms None traceadjant synset structure Trace adjective antonyms None isdefined word Find all possible searches Bit mask with one bit setsyntactic category for word for each possible search type indexlookup word Find word in index file Data structure for index entrygetindex syntactic category readsynset syntactic category Read synset from data file Data structure for synsetoffsetword freesyns synset list pointer Free synsets from findtheinfods None morphstr word Morphology on collocation or Base form of word ormorphword syntactic category single word NULL if none wninit None Initialize library functions None binsearch word Binary search algorithm Line from file containing wordfile descriptor or NULL if not found cntwords collocation Count number of words in string Integer number ofchar separated by char words in collocation strtolower string Convert string to lower case Lower case string, ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,strsubst string Replace all occurrences of Modified stringfrom char from with to in stringto char getptrtype pointer name Convert string to pointer type Integer pointer type. ...........................................................................................getpos string Convert string to syntactic category Integer syntactic category getsstype string Convert string to synstet type Integer synset type0 00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111 82 ReferencesAronoff, M. 1976. Word Formation in Generative Grammar. Cambridge, Mass. MITPress.Austin, J. L. 1962. How to Do Things with Words. Oxford Clarendon Press.Bartning, Inge. 1980. Syntaxe et semantique des pseudoadjectifs franc,ais. StockholmAlmqvist and Wiksell.Beckwith, R., Fellbaum, C., Gross, D., and Miller, G. A. in press. WordNet ALexical Database Organized on Psycholinguistic Principles in Zernik, U. ed..Using Online Resources to Build a Lexicon. Hillsdale, N.J. Erlbaum.Berlin, B., Breedlove, D., and Raven, P. H. 1966. Folk Taxonomies and BiologicalClassification. Science 154 273275.Berlin, B., Breedlove, D., and Raven, P. H. 1973. General Principles of Classificationand Nomenclature in Folk Biology. American Anthropologist 75 214242.Berlin, B., and Kay, P. 1969. Basic Color Terms Their Universality and Evolution.Berkeley and Los Angeles University of California Press.Bever, T. G., and Rosenbaum, P. S. 1970. Some Lexical Structures and TheirEmpirical Validity in Jacobs, R. A., and Rosenbaum, P. S. eds.. Readings inEnglish Transformational Grammar. Waltham, Mass. Ginn.Bierwisch, M. 1967. Some Semantic Universals of German Adjectives. Foundationsof Language 3 136.Bierwisch, M. 1989. The Semantics of Gradation in Bierwisch, M., and Lang, E. eds..Dimensional Adjectives Grammatical Structure and Conceptual Interpretation.Berlin SpringerVerlag.Bolinger, Dwight. 1967. Adjectives in English attribution and predication. Lingua18.134.Calzolari, N. 1988. The Dictionary and the Thesaurus Can Be Combined in Evens, M.ed., Relational Models of the Lexicon Representing Knowledge in SemanticNetworks. Cambridge Cambridge University Press.Caramazza, A., and Berndt, R. S. 1978. Semantic and Syntactic Processes in AphasiaA Review of the Literature. Psychological Bulletin 85 898918.Carnap, R. 1947. Meaning and Necessity. Chicago University of Chicago Press.Carter, R. 1976. Some Constraints on Possible Words. Semantikos 1 2766.Chafe, W. 1970. Meaning and the Structure of Language. Chicago University ofChicago Press.Chaffin, R., Hermann, D. J., and Winston, M. 1988. An Empirical Taxonomy ofPartWhole Relations Effects of PartWhole Relation Type on RelationIdentification. Language and Cognitive Processes 3 1748.Charles, W. G., and Miller, G. A. 1989. Contexts of Antonymous Adjectives.Applied Psycholinguistics 10 357375.Chomsky, N. 1972. Studies on Semantics in Generative Grammar. The Hague Mouton.Chomsky, N. 1977. Deep Structure, Surface Structure, and Semantic Interpretation inSteinberg, D., and Jakobovits, L. eds. Semantics An Interdisciplinary Reader. 83 Cambridge Cambridge University Press.Cliff, N. 1959. Adverbs as Multipliers. Psychological Review 66 2744.Collins, A. M., and Quillian, M. R. 1969. Retrieval Time From Semantic Memory.Journal of Verbal Behavior and Verbal Learning 8 240247.Conrad, C. 1972. Cognitive Economy in Semantic Memory. Journal of ExperimentalPsychology 55 7584.Cruse, D. A. 1986. Lexical Semantics. New York Cambridge University Press.Deese, J. 1964. The Associative Structure of Some English Adjectives. Journal ofVerbal Learning and Verbal Behavior 3 347357.Deese, J. 1965. The Structure of Associations in Language and Thought. BaltimoreJohns Hopkins Press.Dowty, D. 1979. Word Meaning and Montague Grammar. Dordrecht Reidel.Dunker, K. 1945. On Problem Solving. Psychological Monographs, 58 Whole No.270.Fahlman, S. E. 1979. NETL A System for Representing and Using RealWorldKnowledge. Cambridge, Mass. MIT Press.the Organization of Verbs in the Mental Lexicon. In Proceedings of the 12th AnnualConference of the Cognitive Science Society. Hillsdale, NJ Erlbaum.Fellbaum, C., and Kegl, J. 1988. Taxonomic Hierarchies in the Verb Lexicon.Presented at the EURALEX Third International Congress, Budapest, Hungary.Fellbaum, C., and Kegl, J. 1989. Taxonomic Structures and CrossCategory Linking inthe Lexicon in de Jong, K., and No, Y. eds.. Proceedings of the Sixth EasternState Conference on Linguistics. Columbus, Ohio Ohio State UniversityFellbaum, C., and Miller, G. A. in press. Folk Psychology or Semantic EntailmentA Reply to Rips and Conrad. Psychological Review.Fillenbaum, S., and Jones, L. V. 1965. Grammatical Contingencies in WordAssociation. Journal of Verbal Learning and Verbal Behavior 4 248255.Fillmore, C. J. 1968. The Case for Case in Bach, E., and Harms, R. eds.. Universalsin Linguistic Theory. New York Holt, Reinhart, and Winston.Fillmore, C. J. 1986. Pragmatically Controlled Zero Anaphora in Proceedings of theTwelfth Annual Meeting of the Berkeley Linguistics Society.Fodor, J. 1970. Three Reasons for Not Deriving Kill From Cause To Die. Linguistic Inquiry 1 429438.Francis, W. N., and Kucvera, H. 1982. Frequency Analysis of English Usage Lexiconand Grammar. Boston Houghton Mifflin.Gardner, H. 1973. The Contribution of Operativity to Naming Capacity in AphasicPatients. Neuropsychologia 11 213220.Garrett, M. F. 1982. Production of Speech Observations from Normal andPathological Language Use in A. Ellis ed.. Normality and Pathology in CognitiveFunctions. London Academic Press.Gentner, D., and France, I. 1988. The Verb Mutability Effect Studies of theCombinatorial Semantics of Nouns and Verbs in Small, S., Cottrell, G., andTanenhaus, M. eds.. Lexical Ambiguity Resolution. Los Altos, Calif. MorganKaufmann. 84 Gibson, J. J. 1979. The Ecological Approach to Visual Perception. Boston HoughtonMifflin.Gleitman, L. 1990. The Structural Sources of Verb Meanings. Language Acquisition1 155.Gross, D., Fischer, U., and Miller, G. A. 1989. The Organization of AdjectivalMeanings. Journal of Memory and Language 28 92106.Gross, D., Kegl, J., Gildea, P., and Miller, G. A. 1989. A Coded Corpus andCommentary on Childrens Dictionary Strategies. Princeton, N.J. CognitiveScience Laboratory Report 39.Gruber, J. 1976. Lexical Structures in Syntax and Semantics. New York NorthHolland.Heider, E. R. 1972. Universals in Color Naming and Memory. Journal ofExperimental Psychology 93 1020.Heider, E. R., and Olivier, D. C. 1972. The Structure of Color Space in Naming andMemory for Two Languages. Cognitive Psychology 3 337354.Hoffmann, J., and Ziessler, C. 1983. Objektidentifikation in ku..nstlichenBegriffshierarchien. Zeitschrift fu..r Psychologie 191 135167.Horn, L. 1989. Morphology, Pragmatics, and the un Verb in Powers, J., and de Jong,K. eds.. Proceedings of the Fifth Eastern State Conference on Linguistics.Columbus, Ohio Ohio State University.Jackendoff, R. S. 1972. Semantic Interpretation in Generative Grammar. Cambridge,Mass. MIT Press.Jackendoff, R. S. 1976. Toward an Explanatory Semantic Representation. LinguisticInquiry 7 89150.Jackendoff, R. S. 1983. Semantics and Cognition. Cambridge, Mass. MIT Press.Jastrezembski, J. E. 1981. Multiple Meanings, Number of Related Meanings,Frequency of Occurrence, and the Lexicon. Cognitive Psychology 13 278305.JohnsonLaird, P. N., and Oatley, K. 1989. The Language of Emotion An Analysis ofa Semantic Field. Cognition and Emotion 3 81123.Justeson, John S., and Katz, Slava M. 1991a. Cooccurrences of AntonymousAdjectives and Their Contexts. Computational Linguistics 17.119.Justeson, John S., and Katz, Slava M. 1991b. Redefining Antonymy The TextualStructure of a Semantic Relation. Proceedings of the Seventh Annual Conference ofthe UW Centre for the New OED, 138154. Waterloo, Canada.Justeson, Johm S., and Katz, Slava, M. 1993. Principled DisambiguationDiscriminating Adjective Senses with Modified Nouns. Ms., IBM T. WatsonResearch Center, Yorktown Heights, NY.Katz, J. J. 1964. Semantic Theory and the Meaning of Good. Journal ofPhilosophy 61 739766.Katz, J. J. 1972. Semantic Theory. New York Harper and Row.Katz, J. J., and Fodor, J. 1963. The Structure of a Semantic Theory. Language 39170210.Keil, F. C. 1979. Semantic and Conceptual Development An Ontological Perspective.Cambridge, Mass. Harvard University Press. 85 Keil, F. C. 1983. On the Emergence of Semantic and Conceptual Distinctions.Journal of Experimental Psychology General 112 357385.Kempson, R. 1977. Semantic Theory. Cambridge Cambridge University Press.Lakoff, G. 1970. Irregularity in Syntax. New York Holt, Reinhart, and Winston.Levi, J. N. 1978. The Syntax and Semantics of Complex Nominals. New YorkAcademic Press.Levin, B. 1985. Introduction in Levin, B. ed.. Lexical Semantics in Review.Cambridge, Mass. Center for Cognitive Science, MIT.Levin, B. 1989. Towards a Lexical Organization of English Verbs. Ms., EvanstonNorthwestern University.Lyons, J. 1977. Semantics. 2 vols. New York Cambridge University Press.Marchand, H. 1969. The Categories and Types of PresentDay English WordFormation, 2nd ed. Munich C. H. Beck.McCawley, J. D. 1968. Lexical Insertion in a Transformational Grammar WithoutDeep Structure in Darden, B. J., Bailey, CJ. N., and Davison, A. eds.. Papersfrom the fourth regional meeting, Chicago Linguistic Society. Chicago, Ill.Department of Linguistics, University of Chicago. Pp. 7180.Miller, G. A. 1985. Wordnet A Dictionary Browser in Information in Data,Proceedings of the First Conference of the UW Centre for the New OxfordDictionary. Waterloo, Canada University of Waterloo.Miller, G. A. 1986. Dictionaries in the Mind. Language and Cognitive Processes 1171185.Miller, G. A. in press. Lexical Echoes of Perceptual Structure in The Perception ofStructure, in honor of W. R. Garner. Washington, DC American PsychologicalAssociation.Miller, G. A., and Charles, W. in press. Contextual Correlates of SemanticSimilarity. Language and Cognitive Processes.Miller, G. A., and Fellbaum, C. submitted. Semantic Networks of English.Cognition.Miller, G. A., and Gildea, P. M. 1987. How Children Learn Words. ScientificAmerican 257 No. 3 9499.Mittwoch, A. 1982. On the Difference Between Eating and Eating SomethingActivities vs. Accomplishments. Linguistic Inquiry 13 113122.A New Dictionary Compiled on Historical Principles. 1928. Oxford Oxford UniversityPress. OED.Murphy, Gregory L., and Andrew, Jane M. 1993. The Conceptual Basis ofAntonymy and Synonymy in Adjectives. Journal of Memory and Language32.301319.Osgood, C. E., Suci, G. J., and Tannenbaum, P. H. 1957. The Measurement ofMeaning. Urbana, Ill. University of Illinois Press.Pinker, S. 1989. Learnability and Cognition The Acquisition of Argument Structure.Cambridge, Mass. MIT Press.Quillian, M. R. 1967. Word Concepts A Theory and Simulation of Some BasicSemantic Capabilities. Behavioral Science 12 410430. 86 Quillian, M. R. 1968. Semantic Memory. In Minsky, M. ed.. Semantic InformationProcessing. Cambridge, Mass. MIT Press.Rips, L., and Conrad, F. 1989. Folk Psychology of Mental Activities. PsychologicalReview 96 187207.Rogets International Thesaurus, 4th ed. 1977. New York Harper and Row.Rosch, E. 1975. Cognitive Representations of Semantic Categories. Journal ofExperimental Psychology, 104 192233.Rosch, E., Mervis, C. B., Gray, W., Johnson, D., and BoyesBraem, P. 1976. BasicObjects in Natural Categories. Cognitive Psychology 8 382439.Sapir, E. 1944. Grading A Study in Semantics. Philosophy of Science 11 83116.Schachter, P. 1985. PartsofSpeech Systems. In Shopen, T., ed.. LanguageTypology and Syntactic Description, vol. 1. Cambridge Cambridge UniversityPress.Schank, R. C. 1972. Conceptual Dependency A Theory of Natural LanguageUnderstanding. Cognitive psychology 3 552631.Schank, R. C., and Abelson, R. 1977. Scripts, Goals, Plans, and Understanding.Hillsdale, NJ Erlbaum.Shibatani, M. 1972. Three Reasons for Not Deriving Kill From Cause to Die inJapanese in Kimball, J. ed.. Syntax and Semantics, vol.1. New York AcademicPress.Smith, E. E. 1978. Theories of Semantic Memory. In Estes, W. K. ed.. Handbookof Learning and Cognitive Processes, vol. 5. Hillsdale, NJ Erlbaum.The Synonym Finder. 1978. Emmaus, Pa. Rodale Press.Talmy, L. 1985. Lexicalization Patterns Semantic Structure in Lexical Forms inShopen, T. ed.. Language Typology and Syntactic Description, vol. 3. CambridgeCambridge University Press.Thorndike, E. L., and Lorge, I. 1944. The Teachers Word Book of 30,000 Words.New York Bureau of Publications, Columbia University.Touretzky, D. S. 1986. The Mathematics of Inheritance Systems. Los Altos, Calif.Morgan Kaufmann.Tversky, B., and Hemenway, K. 1984. Objects, Parts, and Categories. Journal ofExperimental Psychology General 113 169193.Vizetelly, F. H. 1915. The Development of the Dictionary of the English Language.New York Funk and Wagnalls.Wierzbicka, A. 1984. Apples are Not a Kind of Fruit.  American Ethnologist 11313328.Wilkins, A. J. 1971. Conjoint Frequency, Category Size, and Categorization Time.Journal of Verbal Learning and Verbal Behavior 10 382385.Winston, M. E., Chaffin, R., and Hermann, D. J. 1987. A Taxonomy of PartWholeRelations. Cognitive Science 11 417444.Zipf, G. K. 1945. The MeaningFrequency Relationship of Words. Journal of GeneralPsychology 33 251256.
