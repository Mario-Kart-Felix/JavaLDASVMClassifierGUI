A Model of Multimedia Information RetrievalCARLO MEGHINI, FABRIZIO SEBASTIANI, AND UMBERTO STRACCIAConsiglio Nazionale delle Ricerche, Pisa, ItalyAbstract. Research on multimedia information retrieval MIR has recently witnessed a boominginterest. A prominent feature of this research trend is its simultaneous but independent materializationwithin several fields of computer science. The resulting richness of paradigms, methods and systemsmay, on the long run, result in a fragmentation of efforts and slow down progress. The primary goal ofthis study is to promote an integration of methods and techniques for MIR by contributing a conceptualmodel that encompasses in a unified and coherent perspective the many efforts that are being producedunder the label of MIR. The model offers a retrieval capability that spans two media, text and images,but also several dimensions form, content and structure. In this way, it reconciles similaritybasedmethods with semanticsbased ones, providing the guidelines for the design of systems that are ableto provide a generalized multimedia retrieval service, in which the existing forms of retrieval not onlycoexist, but can be combined in any desired manner. The model is formulated in terms of a fuzzydescription logic, which plays a twofold role 1 it directly models semanticsbased retrieval, and2 it offers an ideal framework for the integration of the multimedia and multidimensional aspectsof retrieval mentioned above. The model also accounts for relevance feedback in both text and imageretrieval, integrating known techniques for taking into account user judgments. The implementation ofthe model is addressed by presenting a decomposition technique that reduces query evaluation to theprocessing of simpler requests, each of which can be solved by means of widely known methods fortext and image retrieval, and semantic processing. A prototype for multidimensional image retrievalis presented that shows this decomposition technique at work in a significant case.Categories and Subject Descriptors H.3.3 Information Storage and Retrieval Information Search and Retrievalquery formulation relevance feedback retrieval models I.2.4 Artificial Intelligence Knowledge Representation Formalisms and Methodsrepresentation languages I.4.10Image Processing and Computer Vision Image RepresentationmultidimensionalGeneral Terms Design, Languages, TheoryAdditional Key Words and Phrases Description logics, fuzzy logics, multimedia information retrieval1. IntroductionThe central concern of multimedia information retrieval MIR is easily statedgiven a collection of multimedia documents i.e., a complex information object,with components of different kinds, such as text, images, video and sound, allin digital form, find those that are relevant to information need of the user. AnPartial support from the European Union was kindly provided under the MIRO Working Groupn. 6175 and the FERMI Action n. 8134, both part of the ESPRIT Basic Research Programme. Wethank our teammates in these two actions for the many stimulating discussions.Authors address Istituto di Elaborazione dellInformazione, Consiglo Nazionale delle Ricershe, ViaSiuseppe Moruzzi 1  56124 Pisa, Italy, email meghini, fabrizio, stracciaiei.pi.cnr.it.Permission to make digitalhard copy of part or all of this work for personal or classroom use isgranted without fee provided that the copies are not made or distributed for profit or commercialadvantage, the copyright notice, the title of the publication, and its date appear, and notice is giventhat copying is by permission of the ACM, Inc. To copy otherwise, to republish, to post on servers,or to redistribute to lists, requires prior specific permission andor a fee.C 2001 ACM 000454110109000909 5.00Journal of the ACM, Vol. 48, No. 5, September 2001, pp. 909970.910 C. MEGHINI ET AL.evergrowing amount of people are accessing collections of such documents everyday in order to satisfy the most disparate information needs. Indeed, the numberand types of multimedia information providers are steadily increasing Currently,it includes publishing houses cultural, scientific and academic institutions cinemaand TV studios as well as commercial enterprises offering their catalogs online.The potential users of the provided information range from highly skilled specialists to laymen. All these users share the same expectation to be able to retrieve thedocuments that are relevant to their information needs. While commercial products offering generalized MIR are still to come, research on MIR has witnessed abooming interest during the last years. The most striking feature of this researchis its simultaneous but independent materialization within several fields of computer science. To mention only the main streams, there has been work on MIRcarried out within the multimedia, the information retrieval, the digital signal processing, and the database communities, while significant signs of interests may beobserved in other sectors, notably artificial intelligence. This also reveals that thereare many different aspects involved in MIR, each requiring a specific backgroundand methodology to be successfully tackled, and also that there may be complementary approaches to the same problems, not only within the same discipline suchas different index structures for multimedia data, but also across different disciplines such as similarity versus semanticbased image retrieval. Such a richnessof paradigms, methods and systems is somewhat inherent in the early stages ofdevelopment of a new discipline, when empirical studies are needed to understandthe nature of a phenomenon and try out different ways of capturing it. However, onthe long run, this very same richness may ultimately result in a fragmentation ofefforts that may slow down progress.We believe that MIR has reached the stage in which unification of the existingapproaches is called for, given that the basic concepts underlying the disciplineare understood sufficiently well. The primary goal of this study is to promote suchunification by contributing a conceptual model of MIR, which encompasses ina unified and coherent perspective the many efforts and results that are being produced under the label of MIR in the abovementioned fields.The basic feature of our model is that it captures the kinds of retrieval investigatedin the various areas of computer science mentioned above. These kinds of retrievalcan be broadly classified on the basis of the aspect of documents that each of themaddresses. Thus, we have retrieval based on syntactic similarity, on semantics, onstructure, and on profile. This categorization is indicative of the method that wehave followed in deriving our view of MIR. Rather than proceeding from the bottomup by connecting together existing models, our approach has been a topdown one,since it models the various forms of retrieval as the projections of a basic operationon the different dimensions that make up the structure of the information space.For better clarity, our conceptual model will be specified both at the informal andat the formal level, by letting each introduced notion be followed by a correspondingdefinition in a suitable formalism. The formalism we have chosen is mathematical logic. The rationale of this choice lies primarily in the fact that mathematicallogic has proven most successful in capturing the essential nature of informationsystems, and a MIR system, as it is to be expected, is no exception. The particular logic we adopt is Description Logic DL. DLs are a family of contractionsof the predicate calculus that, in the recent past, have been subject to thoroughinvestigations both from the logical and the computational viewpoint. In choosingA Model of Multimedia Information Retrieval 911a specific DL, we have been guided by the need, typical of information modelling, of finding a formalism that represents a good compromise between expressive power and the computational complexity of the reasoning problems involvedin MIR.Besides the foundational goal pointed out above, the aim of the present study isto bring concrete benefits to various players in the MIR arena. In particularTo the designers of MIR systems, the model provides guidelines for the designof systems that are able to provide a generalized retrieval service, in whichthe existing forms of retrieval not only coexist, but can be combined in anydesired manner. This feature places our model beyond the current state of the art.Following these guidelines, and using an appropriate tool that implements themodel, a designer can quickly build a prototype of the system to be developed,and use such prototype to test its adequacy to the users functional requirements.We have prototyped a significant portion of such a tool, as illustrated later inthis paper.To users of MIR systems, the model is a tool for an effective communicationwith the application designers, enabling them to state precisely what they expectfrom the system. To this end, the model provides a terminology that is at thesame time rigorous and shared with the system designers. Once a prototypeof the application has been realized, the dialogue between users and designersmoves to an operational level, where the prototype is evaluated and, if necessary,refined.To researchers who offer various contributions to MIR, the model gives thepossibility to see these contributions as part of a larger endeavor. Hopefully, thiswill increase awareness of the limitations of current approaches and will stimulateimprovement by integration of complementary approaches. As a further benefitto researchers, the formal specification of the model, by viewing MIR as a specialform of implication, may be used as a basis for formal investigations on specificaspects of MIR, including extensions to the present model.The paper is structured as follows The conceptual framework underlying ourmodel, and a corresponding terminology, is laid down in Section 2, and subsequentlyused to review a significant part of related work, in Section 3. The rest of thepaper presents the technical development of the model, starting with Section 4,which concisely introduces the description logic that will constitute our main toolthroughout the paper. Sections 5 to 7 deal with the aspects of documents that ourmodel addresses for each of them, we first discuss issues related to modellingand then switch to the semantics of the related query facilities. Section 8 presentsa unified, hierarchically structured query language which brings together all theissues discussed in Sections 5 to 7. In Section 9, we deal with retrieval and showhow the degree of relevance of a document to a query may be seen in terms of thefuzzy DL that underlies both the representation and query languages. Section 10discusses the implementation of the model, and presents a general technique forquery evaluation. Relevance feedback is tackled in the following section, where itis shown how this important stage of retrieval is incorporated into the previouslypresented model. Section 12 briefly sketches the main traits of the tool that we haveimplemented to support the development of prototypical MIR systems. Section 13concludes this article.912 C. MEGHINI ET AL.2. A View of Multimedia Information RetrievalAfter settling for such ambitious goals, we limit the scope of our work to the treatment of two media text and images. These media are by far the most investigatedand therefore best understood ones, therefore they suit the foundational work we arepresenting here. Throughout the paper, it is argued that the principles that inspireour approach can also be applied to other media, such as audio and video. However,we have preferred to deal only with text and images in order to be able to discussthe relevant issues with the necessary depth, while relieving the reader from theburden of getting acquainted with a large formal lexicon.2.1. INFORMATION RETRIEVAL. The notion of information retrieval IR, forshort has much evolved from the late 50s, when it attracted significant scientificinterest in the context of textual document retrieval. Early characterizations of IRsimply relied on an objective notion of topicrelatedness of a document to aquery. Later, the essentially subjective concept of relevance gained ground, andeventually became the cornerstone of IR Saracevic 1975. Nowadays, everybodyin the IR community would agree that IR is synonymous with determination ofrelevance. Unfortunately, relevance is itself a vaguely defined concept. In quitea different context, philosophers of language Anderson and Belnap 1975 andcognitive scientists Sperber and Wilson 1986 have proposed alternative characterizations of this notion, all making the subject a controversial one. Not surprisinglythen, the debate on what relevance may mean in the context of IR is still opena recent account of such a debate can be found in Mizzaro 1997.In the meantime, the area of multimedia documents came into existence anddemanded an IR functionality that no classical method was able to answer, dueto the medium mismatch problem in the image database field, this is often calledthe medium clash problem. This problem refers to the fact that, when documentsand queries are expressed in different media, matching is difficult, as there is aninherent intermediate mapping process that needs to reformulate the concepts expressed in the medium used for queries e.g., text in terms of the other mediume.g., images. In response to this demand, a wide range of methods for achieving IR on multimedia documents has been produced, often based on techniqueslargely foreign to the IR field. Our basic motivation in conducting the researchpresented here is that a reconciliation between these new developments and traditional IR is needed, in order to foster crossfertilization and promote the development of a more mature technology, able to enhance the respective approaches viatheir integration.As a first step towards this reconciliation, we now propose a general definitionof IR that preserves the meaning underlying the tradition, while being consistentwith new developments in multimedia. We regard information retrieval as the taskof identifying documents in a collection on the basis of properties ascribed to thedocuments by the user requesting the retrieval. That is, a document d is to beretrieved in response to a request r issued by a certain user if and only if that userwould recognize d as having the property expressed by r. The many different typesof retrieval that can be envisaged on a multimedia document can then be seen asspecial cases of the operation just defined, via an appropriate categorization of theproperties that may be ascribed to a document. This categorization is outlined inthe next section.A Model of Multimedia Information Retrieval 9132.2. DIMENSIONS OF MULTIMEDIA DOCUMENTS. We call a document simpleif it cannot be further decomposed into other documents. In the present context,images and pieces of text are the only simple documents. A simple document isan arrangement of symbols that carry information via meaning, thus concurring informing what is called the content of the document. In the case of text, the symbolsare words or their semantically significant fractions, such as stems, prefixes orsuffixes, whereas for images the symbols are colors and textures.We thus characterize simple documents as having two parallel dimensions, thatof form or syntax, or symbol and that of content or semantics, or meaning. Aswe have just remarked, the form of a simple document is dependent on the mediumthat carries the document. On the contrary, we take the content dimension to bemediumindependent, as we assume an objective view of meaning the meaning ofa simple document is the set of states of affairs or worlds in which it is true. Forinstance, the meaning of a piece of text is the set of spatiotemporally determinedstates of affairs in which the assertions made are true, and the meaning of animage is the set of such states of affairs in which the scene portrayed in the imageindeed occurs.Complex documents or simply documents are structured sets of simple documents. This leads to the identification of structure as the third dimension of ourcharacterization of documents. For the sake of simplicity, we assume the structureof documents to be hierarchical, but this is no serious limitation, as extensions toother structures are well known and can be included in this framework without anymajor conceptual shift. Note that this notion of structure only applies to complexdocuments and should not be confused with the notion of structure that is embodiedin the syntax of simple documents, such as the structure of an image as the particulararrangement of color regions that the image exhibits.Finally, documents, whether simple or complex, exist as independent entitiescharacterized by metaattributes often called metadata in the recent literature ondigital libraries, which describe the relevant properties of such entities. The set ofsuch attributes is usually called the profile of a document, and constitutes the fourthand last document dimension that our model considers.Corresponding to the four dimensions of documents just introduced, there canbe four categories of retrieval, each one being a projection of the general notionof retrieval defined in Section 2.1 onto a specific dimension. The usefulness ofretrieval based on document structure or profile mostly lies in the possibility ofusing these categories of retrieval in conjunction with the other categories, whichare discussed in the following section.2.3. FORM AND CONTENTBASED MULTIMEDIA INFORMATION RETRIEVAL.The retrieval of information based on form addresses the syntactic properties ofdocuments. In particular, formbased retrieval methods automatically create thedocument representations to be used in retrieval by extracting lowlevel featuresfrom documents, such as the number of occurrences of a certain word in a text,or the energy level in a certain region of an image. The resulting representationsare abstractions which retain that part of the information originally present in thedocument that is considered sufficient to characterize the document for retrievalpurposes. User queries to formbased retrieval engines may be documents themselves this is especially true in the nontextual case, as this allows to overcome the914 C. MEGHINI ET AL.medium mismatch problem, from which the system builds abstractions analogousto those of documents. Document and query abstractions are then compared by anappropriate function, aiming at assessing their degree of relatedness. A documentranking results from these comparisons, in which the documents with the highestscores occur first.In the case of text, formbased retrieval includes most of the traditional IR methods, ranging from simple string matching as used in popular Web search enginesto the classical tfidf term weighting method, to the most sophisticated algorithmsfor similarity measurement. Some of these methods make use of information structures, such as thesauri, for increasing retrieval effectiveness Schauble and Knaus1992 however, what makes them formbased retrieval methods is their relying ona fully automatic indexing. In the case of images, formbased retrieval includes allsimilaritybased image retrieval methods, such as those employed by system likeQBIC Faloutsos et al. 1994 or VIRAGE Bach et al. 1996.On the contrary, semanticbased retrieval methods rely on symbolic representations of the meaning of documents, that is descriptions formulated in some suitableknowledge representation language, spelling out the truth conditions of the involveddocument. Various languages have been employed to this end, ranging from netbased to logical. Retrieval by reasoning on the spatial relationships between imageobjects see, e.g., Gudivada and Raghavan 1995a falls under this category. Forreasons of space, this kind of retrieval is not dealt with in this paper. However,integration of spatial retrieval in the present framework can be accomplished as illustrated in Aiello et al. 1999. Typically, meaning representations are constructedmanually, perhaps with the assistance of some automatic tool as a consequence,their usage on text in not viable because of the remarkable size up to millions ofdocuments that collections of textual documents may reach.While semanticbased methods explicitly apply when a connection in meaningbetween documents and queries is sought, the status of formbased methods is,in this sense, ambiguous. On one hand, these methods may be viewed as patternrecognition tools that assist an information seeker by providing associative accessto a collection of signals. On the other hand, formbased methods may be viewedas an alternative way to approach the same problem addressed by semanticbasedmethods, that is deciding relevance, in the sense of connection in meaning, betweendocuments and queries. This latter, much more ambitious view, can be justified onlyby relying on the assumption that there be a systematic correlation between sameness in lowlevel signal features and sameness in meaning. Establishing thesystematic correlation between the expressions of a language and their meaning isprecisely the goal of a theory of meaning see, e.g., Davidson 1994, a subject ofthe philosophy of language that is still controversial, at least as far as the meaning of natural languages is concerned. So, pushed to its extreme consequences,the ambitious view of formbased retrieval leads to viewing a MIR system as analgorithmic simulation of a theory of meaning, in force of the fact that the samenessassumption is relied upon in every circumstance, not just in the few, happy casesin which everybodys intuition would bet on its truth. At present, this assumptionseems more warranted in the case of text than in the case of nontextual media, asthe representations employed by formbased textual retrieval methods i.e., vectors of weighted words come much closer to a semantic representation than thefeature vectors employed by similaritybased image retrieval methods. Anyway,irrespectively of the tenability of the sameness assumption, the identification of theA Model of Multimedia Information Retrieval 915alleged syntacticsemantic correlation is at the moment a remote possibility, so wesubscribe to the weaker view of formbased retrieval and present a model wherethis is just one of the possible ways to access multimedia information.3. Related WorkA model of structured multimedia documents finalized to retrieval is proposedin Ounis and Chevallet 1996 and subsequently used for building the PRIME information retrieval system Berrut et al. 1998. Although subscribing to the logicalview of information retrieval, this model is indeed expressed in terms of Sowas1984 conceptual graphs. This fact makes the comparison with our model hard,due to the more algebraicoperational, as opposed to logicaldeclarative, nature ofconceptual graphs. From a pragmatic point of view, the two models can be considered to share some basic intuitions, notably a categorization of documents intoorthogonal dimensions. However, the fully formal status of our model enables us toaddress fundamental questions such as the computational complexity of the retrievalproblem and the relation between form and contentbased retrieval.Logical models in a more orthodox sense of information retrieval, first proposed in van Rijsbergen 1986, have been actively investigated in the last ten yearsCrestani et al. 1998 Sebastiani 1998, 1999. Within this research trend, the workclosest in spirit to this is the work by Fuhr and colleagues on Probabilistic Datalogsee, e.g., Rolleke and Fuhr 1998, an extension of Stratified Datalog by probabilistic features. It is similar in that a logic with a modeltheoretic semantics isused as a deductive tool in which to encode independently defined models of IR,but it is different in most other respects. For instance, Fuhr and colleagues do notdefine independently motivated mereologies for the various types of media seeSections 5.1 and 5.3, and do not cater for the integration, within their formalism, ofapproaches to MIR originating from different fields such as those based on digitalsignal processing, as we instead do.In the area of image processing, a considerable effort has been devoted to theinvestigation of effective methods for formbased image retrieval.1 This effort hasled to the development of a number of systems see, e.g., Gudivada and Raghavan1995b, Orphanoudakis et al. 1994, and Smith and Chang 1996 which, in somecases, have also been turned into commercial products Bach et al. 1996 Faloutsoset al. 1994. These systems, and in general the methods found in the literature,differ in the aspect of image form that is considered, in the features that are used tocapture each aspect, in the algorithms employed to compute features, in the functionadopted to match features for assessing similarity. While an exhaustive review isoutside the scope of this paper, a general account of formbased image retrieval isgiven later, in Section 5.2, when we will consider the representation and retrievalof image forms. A survey of current trends can be found in Gupta et al. 1997.Given the context in which Gupta et al. 1997 originated, it is not surprising that1 The kind of image retrieval that we call formbased to contrast it with the retrieval based on thesemantics of images, has been called contentbased retrieval by the image processing community,to contrast it with the retrieval based on externally attributed properties of images metadata. Thisterminological mismatch is a typical inconvenient of the integration between different worlds. Wehave decided to live with it in order to preserve the connotation underlying our reference model, asdiscussed in Section 2.2.916 C. MEGHINI ET AL.its unifying trait is the lack of a proper representation and use of what we call thecontent of images.Indexing methods based on statistical Salton and Buckley 1988 or probabilistic Fuhr and Buckley 1991 methods may be viewed as attempts to capture perhapsshallow semantic properties of the document, as they abstract from supposedlyuseless properties of a word e.g., its contexts of occurrence in the document toconcentrate on properties of it that are deemed more significant from a semanticpoint of view e.g., the number of times it occurs in a document.More daring approaches to capturing more document semantics are those basedon natural language processing NLP. So far, no real attempt has been made tocapture document semantics through NLPbased understanding of the document.This is unsurprising, given the substantial distance that still separates NLP fromachieving real text understanding. More surprisingly, also less ambitious NLPbased efforts to capture document semantics have failed to yield improved retrievaleffectiveness. The paradigmatic case is the attempt to index documents by nounphrases rather than by individual words although intuitively capturing more semantics than the latter, the former have been experimentally shown to be lesseffective indexing units, perhaps because of their different statistical propertiessee, e.g., Lewis 1992.Methods based on either statistical or probabilistic indexing have been applied tothe retrieval of images via textual annotations see, e.g., Liu and Sun 1997, Srihari1995, and Smeaton and Quigley 1996, in some cases supported by the use ofthesauri to semantically connect the terms occurring in the text Alp Aslandoganet al. 1997 Guglielmo and Rowe 1996 Pentland et al. 1994. The resulting methods have proved effective only in very narrow contexts, and do not fully exploitthe capabilities of human memory and the potentiality of the visual language insupporting such capabilities.Image retrieval methods based on both textual annotation and visual similarityhave also been investigated as a way of enhancing retrieval performance and systemusability Smith and Chang 1997. While very naive in the representation of imagesemantics, the resulting systems sell formbased text retrieval for retrieval basedon image semantics. As a consequence, they face the problem of how to combinethe results of two sources of imprecision each addressing the same aspect, that is,document form, in a different way.Models and methods for MIR developed in the database community tend to focusexclusively on the symbolic representation and usage of the content of images,regarding formbased retrieval just as a challenging application area for fast accessmethods to secondary storage Faloutsos 1996. In the classification of multimediasystems outlined in Gudivada 1995, this would fall under the category of retrievaltermed as based on logical data units, where a logical data unit is a multimediadata structure determined a priori. A paradigmatic case is the model presentedin Marcus and Subrahmanian 1996, where visual aspects of images are treated atthe symbolic level as semantic properties, and visual similarity is not provided bythe models query language. Incidentally, this view of MIR has been pursued alsoby relying on a description logic as modelling tool Goble et al. 1996.As already argued, our view of MIR is that the requirements of applications donot mirror the partition of the field that has been induced in practice by the differentbackgrounds of researchers. The application areas that have been mentioned at thebeginning of this paper do require an information retrieval functionality able toA Model of Multimedia Information Retrieval 917address all the document dimensions and, most importantly, able to address eachdimension in its own modality. In order to fulfill this goal, integration is the keyconcept, and, indeed, the basis of our approach. In this sense, our model can beseen as a generalization of current MIR methods. This does not mean that everyfunctionality found in any text or image retrieval modelsystem is also provided bythe model being presented. Rather, it means that our model provides the basis forintegrating retrieval methods pertaining to different media and document dimensions. In so doing, it relies on a standard set of services for the various kinds ofretrieval considered. It will be shown in due course that these services can be madesignificantly more sophisticated without altering the architecture of the model.This model is the result of a research effort spanning almost a decade. Therequirements of a suitable MIR model were outlined in Meghini et al. 1991, alsobased on the insights gained through the MULTOS Project Thanos 1990. A firstformulation of this model based on a description logic was given in Meghini et al.1993. Starting from that formulation, two parallel streams of development havebeen undertaken. On the one hand, we have worked on the tool, aiming at thedefinition of a description logic more tightly coupled with the task of informationretrieval Buongarzoni et al. 1995 Meghini et al. 1998 Meghini and Straccia 1996Sebastiani 1994 Straccia 1996, 1997a, 1997b, 1998, 2000. On the other hand, wehave worked on the application of this tool to image retrieval Meghini 1995Meghini et al. 1997a, and successively generalized the model to MIR Meghiniet al. 1997b. In order to simplify the presentation, the present paper does notinclude the fullblown logical tool resulting from the former stream of research,but rather focuses on the results of the latter stream. A preliminary version of thismodel can be found in Meghini et al. 1997b.4. A Fuzzy Description LogicDescription Logics DLs, for shortsee, e.g., Borgida 1995 are contractionsof the predicate calculus that descend from the formalization of early semantic network or framebased knowledge representation languages. DLs have anobjectoriented character that makes them especially suitable for reasoning abouthierarchies of structured objects.DL systems have been used for building a variety of applications includingsystems supporting configuration management McGuinness and Wright 1998,software management Devanbu et al. 1991, browsing and querying of networkedinformation sources Duschka and Levy 1997, data archaeology Brachman et al.1992, plan recognition Weida and Litman 1992, natural language understanding Bollinger and Pletat 1991 and multimedia data description and classification Goble et al. 1996. The grandfather of DL systems was KLONE Brachmanand Schmolze 1985. Nowadays, a whole family of DLbased knowledge representation systems has been built, like BACK Peltason 1991, CLASSIC Brachmanet al. 1991, KRIS Baader and Hollunder 1991, and LOOM MacGregor 1991.For most of these systems, the computational complexity of the underlying reasoning problems is known. The systems mostly differ for the expressiveness of thelanguage and the completeness of the inferential algorithms.The specific DL that we use to express our model is ALC SchmidtSchauand Smolka 1991. ALC is universally considered a significant representative ofa family of expressive DLs and is therefore regarded as a convenient workbench918 C. MEGHINI ET AL.FIG. 1. Grammar rules for ALC concepts.for carrying out any kind of logical work of an experimental nature. However, westress that our model is not tied in any way to this particular choice. Indeed, mostimplemented systems rely on DLs that are less expressive than ALC. On the otherhand, IR models based on more expressive DLs have been also studied Meghiniet al. 1993.4.1. A QUICK LOOK ATALC. Concepts, roles and individual constants are thebasic building blocks of ALC. Concepts describe sets of objects, such as Italianmusician, or, in ALC notation, ItalianuMusician. Roles give binary properties,such as Friend. Individual constants are simple names for individuals, such astim. From a data modelling point of view, concepts correspond to classes, roles toattributes and individual constants to basic objects. From a logical point of view,concepts can be seen as possibly complex unary predicate symbols obtained bylambdaabstraction, roles as binary predicate symbols and individual constants asconstant symbols.Formally, we assume three alphabets of symbols, called primitive concepts, primitive roles and individual constants. The concepts of the languageALC are formed out of primitive concepts according to the syntax rules givenin Figure 1. In ALC, roles are always primitive. Other DLs have instead also roleforming operators.For example, the complex concept MusicianuPlays.ElectricInstrument isobtained by combining the primitive concepts Musician and ElectricInstrumentand the primitive role Plays by the conjunction u, universal quantification and negation  constructors. Under the intended interpretation and in a way thatwill be formalized soon, such concept denotes the musicians who do not play anyelectric instrument.It is immediate to verify that ALC is a notational variant of a conservativecontraction of predicate calculus, determined by the very limited usage of quantifiersand variables, the latter always implicit.2 Accordingly, the semantics of DLs is therestriction of the Tarskian semantics for the predicate calculus corresponding to thissyntactical contraction. An interpretation I is a pair I  1I, I consisting of anonempty set1I called the domain and of an interpretation function I . Followingthe intuitive meaning of constants, roles and concepts, given at the beginning ofthis section, I maps different individual constants into different elements of 1I ,2 A calculus C is a contraction of a calculus C  when the language L and the set of valid formulas V ofthe former are, respectively, subsets of the language L  and of the set of valid formulas V  of the latter.The contraction is conservative when V   V  does not contain any formula which is expressiblesolely by means of L .A Model of Multimedia Information Retrieval 919primitive concepts into subsets of1I and primitive roles into subsets of1I 1I .The interpretation of complex concepts is defined by structural induction via thefollowing rules, where C,C1,C2 stand for concepts and R for rolesI  1II  C1 u C2I  CI1  CI2C1 t C2I  CI1  CI2CI  1I  CIR.CI  d  1I  d   1I .d, d   RI implies d   CIR.CI  d  1I  d   1I .d, d   RI and d   CI.For instance, R.CI is the result of viewing R.C as the first order formulay.Rx, y  Cy. Similarly, R.CId is the result of viewing R.C as theformula y.Rx, y  Cy. As a consequence, it can be verified that for all interpretations IC1 u C2I  C1 t C2IR.CI  R.CI .ALC concepts and roles can be used for making crisp assertions about individualconstants metavariables a, a1, a2, that is, expressions belonging to one of thefollowing categories1 Ca, asserting that a is an instance of C  for example, Musician uTeachertim makes the individual constant tim a Musician and a Teacher2 Ra1, a2, asserting that a1 is related to a2 by means of R e.g.,Friendtim,tom3 C1 v C2, asserting that C1 is more specific than C2 for instance, Pianist vArtist u Plays.Piano.Assertions of type 1 and 2 are called simple assertions, and have identical analoguesin the predicate calculus. An assertion of type 3 is called an axiom, and its predicatecalculus analogue is the sentence x .C1x C2x. By stating both C1 v C2 andC2 v C1, the primitive concept C1 is defined to be equivalent to C2.Semantically, the assertion Ca respectively, Ra, b and C1 v C2 is satisfiedby I iff aI  CI respectively, aI, bI  RI and C1I  C2I. A set6 of assertionswill be called a knowledge base KB. An interpretation I satisfies is a model of a KB 6 iff I satisfies each element in 6. A KB 6 entails an assertion  written6   iff every model of 6 also satisfies . For instance, if 6 is6  Italian v European, Italian u Pianisttom,Friendtim, tom,then6  Friend.Pianist u Europeantim,that is, tim has a friend who is a European pianist.4.2. FUZZYALC. In order to deal with the imprecision inherent in informationretrieval, we extend ALC with fuzzy capabilities Straccia 1998. The extension of DLs to this end is not new. Yen 1991 was the first to introduce imprecision into a simple DL the resulting language has interesting features it allows the920 C. MEGHINI ET AL.definition of imprecise concepts by means of explicit membership functions overa domain, and it introduces concept modifiers, like Very or Slightly, by means ofwhich concepts like very low pressure can be defined. This last idea has beengeneralized to ALC in Tresp and Molitor 1998, where a certain type of conceptmodifiers are allowed. The result is a more expressive language than just fuzzyALC, with radically different computational properties, though.From a syntactical point of view, fuzzy ALC provides fuzzy assertions, thatis, expressions of type , n, where  is a crisp assertion and n  0, 1. Weuse the terms fuzzy simple assertion, fuzzy axiom, and fuzzy KB with the obviousmeaning. Then, About.Pianoi, .7 is a fuzzy simple assertion with intendedmeaning see below the membership degree of individual constant i to conceptAbout.Piano is at least .7, or, in less technical terms, i is likely to be abouta piano.According to Zadeh 1965, a fuzzy set X with respect to a set S is characterizedby a membership function X  S  0, 1, assigning a X membership degree,X s, to each element s in S. This membership degree gives us an estimation ofhow much s belongs to X . Typically, if X s  1 then s definitely belongs to X ,while X x  .7 means that s is likely with degree of likelihood .7 to be anelement of X . Membership functions have to satisfy the following three restrictionsfor all s  S and for all fuzzy sets X, Y with respect to SXY s  minX s, Y sXY s  maxX s, Y sX s  1 X s.where X is the complement of X in S, that is, SX . Other membership functionshave been proposed in the literature the interested reader can consult, for example,Dubois and Prade 1980 or Kundu and Chen 1994.In fuzzy ALC, concepts and roles are interpreted as fuzzy sets, thus becomingimprecise. Formally, a fuzzy interpretation is a pair I  1I, I, where 1I is, asfor the crisp case, the domain, whereas I is an interpretation function mapping1 different individual constants to different elements of1I , as for the crisp case2 ALC concepts into a membership degree function 1I  0, 1, and3 ALC roles into a membership degree function 1I 1I  0, 1.Therefore, if C is a concept then CI will be interpreted as the membership degreefunction of the fuzzy set which is denoted by C with respect to I, that is, if d is anobject of the domain1I then CId gives us the degree of membership of d in thedenotation of C under the interpretation I. Similarly for roles. In order to reflectintuition, I has to satisfy the following equations for all d  1IId  1Id  0C1 u C2Id  minC1Id,C2IdC1 t C2Id  maxC1Id,C2IdCId  1 CIdR.CId  mind 1I max1 RId, d ,CId R.CId  maxd 1I minRId, d ,CId A Model of Multimedia Information Retrieval 921Again, R.CId is the result of viewing R.C as the formula y.Rx, y Cy, where F  G is F  G and the universal quantifier  is viewed as a possibly infinite conjunction over the elements of the domain in the literature, severaldifferent definitions of the fuzzy implication connective have been proposedsee, for example, Kundu and Chen 1994 for a discussion. The overall effect is,informallyR.Cd d 1IRd, d   Cd  d 1IRd, d ,Cd .By applying in this order the rules for conjunction, disjunction and negation tothe last formula, the minmax expression above yields. Similarly, R.CId is theresult of viewing R.C as y.Rx, y  Cy, where the existential quantifier  isconsidered as a possibly infinite disjunction over the elements of the domain seealso Lee 1972.Also in this case, it is verified that for all interpretations I and individual constants d 1I , C1 u C2Id C1 t C2Id and R.CId R.CId. Moreover, every crisp interpretation I can be seen as a fuzzyinterpretation with membership degree in 0, 1 rather than in 0, 1.An important operator of DLs concerns number restrictions on role fillersBuchheit et al. 1993. The interested reader can find the fuzzy semantic rulesfor number restriction operators in Yen 1991.An interpretation I satisfies is a model of  a fuzzy assertion Ca, nrespectively, Ra1, a2, n and C1 v C2, n iff CIa1I n respectively,RIa1I, a2I n and mind1I max1C1Id,C2Id n. Note that the satisfiability condition mind1I max1C1Id,C2Id n for C1 v C2, n is aconsequence of viewing C1vC2 as the formulax .C1xC2x,orx .C1xC2x.An interpretation I satisfies is a model of  a fuzzy KB 6 iff I satisfies eachelement of 6. A fuzzy KB 6 entails a fuzzy assertion  written 6   iffevery model of6 also satisfies . Given a fuzzy KB6 and a fuzzy assertion , wedefine the maximal degree of truth of  with respect to6 written Maxdeg6, asmaxn  0 6  , n max   0. Note that6  , n iff Maxdeg6,  n.For example, suppose we have two images i1 and i2 indexed as follows6i1  Abouti1, tim, .9, Talltim, .8, Abouti1, tom, .6, Talltom, .76i2  Abouti2, joe, .6, Talljoe, .9Moreover, let the background KB be6B  Imagei1, 1, Imagei2, 1,Musiciantim, 1, Musiciantom, 1, Musicianjoe, 1,Tall v Adult, .9,and let 61  6i1 6B and 62  6i2 6B. Our intention is to retrieve all imagesin which there is an adult musician. This can be formalized by the query conceptC  Image u About.Adult uMusician.It can be verified that Maxdeg61,Ci1  .9, whereas Maxdeg61,Ci2  .6.Therefore, in retrieving both images we rank i1 before i2.922 C. MEGHINI ET AL.The pivotal role that fuzzy ALC has in the context of our model will becomeclear in the next sections. The connection between logical reasoning in fuzzyALC and nonlogical computation through mediumspecific document processing techniques will be realized by identifying a number of specialALC individualconstants and predicate symbols and imposing that their semantics be not a genericsubset of 1I or 1I 1I but one that complies with the results of the documentprocessing analysis.5. FormWe now proceed to discussing the form dimension of simple documents. Wepresent models for image layouts and text layouts, which consist of the symbolicrepresentations of the formrelated aspects of an image or text, respectively. Eachnotion is endowed with a mereology, that is, a theory of parts, based on notions suchas atomic region, region and grounded region. Each of these three notions will bedefined twice, once for images and once for text. The context will tell which notionis meant from time to time. Note also that the term layout is used elsewhere inthe literature in a different sense, namely to denote the rendering of a documenton a display device. In order to query image and text models, we introduce specialpredicate symbols, which will be used in the unified query language discussed inSection 8. The reader will note the evident parallelism, even down to many details,in our treatment of image form and text form given that form is the only mediumspecific aspect of documents, this shows the potential of this model for extensionto other media.5.1. MODELLING IMAGE LAYOUTS. In order to make the paper selfcontained,some elementary notions from digital geometry are briefly recalled below see also,for example, Rosenfeld and Kak 1982, Chap. 11.Let IN be the set of natural numbers. A zone is any subset of IN2, that is, a set ofpoints. A zone S is aligned ifminx  x, y  S  0 and miny  x, y  S  0.The neighbors of a point P  x, y, when both x and y are nonzero, are the pointsx  1, y, x, y  1, x, y  1, and x  1, y. If only one of Ps coordinates is0, then P has only three neighbors 0, 0 has only two neighbors. Two zones aresaid to be neighbor to each other if they are disjoint and a point in one of them isa neighbor of a point in the other one. A path of length n from point P to pointP  is a sequence of points P  P0, P1, . . . , Pn  P  such that P0  P, Pn  P and Pi is a neighbor of Pi1, 1  i  n. Let S be a zone and P and P  points ofS P is connected to P  in S if there is a path from P to P  consisting entirely ofpoints of S. For any P in S, the set of points that are connected to P in S is calleda connected component of S. If S has only one connected component, it is called aconnected zone.We now formalize the notion of an image layout. Given a set of colors C, animage layout is a triple i  Ai ,  i , f i , whereAi , the domain, is a finite, aligned, rectangular zone rectangular zone beingdefined in the obvious way i is a partition of Ai into nonempty connected zones T1, . . . , Tn, called atomicregionsA Model of Multimedia Information Retrieval 923FIG. 2. The atomic regions of a simple image. f i is a total function the color function from  i to C assigning a color to eachatomic region in such a way that no two neighbor atomic regions have the samecolor.Figure 2 shows the partition  underlying a simple image layout. From an imageprocessing point of view, an image layout is a segmentation, based on a color uniformity criterion. As a consequence, in our model atomic region is synonymousto color region. The reason behind this choice is that the mereology induced bythis criterion permits usto model a widely used class of queries on image form, namely those addressingsingle color regions as well as shapesto model regions corresponding to objects within images, as these regions canbe seen as aggregations of color regions.This choice, on the other hand, has no impact on global image similarity, suchas color or texturebased similarity, because these kinds of similarity are notexpressed nor computed in terms of single image regions. Also, it is important to note that other image segmentation criteria, and the consequent mereologies, can be accommodated into the model by generalizing the definitionof image layout in the following way i Ai ,  i1, f i1 ,  i2, f i2 , . . . ,  in, f in ,where each pair  ij , f ij  captures a different segmentation criterion. To keepthe model simple, and the paper readable, we consider only one segmentation criterion.The calculation of the partition  i from a pixel representation is notoriouslydifficult and, in fact, still an open problem. For this reason, we next provide a moregeneral notion of image region, which is defined on top of the notion of atomicregion, but which could as well be assumed as primitive, thus reconciling the modelwith the current status of image processing.The regions of an image layout i  Ai ,  i , f i  are defined to be the set ie S   T1, . . . , Tk   i , k  1, S kj1Tj , S connectedA region is a connected zone obtained by the union of one or more atomic regions.The fact that we allow S to have holes enables the model to deal with partialocclusion e.g., the area of an image showing a goalkeeper partly covered by anapproaching ball counts as a region. Accordingly, the extended color function ofan image layout i  Ai ,  i , f i  is defined as the function f ie that assigns to eachregion S the color distribution induced by the atomic regions that make up S.Technically, if S  ki1Ti , f ie S is a mapping from C to 0,1 defined as follows924 C. MEGHINI ET AL.for all c  C and letting A be the cardinality of Af ie Sc TZc T S , where Zc  T  T1, . . . , Tk  fi T   c.Since Zc is the subset of the atomic regions making up S that have color c, f ie Scgives the percentage of S that has color c. In fact, it is immediately verified thatcCf ie Sc  1, for all regions S.For any given region S, let S stand for the shape of the region, that is the closedcurve that delimits S. We let S be the set of closed curves in IN2.By definition, a region may occur in more than one image, since it is defined in apurely extensional way. For instance, whenever an object shows up in two imagesin exactly the same way, those two images will share at least one region, namelythe portion of the image domain containing the object. In general, the same regionwill occur in all images having at least one atomic region in common. In order toevaluate image queries, though, we need a more selective notion of region, boundto the specific image where a region belong. To this end, we introduce the notionof grounded image region, which we define as a pair i, S where i  Ai ,  i , f i is an image layout and S   ie . For simplicity of notation, in what follows wedirectly refer to the shape of a grounded image region i, S, actually meaning theshape of its component region S. Formally, we extend the function  by stipulatingthat i, SS. Analogously, we define the function fe on grounded imageregions i, S as followsfei, Sc  f ie Sc.Finally, we define the image universe IU as the set of all possible image layoutsof any domain. The set of all grounded image regions, denoted asR, is defined ontop of the image universe asR  i, S  IU  2IN2  S   ie.5.2. QUERYING IMAGE LAYOUTS. Queries referring to the form dimension ofimages are called visual queries, and can be partitioned as follows for a taxonomyof approaches to image retrieval, see, e.g., Gudivada and Raghavan 19971 Concrete Visual Queries. These consist of fullfledged images that are submitted to the system as a way to indicate a request to retrieve similar images the addressed aspect of similarity may concern color Bach et al. 1996Faloutsos et al. 1994 Stricker and Orengo 1995 Swain and Ballard 1991,texture Liu and Picard 1996 Pentland et al. 1994 Smith and Chang 1994,appearance Ravela and Manmatha 1997 combinations of these are gainingground Rui et al. 1998 Ciocca and Schettini 19992 Abstract Visual Queries. These are artificially constructed image elementshence, abstractions of image layouts that address specific aspects of imagesimilarity they can be further categorized intoa Color Queries. Specifications of color patches, used to indicate a requestto retrieve those images in which a similar color patch occurs Del Bimboet al. 1997 Faloutsos et al. 1994A Model of Multimedia Information Retrieval 925b Shape Queries. Specifications of one or more shapes closed simplecurves in the 2D space, used to indicate a request to retrieve thoseimages in which the specified shapes occur as contours of significantobjects Del Bimbo and Pala 1997 Hirata and Kato 1992 Petrakis andFaloutsos 1997c combinations of the above Jain and Vailaya 1996.As mentioned in Section 2.3, visual queries are processed by matching a vectorof features extracted from the query image, with each of the homologous vectorsextracted from the images candidate for retrieval. For concrete visual queries, thefeatures are computed on the whole image, while for abstract visual queries only thefeatures indicated in the query such as shape or color are represented in the vectorsinvolved. For each of the above categories of visual queries, a number of differenttechniques have been proposed for performing image matching, depending on thefeatures used to capture the aspect addressed by the category, or the method usedto compute such features, or the function used to assess similarity. For instance,a color similarity criterion for concrete visual query is captured by the followingfunction Stricker and Orengo 1995si, i  jHSBw1 jmi1 j  mi 1 j  w2 j mi2 j  mi 2 j  w3 j mi3 j  mi 3 j , 1whereH SB is the set of color channels, H SB  H, S, Bmgkj is the kth moment of the true color histogram of image layout g, for thechannel j of the HBS color space, that ismg1 j 1NNl1pgj,lmg2 j  1NNl1pgj,l  mg1 j2mg3 j  3 1NNl1pgj,l  mg1 j3where pgj,l is the value of the channel j in the point l of the image layout gwi j  0, 1  j, i  3 are user specified weights.As the last example shows, the inference carried out by a similarity retrieval engine is heavily based on numerical techniques, hence the least apt to be captured bylogic. For this reason, the model does not provide the machinery for defining similarity functions, and indeed assumes that similarity reasoning will not be performedby means of logic.However, against current practice, we argue that visual queries are expressions ofa formal language, and that logic is a most suitable tool for the specification of sucha language. Of course, the primitive elements of the language for querying imageforms we are about to introduce will be specifiable in a visual way, being visualin nature. So, at the surface level, any system based on this model can be made tolook identical to the similarity retrieval engines in current practice nowadays. But926 C. MEGHINI ET AL.the existence of the query language marks an important difference, since it permits,among other things, the integration of formbased image retrieval with other kindsof retrieval, on images as well as on documents pertaining to any other medium.The categorization of visual queries pointed out above will be used as the guideline for the definition of the query language on image layouts. The building blocks ofthe query language are, as anticipated at the end of Section 4.2, specialALC individual constants and predicate symbols abbreviated in SICs and SPSs, respectively.In particular, in order to express visual queries, two kinds of symbols are called for1 symbols for denoting image layouts, their component regions, the properties ofregions such as colors and shapes, and the appropriate relationships amongthese entities we call these symbols mereological SICs and SPSs2 symbols for denoting similarity between whole images for concrete visualqueries and image components for abstract visual queries we call thesesymbols similarity SPSs.As far as mereological SICs are concerned, the following disjoint countable alphabets are introduced, each consisting of description logic individual constantsI , the names of image layouts metavariable i, optionally followed by a naturalnumberR , the names of grounded image regions rC , the names of colors cS , the names of shapes s.Even though, at first sight, these alphabets may seem to be an unnecessary complication imposed by the formalism in which this model is stated, it is worthwhile toobserve that they are in everyday use. For instance, one could think ofI as the setof image URLs. C can be thought of as naming the elements of one of the manycolor spaces proposed in the literature for instance, in the RGB space each suchname is a triple giving the level of energy of a pixel on the corresponding channel. Analogously, S may be understood as any suitable notation for representingcontours, such as, for instance, the 8contour notation, given by elements of the set0, 1, . . . , 7. Finally, each element in R could consist of the composition of animage name, a region shape and a point for locating the shape within the imagerange, thereby uniquely identifying a region of the image. Formally, the intendedsemantics of these SICs is given by conditions which constraint the generic fuzzyinterpretation I to use a specific function to interpret each of them. In particular,we treat each of the above introduced individual constants as a rigid designatori.e., interpretationindependent name, compliant with the given intuitive accountof the alphabets for a corresponding semantic entity. These conditions require I tobe a total bijective mapping fromI to IU , fromR toR, fromC to C, and fromS to S. In this way, for instance, each image layout has a name in the language,and each name in the language names a different layout.Furthermore, the following mereological SPSs are assumed, each having thesyntactical status of a description logic roleHAIRi,r standing for Has Atomic Image Region. Relates the image layouti to one of its grounded atomic regions rA Model of Multimedia Information Retrieval 927HIRi,r Has Image Region. Relates the image layout i to one of its groundedregions rHSr,s Has Shape. Relates a grounded image region r to its shape sHCr,c Has Color. Relates a grounded image region r to its color c.The semantic conditions on mereological SPSs are as follows for all image layoutsi, i , regions S, shapes s and colors cHAIRI  IU  IU  2IN2 0, 1,such that HAIRIi, i , S 1 if i  i  and S   i0 otherwise 2HIRI  IU  IU  2IN2 0, 1,such that HIRIi, i , S 1 if i  i  and S   ie0 otherwise 3HSI IU  2IN2 S  0, 1,such that HSIi, S, s 1 if S   ie and s  S0 otherwise 4HCI IU  2IN2 C  0, 1,such that HCIi, S, c  f ie S c 5HAIR and HIR give raise, as expected, only to crisp assertions, that are valuatedas true i.e., 1 just in case the grounded image region given as second argumentbelongs to the image layout given as first argument. The reason why we haveincluded both these SPSs in the language, despite the obvious subsumption relationthat links them i.e., HAIRvHIR, is that color and shape queries, while alwaysallowed on atomic image regions, will be allowed on extended regions only inrestricted cases. The rationale for this choice is of a computational nature and willbe discussed in detail later, in Section 8.2. Also HS is a crisp role, true only ifthe given closed curve is the contour of the given grounded image region. Finally,HC is a truly fuzzy role, assigning to each pair grounded image region, color thepercentage of the latter that occurs in the former. Note that, in order to computethat percentage, the color function must be known, hence it is mandatory to havegrounded image regions, in this case. Clearly, HC behaves as a crisp role on atomicregions, on which it is true just in case the given color is indeed the color of theregion, otherwise HC is false, that is 0.As far as similarity SPSs, these are categorized into two groups, mirroring thecategorization of visual queriesglobal similarity SPSs. In general, there will be a family of such SPSs, eachcapturing a specific similarity criterion. Since from the conceptual viewpointthese SPSs form a uniform class, this model provides just one of them, to beunderstood as a representative of the whole class. Any other symbol of the samesort can be added without altering the structure and philosophy of the language.So, for global similarity matching we use the role928 C. MEGHINI ET AL.SIi, i  Similar Image. Denotes the similarity between the given imagelayoutslocal similarity SPSs. Assessing the similarity between individual features ofimages. Similarly for what we have done for global similarity, we include in thelanguage one SPS for each type of abstract visual query. So we haveSCc, c Similar Color. Denotes the similarity between the given colorsSSs, s  Similar Shape. Denotes the similarity between the given shapes.The semantic clauses for both global and local similarity SPSs are defined onthe basis of corresponding functions i , c and s , that measure in the 0,1 intervalthe degree of similarity of two image layouts, colors and shapes, respectivelySII  IU  IU  0, 1, such that SIIi, i   i i, i  6SCI  C  C  0, 1, such that SCIc, c  cc, c 7SSI  S  S  0, 1, such that SSIs, s   ss, s . 8The prototype of the model introduced in Section 12 uses, as image similarityfunction i , a close relative of the function 1. This function can be calculatedfrom an image layout, once a channel structure on the color set C is imposed. Weremark that this particular choice for i is not fundamental, as the present workis not a study in similarity image retrieval. In selecting i we have just pickeda function that is considered as a reasonable measure for image similarity by thedigital image processing experts. The weightsw1H , . . . , w3B will play an importantrole in relevance feedback, hence we postpone the complete definition of i untilSection 11. The functions c and s used for the prototype are given in Section 12.The semantic clauses introduced in this section capture the desired behavior ofthe special symbols that have been defined to query image layouts. In order to turnthe desired behavior into the actual behavior, we restrict the semantic universe of ourlogic to only those interpretations that satisfy these conditions. A fuzzy interpretation I will thus be called an image interpretation if it satisfies conditions 2 to 8.From the semantic point of view this modeling style is an application of thesocalled method of concrete domains Baader and Hanschke 1991, by whichcertain symbols are treated as having a fixed, interpretationindependent meaning.From the practical point of view, it results in interpreting every occurrence ofthe SPSs in question not as the occurrence of an uninterpreted role, but as a callto a routine that implements the corresponding image processing technique. Inknowledge representation, this would be called a procedural attachment Myers1994. Section 10 will show how procedural attachment works in our model.5.3. MODELLING TEXT LAYOUTS. In order to strictly parallel conceptual uniformity with modelling uniformity, we now define the notion of text layout as asemantic entity that conforms, as much as possible, to the notion of image layout.To this end, we allow ourselves a moderate amount of overloading, and use some ofthe names introduced for modelling image form also for the corresponding notionspertaining to text form. Ambiguity will always be resolved by context.In the singledimensional space where text layouts belong, the notion of connected zone corresponds to the notion of interval. We define an interval S  IN tobe aligned iff minx  x  S  0. Given the set of words on an alphabet 3, wedefine a text layout to be a triple t  At ,  t , f t whereA Model of Multimedia Information Retrieval 929At the domain is a finite aligned interval, t is a partition of At into nonempty intervals T1, ..., Tn called atomic regions,and f t is a total function the word function assigning a word to each atomic region.In paralleling monochromatic image regions with the words of text, we do notintend to suggest any cognitive correspondence between these concepts. Rather, weconsider as convenient to assume them as elementary notions of the correspondinglayout model.The regions of a text layout t  At ,  t , f t are defined as the set te S  T1, ..., Tk   t , k  1, S ki1Ti , S is an intervalthat is, a region is the interval obtained by the union of one or more pairwiseadjacent atomic regions. Similarly to the case of images, a region S is not bound toa particular text layout, but is just a window that can be opened on many of them.This binding is realized in the notion of grounded text region, which we define tobe a pair t, S, where t  At ,  t , f t is a text layout and S   te .Finally, we define the text universe T U as the set of all possible text layouts ofany domain, and use the symbol E to denote the set of all grounded text regions.5.4. QUERYING TEXT LAYOUTS. Similarly to what has been done for images,we introduce the query language on the form of text by giving an elementary textmereology. This consists of two more sets of SICs one for text layouts and theother for grounded text regions and one SPS whose function is to allow queriessee below to be addressed to a portion of a text layout, rather than to the textlayout as a whole. These symbols are as followsT , the names of text layouts metasymbol t, optionally followed by a naturalnumberE , the names of grounded text regions r andHTRt,r Has Text Region A role relating the text layout t to one of its groundedregions r.The semantic conditions for these symbols parallel those for their image analogsand will not be spelled out for brevity. Note that no SPS is provided to addressatomic text regions, as the textual analogue to queries on color patches or shapesi.e., fulltext queries, see below will be handled in a different way.We distinguish between two categories of queries addressing text layouts1 fulltext queries, each consisting of a text pattern, which denotes, in a deterministic way, a set of texts when used as a query, the text pattern is supposedto retrieve any text layout belonging to its denotation2 similarity queries, each consisting of a text, and aimed at retrieving those textlayouts which are similar to the given text.In a fulltext query, the text pattern can be specified in many different ways, forexample, by enumeration, via a regular expression, or via ad hoc operators specificto text structure such as proximity, positional and inclusion operators for instance,in the style of the model for text structure presented in Navarro and BaezaYates930 C. MEGHINI ET AL.1995. As in the case of images Section 5.2, the choice as to what sublanguageLp for text patterns to adopt is not crucial for the rest of the model, so we will leavethis piece of the query language unspecified and limit ourselves to specifying howto link it to the main body of the language.The basic idea is to consider each wellformed expression   Lp, as representative of a language in its own right. This language, which will be denoted, consistsof those text layouts that match . For instance, if we adopted the language ofregular expressions as Lp, then the expression info would be the name of alanguage consisting of the text layouts in which at least one word with info as aprefix occurs. Furthermore, in accordance with its syntactical status, each   Lpis assumed to be an SPS, that is anALC concept having as instances the individualconstants naming the text layouts in . In order to query text layouts, therefore,countably many SPSs are introduced, as follows is the generic member of the language for text pattern Lp.The semantics of these symbols are the followingI  T U  0, 1, such that It 1 if t  0 otherwise.9Similarity queries involve a similarity matching between text layouts that parallelsimage similarity matching. These queries are processed on the basis of automaticallyconstructed abstractions of documents and queries, typically sets of weighted termsoccurring in the text which, based on statistical properties of language and ofthe particular collections in which documents belong, are deemed significant forassessing similarity. To this end, these abstractions are compared by appropriatesimilarity assessing functions, leading to a document ranking on the basis of abest match criterion. For instance, a by now standard text similarity function is thecosine function Salton 1989, given bycosEt, Et  mk1 vtk  vt kmk1 v2tk mk1 v2t k, 10where Ee is the index of text layout e, and is given by a vector of weightsve1, . . . , vem. vei is the weight of the i th term. The index Ee can be directly computedfrom the layout Ae,  e, f e.As for images, the model supports similarity of text layouts by endowing thequery language with a specific class of SPSs, each modelling textual similarity.The generic representative of this class is the ALC role ST, realizing the textsimilarity function t . Syntax and semantics of ST are given belowSTt, t  standing for Similar Text. Denotes the degree of similarity betweenthe given text layouts.Formally,STI  T U  T U  0, 1, such that STt, t   t t, t . 11A suitable choice could be t t, t   cosEt, Et . An image interpretation I will becalled a basic document interpretation if it satisfies the semantic conditions for theSPSs introduced in this section.A Model of Multimedia Information Retrieval 9316. ContentWe take the content of a simple document be it a text or an image to be a situation, that is, the set of all worlds or states of affairs that are compatible with theinformation carried by the document. For instance, the content of an image will bethe set of worlds where the facts depicted in the image hold, irrespective of everyother fact that is not visually evident, such as what the people represented in theimage are thinking of, or what is taking place outside the setting of the image.Analogously, the content of a text will consist of all worlds in which the sentencesmaking up the text simultaneously hold.3 This view is inspired to a simple and bynow classical notion of semantics, taking an objective stance on the meaning ofnatural language. Other views are possible, of course. For instance, one could moresubjectively understand the content of an image in terms of the impressions causedon the image viewer. For obvious reasons of generality, we choose the objectiveview.The objectivity of the view, of course, does not imply the objectivity of thedescriptions used to represent document semantics. The reason is that access tosemantics is always through interpretation, a subjective endeavor by definition. Inaddition, the identification of what counts as the content of a document, althoughnecessary, is not sufficient by itself to determine a model of document content.The reason is that the amount of facts that ought to be represented to exhaustivelydescribe, for example, an image, is typically too large to be considered as a step ofan information retrieval methodology. This latter fact is even more evident from thefamous saying A picture is worth a thousand words. An inevitable prerequisite isthe selection of a suitable abstraction of the documents at hand, to be described viathe elements of a corresponding ontology. Such ontology would be a small subsetof the users real ontology, but central to the purpose of retrieval.The selection of an appropriate ontology is neutral to that of the tool for representing document contents, as far as the latter is powerful enough to allow thedescription of any document candidate to retrieval. For the reasons pointed out inSections 1 and 4, we have adopted a fuzzy description logic as a content representation language. The rest of this section is devoted to illustrate how fuzzy ALC isto be used to represent, and to retrieve by content, multimedia information.6.1. MODELLING CONTENT. Let l be a layout either text or image uniquelyidentified by the individual constant l, that is, lI  l for any basic document interpretation I. In this model, l may have an arbitrary number of associated contentdescriptions. Each such content description  is a set of fuzzy assertions, given bythe union of four component subsets1 the layout identification, a singleton with a fuzzy assertion of the formSelfl, 1 whose role is to associate a content description with the layoutit refers to. The layout identification is the same for all content descriptionsof the same layout. In what follows, we let  l denote the set of the content3 Indeed, the semantics of a text may be a fairly articulated world structure, if, for instance, differenttime instants are referenced in the text. We believe that these structures need not be considered forretrieval purposes, due to the fact that the content representations involved in a retrieval system canrealistically be expected to be gross abstractions of the full text semantics. We have elaborated onthis theme more deeply elsewhere Meghini et al. 1998.932 C. MEGHINI ET AL.descriptions associated to the layout l, that is,   l iff Selfl, 1  2 the object anchoring, a set of fuzzy assertions of the form Representsr,o, nwhere r is an individual constant that uniquely identifies a grounded region r ofl and o is an individual constant that uniquely identifies the object representedin the region r. The combined effect of components 1 and 2 could have beenachieved by eliminating the Self concept and making Represents a ternarypredicate symbol, that is, Representsl,r,o. While extended DLs capable ofdealing with predicate symbols of arity greater than 2 do exist, we prefer to useOckhams razor and stick to the simpler, orthodox DLs of which ALC is thestandard representative3 the situation anchoring, a set of fuzzy assertions of the form Aboutl,o, nwhere l and o are as above. By using these assertions, it can be stated what thesituation described by the layout is globally about4 the situation description, a set of fuzzy simple assertions where none of thesymbols Self, Represents or About occur, describing important facts stated inthe layout about the individual constants identified by assertions of the previoustwo kinds.The task of components 1 to 3 is actually that of binding the form and contentdimensions of the same layout, thus allowing form and contentbased retrieval tobe simultaneously performed on the same text or image.As an example, let us consider a photograph showing a singer, Kiri, performingas Zerlina in Mozarts Don Giovanni. Part of a plausible content description forthis image, named i, could be of course, the truthvalues of the assertions reflectthe best of the image indexers knowledge Selfi, 1,Representsr,Kiri, .7,Abouti,o, .8,DonGiovannio, 1, PlaysKiri,Zerlina, .6.12Since there may be more than one content description for the same layout l,our model permits to consider a simple document under multiple viewpoints. InSection 9, we see that, as a result of this, the retrieval status values of a layout to a query resulting from different content descriptions do not add up. Any ofcomponents 2 to 4 can be missing in a content description.6.2. QUERYING CONTENT. Queries pertaining to content are called contentbased queries, and involve conditions on the semantics of a text or image. Sincecontent description is, as remarked at the beginning of this section, ontologyneutral,there are no SPSs specific to contentbased queries.Reasoning about content is performed directly i.e., without procedural attachments by fuzzyALC on the content descriptions illustrated in the previous section.The results of this logical reasoning activity will, if needed, be transparently mergedto the results of nonlogical computations obtained through the procedural attachments to the various SPSs by fuzzy ALC using the other components of contentdescriptions.A Model of Multimedia Information Retrieval 9337. Structured DocumentsAs mentioned in the introduction, we take multimedia documents to be complexobjects consisting, in general, of a hierarchically structured set of simple documents,which may in turn be either chunks of text or images. It is just natural, then, to allowthis model to deal not only with the features of simple documents, but also withthe way these are structured into a complex document. We hence define the notionsof document and document structure, along with a set of SPSs for addressing bothwithin queries.In order to reflect the objective, domain and applicationindependent nature ofthe notion of document, the latter is defined in the semantic universe of our model,as it is the form dimension of documents. More precisely, the model considers documents to be just structurally organized layouts, and for this reasons the two notionsdocument and structure are defined together. In this way, the content dimension isleft out of the document definition, as something to be considered only in the context of specific, hence subjective, domain and applicationdependent, documentbases. Indeed, the link between documents and their content representations willbe established precisely upon defining document bases.7.1. MODELLING STRUCTURED DOCUMENTS. The kind of structure that is offered by the model is intentionally simple. It is designed having in mind documentssuch as newspaper articles or books, including images, possibly captioned. Theoperators for navigating these documents directly reflect their hierarchical structure, and so are the expected ones, with the additional expressive power permittedby the logical structure of the ALC language. More complex structures or morecomplex navigation operators can be considered, of course a review of researchwork on richer document structures and associated query languages can be foundin Abiteboul et al. 1997. However, in order to keep the complexity of this modelat a reasonable level, we have preferred to limit ourselves to hierarchical structures,as a realistic case which gives us the opportunity of introducing a modelling stylethat can be applied to more sophisticated structures.The model views a document as a sequence of simple documents. A structure isimposed on this sequence by grouping contiguous simple documents into aggregatesthat are not allowed to partially overlap. Each aggregate determines a structuralelement of d.Formally, a document is a 4tuple d  n, B, w, R, where1 n  IN is the order of the document, that is the number of basic componentsin d2 B  IU  T U is any finite set of image or text layouts, constituting thebasic components of the document3 w 1, n B is the total and surjective function that gives, for each i  1, n,the i th basic component of d4 R  1, . . . , m is a set of intervals, in fact subintervals of 1, n, each ofwhich is used to define, in a way to be seen soon, a structural element of d tothis end, R must satisfy the following conditionsa for all 1  i  m, i  1, nb 1, n  R, that is, the whole document is a distinguished member of thedocument structure934 C. MEGHINI ET AL.FIG. 3. A document.FIG. 4. The representation of document d.c for all i ,  j  R, either i   j or  j  i or i   j  .This definition permits to model a simple document as a document. In particular,any image or text layout l is to be viewed as the document 1, l, w1, R1 wherew11  l and R1  1, 1. The structure of a document d  n, B, w, R isdefined by the pair Sd  R, E, where E is given byE  1, 2  R2  2  1 and there is no 3  R such that 2  3  1.As anticipated, Sd is completely determined by d. It can be verified that Sd is a treehaving R as nodes and E as edges. Needless to say, the root of Sd is 1, n. Notethat in the case of a document consisting of one simple document, E is empty.As for document form, also for document structure the notion of grounded region is introduced, to enable the reference to structural elements within queries. Agrounded region of a document d  n, B, w, R is defined as a pair d,  suchthat   R4. The extent of a grounded region d,  is defined as the set of imageor text layouts to which elements in  are mapped by w, that is, wi  i  .Finally, we let D be the set of all documents and G that of all grounded regions.Let us consider a document about the opera Don Giovanni, consisting of two partsone part shows, as an image of the opera, the image layout i introduced at the endof Section 6.1, with an accompanying caption tl1 the other part is just a text layoutreporting a positive critical review of the opera. The document is schematicallyrepresented in Figure 3, whereas its symbolic representation according to the justintroduced model is given in tabular form in Figure 4.The document has five grounded regions dI, , for each   R, correspondingto the nodes of the tree shown in Figure 3. The extent of the grounded regiondI, 1, 2 is the set of layouts tl1I, iI. The E component of dIs structure has fourelements, corresponding to the edges of the tree in Figure 3.4 So, a grounded region is not either a grounded image region or a grounded text region, as the standardusage of natural language would maybe suggest. The reason for this somehow counterintuitive choiceis to keep the models lexicon as small as possible.A Model of Multimedia Information Retrieval 9357.2. QUERYING STRUCTURED DOCUMENTS. In querying structured documents,the following kinds of operations are typically performednavigation along the structure of documents. SPSs for expressing this kind ofoperation will be called structural SPSsaccess to the basic constituents of a grounded region, that is, the image and textlayouts that are in the extent of that region. SPSs for expressing these accesseswill be termed extensional SPSsquery the image and text layouts. These queries called ground queries are tobe expressed by means of the SPSs introduced in Sections 5 and 6.Structural symbols, in turn, can be categorized as generic and positional symbols.The former allow one to denote documents, their grounded regions and the relationships between these. We have two sets of generic SICsD naming documents, andG naming grounded regions.As customary, the intended meaning of these alphabets is formally captured byhaving I as a total bijective mapping fromD toD and fromG toG.Furthermore,we introduce one generic SPS, that isHN standing for Has Node, relating a document to one of its grounded regions.The semantics of HN is given by for all documents d and sets of natural numbersHNI  D  D  2IN 0, 1, such thatHNId, d ,  1 if d  d  and   R0 otherwise. 13In conformance with the semantics of the structural symbols defined on layouts,that of HN assigns 1 only to the pairs document, grounded region such that thelatter is a grounded region of the former.Positional SPSs, on the other hand, allow one to navigate in the structure of thedocument. Among the many primitives that might be envisaged in order to modeltree navigation, we propose the following SPSsRoot, the concept denoting roots of document structuresLeaf, the concept denoting leaf nodes of document structuresHCh standing for Has Child, a role denoting the link between nodes and theirchildren nodesHP Has Parent, a role denoting the link between nodes and their parent nodeHD Has Descendent, the transitive closure of HChHA Has Ancestor, the transitive closure of HP.We just show the semantics of two positional symbols, leaving that of the othersto the reader. In what follows, d, d  denote documents, ,   denote sets of naturalnumbers, the structure of d is Sd R, E and, as customary, E indicates thetransitive closure of E .936 C. MEGHINI ET AL.Leaf I  D  2IN  0, 1, such thatLeafId,  1 if for no  , ,    E0 otherwise, 14HDI  D  2IN D  2IN 0, 1, such thatHDId, , d ,   1 if d  d  and ,    E0 otherwise. 15As for extensional SPSs, we include two of them in the language, relating a groundedregion of a document to the image and text layouts it contains. These SPSs areHasImage and HasText. The semantics of the former isHasImageI  D  2IN IU  0, 1, such thatHasImageId, , l 1 if   R andwk  l for some k  0 otherwise,16while that of the latter is perfectly analogous. A basic document interpretation Iwill be called a document interpretation if it satisfies the semantic conditions forthe SPSs 13 to 16 as well as the conditions not explicitly stated for brevity.8. A Unified Query LanguageWe are now in the position to define the query language of the model. This languagesatisfies the two basic requirements necessary for complying with the philosophyof this model, namely1 It is the language of a description logic, so that matching queries against document bases can be done in the logical framework defined in Section 4.2 Its syntax is a restriction of the general DL syntax that reflects the intendedmeaning of the SPSs for addressing form, content and structure previouslyintroduced. More specifically, the syntax rules to be introduced shortly, ruleout those concepts that would be meaningless according to the conditions oninterpretations 2 to 16. As an example, let us consider the conceptRoot u HAIR.Leafdenoting the basic objects that are, at the same time, root nodes of documentstructures and images, the latter having an atomic region that is a leaf node.No such basic object may exist, a fact that is captured by the semantics ofthe involved SPSs. Even though, from a strictly logical viewpoint, conceptslike the above would cause no problems, when used as queries since they aresatisfied by no interpretation, no documents would be returned by the systemin response to them, licensing them would go against intuition and ultimatelybe misleading.Before dwelling into the technical details, we would like to emphasize that thelanguage that is about to be introduced is a rigorous notation for expressing information needs as queries. How queries will be specified by users is an entirelyA Model of Multimedia Information Retrieval 937FIG. 5. Grammar rules for document queries.different matter, which will be addressed in Section 12 and should not be confusedwith the question of what queries are.The language will be presented in the remainder of this section, following a topdown style, starting from concepts addressing documents and their structure, andproceeding down to the queries addressing the basic components of documents,that is, text and image layouts.8.1. DOCUMENT QUERIES. The grammar given in Figure 5 defines the documentquery language. The categories capturing text and image queries will be definedlater and are underlined for the readers convenience.A document query is a combination, via the conjunction and disjunction constructors, of concepts of the form HN.C where C is a nodeconcept. Technically,the above concept reads as the individual constants related through the role HN toan individual constant that is a C . Given the semantics of HN, this becomes thedocuments having a node that is a C . From a pragmatic viewpoint, the prefix HNintroduces a concept that specifies the characteristics to be satisfied by a structuralcomponent i.e., a node of the sought documents. By combining the above concept, conditions on several, possibly different, nodes of the same document maybe stated. For instance, HN.C1 t HN.C2 expresses two conditions C1 andC2 on two nodes of a document which may stand in any structural relationship, oreven be the same node. On the contrary, if the nodes to be addressed are known tobe structurally related in a specific way, then the whole query is to be stated as anodeconcept, as it will be illustrated below see concept 17.The reason why the negation constructor is not allowed here, as well as in otherparts of the query language, is twofold. From one hand, this operator would makequery evaluation an expensive operation. For instance, the simple query HN.Cwhen evaluated for a document d, would imply to check, for each structural component n of d, that n is a C. This is a consequence of the fact that, accordingto the semantics of fuzzy ALC, the above query is equivalent to HN.C Ultimately, all components of all documents would have to be considered in answeringthe query. On the other hand, it is difficult to grasp the intuitive meaning of thenegation applied to a similarity symbol. In other words, if the formal semantics offuzzy ALC entitles one say that the maximal degree of truth of Ca is .3 whenthat of Ca is .7, intuition may find meaningless this attribution when applied to938 C. MEGHINI ET AL.a complex notion such as similarity. For these reasons, negation is only allowed inthose parts of queries that are concerned with content. In such cases, its intuitiveinterpretation poses no problem, at least to those who accept the philosophy offuzzy logic, as we do.A nodeconcept may be comprised of several conditions, combined via theu ortoperators. In its basic form, the syntax of a nodeconcept reflects two possibilitieswhether or not the condition has a structural clause.If no structural clause is present, a nodeconcept takes the form of an extentconcept, which addresses directly the basic constituents of the document withoutmentioning any condition on the document structure. An extentconcept, in turn,may take one of two forms, depending on the kind of basic component that itaddresses. If the addressed basic component is a text layout, then the HasText roleis used. For instance, the concept HN.HasText.Ct denotes the documents havinga node with a textual basic component that is a Ct . If the basic component is animage layout, the HasImage roles is used in a perfectly analogous way. Otherwise,a nodeconcept states structural conditions, which are couched in terms of thestructural symbols introduced in Section 7.2. The simplest structural conditionsare positionalconcepts, which regard whether a node is a Root or a Leaf. Morecomplex conditions involve positionalroles and recursively introduce other nodeconcepts. For instance, the conceptHN.Root u HCh.HasImage.Ci denotes the documents whose root has a child with an image that is a Ci , whereasHN.Leaf u HasText.Ct  u HA.HasImage.Ci  17denotes the documents having a node satisfying two conditions 1 it is a leafcontaining a text that is a Ct and 2 it has an ancestor with an image that is a Ci .Before closing the structure topic, we would like to stress again that this modeldoes not purport to be an advanced one in its treatment of structure. On the contrary,it merely aims at showing what is the role of structure in the general frameworkof document modeling, and how structure can be included in the query language.Having done this, the way is open to the consideration of more sophisticated structural models, a good example of which is presented in Navarro and BaezaYates1997.8.2. IMAGE QUERIES. The syntax of image queries is given in Figure 6. The firstthing to observe is the presence, in the clauses defining image, color and shapeconcepts, of a new DL concept constructor of the form awhere a is an individualconstant, which may be a layout, a color or a shapename, respectively. In theDL terminology, this constructor is called singleton, and represents, as expected, aconcept having only the individual constant a as instance. From a semantics pointof view, an interpretation has to satisfy the following condition for all d  1IaId 1 if d  aI0 otherwise.Image queries are thus concepts of the DL ALCO, which extends ALC with thesingleton constructor. The additional expressive power ofALCO overALC has noimpact on the complexity of the image retrieval problem, as it will be argued later.A Model of Multimedia Information Retrieval 939FIG. 6. Grammar rules for image queries.All names in the query language are defined as individual constants, whose syntaxis left unspecified as unnecessary.An image query is a combination through u and t of imageconcepts, each ofwhich may have one of four forms, illustrated in the following in the same order asthey appear in Figure 6.First, an imageconcept may be a query on some content object, explicitly assertedto be related to the sought images through an About role assertion termed situationanchoring in Section 6.1. In the query, the object in question is required to be aninstance of contentconcept, that is an ALCO concept built with the symbols usedfor situation descriptions. The grammar rule for contentconcept is thus that forgeneric ALC concepts given in Figure 1, Section 4, with the addition of the rulefor the singleton operator presented above. For instance, under the obvious lexicon,the images about an Italian musician are retrieved via the queryAbout.Musician u Born.Italy.Second, an imageconcept may be a concrete visual query, according to the terminology defined in Section 5.2. In this case, a prototype image layout l is to beprovided with the query this is done by specifying the singleton with the layoutname l in the scope of the existential quantification on the SPS SI. By so doing, thesimilarity with l is captured in the query.Third, an imageconcept may be a query on the color of an atomic region, thatis a color abstract visual query, expressed via an existential quantification on theHC SPS, followed by a colorconcept the latter is a singleton with the name of thecolor, optionally preceded by a color similarity predicate.Finally, an imageconcept may be a query on an image region. This kind ofqueries come in two forms1 The first form is meant to address the content dimension, and just consists ofa Represents clause. In order to qualify for this kind of queries, an image must940 C. MEGHINI ET AL.have an associated content description containing a Represents role assertionobject anchoring, relating a region of the image to an individual constant that isan instance of the contentconcept that follows.2 The second form extends the first with an additional condition regionconcept on the color or the shape or both of the involved region. A shape conditionis expressed via a shapeconcept, which is strictly analogous to colorconcept. Thereason why such conditions are allowed only in conjunction with a Representsclause is that, in this way, their evaluation only involves the regions that have beenthe subject of an object anchoring. If this restriction is removed, then the evaluationof this type of queries would require, in the worst case, as many checks as thepossible regions of an image, a number that is exponential in the number of atomicregions. As a verification of this latter fact, consider again Figure 2, showing theatomic regions of a simple image. This image has a region connected with regionT1 for each subset of the set T2, T3, T4, T5.As an instance of an image query, let us consider the query asking for the imagesshowing a cylindric reddish hat. This query can be expressed by the following imageconceptHIR.Represents.Hat u HC.SC.red u HS.cylinder.The above query presents an interesting case of mixed form and contentbasedimage retrieval. In particular, the Represents clause refers to the semantics ofthe image, namely to what an object is. An image is retrieved only if it displayssomething that has been explicitly asserted to be a hat. The HC clause refers toimage form, and requires, in the retrieved images, the presence of a patch of colorsimilar to red. The HS clause poses a condition on the contour of an atomic imageregion. The conjunction of these three clauses constraints the condition that theyeach of them expresses to be true of the same region, thus capturing the query spelledout above. It is important to realize that here red is just a name possibly given bythe system to a visual entity, namely a color, specified by the user via a convenientfacility, such as the selection from a color palette. Analogously, cylinder is a systemname for a shape that the user has perhaps drawn on the screen or selected from apalette of common shapes.Let us reconsider the example introduced in Section 6. The images about theopera Don Giovanni are retrieved by the query About.DonGiovanni. Thoseshowing the singer Kiri are described by HIR.Represents.Kiri. Turning tovisual queries, the request to retrieve the images similar to a given one, named this,is expressed by SI.this, and can be combined with any conceptual query, forexample, yielding SI.this t About.DonGiovanni, which would retrieve theimages that are either similar to the given one or are about Don Giovanni. As forabstract visual queries, the images in which there is a blue region whose contourhas a shape similar to a given curve s are retrieved by HAIR.HC.blue uHS.SS.s. Finally, the user interested in retrieving the images in which Kiriplays Zerlina and wears a blueish dress, can use the queryHIR.Represents.Kiri u Plays.Zerlina u HC.SC.blue. 188.3. TEXT QUERIES. The syntax of text queries is given in Figure 7. A text queryis a combination, via the usualu andt constructors, of concepts, each of which mayhave one of the following forms following the order of presentation in Figure 7A Model of Multimedia Information Retrieval 941FIG. 7. Grammar rules for text queries.1 It may be a semantic query on the whole text layout, which is required to beAbout the contentconcept that follows, or on a portion of it, which is introducedby the quantification on the mereological SPS HTR and which Represents aninstance of the contentconcept that follows.2 It may be an exact match query driven by textpattern.3 It may be a similarity match request, syntactically similar to the analogousimage query category.As an example of the last category, the layouts that are about in a traditionaltext retrieval sense successful representations of Mozarts operas are retrievedby the queryST.tl, 19where tl is a text layout consisting of exactly the abovequoted words.9. Document Bases and Document RetrievalThe behavior of our query language is specified by formally defining the notion ofa document base and of document retrieval. We model a document base as havingthree main components1 a collection of documents, that is, structured aggregates of layouts, which collectively form the objective level of the document base2 a collection of content descriptions associated to the layouts of the structureddocuments these descriptions collectively form the subjective level of thedocument base3 a knowledge base providing definitions of the concepts in the form of fuzzy DLaxiomssee Section 4 employed in content representations, as well as generalknowledge in the form of fuzzy DL assertions or axiomssee Section 4 onthe domain of discourse that applies to the whole document base this lattercomponent may be thought of as representing the conceptual context in whichthe document base lives.More formally, a document base is a triple DB  D, 6C , 6D whereD is a set of documents as defined in Section 7, that is,D  ni , Bi , wi , Ri   i  1, . . . , N .942 C. MEGHINI ET AL.We let BDB stand for the set of layouts of the documents in DB, that is,BDB Ni1Bi6C is the set of content descriptions of the layouts in the document base, that is6C lIBDB lwhere  l is defined in Section 6.1 as the set of content descriptions associatedto the layout l.6D is a set of fuzzy assertions and axioms giving the document base context.In response to a query Q addressed to a document base DB  D, 6C , 6D, eachdocument is attributed a retrieval status value RSV, which is the numerical valueaccording to which the document is ranked against all others. The RSV m of a givendocument dI  n, l1I, . . . , lnI, w, R is determined in the following way. Let0d be the Cartesian product l1   ln.Each tuple   1, . . . , n  0drepresents a choice of a content description for each layout in d. Let n be the valuen  Maxdeg6D 1 jn j , Qd,where Maxdeg is the same as the Maxdeg function discussed in Section 4 exceptfor the fact that it is calculated with respect to document interpretations only. ncan be interpreted as the RSV of d to Q calculated on the specific choice of contentdescriptions represented by . The RSV of d is then simply obtained by taking themaximum over all such choices, that is,m  max0dn . 20As an example, let us consider the document base DB  D, 6C , 6D, where iD contains the document d of Figure 3, that is, d  D ii 6C includes the imagei content description 12 and iii 6D includes the following axiomsDonGiovanni v EuropeanOpera, 1WestSideStory v AmericanOpera, 1EuropeanOpera v Opera u ConductedBy.European, .9AmericanOpera v Opera u ConductedBy.European, .8Suppose we are interested in documents containing images about operas conductedby a European director. To this end, we can use the queryHN.HasImage.About.Opera u ConductedBy.European. 21The RSV attributed to d in response to this query, is .8, because i d, withtruthvalue 1, has the node 1, 3 ii this node, with truthvalue 1, has the image i iii image i, with truthvalue .8, is about o iv o is an instance ofthe concept Opera u ConductedBy.European, with truthvalue .9. This latter fact is a consequence of the axioms DonGiovanni v EuropeanOpera, 1,EuropeanOpera v Operau ConductedBy.European, .9 and of the assertion DonGiovannio, 1. Combining the evidence iiv according to thesemantic rule for conjunction, we obtain .8  min1, 1, .8, .9.A Model of Multimedia Information Retrieval 94310. Implementing the ModelAs pointed out in the introduction, the model presented so far has a twofold roleon one hand, it aims at presenting multimedia information retrieval as a uniquediscipline, endowed with its own goals and techniques. On the other hand, themodel aims at guiding the design of systems supporting a wider class of multimediainformation retrieval applications than those supported by current models. The latterrole, though, can be legitimately advocated only if the model proves implementablewith stateoftheart technology.The rest of the paper elaborates on this aspect. First, in the present section, theimplementation of the retrieval capability of the model is addressed, to the end ofproving that such implementation can indeed be achieved with offtheshelf techniques borrowed from text and image retrieval, and knowledge representation. Theproof hinges on the query evaluation procedure, which is first informally presentedin Section 10.1, then fully specified in Section 10.2. Finally, in keeping with theformal style adopted all along the paper, the soundness and completeness of theprocedure are stated in Section 10.3 and proved in the Appendix. It is important tonote that the query evaluation procedure is not a mere formal device, but an effectivetechnique that could in fact, should be adopted in concrete implementations ofthe model, as we have done in our prototype see below.Once an implementation strategy is laid down, we are able to present, in Section 11, a technique for performing relevance feedback, a crucial aspect of formbased retrieval.Finally, Section 12 presents the prototypical implementation of a substantial partof the model, namely that dealing with form and contentbased image retrieval. Theaim of this implementation is not to demonstrate the feasibility of the model forthis purpose, the query evaluation procedure is enough. The aim of this implementation is, first, to show an effective realization of the query evaluation procedure,and, second, to make concrete the benefits of our work by presenting a retrievalengine endowed with a semanticcontent based capability that largely surpassesthe functionalities of analogous similar systems. For this latter goal, we have chosenthe medium most difficult to handle i.e., images, leaving aside text and structurethat are easier because of their more consolidated status. Our prototypical systemhas also a practical value, as it can be used for the rapid prototyping of specificationsbuilt according to the model.10.1. THE QUERY EVALUATION PROCEDURE AN EXAMPLE. The query evaluation procedure is schematically given in Figure 8 boxes standing for data, ovalsfor functions. For greater clarity, this procedure will be illustrated through an example. The query employed to this end is documents with a critical review on asuccessful representation of a Mozarts opera with an Italian conductor, and witha picture showing Kiri in a blueish dress, playing Zerlina. This query is in factthe composition of queries that have been introduced in previous sections, namelyqueries 19, 18, and 21, which are here recollectedA ST.tlB HIR.Represents.Kiri u Plays.Zerlina u HC.SC.blueC About.Opera u ConductedBy.European944 C. MEGHINI ET AL.FIG. 8. The query evaluation procedure.Using the abbreviations above, the sample query is expressed asHN.HasText.A u HasImage.B u C. 22Following Figure 8, this query is input, along with each document to be evaluateddoc, to the Query Assertion Builder, which produces the query assertion Qdoc.For our example, we consider, as doc, the document d introduced in Figures 3 and 4,so that the query assertion turns out to beHN.HasText.A u HasImage.B u Cd. 23This assertion is input to Query Decomposition  Evaluation, which is realizedby the function8. This is a central step of the procedure, which we now introducein an informal way, leaving the precise definition of 8, as well as the proof of itssoundness and completeness, for the forthcoming sections. In essence, 8 scansthe query assertion with the aim of generating knowledge, in the form of fuzzyassertions, to be passed to the DL Theorem Prover TP for evaluating the queryassertion. The assertions generated by 8 concern the SPSs of the model and cantherefore be considered as domain knowledge, where the domain in question isMIR and a specific document base. Once these assertions are provided to the DLTP, the latter can proceed to calculate the RSV of each considered document justperforming standard fuzzy logical reasoning.A Model of Multimedia Information Retrieval 945At each step8 is given an assertion at step 1, that is the query assertion at stepn, n 2, that is one of the assertions generated in the previous step.8 analyzes theoutmost part of the given assertion and performs two tasks1 the generative task, in which it generates the fuzzy assertions that are necessaryto the DL TP to reason about the analyzed part, and,2 the recursive task, in which it provides for the continuation of the procedureby recursively applying itself to the remaining part of the assertion.Let us now see this practically on the assertion 23. From a decomposition pointof view, this assertion can be analyzed as HN.Cd, saying that d has a node thatis an instance of concept C. Consequently, in its generative task,8 produces all theassertions that will inform the DL TP about what are ds nodes, namelyHNd, d, 1, 3, 1HNd, d, 1, 2, 1HNd, d, 3, 3, 1 24HNd, d, 1, 1, 1HNd, d, 2, 2, 1.Needless to say, in order to calculate the above assertions 8 must have access to adatabase storing document structure this aspect concerns how 8 works, and willbe discussed in Section 12 for this section, we confine ourselves to what 8 does.In its recursive task, 8 applies itself to the following assertionsHasText.A u HasImage.B u Cd, 1, 3HasText.A u HasImage.B u Cd, 1, 2HasText.A u HasImage.B u Cd, 3, 3HasText.A u HasImage.B u Cd, 1, 1HasText.A u HasImage.B u Cd, 2, 2.The combined affect of the generative and recursive tasks seen so far, can becompactly described by letting 8HN.HasText.A u HasImage.B uCdbe defined as followsHNd, d, 1, 3, 1, . . . , HNd, d, 2, 2, 1 8HasText.A u HasImage.B u Cd, 1, 3    8HasText.A u HasImage.B u Cd, 2, 2.Intuitively, only the applications involving intervals 1,3 and 1,2 will generatenonzero fuzzy assertions, as they address the only nodes of d having both a textand an image, that is, the root node and its left descendant. So, in the following,we consider only the decomposition of these two assertions. Since each of them isa conjunction, not surprisingly, 8 will handle it by generating no assertions as nospecial knowledge is required by the TP to handle conjunction, while recursivelyapplying itself to the single conjuncts8HasText.A u HasImage.B u Cd, 1, 3 8HasText.Ad, 1, 3 25946 C. MEGHINI ET AL. 8HasImage.B u Cd, 1, 3 26and the same for interval 1,2. Let us consider the first application 25. Fullystated, it is as follows8HasText.ST.tld, 1, 3. 27Following the same approach as above, 8 will let the DL TP know what are thetext layouts in the grounded region d, 1, 3 by generating the assertionsHasTextd, 1, 3, tl1, 1 HasTextd, 1, 3, tl2, 1,while proceeding on to compute 8ST.tltl1 and 8ST.tltl2. In order tohandle the text similarity addressed by these two last assertions, 8 calls eachtime the function t , in order to obtain the degree of similarity between the querylayout tl and each layout tli . The result of this call, denoted as usual t tl, tli , isthen embodied into an apposite assertion for the DL TP. Therefore, the results ofthe last two applications of 8 are8ST.tltl1  STtl, tl1, t tl, tl18ST.tltl2  STtl, tl2, t tl, tl2.This concludes application 27. In working out the analogous assertion on interval 1,2, that is, HasText.ST.tld, 1, 2, 8 regenerates the assertionsconcerning the text layout tl1, which is the only text layout contained in the region d, 1, 2, giving no contribution to the overall process. Let us now considerapplication 26. Following the same behavior seen so far on structure8HasImage.B u Cd, 1, 3 HasImaged, 1, 3, i, 1 8B u Ci. 28The application of 8 to the analogous assertion on region d, 1, 2, is not goingto produce anything new, since both these regions have only image i in their extent.So we do not consider such application. Turning back to 288B u Ci  8Bi 8Ci 8HIR.Represents.Kiri u Plays.ZerlinauHC.SC.bluei8About.Opera u ConductedBy.Europeani. 29The last application is easily handled since it is a semantic assertion, 8 has nojob to do on it the DL TP, using the axioms in6D as well as the content descriptionsassociated to i, is perfectly able to evaluate it. Therefore8About.Opera u ConductedBy.Europeani  .On the contrary, the processing of assertion 29 is much more elaborated. In handling the HIR role,8must identify the grounded image regions of i that have beenannotated with a Represents assertion. Looking at the content description of i 12in Section 6.1, only region i, r is the case, thus, the assertionHIRi, i, r, 1 30is generated, along with application8Represents.Kiri u Plays.Zerlina u HC.SC.bluei, r,A Model of Multimedia Information Retrieval 947which turns out to be8Represents.Kiri u Plays.Zerlina 8HC.SC.bluei, r.The first term of this last union is a semantic application, and thus will produce theempty set. What is left is then the second term, whose argument HC.SC.bluei, ris logically equivalent to a disjunction, ranging on all colors l, of the assertionHCi, r,l u SCl, blue. 31According to the rules of fuzzy semantics, the truthvalue of the last assertion isgiven by the minimum of its conjuncts truthvalues, which are in turn establishedby the semantic clauses for the SPSs HC and SC. Considering that each suchassertion is embedded in a global disjunction, we have the following8HC.SC.bluei, r  HC.SC.bluei, r, n, 32wheren  maxlCmin ferIl, cl, blueI. 33And this concludes the decomposition and evaluation of the query assertion. Forconvenience, all the assertions that are generated in this stage are classified asindicated in Figure 8 into the following categoriesstructural assertions, that is, the assertions involving structural SPSsimage global similarity assertions, that is, SI assertionsimage local similarity assertions, that is, image structural HAIR, HIR assertions,and HC, HS assertionstext global similarity assertions, that is, ST assertions andtext local similarity assertions, that is, text structural HTR assertions, and assertions.As shown in Figure 8, all these assertions are input to the fuzzy ALCO theoremprover TP for the computation of m, along with the context knowledge base6C andall combinations of ds content descriptions. The graphical illustration of this latterinput in Figure 8 has been simplified by omitting the feeding loop. Clearly, if at mostone content description is provided for each layout in d, then0d is a singleton andits consideration adds no complexity to the query evaluation process. Otherwise,the size of 0d is exponential in the number of ds layouts and its considerationheavily impacts on the complexity of the query evaluation procedure. This is theprice to be paid for considering multiple content descriptions.For space reasons, we cannot discuss the TP here. The interested reader is referredto the papers quoted in Section 3 for detailed descriptions of the various aspectsinvolved in the design and evaluation of the TP. From a computational complexityviewpoint, the implication problem for fuzzy ALCO is proved to be PSPACEcomplete. This result, albeit negative, is expected to have no significant impact onthe tool being described for two basic reasons. First, it is a worstcase result thingsdo not necessarily go as bad in practical cases. Second, the size of the prototypicalsystems for which our tool is designed is expected to be limited. Experimentalresults with an implementation of the TP show that the system is reactive with KBsof the order of a few thousands assertions.948 C. MEGHINI ET AL.FIG. 9. The decomposition function for structural queries.10.2. QUERY DECOMPOSITION AND EVALUATION. We now proceed to the formal specification of the function 8. For greater clarity, being a function definedon the query language, 8 will be introduced by following the query languagesyntactical structure.10.2.1. Decomposition and Evaluation of Document Queries. In the most general case, a query begins by addressing document structure, so the definition of 8begins, in Figure 9, from document queries, whose syntax is given in Figure 5. Inillustrating 8, we follow the order established by Figure 9 and the forthcomingfigures that make up 8s definition.Composite queries, consisting of conjunctions and disjunctions of documentqueries, are separately treated by8, each in fact being a query of its own. This wayof handling conjunctions and disjunctions will be applied whenever correctness ispreserved.Upon operating on the simplest document queries, that is, assertions of the formHN.Cd, 8 generates an assertion HNd,n, 1, for each grounded region nof d, and recursively applies itself to the assertion Cn. This is one of the fewbasic principles that inspire the definition of 8, and we believe that the informalexplanation given in the previous section is sufficient to make it clear. The treatment of assertions of the form HasImage.Cn is analogous. For each imagelayout i j of n, the assertion HasImagen, i j , 1 is generated while continuing theevaluation on Ci j . The same, mutatis mutandis, is done for assertions involvingthe other positional roles or concepts.10.2.2. Decomposition and Evaluation of Image Subqueries. The decomposition and evaluation of image queries is presented in Figure 10. Concrete visualqueries, having the form SI.qii are evaluated by generating the fuzzy assertion stating the similarity between the given image layout i and the query layoutqi, with degree of truth equal to the degree of similarity between these layouts, asestablished by the global similarity function i . Note that, in case the latter valueis zero, no assertion is generated so as not to block the inference on the rest of theA Model of Multimedia Information Retrieval 949FIG. 10. The decomposition function for image queries.query. The same behavior is adopted whenever a similarity function is involved andis guided by the fulfillment of the query decomposition principle.Queries on situation anchoring, formulated in terms of the About SPS, are, asalready remarked in the previous section, just ignored by 8, as the knowledge fortheir evaluation is already part of the document base, namely it is contained in thecontent descriptions collected in 6C and in the context knowledge base 6D. Thesame applies to queries on object anchoring, formulated in terms of the RepresentsSPS. These queries may stand alone i.e., be of the form Represents.Cr orbe conjoined to a region concept i.e., Represents.C u Dr in both cases,the content subquery gives no contribution to 8Cd.Abstract visual queries come in two sorts, depending on the kind of image regionaddressed. The first and simplest sort address exclusively atomic regions. It consistsof color queries and aim at retrieving images having a patch of a specified color.These queries have the form HAIR.HC.ci, where c is the name of the colorthat an atomic region of the image layout named i must have. If this is indeed the case,8 evaluates the query by generating the fuzzy assertion made by attaching to thequery assertion with degree of truth 1. If not, the empty set is generated. Optionally,a similarity condition on the specified color may be stated, yielding queries of theform HAIR.HC.SC.ci. The specification of the color similarity conditionradically changes the query evaluation, which yields, as degree of truth, the degreeof similarity between the given color and the color of the atomic regions of i thatcomes closest to it. If i has an atomic region of color c, then the degree of truth is 1, atleast as long as ccI, cI  1,which would seem a quite reasonable assumption onsimilarity functions, even though it has not been so stated for generality otherwise,the evaluation produces the best match among is colors and c. As a desirableconsequence, the latter type of color queries generalizes the former.The second sort of abstract visual queries address both atomic and nonatomicregions and takes the general form HIR.Ci. As for the other mereologicalsymbols,8 treats these queries by generating an assertion of the form HIRi, r, 1for each region r of i that is the subject of an object anchoring assertion, whilerecursively applying itself to the assertion Cr. The reason for this is that, forthe computational reasons that have been illustrated in Section 8.2, C is bound toinclude a Represents clause, which, of course, restricts the candidate regions950 C. MEGHINI ET AL.FIG. 11. The decomposition function for text queries.to all and only those referenced by object anchoring. As discussed above, Cmay optionally contain a region concept, which may be a color query, a shapequery or a conjunction of the two. The last case is handled, as customary, by separately evaluating the conjuncts, and is not reported in Figure 10 for brevity. Let usquickly review the first two cases they may assume the following formsHC.cr. This case is evaluated by generating the corresponding fuzzy assertion, having as degree of truth the percentage of color c in the region r.HC.SC.cr. This case has been already discussed in the previous sectionit is easy to verify that this is a generalization over the previous case.HS.sr. If the shape of r equals s, the evaluation of this query yields thecorresponding assertion with degree 1 otherwise, no assertion is generated.HS.SS.sr. Same as before, except that in this case the similarity betweenrs shape and s is assigned as degree of truth to the corresponding assertion.The decomposition and evaluation of text queries described in Figure 11 isperformed in an analogous way, and is not further discussed.10.3. FOUNDATIONS. Last but not least, we provide formal foundation to whathas been so far justified on a purely intuitive basis. The intuitive justification for8, given in Section 10.1, is that 8 generates all the knowledge needed to reducedocument retrieval to standard fuzzy logical reasoning. Here, the word standardmeans treating the SPSs respectively, SICs as standard DL roles individuals,or to put it another way, ignoring the special semantics of the special symbols ofthe query language. In technical terms, this amounts to saying that the assertionsgenerated by 8 permit it to perform the computation of the Retrieval Status Valueon standard interpretations rather than on document interpretations. Formally, thisis stated as followsTHEOREM 10.1. For all document bases, the RSV of the document d to the queryQ is given by the maximal degree of truth of Qd with respect to the knowledgebase consisting of the decomposition of query Q, 8Qd, the context knowledgebase 6D and the set of ds content descriptions. That isMaxdeg6D 1 jn j , QdMaxdeg6D 8Qd 1 jn j , Qd.This theorem, whose proof is given in the Appendix, captures both soundnessand completeness of the query evaluation procedure QEP. From the soundnesspoint of view, it says that the RSV computed by the QEP is indeed correct. FromA Model of Multimedia Information Retrieval 951the completeness point of view, it says that, if m is the RSV of a document d withrespect to query Q, then the QEP computes the RSV precisely.11. Relevance FeedbackTraditional i.e., text information retrieval systems are interactive. A most interesting aspect of this interactivity concerns the possibility for the user to give the systemindications about the relevance or irrelevance of certain documents, and have thesystem take into account these indications to improve retrieval performance. Thisis the basis of relevance feedback RF.Techniques for performing RF in text retrieval date back to the SMART system Rocchio 1971, but this is still an active research field, as witnessed by morerecent work Dunlop 1997 Lundquist et al. 1997 Wood et al. 1998. RF has attracted also the interest of researchers in image retrieval. However, this interestdates to the very recent past, hence the results obtained so far are less numerousand consolidated Bouet and Djeraba 1998 Ciocca and Schettini 1999 Rui et al.1998 Santini et al. 1999 Wood et al. 1998.In the following, we enrich the model presented so far with a RF capabilitythat applies to global similarity retrieval, either on text or image layouts. We firstpresent, in Section 11.1, our approach to the problem in general terms, discussinghow a feedback mechanism can be embedded in the model. Then, we move on toillustrate, in Sections 11.2 and 11.3, specific RF techniques for each of the twoconsidered media. These techniques, analogously to all the other specific text orimage techniques used by the model, are not new rather, they are borrowed fromthe corresponding field and imported into the model in order to concretely showhow integration amongst the various fields involved in MIR can be achieved. In thissense, the main contribution of this section is Section 11.1, which illustrates howRF works in our model independently of any mediumdependen technique.11.1. THE APPROACH. RF typically pertains to the form dimension of MIR, asit addresses the imprecision inherent in the usage of a layout whether text or imageas a query. The application of RF to semanticsbased retrieval is not appropriate,since this kind of retrieval hinges on logical reasoning, which is quite at odds withthe best match inference on which formbased retrieval relies. This does not meanthat imprecision is not present in semantic retrieval, but only that it is to be handledat the logical level, by appropriately defining the logical implication relation of themodel. We have carried out work in this sense, and refer the interested reader toMeghini et al. 1998. For the same reason, we do not consider RF on the structuredimension of retrieval, which is in fact a kind of exact retrieval, hence outside thescope of techniques such as RF.Whether text or images are considered, RF consists of a few, basic steps, whichare here outlined1 The user submits a query to the system2 The system returns the top k documents, D1, . . . , Dk , ordered according theirRSVs. If the user is satisfied, then the retrieval session is over. Otherwise3 On the top k documents the user performs a relevance assessment, by indicatingfor each document whether it is relevant or irrelevant, and possibly to whatextent. The user may also express no judgment on a document4 The system takes into account the user judgments by changing its internal status952 C. MEGHINI ET AL.FIG. 12. The nth relevance feedback iteration n  1.5 Step 2 is repeated in order to determine the top k documents according tothe new system status.The difference between text and images emerges in the way the system status is modified. For the moment, however, we leave this aside so as to focus on a general RFprocedure for our model. Global, formbased retrieval is captured in the query language via concrete visual queries or text similarity queries, respectively, given bySI.qi and ST.qt.In the query evaluation procedure, these queries generate, through the function 8detailed in the last section, global similarity assertions, that is, assertions of the formSIi, qi, i iI, qiI, where qi is the query image, and i is an image of thedocument being evaluated that the decomposition of the query assertion hasidentified as a candidate image orSTt, qt, t tI, qtI, where qt and t are analogous to qi and i.It follows then that, in the context of our model, relevance judgments impact onglobal similarity assertions, which, as argued, are the only assertions that reflectthe kinds of queries suitable to RF.Based on this consideration, Figure 12 shows the basic functioning of a relevancefeedback mechanism for the model presented in the previous parts of this paper,relatively to a document doc. This figure outlines the nth RF pass, and follows thesame conventions as Figure 8, to which it directly relates.A Model of Multimedia Information Retrieval 953RF begins with the user performing an assessment of relevance on a ranked listof documents of course, this assessment is performed only once for each pass, andnot repeated for each document doc. In the first RF pass, that is, n 1, the rankedlist considered by the user is the one produced by the initial pass for n 1, theranked list on which relevance is assessed is the result of the previous RF pass.As Figure 12 shows, the assessment of relevance produces two different judgmentsets, those on text and those on images. In case the retrieved documents are simple,that is, texts or images, then, clearly, one of these two sets is empty. But our modelpermits the retrieval of structured documents incorporating texts and images thus,in the general case, the user is able to express judgment on both images and texts.The case may arise in which the query contains more than one global similaritycondition. There is no reason to rule out RF in this case it suffices to assume thateach similarity condition in the query is associated with the relevance judgmentsthat pertain to it.In illustrating the rest of the RF pass following Figure 12, we only refer to onemedium, say images it is understood that what we say applies to text as well. Thecentral task of an RF pass is carried out by the Image RF Module. This module takesas input a the relevance judgments on images, and b the current, i.e., nth docsimage global similarity assertions SIi, qi,  ni iI, qiI for n 1, these latter arethe image global similarity assertions deriving from 8Qdoc otherwise, theyresult from the previous RF pass. As output, the Image RF Module produces then  1th docs image global similarity assertions SIi, qi,  n1i iI, qiI. EachRF pass leaves therefore unchanged the logical part of each similarity assertion,that is, SIi, qi, which guides the DL TP to resolve the query assertion, while thetruthvalue, that is,  ni iI, qiI, is updated in order to reflect the users relevancejudgments. Sections 11.2 and 11.3 will present methods to compute the new truthvalues for text and images, respectively.After computing the new global similarity assertions, the procedure is in thesame conditions as the query evaluation procedure after the query decompositionand evaluation stage. Hence, the newly calculated assertions are input to the DLTP, along with structural and local similarity assertions, which are untouched byRF. Clearly, it is possible that RF be centered around some local image similaritycriterion, such as shape similarity in this case, the RF pass will produce, throughan appropriate module, new local shape similarity assertions.As the last step, the DL TP reevaluates the query to produce the n  1thdocument ranking.11.2. RELEVANCE FEEDBACK FOR TEXTS. The aim of this section is to comeup with a suitable value for  n1t tI, qtI, to be computed by the Text RF Moduleduring the nth RF pass.Typically, in text RF relevance judgments are ternary, that is, for each of the topk documents, a user may1 indicate relevance. In this case, the document ends up into a set RTn of documents judged relevant at the nth RF pass2 indicate irrelevance. In this case, the document ends up into a set N Tn ofdocuments judged not relevant at the nth RF pass3 give no indication. In this case, the document is ignored by RF.954 C. MEGHINI ET AL.These judgments are taken into account by the system by reweighting the queryterms based on the user relevance judgment. We must then specify how the weightsof the query layout index are recomputed on the basis of the sets RTn and NTn.The three best options that exist on this aspect have been shown to offer similarperformance improvements among them, we pick Rocchios, 1971 formula.Consequently, the function t that computes the degree of similarity betweentwo text layouts as a result of the nth RF pass, where the 0th RF pass is consideredto be the initial pass, can be stated as followsn1t tI, qtI  cos EtI, EqtIn1.The dynamic component of t is the query layout, whose index, as said above,is recomputed at each RF pass on the basis of the user judgments. Initially,for the initial pass, the query layout index is determined via one of the manyindexing methods for text, such as the tf  idf method mentioned earlier, that is,EqtI1  EqtI. The query layout index computed during the n1th RF pass n  1,according to the Rocchio formula, is given byEqtIn1    EqtIn   1RTn tlRTnEtlI    1N Tn tlN TnEtlI 34for all terms i, 1  i  m, where ,  and  are suitable constants such that      1. In words, 34 says that the i th term weight of the n  1th queryindex is a linear combination of the i th term weight of the previous query index, theaverage i th term weight of the layouts judged relevant, and the average i th weightof the layouts judged irrelevant. This very intuitive reweighting scheme directlystems from the best query vector that can be used for retrieval in the ideal situationin which all relevant documents are known. Typically,  is set to 1, while  ischosen greater than  as the information contained in judged relevant documentsis usually more important than that given by documents judged not relevant.11.3. RELEVANCE FEEDBACK FOR IMAGES. RF techniques for image retrievaldiffer substantially from those for text due to the fact that both image indexesand image similarity functions are much more elaborate than the text ones. Whiledecades of study and experimentation have established term weightsbased representations and the cosine function as very reasonable, if not optimal, choices fortext similarity, analogously solid choices for image similarity are still to be found.In fact, both the intuitive fact that images have a much richer perceptual contentthan text as well as the experimental evidence gathered so far seem to indicate thata representation of images that is, at the same time, as simple and as effective forretrieval as that of text is unlikely to exist.For these reasons, image indexes, in the most general case, are collections offeatures e.g., color, texture, shape each feature possibly being itself multiplyrepresented e.g., histogram and moments for color each representation being amultidimensional object, such as a vector, of its own. As a consequence, image similarity functions are typically linear combinations of distance measures relative tothe single features. Under these circumstances, RF can be used to calculate whatemphasis should be given to each feature, to each representation of the same feature, and to each component with each feature representation Rui et al. 1998.Other usages of the user judgments are possible, such as for altering the queryA Model of Multimedia Information Retrieval 955index Ciocca and Schettini 1999 however, given the composite nature of suchindexes, emphasizing and deemphasizing their components according to the userpreferences would seem more appropriate than numerically manipulating them.In order to illustrate RF on images concretely, in the rest of this section we introduce the image similarity function used by the prototype ARIANNA fully describedin Section 12, and show how the RF technique presented in Rui et al. 1998 can beapplied to this function. Although the function only considers one feature color,singularly represented via moments, what follows will suffice to demonstrate howan image RF technique can be integrated in our model.As for text, the function i for computing global image similarity is the same,whether the calculation is performed in the initial pass or in the course of a RFpass, the former being considered, as usual, the 0th RF pass. Then, the similaritybetween two image layouts i and i  resulting from the nth RF pass, is given byi i, in1 jH SBwn11 j i1 j  i 1 j  wn12 j  i2 j  i 2 j wn13 j i3 j  i 3 j , 35wherek j is the normalization of mkj , performed in order to assign equal emphasison each color moment, and wn1i j are the n  1th weights. The dynamic components of i i, i n1 are, as announced, its weights wn1i j , which are affected byRF. Initially, for the initial pass, the weights are fixed according to an objectivecriterion, assigning equal emphasis to each color moment. Hencew1i j 19for 1  i, j  3.The resulting  1i is the truthvalue associated with each image global similarityassertion generated during query evaluation. Let us now see howwn1i j is computed,for n  1.In the nth relevance assessment, the user is presented the top k images, on whichrelevance judgment is expressed, resulting in the set RIn, analogous to the set RTnobtained for text.5 The idea is to consider the vector V ni j containing the values ofthe color momenti j for all the images in RIn . If all such images have similar valuesfor i j , then i j can be considered as a good indicator of the users informationneed instead, if the V ni j values differ significantly, i j does not look like as a goodindicator. Letting  ni j stand for the standard deviation of Vni j , we then setwn1i j 1ni j W,where W is a normalization factor given by the sum of all weights wn1i j .Experimental results reported in Rui et al. 1998 show that this RF techniqueoffers a significant improvement in retrieval performance. These improvements5 In Rui et al. 1998, a richer model is presented, able to cope with multifeatured and multirepresentations similarity functions, and allowing 5ary relevance assessment. Since our similaritymodel is much simpler, the extra judgment levels would not be used hence, we have not consideredthem.956 C. MEGHINI ET AL.FIG. 13. Image acquisition in ARIANNA.mostly emerge after one RF pass, while successive passes only produce marginalbenefits.12. A Prototype ImplementationThe prototype system that we have developed, named ARIANNA, implements theform and contentbased retrieval of images, thus addressing one of the fundamentaltraits of the model, namely the integration of several kinds of image retrieval into aunique framework. ARIANNA consists of two main modules the indexing modulehereafter IM for short supporting the acquisition of images and the creation ofthe various representations needed for performing retrieval, and the query moduleQM, performing query evaluation.12.1. THE INDEXING MODULE. Figure 13 illustrates the various operationscomprising image acquisition in what may be considered as the typical sequencein this figure, rectangular boxes represent data, while ovals represent modules.12.1.1. Filtering and Size Reduction. Acquisition begins from an Input Image,which, in our case, may be any image in GIF or JPEG format. As a first step,the input image is reduced, if necessary, to the size handled by the system, whichis a parameter currently fixed to 128128 pixels. The reduction is performed bymeans of a resampling technique. After size reduction, the RGB color space isabandoned in favor of the HSB space, and noise reduction is performed on theA Model of Multimedia Information Retrieval 957FIG. 14. A Sample Input Image and the corresponding Basic Image.image, by applying a color median filter. As a result, the Basic Image is produced. Figure 14 presents a sample input image left and the corresponding basicimage.12.1.2. Segmentation. The task of the Segmentation Module is to derive theImage Layout from the Basic Image. The Image Layout is used solely to supportthe user in specifying the image regions that are to be annotated via Representsassertions. This may be surprising to the uninitiated to formbased image retrievalgiven that the model supports retrieval by color patches, it is natural to expectthat this kind of retrieval be implemented on top of the Image Layout. Unfortunately, the number of atomic regions in an image tends to be very large, often it isof the same order of magnitude as the image size, as it is very well known in the image retrieval context. In fact, image retrieval systems implement retrieval by colorpatches by relying on various approximations, aiming at cutting down the size ofthe computational space. ARIANNA is no exception.The derivation of the Image Layout implies two operations segmentation andcolor quantization. These operations are strictly related, and in fact they are bothperformed by the Segmentation Module. As already pointed out in Section 5.1, thesegmentation of color images is still an open problem, for which no universallyvalid algorithm is currently known. Successful techniques have been developed forspecific image types. However, given the generality of the tool being presented,we have adopted a flexible solution which produces seven different segmentations,each provided at several levels of quantization of the color space. The image indexercan use the image partition of anyone of these segmentations, or of any combinationof them, in order to select the image regions to be annotated.The channels on which the Basic Image is segmented are color, saturation, colorand saturation, and brightness. For each channel, three levels of quantizations areused, namely 3, 7, and 15 levels. In order to obtain these segmentations, textbooktechniques based on region growing have been employed these techniques, as wellas the others used for image segmentation, are not presented as not new nor centralto the present context. The color, saturation, color and saturation, and brightnesssegmentations of the sample image of Figure 14 are shown in Figure 15, in thisorder, from the top down in this figure, colors are used to highlight regions and donot have direct correspondence with those in the image.In addition, two segmentations based on edges are generated, each with threelevels of quantization 2, 7, and 15 colors. Edge detection techniques have beenemployed to obtain these segmentations see Figure 16.Finally, a segmentation on texture is derived, at two levels of quantization seeFigure 17. The reason for having these segmentations and not others are, of course,mostly empirical we presume that the combination of these segmentations covers958 C. MEGHINI ET AL.FIG. 15. Segmentation by color, saturation, color and saturation, and brightness at three levels ofquantization.A Model of Multimedia Information Retrieval 959FIG. 16. Segmentations by edge at three levels of quantization.FIG. 17. Segmentations by texture at two levels of quantization.a significant range of difficult images. Different presumptions would maybe leadto a different choice, but this is not important for the model.Figure 18 shows how the screen looks like after the segmentation operation hasbeen performed on the sample image. A 33 grid is used to display the variousimages in particular, the central image is the input image, and is surrounded by theseven different segmentations introduced above. Only one level is shown for eachsegmentation, and the user can move through the different levels by clicking on thecorresponding cell of the grid. The empty cell is reserved to region selection forannotation, as we will see in a moment.12.1.3. Naming. Prior to any indexing operation, the derived Image Layoutmust be identified as an individual of fuzzy ALCO, and this is the objective ofthe Naming operation. When this operation is requested, the user is asked to givea name for the image being acquired the system validates the proposed name bychecking that it is not used as the name of another image. From that point on, thename becomes the unique image identifier and two operations are possible GlobalFeature Extraction and Logical Annotation.12.1.4. Global Feature Extraction. This operation aims at deriving the representation of the image needed to answer user queries. The soobtained representation, named Global Image Index to stress its being relative to the whole image,is stored into an archive which is part of the Image Database. According to thedefinition of the8 function given in Figure 10, the following features are extractedfrom the Basic Image named iThe first three moments of the image true color histogram for each channel ofthe HBS color space. These features are extracted in order to compute the imagesimilarity function i , given in Section 5.2.960 C. MEGHINI ET AL.FIG. 18. The screen shown by IM after segmenting the sample image.The list of colors occurring in the image this is used in order to process colorqueries on atomic regions, that is, HAIR.HC.ci.In order to evaluate queries on color similarity i.e., HAIR.HC.SC.ci,the vector V is extracted, defined as follows. V has as many positions as theelements of the color set from which the user draws in specifying similar colorqueries on atomic regions 15 3 3 135, in our case the V position associated to the color cI gives the degree of similarity between cI and the color in theimage that best approximates it, that is, maxT c f T , cI, as required by8. The distance measure used as color similarity function c is the normalizationin the 0,1 interval of c3k1m iIkc  m jIkc,where c ranges on the three channels of the color space.12.1.5. Logical Annotation. This operation permits the specification of one ormore Content Descriptions for named images. Upon requesting it, IM automaticallycreates the layout identification assertion i.e., Selfi, 1, and supports the creationof the other kinds of assertions. In particularSituation anchoring is supported by asking the user for the name of the object tobe linked to the present image via an About assertion.Object anchoring is supported analogously, with an additional help to the user inselecting a region image. Region naming is done on demand, that is, whenevera new Represents assertion is to be specified, IM automatically creates a namefor the involved Annotation Region and proposes it to the indexer, who is free toA Model of Multimedia Information Retrieval 961FIG. 19. The screen shown by the IM during region selection.use or change it. Figure 19 shows the IM screen during the selection of a regionto be annotated via a Represents assertion. The region is constructed in the cellthat is at the right of the cell showing the input image. The user just clicks onany region of any segmentation and, as a result, the region containing the clickpoint is displayed. In the lower part of the screen, the identification assertion,automatically created by the system, is displayed in the format the TP expects.The specification of situation description assertions closes the annotation of animage. Each content description is then passed to the TP, which files it in the FuzzyALCO Knowledge Base.12.1.6. Local Feature Extraction Module. In order to support abstract visualqueries, a feature extraction task is performed on annotation regions. The extractedfeatures make up a Local Image Index, which is filed in an apposite archive of theImage Database. The structure of the local image index, relatively to the annotationregion r, is as follows see Figure 10The name of the region r.The region color histogram, used to process color queries on the region i.e.,HC.cr. Most of the entries in this histogram will be 0, since r is the unionof a few atomic regions. Consequently, the histogram is not expected to be large.The vector T, having as many positions as the vector V above, and used toevaluate similar color queries on annotation regions the T position associatedto the color cI, TcI , gives the maximum, for all colors l, of the values vcI, l,each of which is the minimum between the percentage of l in the region r andthe similarity between l and cI, that is, TcI  maxlCmin ferIl, cl, cI,as given in Figure 10.962 C. MEGHINI ET AL.FIG. 20. The QM displaying the result of a query.The shape of the region represented by the 8contour and by seven invariantmoments Mehtre et al. 1997. The former representation is used to processprecise shape queries i.e., HS.sr while the latter is used when theoptional similarity condition is given i.e., HS.SS.sr. In this latter case,the similarity function s is the Euclidean distance between the seven moments,normalized in the 0,1 interval.12.2. THE QUERY MODULE. The query module QM provides two basic servicesquery specification and query evaluation.12.2.1. Query Specification. Query specification supports the construction ofimage queries, according to the syntax given in Figure 6. The specification is performed by the user via the interface shown in Figure 20. During query specification,the system keeps track of the indications given by the user, so that, at the end of thespecification, it can automatically construct the query.Following the syntax of the image query language Figure 6, from the top down,there are two buttons labeled AND and OR in the bottom left part of the querypanel, which the user must first select in case the query involves conjunctions ordisjunctions image concepts, which are the elementary queries. Image concepts arespecified in the middle left area of the panel, which is divided in three main partsthat strictly reflect the language syntaxa part labeled GLOBAL, which is to be used for specifying concepts involvinga whole image these, in turn, can be of two types, corresponding to the twobuttons in this area of the panelA Model of Multimedia Information Retrieval 963Content, that is, About.C,where C is a content concept, that is, a standardALCO concept on image contents. The specification of such concept is givenin the top part of the query panel by inputting the concept in textual form.Form, that is, SI.qi. The query image qi is indicated by selection fromthe display area the widest area in the panel, where it can be loaded via theLoad Image button bottom left corner.a part labelled ATOMIC REGION, which is to be used for specifying a queryof the form HAIR.HC.D, where D is a color concept. In fact, there is onlyone button in this area, tagged COLOR. If this button is used with the Usesimilar color match box not checked, then it is understood that D is just a colorspecification, that is, c. If, on the other hand, the COLOR button is clickedwith the Use similar color match box checked, then it is understood that D isof the form SC.c. In either case, c is specified by clicking on the Pick colorbutton and then selecting a color in the color space depicted next to this button.a part labeled ANNOTATED REGION, which is to be used for specifyingqueries on image regions that have been previously annotated with a Representsassertions. The three buttons in this area, have the following usageclicking on the SEMANTIC button, implies that an image concept of theformHIR.Represents.C is being specified, where C is a content concept thatthe user is asked to textually input in the topmost part of the query panelclicking on the COLOR button, implies that an image concept of the formHIR.Represents.C t HC.D is being specified, where C is a contentconcept and D is a color concept the specification of these two kinds ofconcepts has been illustrated aboveclicking on the SHAPE button, implies that an image concept of the formHIR.Represents.C t HS.D is being specified, where C is a contentconcept and D is a shape concept. Concepts of the latter kind are input to thesystem in a perfectly analogous way to color concepts, except that the user isasked to draw the shape.12.2.2. Query Evaluation. Query evaluation is performed by the Image QueryEvaluation Procedure, which is in fact a restriction of the Query Evaluation Procedure previously illustrated see Figure 8 to image queries. More specifically,given an image query Q, the Image Query Assertion Builder iteratively producesa query assertion Qi for each acquired image i. The image assertion is passedon to the Image Query Decomposition  Evaluation IQDE for short functionwhich implements the evaluation by decomposition process described in detail inSection 10.Essentially, in deriving 8Qi, which in the present case only includes ImageAssertions, the IQDE accesses the Image Database in order to fetch the GlobalImage Index of i and the Local Image Index of each of is annotation regions, bothbuilt during is acquisition. The way these representations are used by the IQDE ismostly straightforward, once one bears in mind the definition of8 for image queriesand the structure of the representations themselves. For instance, upon evaluatingthe query assertion HAIR.HC.ci, the IQDE checks whether c is in the listof colors occurring in i, which is part of the global index if the check is positive,then the assertion HAIR.HC.ci, 1 is generated. Analogously, in order to964 C. MEGHINI ET AL.evaluate the query HIR.Ci, the IQDE generates an assertion HIRi, r1, 1 foreach annotation region r , then applies itself to the evaluation of Cr. As a finalexample, HC.SC.cr is evaluated by generating a fuzzy assertion whosedegree of truth is the value found in the TcI vector position, part of rs local index.The last step of the evaluation procedure is the invocation of the TP, to whichthe query assertion Qi is sent with the purpose of computing its m value againsta the context knowledge base 6D, b is content descriptions both these arepart of the Fuzzy ALCO Knowledge Base maintained by the TP and c the justcomputed 8Qi.13. ConclusionsWe have presented a view of multimedia information retrieval that reconciles in aunique, wellfounded framework the many functionalities that are found under theMIR label. The view has been introduced both at the informal and formal level, thelatter taking the shape of a logical model endowed with a syntax and a semantics.Implementation of the model has been discussed, and a simple prototype of multimodal image retrieval has been presented.At the technical level, the model makes two important contributions. First, at thesinglemedium level, it makes full and proper use of semantics and knowledge indealing with the retrieval of images and text, while offering, at the same time, thesimilaritybased kind of retrieval that is undoubtedly the most significant contribution of the research carried out in these two areas during the last decade. Moreimportantly, all these forms of retrieval coexist in a wellfounded framework, whichcombines in a neat way the different techniques, notably digital signal processingand semantic information processing, required to deal with the various aspects ofthe model. Secondly, at the multimedia level, the model addresses the retrieval ofstructural aggregates of images and texts, casting the single medium models ina framework informed by the same few principles. At present, to the best of ourknowledge, no other model offering the same functionalities as the one presentedhere exists.Since the representations handled by the model have a clean semantics, furtherextensions to the model are possible. For instance, image retrieval by spatial similarity can be added at the form level, effective spatial similarity algorithms e.g.,Gudivada and Raghavan 1995a can be embedded in the model via proceduralattachment, while significant spatial relationships can be included in content descriptions by drawing from the many formalisms developed within the qualitativespatial reasoning research community Cohn 1996. Analogously, the model canbe enhanced with the treatment of texturebased similarity image retrieval.We believe that the presented model can open the way to a novel approach tothe modelling of multimedia information, leading to the development of retrievalsystems able to cope in a formally neat and practically adequate way with documentsincluding text and images. More research is needed to attack delaysensitive media,such as audio and video, but we think that the present model offers a suitableframework for the development of conceptual models for these media.AppendixTHEOREM A.1. For all document basesA Model of Multimedia Information Retrieval 965Maxdeg6D 1 jn j , Qd  Maxdeg6D 8Cd 1 jn j , Qd.36PROOF. Let  be a fuzzy assertion. With 6 di , we denote the case where is satisfied by all document interpretations I satisfying 6. We show that for alln  0, 1,6D1 jn j di Qd, n iff 6D8Cd1 jn j  Qd, n. 37From 37, 36 quickly follows just take n being the maximal degree. Hence, letus prove 37.First of all, we show that for all   8Cd,6D 1 jn j di  38follows. The proof consists in a case analysis through the tables in Figures 9, 10and 11. Due to space limitations, we consider some of these cases only.Consider Figure 10 and consider a document interpretation I satisfying 6D 1 jn  j .1 Let x be SI.qii and let   8x be SIi, qi, i iI, qiI. By definitionof document interpretations, SIIiI, qiI  i iI, qiI. Therefore, I satisfiesSIi, qi, i iI, qiI.2 Let x be HIR.Ci and let   8x be HIRi, r j , 1. By definition of8x,I satisfies .3 Let x be HC.SC.cr and let   8x be x, n, wheren  maxcCmin ferIc, cc, cIBy definition of document interpretations, for all c  C,HCIrI, c  ferIcSCIc, cI  cc, cI.Therefore,HC.SC.cIrI maxcCminHCIrI, c, SC.cIc maxcCmin ferIc,maxcCminSCIc, c, cIc maxcCmin ferIc,SCIc, cI maxcCmin ferIc, cc, cIAs a consequence, I satisfies .All the other cases can be proved by similar arguments, thus obtaining the proofof 38.An immediate consequence of 38 is that all document interpretations satisfying6D1 jn  j also satisfy6D8Cd1 jn  j , and viceversa. Therefore,for all n  0, 1966 C. MEGHINI ET AL.6D 1 jn j di Qd, n iff 6D 8Cd 1 jn j di Qd, n.39Finally, we have to show that for all n  0, 16D 8Cd 1 jn j di Qd, niff 6D 8Cd 1 jn j  Qd, n, 40which combined with 39 proves 37.only if  Consider n  0, 1 and assume that 6D  8Cd 1 jn  j Qd, n. LetI be a document interpretation satisfying6D8Cd1 jn  j .Since I is an interpretation, by hypothesis it follows that I satisfies Qd, n.if  Consider n  0, 1 and assume that 6D  8Cd 1 jn  j diQd, n. Let I be an interpretation, not necessarily being a document interpretation, satisfying6D8Cd1 jn  j . We show thatI satisfies Qd, n. Consider the restriction of I to all the symbols appearing in 6D, 8Cd,1 jn  jand Qd. Since i Q can not query any negative information about SPSs, thatis, the negation connective  may involve content concepts only and there is nouniversal quantification on SPSs and i i I satisfies 8Qd, it follows that theinterpretation I, with respect to the restricted symbols, is a document interpretation.From hypothesis, I satisfies Qd, n follows, completing the proof.ACKNOWLEDGMENTS. Our thanks to Riccardo Marangone, who developedARIANNA, and to Antonio Lopreiato, who developed the fuzzy ALCO theoremprover.REFERENCESABITEBOUL, S., CLUET, S., CHRISTOPHIDES, V., MILO, T., MOERKOTTE, G., AND SIMEON, J. 1997. Querying documents in object databases. Int. J. Dig. Lib. 1, 1, 519.AIELLO, M., ARECES, C., AND RIJKE, M. 1999. Spatial reasoning for image retrieval. In Proceedings ofDL99, 8th International Workshop on Description Logics Linkoeping SE, 2327.ALP ASLANDOGAN, Y., THIER, C., YU, C., ZOU, J., AND RISHE, N. 1997. Using semantic contents andWordNet in image retrieval. In Proceedings of SIGIR97, 20th ACM Conference on Research and Development in Information Retrieval Philadelphia, Pa.. ACM, New York, pp. 286295.ANDERSON, A., AND BELNAP, N. 1975. EntailmentThe Logic of Relevance and Necessity. PrincetonUniversity Press, Princeton, N. J.BAADER, F., AND HANSCHKE, P. 1991. A schema for integrating concrete domains into concept languages.In Proceedings of IJCAI91, 12th International Joint Conference on Artificial Intelligence Sydney,Australia. pp. 452457.BAADER, F., AND HOLLUNDER, B. 1991. KRIS Knowledge representation and inference systemSystemdescription. ACM SIGART Bull. 2, 3, 814.BACH, J. R., FULLER, C., GUPTA, A., HAMPAPUR, A., HOROWITZ, B., HUMPHREY, R., JAIN, R., AND SHU,C.F. 1996. The Virage image search engine An open framework for image management. In Proceedings of SPIE96, 4th SPIE Conference on Storage and Retrieval for Still Images and Video DatabasesSan Jose, Calif.. pp. 7687.BERRUT, C., MULHEM, P., FOUREL, F., AND MECHKOUR, M. 1998. The PRIME information retrievalsystem applied on a medical corpus. In Proceedings of MINAR98,Workshop on Multimedia InformationAnalysis and Retrieval Hong Kong, China. Lecture Notes in Computer Science, vol. 1464. SpringerVerlag, Heidelberg, Germany, pp. 224241.A Model of Multimedia Information Retrieval 967BOLLINGER, T., AND PLETAT, U. 1991. The LILOG knowledge representation system. ACM SIGARTBull. 2, 3, 2227.BORGIDA, A. 1995. Description logics in data management. IEEE Trans. Knowl. Data Eng. 7, 5, 671682.BOUET, M., AND DJERABA, C. 1998. Visual contentbased retrieval in image databases with relevancefeedbacks. In Proceedings of MMDBMS98, 4th International Workshop on MultiMedia DatabaseManagement Systems Dayton, Ohio. pp. 98105.BRACHMAN, R. J., MCGUINNESS, D. L., PATELSCHNEIDER, P. F., ALPERIN RESNICK, L., AND BORGIDA,A. 1991. Living with CLASSIC When and how to use a KLONElike language. In Principles ofSemantic Networks, J. F. Sowa, Ed. MorganKaufmann, San Mateo, Calif., pp. 401456.BRACHMAN, R. J., AND SCHMOLZE, J. G. 1985. An overview of the KLONE knowledge representationsystem. Cog. Sci. 9, 2, 171216.BRACHMAN, R. J., SELFRIDGE, P. G., TERVEEN, L. G., ALTMAN, B., BORGIDA, A., HALPERN, F., KIRK, T.,LAZAR, A., MCGUINNESS, D. L., AND RESNICK, L. A. 1992. Knowledge representation support fordata archaeology. In Proceedings of CIKM92, International Conference on Information and KnowledgeManagement Baltimore, Md.. pp. 457464.BUCHHEIT, M., DONINI, F. M., AND SCHAERF, A. 1993. Decidable reasoning in terminological knowledgerepresentation systems. In Proceedings of IJCAI93, 13th International Joint Conference on ArtificialIntelligence Chambery, France. pp. 704709.BUONGARZONI, P., MEGHINI, C., SALIS, R., SEBASTIANI, F., AND STRACCIA, U. 1995. Logical and computational properties of the description logic MIRTL. In Proceedings of DL95, 4th International Workshopon Description Logics Roma, Italy. pp. 8084.CIOCCA, R., AND SCHETTINI, R. 1999. Using a relevance feedback mechanism to improve contentbasedimage retrieval. In Proceedings of VISUAL99, 3rd International Conference on Visual InformationSystems Amsterdam, The Netherlands. Lecture Notes in Computer Science, vol. 1614. SpringerVerlag,Heidelberg, Germany, pp. 107114.COHN, A. G. 1996. Calculi for qualitative spatial reasoning. In Artificial Intelligence and SymbolicMathematical Computation, J. Calmet, J. Campbell, and J. Pfalzgraf, Eds. SpringerVerlag, Heidelberg,Germany, pp. 124143.CRESTANI, F., LALMAS, M., AND VAN RIJSBERGEN, C. J., EDS. 1998. Logic and Uncertainty in Information Retrieval Advanced Models for the Representation and Retrieval of Information. Kluwer AcademicPublishing, Dordrecht, The Netherlands.DAVIDSON, D. 1994. Truth and meaning. In Inquiries into truth and interpretation. Collected essays byDonald Davidson. Clarendon Press, Oxford, England, pp. 1736.DEL BIMBO, A., MUGNAINI, M., PALA, P., TURCO, F., AND VERZUCOLI, L. 1997. Image retrieval by colorregions. In Proceedings of ICIAP97, 9th International Conference on Image Analysis and ProcessingFirenze, Italy. Lecture Notes in Computer Science vol. 1311. SpringerVerlag, Heidelberg, Germany,pp. 180187.DEL BIMBO, A., AND PALA, P. 1997. Visual image retrieval by elastic matching of user sketches. IEEETrans. Patt. Anal. Mach. Int. 19, 2, 121132.DEVANBU, P., BRACHMAN, R. J., SELFRIDGE, P. J., AND BALLARD, B. W. 1991. LASSIE A knowledgebased software information system. Commun. ACM 34, 5, 3649.DUBOIS, D., AND PRADE, H. 1980. Fuzzy Sets and Systems. Academic Press, New York.DUNLOP, M. D. 1997. The effect of accessing nonmatching documents on relevance feedback. ACMTrans. Inf. Syst. 15, 2, 137153.DUSCHKA, M. O., AND LEVY, Y. A. 1997. Recursive plans for information gathering. In Proceedingsof IJCAI97, 15th International Joint Conference on Artificial Intelligence Nagoya, Japan. pp. 778784.FALOUTSOS, C. 1996. Searching Multimedia Databases by Content. Kluwer Academic Publishers,Dordrecht, The NetherlandsFALOUTSOS, C., BARBER, R., FLICKNER, M., HAFNER, J., AND NIBLACK, W. 1994. Efficient and effectivequerying by image content. J. Int. Inf. Syst. 3, 34, 231262.FUHR, N., AND BUCKLEY, C. 1991. A probabilistic learning approach for document indexing. ACM Trans.Inf. Syst. 9, 3, 223248.GOBLE, C. A., HAUL, C., AND BECHHOFER, S. 1996. Describing and classifying multimedia using thedescription logic GRAIL. In Proceedings of SPIE96, 4th SPIE Conference on Storage and Retrieval forStill Images and Video Databases San Jose, Calif.. pp. 132143.GUDIVADA, V. N. 1995. Multimedia systemsAn interdisciplinary perspective. ACM Comput.Surv. 27, 4, 545548.968 C. MEGHINI ET AL.GUDIVADA, V. N., AND RAGHAVAN, V. V. 1995a. Design and evaluation of algorithms for image retrievalby spatial similarity. ACM Trans. Inf. Syst. 13, 2, 115144.GUDIVADA, V. N., AND RAGHAVAN, V. V. 1995b. Guest editors introduction to the special issue oncontentbased image retrieval. IEEE Comput. 28, 9, 1822.GUDIVADA, V., AND RAGHAVAN, V. V. 1997. Modeling and retrieving images by content. Inf. Proc.Manage. 33, 4, 427452.GUGLIELMO, E. J., AND ROWE, N. C. 1996. Naturallanguage retrieval of images based on descriptivecaptions. ACM Trans. Inf. Syst. 14, 3, 237267.GUPTA, A., SANTINI, S., AND JAIN, R. 1997. In search of information in visual media. Commun.ACM 40, 12, 3442.HIRATA, K., AND KATO, T. 1992. Query by visual example. In Proceedings of EDBT92, 3rd InternationalConference on Extending Database Technology Wien, Austria. pp. 5671.JAIN, A. K., AND VAILAYA, A. 1996. Image retrieval using color and shape. Patt. Rec. 29, 8, 12331244.KUNDU, S., AND CHEN, J. 1994. Fuzzy logic or Lukasiewicz logic A clarification. In Proceedingsof ISMIS94, 8th International Symposium on Methodologies for Intelligent Systems, Z. W. Ras andM. Zemankova, Eds. Charlotte N.C.. Lecture Notes in Computer Science, vol. 869. SpringerVerlag,Heidelberg, Germany, pp. 5664.LEE, R. C. 1972. Fuzzy logic and the resolution principle. J. ACM 19, 1, 109119.LEWIS, D. D. 1992. An evaluation of phrasal and clustered representations on a text categorization task.In Proceedings of SIGIR92, 15th ACM International Conference on Research and Development inInformation Retrieval Kobenhavn, Denmark. ACM, New York, pp. 3750.LIU, F., AND PICARD, R. 1996. Periodicity, directionality, and randomness Wold features for imagemodelling and retrieval. IEEE Trans. Patt. Anal. Mach. Int. 18, 7, 722733.LIU, Z., AND SUN, J. 1997. Structured image retrieval. J. Vis. Lang. Comput. 8, 3, 333357.LUNDQUIST, C., GROSSMAN, D. A., AND FRIEDER, O. 1997. Improving relevance feedback in the vector space model. In Proceedings of CIKM97, 6th ACM International Conference on Information andKnowledge Management Las Vegas, Nev.. ACM, New York, pp. 1623.MACGREGOR, R. 1991. Inside the LOOM description classifier. SIGART Bull. 2, 3, 8892.MARCUS, S., AND SUBRAHMANIAN, V. 1996. Foundations of multimedia information systems. J.ACM 43, 3, 474523.MCGUINNESS, D. L., AND WRIGHT, J. 1998. An industrial strength description logicbased configuratorplatform. IEEE Int. Syst. 13, 4, 6977.MEGHINI, C. 1995. An image retrieval model based on classical logic. In Proceedings of SIGIR95, 18thACM Conference on Research and Development in Information Retrieval Seattle, Wash.. ACM, NewYork, pp. 300308.MEGHINI, C., RABITTI, F., AND THANOS, C. 1991. Conceptual modelling of multimedia documents. IEEEComput. 24, 10, 2330.MEGHINI, C., SEBASTIANI, F., AND STRACCIA, U. 1997a. The terminological image retrieval model. InProceedings of ICIAP97, 9th International Conference on Image Analysis and Processing Firenze,Italy. Lecture Notes in Computer Science, vol. 1311. SpringerVerlag, Heidelberg, Germany, pp.156163.MEGHINI, C., SEBASTIANI, F., AND STRACCIA, U. 1997b. Modelling the retrieval of structured documentscontaining texts and images. In Proceedings of ECDL97, 1st European Conference on Research andAdvanced Technology for Digital Libraries Pisa, Italy. Lecture Notes in Computer Science, vol. 1324.SpringerVerlag, Heidelberg, Germany, pp. 325344.MEGHINI, C., SEBASTIANI, F., AND STRACCIA, U. 1998. MIRLOG A logic for multimedia informationretrieval. In Logic and Uncertainty in Information Retrieval Advanced Models for the Representationand Retrieval of Information, F. Crestani, M. Lalmas, and C. J. van Rijsbergen, Eds. Kluwer AcademicPublishing, Dordrecht, The Netherlands, pp. 151185.MEGHINI, C., SEBASTIANI, F., STRACCIA, U., AND THANOS, C. 1993. A model of information retrievalbased on a terminological logic. In Proceedings of SIGIR93, 16th ACM Conference on Research andDevelopment in Information Retrieval Pittsburgh, Pa.. ACM, New York, pp. 298307.MEGHINI, C., AND STRACCIA, U. 1996. A relevance terminological logic for information retrieval. InProceedings of SIGIR96, 19th ACM Conference on Research and Development in Information RetrievalZurich, Switzerland. ACM, New York, pp. 197205.MEHTRE, B., KANKANHALLI, M. S., AND LEE, W. F. 1997. Shape measures for contentbased imageretrieval A comparison. Inf. Proc. Manage. 33, 3, 319336.A Model of Multimedia Information Retrieval 969MIZZARO, S. 1997. Relevance The whole history. J. Amer. Soc. Inf. Sci. 48, 9, 810832.MYERS, K. L. 1994. Hybrid reasoning using universal attachment. Artif. Int. 67, 2, 329375.NAVARRO, G., AND BAEZAYATES, R. 1995. A language for queries on structure and contents of textual databases. In Proceedings of SIGIR95, 18th ACM Conference on Research and Development inInformation Retrieval Seattle, Wash.. ACM, New York, pp. 93101.NAVARRO, G., AND BAEZAYATES, R. 1997. Proximal nodes A model to query document databases bycontent and structure. ACM Trans. Inf. Syst. 15, 4, 400435.ORPHANOUDAKIS, S., CHRONAKI, C., AND KOSTOMANOLAKIS, S. 1994. I2C A system for the indexing,storage, and retrieval of medical images by content. Med. Informat. 19, 2, 109122.OUNIS, I., AND CHEVALLET, J.P. 1996. Using conceptual graphs in a multifaceted logical model forinformation retrieval. In Proceedings of DEXA96, 7th International Conference on Database and ExpertSystems Applications Zurich, Switzerland. Lecture Notes in Computer Science, vol. 1134. SpringerVerlag, Heidelberg, Germany, pp. 812823.PELTASON, C. 1991. The BACK systemAn overview. SIGART Bull. 2, 3, 114119.PENTLAND, A., PICARD, R., AND SCLAROFF, S. 1994. Photobook Contentbased manipulation of imagedatabases. In Proceedings of SPIE94, 2nd SPIE Conference on Storage and Retrieval for Still Imagesand Video Databases San Jose, Calif.. pp. 3447.PETRAKIS, E. G., AND FALOUTSOS, C. 1997. Similarity searching in medical image databases. IEEETrans. Data Knowl. Eng. 9, 3, 435447.RAVELA, S., AND MANMATHA, R. 1997. Image retrieval by appearance. In Proceedings of SIGIR97,20th ACM Conference on Research and Development in Information Retrieval Philadelphia, Pa.. ACM,New York, pp. 278285.ROCCHIO, J. J. 1971. Relevance feedback in information retrieval. In The SMART retrieval systemExperiments in automatic document processing, G. Salton, Ed. PrenticeHall, Englewood Cliffs, N.J.,pp. 313323.ROLLEKE, T., AND FUHR, N. 1998. Information retrieval with probabilistic datalog. In Logic and Uncertainty in Information Retrieval Advanced Models for the Representation and Retrieval of Information,F. Crestani, M. Lalmas, and C. J. van Rijsbergen, Eds. Kluwer Academic Publishing, Dordrecht, TheNetherlands, pp. 221245.ROSENFELD, A., AND KAK, A. C. 1982. Digital Picture Processing, 2nd ed. Academic Press, New York.RUI, Y., HUANG, T., ORTEGA, M., AND MEHROTRA, S. 1998. Relevance feedback A power tool forinteractive contentbased image retrieval. IEEE Trans. Circ. Syst. Video Tech. 8, 5, 644655.SALTON, G. 1989. Automatic Text Processing The Transformation, Analysis, and Retrieval of Information by Computer. AddisonWesley, Reading, Mass.SALTON, G., AND BUCKLEY, C. 1988. Termweighting approaches in automatic text retrieval. Inf. Proc.Manage. 24, 5, 513523.SANTINI, S., GUPTA, A., AND JAIN, R. 1999. User interfaces for emergent semantics in image databases.In Proceedings of DS8, 8th IFIP Working Conference on Database Semantics Rotorua, New Zealand.SARACEVIC, T. 1975. Relevance a review of and a framework for the thinking on the notion in informationscience. J. Amer. Soc. Inf. Sci. 26, 6, 321343.SCHAUBLE, P., AND KNAUS, D. 1992. The various roles of information structures. In Proceedings of the16th Annual Conference of the Gesellschaft fur Klassifikation, O. Opitz, B. Lausen, and R. Klar, Eds.Dortmund, Germany. Springer Verlag, Heidelberg, Germany.SCHMIDTSCHAUSS, M., AND SMOLKA, G. 1991. Attributive concept descriptions with complements.Artif. Int. 48, 1, 126.SEBASTIANI, F. 1994. A probabilistic terminological logic for modelling information retrieval. In Proceedings of SIGIR94, 17th ACM International Conference on Research and Development in InformationRetrieval. Dublin, IE, 122130.SEBASTIANI, F. 1998. On the role of logic in information retrieval. Inf. Proc. Manage. 34, 1, 118.SEBASTIANI, F. 1999. Towards a logical reconstruction of information retrieval theory. Cybernet.Syst. 30, 5, 411428.SMEATON, A. F., AND QUIGLEY, I. 1996. Experiments on using semantic distances between wordsin image caption retrieval. In Proceedings of SIGIR96, 19th International Conference on Research and Development in Information Retrieval Zurich, Switzerland. ACM, New York, pp. 174180.SMITH, J. R., AND CHANG, S.F. 1994. Transform features for texture classification and discriminationin large image databases. In Proceedings of the 1st IEEE International Conference on Image ProcessingAustin, Tex.. IEEE Computer Society Press, Los Alamitos, Calif., pp. 407411.970 C. MEGHINI ET AL.SMITH, J. R., AND CHANG, S.F. 1996. Visualseek A fully automatic contentbased image query system.In Proceedings of MM96, 4th ACM International Conference on Multimedia Boston, Mass.. ACM,New York, pp. 8793.SMITH, J. R., AND CHANG, S.F. 1997. Visually searching the Web for content. IEEE Multimedia 4, 3,1220.SOWA, J. F. 1984. Conceptual Structures Information Processing in Mind and Machine. AddisonWesley, Reading, Mass.SPARCK JONES, K., AND WILLETT, P., Eds. 1997. Readings in information retrieval. MorganKaufmann,San Mateo, Calif.SPERBER, D., AND WILSON, D. 1986. Relevance. Communication and Cognition. Basil Blackwell,Oxford, England.SRIHARI, R. 1995. Automatic indexing and contentbased retrieval of captioned images. IEEE Comput. 28, 9, 4956.STRACCIA, U. 1996. Document retrieval by relevance terminological logics. In Proceedings of MIRO95,Workshop on Multimedia Information Retrieval, I. Ruthven, Ed. Glasgow, EnglandSTRACCIA, U. 1997a. A fourvalued fuzzy propositional logic. In Proceedings of IJCAI97, 15th International Joint Conference on Artificial Intelligence Nagoya, Japan. pp. 128133.STRACCIA, U. 1997b. A sequent calculus for reasoning in fourvalued description logics. In Proceedings of TABLEAUX97, International Conference on Analytic Tableaux and Related Methods PontaMousson, France. Lecture Notes in Computer Science, vol. 1227. SpringerVerlag, Heidelberg, Germany,pp. 343357.STRACCIA, U. 1998. A fuzzy description logic. In Proceedings of AAAI98, 15th Conference of theAmerican Association for Artificial Intelligence Madison, Wisc.. pp. 594599.STRACCIA, U. 2000. A framework for the retrieval of multimedia objects based on fourvalued fuzzydescription logics. In Soft Computing in Information Retrieval Techniques and Applications, F. Crestaniand G. Pasi, Eds. Physica Verlag, Heidelberg, Germany, pp. 332357.STRICKER, M., AND ORENGO, M. 1995. Similarity of color images. In Proceedings of SPIE95, 3rdSPIE Conference on Storage and Retrieval for Still Images and Video Databases San Jose, Calif..pp. 381392.SWAIN, M., AND BALLARD, D. 1991. Color indexing. Int. J. Comput. Vision 7, 1, 1132.THANOS, C., ED. 1990. Multimedia Office Filing. The MULTOS Approach. NorthHolland, Amsterdam,The Netherlands.TRESP, C., AND MOLITOR, R. 1998. A description logic for vague knowledge. In Proceedings of ECAI98,13th European Conference on Artificial Intelligence Brighton, England. pp. 361365.VAN RIJSBERGEN, C. J. 1986. A nonclassical logic for information retrieval. The Comput. J. 29, 481485.WEIDA, R., AND LITMAN, D. 1992. Terminological reasoning with constraint networks and an applicationto plan recognition. In Proceedings of KR92, 3rd International Conference on Principles of KnowledgeRepresentation and Reasoning Cambridge, Mass.. pp. 282293.WOOD, M., CAMPBELL, N., AND THOMAS, B. 1998. Iterative refinement by relevance feedback in contentbased digital image retrieval. In Proceedings of MM98, 6th ACM International Conference on Multimedia Bristol, England. ACM, New York, pp. 1320.YEN, J. 1991. Generalizing term subsumption languages to fuzzy logic. In Proceedings of IJCAI91,12th International Joint Conference on Artificial Intelligence Sydney, Australia. pp. 472477.ZADEH, L. A. 1965. Fuzzy sets. Inf. Contr. 8, 3, 338353.RECEIVED APRIL 1999 REVISED JULY 2001 ACCEPTED JULY 2001Journal of the ACM, Vol. 48, No. 5, September 2001.
