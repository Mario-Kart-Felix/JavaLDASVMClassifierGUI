Workload Characterization of the1998 World Cup Web SiteMartin Arlitt, Tai JinInternet Systems and Applications LaboratoryHP Laboratories Palo AltoHPL199935R.1September, 1999Email arlitt, taihpl.hp.comWorldWideWeb, workloadcharacterization,performance,servers, caching,World CupThis paper presents a detailed workload characterization studyof the 1998 World Cup Web site. Measurements from this sitewere collected over a three month period. During this time thesite received 1.35 billion requests, making this the largest Webworkload analyzed to date. By examining this extremely busysite and through comparison with existing characterizationstudies we are able to determine how Web server workloads areevolving. We find that improvements in the cachingarchitecture of the WorldWide Web are changing theworkloads of Web servers, but that major improvements to thatarchitecture are still necessary. In particular, we uncoverevidence that a better consistency mechanism is required forWorldWide Web caches. Copyright HewlettPackard Company 1999Internal Accession Date OnlyIntroductionArlitt and Jin Page 2 of 901 INTRODUCTIONThe 16th Federation Internationale de Football Association FIFA World Cup was held inFrance from June 10th through July 12th, 1998. France 98, as the 16th FIFA World Cup wascommonly called, was the most widely covered media event in history 36. An estimatedcumulative television audience of 40 billion watched the 64 matches of France 98, morethan twice the cumulative television audience of the 1996 Summer Olympic Games inAtlanta. The Web site for France 98, www.france98.com, also proved to be very popular,receiving more than 1 billion client requests during the tournament.This paper presents a detailed workload characterization of the France 98 Web site. Thisstudy provides insights on the current state of the WorldWide Web. By comparing theresults of this study to earlier Web characterization studies we are able to determine howWeb workloads are evolving as the Web increases in popularity and utilizes new technologies.Some of the more significant characteristics that we observed in the World Cup workload,and the performance implications of these characteristics include HTTP1.1 clients are becoming more prevalent, accounting for 21 of all requests.Widespread deployment of HTTP1.1 compliant clients and servers is necessary for thefunctionality of HTTP1.1 to be fully utilized. 88 of all requests were for Image files an additional 10 were for HTML files, indicating that most user interest was in static i.e., cacheable files.IntroductionArlitt and Jin Page 3 of 90 almost 19 of all responses were Not Modified, indicating that cache consistency traffichad a greater impact in the World Cup workload than in previous Web server workloads3 the workload was quite bursty although over longer time scale e.g., hours or more thearrival of these bursts was quite predictable for timeouts of 100 seconds or less, many users sessions contained only a singlerequest and a single response. We believe that this characteristic is due to the improvedWeb caching architecture that now exists. This characteristic has possible implicationson both server and protocol design during periods of peak user interest in the World Cup site the volume of cache consistency traffic increased dramatically. This indicates that the lack of an efficient consistency mechanism either the specification or utilization of one is preventing Web cachesfrom eliminating flash crowds in the network and at the servers, which is supposed to beone of the main benefits of Web caching.Workload characterization plays an important role in systems design. It allows us to understand the current state of the system. By characterizing the system over time we can learnwhat effects changes to the system have had. Workload characterization is also crucial tothe design of new system components. In this paper we focus on the characterization of aWeb server workload. We compare our results to those from previous studies e.g., 328to determine how Web server workloads have changed over time. Furthermore, theThe 1998 World CupArlitt and Jin Page 4 of 90extremely heavy workload of the World Cup site allows us to predict what the workloads offuture Web servers may look like, so that we may plan accordingly.Web server workload characterization is only one of the necessary steps for understandingthe changes occurring in Web traffic. Research efforts on Web client workloads e.g., 5,Web proxy workloads e.g., 278151718222733, network traffic characterizations e.g., 34 as well as HTTP analyses e.g., 4212330 are all required in order betterunderstand the Web.The remainder of the paper is organized as follows. Section 2 provides background information on the 1998 World Cup, focusing on the structure of the tournament. Section 3 introduces the World Cup Web site and describes the technology that it utilized. Section 4discusses the collection and reduction of the data set used in the workload characterizationstudy. Section 5 presents the results of our workload characterization study. Section 6 analyzes a particularly busy segment of the World Cup workload and compares the results tothe overall study in Section 5. Section 7 describes in more detail the performance implications of the results from Section 5 and Section 6. Section 8 summarizes the contributions ofour paper and lists areas of future work.2 THE 1998 WORLD CUPIn order to better understand the nature of the workload from the France 98 Web site knowledge of the tournament itself is required. In this section we provide a brief overview of theThe 1998 World CupArlitt and Jin Page 5 of 90World Cup, focusing on the France 98 tournament in particular. Additional information onthe World Cup and the France 98 tournament is available on the FIFA Web site 20.The FIFA World Cup is a tournament that is held once every four years to determine the bestfootball soccer team in the world. This competition is open to all teams that represent theFIFA affiliated national football association of their respective countries. Due to the largenumber of teams interested in participating, a qualifying round is now used to select theteams that will play in the World Cup tournament. The qualifying round for France 98 washeld from March 1996 until November 1997. Of the 172 countries that entered the qualifyinground 30 were selected to compete in France 98, along with the host country, France, andthe reigning champions, Brazil.France 98 began on June 10th, 1998 and ended on July 12th, 1998. The tournament consisted of several rounds of play. The opening round lasted from June 10th until June 26th.During this round the 32 participating teams were divided into eight groups. Each team thenplayed one match against each of the other teams in its group. The top two finishers fromeach group qualified for the second round, known as the Round of 16. This round lastedfrom June 27th through July 1st. Beginning with this round the winner of each matchadvanced to the next round while the loser was eliminated. The remaining rounds of thetournament were the Quarter Finals, held on July 3rd and 4th the Semi Finals, held on July7th and 8th and the Final, held on July 12th. A match to determine the third place finisherwas held on July 11th for the losing teams of the Semi Final round.The 1998 World Cup Web SiteArlitt and Jin Page 6 of 90During the opening round each match was 90 minutes in length and was played in two 45minute halves. During all subsequent rounds each match required a winner, so several tiebreaking measures were used. If the match was tied after 90 minutes of regulation play, a30 minute overtime period was played, with the first team to score declared the winner. If awinner had still not been determined, penalty kicks were used to decide which team wouldadvance to the next round.3 THE 1998 WORLD CUP WEB SITEThe Web site of the 1998 World Cup, www.france98.com, provided Internetsavvy footballfans around the world with a wide range of information. Besides being able to access thecurrent scores of the football matches in real time, fans could also access previous matchresults, player statistics, player biographies, team histories, information on the stadiums,facts about local attractions and festivities, as well as a wide range of photos and sound clipsfrom the matches and interviews with players and coaches. Fans could also download freesoftware, such as World Cup screensavers and wallpapers from the France 98 Web site. Allof the information on the site was available in English and French.The France 98 Web site went online May 6th, 1997. The site was established through thecooperative efforts of the Official Technology Suppliers to the World Cup EDS, France Telecom, HewlettPackard, and Sybase. In anticipation of significant interest from the Internetcommunity in this Web site, emphasis was put on deploying an available, reliable and lowlatency platform to power the Web site. During the tournament 30 servers were used, disCollection and Reduction of DataArlitt and Jin Page 7 of 90tributed across four locations 4 servers in Paris, France 10 servers in Herndon, Virginia 10servers in Plano, Texas and 6 servers in Santa Clara, California. All of the Web pages werecreated andor modified in France. New or updated pages were sent from France to thePlano site, which then distributed them to the other U.S. based locations. A Cisco Distributed Director was used to distributed client requests across the four locations. At each location various load balancers were used to distribute the incoming requests among theavailable servers.4 COLLECTION AND REDUCTION OF DATAThe data set used in this workload characterization study is composed of the access logscollected from each of the servers used in the World Cup Web site. The access logs fromeach server were archived on a daily basis. For this study all of the access logs from May1st, 1998 until July 23rd, 1998 were analyzed.Each access log is in the Common Log Format 35. For every request received by the Webserver, the following information is storedremotehost rfc931 authuser date request status bytesThese fields are defined as follows remotehost   the IP address of the client issuing the request rfc931 the remote loginame of the user authuser the username as which the user has authenticated himself date   the date and time of the requestCollection and Reduction of DataArlitt and Jin Page 8 of 90 request  the request line exactly as it came from the client status  the HTTP response status code returned to the client bytes  the content length of the document transferredThe request line from the client includes the method e.g., GET, HEAD to be applied to therequested resource, the name of the resource e.g., index.html, and the protocol version inuse e.g., HTTP1.0.An example of a fabricated access log entry is192.168.0.1   10Jun1998000001 0200 GET index.html HTTP1.0 200 1000This entry tells us that on June 10th, 1998, at one second past midnight, local time in France,the client 192.168.0.1 asked this server for the file index.html. The server was informedthat the client supported HTTP1.0. The server successfully responded to this request thisis indicated by the status code of 200 and transferred 1,000 bytes of content data to the client.Table 1 summarizes the access logs that we acquired from the World Cup site. In total morethan 1.35 billion requests were received by the Web site during the collection period, andTable 1 Summary of Access Log Characteristics Raw DataDuration May 1st  July 23, 1998Total Requests 1,352,804,107Avg RequestsMinute 10,796Total Bytes Transferred GB 4,991Avg Bytes TransferredMinute MB 40.8Collection and Reduction of DataArlitt and Jin Page 9 of 90almost 5 TB of data sent to clients. The site averaged nearly 11,000 requests per minuteand 41 MB of data were transferred to clients per minute on average.Our first concern was with the size of the raw access logs  125 GB in total, 14 GB whencompressed. In order to make our workload analyses more efficient we chose to convert thelogs to a more compact binary format. We reduced the storage requirements in two ways.One approach removed unnecessary data. For example, we deleted the rfc931 andauthuser fields as they were not used by the servers and thus provided no information thatwas of interest to us. The second tactic that we used to reduce the size of the data set wasto represent the remaining fields in more efficient ways when possible. For example, wemapped all of the URLs to unique integers. We also mapped each distinct IP address to aunique integer identifier. Finally, we collated the access logs of all the servers by requesttime. The resulting binary log file was 25 GB in size, 9 GB when compressed. Furthermore,each request is now in a fixed size structure, which also helps to improve the efficiency ofour analyses. Since all of the mappings we performed are reversible, we did not lose anysignificant information in the reduction process. There was some incorrect information inthe raw access logs. For example, some of the status 304 replies included a nonzeroresponse size. We left this incorrect information in the reduced log in case it is of interest forother researchers we ignored it in our analyses.Despite the vast amount of data that was collected by each of the servers, a lot of interestinginformation is still not available. For example, the access logs do not appear to contain information on the number of aborted connections that occurred. As a result, the number ofWorkload CharacterizationArlitt and Jin Page 10 of 90bytes transferred reported in Table 1 overestimates the actual data traffic. The access logshave no information on either request or response header sizes which makes it impossibleto know the total HTTP traffic for the site. Unfortunately the access logs have no preciseinformation on when file modifications occurred. While the logs do have a timestamp thatrecords when the request was received by the server, it has a one second resolution whichis too coarsegrained to be of use for numerous analyses e.g., interrequest times. Theseare just a few examples of useful information that could be added to a revised log file format.5 WORKLOAD CHARACTERIZATIONThis section presents the results of our workload characterization. Section 5.1 discussesvarious statistical characteristics of the data set, including the protocol version, method,response status code and file type distributions. Section 5.2 analyzes the usage of theWorld Cup site. Section 5.3 describes the file and transfer size distributions while Section5.4 looks at the file referencing patterns. Section 5.5 investigates the usage of embeddedfiles on the Web pages of the World Cup site. Section 5.6 presents an analysis of user sessions.Workload Characterization Statistical CharacteristicsArlitt and Jin Page 11 of 905.1 Statistical CharacteristicsOur first analysis in this section looks at the version of the HyperText Transfer ProtocolHTTP supported by the client issuing the request. Table 2 shows the results of this analysis. As expected, HTTP1.0 is still the protocol used by most of the clients. However, theresults indicate that a significant portion of the traffic, over 20, came from clients that support HTTP1.1. This indicates that browsers that support HTTP1.1 are slowly replacingbrowsers that do not. These results do not indicate what percentage of the requests to theWorld Cup site, if any, actually used HTTP1.1 functionality. We did not find any requestsfrom clients that supported only HTTP0.9. We did discover 270,561 requests 0.02 thatdid not have a valid HTTP version entered in the access log. We chose to ignore this erroras it will have no significant effect on our results.Our next analysis looked at the resource method included in the each client request. Table 3shows the distribution of requests by the method. 99.88 of all requests contained the GETmethod, which indicates that the stated URL is simply to be retrieved 19. Included in thiscategory are conditional GETs e.g., requests that include the IfModifiedSince headerTable 2 Breakdown of HTTP Version Supported by ClientHTTP Version  of Requests  of Content Data Transferred0.9 0.00 0.001.0 78.66 79.831.1 21.32 20.09x.x 0.02 0.08Total 100.00 100.00Workload Characterization Statistical CharacteristicsArlitt and Jin Page 12 of 90field and partial GETs e.g., requests that include the Range header field 19. Unfortunately there is insufficient information in the log files to determine the exact number of conditional GETs that were issued by clients. This value is of interest as it would give us a betterindication of how much impact client, proxy and network caching is having on the serverworkload. The next two most common methods seen were HEAD and POST. HEADrequests are issued when only the header of a file is desired and not the content. POSTrequests allow the client to send information to a specified URL on the server. A small number of other methods also appeared in the access logs, but not in sufficient numbers to affectthe distributions given in Table 3. Table 3 indicates that some of the responses to HEADrequests appeared to have included content data which is a violation of the HTTP specification 19.  However, we ignore this as it has no noticeable impact on our study,For the remainder of this paper we focus on analyzing the GET requests, as these accountfor almost all of the requests to the World Cup site. Since the primary purpose of this sitewas to provide information to people it is not surprising to see such a high percentage ofrequests include the GET method i.e., the percentage of GET and POST requests is basically defined by the content on the Web site. We would like to point out that this will not bethe case for all Web sites. In studies where methods other than GET are common, wewould recommend analyzing all of the frequently used methods.Workload Characterization Statistical CharacteristicsArlitt and Jin Page 13 of 90Table 4 shows the breakdown of server response codes. For a more complete description ofpossible response codes please refer to the HTTP1.1 specification 19. In this section wefocus on the most commonly seen status codes in the access logs. Table 4 reveals that themajority of requests resulted in the Successful transfer of an object response status 200.The Successful transfers account for almost all of the content data 97.86 that was transferred from the Web site back to clients. The majority of the remaining content data trafficTable 3 Breakdown of Resource MethodsMethod  of Requests  of Content Data TransferredGET 99.88 99.62HEAD 0.10 0.30POST 0.02 0.08Total 100.00 100.00Table 4 Breakdown of Server Response CodesResponse Code  of Requests  of Content Data Transferred200 Successful 80.52 97.86206 Partial Content  0.09 2.08304 Not Modified 18.75 0.004xx Client Error 0.64 0.065xx Server Error 0.00 0.00Other Codes 0.00 0.00Total 100.00 100.00Workload Characterization Statistical CharacteristicsArlitt and Jin Page 14 of 90was sent in status 206 Partial Content responses. The second most common status codewas the Not Modified 304 response which accounted for almost 19 of all responses to client requests. This represents a substantial increase over the percentage of Not Modifiedresponses seen in earlier server workloads 3. The reason for this increase can be attributed to the improved caching architecture in the Web, including persistent caches in browsers, and more recently in proxies and networks e.g., transparent caches. This type ofresponse indicates that the client issued a conditional GET request to verify that its cachedcopy of the file is consistent with the version being served at the Web site. Since the NotModified response is not the only possible response to a conditional GET request we stillcannot determine the exact volume of conditional GET requests, although we can establisha lower bound. Relatively few requests resulted in error responses. Most of the errors thatdid occur were the result of incorrect URLs which resulted in a status 404 File Not Foundresponse.Workload Characterization Statistical CharacteristicsArlitt and Jin Page 15 of 90Table 5 shows the breakdown of response by the type of file requested by the client. The filetype was determined in several ways. For the majority of the responses the file extensionwas used to categorize the file by type. For example, files ending with .jpg or .gif wereplaced in the Images category, while files ending in .zip were placed in the Compressedcategory. We considered any URL that included cgibin in the string to be a dynamicresponse, as well as any file that had a .cgi or .pl extension. Furthermore, any URL thatcontained a parameter list e.g., example.htmlparameterlist was considered tobe a dynamic file. For all of the remaining unique requests we issued HEAD requests tothe Web site and used the Contenttype response header to classify the file.Table 5 reveals that almost all client requests 98.01 were for either HTML 9.85 orImage 88.16 files. A similar characteristic was observed in earlier Web server workloads3. Many of the remaining requests were for Java files. Few requests were made for multiTable 5 Breakdown by File TypeFile Type  of Requests  of Content Data TransferredHTML 9.85 38.60Images 88.16 35.02Audio 0.02 0.10Video 0.00 0.82Compressed 0.08 20.33Java 0.82 0.83Dynamic 0.02 0.38Other Types 1.05 3.92Total 100.00 100.00Workload Characterization Statistical CharacteristicsArlitt and Jin Page 16 of 90media types such as audio and video. HTML files had more impact than image files on thevolume of content data transferred from the Web site 38.60 for HTML compared with35.02 for Images. Most Image requests were for small inline graphics while the HTMLrequests were for substantially larger files. Furthermore many requests for Image files wereconditional GETs that resulted in Not Modified responses. Thus many of the Imageresponses contained no data. The Compressed files, which accounted for only 0.08 of allrequests were responsible for over 20 of the content data traffic. Most of the Compressedrequests were for downloadable software, in particular World Cup screensavers for PCs.The huge discrepancy between the percentage of requests for Compressed files and thepercentage of content data transferred for the corresponding transfers is an indication of theeffects that large files can have on the workload of a Web server and of the network. Thepercentage of the content data transferred for Audio files does not indicate the actual impacton the network. Many of the Audio requests received at the Web site were for Real Audiofiles i.e., streamed data. These requests were redirected to other servers. No informationon these servers is available.Workload Characterization Statistical CharacteristicsArlitt and Jin Page 17 of 90Table 6 shows the percentage of requests handled by as well as the content data transferredby each of the locations that participated in hosting the World Cup Web site. Client requeststo the World Cup site were redirected to one of the four hosting locations by a Cisco Distributed Director. The goal of the Distributed Director is to transparently redirect client requeststo the closest server. Closeness may be determined by clienttoserver topological proximity or clienttoserver latency 14. However, both of these metrics are difficult to estimate.Table 6 indicates that most of the requests were handled by servers in North America, withthe Plano location receiving the bulk of the work 44.50 of requests, 45.03 of contentdata.The final analysis in this section examines the unique clients that accessed the World CupWeb site during the period of study. Determining an exact figure for the number of clients isvirtually impossible. The presence of proxy caches and shared workstations hides some ofthe unique clients from our analysis. The use of DHCP to assign IP addresses to clientmachines inflates the number of unique clients seen in the log. Thus we can neither establish a lower nor an upper bound on the number of unique clients that issued requests.Table 6 Breakdown by LocationLocation  of  Requests  of Content Data TransferredSanta Clara, CA 16.60 16.89Plano, TX 44.50 45.03Herndon, VA 25.91 23.72Paris, FR 12.99 14.36Total 100.00 100.00Workload Characterization Statistical CharacteristicsArlitt and Jin Page 18 of 90The access logs contain 2,770,108 unique IP addresses. We analyzed each unique IPaddress to determine the number of requests they made to the World Cup Web site, thenumber of content bytes they received from the site, and the number of hosting locationsthat they communicated with during the trace. Table 7 presents the results of this analysis.Workload Characterization Statistical CharacteristicsArlitt and Jin Page 19 of 90Table 7 is divided into four parts, with each part providing information on the percentage ofclients that communicated with servers at a particular location or number of locations. Forexample, the first section of Table 7 indicates the percentage of clients that communicatedwith servers at only a single location. 61 of all the unique clients communicated with servTable 7 Breakdown of ClientsLocationa  of Unique Clients  of Requests  of Bytes TransferredSingle Location SC only 10.49 2.75 2.67PL only 27.95 8.20 8.23HN only 14.23 3.98 3.60PA only 8.33 2.10 2.29Subtotal 61.00 17.03 16.79Two Locations SC  PL 8.01 8.11 8.30SC  HN 0.79 0.47 0.43SC  PA 0.47 0.24 0.27PL  HN 9.35 9.97 9.36PL  PA 5.54 4.06 4.62HN  PA 2.42 1.43 1.44Subtotal 26.58 24.28 24.42Three Locations SC, PL  HN 2.70 7.05 6.60SC, PL  PA 1.51 2.77 2.99SC, HN  PA 0.17 0.16 0.16PL, HN  PA 5.28 11.61 11.57Subtotal 9.66 21.59 21.32Four Locations SC, PL, HN  PA 2.76 37.10 37.47Total 100.00 100.00 100.00a. Abbreviation definitions are given in Table 21, section 10 on page 87Workload Characterization Statistical CharacteristicsArlitt and Jin Page 20 of 90ers at only one of the four hosting locations. These clients issued 17.03 of all requests tothe World Cup Web site and received 16.79 of all content data transferred from the site.From Table 7 we can see that most of the unique clients 87.58 accessed servers at onlyone or two of the hosting locations. Assuming that the DistributedDirector is able to redirectclients to the closest hosting location this is not an unexpected behaviour. However, theseclients are responsible for only 41.21 of all requests. 2.76 of all clients issued requeststo all four hosting locations. Since these clients made over 37 of all requests it is likely thatmany of these clients are proxies. Although it seems counterintuitive that a client shouldcommunicate with servers from each location, particularly with the locations spread acrosstwo continents, we do not have sufficient information to properly evaluate the performance ofthe DistributedDirector.Workload Characterization Usage AnalysisArlitt and Jin Page 21 of 905.2 Usage AnalysisFigure 1 shows the daily traffic volume handled by the World Cup Web site. From the beginning of May until the start of the World Cup on June 10th the traffic volume is quite lightalthough clearly building in anticipation of the start of the event. Beginning on June 10th thevolume of traffic grows enormously. This marks the beginning of a prolonged flash crowd.That is, the site suddenly became very popular, remained popular for a lengthy period oftime, and then just as quickly became relatively unpopular again. Although the daily trafficvolume is quite bursty during the World Cup, the traffic volume remains higher than it was atany time prior to the start of the event. The busiest day for the site was June 30th when over73 million requests were handled by the France 98 site. After June 30th the daily traffic volumes begin to slowly diminish until the end of the World Cup, at which time the volume oftraffic quickly subsides.10203040506070May June July AugMillions of Requests Per Day Start EndFigure 1 Daily Traffic Volume to the World Cup Web SiteWorkload Characterization Usage AnalysisArlitt and Jin Page 22 of 90In order to better understand the causes of this burstiness we analyzed the traffic in moredetail.  Figure 2 shows the hourly traffic volume of the World Cup Web site.Workload Characterization Usage AnalysisArlitt and Jin Page 23 of 90I24681012SunJune 7MonJune 8Tue June 9WedJune 10ThuJune 11FriJune 12SatJune 13Millions ofReqs per Hour BRASCOMORNORITACHICMRAUTPARBGRKSADENFRARSAESPNGAKORMEXHOLBEL1998 World Cupbegins6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm24681012SunJune 14MonJune 15TueJune 16WedJune 17ThuJune 18FriJune 19SatJune 20Millions ofReqs per Hour ARGJPNYUGIRNJAMHRVENGTUNROMCOLGERUSASCONORBRAMORCHIAUTITACMRRSADENFRAKSANGABGRESPPARJPNHRVBELMEXHOLKOR6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm24681012SunJune 21MonJune 22TueJune 23WedJune 24ThuJune 25FriJune 26SatJune 27Millions ofReqs per Hour GERYUGARGJAMUSAIRNCOLTUNROMENGITAAUTCHICMRSCOMORBRANORFRADENRSAKSAESPBGRNGAPARBELKORHOLMEXGERIRNUSAYUGJPNJAMARGHRVROMTUNCOLENGBRACHIITANORRoundof 16begins6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm24681012SunJune 28MonJune 29TueJune 30WedJuly 1ThuJuly 2FriJuly 3SatJuly 4Millions ofReqs per Hour FRAPARNGADENGERMEXHOLHUG ARGENGPROMHRV ITAFRAPBRADENHOLARGGERHRVQuarterFinalsbegin6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm24681012SunJuly 5MonJuly 6TueJuly 7WedJuly 8ThuJuly 9FriJuly 10SatJuly 11Millions ofReqs per Hour BRAHOLP FRAHRV HOLHRVSemiFinalsbeginThirdPlacegame6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm24681012SunJuly 12MonJuly 13TueJuly 14WedJuly 15ThuJuly 16FriJuly 17SatJuly 18Millions ofReqs per Hour 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pm 6am 12pm 6pmBRAFRAChampionshipGame1998 World CupendsFigure 2 Hourly Traffic Volume to the World Cup Web SiteWorkload Characterization Usage AnalysisArlitt and Jin Page 24 of 90Figure 2 consists of six bar graphs, one for each week of the World Cup tournament. Thesolid black curve in each graph represents the hourly volume of requests yaxis for thegiven time xaxis, normalized to local time in France. The scale of both the x and yaxesare kept constant across all bar graphs to facilitate comparisons in traffic volume over timeand by dayofweek. The dashed vertical lines indicate the starting time of a World Cup football match. The teams involved in each match are also listed the abbreviations are definedin Table 22 in Section 10. For example, at 530pm in France on Wednesday June 10th thefirst match of the 1998 World Cup was played between Brazil BRA and Scotland SCO.Approximately six million requests per hour were received by the World Cup Web site at thistime. The bar graphs also indicate the days on which each round of the tournament begane.g., the Round of 16 began on Saturday June 27th, as well as those matches that requiredpenalty kicks to decide a victor e.g., on Tuesday July 7th the match between Brazil and theNetherlands was decided with penalty kicks this is indicated by the P following the namesof the teams.Figure 2 reveals that there were many variables that affected the hourly traffic volume at theWorld Cup Web site. For example, the volume of traffic increased when matches were inprogress and decreased once they had finished. These bursts represent flashcrowds on asmaller scale. The traffic volume was also affected by the teams involved in the matchese.g., traditional football powers like Brazil and Germany are of interest to football fans everywhere and not just Brazilians and Germans, the number of matches in progress e.g., fromWorkload Characterization Usage AnalysisArlitt and Jin Page 25 of 90June 23rd through June 26th matches were played in parallel, and the playoff implicationsof the match.One interesting observation to be made from Figure 2 is that the volume of traffic to theWorld Cup Web site was quite low on weekends, even though a higher percentage ofmatches were played on Saturday and Sunday than on weekdays. The obvious reason forthis reduction in traffic volume is that people preferred to watch the matches on television.When these fans were unable to watch the matches on television, such as when they wereat work or school, or when certain matches were not televised in their area, they relied onthe Web to provide them with progress reports on the matches that they were interested in.Timezone differences also contributed to the usage of the World Cup site. Since most of thematches were held in the late afternoon or evening local time this enabled European fans towatch most of the matches on television. Because of this we would expect to see differentusage patterns for Europeanbased clients accessing the World Cup site e.g., fewerrequests while matches are in progress. For fans in the Americas and eastern Asia thismeant early morning or afternoon matches, which would often conflict with their daily routines.As we mentioned earlier the busiest day for the World Cup Web site was June 30th. Figure 2provides us with an explanation of why this day was so popular. First of all, June 30th wasthe last day of the Round of 16. Thus, the two victors on this day would advance to theQuarter Finals. Second, the match between Argentina and England went into overtime, andWorkload Characterization Size DistributionsArlitt and Jin Page 26 of 90eventually required penalty kicks to determine the winner. During this match the requestrate peaked at almost 12 million per hour.5.3 Size DistributionsIn this section we analyze the distribution of sizes for all unique files requested from theWorld Cup Web site.  We also examine the distribution of all transfer sizes from the site.5.3.1 Size Distribution of Unique FilesOur first analysis looks at the sizes for each of the unique files that were requested and successfully transferred at least once in the access log. For the purpose of this study we utilizethe initial nonzero size recorded for each unique file. Since some of the unique files changeover time so too will the results of our analysis. However, we believe that the choice of whichsize to use for a file will only affect the parameters of the distribution and not the distributionitself. We have no information on the files that were available on the Web site but were notrequested during the collection period.Table 8 Unique File Size Information by File TypeAll Files HTML Image Audio Video Java Compressed DynamicNumber 20,728 11,411 7,025 344 12 14 67 1,783Mean bytes 15,524 7,311 8,961 24,117 1,418,329 4,571 1,537,833 20,896Median bytes 4,674 4,670 4,490 133 1,367,199 4,808 39,046 18,960Maximum MB 61.2 0.14 1.32 1.33 1.86 0.006 61.2 2.9Total Size MB 307 80 60 8 16 0.01 98 36Workload Characterization Size DistributionsArlitt and Jin Page 27 of 90Table 8 presents some overall statistics on the unique files that were requested from theWorld Cup Web site. These statistics were calculated for the complete set of unique filescolumn entitled All Files as well as for several different file types. Table 8 indicates thatthere were 20,728 unique files requested and successfully transferred from the World Cupsite during the measurement period. The total combined size of these files was 307 MB.The mean size of these files was 15,524 bytes, the median size 4,674 bytes, and the maximum size 61.2 MB. Most of the unique files 18,436 of 20,728 or 89 were in either HTMLor Image format. An additional 9 of the unique files were considered to be dynamic e.g.,cgibin files. The unique HTML and Image files accounted for only 46 140 of 307 MB ofthe total size of the set of unique files. Much of the total size was due to a few large files,such as Video or Compressed. The Audio files were in general quite small. This occurredbecause many of the files in this category simply contained a URL that redirected the clientto a Real Audio server. The few large Audio files were compressed sound clips e.g., .wavfiles.02468100 2 4 6 8 10 12 14 16 18 20 22 24 26PercentageFile Size in log2BytesEmpirical Synthetic0204060801000 2 4 6 8 10 12 14 16 18 20 22 24 26PercentageFile Size in log2BytesEmpirical Synthetic432100 1 2 3 4 5 6 7 8log 10PXxFile Size in log 10BytesFigure 3 Size Distribution of Unique Files   a Frequency b Cumulative Frequency c Taila b cWorkload Characterization Size DistributionsArlitt and Jin Page 28 of 90Figure 3 shows the analysis of the size distribution for all unique files in the World Cup dataset. Figure 3a presents the frequency histogram while Figure 3b provides the cumulativefrequency histogram of the unique file sizes. We have applied a logarithmic transformationto the file sizes to enable us to identify patterns across the wide range of values 32. For alog2 transformation, bini includes values in the range 2i  x  2i11. Similarly, for a log10transformation, bini includes values in the range 10i  x  10i11. Figure 3a indicates thatmost unique files have sizes in the 256 byte to 64 KB range 28  216 bytes. In other Webworkload characterizations the file size distribution has been found to be lognormal 25.That is, after applying a logarithmic transformation to the data, the data appears to be normally distributed. We compare the unique file size distribution the empirical data to a synthetic lognormal distribution with parameters 12.14 and 1.73. From Figure 3a we cansee that the empirical data deviates quite substantially from the synthetic model. These differences are due to the distinct nature of the World Cup site. For example, in Figure 3aabout 10 of all unique files were around 4 KB 212 bytes in size. 65 of these files areHTML objects that provided profiles on the individual players who participated in the WorldCup tournament. All of the other large spikes in Figure 3a are also the result of groups ofrelated objects having approximately the same size. On typical Web sites we would notexpect to see such large clusters of related objects that make up a substantial percentage ofall files on the Web site.Despite the number of spikes seen in Figure 3a the cumulative frequency histogramshown in Figure 3b indicates that the lognormal distribution still provides a reasonableWorkload Characterization Size DistributionsArlitt and Jin Page 29 of 90estimate for the body of the unique file size distribution. While it is clearly not exact, the lognormal distribution may be sufficiently accurate for most modeling purposes.While most of the unique files are less than 64KB in size a few are substantially larger. Ournext analysis examined the tail of the unique file size distribution to determine if it is heavytailed. A distribution is considered heavytailed if .This means that if the asymptotic shape of the distribution is hyperbolic it is heavytailed ,regardless of the behaviour of the distributions for small values 12. To determine if theunique file size distribution from the World Cup Web site is heavytailed we plotted the complementary distribution CD function on loglog axes and examined the results for linearbehaviour on the upper tail. This method of analysis is described in 11. The results of thisanalysis for the World Cup data are shown in Figure 3c. The tail of the distribution doesexhibit some linear behaviour which suggests that the distribution is indeed heavytailed.However, this linearity does not exist throughout the entire tail. Specifically, a spike exists inthe 14 MB range. This spike is caused by the existence of 44 files whose sizes are in the 14 MB range. These files include 13 uncompressed, high resolution images, 4 audio clips, 15screen savers i.e., downloadable software and 12 video clips.To verify that the unique file size distribution is indeed heavytailed we utilized the scalingestimator tool aest created by Crovella and Taqqu 11. This tool aggregates the datapoints in the distribution and then plots the complementary distribution of the aggregateddata set. If the distribution is heavytailed then the tails of each successive aggregated dataset will be approximately parallel with slope approximately  11.P X x  x  x  0  2 ,,Workload Characterization Size DistributionsArlitt and Jin Page 30 of 90Figure 4 presents the results of this test on the unique file size distribution for the World CupWeb site. The leftmost curve on the graph is the complementary distribution for the original,unaggregated data set. Each subsequent curve is the CD function for the data set that hasbeen aggregated a factor of two more than the previous curve. The aggregation factorsshown in Figure 4 are 1 raw data, 2, 4, 8, 16, 32, 64, 128, 256, 512 and 1024.The results in Figure 4 indicate that the unique file size distribution is heavytailed, as thetails of the successive CD plots are roughly parallel to one another. As the aggregation factor increases, the tails become linear throughout the tail of the distribution as the impact ofthe set of files in the 14 MB range diminishes. The estimate for the  parameter for the tailof this distribution is 1.37.In summary, we believe that the unique file size distribution could be reasonably approximated using a hybrid model that combines a lognormal distribution for the body and a power5432100 1 2 3 4 5 6 7 8Log10PX  xFile Size in log 10BytesUnaggregated datasetFigure 4 Size Distribution of Unique Files  Complementary Distribution Plots of Aggregated DataWorkload Characterization Size DistributionsArlitt and Jin Page 31 of 90law distribution for the tail. This is the approach taken with SURGE, a Web workload generator developed by Barford and Crovella 6. A more precise model would need to account forthe clusters of related files found in the workload which affects both the body and tail of thedistribution.5.3.2 Size Distribution of Successful TransfersOur next analysis focuses on the sizes of all successful transfers i.e., status 200 responsesfrom the World Cup Web site.Table 9 presents the overall statistics on the successful transfers, for all transfers and by filetype. By comparing Table 8 and Table 9 we can see numerous differences between theunique file and successful transfer size distributions. For example, the median successfultransfer size is 965 bytes, which is significantly smaller than median of 4,674 bytes for theunique file size distribution. This difference indicates that the smaller files available at thesite were requested significantly more often than the larger files. For HTML files the mediantransfer size is larger than the median unique size. This occurred in part because the morepopular HTML pages were quite large, and because some of the HTML pages increased inTable 9 Successful Transfer Size Information by File TypeAll Transfers HTML Image Audio Video Java Compressed DynamicNumber 1,087,916,098 107,312,796 946,428,396 281,149 28,600 10,139,230 969,058 282,615Mean bytes 4,802 18,693 1,965 19,370 1,464,641 4,367 1,018,305 72,323Median bytes 965 12,624 914 131 1,367,199 4,406 1,272,120 6,122Maximum MB 61.2 0.23 1.32 1.33 1.86 0.01 61.2 4.32 Bytes Transferred GB 4,856 1,868 1,732 5 39 41 918 19Workload Characterization Size DistributionsArlitt and Jin Page 32 of 90size during the data collection period. Evidence of these increases can be seen by comparing the maximum initial size for all HTML files and the maximum transfer size seen forHTML files.Figure 5a shows the frequency histogram for the successful transfer size distribution. Aswas the case for the unique file size distribution, the frequency histogram contains a numberof large spikes. This characteristic is due to several of the more popular objects having verysimilar sizes. The cumulative frequency histogram, shown in Figure 5b, reveals that thesyntheticallygenerated lognormal distribution with parameters 10.13 and 2.19 is amuch better model for the successful transfer size distribution than it is for the unique filesize distribution.Figure 5c presents the analysis of the tail of the successful transfer size distribution. InFigure 5c we can see that the tail is affected by transfers in the 14 MB range just as the tailof the unique file size distribution was affected by files in this range Figure 3c. For theSuccessful Transfer case the tail of the distribution is not affected by the number of files in02468100 2 4 6 8 10 12 14 16 18 20 22 24 26PercentageFile Size in log2BytesEmpirical Synthetic0204060801000 2 4 6 8 10 12 14 16 18 20 22 24 26PercentageFile Size in log2BytesEmpirical Synthetic10864200 1 2 3 4 5 6 7 8log 10PXxFile Size in log10BytesFigure 5 Size Distribution of Successful Transfers a Body c Taila b cWorkload Characterization Size DistributionsArlitt and Jin Page 33 of 90this size range but rather by the popularity of several of these large files 10. For example,the five most popular files in this set of large files were World Cup screen savers that peoplecould download and use on their PCs. These five files were transferred over 600,000 timesduring the period of data collection.5.3.3 Size Distribution of All TransfersIn this section we examine the size distribution of all transfers from the World Cup Web site.Figure 6 presents the analysis of the body and tail of the size distribution for all transfers.Figure 6a and Figure 6b show the frequency and cumulative histograms respectively forthe overall transfer size distribution. The spike at 0 in this graph corresponds to the high volume of Not Modified responses seen in the workload we placed all zerosized transfers inthe 20 bin since log2 0 is undefined. The presence of this large quantify of zerosized transfers reduces the median transfer size to 828 bytes from 965 bytes for the Successful trans02468100 2 4 6 8 10 12 14 16 18 20 22 24 26PercentageFile Size in log2Bytes10864200 1 2 3 4 5 6 7 8log 10PXxFile Size in log10Bytes0204060801000 2 4 6 8 10 12 14 16 18 20 22 24 26PercentageFile Size in log2BytesFigure 6 Size Distribution of All Transfers a Body b Taila b cWorkload Characterization Size DistributionsArlitt and Jin Page 34 of 90fers. This spike is the main difference between the Overall Transfer size distribution and theSuccessful transfer size distribution.5.3.4 Impact of Size DistributionsFigure 7 indicates the effect of the size distributions on the storage requirements at theWorld Cup Web site as well as on network traffic. For example, files up to, but not including1 KB in size up to and including 29 bytes account for 10.4 of all files stored at the WorldCup site but utilize only 0.4 of the storage space at the site. 55.7 of all client requestswere for files less than 1 KB in size. Responses to these requests generated only 5.8 ofthe total content data transferred from the Web site. Meanwhile, files 64 KB and larger 216bytes made up only 0.4 of the unique files but consumed 50.7 of the required storagespace. Although these files received only 0.1 of all client requests they accounted for 21of the content data transferred. These numbers suggest that the impact that these few large0204060801000 2 4 6 8 10 12 14 16 18 20 22 24Cumulative PercentageFile Size in log2BytesUnique FilesStorage SpaceRequestsContent DataTransferredFigure 7 Impact of File Size Distributions on Servers and NetworkWorkload Characterization File Referencing BehaviourArlitt and Jin Page 35 of 90files can have on the system is substantial. Thus it is important to accurately model theupper tails of both the unique file and transfer size distributions in order to make betterassessments of the impact of a workload on a Web server 6.5.4 File Referencing BehaviourIn this section we analyze the World Cup workload for the presence of two important file referencing characteristics temporal locality and concentration of references.5.4.1 Temporal LocalityTemporal locality means that a file that was recently referenced will likely be referencedagain in the near future 13. To measure the temporal locality we utilize the standard LRULeast Recently Used stackdepth analysis. This analysis works in the following manner.When a file is initially referenced it is added to the top of the LRU stack position 1. All filesthat are currently in the stack are pushed down by one position. When a file is referencedagain its current depth i.e., position in the stack is recorded and then the file is moved backto the top of the stack. The other files in the stack are pushed down as necessary. Once theentire log has been analyzed the record of the depths at which rereferences occurred isexamined. Logs which exhibit a high degree of temporal locality will have a small averageor median stack depth. Conversely, logs with a low degree of temporal locality will have alarge mean or median stack depth.Workload Characterization File Referencing BehaviourArlitt and Jin Page 36 of 90Table 10 shows the results of the stack depth analysis for the World Cup workload. We performed the analysis for the site as a whole i.e., considering all requests and for each location independently. Similar mean stack depths in Table 10 indicate that the degree oftemporal locality is quite consistent across the three North American locations. The degreeof temporal locality is noticeably weaker at the Paris site. This difference is due to the Parissite having to serve both French and English pages on a regular basis. The US based locations typically received requests only although not exclusively for pages in English.In Table 10 we also provide the median stack depth. Across all sites the median stack depthis significantly smaller than the mean, indicating that the degree of temporal locality in theworkload is even stronger than is suggested by the mean depth. This observation suggeststhat the stack depth distribution has an extremely long tail. Further evidence of this is provided by examining the 90th percentile. Across all of the server locations 90 of the referTable 10 Temporal Locality AnalysisAll Locations Santa Clara Plano Herndon Parismean stack depth 290 272 261 261 414standard deviation 721 637 621 639 1073median stack depth 106 107 101 97 13790th percentile 615 589 564 559 816normalized mean stack depth 0.015 0.014 0.014 0.014 0.022normalized median stack depth 0.0051 0.0052 0.0048 0.0047 0.0066Workload Characterization File Referencing BehaviourArlitt and Jin Page 37 of 90ences were at a depth of 816 or less, which is only 4 of the maximum depth of 20,728 thenumber of unique files in the trace.Table 10 also includes the normalized mean and median stack depths. We calculated thesevalues by dividing the mean or median stack depth by the number of unique files in the trace.By normalizing the stack depth we can compare the degree of temporal locality across different access logs 5. For example, Barford et. al. reported a normalized mean stack depthof 0.2340 and a normalized median stack depth of 0.0399 for a recent proxy trace 5. Thenormalized mean and normalized median stack depths reported in Table 10 are significantlysmaller than the values reported by Barford indicating as expected that the temporal locality is much stronger in the Web site accesses.Figure 8a and Figure 8b provide the frequency and cumulative frequency histograms forthe stack depth distributions. The results for the overall workload as well as for each locationare presented. These two figures clearly show that most of the references occurred nearthe top of the stack, indicating a strong degree of temporal locality. In fact, 94 of all references occurred at a stack depth of less than 1000. These figures also show, as we indi00.10.20.30.40.50.60.70 100 200 300 400 500 600 700 800 900 1000PercentageStack DepthAllSCPlanoHerndonParis0204060801000 1 2 3 4 5 6 7 8 9 10 11 12 13 14Percentagelog2Stack DepthAllSCPlanoHerndonParis0204060801000 100 200 300 400 500 600 700 800 900 1000PercentageStack DepthAllSCPlanoHerndonParisFigure 8 Stack Depth Distribution a Frequency b Cumulative Frequency c LogTransformed Cumulative Freq.a b cWorkload Characterization File Referencing BehaviourArlitt and Jin Page 38 of 90cated earlier, that the stack depth distributions are quite consistent across the three NorthAmerican locations but noticeably different for the Paris location. In order to view the entirestack depth distribution we applied a logarithmic transformation to the data. The results areshown in Figure 8c. The remaining 6 of references occurred in the bottom 95 of thestack positions 210 and greater.5.4.2 Concentration of ReferencesThe second file referencing characteristic that we focus on is concentration of references.Many studies, including 3 and 13, have found that a nonuniform referencing patternexists for files on the WorldWide Web. This means that a small number of files on a Website are extremely popular and are responsible for most of the requests arriving at the site.Most of the unique files on a Web site are unpopular and are seldomly requested.0204060801000 10 20 30 40 50 60 70 80 90 100Cumulative PercentagePercentage of Unique FilesStorage SpaceRequestsContent Data TransferredFigure 9 Concentration of References cumulative distributionWorkload Characterization File Referencing BehaviourArlitt and Jin Page 39 of 90Figure 9 shows the distribution of all client requests across the set of unique files available atthe World Cup Web site. In this figure all of the unique files x axis have been sorted indecreasing order by the number of references that each received. The volume of contentdata that each of these files generated in network traffic along with each files storagerequirements at the site were also computed. Figure 9 clearly shows that there is a concentration of references among a small subset of the unique files. For example, the top 10i.e., the most popular unique files received 97 of all requests, generated 89 of the network traffic i.e., content data while occupying less than 7 of the storage space on theWeb site. The top 1 of files received 75 of all requests, generated 46 of the networktraffic and consumed a mere 0.12 of the required storage space.While a number of the files on the World Cup site were extremely popular, many were relatively unpopular. In fact, 9.2 of the unique files were requested only a single time. Werefer to these files as onetimers 3. The combined size of these onetimers was 98 MB,or 31.8 of the combined size of all unique files. This characteristic is of interest because ofits obvious effect on caching even over a long period of time and with an exceptionallyheavy workload, some files on a Web site will not be referenced more than once. Thus,there is no benefit in caching these files.Several studies, including 3, 5, 7 and 13, have found that a Zipflike distribution can beused to characterize the popularity of files on the Web. A distribution is considered to beZipflike if the relative probability of a request for the ith most popular object is inversely proportional to 1i 7. In Web proxy workloads, estimates of  typically range from 0.5 to 1Workload Characterization File Referencing BehaviourArlitt and Jin Page 40 of 90572733. The more concentrated the references are to a set of popular objects, thehigher the estimate of . Since the concentration of references in Web server workloads isgenerally much stronger than what is found in Web proxy workloads, the estimates of  arealso higher.To test if a distribution is Zipflike a logtransformed plot of the number of requests for eachfile as a function of the files rank is created. The most frequently requested file is assigneda rank of 1 while the least frequently requested file is assigned rank N in this case 20,728.If the distribution is Zipflike the graph should appear linear with slope near  5.Figure 10a shows the relative popularity of the unique files in the World Cup workload.This graph exhibits three distinct linear regions thus it does not appear to be Zipflike whenconsidering all unique files. The three distinct regions are I files 1100, II files 10013,000, and III files 13,000 to 20,728. Figure 10a also includes information that indicates1101001,00010,0001e51e61e71 10 100 1,000 10,000Reference CountFile RankHTML filesImage files1101001,00010,0001e51e61e71 10 100 1,000 10,000Number of RequestsHTML File RankFigure 10 Concentration of References reference count vs. rank a All files b HTML files onlya bWorkload Characterization File Referencing BehaviourArlitt and Jin Page 41 of 90which files are HTML and which are images. The two horizontal lines at the bottom ofFigure 10a indicate if the file was an HTML or an Image file. For example, these lines canbe used to determine that the most popular file rank 1 was an image while the second mostpopular file rank 2 was an HTML file. These lines also reveal that most of the top 500 fileswere images and only a few were HTML. Unfortunately these lines are too dense to distinguish the types of the less popular files.We will now examine each of the regions mentioned above in more detail. In region I theslope of the graph is nearly horizontal slope is approximately 0.25, indicating that all of thefiles have nearly equivalent reference counts. These 100 files received 61 of all requeststo the World Cup site and caused 37 of all content data traffic. Of these 100 files six wereHTML and 93 were images. We speculate that the reason there are so many files withnearly equivalent reference counts is due to the number of embedded files in the popularHTML files 58 of the 93 Image files were embedded in the 6 HTML files in region I, and theuse of the same images across many different pages on the World Cup site the remainingImage files in region I were embedded in multiple pages 13 of these Image files were utilized on 400 or more pages. Caching within the network e.g., at clients and proxies mayhave reduced the reference counts of some of the more popular files. The graph in region IIof Figure 10a is linear with a slope estimated at 1.92. In region III the graph drops offalmost vertically slope estimated at 14.7. We are unsure of the cause of this. Onehypothesis is that the extreme popularity of the World Cup site and the relatively small set ofunique files changes the behaviour of the distribution.Workload Characterization Embedded FilesArlitt and Jin Page 42 of 90Since the popularity distribution for all unique files did not appear to be Zipflike we decidedto perform the same analyses just on the HTML files. We chose to examine the HTML filesas this would provide us with an estimate of the popularity of the pages on the World CupWeb site due to the use of Frames on this site, a number of pages actually consist of multiple HTML files. The results of this analysis can be seen in Figure 10b. Two distinctiveregions can be seen in this graph. In region I files 1  6,000 the popularity of HTML filesappear to follow a Zipflike distribution reasonably well. We estimate the slope of this portionof the graph at approximately 1.16. In region II files 6,000  11,411 the graph drops offalmost vertically, with a slope estimated at 20.6. We are unsure of the cause of this changein the graph. One possibility is that many of the HTML files in region II were available i.e.,linked to other pages for only short periods of time, or perhaps not at all. Once a file is nolonger linked to other files it can only be accessed by directly requesting it i.e., typing in theURL of the file.  This would significantly reduce the number of accesses to the file.5.5 Embedded FilesIn an updated version of the SURGE workload generator 6, Barford and Crovella definethree classes of files 4 base files  HTML files which contain embedded files embedded files  files which are referenced by base files e.g., images, java single files files which are neither base nor embedded e.g., compressedFor simplicity we assume all HTML files are base files, all images and java files are embedded files, and all other types are single files.Workload Characterization Embedded FilesArlitt and Jin Page 43 of 90In this section we focus on the embedded files. In particular we want to determine the distribution of total embedded files per base file, as well as the distribution of unique embeddedfiles per base file. We also examine the use of individual embedded files across multiplebase files.The total number of embedded files in a base page represents the upper limit on the numberof additional HTTP requests that will be generated whenever the base file is requested. Dueto caching by the browser additional HTTP requests should only be needed for the uniqueembedded files referred to by the base file. Because some files may be embedded in morethan one base file the actual number of additional HTTP requests that are automaticallygenerated when a particular base file is requested should be less than the number of uniqueembedded files contained in that base file. However, this distribution is affected by thecache size and consistency policy at the client and is therefore more difficult to quantify.We did not utilize information from the log files to determine the number of embedded filesper base file. Instead we analyzed a copy of the World Cup site. We set up a local Webserver to host the files from the site. We then utilized the remote control feature of theNetscape Navigator browser 31 to request each base file. We used the browser to interpret the Javascript in the base files and to request the appropriate embedded files we tookseveral steps to ensure that the browser would issue requests for all of the embedded filesrather than files from its cache. This step was required as the number of embedded objectsper base file depended on the capabilities of the clients browser. Simply counting the number of embedded files in each HTML file would overestimate the number of embedded filesWorkload Characterization Embedded FilesArlitt and Jin Page 44 of 90utilized for a particular browser e.g., simply scanning the HTML files resulted in a maximumof 76 embedded files compared to a maximum of 61 using Netscape to generate therequests. The results we report are for Mozilla 4.0 i.e., Netscape 4.0 compliant browsers.We believe that fewer embedded files were utilized for older browsers although we have notanalyzed this thoroughly. Finally we analyzed the access log of our Web server to determine the embedded files for each base file.Figure 11a shows the distributions for the total embedded files per base file as well as forthe unique embedded files per base file for the World Cup Web site. 90 of the base fileshad a total of 19 or fewer embedded files. The median value was 13 total embedded filesper base file. The maximum number of embedded files on a single base file was 61. Sincesome embedded files are used more than once in a single base file we also analyzed thedistinct embedded files per base file. When only the unique embedded files are considered01020304050607080901000 10 20 30 40 50 60 70Percent of Base FilesEmbedded Objects per Base FileTotal Unique01020304050607080901000 1 2 3 4 5 6 7 8 9 10 11 12 13 14Percent of Embedded Fileslog2 Number of Base Files Using Embedded FileFigure 11 Analysis of Embedded Files aEmbedded Files per Base File b Sharing of Embedded Filesa bWorkload Characterization User Session AnalysesArlitt and Jin Page 45 of 90the numbers are slightly smaller 90 of the base files included 17 or fewer embedded files,while the median value was 11.  The maximum number of unique embedded files was 58.Figure 11b shows the number of base files that an individual embedded file is likely to beincluded in. Most of the embedded files are included in only a few base files. For example,90 of all embedded files are used in 15 or fewer base files. Included in this group ofembedded files are the pictures of individual players. Many of these images appear in onlya single base file, namely the biography page for the particular player. While most embedded files appear in only a few base files, a small number of embedded files are widely used.The most popular embedded file, a small icon, appears on 7,969 of the 11,411 HTML files.5.6 User Session AnalysesIn this section we investigate various characteristics of user sessions. For the purpose ofthese analyses we define a user session as all requests from a single client to the WorldCup Web site, with the time between requests from that IP address less than some threshold value. That is, if request ri1 from client C arrives at the Web site x seconds afterrequest ri from client C, and x  t t is the timeout value in seconds then requests ri and ri1are both considered to be part of session sn for client C. If x  t then request ri is deemed tobe the final request of session sn for client C, while request ri1 is the initial request of session sn1 for client C.We consider each unique IP address in the access log to be a distinct client or user. Clearlythis is not true in all cases. For example, some of the IP addresses in the access log belongWorkload Characterization User Session AnalysesArlitt and Jin Page 46 of 90to proxies which issue requests on behalf of multiple users. The presence of proxies in thedata set can reduce the estimates of the number of unique users of the site and alter thecharacteristics of user sessions. It is also possible that some unique users utilize multiple IPaddresses e.g., using different computers to access the Web, or receiving a different IPaddress via DHCP when connecting to the Internet. The main effect of this is an inflation inthe estimated number of unique users. Nonhuman users such as Web crawlers may alsobe present in the access logs. The behaviour of these type of clients is quite different fromhuman users and will result in different session characteristics. However, based on theresults from Section 5.2 we believe that most of the traffic to this site was generated byhuman users. Thus we make no attempt to identify or remove requests that may have beengenerated by agents such as Web crawlers. Also, we have no information on whether persistent connections were enabled on the World Cup servers.Although estimates of the number of unique users and the cumulative number of users thatvisited the World Cup Web site are of interest, our focus in this section is on user sessioncharacteristics and the possible implications on HTTP behaviour. In particular we concentrate on evaluating at a high level the effectiveness of persistent connections in reducingthe number of TCP connections required for clientserver communication on the Web. Byreducing the number of TCP connections persistent connections reduce user latency byeliminating unnecessary round trips for the establishment of TCP connections. Persistentconnections are also able to avoid latency associated with TCP slow start under certain conditions 430. One disadvantage of persistent connections is the need for the server toWorkload Characterization User Session AnalysesArlitt and Jin Page 47 of 90maintain a much larger number of open TCP connections. We estimate this effect by monitoring the number of active sessions at the World Cup Web site. We consider a session tobe active if the client has issued at least one request within the last t seconds i.e., the session has not timedout at the server. Since we are evaluating persistent connections at ahigh level we do not investigate the effects of pipelining requests within a persistent connection. Our goal is to get an initial indication of the effectiveness reusing TCP connections forthis workload. We realize that we will be underestimating the number of connections that aserver would have to keep state on, since a server must maintain state for a period of timeafter the connection has been closed.  This more precise analysis is left for future work.In the remainder of this section we examine the effects of various timeout values on the totalnumber of user sessions in the World Cup workload, the maximum number of active sessions, the length of sessions, the number of requests per session, and the time betweensessions.5.6.1 Total SessionsOur first analysis looks at the total number of sessions and the maximum number of activesessions that occur for a wide range of timeout values. There are two extreme cases to beaware of. If no reuse of TCP connections happens as is the case with HTTP1.0, ignoringKeepAlive connections, 1,351,193,319 sessions would occur, one for each GET request. Inthis case relatively few sessions would be active simultaneously during the busiest period ofthe workload requests arrived at a rate of 3,600 per second. The other extreme happenswhen each client receives a persistent connection that is held open indefinitely. In this situaWorkload Characterization User Session AnalysesArlitt and Jin Page 48 of 90tion 2,770,108 sessions would occur, one for each unique client in the access log. This represents only 0.2 of the sessions that occur in the other extreme, although the site is nowrequired to maintain state on three orders of magnitude more active sessions.Figure 12 shows the effects that different timeout values have on the total number of sessions and on the maximum number of active sessions seen in the World Cup workload. Theresults are quite similar to those reported by Mogul 30. Figure 12a shows the actualnumber of sessions that occur for a given timeout value.  As the timeout values increase thetotal number of sessions drops rapidly. For example, with a timeout value of 100 seconds,the number of observed sessions is 29,249,442 compared to 1.35 billion sessions when noreuse occurs. Once timeout values larger than 100 seconds are used there is little furtherreduction in the total number of sessions, even with substantial increases in the timeoutvalue. However, the maximum number of active sessions grows quite rapidly with increases1e61e71e81e91 10 100 1000 10000 1000001e31e41e51e6Total SessionsMaximum Active SessionsIdle Timeout secondsTotal SessionsMax Sessions00.20.40.60.810 1 10 100 1000 10000 10000000.20.40.60.81 Sessions   GET Requests Active SessionsUnique ClientsIdle Timeout secondsTotal SessionsMax SessionsFigure 12 Effect of Timeout Values on Total Number of Sessionsa bWorkload Characterization User Session AnalysesArlitt and Jin Page 49 of 90in the timeout threshold. Figure 12b shows the results of this analysis as a fraction of theextreme case i.e., one session per request. For example, with a 100 second timeout only29 million sessions, or 2.2 of the maximum 1.35 billion sessions occur. The maximumactive sessions for this timeout value is 12,890, or 0.47 of the maximum of 2.8 million.5.6.2 Active SessionsIn the previous subsection we discussed the maximum number of active sessions thatoccurred for various timeout values. In this section we analyze the number of active sessions over time. Figure 13a shows the number of active sessions reported at the beginning of each one hour interval over the entire World Cup workload. In this graph a onesecond session timeout is used. As expected the number of active sessions is very bursty,The spikes in Figure 13a increase in size as the World Cup tournament progressed. Thelargest spikes correspond to the two semi final matches. The results change somewhat as020040060080010001200140016001800May June JulyActive Sessions050000100000150000200000250000300000350000May June JulyActive SessionsFigure 13 Active Sessions over Time a 1 second Timeout b 100,000 second Timeout baWorkload Characterization User Session AnalysesArlitt and Jin Page 50 of 90larger timeout values are used. Figure 13b shows the number of active sessions eachhour when a 100,000 second timeout is used slightly more than one day. This graph is stillbursty although much less so than with smaller timeout values as many of the short sessions from clients who visited the site multiple times have been merged into a few longersessions. Perhaps the biggest difference though between Figure 13a and Figure 13b isthe trend in the size of the spikes, which are now decreasing in size over time. This suggests that the number of people visiting the site decreased over time although those whoremained visited more frequently and for shorter durations.5.6.3 Session LengthOur next analysis looks at the effect of the timeout value on the length of sessions. We calculate the session length as the time between the arrival of the first request and the arrival ofthe last request in the session. The session length does not include the timeout value.Excluding the timeout value allows us to see how long the clients are using the sessions. Todetermine how long the server would need to maintain the session simply shift each curveby the timeout value. Since the access logs do not include any information on the timeneeded for the server to complete the response our results will underestimate the sessionlengths, particularly for the shorter timeout values.Workload Characterization User Session AnalysesArlitt and Jin Page 51 of 90The results of this analysis are presented in Figure 14. As expected the session lengthsincrease with longer timeout thresholds. For example, with a one second timeout 85 of thesessions lasted only a single second. When the timeout value is increased to 100 seconds81 of the sessions lasted longer than one second, with 52 lasting longer than 64 seconds. As the timeout values increase beyond 1,000 seconds the bodies of the sessionlength distributions change very little. However, the tails of these distributions get longer andlonger. We assume that this is caused by the presence of proxies in the access log. The20 tail of the 100,000 second timeout curve is quite different from all of the other curves.The cause of this is the group of clients, presumably diehard football fans, that retrievedinformation from the site on a daily basis. Once the timeout value exceeded the timebetween the daily sessions of these clients a few extremely long sessions were created.The longest session length calculated was 49 days.0204060801000 2 4 6 8 10 12 14 16 18 20 22PercentSession Length log 2 seconds1 sec10 sec100 sec1e3 sec1e4 sec1e5 secFigure 14 Analysis of Session LengthsWorkload Characterization User Session AnalysesArlitt and Jin Page 52 of 905.6.4 Sessions Per ClientFigure 15 shows the distribution of the number of sessions that each client had for the rangeof timeout values examined. From Figure 15 we can see that as the timeout valueincreases, the number of sessions per client drops substantially. For example, with a onesecond timeout 65 of clients had more than 16 sessions 24 during the course of theWorld Cup. As the session timeout increases to 100 seconds, only 40 of clients had morethan 16 sessions. Increasing the session timeout value beyond 1,000 seconds decreasesthe number of sessions only slightly.01020304050607080901000 2 4 6 8 10 12 14 16 18 20Percentlog2Sessions per Client1e5 sec1e4 sec1e3 sec100 sec10 sec1 secFigure 15 Analysis of the Number of Sessions Per ClientWorkload Characterization User Session AnalysesArlitt and Jin Page 53 of 905.6.5 Requests and Bytes Transferred per SessionIn this subsection we analyze the number of requests issued by each client as well as thenumber of content data bytes transferred to each client during a session. Obviously thesenumbers will tend to increase as the timeout value and session length grows. The resultsof this analysis are shown in Figure 16. The right most curve in each graph indicates thedistribution of requests or bytes transferred when exactly one session is used for eachunique client. Thus this curve reveals the highest utilization of persistent connections thatcould have occurred for this workload i.e., this is the best case scenario once a session isestablished it never times out The other curves on the graphs indicate the distributions forthe various timeout values that we examined. For timeout values of 1,000 seconds or morethe distributions are becoming very close to the best utilization that we could expect to see.01020304050607080901000 2 4 6 8 10 12 14 16 18 20Percentlog2Requests per SessionRequests per Client1 sec10 sec100 sec1e3 sec1e4 sec1e5 sec01020304050607080901000 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32Percentlog2Bytes per SessionBytes Per Client1 sec10 sec100 sec1e3 sec1e4 sec1e5 secFigure 16 Analysis of per Session Activity a Requests b Bytes Transferreda bWorkload Characterization User Session AnalysesArlitt and Jin Page 54 of 90Figure 16a indicates the number of requests per session for the different timeout values.One intriguing observation from this graph is the percentage of sessions during which theclient issues only a single request. Even though the percentage of sessions that exhibit thisbehaviour decreases rapidly as the timeout value increases, 17 of sessions when using a100 second timeout sent only a single request to the World Cup site. To determine thecause of this phenomenon we analyzed these single request sessions more rigorously. Wefound that for the 100 second timeout case, 50 of these single requests were for base filese.g., HTML, 38 for embedded files e.g., Image and Java, 6 for single files e.g., Compressed and 6 for noncacheable responses e.g., Dynamic requests, error messages.This is vastly different from the overall file type distribution reported in Table 5. We believethat caching, either at the client or within the network, is responsible for many of these shortsessions. That is, many user requests are being served from caches so substantially fewerrequests are reaching the Web site. Embedded files in particular are likely to be cached,which is why we see such a change in the file type distribution. The popularity of the WorldCup site may have added to this phenomenon by increasing the probability that its fileswould be stored in shared caches throughout the Internet. However, we speculate that if thenetwork caching architecture continues to grow more and more sessions may consist of onlya single request or a few requests. Wide spread adoption of Web cache consistencymechanisms, including those in HTTP1.1 19, could also reduce the number of requestsper session.Workload Characterization User Session AnalysesArlitt and Jin Page 55 of 90Figure 16b shows the distribution of total response content bytes sent from the World Cupsite to the client during a session. Not only does the rightmost curve Bytes per Client indicate the best possible use of a session for this workload, it also reveals the amount of content data that each client received for the entire monitoring period. For example, 15 of allclients received more than 1 MB 220 bytes of data. Looking at Figure 16b we can seethat for small timeout values e.g., 1 or 10 seconds about 10 of all sessions transferred nocontent data. These sessions consisted primarily of Not Modified responses, another indication of caching at work. With a 100 second timeout 50 of all sessions transferredbetween 64 KB and 1 MB of content 216  220 bytes.5.6.6 InterSession TimesOur next analysis of sessions studies the offtimes between successive sessions from thesame client. We calculate the offtime from the moment a session times out until the arrivalof the first request in the clients next session. By eliminating the timeout value from theintersession time we can determine how long a server would have been required to maintain the session before receiving the next request from the client. The distribution for thetime between the last request of session si and the first request of session si1 can be determined by shifting the curve to the right by the timeout value.Workload Characterization User Session AnalysesArlitt and Jin Page 56 of 90The results of this analysis are shown in Figure 17. For small timeout values the graphreveals that the sessions would have been reused had the server maintained them for a fewadditional seconds. For example, with a one second timeout more than half of the sessionscould have been reused if the server had waited an additional two seconds before closingthem. As the timeout values increase the server would need to maintain the sessions for asignificantly longer period of time in order to see any further use. Assuming a 100,000 second timeout only 22 of the sessions could have been reused if the server had maintainedthem for an additional day 216 seconds.0204060801000 2 4 6 8 10 12 14 16 18 20 22PercentInterSession Times, Same Client log 2 seconds1 sec10 sec100 sec1e3 sec1e4 sec1e5 secFigure 17 Analysis of InterSession TimesWorkload Characterization User Session AnalysesArlitt and Jin Page 57 of 905.6.7 IntraSession TimesOur final set of analyses in this section examine intrasession times. This information maybe useful in developing more adaptive policies for managing TCP connections on a Webserver.We conducted two separate analyses. One of these analyses measured the time betweenrequests in each distinct session. Figure 18 shows the cumulative frequency distribution forall of these interrequest times. Due to the coarse timestamp granularity, most of the interrequest times are either 0 or 1 second over 60 for all session timeout values. This indicates that most of the requests in a user session are automatically generated by the client i.e., the browser automatically retrieving all of the embedded objects in the Web page thatthe user requested. Most of the remaining interrequest times are less than 64 seconds26. These correspond to the time between the last automatically generated request andthe request for the next page that the user is interested in. In a few cases the interrequesttime exceeds 64 seconds.0204060801000 2 4 6 8 10 12 14 16 18 20PercentInter Request Times, Same Client log2 seconds1 sec10 sec100 sec1e3 sec1e4 sec1e5 secFigure 18 Analysis of InterRequest Times in Individual User SessionsWorkload Characterization User Session AnalysesArlitt and Jin Page 58 of 90In order to get a better estimate of user think times i.e., the time between a user requesting Web page i and Web page i1, we decided to monitor the time between requests forHTML objects in each distinct session. As expected, the interrequest times for HTMLobjects shown in Figure 19b are much longer than for all object types Figure 18. Thereare fewer interrequest times of 0 or 1 second when only the HTML files are considered, dueto fewer automatically generated requests. Since many of the World Cup Web pages utilized frames i.e., were composed of several HTML objects there are still a significant number of automatically generated requests. For the larger session timeouts e.g., 1,000 to100,000 seconds approximately 45 of the interHTML request times are between 8 and255 seconds 23 up to, but not including, 28 in duration. For these session timeout valuesFigure 19a indicates that the most common use think times are in the 3263 secondrange 25 seconds. As the session timeout value increases we see a larger number of longinterrequest times for HTML objects. While some of these are userthink times, othersresult from the merging of multiple sessions into one logical session.In our analyses a session ends when it has been idle for more than a threshold value tseconds. In other words the session will timeout when no request has been made by theclient in more than t seconds. Using this definition no interrequest times greater than t willbe seen. Thus, in Figure 18 all of the curves are bounded by the session timeout value.However, it is possible for the time between subsequent requests for HTML objects toexceed t. For example, when HTML object i is requested, it is usually followed by a numberof automatically generated requests for the embedded objects e.g., the inline images. ThisWorkload Characterization User Session AnalysesArlitt and Jin Page 59 of 90process may take several e.g., x seconds to complete, depending on the network connectivity, the server load, the number of embedded objects, etc. Following this there is typicallyan idle time e.g., y seconds as the user reads the Web page. The idle time ends when theuser selects a hyperlink which results in the request of HTML object i1. If the idle timeexceeds the timeout threshold i.e., y  t then the existing session ends and the request forthe HTML object i1 starts a new session. If the idle time does not exceed the timeoutthreshold i.e., y  t then the existing session remains active and we calculate the interHTML request time ihrt for objects i and i1 as ihrtxy. For example, if x8, y7 andt10, then ihrt15 this satisfies both the properties of y  t and ihrt  t. Thus, it is possiblefor inter HTML request times to exceed the session timeout value. Therefore, the curves inFigure 19 are not bounded by the session timeout value.01020304050607080900 2 4 6 8 10 12 14 16 18 20PercentInter HTML Request Times, Same Client log2 seconds1 sec10 sec100 sec1e3 sec1e4 sec1e5 sec0204060801000 2 4 6 8 10 12 14 16 18 20PercentInter HTML Request Times, Same Client log2 seconds1 sec10 sec100 sec1e3 sec1e4 sec1e5 secFigure 19 Analysis of InterRequest Times for HTML Objects a Frequency b Cumulative Frequencya bAnalysis of a Peak Workload Analysis PeriodArlitt and Jin Page 60 of 906 ANALYSIS OF A PEAK WORKLOADIn Section 5 we characterized the World Cup workload across the entire data collectionperiod. In Section 5.2 we noted that much of the traffic came in large bursts that occurredwhile football matches were in progress. In this section we analyze the workload from one ofthese large bursts and compare the results to those in Section 5. The purpose of this studyis to determine what changes, if any, occur to the workload characteristics when the traffic isexceptionally heavy.6.1 Analysis PeriodFor this analysis we chose the busiest 15 minute period from the overall World Cup workload. This period occurred from 1130pm until 1145pm, June 30th, 1998. During this timepenalty kicks were being used to determine the victor in a playoff match between Argentinaand England. For the remainder of this paper we shall refer to this subset of the overallWorld Cup workload as the AE workload.Table 11 Summary of Access Log Characteristics AE WorkloadDuration 1130pm1145pm, June 30th, 1998Total Requests 3,135,993Avg RequestsMinute 209,066Total Bytes Transferred GB 8.5Avg Bytes TransferredMinute MB 580Analysis of a Peak Workload Statistical CharacteristicsArlitt and Jin Page 61 of 90Table 11 reports some overall statistics on the AE workload. Over three million requestswere received by the World Cup site during the 15 minute period. The average number ofrequests received per minute was over 19 times the average rate for the overall workloadsee Table 1 on page 8. The average rate of data transfer per minute for the AE workloadwas 13 times that of the overall workload.6.2 Statistical CharacteristicsTable 12 reports the breakdown of HTTP versions supported by clients in the AE workload.The results are quite similar to those for the overall workload shown in Table 2 on page 11.Table 12 Breakdown of HTTP Version AE WorkloadHTTP Version  of Requests  of Content Data Transferred0.9 0.00 0.001.0 78.30 82.361.1 21.67 17.54x.x 0.03 0.10Total 100.00 100.00Table 13 Breakdown of Resource Methods AE WorkloadMethod  of Requests  of Content Data TransferredGET 99.99 99.97HEAD 0.01 0.03POST 0.00 0.00Total 100.00 100.00Analysis of a Peak Workload Statistical CharacteristicsArlitt and Jin Page 62 of 90Table 13 lists the breakdown of resource methods for all of the requests in the AE workload.This breakdown is also quite similar to the overall results Table 3 on page 13. For allremaining analyses we focus exclusively on the requests which utilized the GET resourcemethod.Table 14 shows the breakdown of server response codes from the AE workload. Thisbreakdown is quite different from the overall distribution provided by Table 4 on page 13.The most significant change between the workloads is the percentage of Not Modifiedresponses. In the AE Workload over 37 of all server responses were Not Modified. Thisis twice the percentage seen in the overall workload. This characteristic indicates that manyof the clients are simply performing consistency checks to ensure that the World Cup filesthat they have stored in their caches are still uptodate. This is likely the result of users hitting the reload button on their browsers to check whether there has been a change in thestatus of the match.Table 14 Breakdown of Server Response Codes AE WorkloadResponse Code  of Requests  of Content Data Transferred200 Successful 62.63 99.94206 Partial Content 0.01 0.04304 Not Modified 37.18 0.004xx Client Error 0.18 0.025xx Server Error 0.00 0.00Other Codes 0.00 0.00Total 100.00 100.00Analysis of a Peak Workload Statistical CharacteristicsArlitt and Jin Page 63 of 90Table 15 presents the breakdown of the requests in the AE workload by file type. There areseveral differences between the file type distribution for this workload and the overall workload reported in Table 5 on page 15. For example, in the AE workload HTML files are nowthe dominant source of the content data transferred. This occurs because the HTML filesare being modified to reflect changes in the status of the match and thus must be served intheir entirety. Images, which account for most of the requests, account for a much smallerpercentage of the content data transferred as many responses are simply acknowledgmentsthat the file has not been modified and thus contain no content data. Since most usersappear to be interested primarily in the status of the match, the compressed files are evenless popular than normal and therefore have less impact on the total content data transferred in the AE workload than they did in the overall workload.Table 15 Breakdown by File Type AE WorkloadFile Type  of Requests  of Content Data TransferredHTML 7.36 67.84Images 90.96 26.08Audio 0.00 0.09Video 0.00 0.14Compressed 0.00 1.13Java 0.34 0.45Dynamic 0.00 0.00Other Types 1.34 4.27Total 100.00 100.00Analysis of a Peak Workload Statistical CharacteristicsArlitt and Jin Page 64 of 90Table 16 shows how the requests in the AE workload were distributed across the fourserver locations. These results indicate that the Paris location received a substantiallysmaller percentage of the requests in the AE workload compared to the overall workloadsee Table 6 on page 17. Meanwhile the Herndon site received a larger percentage of therequests. Assuming that the clients were sent to a geographically close location which isnot always the case we would expect to see this behaviour, as most European users wouldlikely be watching the match on television recall that the match is in the late evening forEuropean fans.Table 16 Breakdown by Location AE WorkloadLocation  of  Requests  of Content Data TransferredSanta Clara, CA 13.36 13.68Plano, TX 46.99 45.53Herndon, VA 34.61 36.11Paris, FR 5.04 4.68Total 100.00 100.00Analysis of a Peak Workload Statistical CharacteristicsArlitt and Jin Page 65 of 90Table 17 reports the breakdown of clients by the number of server locations that they contacted. A total of 20,531 unique clients were seen during the 15 minute AE workload.Many of these clients 82.72 contacted only a single location during this time. These clients accounted for 67.81 of all requests in the AE workload and 66.44 of the bytesTable 17 Breakdown of Clients AE WorkloadLocationa  of Unique Clients  of Requests  of Bytes TransferredSingle Location SC only 10.69 7.65 7.67PL only 35.61 32.62 30.96HN only 29.38 24.02 24.56PA only 7.04 3.52 3.25Subtotal 82.72 67.81 66.44Two Locations SC  PL 4.55 7.16 7.44SC  HN 1.69 2.10 2.23SC  PA 0.20 0.20 0.20PL  HN 6.16 10.50 11.24PL  PA 1.02 1.26 1.31HN  PA 1.11 1.21 1.33Subtotal 14.73 22.43 23.75Three Locations SC, PL  HN 1.35 5.46 5.50SC, PL  PA 0.22 0.77 0.76SC, HN  PA 0.13 0.21 0.25PL, HN  PA 0.55 1.55 1.57Subtotal 2.25 7.99 8.08Four Locations SC, PL, HN  PA 0.30 1.77 1.73Total 100.00 100.00 100.00a. Abbreviation definitions are given in Table 21 on page 87.Analysis of a Peak Workload UsageArlitt and Jin Page 66 of 90transferred. This should not be unexpected as the network dynamics should be relativelystable during this short period of time, although the flash crowd could affect this. Therewere still a significant number of clients that contacted multiple locations although the percentages were much smaller than for the overall workload Table 7 on page 19. There wereeven a few clients 0.30 that sent requests to each of the four server locations during this15 minute time frame.  A lack of information prevents us from examining this in more depth.6.3 UsageFigure 20 shows the request rate for the AE workload. Figure 20a reveals that throughoutthis 15 minute period the request rate is relatively stable, with an average rate of 3,484requests per second and a peak rate of 3,816 requests per second. Figure 20b indicatesthat on a per minute basis the request rate is even more stable, peaking at 215,241 requestsper minute and averaging 209,066 requests per minute.050010001500200025003000350040001130pm 1135pm 1140pm 1145pmRequests per SecondTime0500001000001500002000001130pm 1135pm 1140pm 1145pmRequests per MinuteTimeFigure 20 AE Workload, Volume of Requests a per second b per minutebaAnalysis of a Peak Workload Size DistributionsArlitt and Jin Page 67 of 906.4 Size Distributions6.4.1 Size Distribution of Unique FilesTable 18 provides a breakdown of the size distributions by type for the unique files requestedin the AE workload. There are a number of differences compared to the unique size distribution of the overall workload refer to Table 8 on page 26. For example, fewer unique fileswere accessed in the AE workload. This indicates the focus of the users on a particularsubject. Also, the number of unique HTML files accessed was substantially less, again indicating that the users were interested in a smaller set of the pages available at the World Cupsite.  Finally, fewer large files were accessed in the AE workload.Figure 21 presents the unique file size distribution for the AE workload. The results showthat the distributions are quite similar to those from the overall workload see Figure 3 onpage 27 except that no extremely large files e.g., greater than 10 MB were seen in the AE workload.Table 18 Unique File Size Information by File Type AE WorkloadAll Files HTML Image Audio Video Java Compressed DynamicNumber 5,201 1,948 3,184 22 9 4 14 9Mean bytes 15,238 11,418 6,054 375,163 1,458,673 4,043 1,139,356 33,510Median bytes 4,850 6,066 3,876 139 1,367,199 4,406 1,419,393 25,596Maximum MB 2.8 0.12 0.10 1.3 1.9 0.004 2.8 0.06Total Size MB 75.6 21.2 18.4 7.9 12.5 0.02 15.2 0.29Analysis of a Peak Workload Size DistributionsArlitt and Jin Page 68 of 906.4.2 Size Distribution of Successful TransfersTable 19 breaks down the successful transfer size distribution by file type. The mean andmedian successful transfer sizes are quite similar to those reported in Table 9 on page 31 forthe overall workload. For example the median successful transfer size in the AE workloadis 933 bytes compared to 965 bytes for the overall workload. Perhaps the most significantdifference is the changes in the mean and median transfer sizes for HTML files. For example the median HTML transfer size nearly quadrupled to 46,941 bytes in the AE workloadfrom 12,624 bytes in the overall workload.Table 19 Successful Transfer Size Information by File Type AE WorkloadAll Transfers HTML Image Audio Video Java Compressed DynamicNumber 1,963,850 183,207 1,735,079 139 9 9,755 136 20Mean bytes 4,619 33,609 1,363 59,486 1,458,673 4,186 738,062 17,884Median bytes 933 46,941 872 124 1,367,199 4,406 263,198 6,218Maximum MB 2.8 0.12 0.10 1.3 1.9 0.004 2.8 0.06 Bytes Transferred GB 8.5 5.7 2.2 0.01 0.01 0.038 0.09 0.000302468100 2 4 6 8 10 12 14 16 18 20 22 24 26PercentageFile Size in log2BytesEmpirical Synthetic432100 1 2 3 4 5 6 7 8log 10PXxFile Size in log 10Bytes0204060801000 2 4 6 8 10 12 14 16 18 20 22 24 26PercentageFile Size in log2BytesEmpirical SyntheticFigure 21 Size Distribution of Unique Files, AE Workload a Frequency b Cumulative Frequency c Taila b cAnalysis of a Peak Workload Size DistributionsArlitt and Jin Page 69 of 90Figure 22 shows the graphs of the body and tail of the successful transfer sizes in the AEworkload. These distributions are similar to those for the overall workload shown in Figure 5on page 32. The main difference is in the tail of the distributions, due to fewer large filesbeing requested in the AE workload.6.4.3 Size Distribution of All TransfersFigure 23 shows the size distribution for all transfers in the AE workload. The increase inNot Modified responses in this workload adds significantly more 0sized transfers toFigure 23a. The presence of these 0sized responses lowers the median transfer size to305 bytes compared to 828 bytes for the overall workload described in Section 5.3.3. Thetail of the transfer size distribution for the AE workload, shown in Figure 23b is not asheavy as the overall workload see Figure 6b, indicating a lower probability that large fileswill be requested.02468100 2 4 6 8 10 12 14 16 18 20 22 24 26PercentageFile Size in log2BytesEmpirical Synthetic10864200 1 2 3 4 5 6 7 8log 10PXxFile Size in log10Bytes0204060801000 2 4 6 8 10 12 14 16 18 20 22 24 26PercentageFile Size in log2BytesEmpirical SyntheticFigure 22 Size Distribution of Successful Transfers, AE Workload a Frequency b Cumulative Frequency c Taila b cAnalysis of a Peak Workload Size DistributionsArlitt and Jin Page 70 of 906.4.4 Impact of Size DistributionsFigure 24 relates the size of the unique files requested in the AE workload to the number ofrequests and bytes transferred. As was the case in the overall workload Figure 7 on page34 most of the unique files are quite small while most of the storage space is consumed bya few large files. Also, most of the requests to the site are for the extremely small files. Theone significant difference between the workloads is that in the AE workload files in the 1664 KB range account for most of the bytes transferred larger files have little impact on thenetwork bandwidth. In the overall workload responses containing files larger than 64 KBaccounted for 21 of all bytes transferred.02468100 2 4 6 8 10 12 14 16 18 20 22 24 26PercentageFile Size in log2Bytes10864200 1 2 3 4 5 6 7 8log 10PXxFile Size in log10Bytes0204060801000 2 4 6 8 10 12 14 16 18 20 22 24 26PercentageFile Size in log2BytesFigure 23 Size Distribution of All Transfers, AE Workload a Frequency b Cumulative Frequency c Taila b cAnalysis of a Peak Workload File Referencing BehaviourArlitt and Jin Page 71 of 906.5 File Referencing Behaviour6.5.1 Temporal LocalityTable 20 lists the results of the stack depth analysis for the AE workload. Compared to theresults in Table 10 on page 36 for the overall workload, both the mean and median stackTable 20 Temporal Locality Analysis AE WorkloadAll Locations Santa Clara Plano Herndon Parismean stack depth 75 62 71 73 85standard deviation 147 72 123 111 123median stack depth 52 49 51 53 5990th percentile 121 111 116 125 154normalized mean stack depth 0.014 0.012 0.014 0.014 0.016normalize median stack depth 0.010 0.009 0.010 0.010 0.0110204060801000 2 4 6 8 10 12 14 16 18 20 22 24Cumulative PercentageFile Size in log2BytesUnique FilesStorage SpaceRequestsContent DataTransferredFigure 24 Impact of Size Distributions on Server and Network, AE WorkloadAnalysis of a Peak Workload File Referencing BehaviourArlitt and Jin Page 72 of 90depths are substantially shorter. This difference illustrates the interest in a smaller set offiles at the World Cup site during the AE workload.Figure 25 provides the frequency, cumulative frequency and logtransformed cumulative frequency histograms for the stack depth distribution for the AE workload. These graphs indicate that the temporal locality is much stronger in the AE workload than it was in the overallworkload. That is, the top of the stack received a much higher percentage of references inFigure 25 than in Figure 8 on page 37 the overall workload.6.5.2 Concentration of ReferencesFigure 26 shows the distribution of all client requests across the unique files in the AE workload. The results in Figure 26 show that the references in the AE workload were even moreconcentrated than they were in the overall workload Figure 9 on page 38. For example, themost popular 10 of the unique files in the AE workload received 99 of the requests andaccounted for 96 of the content data transferred while occupying only 2 of the total stor00.20.40.60.811.21.40 100 200 300 400 500 600 700 800 900 1000PercentageStack DepthAllSCPlanoHerndonParis0204060801000 1 2 3 4 5 6 7 8 9 10 11 12 13 14Percentagelog2Stack DepthAllSCPlanoHerndonParis0204060801000 100 200 300 400 500 600 700 800 900 1000PercentageStack DepthAllSCPlanoHerndonParisFigure 25 Stack Depth Distribution, AE Workload a Frequency b Cumulative Frequency c LogTransformed CFa b cAnalysis of a Peak Workload File Referencing BehaviourArlitt and Jin Page 73 of 90age space. In the overall workload the most popular 10 of files accounted for only 97 ofreferences and 89 of the bytes transferred.Onetimers are much more prevalent in the AE workload than they were in the overall workload. 2,069 39.8 of the 5,201 unique files in the AE workload were accessed only a single time. These files accounted for 59.0 of the total size of the unique files accessedduring this collection period. These observations indicate that very few people were browsing through the site during this period the attention of most users was on a few extremelypopular pages.Figure 27a shows the relative popularity of the unique files referenced in the AE workload.As was the case with the overall workload Figure 10 on page 40 the popularity rankingdoes not appear to follow a Zipflike distribution. In Figure 27a two linear regions are evi0204060801000 10 20 30 40 50 60 70 80 90 100Cumulative PercentagePercentage of Unique FilesStorage SpaceRequestsContent Data TransferredFigure 26 Concentration of References, cumulative distribution, AE WorkloadAnalysis of a Peak Workload User Session AnalysesArlitt and Jin Page 74 of 90dent the first for files 1100 and the second for files 1005,201. Figure 27a does not havethe third linear region that is present in Figure 10a for the overall workload.Figure 27b presents the relative popularity of the HTML files referenced in the AE workload. Two distinct regions can be seen in this graph. In region I files 120 the files are substantially more popular than the files in region II files 201,948. In region II the graph isroughly linear with slope estimated at 1.5. Thus a Zipflike distribution would not accuratelycapture the concentration of references to the most popular files. A Zipflike distribution maystill provide a reasonable approximation for some testing purposes.6.6 User Session AnalysesIn this section we analyze the user sessions from the AE workload using the approachdescribed in Section 5.6. We then compare the results for this workload with those for theoverall workload.1101001000100001000001e061 10 100 1000 10000Reference CountFile RankHTML filesImage files1101001,00010,0001 10 100 1,000Number of RequestsHTML File RankFigure 27 Concentration of References, reference count vs. rank, AE Workload a All Files b HTML files onlya bAnalysis of a Peak Workload User Session AnalysesArlitt and Jin Page 75 of 906.6.1 Total SessionsFigure 28 shows the analysis results for the number of user sessions calculated for varioustimeout values. Since the AE workload is only 900 seconds in duration we only tested threetimeout values 1, 10, and 100 seconds. With this workload the two extreme cases are3,135,993 sessions when each HTTP request utilizes its own TCP connection, and 20,531sessions when each unique client in the workload receives a persistent connection to use forthe duration of the analysis period.Figure 28a shows the total number of sessions seen for each of the timeout values examined along with the corresponding maximum number of active sessions. For example, with a10 second timeout, a total of 174,123 sessions occurred with at most 5,282 active at once.As expected, the total number of sessions decreases and the maximum number of activesessions increases as the timeout value increases.1e41e51e61 10 1001e31e41e5Total SessionsMaximum Active SessionsIdle Timeout secondsTotal SessionsMax Sessions00.20.40.60.810 1 10 10000.20.40.60.81 Sessions   GET Requests Active SessionsUnique ClientsIdle Timeout secondsTotal SessionsMax SessionsFigure 28 Effect of Timeout Values on Total Number of Sessions AE WorkloadAnalysis of a Peak Workload User Session AnalysesArlitt and Jin Page 76 of 90Figure 28b compares the total number of sessions and the maximum number of activesessions to the extreme cases. For example, when a 10 second timeout is used only 5.6of the total sessions occur compared to when each HTTP request uses its own TCP connection. At the same time 25.7 of the unique clients have active sessions. The main difference between Figure 28b and Figure 12b in section 5.6.1 on page 47 is the fraction ofclients that have an active session. There is also a slightly better reuse of sessions in the AE workload as indicated by the lower percentage of total sessions to GET requests for equivalent timeout values.6.6.2 Active SessionsFigure 29 shows the number of active sessions measured at the start of each one secondinterval. Figure 29a reports the results for a one second session timeout value. With thistimeout value the number of active sessions is quite variable. This variability is related tosessions timing out at the server before the client returns to the site to recheck the status of16001650170017501800185019002330 2335 2340 2345Active SessionsTime020004000600080001000012000140002330 2335 2340 2345Active SessionsTimeFigure 29 Active Sessions Over Time, AE Workload a 1 Second Timeout b 100 Second TimeoutAnalysis of a Peak Workload User Session AnalysesArlitt and Jin Page 77 of 90a match. When the client does return a new session must be created. Figure 29b provides the results for a 100 second session timeout value. In this graph the number of activesessions is quite stable. During the first two minutes we can see the growth in active sessions as more and more clients visit this site. This growth is mainly an artifact of our analysis having no knowledge of the active sessions prior to the start of the AE workload. Oncemost of the unique clients around 12,000 have established sessions with the site theyappear to reuse their sessions within 100 seconds. This behaviour maintains their sessionfor the duration of the workload.6.6.3 Session LengthFigure 30 shows the length of sessions for the tested timeout values. In the AE workloadsessions tended to last slightly longer when short timeout values were used e.g., 1 secondbut not as long when greater timeout values were used e.g., 100 seconds compared to theoverall workload Figure 14 on page 51. Also, the session lengths in the AE workload areconstrained by the duration of the workload 15 minutes or 29 seconds.0204060801000 2 4 6 8 10 12 14 16 18 20 22PercentSession Length log 2 seconds1 sec 10 sec 100 secFigure 30 Analysis of Session Lengths, AE WorkloadAnalysis of a Peak Workload User Session AnalysesArlitt and Jin Page 78 of 906.6.4 Sessions Per ClientFigure 31 shows the number of sessions per client for the AE workload. Due to the shortduration of this workload the reduced number of sessions per client is to be expected whencompared to the overall workload results Figure 15 on page 52. however, Figure 31 indicates that many clients repeatedly visited the site during the 15 minute period that we analyzed. This behaviour is consistent with the reloading of a page to check on the status of thematch.6.6.5 Requests and Bytes Transferred Per SessionFigure 32 shows the number of requests made and the number of content bytes transferredper session for the AE workload. Comparing these results to Figure 16 on page 53 for theoverall workload results reveals that the distributions are quite similar. Figure 32 shows thatfewer sessions are sending only a single request that is, the sessions in the AE workload0204060801000 2 4 6 8 10 12 14 16 18 20Percentlog2Sessions per Client1e2 sec 10 sec 1 secFigure 31 Analysis of the Number of Sessions Per Client, AE WorkloadAnalysis of a Peak Workload User Session AnalysesArlitt and Jin Page 79 of 90were reused more often, particularly with the 100 second timeout. In Figure 32b more ofthe sessions short timeouts only transferred no content. This is due to the increased volume of cache consistency traffic.6.6.6 InterSession TimesFigure 33 shows the intersession time distributions for the AE workload. There are twomain differences between these results and those from the overall workload reported in Figure 17 on page 56. The first difference is that the tails in Figure 33 are much shorter. Thischaracteristic is expected since the AE workload is only 15 minutes 29 seconds in duration. The other difference is the intersession time distribution for the 100 second timeout.In the AE workload the intersession times for this timeout value are much shorter than inthe overall workload. For example, about 55 of the sessions assuming a 100 second timeout in the AE workload were reestablished 32 seconds or less after the previous session01020304050607080901000 2 4 6 8 10 12 14 16 18 20Percentlog2Requests per SessionRequests per Client1 sec 10 sec 100 sec0204060801000 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32Percentlog2Bytes per SessionBytes Per Client1 sec 10 sec 100 secFigure 32 Analysis of Per Session Activity, AE Workload a Requests b Bytes TransferredAnalysis of a Peak Workload User Session AnalysesArlitt and Jin Page 80 of 90timedout. In the overall workload only 17 of sessions were reestablished in this amount oftime. This characteristic of the AE workload indicates that many users were accessing theWorld Cup site about every two minutes 32 seconds  100 seconds for the previous session to timeout to check on the progress of the football match.6.6.7 IntraSession TimesOur final analysis examines the intrasession times for the AE workload. Figure 34 provides the cumulative frequency histogram of the interrequest times collected from each distinct session. This figure indicates that a higher percentage of requests appear to bemachinegenerated in the AE workload than was the case in the overall workload refer toFigure 18 on page 57. This observation is consistent with our hypothesis that most users inthe AE workload were simply reloading the same page again and again.0204060801000 2 4 6 8 10 12 14 16 18 20 22PercentInterSession Times, Same Client log 2 seconds1 sec 10 sec 100 secFigure 33 Analysis of InterSession Times, AE WorkloadAnalysis of a Peak Workload User Session AnalysesArlitt and Jin Page 81 of 90Figure 35 shows the interrequest time distribution for HTML objects. These results indicatethat there were substantially fewer automatically generated HTML requests as indicated bythe 01 second spacing, while more of the interrequest spacings were in the 4127 second22 upto, but not including 27. These results seem consistent with users reloading a pagemultiple times over the duration of the workload.0204060801000 2 4 6 8 10 12 14 16 18 20PercentInter Request Times, Same Client log2 seconds1 sec 10 sec 100 secFigure 34 Analysis of InterRequest Times in Individual User Sessions, AE Workload0204060801000 2 4 6 8 10 12 14 16 18 20PercentInter HTML Request Times, Same Client log2 seconds1 sec 10 sec 100 sec0204060801000 2 4 6 8 10 12 14 16 18 20PercentInter HTML Request Times, Same Client log2 seconds1 sec 10 sec 100 secFigure 35 Analysis of InterRequest Times for HTML Objects, AE Workload a Frequency b Cumulative Frequencya bPerformance Implications User Session AnalysesArlitt and Jin Page 82 of 907 PERFORMANCE IMPLICATIONSDuring our workload characterization study Section 5 and Section 6 we examined numerous characteristics of the World Cup workload. In this section we discuss the implications ofseveral of these characteristics on Web server performance.In Section 5.6.5 we discovered that a significant number of user sessions 17 when a 100second timeout was used contained only a single request during the lifetime of the session.There is no benefit in maintaining a persistent connection for this type of session, particularly for the server that must reserve resources for the connection. This characteristic ofuser sessions suggests that a trivial fixed length timeout policy for closing idle connectionson the server may be inadequate. A more appropriate, but still relatively simple approachwould be to utilize an adaptive timeout scheme like the one suggested by Mogul for dealingwith proxies that do not support persistent connections 30. With this approach the initialtimeout value is quite small, so that if the connection is not reused it will quickly be considered idle and be closed by the server. If the connection is reused the timeout value would beincreased to a more appropriate value. More adaptive TCP connection management policies for Web servers may also be useful. For example, a Web server could automaticallyadjust the idle timeout value in order to keep the number of active sessions within a specifiedrange. A number of TCP connection management policies for persistent HTTP have beenexamined by Cohen et. al. 9.Our previous work on Web server workload characterization 3 analyzed access logs thatpredated the widespread use of browsers with persistent i.e., disk caches, proxy caches,Performance Implications User Session AnalysesArlitt and Jin Page 83 of 90and transparent network caches. Today, Web server workloads have changed due to thegrowth of a Web caching architecture. In particular, many Web server responses are NotModified and contain no content data. The results of this workload characterization studyhave identified several other ways in which caching is altering Web server workloads. In ouranalysis of user sessions in Section 5.6.5 we determined that caching, in some cases, isreducing the number of requests that might utilize a persistent connection. The implicationsof this characteristic on server design are discussed at the beginning of this section. Furtherresearch is required to determine if fewer requests per session is a growing trend, and if so,what are the implications on Web servers and on HTTP.A second observation regarding the effects of caching on Web server workloads was madein Section 6. From the perspective of Web server performance the main benefit of client,proxy and network caching is the reduction in workload at the server, particularly during periods of extreme user interest. Our results in Section 6 indicate that the lack of an efficientconsistency mechanism is preventing Web servers from fully benefiting from caching. Inother words when portions of the Web sites content is extremely popular the sites serversare not seeing a substantial reduction in workload. Instead of responding to a large numberof GET requests, the servers must respond to a large number of cache consistency requestsi.e., GET If Modified Since requests.Many of the requests for consistency information in the World Cup workload were caused bythe caching of static image files. Much of this traffic could have been eliminated if the consistency functionality of HTTP1.1 19 had been utilized by the site and supported by theSummary, Contributions and Future Work User Session AnalysesArlitt and Jin Page 84 of 90caches. However, the consistency mechanisms in HTTP1.1 are not adequate in all situations e.g., the modification patterns of some files are unpredictable, like the score of a football match that is in progress.  Furthermore, it remains to be seen whether this functionalityof HTTP1.1 will meet the needs of content providers or whether a new, more automatedsystem will be required. Several research efforts have looked at alternative cache consistency mechanisms 162526. If a new system is indeed required it should include amethod of propagating only the changes to the cache storing the old version of a file, as suggested by Mogul et. al.  29.During the World Cup tournament an estimated 13 million cumulative users visited theFrance 98 Web site. During this same period an estimated cumulative audience of 40 billionwatched the matches on television. While the gap between Internet users and televisionaudiences is partially due to restricted Internet access in some countries the main reason isclear  the audiences preferred live high quality video to still images and text descriptions.This suggests the integration of video and the Web may be necessary to reach a muchgreater portion of the worlds population. Adding high quality video to a Web site would havesignificant performance implications.8 SUMMARY, CONTRIBUTIONS AND FUTURE WORKThis paper has presented a detailed workload characterization study of the 1998 World CupWeb site. The data set analyzed in this study contained 1.35 billion requests collected overa three month period, making this the largest Web server characterization study to date.Summary, Contributions and Future Work User Session AnalysesArlitt and Jin Page 85 of 90Throughout the paper emphasis was placed on comparing the characteristics of the WorldCup workload to those observed in other Web server workloads.The results of our study revealed that caching at Web clients, proxies and within the networkis changing the workloads seen by Web servers. The lack of an efficient, supported andwidely adopted cache consistency mechanism is the main cause of these changes and theprimary reason why Web caches are failing to significantly reduce Web server workloadsduring times of extreme user interest in the content on those servers.This paper presented preliminary results on many different facets on the workload of theWorld Cup Web site. Further, more indepth analyses are needed on many of the topics discussed in this paper. For example, more precise modeling of sessions is required to evaluate the effects of longer sessions on server resource utilization. Other future work in thisarea includes developing new or reconfiguring existing Web server benchmarks to reflectcurrent workloads. Such benchmarks are needed to more accurately estimate the performance of a particular server configuration. Additional workload characterization is needed,particularly of sites on an ongoing basis, to determine if the characteristics observed in thisdata set are present in others and to understand how these characteristics change overtime. In order to perform more accurate analyses in the future, more precise measurementsof server workloads are needed. This may involve changing the data collected in accesslogs e.g., store finergrained timestamps or utilizing alternative methods of data collectione.g., system instrumentation. Finally, as we alluded to earlier in this paper, a more efficientAcknowledgments User Session AnalysesArlitt and Jin Page 86 of 90cache consistency mechanism, preferably one that requires little human intervention, isneeded to further the scalability of the Web.9 ACKNOWLEDGMENTSThe authors would like to thank all of the people who made this work possible. The authorsare particularly grateful to the people at EDS who provided the World Cup access logs toChristian Hostelet, HP Technical Director of the World Cup as well as Joel Dubedat andJean Le Saint for providing information on the World Cup Web site architecture to KateyKennedy and Robert Slinn for providing statistics on the television audiences for the WorldCup to Mark Crovella of Boston University, for his assistance with the statistical analysesand to Paul Barford of Boston University, Jim Pitkow of Xerox PARC, and Sharad Singal andGary Herman of HP Labs for their constructive comments on the paper.Appendix A User Session AnalysesArlitt and Jin Page 87 of 9010 APPENDIX ATable 21 Abbreviations for Hosting LocationsAbbreviation LocationSC Santa Clara, CAPL Plano, TXHN Herndon, VAPA Paris, FranceTable 22 Abbreviations for Team NamesAbbreviation Team Abbreviation TeamARG Argentina ITA ItalyAUT Austria JAM JamaicaBEL Belgium JPN JapanBGR Bulgaria KOR South KoreaBRA Brazil KSA Saudi ArabiaCHI Chile MEX MexicoCMR Cameroon MOR MoroccoCOL Columbia NGA NigeriaDEN Denmark NOR NorwayENG England PAR ParaguayESP Spain ROM RomaniaFRA France RSA South AfricaGER Germany SCO ScotlandHOL The Netherlands TUN TunisiaHRV Croatia USA United StatesIRN Iran YUG YugoslaviaReferences User Session AnalysesArlitt and Jin Page 88 of 9011 REFERENCES1 V. Almeida, A. Bestavros, M. Crovella and A. de Oliveira, Characterizing Reference Locality in the WWW,Proceedings of 1996 International Conference on Parallel and Distributed Information Systems PDIS 96,pp. 92103, December 1996.2 M. Arlitt, R. Friedrich and T. Jin, Workload Characterization of a Web Proxy in a Cable ModemEnvironment, ACM SIGMETRICS Performance Evaluation Review, Vol. 27, No. 2, pp. 2536, August 1999.3 M. Arlitt and C. Williamson, Internet Web Servers  Workload Characterization and PerformanceImplications, IEEEACM Transactions on Networking, Vol. 5, No. 5, pp. 631645, October 1997.4 P. Barford and M. Crovella, A Performance Evaluation of HyperText Transfer Protocols, Proceedings ofACM SIGMETRICS 99, Atlanta, GA, pp. 188197, May 1999.5 P. Barford, A. Bestavros, A. Bradley and M. Crovella, Changes in Web Client Access Patterns, to appearin World Wide Web Journal, Special Issue on Characterization and Performance Evaluation, 1999.6 P. Barford and M. Crovella, Generating Representative Web Workloads for Network and ServerPerformance Evaluation, Proceedings of ACM SIGMETRICS 98, Madison, WI, pp. 151160, June 1998.7 L. Breslau, P. Cao, L. Fan, G. Phillips and S. Shenker, Web Caching and ZipfLike Distributions Evidenceand Implications, Proceedings of IEEE Infocom 99, New York, NY, March 1999.8 P. Cao and S. Irani, CostAware Proxy Caching Algorithms, Proceedings of USENIX Symposium onInternet Technologies and Systems USITS, Monterey, CA, pp. 193206, December 1997.9 E. Cohen, H. Kaplan and J. Oldham, Managing TCP Connections under Persistent HTTP, Proceedings ofthe Eighth International World Wide Web Conference, Toronto, Canada, May 1999.10M. Crovella, personal communication email, January 1999.11M. Crovella and M. Taqqu, Estimating the Heavy Tail index from Scaling Properties, to appear inMethodology and Computing in Applied Probability, Vol. 1, November 1, 1999.12M. Crovella and A. Bestavros, SelfSimilarity in World Wide Web Traffic Evidence and Possible Causes,IEEEACM Transactions on Networking, Vol. 5, No. 6, pp. 835846, December 1997.13C. Cunha, A. Bestavros, and M. Crovella, Characteristics of WWW ClientBased Traces, Technical ReportTR95010, Boston University Department of Computer Science, April 1995.14K. Delgadillo, Cisco DistributedDirector, Cisco White Paper, 1997.  Available at www.cisco.com.15J. Dilley, The Effect of Consistency on Cache Response Time, HewlettPackard Laboratories TechnicalReport HPL1999XXX, September 1999.16J. Dilley, M. Arlitt, S. Perret and T. Jin, The Distributed Object Consistency Protocol, HewlettPackardLaboratories Technical Report HPL1999XXX, September 1999.17B. Duska, D. Marwood and M. Feeley, The Measured Access Characteristics of WorldWide Web ClientProxy Caches, Proceedings of USENIX Symposium of Internet Technologies and Systems USITS,Monterey, CA, pp. 2335, December 1997.References User Session AnalysesArlitt and Jin Page 89 of 9018A. Feldmann, R. Caceres, F. Douglis, G. Glass and M. Rabinovich, Performance of Web Proxy Caching inHeterogeneous Bandwidth Environments, Proceedings of IEEE Infocomm 99, New York, NY, pp.107116,March 1999.19R. Fielding, J. Gettys, J. Mogul, H. FrystykNielsen, L. Masinter, P. Leach, and T. BernersLee, RFC 2616 Hypertext Transfer Protocol   HTTP1.1, June 1999.20FIFA Web site, httpwww.fifa.com21H. FrystykNielsen, J. Gettys, A. BairdSmith, E. Prudhommeaux, H. WiumLie and C. Lilley, NetworkPerformance Effects of HTTP1.1, CSS1 and PNG, Proceedings of ACM SIGCOMM 97, Cannes, France,September 1997.22S. Gribble and E. Brewer, System Design Issues for Internet Middleware Services Deductions from aLarge Client Trace, Proceedings of USENIX Symposium on Internet Technologies and Systems USITS,Monterey, CA, pp. 207218, December 1997.23B. Krishnamurthy and M. Arlitt, PROCOW Protocol Compliance on the Web, HewlettPackardLaboratories Technical Report HPL199999, September 1999.24B. Krishnamurthy, J. Mogul and D. Kristol, Key Differences between HTTP1.0 and HTTP1.1, Proceedingsof the Eighth International World Wide Web Conference, Toronto, Canada, May 1999.25B. Krishnamurthy and C. Wills, Study of Piggyback Cache Validation for Proxy Caches in the WorldWideWeb, Proceedings of USENIX Symposium on Internet Technologies and Systems USITS, Monterey, CA,pp. 112, December 1997.26C. Liu and P. Cao, Maintaining Strong Cache Consistency in the WorldWide Web, Proceedings of the17th IEEE International Conference on Distributed Computing Systems, May 1997.27A. Mahanti and C. Williamson, Web Proxy Workload Characterization, Technical Report, Department ofComputer Science, University of Saskatchewan, February 1999.28S. Manley and M. Seltzer, Web Facts and Fantasy, Proceedings of USENIX Symposium on InternetTechnologies and Systems USITS, Monterey, CA, pp. 125133, December 1997.29J. Mogul, F. Douglis, A. Feldmann, and B. Krishnamurthy, Potential Benefits of Delta Encoding and DataCompression for HTTP, Proceedings of ACM SIGCOMM 97, Cannes, France, pp. 181194, September1997.30J. Mogul, The Case for PersistentConnection HTTP, Proceedings of ACM SIGCOMM 95, Cambridge,MA, pp. 299313, 1995.31Netscape Navigator Remote Control, httphome.netscape.comnewsrefstdxremote.html.32V. Paxson, EmpiricallyDerived Analytic Models of WideArea TCP Connections, IEEEACM Transactionson Networking, Vol. 2, No. 4, pp. 316336, August 1994.33C. Roadknight, I. Marshall and D. Vearer, File Popularity Characterisation, Proceedings of the 2ndWorkshop on Internet Server Performance WISP 99, Atlanta, GA, May 1999.34K. Thompson, G. Miller and R. Wilder, WideArea Internet Traffic Patterns and Characteristics, IEEENetwork, Vol. 11, pp. 1023, NovemberDecember 1997.References User Session AnalysesArlitt and Jin Page 90 of 9035W3C Web page, Logging in W3C httpd, httpwww.w3.orgDaemonUserConfigLogging.html36World Cup Press Literature Kit.
