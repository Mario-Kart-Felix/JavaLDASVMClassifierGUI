HardwareSoftware CoDesignGIOVANNI DE MICHELI, FELLOW, IEEE, AND RAJESH K. GUPTA, MEMBER, IEEEInvited PaperMost electronic systems, whether selfcontained or embedded,have a predominant digital component consisting of a hardwareplatform which executes software application programs. Hardwaresoftware codesign means meeting systemlevel objectivesby exploiting the synergism of hardware and software throughtheir concurrent design. Codesign problems have different flavorsaccording to the application domain, implementation technologyand design methodology.Digital hardware design has increasingly more similarities tosoftware design. Hardware circuits are often described using modeling or programming languages, and they are validated andimplemented by executing software programs, which are sometimesconceived for the specific hardware design. Current integratedcircuits can incorporate one or more processor cores andmemory arrays on a single substrate. These systems on siliconexhibit a sizable amount of embedded software, which providesflexibility for product evolution and differentiation purposes. Thusthe design of these systems requires designers to be knowledgeablein both hardware and software domains to make good designtradeoffs.This paper introduces the reader to various aspects of codesign.We highlight the commonalities and point out the differences invarious codesign problems in some application areas. Codesignissues and their relationship to classical system implementationtasks are discussed to help the reader develop a perspective onmodern digital system design that relies on computeraided designCAD tools and methods.I. INTRODUCTIONMost engineering designs can be viewed as systems,i.e., as collections of several components whose combinedoperation provides useful services. Components can beheterogeneous in nature and their interaction may be regulated by some simple or complex means. Most examplesof systems today are either electronic in nature e.g.,information processing systems or contain an electronicsubsystem for monitoring and control e.g., plant control.Manuscript received February 1, 1996 revised December 2, 1996. Thiswork was supported in part by DARPA, under Contract DABT 6395C0049, and in part by NSF CAREER Award MIP 9501615.G. De Micheli is with the Computer Systems Laboratory, StanfordUniversity, Stanford, CA 94305 USA email nannigalileo.stanford.edu.R. K. Gupta is with the Department of Computer Science, Universityof California, Irvine, CA 92797 USA email rguptaics.uci.edu.Publisher Item Identifier S 0018921997020173.Moreover, the implementation of electronic systems andsubsystems shows often a predominant digital component.We focus in this paper on the digital component ofelectronic systems, and refer to them as digital systems forbrevity. The majority of such systems are programmable,and thus consist of hardware and software components. Thevalue of a system can be measured by some objectives thatare specific to its application domain e.g., performance,design, and manufacturing cost, and ease of programmability and it depends on both the hardware and the softwarecomponents. Hardwaresoftware codesign means meetingsystemlevel objectives by exploiting the synergism ofhardware and software through their concurrent design.Since digital systems have different organizations and applications, there are several codesign problems of interest.Such problems have been tackled by skillful designersfor many years, but detailedlevel design performed byhumans is often a timeconsuming and errorprone task.Moreover, the large amount of information involved in codesign problems makes it unlikely that human designerscan optimize all objectives, thus leading to products whosevalue is lower than the potential one.The recent rise in interest in hardwaresoftware codesign is due to the introduction of computeraided designCAD tools for codesign e.g., commercial simulatorsand to the expectation that solutions to other codesignproblems will be supported by tools, thus raising thepotential quality and shortening the development time ofelectronic products. Due to the extreme competitivenessin the marketplace, codesign tools are likely to play akey strategic role. The forecast of the worldwide revenuesof integrated circuit sales Fig. 1, and in particular forthose used in dedicated applications Fig. 2, explains thehigh demand of electronic systemlevel design tools, whosevolume of sales is expected to grow at a compound annualrate of 34 in the 19931998 time frame, according toDataquest.The evolution of integrated circuit technology is alsomotivating new approaches to digital circuit design. Thetrend toward smaller masklevel geometries leads to higherintegration and higher cost of fabrication, hence to the need001892199710.00  1997 IEEEPROCEEDINGS OF THE IEEE, VOL. 85, NO. 3, MARCH 1997 349Fig. 1. Forecast of the growth of electronic components. SourceDataquest.Fig. 2. Worldwide revenues for the sales of microcontrollers andDSP integrated circuits. The bold line shows the total growth.Source ICE.of amortizing hardware design over large production volumes. This suggests the idea of using software as a meansof differentiating products based on the same hardware platform. Due to the complexity of hardware and software, theirreuse is often key to commercial profitability. Thus complexmacrocells implementing instructionset processors ISPsare now made available as processor cores Fig. 3 38.Standardizing on the use of cores or of specific processorsmeans leveraging available software layers, ranging fromoperating systems to embedded software for userorientedapplications. As a result, an increasingly larger amountof software is found on semiconductor chips, which areoften referred to as systems on silicon. Thus hardware e.g.,cores and software e.g., microkernels can be viewed ascommodities with large intellectual property values. Todayboth the electronic market expansion and the design ofincreasingly complex systems is boosted by the availabilityof these commodities and their reuse as system buildingblocks.The recent introduction of fieldprogrammable gate arrayFPGA technologies has blurred the distinction betweenhardware and software. Traditionally a hardware circuitused to be configured at manufacturing time. The functionsof a hardware circuit could be chosen by the executionof a program. Whereas the program could be modifiedeven at runtime, the structure of the hardware was invariant. With fieldprogrammable technology it is possibleto configure the gatelevel interconnection of hardwarecircuits after manufacturing. This flexibility opens newapplications of digital circuits, and new hardwaresoftwarecodesign problems arise. For example, one or moreFPGA circuits may be configured onthefly to implementa specific software function with better performances thanexecuting the corresponding code on a microprocessor.Subsequently, the FPGA can be reprogrammed to performanother specific function without changing the underlyinghardware. Thus from a user perspective, a reprogrammablehardware board can perform a function indistinguishablefrom that of a processor. Nevertheless the programmingmechanisms and the programmers view of the hardwareis very different.Hardwaresoftware codesign is a complex discipline, thatbuilds upon advances in several areas such as softwarecompilation, computer architecture and very large scaleintegration VLSI circuit design. Codesign is perceived asan important problem, but the field is fragmented becausemost efforts are applied to specific design problems. Thuscodesign has a different flavor according to the context inwhich it is applied. For example, codesign can be seen as amanagement discipline to achieve complex system products15.It is the purpose of this special issue to shed somelight on the recent developments of codesign in differentapplication domains. In this paper, we want to put severalcodesign problem in perspective, to show differences andsimilarities, as well as to show the cross fertilization indifferent scientific fields. For this reason, we describe firstdistinguishing features of electronic systems that are usefulto classify codesign problems. We consider next systemlevel codesign issues for different kinds of electronicsystems and components. Eventually, we review the fundamental algorithmic approaches for systemlevel designand organization of hardwaresoftware systems, that formthe foundations for systemlevel design tools.II. DISTINGUISHING FEATURES OF ELECTRONIC SYSTEMSWe associate codesign problems with the classes ofdigital systems they arise from. We attempt to characterizethese systems using some general criteria, such as domainof application, degree of programmability, and implementation features.A. Application DomainsA digital system may be providing a service as a selfcontained unit, or as a part of a larger system. A traditionalcomputer with its peripherals is an example of the firstkind of systems. A digital control system for a manufacturing plant is an example of the latter case. Systems thatfall in this second category are commonly referred to asembedded systems.350 PROCEEDINGS OF THE IEEE, VOL. 85, NO. 3, MARCH 1997Fig. 3. Example of an integrated circuit with programmable cores. The VCP chip has twoprocessors the VC core, which is based on the MIPSX processor, is placed in the top rightcorner, while the VP DSP processor occupies the top left part of chip above a memory array.Courtesy of Integrated Information Technology.The term embedded means being part of a larger unitand providing a dedicated service to that unit. Thus apersonal computer can be made the embedded controlsystem for manufacturing in an assembly line, by providingdedicated software programs and appropriate interfaces tothe assembly line environment. Similarly, a microprocessorcan be dedicated to a control function in a computere.g., keyboardmouse input control and be viewed as anembedded controller.Digital systems can be classified according to their principal domain of application. Examples of selfcontainedi.e., nonembedded digital systems are information processing systems, ranging from laptop computers to supercomputers, as well as emulation and prototyping systems.Applications of embedded systems are ubiquitous in themanufacturing industry e.g., plant and robot control, inconsumer products e.g., intelligent home devices, in vehicles e.g., control and maintenance of cars, planes, ships,in telecommunication applications, and in territorial andenvironmental defense systems.Digital systems can be geographically distributed e.g.,telephone network, locally distributed e.g., aircraft controlwith different processing units on a local area network, orlumped e.g., workstations. In this paper, we consider asystem to be lumped when it is concentrated in a physicalunit, although it may involve more than one processing unit.DE MICHELI AND GUPTA HARDWARESOFTWARE CODESIGN 351Fig. 4. Some application domains of electronic systems.B. Degree of ProgrammabilityIn most digital systems, the hardware is programmed bysome software programs to perform the desired functions.Nonprogrammable hardwired systems are few and notrelevant to this survey. Hence the abstraction level used forprogramming models is the means of interaction betweenhardware and software. There are two important issuesrelated to programming 1 who has access to programming the system and 2 the technological levels at whichprogramming is performed.1 Access to Programming To understand the extent towhich system programmability has an effect on systemdesign, we distinguish endusers from application developers, system integrators, and component manufacturers.Historically, each of these groups represents a separateindustry or a separate organization. The application developer requires systems to be retargetable so as to port agiven application across multiple hardware platforms. Thechief use of system programmability for a system integratoris in ensuring compatibility of system components withmarket standards. Finally, the component manufacturer isconcerned with maximizing component or module reuseacross its product lines.Let us take the personal computer as an example. Theenduser programming is often limited to applicationlevelprogramming such as a spreadsheet or scripting. Anapplication developer relies on the programming languagetools, operating system, and the highlevel programmingenvironment for application development. Most of theseingredients have, to a large extent, become offtheshelfcommodity products for the personal computer industry,bringing programming closer to the enduser as well. Component manufacturing for personal computers is drivenby interconnection bus and protocol standards. Increasingsemiconductor densities have resulted in coalescing systemcomponents, even with very diverse functionalities, ontosingle chips, leading to fewer but more versatile systemhardware components.When considering embedded systems, the enduser haslimited access to programming because most software isalready provided by the system integrator, who is often alsothe application developer. For example, the motioncontrolsystem of a robot arm for use in manufacturing containsembedded software for coordinating the movement of thedifferent mechanical parts. The user can program only themoves and the actions.2 Levels of Programming Digital systems can be programmed at different levels, namely the application, instruction, or hardware levels. The highest abstraction levelis the application level, where the system is running dedicated software programs that allow the user to specifydesired functionality options using a specialized language.Examples range from programming a videocassette recorderVCR to setting navigation instructions in an automatedsteering controller of a ship.Most digital systems use components with an instructionset architecture ISA. Examples of such components aremicroprocessors, microcontrollers, and programmable digital signal processors DSPs. The instruction set definesthe boundary between hardware and software, by providinga programming model of the hardware. Instructionlevelprogramming is achieved by executing on the hardware theinstructions supported by the architecture. It is importantto note that in some systems the enduser can compileprograms to execute on the ISA, as in the case of computers.In other systems, such as in some embedded systems, theISA is not visible to the user because it runs embeddedsoftware. In the former case, the compiler must have userfriendly features e.g., descriptive diagnostic messages andadequate speed of compilation, while in the latter case thecompiler algorithms can afford to be more computationallyexpensive in the interest of a better final result 74 i.e.,more compact machine code.Hardwarelevel programming means configuring thehardware after manufacturing in a desired way. Asimple and wellknown example is microprogramming,i.e., determining the behavior of the control unit by amicroprogram, which can be stored in binary form in amemory. Emulation of other architectures can be achievedby altering the microprogram. Today microprogrammingis common for DSPs, but not for general purposemicroprocessors using RISC architectures 52 mainly dueto performance reasons.Reconfigurable circuits are the limiting case of hardwarelevel programming. Fieldprogrammable technology allowsus to configure the interconnections among logic blocksand to determine their personality. Reconfiguration can beglobal or local i.e., the entire circuit or a portion thereof can352 PROCEEDINGS OF THE IEEE, VOL. 85, NO. 3, MARCH 1997be altered, and may be applied more than once. Whereasmicroprogramming allows us to reconfigure the controlunit, reconfigurable systems can be modified in both thedata path and controller. Moreover, such circuits need notto be partitioned into data path and control unit, but theycan be organized with wide freedom.Overall, reconfigurabilty increases the usability of a digital system, but it does not increase its performancesexcept on tailored applications. For generalpurpose computing, top performance is achieved today by superscalarRISC architectures 52, which are programmed at theinstruction level. For dedicated applications, hardwirednonprogrammable applicationspecific integrated circuitsASICs achieve often the best performance and the lowestpower consumption. In both cases, hardware design maybe expensive, because of nonrecurrent engineering NREcosts, and not flexible enough to accommodate engineeringchanges and upgrades. Thus the challenge for reconfigurable design technologies is to arrive at a competitive levelof performance, while exploiting the hardware flexibilityin addressing other important systemlevel issues, suchas support for engineering changes, selfadaptation to theenvironment, and faulttolerance.C. Implementation FeaturesSystem implementation deals with circuit design style,manufacturing technology and integration level. We touchbriefly on these issues, because we want to maintain a highlevel view of the problem which is fairly independent ofthe physical implementation.Digital systems rely on VLSI circuit technology. The circuit design style relates to the selection of circuit primitivese.g., choice of library in a semicustom technology, clocking strategy e.g., singlemultiple clocks and asynchronous,and circuit operation mode e.g., static and dynamic.A system may have components with different scaleof integration e.g., discrete and integrated componentand different fabrication technologies e.g., bipolar andCMOS. The choice of hardware technology for the systemcomponents affects the overall performance and cost, andtherefore is of primary importance.Systemlevel field programmability can be achieved bystoring programs in readwrite memories andor exploitingprogrammable interconnections. In the former case, thesoftware component is programmed, while in the latterthe hardware is configured. With fieldprogrammable technologies, circuit configuration is achieved by programmingconnections using transistors driven by memory arrays110 or by antifuses 44. Circuits of the first type arereprogrammable and will be considered in this survey,while the others can be programmed only once.When considering codesign problems for lumpedsystems, we can distinguish between systems consistingof components like ASICs, processors, and memoriesmounted on a board or chip carrier and singlechip systemsconsisting of an ASIC with one or more processor coresandor memories. The programmable core is usuallya processor provided as a macrocell in the ASICFig. 5. Scheme of the essential parts of an embedded controlsystem with one or more ISPs.implementation technology 38, Fig. 3. Whereas a coremay provide the same functionality as the correspondingstandard part, cost and performance considerations may biasthe choice of integration level. The advantages of higherintegration are usually higher reliability, lower powerconsumption budget, and increased performance. The lasttwo factors come from the lack of IO circuitry in thecore and its direct connection to the applicationspecificlogic. The disadvantages are larger chip sizes and highercomplexity in debugging the system.III. GENERAL CODESIGN PROBLEMSAND DESIGN APPROACHESWe consider now different facets of codesign. Namely,we present first the major objectives in embedded systemdesign. We describe next the design of ISAs and their usein both selfcontained information processing systems andembedded systems. Last but not least, we address the majorcodesign issues for reconfigurable systems.A. CoDesign of Embedded SystemsEmbedded systems are elements of larger systems.Some embedded systems provide monitoring and control functions for the overall system e.g., vehicularcontrol, manufacturing control, while others performinformationprocessing functions within a network e.g.,telecommunication systems.Embedded control systems usually regulate mechanicalcomponents via actuators and receive input data provided by sensors. Singlechip implementation of embeddedcontrollers often integrate on the same chip analog todigital conversion and vice versa of some IO signals andsometimes the sensors themselves e.g., accelerometer forairbag control. Often embedded control systems have alsoa dataprocessing component Fig. 5.DE MICHELI AND GUPTA HARDWARESOFTWARE CODESIGN 353Control systems are reactive systems, because they aremeant to react to stimuli provided by the environment. Realtime control systems 99 implement functions that mustexecute within predefined time windows, i.e., satisfy somehard or soft timing constraint 117, 118. Timers are thusimportant components of realtime controllers.The required functions and size of embedded controllersmay vary widely. Standard programmable microcontrollersand microcontroller cores provide usually lowcost andflexible solutions to a wide range of problems. Nevertheless, control systems that are either complex e.g., avioniccontrols or that require highthroughput data processinge.g., radio navigation need specific designs that leveragecomponents or cores such as microprocessors or DSPs.Whereas performance is the most important design criterion for information processing systems, reliability, availability, and safety are extremely important for controlsystems. System reliability measures the probability ofcorrect control operation even in presence of failures ofsome component, whereas availability contemplates theonline repair of faulty components. Safety measures theprobability of avoiding catastrophic failures. For example,the availability of a nuclear steam supply system is theprobability as a function of time that a nuclear reactorcan produce energy under a scheduled maintenance, whileits safety is the probability that the system has no failureleading to a hazardous situation for the operators and theenvironment.Since control functions can be implemented both inhardware and in software, specific design disciplines mustbe used to insure reliability, availability, and safety. Someformal verification techniques for embedded controllersare nowadays available to insure design correctness bycomparing different representation levels and assessingsystem properties. Systemlevel testing techniques must beused to check the correctness of operation of the physicalsystem implementation. Functional redundancy may beused to enhance reliability.Specific codesign problems for embedded systemsinclude modeling, validation, and implementation. Thesetasks may be complex because the system function maybe performed by different components of heterogeneousnature, and because the implementation that optimizes thedesign objectives may require a specific hardwaresoftwarepartition. The design of embedded control systems issurveyed in 36.Embedded systems for telecommunication applicationsinvolve data processing, where data can be a digital formof audio and video information. Data compression, decompression, and routing is often performed with the aidof programmable processors of various kinds. Codesignissues in this domain are described in 17, 43, and 88.B. CoDesign of ISAsThe concept of ISA plays a fundamental role in digitalsystem design 52. An ISA provides a programmers viewof hardware by supporting a specific programming model.The definition of an instruction set permits the paralleldevelopment of the hardware and of the correspondingcompiler. Components based on ISAs, i.e., e.g., microprocessors, DSPs, and programmable microcontrollersare commonly used in selfcontained information processing systems and in embedded systems. Therefore agood ISA design is critical to achieving system usabilityacross applications. In addition, increasing applicationsnow demand processor performance that pushes the limitsof semiconductor technology. Performance critical designof processors requires combined design of hardware andsoftware elements.The primary goal of codesign in ISP development isto optimize utilization of the underlying hardware. Thisis done by customizing the software development ranging from application programs to operating systems. Theoperating system is the software layer closest to the underlying hardware, and its role is different in computingand embedded systems see Section IVB3 The extent ofthe operating system layer in embedded systems variesfrom specialized realtime kernels 99 to lightweight runtime schedulers 45, according to the design goals andrequirements.Compiler development should start as early as ISA definition. Indeed, compilers are needed for the evaluation of theinstructionset choices and overall processor organization,in order to verify whether the overall performance goalsare met 53. Whereas retargetable compilers are usefulin the architectural development phase, optimizing compilers are key to achieving fastrunning code on the finalproducts. In addition, speed of compilation is importantfor information processing applications e.g., computers,where the enduser programs the system at the instructionlevel i.e., via programs in programming languages. Sucha requirement is less important for applications of ISAswithin embedded systems, where the user has limited accessto programmability, as mentioned in Section IIB.The organization of modern generalpurpose processorsexploits deep pipelines, concurrency, and memory hierarchies. Hardwaresoftware tradeoff is possible in pipelinecontrol 57 and cachemanagement mechanisms 53. Theselection of an instruction set is usually guided by performance and compatibility goals. This task is generally basedon experience and on the evaluation of software simulationruns, although recent efforts have aimed at developing toolsfor computerassisted instruction set selection 55.Let us now consider the use of components based onISAs for embedded dataprocessing systems. Such systems often use dedicated software programs with specific instruction profiles. Therefore significant performanceimprovements may be achieved by selecting particularinstruction sets which match the application requirements.In some application domains, such as data processing fortelecommunications see Fig. 4, it has been shown practical to replace standard processors by applicationspecificinstruction set processors ASIPs, which are instructionlevel programmable processors with an architecture tunedto a specific application 43, 88. In an ASIP design, theinstruction set and hardware structure are chosen to support354 PROCEEDINGS OF THE IEEE, VOL. 85, NO. 3, MARCH 1997efficiently the instruction mix of the embedded software ofthe specific application. For example, ASIPs feature particular register configurations and specific interconnectionsamong the registers, busses, and other hardware resources.It is possible to view ASIPs as intermediate solutionsbetween ISPs and ASICs. ASIPs are more flexible thanASICs, but less than ISPs. Nevertheless, they can beused for a family of applications in a specific domain.The performance of an ASIP on specific tasks can behigher than an instructionset processor because of thetuning of the architecture to the instruction mix but itis usually lower than an ASIC. Opposite considerationsapply to power consumption. The ASIP design time andnonrecurring engineering costs can be amortized over alarger volume than an ASIC, when the ASIP has multipleapplications. Moreover, engineering changes and productupdates can be handled graciously in ASIPs by reprogramming the software and avoiding hardware redesign.Unfortunately, because an ASIP is a specific architecture,it requires a compiler development which adds to thenonrecurring engineering costs. Such a compiler must alsoproduce highquality machine code to make the ASIPsolution competitive. On the other hand, compilation speedis not a major requirement, since most ASIPbased systemprogrammed once only by the manufacturer and not bythe enduser.Differently from generalpurpose and digitalsignal processors, ASIPs may be designed to support fairly differentinstruction sets, because compatibility requirements areless important and supporting specific instruction mixesis a desired goal. Unfortunately the price of the flexibility in choosing instruction sets is the need of developing applicationspecific compilers. Despite the use ofretargetablecompiler technology 79, the computeraideddevelopment of compilers that produce highquality codefor specific architectures is a difficult problem and solvedonly in part to date, namely for fixedpoint arithmetic operations. Problems and solutions in retargetable compilationare addressed by 43 and 88 in this issue.C. CoDesign of Reconfigurable SystemsReconfigurable systems exploit FPGA technology, so thatthey can be personalized after manufacturing to fit a specific application. The operation of reconfigurable systemscan either involve a configuration phase followed by anexecution phase or have concurrent partial configurationand execution. In the latter case, the systems are calledevolvable.We consider first nonevolvable systems and their applications to the acceleration of computation and to prototyping.In both cases, the overall digital systems include a reconfigurable subsystem that emulates the software or the hardwareexecution, and sometimes a combination of both.Let us turn our attention to codesign techniques that canaccelerate software execution. There are often bottlenecksin software programs that limit their performance e.g.,executing transcendental floatingpoint operations or innerloops where sequences of operations are iterated. ASICcoprocessors can reduce the software execution time, whenthey are dedicated to support specific operations e.g.,floatingpoint or graphic coprocessors or when they implement the critical loops in hardware while exploiting thelocal parallelism. Whereas ASIC coprocessors acceleratespecific functions, coprocessors based on reconfigurablehardware can be applied to the speedup of arbitrary software programs with some distinctive characteristics e.g.,programs with parallelizable bitlevel operations.One of the first examples of programmable coprocessorsis provided by the programmable active memories PAMs13, which consist of a board of FPGAs and local memoryinterfaced to a host computer. Two models of PAMs,named PeRLe0 and PeRLe1, were built. They differ inthe number and type of FPGA used, as well as operatingfrequency. The hardware board for PeRLe1 is shown inFig. 6 112.To accelerate the execution of a program with a PAM,the performancecritical portion of the program is firstextracted and compiled into the patterns that configurethe programmable board. Then, the noncritical portion ofthe program is executed on the host, while the criticalportions are emulated by the reconfigurable subsystem.Experimental results show a speedup of one to two orders ofmagnitude, on selective benchmark programs, as comparedto the execution time on the host 13.The major hardwaresoftware codesign problems consistof identifying the critical segments of the software programsand compiling them efficiently to run on the programmablehardware. The former task is not yet automated for PAMsand is achieved by successive refinement, under constraintsof communication bandwidth and load balancing betweenthe host and the programmable hardware. The latter taskis based on hardware synthesis algorithms, and it benefitsfrom performance optimization techniques for hardwarecircuits 13, 30. Several other systems for softwareacceleration have been implemented 7, 86.1A different application of reconfigurable systems is incomputeraided prototyping. In this case, we are interested in validating a target system yet to be manufacturedby configuring and executing a prototype implementedwith a reconfigurable medium. Prototypes provide designengineers with more realistic data on correctness and performance than systemlevel simulation 81, thus reducingthe likelihood of an expensive redesign of the target system.Prototyping of complex digital systems including multiple hardware components and software programs is appealing to designers, because it allows testing softwareprograms on hardware, while retaining the ability to changethe hardware and software implementation concurrently.Once the hardware configuration has been finalized, it canbe mapped onto a hard silicon implementation using synthesis systems 30 that accept as inputs hardware modelscompatible with those used by the emulation systems e.g.,VHDL 91 and Verilog HDL 107 models.1 See URL httpwww.io.comguccioneHWlist.html for a comprehensive list.DE MICHELI AND GUPTA HARDWARESOFTWARE CODESIGN 355Fig. 6. The PeRLe1 implementation. Courtesy of P. Bertin.Evolvable systems 97 are digital systems where reconfiguration of one of its parts is concurrent with execution.One of the goals of evolvable systems is to adapt automatically to the environment. As an example, consider anetwork interface unit, that receives and retransmits datawith different formats. Upon sensing the protocol andformat of the incoming data, such a unit configures itself tooptimize data translation and transmission. Whereas such aunit could be implemented with nonevolvable technology,the ability to reconfigure the hardware may be the key tosustain higher data rates.Fault tolerance in evolvable systems can be obtained bydetecting the malfunctioning unit, and by reconfiguring apart of the system to regenerate a faultfree replacementof the faulty unit. This can be achieved under severalassumptions, some of which are typical of faulttolerantsystem design, including that of having enough spare reconfigurable circuits to implement the faulty unit onthefly.Evolvable systems are the subject of several researchefforts 97. An interesting application of reconfigurablehardware for faulttolerance applications is embryonicsembryological electronics 28, 78, a discipline wherebiological models of organization are used for electronicsystem design. There are a few implementations of embryonic systems, relying on this general implementationstrategy 78. The underlying hardware is a memorybasedfieldprogrammable circuit that uses a decision diagramstructure. The hardware is organized as a rectangular matrixof cells, each one addressable by its coordinates and communicating with its neighbors. The overall system functionis mapped onto the programmable cells. Circuit configuration is performed by feeding each cell with a compiledsoftware program bit stream containing the functionalityof the entire system. This parallels the organization ofmulticellular living beings, where the genome of each cellis a repository of information of the entire being. Theprogram is transmitted from an initial cell to the others.Then each cell extracts the portion of the overall programpertinent to its operation using the coordinate informationand configures itself. This parallels the synthesis of a livingcell from the gene structure.After a boot phase in which the information is transmittedto all cells and the cells selfconfigure, the system can startoperating. Upon failure of a cell in providing the requiredfunction, the neighboring cells readapt their operations sothat the faulty cell is replaced by a working clone, and theoverall system function is preserved. This reconfiguration,called cicatrization, allows the system to recover fromfailures after a finite delay.Interesting applications of embryological circuits includeembedded system applications with high reliability requirements, such as control of unmanned spacecrafts or of robotsoperating in hostile environments. Hardwaresoftware codesign problems relate to how software programs are usedto configure and program the underlying hardware circuit,as well as to how the reconfigurable circuit is organized.356 PROCEEDINGS OF THE IEEE, VOL. 85, NO. 3, MARCH 1997IV. DESIGN OF HARDWARESOFTWARE SYSTEMSWe consider here the highlevel i.e., technology independent steps in the design of hardwaresoftware systems.We consider the problem in its breadth, rather than in itsdepth, to highlight similarities and differences in codesignof digital systems of different nature. We also draw parallelsamong techniques applicable to hardware and softwaree.g., scheduling. We refer the interested reader to the otherarticles in this issue for an indepth analysis applicable todifferent domains.The design of hardwaresoftware systems involves modeling, validation, and implementation. We call modeling theprocess of conceptualizing and refining the specifications,and producing a hardware and software model. We callvalidation the process of achieving a reasonable level ofconfidence that the system will work as designed, and wecall implementation the physical realization of the hardwarethrough synthesis and of executable software throughcompilation.When considering embedded systems, different modelingparadigms and implementation strategies may be followed36. We exclude here pure hardware e.g., ASIC andpure software e.g., embedded software running on an ISAimplementations, because we concentrate on codesign.Therefore, the overall model of an embedded system involves both hardware and software. The modeling stylecan be homogeneous or heterogeneous. In the former case,a modeling language e.g., the C programming languageor a graphical formalism e.g., Statecharts 51 is usedto represent both the hardware and software portions. Ahardwaresoftware partitioning problem can then be statedas finding those parts of the model best implemented inhardware and those best implemented in software. Partitioning can be decided by the designer, with a successiverefinement and annotation of the initial model, or determined by a CAD tool. We will consider computeraidedpartitioning in more detail in Section IVA.When using a heterogeneous modeling style, the hardwaresoftware partition is often outlined by the modelitself, because hardware and software components maybe expressed in the corresponding languages. Nevertheless, system designers may want to explore alternativeimplementations of some components. For example, thefirst release of a product may contain a sizable softwarecomponent for time to market and flexibility reasonswhile later releases may implement part of this softwarein hardware for performance andor cost reasons. Toolswhich support implementation retargeting help the designeravoiding manual translation of the models or parts thereof.A few CAD environments for heterogeneous design andretargeting have been realized 8, 24, 26, 29, 64,114.ISAs are modeled at different levels. Instruction setsprovide the essential information about the architecture,supporting both hardware and software development. Theprocessor organization is usually described in a hardwaredescription language HDL for hardware synthesis purposes, while processor models e.g., bus functional modelsare often used for cosimulation.In the case of reconfigurable systems, we need to distinguish between modeling the target application and modelingthe host. The first task is pertinent to the system user, whilethe second to its developer. Thus, these two modeling tasksare very different aspects of codesign.As systems become more complex, validation is necessary to insure that correct functionality and requiredperformance levels are achieved in the implementationof a system model. Moreover, validation takes differentflavors according to the systems application domain. Forexample, satisfaction of performance objectives in additionto correctness is extremely important in processor design.Performance validation is often based on cosimulation ofhardware and software 53. On the other hand, embeddedcontrollers may have less stringent performance requirements to be validated, but their correctness of operationmust be verified under all possible environmental conditions, to insure overall system safety levels 36.The implementation of a hardwaresoftware system mayinvolve several subtasks, the major being hardware synthesis and software compilation. Both topics are complexand several references describe them in depth 2, 30.We review in Sections IVAB techniques affecting themacroscopic system implementation characteristics, and inparticular the boundary between hardware and software.Namely, we focus our attention on 1 partitioning andallocation of system functions to hardware and software and2 scheduling hardware operations, program instructionsand software processes. These two topics address where andwhen the system functions are implemented respectively.A. HardwareSoftware PartitioningThe partition of a system into hardware and software isof critical importance because it has a first order impacton the costperformance characteristics of the final design.Therefore any partitioning decision, performed either bya designer or by a CAD tool, must take into account theproperties of the resulting hardware and software blocks.The formulation of the hardwaresoftware partitioningproblem differs according to the codesign problem beingconfronted with. In the case of embedded systems, ahardwaresoftware partition represents a physical partitionof system functionality into applicationspecific hardwareand software executing on one or more processors.Various formulations to this partitioning problem can becompared on the basis of the architectural assumptions,partitioning goals and solution strategy. We consider eachof these issues in detail in the next subsections.When considering general purpose computing systems,a partition represents a logical division of system functionality, where the underlying hardware is designed tosupport the software implementation of the complete systemfunctionality. This division is elegantly captured by theinstruction set. Thus instruction selection strongly affectsthe system hardwaresoftware organization.DE MICHELI AND GUPTA HARDWARESOFTWARE CODESIGN 357In the case of reconfigurable systems, the flavor ofthe partitioning problem depends on the available primitives. For systems consisting of arrays of FPGA chipsonly, partitioning the system function into the componentscorresponds to performing technology mapping 16. Onthe other hand, for systems consisting of processors andFPGA components, partitioning involves both a physicalpartition of system functionality as in the case of embeddedsystems and mapping.1 Architectural Assumptions Since usually embeddedsystems are implemented by processors and applicationspecific hardware, the most common architecture in thesesystems can be characterized as one of coprocessing, i.e., aprocessor working in conjunction with dedicated hardwareto deliver a specific application. The particular implementation of the coprocessing architecture varies in the degreeof parallelism supported between hardware and softwarecomponents. For instance, the coprocessing hardware maybe operated under direct control of the processor, whichstalls while the dedicated hardware is operational 37, orthe coprocessing may be done concurrently with softwareexecution 47. Similarly, the choice of one or more thanone processors for the target architecture strongly affectsthe partitioning formulation 11. As an example 77,an evaluation of possible coprocessing architectures fora threedimensional 3D computer graphics applicationleads to an architecture where a processor controlsthe applicationspecific coprocessor which maintains itsindependent data storage. The reported speedup variesfrom 1.32 to 2.0 across different benchmarks.The hardwaresoftware interface defines another architectural variable that strongly affects the partitioning problemformulation. It is common to assume that communicationoperations are conducted using memorymapped IO bythe processor 26, 49. However, memorymapped IOis often an inefficient mechanism for data transfer 63.More efficient methods, including dedicated device drivers,have been considered for coprocessing architectures 21,but their relation to partitioning has not been articulatedyet. Yen and Wolf 119 developed analysis and synthesismethods of busoriented communication schemes amongprocessing elements. Other researchers 84 use explicitscheduling of the communication operations in the partitioning loop to improve the quality of the resulting partitionin terms its ability to satisfy external timing constraints.2 Partitioning Objectives Coprocessing architecturesare often chosen to improve the system performance inexecuting specific algorithms 5, 34. Accordingly, insome approaches partitioning seeks to maximize the overallspeedup for a given application 13, 37, 63, 108. Thespeedup estimation is almost always done by a profilinganalysis that takes into account typical data sets overwhich the application behavior is estimated. Due to thisdata dependence, in some application areas the overallspeedup may not be a welldefined metric. Furthermore, insome applications and particularly in those with realtimeresponse requirements, it may not be a useful metric either.In such cases, metrics such as size of implementationand timing constraint satisfaction are used to drive thepartitioning subtask. For instance, partitioning is used toimprove the hardware utilization by pipelining multiplefunctions 14.Constrained partitioning formulations often use capacityconstraints, such as size of individual hardware or softwareportions, to generate a physical division of functionalitysuch that each block can be implemented in a single component. This capacityconstrained partitioning formulation iscommonly used in system prototyping applications, wherean application is mapped onto multiple FPGA componentsby a partitioning method 16.Performanceconstrained partitioning formulations focuseither on global constraints such as overall latency 65, oron the satisfaction of local timing constraints between operations 45. In this case the partitioning goal is to reducesystem cost by migrating part of the system functionality tosoftware, thus reducing the applicationspecific hardware toimplement, while satisfying the performance requirements.3 Partitioning Strategies A common misconception inpartitioning formulations is that automated methods arethe only viable approach to solving partitioning problems when using CAD tools. Often a determination ofhardware versus software implementation of a specificfunctionality is done at levels of abstraction that are noteven modeled in system specifications. In the absenceof requisite modeling capability, the system partitioningsimply can not be carried out using automated tools. Thusthere exists a strong relationship between the models usedfor capturing system functionality and the abstraction levelat which the partitioning is carried out. Even when itis possible to create a detailed mathematical model ofthe partitioning problem, the complexity of the resultingformulation renders it useless for conventional algorithmicmethods. Thus we will consider in this section both heuristic approaches and a problem decomposition strategy tohandle the complexity of the partitioning problem undersome architectural assumptions.Given a specific architecture, partitioning of a systemlevel functional description results in a labeling of itstasks as hardware or software operations. The exact solution of such a partitioning problem, even in the simplestcases, requires a solution to computationally intractableproblems 41. In an attempt to mathematically modelthe variables affecting the partitioning problem, integerprogramming IP and integer linear programming ILPformulations have been proposed recently 11, 42, 84.Comparison of mathematical programming approaches tohardwaresoftware partitioning is difficult, because the quality of results is often strongly affected by the parametricaccuracy of the variables used and by the complexity ofthe costperformance model.Heuristic approaches to partitioning consist primarily oftwo strategies constructive methods such as clusteringtechniques 9, 33 and iterative methods such as networkflow 101, binaryconstraint search 111, and dynamicprogramming 63. By far, the most used methods are basedon variabledepth search methods such as variants of the358 PROCEEDINGS OF THE IEEE, VOL. 85, NO. 3, MARCH 1997KernighanLin KL migration heuristics, or probabilistichillclimbing methods such as simulatedannealing or genetic algorithms. Ernst et al. 37 used profiling resultson a Clike description to estimate the potential speedupin extracting blocks of code for hardware implementation.The actual selection of code blocks for hardware is done bya simulated annealing algorithm that is used to maximizeoverall speedup. Reported results indicate speedup of upto a factor of three on a chromakey algorithm for HDTV37. Design space search methods, such as using KLsalgorithm, are often used following a constructive initialsolution to arrive at a feasible solution that meets imposedcostperformance constraints. Reference 45 presents aKLbased algorithm that is used to drive the partitiontoward meeting timing constraints. Vahid et al. 111 usea combination of clustering followed by binaryconstraintsearch that dynamically adjusts the optimization functionbalance between performance and hardware size as thealgorithm progresses to minimize size of hardware whilemeeting constraints. Another similar approach 65 usesa composite objective function taking time criticality andlocal affinity into account to drive the partition. The resultsare shown to be qualitatively close to optimal while takingmuch less computing time.Let us now examine what makes the problem of partitioning hard. The partitioning and synthesis subtasks areclosely interrelated. The cost function of a partitioningproblem needs to be evaluated using estimates of theresulting hardware and software. However, the abstraction level at which partitioning is carried out is so highthat only rough estimates are available. As an example,consider a hardwaresoftware partitioning problem whoseobjective is to maximize the application speedup under aconstraint on the hardware size. The results of operationscheduling can be used to better estimate the effect ofpartitioning on the overall latency, and more importantly onthe communication cost. This information can be used toselect operations for partitioning that results in maximumoverall speedup. On the other hand, partitioning a set ofscheduled tasks would sacrifice the flexibility of optimizingthe communication cost. This dilemma is addressed directly84 using an integer programming formulation for thepartitioning problem that uses an approximate schedule ofoperations. Solution to this IP programming is followed bya solution to the IP formulation of the scheduling problemthat updates the schedule.The above solution points to a problem decompositionstrategy that is a straightforward extension of the decoupling of scheduling and binding in highlevel synthesis 30.In principle, task partitioning, scheduling, and binding toresources should be performed concurrently. Nevertheless,most practical approaches serialize these tasks, while somesuggested interactive and iterative approached to partitioning and synthesis 62, 68.Let us consider first the case where scheduling is followed by concurrent bindingpartitioning subtasks. An example of this approach targets pipelined ASIPs 14. Partitioning is done simultaneously with binding, and the clockcycle constraint of partitioning is derived from pipelinescheduling done prior to partitioning. This approach workswell in cases where the objective of partitioning is tominimize hardware resource requirements. A scheduledinput identifies the temporally mutually exclusive operations that can be implemented on a common resource.The partitioner can use the schedule information to divideoperations into compatible groups such that binding subtaskis able to maximize resource utilization. Such designs aretypically resource dominated, therefore, an optimal resourceutilization results in reduction of overall size.The approach of applying partitioning prior to schedulingbinding is fairly common. A difficulty with thisapproach is the loss of parametric accuracy and controllability of the final result since the partitioning decisions aremade early on. As a result most methods in this categoryeither rely on extensive profiling or preprocessing of theinput in order to make intelligent decisions about the hardware versus software implementations. Eles 35 presentsa twostage partitioning approach where a prepartitioningof VHDL input is followed by a detailed partitioningusing simulated annealing. Constructive methods are quitepopular to derive initial hardwaresoftware grouping. Forinstance, different forms of clustering methods based onsimilarity measures 9 or closeness criteria 4, 8 are usedto group together operations into hardware and softwareparts.In addition to handling the strong relationship betweendifferent implementation subtasks, a partitioning problemformulation faces the classical dilemma of having to choosebetween accurate performancecost measures on partitionresults versus the efficiency of the partitioning algorithmthat determines the extent of design space search. Whilegood estimation methods for hardware performance andsize exist, the software component is generally characterized by a significant variability in performance parametersprimarily due to architectural features such as caches and avery strong dependence of delay on the input data values.Recent research effort in this direction has been directedat accurate modeling of software delay using analysis ofcontrol paths 72, 87, 93, and program annotations82. Architectural modeling for software uses pipelining120, instruction caches 73 and busactivity using DMA60. These continuing efforts have successfully improvedthe estimation accuracy to be within 50100 of theactual worstcase delay. The need for timing predictabilitycontinues to adversely affect the design of tightly constrained systems to such an extent that many systems usedistressingly simple architectures such as turning off cachememories, thus rarely exploiting the peak performance ofthe underlying hardware in real applications.B. SchedulingThe scheduling problem has many facets. Schedulingalgorithms have been developed in both the operationresearch and computer science community, with differentmodels and objectives. The techniques that are applicableDE MICHELI AND GUPTA HARDWARESOFTWARE CODESIGN 359today to the design of hardware and software systems drawideas from both communities.Generally speaking, hardware and software schedulingproblems differ not just in the formulation but in theiroverall goals. Nevertheless, some hardware scheduling algorithms are based on techniques used in the softwaredomain, and some recent systemlevel process scheduling methods have leveraged ideas in hardware sequencing.Scheduling can be loosely defined as assigning an execution start time to each task in a set, where tasks arelinked by some relations e.g., dependencies, priorities, .The tasks can be elementary like hardware operations orcomputer instructions or can be an ensemble of elementaryoperations like software programs. When confusion mayarise, we will refer to tasks as operations in the former case,and to processes in the latter. The tasks can be periodicor aperiodic, and task execution may be subject to realtime constraints or not. Scheduling under timing constraintsis common for hardware circuits, and for software applications in embedded control systems. Tasks executionrequires the use of resources, which can be limited in number, thus causing the serialization of some task execution.Most scheduling problems are computationally intractable41, and thus their solutions are often based on heuristictechniques.We consider next scheduling algorithms as applied to thedesign of hardware, compilers, and operating systems.1 Operation Scheduling in Hardware We consider nowthe major approaches to hardware scheduling. These techniques have been implemented to different extent in CADtools for the design of ASICs and DSPs 32, 66, 85,106, which are modeled with a behaviorallevel HDLe.g., VHDL, Verilog HDL, and DFL 115. The behavioral model can be abstracted as a set of operations anddependencies. The hardware implementation is assumedto be synchronous, with a given cycletime. Operationsare assumed to take a known, integer number of cyclesto execute. We will consider removing this assumptionlater. The result of scheduling, i.e., the set of start timesof the operations, is just a set of integers. The usual goalis to minimize the overall execution latency, i.e., the timerequired to execute all operations.Constraints on scheduling usually relate to the numberof resources available to implement each operation andto upperlower bounds on the time distance between starttimes of operation pairs. Usually, the presence of resourceconstraints makes the problem intractable 30, 41.The scheduling problem can be cast as an integer linearprogram 30, 42, 50, where binaryvalued variablesdetermine the assignment of a start time to each operation.Linear constraints require each operation to start once,to satisfy the precedence and the resource constraints.Latency can also be expressed as a linear combination ofthe decision variables. The scheduling problem has a dualformulation, where latency is bounded from above and theobjective function relates to minimizing the resource usage,which can also be expressed as a linear function. Timingand other constraints can be easily incorporated in the ILPmodel 42.The appeal of using the ILP model is due to the uniformformulation even in presence of different constraints andto the possibility of using standard solution packages. Itslimitation is due to the prohibitive computational cost formediumlarge cases. This relegates the ILP formulationto specific cases, where an exact solution is required andwhere the problem size makes the ILP solution viable.Most practical implementations of hardware schedulersrely on list scheduling, which is a heuristic approachthat yields good but not necessarily optimal schedulesin linear or overlinear time. A list scheduler considersthe time slots one at a time, and schedules to each slotthose operations whose predecessors have been scheduled,if enough resources are available. Otherwise the operationexecution is deferred. Ties are broken using a priority list,hence the name.Another heuristic for scheduling is forcedirected scheduling 89, which addresses the latencyconstrained scheduling problem. Here, operations are scheduled into the timeslots one at a time, subject to timewindow constraintsinduced by precedence and latency constraints. Ties amongdifferent time slots for each operation are broken using aheuristic based on the concept of force, which measuresthe tendency of the operation to be in a given slot, tominimize overall concurrency. The computational cost offorcedirected scheduling is quadratic in the number ofoperations.When resource constraints are relaxed, the schedulingproblem can sometimes be solved in polynomial time. Forexample, scheduling with timing constraints on operationtime separation can be cast as a longestpath problem 30.On the other hand, scheduling under release times anddeadlines is intractable, unless the operations take a singlecycle to execute 41.There are several generalizations of the scheduling problem. In some cases, operations are not restricted to takean integral number of cycles to execute, and more thanone operation can be chained into a single time slot.Pipelined circuits require specific constraints on data rates,and additional resource conflicts have to be taken intoaccount due to the concurrent execution of operations in different pipestages. Periodic operation subsets, e.g., iterationconstruct bodies, may be advantageously scheduled usingloop pipelining techniques 30, which is an example of amethod borrowed from software compilers 116. Chainingand pipelining can be incorporated in ILP, list, and forcedirected schedulers.The synchronization of two or more operations orprocesses is an important issue related to scheduling. Synchronization is needed when some delay is unknown inthe model. Relative scheduling is an extended schedulingmethod to cope with operations with unbounded delays 67called anchors. In this case, a static schedule cannot bedetermined. Nevertheless, in relative scheduling the operations are scheduled with respect to their anchor ancestors.A finitestate machine can be derived that executes the360 PROCEEDINGS OF THE IEEE, VOL. 85, NO. 3, MARCH 1997operations in an appropriate sequence, on the basis ofthe relative schedules and the anchor completion signals.The relative scheduling formulation supports the analysisof timing constraints, and when these are consistent withthe model, the resulting schedule satisfies the constraint forany anchor delay value. Scheduling with templates 70 isa similar approach, where operations are partitioned intotemplates that can be seen as single scheduling units. Thustemplates are useful for hierarchical scheduling and scheduling multicycle resources e.g., pipelined multipliers.2 Instruction Scheduling in Compilers Compilers arecomplex software tools, consisting of a frontend, a suiteof optimization routines operating on an intermediateform, and a backend called also code generation whichgenerates the machine code for the target architecture.In the context of compilation, instruction scheduling ona uniprocessor is the task of obtaining a linear order ofthe instructions. Thus it differs from hardware schedulingbecause the resource constraints typically refer to storageelements e.g., registers and the hardware functionalresource is usually one ALU. In the more general case,scheduling can be viewed as the process of organizinginstructions into streams.Instruction scheduling is related to the choice of instructions, each performing a fragment of the computation,and to register allocation. When considering compilationfor generalpurpose microprocessors, instruction selectionand register allocation are often achieved by dynamic programming algorithms 2, which also generate the order ofthe instructions. When considering retargetable compilersfor ASIPs, the compiler backend is often more complex,because of irregular structures such as inhomogeneousregister sets and connections. As a result, instruction selection, register allocation and scheduling are tightlycoupledphases of code generation 43. In both cases, schedulingobjectives are reducing the code size which correlates withthe latency of execution time and minimizing spills, i.e.,overflows of the register file which require memory access.Optimizing compiler algorithms for ASIPs and generalpurpose DSPs has been a subject of recent research activities 79. Instruction selection, instruction scheduling,and register spilling problems for ASIPs are addressed byLiao et al. 71. The same group formulates the instructionselection problem as a binate covering problem, that issolved using a branchandbound algorithm 74. Scheduling has been modeled by resource and instruction setconflicts and solved by bipartite matching algorithms 109.Araujo et al. 6 considered code generation for basic blocksin heterogeneous memoryregister DSP processors and usedregistertransfer paths to convert basic block graphs intoexpression trees which are used in code generation.The codesign of deeply pipelined microprocessors canleverage the coupling between instruction scheduling andhardware organization. Pipeline hazard avoidance can beachieved by hardware means e.g., stall or by softwaremeans e.g., instruction reorder and NOP insertion. Recentresearch 57 has addressed the problem of the concurrent synthesis of the pipeline control hardware and thedetermination of an appropriate instruction reorder thatthe corresponding backend compiler should use to avoidhazards. The same group 59 has also proposed a methodology for synthesizing instruction sets from applicationbenchmarks.3 Process Scheduling in Different Operating SystemsProcess scheduling is the problem of determining whenprocesses execute and includes handling synchronizationand mutual exclusion problems. Algorithms for processscheduling are important constituents of operating systemsand runtime schedulers 104.The model of the scheduling problem is more general than the one previously considered. Processes have acoarser granularity and their overall execution time maynot be known. Processes may maintain a separate contextthrough local storage and associated control information.Scheduling objectives may also vary. In a multitaskingoperating system, scheduling primarily addresses increasing processor utilization and reducing response time. Onthe other hand, scheduling in realtime operating systemsRTOS primarily addresses the satisfaction of timing constraints.We consider first scheduling without realtime constraints. The scheduling objective involves usually avariety of goals, such as maximizing CPU utilization andthroughput as well as minimizing response time. Schedulingalgorithms may be complex, but they are often rooted onsimple procedures such as shortestjob first SJF or roundrobin RR 92. The SJF is a prioritybased algorithm thatschedules processes according to their priorities, where theshorter the process length or, more precisely, its CPU burstlength the higher the priority. This algorithm would givethe minimum average time for a given set of processes, iftheir CPUburst lengths were known exactly. In practice,predictive formulas are used. Processes in a SJF may beallowed to preempt other processes to avoid starvation.The roundrobin scheduling algorithm uses a circularqueue and it schedules the processes around the queue fora time interval up to a predefined quantum. The queueis implemented as a firstinfirstout FIFO queue andnew processes are added at the tail of the queue. Thescheduler pops the queue and sets a timer. If the poppedprocess terminates before the timer, the scheduler pops thequeue again. Otherwise it performs a context switch byinterrupting the process, saving the state, and starting thenext process on the FIFO.Process scheduling in realtime operating system 100is characterized by different goals and algorithms. Schedules may or may not exist that satisfy the given timingconstraints. In general, the primary goal is to schedulethe tasks such that all deadlines are met in case ofsuccess failure a secondary goal is maximizing earlinessminimizing tardiness of task completion. An importantissue is predictability of the scheduler, i.e., the level ofconfidence that the scheduler meets the constraints.The different paradigms for process scheduling in RTOScan be grouped as static or dynamic 100. In the formercase, a schedulability analysis is performed before runDE MICHELI AND GUPTA HARDWARESOFTWARE CODESIGN 361time, even though task execution can be determined at runtime based on priorities. In the latter case, feasibility ischecked at run time 100. In either case, processes may beconsidered periodic or aperiodic. Most algorithms assumeperiodic tasks and tasks are converted into periodic taskswhen they are not originally so.Rate monotonic RM analysis 76 is one of the mostcelebrated algorithms for scheduling periodic processes ona single processor. RM is a prioritydriven preemptivealgorithm. Processes are statically scheduled with priorities that are higher for processes with higher invocationrate, hence the name. Liu and Layland showed that thisschedule is optimum in the sense that no other fixedpriority scheduler can schedule a set of processes whichcannot be scheduled by RM 76. The optimality of RM isvalid under some restrictive assumptions, e.g., neglectingcontextswitch time. Nevertheless, RM analysis has beenthe basis for more elaborate scheduling algorithms 21,27.Let us consider now hardwaresoftware system implementations obtained by partitioning a systemlevel specification, as mentioned in Section IVA. The implementationconsists of a set of software fragments executing on aprocessor in parallel with the execution of other tasks indedicated hardware. A relevant problem is to determinethe execution windows for both the hardware and softwaretasks. Since the partition depends on the specific application and design objectives, a runtime scheduler for thesystem is required that fits the hardwaresoftware partition.Conversely, a given partition may be chosen because a runtime scheduler can assign schedule tasks while satisfyinggiven deadline and rate constraints.We summarize an approach fully described in 45.Software tasks are represented by threads, each threadbeing a set of operations with known execution, exceptpossibly the head of the thread. Operations within threadsare statically scheduled with respect to the head of thethread, so that timing constraints are marginally satisfied,i.e., within the limits of the lack of knowledge of thedelay of the thread head operation. Threads execution isthen dynamically determined by a nonpreemptive runtimescheduler whose task is to synchronize the execution ofhardware and software. Threadbased scheduling can beseen as an application and extension of relative schedulingto the hardwaresoftware domain, thus showing the crossfertilization of the hardware and software fields.We briefly describe now process scheduling in Chinook, aCAD environment for designing reactive realtime systems21. The overall system can have different modes ofoperation, each having a schedule. Timing watchdogs candisable modes and cause mode transitions. Upon changingof mode, the system starts running the corresponding schedule. Timing constraints may be intermodal or intramodal.Each mode has a periodic set of tasks, which is unrolledand scheduled under timing constraints, using an extension of the relative scheduling formulation 21. With thisscheduling technique, Chinook supports the mapping ofan embedded system model to one or more processorand peripherals while ensuring the satisfaction of timingconstraints.In summary, process scheduling plays an important rolein the design of mixed hardwaresoftware systems, becauseit handles the synchronization of the tasks executing in boththe hardware and software components. For this reason, itis currently a subject of intensive research.V. ACCOMPLISHMENTSWe underline here briefly the major accomplishments inthis field, and we refer the readers to the other articles of thisissue for specific results. Hardwaresoftware codesign hasattracted the attention of several research groups worldwide,as documented by books 29, 39, 95, journal articles,and publications in symposia. Some of the research addresses incremental changes to systemlevel design tools, tocope with software components in predominantly hardwaredesigns. The need for addressing practical problems and forfitting into existing design methodologies where modelingstyles and languages are not negotiable, limits significantlythe power of these tools to search creatively the codesign solution space. Other research contributions proposeparadigm shifts in systemlevel design, by assuming a widefreedom in the way systems are modeled and designed.While these approaches will probably provide the basisfor longterm innovation, they often lead to design toolswhich are not readily usable by system designers becausedisconnected from existing design practices.Several research computeraided codesign environmentshave been released, and some of these are used for researchandor product development, e.g., Castle 105, Chinook24, Cosmos 61, Cosyma 37, Coware 114, Polis 26,Ptolemy 64, Siera 103, Specsym 40, and Tosca 8.See 29 for additional information on some of thesesystems.Commercial codesign tools are available to address someof the problems mentioned in this survey. Some CADvendors provide design entry systems and cosimulationenvironments. Cosimulation is widely applicable to generalpurpose and digitalsignal processor design, as well as toembedded system design. For the telecommunication domain, specialized environments support the vertical designof systems from design entry to physical realization. Systememulators, based on fieldprogrammable technology, haveproven to be successful for validating large systems.Commercial products in the software domain includecompilers for generalpurpose and dedicated processorswith standard and applicationspecific architectures, as wellas realtime operating systems and microkernels. Suchproducts find several applications in embedded systems.VI. CONCLUSIONHardwaresoftware codesign presents an enormous challenge, as well as an opportunity, for system designers.Use and reuse of hardware and software macro blocks canlead to products of superior quality i.e., performancecost,flexibility,  with a shorter design and development362 PROCEEDINGS OF THE IEEE, VOL. 85, NO. 3, MARCH 1997time as compared to traditional integrated circuit designmethodologies. The progress in electrical system designwill depend, among other factors, on the level of supportprovided by CAD tools. In particular, digital system products will benefit from concurrent hardwaresoftware designwhich exploits the synergism of hardware and softwarein the search for solutions that use at best the currentmanufacturing technology and the availability of hardwarecomponents and software programs.Scientific and commercial interest in hardwaresoftwarecodesign methods and tools has risen significantly in therecent years. Productlevel use of codesign tools has beenreported in some application domains, e.g., cosimulation,emulation, synthesis for embedded controllers, retargetablecompilers. The sector of computeraided codesign toolsis growing at a rapid pace because the potential payoffsmake it an attractive area for research as well as an excitingbusiness opportunity.Overall, hardwaresoftware codesign is a wide field ofresearch, because of the diversity of applications, designstyles and implementation technologies. Since this area isstill not completely defined, we can expect some evolutionary and some revolutionary changes in the way digitalsystems are designed. Thus hardwaresoftware codesign isthe key design technology for digital systems.REFERENCES1 T. Agerwala, Microprogramming optimization A survey,IEEE Trans. Computers, vol. C25, pp. 962973, Oct. 1976.2 A. Aho, R. Sethi, and J. Ullman, Compilers Principles, Techniques and Tools. Reading, MA AddisonWesley, 1988.3 A. Alomary, T. Nakata, Y. Honma, M. Imai, and N. Hikichi,An ASIP instruction set optimization algorithm with functional module sharing constraints, in Proc. ICCAD, 1993, pp.526532.4 S. Antoniazzi, A. Balboni, W. Fornaciari, and D. Sciuto,HWSW codesign for embedded telecom systems, in Proc.ICCD, 1994, pp. 278281.5 R. Amerson, R. Carter, W. B. Culberttson, P. Kuekes, and G.Snider, Teramacconfigurable custom computing, in FPGAsfor Custom Computing Machines, Apr. 1995.6 G. Araujo, S. Malik, and M Lee, Using registertransferpaths in code generation for heterogeneous memoryregisterarchitectures, in Proc. DAC, 1996, pp. 591596.7 J. Babb, R. Tessier, and A. Agarwal, Virtual wires Overcoming pin limitations in FPGAbased logic emulators, in Proc.IEEE Workshop on FPGAs for Custom Computing Machines,Apr. 1993.8 A. Balboni, W. Fornaciari, and D. Sciuto, Cosynthesis andcosimulation of controldominated embedded systems, DesignAutomat. Embedded Syst., vol. 1, no. 3, pp. 257289, July 1996.9 E. Barros, W. Rosenstiel, and X. Xiong, A method for partitioning UNITY language in hardware and software, in Proc.EURODAC, 1994, pp. 220225.10 D. Becker, R. Singh, and S. Tell, An engineering environmentfor hardwaresoftware cosimulation, in Proc. DAC, 1992, pp.129134.11 A. Bender, Design of an optimal loosely coupled heterogeneous multiprocessor system, in Proc. EDTC, 1996, pp.275281.12 A. Benveniste and G. Berry, The synchronous approach toreactive and realtime systems, Proc. IEEE, vol. 79, pp.12701282, Sept. 1991.13 P. Bertin, D. Roncin, and J. Vuillemin, Introduction to programmable active memories, in Systolic Array Processors, J.McCanny, J. McWhirter, and E. Schwartzlander, Eds. Englewood Cliffs, NJ PrenticeHall, 1989.14 N. Binh, M. Imai, A. Shiomi, and N. Hickichi, A HWSWpartitioning algorithm for designing pipelined ASIPs with leastgate counts, in Proc. DAC, 1996, pp. 527532.15 K. Buchenrieder, A. Sedelmeier, and C. Veith, IndustrialHWSW codesign, in HardwareSoftware CoDesign, G. DeMicheli and M. Sami, Eds. Amsterdam Kluwer, 1996, pp.453466.16 J. Cong and Y. Ding, Combinational logic synthesis for LUTbased field programmable gate arrays, TODAES, ACM Trans.Design Automat. Electron. Syst., vol. 1, no. 2, pp. 145204,Apr. 1996.17 I. Bolsens, H. De Man, B. Lin, K. van Rompaey, S. Vercautern, and D. Verkest, Hardwaresoftware codesign of digital telecommunication systems, Proc. IEEE, this issue, p.391418.18 J. R. Burch, E. M. Clarke, K. L. McMillan, D. L. Dill, and L. J.Hwang, Symbolic model checking 20 states and beyond,Informat. and Computation, vol. 98, no. 2, pp. 142170, June1992.19 J. R. Burch, E. M. Clarke, D. E. Long, K. L. McMillan,and D. L. Dill, Symbolic model checking for sequentialcircuit verification, IEEE Trans. CADICAS, vol. 13, no. 4,pp. 401424, Apr. 1994.20 D. Bursky, Microcontroller design exploits reusable cores,Electron. Design, vol. 42, no. 6, pp. 5368, Mar. 1994.21 P. Chou, E. Walkup, and G. Borriello, Scheduling strategiesin the cosynthesis of reactive realtime systems, IEEE Micro,vol. 14, no. 4, pp. 3747, Aug. 1994.22 P. Chou and G. Borriello, Software scheduling in cosynthesisof reactive realtime systems, in Proc. DAC, 1994, pp. 14.23 , Interval scheduling Finegrained code scheduling forembedded systems, in Proc. DAC, 1995.24 P. Chou, R. Ortega, and G. Borriello, The Chinookhardwaresoftware codesign system, in Proc. ISSS, Cannes,France, 1995, pp. 2227.25 M. Chiodo, P. Giusto, A. Jurecska, H. Hsieh, L. Lavagno, andA. Sangiovanni, A formal methodology for hardwaresoftwarecodesign of embedded systems, IEEE Micro, vol. 14, no. 4,pp. 2636, Aug. 1994.26 M. Chiodo, D. Engels, P. Giusto, A. Jurecska, H. Hsieh, L.Lavagno, K. Suzuki, and A. Sangiovanni, A case study incomputeraided codesign of embedded controllers, DesignAutomat. Embedded Syst., vol. 1, no. 2, pp. 5167.27 M. Cochran, Using the rate monotonic analysis to analyze theschedulability of ADARTS realtime software design, in Int.Workshop on HardwareSoftware Codesign, Sept. 1992.28 H. de Garis, Evolvable hardware, in Proc. Artificial Neur.Nets and Genetic Algorithms, Apr. 1993, pp. 441449.29 G. De Micheli and M. Sami, HardwareSoftware CoDesign.Amsterdam Kluwer, 1996.30 G. De Micheli, Synthesis and Optimization of Digital Circuits.New York McGrawHill, 1994.31 , Computeraided hardwaresoftware codesign, IEEEMicro, vol. 14, no. 4, pp. 1016, Aug. 1994.32 G. De Micheli, D. Ku, F. Mailhot, and T. Truong, The olympussynthesis system for digital design, IEEE Design and Test, pp.3753, Oct. 1990.33 E. D. Lagnese and D. Thomas, Architectural partitioning forsystem level descriptions, in Proc. DAC, 1989, pp. 6267.34 T. Ebisuzaki et al., GRAPE Special purpose computer forclassical manybody simulations, in Proc. Advances in Computing Techniques, 1994, pp. 218231.35 P. Eles, VHDL systemlevel specification and partitioning ina hardwaresoftware cosynthesis environment, Int. Workshopon HardwareSoftware Codesign, Sept. 1994, pp. 2224.36 S. Edward, L. Lavagno, E. Lee, and A. Sangiovanni, Design ofembedded systems Formal models, validation and synthesis,Proc. IEEE, this issue, pp. 366390.37 R. Ernst, J. Henkel, and T. Benner, Hardwaresoftware cosynthesis for microcontrollers, IEEE Design and Test, pp.6475, Dec. 1993.38 C. Feigel, Processors aim at desktop video, Microprocess.Rep., vol. 8, no. 2, Feb. 1994.39 D. Gajski, S. Narayan, F. Vahid, and J. Gong, Specification andDesign of Embedded Systems. Englewood Cliffs, NJ PrenticeHall, 1994.40 D. Gajski, F. Vahid, and S. Narayan, A system design methodology Executable specification refinement, in Proc. EDAC,DE MICHELI AND GUPTA HARDWARESOFTWARE CODESIGN 3631994, pp. 458463.41 M. Garey and D. Johnson, Computers and Intractability. NewYork Freeman, 1979.42 C. Gebotys and M. Elmasry, Optimal VLSI Architectural Synthesis. Amsterdam Kluwer, 1992.43 G. Goossens, P. G. Paulin, J. Van Praet, D. Lanneer, W. Guerts,A. Kifli, and C. Liem, Embedded software in realtime signalprocessing systems Design technologies, Proc. IEEE, thisissue, pp. 436454.44 J. Green, E. Hamdy, and S. Beal, Antifuse field programmablegate arrays, Proc. IEEE, vol. 81, pp. 10411056, July 1993.45 R. Gupta, CoSynthesis of Hardware and Software for DigitalEmbedded Systems. Amsterdam Kluwer, 1995.46 R. Gupta, C. Coelho, and G. De Micheli, Synthesis andsimulation of digital systems containing interacting hardwareand software components, in Proc. DAC, 1992, pp. 225230.47 R. Gupta and G. De Micheli, System cosynthesis for digitalsystems, IEEE Design and Test, vol. 10, no. 3, pp. 2941,Sept. 1993.48 , A cosynthesis approach to embedded system designautomation, Design Automat. for Embedded Syst., vol. 1, nos.12, pp. 69120, Jan. 1996.49 R. Gupta, C. Coelho, and G. De Micheli, Program implementation schemes for hardwaresoftware systems, IEEE Computer,pp. 4855, Jan. 1994.50 L. Hafer and A. Parker, Automated synthesis of digital hardware, IEEE Trans. Computers, vol. C31, no. 2, Feb. 1982.51 D. Harel, A. Pneuli, J. Schmidt, and R. Sherman, StatechartsA visual formalism for complex systems, Sci. Computer Programming, no. 8, pp. 231274, 1987.52 J. Hennessy and D. Patterson, Computer Architecture A Quantitative Approach. San Francisco Morgan Kaufmann, 1990.53 M. Heinrich, D. Ofelt, M. A. Horowitz, and J. Hennessy,Hardwaresoftware codesign of the stanford FLASH multiprocessor, Proc. IEEE, this issue, p. 455466.54 M. Horowitz and K. Keutzer, Hardwaresoftware codesign,in Proc. SASIMI, Nara, 1993, pp. 514.55 B. Holmer, A tools for processor instruction set design, inProc. DAC, 1994, pp. 150155.56 X. Hu, J. DAmbrosio, and D.L. Tang, Codesign architecturesfor automotive powertrain modules, IEEE Micro, vol. 14, no.4, pp. 1725, Aug. 1994.57 I. Huang and A. Despain, Highlevel synthesis of pipelinedinstruction set processors and backend compilers, in Proc.DAC, 1992, pp. 135140.58 , Hardwaresoftware resolution of pipeline hazards inpipeline synthesis of instruction set processors, in Proc. ICCAD, 1993, pp. 594599.59 , Synthesis of instruction sets for pipelined microprocessors, in Proc. DAC, 1994, pp. 511.60 T.Y. Huang, Worstcase timing analysis of concurrently executing DMA IO and programs, Ph.D. dissertation, Univ.Illinois, Dept. Computer Sci., Sept. 1996.61 T. Ismail and A. Jerraya, Synthesis steps and design modelsfor codesign, IEEE Computer, no. 2, pp. 4452, Feb. 1995.62 T. Ismail, K. OBrien, and A. Jerraya, Interactive systemlevel partitioning with PARTIF, in Proc. EDAC, Feb. 1994,pp. 464468.63 A. Jantasch, P. Ellervee, J. Oberg, A. Hemani, and H. Tenhunen,Hardwaresoftware partitioning and minimizing memory interface traffic, in Proc. EURODAC, 1994, pp. 226231.64 A. Kalavade and E. Lee, A hardwaresoftware codesignmethodology for DSP applications, IEEE Design and Test, vol.10, no. 3, pp. 1628, Sept. 1993.65 , A global criticalitylocal phase driven algorithm forthe constrained hardwaresoftware partitioning problem, in 3rdInt. Workshop on HardwareSoftware Codesign, Sept. 1994, pp.4248.66 D. Knapp, Behavioral Synthesis. Englewood Cliffs, NJPrenticeHall, 1996.67 D. Ku and G. De Micheli, Relative scheduling under timing constraints Algorithms for highlevel synthesis of digitalcircuits, IEEE Trans. CADICAS, June 1992, pp. 696718.68 K. Kucukcakar and A. Parker, CHOP A constraintdrivensystemlevel partitioner, in Proc. DAC, 1991, pp. 514519.69 D. Lanneer, J. Van Praet, A. Kifli, K. Schoofs, W. Guerts, F.Thoen, and G. Goossens, CHESS Retargetable code generation for embedded DSP processors, in Code Generators forEmbedded Processors, P. Marwedel and G. Goossens, Eds.Amsterdam Kluwer, 1995.70 T. Ly, D. Knapp, R. Miller, and D. MacMillen, Scheduling withing behavioral templates, in Proc. DAC, 1995, pp.101106.71 S. Liao, K. Keutzer, S. Tjiang, and A. Wang, Code optimization techniques for embedded DSP microprocessors, in DACProc. Design Automat. Conf., 1995, pp. 599604.72 Y.T. Li and S. Malik, Performance analysis of embeddedsoftware using implicit path enumeration, in Proc. DAC, 1995,pp. 456461.73 Y.T. Li, S. Malik, and A. Wolfe, Performance estimation ofembedded software with instruction cache modeling, in Proc.ICCAD, Nov. 1995, pp. 380387.74 S. Liao, K. Keutzer, K. Keutzer, and S. Tjiang, Instruction setselection using binate covering for code size optimization, inProc. ICCAD, 1995, pp. 393399.75 C. Liem, T. May, and P. Paulin, Instructionset matching andselection for DSP and ASIP code generation, in Proc. Europe.Design and Test Conf., 1994, pp. 3137.76 C. L. Liu and J. Layland, Scheduling algorithms for multiprogramming in a hardrealtime environment, J. ACM, vol. 20,pp. 4461, Jan. 1973.77 J. Madsen and J. P. Brage, Codesign analysis of a computergraphics application, Design Automat. for Embedded Syst., vol.1, pp. 121145, 1996.78 D. Mange, M. Goeke, D. Madon, A. Stauffer, G. Tempesti,and S. Durand, Embryonics A new family of coarsegrainedFPGAs with selfrepair and selfreproducing properties, inToward Evolvable Hardware, E. Sanchez and M. Tomassini,Eds. Amsterdam Springer, 1996.79 P. Marwedel and G. Goossens, Eds., Code Generators forEmbedded Processors. Amsterdam Kluwer, 1995.80 P. Marwedel, Treebased mapping of algorithms to predefinedstructures, in Proc. ICCAD, 1993, pp. 586593.81 L. Maliniak, Logic emulator meets the demands of CPUdesigners, Electron. Design, Apr. 1993.82 A. Mok, P. Amerasinghe, M. Chen, and K. Tantisirivat, Evaluating tight execution bounds of programs by annotations, inProc. 6th IEEE Workshop on RealTime Operating Syst. andSoftware, May 1989, pp. 272279.83 S. Narayan, F. Vahid, and D. Gajski, Translating systemspecifications to VHDL, in Proc. EDAC, 1991, pp. 390394.84 R. Niemann and P. Marwedel, Hardwaresoftware partitioning using integer programming, in Proc. EDTC, 1996, pp.473479.85 S. Note, F. Chattoor, G. Goossens, and H. De Man, Combinedhardware selection and pipelining in highlevel performancedatapath design, IEEE Trans. CADICAS, pp. 413423, Apr.1992.86 K. Olukotun, R. Helahel, J. Levitt, and R. Ramirez, A softwarehardware cosynthesis approach to digital system simulation, IEEE Micro., vol. 14, no. 4, pp. 4858, Aug. 1994.87 C.Y. Park, Predicting program execution times by analyzingstatic and dynamic program paths, J. RealTime Syst., vol. 5,pp. 3162, Mar. 1993.88 P. Paulin, G. Goossens, C. Liem, M. Cornero, and F. Nacabal,Embedded software in realtime signal processing systemsApplications and architecture trends, Proc. IEEE, this issue,pp. 419435.89 P. Paulin, C. Liem, T. May, and S. Sutarwala, FlexwareA flexible firmware development environment for embeddedsystems, in Code Generators for Embedded Processors, P.Marwedel and G. Goossens, Eds. Amsterdam Kluwer, 1995.90 , DSP design tool requirements for embedded systemsA telecommunications industrial perspective, J. VLSI SignalProcess., no. 9, pp. 2347, 1995.91 D. Perry, VHDL. New York McGrawHill, 1991.92 J. Peterson and A. Silbershatz, Operating Systems Principles.Reading, MA AddisonWesley.93 P. Puschner and C. Koza, Calculating the maximum executiontime of realtime programs, J. RealTime Syst., vol. 1, pp.159176, Sept. 1989.94 J. Rowson, Hardwaresoftware cosimulation, in Proc. DesignAutomat. Conf., 1994, pp. 439440.95 J. Rozenblit and K. Buchenrieder, Codesign ComputerAidedSoftwareHardware Engineering. Piscataway, NJ IEEE, 1995.96 M. Salinas, B. Johnson, and H. Aylor, Implementationindependent model of an instruction set architecture in VHDL,364 PROCEEDINGS OF THE IEEE, VOL. 85, NO. 3, MARCH 1997IEEE Design and Test, vol. 10, no. 3, pp. 4255, Sept. 1993.97 E. Sanchez and M. Tomassini, Toward Evolvable Hardware.Amsterdam Springer, 1996.98 R. Saracco and P. Tilanus, CCITT SDL Overview of thelanguage and its applications, Computer Networks and ISDNSyst., vol. 13, no. 2, pp. 6574, 1987.99 K. Shin and P. Ramanathan, Realtime computing A newdiscipline of computer science and engineering, Proc. IEEE,vol. 82, pp. 624, Jan. 1994.100 P. Ramanathan and J. Stankovic, Scheduling algorithms andoperating system support for realtime systems, Proc. IEEE,vol. 82, pp. 5567, Jan. 1994.101 S. Agrawal and R. Gupta, System partitioning using globaldataflow, Univ. Illinois Memo. UIUC DCS, 1995.102 A. Smailagic and D. Siewiorek, A casestudy in embeddedsystem design The VuMan2 wearable computer, IEEE Designand Test, vol. 10, no. 3, pp. 5667, Sept. 1993.103 M. B. Srivastava and R. W. Broderson, Rapidprototypingof hardware and software in a unified framework, in Proc.ICCAD, 1991, pp. 152155.104 J. Stankovich, M. Spuri, M. Di Natale, and C. Buttazzo, Implications of classical scheduling results for realtime systems,IEEE Computer, vol. 28, no. 6, pp. 1625.105 M. Theissinger, P. Stravers, and H. Veit, CASTLE A designenvironment for codesign, in Proc. Int. Workshop on HardwareSoftware CoDesign, Grenoble, Sept. 1994, pp. 203209.106 D. Thomas, E. Lagnese, R. Walker, J. Nestor, J. Rajan, and R.Blackburn, Algorithmic and Register Transfer Level SynthesisThe System Architects Workbench. New York Kluwer, 1990.107 D. Thomas and P. Moorby, The Verilog Hardware DescriptionLanguage. New York Kluwer, 1991.108 D. Thomas, J. Adams, and H. Schmitt, A model and methodology for hardwaresoftware codesign, IEEE Design and Test,vol. 10, no. 3, pp. 615, Sept. 1993.109 A. Timmer, M. Strik, J. van Meerbergen, and J. Jess, Conflictmodeling and instruction scheduling in code generation for inhouse DSP cores, in DAC Proc. Design Automat. Conf., 1995,pp. 593598.110 S. Trimberger, A reprogrammable gate array and applications,Proc. IEEE, vol. 81, no. 7, pp. 10301041, July 1993.111 F. Vahid, J. Gong, and D. Gajski, A binaryconstraint searchalgorithm for minimizing hardware during hardwaresoftwarepartitioning, in Proc. EURODAC, 1994, pp. 214219.112 J. Vuillemin, P. Bertin, D. Roncin, M. Shand, H. Touati, andP. Boucard, Programmable active memories Reconfigurablesystems come of age, IEEE Trans. VLSI, vol. 4, no. 2, pp.5669, Mar. 1996.113 A. Wenban, J. OLeary, and G. Brown, Codesign of communication protocols IEEE Computers, no. 12, pp. 4652, Dec.1993.114 D. Verkest, K. van Romaey, I. Bolsen, and H. De man,CowareA design environment for heterogeneous hardwaresoftware systems, Design Automat. for Embedded Syst.,vol. 1, no. 4, pp. 357386, Oct. 1996.115 P. Willekens et al., Algorithm specifications in DSP stationusing data flow language, DSP Applicat., vol. 3, no. 1, pp.816, Jan. 1994.116 M. Wolf and M. Lam, A loop transformation theory andan algorithm to maximize parallelism, IEEE Trans. ParallelDistrib. Syst., vol. 2, no. 4, pp. 452471, Oct. 1991.117 W. Wolf and E. Frey, Tutorial on embedded system design,in Proc. ICCD, 1992, pp. 1821.118 W. Wolf, Hardwaresoftware codesign of embedded systems,Proc. IEEE, vol. 82, pp. 967989, July 1994.119 T.Y. Yen and W. Wolf, Communicating synthesis fordistributed embedded systems, in Proc. ICCAD, 1995, pp.288294.120 N. Zhang, A. Burns, and M. Nicholson, Pipelined processorsand worst case execution times, J. RealTime Syst., vol. 5, pp.319343, Oct. 1993.Giovanni De Micheli Fellow, IEEE, for a photograph and biography,see this issue, p. 349.Rajesh K. Gupta Member, IEEE received theB.Tech. degree in electrical engineering fromthe Indian Institute of Technology, Kanpur, India, the M.S. degree in electrical engineeringand computer science from the University ofCalifornia at Berkeley, and the Ph.D. degree inelectrical engineering from Stanford University,Stanford, CA, in 1984, 1986, and 1993, respectively.He is presently an Assistant Professor ofInformation and Computer Science at the University of California, Irvine. During 19941996 he was an AssistantProfessor at the University of Illinois at UrbanaChampaign. From 1986to 1989 he was with Intel Corporation, Santa Clara, CA, where he workedon VLSI design at various levels of abstraction as a member of the designteams for the 80386SX, 80486, and Pentium microprocessor devices. Hehas worked on a number of successful chip designs, including CMOS,BiCMOS, ECL, and highspeed GaAs devices. He coauthored a patenton PLLbased clock circuit. He authored Cosynthesis of Hardware andSoftware for Digital Embedded Systems Kluwer.Dr. Gupta was nominated for the NSF Presidential Faculty FellowAward by the University of Illinois in 1996. He received the NSFCAREER Award in 1995, the Philips Graduate Fellowship in 1991 and1992, the Departmental Achievements by Microcomputer Division atIntel Corporation in 1987 and 1989, the Components Research AwardTechnology Development Division, Intel in 1991, and the Joseph DiasFellowship and the David and Sylvia Gale Fellowship, both from U.C.Berkeley, in 1984 and 1985, respectively. He serves on the programcommittees of the Great Lakes Symposium on VLSI, CODES workshop,ICCD, ICCAD, and DAC.DE MICHELI AND GUPTA HARDWARESOFTWARE CODESIGN 365
