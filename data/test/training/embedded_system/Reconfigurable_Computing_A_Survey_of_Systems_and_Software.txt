Reconfigurable Computing A Survey of Systems and SoftwareKATHERINE COMPTONNorthwestern UniversityANDSCOTT HAUCKUniversity of WashingtonDue to its potential to greatly accelerate a wide variety of applications, reconfigurablecomputing has become a subject of a great deal of research. Its key feature is the abilityto perform computations in hardware to increase performance, while retaining much ofthe flexibility of a software solution. In this survey, we explore the hardware aspects ofreconfigurable computing machines, from single chip architectures to multichipsystems, including internal structures and external coupling. We also focus on thesoftware that targets these machines, such as compilation tools that map highlevelalgorithms directly to the reconfigurable substrate. Finally, we consider the issuesinvolved in runtime reconfigurable systems, which reuse the configurable hardwareduring program execution.Categories and Subject Descriptors A.1 Introductory and Survey B.6.1 LogicDesign Design Stylelogic arrays B.6.3 Logic Design Design Aids B.7.1Integrated Circuits Types and Design Stylesgate arraysGeneral Terms Design, PerformanceAdditional Key Words and Phrases Automatic design, fieldprogrammable, FPGA,manual design, reconfigurable architectures, reconfigurable computing, reconfigurablesystems1. INTRODUCTIONThere are two primary methods in conventional computing for the executionThis research was supported in part by Motorola, Inc., DARPA, and NSF.K. Compton was supported by an NSF fellowship.S. Hauck was supported in part by an NSF CAREER award and a Sloan Research Fellowship.Authors addresses K. Compton, Department of Electrical and Computer Engineering, Northwestern University, 2145 Sheridan Road, Evanston, IL 602083118 email katiece.northwestern.edu S. Hauck, Department of Electrical Engineering, The University of Washington, Box 352500, Seattle, WA 98195 emailhauckee.washington.edu.Permission to make digital or hard copies of part or all of this work for personal or classroom use is grantedwithout fee provided that copies are not made or distributed for profit or direct commercial advantage andthat copies show this notice on the first page or initial screen of a display along with the full citation.Copyrights for components of this work owned by others than ACM must be honored. Abstracting with creditis permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission andor a fee. Permissions may be requestedfrom Publications Dept., ACM, Inc., 1515 Broadway, New York, NY 10036 USA, fax 1 212 8690481, orpermissionsacm.org.c2002 ACM 036003000206000171 5.00of algorithms. The first is to use hardwired technology, either an ApplicationSpecific Integrated Circuit ASIC or agroup of individual components forming aACM Computing Surveys, Vol. 34, No. 2, June 2002, pp. 171210.172 K. Compton and S. Hauckboardlevel solution, to perform the operations in hardware. ASICs are designedspecifically to perform a given computation, and thus they are very fast andefficient when executing the exact computation for which they were designed.However, the circuit cannot be altered after fabrication. This forces a redesign andrefabrication of the chip if any part of itscircuit requires modification. This is an expensive process, especially when one considers the difficulties in replacing ASICsin a large number of deployed systems.Boardlevel circuits are also somewhat inflexible, frequently requiring a board redesign and replacement in the event ofchanges to the application.The second method is to use softwareprogrammed microprocessorsa farmore flexible solution. Processors executea set of instructions to perform a computation. By changing the software instructions, the functionality of the system isaltered without changing the hardware.However, the downside of this flexibilityis that the performance can suffer, if notin clock speed then in work rate, and isfar below that of an ASIC. The processormust read each instruction from memory,decode its meaning, and only then execute it. This results in a high executionoverhead for each individual operation.Additionally, the set of instructions thatmay be used by a program is determinedat the fabrication time of the processor.Any other operations that are to be implemented must be built out of existinginstructions.Reconfigurable computing is intended tofill the gap between hardware and software, achieving potentially much higherperformance than software, while maintaining a higher level of flexibility thanhardware. Reconfigurable devices, including fieldprogrammable gate arraysFPGAs, contain an array of computational elements whose functionality is determined through multiple programmableconfiguration bits. These elements, sometimes known as logic blocks, are connectedusing a set of routing resources that arealso programmable. In this way, customdigital circuits can be mapped to the reconfigurable hardware by computing the logicfunctions of the circuit within the logicblocks, and using the configurable routingto connect the blocks together to form thenecessary circuit.FPGAs and reconfigurable computinghave been shown to accelerate a variety ofapplications. Data encryption, for example, is able to leverage both parallelismand finegrained data manipulation. Animplementation of the Serpent BlockCipher in the Xilinx Virtex XCV1000shows a throughput increase by a factorof over 18 compared to a Pentium ProPC running at 200 MHz Elbirt and Paar2000. Additionally, a reconfigurable computing implementation of sieving for factoring large numbers useful in breakingencryption schemes was accelerated by afactor of 28 over a 200MHz UltraSparcworkstation Kim and MangioneSmith2000. The Garp architecture shows acomparable speedup for DES Hauserand Wawrzynek 1997, as does anFPGA implementation of an elliptic curvecryptography application Leung et al.2000.Other recent applications that havebeen shown to exhibit significant speedups using reconfigurable hardwareinclude automatic target recognitionRencher and Hutchings 1997, string pattern matching Weinhardt and Luk 1999,Golomb Ruler Derivation Dollas et al.1998 Sotiriades et al. 2000, transitiveclosure of dynamic graphs Huelsbergen2000, Boolean satisfiability Zhong et al.1998, data compression Huang et al.2000, and genetic algorithms for the travelling salesman problem Graham andNelson 1996.In order to achieve these performancebenefits, yet support a wide range of applications, reconfigurable systems are usually formed with a combination of reconfigurable logic and a generalpurposemicroprocessor. The processor performsthe operations that cannot be done efficiently in the reconfigurable logic, suchas datadependent control and possiblymemory accesses, while the computationalcores are mapped to the reconfigurablehardware. This reconfigurable logic can beACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 173composed of either commercial FPGAs orcustom configurable hardware.Compilation environments for reconfigurable hardware range from tools to assista programmer in performing a hand mapping of a circuit to the hardware, to complete automated systems that take a circuit description in a highlevel languageto a configuration for a reconfigurable system. The design process involves first partitioning a program into sections to be implemented on hardware, and those whichare to be implemented in software on thehost processor. The computations destinedfor the reconfigurable hardware are synthesized into a gate level or register transfer level circuit description. This circuit ismapped onto the logic blocks within the reconfigurable hardware during the technology mapping phase. These mapped blocksare then placed into the specific physical blocks within the hardware, and thepieces of the circuit are connected usingthe reconfigurable routing. After compilation, the circuit is ready for configuration onto the hardware at runtime. Thesesteps, when performed using an automaticcompilation system, require very little effort on the part of the programmer toutilize the reconfigurable hardware. However, performing some or all of these operations by hand can result in a more highlyoptimized circuit for performancecriticalapplications.Since FPGAs must pay an area penaltybecause of their reconfigurability, devicecapacity can sometimes be a concern. Systems that are configured only at powerup are able to accelerate only as muchof the program as will fit within the programmable structures. Additional areas ofa program might be accelerated by reusingthe reconfigurable hardware during program execution. This process is knownas runtime reconfiguration RTR. Whilethis style of computing has the benefit ofallowing for the acceleration of a greaterportion of an application, it also introducesthe overhead of configuration, which limits the amount of acceleration possible. Because configuration can take millisecondsor longer, rapid and efficient configurationis a critical issue. Methods such as configuration compression and the partial reuseof already programmed configurations canbe used to reduce this overhead.This article presents a survey of current research in hardware and softwaresystems for reconfigurable computing, aswell as techniques that specifically targetruntime reconfigurability. We lead off thisdiscussion by examining the technologyrequired for reconfigurable computing, followed by a more indepth examination ofthe various hardware structures used inreconfigurable systems. Next, we look atthe software required for compilation ofalgorithms to configurable computers, andthe tradeoffs between handmapping andautomatic compilation. Finally, we discussruntime reconfigurable systems, whichfurther utilize the intrinsic flexibility ofconfigurable computing platforms by optimizing the hardware not only for differentapplications, but for different operationswithin a single application as well.This survey does not seek to cover every technique and research project in thearea of reconfigurable computing. Instead,it hopes to serve as an introduction tothis rapidly evolving field, bringing interested readers quickly up to speed ondevelopments from the last halfdecade.Those interested in further backgroundcan find coverage of older techniquesand systems elsewhere Rose et al. 1993Hauck and Agarwal 1996 Vuillemin et al.1996 MangioneSmith et al. 1997 Hauck1998b.2. TECHNOLOGYReconfigurable computing as a concepthas been in existence for quite some timeEstrin et al. 1963. Even generalpurposeprocessors use some of the same basicideas, such as reusing computational components for independent computations,and using multiplexers to control therouting between these components. However, the term reconfigurable computing, as it is used in current researchand within this survey, refers to systems incorporating some form of hardware programmabilitycustomizing howthe hardware is used using a numberACM Computing Surveys, Vol. 34, No. 2, June 2002.174 K. Compton and S. HauckFig. 1. A programming bit for SRAMbased FPGAs Xilinx 1994 left and a programmable routing connection right.of physical control points. These controlpoints can then be changed periodically inorder to execute different applications using the same hardware.The recent advances in reconfigurablecomputing are for the most part derived from the technologies developedfor FPGAs in the mid1980s. FPGAswere originally created to serve as a hybrid device between PALs and MaskProgrammable Gate Arrays MPGAs.Like PALs, FPGAs are fully electricallyprogrammable, meaning that the physicaldesign costs are amortized over multipleapplication circuit implementations, andthe hardware can be customized nearly instantaneously. Like MPGAs, they can implement very complex computations on asingle chip, with devices currently in production containing the equivalent of overa million gates. Because of these features,FPGAs had been primarily viewed as gluelogic replacement and rapidprototypingvehicles. However, as we show throughout this article, the flexibility, capacity,and performance of these devices hasopened up completely new avenues inhighperformance computation, formingthe basis of reconfigurable computing.Most current FPGAs and reconfigurable devices are SRAMprogrammableFigure 1 left, meaning that SRAM1bits are connected to the configurationpoints in the FPGA, and programmingthe SRAM bits configures the FPGA.1 The term SRAM is technically incorrect for manyFPGA architectures, given that the configurationmemory may or may not support random access. Infact, the configuration memory tends to be continually read in order to perform its function. However,this is the generally accepted term in the field andcorrectly conveys the concept of static volatile memory using an easily understandable label.Thus, these chips can be programmed andreprogrammed about as easily as a standard static RAM. In fact, one researchproject, the PAM project Vuillemin et al.1996, considers a group of one or moreFPGAs to be a RAM unit that performscomputation between the memory writesending the configuration informationand input data and memory read reading the results of the computation. Thisleads some to use the term ProgrammableActive Memory or PAM.One example of how the SRAM configuration points can be used is to control routing within a reconfigurable device Chowet al. 1999a. To configure the routing onan FPGA, typically a passgate structureis employed see Figure 1 right. Here theprogramming bit will turn on a routingconnection when it is configured with atrue value, allowing a signal to flow fromone wire to another, and will disconnectthese resources when the bit is set to false.With a proper interconnection of these elements, which may include millions of routing choice points within a single device, arich routing fabric can be created.Another example of how these configuration bits may be used is to control multiplexers, which will choose between theoutput of different logic resources withinthe array. For example, to provide optionalstateholding elements a D flipflop DFFmay be included with a multiplexer selecting whether to forward the latchedor unlatched signal value see Figure 2left. Thus, for systems that require stateholding the programming bits controllingthe multiplexer would be configured to select the DFF output, while systems thatdo not need this function would choosethe bypass route that sends the input directly to the output. Similar structuresACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 175Fig. 2. D flipflop with optional bypass left and a 3input LUT right.can choose between other onchip functionalities, such as fixedlogic computationelements, memories, carry chains, or otherfunctions.Finally, the configuration bits may beused as control signals for a computationalunit or as the basis for computation itself. As a control signal, a configurationbit may determine whether an ALU performs an addition, subtraction, or otherlogic computations. On the other hand,with a structure such as a lookup tableLUT, the configuration bits themselvesform the result of the computation seeFigure 2 right. These elements are essentially small memories provided for computing arbitrary logic functions. LUTs cancompute any function of N inputs whereN is the number of control signals for theLUTs multiplexer by programming the2N programming bits with the truth table of the desired function. Thus, if allprogramming bits except the one corresponding to the input pattern 111 wereset to zero a 3input LUT would act as a3input AND gate, while programming itwith all ones except in 000 would computea NAND.3. HARDWAREReconfigurable computing systems useFPGAs or other programmable hardwareto accelerate algorithm execution by mapping computeintensive calculations to thereconfigurable substrate. These hardwareresources are frequently coupled with ageneralpurpose microprocessor that isresponsible for controlling the reconfigurable logic and executing program codethat cannot be efficiently accelerated. Invery closely coupled systems, the reconfigurability lies within customizable functional units on the regular datapath ofthe microprocessor. On the other hand, areconfigurable computing system can beas loosely coupled as a networked standalone unit. Most reconfigurable systemsare categorized somewhere between thesetwo extremes, frequently with the reconfigurable hardware acting as a coprocessor to a host microprocessor. The programmable array itself can be comprisedof one or more commercially availableFPGAs, or can be a custom device designedspecifically for reconfigurable computing.The design of the actual computationblocks within the reconfigurable hardwarevaries from system to system. Each unit ofcomputation, or logic block, can be as simple as a 3input lookup table LUT, or ascomplex as a 4bit ALU. This differencein block size is commonly referred to asthe granularity of the logic block, wherethe 3bit LUT is an example of a veryfinegrained computational element, and a4bit ALU is an example of a quite coarsegrained unit. The finergrained blocks areuseful for bitlevel manipulations, whilethe coarsegrained blocks are better optimized for standard datapath applications.Some architectures employ different sizesor types of blocks within a single reconfigurable array in order to efficiently support different types of computation. Forexample, memory is frequently embeddedwithin the reconfigurable hardware to provide temporary data storage, forming aheterogeneous structure composed of bothlogic blocks and memory blocks Ebelinget al. 1996 Altera 1998 Lucent 1998Marshall et al. 1999 Xilinx 1999.ACM Computing Surveys, Vol. 34, No. 2, June 2002.176 K. Compton and S. HauckThe routing between the logic blockswithin the reconfigurable hardware is alsoof great importance. Routing contributessignificantly to the overall area of the reconfigurable hardware. Yet, when the percentage of logic blocks used in an FPGA becomes very high, automatic routing toolsfrequently have difficulty achieving thenecessary connections between the blocks.Good routing structures are therefore essential to ensure that a design can be successfully placed and routed onto the reconfigurable hardware.Once a circuit has been programmedonto the reconfigurable hardware, it isready to be used by the host processor during program execution. The runtime operation of a reconfigurable system occursin two distinct phases configuration andexecution. The programming of the reconfigurable hardware is under the control ofthe host processor. This host processor directs a stream of configuration data to thereconfigurable hardware, and this configuration data is used to define the actualoperation of the hardware. Configurationscan be loaded solely at startup of a program, or periodically during runtime, depending on the design of the system. Moreconcepts involved in runtime reconfiguration the dynamic reconfiguration of devices during computation execution arediscussed in a later section.The actual execution model of the reconfigurable hardware varies from system to system. For example, the NAPAsystem Rupp et al. 1998 by defaultsuspends the execution of the host processor during execution on the reconfigurable hardware. However, simultaneous computation can occur with theuse of forkandjoin primitives, similar tomultiprocessor programming. REMARCMiyamori and Olukotun 1998 is a reconfigurable system that uses a pipelinedset of execution phases within the reconfigurable hardware. These pipeline stagesoverlap with the pipeline stages of the hostprocessor, allowing for simultaneous execution. In the Chimaera system Haucket al. 1997, the reconfigurable hardwareis constantly executing based upon the input values held in a subset of the host processors registers. A call to the Chimaeraunit is in actuality only a fetch of the result value. This value is stable and validafter the correct input values have beenwritten to the registers and have filteredthrough the computation.In the next sections, we consider ingreater depth the hardware issues in reconfigurable computing, including bothlogic and routing. To support the computation demands of reconfigurable computing, we consider the logic block architectures of these devices, including possiblythe integration of heterogeneous logic resources within a device. Heterogeneityalso extends between chips, where one ofthe most important concerns is the coupling of the reconfigurable logic with standard, generalpurpose processors. However, reconfigurable devices are more thanjust logic devices the routing resourcesare at least as important as logic resources, and thus we consider interconnect structures, including 1Doriented devices that are beginning to appear.3.1. CouplingFrequently, reconfigurable hardware iscoupled with a traditional microprocessor.Programmable logic tends to be inefficientat implementing certain types of operations, such as variablelength loops andbranch control. In order to run an application in a reconfigurable computing systemmost efficiently, the areas of the programthat cannot be easily mapped to the reconfigurable logic are executed on a host microprocessor. Meanwhile, the areas with ahigh density of computation that can benefit from implementation in hardware aremapped to the reconfigurable logic. For thesystems that use a microprocessor in conjunction with reconfigurable logic, thereare several ways in which these two computation structures may be coupled, asFigure 3 shows.First, reconfigurable hardware can beused solely to provide reconfigurablefunctional units within a host processor Razdan and Smith 1994 Haucket al. 1997. This allows for a traditional programming environment with theACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 177Fig. 3. Different levels of coupling in a reconfigurable system. Reconfigurable logicis shaded.addition of custom instructions that maychange over time. Here, the reconfigurableunits execute as functional units on themain microprocessor datapath, with registers used to hold the input and outputoperands.Second, a reconfigurable unit maybe used as a coprocessor Wittig andChow 1996 Hauser and Wawrzynek 1997Miyamori and Olukotun 1998 Rupp et al.1998 Chameleon 2000. A coprocessor is,in general, larger than a functional unit,and is able to perform computations without the constant supervision of the hostprocessor. Instead, the processor initializes the reconfigurable hardware and either sends the necessary data to the logic,or provides information on where this datamight be found in memory. The reconfigurable unit performs the actual computations independently of the main processor,and returns the results after completion.This type of coupling allows the reconfigurable logic to operate for a large number of cycles without intervention fromthe host processor, and generally permitsthe host processor and the reconfigurablelogic to execute simultaneously. This reduces the overhead incurred by the useof the reconfigurable logic, compared to areconfigurable functional unit that mustcommunicate with the host processor eachtime a reconfigurable instruction is used.One idea that is somewhat of a hybrid between the first and second coupling methods, is the use of programmable hardwarewithin a configurable cache Kim et al.2000. In this situation, the reconfigurablelogic is embedded into the data cache.This cache can then be used as either aregular cache or as an additional computing resource depending on the targetapplication.Third, an attached reconfigurableprocessing unit Vuillemin et al. 1996Annapolis 1998 Laufer et al. 1999 behaves as if it is an additional processor ina multiprocessor system or an additionalcompute engine accessed semifrequentlythrough external IO. The host processorsdata cache is not visible to the attachedreconfigurable processing unit. There is,therefore, a higher delay in communication between the host processor and the reconfigurable hardware, such as when communicating configuration information,input data, and results. This communication is performed though specializedprimitives similar to multiprocessor systems. However, this type of reconfigurablehardware does allow for a great deal ofcomputation independence, by shiftinglarge chunks of a computation over to thereconfigurable hardware.Finally, the most loosely coupled formof reconfigurable hardware is that ofan external standalone processing unitQuickturn 1999a, 1999b. This type ofreconfigurable hardware communicatesinfrequently with a host processor ifpresent. This model is similar to thatof networked workstations, where processing may occur for very long periodsof time without a great deal of communication. In the case of the Quickturnsystems, however, this hardware is gearedACM Computing Surveys, Vol. 34, No. 2, June 2002.178 K. Compton and S. Hauckmore towards emulation than reconfigurable computing.Each of these styles has distinct benefits and drawbacks. The tighter the integration of the reconfigurable hardware,the more frequently it can be used withinan application or set of applications dueto a lower communication overhead. However, the hardware is unable to operatefor significant portions of time without intervention from a host processor, and theamount of reconfigurable logic available isoften quite limited. The more loosely coupled styles allow for greater parallelism inprogram execution, but suffer from highercommunications overhead. In applicationsthat require a great deal of communication, this can reduce or remove any acceleration benefits gained through this typeof reconfigurable hardware.3.2. Traditional FPGAsBefore discussing the detailed architecture design of reconfigurable devices ingeneral, we will first describe the logicand routing of FPGAs. These conceptsapply directly to reconfigurable systemsusing commercial FPGAs, such as PAMVuillemin et al. 1996 and Splash 2Arnold et al. 1992 Buell et al. 1996,and many also extend to architecturesdesigned specifically for reconfigurablecomputing. Hardware concepts applyingspecifically to architectures designed forreconfigurable computing, as well as variations on the generic FPGA descriptionprovided here, are discussed following thissection. More detailed surveys of FPGA architectures themselves can be found elsewhere Brown et al. 1992a Rose et al.1993.Since the introduction of FPGAs in themid1980s, there have been many different investigations into what computationelements should be built into the array Rose et al. 1993. One could considerFPGAs that were created with PALlikeproduct term arrays, or multiplexerbasedfunctionality, or even basic fixed functionssuch as simple NAND and XOR gates. Infact, many such architectures have beenbuilt. However, it seems to be fairly wellFig. 4. A basic logic block, with a 4inputLUT, carry chain, and a Dtype flipflop withbypass.established that the best function blockfor a standard FPGA, a device whose primary role is the implementation of random digital logic, is the one found in thefirst devices deployedthe lookup tableFigure 2 right. As described in the previous section, an Ninput LUT is basicallya memory that, when programmed appropriately, can compute any function of up toN inputs. This flexibility, with relativelysimple routing requirements each inputneed only be routed to a single multiplexercontrol input turns out to be very powerful for logic implementation. Although it isless areaefficient than fixed logic blocks,such as a standard NAND gate, the truthis that most current FPGAs use less than10 of their chip area for logic, devotingthe majority of the silicon real estate forrouting resources.The typical FPGA has a logic blockwith one or more 4input LUTs, optional D flipflops DFF, and some formof fast carry logic Figure 4. The LUTsallow any function to be implemented, providing generic logic. The flipflop can beused for pipelining, registers, stateholding functions for finite state machines, orany other situation where clocking is required. Note that the flipflops will typically include programmable setreset linesand clock signals, which may come fromglobal signals routed on special resources,or could be routed via the standard interconnect structures from some otherinput or logic block. The fast carry logicACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 179Fig. 5. A generic islandstyle FPGA routing architecture.is a special resource provided in the cellto speed up carrybased computations,such as addition, parity, wide AND operations, and other functions. These resources will bypass the general routingstructure, connecting instead directly between neighbors in the same column.Since there are very few routing choicesin the carry chain, and thus less delay onthe computation, the inclusion of these resources can significantly speed up carrybased computations.Just as there has been a great dealof experimentation in FPGA logic blockarchitectures, there has been equallyas much investigation into interconnectstructures. As logic blocks have basicallystandardized on LUTbased structures,routing resources have become primarilyislandstyle, with logic surrounded by general routing channels.Most FPGA architectures organize theirrouting structures as a relatively smoothsea of routing resources, allowing fast andefficient communication along the rowsand columns of logic blocks. As shownin Figure 5, the logic blocks are embedded in a general routing structure,with input and output signals attachingto the routing fabric through connectionblocks. The connection blocks provide programmable multiplexers, selecting whichof the signals in the given routing channelwill be connected to the logic blocks terminals. These blocks also connect shorterlocal wires to longerdistance routing resources. Signals flow from the logic blockinto the connection block, and then alonglonger wires within the routing channels.At the switchboxes, there are connectionsbetween the horizontal and vertical routing resources to allow signals to changetheir routing direction. Once the signalhas traversed through routing resourcesand intervening switchboxes, it arrives atthe destination logic block through one ofits local connection blocks. In this manner, relatively arbitrary interconnectionscan be achieved between the logic blocksin the system.Within a given routing channel, theremay be a number of different lengths ofrouting resources. Some local interconnections may only move between adjacentlogic blocks carry chains are a good example of this, providing highspeed local interconnect. Medium length lines mayrun the width of several logic blocks, providing for some longer distance interconnect. Finally, longlines that run the entirechip width or height may provide for moreglobal signals. Also, many architecturescontain special global lines that providehighspeed, and often lowskew, connections to all of the logic blocks in the array.These are primarily used for clocks, resets,and other truly global signals.While the routing architecture of anFPGA is typically quite complexthe connection blocks and switchboxes surrounding a single logic block typically have thousands of programming pointsthey aredesigned to be able to support fairly arbitrary interconnection patterns. Most usersignore the exact details of these architectures and allow the automatic physical design tools to choose appropriate resourcesto use in order to achieve a given interconnect pattern.3.3. Logic Block GranularityMost reconfigurable hardware is basedupon a set of computation structures thatare repeated to form an array. Thesestructures, commonly called logic blocksor cells, vary in complexity from a veryACM Computing Surveys, Vol. 34, No. 2, June 2002.180 K. Compton and S. HauckFig. 6. The functional unit from a Xilinx 6200 cellXilinx 1996.small and simple block that can calculatea function of only three inputs, to a structure that is essentially a 4bit ALU. Someof these block types are configurable, inthat the actual operation is determined bya set of loaded configuration data. Otherblocks are fixed structures, and the configurability lies in the connections betweenthem. The size and complexity of the basic computing blocks is referred to as theblocks granularity.An example of a very finegrained logicblock can be found in the Xilinx 6200 seriesof FPGAs Xilinx 1996. The functionalunit from one of these cells, as shown inFigure 6, can implement any twoinputfunction and some threeinput functions.However, although this type of architecture is useful for very finegrained bit manipulation, it can be too finegrained to efficiently implement many types of circuits,such as multipliers. Similarly, finite statemachines are frequently too complex toeasily map to a reasonable number ofvery finegrained logic blocks. However, finite state machines are also too dependentupon single bit values to be efficiently implemented in a very coarsegrained architecture. This type of circuit is more suitedto an architecture that provides moreconnections and computational power perlogic block, yet still provides sufficient capability for bitlevel manipulation.The logic cell in the Altera FLEX 10K architecture Altera 1998 is a finegrainedstructure that is somewhat coarser thanthe 6200. This architecture mainly consists of a single 4input LUT with aflipflop. Additionally, there is specializedcarrychain circuitry that helps to accelerate addition, parity, and other operationsthat use a carry chain. These types of logicblocks are useful for finegrained bitlevelmanipulation of data, as can frequently befound in encryption and image processingapplications. Also, because the cells arefinegrained, computation structures ofarbitrary bit widths can be created. Thiscan be useful for implementing datapathcircuits that are based on data widths notimplemented on the host processor 5 bitmultiply, 18 bit addition, etc. Reconfigurable hardware can not only take advantage of small bit widths, but also large datawidths. When a program uses bit widthsin excess of what is normally available ina host processor, the processor must perform the computations using a number ofextra steps in order to handle the full datawidth. A finegrained architecture wouldbe able to implement the full bit width in asingle step, without the fetching, decoding,and execution of additional instructions,as long as enough logic cells are available.A number of reconfigurable systems usea granularity of logic block that we categorize as mediumgrained Xilinx 1994Hauser and Wawrzynek 1997 Haynes andCheung 1998 Lucent 1998 Marshall et al.1999. For example, Garp Hauser andWawrzynek 1997 is designed to performa number of different operations on upto four 2bit inputs. Another mediumgrained structure was designed specifically to be embedded inside of a generalpurpose FPGA to implement multipliersof a configurable bit width Haynes andCheung 1998. The logic block used in themultiplier FPGA is capable of implementing a 44 multiplication, or cascaded intolarger structures. The CHESS architecture Marshall et al. 1999 also operateson 4bit values, with each of its cells acting as a 4bit ALU. Mediumgrained logicblocks may be used to implement datapathcircuits of varying bit widths, similar tothe finegrained structures. However, withthe ability to perform more complex operations of a greater number of inputs, thistype of structure can be used efficiently toimplement a wider variety of operations.ACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 181Fig. 7. One cell in the RaPiDI reconfigurable architecture Ebeling et al.1996. The registers, RAM, ALUs, and multiplier all operate on 16bit values.The multiplier outputs a 32bit result, split into the high 16 bits and the low16 bits. All routing lines shown are 16bit wide busses. The short parallellines on the busses represent configurable bus connectors.Very coarsegrained architectures areprimarily intended for the implementation of wordwidth datapath circuits. Because the logic blocks used are optimizedfor large computations, they will performthese operations much more quickly andconsume less chip area than a set ofsmaller cells connected to form the sametype of structure. However, because theircomposition is static, they are unableto leverage optimizations in the size ofoperands. For example, the RaPiD architecture Ebeling et al. 1996, shown inFigure 7, as well as the Chameleon architecture Chameleon 2000, are examples of this very coarsegrained type ofdesign. Each of these architectures is composed of wordsized adders, multipliers,and registers. If only three 1bit valuesare required, then the use of these architectures suffers an unnecessary area andspeed overhead, as all of the bits in the fullword size are computed. However, thesecoarsegrained architectures can be muchmore efficient than finegrained architectures for implementing functions closer totheir basic word size.An alternate form of a coarsegrainedsystem is one in which the logic blocksare actually very small processors, potentially each with its own instruction memory andor data values. The REMARC architecture Miyamori and Olukotun 1998is composed of an 8  8 array of 16bitprocessors. Each of these processors usesits own instruction memory in conjunctionwith a global program counter. This styleof architecture closely resembles a singlechip multiprocessor, although with muchsimpler component processors because thesystem is intended to be coupled with ahost processor. The RAW project Moritzet al. 1998 is a further example of a reconfigurable architecture based on a multiprocessor design.The granularity of the FPGA also hasa potential effect on the reconfigurationtime of the device. This is an importantissue for runtime reconfiguration, whichis discussed in further depth in a later section. A finegrained array has many configuration points to perform very small computations, and thus requires more databits during configuration.3.4. Heterogeneous ArraysIn order to provide greater performanceor flexibility in computation, some reconfigurable systems provide a heterogeneousstructure, where the capabilities of thelogic cells are not the same throughoutthe system. One use of heterogeneity inreconfigurable systems is to provide multiplier function blocks embedded withinthe reconfigurable hardware Haynes andACM Computing Surveys, Vol. 34, No. 2, June 2002.182 K. Compton and S. HauckCheung 1998 Chameleon 2000 Xilinx2001. Because multiplication is one of themore difficult computations to implementefficiently in a traditional FPGA structure, the custom multiplication hardwareembedded within a reconfigurable arrayallows a system to perform even that function well.Another use of heterogeneous structures is to provide embedded memoryblocks scattered throughout the reconfigurable hardware. This allows storage offrequently used data and variables, andallows for quick access to these valuesdue to the proximity of the memory tothe logic blocks that access it. Memorystructures embedded into the reconfigurable fabric come in two forms. The firstis simply the use of available LUTs asRAM structures, as can be done in theXilinx 4000 series Xilinx 1994 and VirtexXilinx 1999 FPGAs. Although makingthese very small blocks into a largerRAM structure introduces overhead to thememory system, it does provide local, variable width memory structures.Some architectures include dedicatedmemory blocks within their array, suchas the Xilinx Virtex series Xilinx 1999,2001 and Altera Altera 1998 FPGAs, aswell as the CS2000 RCP reconfigurablecommunications processor device fromChameleon Systems, Inc. Chameleon2000. These memory blocks have greaterperformance in large sizes than similarsized structures built from many smallLUTs. While these structures are somewhat less flexible than the LUTbasedmemories, they can also provide some customization. For example, the Altera FLEX10K FPGA Altera 1998 provides embedded memories that have a limited totalnumber of wires, but allow a tradeoff between the number of address lines and thedata bit width.When embedded memories are not usedfor data storage by a particular configuration, the area that they occupy doesnot necessarily have to be wasted. By using the address lines of the memory asfunction inputs and the values stored inthe memory as function outputs, logicalexpressions of a large number of inputscan be emulated Altera 1998 Cong andXu 1998 Wilton 1998 Heile and Leaver1999. In fact, because there may be morethan one value output from the memoryon a read operation, the memory structure may be able to perform multiple different computations one for each bit ofdata output, provided that all necessaryinputs appear on the address lines. In thismanner, the embedded RAM behaves thesame as a very large LUT. Therefore, embedded memory allows a programmer ora synthesis tool to perform a tradeoff between logic and memory usage in order toachieve higher area efficiency.Furthermore, a few of the commercialFPGA companies have announced plans toinclude entire microprocessors as embedded structures within their FPGAs. Alterahas demonstrated a preliminary ARM9based Excalibur device, which combinesreconfigurable hardware with an embedded ARM9 processor core Altera 2001.Meanwhile, Xilinx is working with IBM toinclude a PowerPC processor core withinthe VirtexII FPGA Xilinx 2000. By contrast, Adaptive Silicons focus is to providereconfigurable logic cores to customers forembedding in their own systemonachipSoC devices Adaptive 2001.3.5. Routing ResourcesInterconnect resources are provided in areconfigurable architecture to connect together the devices programmable logic elements. These resources are usually configurable, where the path of a signal isdetermined at compile or runtime ratherthan fabrication time. This flexible interconnect between logic blocks or computational elements allows for a wide varietyof circuit structures, each with their owninterconnect requirements, to be mappedto the reconfigurable hardware. For example, the routing for FPGAs is generally islandstyle, with logic surroundedby routing channels, which contain several wires, potentially of varying lengths.Within this type of routing architecture,however, there are still variations. Some ofthese differences include the ratio of wiresto logic in the system, how long each of theACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 183Fig. 8. Segmented left and hierarchical right routing structures. The whiteboxes are logic blocks, while the dark boxes are connection switches.wires should be, and whether they shouldbe connected in a segmented or hierarchical manner.A step in the design of efficient routing structures for FPGAs and reconfigurable systems therefore involves examining the logic vs. routing area tradeoffwithin reconfigurable architectures. Onegroup has argued that the interconnectshould constitute a much higher proportion of area in order to allow for successfulrouting under highlogic utilization conditions Takahara et al. 1998. However, forFPGAs, highLUT utilization may not necessarily be the most desirable situation,but rather efficient routing usage may beof more importance DeHon 1999. Thisis because the routing resources occupy amuch larger part of the area of an FPGAthan the logic resources, and therefore themost area efficient designs will be thosethat optimize their use of the routing resources rather than the logic resources.The amount of required routing does notgrow linearly with the amount of logicpresent therefore, larger devices requireeven greater amounts of routing per logicblock than small ones Trimberger et al.1997b.There are two primary methods to provide both local and global routing resources, as shown in Figure 8. The firstis the use of segmented routing Betz andRose 1999 Chow et al. 1999a. In segmented routing, short wires accommodatelocal communications traffic. These shortwires can be connected together usingswitchboxes to emulate longer wires. Frequently, segmented routing structuresalso contain longer wires to allow signals to travel efficiently over long distances without passing through a greatnumber of switches. Hierarchical routingAggarwal and Lewis 1994 Lai and Wang1997 Tsu et al. 1999 is the second methodto provide both local and global communication. Routing within a group or cluster of logic blocks is at the local level,only connecting within that cluster. Atthe boundaries of these clusters, however,longer wires connect the different clusterstogether. This is potentially repeated at anumber of levels. The idea behind the useof hierarchical structures is that, provideda good placement has been made onto thehardware, most communication should belocal and only a limited amount of communication will traverse long distances.Therefore, the wiring is designed to fit thismodel, with a greater number of local routing wires in a cluster than distance routingwires between clusters.Because routing can occupy a large partof the area of a reconfigurable device, thetype of routing used must be carefully considered. If the wires available are muchlonger than what is required to route a signal, the excess wire length is wasted. Onthe other hand, if the wires available aremuch shorter than necessary, the signalACM Computing Surveys, Vol. 34, No. 2, June 2002.184 K. Compton and S. HauckFig. 9. A traditional twodimensional islandstyle routing structure left and a onedimensional routing structure right. The white boxes represent logic elements.must pass through switchboxes that connect the short wires together into a longerwire, or through levels of the routing hierarchy. This induces additional delay andslows the overall operation of the circuit.Furthermore, the switchbox circuitry occupies area that might be better used foradditional logic or wires.There are a few alternatives to theislandstyle of routing resources. Systemssuch as RaPiD Ebeling et al. 1996 usesegmented busbased routing, where signals are full wordsized in width. This ismost common in the onedimensional typeof architecture, as discussed in the nextsection.3.6. OneDimensional StructuresMost current FPGAs are of the twodimensional variety, as shown in Figure 9.This allows for a great deal of flexibility,as any signal can be routed on a nearlyarbitrary path. However, providing thislevel of routing flexibility requires a greatdeal of routing area. It also complicatesthe placement and routing software, as thesoftware must consider a very large number of possibilities.One solution is to use a more onedimensional style of architecture, also depicted in Figure 9. Here, placement isrestricted along one axis. With a morelimited set of choices, the placement canbe performed much more quickly. Routingis also simplified, because it is generallyalong a single dimension as well, with theother dimension generally only used forcalculations requiring a shift operation.One drawback of the onedimensionalrouting is that if there are not enoughrouting resources in a particular area ofa mapped circuit, routing that circuit becomes actually more difficult than on atwodimensional array that provides morealternatives. A number of different reconfigurable systems have been designedin this manner. Both Garp Hauser andWawrzynek 1997 and Chimaera Haucket al. 1997 are structures that providecells that compute a small number of bitpositions, and a row of these cells together computes the full data word. Arow can only be used by a single configuration, making these designs one dimensional. In this manner, each configurationoccupies some number of complete rows.Although multiple narrowwidth computations can fit within a single row, thesestructures are optimized for wordbasedcomputations that occupy the entire row.The NAPA architecture Rupp et al. 1998is similar, with a full column of cells acting as the atomic unit for a configuration, as is PipeRench Cadambi et al. 1998Goldstein et al. 2000.In some systems, the computationblocks in a onedimensional structure operate on wordwidth values instead ofsingle bits. Therefore, busses are routedinstead of individual values. This alsodecreases the time required for routing,as the bits of a bus can be consideredtogether rather than as separate routes.As shown previously in Figure 7, RaPiDEbeling et al. 1996 is basically a onedimensional design that only includeswordwidth processing elements. The different computation units are organized ina single dimension along the horizontalACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 185Fig. 10. Mesh left and partial crossbar right interconnect topologies for multiFPGAsystems.axis. The general flow of information follows this layout, with the major routingbusses also laid out in a horizontal manner. Additionally, all routing is of wordsized values, and therefore all routing isof busses, not individual wires. A few vertical resources are included in the architecture to allow signals to transfer between busses, or to travel from a bus toa computation node. However, the majority of the routing in this architecture isonedimensional.3.7. MultiFPGA SystemsReconfigurable systems that are composedof multiple FPGA chips interconnectedon a single processing board have additional hardware concerns over singlechipsystems. In particular, there is a need foran efficient connection scheme betweenthe chips, as well as to external memoryand the system bus. This is to provide forcircuits that are too large to fit within asingle FPGA, but may be partitioned overthe multiple FPGAs available. A numberof different interconnection schemes havebeen explored Butts and Batcheller 1991Hauck et al. 1998a Hauck 1998 Khalid1999 including meshes and crossbars, asshown in Figure 10. A mesh connects thenearestneighbors in the array of FPGAchips. This allows for efficient communication between the neighbors, but mayrequire that some signals pass throughan FPGA simply to create a connectionbetween nonneighbors. Although this canbe done, and is quite possible, it uses valuable IO resources on the FPGA that formsthe routing bridge. One system that usesa mesh topology with additional boardlevel column and row busses is the P1system developed within the PAM projectVuillemin et al. 1996. This architectureuses a central array of 16 commercialFPGAs with connections to nearestneighbors. However, four 16bit row bussesand four 16bit column busses run thelength of the array and facilitate communication between nonneighbor FPGAs.A crossbar attempts to remove this problem by using special routingonly chipsto connect each FPGA potentially to anyother FPGA. The interchip delays aremore uniform, given that a signal travels the exact same distance to get fromone FPGA to another, regardless of wherethose FPGAs are located. However, acrossbar interconnect does not scale easily with an increase in the number ofFPGAs. The crossbar pattern of the chipsis fixed at fabrication of the multiFPGAboard. Variants on these two basic topologies attempt to remove some of the problems encountered in mesh and crossbartopologies Arnold et al. 1992 Vargheseet al. 1993 Buell et al. 1996 Vuilleminet al. 1996 Lewis et al. 1997 Khalid andRose 1998. One of these variants can befound in the Splash 2 system Arnold et al.1992 Buell et al. 1996. The predecessor,Splash 1, used a linear systolic communication method. This type of connectionwas found to work quite well for a variety of applications. However, this highlyconstrained communication model madesome types of computations difficult oreven impossible. Therefore, Splash 2 wasdesigned to include not only the linear connections of Splash 1 that were found tobe useful for many applications, but alsoa crossbar network to allow any FPGAACM Computing Surveys, Vol. 34, No. 2, June 2002.186 K. Compton and S. Hauckto communicate with any other FPGA onthe same board. For multiFPGA systems,because of the need for efficient communication between the FPGAs, determining the interchip routing topology is avery important step in the design process.More details on multiFPGA system architectures can be found elsewhere Hauck1998b Khalid 1999.3.8. Hardware SummaryThe design of reconfigurable hardwarevaries wildly from system to system. Thereconfigurable logic may be used as aconfigurable functional unit, or may bea multiFPGA standalone unit. Withinthe reconfigurable logic itself, the complexity of the core computational units,or logic blocks, vary from very simple toextremely complex, some implementinga 4bit ALU or even a 16  16 multiplication. These blocks are not requiredto be uniform throughout the array, asthe use of different types of blocks canadd highperformance functionality in thecase of specialized computation circuitry,or expanded storage in the case of embedded memory blocks. Routing resourcesalso offer a variety of choices, primarily inamount, length, and organization of thewires. Systems have been developed thatfit into many different points within thisdesign space, and no true best systemhas yet been agreed upon.4. SOFTWAREAlthough reconfigurable hardware hasbeen shown to have significant performance benefits for some applications, itmay be ignored by application programmers unless they are able to easily incorporate its use into their systems. Thisrequires a software design environmentthat aids in the creation of configurationsfor the reconfigurable hardware. This software can range from a software assistin manual circuit creation to a completeautomated circuit design system. Manualcircuit description is a powerful methodfor the creation of highquality circuit designs. However, it requires a great deal ofbackground knowledge of the particularFig. 11. Three possible design flows for algorithmimplementation on a reconfigurable system. Greystages indicate manual effort on the part of the designer, while white stages are done automatically.The dotted lines represent paths to improve the resulting circuit. It should be noted that the middledesign cycle is only one of the possible compromisesbetween automatic and manual design.reconfigurable system employed, as wellas a significant amount of design time. Onthe other end of the spectrum, an automatic compilation system provides a quickand easy way to program for reconfigurable systems. It therefore makes the useof reconfigurable hardware more accessible to general application programmers,but quality may suffer.Both for manual and automatic circuit creation, the design process proceedsthrough a number of distinct phases, asindicated in Figure 11. Circuit specification is the process of describing the functions that are to be placed on the reconfigurable hardware. This can be done assimply as by writing a program in C thatrepresents the functionality of the algorithm to be implemented in hardware. Onthe other hand, this can also be as complexas specifying the inputs, outputs, and operation of each basic building block in thereconfigurable system. Between these twomethods is the specification of the circuitusing generic complex components, suchas adders and multipliers, which will bemapped to the actual hardware later inthe design process. For descriptions in ahighlevel language HLL, such as CCor Java, or ones using complex buildingblocks, this code must be compiled intoa netlist of gatelevel components. Forthe HLL implementations, this involvesACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 187Fig. 12. A wide function implemented with multipleLUTs.generating computational components toperform the arithmetic and logic operations within the program, and separatestructures to handle the program control,such as loop iterations and branching operations. Given a structural description,either generated from a HLL or specifiedby the user, each complex structure is replaced with a network of the basic gatesthat perform that function.Once a detailed gate or elementleveldescription of the circuit has been created,these structures must be translated to theactual logic elements of the reconfigurablehardware. This stage is known as technology mapping, and is dependent uponthe exact target architecture. For a LUTbased architecture, this stage partitionsthe circuit into a number of small subfunctions, each of which can be mapped to asingle LUT Brown et al. 1992a Abouzeidet al. 1993 SangiovanniVincentelli et al.1993 Hwang et al. 1994 Chang et al.1996 Hauck and Agarwal 1996 Yi andJhon 1996 Chowdhary and Hayes 1997Lin et al. 1997 Cong and Wu 1998 Panand Lin 1998 Togawa et al. 1998 Conget al. 1999. Some architectures, such asthe Xilinx 4000 series Xilinx 1994, contain multiple LUTs per logic cell. TheseLUTs can be used either separately to generate small functions, or together to generate some widerinput functions Inuaniand Saul 1997 Cong and Hwang 1998.By taking advantage of multiple LUTs andthe internal routing within a single logiccell, functions with more inputs than canbe implemented using a single LUT canefficiently be mapped into the FPGA architecture. Figure 12 shows one exampleof a wide function mapped to a multiLUTFPGA logic cell.For reconfigurable structures that include embedded memory blocks, the mapping stage may also consider using thesememories as logic units when they are notbeing used for data storage. The memoriesact as very large LUTs, where the numberof inputs is equal to the number of addresslines. In order to use these memories aslogic, the mapping software must analyzehow much of the memory blocks are actually used as storage in a given mapping. Itmust then determine which are availablein order to implement logic, and what partor parts of the circuit are best mapped tothe memory Cong and Xu 1998 Wilton1998.After the circuit has been mapped, theresulting blocks must be placed onto thereconfigurable hardware. Each of theseblocks is assigned to a specific locationwithin the hardware, hopefully close tothe other logic blocks with which it communicates. As FPGA capacities increase,the placement phase of circuit mappingbecomes more and more time consuming.Floorplanning is a technique that canbe used to alleviate some of this cost.A floorplanning algorithm first partitionsthe logic cells into clusters, where cellswith a large amount of communicationare grouped together. These clusters arethen placed as units onto regions of thereconfigurable hardware. Once this globalplacement is complete, the actual placement algorithm performs detailed placement of the individual logic blocks withinthe boundaries assigned to the clusterSankar and Rose 1999.The use of a floorplanning tool is particularly helpful for situations where thecircuit structure being mapped is of a datapath type. Large computational components or macros that are found in datapathcircuits are frequently composed of highlyregular logic. These structures are placedas entire units, and their component cellsare restricted to the floorplanned locationShi and Bhatia 1997 Emmert and Bhatia1999. This encourages the placer to find avery regular placement of these logic cells,resulting in a higher performance layoutof the circuit. Another technique for themapping and placement of datapath elements is to perform both of these stepssimultaneously Callahan et al. 1998.ACM Computing Surveys, Vol. 34, No. 2, June 2002.188 K. Compton and S. HauckThis method also exploits the regularity of the datapath elements to generate mappings and placements quickly andefficiently.Floorplanning is also important whendealing with hierarchically structured reconfigurable designs. In these architectures, the available resources have beengrouped by the logic or routing hierarchyof the hardware. Because performance isbest when routing lengths are minimized,the cells to be placed should be groupedsuch that cells that require a great dealof communication or which are on a critical path are placed together within a logiccluster on the hardware Krupnova et al.1997 Senouci et al. 1998.After floorplanning, the individual logicblocks are placed into specific logic cells.One algorithm that is commonly usedis the simulated annealing techniqueShahookar and Mazumder 1991 Betzand Rose 1997 Sankar and Rose 1999.This method takes an initial placementof the system, which can be generatedpseudo randomly, and performs a seriesof moves on that layout. A move is simply the changing of the location of a single logic cell, or the exchanging of locations of two logic cells. These moves areattempted one at a time using randomtarget locations. If a move improves thelayout, then the layout is changed to reflect that move. If a move is considered tobe undesirable, then it is only accepted asmall percentage of the time. Accepting afew bad moves helps to avoid any localminima in the placement space. Other algorithms exist that are not so based onrandom movements Gehring and Ludwig1996, although this searches a smallerarea of the placement space for a solution,and therefore may be unable to find a solution which meets performance requirements if a design uses a high percentageof the reconfigurable resources.Finally, the different reconfigurablecomponents comprising the applicationcircuit are connected during the routingstage. Particular signals are assigned tospecific portions of the routing resourcesof the reconfigurable hardware. This canbecome difficult if the placement causesmany connected components to be placedfar from one another, as the signals thattravel long distances use more routingresources than those that travel shorterones. A good placement is therefore essential to the routing process. One ofthe challenges in routing for FPGAs andreconfigurable systems is that the available routing resources are limited. In general hardware design, the goal is to minimize the number of routing tracks usedin a channel between rows of computationunits, but the channels can be made aswide as necessary. In reconfigurable systems, however, the number of availablerouting tracks is determined at fabricationtime, and therefore the routing softwaremust perform within these boundaries.Thus, FPGA routing concentrates on minimizing congestion within the availabletracks Brown et al. 1992b McMurchieand Ebeling 1995 Alexander and Robins1996 Chan and Schlag 1997 Lee and Wu1997 Thakur et al. 1997 Wu and MarekSadowska 1997 Swartz et al. 1998 Namet al. 1999. Because routing is one ofthe more timeintensive portions of thedesign cycle, it can be helpful to determine if a placed circuit can be routedbefore actually performing the routingstep. This quickly informs the designerif changes need to be made to the layoutor a larger reconfigurable structure is required Wood and Rutenbar 1997 Swartzet al. 1998.Each of the design phases mentionedabove may be implemented either manually or automatically using compiler tools.The operation of some of these individualsteps are described in greater depth in thefollowing sections.4.1. HardwareSoftware PartitioningFor systems that include both reconfigurable hardware and a traditional microprocessor, the program must first be partitioned into sections to be executed onthe reconfigurable hardware and sectionsto be executed in software on the microprocessor. In general, complex control sequences such as variablelength loops aremore efficiently implemented in software,ACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 189while fixed datapath operations may bemore efficiently executed in hardware.Most compilers presented for reconfigurable systems generate only the hardware configuration for the system, ratherthan both hardware and software. In somecases, this is because the reconfigurablehardware may not be coupled with a hostprocessor, so only a hardware configuration is necessary. For cases where reconfigurable hardware does operate alongsidea host microprocessor, some systems currently require that the hardware compilation be performed separately from the software compilation, and special functionsare called from within the software inorder to configure and control the reconfigurable hardware. However, this requireseffort on the part of the designer to identify the sections that should be mappedto hardware, and to translate these intospecial hardware functions. In order tomake the use of the reconfigurable hardware transparent to the designer, the partitioning and programming of the hardware should occur simultaneously in asingle programming environment.For compilers that manage both thehardware and software aspects of application design, the hardwaresoftware partitioning can be performed either manually,or automatically by the compiler itself.When the partitioning is performed bythe programmer, compiler directives areused to mark sections of program code forhardware compilation. The NAPA C language Gokhale and Stone 1998 providespragma statements to allow a programmer to specify whether a section of code isto be executed in software on the Fixed Instruction Processor FIP, or in hardwareon the Adaptive Logic Processor ALP.Cardoso and Neto 1999 present anothercompiler that requires the user to specifyusing information gained through the useof profiling tools which areas of code tomap to the reconfigurable hardware.Alternately, the hardwaresoftware partitioning can be done automaticallyChichkov and Almeida 1997 Kress et al.1997 Callahan et al. 2000 Li et al. 2000a.In this case, the compiler will use costfunctions based upon the amount of acceleration gained through the executionof a code fragment in hardware to determine whether the cost of configurationis overcome by the benefits of hardwareexecution.4.2. Circuit SpecificationIn order to use the reconfigurable hardware, designers must somehow be able tospecify the operation of their custom circuits. Before highlevel compilation toolsare developed for a specific reconfigurablesystem, this is done through hand mapping of the circuit, where the designerspecifies the operation of the componentsin the configurable system directly. Here,the designers utilize the basic buildingblocks of the reconfigurable system to create the desired circuit. This style of circuit specification is primarily useful onlywhen a software frontend for circuit design is unavailable, or for the design ofsmall circuits or circuits with very highperformance requirements. This is dueto the great amount of time involved inmanual circuit creation. However, for circuits that can be reasonably hand mapped,this provides potentially the smallest andfastest implementation.Because not all designers can be intimately familiar with every reconfigurablearchitecture, some design tools abstractthe specifics of the target architecture.Creating a circuit using a structural design language involves describing a circuit using building blocks such as gates,flipflops and latches Bellows and Hutchings 1998 Gehring and Ludwig 1998Hutchings et al. 1999. The compiler thenmaps these modules to one or more basic components of the architecture of thereconfigurable system. Structural VHDLis one example of this type of programming, and commercial tools are available for compiling from this languageinto vendorspecific FPGAs Synplicity1999.However, these two methods requirethat the designer possess either an intimate knowledge of the targeted reconfigurable hardware, or at least a working knowledge of the concepts involvedACM Computing Surveys, Vol. 34, No. 2, June 2002.190 K. Compton and S. Hauckin hardware design. In order to allowa greater number of software developersto take advantage of reconfigurable computing, tools that allow for behavioralcircuit descriptions are being developed.These systems trade some area and performance quality for greater flexibility andease of use.Behavioral circuit design is similar tosoftware design because the designer indicates the steps a hardware subsystem must go through in order to perform the desired computation rather thanthe actual composition of the circuit.These behavioral descriptions can be either in a generic hardware descriptionlanguage such as VHDL or Verilog, or ageneralpurpose highlevel language suchas CC or Java. The eventual goal ofthis type of compilation is to allow usersto write programs in commonly used languages that compile equally well, without modification, to both a traditionalsoftware executable and to an executablewhich leverages reconfigurable hardware.Working towards this direction,Transmogrifier C Galloway 1995 allows a subset of the C language to beused to describe hardware circuits. Whilemultiplication, division, pointers, arrays,and a few other C language specifics arenot supported, this system provides abehavioral method of circuit descriptionusing a primitive form of the C language.Similarly, the C programming environment used for the P1 system Vuilleminet al. 1996 provides a hybrid method ofdescription, using a combination of behavioral and structural design. SynopsysCoCentric compiler Synopsys 2000,which can be targeted to the Xilinx Virtexseries of FPGA, uses SystemC to providefor behavioral compilation of CCwith the assistance of a set of additionalhardwaredefining classes. Other compilers, such as Nimble Li et al. 2000a andthe Garp compiler Callahan et al. 2000,are fully behavioral C compilers, handlingthe full set of the ANSI C language.Although behavioral description, andHLL description in particular, providesa convenient method for the programming of reconfigurable systems, it doessuffer from the drawback that it tends toproduce larger and slower designs thanthose generated by a structural description or handmapping. Behavioral descriptions can leave many aspects of the circuit unspecified. For example, a compilerthat encounters a while loop must generate complicated control structures in order to allow for an unspecified numberof iterations. Also, in many HLL implementations, optimizations based upon thebit width of operands cannot be performed.The compiler is generally unaware ofany applicationspecific limitations on theoperand size it only sees the programmers choice of data format in the program.Problems such as these might be solvedthrough additional programmer effort toreplace while loops whenever possiblewith for loops, and to use compiler directives to indicate exact sizes of operandsGalloway 1995 Gokhale and Stone 1998.This method of hardware design falls between structural description and behavioral description in complexity, becausealthough the programmers do not needto know a great deal about hardware design, they are required to follow additional guidelines that are not required forsoftwareonly implementations.4.3. Circuit LibrariesThe use of circuit or macro librariescan greatly simplify and speed the design process. By predesigning commonlyused structures such as adders, multipliers, and counters, circuit creationfor configurable systems becomes largelythe assembly of highlevel components,and only applicationspecific structuresrequire detailed design. The actual architecture of the reconfigurable devicecan be abstracted, provided only librarycomponents are used, as these lowleveldetails will already have been encapsulated within the library structures. Although the users of the circuit librarymay not know the intricacies of the destination architecture, they are still ableto make use of architecturespecific optimizations, such as specialized carryACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 191chains. This is because designers veryfamiliar with the details of the target architecture create the components within acircuit library. They can take advantageof architecture specifics when creating themodules to make these components fasterand smaller than a designer unfamiliarwith the architecture likely would. Anadded benefit of the architecture abstraction is that the use of library componentscan also facilitate design migration fromone architecture to another, because designers are not required to learn a newarchitecture, but only to indicate the newtarget for the library components. However, this does require that a circuit library contain implementations for morethan one architecture.One method for using library components is to simply instantiate themwithin an HDL design Xilinx 1997 Altera1999. However, circuit libraries can alsobe used in general language compilers by comparing the dataflow graph ofthe application to the dataflow graphsof the library macros Cadambi andGoldstein 1999. If a dataflow representation of a macro matches a portion ofthe application graph, the corresponding macro is used for that part of theconfiguration.Another benefit of circuit design withlibrary macros is that of fast compilation. Because the library structures mayhave been premapped, preplaced, and prerouted at least within the macro boundaries, the actual compile time is reducedto the time required to place the librarycomponents and route between them. Forexample, fast configuration was one ofthe main motivations for the creation oflibraries for circuit design in the DISCreconfigurable image processing systemHutchings 1997.4.4. Circuit GeneratorsCircuit generators fulfill a role similar tocircuit libraries, in that they provide optimized highlevel structures for use withinlarger applications. Again, designers arenot required to understand the lowleveldetails of particular architectures. However, circuit generators create semicustomized highlevel structures automatically at compile time, as opposed to circuitlibraries that only provide static structures. For example, a circuit generator cancreate an adder structure of the exact bitwidth required by the designer, whereas acircuit library is likely to contain a limitednumber of adder structures, none of whichmay be of the correct size. Circuit generators are therefore more flexible than circuit libraries because of the customizationallowed.Some circuit generators, such asMacGen Yasar et al. 1996, are executedat the command line using custom description files to generate physical designlayout data files. Newer circuit generators, however, are functions or methodscalled from highlevel language programs.PAMBlox Mencer et al. 1998, for example, is a set of circuit generators executedin C that generate structures for usewith the PCI Pamette reconfigurableprocessing board. The circuit generatorpresented by Chu et al. 1998 containsa number of Java classes to allow aprogrammer to generate arbitrarily sizedarithmetic and logical components for acircuit. Although the examples presentedin that paper were mapped to a Xilinx4000 series FPGA, the generator usesarchitecture specific libraries for modulegeneration. The target architecture cantherefore be changed through the useof a different design library. The CarryLookAhead circuit generator describedby Stohmann and Barke 1996 is alsoretargetable, because it maps to anFPGA logic cell architecture defined bythe user.One drawback of the circuit generatorsis that they depend on a regular logicand routing structure. Hierarchical routing structures such as those present inthe Xilinx 6200 series Xilinx 1996 andspecialized heterogeneous logic blocks arefrequently not accounted for. Therefore,some optimized features of a particular architecture may be unused. For these cases,a circuit macro from a library may provide a more highly optimized structurethan one created with a circuit generator,ACM Computing Surveys, Vol. 34, No. 2, June 2002.192 K. Compton and S. Hauckprovided that the library macro fits theneeds of the application.4.5. Partial EvaluationFunctions that are to be implemented onthe reconfigurable array should occupyas little area as possible, so as to maximize the number of functions that can bemapped to the hardware. This, combinedwith the minimization of the delay incurred by each circuit, increases the overall acceleration of the application. Partialevaluation is the process of reducing hardware requirements for a circuit structurethrough optimization based upon knownstatic inputs. Specifically, if an input isknown to be constant, that value can potentially be propagated through one ormore gates in the structure at compiletime, and only the portions of a circuit thatdepend on timevarying inputs need to bemapped to the reconfigurable structure.One example of the usefulness of thisoperation is that of constant coefficientmultipliers. If one input to a multiplieris constant, a multiplier object can be reduced from a generalpurpose multiplierto a set of additions with staticlengthshifts between them corresponding to thelocations of 1s in the binary constant.This type of reduction leads to a lowerarea requirement for the circuit, and potentially higher performance due to fewergate delays encountered on the criticalpath. Partial evaluation can also be performed in conjunction with circuit generation, where the constants passed to thegenerator function are used to simplifythe created hardware circuit Wang andLewis 1997 Chu et al. 1998. Other examples of this type of optimization for specificalgorithms include the partial evaluationof DES encryption circuits Leonard andMangioneSmith 1997, and the partialevaluation of constant multipliers andfixed polynomial division circuits Payne1997.4.6. Memory AllocationAs with traditional software programs, itmay be necessary in reconfigurable computing to allocate memories to hold variables and other data. Offchip memoriesmay be added to the reconfigurable system. Alternately, if a reconfigurable system includes memory blocks embeddedinto the reconfigurable logic, these may beused, provided that the storage requirements do not surpass the available embedded memory. If multiple offchip memoriesare available to a reconfigurable system,variables used in parallel should be placedinto different memory structures, suchthat they can be accessed simultaneouslyGokhale and Stone 1999. When smallerembedded memory units are used, largermemories can be created from the smallerones. However, in this case, it is desirable to ensure that each smaller memory is close to the computation that mostrequires its contents Babb et al. 1999.As mentioned earlier, the small embedded memories that are not allocated fordata storage may be used to perform logicfunctions.4.7. ParallelizationOne of the benefits of reconfigurable computing is the ability to execute multiple operations in parallel. In cases wherecircuits are specified using a structuralhardware description language, the userspecifies all structures and timing, andtherefore either implicitly or explicitlyspecifies any parallel operation. However,for behavioral and HLL descriptions, thereare two methods to incorporate parallelism manual parallelization throughspecial instructions or compiler directives, and automatic parallelization by thecompiler.To manually incorporate parallelismwithin an application, the programmercan specifically mark sections of codethat should run as parallel threads, anduse similar operations to those used intraditional parallel compilers Cronquistet al. 1998 Gokhale and Stone 1998.For example, a signalwait technique canbe used to perform synchronization ofthe different threads of the computation.The RaPiDB language Cronquist et al.1998 is one that uses this methodology.ACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 193Although the NAPA C compiler Gokhaleand Stone 1998 requires programmersto mark the areas of code for executingthe host processor and the reconfigurablehardware in parallel, it also detects andexploits finegrained parallelism withincomputations destined for the reconfigurable hardware.Automatic parallelization of inner loopsis another common technique in reconfigurable hardware compilers to attemptto maximize the use of the reconfigurable hardware. The compiler will select the innermost loop level to be completely unrolled for parallel execution inhardware, potentially creating a heavily pipelined structure Cronquist et al.1998 Weinhardt and Luk 1999. For thesecases, outer loops may not have multiple iterations executing simultaneously.Any loop reordering to improve the parallelism of the circuit must be done by theprogrammer. However, some compiler systems have taken this procedure a step further and focus on the parallelization of allloops within the program, not just the inner loops Wang and Lewis 1997 Budiuand Goldstein 1999. This type of compilergenerates a control flow graph based uponthe entire program source code. Loop unrolling is used in order to increase theavailable parallelism, and the graph isthen used to schedule parallel operationsin the hardware.4.8. MultiFPGA System SoftwareWhen reconfigurable systems use morethan one FPGA to form the completereconfigurable hardware, there are additional compilation issues to deal withHauck and Agarwal 1996. The designmust first be partitioned into the different FPGA chips Hauck 1995 Acock andDimond 1997 Vahid 1997 Brasen andSaucier 1998 Khalid 1999. This is generally done by placing each highly connected portions of a circuit into a singlechip. MultiFPGA systems have a limitednumber of IO pins that connect the chipstogether, and therefore their use must beminimized in the overall circuit mapping.Also, by minimizing the amount of routingrequired between the FPGAs, the number of paths with a high interchip delay is reduced, and the circuit may havean overall higher performance. Similarly,those sections of the circuit that require ashort delay time must be placed upon thesame chip. Global placement then determines which of the actual FPGAs in themultiFPGA system will contain each ofthe partitions.After the circuit has been partitionedinto the different FPGA chips, the connections between the chips must berouted Mak and Wong 1997 Ejnioui andRanganathan 1999. A global routing algorithm determines at a high level theconnections between the FPGA chips. Itfirst selects a region of output pins on thesource FPGA for a given signal, and determines which if any routing switchesor additional FPGAs the signal mustpass through to get to the destinationFPGA. Detailed routing and pin assignment SlimaneKade et al. 1994 Hauckand Borriello 1997 Mak and Wong 1997Ejnioui and Ranganathan 1999 are thenused to assign signals to traces on an existing multiFPGA board, or to create tracesfor a multiFPGA board that is to be created specifically to implement the givencircuit.Because multiFPGA systems use interchip connections to allow the circuit partitions to communicate, they frequently require a higher proportion of IO resourcesvs. logic in each chip than is normally required in singleFPGA use. For this reason, some research has focused on methods to allow pins of the FPGAs to be reusedfor multiple signals. This procedure is referred to as Virtual Wires Babb et al.1993 Agarwal 1995 Selvidge et al. 1995,and allows for a flexible tradeoff betweenlogic and IO within a given multiFPGAsystem. Signals are multiplexed onto asingle wire by using multiple virtual clockcycles, one per multiplexed signal, withina user clock cycle, thus pipelining the communication. In this manner, the IO requirements of a circuit can be reduced,while the logic requirements because ofthe added circuitry used for the multiplexing are increased.ACM Computing Surveys, Vol. 34, No. 2, June 2002.194 K. Compton and S. Hauck4.9. Design TestingAfter compilation, an application needsto be tested for correct operation before deployment. For hardware configurations that have been generated frombehavioral descriptions, this is similarto the debugging of a software application. However, structurally and manually created circuits must be simulatedand debugged with techniques based uponthose from the design of general hardware circuits. For these structures, simulation and debugging are critical not onlyto ensure proper circuit operation, butalso to prevent possible incorrect connections from causing a short within the circuit, which can damage the reconfigurablehardware.There are several different methods ofobserving the behavior of a configurationduring simulation. The contents of memory structures within the design can beviewed, modified, or saved. This allows onthefly customization of the simulated execution environment of the reconfigurablehardware, as well as a method for examining the computation results. The inputand output values of circuit structures andsubstructures can also be viewed either ona generated schematic drawing or with atraditional waveform output. By examining these values, the operation of the circuit can be verified for correctness, andconflicts on individual wires can be seen.A number of simulation and debuggingsoftware systems have been developedthat use some or all of these techniquesArnold et al. 1992 Buell et al. 1996Gehring and Ludwig 1996 Lysaght andStockwood 1996 Bellows and Hutchings1998 Hutchings et al. 1999 McKay andSingh 1999 Vasilko and Cabanis 1999.4.10. Software SummaryReconfigurable hardware systems requiresoftware compilation tools to allow programmers to harness the benefits ofreconfigurable computing. On one endof the spectrum, circuits for reconfigurable systems can be designed manually, leveraging all applicationspecific andarchitecturespecific optimizations available to generate a highperformance application. However, this requires a greatdeal of time and effort on the part of the designer. At the opposite end of the spectrumis fully automatic compilation of a highlevel language. Using the automatic tools,a software programmer can transparentlyutilize the reconfigurable hardware without the need for direct intervention. Thecircuits created using this method, whilequickly and easily created, are generallylarger and slower than manually createdversions. The actual tools available forcompilation onto reconfigurable systemsfall at various points within this range,where many are partially automated butrequire some amount of manual aid. Circuit designers for reconfigurable systemstherefore face a tradeoff between the easeof design and the quality of the finallayout.5. RUNTIME RECONFIGURATIONFrequently, the areas of a program thatcan be accelerated through the use ofreconfigurable hardware are too numerous or complex to be loaded simultaneously onto the available hardware. Forthese cases, it is beneficial to be ableto swap different configurations in andout of the reconfigurable hardware asthey are needed during program executionFigure 13. This concept is known as runtime reconfiguration RTR.Runtime reconfiguration is based uponthe concept of virtual hardware, which issimilar to virtual memory. Here, the physical hardware is much smaller than thesum of the resources required by eachof the configurations. Therefore, insteadof reducing the number of configurationsthat are mapped, we instead swap themin and out of the actual hardware as theyare needed. Because runtime reconfiguration allows more sections of an application to be mapped into hardware thancan be fit in a nonruntime reconfigurable system, a greater portion of theprogram can be accelerated. This providespotential for an overall improvement inperformance.ACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 195Fig. 13. Applications which are too large to entirely fit on the reconfigurablehardware can be partitioned into two or more smaller configurations thatcan occupy the hardware at different times.During a single programs execution,configurations are swapped in and outof the reconfigurable hardware. Some ofthese configurations will likely require access to the results of other configurations.Configurations that are active at different periods in time therefore must be provided with a method to communicate withone another. Primarily, this can be donethrough the use of registers Ebeling et al.1996 Cadambi et al. 1998 Rupp et al.1998 Scalera and Vazquez 1998, the contents of which can remain intact betweenreconfigurations. This allows one configuration to store a value, and a later configuration to read back that value for use infurther computations. An alternative forreconfigurable systems that do not includestateholding devices is to write the resultback to registers or memory external to thereconfigurable array, which is then readback by successive configurations Haucket al. 1997.There are a few different configurationmemory styles that can be used with reconfigurable systems. A single context device is a serially programmed chip thatrequires a complete reconfiguration in order to change any of the programming bits.A multicontext device has multiple layersof programming bits, each of which canbe active at a different point in time. Devices that can be selectively programmedwithout a complete reconfiguration arecalled partially reconfigurable. These different types of configuration memory aredescribed in more detail later. An advantage of the multicontext FPGA over asingle context architecture is that it allows for an extremely fast context switchon the order of nanoseconds, whereas thesingle context may take milliseconds ormore to reprogram. The partially reconfigurable architecture is also more suited toruntime reconfiguration than the singlecontext, because small areas of the arraycan be modified without requiring that theentire logic array be reprogrammed.For all of these runtime reconfigurablearchitectures, there are also a number ofcompilation issues that are not encountered in systems that only configure atthe beginning of an application. For example, runtime reconfigurable systemsare able to optimize based on values thatare known only at runtime. Furthermore,compilers must consider the runtime reconfigurability when generating the different circuit mappings, not only to beaware of the increase in timemultiplexedcapacity, but also to schedule reconfigurations so as to minimize the overhead thatthey incur. These software issues, as wellas an overview of methods to perform fastconfiguration, will be explored in the sections that follow.5.1. Reconfigurable ModelsTraditional FPGA structures have beensingle context, only allowing one fullchipconfiguration to be loaded at a time. However, designers of reconfigurable systemshave found this style of configurationto be too limiting or slow to efficientlyimplement runtime reconfiguration. TheACM Computing Surveys, Vol. 34, No. 2, June 2002.196 K. Compton and S. HauckFig. 14. The different basic models of reconfigurable computing single context, multicontext, and partially reconfigurable. Each of these designs is shown performing a reconfiguration.following discussion defines the single context device, and further considers newerFPGA designs multicontext and partiallyreconfigurable, along with their impacton runtime reconfiguration.5.1.1. Single Context. Current singlecontext FPGAs are programmed usinga serial stream of configuration information. Because only sequential accessis supported, any change to a configuration on this type of FPGA requires acomplete reprogramming of the entirechip. Although this does simplify thereconfiguration hardware, it does incura high overhead when only a small partof the configuration memory needs to bechanged. Many commercial FPGAs are ofthis style, including the Xilinx 4000 series Xilinx 1994, the Altera Flex10Kseries Altera 1998, and Lucents Orcaseries Lucent 1998. This type of FPGAis therefore more suited for applicationsthat can benefit from reconfigurable computing without runtime reconfiguration.A single context FPGA is depicted inFigure 14.In order to implement runtime reconfiguration onto a single context FPGA, theconfigurations must be grouped into contexts, and each full context is swapped inand out of the FPGA as needed. Becauseeach of these swap operations involve reconfiguring the entire FPGA, a good partitioning of the configurations between contexts is essential in order to minimize thetotal reconfiguration delay. If all the configurations used within a certain time period are present in the same context, noreconfiguration will be necessary. However, if a number of successive configurations are each partitioned into differentcontexts, several reconfigurations will beneeded, slowing the operation of the runtime reconfigurable system.5.1.2. Multicontext. A multicontext FPGAincludes multiple memory bits for eachprogramming bit location DeHon 1996Trimberger et al. 1997a Scalera andVazquez 1998 Chameleon 2000. Thesememory bits can be thought of as multiple planes of configuration information,as shown in Figure 14. One plane of configuration information can be active at agiven moment, but the device can quicklyswitch between different planes, or contexts, of alreadyprogrammed configurations. In this manner, the multicontext device can be considered a multiplexed set ofsingle context devices, which requires thata context be fully reprogrammed to perform any modification. This system doesallow for the background loading of a context, where one plane is active and in execution while an inactive place is in theprocess of being programmed. Figure 15shows a multicontext memory bit, as usedin Trimberger et al. 1997a. A commercial product that uses this technique is theCS2000 RCP series from Chameleon, IncChameleon 2000. This device providesACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 197Fig. 15. A fourbit multicontexted programming bitTrimberger et al. 1997a. P0P3 are the storedprogramming bits, while C0C3 are the chipwidecontrol lines that select the context to program oractivate.two separate planes of programming information. At any given time, one of theseplanes is controlling current execution onthe reconfigurable fabric, and the otherplane is available for background loadingof the next needed configuration.Fast switching between contexts makesthe grouping of the configurations intocontexts slightly less critical, because ifa configuration is on a different contextthan the one that is currently active, it canbe activated within an order of nanoseconds, as opposed to milliseconds or longer.However, it is likely that the number ofcontexts within a given program is largerthan the number of contexts available inthe hardware. In this case, the partitioning again becomes important to ensurethat configurations occurring in close temporal proximity are in a set of contextsthat are loaded into the multicontext device at the same time. More aspects involving temporal partitioning for single andmulticontext devices will be discussed inthe section on compilers for runtime reconfigurable systems.5.1.3. Partially Reconfigurable. In somecases, configurations do not occupy the fullreconfigurable hardware, or only a part ofa configuration requires modification. Inboth of these situations, a partial reconfiguration of the array is required, ratherthan the full reconfiguration required bya single or multicontext device. In a partially reconfigurable FPGA, the underlying programming bit layer operates likea RAM device. Using addresses to specify the target location of the configurationdata allows for selective reconfigurationof the array. Frequently, the undisturbedportions of the array may continue execution, allowing the overlap of computationwith reconfiguration. This has the benefitof potentially hiding some of the reconfiguration latency.When configurations do not require theentire area available within the array, anumber of different configurations maybe loaded into unused areas of the hardware at different times. Since only partof the array is reconfigured at a givenpoint in time, the entire array does not require reprogramming. Additionally, someapplications require the updating of onlya portion of a mapped circuit, while therest should remain intact, as shown inFigure 14. For example, in a filtering operation in signal processing, a set of constant values that change slowly over timemay be reinitialized to a new value, yet theoverall computation in the circuit remainsstatic. Using this selective reconfigurationcan greatly reduce the amount of configuration data that must be transferred to theFPGA. Several runtime reconfigurablesystems are based upon a partially reconfigurable design, including ChimaeraHauck et al. 1997, PipeRench Cadambiet al. 1998 Goldstein et al. 2000, NAPARupp et al. 1998, and the Xilinx 6200 andVirtex FPGAs Xilinx 1996, 1999.Unfortunately, since address information must be supplied with configuration data, the total amount of informationtransferred to the reconfigurable hardware may be greater than what is requiredwith a single context design. This makesa full reconfiguration of the entire arrayslower than the single context version.However, a partially reconfigurable designis intended for applications in which thesize of the configurations is small enoughthat more than one can fit on the availablehardware simultaneously. Plus, as we discuss in subsequent sections, a number offast configuration methods have been explored for partially reconfigurable systemsin order to help reduce the configurationdata traffic requirements.5.1.4. Pipeline Reconfigurable. A modification of the partially reconfigurableFPGA design is one in which the partialACM Computing Surveys, Vol. 34, No. 2, June 2002.198 K. Compton and S. HauckFig. 16. A timeline of the configuration and reconfiguration of pipeline stages on a pipelinereconfigurable FPGA. This example shows three physical pipeline stages implementing fivevirtual pipeline stages Cadambi et al. 1998.reconfiguration occurs in increments ofpipeline stages. This style of reconfigurable hardware is called pipeline reconfigurable, or sometimes a striped FPGALuk et al. 1997b Cadambi et al. 1998Deshpande and Somani 1999 Goldsteinet al. 2000. Each stage is configured as awhole. This is primarily used in datapathstyle computations, where more pipelinestages are used than can fit simultaneously on available hardware. Figure 16shows an example of a pipeline reconfigurable array implementing more pipelinestages than can fit on the available hardware. In a pipelinereconfigurable FPGA,there are two primary execution possibilities. Either the number of hardwarepipeline stages available is greater thanor equal to the number of pipeline stagesof the designed circuit virtual pipelinestages, or the number of virtual pipelinestages will exceed the number of hardwarepipeline stages. The first case is straightforward the circuit is simply mapped tothe array, and some hardware stages maygo unused. The second case is more complex and is the one that requires runtime reconfiguration. The pipeline stagesare configured one by one, from the startof the pipeline, through the end of theavailable hardware stages steps 1, 2,and 3 in Figure 16. After each stage isprogrammed, it begins computation. Inthis manner, the configuration of a stageis exactly one step ahead of the flow ofdata. Once the hardware pipeline hasbeen completely filled, reuse of the hardware pipeline stages begins. Configuration of the next virtual stage begins atthe first pipeline location in the hardware step 4, overwriting the first virtualpipeline stage. The reconfiguration of thehardware pipeline stages continues untilthe last virtual pipeline stage has beenprogrammed step 7, at which point thefirst stage of the virtual pipeline is againconfigured onto the hardware for the nextdata set. These structures also allow forthe overlap of configuration and execution,as one pipeline stage is configured whilethe others are executing. Therefore, N1data values are processed each time thevirtual pipeline is fully traversed on anNstage hardware system.5.2. RunTime Partial EvaluationOne of the advantages that a runtime reconfigurable device has over a system thatis only programmed at the beginning ofan application is the ability to performhardware optimizations based upon values determined at runtime. Partial evaluation was already discussed in this articlein reference to compilation optimizationsfor general reconfigurable systems. Runtime partial evaluation allows for the further exploitation of constants becausethe configurations can be modified basednot only on completely static values, butalso those that change slowly over timeBurns et al. 1997 Luk et al. 1997a Payne1997 Wirthlin and Hutchings 1997 Chuet al. 1998 McKay and Singh 1999. Thisgives reconfigurable circuits the potentialto achieve an even higher performancethan an ASIC, which must retain generality in these situations. The circuit in theACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 199reconfigurable system can be customizedto the application at a given time, ratherthan to the application as a category. Forexample, where an ASIC may have toinclude a generic multiplier, a reconfigurable system could instantiate a constantcoefficient multiplier that changes overtime. Additionally, partial evaluation canbe used in encryption systems Leonardand MangioneSmith 1997. A keyspecificreconfigurable encrypter or decrypter isoptimized for the particular key beingused, but retains the ability to use morethan one key over the lifetime of the hardware unlike a keyspecialized ASIC orduring actual runtime.Although partial evaluation can be usedto reduce the overall area requirementsof a circuit by removing potentially extraneous hardware within the implementation, occasionally it is preferable to reserve sufficient area for the largest case,and have all mappings occupy that area.This allows the partially evaluated portion of a given configuration to be reconfigured, while leaving the remainder of thecircuit intact. For example, if a constantcoefficient multiplier within a larger configuration requires that the constant bechanged, only the area occupied by themultiplier requires reconfiguration. Thisis true even if the new constant coefficientmultiplier is a larger structure than theprevious one, because the reserved areafor it is based upon the largest possibilityMcKay and Singh 1999. Although partial evaluation does not minimize the areaoccupied by the circuit in this case, thespeed of configuration is improved by making the multiplier a modular replaceablecomponent. Additionally, this method retains the speed benefits of partial reconfiguration because it still minimizes thelogic and routing actually used to implement the structure.5.3. Compilation and ConfigurationSchedulingFor some reconfigurable systems, a configuration requires programming the reconfigurable hardware only at the startof its execution. On the other hand, in aruntime reconfigurable system, the circuits loaded on the hardware change overtime. If the user must specify by handthe loading and execution of the circuitsin the reconfigurable hardware, then thecompilers must include methods to indicate these operations. JHDL Bellows andHutchings 1998 Hutchings et al. 1999 isone such compiler. It provides for the instantiation of configurations through theuse of Java constructors, and the removalof the circuits from the hardware by usinga destructor on the circuit objects. This allows the programmer to indicate exactlythe loading pattern of the configurations.Alternately, the compiler can automatethe use of the runtime reconfigurablehardware. For a single context or multicontext device, configurations must betemporally partitioned into a number ofdifferent full contexts of configurationinformation. This involves determiningwhich configurations are likely to be usednear in time to one another, and whichconfigurations are able to fit together ontothe reconfigurable hardware. Ideally, thenumber of reconfigurations that are to beperformed is minimized. By reducing thenumber of reconfigurations, the proportion of time spent in reconfiguration compared to the time spent in useful computation is reduced.The problem of forming and scheduling single and multiconfiguration contexts for use in single context or multicontext FPGA designs has been discussed bya number of groups Chang and MarekSadowska 1998 Trimberger 1998 Liu andWong 1999 Purna and Bhatia 1999 Liet al. 2000a. In particular, a single circuit that is too large to fit within the reconfigurable hardware may be partitionedover time to form a sequential set of configurations. This involves examining thecontrol flow graph of the circuit and dividing the circuit into distinct computationnodes. The nodes can then be grouped together within contexts, based upon theirproximity to one another within the flowcontrol graph. If possible, those configurations that are used in quick succession will be placed within the same group.These groups are finally mapped into fullACM Computing Surveys, Vol. 34, No. 2, June 2002.200 K. Compton and S. Hauckcontexts, to be loaded into the reconfigurable hardware at runtime. Nimble Liet al. 2000a is one of the compilers thatperform this type of operation. This compiler focuses on mapping core loops withinC code to reconfigurable hardware. Hardware models for the candidate loops thatwill fit within the reconfigurable hardwareare first extracted from the C application.Then these loops are grouped into individual configurations using a partitioningmethod in order to encourage the hardware loops that are used in close temporalproximity to be mapped to the same configuration, reducing configuration overhead.For partially reconfigurable designs, thecompiler must determine a good placement in order to prevent configurationsthat are used together in close temporalproximity from occupying the same resources. Again, through minimizing thenumber of reconfigurations, the overallperformance of the system is increased, asconfiguration is a slow process Li et al.2000b. An alternative approach, whichallows the final placement of a configuration to be determined at runtime, is alsodiscussed within the Fast Configurationsection of this article.5.4. Fast ConfigurationBecause runtime reconfigurable systemsinvolve reconfiguration during programexecution, the reconfiguration must bedone as efficiently and as quickly as possible. This is in order to ensure that theoverhead of the reconfiguration does noteclipse the benefit gained by hardware acceleration. Stalling execution of either thehost processor or the reconfigurable hardware because of configuration is clearlyundesirable. In the DISC II system, from25 Wirthlin and Hutchings 1996 to 71Wirthlin and Hutchings 1995 of execution time is spent in reconfiguration, whilein the UCLA ATR work this figure can riseto over 98.5 MangioneSmith 1999. Ifthe delays caused by reconfiguration arereduced, performance can be greatly increased. Therefore, fast configuration is animportant area of research for runtime reconfigurable systems.There are a number of different tacticsfor reducing the configuration overhead.First, loading of the configurations can betimed such that the configuration overlaps as much as possible with the execution of instructions by the host processor.Second, compression techniques can be introduced to decrease the amount of configuration data that must be transferred tothe system. Third, specialized hardwarecan be used to adjust the physical location of configurations at runtime based onwhere the free area on the hardware is located at any given time. Finally, the actualprocess of transferring the data from thehost processor to the reconfigurable hardware can be modified to include a configuration cache, which would provide a fasterreconfiguration.5.4.1. Configuration Prefetching. Performance is improved when the actual configuration of the hardware is overlappedwith computations performed by thehost processor, because programming thereconfigurable hardware requires frommilliseconds to seconds to accomplish.Overlapping configuration and executionprevents the host processor from stallingwhile it is waiting for the configuration tofinish, and hides the configuration timefrom the program execution. Configuration prefetching Hauck 1998a attemptsto leverage this overlap by determiningwhen to initiate reconfiguration of thehardware in order to maximize overlapwith useful computation on the hostprocessor. It also seeks to minimize thechance that a configuration will be prefetched falsely, overwriting the configuration that is actually used next.5.4.2. Configuration Compression. Unfortunately, there will always be cases inwhich the configuration overheads cannotbe successfully hidden using a prefetching technique. This can occur when a conditional branch occurs immediately before the use of a configuration, potentiallymaking a 100 correct prefetch prediction impossible, or when multiple configurations or contexts must be loaded inquick succession. In these cases, the delayincurred is minimized when the amountACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 201of data transferred from the host processor to the reconfigurable array is minimized. Configuration compression can beused to compact this configuration information Hauck et al. 1998b Hauck andWilson 1999 Li and Hauck 1999 Dandalisand Prasanna 2001.One form of configuration compressionhas already been implemented in a commercial system. The Xilinx 6200 series ofFPGA Xilinx 1996 contains wildcardinghardware, which provides a method to program multiple logic cells with a single address and data value. This is accomplishedby setting a special register to indicatewhich of the address bits should behaveas dontcare values, resolving to multiple addresses for configuration. For example, suppose two configuration addresses,00010 and 00110, are both to be programmed with the same value. By settingthe wildcard register to 00100, the addressvalue sent is interpreted as 00X10 andboth these locations are programmed using either of the two addresses above in asingle operation. Hauck et al. 1998b discuss the benefits of this hardware, whileLi and Hauck 1999 cover a potential extension to the concept, where dont carevalues in the configuration stream can beused to allow areas with similar but notidentical configuration data values to alsobe programmed simultaneously.Within partially reconfigurable systems, there is an added potential to compress effectively the amount of data sentto the reconfigurable hardware. A configuration can possibly reuse configuration information already present on thearray, such that only the areas differingin configuration values must be reprogrammed. Therefore, configuration timecan be reduced through the identificationof these common components and the calculation of the incremental configurationsthat must be loaded Luk et al. 1997aShirazi et al. 1998.Alternately, similar operations can begrouped together to form a single configuration that contains extra control circuitry in order to implement the variousfunctions within the group Kastrup et al.1999. By creating larger configurationsout of groups of smaller configurations,the configuration overhead of partial reconfiguration is reduced because more operations can be present on chip simultaneously. However, there are some areaand execution penalties imposed by thismethod, creating a tradeoff between reduced reconfiguration overhead and fasterexecution with a smaller area.5.4.3. Relocation and Defragmentation inPartially Reconfigurable Systems. Partiallyreconfigurable systems have the advantage over single context systems in thatthey allow a new configuration to be written to the programmable logic while theconfigurations not occupying that samearea remain intact and available for futureuse. Because these configurations will nothave to be reconfigured onto the array,and because the programming of a single configuration can require the transferof far less configuration data than the programming of an entire context, a partiallyreconfigurable system can incur less configuration overhead than a single contextFPGA.However, inefficiencies can arise if twopartial configurations are supposed tobe located at overlapping physical locations on the FPGA. If these configurations are repeatedly used one after another, they must be swapped in and out ofthe array each time. This type of conflictcould negate much of the benefit achievedby partially reconfigurable systems. Abetter solution to this problem is to allowthe final placement of the configurationsto occur at runtime, allowing for runtime relocation of those configurationsLi et al. 2000b Compton et al. 2002.Using relocation, a new configurationmay be placed onto the reconfigurablearray where it will cause minimum conflict with other needed configurations already present on the hardware. A number of different systems support runtimerelocation, including Chimaera Haucket al. 1997, Garp Hauser and Wawrzynek1997, and PipeRench Cadambi et al.1998 Goldstein et al. 2000.Even with relocation, partially reconfigurable hardware can still suffer from someACM Computing Surveys, Vol. 34, No. 2, June 2002.202 K. Compton and S. Hauckplacement conflicts that could be avoidedby using an additional hardware optimization. Over time, as a partially reconfigurable device loads and unloads configurations, the location of the unoccupiedarea on the array is likely to become fragmented, similar to what occurs in memory systems when RAM is allocated anddeallocated. There may be enough emptyarea on the device to hold an incomingconfiguration, but it may be distributedthroughout the array. A configuration normally requires a contiguous region of thechip, so it would have to overwrite a portion of a valid configuration in order tobe placed onto the reconfigurable hardware. A system that incorporates the ability to perform defragmentation of the reconfigurable array, however, would be ableto consolidate the unused area by moving valid configurations to new locationsDiessel and El Gindy 1997 Compton et al.2002. This area can then be used by incoming configurations, potentially without overwriting any of the moved configurations.5.4.4. Configuration Caching. Because agreat deal of the delay caused by configuration is due to the distance betweenthe host processor and the reconfigurablehardware, as well the reading of theconfiguration data from a file or mainmemory, a configuration cache can potentially reduce the costs of reconfigurationDeshpande et al. 1999 Li et al. 2000b.By storing the configurations in fast memory near to the reconfigurable array, thedata transfer during reconfiguration is accelerated, and the overall time requiredis reduced. Additionally, a special configuration cache can allow for specialized direct output to the reconfigurable hardwareCompton et al. 2000. This output canleverage the close proximity of the cacheby providing highbandwidth communications that would facilitate wide parallelloading of the configuration data, furtherreducing configuration times.5.5. Potential Problems with RTRPartial reconfiguration involves selectively programming portions of the reconfigurable array. However, in many architectures, there are some routing resourcesthat traverse long distances, and may traverse areas allocated to different configurations. Care must be taken such thatdifferent configurations do not attempt todrive to these wires simultaneously, asmultiple drivers to a wire can potentiallydamage the hardware. Therefore, systemssuch as the Xilinx 6200 Xilinx 1996 andChimaera Hauck et al. 1997 have specially designed routing resources that prevent multiple drivers. LEGO Chow et al.1999b includes an additional control signal preventing conflicts during the span oftime between startup and actual programming of the hardware.An additional difficulty in using runtime reconfigurable systems occurs whenthe host processor runs multiple threadsor processes. These threads or processesmay each have their own sets of configurations that are to be mapped to thereconfigurable hardware. Issues such asthe correct use of memory protection andvirtual memory must be considered during memory accesses by the reconfigurablehardware Chien and Byun 1999 Jacoband Chow 1999 Jean et al. 1999. Another problem can occur when one threador process configures the hardware, whichis then reconfigured by a different threador process. Threads and processes must beprevented from incorrectly calling hardware functions that no longer appearon the reconfigurable hardware. This requires that the state of the reconfigurablehardware be set to dirty on a main processor context switch, or reloaded withthe correct configuration context.Partially reconfigurable systems mustalso protect against interprocess or interthread conflicts within the array. Evenif each application has ensured thattheir own configurations can safely coexist, a combination of configurations fromdifferent applications reintroduces thepossibility of inadvertently causing anelectrical short within the reconfigurablehardware. This particular issue can besolved through the use of an architecturethat does not have bad configurations,such as the 6200 series Xilinx 1996 andACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 203Chimaera Hauck et al. 1997. The potential for this type of conflict also introduces the possibility of extremely destructive configurations that can destroy thesystems underlying hardware.5.6. RunTime Reconfiguration SummaryWe have discussed the benefits of usingruntime reconfiguration to increase thebenefits gained through reconfigurablecomputing. Different configurations maybe used at different phases of a programsexecution, customizing the hardware notonly for the application, but also for thedifferent stages of the application. Runtime reconfiguration also allows configurations larger than the available reconfigurable hardware to be implemented,as these circuits can be split into several smaller ones that are used in succession. Because of the delays associated withconfiguration, this style of computing requires that reconfiguration be performedin a very efficient manner. Multicontextand partially reconfigurable FPGAs areboth designed to improve the time required for reconfiguration. Hardware optimizations, such as wildcarding, runtimerelocation, and defragmentation, further decrease configuration overhead ina partially reconfigurable design. Software techniques to enable fast configuration, including prefetching and incremental configuration calculation, were alsodiscussed.6. CONCLUSIONReconfigurable computing is becoming animportant part of research in computerarchitectures and software systems. Byplacing the computationally intense portions of an application onto the reconfigurable hardware, that application can begreatly accelerated. This is because reconfigurable computing combines many of thebenefits of both software and ASIC implementations. Like software, the mappedcircuit is flexible, and can be changed overthe lifetime of the system or even thelifetime of the application. Similar to anASIC, reconfigurable systems provide amethod to map circuits into hardware. Reconfigurable systems therefore have thepotential to achieve far greater performance than software as a result of bypassing the fetchdecodeexecute cycle of traditional microprocessors as well as possiblyexploiting a greater degree of parallelism.Reconfigurable hardware systems comein many forms, from a configurable functional unit integrated directly into a CPU,to a reconfigurable coprocessor coupledwith a host microprocessor, to a multiFPGA standalone unit. The level of coupling, granularity of computation structures, and form of routing resources are allkey points in the design of reconfigurablesystems. The use of heterogeneous structures can also greatly add to the overallperformance of the final design.Compilation tools for reconfigurablesystems range from simple tools that aidin the manual design and placement ofcircuits, to fully automatic design suitesthat use program code written in a highlevel language to generate circuits and thecontrolling software. The variety of toolsavailable allows designers to choose between manual and automatic circuit creation for any or all of the design steps.Although automatic tools greatly simplifythe design process, manual creation is stillimportant for performancedriven applications. Circuit libraries and circuit generators are additional software tools thatenable designers to quickly create efficientdesigns. These tools attempt to aid thedesigner in gaining the benefits of manual design without entirely sacrificing theease of automatic circuit creation.Finally, runtime reconfiguration provides a method to accelerate a greater portion of a given application by allowing theconfiguration of the hardware to changeover time. Apart from the benefits of addedcapacity through the use of virtual hardware, runtime reconfiguration also allowsfor circuits to be optimized based on runtime conditions. In this manner, performance of a reconfigurable system can approach or even surpass that of an ASIC.Reconfigurable computing systems haveshown the ability to accelerate programACM Computing Surveys, Vol. 34, No. 2, June 2002.204 K. Compton and S. Hauckexecution greatly, providing a highperformance alternative to softwareonlyimplementations. However, no one hardware design has emerged as the clear pinnacle of reconfigurable design. Althoughgeneralpurpose FPGA structures havestandardized into LUTbased architectures, groups designing hardware for reconfigurable computing are currently alsoexploring the use of heterogeneous structures and wordwidth computational elements. Those designing compiler systemsface the task of improving automatic design tools to the point where they mayachieve mappings comparable to manualdesign for even highperformance applications. Within both of these research categories lies the additional topic of runtime reconfiguration. While some workhas been done in this field as well, research must continue in order to be ableto perform faster and more efficient reconfiguration. Further study into each ofthese topics is necessary in order to harness the full potential of reconfigurablecomputing.REFERENCESABOUZEID, P., BABBA, P., DE PAULET, M. C., AND SAUCIER,G. 1993. Inputdriven partitioning methodsand application to synthesis on tablelookupbased FPGAs. IEEE Trans. Comput. Aid. Des.Integ. Circ. Syst. 12, 7, 913925.ACOCK, S. J. B. AND DIMOND, K. R. 1997. Automaticmapping of algorithms onto multiple FPGASRAM Modules. FieldProgrammable Logic andApplications, W. Luk, P. Y. K. Cheung, andM. Glesner, Eds. Lecture Notes in ComputerScience, vol. 1304, SpringerVerlag, Berlin,Germany, 255264.ADAPTIVE SILICON, INC. 2001. MSA 2500 Programmable Logic Cores. Adaptive Silicon, Inc.,Los Gatos, CA.AGARWAL, A. 1995. VirtualWires A Technologyfor Massive MultiFPGA Systems. Availableonline at httpwww.ikos.comproductsvirtualwires.ps.AGGARWAL, A. AND LEWIS, D. 1994. Routing architectures for hierarchical field programmablegate arrays. In Proceedings of the IEEE International Conference on Computer Design, 475478.ALEXANDER, M. J. AND ROBINS, G. 1996. Newperformancedriven FPGA routing algorithms.IEEE Trans. CAD Integ. Circ. Syst. 15, 12, 15051517.ALTERA CORPORATION. 1998. Data Book. AlteraCorporation, San Jose, CA.ALTERA CORPORATION. 1999. Altera MegaCoreFunctions. Available online at httpwww.altera.comhtmltoolsmegacore.html. Altera Corporation, San Jose, CA.ALTERA CORPORATION. 2001. Press Release Altera Unveils First Complete SystemonaProgrammableChip Solution at EmbeddedSystems Conference. Altera Corporation, SanJose, CA.ANNAPOLIS MICROSYSTEMS, INC. 1998. Wildfire Reference Manual. Annapolis Microsystems, Inc,Annapolis, MD.ARNOLD, J. M., BUELL, D. A., AND DAVIS, E. G. 1992.Splash 2. In Proceedings of the ACM Symposiumon Parallel Algorithms and Architectures, 316324.BABB, J., RINARD, M., MORITZ, C. A., LEE, W., FRANK,M., BARUA, R., AND AMARASINGHE, S. 1999. Parallelizing applications into silicon. IEEE Symposium on FieldProgrammable Custom Computing Machines, 7080.BABB, J., TESSIER, R., AND AGARWAL, A. 1993. Virtual wires Overcoming pin limitations in FPGAbased logic emulators. In IEEE Workshopon FPGAs for Custom Computing Machines,142151.BELLOWS, P. AND HUTCHINGS, B. 1998. JHDLAnHDL for reconfigurable systems. IEEE Symposium on FieldProgrammable Custom Computing Machines, 175184.BETZ, V. AND ROSE, J. 1997. VPR A new packing,placement and routing tool for FPGA research.Lecture Notes in Computer Science 1304FieldProgrammable Logic and Applications. W. Luk,P. Y. K. Cheung, and M. Glesner, Eds. SpringerVerlag, Berlin, Germany, 213222.BETZ, V. AND ROSE, J. 1999. FPGA routing architecture Segmentation and buffering to optimizespeed and density. ACMSIGDA InternationalSymposium on FPGAs, 5968.BRASEN, D. R., AND SAUCIER, G. 1998. Using conestructures for circuit partitioning into FPGApackages. IEEE Trans. CAD Integ. Circ. Syst. 17,7, 592600.BROWN, S. D., FRANCIS, R. J., ROSE, J., AND VRANESIC,Z. G. 1992a. FieldProgrammable Gate Arrays, Kluwer Academic Publishers, Boston, MA.BROWN, S., ROSE, J., AND VRANESIC, Z. G. 1992b. Adetailed router for fieldprogrammable gate arrays. IEEE Trans. Comput. Aid. Desi. 11, 5, 620628.BUDIU, M. AND GOLDSTEIN, S. C. 1999. Fast compilation for pipelined reconfigurable fabrics.ACMSIGDA International Symposium onFPGAs, 195205.BUELL, D., ARNOLD, S. M., AND KLEINFELDER, W. J.1996. SPLASH 2 FPGAs in a Custom Computing Machine, IEEE Computer Society Press, LosAlamitos, CA.ACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 205BURNS, J., DONLIN, A., HOGG, J., SINGH, S., ANDDE WIT, M. 1997. A dynamic reconfiguration runtime system. IEEE Symposiumon FieldProgrammable Custom ComputingMachines, 6675.BUTTS, M. AND BATCHELLER, J. 1991. Method of using electronically reconfigurable logic circuits.US Patent 5,036,473.CADAMBI, S. AND GOLDSTEIN, S. C. 1999. CPR Aconfiguration profiling tool. IEEE Symposiumon FieldProgrammable Custom ComputingMachines, 104113.CADAMBI, S., WEENER, J., GOLDSTEIN, S. C., SCHMIT, H.,AND THOMAS, D. E. 1998. Managing pipelinereconfigurable FPGAs. ACMSIGDA International Symposium on FPGAs, 5564.CALLAHAN, T. J., CHONG, P., DEHON, A., AND WAWRZYNEK,J. 1998. Fast Module Mapping and Placementfor Datapaths in FPGAs. ACMSIGDA International Symposium on FPGAs, 123132.CALLAHAN, T. J., HAUSER, J. R., AND WAWRZYNEK, J.2000. The Garp architecture and C compiler.IEEE Comput. 3, 4, 6269.CARDOSO, J. M. P. AND NETO, H. C. 1999. Macrobased hardware compilation of JavaTM bytecodes into a dynamic reconfigurable computingsystem. IEEE Symposium on FieldProgrammable Custom Computing Machines, 211.CHAMELEON SYSTEMS, INC. 2000. CS2000 AdvanceProduct Specification. Chameleon Systems, Inc.,San Jose, CA.CHAN, P. K. AND SCHLAG, M. D. F. 1997. Acceleration of an FPGA router. IEEE Symposiumon FieldProgrammable Custom ComputingMachines, 175181.CHANG, D. AND MAREKSADOWSKA, M. 1998. Partitioning sequential circuits on dynamically reconfigurable FPGAs. ACMSIGDA InternationalSymposium on FPGAs, 161167.CHANG, S. C., MAREKSADOWSKA, M., AND HWANG, T. T.1996. Technology mapping for TLU FPGAsbased on decomposition of binary decisiondiagrams. IEEE Trans. CAD Integ. Circ. Syst. 15,10, 12261248.CHICHKOV, A. V. AND ALMEIDA, C. B. 1997. An hardwaresoftware partitioning algorithm for custom computing machines. Lecture Notes in Computer Science 1304FieldProgrammable Logicand Applications. W. Luk, P. Y. K. Cheung,and M. Glesner, Eds. SpringerVerlag, Berlin,Germany, 274283.CHIEN, A. A. AND BYUN, J. H. 1999. Safe and protected execution for the morphAMRM reconfigurable processor. IEEE Symposium on FieldProgrammable Custom Computing Machines,209221.CHOW, P., SEO, S. O., ROSE, J., CHUNG, K., PAEZMONZON,G., AND RAHARDJA, I. 1999a. The design of anSRAMbased fieldprogrammable Gate ArrayPart I Architecture. IEEE Trans. VLSI Syst. 7,2, 191197.CHOW, P., SEO, S. O., ROSE, J., CHUNG, K., PAEZMONZON,G., AND RAHARDJA, I. 1999b. The design of anSRAMbased fieldprogrammable Gate ArrayPart II Circuit Design and Layout. IEEE Trans.VLSI Syst. 7, 3, 321330.CHOWDHARY, A. AND HAYES, J. P. 1997. Generalmodeling and technologymapping technique forLUTbased FPGAs. ACMSIGDA InternationalSymposium on FPGAs, 4349.CHU, M., WEAVER, N., SULIMMA, K., DEHON, A., ANDWAWRZYNEK, J. 1998. Object oriented circuitgenerators in Java. IEEE Symposium on FieldProgrammable Custom Computing Machines,158166.COMPTON, K., COOLEY, J., KNOL, S., AND HAUCK,S. 2000. Configuration relocation and defragmentation for FPGAs, Northwestern University Technical Report, Available online at httpwww.ece.nwu.edukatipublications.html.COMPTON, K., LI, Z., COOLEY, J., KNOL, S., AND HAUCK,S. 2002. Configuration relocation and defragmentation for runtime reconfigurable computing. IEEE Trans. VLSI Syst., to appear.CONG, J. AND HWANG, Y. Y. 1998. Boolean matching for complex PLBs in LUTbased FPGAs withapplication to architecture evaluation. ACMSIGDA International Symposium on FPGAs,2734.CONG, J. AND WU, C. 1998. An efficient algorithmfor performanceoptimal FPGA technology mapping with retiming. IEEE Trans. CAD Integr.Circ. Syst. 17, 9, 738748.CONG, J., WU, C., AND DING, Y. 1999. Cut rankingand pruning enabling a general and efficientFPGA mapping solution. ACMSIGDA International Symposium on FPGAs, 2935.CONG, J. AND XU, S. 1998. Technology mappingfor FPGAs with embedded memory blocks.ACMSIGDA International Symposium onFPGAs, 179188.CRONQUIST, D. C., FRANKLIN, P., BERG, S. G.,AND EBELING, C. 1998. Specifying and compiling applications for RaPiD. IEEE Symposium on FieldProgrammable Custom Computing Machines, 116125.DANDALIS, A. AND PRASANNA, V. K. 2001. Configuration compression for FPGAbased embedded systems. ACMSIGDA International Symposiumon FieldProgrammable Gate Arrays, 173182.DEHON, A. 1996. DPGA Utilization and Application. ACMSIGDA International Symposium onFPGAs, 115121.DEHON, A. 1999. Balancing interconnect and computation in a reconfigurable computing array or,why you dont really want 100 LUT utilization. ACMSIGDA International Symposiumon FPGAs, 6978.DESHPANDE, D., SOMANI, A. K., AND TYAGI, A.1999. Configuration caching vs data cachingfor striped FPGAs. ACMSIGDA InternationalSymposium on FPGAs, 206214.ACM Computing Surveys, Vol. 34, No. 2, June 2002.206 K. Compton and S. HauckDIESSEL, O. AND EL GINDY, H. 1997. Runtime compaction of FPGA designs. Lecture Notes inComputer Science 1304FieldProgrammableLogic and Applications. W. Luk, P. Y. K.Cheung, M. Glesner, Eds. SpringerVerlag,Berlin, Germany, 131140.DOLLAS, A., SOTIRIADES, E., AND EMMANOUELIDES, A.1998. Architecture and design of GE1, A FCCMfor golomb ruler derivation. IEEE Symposium on FieldProgrammable Custom Computing Machines, 4856.EBELING, C., CRONQUIST, D. C., AND FRANKLIN, P.1996. RaPiDReconfigurable pipelined datapath. Lecture Notes in Computer Science1142FieldProgrammable Logic Smart Applications, New Paradigms and Compilers. R. W.Hartenstein, M. Glesner, Eds. SpringerVerlag,Berlin, Germany, 126135.EJNIOUI, A. AND RANGANATHAN, N. 1999. Multiterminal net routing for partial crossbarbasedmultiFPGA systems. ACMSIGDA International Symposium on FPGAs, 176184.ELBIRT, A. J. AND PAAR, C. 2000. An FPGA implementation and performance evaluation ofthe serpent block cipher. ACMSIGDA International Symposium on FPGAs, 3340.EMMERT, J. M. AND BHATIA, D. 1999. A methodologyfor fast FPGA floorplanning. ACMSIGDA International Symposium on FPGAs, 4756.ESTRIN, G., BUSSEL, B., TURN, R., AND BIBB, J. 1963.Parallel processing in a restructurable computer system. IEEE Trans. Elect. Comput. 747755.GALLOWAY, D. 1995. The transmogrifier C hardware description language and compiler forFPGAs. IEEE Symposium on FPGAs for CustomComputing Machines, 136144.GEHRING, S. AND LUDWIG, S. 1996. The trianus system and its application to custom computing.Lecture Notes in Computer Science 1142FieldProgrammable Logic Smart Applications, NewParadigms and Compilers. R. W. Hartensteinand M. Glesner, Eds. SpringerVerlag, Berlin,Germany, 176184.GEHRING, S. W. AND LUDWIG, S. H. M. 1998. Fastintegrated tools for circuit design with FPGAs.ACMSIGDA International Symposium onFPGAs, 133139.GOKHALE, M. B. AND STONE, J. M. 1998. NAPA CCompiling for a hybrid RISCFPGA architecture. IEEE Symposium on FieldProgrammableCustom Computing Machines, 126135.GOKHALE, M. B. AND STONE, J. M. 1999. Automaticallocation of arrays to memories in FPGA processors with multiple memory banks. IEEE Symposium on FieldProgrammable Custom Computing Machines, 6369.GOLDSTEIN, S. C., SCHMIT, H., BUDIU, M., CADAMBI,S., MOE, M., AND TAYLOR, R. 2000. PipeRenchA Reconfigurable Architecture and Compiler,IEEE Computer, vol. 33, No. 4.GRAHAM, P. AND NELSON, B. 1996. Genetic algorithms in software and in hardwareA performance analysis of workstations and customcomputing machine implementations. IEEESymposium on FPGAs for Custom ComputingMachines, 216225.HAUCK, S. 1995. MultiFPGA systems. Ph.D. dissertation, Univ. Washington, Dept. of C.S.E.HAUCK, S. 1998a. Configuration prefetch for single context reconfigurable coprocessors. ACMSIGDA International Symposium on FPGAs,6574.HAUCK, S. 1998b. The roles of FPGAs in reprogrammable systems. Proc. IEEE 86, 4, 615638.HAUCK, S. AND AGARWAL A. 1996. Software technologies for reconfigurable systems. Dept. ofECE Technical Report, Northwestern Univ.Available online at httpwww.ee.washington.edufacultyhauckpublications.html.HAUCK, S. AND BORRIELLO, G. 1997. Pin assignmentfor multiFPGA systems. IEEE Trans. Comput.Aid. Desi. Integ. Circ. Syst. 16, 9, 956964.HAUCK, S., BORRIELLO, G., AND EBELING, C. 1998a.Mesh routing topologies for multiFPGA systems. IEEE Trans. VLSI Syst. 6, 3, 400408.HAUCK, S., FRY, T. W., HOSLER, M. M., AND KAO, J. P.1997. The Chimaera reconfigurable functionalunit. IEEE Symposium on FieldProgrammableCustom Computing Machines, 8796.HAUCK, S., LI, Z., AND SCHWABE, E. 1998b. Configuration compression for the Xilinx XC6200 FPGA.IEEE Symposium on FieldProgrammable Custom Computing Machines, 138146.HAUCK, S. AND WILSON, W. D. 1999. Runlengthcompression techniques for FPGA configurations. Dept. of ECE Technical Report, Northwestern Univ. Available online at httpwww.ee.washington.edu faculty hauck publications.html.HAUSER, J. R. AND WAWRZYNEK, J. 1997. Garp AMIPS processor with a reconfigurable coprocessor. IEEE Symposium on FieldProgrammableCustom Computing Machines, 1221.HAYNES, S. D. AND CHEUNG, P. Y. K. 1998. A reconfigurable multiplier array for video imageprocessing tasks, suitable for embedding in anFPGA structure. IEEE Symposium on FieldProgrammable Custom Computing Machines,226234.HEILE, F. AND LEAVER, A. 1999. Hybrid productterm and LUT based architectures using embedded memory blocks. ACMSIGDA InternationalSymposium on FPGAs, 1316.HUANG, W. J., SAXENA, N., AND MCCLUSKEY, E. J.2000. A reliable LZ data compressor onreconfigurable coprocessors. IEEE Symposiumon FieldProgrammable Custom ComputingMachines, 249258.HUELSBERGEN, L. 2000. A representation for dynamic graphs in reconfigurable hardwareand its application to fundamental graphACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 207algorithms. ACMSIGDA International Symposium on FPGAs, 105115.HUTCHINGS, B. L. 1997. Exploiting reconfigurability through domainspecific systems.Lecture Notes in Computer Science 1304FieldProgrammable Logic and Applications.W. Luk, P. Y. K. Cheung, and M. Glesner,Eds. SpringerVerlag, Berlin, Germany, 193202.HUTCHINGS, B., BELLOWS, P., HAWKINS, J., HEMMERT,S., NELSON, B., AND RYTTING, M. 1999. A CADsuite for highperformance FPGA design. IEEESymposium on FieldProgrammable CustomComputing Machines, 1224.HWANG, T. T., OWENS, R. M., IRWIN, M. J., ANDWANG, K. H. 1994. Logic synthesis for fieldprogrammable gate arrays. IEEE Trans. Comput. Aid. Des. Integ. Circ. Syst. 13, 10, 12801287.INUANI, M. K. AND SAUL, J. 1997. Technology mapping of heterogeneous LUTbased FPGAs. Lecture Notes in Computer Science 1304FieldProgrammable Logic and Applications. W. Luk,P. Y. K. Cheung, and M. Glesner, Eds. SpringerVerlag, Berlin, Germany, 223234.JACOB, J. A. AND CHOW, P. 1999. Memory interfacingand instruction specification for reconfigurableprocessors. ACMSIGDA International Symposium on FieldProgrammable Gate Arrays, 145154.JEAN, J. S. N., TOMKO, K., YAVAGAL, V., SHAH, J.,AND COOK R. 1999. Dynamic reconfigurationto support concurrent applications. IEEE Trans.Comput. 48, 6, 591602.KASTRUP, B., BINK, A., AND HOOGERBRUGGE, J. 1999.ConCISe A compilerdriven CPLDbased instruction set accelerator. IEEE Symposiumon FieldProgrammable Custom ComputingMachines, 92101.KHALID, M. A. S. 1999. Routing architecture andlayout synthesis for multiFPGA systems. Ph.D.dissertation, Dept. of ECE, Univ. Toronto.KHALID, M. A. S. AND ROSE, J. 1998. A hybridcompletegraph partialcrossbar routing architecture for multiFPGA systems. ACMSIGDAInternational Symposium on FPGAs, 4554.KIM, H. J. AND MANGIONESMITH, W. H. 2000. Factoring large numbers with programmable hardware. ACMSIGDA International Symposiumon FPGAs, 4148.KIM, H. S., SOMANI, A. K., AND TYAGI, A. 2000. Areconfigurable multifunction computing cachearchitecture. ACMSIGDA International Symposium on FPGAs, 8594.KRESS, R., HARTENSTEIN, R. W., AND NAGELDINGER, U.1997. An operating system for custom computing machines based on the Xputer paradigm.Lecture Notes in Computer Science 1304FieldProgrammable Logic and Applications. W. Luk,P. Y. K. Cheung, and M. Glesner, Eds. SpringerVerlag, Berlin, Germany, 304313.KRUPNOVA, H., RABEDAORO, C., AND SAUCIER, G. 1997.Synthesis and floorplanning for large hierarchical FPGAs. ACMSIGDA International Symposium on FPGAs, 105111.LAI, Y. T. AND WANG, P. T. 1997. Hierarchical interconnection structures for field programmablegate arrays. IEEE Trans. VLSI Syst. 5, 2, 186196.LAUFER, R., TAYLOR, R. R., AND SCHMIT, H. 1999.PCIPipeRench and the SwordAPI A system forstreambased reconfigurable computing. IEEESymposium on FieldProgrammable CustomComputing Machines, 200208.LEE, Y. S. AND WU, A. C. H. 1997. A performanceand routabilitydriven router for FPGAs considering path delays. IEEE Trans. CAD Integ. Circ.Syst. 16, 2, 179185.LEONARD, J. AND MANGIONESMITH, W. H. 1997. Acase study of partially evaluated hardware circuits Keyspecific DES. Lecture Notes in Computer Science 1304FieldProgrammable Logicand Applications. W. Luk, P. Y. K. Cheung,and M. Glesner, Eds. SpringerVerlag, Berlin,Germany, 151160.LEUNG, K. H., MA, K. W., WONG, W. K., AND LEONG,P. H. W. 2000. FPGA Implementation of a microcoded elliptic curve cryptographic processor.IEEE Symposium on FieldProgrammable Custom Computing Machines, 6876.LEWIS, D. M., GALLOWAY, D. R., VAN IERSSEL, M., ROSE,J., AND CHOW, P. 1997. The Transmogrifier2A 1 million gate rapid prototyping system.ACMSIGDA International Symposium onFPGAs, 5361.LI, Y., CALLAHAN, T., DARNELL, E., HARR, R., KURKURE,U., AND STOCKWOOD, J. 2000a. Hardwaresoftware codesign of embedded reconfigurablearchitectures. Design Automation Conference,507512.LI, Z., COMPTON, K., AND HAUCK, S. 2000b. Configuration caching for FPGAs. IEEE Symposiumon FieldProgrammable Custom ComputingMachines, 2236.LI, Z. AND HAUCK, S. 1999. Dont care discovery forFPGA configuration compression. ACMSIGDAInternational Symposium on FPGAs, 9198.LIN, X., DAGLESS, E., AND LU, A. 1997. Technology mapping of LUT based FPGAs for delayoptimisation. Lecture Notes in Computer Science 1304FieldProgrammable Logic and Applications. W. Luk, P. Y. K. Cheung, and M.Glesner, Eds. SpringerVerlag, Berlin, Germany,245254.LIU, H. AND WONG, D. F. 1999. Circuit partitioningfor dynamically reconfigurable FPGAs. ACMSIGDA International Symposium on FPGAs,187194.LUCENT TECHNOLOGIES, INC. 1998. FPGA DataBook. Lucent Technologies, Inc., Allentown, PA.LUK, W., SHIRAZI, N., AND CHEUNG, P. Y. K. 1997a.Compilation tools for runtime reconfigurableACM Computing Surveys, Vol. 34, No. 2, June 2002.208 K. Compton and S. Hauckdesigns. IEEE Symposium on FieldProgrammable Custom Computing Machines, 5665.LUK, W., SHIRAZI, N., GUO, S. R., AND CHEUNG, P.Y. K. 1997b. Pipeline morphing and virtualpipelines. Lecture Notes in Computer Science1304FieldProgrammable Logic and Applications. W. Luk, P. Y. K. Cheung, and M. Glesner,Eds. SpringerVerlag, Berlin, Germany, 111120.LYSAGHT, P. AND STOCKWOOD, J. 1996. A simulationtool for dynamically reconfigurable field programmable gate arrays. IEEE Trans. VLSI Syst.4, 3, 381390.MAK, W. K. AND WONG, D. F. 1997. Boardlevel multi net routing for FPGAbased logicemulation. ACM Trans. Des. Automat. Elect.Syst. 2, 2, 151167.MANGIONESMITH, W. H. 1999. ATR from UCLA.Personal Commun.MANGIONESMITH, W. H., HUTCHINGS, B., ANDREWS, D.,DEHON, A., EBELING, C., HARTENSTEIN, R., MENCER,O., MORRIS, J., PALEM, K., PRASANNA, V. K., ANDSPAANENBURG, H. A. E. 1997. Seeking solutions in configurable computing. IEEE Comput.30, 12, 3843.MARSHALL, A., STANSFIELD, T., KOSTARNOV, I., VUILLEMIN,J., AND HUTCHINGS, B. 1999. A reconfigurablearithmetic array for multimedia applications.ACMSIGDA International Symposium onFPGAs, 135143.MCKAY, N. AND SINGH, S. 1999. Debugging techniques for dynamically reconfigurable hardware. IEEE Symposium on FieldProgrammableCustom Computing Machines, 114122.MCMURCHIE, L. AND EBELING, C. 1995. PathfinderA negotiationbased performancedriven routerfor FPGAs. ACMSIGDA International Symposium on FPGAs, 111117.MENCER, O., MORF, M., AND FLYNN, M. J. 1998. PAMblox High performance FPGA design for adaptive computing. IEEE Symposium on FieldProgrammable Custom Computing Machines,167174.MIYAMORI, T. AND OLUKOTUN, K. 1998. A quantitative analysis of reconfigurable coprocessorsfor multimedia applications. IEEE Symposiumon FieldProgrammable Custom ComputingMachines, 211.MORITZ, C. A., YEUNG, D., AND AGARWAL, A. 1998.Exploring optimal cost performance designsfor Raw microprocessors. IEEE Symposiumon FieldProgrammable Custom ComputingMachines, 1227.NAM, G. J., SAKALLAH, K. A., AND RUTENBAR,R. A. 1999. Satisfiabilitybased layout revisited detailed routing of complex FPGAsvia searchbased boolean SAT. ACMSIDGAInternational Symposium on FPGAs, 167175.PAN, P. AND LIN, C. C. 1998. A new retimingbasedtechnology mapping algorithm for LUTbasedFPGAs. ACMSIGDA International Symposiumon FPGAs, 3542.PAYNE, R. 1997. Runtime parameterised circuitsfor the Xilinx XC6200. Lecture Notes in Computer Science 1304FieldProgrammable Logicand Applications. W. Luk, P. Y. K. Cheung,and M. Glesner, Eds. SpringerVerlag, Berlin,Germany, 161172.PURNA, K. M. G. AND BHATIA, D. 1999. Temporalpartitioning and scheduling data flow graphs forreconfigurable computers. IEEE Trans. Comput.48, 6, 579590.QUICKTURN, A CADENCE COMPANY. 1999a. SystemRealizerTM. Available online at httpwww.quickturn . com  products  systemrealizer . htm.Quickturn, A Cadence Company, San Jose, CA.QUICKTURN, A CADENCE COMPANY. 1999b.MercuryTM Design Verification System Technology Backgrounder. Available online at httpwww.quickturn.comproductsmercury backgrounder.htm. Quickturn, A Cadence Company,San Jose, CA, 1999.RAZDAN, R. AND SMITH, M. D. 1994. A highperformance microarchitecture with hardwareprogrammable functional units. InternationalSymposium on Microarchitecture, 172180.RENCHER, M. AND HUTCHINGS, B. L. 1997. Automated target recognition on SPLASH2. IEEESymposium on FieldProgrammable CustomComputing Machines, 192200.ROSE, J., EL GAMAL, A., AND SANGIOVANNIVINCENTELLI,A. 1993. Architecture of fieldprogrammablegate arrays. Proc. IEEE 81, 7, 10131029.RUPP, C. R., LANDGUTH, M., GARVERICK, T., GOMERSALL,E., HOLT, H., ARNOLD, J. M., AND GOKHALE, M.1998. The NAPA adaptive processing architecture. IEEE Symposium on FieldProgrammableCustom Computing Machines, 2837.SANGIOVANNIVINCENTELLI, A., EL GAMAL, A., AND ROSE,J. 1993. Synthesis methods for field programmable gate arrays. Proc. IEEE 81, 7, 10571083.SANKAR, Y. AND ROSE, J. 1999. Trading qualityfor compile time Ultrafast placement forFPGAs. ACMSIGDA International Symposiumon FPGAs, 157166.SCALERA, S. M. AND VAZQUEZ, J. R. 1998. Thedesign and implementation of a contextswitching FPGA. IEEE Symposium on FieldProgrammable Custom Computing Machines,7885.SELVIDGE, C., AGARWAL, A., DAHL, M., AND BABB J.1995. TIERS Topology IndependEnt PipelinedRouting and Scheduling for VirtualWireTMCompilation. ACMSIGDA International Symposium on FieldProgrammable Gate Arrays,2531.SENOUCI, S. A., AMOURA, A., KRUPNOVA, H., AND SAUCIER,G. 1998. Timing driven floorplanning on programmable hierarchical targets. ACMSIGDAInternational Symposium on FPGAs, 8592.ACM Computing Surveys, Vol. 34, No. 2, June 2002.Reconfigurable Computing 209SHAHOOKAR, K. AND MAZUMDER, P. 1991. VLSI cellplacement techniques. ACM Comput. Surv. 23,2, 145220.SHI, J. AND BHATIA, D. 1997. Performance drivenfloorplanning for FPGA based designs.ACMSIGDA International Symposium onFPGAs, 112118.SHIRAZI, N., LUK, W., AND CHEUNG, P. Y. K. 1998.Automating production of runtime reconfigurable designs. IEEE Symposium on FieldProgrammable Custom Computing Machines,147156.SLIMANEKADI, M., BRASEN, D., AND SAUCIER, G. 1994.A fastFPGA prototyping system that usesinexpensive highperformance FPIC. ACMSIGDA Workshop on FieldProgrammable GateArrays.SOTIRIADES, E., DOLLAS, A., AND ATHANAS, P. 2000.Hardwaresoftware codesign and parallel implementation of a Golomb ruler derivation engine.IEEE Symposium on FieldProgrammable Custom Computing Machines, 227235.STOHMANN, J. AND BARKE, E. 1996. An universalCLA adder generator for SRAMbased FPGAs.Lecture Notes in Computer Science 1142FieldProgrammable Logic Smart Applications, NewParadigms and Compilers. R. W. Hartensteinand M. Glesner, Eds. SpringerVerlag, Berlin,Germany, 4454.SWARTZ, J. S., BETZ, V., AND ROSE, J. 1998. Afast routabilitydriven router for FPGAs. ACMSIGDA International Symposium on FPGAs,140149.SYNOPSYS, INC. 2000. CoCentric System C Compiler. Synopsys, Inc., Mountain View, CA.SYNPLICITY, INC. 1999. Synplify User Guide Release5.1. Synplicity, Inc., Sunnyvale, CA.TAKAHARA, A., MIYAZAKI, T., MUROOKA, T., KATAYAMA, M.,HAYASHI, K., TSUTSUI, A., ICHIMORI, T., AND FUKAMI,K. 1998. More wires and fewer LUTs Adesign methodology for FPGAs. ACMSIGDAInternational Symposium on FPGAs, 1219.THAKUR, S., CHANG, Y. W., WONG, D. F., ANDMUTHUKRISHNAN, S. 1997. Algorithms for anFPGA switch module routing problem with application to global routing. IEEE Trans. CADInteg. Circ. Syst. 16, 1, 3246.TOGAWA, N., YANAGISAWA, M., AND OHTSUKI, T. 1998.MapleOPT A performanceoriented simultaneous technology mapping, placement, and globalgouting algorithm for FPGAs. IEEE Trans. CADInteg. Circ. Syst. 17, 9, 803818.TRIMBERGER, S. 1998. Scheduling designs into atimemultiplexed FPGA. ACMSIGDA International Symposium on FPGAs, 153160.TRIMBERGER, S., CARBERRY, D., JOHNSON, A., ANDWONG, J. 1997a. A timemultiplexed FPGA.IEEE Symposium on FieldProgrammable Custom Computing Machines, 2228.TRIMBERGER, S., DUONG, K., AND CONN, B. 1997b.Architecture issues and solutions for a highcapacity FPGA. ACMSIGDA InternationalSymposium on FPGAs, 39.TSU, W., MACY, K., JOSHI, A., HUANG, R., WALKER, N.,TUNG, T., ROWHANI, O., GEORGE, V., WAWRZYNEK,J., AND DEHON, A. 1999. HSRA Highspeed,hierarchical synchronous reconfigurable array. ACMSIGDA International Symposium onFPGAs, 125134.VAHID, F. 1997. IO and performance tradeoffswith the FunctionBus during multiFPGA partitioning. ACMSIGDA International Symposiumon FPGAs, 2734.VARGHESE, J., BUTTS, M., AND BATCHELLER, J. 1993.An efficient logic emulation system. IEEE Trans.VLSI Syst. 1, 2, 171174.VASILKO, M. AND CABANIS, D. 1999. Improving simulation accuracy in design methodologies for dynamically reconfigurable logic systems. IEEESympos. FieldProg. Cust. Comput. Mach. 123133.VUILLEMIN, J., BERTIN, P., RONCIN, D., SHAND, M.,TOUATI, H., AND BOUCARD, P. 1996. Programmable active memories Reconfigurablesystems come of age. IEEE Trans. VLSI Syst. 4,1, 5669.WANG, Q. AND LEWIS, D. M. 1997. Automated fieldprogrammable compute accelerator design usingpartial evaluation. IEEE Symposium on FieldProgrammable Custom Computing Machines,145154.WEINHARDT, M. AND LUK, W. 1999. Pipeline vectorization for reconfigurable systems. IEEE Symposium on FieldProgrammable Custom Computing Machines, 5262.WILTON, S. J. E. 1998. SMAP Heterogeneous technology mapping for area reduction in FPGAswith embedded memory arrays. ACMSIGDAInternational Symposium on FPGAs, 171178.WIRTHLIN, M. J. AND HUTCHINGS, B. L. 1995. A dynamic instruction set computer. IEEE Symposium on FPGAs for Custom ComputingMachines, 99107.WIRTHLIN, M. J. AND HUTCHINGS, B. L. 1996. Sequencing runtime reconfigured hardware withsoftware. ACMSIGDA International Symposium on FPGAs, 122128.WIRTHLIN, M. J. AND HUTCHINGS, B. L. 1997. Improving functional density through runtime constant propagation. ACMSIGDA InternationalSymposium on FPGAs, 8692.WITTIG, R. D. AND CHOW, P. 1996. OneChip AnFPGA processor with reconfigurable logic. IEEESymposium on FPGAs for Custom ComputingMachines, 126135.WOOD, R. G. AND RUTENBAR, R. A. 1997. FPGArouting and routability estimation via Booleansatisfiability. ACMSIGDA International Symposium on FPGAs, 119125.WU, Y. L. AND MAREKSADOWSKA, M. 1997. Routingfor arraytype FPGAs. IEEE Trans. CAD Integ.Circ. Syst. 16, 5, 506518.ACM Computing Surveys, Vol. 34, No. 2, June 2002.210 K. Compton and S. HauckXILINX, INC. 1994. The Programmable Logic DataBook. Xilinx, Inc., San Jose, CA.XILINX, INC. 1996. XC6200 Advance Product Specification. Xilinx, Inc., San Jose, CA.XILINX, INC. 1997. LogiBLOX Product Specification. Xilinx, Inc., San Jose, CA.XILINX, INC. 1999. VirtexTM 2.5 V Field Programmable Gate Arrays Advance Product Specification. Xilinx, Inc., San Jose, CA.XILINX, INC. 2000. Press Release IBM and XilinxTeam to Create New Generation of IntegratedCircuits. Xilinx, Inc., San Jose, CA.XILINX, INC. 2001. VirtexII 1.5V Field Programmable Gate Arrays Advance ProductSpecification. Xilinx, Inc., San Jose, CA.YASAR, G., DEVINS, J., TSYRKINA, Y., STADTLANDER,G., AND MILLHAM, E. 1996. Growable FPGAmacro generator. Lecture Notes in Computer Science 1142FieldProgrammable Logic SmartApplications, New Paradigms and Compilers. R. W. Hartenstein and M. Glesner,Eds. SpringerVerlag, Berlin, Germany, 307326.YI, K. AND JHON, C. S. 1996. A new FPGA technology mapping approach by cluster merging.Lecture Notes in Computer Science 1142FieldProgrammable Logic Smart Applications, NewParadigms and Compilers. R. W. Hartensteinand M. Glesner, Eds. SpringerVerlag, Berlin,Germany, 366370.ZHONG, P., MARTINOSI, M., ASHAR, P., AND MALIK, S.1998. Accelerating Boolean satisfiability withconfigurable hardware. IEEE Symposiumon FieldProgrammable Custom ComputingMachines, 186195.Received May 2000 revised October 2001 and January 2002 accepted February 2002ACM Computing Surveys, Vol. 34, No. 2, June 2002.
