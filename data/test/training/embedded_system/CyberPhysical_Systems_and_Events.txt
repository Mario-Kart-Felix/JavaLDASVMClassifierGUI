CyberPhysical Systems and EventsCarolyn TalcottSRI InternationalMenlo Park, CA 940253493, USAcltcs.stanford.eduAbstract. This paper discusses eventbased semantics in the context of theemerging concept of Cyber Physical Systems and describes two related formalmodels concerning policybased coordination and Interactive Agents.1 IntroductionCyberphysical systems CPSs integrate computing and communication with monitoring andor control of entities in the physical world. Sensing and manipulation of thephysical world occurs locally, system behavior emerges as a result of communicationand other forms of interaction. Example CPSs include automobiles, aircraft, air traffic control, power grids, oil refineries, medical devices, patient monitoring, and smartstructures. Software is becoming an increasingly important element of the operation ofthese systems, and must do so dependably, safely, securely, efficiently and in realtime.CPSs go beyond traditional embedded and distributed systems. They are often longlasting, with 24x7 operation and must evolve without losing stability. Some CPSs ortheir components have stringent QoS requirements, others are more flexible.Traditional embedded and critical systems are closed, not only in the sense of closedphysical locations or dedicated networks, but also closed with respect to their computational boundaries, i.e., all the participating elements in the systems are known initially.Thanks to network technology and mobility, todays embedded systems are shifting towards openness and federation This leads to multiscale, wide area critical systems withrealtime requirements, all this still with certification requirements, a major verificationchallenge. The openness brings more convenience and flexibility for controlling thesystems. However, it also introduces extra complexity into the systems large scale, uncertainty, and dynamicsentities can come into or leave from the systems, and makesthe coordination of entities even harder.QoS requirements, such as timing properties, faulttolerance, security, etc., dictatehow individual entities of the system being considered coordinate with each other. Forinstance, a deadline constraint on a task indicates that there must exist another entitythat is coordinated with the constrained task. Or the deadline misses its meaning. If weconsider computation is to achieve the systems functional requirements, QoS requirements are reflected through coordination among computational entities. With this view,embedded or critical systems are compositions of two main elementscomputationand coordination.A solid semantic foundation is crucial for design, deployment, monitoring and adaptation of CPSs. Such a foundation must support reasoning locally about individual components and globally about system wide properties. Our hypothesis is that eventbasedM. Wirsing et al. Eds. SoftwareIntensive Systems, LNCS 5380, pp. 101115, 2008.c SpringerVerlag Berlin Heidelberg 2008102 C. Talcottsemantics can provide such a foundation. In Section 2 we discuss the general idea ofeventbased semantics. A sampling of related work is presented in Section 3. This isfollowed by brief overviews of two specific ideas PAGODAa policy and goalbasedapproach to modeling autonomous system components, and Interactive agentswhichcombines a policy based coordination model and an extension of the notion of actors toinclude interactions other than messages.2 EventBased SemanticsWe begin with a discussion of various notions of event, followed by essential features,and challenges to be met in developing eventbased semantics for CPSs.2.1 What Is an EventAn instance of an action An occurrence in time and space A change of conditionThere are many notions of event, different notions being useful for different purposes,including In the actor model of computation an event is a message send or receive. In the process algebra model of computation an event is an action shared by twoprocesses. In the world of linguistics events may happen over time or be nested. For exampleTim and Ben played World of WarCraft. They completed a quest.We can classify event models along several dimensions punctual for example, message sendreceive vs durative for example, filling thetank, attending a class single vs stream for example, card reader readings, periodic chemical sensor readings, or object tracking change vs actionobservation.In addition, event models may have different underlying temporal models causal ordering beforeafter, discrete time, continuous time.It is important for an eventbased semantic to include many different notions of event,and to allow moving from one to another in meaningful ways.2.2 Why EventBasedWhat are the essential features of eventbased semantics One key feature of events isthat they concern interactions between components and observations rather that internalstate. This enables specification and reasoning at higherlevels while integrating easilywith more detailed information. Another key feature of events is the notion of causalpartial order that reflects the physical reality that for events separated in space we maynot be able to decide a linear order and should not depend on it.CyberPhysical Systems and Events 103 Events are a natural way to think about reactive systems, such as CPSs. They provide a natural way to specify components of open systems in terms of interfaces andobservable behavior. Events also can form the basis for specifying coordination andcomposition of components. Global state and local state can be abstracted to event partial orders. The causalpartial order of an event semantics captures dependenciesconsequences and allows reasoning about what must have happened in the past, given some reasonableassumptions about the behavior of system components. Further, by logically locating events, reasoning can be localized, and will scale. Event models can be used to give semantics to specifications, as well and to supportruntime observationmonitoring adaptation, security decisions, trust building. Theysupport new programming abstractions that deal with actions and interactions ratherthan state transformations. Events may have associated evidence, for example the sensor generating low levelevents, the algorithm used to extract information colors, shapes, faces, sound patterns, . . . , rules used to infer higher level events from lower level events locationof a person, end of lecture, or human input.2.3 Challenge AreasThere are many challenges to realizing the full promise of eventbased semantics. Theoverall challenge is to develop general mathematical models together with domain specific refinements that are both natural and expressive. Beyond models its is crucial todevelop logics and reasoning principles. Finally these models and logics need tools tomake them usable for analysis, synthesis, and transformations. Below we discuss someof things an appropriate event model should capture and some of the issues that will befaced in doing so.Identifying, Modeling and Reasoning About Interdependencies. It is critical to enableincreasing dynamic computer control that is safe and without unpleasant surprises.Consider for example, a power grid versus a transportation system. One the one hand,some elements of the transportation system depend on the power grid trolly cars, fuelpumps, logistics planning. On the other hand changes in the transportation system mayaffect loads on the power grid. How can event partial orders combined with event timelines enable effective modeling and analysis For example, an event based model couldexpress dynamic consequences of dependencies, not just static relations.Dealing with Time, Space, Scale, and Uncertainty. Time resolution of observation andactions. Events must be communicated in time to be useful. An example is sub secondcontrol on a power grid. Local event and control models may change over time. Oneexample is different aircraft flight modestakeoff, landing, or cruising. Another example is traffic control for high density landing of aircraft, weather and traffic patterns canchange things substantially. Thus we must be able to model and reason about changesof event structures over time.Systems operate at multiple time scales, for example realtime control of a single device in the context of scheduling of trainair traffic or coordination of human activity. An104 C. Talcotteventbased semantics is needed that supports reasoning at each scale and integratingmultiple scales.Event hierarchies and rules for deriving high level events from lower level evidenceor refining high level events to lower level events such as actions are needed.Privacy Issues for Human Centric CPS. Access to dynamic data raises new issues aspatterns over time, together with context, can enable unexpected inference of information. An example the water company may monitor patterns of water usage, for thepurpose of optimizing flow control. Maybe be able to detect activity such as shower,toilet flush, running a dishwasher. If the electricity company and the water companyshared information, it might be possible to infer more refined differences. Electricitypatterns for a dishwasher might be different than those for a washing machine. Clearlythere is the possibility of invasiveness if such inferences are made and exposed .Notice that the dynamic data can be modeled as event streams and transformationson event streams can be used to control what information is exposed. Much work developing formal threat models knowledge context and ability of entity accessing datais needed to realize this possibility.Composition Composing is not just putting things together in parallel It is also necessary to provide a means of interaction, and a means of constraining possible interactions. For example, What network and communication protocols are needed to enable interacting withphysical systems What coordination primitives are needed to describe eventbased compositions thatinvolve physical systems What properties of the components and their composition are importantIncomplete specifications are often more elegant and easier for a designer or implementor to work with, but they are generally not composableas the missing information leaves open the possibility of interference or unexpected combined behaviors.Arguments for composition properties typically assume all events are known, while ina given event model some information will be implicit in the model. Assumeguaranteeformalizations can help, but when composing using multiple models it will be crucial tomake explicit all information relevant to the composition. A possible approach to crossmodel composition is to develop metamodels that make explicit model assumptions.Another aspect of composition is composing evidenceproofs, statistical confidencelevels, trust. For example, low level events or event streams may be combined an abstracted to infer higher level events. Event models are a good basis for thinking aboutsituation awareness, and it may be important to know how and event was detected,before taking action.New Models for Thinking About Things Top to Bottom. Currently embedded systemshave their control loop in the hardware or a realtime operating system. This does notscale and does not work well in open systems. How can thinking in terms of events leadto better modelsCyberPhysical Systems and Events 105New Languages Based on New Models of Computation and Interaction. Languages areneeded for eventbased requirements, executable specification, composing, monitoring,and even programming. Considerations include the ability to change the way instructionsdescriptions are interpreted scoping visibility and effects of actions containing effects of errors or unexpected eventsboth physical and cyber programming concepts with resource sensitivity built in what can be monitored, detected andor controlled3 Related WorkIn the following we review a sampling of work related to eventbased semantics.Events Vs. State, Partial Order Vs. Interleaving. In 26,25 an argument is presentedthat the traditional computer science model of concurrent programming using statebased models and threads incurs unnecessary complexity and results in code that isdifficult to debug. For sequential computation and function composition they worknicely. When deterministic sequential threads are composed in parallel they becomenondeterministic and difficult to manage. A tag based signal model is proposed building on 24. The domain of tags comes equipped with an ordering relation, events aretagvalue pairs, and signals are sets of events describing incremental evolution of a system. Components modeled in terms of signals compose naturally. The model is elaborated to model both components and connectors, thus capturing interactions and alsointroducing the possibility of feedback loops. A mathematical theory based on topological concepts has been developed to give a compositional semantics to the componentsconnector wiring diagrams 27.In 9 Clinger proves the existence of global times for event diagrams a form ofevent partial orders corresponding to possible interleavings. This provides an associated interleaving model allowing one to reason sequentially or about partial orders.Rewriting logic 28,30 extends equational logic with local rewrite rules that modelchange over time. Proofs in rewriting logic can also be thought of as computations.Since rules are applied locally, a computation step may involve multiple parallelrewrites, while an equivalent computation carries these out one step at a time. In 29 itwas shown that in a restricted class of rewrite theories modeling object  actor systems,there is an isomorphism between equivalence classes of proofscomputations and theevent partial order generated by the computation.In 36 an abstract interpretation of time is proposed to model systems involvingpreemptive scheduling. In this approach, models of the individual process are composedinto a single time domain with the result being an infinite state timed automaton calleda time domain automaton. Each state of such an automaton represents an equivalenceclass of all possible execution interleavings that result in that particular event ordering.Abstract interpretation combined with constraint solving techniques are used to makethe model amenable to analysis.106 C. TalcottEvent Models for Actors. The actor model 20,2,1 is a model of concurrent and distributed computation based on asynchronous message passing. Actors are reactive entities that encapsulate state and control and interact with other actors only by sendingand receiving messages. Events are the basis of semantics of actor languages and systems. Grief 18 introduced the notion of event diagram which captures the linear orderof events at each actor and the causal order between message sends and correspondingreceives. Baker and Hewitt 5 proposed a set of laws characterizing these event partialorders. In 33 a compositional notion of Actor Algebra is developed. Actor Algebramodels include interfaces, specifications, event diagrams, and interaction paths withmappings between the different algebras.PastTime Distributed Temporal Logic PtDTL. PtDTL, a variant of PastTime Temporal logic was introduced in 32. This logic reasons not over interleavings and linearsequences of past states, but over partially ordered sets of events causally in the past. Asfor event diagrams, events are located and the logic introduces epistemic operators thatallow reasoning about what holds at the most recent causally previous state of anotheractor or process. The logic is used as the basis of an efficient algorithm for distributedmonitoring.Causal Logic of Events. Causal Logic of Events CLE 8,6,7 is a logic for distributedcomputing that has the explanatory and technical power of constructive logics of computation. CLE provides a proof technology that supports correctbyconstruction programming based on the notion that concurrent processes can be extracted from proofsthat specifications are achievable. A methodology for specifying distributed systems inCLE has been developed and implemented in NuPrl 3. Requirements for a distributedsystem are expressed in terms of events, these requirements are then refined to collections of constraints called Message Automata MAs that imply the original requirements. MAs can be compiled to standard languages such as Java. Models of messageautomata are event diagrams, with events localized and the event order at each locationa total order. Working bottom up, system properties can be inferred from MAs. Eventclasses and laws for composition allow specification and reasoning at a higher level ofabstraction. The logical framework also supports timing properties, for example usingvariables that are trajectories of values rather than discrete values. The methodologyhas been applied to a variety of networking and security protocols.Strand Spaces as an Event Model for Security and Location. Key exchange has logically simple goals, agnostic to communication concerns. In contrast, location protocolshave quantitative goals, and models must consider transmission properties and use geometry. Strand spaces are a mathematical model that provides a specialpurpose execution semantics, called Bundles, based on a causal partial order, that is complete forsymbolic analysis of key exchange 16. Reasoning about properties such as authentication or confidentiality makes combined use of causality and cryptographic properties.Strand spaces have been used to model and analyze a variety of security related protocols, including key exchange, contract negotiations, and secure payments systems.Metric strand spaces are introduced in order to also reason about space and time.Bundles in a metric strand space have a distance and time elapse measures on some pairsof events that obey axioms reflecting by a model of transmission speed 19. SecureCyberPhysical Systems and Events 107location protocols combine cryptography with the physics of message transmission.The cryptographic operations authenticate the principals and preserve confidentiality,while the physics of message transmission constrain their possible locations. In the caseof metric strand spaces, the strand space model is enriched by associating a spacetimelocation with each node. The strands follow the world lines of principals. Some bundlesare compatible with the physics of message transmission  e.g. the maximum messagetransmission speed  while others are not. An assertion true in every bundle compatiblewith the physics is a valid conclusion of a secure location protocol.CEL and strand spaces are similar in a number of ways. They share notions of causalorder and the need to express limitations on the adversary. Strand spaces have a notionof unique origination that is similar to the CEL notion of nonce. The two formalism differ in their treatment of logical locality in CEL locality encompasses multiple activities of a single principle or actor and may allow sharing of information across multiplethreadsactivities. In contrast the Strand space model explicitly isolates each activity ofa principal a strand enforcing further localization.Event Streams and Uncertainty. Eventbased semantics is natural for many realtimeembedded applications. In such applications the issue of temporal uncertainty is acommon and challenging problem. Temporal uncertainty comes from the inherent restrictions in the underlying sensing layer, such as the temporalspatial limitations ofsampling, inaccurate clocks and unpredictable network latency. Although events occurinstantaneously dense time in the physical world, an event occurrence often cannot beassigned a precise time owing to the above limitations. PTMON Probabilistic TimingMONitor 42,41 is a generic framework for incorporating various uncertainty models on event time stamps, developed in the context of monitoring timing constraints onevent streams. A monitor task is formulated by timing constraints in a simple realtimetemporal logic and satisfactionviolation of these formulas is checked at run time. Givena probability model of the temporal distance from event occurrence to event detection,timing constraints based on event occurrences can be transformed to those based onevent detection. This transformation enables the early detection of timing constraintviolations. Applications include realtime baggage tracking, wireless process control,remote monitoring, online multimedia downloading, and teleconference.Grounding HighLevel Event Definition. Highlevel eventbased models require a precise notion of events in the model. A formal way of defining highlevel events in termsof lowlevel system state helps to define a faithful abstraction for an eventbased model.The logic of events and conditions LEC 22 is a twosorted logic bridging the gap between statebased formalisms, commonly found in lowlevel models, and higherlevelevent formalisms. Conditions represent an abstract view of the system state, with primitive conditions being state predicates over the observable state variables in the system.Primitive events can also be directly observed during a system run. The use of LEC forevent definition was developed in the context of runtime verification. The same separation of concerns used in runtime verification can be applied to highlevel modelingin general. The basic approach is to provide an eventbased model that uses highlevelevents as atomic building blocks, reducing the size and complexity of the model. Theevent definition layer provides grounding of the highlevel model in the implicit lowlevel model. It can be used to establish a mapping between behaviors of the highlevel108 C. Talcottand lowlevel models, which can be used to demonstrate, without ever constructing thelowlevel model explicitly, that the highlevel model is a faithful representation of thesystem.Event Models for Pervasive Spaces. The Responsphere Infrastructure is a campuslevelpervasive computing and communication infrastructure at University of California atIrvine httpwww.responsphere.org. It consists of a variety of sensors video cameras, sensor mounted mobile robots, people counters, RFID, acoustic sensors, thermaland gas sensors dispersed over approximately a third of the campus, connected via avariety of network and communication technologies 802.11, cellular, mesh, and powerline networks. It includes dense sensing in a few chosen buildings where it monitors allcorridors, entries, exits, and public areas using cameras. In addition, some designatedpublic spaces and laboratories are instrumented with RFID readers. Responsphere alsoincludes mobile sensor mounted robots with communication capabilities that can beprogrammed for autonomous data collection. Responsphere serves as a test bed for developing a variety of pervasive functionalities, for example, using a mixture of videoand RFID technologies to implement social policies of a shared common facility withina particular building. Examples include reminding people to switch off the coffee machine and conducting social experiments to study recycling behavior. In addition Responsphere has been used to conduct and monitor a variety of emergency drills such asbuilding and region evacuations. The SATware System 21 httpsatware.ics.uci.eduis a scalable middleware, that runs on Responsphere and provides seamless access tosensor and event level data. Applications access this information via a SQL style querylanguage referred to as SATQL, at both the physical e.g., raw sensor feeds and semantic levels i.e., at the level of entities, activities, and events. The key concept is thatof a virtual sensor that empowers programmers to define and detect semantic conceptsthereby realizing information abstraction. Virtual sensors are mapped at runtime toa graph of operators which are implemented over physical sensor streams. Challengesfor management and programming of pervasive spaces include privacy and trustworthiness, evidence for judging semantic event reports, trading function for privacy, and selfmonitoring and adaptation.4 Policy and GoalBased Operation of Autonomous AgentsThere is a growing interest in autonomous agents that interact with and affect theirenvironment, and have some ability to observe, reason, and adapt. As part of a largersystem agents should also be able to compete for resources but also to cooperate formutual benefit or to achieve an overall goal.PAGODA Policy And GOal based Distributed Autonomy is a modular architecturefor design of interactive autonomous systems. A PAGODA system is a collection ofPAGODA nodes cooperating to achieve some mutual goal. A PAGODA node agentinteracts with its environment by sensing and affecting, driven by goals to achieve andconstrained by policies. The PAGODA architecture was inspired by studying architectures developed for autonomous space systems, especially the MDS architecture 15and its precursors 31. Software for deep space missions must beCyberPhysical Systems and Events 109 autonomousoperating remotely for extended time robustoperating under unpredictable conditions dependablemission failure is costlyIn PAGODA policybased coordination is used at two levels local modular combination of components making up an agents behavior and coordination of a distributedsystem of agents constraining the possible interaction scenarios to meet endtoend requirements.The long term objective of the PAGODA project is to develop techniques for specification and analysis that take advantage of the modularity and the declarative nature ofpolicy and goalbased systems. PAGODA has been developed in the context of projectsproviding driving applications, including a rover for example for exploration or patrol13,14 and software defined radios 40 supporting specific missions. Other potentialapplications include reactiveadaptive planners, cognitive radios, software assistants,and selfconfiguring systems.Our approach is based on the Reflective Russian Dolls RRD model of distributedobject reflection 29,34 which in turn is founded on the rewriting logic formal modeling framework 28,30. In 34 a general approach to modeling policybased coordination using RRD was presented. The question addressed by PAGODA is how to specifyautonomous behavior that meets or achieves its goals subject to constraints on external conditions in a modular and declarative manner using models of its environment.Our solution is to factor the behavior into components, each with a specific role, thatcombine to achieve the desired result.4.1 PAGODA NodesFigure 1 shows the principal components of a PAGODA node a knowledge base KB,a reasoner R, a monitor M, a learner L, and a hardware abstraction layer HAL.These interact with each other and the environment under the control of acoordinator C.The knowledgebase KB is the centerpiece. It contains knowledge that is sharedand updated by the remaining components. This knowledge includes a wide range ofinformation Goals that specify what the node or system is trying to achieve. A goal could be avery highlevel goal such as carrying out a scientific experiment or tuning parameters to achieve a given quality of service or lower level goals that correspond toactions that can be carried out. Policies that constrain the allowed actions  interactions of a node or system. Apolicy might reduce the number of choices for setting parameters, for examplebased on importance of different competing effects. Another policy might determine tradeoffs between speed and power usage. Other policies might control aggregation and abstraction of information used locally or communicated to otheragents. A device model that specifies the HAL interface parametersknob that can be seteffecting and read sensing and their relationships. At the system level the model110 C. TalcottFig. 1. PAGODA node architectureshould also specify how values sensed at different nodes can be combined to determine nonlocal system properties, and the relationships of such properties to higherlevel goals. An environment model, representing relevant features of the environment in whichthe node is operating, including information about other nodes. For a mobile nodethis could include terrain information or building maps. Node state, which includes values of variables determined by sensor readings anddeduced from actions and information collected from other nodes. It also includessituation information such as the stage in a complex taskmission or progresstowards achieving a goal. History, a log of eventsgoals received, knob settings and sensor readings, monitoralerts, and so on.The job of the reasoner component R is to determine proper parameter settings inresponse to goals requests new goals, starting a new stage of a current goal, or alertsraised due to unexpected sensor values, indicating that adjustments need to be made.The reasoner uses information from the KB as a basis for its deductions the device andenvironment model, the goals and policies, and the current state. When new parametersettings are determined, the reasoner also provides justifications such as what sensorvalues andor what relationships from the device model were used to infer the newsettings. This can be used for diagnostics if things dont go as expected. The reasoneralso specifies sensors that should be monitored and conditions on sensor reading underwhich the reasoner to be alerted to take corrective action.The monitor component M receives monitoring tasks from the reasoner, reads andevaluates specified sensors, and sends alerts to the reasoner when sensor readings arenot within specified limits.The job of the learner component L is to improve the model used by the reasonerto infer appropriate knob settings. In passive mode it observes events such as goals,settings, sensor readings and alerts and attempts to improve relationships specified bythe model based on this information. A learner may also have an active mode where itis allowed to propose experimental settings and observe the results.CyberPhysical Systems and Events 111The hardware abstraction layer component HAL is an interface to the sensors andeffectors used by the node. It plays the role of device driver, handling knob setting andsensor reading requests. In a real system the HAL might map requests to a format that isunderstood by the actual hardware, or even to a lower level abstraction layer. The intentis that these interactions should obey the physics specified by the device model, but thenode needs to be prepared for things to go wrongsome hardware component breaks,the environment is different than expected, it is being operated outside the expectedoperational mode, and so on.The coordinator C controls message semantics for internal components and mediates interactions with the external world. The coordinator is responsible for ensuring specified relationships between the events message deliveries seen by differentcomponents, and for meeting logging and notification requirements. It also enforcescomponent level synchronization constraints only delivering messages for which thecomponent is enabled. The coordinator actions are specified declaratively by policies.Note that coordinator policies are similar in spirit, to policies used by the reasoner, butdifferent in detail.Each PAGODA component type has an interface specified using events. The semantics of given component is an eventbased semantics in the spirit of the Actor Algebradiscussed in Section 2. This enables eventbased composition of components and theirsemantics. Composition with a coordinator can be treated as a vertical composition inthe spirit of 12.This architecture provides a simple means of plugging in different component instances. PAGODA node components interact with other node components based oncomponent type not on component instance identity. Thus it is easy to have multiplereasoners, knowledge bases, learners, etc., by simply modifying the coordinator policyto choose appropriate component instances. Different reasoners might be appropriatefor different situations or goals, knowledge might be split into categories and stored inseparate KB instances, or two KB instances might contain knowledge at different levelsof abstraction appropriate for different situations.Additional components types could be easily incorporated. For example a componentcapable of knowledge abstraction or aggregation could be invoked from time to timeby the coordinator to infer higherlevel information from sensor data or informationreceived from peers. Such a component could be used to raise the level of abstractionat which the reasoner or learner operates.5 Interactive AgentsMuch has been written contrasting interactive computation and other models such asTuring machines and logic programming 37,38,39. Our focus is on modeling andreasoning about the capabilities enabled by interactivity.An interactive agent must be aware of its surroundings, and it may also affect itsenvironment. It may need to negotiate, cooperate, or compete. A formal framework formodeling interactive agents was introduced in 35. The framework was based on theneed to consider the following features in the design of interactive agents.112 C. Talcott An agent has a boundary consisting of points of interaction with the environment.From the outside only what crosses the boundary is visible. Interaction points couldbe sensors, such as light detectors or thermometers, effectors such as switches ordials, or message queues for exchange of messages with other agents. An agent has actions that it can execute. It may also have goals, knowledge aboutits environment and itself, policies constraining actions, or strategies for achievinggoals. Internally an agent may have multiple concurrent activities observing and processing sensory information refining goals to subgoals, choosing actions, executingactions evaluating and analyzing results did actions have expected effect updating knowledge by learning and inference Interactivity means internal processes must be interruptible.The framework is based on rewriting logic and a reflective model of coordinationfor managing an agents activities. New forms of interaction are introduced to modelboth message and channelsignal based interactions, and to pave the way for modelingcontinuous interactions. The compositional interaction semantics of 33,12 is extendedto handle the new forms of interaction. The aims of the framework include a higher level means of specifying and understanding agent behavior a place to classify agents with different skills a formal design space to represent a variety of design decisions and to study tradeoffs resulting from decisions such as adaptability vs. predictabilityOne advantage of the proposed framework is that specifications are executable, allowingprototyping of designs at many stages. In addition, such specifications are formallyanalyzable using the Maude rewriting logic system, and connections with other formalsystems.Briefly, interactive agents are formalized as actor like objects with rules for communication by messages, interaction through interface points, and policies for coordinatingactivities, also represented as subagents. What the agent reads at an interaction pointis controlled by the environment. What the environment can read is controlled by theagent by a write action.An interaction path is a possibly infinite sequence of interactions events as viewedfrom an imaginary external observer. Each computation of an agent allowed by therewrite rules gives rise to a set of interaction paths consisting of the nonsilent interactions labeling the transitions rewrite rule applications. The observable semanticsof an interactive agent is thus the set of interaction paths of its possible computations.This definition derives from earlier work developing interaction semantics for actors33,12, ideas from Timed Data Stream semantics for the Reo coordination model 4,and signal event semantics 23. Interaction semantics is similar in spirit to the Interactive Stream Languages of 17. The ideas are also related to work on interfaces ofreactive and concurrent systems such as, 10,11.Interaction semantics is compositional both vertically and horizontally. The semanticsof the horizontal parallel composition of two systems is done by zipping compatiblepaths, one from the semantics of each system. Two paths are compatible if their subsequences of complimentary interactions, such as outwrite in one and inread in the otherCyberPhysical Systems and Events 113match. In the composed path, these interactions become silent transitions and disappear,and the remaining interactions are merged. See 33 for details in the case of horizontal,actoractor composition, and 12 for vertical, actormetaactor, composition.6 ConclusionCyber physical systems CPSs are an emerging phenomena. These systems are oftennot only software intensive, but also are tightly integrated with physical system, leadingto many new challenges for design and development. We have proposed eventbased semantics as a semantic foundation for Cyber physical Systems. We discussed a variety ofnotions of event, essential features and challenges for developing eventbased semantics for CPSs. We also sketched two compositional models, one for autonomous agentsand one for interactive agents. The latter providing forms of interaction such as neededin CPSs.References1. Agha, G. Actors A Model of Concurrent Computation in Distributed Systems. MIT Press,Cambridge 19862. Agha, G. Concurrent objectoriented programming. Communications of the ACM 339,125141 19903. Allen, S., Constable, R., Eaton, R., Kreitz, C., Lorigo, L. The Nuprl open logical environment. In McAllester, D. ed. CADE 2000. LNCS LNAI, vol. 1831, pp. 170176. Springer,Heidelberg 20004. Arbab, F., Rutten, J.J.M.M. A coinductive calculus of component connectors. In Wirsing,M., Pattinson, D., Hennicker, R. eds. WADT 2003. LNCS, vol. 2755, pp. 3455. Springer,Heidelberg 20035. Baker, H.G., Hewitt, C. Laws for communicating parallel processes. In IFIP Congress, pp.987992 August 19776. Bickford, M. Specification and derivation of distributed programs using a logic of events2007, Invited lecture for Worshop on Eventbased Semantics 2007,httpblackforest.stanford.edueventsemantics7. Bickford, M. Abstract sequential programs and a logic of events 2008, Invited lecture forWorshop on Eventbased Semantics 2008,httpblackforest.stanford.edueventsemantics8. Bickford, M., Constable, R.L. A causal logic of events in formalized computational typetheory. Technical Report Technical Report 20052010, Cornell University 20059. Clinger, W.D. Foundations of actor semantics. AITR 633, MIT Artificial Intelligence Laboratory May 198110. de Alfaro, L., Henzinger, T.A. Interface automata. In Ninth Annual Symposium on Foundations of Software Engineering FSE, pp. 109120. ACM Press, New York 200111. de Alfaro, L., Henzinger, T.A. Interface theories for componentbased design. In Henzinger,T.A., Kirsch, C.M. eds. EMSOFT 2001. LNCS, vol. 2211, p. 148. Springer, Heidelberg200112. Denker, G., Meseguer, J., Talcott, C.L. Rewriting semantics of distributed meta objectsand composable communication services. In Third International Workshop on RewritingLogic and Its Applications WRLA 2000. Electronic Notes in Theoretical Computer Science, vol. 36. Elsevier, Amsterdam 2000114 C. Talcott13. Denker, G., Talcott, C.L. Formal checklists for remote agent dependability. In Fifth International Workshop on Rewriting Logic and Its Applications WRLA 2004. Electronic Notesin Theoretical Computer Science. Elsevier, Amsterdam 200414. Denker, G., Talcott, C.L. A formal framework for goal net analysis. In Workshop on Verification and Validation of Planning Systems. AAAI Press, Menlo Park 200515. Dvorak, D., Rasmussen, R., Reeves, G., Sacks, A. Software Architecture Themes In JPLsMission Data System. In IEEE Aerospace Conference, USA 200016. Fabrega, F.J.T., Herzog, J.C., Guttman, J.D. Strand spaces Proving cryptographic protocolscorrect. Journal of Computer Security, 191230 199917. Goldin, D., Smolka, S., Attie, P., Sonderegger, E. Turing machines, transition systems, andinteraction. Information and Computation Journal 1942, 101128 200418. Greif, I. Semantics of communicating parallel processes. Technical Report 154, MIT, ProjectMAC 197519. Guttman, J. Strand spaces From key exchange to secure location, Invited lecture for Worshop on Eventbased Semantics 2008 2008,httpblackforest.stanford.edueventsemantics20. Hewitt, C., Bishop, P., Steiger, R. A universal modular actor formalism for artificial intelligence. In Proceedings of 1973 International Joint Conference on Artificial Intelligence, pp.235245 August 197321. Hore, B., Jafarpour, H., Jain, R., Ji, S., Massaguer, D., Mehrotra, S., Venkatasubramanian,N., Westermann, U. Design and implementation of a middleware for sentient spaces. InProceedings of ISI 2007 200722. Kim, M., Kannan, S., Lee, I., Sokolsky, O., Viswanathan, M. JavaMaC A runtime assurance approach for Java programs. Formal Methods in Systems Design 242, 129155200423. Lee, E.A. Concurrent semantics without the notions of state or state transitions. In FormalModeling and Analysis of Timed Systems. LNCS, pp. 1831. Springer, Heidelberg 200624. Lee, E.A., SangiovanniVincentelli, A. A framework for comparing models of computation.IEEE Transactions on ComputerAided Design of Circuits and Systems 1712, 12171229199825. Lee, E.A. Concurrent semantics without the notions of state or state transitions. In FormalModeling and Analysis of Timed Systems. LNCS, pp. 1831 200626. Lee, E.A. The problem with threads. IEEE Computer 395, 3342 200627. Liu, X., Matsikoudis, E., Lee, E.A. Modeling timed concurrent systems. In CONCUR200628. Meseguer, J. Conditional Rewriting Logic as a unified model of concurrency. TheoreticalComputer Science 961, 73155 199229. Meseguer, J., Talcott, C.L. Semantic models for distributed object reflection invited paper.In Magnusson, B. ed. ECOOP 2002. LNCS, vol. 2374, pp. 136. Springer, Heidelberg200230. Meseguer, J. A rewriting logic sampler. In Van Hung, D., Wirsing, M. eds. ICTAC 2005.LNCS, vol. 3722, pp. 128. Springer, Heidelberg 200531. Muscetolla, N., Pandurang, P., Pell, B., Williams, B. Remote Agent To Boldly Go WhereNo AI System Has Gone Before. Artificial Intelligence 10312, 548 199832. Sen, K., Vardhan, A., Agha, G., Rosu, G. Efficient decentralized monitoring of safety indistributed systems. In ACM TOSEM submitted, 2006 invited papers33. Talcott, C.L. Composable semantic models for actor theories. HigherOrder and SymbolicComputation 113, 281343 199834. Talcott, C. Coordination models based on a formal model of distributed object reflection. In1st International Workshop on Methods and Tools for Coordinating Concurrent, Distributedand Mobile Systems MTCoord 2005 2005CyberPhysical Systems and Events 11535. Talcott, C. A formal framework for interactive agents. In Arbab, F., Golden, D. eds. Foundations of Interactive Computation FInCo 2007. Electronic Notes in Theoretical ComputerScience, vol. 203, pp. 95106. Elsevier, Amsterdam 200736. Tidwell, T., Gill, C. Abstract interpretation of time for preemptive scheduling of cyberphysical systems. Position paper for Worshop on Eventbased Semantics 2007 2007,httpblackforest.stanford.edueventsemantics37. Wegner, P. Why interaction is more powerful than algorithms. CACM May 199738. Wegner, P., Goldin, D. Computation beyond turing machines. CACM April 200339. Wegner, P., Goldin, D. The churchturing thesis Breaking the myth. In Cooper, S.B., Lowe,B., Torenvliet, L. eds. CiE 2005. LNCS, vol. 3526, pp. 152168. Springer, Heidelberg200540. Wirsing, M., Denker, G., Talcott, C., Poggio, A., Briesemeister, L. A rewriting logic framework for soft constraints. In WRLA 2006 submitted, 200641. Woo, H., Mok, A.K., Chen, D. Realizing the potential of monitoring uncertain event streamsin realtime embedded applications. Position paper for Worshop on Eventbased Semantics2007 2007, httpblackforest.stanford.edueventsemantics42. Woo, H., Mok, A.K., Lee, C.G. A generic framework for monitoring timing constraintsover uncertain events. In 27th IEEE International RealTime Systems Symposium 2006
