Chapter 1MODELING SECURITY INCYBERPHYSICAL SYSTEMSMike Burmester, Emmanouil Magkos and Vassilis ChrissikopoulosAbstract We propose a framework for modeling the security of cyberphysical systems in which the behavior of the adversary is controlled by a threatmodel that captures both the cyber aspects with discrete values andthe physical aspects with continuous values of such systems in a unifiedway. In particular, it addresses combined dependent vector attacks, andsynchronizationlocalization issues. The framework identifies the cyberphysical features specified by the security policies that need to be protected, and can be used for proving formally the security of cyberphysicalsystems.Keywords Cyberphysical systems, threat models, protocols for treaty verification.1. IntroductionThe rapid growth of information and communication technologies hasprompted the expansion of network computer systems that address realworld applications, including physical and social applications. This hasled to the integration of computing and communication technologies withphysical processes, under the name of cyberphysical systems CPS. CPScapture novel aspects of networked systems that include integrating distributed computing systems with monitoring and controlling entities inthe physical environment. For example, in realtime control systems ahierarchy of sensors, actuators and control processing components areconnected to centralized control stations. Other examples include smartgrid systems and supervisory control and data acquisition SCADA systems that monitor power, gasoil transportation, water and wastewaterdistribution. Such systems used to be standalone networks in physicallyprotected locations, using proprietary technology. Nowadays software,Part of this material is based upon work by the first author supported by the National ScienceFoundation under Grant No. DUE 1027217.2hardware and communication technologies are used to extend their connectivity and improve their operations.Prior work on control systems, by focusing on reliability and resilience,i.e., by protecting CPS against random, independent or benign faults andfailures of cyberphysical components 8, 31, fails to adequately addressintegrity, confidentiality and denialofservice threats 22, 14, 25, 44, 34,13. In addition, traditional computer and network security approachesdo not address in a unified way how systems outlive malicious attackssurvivability or how they recover after an attack recoverability 23,25, 34, 53.Securing a CPS goes well beyond securing the individual system components separately. A motivated and highskilled attacker may use amultivector attack that exploits the weaknesses of the separate components of the system, e.g., the physical and cyber components, none ofwhich may pose a serious threat for the corresponding component. Thecombined effect, however, may be catastrophic the attack vectors maybe dependent. An example of a multivector attack is the Stuxnet attack 24 that targeted nuclear centrifuges in this attack a worm that useszeroday exploits spreads to Windows machines via LAN or USB disks,carrying a malware payload that infects and reprograms programmablelogic controllers. An insider SCADA attack on a sewage treatment system in Maroochy Shire, Queensland, Australia, caused 80,000 liters of rawsewage to be released into local rivers and parks 49. Another exampleof a multivector attack is the Slammer SQL worm attack, in which aprivate computer network at the DavisBesse nuclear power plant in OakHarbor, Ohio, was infected 39.There have been many efforts to ensure the security of CPS. Theseare primarily based on extending mechanisms already used to protectthe separate components cyber and physical of these systems. Howeverthere is no formal security model for CPS that addresses security in aunified framework, and that deals with software threats, hardware threats,network threats and physical threats, possibly combinedalthough thereis a lot of work in the literature highlighting the difficulties in securingphysical systems, in particular with regards to timing attacks 28, 50,38, noninterference 26, execution monitoring 36, 37, 28. One of ourgoals in this article is to address this issue. The approach we shall useis to extend the traditional Byzantine faults model for cryptographicalapplications to cyberphysical systems.In the Byzantine faults paradigm a cyber system is represented by aset of linked abstract machines a graph, some of which may be faulty,and the messages exchanged are represented by formal expressions. Theadversary is active and has full control of the faulty components the adversary can eavesdrop wiretap, intercept, and corrupt any message andis only limited by the constraints of the cryptographic methods used. Inparticular the adversary may be computationally unbounded, polynomially bounded, or bounded by the inability to solve a particular hardBurmester, Magkos  Chrissikopoulos 3problem. To get reliable robust communication for a system with ncomponents with an adversary that is computationally unbounded, thenumber of faulty components t should be less than n2 for a fully connected system. This model focuses on the protocol layer and deals withattacks at this layer resulting from interactions between an active attackerand the system parties in a possibly unbounded number of parallel sessions. There are variants of this model in which the power of the adversaryis restricted, e.g., the adversary may be passive.A slightly different model was proposed by Herzberg et al. in 30. Inthis case the adversary is computationally bounded and the faulty components are periodically repairede.g., compromised keys are refreshed.Security is assured if throughout the lifetime of the system the adversary is restricted to compromising t  n2 components of the system atdifferent times, different components may be compromised, where n isthe number of components. This model captures a physical aspect of thesystem, if we regard the faults as being caused by adversarial operatorsinsiders and assume that components are periodically repaired.Traditional threat models are restrictive and do not capture adequatelythe security of CPS. In particular, they typically exclude survivabilityand recovery. For example, abnormal behavior may be tolerated by aCPS a system may transition to critically vulnerable i.e., unsafe states,but eventually converge to a safe statein the course of time, or with aprobability. Furthermore, in the Byzantine faults model the number offaulty components cannot be reduced in a physical system however, nodesmay become nonfaulty in a dynamic way, e.g., after sporadic humanintervention or because of Nature.Our contribution. The contributions of this article are to1 Discuss the inadequacies of traditional adversary models for CPS.2 Present a high level threat model that captures adversarialbehavior in CPS and that addresses multivector threats of multicomponent systems.3 Show how this adversarial threat model can be used to secure atypical CPS.2. A threat model for cyberphysical systemsA cyberphysical system CPS is a finite state system consisting ofseveral networked components, some of which may be cyber while othersare physical. It can be modeled by a finite, hybrid timed automaton A 7,3, 29 with faults, which is a tuple,A,Q, q0,D,F,with   t1, t2, . . . a strict monotone unbounded time schedule of positivereal numbers, A a finite set of actions that includes a special symbol4, Q 6  a finite set of states that is partitioned into safe states Qs,critical states Qc, and terminal states Qt, q0  Qs an initial state, andD  QQA a transition function that is time triggered for q, q , a  Dand ti   ,Dti  qti,a qdescribes the transition that action a causes at time ti. Critical statesare unsafe states from which the system can recover terminal states areunsafe states from which the system cannot recover. F is the faults distribution of the CPS, that corresponds to component failure. The transition function D is deterministic when a  A and probabilistic whena . When a  the posteriori state q  is selected by Nature using thedistribution F .A timed execution of A is a path that starts at time t1 from state q0r  q0t1,a1 q1t2,a2 q2t3,a3 q3     qi1ti,ai qi    ,and traverses the states qi instantiated by actions ai at time ti.The parties involved in a CPS are those specified by the system e.g.,the operators, the adversary an entity that controls all parties that donot adhere to the system policiesspecifications, and Nature the Environment. We use the Game Theory paradigm to model Nature. Inparticular,a Nature uses the probability distribution F to select from among herstrategies for component failure randomly.b Nature controls the temporal and location aspects of all events andschedules the state transitions in a timely manner according to thetime schedule  .c Nature resolves concurrency issues, by linking events to their real starttime if two events take place during ti1, ti then Nature will schedulethem according to the order in which they occurred.1The threat model for a CPS must capture those features of the systemthat may lead to system failure and the adversarial intent. System failurecan result from actions by Nature, the adversary or both the adversarycan manipulate Nature, e.g., in a terrorist attack. The adversary canbe passive or active. Passive adversaries are restricted to eavesdroppingon communication channels active adversaries can additionally modifythe contents of the communication channels and use compromised components to undermine the security of the system.Our threat model restricts the adversary to exploiting specific systemvulnerabilities. These are identified bya The security policies of the system e.g., availability of services, resilience, privacy of records, etc,b Vulnerability assessments 19, andBurmester, Magkos  Chrissikopoulos 5 itD if tD, 11 ii qt , ii qtff1iV iVFigure 1. The mapping f that identifies the prioriposteriori vulnerabilities of thestates qi1, qi of the transition Df  .c Greybox penetration testing 19.The vulnerabilities involve the components of the system, such as thecontrol systems and the embedded systems and the communication channels, but may also involve the system A as a whole. The security goal ofA is to prevent the adversary from exploiting these features.Let V  v1, v2, . . . , vm be the set of identified features of the statesof Q that are vulnerable and need to be protected. The features vi arevectors with discrete andor continuous values. The vulnerabilities of aCPS may be timedependent. That is, the adversary may only be able toaccess vi  V some times ti.2 To identify the vulnerabilities at time ti weuse the functionf  ,Q 7 2V  ti, qj  fiqj  V,that specifies the vulnerabilities of state qj the adversary can exploit attime ti. The threat model of A is defined by a timed vulnerabilities transition function Df Df ti  fi1qj1ti,a fiqj,that specifies the priori and posteriori features of an adversarial exploitattackduring ti1, ti Fig. 1. In a passive attack the adversary can eavesdropon the priori fi1qj1features and the posteriori fiqjfeatures, andno more. In an active attack the adversary can also cause a transitionDf ti, and exploit the priori and posteriori features. We assume that theadversary may have prior knowledge of the vulnerabilities vj  V of thesystem and the structure of Df ti, but not necessarily their values vj.Definition 1 An adversary that is restricted to the vulnerabilities ofthe transitions Df  is called a Df adversary. The automaton Ais Df tolerant if it operates as specified in the presence of a Df adversary.The specifications for the automaton A typically require that the system should never enter into a terminal state, and that it should not stayin a critical state for longer than a certain time period. Df toleranceguarantees resilience against adversaries that try to exploit the vulnerabilities v  V of A and cause it to transition to a state that violates itsspecifications.6Traditional threat models for cyber systems such as the Byzantinefaults model 21 do not capture physical aspectsfeaturesbehavior. Forexample, the state of a system that uses a wireless medium for communication such as a sensor andor RFID system contains discrete valuesextracted from continuous values e.g., RF waveforms. There are severalattacks that exploit such physical system aspects. For exampleOnline maninthemiddle relay attacks 6, 33 in which the adversary interposes between parties and relays messages, andSide Channel and Power Analysis attacks 43 in which the adversary exploits information leaked during the physical implementationof protocols.Both attacks are at the physical layer and are typically excluded fromcyber threat models and their security analysis 11. To protect againstsuch attacks, one needs physical layer mechanisms such as temporalandor location mechanisms, screening, etc.To motivate our approach we show how the transition function Df is used to model the vulnerabilities of some cyber and cyberphysicalsystems.2.1 The Byzantine faults modelThe Byzantine model 21 assumes a system with n cyber componentsand an adversary that may compromise up to k  n components. In thiscase the identified vulnerabilities are fti, qj  Vj , where Vj  V is a setof j  0  k faulty components of qj. The threat transition function isDf ti  Vjti,a Vs,where Vj  Vs. That is, an adversary that has compromised the components of Vj is restricted to attacking those states with Vs  Vj . Thisdefines the allowable system transitions that the adversary can exploit.Note that for this model, faulty components cannot recover.For the model proposed by Herzberg et al. 30, discussed in the Introduction, the state of the system is repairedrefreshed at regular intervals. This relabels the faulty components. We then get fti, qj  z,0  z  k, the number of faulty components. For this model the vulnerabilities transition function isDf ti  zti,a z,where z can be any number in 0  k, if the system has been refreshedduring ti1, ti. Otherwise, 0  z  z  k. In this threat model thetransitions allow for a reduction of the number of faulty componentsfor example, if at some point in time the number of faulty componentsis z  k, then in the next time period there may be no faulty componentif faulty components are replaced by with nonfaulty components. ThisBurmester, Magkos  Chrissikopoulos 7captures the behavior of certain types of physical faults, e.g., faults thatcan be fixed.Such models are typical of physical systems that may tolerate criticalstate levels provided the system can recover, e.g., provided the faults arefixed and their duration is short. In this cyberphysical model the duration is enforced by Nature, and cannot be manipulated by the adversary.In the Byzantine model the adversary controls the communicationchannels of the system which messages are sent, which messages arereceived, to whom or by whom, as well as which messages get compromised through faulty components devices andor channels. This appliesto our model as well, when the communication channels are identified asvulnerabilities.2.2 Threat transitions for network trafficFor this model fti, q  z1, . . . , zn, Z, where zi is the number ofpackets sent by node Ni, i  1, . . . , n, in a network domain and Z isthe traffic volume in that domain in packets during the time intervalti1, ti. We distinguish three cases for zic1  zi  a, c2  a  zi  b, c3  b  zi,with 0  a  b, where a is an upper bound for normal use and b themaximum tolerated value for packet transmissions permitted for shortperiods only and three cases for ZC1  Z  A, C2  A  Z  B, C3  B  Z,with 0  A  B, where A is a threshold for domain traffic and B themaximum tolerated level.States for which the constraint C3 holds are terminal, and will leadto domain shutdown. Similarly, nodes that violate the constraint c3 aredenied access to the domain.3 States for which C2 holds are critical. Thethresholds a,A are such that Z  A if, and only if, for all nodes Ni wehave zi  a. The system specifications require that when the state of thesystem is critical A  Z  B then all nodes Ni for which zi  a reducethe number of packets sent to  a at time ti. Finally, states bound by C1are safe, provided all the zi are bounded by the constraints c1 or c2. Forthis model, the vulnerabilities transition functionDf ti  z1, . . . , zn, Zti,a z1, . . . , zn, Zrequires that priori and posteriori states are not terminal, and that ifa priori state is critical then the posteriori state must be safe so zi a implies zi  a. This restricts the adversary to attacking states forwhich the traffic volume Z is bounded by A over time. Df toleranceis achieved by requiring that, whenever the traffic volume exceeds A, allnodes Ni for which zi  a reduce the number of packets sent to zi  a attime ti.8A B C FCS A FCS B FCS C Communications network flow A flow B flow C D flow D FCS D flow A Figure 2. The RussiaUkraine natural gas grid with subnetworks B North EU, DUkraine and C South EU.This model addresses attacks in which the adversary may try to exploitthe dependence between the vulnerabilities zi and Z e.g., when somenodes send zi  b  zi  a packets constraint c2 and the traffic loadis critical constraint C2. This behavior is checked by restricting theadversary to transitions that lead to states with lesser traffic load. Thenetwork is allowed to stay in a critical state for short periods one timeinterval in this case. This is a temporal feature that captures a physicalsecurity aspect that is normally excluded from the threat model of cybersystems, and highlights one of the main differences between cyber andphysical systems.3. Protecting a natural gas gridThis model is motivated by the RussianUkrainian dispute over theprice of natural gas and the cost of its transportation, which threatenedthe gas supplies to the European Union EU from 2005 to 2010 17.Russia provides approximately one quarter of the natural gas consumedin the EU, and 80 of this is piped across Ukraine to reach the EU.Ukraine manages the natural gas grid within Ukraine. For this serviceUkraine is allocated a certain amount of natural gas, drawn from thepipeline grid.The RussiaUkraine grid starts in Russia and branches in Ukraine, withone branch going to the EU while the other is for domestic supplies.In this paper we consider an application for which the EU pipeline hastwo branches, one for North EU subnetwork B, the other for SouthEU subnetwork Csee Figure 2 a slightly different application wasinvestigated and analyzed in 1. Subnetwork A supplies the natural gasBurmester, Magkos  Chrissikopoulos 9from Russia, and subnetwork D provides Ukraine with its allocation. Weshall refer to this as the RU natural gas grid, or simply the RU grid.We denote by flowA, flowB, flowC and flowD the flows of the subnetworks A,B,C and D respectively. The Ukraine entitlement flowD is10 of the natural gas that flows to North EU and 5 of the natural gasthat flows to South EU. That is,flowD  10flowB  5flowC .Natural gas flows are regulated by Flow Controller Systems FCS whichautomate and control the gas flowing through the pipeline, and enforceflow agreements. A FCS has sensors, actuators, an embedded programmablelogic controller PLC and a transceiver. The PLC controls the flows inthe pipeline and communicates with neighboring FCS to regulate flows.It can execute commands that raise or lower the flows. In the RU gridthree flow controllers FCSA, FCSB and FCSC are controlled by Russia,and regulate the flows coming from Russia and going to North and SouthEU respectively. A fourth flow controller FCSD, controlled by Ukraine,regulates the natural gas allocated to Ukraine. All four controllers arelocated in Ukraine.SAF Safety specifications.The value of flowi, i  A,B,C,D, should not exceed the critical threshold flow level and normally be within a safe rangethethresholds and ranges are system parameters.0  flowA  flowB  flowC  flowD  , where  is a smallflow variation corresponding to typical gas leakagesfluctuationsasystem parameter.SEC Security specifications.Flow privacy The values of flowA, flowB and flowC should notbe inferable from signals transmitted by the flow controllers FCSA,FCSB and FCSC .Flow integrityverifiability At all times flowD  10flowB 5flowC  . Furthermore Ukraine should be able to verify correctness.Threat model, the Df adversary. The vulnerabilities that areidentified by the system specifications of the RU grid concern the flowsflowA, flowB, flowC , flowD SAF and its communication channelsSEC. In particularfstate  flowA, f lowB, f lowC , f lowD, z5, z6,with z5  flowAflowBflowCflowD and z6  20flowD2flowBflowC .10The constraints for the safe, critical and terminal flow levels are specified byc1  0  flowA  y1, c1  y1  flowA  y1, c1  y1  flowA,c2  0  flowB  y2, c2  y2  flowB  y2, c2  y2  flowB,c3  0  flowC  y3, c3  y3  flowC  y3, c3  y3  flowC ,c4  0  flowD  y4, c4  y4  flowD  y4, c4  y4  flowD,c5  0  z5  , c5    z5,c6  0  z6  , c6    z6,where yi, yi, i  1, 2, 3, 4, are system parameters with y2  y3  y4 y1  y1  y2  y3  y4. States that are bound by the constraints ci,i  1  6, are safe. States bound by ci, i  1  4 are critical and requirean action to reduce flows flowA, flowB, f lowC and flowD should bereduced proportionately to the levels of the constraints ci, i  1  5,while maintaining c6. Finally, states for which one of c1 , c2 , c3 , c4 , c5, c6holds are terminal. When c1 , c2, c3 , or c4 hold, the flow in one of thesubnetworks of the pipeline grid exceeds the safety levels. When c5 holdsthen the pipeline grid has a leakage that exceeds the safety levels. Whenc6 holds, the flow of natural gas to Ukraine exceeds the allowed levelscontractual allocation. If the system transitions to a terminal state,then it will shut down with all flows reduced to zero.The security specifications SEC require that Ukraine should not haveaccess to the values of the flows to South EU and North EU. Also, thatUkraine should be able to verify that it gets its correct allocation ofnatural gas.Verification with privacy. Several cryptographic mechanisms can beused to support an application in which one party Ukraine can verifythe correctness of a particular value its gas allocation without gettingany additional information about other component values the gas flowsto South EU and North EU.Clearly Ukraine may get such information by using covert channels,e.g., by accessing the pipelines directly, or accountsreceipts and payments made by South EU and North EU, if these are available. Ourthreat model does not address security aspects that are not part of thesecurity specifications, and assumes that the RU agreement protocol isbased only on readings taken at FCSB, FCSC and FCSD. However, ifcovert channels are an issue, then the system vulnerabilities must takethis feature into accountthis extends the scope of an Df adversary,and Df tolerance requires additional protection.4We now describe a cryptographic protocol that can be used by Ukraineto verify the correctness of flows while providing privacy to Russia. Thesecurity of this protocol reduces to the Decision DiffieHellman DDHassumption.Burmester, Magkos  Chrissikopoulos 11Definition 2 The DDHassumption. Let Gq be a cyclic group of primeorder q with generator g. The DDHassumption concerns the indistinguishability of tuples of type g, gx, gy , gxy, 0  x, y  q, called DHtuples, from general tuples g, gx, gy , gz, 0  x, y, z  q. Let D0 be theset of DHtuples and D1 the set of nonDH tuples with z 6 xy mod q.A DDHdistinguisher D is a probabilistic polynomialtime algorithm inthe length q of q that on input a tuple T  Di, i a random bit, willpredict its type with probability better than 12. More specifically, thereis a constant   0, such that for sufficiently large q on input a tuple Tselected uniformly from Di, i a random bit,PrDT   typeT   i  T  Di 12 q, i  0, 1here q is a nonnegligible quantity. The DDHassumption is that forsome families of groups Gq including the one considered below there isno DDHdistinguisher. For more details see 9.The Flow Verification protocol uses a family of multiplicative integergroups Zp whose modulus is a safe prime p, that is p  2q  1, whereq is a prime. Let g  Zp have order q and Gq be the subgroup generatedby g. Set b  flowB, c  flowC , d  flowD. We shall assume that b, care rounded to an integer value and that 2b  c  q.A Flow Verification protocol for the RU gridFCSB Read flow b select tb uniformly from Zq compute yb  g2btb .Send to FCSC  yb.FCSC  Read flow c and message yb select sc, tc uniformly from Zqcompute xc  gsc , yc  ybtc  g2btbtc . Send to FCSB  yc.FCSB Read message yc compute zb  ytb1c  g2btc .Send to FCSC  zb.FCSC  Read zb compute zc  zt1c  scb  xcc  g 2bcsc .Send to FCSD xc, zc.FCSD Read flow d and xc, zc compute zd  x20dc .If zd  zc then send to the verifier valid.This protocol captures correctness5 because 20d  2b  c. It usesa oneway homomorphic function, whose security reduces to the DDHassumption, as we shall see.Definition 3 Oneway homomorphic functions. A mapping F  G  Hfrom a group G to a group H is a oneway homomorphism ifa F is oneway that is, it is infeasible for a probabilistic polynomialtime algorithm to invert any y  F x.b F x  y  F x  F y, for all x, y  G.12In the Flow Verification protocol the flow controllers FCSB and FCSCgenerate the proof. The verifier Ukraine employs FCSD to verify theproof.We shall assume that the flow controllers of the RU grid are tamperresistant, that FCSB and FCSC are managed by Russia, and that FCSDis managed by Ukraine. That is, even though all three FCSs are locatedin Ukraine, Ukraine has physical access only to FCSD, with Russia havingaccess to FCSA, FCSB and FCSC . Also that the embedded programmablelogic controllers PLC are trusted and autonomous. The components ofthe FCS can be checked by all parties concerned6 prior to deployment. Weshall also assume that the communication channels between the FCS arereliable and authenticated this can be achieved by employing redundancyand using cryptographic authentication mechanisms either Message Authentication Codes MAC or digital signatures. Digital signatures mustbe used for validation. The communication can be over fixed lines, orwireless.The Df adversary can be any party other than the prover. For ourapplication the adversary is an insider possibly Ukraine who knows thevalue of 2b  c this should be 20d, where d is the amount of naturalgas allocated to Ukraine. The goal of the adversary is to undermine theprivacy of the flows b,c.Theorem 4 Suppose that1 FCSA, FCSB, FCSC and FCSD are tamperresistant2 The communication channels linking FCSA, FCSB, FCSC and FCSDare reliable and authenticated.Then the RU pipeline grid will tolerate an Df adversary.Proof. The first requirement implies that the adversary cannot accessthe inner state of the FCS e.g., the values of b, c or the randomnesstb, sc, tc used to compute their outputs. The second that transmissionsare reliable and the origin of messages can be established.The embedded programmable logic controllers of the FCS can be designed to enforce Df tolerance since we are assuming that i they arenot faulty, ii their communication channels are trusted, and iii thesystem is autonomous. Insider threats on the FCS are thwarted becausethe system is autonomous with tamperproof components. Theorem 5 Suppose the RU pipeline grid is Df tolerant, and that1 There are no covert channels that leak the values b, c.2 The DDHassumption holds.Then the Flow Verification protocol is correct and provides privacy for theflows b, c against an eavesdropping Df adversary who knows the valueof the flow d.Burmester, Magkos  Chrissikopoulos 13Proof. The first assumption states that the Df adversary cannot findthe values of b, c by using some other means, external to the protocol, e.g.,by accessing directly the pipelines, or monitoring the EU gas consumptionpayments. Correctness follows from the fact that 20d  2b  c.For the privacy of b, c, suppose that an eavesdropping Df adversaryE can access the valuesg2btb , g2btc , g2btbtc , and gsc , g2bcscof the communication channels of the RUgrid. Since we are assumingthat E knows the value of d, and 20d  2b  c, the last two values donot contribute any additional knowledge regarding the values of b and c.To prove the privacy of b in the presence of E we consider an experimentPriveavE in which E chooses two values b0, b1 of b, and is then given theobfuscated tupleTbi  g, g2bitb , g2bitc , g2bitbtcof one of these, where i is random uniform bit. In this experiment theadversary E a probabilistic polynomialtime algorithm must find whichone of b0, b1 was used in Tbi .7 Of course E can toss a coin to guess whichone was encrypted. He will succeed with probability 12. Suppose that Ecan find the correct value bi with probability 12 ,   q. We shallshow that  is negligible in q by reducing E to a DDHdistinguisher D.Let T  g, gx, gy, gz be the Gqtuple input to the distinguisher. Dmust decide if this is a DHtuple that is, if z  xy mod q, or not. Forthis purpose D queries E for two values b0, b1 and then computes the tupleT bi  g, g2bix, g2biy, g2biz,where i is a random bit. The distinguisher D gives T bi to the adversaryE in the experiment PriveavE , instead of Tbi . If E predicts that the value biwas used in the computation of T bi then Ds prediction is that T is a DHtuple z  xy mod q. D outputs 1. Otherwise D tosses a coin, and basesits prediction on the outcome of the toss 0 or 1. It is easy to see thatthe probability that D will distinguish DHtuples output 1 is 12 2,since E will succeed with probability  whenever T is a DHtuple. Thenby the DDHassumption, 2 and hence  must be negligible in q. Thiscompletes the proof. Remark 6 The Flow Verification protocol is a proof that the cyberequation 20d  2b  c  0 holds, whereas for correctness we have toshow that the physical inequality 0  20d  2b  c   holds. Forthis particular application there is a simple fix, however in general usinga cyber mechanism cryptography to secure a physical system may beinadequate, and we may have to use hybrid security mechanisms.To show that the proof is valid we first sandbox the Flow Verificationprotocol to separate it from the Df tolerance supporting mechanisms.We then calculate the value of flows by using a unit of measurement for14which 14 unit  . We take integer values and map these to Zq. Forexample, if the flow measurement is x, it is first reduced by using a newmeasurement unit to get x units, and then it is reduced to its integer valuex  x in Zq. This approach is good enough for applications in whichthe fluctuations in measured values are small. Observe that the exact flowvalues x, as measured at the FCSs, are used to prove Df tolerance.Remark 7 A change of flow in the flow controller FCSA will only registerat one of the flow controllers FCSB, FCSC , or FCSD, at a later time 42.To deal with time dependencies of flows, the values of flowA, flowB,flowC , flowD are timestamped, and when verifying the values of flowallocations such delays should be taken into account.4. Related workIn a CPS, distributed computing components interact with the physicalenvironment. Several approaches have been proposed for modeling a CPSA hybrid automaton 2, 29, 40 is a formal model that combines finite statetransition systems with discrete variables whose values capture the stateof the modeled discrete or cyber components and continuous variableswhose values capture the state of the modeled continuous or physicalcomponents. In another related formalism, timed automata 3, 32 canmodel timing properties of CPS. Such machines are finite automata witha finite set of realvalued clocks. They accept timed words, i.e., infinite sequences in which a realtime of occurrence is associated with eachsymbol.Hybrid process algebras 5, 18 are a powerful tool used for reasoning aboutphysical systems and provide techniques for analysis and verification ofsecurity protocols for hybrid automata. Bond graphs 47 are used to synthesize mixed component systems, with electrical, mechanical, hydraulic,thermal and more generally, physical components. Bond graphs are domain independent, allow free composition, and allow efficient analysisand classification of models, permitting rapid determination of varioustypes of feasibility or acceptability of candidate designs. Genetic programming 35 is an evolutionary algorithmbased methodology inspired by biological evolution. It is a powerful tool for finding computer programs thatperform a userdefined task. When combined with bond graphs it provides for better synthesis of complex mixed component systems. Hybridbond graphs 45 combine bond graphs with hybrid automata to providea uniform, physicsbased formal model that incorporates controlled andautonomous mode changes as idealized switching functions.Security and survivability goals, threats and attacks on CPS controlsystems, as well as proactivereactive mechanisms for robust distributedcontrol and distributed consensus in the presence of deception and DoSadversaries are summarized in 14, 13. A survey of vulnerabilities, failures and attacks on realtime distributed control systems, as well as ofmitigation recovery strategies is given in 34. A taxonomy of attacksBurmester, Magkos  Chrissikopoulos 15against energy control systems was also given in 25. Data replay threatson control systems are studied and formulated in 44. A comprehensivethough, informal threat model and a taxonomy of attacks against sensor networks in SCADA systems was given in 15, while an emphasison monitoring and intrusionanomaly detection methodologies and automatic response for control systems, as well as a formalism of the anomalydetection problem is given on 13. In 13 risk assessment formalisms areproposed for measuring the possible damages caused by cyber attacks oncontrol systems.In 31 failures and fault tolerance in distributed CPS are modeled,where such CPS are modeled as distributed algorithms executed by aset of agents and the continuous dynamics of the CPS are abstracted asdiscrete transitions. An informal attack model for energy control systemsis given in 25, where attacks are related to the vulnerabilities they exploitand the damages they cause. Finite state machine models based on Petrinets have also be proposed to describe cyber attacks 52. Other attackmodels also include attacks trees 46, where the root node denotes thegoal of an attacker and a path from leaf nodes to the root node denotesan attack instance, i.e., the steps for completing the attack 51 attacktrees are criticized in 12. A model using graph theory for expressingcontrol system failures and attacks is also given in 12. In 16 a languagefor modeling multistep attack scenarios on process control systems wasproposed, enabling correlation engines to use these models to recognizeattack scenarios.In another realm, stochastic approaches were initially proposed formodeling the different probabilities with which failures occur in distributedcomputing systems 4. Game theoretic techniques and formalisms formodeling attacks and defense strategies in CPS were given in 41. There,the game is between an attacker and the defender of a CPS system, wherethe attacker tries to disrupt either the cyber or the physical system components. Finally, access control and information flowbased policies forCPS security are analyzed in 1, 27, while in 27 a framework to enforceinformation flow policies in CPS in order to obfuscate the observable effects of a system is presented.5. ConclusionWe proposed a threat framework for cyberphysical systems. This isbased on the traditional Byzantine paradigm for cryptographic securityin which the basic security features and requirements as specified by thesecurity policies are used to identify system vulnerabilities. This modelallows for a formal analysis and a security proof using existing cryptographic methodologies.Notes1. We are assuming that only a countable number of events are related to the execution ofA, so their start time is a sparse subset of the realtime set the positive real numbers.162. An insider may only be able to access system software while it is servicedupgraded.3. For this model the system can easily recover from a shutdown.4. The challenge of preventing covert channels should not be underestimated, particularlyin cases where it is possible to collect information leaked from third parties e.g., throughpayments made. The issue here is that such information cannot be used to violate the treatythough it may provide side information. A similar issue, but strategic, is discussed in Footnote 6.5. The values of the flows must be securely linked to the time and location of their readingtimestamps should be included in all messages.6. The Strategic Arms Limitation Treaty SALT II between the United States and the SovietUnion 19771979 sought to curtail the number of Inter Continental Ballistic Missiles ICBMto 2,250 on each sides. This would involve installing tamperresistant sensor control units inthe ICBM silos to detect the presence of missiles. The sensors were to be used to verify thenumber of deployed ICBM. Both parties would have access to this information, but to no otherinformation, particularly regarding the location of the responding silos 48, 20, 10.7. Indistinguishability of obfuscated data by a polynomialtime adversary captures a strongaspect of privacy, and is the basis for semantic security.References1 R. Akella, H. Tang, and B. McMillin, Analysis of information flowsecurity in cyberphysical systems, International Journal of CriticalInfrastructure Protection, vol. 334, pp. 157173, 2010.2 R. Alur, C. Courcoubetis, T. Henzinger, and P. Ho, Hybrid automataAn algorithmic approach to the specification and verification of hybrid systems, Hybrid Systems, LNCS vol. 736, pp. 209229, SpringerBerlin Heidelberg, Germany, 1992.3 R. Alur and D. Dill, A theory of timed automata, Theoretical Computer Science, vol. 1262, pp. 183235, 1994.4 O. Babaoglu, On the reliability of consensusbased faulttolerantdistributed computing systems, ACM Transactions on ComputerSystems, vol. 54, pp. 394416, 1987.5 J. Baeten, B. Beek, P. Cuijpers, M. Reniers, J. Rooda, R. Schiffelers,and R. Theunissen, Modelbased engineering of embedded systemsusing the hybrid process algebra Chi, Electronic Notes in TheoreticalComputer Science, vol. 209, pp. 2153, 2008.6 S. Bengio, G. Brassard, Y. Desmedt, C. Goutier, and J. Quisquater,Secure implementations of identification systems, Journal of Cryptology, vol. 43, pp. 175183, 1991.7 J. Bengtsson and W. Yi, Timed Automata Semantics, Algorithmsand Tools, Lectures on Concurrency and Petri Nets, LNCS vol. 3098,pp. 87124, SpringerBerlin Heidelberg, Germany, 2003.8 M. Blanke, M. Kinnaert, J. Schroder, and J. Lunze, Diagnosis andfaulttolerant control. SpringerVerlag Berlin Heidelberg, Germany,2006.9 D. Boneh, The Decision DiffieHellman Problem, Proceedings of theThird International Symposium on Algorithmic Number Theory, pp.4863, 1998.Burmester, Magkos  Chrissikopoulos 1710 M. Burmester, Y. Desmedt, T. Itoh, K. Sakurai, H. Shizuya, andM. Yung, A progress report on subliminalfree channels, Proceedingsof the First International Workshop on Information Hiding, pp. 157168, 1996.11 M. Burmester, T. Le, B. Medeiros, and G. Tsudik, Universallycomposable RFID identification and authentication protocols, ACMTransactions on Information and System Security, vol. 124, pp.133, 2009.12 J. Butts, M. Rice, and S. Shenoi, Modeling control system failuresand attacksthe Waterloo campaign to oil pipelines, Proceedings of4th Annual IFIP Working Group 11.10 International Conference onCritical Infrastructure Protection, pp. 4362, 2010.13 A. Cardenas, S. Amin, Z. Lin, Y. Huang, C. Huan, and S. Sastry, Attacks against process control systems risk assessment, detection, andresponse, Proceedings of the 6th ACM Symposium on Information,Computer and Communications Security, pp. 355366, 2011.14 A. Cardenas, S. Amin, and S. Sastry, Secure control Towards survivable cyberphysical systems, Proceedings of the 28th IEEE International Conference on Distributed Computing Systems Workshops,pp. 495500, 2008.15 A. Cardenas, T. Roosta, and S. Sastry, Rethinking security properties, threat models, and the design space in sensor networks A casestudy in SCADA systems, Ad Hoc Networks, vol. 78, pp. 14341447, 2009.16 S. Cheung, U. Lindqvist, and M. Fong, Modeling multistep cyber attacks for scenario recognition, Proceedings of the 3rd DARPA Information Survivability Conference and Exposition, pp. 284292, 2003.17 E. Chow and J. Elkind, Where East meets West European gas andUkrainian reality, The Washington Quarterly Center for Strategicand International Studies, vol. 321, pp. 7792, 2009.18 P. Cuijpers, J. Broenink, and P. Mosterman, Constitutive hybridprocesses a processalgebraic semantics for hybrid bond graphs, Simulation, vol. 847, pp. 339358, 2008.19 DHS and CPNI, Cyber Security Assessments of Industrial ControlSystems, Control Systems Security Program, Natioanl Cyber SecurityDivision, November, 2010.httpwww.uscert.govcontrol systemspdfCyber Security Assessments of Industrial Control Systems.pdf20 W. Diffie, The national security establishment and the developmentof publickey cryptography, Designs, Codes and Cryptography, vol.72, pp. 911, 1995.21 D. Dolev, The Byzantine generals strike again, Journal of Algorithms, vol. 31, pp. 1430, 1982.1822 J. Eisenhauer, P. Donnelly, M. Ellis, and M. OBrien, Roadmapto secure control systems in the energy sector, Energetics Incorporated, Columbia, Maryland, USA httpenergy.govsitesprodfilesoeprodDocumentsandMediaroadmap.pdf, 2006.23 R. Ellison, D. Fisher, R. Linger, H. Lipson, T. Longstaff, andN. Mead, Survivable network systems An emerging discipline, Technical report, CMUSEI97TR013, Carnegie Mellon, Software Engineering Institute, Pittsburgh, USA, 1997.24 N. Falliere, L. Murchu, and E. Chien, W32.stuxnet dossier, version 1.4, Symantec Security Response httpwww.symantec.com,February 2011.25 T. Fleury, H. Khurana, and V. Welch, Towards a taxonomy of attacks against energy control systems, Proceedings of the 2nd AnnualIFIP Working Group 11.10 International Conference on Critical Infrastructure Protection, pp. 7185, 2009.26 T. Gamage and B. McMillin, Enforcing information flow propertiesusing compensating events, Proceedings of the 42nd Hawaii International Conference on System Sciences, pp. 17, 2009.27 T. Gamage, B. McMillin, and T. Roth, Enforcing information flow security properties in cyberphysical systems A generalized frameworkbased on compensation, Proceedings of the 34th Annual IEEE Computer Software and Applications Conference Workshops, pp. 158163,2010.28 K. Hamlen, G. Morrisett, and F. Schneider, Computability classesfor enforcement mechanisms, ACM Transactions on ProgrammingLanguages and Systems, vol. 281, pp. 175205, 2006.29 T. Henzinger, The theory of hybrid automata, Proceedings of the11th Annual IEEE Symposium on Logic in Computer Science, pp.278292, 1996.30 A. Herzberg, S. Jarecki, H. Krawczyk, and M. Yung, Proactive secret sharing or How to cope with perpetual leakage, Proceedings ofthe 15th Annual International Cryptology Conference on Advancesin Cryptology CRYPTO 95, pp. 339352, 1995.31 T. Johnson, Faulttolerant distributed cyberphysical systems Twocase studies, Masters Thesis, University of Illinois, Department ofElectrical and Computer Engineering, Urbana, USA, 2010.32 D. Kaynor, N. Lynch, R. Segala, and F. Vaandrager, The theory oftimed IO automata, Synthesis Lectures on Distributed ComputingTheory, vol. 11, pp. 1137, 2010.33 C. Kim, G. Avoine, F. Koeune, F. Standaert, and O. Pereira, Theswissknife RFID distance bounding protocol, Proceedings of the11th International Conference on Information Security and Cryptology ISC 08, pp. 98115, 2008.Burmester, Magkos  Chrissikopoulos 1934 R. Kisner, W. Manges, T. Mcintyre, J. Nutaro, J. Munro, P. Ewing,M. Howlader, P. Kuruganti, and M. Olama, Cybersecurity throughrealtime distributed control systems, Technical report, Oak RidgeNational Laboratory ORNL, Oak Ridge, Tennessee, USA, 2010.35 J. Koza, Genetic Programming On the Programming of Computers by Means of Natural Selection, MIT Press, Cambridge, London,England, 1992.36 L. Lamport, Proving the correctness of multiprocess programs, IEEETransactions on Software Engineering, vol. 32, pp. 125143, 1997.37 L. Lamport, Proving possibility properties, Theoretical ComputerScience, vol. 20612, pp. 341352, 1998.38 L. Lamport, Realtime model checking is really simple, Proceedings of the 13th Advanced Research Working Conference on CorrectHardware Design and Verification Methods, pp. 162175, 2005.39 E. Levy, Crossover Online pests plaguing the offline world, IEEESecurity  Privacy, vol. 16, pp. 7173, 2003.40 N. Lynch, R. Segala, F. Vaandrager, and H. Weinberg, Hybrid IOautomata, Proceedings of the DIMACS Workshop on Verificationand Control of Hybrid Systems, pp. 496510, 1995.41 C. Ma, N. Rao, and D. Yau, A game theoretic study of attack anddefense in cyberphysical systems, Proceedings of the 1st IEEE International Workshop on CyberPhysical Networking Systems, pp. 708 713, 2011.42 B. McMillin, personal communication, 2012.43 S. Mangard, E. Oswald, and T. Popp, Power analysis attacks  revealing the secrets of smart cards, SpringerVerlag New York, USA,2007.44 Y. Mo and B. Sinopoli, Secure control against replay attacks, Proceedings of the 47th Annual Allerton Conference on Communication,Control, and Computing, pp. 911918, 2009.45 I. Roychoudhury, M. Daigle, P. Mosterman, G. Biswas, and X. Koutsoukos, A method for efficient simulation of hybrid bond graphs,Proceedings of the International Conference on Bond Graph Modeling ICBGM 2007, pp. 177184, 2007.46 B. Schneier, Attack trees, Dr. Dobbs journal, vol. 2412, pp. 2129,1999.47 K. Seo, Z. Fan, J. Hu, E. Goodman, and R. Rosenberg, Toward anautomated design method for multidomain dynamic systems usingbond graph and genetic programming, Mechatronics, vol. 1389,pp. 851885, 2003.48 G. Simmons, Personal communication, 1993.49 J. Slay and M. Miller, Lessons learned from the Maroochy waterbreach, Proceedings of the 1st Annual IFIP Working Group 11.1020International Conference on Critical Infrastructure Protection, pp.7382, 2007.50 H. Tang and B. McMillin, Security property violation in CPS throughtiming, Proceedings of the 28th International Conference on Distributed Computing Systems Workshops ICDCS 08, pp. 519524,2008.51 C. Ten, C. Liu, and G. Manimaran, Vulnerability assessment ofcybersecurity for SCADA systems, IEEE Transactions on PowerSystems, vol. 234, pp. 18361846, 2008.52 R. Wu, W. Li, and H. Huang, An attack modeling based on hierarchical colored Petri nets, Proceedings of the 1st InternationalConference on Computer and Electrical Engineering ICCEE 08,pp. 918921, 2008.53 K. Xiao, S. Ren, and K. Kwiat, Retrofitting cyber physical systemsfor survivability through external coordination, Proceedings of the41st Hawaii International Conference on Systems Science HICSS08, pp. 454466, 2008.
