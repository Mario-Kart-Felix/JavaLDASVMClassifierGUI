www.xilinx.comxcellS O L U T I O N S  F O R  A  P R O G R A M M A B L E  W O R L DXcell journalI S SUE  83 ,  S ECOND QUAR TER  2013  How OpenCV and Vivado HLS  Accelerate Embedded Vision AppsHow to Configure Your Zynq SoC BareMetal SolutionUsing Xilinxs Power Estimator and Power Analyzer ToolsVivado Design Suite 2013.1 Available for DownloadAll Eyes on Zynq SoC forSmarter Vision Inside Xilinxs HighLevel Synthesis Tool page32Avnet Electronics Marketing presents a new series of videobased SpeedWay Design Workshops, featuring the new Xilinx Zynq7000 All Programmable SoC Architecture. This workshop series includes three online courses progressing from introductory, through running a Linux operating system on the Zynq7000 SoC, and finally to the integration of the highspeed analog signal chain with digital signal processing from RF to baseband for wireless communications. Avnet, Inc. 2013. All rights reserved. AVNET is a registered trademark of  Avnet, Inc. Xilinx and Zynq are trademarks or registered trademarks of Xilinx, Inc.www.zedboard.orgtrainingsandvideoswww.zedboard.orgL E T T E R  F R O M  T H E  P U B L I S H E RXilinx, Inc.2100 Logic DriveSan Jose, CA 951243400Phone 4085597778FAX 4088794780www.xilinx.comxcell 2013 Xilinx, Inc. All rights reserved. XILINX, the Xilinx Logo, and other designated brands includedherein are trademarks of Xilinx, Inc. All other trademarks are the property of their respective owners.The articles, information, and other materials includedin this issue are provided solely for the convenience ofour readers. Xilinx makes no warranties, express,implied, statutory, or otherwise, and accepts no liabilitywith respect to any such articles, information, or othermaterials or their use, and any use thereof is solely atthe risk of the user. Any person or entity using suchinformation in any way releases and waives any claim itmight have against Xilinx for any loss, damage, orexpense caused thereby.PUBLISHER Mike Santarinimike.santarinixilinx.com4086265981EDITOR Jacqueline DamianART DIRECTOR Scott BlairDESIGNPRODUCTION Teie, Gelwicks  Associates18004935551ADVERTISING SALES Dan Teie18004935551xcelladsalesaol.comINTERNATIONAL Melissa Zhang, Asia Pacificmelissa.zhangxilinx.com Christelle Moraga, EuropeMiddle EastAfricachristelle.moragaxilinx.comTomoko Suto, Japantomokoxilinx.comREPRINT ORDERS 18004935551Xcell journalwww.xilinx.comxcellWork Smarter With Xilinx All Programmable SolutionsI f youve checked out Xilinxs home page lately, youve probably noticed that we haveplunged full force into a new campaign touting Smarter systems. Inspired by whatour customers have already been able to create with Xilinx devices, we are deliveringtools today to help you create the Smarter technologies that will shape tomorrow.In the last two months, Xilinx has rolled out our Smarter Networks initiative, and now,as reflected in the cover story of this issue, our Smarter Vision program. In both cases,Xilinx not only offers devices that allow customers to create smarter systems, but the IP,tools and design environments to support those chips.In this issue, DSP specialist Chris Dick writes about how the wireless carriers are rapidlygetting smarter in finding ways to increase the profitability of their nextgeneration networks.Gone are the days when carriers would just install a greater number of faster and more powerful basestations to increase bandwidth. Today they are adding intelligence and lookingtoward selforganizing network architectures to dynamically shift coverage to where it isneeded mostworking smarter, not harder, and raising profits while doing so.On another front, my cover story discusses a subject I find very fascinating Smarter Vision.As youll read, the world of embedded vision has been growing by leaps and bounds, to thepoint where vision systems are becoming ubiquitous. Today you can find them in everythingfrom gaming consoles to the car you drive to factories and hospitals. Even produce distributors are benefiting from embedded vision technology, which traditionally has paired FPGAswith standalone processors. But we at Xilinx think that with a silicon platform as powerful asthe Zynq7000 All Programmable SoC, youll be able to create much more capable embedded vision systemsSmarter Vision systemsusing one chip instead of two or three. To facilitate that effort, Xilinx is going the extra mile by offering the industry thebroadest software development environment support and proliferating highlevel synthesis technology through the Vivado HLS tool in our Vivado Design Suite. System architectscan design vision algorithms in CC and use Vivado HLS to create RTL versions. In doingso, they can see, for example, whether certain algorithms or parts of an algorithm wouldrun better in the Zynq SoCs processor system or in its FPGA fabric. In early April, Xilinx added even more Smarter Vision automation to the Vivado DesignSuite in release 2013.1. Designers now can use a tool called IP Integrator to deliver theindustrys fastest time to integration. With this release of Vivado, we also announced ourOpenCV cores library to help vision architects design more productively. In the initialrelease, Xilinx has provided more than 30 commonly used algorithms from the OpenCVlibrary and created RTL versions that you can add to your design to get a jump on developing Smarter Vision systems. You can even use them to evaluate hardware platforms byrunning the functions on the Zynq SoC vs. other ARMDSP and ARMGPUbased hardwareplatforms. Jose Alvarez and Fernando Vallina discuss the OpenCV advantage on page 24.Finally, Im happy to announce that an old friend from the trade press, Steve Leibson,the former editorinchief of the Microprocessor Report and EDN, recently joined Xilinxand has penned a comprehensive backgrounder on smarter wired and wireless networksand smarter data centers. Steves backgrounder goes into great depth on the trends in thesemarkets and how Xilinx is helping customers address them with our Smarter Networkingtechnology. You can download a PDF from httpwww.xilinx.compublicationsprodmktgsmarternetworksbackgrounder.pdf.I hope this issue and associated resources will inspire you to take the next step and tryout the Zynq SoC, if you havent already. Mike SantariniPublisherInterested in adding published author to your resume and achieving a greater level of credibilityand recognition in your peer community Consider submitting an article for global publication inthe highly respected, awardwinning Xcell Journal.The Xcell team regularly guides new and experienced authors from idea development to publishedarticle with an editorial process that includes planning, copy editing, graphics development, andpage layout. Our author guidelines and article template provide ample direction to keep you ontrack and focused on how best to present your chosen topic, be it a new product,research breakthrough, or inventive solution to a common design challenge.Our design staff can even help you turn artistic concepts into effective graphics orredraw graphics that need a professional polish.We ensure the highest standards of technical accuracy by communicating withyou throughout the editorial process and allowing you to review your article tomake any necessary tweaks.Submit final draft articles for publication in our Webbased Xcell Online orour digital and print Xcell Journal. We will assign an editor and a graphicsartist to work with you to make your papers clear, professional, and effective.For more information on this exciting and highly rewarding opportunity, please contactMike SantariniPublisher, Xcell Publicationsxcellxilinx.comWould you like to write for Xcell Publications Its easier than you think.Get Publishedwww.xilinx.comxcellC O N T E N T SVIEWPOINTS XCELLENCE BY DESIGN APPLICATION FEATURESCover StoryAll Eyes on Zynq SoC for Smarter Vision  8Xcellence in Wireless CommunicationsXilinx All Programmable Devices Enable Smarter Wireless Networks 16Xcellence in Embedded VisionUsing OpenCV and Vivado HLS toAccelerate Embedded Vision Applications in the Zynq SoC 24Letter From the PublisherWork Smarter with Xilinx AllProgrammable Solutions 41624S E C O N D  Q U A R T E R  2 0 1 3 ,  I S S U E 8 3Xplanation FPGA 101Xilinx HighLevel Synthesis Tool Speeds FPGA Design 32Xplanation FPGA 101How to Configure Your Zynq SoC BareMetal Solution 40Xplanation FPGA 101Using Xilinxs Power Estimator and Power Analyzer Tools 46THE XILINX XPERIENCE FEATURESExcellence in Magazine  Journal Writing2010, 2011Excellence in Magazine  Journal Design and Layout2010, 2011, 2012Tools of Xcellence Tiny GPS disciplined oscillator will tell you what time it is 52Xamples... A mix of new and popular application notes 56Xpedite... Latest and greatest from the Xilinx Alliance Program partners 60Xtra, Xtra The latest Xilinx tool updates, as of April 2013 62Xclamations Share your wit and wisdom by supplying a caption for our techy cartoon winner nabs an Avnet Zedboard 64XTRA READING325240COVER STORY8 Xcell Journal      Second Quarter 2013All Eyes on Zynq SoC for Smarter Vision by Mike SantariniPublisher, Xcell JournalXilinx, Inc. mike.santarinixilinx.comSecond Quarter 2013 Xcell Journal 9C O V E R  S T O R YIf you have seen a demonstration of AudisAutomated Parking technology in which thecar autonomously finds a parking spot andparks itself without a driveror if you haveplayed an Xbox 360 game with its Kinectcontroller or even just bitten into a flawlesspiece of fruit from your local grocerystorethen you can count yourself as aneyewitness to the dawning of the era ofsmarter vision systems. All manner of products, from the most sophisticated electronicsystems down to the humble apple, areaffected by smarter vision technologies. Andwhile todays systems are impressiveenough, some experts predict that in 10years time, a vast majority of electronicssystemsfrom automotive to factoryautomation, medical, as well as surveillance,consumer, aerospace and defensewillinclude smarter vision technologies witheven more remarkable capabilities. As smarter vision systems increase incomplexity, well very likely become passengers in autonomous automobiles flowing innetworked highways. Medical equipmentsuch as Intuitive Surgicals amazing roboticassisted surgical system will advance evenfurther and may enable surgeons to performprocedures from remote locations.Television and telepresence will reach newlevels of immersion and interactivity, whilethe content on screens in theaters, homesand stores will cater to each individual consumers interests, even our moods.The Zynq All ProgrammableSoC, in tandem with newXilinx tools and IP, forms the foundation for the nextgeneration of embeddedvision products. Xilinx All Programmable solutionsfor Smarter Vision are at the forefront ofthis revolution. With the Zynq7000All Programmable SoCthe first deviceto marry an ARM dualcore CortexA9 MPCore, programmable logic andkey peripherals on a single chipas thefoundation, Xilinx has fielded a supporting infrastructure of tools and IP thatwill play a pivotal role in enablingthe development and faster deliveryof these innovations in vision. Thesupporting infrastructure includesVivado HLS highlevel synthesis, thenew IP Integrator tools, OpenCV computer vision libraries, SmartCORE IPand specialized development kits. Through Xilinxs All ProgrammableSmarter Vision technologies, we areenabling our customers to pioneer thenext generation of smarter vision systems, said Steve Glaser, senior vicepresident of corporate strategy andmarketing at Xilinx. Over the lastdecade, customers have leveraged ourFPGAs to speed up functions thatwouldnt run fast enough in theprocessors they were using in theirsystems. With the Zynq7000 AllProgrammable SoC, the processorand FPGA logic are on the same chip,which means developers now have asilicon platform ideally suited forsmarter vision applications.In support of the device, said Glaser,Weve complemented the Zynq7000All Programmable SoC with a robustdevelopment environment consistingof Vivado HLS, new IP Integrator tools,OpenCV libraries, SmartCORE IP anddevelopment kits. With these SmarterVision technologies, our customerswill get a jump on their next design andbe able to achieve new levels of efficiency, lower system power, increasesystem performance and drasticallyreduce the bill of materialsenrichingand even saving lives while increasingprofitability as these innovations rollout at an ever faster pace. FROM DUMB CAMERAS TO SMARTER VISION At the root of Smarter Vision systemsis embedded vision. As defined bythe rapidly growing industry groupthe Embedded Vision Alliance w w w. e m b e d d e d  v i s i o n . c o m  ,embedded vision is the merging oftwo technologies embedded systemsany electronic system other than acomputer that uses a processor andcomputer vision also sometimesreferred to as machine vision. Jeff Bier, founder of the EmbeddedVision Alliance and CEO of consultingfirm BDTI, said embedded vision technology has had a tremendous impact onseveral industries as the discipline hasevolved beyond motorized pantiltzoomanalog camerabased systems. We haveall been living in the digital age for sometime now, and we have seen embeddedvision rapidly evolve from early digitalsystems that excelled in compressing,storing or enhancing the appearance ofwhat cameras are looking at into todayssmarter embedded vision systems thatare now able to know what they arelooking at, said Bier. Cuttingedge embedded vision systems not only enhance and analyzeimages, but also trigger actions basedon those analyses. As such, the amountof processing and compute power, andthe sophistication of the algorithms,have spiked dramatically. A case inpoint is the rapidly advancing marketof surveillance. Twenty years ago, surveillance systems vendors were in a race to providethe best lenses enhanced by mechanical systems that performed autofocusand tilting for a clearer and wider fieldof view. These systems were essentially analog video cameras connected viacoaxial cables to analog monitors, coupled with videorecording devicesmonitored by security guards. The clarity, reliability and thus effectiveness ofthese systems were only as good as thequality of the optics and lenses, and thediligence of the security guards in monitoring what the cameras displayed. With embedded vision technology,surveillance equipment companiesbegan to use lowercost cameras basedon digital technology. This digital processing gave their systems extraordinary features that outclassed andunderpriced analog and lensbasedsecurity systems. Fisheye lenses andembedded processing systems withvarious visioncentric algorithms dramatically enhanced the image the camera was producing. Techniques thatcorrect for lighting conditions,improve focus, enhance color and digitally zoom in on areas of interest alsoeliminated the need for mechanicalmotor control to perform pan, tilt andzoom, improving system reliability.Digital signal processing has enabledvideo resolution of 1080p and higher. But a clearer image that can bemanipulated through digital signal processing was just the beginning. Withconsiderably more advanced pixel processing, surveillance system manufacturers began to create more sophisticated embedded vision systems that performed analytics in real time on thehighquality images their digital systemswere capturing. The earliest of theseembedded vision systems had thecapacity to detect particular colors,shapes and movement. This capabilityrapidly advanced to algorithms thatdetect whether something has crossed a10 Xcell Journal      Second Quarter 2013C O V E R  S T O R YCuttingedge vision systems enhance andanalyze images, but also trigger actionsbased on those analyses. As such, the needfor compute power has spiked dramatically.virtual fence in a cameras field of viewdetermine if the object in the image is infact a human and, through links to databases, even identify individuals. SUSPICIOUS BEHAVIORThe most advanced surveillance systems include analytics that track individuals of interest as they movethrough the field of view of the securitynetwork, even as they leave the field ofview of one camera, move into a blindspot and then enter into the field ofview of another camera in the surveillance network. Vision designers haveprogrammed some of these systems toeven detect unusual or suspiciousmovements. Analytics is the biggesttrend in the surveillance market today,said Mark Timmons, system architectin Xilinxs Industrial, Scientific andMedical ISM group. It can accountfor human error and even take awaythe need for diligent human viewingand decision making. As you can imagine, surveillance in crowded environments such as train stations and sporting events can become extremely difficult, so having analytics that can spotdangerous overcrowding conditions ortrack individuals displaying suspiciousbehavior, perhaps radical movements,is very advantageous.To further enhance this analysisand increase the effectiveness of thesesystems, surveillance and many othermarkets leveraging smarter vision areincreasingly using fusion architectures that combine cameras with othersensing technologies such as thermalvision, radar, sonar and LIDARLightLaser Detection and Ranging.In this way, the systems can enablenight vision detect thermalheat signatures or pick up objects not capturedby or visible to the camera alone. Thiscapability drastically reduces falsedetections and in turn allows for muchmore precise analytics. Needless tosay, the added complexity of fusing thetechnologies and then analyzing thatdata requires ever more analyticprocessing horsepower. Timmons said that another megatrend in this market is products that perform all these forms of complex analysisat the edge of a surveillance systemnetworkthat is, within each camerarather than having each camera transmitits data to a central mainframe system,which then performs a more refinedanalysis from these multiple feeds.Localized analytics adds resilience tothe overall security system, makes eachpoint in the system much faster andmore accurate in detection, and thus canwarn security operators sooner if indeeda camera spots a valid threat. Localized analytics means that eachunit not only requires greater processing horsepower to enhance and analyze what it is seeing, but must also becompact and yet incorporate highlyintegrated electronics. And becauseeach unit must be able to communicatereliably with the rest of the network, itmust also integrate electronic communication capabilities, adding furthercompute complexity. Increasingly,these surveillance units are connectedvia a wireless network as part of a larger surveillance system. And increasingly, these surveillance systems arebecoming part of larger enterprise networks or even larger, global networks,like the U.S. militarys GlobalInformation Grid see cover story, XcellJournal issue 69, www.xilinx.compublications archivesxcellXcell69.pdf. This high degree of sophistication isbeing employed in the militaryanddefense market in everything from footsoldier helmets to defense satellitesnetworked to central command centers. Whats perhaps more remarkableis how fast smarter vision technology ismoving into other markets to enhancequality of life and safety. SMARTER VISION FOR THE PERFECT APPLE Take, for example, an apple. Ever wonder how an apple makes it to your grocery store in such good conditionGiulio Corradi, an architect in XilinxsISM group, said that food companies areusing eversmarter vision systems infood inspection lines to, for example,sort the bad apples from the good ones.Corradi said firstgeneration embeddedvision systems deployed on highspeedfood inspection lines typically used acamera or perhaps several cameras tospot surface defects in apples or otherproduce. If the embedded vision systemspotted an unusual color, the applewould be markedsorted for furtherinspection or thrown away. BENEATH THE SKINBut what happens if, at some pointbefore that, the fruit was dropped but thedamage wasnt visible In some cases,damage that resulted from a drop maynot be easily spotted by a camera, letalone by the human eye, said Corradi.The damage may actually be in the fleshof the apple. So some smarter vision systems fuse an infrared sensor with thecameras to detect the damage beneaththe surface of the apples skin. Finding abruised fruit triggers a mechanical sorterto pull the apple off the line before it getspacked for the grocery store. If the damaged apple had passed by without thesmarter fusion vision system, the damage would likely become apparent by thetime it was displayed on the grocerystore shelves the fruit would probablyhave to be thrown away. One rottenapple can, of course, spoil the bunch.Analytics can also help a food company determine if the bruised apple is ingood enough condition to divert to anew line, in which another smartervision system can tell if it is suitable forsome other purposeto make applesauce, dried fruit or, if it is too far gone,best suited for composting. Factory floors are another site forsmarter vision, Corradi said.  A growingnumber use roboticassisted technologies or completely automated roboticlines that manufacturers can retool fordifferent tasks. The traditional safetycages around the robots are too restrictive or too small to accommodate therange of movement required to manufacture changing product lines. Second Quarter 2013 Xcell Journal 11C O V E R  S T O R YSo to protect workers while notrestricting the range of motion of automated factory lines, companies areemploying smarter vision to createsafety systems. Cameras and laserserect virtual fences or barriers thataudibly warn workers and safety monitor personnel if someone is gettingtoo close to the factory line given theproduct being manufactured. Someinstallations include a multiphase virtual barrier system that will send anaudible warning as someone crossesan outer barrier, and shut down theentire line automatically if the individual crosses a second barrier that iscloser to the robot, preventing injury.Bier of the Embedded Vision Alliancenotes that this type of virtual barriertechnology has wide applicability. Itcan have a tremendous impact inreducing the number of accidents infactories, but why not also have virtualbarriers in amusement parks, or at ourhomes around swimming pools or oncars said Bier. I think well see a lotmore virtual barrier systems in ourdaily lives very soon. SMARTER VISION FOR BETTER DRIVING Automotive is another market that isfully embracing smarter vision to create a less stressful and safer drivingexperience. Paul Zoratti, a systemsarchitect within Xilinx Automotive,said that advanced driver assistancesystems ADAS are all about usingremote sensing technologies, including smarter vision, to assist driverssee cover story, Xcell Journal issue66, www.xilinx.compublicationsarchivesxcellXcell66. pdf. Each year over the past decade,automakers have unveiled evermoreimpressive DA features in their luxurylines, while also making a growingnumber of driver assistance featuresavailable in their sport and standardproduct lines. Many of these featuressuch as blindspot detection,lane change assist, pedestrian and signdetectionsend drivers a warning ifthey sense a potentially dangerous situation. Recent offerings from automanufacturers include even moreadvanced systems such as automaticemergency braking and lane keeping,which not only monitor the vehicleenvironment for potential problemsbut assist the driver in taking corrective actions to avoid accidents ordecrease their severity. Zoratti said that some newmodelcars today are outfitted with fourcameraslocated on the sides, front,and rear of the vehiclethat offer acontinuous 360degree view of thevehicles surroundings. While thefirstgeneration surroundview systems are using those cameras to provide an image to the driver, futuresystems will bundle additional DAfeatures. Using the same four cameras and imageprocessing analytics,these nextgeneration systems willsimultaneously generate a birds eyeview of the vehicle and also warn ofpotential danger such as the presenceof a pedestrian. Furthermore, whilethe vehicle is traveling at higherspeeds, the automobile will use thecameras on the side and rear of thevehicle for blindspot detection, lanechange assistance and lane departurewarning. Adding another, forwardlooking camera behind the windshield will support traffic sign recognition and forwardcollision warningfeatures. Finally, when the driverreaches his or her destination andactivates automated parking, the system will employ those same camerasalong with other sensors to help thecar semiautonomously maneuverinto a parking spot. Handling all these tasks in real timerequires a tremendous amount of processing power that is wellsuited forparallel hardware computation,Zoratti said. Thats why many early DAsystems paired standalone microprocessors with FPGAs, with theFPGA handling most of the parallelcomputations and microprocessorsperforming the serial decision making. The cost pressures in automotive aredriving the analytics to be performed ina central compute hub, rather than ateach camera as is the case in other markets, such as surveillance. In this way,carmakers can minimize the cost ofeach camera sensor and, ultimately, thecost of the entire system. That meansthe processing platform in the centralunit needs to deliver very high performance and bandwidth to support thesimultaneous processing of four, five oreven six realtime video inputs. A SMARTER VISION FOR LONGER LIVES Another area where smarter vision ismaking a dramatic difference is in themedical electronics industry, whichuses smarter vision technology in awide range of medical imaging systems,from endoscopes and imaging scannersCT, MRI, etc. to roboticsurgical systems such as Intuitive Surgicals DaVinci, detailed in Xcell Journal issue 77see www.xilinx.compublicationsarchivesxcellXcell77.pdf. Da Vincis sophisticated 3D visionsystem allows surgeons to guide robotic surgical instruments with extremeprecision, fluidity and tactile sensitivityto perform a number of delicate, intriC O V E R  S T O R Y12 Xcell Journal      Second Quarter 2013Virtual barriers can reduce factory accidents, but why not also have virtual barriers in amusement parks, or at our homes, around swimming pools or on carscate surgical procedures. With everygeneration of system, surgeons are ableto perform a greater number and variety of surgeries, helping to ensure better patient outcomes and faster recovery times. The degree of technologicalsophistication to control and coordinate these procedures is remarkableand is heavily reliant on the combinedhorsepower of processing and logic.Each generation of newer technologywill thus benefit from greater integration between processor and logic.A SMARTER VISION FOR AN IMMERSIVE EXPERIENCE Smarter vision is also making greatstrides in keeping us connected. If youwork in a modern office building,chances are your company has at leastone conference room with anadvanced telepresence conferencingsystem that not only allows you to talkto others around the world, but alsolets you see them as though they werethere in person. These videoconferencing systems are increasing in sophistication to the point that they can sensewho at a table or conference is speaking, and automatically turn and zoomin on that person, displaying him or herin everhigherquality immersive video. Ben Runyan, director of the broadcast and consumer segment marketingat Xilinx, said that companies developing telepresence technologies are seeking ways to create a more immersiveexperience for users. The goal is tomake users feel like they are in thesame room when in fact they could beon the other side of the globe, saidRunyan. To do this requires stateoftheart cameras and display technologies, which require advanced imageprocessing. As these technologiesbecome more advanced and deliver amore immersive experience, it willmake collaboration easier and makecompanies more productive while cutting down the need, and thus expense,to travel. XILINX ALLPROGRAMMABLEFOR SMARTER VISION To enable smarter vision to progresson all fronts rapidly and to reachnew markets requires an extremelyflexible processing platform, a richset of resources and a viable ecosystem dedicated to smarter vision.Xilinx devices have played a keyrole in helping companies innovatethese vision systems over the lastdecade. Today, after five years indevelopment, Xilinx is delivering aholistic solution that will helpdevelopers of smarter vision applications to quickly deliver the nextgeneration of innovations.For more than a decade, embeddedvision designers have leveraged theprogrammability, parallel computingand fast IO capabilities of XilinxFPGAs in a vast number of embeddedvision systems. Traditionally, designershave used FPGAs to speed up functions that were slowing down the mainprocessor in their systems, or wereusing the FPGA to run parallel computing tasks that processors simply couldnot perform. Now, with the Zynq7000All Programmable SoC, embeddedvision developers have a fully programmable device that is ideally suited fordeveloping the next generation ofsmarter vision applications.Smarter vision can be implemented in separate processors and FPGAscommunicating on the same board,but what the Zynq SoC delivers is alevel of integration that the electronicsindustry didnt have before, said JoseAlvarez, engineering director of videotechnology at Xilinx. Now, instead ofSecond Quarter 2013 Xcell Journal 13C O V E R  S T O R YMicroprocessor  DSP  FPGA PreprocessorMicro Frame Processingand CommunicationsProcessing System PSFeatures A, B, C, D, Application SWDSP SerialElement ProcessingFPGAFPGA ParallelPixel ProcessingFeatures A Features B Features C Features DCameraCameraCameraCameraCameraCameraCameraCameraObject Classification Motion EstimationImage Captureand TransformImage Warpand StitchObject DetectionZynq SoCProgrammable Logic PL HW AccelerationSolution BenefitsSystem Integration3 chips to 1 chipSystem Performance 2xBOM Cost25Total Power50Xilinx Zynq7000 All Programmable SoC SolutionFigure 1  Zynq All Programmable SoC vs. multichip, multiplecamera systems in driver assistance applications interchanging information betweenthe main intelligent processor andFPGA logic at board speeds, we can doit at silicon speeds through 3,000 highperformance connections between theprocessor and logic on the same chip. Figure 1 reveals the benefits of theZynq SoC over a traditional multicamera, multichip architecture in the creation of a multifeature automotivedriver assistance system. Using oneset of cameras connected to one ZynqSoC, the Xilinx architecture bottomleft in the graphic can enable featurebundles such as blindspot detection,360degree surround view, lane departure warning and pedestrian detection.In comparison, existing multifeatureDA systems require multiple chips andmultiple cameras, which complicatesintegration, adversely affects performance and system power consumption,and leads to higher BOM costs.  A few silicon vendors offer ASSPsthat pair ARM processors with DSPsor with GPUs, but those devices tendto be too rigid or provide insufficientcompute performance for many oftodays smarter vision applications.Often, solutions based on thesedevices require the addition of standalone FPGAs to fix these deficiencies. PROGRAMMABILITY AND PERFORMANCEThe Zynq SoCs programmability andperformance provide key advantagesover GPU and DSPcentric SoCs. TheARM processing system is softwareprogrammable the FPGA logic is programmable via HDLs or C and eventhe IO is fully programmable. As aresult, customers can create extremelyhighperformance smarter vision systems suited to their specific applications, and differentiate their systemsfrom those offered by competitors. Figure 2 details a generic signal flowof a smarter vision system and showshow the Zynq SoC stacks up againstARMplusDSP and ARMplusGPUbased ASSPs.   The first signalprocessing block inthe flow shown in green is the inputthat connects the device to a camerasensor. In the Zynq SoC, developerscan accommodate a wide range of IOsignals to conform to whatever camera connectivity their customersrequire. The next signalprocessingblock performs pixellevel processingor video processing depending onwhether the application is for imageprocessing or display. The next blockperforms analytics on the image, acomputeintensive process that oftenrequires parallel computing bestimplemented in FPGA logic. The subsequent three blocks in red arewhere the processing system derivesmetadata results from the analytics,creates a graphic representation of theresult the graphics step and encodesresults for transmission.In the Zynq SoC, the processing subsystem and FPGA logic work together.When compression is required, theappropriate codec can be readilyimplemented in FPGA logic. Then, inthe final signalprocessing blocklabeled Output, the Zynq SoCs programmable IO allows developers totarget a vast number of communication protocols and video transportstandards, whether they be proprietary, market specific or industrystandard IP protocols. In comparison, inboth DSP and GPUcentric SoCs,developers run the risk of developingalgorithms that require performancenot achievable with the DSP or GPUsections of these ASSPs. They willoften have to make up for this deficiency by adding a standalone FPGA totheir systems. While the Zynq SoC is clearly thebest silicon choice for smarter visionC O V E R  S T O R Y14 Xcell Journal      Second Quarter 2013Input4K2KMIPIOutputSDIHDMIDisplayPortImageProcessing IPVideoProcessing IPCodecH.265HEVCH.264VideoAnalyticsMetadataVideoAnalyticsAnalysisGraphicsComputeRequirements IO IO240 Gops 50100 Gops 110 GopsDedicated50200 GopsZynq SoCDSP  ARMGPU  ARMProgrammableIOProgrammableFPGAProgrammableFPGAFixedIOFixedIPFixedIOLimitedFixed IONotPossibleLimitedFixed IO ARMARM FPGADSPARMGPUIPGPUIPProgrammableFPGAProgrammableIOFixedIOFixedIOFigure 2  Generic video and imageprocessing system flowsystems, Xilinx realized early in thedevices development that programming needed to be streamlined,especially for designers who aremore accustomed to C and Cbased development of vision algorithms. To this end, in June 2012Xilinx delivered to customers astateoftheart software environment called the Vivado Design Suitethat includes, among other technologies, bestinclass highlevelsynthesis technology that the company gained in its January 2011acquisition of AutoESL. Vivado HLSis particularly wellsuited to embedded vision applications. If, forexample, vision developers usingthe Zynq SoC have created an algorithm in C or C that doesnt runfast enough or is overburdening theprocessing system, they can sendtheir C algorithms to Vivado HLSand synthesize the algorithms intoVerilog or VHDL to run in the FPGAlogic on the device. This frees upthe processing subsystem on theZynq SoC to handle tasks it is bettersuited to run, and thus speeds upthe overall system performance. OPENCV LIBRARYXilinx has also rounded out itsSmarter Vision technology offeringby releasing its OpenCV computervision library. OpenCV is an industrystandard, opensource library ofalgorithms from OpenCV.org thatembedded vision developers use toquickly create vision systems.Embedded vision developers acrossthe world actively contribute newalgorithms to the library, which nowcontains more than 2,500 algorithmswritten in C, C, Java and Pythonsee OpenCV story, page 24.Algorithms in the library range incomplexity from simple functionssuch as image filters to moreadvanced functions for analyticssuch as motion detection. Alvarez said that these OpenCValgorithms target implementation injust about any commercial microprocessor and DSP. Because the ZynqSoC uses an ARM processing system,users can implement these algorithms,written in C, in its processor portion. Thanks to Vivado HLS, said Alvarez,users can also take these algorithmswritten in C or C, modify functioncalls from OpenCV to HLS and then,using Vivado HLS, synthesize or compile the algorithms into RTL code optimized for implementation in the logicportion of the Zynq7000 SoC. HavingOpenCV in the Vivado environmentallows smarter vision architects toeasily compare and contrast whether agiven algorithm in their design will runmost optimally in the processor orFPGA logic portion of the Zynq7000All Programmable SoC. With therelease of Xilinxs Open Source library,Xilinx has essentially given customersa head start. Using Vivado HLS, Xilinxhas already compiled more than 30 ofthe most used embedded vision algorithms from the OpenCV library.Customers can quickly make processor vs. logic tradeoffs at the systemslevel and run them immediately in theZynq7000 All Programmable SoC toderive the optimal system for theirgiven application.Xilinx and its Alliance members willactively migrate more functions fromthe OpenCV library on an ongoingbasis, making them available to Xilinxsuser base quarterly. Because developers can run OpenCV libraries on justabout any commercial processor,vision designers will be able to compare and even benchmark the performance of algorithms running on varioussilicon devices. As part of its Smarter Vision initiative, Xilinx has also created an intellectual property IP suite calledSmartCORE IP, addressing smartervision requirements from across themany market segments that will designsmarter vision into their nextgeneration products. Customers can implement cores from the SmartCORE IPsuite and algorithms from the OpenCVlibrary into their designs quickly usingXilinxs newly introduced IP Integratortool. The new tool is a modern plugandplay IP environment that allowsusers to work in schematics or, if theyprefer, a commandline environment. TARGETED PLATFORM AWAREAlvarez said that since the VivadoDesign Suites inception, Xilinx architected the suite to be device aware, soas to take full advantage of eachdevices capabilities. Alvarez said thatthanks to IP Integrator, the VivadoDesign suite is not only device awarebut now targeted platform aware aswellsupporting all Zynq SoC and 7series FPGA boards and kits. Being target platform aware means that theVivado Design Suite will configure andapply boardspecific design rulechecks, which ensures rapid bringupof working systems. For example, when a designerselects the Xilinx Zynq7000 SoCVideo and Imaging Kit, and instantiates a Zynq SoC processing systemwithin IP Integrator, Vivado DesignSuite preconfigures the processingsystem with the correct peripherals,drivers and memory map to supportthe board. Embedded design teamscan now more rapidly identify, reuseand integrate both software and hardware IP, targeting the dualcore ARMprocessing system and highperformance FPGA logic. Users specify the interface betweenthe processing system and their logicwith a series of dialog boxes. IPIntegrator then automatically generates RTL and optimizes it for performance or area. Then users can add theirown custom logic or use the Vivado IPcatalog to complete their designs. Its remarkable to see what smartervision systems Xilinx customers havecreated to date with Xilinx FPGAs.The advent of the Zynq7000 AllProgrammable SoC and the powerfulSmarter Vision environment guarantees that the next crop of productswill be even more amazing.Second Quarter 2013 Xcell Journal 15C O V E R  S T O R Y16 Xcell Journal      Second Quarter 2013XCELLENCE IN WIRELESS COMMUNICATIONSXilinx All Programmable DevicesEnable Smarter Wireless NetworksSecond Quarter 2013 Xcell Journal 17Wireless carriers are urgently looking forways to capitalize on the explosivegrowth in mobile Internet usage. Butinstead of simply deploying more andfaster equipment, the carriers are seeking smarter waysto use their networks. They are actively developingnovel architectures such as selforganizing networks todeliver superior quality of service to customers and tomaximize profitability. Xilinx is helping wirelessnetwork companies pioneer these new architectures and deliver them to marketwith 28nanometer All Programmable devices andSmarter Wireless Networking solutions and supportinginfrastructure, including SmartCORE IP, the VivadoDesign Suite and services expertise.EXPLOSIVE GROWTH OF MOBILE IPThe last four years have seen explosive growth in mobileInternet Protocol usage. The International Telecommunications Unions ICT statistics show that in the period from 2000 to 2010, the number of mobile cellular subscriptions increased by eightfold, a rate that far exceedsthe growth in the number of Internet users over the sameperiod. The dominance of mobility stands in stark contrast to trends for fixed telephone line subscriptions,which continue to decline. As of 2010 there were fourtimes more mobile subscriptions than fixedline. Theintroduction of smartphone and tablet technology hasfundamentally changed the way we do business, spendour leisure time and interact with our family and friends. There is a symbiotic connection between the capabilities and the business models enabled by smartphones and tablets, and the cellular network that is theanchor point to the Internet Each feeds off the other.As smartphones and tablets become more capable,people figure out new ways to exploit their capabilities, stressing network capacity. Marketplace dynamicsengage, and network operators respond with networkupgrades. In turn, mobile equipment companies introduce new devices that consume the new capacity, andso the cycle continues. Today, analysts paint a pictureof a network in 2020 needing to support a capacity thatis 1,000 times greater than todays. In the four years since the smartphone moved into themainstream, we have seen screen pixel density doublefrom 163 pixels per square inch to 326 PPI today. At thesame time, storage has doubled from 32 to 64 gigabytes,and rearfacing camera capability has progressed from 3megapixel photos and VGA video to 8megapixel camerassupporting 1024p HD video at 30 framessecond. Mobiledevice manufacturers now offer frontfacing cameras withapplications like FaceTime, which enable mobile businessX C E L L E N C E  I N  W I R E L E S S  C O M M U N I C AT I O N Sby Chris DickChief DSP ArchitectXilinx, Inc. chrisdxilinx.comWith the meteoric growth ofmobile IP, carriers need flexiblesilicon and design tools tobuild the highperformance heterogeneous network architectures of the future.videoconferencing and permit themobile user, say, on overseas businesstravel to stay connected with home. From 2009 to now, there has beenan astonishing six generations ofsmartphone. In the three short yearssince the introduction of the first commercially successful tablet, we haveseen five generations of this technology, taking us from 720p video capability only two years ago to 1024p HDvideo on a typical rearfacing cameratoday. With in excess of 1 billionsmartphones on the planet, and withmore than half of the population ofNorth America owning a smartphone,feeding all of these pixels with mediarich content and delivering image andvideo data from the mobile back to thecloud, the upshot has been a networkcapacity and latency challenge. Andwhile it took 16 years to reach 1 billionsmartphones worldwide, it is estimated that it will take only three years forthe next billion smartphone users tocome onboard. The capacity challengewill rise exponentially.As people have invented new services and applications that increasinglycapable smartphones and tablets cansupport, the network has had toevolve and supply increased capacityand coverage, new levels of qualityofexperience and reduced latency toenhance the mobile experience foranything from videoconferencing andvideo streaming to media contentdownloading to the local device.Before boarding a longhaul flight, forexample, youll want to download thelatest edition of Xcell Journal or IEEECommunications Magazine, a newspaper or two, other magazines, technical reports from the office or multiplevideos to view later, at a more convenient time. The growth in online andinteractive gaming and financial transactions has also made demands oncapacity and latency. Advanced sociotechnical systems,such as Facebook for example, together with increasingly capable mobiledevices have become a central part ofdaily life for billions of people worldwide. Social media users are activelyusing mobile applications more thanever before. A recent study by mediaagency Ruder Finn pointed out that 91percent of the mobile subscribersengage in social computing applications, compared with 79 percent ofdesktop users. People in the UnitedStates, on the average, spend 2.7 hoursper day on mobile devices, of which 45percent post comments, 43 percentconnect with friends, 40 percent sharecontent with others and 38 percentshare photos on social networkingwebsites, making it an increasinglyfavorable platform for socializing.One consequence of the changingnature of how people exploit mobilityis that data traffic is now significantlygreater than voice traffic on the wireless network. Some industry reportspredict that the global mobile datagrowth will scale by approximately afactor of 40 in the coming years, goingfrom 90 petabytes per month in 2009to in excess of 3.5 exabytes per monthin 2014.STRUGGLING TO SCALE WITHBANDWIDTH DEMANDSIn response to these demands, and tothe invention of new mobile applications and associated business models,wireless networks have made dramatic capacity improvements. Over thepast three decades, since the conception of the 2G GSM system, the industry has achieved bitrate improvements in excess of three orders ofmagnitude, corresponding to an orderofmagnitude throughput improvement for each of the past threedecades. Clearly, the increasing smartphone and tablet computer populationhas resulted in substantial teletrafficgrowth, and it is anticipated that thisgrowth will continue until 2020.Since the first radio communications at the end of the 19th century,mankind has been on a path of developing technologies enabling people tocommunicate with anyone, anywhereand at any time using a range of mediarich services. However, despite significant advances in mobile user equipment and the wireless and wired networks themselves, the provisioning ofa true telepresence capability is notyet within our grasp, as anyone whohas experienced dropped connections,capacity and coverage problems, slowcontent download times, terminal batterylife issues and network latencydisrupting the quality of the mediaexperience would know. In addition tohumantohuman and IP network typecommunications, we are also seeing anew class of service evolve, machinetomachine or machinetype communication that will place furtherdemands on network capabilities. THE NETWORK EVOLVESStandards organizations, such as3GPP, along with industry conglomerates such as the Next GenerationNetwork Mobility Alliance andresearch laboratories in industry andacademia have been racing to defineand drive mobile broadband 4G technologies such as LTE longterm evolution and the Evolved Packet Core toaddress all of these varied challenges.In the past four years, we have gone18 Xcell Journal      Second Quarter 2013X C E L L E N C E  I N  W I R E L E S S  C O M M U N I C AT I O N SIt took 16 years to reach 1 billion smartphones worldwide it is estimatedthat it will take only three years for the next billion smartphone users tocome onboard. The capacity challenge will rise exponentially.improvements promised by spatialmultiplexing in practice, and the reality is that implementation lossesforexample through imprecise channelestimateslimit the gains promisedby theory.We are already seeing, and will continue to see at an accelerated pace, thedeployment of heterogeneous networks comprising a macrocell augmented with relays and with a smallcell underlay to address issues of bothcapacity and coverage in dense urbancanyon environments, to extend inbuilding coverage and for use in environments where regulatory considerations prevent the installation of amacrocell. Heterogeneous networksaka HetNets and cell densificationbring yet further challenges to the network designer in the form of backhaul,intercell interference and managinghandover between cells or even to carriergrade WiFi.Sixty years of research followingShannons pioneering paper have ledto advanced coding schemesturbofrom the standardization of the 3GPPRelease 8 specification in late 2008the first 3GPP standard to define nextgeneration capability making use ofmulticarrier OFDMA and SCFDMAtechnologythrough the first majorevolution of LTE with the LTEAdvanced Release 10 specification,ratified in 2011. While LTE and LTEAsystems are still being deployed, theRelease 12 working groups are planning the requirements and technologies for LTEB. One of the key challenges the wireless industry faces is extending capacity. Claude E. Shannons famous channelcapacity formulaoutlined in aseminal 1948 paper A MathematicalTheory of Communication published when the comms pioneerworked at Bell Labsinforms us thatbandwidth efficiency can onlyimprove at the cost of reduced powerefficiency. The law shows that capacity is a linear function of bandwidthbut a logarithmic function of signaltonoise ratio. This has led the researchcommunity to invent increasinglyeffective ways to use bandwidth within a complex set of constraints involving regulatory requirements, considerations for spectrum licensing, interoperability, multiple access, reliability,quality of service and spectral flexibility to the level of each individual pieceof user equipment. These constraints are some of themotivating principles that led to themulticarrier modulation scheme andevolved packet core employed in LTE,and they continue to be the motivatorsfor features such as carrier aggregation in LTEAdvanced. But relying onchannel bandwidth alone to addressthe capacity challenge is not enough. Further capacity improvementshave been made possible through theuse of spatialdivision multiplexingSDM MIMO, where and in contrastto the logarithmic capacity formula alinear increase in capacity is theoretically possible with respect to the number of antennas when the number oftransmit and receive antennas is thesame. While SDM can be employed toincrease the throughput for a singleuser, spatialdivision multiple accessSDMA configurations can maximizethe number of supported users in acell by sharing the total systemthroughput among the users. MIMOtransceivers, together with distributedor virtual MIMO, have permittedpowerefficient or green solutions tothe capacity problem. As the industrymoves to LTEB, it is likely that 3DMIMO, or fulldimension MIMO, willbe embraced by both a future versionof the 3GPP standard and by OEMsbuilding macro basestations Figure1. Operators will deploy heterogeneous networks along with beamforming small cells that offer verticaland horizontal electricalbeam tilt toaddress coverage holes and minimizeintercell interference.However, augmenting carrier aggregation with advanced multiantennatechniques is still not enough. Its difficult to realize the theoretical capacityX C E L L E N C E  I N  W I R E L E S S  C O M M U N I C AT I O N SSecond Quarter 2013 Xcell Journal 19 2D active antenna array AAA and up to 100 at eNB   MUMIMO with 10s of EUs Highorder MUMIMO transmissionto more than 10 EUsLTEInfrastructure IPFDMIMO eNB CPRISolution for Capacity DemandFigure 1  Industrial and academic research communities, and the 3GPP PHY workinggroup, are analyzing the potential use of massive, or 3D, MIMO for futuregeneration cellular access. Massive MIMO scales the antenna system by an order of magnitude comparedwith the systems of today, deploying hundreds of antennas.codes, for examplealong with multiantenna techniques, modulation systems, communication protocols anddigitalIF processing that networkcompanies can combine to realize systems that operate arbitrarily close tochannel capacity. But there is still along way to go to address the ferocious appetite for even more capacity,robust communications and reducedendtoend latency. In addition to moreflexible and sophisticated or smarterif you will use of spectrum by meansof OFDMA and smartantenna configurations, concepts such as enhancedintercell interference cancellation arecoming online to assist with handoverand maintaining the resilience of aconnected device. The rich set of concepts capturedunder the umbrella of selforganizingnetworks SONs is one of the musthave technologies on the LTE roadmap. There are multiple facets toSON, including automatic neighborrelations, load balancing, trafficgrowth and capacity management.The use of selfoptimizing, selfhealing technology promises energy savings, improved coverage and LTEparameter optimization, an examplebeing the randomaccess channel, orRACH, optimization. Another key aspect of SON is making the network smarter, with the endgoal of minimizing OPEXrelated drivetests. To improve their networks, operators often deploy engineers in thefield to collect radio measurements, todiscover problems such as coverageholes in the network and to determinewhether theres a need to tune basestation or network parameters. However,such conventional drive tests areexpensive, and the measurements theycollect can only give a limited view, atone point in time, of the entire network. Member companies of the NextGeneration Mobile Networks and3GPP organization are actively discussing ways to address these challenges. The Release 10 specificationintroduced the concept of minimization of drive tests and is an importantcontribution to the area of SON thatwill assist with node insertion in thenetwork and enabling  automaticparameter tuning over the life of thenode and network.Yet another consideration for network design is the operating cost, withone of the significant contributors toOPEX, and actually CAPEX, being theRF platform, which includes thepower amplifier, or amplifiers formultiantenna systems. The green considerations for the RF electronics aremultifaceted. Deployment of a nonlinear power amplifier is desirable fromthe vantage point of cost, but the nonconstantenvelope OFDMA modulationscheme used in the LTE RAN downlinkhas the undesirable consequence ofspectral regrowth when processed by alowcost nonlinear amplifier. Thesehighly undesirable outofband spectralemissions, which are delivered to neighboring spectrum, compromise nearbycommunication systems and breachregulatory requirements.  One solution is to use a large backoff and exercise only the linear portion of the amplifier transfer function.However, since we are also interestedin the efficiency of the power amplifier or the effectiveness of the amplifier to convert DC power to the RF carrier, its best to operate the amplifierwith only a small output backoff,since the amplifier is most efficient atthis bias point. Biasing the amplifierto minimize the backoff means moving closer to the compressive part of20 Xcell Journal      Second Quarter 2013X C E L L E N C E  I N  W I R E L E S S  C O M M U N I C AT I O N SFigure 2  The firstever published waterfall plot for convolutional turbocodes, published by Berrou et al. in their famous 1993 paper. Turbo codesrevolutionized the coding system employed in 3G and 4G wireless systems.tectures that integrate  the basebandinto the radio head, or remote radiohead architectures supporting thebaseband hotel model exploiting thecloud. The gotomarket and technology considerations will even be different for a single OEM based on thegeography of the deployed network.Moreover, now more than ever timetomarket governs whether a companyis successful, wildly successful orobsolete. It comes down to selectingtechnology that is flexible, scalableand possesses the rich mix of embedded software, compute capability andconnectivity to match the complex setof attributes that characterizes wireless networks. Beyond the silicon platform, design tools and intellectualproperty IP libraries also play a crucial role in enhancing productivity.Xilinxs 28nm 7 series technology,and in particular the All ProgrammableZynq SoC, bring to bear the connectivity, signalprocessing and embeddedcomputing capability that is required atthe heart of nextgeneration networks.The FPGA compute fabric, and itsunparalleled signalprocessing capability, can be applied to OFDMA and SCFDMA LTE baseband processing forrealizing the highspeed math requirements of advanced receivers that mightemploy iterative techniques, exchanging statistical information between thechannel decoder, equalizer and MIMOdetector in a multiantenna system. TheZynq SoC likewise supports futuregeneration systems that might exploit 3DMIMO as one option for increasingcapacity and exceeding the minimumrequirements defined by the ITU as partof the IMTAdvanced requirements.  Another application of FPGA signalprocessing is to address the cost,CAPEX and OPEX, and what we mightthe transfer function, which causesissues with multicarrier signals. TheLTE OFDMA downlink waveform isformed as the weighted sum oforthogonal sampled sine waves. Thesignal formed by this sum exhibits alarge peaktoaverage power ratio.The amplitude of the real and imaginary time series tends to be Gaussianwith  a Rayleigh distributed envelope. The Rayleigh envelope exhibits alarge peaktoaverage ratio, with peakvalues exceeding four times the average value, with a probability of 0.00035.To preserve the fidelity of the OFDMAtime series and to avoid spectral artifacts due to power amplifier clipping,we may choose to operate the amplifierwith the average signal level at onefourth of full scale however, the efficiency sacrificed in passing signals witha 4to1 peaktoaverage ratio through apower amplifier is excessive. The peakpower level would be 16 times the average power level. This means that anamplifier required to deliver 5 watts ofaverage power must be capable ofdelivering 80 W of peak power. Power amplifiers are very inefficientin their transduction process of turningDC power to signal power when theyoperate at small fractions of their peakpower level. For a Class B amplifier, todo a first approximation and for a widerange of output power levels, thepower pulled from the power supply isconstant and approximately 35 percentof the peak power level. Thus, our 80Wamplifier will pull 28 W from the DCpower supply and deliver 23 of thesewatts to its heat sink while delivering5 W to the external load.The answer to these dilemmas isdigital signal processing. A midrangeAll Programmable device such asXilinxs 28nm Kintex7 410T, with1,540 multiplyaccumulators, operating at 491.52 MHz, can deliver a peakcompute performance of 757 billionMACs per second. That is a 300,000xincrease over the first generation ofHarvard architecture, integrated DSPprocessors released in the early 1980s.Companies can use this DSP computepower to implement advanced crestfactor reduction to control the peaktoaverage ratio of the transmissionwaveform, and to apply digital predistortion processing to linearize a lowcost, highly nonlinear Doherty poweramplifier. In this way, designers control the overall cost of their equipmentby defraying some of the high costassociated with building highfidelityRF processing and amplification to therelatively lowcost world of digital signal processing, which unlike the former, has been able to benefit fromMoores Law process node scaling.XILINX AND NEXTGENERATIONSMARTER NETWORKSThe approach to solving for capacity,latency, coverage, quality of service,OPEX and CAPEX is going to be different for each mobilenetwork operatorand cellularinfrastructure manufacturer. Each unique solution will be afunction of existing assets, expertiseand different gotomarket strategies.A single hardware platform with a single SoC is not going to allow OEMs todifferentiate, or to have a unified, orcommon platform approach that permits technology scaling from smallcell through to macrocell through tocloud RAN network architectures. A conventional merchant siliconsystemonachip doesnt allow for thevarious architectures that an OEMmight need to support, ranging fromthe conventional basestation to archiX C E L L E N C E  I N  W I R E L E S S  C O M M U N I C AT I O N SSecond Quarter 2013 Xcell Journal 21The approach to solving for capacity, latency, coverage, quality of service, OPEX and CAPEX is going to be different for each mobilenetwork operator and cellularinfrastructure manufacturer.call green considerations for the network. With LTEA and carrier aggregation, channel bandwidths have movedto 100 MHz. Crestfactor reductionCFR and power amplifier linearization techniques need to evolve to handle these wide channels, and thismeans more signal processing. TheCommunications Business Unit atXilinx has been busy for some yearsnow working on these problems andhas developed CFR and digitalpredistortion IP to service a wide range of airinterface protocols. As we look to the future, it is easyto see that radio processing is goingto become more complicated as aneverwidening range of carrier configurations must be supported. In lessthan four years, the LTE specificationhas evolved from a basic set of sixchannel bandwidths 1.4, 3, 5, 10, 15and 20 MHz through to Release 10,where component carriers can beaggregated in intra as well as interband configurations. It is within thescope of Release 12 work that is onlybeginning now to investigate solutions to achieve even further spectrum flexibility. Of course, not all basestations,whether macro or small cell, need tosupport all possible scenarios. Thatfact leaves OEMs with the dilemma ofneeding to rapidly build a suite of costeffective solutions that can capture thefrequencyplanning requirements of anetwork operator. These requirementsare a complex equation based on theparameters of spectrum licensing,spectrum fragmentation and the needto support multiple radioaccess technologies from a single RF chainthemultiRAT challenge. Further complicating the picture is the introductionof heterogeneous networks comprisinga mixture of macro basestations, smallcell underlays and WiFi offload. Its aquestion of scale and flexibility, twoproperties at the very heart of XilinxAll Programmable SoCs and FPGAs.But there is more to the problemthan signal processing in the PHY.LTE, and the future LTEA and LTEBnetworks, are getting smarter in somany dimensions, especially as software increasingly becomes a key consideration for anything from runningselforganizing network applicationsand minimizing drive tests, performingLTE parameter optimization, implementing realtime performance management, collecting statistics for network and equipment planning purposes, through to running protocol stacksand OM software.  With the introduction of the ZynqSoC in 2012, Xilinx put an industryfirstcomputing paradigm into the hands ofsystem designers by providing a combination of dualCortex A9 processingtightly coupled with a highperformanceprogrammable logic fabric that can beused for signal processing, MAClayeracceleration and connectivity such asEthernet, CPRI and OBSAI. Thesedevices, and other products in the portfolio, go directly toward meeting thediverse mix of compute requirements,ISA and datapath, scalability and flexibility needed for an OEM to build differentiated products and get them to market quickly and costeffectively.Backhaul in this emerging age willalso be a challenge. As the capabilityof the radioaccess network evolves,the backhaul requirements of the network increase dramatically. Differentcell structures and deployment scenarios will use different backhaul22 Xcell Journal      Second Quarter 2013X C E L L E N C E  I N  W I R E L E S S  C O M M U N I C AT I O N SDACDACADCADCADCOpticalModulesMemoryMemoryControl SPII2C UARTS GPIO610GSerdes610GSerdesCPRIOBSAIMasterCPRIOBSAIMasterARM A9OMRTOSARM A9DPDUpdateDigital UpconversionDUCDigital DownconversionDDCCrestFactorReductionCFRDigitalPredistortionDPDJESD204or LVDSJESD204or LVDSJESD204or LVDSFigure 3   The Zynq SoC enables the construction of a singlechip digitalIF processing chain incorporating the functions of up and downconversion, crestfactor reduction, digital predistortion and connectivity. brought a new generation of designtools to the market. One of the excitingadvances in this area was with the 2012public release of highlevel synthesistechnology Vivado HLS. With this flowcustomers can write in C, C orSystemC, and compile to Xilinx silicon.This ability to program FPGAs from ahighlevel language enhances productivity and puts the All Programmabledevices within reach of designers whodont speak hardware description languages as a first language. A new Vivadophysicalimplementation tool bringsadvances in quality of results, runtimeand ease of use to customers.For more information on how Xilinxis helping customers build smarter networks, visit httpwww.xilinx.comapplicationssmarternetworksindex.htm. technologies, ranging from Ethernetand optical fiber for some smallcellinstallations, through pointtopointmicrowave and eband  millimeterwave links in other configurations.One way Xilinx is assisting OEMs inthis area is with backhaul modem IP.The recent acquisition of a company with expertise in this space meansthat Xilinx can now supply backhaultechnology that not only competeswith incumbent ASSP silicon, but goesa step further by providing the flexibility to scale up, or down, link capacitybased on the exact needs of the problem at hand. For example, for somehighend scenarios, dualmode transmission on both the vertical and horizontal polarizations of the electromagnetic wave can be used to increaselink capacity or reliability. In other situations, a simpler, lowerdatarate andalso lowercost, single polarizationscheme might be sufficient. The softmodem IP can be integrated in a chipto realize any of the common configurations, 11, 20 and so on, in a flexible manner, enabling a customer witha progression of solutions that scaleover performance and cost.The Zynq SoC can bring all of theseaspects of network design to reality ina single chip software running on theARM CortexA9 processors RANphysicallayer functions and the backhaul modem implemented within thecompute fabric and massively parallelarray of multiplyaccumulate enginesand connectivity protocols built usingthe highspeed serdes Figure 3. Along with advanced silicon and IPsolutions, Xilinx has also recentlyX C E L L E N C E  I N  W I R E L E S S  C O M M U N I C AT I O N SSecond Quarter 2013 Xcell Journal 23Debugging Xilinxs  ZynqTM 7000 familywith ARM CoreSightRTOS support, including Linux kernel and process debuggingSMPAMP multicore CortexTM A9 MPCoreTMs debuggingUp to 4 GByte realtime traceincluding PTMITMProfiling, performance and statistical analysis of Zynqs multicore CortexTM A9 MPCoreTM24 Xcell Journal     Second Quarter 2013XCELLENCE IN EMBEDDED VIS IONUsing OpenCV and Vivado HLS to AccelerateEmbedded Vision Applicationsin the Zynq SoCSecond Quarter 2013 Xcell Journal 25Computer vision has been awellestablished discipline inacademic circles for severalyears many vision algorithms todayhail from decades of research. Butonly recently have we seen the proliferation of computer vision in manyaspects of our lives. We now have selfdriving cars, game consoles that reactto our every move, autonomous vacuum cleaners and mobile phones thatrespond to our gestures, among othervision products. The challenge today is how toimplement these and future vision systems efficiently while meeting strictpower and timetomarket constraints.The Zynq All Programmable SoCcan be the foundation for such products, in tandem with the widely usedcomputer vision library OpenCV andthe highlevel synthesis HLS toolsthat accelerate critical functions inhardware. Together, this combinationmakes a powerful platform fordesigning and implementing SmarterVision systems.Embedded systems are ubiquitousin the market today. However, limitations in computing capabilities, especially when dealing with large picturesizes and high frame rates, haverestricted their use in practical implementations for computermachinevision. Advances in image sensortechnologies have been essential inopening the eyes of embeddeddevices to the world so they can interact with their environment using computer vision algorithms. The combination of embedded systems and computermachine vision constitutesembedded vision, a discipline that isfast becoming the basis for designingmachines that see and understandtheir environments. DEVELOPMENT OF EMBEDDEDVISION SYSTEMSEmbedded vision involves runningintelligent computer vision algorithmsin a computing platform. For manyusers, a standard desktopcomputingprocessing platform provides a conveniently accessible target. However, ageneral computing platform may notmeet the requirements for producinghighly embedded products that arecompact, efficient and low in powerwhen processing large imagedatasets, such as multiple streams of realtime HD video at 60 framessecond.Figure 1 illustrates the flow thatdesigners commonly employ to createembedded vision applications. Thealgorithm design is the most important step in this process, since thealgorithm will determine whether wemeet the processing and quality criteria for any particular computer visiontask. At first, designers explore algorithm choices in a numericalcomputing environment like MATLAB inorder to work out highlevel processing options. Once they have determined the proper algorithm, they typically model it in a highlevel language,generally CC, for fast executionand adherence to the final bitaccurate implementation.System partitioning is an importantstep in the development process. Here,through algorithm performance analysis, designers can determine what porPairing Vivado HLS with the OpenCVlibraries enables rapid prototyping anddevelopment of Smarter Vision systemstargeting the Zynq All Programmable SoC.X C E L L E N C E  I N  E M B E D D E D  V I S I O Nby Fernando Martinez Vallina HLS Design Methodology Engineer  Xilinx, Inc.Vallinaxilinx.com Jos Roberto AlvarezEngineering Director for Video TechnologyXilinx, Inc.jalvarezxilinx.comtions of the algorithm they will needto accelerate in hardware given therealtime requirements for processingrepresentative input data sets. It isalso important to prototype the entiresystem in the target platform, so as torealistically measure performanceexpectations. Once the prototypingprocess indicates that a design hasmet all performance and quality targets, designers can then start implementing the final system in the actualtargeted device. Finally, the last stepis to test the design running on thechip in all usecase scenarios. Wheneverything checks out, the team canrelease the final product.ZYNQ SOC SMARTEST CHOICEFOR EMBEDDED VISIONIn the development of machinevision applications, it is very important for design teams to choose ahighly flexible device. They need acomputing platform that includespowerful generalpurpose processing capabilities supporting a widesoftware ecosystem, along withrobust digital signalprocessing capabilities for implementing computationally demanding and memoryefficient computer vision algorithms.Tight integration at the silicon level isessential for implementing efficientand complete systems.Xilinx All Programmable SoCs areprocessorcentric devices that offersoftware, hardware and IO programmability in a single chip. The ZynqSoC features an ARM dualcoreCortexA9 MPCore processingsystem coupled with FPGA logic andkey peripherals on a single device. Assuch, the device enables designers toimplement extremely efficient embedded vision systems.This level of integration betweenthe processing subsystem, FPGA logicand peripherals in the Zynq SoCensures faster data transfer speeds anda much lower power requirement andBOM cost than a system designed withindividual components. It is feasible toimplement systems in the Zynq SoCthat require realtime processing for1080p60 video sequences 1,920 x 1,080RGB pictures at 60 framess with processing capabilities in the hundreds ofgigaoperations per second.To take full advantage of the manyfeatures of the Zynq SoC, Xilinx provides the Vivado Design Suite, an IPand systemcentric design environment that increases designer development productivity with the fast integration and implementation cyclesneeded to dynamically developsmarter embedded products. A component of that suite, Vivado HLS,allows you to take algorithms youvedeveloped in CC and compile theminto RTL to run in the FPGA logic. The Vivado HLS tool is particularlywellsuited to embedded vision design.In this flow, you create your algorithmsin CC compile the algorithm orparts of the algorithm into RTL usingVivado HLS and determine which functions are better suited to run in FPGAlogic and which are better suited to runon the ARM processor. In this way, yourdesign team can home in on the optimalperformance for their vision systemsrunning in the Zynq SoC.To further help embedded visiondevelopers to create Smarter Vision26 Xcell Journal      Second Quarter 2013X C E L L E N C E  I N  E M B E D D E D  V I S I O NAlgorithmDesignModelingImplementationReleaseSystemPartitioningPrototyping C, C or SystemCVHDL or VerilogSystem IP IntegrationAlgorithmic SpecificationMicroarchitecture ExplorationRTL ImplementationComprehensive Integration withthe Xilinx Design EnvironmentAccelerate Algorithmic CtoIP IntegrationVivado HLSFigure 1  Embedded vision systemdevelopment processFigure 2  Highlevel synthesis design flowsystems, Xilinx has added to Vivadosupport for the OpenCV libraries ofcomputer vision algorithms. Xilinxhas also introduced the new IPIntegrator tools and SmartCORE IPto support these kinds of designs seecover story, page 8.OPENCV MAKES COMPUTERVISION ACCESSIBLEOpenCV provides a path to the development of intelligent computer visionalgorithms that are predicated on realtime performance. The libraries provide designers with an environmentfor experimentation and fast prototyping of algorithms.The design framework of OpenCVis supported in multiple platform. Butin many cases, to make the librariesefficient for embedded productsrequires implementation in an embedded platform that is capable of accelerating demanding routines for realtime performance.While OpenCV was designed withcomputational efficiency in mind, itoriginated in traditional computingenvironments with support for multicore processing. These computingplatforms may not be optimal for anembedded application where efficiency, cost and power consumption areparamount.FEATURES OF OPENCVOpenCV is an opensource computervision library released under a BSDlicense. This means that it is free touse in academic and commercialapplications. It was originallydesigned to be computationally efficient on generalpurpose multiprocessing systems, with a strong focuson realtime applications. In addition, OpenCV provides access tomultiple programming interfaceslike CC and Python.The advantage of an opensourceproject is that the user community isconstantly improving algorithms andextending them for use in a widevariety of application domains. Thereare now more than 2,500 functionsimplemented in OpenCV here aresome examples Matrix math Utilities and data structures General imageprocessing functions Image transforms Image pyramids Geometric descriptor functions Feature recognition, extractionand tracking Image segmentation and fitting Camera calibration, stereo and3D processing Machine learning detection,recognitionFor a more detailed description ofOpenCV, please go to opencv.org andopencv.willowgarage.com.ACCELERATING OPENCV FUNCTIONS USING HLSOnce you have partitioned thearchitecture of an embedded visionsystem to single out computationally demanding portions, HLS toolscan help you accelerate these functions while still written in C.Vivado HLS makes use of C, C orSystemC code to produce an efficient RTL implementation.Furthermore, the Vivado IPcentricdesign environment provides a widerange of processing IP SmartCOREsthat simplify connections to imagingsensors, networks and other necessary IO interfaces, easing the processof implementing those functions in theOpenCV libraries. This is a distinctadvantage from other implementationalternatives, where there is a need toaccelerate even the most fundamentalOpenCV IO functionality.WHY HIGHLEVEL SYNTHESISThe Vivado HLS compiler from Xilinxis a software compiler designed totransform algorithms implemented inC, C or SystemC into optimized RTLfor a userdefined clock frequency anddevice in the Xilinx product portfolio.It has the same core technology underpinnings as a compiler for an x86processor in terms of interpretation,analysis and optimization of CCprograms. This similarity enables arapid migration from a desktop development environment into an FPGAX C E L L E N C E  I N  E M B E D D E D  V I S I O NSecond Quarter 2013 Xcell Journal 27Current FramePrevious FrameDetected New CarOutput FrameOpenCVMotionDetectionAlgorithmFigure 3  Motiondetection example from the OpenCV library of algorithmsimplementation. The default behaviorof Vivado HLS will generate an RTLimplementation without the need foruser input after you have selected thetarget clock frequency and device. Inaddition, Vivado HLS, like any othercompiler, has optimization levels.Since the final execution target of thealgorithm is a tailormade microarchitecture, the level of optimizations possible in Vivado HLS is finergrainedthan in a traditional compiler. Theconcept of O1  O3 optimizations typical in software design for a processoris replaced with architectureexploration directives. These directivesdraw on the expertise of the user toguide Vivado HLS in creating the bestpossible implementation for a particular algorithm in terms of power, areaand performance. The user design flow for the HLScompiler is shown in Figure 2. At aconceptual level, the user provides aCCSystemC algorithmic description and the compiler generates anRTL implementation. The transformation of a program code into RTL isdivided into four major regions algorithm specification, microarchitecture exploration, RTL implementation and IP packaging.The algorithmicspecification stagerefers to the development of the software application that will be targetedto the FPGA fabric. This specificationcan be developed in a standard desktop softwaredevelopment environment and can make complete use ofXilinxprovided software librariessuch as OpenCV. In addition toenabling a softwarecentric development flow, Vivado HLS elevates theverification abstraction from RTL toCC. The user can carry out complete functional verification of thealgorithm using the original software.After RTL generation through VivadoHLS, the generated design is analogous to processor assembly code generated by a traditional software compiler. The user can debug at thisassembly code level, but is notrequired to do so. While Vivado HLS can handlealmost all CC code targeted atother software compilers, there isone restriction placed on the code.For compilation into an FPGA usingVivado HLS, the user code cannotinclude any runtime dynamic memory allocations. Unlike a processor,where the algorithm is bounded by asingle memory architecture, an FPGAimplementation has an algorithmspecific memory architecture. Byanalyzing the usage patterns ofarrays and variables, Vivado HLS candetermine the physicalmemory lay28 Xcell Journal      Second Quarter 2013X C E L L E N C E  I N  E M B E D D E D  V I S I O NFigure 4  Motion detection on the Zynq SoC using the ARM processorout and memory types that will bestfit the storage and bandwidthrequirements in an algorithm. Theonly requirement for this analysis towork is that you explicitly describeall memory that an algorithm consumes in the CC code in the formof arrays.The second step in the transformation from a CC implementation into an optimized FPGA implementation is the microarchitectureexploration. At this stage, you applyVivado HLS compiler optimizationsto test out different designs for theright mix of area and performance.You can implement the same CCcode at different performance pointswithout having to modify sourcecode. The Vivado HLS compiler optimizations or directives are how theperformance of different portions ofan algorithm are stated. The final stage in the Vivado HLScompiler flow is RTL implementationand IP packaging. These are automatic stages inside the Vivado HLS compiler that do not require RTL knowledge from users. The details of optimized RTL creation for differentdevices in the Xilinx product portfolio are built into the compiler. At thisstage, the tool is, for all intents andpurposes, a pushbutton utility thathas been thoroughly tested and verified to produce timingdriven andFPGA fabricdriven RTL. The outputfrom the Vivado HLS compiler isautomatically packaged in formatsaccepted by other Xilinx tools such asIPXACT. Therefore, there are noadditional steps in using an HLSgenerated IP core in Vivado. The OpenCV libraries from Xilinxprovide a shortcut in the process ofdesign optimization using VivadoHLS. These libraries have beenprecharacterized to yield functionscapable of pixelrate processing at1080p resolutions. The optimizationknowledge required to guide theVivado HLS compiler is embeddedinto these libraries. Thus, you are freeto quickly iterate between an OpenCVconcept application in a desktop environment to a running OpenCV application on the Zynq SoC, which enablesoperations on the ARM processor andthe FPGA fabric. Figure 3 shows an overview of amotiondetection application developed in OpenCV. The goal of thisdesign is to detect moving objects ina video stream by comparing the current image frame with the previousone. The first stage in the algorithmis to detect the edges in both frames.This datareduction operation makesit easier to analyze the relativeX C E L L E N C E  I N  E M B E D D E D  V I S I O NSecond Quarter 2013 Xcell Journal 29Figure 5  Motion detection on the Zynq SoC using the programmable fabricchange between consecutive frames.Once the edge information has beenextracted, edges are compared todetect edges that appear in the current image but not in the previousimage. These new detected edgescreate a movementdetection maskimage. Before the results of the newedge detection can be highlighted onthe current image, you must takeinto account the effects of imagesensor noise. This noise, which canvary from frame to frame, can leadto random false edges in the motiondetection mask image. Therefore,you must filter this image to reducethe impact of noise on the quality ofthe algorithm. Noise reduction for this applicationis accomplished through the use of a7x7 median filter on the movementdetection mask image. The centralidea of a median filter is to take themiddle value in a 7x7 window ofneighboring pixels. The filter thenreports back the median value as thefinal value for the center pixel of thewindow. After noise reduction, themovementdetection mask image iscombined with the live input image tohighlight moving edges in red. You can fully implement the application to run on the ARM processingsubsystem with the source code toZynq SoC mapping shown in Figure4. The only hardware elements in thisimplementation are for the cvgetframe and showimage functions.These video IO functions are implemented using Xilinx video IO subsystems in the FPGA fabric. At thetime of the cvgetframe function call,the input side of the video IO subsystem handles all the details, grabbing and decoding a video streamfrom an HDMI interface and placingthe pixel data into DDR memory. Atthe time of showimage, this subsystem handles the transfer of pixel datafrom DDR memory into a video display controller in order to drive a TVor other HDMIcompliant video display device.Vivado HLSoptimized OpenCVlibraries for hardware accelerationenable the porting of the code inFigure 4 into a realtime 60framespixelprocessing pipeline on theFPGA fabric. These OpenCV librariesprovide foundational functions forthe elements in OpenCV that requirehardware acceleration. Without hardware accelerationthat is, if youwere to run all the code in the ARMprocessors onlythis algorithm hasa throughput of merely 1 frame every13 seconds 0.076 framess. Figure 5shows the new mapping of the application after Vivado HLS compilation.Note that the video IO mapping ofthe original system is reused. Thecomputational core of the algorithm,which was previously executing onthe ARM processor, is compiled intomultiple Vivado HLSgenerated IPblocks. These blocks, which are connected to the video IO subsystem inVivado IP Integrator, are optimizedfor 1080p resolution video processing at 60 framess. The All Programmable environment provided by the Zynq SoC andVivado Design Suite is wellsuitedfor the design, prototyping and testing of embedded vision systems atthe high dataprocessing ratesrequired by the latest highdefinitionvideo technologies. Using the opensource set of libraries included inOpenCV is the best way to implement demanding computer visionapplications in short developmenttimes. Since OpenCV libraries arewritten in C, we use Vivado HLSto create source code that can beefficiently translated to hardwareRTL in the Zynq SoC FPGA fabric,and used as convenient processingaccelerators without sacrificing theflexibility of the design environmentoriginally envisioned by OpenCV.For more information on creatingSmarter Vision designs with VivadoDesign Suite, visit httpwww.xilinx.comproductsdesigntoolsvivadoindex.htm. 30 Xcell Journal      Second Quarter 2013X C E L L E N C E  I N  E M B E D D E D  V I S I O NFPGA S OLUTIONS 100K Logic Cells  240 DSP Slices DDR3 SDRAM  Gigabit Ethernet SODIMM form factor 68 x 30 mmMars AX3 Artix7 FPGA ModulefromMars ZX3 SoC Module Xilinx Zynq7000 All Programmable SoC   Dual CortexA9  Xilinx Artix7 FPGA DDR3 SDRAM  NAND Flash Gigabit Ethernet  USB 2.0 OTG SODIMM form factor 68 x 30 mmWe speak FPGA.www.enclustra.com Xilinx Kintex7 FPGA Highperformance DDR3 SDRAM USB 3.0, PCIe 2.0  2 Gigabit Ethernet ports Smaller than a credit cardMercury KX1 FPGA ModuleFPGA Manager SolutionSimple, fast hosttoFPGA data transfer, for PCI Express, USB 3.0 and Gigabit Ethernet. Supports user applications written in C, C, C, VB.net, MATLAB, Simulink and LabVIEW.32 Xcell Journal      Second Quarter 2013XPLANATION FPGA 101Xilinx HighLevel Synthesis Tool SpeedsFPGA Designby Sharad SinhaPhD CandidateNanyang Technological University, Singaporesharadsinhapmail.ntu.edu.sgH ighlevel synthesis HLSrefers to an automated wayof synthesizing a digitaldesign beginning with its C, C orSystemC description. Engineershave a keen interest in highlevelsynthesis not only because it allowsthem to work at a high level ofabstraction, but also because itoffers the ability to easily generatemultiple design solutions. With HLS,you get the opportunity to investigate numerous possibilities andweigh their area and performancecharacteristics before settling onone of them to implement on yourFPGA chip. For instance, you caninvestigate the effects of mappingmemories to Block RAM BRAM ordistributed RAM, or explore theeffects of loop unrolling and otherlooprelated optimizationsall without manually generating differentregistertransferlevel RTL designs.Just setting the relevant directives inthe CCSystemC design is all youneed to do.  Xilinx has introduced an HLS toolwithin its newly released Vivadotool suite. Vivado HLS, a rebrandingand respin of the AutoESL tool, provides many techniques to optimizeyour CCSystemC code to achievetarget performance. HLS tools likethis one help you rapidly implement algorithms on FPGAs withoutresorting to a timeconsuming RTLdesign methodology based on hardware description languages such asVerilog and VHDL.To get a handle on how VivadoHLS operates from a users perspective, lets take a walk through an endtoend synthesis process, fromdesign description CCSystemCall the way to FPGA implementation,using matrix multiplication as ourdesign example. Matrix multiplication is common in many applicationsand is extensively used in image andvideo processing, scientific computing and digital communications.  Allthe results in this project were generated using Vivado HLS 2012.4,along with Xilinx ISE softwareversion 14.4 for physical synthesisand placeandroute. This flow alsouses ModelSim and GCC4.2.1mingw32vc9 for RTL cosimulation.Figure 1 shows a simple synthesisoriented flow beginning with aCCSystemC description of thedesign to be synthesized in anFPGA. The CCSystemC testbench is the testbench needed toverify the correct functioning of thisdesign. You will also need it for RTLand C cosimulation. Cosimulationinvolves verifying the generatedRTL design the .v or .vhd designfor functionality using this CCSystemC testbench rather than anRTL testbench or a testbench written in a verification language likee or Vera. The clock period constraint sets the target clock periodat which the design is supposed torun. The target FPGA device is theXilinx FPGA on which the designwill be mapped.Second Quarter 2013 Xcell Journal 33X P L A N A T I O N   F P G A 1 0 1Pairing Vivado HLS with highlevel languages like C allows you to rapidlyimplement algorithms on FPGAs.Synthesis takes place in Step 3, asVivado HLS synthesizes the functiondefined in the source file. The output ofthis stage includes Verilog and VHDLcode the RTL design of the C functionas well as estimates of resource utilization on the target FPGA and the estimated clock period with respect to thetarget clock period. Vivado HLS alsogenerates estimates of latency as wellas looprelated metrics. Step 4 involves simulating the generated RTL using the C testbench. Thisstep is called RTL cosimulation becausethe tool employs the same testbenchthat was used to verify the C source codeto now verify the functional correctnessof the RTL. For this step to be successful, your PATH environment variable onyour system Windows or Linux  shouldinclude the path to your ModelSimMATRIX MULTIPLICATION IN CTo get the most of our matrix multiplication example, we will explore various modifications of the C implementation of matrix multiplication to showtheir effect on the synthesized design.This process will highlight the important points you will need to be aware ofwhen using HLS for prototyping as wellas actual design. I will skip the stepsinvolved in setting up a project, as youcan easily find these in the tool documentation. Instead, I will focus on thedesign and implementation aspects.In a typical Vivado HLS flow, youwill need three CC files the sourcefile, which includes the C function tobe synthesized the header file and afile describing the testbench within acall to the main function. The header file includes not onlythe declaration of the function implemented in the source file, but alsodirectives to support userdefined datatypes with specific bit widths. Thisallows a designer to use bit widths different from the standard bit widthsdefined in CC. For instance, aninteger data type int is always 32 bitslong in C. However, in Vivado HLS, youcan specify a userdefined data type,data, that uses only 16 bits. Figure 2 shows a simple C functionfor matrix multiplication. Two matrices, mat1 and mat2, are multiplied toget matrix prod. For simplicity, allmatrices are of the same sizenamely,two rows by two columns.34 Xcell Journal      Second Quarter 2013X P L A N A T I O N   F P G A 1 0 1The steps you will need to executein the HLS flow are Step 1 Build the project Step 2 Test the build  Step 3 Synthesis Step 4 RTL cosimulation Step 5 Export RTL  RTL implementationStep 1 compiles the project and testsfor syntax errors and so on in the different design files. Step 2 tests the function to be implemented present in thesource file for its functional correctness. In this step, you will execute thecall to the function in the testbench andverify it as functionally correct. If thefunctional verification fails, you can goback and modify the design files.CCSystemC .v.vhd DesignTarget FPGA DeviceClock Period ConstraintCCSystemC Testbench Vivado HLS  Xilinx ISEFPGA bitstreamvoid matrixmultiplydata matleft22, data matright22, dataproduct22  data i,j,k  fori0i2i      forj0j2j      fork0k2k      productijproductijmatleftik matrightkj     Figure 1  FPGA synthesis flow using Vivado HLSFigure 2  Simple C code for 2 x 2 matrix multiplicationX P L A N A T I O N   F P G A 1 0 1Second Quarter 2013 Xcell Journal 35installation. Also, you must also havethe package GCC4.2.1mingw32vc9 inyour ModelSim installation folder. Finally, Step 5 involves exportingthe RTL as an IP block to be used in abigger design and to be processed byother Xilinx tools. You can export theRTL as an IPXACTformatted IPblock, as a System Generator IP blockor as pcoreformatted IP for use witha Xilinx embedded design kit. Whileexporting the Vivadogenerated RTL,you can evaluate its postplaceandroute performance by selecting thetools evaluate option, thus resultingin RTL implementation. In this caseXilinx ISE runs from within theVivado HLS tool itself. For this to happen, you need to set the path to yourISE installation in your PATH environment variable setting, and Vivado HLSwill search for an ISE installation.Of course, you are also free not toexport the Vivadogenerated RTL asan IP block in one of the three formats just described. The exported format files are available in three placesprojectdirectorysolutionnumberimplpcores or projectdirectorysolutionnumberimplsysgen or projectdirectorysolutionnumberimplip. You can aswell use the Vivadogenerated RTL in abigger design or use it as a topleveldesign in itself. You need to take careof its interface requirements wheninstantiated in the bigger design. When the C function in Figure 2 issynthesized, you get the RTlevelimplementation shown in Figure 3. Asyou can see, in this implementation,the elements of matrices 1 and 2 areread into the function and the elements of the product matrix are written out. Thus, this implementationassumes that memory external to thematrixmultiply entity is availablefor storing the elements of matrices 1,2 and prod. Table 1 gives a description of the signals and Table 2 showsthe design metrics.In Table 1, start, done and idle signals are related to the finite statemachine FSM that controls the datapath in the design. As you can see, theVivado HLSgenerated Verilog assumesthat the operation starts with the startsignal and that valid output data isavailable, with the apdone signalgoing high from low. The Vivado HLSgenerated VerilogVHDL will alwayshave at least three basic signals,apstart, apdone and apidle, alongproductwe0productce0productq0150apidleapdoneapstartaprstapclkmatrightce0     matleftaddress010matleftq0150productd0150productaddress010matrixmultiplymatleftce0     matrightaddress010matrightq0150apreadyFigure 3  Design resulting from the code in Figure 2Design MetricDSP48ELookup tablesFlipflopsBest achieved clock period nsLatencyThroughput intitiation intervalDevice XC6VCX75TFF7842144612.8566969Table 1  Design metrics for the design in Figure 3Figure 2 does. This implementationexpects the input and the output matrices data to be available in memoriesexternal to the implementation.RESTRUCTURING THE CODEThe code in Figure 4 will serve yourpurpose. It will be part of the sourcefile, which should be a C file andnot a C file as earlier. You shouldinclude the relevant headershlsstream.h and apint.hin thewith the apclk signal. This meansthat no matter which design youimplement using Vivado HLS, thelatency of the design will constrainyour streaming throughput. Thedesign in Figure 2 has a latency of 69clock cycles at a target clock period of3 nanoseconds. That means that forthis particular case, it will take 69clock cycles for all the product matrixelements to be available. Hence, youcannot feed a new set of input matri36 Xcell Journal      Second Quarter 2013X P L A N A T I O N   F P G A 1 0 1ces to your design before at least 69clock cycles.Now, the implementation as shownin Figure 3 is not probably what youwould have in mind when you tried toimplement matrix multiplication on anFPGA. You would probably want animplementation where you feed theinput matrices, store and computethem internally, and then read out theproduct matrix elements. This is clearly not what the implementation inSignalmatleftce0matleftq0150matleftaddress10matrightce0matrightq0150matrightaddress10productce0productwe0productd0150productq0150productaddress010apclkaprstapstartapdoneapidleapreadyDescriptionChip enable for memory that stores matrix 116bit element of matrix 1Address to read data from memory storing matrix 1Chip enable for memory that stores matrix 216bit element of matrix 2Address to read data from memory storing matrix 2Chip enable for memory that stores product matrixWrite enable for memory that stores product matrixData written to memory that stores product matrixData read from memory that stores product matrixAddress from which data is to be readwritten to in product matrixClock signal for designActive high synchronous reset signal for designStart signal for start of computationDone signal for end of computation and output readyIdle signal indicating that the entity design is idleIndicates to the datafeeding stage that the design is ready for new input data to be used in conjunction with apidleTable 2  Description of signals for the design in Figure 3X P L A N A T I O N   F P G A 1 0 1Second Quarter 2013 Xcell Journal 37header file matrixmultiply.h. Notethat in Figure 2, when the source filewas a C file, the header file includedan apcint.h header. The header filesapint.h and apcint.h help defineuserdefined data types with arbitrary bit widths for C and C sourcefiles respectively. The header filehlsstream.h file is required to makeuse of the stream interfaces and canonly be used when the source file isin the C language.In order to have a design where youcan just stream in input matrices andstream out the product matrix, youneed to implement read and writestreams in your code. The codehlsstream streamname is used toname the read and the write streams.Thus, dmat1 and dmat2 are readstreams and dproduct is a writestream. The streaming interfacesbehave as FIFOs. By default, the depthof the FIFOs is 1. You will need to setthe depths in the Vivado HLS directives pane by selecting the definedstreams. For the code in Figure 4, eachstream is four data units deep. Notehere that the i,j loop executes beforethe p,q loop due to the sequentialnature of C code. Hence, thedmat2 stream will fill up after thedmat1 stream. Once you are done with the streaminterface, you can select the matrices tobe mapped to BRAM by applying thedirective RESOURCE and choosing acore through the directives pane.Otherwise, the matrices will be implemented using flipflops and lookupinclude matrixmultiplystream.husing namespace hlsstream data dmat1stream data dmat2stream data dprodmatvoid matrixmultiplystream streamdata dmat1, streamdata dmat2,streamdata dprodmatdata matrixleft220data matrixright220data matrixproduct220data elementmat1data elementmat2data i,j,p,q,kfor i0i2i forj0j2j        matrixleftij  dmat1.read  for p0p2p forq0q2q       matrixrightpqdmat2.read  fori0i2i  forj0j2jfork0k2k   matrixproductij  matrixproductijmatrixleftikmatrixrightkj     fori0i2i  forj0j2j    dprodmat  matrixproductij  Figure 4  Restructured source code for matrix multiplyIn order to have a design where you can just stream in input matrices and stream out the product matrix, you need to implement read and write streams in your code. The streaming interfaces behave as FIFOs. By default,the depth of the FIFOs is 1.38 Xcell Journal      Second Quarter 2013X P L A N A T I O N   F P G A 1 0 1Without BRAM or distributed RAM for matricesWith singleport BRAM for matricesWith distributed RAM implemented in LUTs for matrices Design MetricDevice XC6VCX75TFF7842DSP48ELookup tablesFlipflopsBRAMBest achieved clock period nsLatencyThroughput initiation interval118533102.8868484110910233.216116116117919002.952104104Signaldmat1Vreaddmat1Vdout 150dmat1Vemptydmat2Vreaddmat2Vdout 150dmat2VemptydproductVdin 150dproductVfullndproductVwriteapclkaprstapstartapdoneapidleapreadyDescriptionSignals when the design is ready for inputs to matrix 1 left matrix16bit streaming element of matrix 1Signals to the design that no more elements for matrix 1 are leftSignals when the design is ready for inputs to matrix 2 right matrix16bit streaming element of matrix 2Signals to the design that no more elements for matrix 2 are left16bit output element of product matrixSignals that product matrix should be written to Signals that data is being written to the product matrixClock signal for designActive high synchronous reset signal for designStart signal to begin computationDone signal to end computation and signal output readyIdle signal to indicate that the entity design is idleIndicates to the datafeeding stage that the design is ready for new input data to be used in conjunction with apidleTable 3  Description of signals for the design in Figure 5Table 4  Design metrics for the design in Figure 5X P L A N A T I O N   F P G A 1 0 1Second Quarter 2013 Xcell Journal 39tables LUTs. Note that the directivespane will be active only if you keep thesource file active in the synthesis view.The implemented design for thecode in Figure 4 is shown in Figure 5.Table 3 describes the signals availableon this designs interface. In Table 3,dproductVfulln is an active lowsignal when the core is to be signaledthat the product matrix is full. Thiswould not be generally required in animplementation. Table 4 shows the different designmetrics after placeandroute for aclock period constraint of 3 ns, withand without mapping matrix arrays toBRAM or distributed RAM. You cansee from Table 4 that the design fails tomeet a timing constraint of 3 ns whenmatrices are mapped to singleportBRAM. This result has been deliberately included in the table to show thatyou can use this methodology to generate a variety of designs with different areatime metrics. You can also seefrom Table 1 that although the code inFigure 2 gives a latency of 69 clockcycles, which is less than the restructured design based on code in Figure 4,this design would require memoryexternal to the matrixmultiply entity asexplained earlier.PRECISION OF THEIMPLEMENTATIONFor the results shown here, I definedthe data type data to be 16 bits wide.Hence, elements of all matrices left,right and product were only 16 bitswide. As a result, the matrix multiplication and addition operations were notdone at full precision. You can chooseto define another data type, datat1, inthe header file that would be 32 bitswide all the elements of the productmatrix would be of this data type,because a 16bit number element ofleft matrix multiplied by another 16bitnumber element of right matrix canbe at most 32 bits wide. In this case, theresource utilization and timing resultswill differ from those in Tables 1 and 4.The restructured source codeshows how multiple design solutionscan arise from the same source files. Inthis case, one design solution hadBRAM while the other one did not.Within each Vivado HLS project directory, you will see that Vivado HLS hasgenerated separate directories for separate solutions. Within each solutiondirectory will be a subdirectory namedimpl for implementation. Here,within this subdirectory, you will havea directory titled Verilog or VHDL,depending on which source code youused during the RTL implementationphase. This same subdirectory alsocontains a Xilinx ISE project file fileextension .xise. If the Vivado HLSgenerated design is your topleveldesign, you can launch your solution inXilinx ISE by clicking on this file, andthen generate the postplaceandroutemodel for gatelevel timing and functional simulation. You cannot do thissimulation from within Vivado HLS.After launching your solution in ISE,you should assign IO pins to yourdesign. Then you can select generateprogramming file in ISE ProjectNavigator to generate the bitstream.In this exercise, we have walkedthrough an actual Vivado HLS endtoend flow and then implementation onan FPGA. For many of the advancedfeatures in Vivado HLS, you need toknow your desired hardware architecture in order to restructure the sourcecode. For further information, a coupleof documents will prove helpful theVivado HighLevel Synthesis TutorialUG871 httpwww.xilinx.comsupportdocumentationswmanualsxilinx20122ug871vivadohighlevelsynthesistutorial.pdf and the VivadoDesign Suite User Guide UG002httpwww.xilinx.comsupportdocum e n t a t i o n  s w  m a n u a l s  x i l inx20122ug902vivadohighlevelsynthesis.pdf. To read more by Sharad Sinha, follow hisblog at httpsharadsinha.wordpress.com.aprstdmat2Vemptyn       dmat1Vdout 150         dmat1Vemptyndmat2Vdout 150dproductVwritedproductVfullnapidleapdoneapstartapclkdproductVdin 150matrixmultiplydmat1Vreaddmat2VreadapreadyFigure 5  Design resulting from the code in Figure 440 Xcell Journal      Second Quarter 2013XPLANATION FPGA 101Having developed your Zynq SoC applicationand tested it using the JTAG interface, the nextstep is to get the boot loader working.How to ConfigureYour Zynq SoCBareMetal Solutionby Adam TaylorPrincipal EngineerEADS Astriumaptaylortheiet.orgBecause of its unique mix of ARM processingclout and FPGA logic in a single device, theZynq7000 All Programmable SoC requires atwofold configuration process, one that takes intoaccount both the processor system and the programmable logic. Engineers will find that the configurationsequence differs slightly from that of traditionalXilinx FPGAs. Nevertheless, the methodology isfamiliar and its not at all difficult to generate a bootimage and program the configuration memory.Where standard FPGA configuration practices normally require only the FPGA bit file, you will need toadd a second type of configuration file to get the maximum benefit from your Zynq SoC the SW Executableand Linakble Format ELF file. The FPGA bit filedefines the behavior of the programmable logic sectionof your design, while ELF file is the software programthat the processing system will execute. So lets have a look at how to implement a baremetal no operating system software application onyour Zynq SoC.CONFIGURATION OVERVIEWWithin a Zynq SoC, the processing system PS is themaster and therefore configures the programmablelogic PL side of the device. The only exception tothis rule is if you use the JTAG interface for configuration. This means you can power the processingsystem and have it operating while the programmable logic side is unpowered, if so desired, to reducethe overall system power. Of course, if you want touse the PL side of the Zynq SoC, you will need topower it too. The software application and FPGA bit file arestored within the same configuration memory deviceattached to the processing system. The PS supportsconfiguration by means of a number of nonvolatilememory types, including quad SPI flash, NAND flash,NOR flash and SD cards. You can also configure thesystem via JTAG, just like any other device. Therefore, the Zynq SoC follows a typical processorboot sequence to configure both sides of the device,initially running from an internal boot ROM that cannot be modified. This boot ROM contains drivers forSecond Quarter 2013 Xcell Journal 41X P L A N A T I O N   F P G A 1 0 1This is the second in a planned series of handson Zynq7000 All Programmable SoC tutorials by AdamTaylor. A frequent contributor to Xcell Journal, Adam wrotethe cover story on Zynq SoC design in Issue 82 as well asthe article on XPE and XPA in this issue see page 46. He is also a blogger at All Programmable Planet.  Ed.quad SPI configuration, FSBL offset and image length2. Firststage boot loader 3. Programmablelogic bit file 4. Software application ELF filefor the processingsystem sideLike all other Xilinx FPGAs, theZynq SoC device uses a number ofmode pins to determine which type ofmemory the program is stored within,the nonvolatile memories supported.You configure it by means of a headercontained within the nonvolatile memory. The header marks the start of theconfiguration image and is the firstthing the boot ROM looks for. The header defines a number of boot options thatthe boot ROM can implement, such asexecute in place not for all memories,however, firststage boot loaderFSBL offset and secure configuration.This header process ensures the bootROM operates in the mode that is compatible with how the configurationmemory has been formatted.For designs, users have the optionof either secure or nosecure methodsof configuration. The boot ROM header supports and defines both modes.In secure configuration, the programmable logic section of the device mustbe powered up as the hard macrosAES and SHA. You need both fordecryption and must place them inthe PL side of the device.For the next stage of configuration,you will need to provide an FSBL thatwill configure the DDR memory andother peripherals on the processor asdefined in Xilinx Platform StudioXPS before loading the softwareapplication and configuring the programmable logic. Overall, the FSBL isresponsible for four major tasks Initializing the processing systemwith the information that XPSprovides Programming the PL side of theZynq SoC if a bit file is provided Loading either a secondstageboot loader SSBL, if an operating system is being used, or a baremetal application into DDR  Starting the execution of the SSBLor the baremetal applicationYou program the PL side of the ZynqSoC via the Processor ConfigurationAccess Port PCAP, which allowsboth partial and full configuration ofthe programmable logic. This meansyou can program the FPGA at any timeX P L A N A T I O N   F P G A 1 0 1once the processing system is up andrunning. The PCAP also lets you readback and check for errors, if you areusing the device in an environmentwhere it may be subject to singleeventfunctional interrupts SEFIs.To create a bootable image for ourZynq SoC, you will need at least the following functions 1. Boot ROM header to control settings for the boot ROM for example, execute in place, encryption,Figure 1  Creating the firststage boot loader projectFigure 2  Creating the FSBL from the template provided42 Xcell Journal      Second Quarter 2013X P L A N A T I O N   F P G A 1 0 1along with other crucial system settings. These mode pins share theMultiuse IO MIO pins on the PS sideof the device. In all, there are sevenmode pins mapped to MIO82, withthe first four defining the boot mode.The fifth defines whether the PLL isused or not, and the sixth and seventhdefine the bank voltages on MIO bank0 and bank 1 during powerup. Thefirststage boot loader can change thevoltage standard defined on MIObanks 0 and 1 to the correct standardfor the application however, if you aredesigning a system from scratch, makesure the voltage used during powerupwill not damage the device connectedto these pins. FIRSTSTAGE BOOT LOADER CREATIONThe next step in making a boot imageis to create a firststage boot loader.Thankfully, you dont have to do thismanuallythe FSBL that Xilinx hasprovided will load your applicationand configure your FPGA. You can, ofcourse, customize the code providedto alter the boot sequence as desiredfor your application. Within the current Software Development Kit SDKworkspacethe one that containsyour projectcreate a new projectusing the new  application project,as shown in Figure 1.Choose whether you want to use Cor C, pick the board support packagedefined for your system and name theprojectin this case, I used the namezynqfsbl0 for our example design. On the next tab, select the ZynqFSBL option from the available templates as shown in Figure 2, and yourFSBL project will be created. You arethen nearly ready to create the bootimage. If you have compile automatically selected, the FSBL will be compiled if not, it will be compiled ondemand later on.However, we need to make achange to the linker script providedwith the FSBL, as it has no ideawhere the DDR memory is located inthe processor address space.Therefore, we need to open thelscrip.ld and add the DDR memorylocation into the file. The location ofthe DDR within the address spacecan be found in the linker script youhave created for your applicationsee cover story, Xcell Journal Issue82, for details on how to create thisscript. Otherwise, you can also findit in the system.xml file under thehardware platform definition.Figure 3 shows the FSBL lscript.ldwith the DDR address for the systemadded in. If you forget to add it, youwill find that the boot loader will runand the FPGA will configurebut theapplication will not run if you haveconfigured it to execute in DDR.GENERATING A CONFIGURATION IMAGELooking under the Xilinx SDK ProjectExplorer, you should hopefully nowFigure 4  Finding the complete files needed for the boot imageFigure 3  Defining the DDR address spaceSecond Quarter 2013 Xcell Journal 430x0 in the dialog box that appears.Then, after making sure your targethardware is powered on, click onprogram Figure 6.It may take a few minutes for thedevice to be programmed and verifiedif you ticked the verify option. Oncethe process is complete, power downyour hardware and reapply the poweralternatively, you can reset the processor. Provided you have the mode pinshave the following four modules. Eachshould have a slightly different symbolidentifying the type of module. UsingFigure 4 as an example, you will seethe following structure.1. procsubsystemhwplatform Named after the processing subsystem you created, this is thehardware definition of your file. 2. zedblog0  This is the boardsupport package you created.  3. zedblogC  This is the application itself.4. zynqfsbl0   This is the firststage boot loader you have justcreated and modified the linkerscript for.Since we are creating a baremetalapplication no OS, you will need threefiles to create a boot image, in this specific order firststage boot loader FPGAprogramming bit file and C application. Creating a boot image is very simplewithin the SDK using the Create ZynqBoot Image option under the Xilinxtools menu. Once you have selectedthe boot image, a new dialog box willopen, allowing you to choose the filesneeded, as seen in Figure 4. It is important to stress that theFPGA bit file must always follow theFSBL. Clicking on create image willcreate both a .bin and .mcs file, whichyou can program into the target device. PROGRAMMING THECONFIGURATION MEMORYYou can program your configurationmemory through either the SDK, usingthe program flash option under theXilinx tools options, or by using XilinxsiMPACT programming tools. For thisexample, we will be storing the configuration file within quad SPI flash. TheQSPI interface is defined in the systemassembly view of Xilinx PlatformStudio. Hence, the hardware definitionwill contain the QSPI IP core and thelocation in the address map, allowingthe firststage boot loader to interface tothis device and configure it. X P L A N A T I O N   F P G A 1 0 1The next stage in programmingthe device is to connect the ZynqSoC hardware system to your PCusing the JTAG programming cable.Programming the configurationmemory is then as simple as selecting the program flash option fromthe Xilinx tools menu within theSDK, as shown in Figure 5. Navigate and select the MCS fileyou generated and enter an offset ofFigure 6  Programming the flash dialogFigure 5  Programming the configuration memory44 Xcell Journal      Second Quarter 2013X P L A N A T I O N   F P G A 1 0 1Second Quarter 2013 Xcell Journal 45configured correctly, your Zynq SoCsystem will spring to life, fully configured, and start to run the applicationsoftware and FPGA design.ADVANCED CONFIGURATIONPARTITION SEARCH ANDMULTIBOOTThe example provided above walksyou through the configuration of asingle configuration image. However,it is possible for the boot ROM to perform a partition search should the initial image fail to load if the boot ROMchecks fail. If this is the case, the bootROM will look for another goldenimage located at a higher locationwithin the configuration memory. Thetype of configuration memory youuse will impact how much of theaddress space the boot ROM searches. If you are using an  SD card,there is no partition search. It is also possible for the ZynqSoC to load a different image fromthe configuration memory following a warm reset. To do this, youmust define the multiboot addressfor the boot ROM either throughthe FSBL or at a later stage withinthe secondstage boot loader orthe application. This allows theZynq SoCs boot ROM following awarm reset to configure from thelocation toward which the multiboot address points, allowing a different image from the initial one tobe loaded. Unlike in the partitionsearch, these images can be locatedin any order within the configuration memory. However, followingfrom poweron reset, the boot ROMwill load the first valid image it findswithin the configuration memory.While different from the traditionalFPGA configuration approach, ZyncSoC configuration is not an arcaneart. Many engineers will be familiarwith the twopronged methodology,and will find it very easy to generate aboot image and program the configuration memory using the tools provided within the Xilinx SoftwareDevelopment Kit. 46 Xcell Journal      Second Quarter 2013XPLANATION FPGA 101Using Xilinxs PowerEstimator and Power Analyzer ToolsF PGAs are unlike many classesof components in that thepower they will require on theircore, auxiliary and IO voltagesdepends upon the implementation ofthe design. Determining the power dissipation of the FPGA in your application is thus a little more complicatedthan just reading the datasheet. It cantherefore be challenging to ensure youhave the correct power architectureone that takes into account not only therequired quiescent currents, ramp ratesand sequencing, but also has the abilityto suitably power the end applicationwhile remaining within the acceptablejunction temperature of the device.What are XPE and XPA These aretwo design tools provided by Xilinxthat enable you to obtain accuratepower analysis of your FPGA design.You will use the spreadsheetbasedXilinx Power Estimator XPE in theearly stages of your design and turn toXilinx Power Analyzer XPA aftercompleting the implementation. XPAallows you to perform further analysison the power requirements of yourdesign and assists in power optimization should it be required.INITIAL STEPSWhen you first launch a developmentproject, it is rare that the completeFPGA design will exist if you arelucky you may get to reuse some code,which will provide more accurateinformation for the power prediction.Therefore, the starting point for yourpower estimation will be the XilinxPower Estimator spreadsheet seehttpwww.origin.xilinx.comproductsdesigntoolslogicdesignxpe.htm.Your first power estimation will bebased on the engineering teams initialthoughts on the number of clocks,logic and additional resources that thedesign will require. Using XPE is very straightforward.Even better, the tool allows you to doplenty of what if implementations todetermine the impact of variousdesign choices on your power estimation. If your solution is power hungry,this capability can prove to be veryimportant in helping you find the optimal implementationThe ability of XPE to predict thejunction temperature of the devicedependent upon the heat sinking, theairflow and the number of layers within the printedcircuit board is very useful at an early stage too. It can showwhether your design can achieve derated junction temperatures for theintended implementation.Within XPE, your first step is tocomplete the settings tab as accurately as you can. Along with selecting the device, pay particular attention that the package, speed gradeand temp grade are correctly setSecond Quarter 2013 Xcell Journal 47X P L A N A T I O N   F P G A 1 0 1Obtaining an accurate power estimation of your FPGA design can be critical for ensuring you havethe correct power architecture.by Adam TaylorPrincipal EngineerEADS Astriumaptaylortheiet.orgresponsible for power engineeringinformed of any change in the estimation. The power engineers should beable to provide worstcase maximumvoltages for the supply rails, which canfurther improve the accuracy of yourestimation. A higher worstcase maximum supply voltage will increase thepower dissipation. XPE is intelligent. It will color thevoltage cells on your spreadsheetorange and issue a warning if theworstcase maximum supply voltage isoutside of the acceptable tolerance forthe device, as shown in Figure 2.likewise stepping, process andpower mode, if applicable. All ofthese parameters will have a considerable impact on the overall powerrequiredespecially the process,which has the settings of maximum or typical. The typical setting will give you the power yourapplication would statistically see,while the maximum will give theworst case. It is important to ensurethe power solution can handle themaximum case, but this can becomechallenging with larger devices thathave higher current requirements. You can also define the operatingenvironment here as well, with theambient temperature, heat sinkingand airflow. Defining the maximumambient temperature at this point willprovide a more accurate power estimation, because the power requiredwill increase as the device junctiontemperature rises. Including heatsinking, airflow or both will thereforelower your power estimation.Also at this stage, dont overlookthe Xilinx ISE optimization setting.This setting will also have an impacton the power estimation, as differentoptimization schemesfor example,timing performance against areaminimizationwill result in varyingimplementations, each with its ownresource usage and fanout. They toowill affect the power estimation.The next stage of the estimationis to go through the tabs at the bottom of the XPE spreadsheet and fillin details on your proposed solutionas accurately as possible. To ensurethe most accurate estimation at anearly stage, it is very important todefine at least the resource usage,clock frequencies, toggle rate andenable rate. It is also a good idea toinclude a level of contingency toaddress the everpresent requirements creep.This process will result in XPEproviding an overall power and junction temperature estimation on thesummary tab, like the one in Figure 1. 48 Xcell Journal      Second Quarter 2013X P L A N A T I O N   F P G A 1 0 1Once your estimation is complete,you can, if you wish, export the settings from XPE for use later within theXilinx Power Analyzer XPA by usingthe export file option on the summary page. This ensures the settings inXPA are aligned with those you initially used for the estimate.As the development progressesthrough RTL production, trail synthesis and placeandroute, it is importantto keep the estimation up to date asmoreaccurate information becomesavailable. Remember also to keep thehardware teamespecially the groupFigure 1   Summary of the XPE device settings and power estimationFigure 2   The warning issued when your power supply voltage is outside of acceptable toleranceX P L A N A T I O N   F P G A 1 0 1Second Quarter 2013 Xcell Journal 49MOVING ON TO XPAOnce you have implemented thedesign, it is possible to obtain a muchmore accurate estimate of its powerpicture using the Xilinx PowerAnalyzer. How accurate this result willbe depends upon the inputs you givethe tool. You can open XPA by clickingon Analyze Power Distribution underthe Place and Route Options withinthe processes window of the ISEdesign suite see Figure 3.Once XPA opens, you will again bepresented with a summary screensimilar to that in XPE Figure 4. Thisis the place where you can define theenvironment and either create additional settings or import the settingsfrom your XPE analysis. To include the .xpa file or open anew project, you will need to use thefollowing flow, which will include A Native Circuit Design NCDfile that defines the physicalFPGA implementation  A Settings File, to define the settings imported from XPE A Physical Constraints FilePCF, which contains the clocking information and mapping andUCF constraints A simulation file, either a ValuesChange Dump VCD or SwitchingActivity Interchange File SAIF,which you can generate with yoursimulation tool, allowing XPA toobtain the switching informationof the designNaturally, the more information youinclude upfront, the more accurate thepower estimation will be. Helpfully,XPA provides a confidence level on itsestimationeither low, medium orhighfor five categories designimplementation state, clock nodesactivity, IO nodes activity, internalnodes activity and device models.These individual confidence levelscontribute to the overall confidencelevel of the estimation. Again, ratherhelpfully, XPA will provide suggesFigure 3  Opening XPA from ISETo ensure you obtain the most accurate power estimation possible, here is a checklist that covers the most important steps. 1. Start with the correct environmental settingstepping, speed grade,heat sinking, airflow and ambient temperature.2. Ensure the process is set correctly to typical or maximum for worst case.3. Set the supply voltages to their worstcase maximum.4. Make sure you have the most accurate toggle rate, fanout, enable rate,IO properties and clock rate.  5. Use a simulation VCDSAIF file to provide the best information on thedesign performance within XPA. To obtain the best results, this fileneeds to be a gatelevel simulation.6. Keep the power estimation up to date as both the hardware and FPGAdesigns progress, so revisit it often.7. Include contingency within your power estimation to address requirements creep in your application.8. Be sure to define termination schemes and load capacitance correctly for the IO in both XPA and XPE.9. Make sure the confidence level reported by XPA is high.10. Ensure the power solution meets all the other power requirements for the device and for reliability, and is not running at or near its load capacity.10 Steps to Accurate Power EstimationWhen you exit the simulation, theresults will be saved into the VCDfile, which you can then use withXPA. If you are using ISim, the formatis a little different vcd dumpfile myvcd.vcddefine the file name andlocation if desiredvcd dumpvars mmemoryiftbuutapply the region of the designthat is to be recorded Run Simulationvcd dumpflush save results to the vcdfile createdThere are many moreadvanced commands within the simulation tools  thatyou can use to generate a VCD theseare detailed within the tool documentation itself. Having included the simulation VCDfile, the level of confidence of yourpower estimation should increase. Ifyou cannot provide a simulation resultsome can take a long time to run,then XPA will run using its internalanalysis engine. For this to be accurate, it is important you again specifythe toggle and enable rates. Just as in XPE, it is also important toinclude the worstcase maximum supply voltages within XPA. It is possibleas well to export the XPA design backinto XPE to allow the engineering teamto try out more experimental changesand determine their effect on the powerand junction temperature estimates.WHAT IF IT IS NOT OKHaving included a simulation and provided the rest of the information, youwill have achieved a high level of confidence in the power estimate and predicted junction temperature. In anideal world, this will hopefully beacceptable for the application.However, should that not be the case,what other options are open to thetions on how to increase the confidence level of each individual category,hence boosting the overall confidencelevel Figure 5.To obtain the highest level of confidence in the power estimation, youare required to include a VCD or SAIFfile from a gatelevel simulation. Thisallows XPA to understand the behavior of the internal nodes, hence providing a better estimate.Obtaining the VCD from your simulation is pretty straightforward, butdepending on the tool you are using50 Xcell Journal      Second Quarter 2013X P L A N A T I O N   F P G A 1 0 1Mentor Graphics ModelSim, XilinxsISim, etc., the format of the commands required might be slightly different. If you are using ModelSim,you can create a simple VCD file withthe following syntaxvcd file myvcd.vcd define the file name andlocation if desiredvcd add memoryiftbuutapply the region of the designthat is to be recorded Figure 4  The XPA summary screenFigure 5  XPA confidencelevel report and suggested actions to improve itX P L A N A T I O N   F P G A 1 0 1Second Quarter 2013 Xcell Journal 51engineer to ensure your design hasachieved the available power budgetor required junction temperatureTo obtain the desired results, thereare three places where we can affectthe design within the source, withinthe implementation or in the case ofjunction temperature within thephysicalmodule design.Within the design source, you cantake the following steps1. Remove any asynchronous resets.2. Include pipeline stages betweenlarge combinatorial functions. 3. Ensure you are using dedicatedresources available within thedevice by either inference orinstantiation. The options available within synthesisand placeandroute are1. Set the optimization scheme forarea minimization or powerreduction. 2. Examine the design constraintsto ensure they are not overly constraining the device. 3. Limit the fanout of highfanoutpaths. 4. Utilize RAMs for things like statemachines wherever possible.5. Ensure retiming is enabled.Hopefully, the above steps will reduceboth the estimated power and the predicted junction temperature. However, ifnecessary you can reduce the junctiontemperature by using heat sinks orforced airflow, should the above not besufficient. Doing so may, however, affectthe mechanical design of the project. ACCURATE ESTIMATESYou can use Xilinx Power Estimator andXilinx Power Analyzer to obtain accuratepower estimations for an FPGA design,and information can be easily sharedbetween the two tools. The accuracy ofthe power estimate will depend on thequality of data from both the simulationand your powerengineering team.You should also provide sufficientcontingencies to account for requirements creep and to ensure the solution is capable of addressing thepower on currents and ramp rates ofthe voltage supplies.52 Xcell Journal      Second Quarter 2013TOOLS OF XCELLENCEA tiny GPS disciplined oscillator from Symmetricom can easily substitute for an atomic clock in your system design. Pair it with aXilinx Zynq SoC to build an NTP server.What Time Is ItSecond Quarter 2013 Xcell Journal 53What if you need to know what time itis, or what frequency you have, orneed to provide a precise frequencyin your system A few months back Iobtained a sample of a small assembly, measuring roughly 1 x 1 x 0.25inch, that seems to perform magic aGPS disciplined temperaturecompensated crystal oscillator GPSTCXO from Symmetricom.The evaluation board has anRS232toUSB chip on the motherboard that converts the interfacetofrom the TCXO and its GPS receiver device. Installing the software tosupport the USB is probably the onlyreal effort required, other than finding a place to stick the magnet baseso that the GPS antenna can viewsome satellites in the sky. Cellular basestations, radio systemsand computer systems all requireeither precise time, or precise frequencies, to operate. One big advantage ofusing a fixed GPS system is that,because it isnt moving, it gives a better frequency reference, a more precise location and more precise timeinformation than a system that is notfixed. If you have a mobile applicationsome of that precision gets lost, but byusing the TCXO you still wind up witha really nice system. WHAT IS PRECISEAn atomic clock is not really a clock,but an atomic oscillator with an activeor passive maser. A cesium clock isthe typical frequency source used forwhat is known as a primary reference. It provides an accurate and precise frequency, which varies by nomore than 1E11. Typical cesium references operate down to perhaps 1E12,but have a wander of about 100nanoseconds associated with them butno drift. Such a reference is also sometimes referred to as a Stratum 1 clock. The GPS constellation consists ofmany such precise clocks in orbitmostly rubidium sources that do notwander, but do drift a tiny bit, steeredand corrected periodically by theworlds stable time sources. Some 200of the worlds most accurate clocksget voted in a complex mathematicalprocess, and then we all agree whattime it was some 30 days ago andapply corrections.Thus, a 10MHz temperaturecompensated crystal oscillator steered bythe GPS constellation becomes a precise Stratum 1 timefrequencypositionreference while locked to the satellites, and when the satellites are lost, itthen drifts. However, even this driftmay be anticipated and canceled if youhave a history of the drift and knowledge of your temperature the temperature compensation is not perfect, andis easily observed in operation.NOW, FOR SOME REALLY SMALL NUMBERSAfter a month of operation  pluggedinto my desktop machine at work and,from time to time, into a laptop athome, my little board settled into itsroutine. When it first turned on, it waswithin 1E10, but after a few weeksthe inherent drift of my unit was clearly visible, about 3.031E12, which isbeing compensated for, so the delivered precision is less than 3E12 Allanvariancev for 6 hours the Allan, ortwosample, variance is a measure offrequency stability in clocks, oscillators and amplifiers.  See Figure 1.This is about three times better than acesium clock, which wanders about abit more but would have zero driftunless it were broken. The drift of aTCXO is not constant, because crystals do age. So the drift is now down to3.029E12 after six months.T O O L S  O F  X C E L L E N C Eby Austin LeseaPrincipal EngineerXilinx Labsaustin.leseaxilinx.comThe pulsepersecond 1PPS output had a sixmonth set of equallyimpressive statistics a median of 397picoseconds it is averaging just under400 ps of late, which could be removedas a fixed delay with a variance of1.72E16.Such levels of precision easily allowyou to measure the effect of gravityand velocity on time both of whichthe GPS satellites correct for as theyorbit around the Earth, affected byboth gravity and acceleration.The delivered frequency is remarkably stable and constant while it islocked, which is almost 100 percent ofthe time. Why does it not stay lockedall the time My window faces southeast, so all satellites directly to thenorthwest are blocked from view ofthe antenna. Even so, the time spentwith no satellites in view is only a fewminutes a day and has little to noeffect on the performance.The receiver needs a minimum offour satellites in view to operate, and itusually sees 10 or 11 in a clear skyview. If the GPS signal is lost, I willstart to see the intrinsic drift of myunit 3.03E12. Since every crystal isdifferent, your unit will have its owndrift. Now that I know that drift isthere, I could modify the 10MHz output with an external synthesizer with areverse correction while the satellitesare not being tracked. I could thenturn off that correction when the satellites come back in view.WHAT ELSEI am also able to download the latitude,longitude and altitude, and form a longterm running average. After six months,you could say that I really know exactly where my antenna is located Of54 Xcell Journal      Second Quarter 2013T O O L S  O F  X C E L L E N C EIn the event that you cannot acquire any satellites,there is another alternative the Network Time Protocol.NTP provides time stamping over the Internet.Figure 2  Chart demonstrates the spectral purity of the outputs Figure 1  The Allan variance from a test run of another unit course, I can see it from my desk, soperhaps I should say I can locate it withreference to WGS84, the WorldGeodetic System standard, on GoogleEarth. If I were in a mobile application,the receiver would also report velocity.If I needed to make precise measurements, I would use the 10 MHz as areference. Most highend lab equipment has a backpanel input for anexternal 10MHz reference, so theinstruments are able to lock to thatreference, and thus all their measurements are traceable back to the international standard.If I were building a frequencymeter, counter or RF signal source, Iwould put such a module in there,and pretty much forget about everhaving to calibrate it. Of course, youhave to occasionally get a view ofthe sky or place the instrument in thewindow so it can see as many satellites as possible. The spectral purityof the outputs is also impressive, asseen in Figure 2 also from a testreport of another unit.NO GPS WHAT THENIn the event that you cannot acquireany satellites, there is another alternative the Network Time Protocol.NTP provides time stamping over theInternet so that you may measuretime or frequency, or control a frequency source. So, in a future frequency meter one could envision awireless 802g modem for theInternet, a GPS disciplined oscillatorand the necessary control electronicsperhaps a Xilinx Zynq7000 AllProgrammable SoC device. Such aninstrument would always be accurateand would always know just how accurate it was. It would be able to diagnose itself and report whether it hadany problems. I need a view of the skyfor an hour or two, please.You could port an NTP server to theZynq SoC platform, as there is publiccode available. Running an NTP serveron one of the ARM cores in the Zynqdevice under a Linux operating systemis a fairly straightforward task.For more on the SymmetricomTCXO, see httpwww.symmetricom.com. Additional information onthe Zynq7000 SoC is available athttpwww.xilinx.comproductssilicondevicessoczynq7000index.htm.T O O L S  O F  X C E L L E N C ESecond Quarter 2013 Xcell Journal 5556 Xcell Journal      Second Quarter 2013XAPP897 DESIGNING VIDEO STREAMING SYSTEMSUSING ZYNQ7000 AP SOC WITH FREERTOShttpwww.xilinx.comsupportdocumentationapplicationnotesxapp897videostreamingsystemfreertos.pdfThis application note by Dinesh Kumar describes how tocreate video systems for Digital Visual Interface DVIinput and video test pattern generator TPG input usingXilinx native IP in the Zynq7000 All ProgrammableAP SoC. The reference design, which is targeted for theZC702 evaluation board, configures video IP cores with aprocessing frame rate of 60 Hz and 1,920 x 1,080 resolution, and displays systemlevel bandwidth utilization andvideo latency as metrics. In this way, designers can createcomplex, highperformance video systems using the Zynq7000 AP SoC, with one input from the DVI and one inputfrom the TPG.This application note demonstrates the application ofFreeRTOS, one of the two recommended operating systemsfor the Zynq7000 AP SoC Linux is the other. FreeRTOS isa free operating system that consists of only a few files. It iseasy to port, use and maintain. FreeRTOS supports multiplethreads or tasks, mutexes, semaphores and software timers.In the reference design, the main application runs in one ofthe FreeRTOS threads while another thread is created togradually change the transparency of the onscreen displayOSD to show the blending effect. The design uses two AXI video directmemory accessVDMA cores to simultaneously move four streams twotransmit video streams and two receive video streams,each in a 1,920 x 1,080 frame size at 60 framessecond and24 data bits per pixel RGB. A TPG with a video timingcontroller VTC block drives one VDMA, while incomingvideo from DVIIn drives the other. The data from bothstreams to memory map S2MM paths of the VDMA coresare buffered into DDR, read back by the MM2S channel ofthe AXI VDMA and sent to a common OSD core that multiplexes or overlays multiple video streams to a single output video stream. The output of the OSD core drives theonboard HDMI video display interface through the colorspace converter.The reference design is created with the Xilinx PlatformStudio XPS in the Vivado System Edition 2012.4.Software created with the Xilinx Software Development Kitruns on the ARM dualcore processor and implements control, status and monitoring functions. The reference designhas been fully verified and tested on hardware. XAPP1078 SIMPLE AMP RUNNING LINUX AND BAREMETAL SYSTEM ON BOTH ZYNQ SOC PROCESSORShttpwww.xilinx.comsupportdocumentationapplicationnotesxapp1078amplinuxbaremetal.pdfThe Zynq7000 All Programmable SoC contains two ARMCortexA9 processors that can be configured to concurrently run independent software stacks or executables. Thisapplication note describes a method of starting up bothprocessors, each running its own operating system andapplication, and allowing the two to communicate throughshared memory.The Zynq7000 SoCs CortexA9 processors share common memory and peripherals. Asymmetric multiprocessing AMP is a mechanism that allows both processors torun their own operating systems or baremetal applications with the possibility of loosely coupling those applications via shared resources. The reference designincludes the hardware and software necessary to run bothCortexA9 processors in an AMP configuration CPU0runs Linux and CPU1 runs a baremetal application.Author John McDougall has taken care to prevent theCPUs from conflicting on shared hardware resources.This document also describes how to create a bootablesolution and how to debug both CPUs. XAMPLES. . .Application NotesIf you want to do a bit more reading about how our FPGAs lend themselves to a broad number of applications,we recommend these application notes.Second Quarter 2013 Xcell Journal 57XAPP890 ZYNQ ALL PROGRAMMABLE SOC SOBEL FILTER IMPLEMENTATION USING THE VIVADO HLS TOOLhttpwww.xilinx.comsupportdocumentationapplicationnotesxapp890zynqsobelvivadohls.pdfThis application note describes how to generate the Sobeledgedetection filter in the Zynq7000 All Programmable SoCZC702 Base Targeted Reference Design TRD using theVivado highlevel synthesis HLS tool. The techniquesdescribed by authors Fernando Martinez Vallina, ChristianKohn and Pallav Joshi present the fundamental flow for integrating an IP block generated by Vivado HLS into a ZynqSoCbased system.The Vivado HLS tool provides a methodology for migrating algorithms from a processor onto the FPGA logic. In thecontext of Zynq devices, this means moving code from theARM dualcore CortexA9 processor to the FPGA logic foracceleration. The code implemented with the HLS tool in hardware represents the computational bottleneck of the algorithm. For this application note, the computational bottleneckis the Sobel edgedetection algorithm running at 60 frames persecond on a resolution of 1080p. The authors describe how totake a C description of the algorithm, generate RTL with theHLS tool and integrate the resulting block into a hardware system design. While this application note focuses on the Sobel IPblock, the techniques described apply to all designs in which aVivado toolgenerated IP block is integrated into a Zynq SoC.XAPP896 SMPTE202256 HIGHBITRATE MEDIATRANSPORT OVER IP NETWORKS WITH FORWARDERROR CORRECTION ON KINTEX7 FPGAShttpwww.xilinx.comsupportdocumentationapplicationnotesxapp896k7smpte202256fec.pdfThis application note by Gilbert Magnaye, Josh Poh, MyoTun Aung and Tom Sun covers the design considerations ofa videooverIP network system using the performance features of the LogiCORE IP SMPTE 202256 videooverIPtransmitter and receiver cores. The design focuses on highbitrate native media transport over 10Gbitsecond Ethernetwith a builtin forward error correction engine. The design isable to support up to three SDHD3G SDI streams.The reference design has two platforms transmitter andreceiver. The transmitter platform design uses threeLogiCORE SMPTE SDI cores to receive the incoming SDIvideo streams. The SMPTE 202256 videooverIP transmitter core receives the SDI streams, multiplexes them andencapsulates them into fixedsize datagrams before sending them out through the LogiCORE IP 10Gigabit EthernetMAC. On the receiver platform, the Ethernet datagrams arecollected at the 10Gigabit Ethernet MAC. The DDR traffic passes through the AXI interconnect tothe AXI 7 series memory controller. A MicroBlazeprocessor is included in the design to initialize the coresand read the status. The reference design targets theXilinx Kintex7 FPGA KC705 evaluation kit.XAPP596 4K2K UPCONVERTER REFERENCE DESIGNhttpwww.xilinx.comsupportdocumentationapplicationnotesxapp5964k2kupconverterrefdesign.pdfIn the digital display market, the next innovation waveultrahighdefinition UHD 4K2Kis now emerging. Gettingto market faster than the competition with 4K2K viewingexperiences is the challenge for product developmentdesigners. Xilinx Kintex7 FPGA Display Targeted ReferenceDesigns give designers immediate access to the power efficiency and priceperformance of 28nanometer 7 seriesFPGA devices for efficiently managing increased bandwidthand algorithm complexity. An upconverter is among threeXilinx reference designs that will enable customers to concentrate on product differentiation by providing basic infrastructure for 4K2K digital display signal processing. The HDTVto4K2K upconverter reference designdescribed in this application note by Yasushi Tatehiraenables upconversion from 1080p highdefinition TV to4K2K progressive images. The upconversion results inshowing HDTV content, which is very popular in broadcasting and packaged media, on a 4K x 2K flatpanel display. Thereference design is built from two pieces of LogiCORE IPthe video scaler and the onscreen display OSD. This reference design, which is part of the Kintex7FPGAbased Display Targeted Design Platform, makes itpossible to show HDTV content on a 4K2K monitor or4K2K flat panel, providing design engineers with the basefor their product designs. With this foundation addressing the mandatory upconversion, engineers can focustheir efforts on differentiating their 4K2K digital TVs, displays and projectors.XAPP891 AXI USB 2.0 DEVICEDEMONSTRATING PERFORMANCE FOR BULKAND ISOCHRONOUS TRANSFERShttpwww.xilinx.comsupportdocumentationapplicationnotesxapp8917seriesaxiusb20.pdfThis application note demonstrates the performancemeasurement of the Xilinx USB 2.0 highspeed devicewith AXI for bulk and isochronous transactions. The testsystem generated is based on a Kintex7 FPGA. The performance is measured with two separate host drivers forbulk and isochronous transactions. Authors Ravi KiranBoddu and Dinesh Kumar describe how to develop a58 Xcell Journal      Second Quarter 2013USB system and corresponding ELF files for these bulkand isochronous transactions. The AXI USB 2.0 device enables USB connectivity for adesign using minimal resources. This interface is suitablefor USBcentric, highperformance designs, bridges andlegacy port replacement operations. The USB 2.0 protocolmultiplexes many devices over a single, halfduplex serialbus. Running at 480 Mbitssecond high speed or at 12Mbps full speed, the AXI USB 2.0 device is designed to beplugandplay. The host controls the bus and sends tokens tothe device specifying the required action. The AXI USB 2.0 device supports up to eight endpoints. Endpoint 0 is used to enumerate the device withcontrol transactions. The seven remaining user endpointscan be configured as bulk, interrupt or isochronous. Also,endpoints can be configured as input to the host or output from the host. The user endpoints data buffers areunidirectional and are configured by the configurationandstatus register of the respective endpoint. The size ofthe buffers can be configured from 0 to 512 bytes forbulk, 64 bytes for interrupt and up to 1,024 bytes forisochronous endpoints.XAPP554 XADC LAYOUT GUIDELINEShttpwww.xilinx.comsupportdocumentationapplicationnotesxapp554xadclayoutguidelines.pdfThe Xilinx analogtodigital converter XADC is a precisionmixedsignal measurement system. As with any othermixedsignalanalog circuitry, a suboptimum printedcircuitboard PCB layout can have a big impact on performance.In this application note, author Cathal Murphy details anumber of simple layout guidelines to help a board designerachieve the best possible performance from the XADC.The first step is to stagger the via associated with eachBGA ball to maximize the routing space for differential signals and shields. Then Route the N and P lines together at the minimum PCBspacing where possible, to maximize the benefits of differential sampling that the XADC offers. Place all decoupling and antialiasing capacitors asclose to the FPGA pins as possible. Minimize the impedance on the power supply andground lines. Minimize any common impedance between the RefNline and the GNDADC of the XADC, preferably using astar connection.Following these guidelines will maximize the probability ofachieving excellent XADC results on the first board iteration.XAPP1077 PHYSICAL LAYER HDMI RECEIVER USING GTP TRANSCEIVERShttpwww.xilinx.comsupportdocumentationapplicationnotesxapp1077phyhdmirxgtp.pdfThe HighDefinition Multimedia Interface HDMI IOstandard utilizes 3.3volt terminated transitionminimizeddifferential signaling TMDS. Although TMDS signalingcan be received natively using the Spartan6 FPGASelectIO interface, the GTP transceivers can increaseperformance. The focus of this application note is on techniques to enable systems using the higherbandwidthcapability of GTP receivers.It is possible to use an external passive network toadapt the GTP transceivers to receive a signal that complies with HDMI technology. Authors Paolo Novelliniand Rodney Stewart present, analyze and compare twoalternative passive networks from both a theoreticaland a practical point of view. The authors tested bothnetworks on a custom development board to exploretheir signal integrity limits and to confirm theoreticalexpectations. Although the results are general, the chiptochip use case is the one they primarily consider inthis application note. The target data rate used for HDMIis 1.45 Gbps.XAPP586 USING SPI FLASH WITH 7 SERIES FPGAShttpwww.xilinx.comsupportdocumentationapplicationnotesxapp586spiflash.pdfThis application note by Arthur Yang describes the advantages of selecting a serial peripheral interface SPI flashas the configuration memory storage for the Xilinx 7series FPGAs. The document includes the required connections between the FPGA and the SPI flash memory,and the details necessary to select the proper SPI flash. The SPI flash is a simple, lowpincount solution forconfiguring 7 series FPGAs. Support of indirect programming enhances ease of use by allowing insystem programming updates through reuse of connections alreadyrequired for the configuration solution. Although someother configuration options permit faster configurationtimes or higher density, the SPI flash solution offers agood balance of speed and simplicity.XAPP797 THROUGHPUT PERFORMANCEMEASUREMENThttpwww.xilinx.comsupportdocumentationapplicationnotesxapp797.pdfThis application note discusses the SPI bandwidth measurement for 1 Mbyte of data, writing and reading from theXAMPLES. . .Second Quarter 2013 Xcell Journal 59SPI flash in the Enhanced Quad mode of the AXI Quad SPIIP core. The document is based on using the KC705 boardwith Numonyx SPI memory, which, with a few modifications in the software example files, can be tested on anyother board.Authors Sanjay Kulkarni and Prasad Gutti show howto measure the performance of the system by writingand reading 1 Mbyte of data to and from SPI flash. Thesesystems are built using Xilinx Platform Studio XPS,v14.4, which is part of the ISE Design Suite SystemEdition. The design also includes software, built usingthe Xilinx Software Development Kit, that runs on aMicroBlaze processor subsystem and implements control, status and monitoring functions. The main focus ofthis application note is to measure the SPI bandwidthwhere the core is configured in Quad SPI mode with anSPI clock rate of 40 MHz.XAPP1084 DEVELOPING TAMPERRESISTANTDESIGNS WITH XILINX VIRTEX6 AND 7 SERIES FPGAShttpwww.xilinx.comsupportdocumentationapplicationnotesxapp1084tampresistdsgns.pdfKeeping one step ahead of the adversary, whether military or commercial, is a continuous process that involvesunderstanding the potential vulnerabilities and attacks,and then developing new mitigation techniques or countermeasures to combat them. By taking advantage of various Xilinx FPGA antitamper AT features, a systemsengineer can choose how much AT to include with theFPGA design, enabling individual silicon AT features orcombining a number of them. This application note provides antitamper guidanceand practical examples to help the FPGA designer protect the intellectual property IP and sensitive data thatmight exist in an FPGAenabled system. Tamper resistance needs to be effective before, during and after theFPGA has been configured by a bitstream. Sensitive datacan include the configuration data that sets up the functionality of the FPGA logic, critical data or parametersthat might be included in the bitstream, along with external data that is dynamically brought in and out of theFPGA during postconfiguration normal operation.Author Ed Peterson summarizes the silicon AT features available in the Virtex6 and 7 series devices andoffers guidance on various methods you can employ toprovide additional tamper resistance.XAPP739 AXI MULTIPORTED MEMORY CONTROLLERhttpwww.xilinx.comsupportdocumentationapplicationnotesxapp739aximpmc.pdfDesigners use a multiported memory controller MPMC inapplications where several devices share a common memory controller. This is often a requirement in many video,embedded and communications applications, where datafrom multiple sources moves through a common memorydevice, typically DDR3 SDRAM memory. This applicationnote by Khang Dao and Dylan Buli demonstrates how to create a basic DDR3 MPMC design using the ISE Design SuiteLogic Edition tools, including Project Navigator and COREGenerator. The idea is to create a highperformanceMPMC by combining the Memory Interface Generator MIGIP block and the AXI Interconnect IP block, both provided inthe ISE Design Suite Logic Edition.The AXI interfaces used in this example design consist ofAXI4, AXI4Lite and AXI4Stream, all of which provide a common IP interface protocol framework for building the system. The example design, a full working hardware system onthe Virtex6 FPGA ML605 evaluation platform board, implements a simple video system in which data from a video testpattern generator loops in and out of memory multiple timesbefore being sent to the DVI display on the board. The DDR3memory therefore acts as a multiported memory shared bymultiple video frame buffers.XAPP593 DISPLAYPORT SINK REFERENCE DESIGNhttpwww.xilinx.comsupportdocumentationapplicationnotesxapp593DisplayPortSink.pdfThis application note by Arun Ananthapadmanaban andVamsi Krishna describes the implementation of aDisplayPort sink core and policy maker referencedesign targeted for a MicroBlaze processor in the Spartan6FPGA Consumer Video Kit. The reference design is a loopthrough system that receives video from a DisplayPortsource via the receive link, buffers the video data andretransmits it over the DisplayPort transmit link. The policy maker performs several tasks, such as initialization ofGTP transceiver links, register probing and other featuresuseful for bringup and use of the core. The applicationcontrols both the sink and source of the reference designand communicates with the monitor sink connected onthe transmit port of the reference design using the auxiliary channel. The reference design uses DisplayPortsource and sink cores generated from the Xilinx COREGenerator tool, along with a policy maker and framebuffer logic using external memory. T he Xilinx Alliance Program is a worldwideecosystem of qualifiedcompanies that collaborate withXilinx to further the development of All Programmable technologies. Xilinx has built thisecosystem, leveraging openplatforms and standards, tomeet customer needs and iscommitted to its longterm success. Alliance membersincluding IP providers, EDA vendors,embedded software providers,system integrators and hardware suppliershelp accelerateyour design productivity whileminimizing risk. Here are reportsfrom five of these members.CUSTOM VISIONALGORITHMS FROMMATHWORKSMathWorks Natick, Mass., providerof the MATLAB and Simulinktools, offers several addons integralfor use with Xilinx hardware forembedded vision. The companysComputer Vision System Toolboxprovides algorithms and tools for thedesign and simulation of computervision and videoprocessing systems.HDL Coder generates portable, synthesizable Verilog and VHDL codefrom MATLAB functions, Simulinkmodels and Stateflow charts. HDLVerifier automates the verification ofHDL code on Xilinx FPGA boards byenabling FPGAintheloop FIL testing. In addition, MathWorks recentlyreleased a hardware support packagefor working with the Xilinx Zynq7000 All Programmable SoC.Smarter vision applications areconstantly evolving, adding new features like analytics, recognition andtracking, said Ken Karnofsky, seniorstrategist at MathWorks These features require improved system performance and greater design flexibilityfor hardware and software implementation. Over the last few years,MathWorks and Xilinx have enabledcustom visiona l g o r i t h m sdeveloped withMATLAB andSimulink to beeasily integrated with available IP andimplementedon Xilinx hardware, includingthe Zynq7000 SoC for hardwaresoftware coprocessing. This workflowaccelerates development by bridgingthe divide between algorithm exploration and system implementation.Please visit www.mathworks.comzynq for more information.NI LABVIEW SIMPLIFIESFPGA PROGRAMMING National Instruments LabVIEWchanges the rules of FPGA programming, delivering new technologiesthat convert graphical block diagramsinto digital hardware circuitry, simplifying development and shortening timetomarket for advanced control, monitoring and test applications. The Austin, Texas, company offersframe grabbers with a userprogrammableFPGA in the image path as well as embedded systems, such as CompactRIO, thathave imageprocessing capabilities combined with FPGAenabled IO.CompactRIO combines an embedded controller for communication and processing,plugin IO modules and a reconfigurable chassishousing the userprogrammableFPGA. Systemdesigners use theLabVIEW graphical developmentplatform for programming floatingpoint processors and FPGAs for imageprocessing, digital and analog IO, communication and more within a singledevelopment environment. Xilinx All Programmable FPGA technology is at the center of the NI LabVIEWRIO architecture, said Jamie Smith,director of embedded systems marketingat NI. LabVIEW lets engineers who arefamiliar with FPGAs take advantage oftheir inherent benefits of performance,versatility and determinism.Learn more about NIs approachto FPGAbased design athttpwww.ni.comfpga.60 Xcell Journal      Second Quarter 2013Latest and Greatest from theXilinx Alliance Program PartnersXpedite highlights the latest technology updates from the Xilinx Alliance partner ecosystem.XPEDITEKen KarnofskyMathWorksJamie Smith National InstrumentsZYNQ SoCBASED VIDEOENGINE FROM OMNITEK The OSVP IP block from IP vendorOmniTek Basingstoke, U.K. provides complete multivideo formatconversion and compositing. Allinterfaces conform to ARMsAXI4 protocol. The IP supports upto eight channels of simultaneouschroma upsample, colorspaceconversion, deinterlacing andresizing, with overlay graphicscapability. The OZ745 is a video development platform based around theXilinx Zynq7045 SoC. The kitincludes all the basic componentsof hardware, design tools, IP, preverified reference designs and aboard support package to rapidlydevelop video and imageprocessing designs.O m n i T e kalso suppliessoftware andfirmware IPcores alongwith designservices tofurther accelerate timetomarket. At OmniTek, we are extremelyproud of our design teams skills inimageprocessing algorithm designfor optimum FPGA and CPU partitioning, said managing directorRoger Fawcett. The latest ZynqSoC devices provide a singlechipsolution for such designs. We haveexploited this efficient architecture in the Real Time Video Engine2.1, which combines highly optimized Xilinx and OmniTek FPGAand software IP.Please visit httpwww.omnitek.tvsitesdefaulfilesOSVP.pdf andhttpwww.omnitek.tvsitesdefaultfilesOZ745.pdf for moreinformation.NEWS FROM THE EMBEDDEDVISION ALLIANCE The Embedded Vision AllianceWalnut Creek, Calif. is an industrypartnership formed to inspire andempower design engineers to createmore capable and responsive products through integration of visioncapabilities. According to the alliances founder,Jeff Bier, computer vision has longbeen a niche technology, becausecomputer vision equipment has beenbig, expensive and complex to use.Recently, however, products like theMicrosoft Kinect and visionbasedautomotive safety systems havedemonstrated that computer visioncan now be deployed even in costsensitive applications, and in waysthat are easy for nonspecialists to use. We use the term embedded visionto refer to the incorporation of visualintelligence into a wide range of systems, creating machines that see andunderstand, said Bier. One of thekey factors enabling the current transition from the niche technology ofcomputer vision to pervasive embedded vision is more capable and efficient processors. Xilinx hasbeen a leaderin this realm,d e v e l o p i n gnew devices,like the Zynq7000 SoC family, that deliveran enormousamount of programmable processing power in avery modest price, power and sizeenvelope.The Embedded Vision All ianceprovides training videos,  tutori al  articles,  code examples andan array of other resources allfree of  charge on its website,www.EmbeddedVision.com.VIDEO AND GRAPHICS IP FROM XYLON The power of the logicBRICKSvideo IP cores from Xylon Zagreb,Croatia are best demonstrated bythe logiADAK Automotive DriverAssistance kit. Built around theXilinx Zynq7000 All ProgrammableSoC, this kit makes it easy to combine hardwareaccelerated videoprocessing features implemented inprogrammable logic with highlevel,complex control algorithms running on the ARM processor systemin a single chip.G r a p h i c scores for fullrange implementations of2D and 3Dgraphics processing unitsGPUs seamlessly blendwith the videoIP cores andcan be immediately used with different operating systems e.g., Linux,Microsoft Windows EmbeddedCompact 7 and Android. More than 15 years ago, whenwe started developing our logicBRICKS IP cores for video processing with Xilinx FPGAs, no one couldimagine todays smart vision applications running on a single XilinxAll Programmable device, saidDavor Kocacec, CEO of Xylon. Oureasytouse IP cores, software anddesign services enable our customers to quickly build large portions of their next Xilinxbased SoCand fully concentrate on key differentiating features.More information about Xylonproducts and solutions for embedded vision, as well as a number ofpreverified reference designs fordownload, can be found atwww.logicbricks.com.Second Quarter 2013 Xcell Journal 61Roger FawcettOmniTekDavor KocacecXylonJeff Bier Embedded VisionAllianceVIVADO IP INTEGRATORACCELERATED TIME TOIP CREATION AND INTEGRATIONTo accelerate the creation of highlyintegrated, complex designs in AllProgrammable FPGA devices, Xilinxhas delivered the earlyaccessrelease of the Vivado IP IntegratorIPI. Vivado IPI accelerates the integration of RTL, Xilinx IP, thirdpartyIP and CC synthesized IP. Basedon industry standards such as theARM AXI interconnect and IPXACT metadata for IP packaging,Vivado IPI delivers intelligent correctbyconstruction assembly ofdesigns cooptimized with Xilinx AllProgrammable solutions. Built on the foundation of theVivado Design Suite, IP Integrator is adevice and platformaware interactive,graphical and scriptable environmentthat supports IPaware automated AXIinterconnect, oneclick IP subsystemgeneration, realtime DRC, interfacechange propagation and a powerfuldebug capability. When targeting aZynq7000 All Programmable SoC,embedded design teams can now morerapidly identify, reuse and integrateboth software and hardware IP targeted for the dualcore ARM processingsystem and highperformance FPGAfabric. To obtain an earlyaccesslicense, please contact your local salesrepresentative. To see a video of the IP Integratorcreating an IP subsystem, please visithttpwww.xilinx.comtrainingvivadocreatingipsubsystemswithvivadoipintegrator.htm.VIVADO HIGHLEVEL SYNTHESIS LIBRARYENHANCEMENTSTo accelerate CC systemleveldesign and highlevel synthesisHLS, Xilinx has enhanced its VivadoHLS libraries with support for industrystandard floatingpoint math.hoperations and realtime videoprocessing functions. More than 350active users and upwards of 1,000customers evaluating Vivado HLSwill now have immediate access tovideoprocessing functions integrated into an OpenCV environment forembedded vision running on thedualcore ARM processing system.The resulting solution enables up to a100x improvement in the performance of existing CC algorithmsthrough hardware acceleration. Atthe same time, Vivado HLS accelerates system verification and implementation times by up to 100x compared with RTL design entry flows. When targeting a Zynq7000 AllProgrammable SoC, design teams cannow more rapidly develop CC codefor the dualcore ARM processing system, while computeintensive functions are automatically accelerated inthe highperformance FPGA fabric.       VIVADO DESIGN SUITEDEVICE SUPPORT Vivado now supports Zynq7000 AllProgrammable SoC devices, includingthe 7Z030 and 7Z045 supportrequires early access to the IPIntegrator. The Vivado Design Suitesupports all 7 series devices and the2013.1 release includes these updates  Productionready Virtex77VX690T, 7VX1140T, 7VX330T,7VX415T and 7VX980T Defensegrade Kintex7Q7K325T and 7K410T andVirtex7Q 7V585T and 7VX485T General ES ready Virtex77VH580T and 7VH870TThe Vivado Design Suite, WebPACK Edition is a free downloadthat provides support for Artix7100T and 200T and Kintex7 70Tand 160T devices, and for Zynq7000All Programmable SoC earlyaccessZ010, Z020 and Z030 devices. 62 Xcell Journal      Second Quarter 2013Whats New in theVivado 2013.1 Release  The Vivado Design Suite provides a highly integrated design environment with a completely new generation of systemtoIClevel features, including highlevel synthesis, analytical placeandroute and an advanced timing engine. These toolsenable developers to increase design integration and implementation productivity.XTRA, XTRAwww.trenzelectronic.dedifference by designPlatform Features 45 cm compatible footprint up to 8 Gbit DDR3 SDRAM 256 Mbit SPI Flash Gigabit Ethernet USB optionAll ProgrammableFPGA and SoC modules4form x factor5Available SoMsDesign Services Module customization Carrier board customization Custom project developmentrugged for harsh environmentsextended device life cycleQ WHAT ARE THE DIFFERENT EDITIONS OF THE VIVADODESIGN SUITEA The Vivado Design Suite is now available in three editions Design,System and WebPACKthe nocost, devicelimited version of theVivado Design Suite Design Edition. Inwarranty Vivado Design Suite customers will receive the ISE Design Suiteat no additional cost.The Vivado and ISE Design Suites are now separate downloads andinstallers. The Vivado Design Edition includes the ISE Embedded Edition theVivado System Edition includes the ISE System Edition, which also includesVivado HighLevel Synthesis and System Generator for DSP. For license generation, please visit www.xilinx.comgetlicense.Q SHOULD I CONTINUE TO USE THE ISE DESIGN SUITE OR MOVE TO VIVADOA ISE Design Suite is an industryproven solution for all generations ofXilinxs All Programmable devices. The Xilinx ISE Design Suite continues to bring innovations to a broad base of developers, and extends the familiardesign flow for 7 series and Xilinx Zynq7000 All Programmable SoC projects.ISE 14.5, which brings new innovations and contains updated device support, isavailable for immediate download. The Vivado Design Suite 2013.1, Xilinxs nextgeneration design environment,supports 7 series devices and Zynq All Programmable SoC earlyaccess devices.It offers enhanced tool performance, especially on large or congested designs.Xilinx recommends that customers starting a new design contact theirlocal FAE to determine if Vivado is right for the design. Xilinx does not recommend transitioning during the middle of a current ISE Design Suite project, asdesign constraints and scripts are not compatible between the environments. For more information, please read the Vivado 2013.1 and ISE 14.5release notes.Q IS VIVADO DESIGN SUITE TRAINING AVAILABLEA Vivado takes full advantage of industry standards such as powerful interactive Tcl scripting, Synopsys Design Constraints, SystemVerilog andmore. To reduce your learning curve, Xilinx has rolled out new instructorledclasses that will show you how to use the Vivado tools. To learn more aboutinstructorled courses, please visit www.xilinx.comtraining.Q IS THERE A WAY TO EXPLORE THE FEATURES OF THE VIVADO DESIGN SUITE ONLINEA Vivado Quick Take Tutorials provide a fast review of specific featuresof the new design environment. Topics include flow overview, systemlevel design, synthesis, design analysis, IO planning and highlevel synthesis.New topics are added regularly. Visit www.xilinx.comtrainingvivadoSecond Quarter 2013 Xcell Journal 6364 Xcell Journal      Second Quarter 2013Xpress Yourself in Our Caption ContestH eavens to Murgatroyd If youre looking to Xercise your funnybone, heres your opportunity. We advise readers to duck forcover before taking on our verbal challenge and submittingan engineering or technologyrelated caption for this cartoon showing anasteroid about to crash into an engineering lab. The image might inspire acaption like 3D printing experiment run amok. Send your entries to xcellxilinx.com. Include your name, job title, companyaffiliation and location, and indicate that you have read the contest rules atwww.xilinx.comxcellcontest. After due deliberation, we will print the submissions we like the best in the next issue of Xcell Journal. The winner willreceive an Avnet Zedboard, featuring the Zynq7000 All Programmable SoChttpwww.zedboard.org. Two runnersup will gain notoriety, fame and acool, Xilinxbranded gift from our swag closet.  The contest begins at 1201 a.m. Pacific Time on April 15, 2013. All entriesmust be received by the sponsor by 5 p.m. PT on July 1, 2013.So, get writingWARREN TUSTIN, a design engineer at Agilent TechnologiesColorado Springs, Colo., won ashiny new Avnet Zedboard withthis caption for the Tarzan cartoonin Issue 82 of Xcell Journal   Congratulations as well to our two runnersupTarzan switches careers from ape man to code monkey. Joseph Trebbien, software engineerYou know things are slow in theValley when the headhunters startmaking house calls. David Pariseau, Technology Plus, Inc.Los Altos, Calif. It always was a bit noisy in the lab at the start of swing shift.DANIELGUIDERAXCLAMATIONSNO PURCHASE NECESSARY. You must be 18 or older and a resident of the fifty United States, the District of Columbia, or Canada excluding Quebec to enter. Entries must be entirely original. Contest begins onApril 15, 2013.  Entries must be received by 500 pm Pacific Time PT on July 1, 2013. Official rules available online at www.xilinx.comxcellcontest. Sponsored by Xilinx, Inc. 2100 Logic Drive, San Jose, CA 95124.belowMOLOKAIModel 1006CN64.5L x 12.75W x 15DPN 2539
