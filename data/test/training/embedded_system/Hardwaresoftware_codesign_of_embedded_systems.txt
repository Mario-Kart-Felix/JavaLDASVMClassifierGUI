HardwareSoftware CoDesign of Embedded Systems WAYNE H. WOLF, SENIOR MEMBER, IEEE Invited Paper This paper surveys the design of embedded computer systems, which use software running on programmable computers to im plement system functions. Creating an embedded computer system which meets its performance, cost, and design time goals is a hardwaresoftware codesign p r o b l e w h e  design of the hard ware and software components influence each other. This paper emphasizes a historical approach to show the relationships be tween wellunderstood design problems and the asyet unsolved problems in codesign. We describe the relationship between hard ware and sofhvare architecture in the early stages of embedded system design. We describe analysis techniques for hardware and software relevant to the architectural choices required for hard waresoftware codesign. We also describe design and synthesis techniques for codesign and related problems. I. INTRODUCTION This paper surveys the state of the art in the design of embedded computer systems products which are im plemented using programmable instructionset processors. While embedded systems range from microwave ovens to aircraftcontrol systems, there are design techniques common to these disparate applications. Furthermore, em bedded system design often requires techniques somewhat different than those used for either the design of general purpose computers or application software running on those machines. Embedded computing is unique because it is a hardwaresoftware codesign problemthe hardware and software must be designed together to make sure that the implementation not only functions properly but also meets performance, cost, and reliability goals. While a great deal of research has addressed design methods for software and for hardware, not as much is known about the joint design of hardware and software. Microprocessors, and in particular highperformance 32bit microprocessors cheap enough to use in consumer prod ucts, have stimulated research in codesign for embedded systems. So long as embedded processors were small and executed only a few hundred bytes of code, handcrafted Manuscript received December 29, 1993 revised April 4, 1994. The author is with the Department of Electrical Engineering, Princeton IEEE Log Number 9402008. University, Princeton, NJ 08544 USA. techniques were sufficient to satisfy functional and perfor mance goals in a reasonable amount of time. However, modem embedded systems may include megabytes of code and run at high speeds to meet tight performance deadlines. In such large projects, building a machine and seeing whether it works is no longer satisfactory. To be able to continue to make use of the everhigher performance CPUs made possible by Moores Law which predicts that the number of transistors per chip doubles every year, we must develop new design methodologies and algorithms which allow designers to predict implementation costs, incrementally refine a design over multiple levels of abstraction, and create a working first implementation. We will use the embedded system design process as a framework for the study of codesign. The goal of this paper is to identify technologies which are important to codesign and to provide examples which illustrate their role in codesign. We must, due to space limitations, ignore certain topics, such as the design of faulttolerant systems and verification. Our description of the literature on covered topics is also meant to be illustrative, not encyclopedic. In spite of these limitations, we hope that the juxtaposition of topics presented here will help to illustrate both what is known about codesign and what remains to be done. The next section surveys the uses of embedded comput ers and the embedded system design process. Section 111 describes performance analysis of hardware and software elements. Section IV surveys techniques for the design of hardwaresoftware systems. 11. EMBEDDED SYSTEMS AND SYSTEM DESIGN A. Characteristics of Embedded Systems The earliest embedded systems were banking and trans action processing systems running on mainframes and ar rays of disks. The design of such a system entails hard waresoftware codesign given the expected number and type of transactions to be made in a day, a hardware configuration must be chosen that will support the expected traffic and a software design must be created to efficiently PROCEEDINGS OF THE IEEE. VOL. 82 ,  NO. 7. JULY 1994 001892199404.00 0 1994 IEEE 961 make use of that hardware. Because early transaction pro cessing systems were built from very expensive equipment, they were used for relatively few but important applica tions. However, the advent of microprocessors has made the average embedded system very inexpensive, pushing microprocessorbased embedded systems into many new application areas. When computers were used for only a few types of applications, design techniques could be developed specific to those applications. Cusumano  161 documented the laborintensive techniques used by Japan ese computer system manufacturers to build mainframe and minicomputerbased systems for industrial automation, banking, and other capitalintensive applications. When the hardware is expensive, it is easier to justify large personnel budgets to design, maintain, and upgrade embedded soft ware. When microprocessors are used to create specialized, lowcost products, engineering costs must be reduced to a level commensurate with the cost of the underlying hardware. Now that microprocessors are used in so many different areas, we need a science of embedded system design which can be applied to previously unforeseen application areas. Because microprocessors can be used in such a wide range of products, embedded systems may need to meet widely divergent criteria. Examples of embedded systems include simple appliances, such as microwave ovens, where the microprocessor provides a friendly interface and advanced features an appliance for a computationally intensive task, such as laser printing a handheld device, such as a cellular phone, for which power consumption and size are critical but digital signal processing and other sophisticated tasks must be performed an industrial controller in a factory, for which reliabil ity, maintainability, and ease of programmability are often concems a safetycritical controller, such as an antilock brake controller in a car or an autopilot. Most readers would agree that each of these examples is an embedded computing system, but a comprehensive definition of embedded computing has not yet achieved wide acceptance. There are clearly examples which may or may not fit varying definitions of a system. For exam ple, many industrial and scientific control applications are implemented on PCs. Since these applications are dedi cated, many though not all would consider such systems embedded. But is a PC used solely to run a spreadsheet in an embedded computing system Is a personal digital assistant PDA which uses the same microprocessor and runs the same spreadsheet software an embedded computer It is difficult to come up with a simple definition which meets everyones intuitive notion of embedded computing. Different applications place primary importance on dif ferent factors design time, manufacturing cost, modifia bility, reliability, etc. What embedded systems share is a belief by the designers that implementing some of the systems functions on microprocessors will make one or more of those goals easier to achieve. One lurking prob lem with any kind of software design that also holds for embedded systems is the desire, well documented by Brooks 7, to add features at the expense of schedule and design elegance. In addition, embedded systems have added problems due to their design constraints. Designing code to meet a performance deadline or squeezing code into the given amount of ROM can be very difficult without a wellunderstood design methodology to help guide decisions. The design of embedded systems is not as well understood as the design of integrated circuits, which have several methodologies for different costperformance tradeoffsseaofgates, standard cell, fullcustomand de sign tools for the phases of design in each methodology. While embedded system designers can make use of ex isting tools for the hardware and software components once the design has been partitioned, much remains to be learned about how a system is partitioned into hardware and software components. Methodologies and tools for hardwaresoftware codesign are critical research topics for embedded system design. Hardwaresoftware codesign of embedded systems must be performed at several different levels of abstraction, but the highest levels of abstraction in codesign are more abstract than the typical software coder or ASIC designer may be used to. Critical architectural decisions are made using abstract hardware and software elements CPUs and memories in hardware, processes in software. As a result, the initial hardware and software design problems are high level the first hardware design decision is to build a network of CPUs, memories, and peripheral devices the first software design problem is to divide the necessary functions into communicating processes. At first blush, a hardware designer in particular may not consider CPU selection to be true hardware design. For example, the major hardware architectural decision may be to choose between a 386based or 486based PC. However, that task is not so different from the design choices faced by VLSI designers. A chip designer does not design the threshold voltage, transconductance, and other transistor parameters to suit a particular applicationrather, digital logic design requires choosing a circuit topology and computing transis tor WILs. The typical ASIC designer will not deal with transistors at all, but will choose logic gates from a library and wire them together to implement the desired function. Whether the components to be selected and interconnected are logic gates or CPUs, the designer faces the same problem characterizing the components understanding the operation of networks of components and choosing a network topology based on the requirements. Embedded system design can be divided into four major tasks partitioning the function to be implemented into smaller, interacting pieces allocating those partitions to microprocessors or other hardware units, where the function may be imple 968 PROCEEDINGS OF THE IEEE, VOL. 82. NO. 7, JULY 1994 mented directly in hardware or in software running on a microprocessor scheduling the times at which functions are executed, which is important when several functional partitions share one hardware unit mapping a generic functional description into an im plementation on a particular set of components, either as software suitable for a given microprocessor or logic which can be implemented from the given hardware libraries. This taxonomy is similar to that given by McFarland et al. for highlevel synthesis 73 with the exception of adding partitioning as a firstclass design problem. The design goals in each task depend on the application performance, manufacturing cost, testability, etc. The solutions to these problems clearly interact the available choices for sched uling are controlled by how the design was partitioned, and so on. To make matters worse, not only can each of these steps be applied to the software and hardware components separately, but also to the division into hardware and soft ware components itself, and the design decisions made for the hardware and software components separately interact with the codesign problem. We will frame our discussion of codesign techniques by reference to the partitioning, allocation, scheduling, and mapping steps. Mapping is the least understood part of codesign while it is often possible to estimate the overall amount of computation required to complete a task, it is much more difficult to determine whether a particular hardware structure and software organization will perform the task on time. Several disciplines help form the basis of embedded system design. Software engineering and VLSI computer aided design CAD provide implementation techniques for the software and hardware components of the system, and those techniques may be useful during codesign as well. Because many embedded systems are implemented as networks of communicating microprocessors, distributed system design is an important foundation for codesign. Realtime system design is another critical foundation since many embedded systems include performance constraints as part of their requirements. Realtime systems are usually divided into hard realtime, for which failure to complete a computation by a given deadline causes catastrophic system failure, and soft realtime, where performance is important but missing a deadline does not cause the system to fail. A clear example of a hard realtime system is an autopilot, where failure to compute a control command from a given control input in a certain interval causes the airplane to go out of control. A laser printer is an example of a machine with soft performance constraints while the user bought the system based in part on its pages perminute rating, the rate at which the printer actually typesets pages can vary without causing the machine or the customer physical harm. The control of the print en gine within the laser printer is, however, a hard realtime taskdata must be delivered to the print drum at specified times and rates or the printed image will be destroyed. Many embedded systems have at least a few hard real time constraints, derived from deadlines imposed by the operation of peripherals. B .  Embedded Processors and Software Architectures Any central processing unit CPU may be used in an embedded computer system. A CPU whose design is op timized for embedded applications is called an embedded processor. Embedded processors may be compatible with workstation CPUs or may have been designed primarily for embedded applications. Many embedded processors do not include memory management units the structure of the application software makes a memory management unit less useful and the chip area occupied by that logic can be put to better uses. An embedded processor optimized for digital signal processing is called a digital signal processor DSP. An embedded controller or microcontroller devotes onchip area to peripherals commonly used in embedded systems. Embedded controllers add peripheral devices such as timers, analogtodigital converters, or universal syn chronousasynchronous receiver transmitters USARTs to the core CPU. Timers are used to count events, to measure extemal time, and to measure the length of time slices for process scheduling. A serial port like a USART may be used to control some simple devices, may be used for debugging, or may be used to communicate with other microcontrollers. Most 4 and 8bit microcontrollers include onboard randomaccess memory RAM and some sort of readonly memory ROM, but 16 and 32bit embedded controllers may not include onchip ROM. The amount of memory available on a microcontroller is usually small 256 bytes of RAM and 1024 bytes of ROM is a common configuration for an 8bit machine. Some applications have been forced to move to 16bit embedded controllers not because of data size, but rather because the application code could not fit into an 8bit controllers address space. Some microprocessor manufacturers provide embedded controller design and manufacturing a customer may de sign a chip using a microprocessor core, standard pe ripherals, and standard cell logic the controller is then manufactured in quantity for the customer. Customers in this market niche must have a large enough demand for the custom controller to justify the design and added manufacturing costs. An alternative approach to the design of customerspecific microcontrollers has been proposed by a number of people, though we do not know that such a chip has yet been manufactured a microcontroller with an onboard RAMbased fieldprogrammable gate array FPGA would allow the customer to add custom peripherals by downloading a personality to the FPGA. An applicationspecific processor ASIP is a CPU optimized for a particular application. A DSP is an example of an ASIP, though ASIP is generally used to refer to processors targeted to application niches much narrower than the audiorate signal processing market. Paulin pointed out that some telecommunications applications require parts in hundreds of thousands to millions, making the gain in performance and reduction in cost provided by an ASIP WOLF HARDWARESOFTWARE CODESIGN OF EMBEDDED SYSTEMS 969 serial bus I I I analog Fig. 1. signal processing and user interface. An embedded system with distributed computing for worth the added design effort 74. Most ASIPs available today were designed by CPU manufacturers for niche markets the laser printer market has attracted several pro cessors, such as the AMD 29000 the Motorola MC68302 is optimized for execution of telecommunication protocol code, such as ISDN. A CPU manufacturer may optimize a design in several ways the memory bus is often tuned for laser printer applications peripherals may be added to support special tasks or, as in the case of FFTrelated instructions for DSPs, applicationspecific instructions may be added. There is growing interest in design tools for ASIPs which can select an instruction set appropriate to the application. Many embedded systems are implemented as distributed systems, with code running in multiple processes on several processors, with interprocessor communication IPC links between the CPUs. For example most marine and general aviation navigation devices communicate via RS232 serial lines modem automobiles contain many microprocessors physically distributed throughout the car which communicate with each other to coordinate their work cellular telephones today generally include at least one generalpurpose microcontroller and an embedded DSP, and some telephones are built from a halfdozen embedded processors. Figure 1 illustrates a hypothetical distributed system which is used to implement a machine which must perform both signal processing and user interaction. A DSP is used to implement the signal processing functions, while an 8bit microcontroller handles the user interface. Each microprocessor has onboard peripheral interfaces, an analogtodigital converter on the DSP, and a parallel port on the microcontroller, which are used in this application. Since each microprocessor has onboard memory and only lowspeed communication is required between the signal processing and interface tasks, a serial interface is used to connect the two CPUs. A distributed system may be the best implementation of an embedded computer for any of several reasons Timecritical tasks may be placed on different CPUs to ensure that all their hard deadlines are met. In the . above example, sampling the keyboard might interfere with the DSP process if both were on the same CPU. Using several small CPUs may be cheaper than using one large CPU. In many cases, several 8bit controllers can be purchased for the price of one 32bit pro cessor. Even after board realestate costs are added in, distributing a task over several small CPUs may be cheaper than combining all the tasks onto one processor. Many embedded computing systems require a large number of devices. Using several microcontrollers with onboard devices may be the cheapest way to implement all the device interfaces. If the system includes a subsystem purchased from a supplier, that subsystem may include its own CPU. The subsystems CPU will impose a communications interface, but it is usually not possible to move other system tasks onto the subsystems processor. Rosebrugh and Kwang described the design of a penbased computer which was implemented as a distributed system 8 13. Their device had to mix timesensitive inputoutput operations, such as tracing the pen on the screen, with computerbound tasks such as updating its intemal data base. Their design used four microprocessors a Motorola MC6833 1, a 68000family processor, as the core processor a Motorola MC68HC05C4, an 8bit microcontroller, for power management a Hitachi 63484 for graphics and an Intel 80C5 1, another 8bit microcontroller, for the pen digitizer. The processors were connected heterogeneously both the MC68331 and 63484 were connected to main memory, but the 63484 graphics processor was the only device connected to the display memory the 80C51 was connected to the digitizer and to the 68HC05, while the 68HC05 talked to the MC68331. A variety of interconnect schemes are used in distributed embedded systems. The processor bus may be used for simple systemsall processors not only share common memory, they also contend for the bus to access mem ory and devices. COprocessors like floatingpoint units often have their own dedicated link to the CPU. Many embedded controllers use serial links, either RS232 or specialpurpose links, between their CPUs. The 12C bus 89 is a serial communications system popular in 8bit distributed controllers it requires two wires, provides mul tiple bus masters, and can run at up to 400 kbs. SAEJ1850 is an emerging standard for automotive communication networks. The Echelon Neuron architecture also uses a mediumperformance serial link between the processors. Bandwidth limitations on the commonly used interproces sor communication systems make process allocation very important to ensure that deadlines are met in the face of IPC delays. Embedded software can usually be thought of as a system of communicating processes, though the underlying code may not have clearly defined processes. A process is an instance of a sequential machine, which we will use to refer to either a hardware or a software implementation. Task is a synonym for process we will use the two 970 PROCEEDINGS OF THE IEEE, VOL. 82, NO. 7, JULY 1994 terms interchangeably, usually choosing the word used by the author whose work we describe. The term thread or lightweight process is used by some authors a thread is usually used to describe a process which shares its memory space with other threads, rather than assuming that each process has its own address space. As will be described in more detail in Section 111D, software processes can be implemented in several different ways using preemptive scheduling, as in timesharing systems through nonpreemptive scheduling, in which a process voluntarily passes control to the next process as a cyclostatic machine, which periodically executes a fixed sequence of operations and as an interruptdriven system. The software architecture appropriate for a task depends in part on the match between the CPU chosen, particularly the speed at which the CPU can switch between processes, and the performance requirements of the application. C .  The Engine Metaphor If an embedded system is thought of as a jumble of microprocessors and code, it can be difficult to discern the structure which leads to a successful architecture. The engine metaphor helps us understand the roles hardware and software play in the implementation of an embedded computer system. While the designs of the hardware and software components clearly interact with each other, es tablishing the roles that hardware and software play in the system is critical to developing a methodology which manages the design process and categorizes the design interactions to guide the designer toward a satisfactory solution. Our model of an embedded computer systems is a hard ware engine which runs application software, as shown in Fig. 2. The engine includes the one or more CPUs and memory as well as peripherals. The engine provides the raw computing power for the system both instruction execution and peripheral operations. Most of the features of the system, however, are not directly implemented in the hardware but are instead designed into the application software. Viewing the hardware as the engine which pro vides the power for the application softwares features helps us decide whether to solve a particular design problem by attacking the software or hardware. Hardware engine design for embedded systems is remi niscent of engine selection for vehicles such as automobiles or airplanes. The engine is selected very early in the design of a motor vehicle 98. While the mission requirements gross weight, maximum speed determine a horsepower range for the engine, the particular engine to be used is selected from a small set of available engines which meet the requirements. Once the engine has been selected, its par ticular characteristicsexact horsepower, torque, weight, shape, cooling requirements, etc.onstrain the design of the vehicle. Similarly, the CPU for a hardware engine must be selected from among the available processors. The characteristics of that processorexecution speed of various instructions, bus throughput, etc.help determine the design of the software which runs on the engine. software functions m Constraints Fig. 2. A hardware engine. The design of the software architecturethe division of the function into communicating processesis closely re lated to engine design. Two systems with identical functions but different process structures may run at very different speeds, require vastly different amounts of memory, etc. For example, in one case, dividing one process into two may increase the amount of concurrency exposed in the system and reduce the execution time required in another case, dividing a task into too many processes may introduce too many context switches and reduce performance. You cannot choose a hardware engine without also choosing a software architecture, since the softwares process structure help determine size and speed. Similarly, a vehicles body and aerodynamics are closely related to the choice of engine a narrow airplane cannot accommodate a wide engine the classic Bugatti limousines have long, elegant shapes in large part to accommodate the straight 16 cylinder en gines undemeath their hoods. Embedded computer system design is hardwaresoftware codesign precisely because system architecture design must simultaneously consider the hardware engine and the software process structure. Performance constraints, both general throughput require ments such as average page printing rate for a laser printer and hard realtime deadlines, determine the minimumsize hardware engine needed for the application. The designers job is to choose an engine which is large enough to meet the applications performance demands, which is no more costly than necessary why pay for more horsepower than you need, and also satisfies the other nonfunctional requirements like physical size, power consumption, etc. Performance constraints for an embedded system play the role of mission requirements in vehicle design. In the absence of performance constraints, any hardware engine will do. It is performance constraints, particularly hard real time deadlines, which determine the basic requirements of the hardware engine. However, unlike in vehicle design, we do not at present have simple rulesofthumb to relate embedded computer mission requirements, analogous to maximum gross weight in vehicle design, to a simple measure of processor perfor mance like an internal combustion engines horsepower. WOLF HARDWARESOFTWARE CODESIGN OF EMBEDDED SYSTEMS 97 1 Benchmarks such as the SPEC benchmark set provide some means to measure processing power, but it is often difficult to extrapolate from benchmark performance to the execution time for the application at hand. If we had such performance prediction rules, they would almost certainly be domainspecific, just as the backoftheenvelope calcu lations for automobile and aircraft design are very different. It is likely that todays large number of choices in CPUs for embedded applications is a historical anomaly. In the future, it is likely that one or two CPUs will be available for each performancefeature regime, much as vehicle designers today have a limited selection of engines available to them. Today, VLSI technology is advancing and embedded computing markets are growing, so semiconductor manufacturers are still incented to invest the large sums required to design new CPUsit is still possible to gain production volume by growing with the market. When VLSI technology and its semiconductor markets mature, manufacturers will probably find CPU design to be too expensive to be justified simply to take market share away from another manufacturer. The diffi culty of developing efficient compilers and their associated development environments for new processors adds an other barrier to entry for new CPUs. There will always be opportunities for customized CPUs, either offered by manufacturers for particular market segments or designed for a particular application by a customer. As with intemal combustion engines, however, simple design changes can be made cheaply but some kinds of engine redesigns require large investments in engineering. In that steadystate condition, distributed system design will probably become even more important, as system designers try to compose an engine which meets their requirements from a collection of interconnected CPUs. The most general way to estimate the required size of an embedded hardware engine by performing an initial synthesis of both the hardware and software subsystems. By choosing one or more processor types and dividing up the software tasks among n such processors, we can determine whether the given architecture can meet its deadlines and indicate where an applicationspecific coprocessor will be required. As we will see later in this paper, many techniques have been developed for mapping a functional specification onto a given hardware engine with constraints, but less is known about the design of the hardware engine itself. Even less is known about the joint optimization of the application software and the hardware engine. D. Design Flow The design process of an embedded system must vary considerably with the application the design of a pager is very different from the design of an autopilot. However, we can identify common steps. Furthermore, a study of a typical design flow shows that the hardware and soft ware components of an embedded system have common abstractions, a fact which we can use to our advantage in hardwaresoftware codesign. specification I parae system architecture comPution behavior communicating processes processes 1 1 1 1 I strmtum registertransfer structura modules description Wed highlevel b g b j  language logic object code physical  integration  1 system testing Fig. 3. A topdown design process for an embedded system. Figure 3 shows a typical sequence of steps in a top down design of an embedded system of course, most actual design processes will mix topdown and bottomup design. For comparison, Smailagic and Siewiorek describe a concurrent design methodology used to design VuMan 2, a portable smart display device 90. Design of the hardware and software components must proceed fairly separately at some point, just as two hardware components must be designed separately once the system has been broken down into a system of components. However, as the figure shows, the hardware and software tracks refine the design through similar levels of abstraction. Processes are used to represent both the hardware and software elements of the initial partition a system of hardware components in a block diagram is equivalent to a system of communicating processes and the interprocess communication links in a software specification correspond to signals in a block diagram. The fact that both hardware and software are specified as processes gives us hope that we can use a common modeling technique to simultaneously design both the hardware engine and the application code to meet performance constraints. It is because hardware and software have related abstractions that codesign can make architectural choices which balance the design problems of each. Design starts with the creation of a specification also known as requirements or requirements specification. A system specification includes not only functional require mentsthe operations to be performed by the system but also nonfunctional requirements, including speed, power, and manufacturing cost. The importance of the specification should not be underestimatedmost systems have at least some predefined requirements or goals, such as a target pageperminute production and maximum sale price for a laser printer. Books by Davis 21 and Dorfman and Thayer 23 give more information on system specification techniques and standards. 912 PROCEEDINGS OF THE IEEE, VOL. 82, NO. 7, JULY 1994 During the writing of the specification and the design of the initial system architecture, phases which often overlap, the system architects must determine that the design goals are in fact feasible. Feasibility checks are simpler in the design of applicationspecific ICs ASICs because the chip to be designed fits into a predefined system and performs a small enough function that it can be specified with confidence. In contrast, embedded computer systems usually employ microprocessors precisely to add a vari ety of sophisticated features which, in tum, complicate the specification of the system and validity tests. And because embedded software is often used to decrease de sign turnaround time, some decisions on the hardware engine must be made from guesses as to the ultimate function to be implemented. An extreme example 3 is offered by several avionics manufacturers even before the Federal Aviation administration had defined the technical standards for new GPSbased navigation services, these manufacturers guaranteed to purchasers of currentmodel radios a cap on their cost to upgrade the radios to the new standards. In many other cases, manufacturers design a single hardware engine which is used both for several products at a time and several generations of products since the exact features of successive generations cannot be precisely predicted due to competitive pressure, it may be necessary to design the hardware engine architecture using only guesses as to the resources required by future features. Embedded system design methodologies must be able to support incomplete specifications, design of a single engine to satisfy multiple product specifications, or changes to the specs during design. Requirements specification inherently deals with descrip tions which are too informal to be defined mathemati callymost customers describe their requirements in Eng lish that is often incomplete and inconsistent. A great deal of work has been done on system and software specification in general, and some of that work has concentrated on the design of realtime systems. HatleyPirbahi analysis 36 is a wellknown technique for the design of realtime systems. A system is described in terms of two models a system requirements model and a system architecture model. These two models are jointly refined in a spiral development cycle once initial requirements have been given, an initial architecture is proposed analysis of the architecture suggests refinements to the architecture, which in tum suggest changes to the architecture and so on until the requirements are wellunderstood and an implementable architecture has been identified. A requirements model consists of a data flow diagram, a control flow diagram, response time specifications, and a requirements dictio nary. A dictionary in software specification is similar to a common dictionaryit lists definitional information, such as type, references, and so on, for elements of the spec ification. The architecture model includes an architecture flow diagram which allocates functional elements of the requirements model to physical units in the architecture, an architecture interconnect diagram a block diagram, and a dictionary. HatleyPirbahi analysis is intended to be used first to define the complete system, then to refine the software and hardware sections of the system. ShlaerMellor analysis 1881 is an objectoriented ap proach to realtime system specification, where an object is a data structure plus a set of member functions which operate on that data structure. In objectoriented designs, functions are performed not by executing monolithic func tions on large data structures, but rather by member func tions updating their objects and calling member functions of other objects. ShlaerMellor analysis views objects as state machines the values in the objects data structure define its state while its member functions can update the objects state and produce outputs based on that state. The behavior of an object can be described as an ASMlike state transition graph. Analysis helps the designer identify which objects make up the system, the behavior of each object, and how objects communicate to implement system behavior. It is critical that specification not bias implementation. If the specification method is too operational, it will contain an implicit or explicit architectural model. The architec tural model which is best suited to specification may not be the most efficient implementation. DAnniballe and Koopman 20 studied techniques biasfree specification of distributed systems. They developed a specification methodology which mixed objectoriented analysis with a settheoretic formal specification of the behavior of the objects. This technique allowed them to better separate the specification of function from the allocation of those operations to architectural components. After the architectural decisions have been made, hard ware and software design can proceed somewhat separately if proper codesign has selected a good architecture, then components designed to the architectural specifications can be put together to build a satisfactory system. Hardware design proceeds through several steps a description of behavior, which may include communicating machines and in which operations are only partially scheduled in time a registertransfer design, which gives combinational logic functions between registers but not the details of logic design the logic design itself the physical design of an integrated circuit, placement and routing in a field programmable logic device, etc. Software design starts with a set of communicating processes since most embedded systems have temporal behavior which is best expressed as a concurrent system the decomposition of function into modules is an intermediate step in software design, which proceeds to coding in some combination of assembly and highlevel languages. The software and hardware compo nents must be integrated and then tested to be sure that the system meets its specifications. The separation of design tasks into concurrent design of hardware and software components highlights the im portance of early selection of a hardware engine and an accompanying software architecture. The architectural choices made early in the design process guide the detailed implementation choices for the hardware and software com ponents. As in any complex design, the architect must make key choices early, looking ahead to possible implementation WOLF HARDWARESOFTWARE CODESIGN OF EMBEDDED SYSTEMS 973 problems, but without completing a full implementation. When an aircraft designer selects an engine for a new airplane, he or she does not need to design the arrange ment of rivets on the airplanes tail to determine the horsepower requirements of the new engine such detailed implementation decisions would only be an abstraction. The detailed design of the airframe must, however, be completed in a way that does not violate the assumptions about gross weight, drag, and other factors that were used to determine the engine requirements. In an embedded computing system, the implementation of the software processes and the hardware components must be consistent with the assumptions made about computing loads. Once the hardware and software components have been implemented, they must be separately tested, integrated, and tested again. Unfortunately, the hardware and software design communities use the word testing very differently hardware designers use it to mean manufacturing testing, or tests which ensure that each manufactured copy of a component was correctly manufactured software designers use it to mean system validation, or ensuring that the design meets the specification. We prefer to reserve the word verification for mathematical techniques which give proofs of the correctness of certain system properties, leaving validation for informal techniques which give reasonable assurance but fall short of proofs. Both forms of testing are necessary the hardware and software elements must be executed together to ensure that the system satisfies its specification and each copy must be tested for defects as it comes off the manufacturing line. Manufacturing test of embedded systems does not introduce major new problems, since the hardware can be tested independently of the soft ware and the integrity of ROM code can be easily checked. Design validation of the integrated hardwaresoftware sys tem does, however introduce some problems. The first problem to be considered is that software de velopment must rely as little as possible on the completion schedule of the hardware design. Design methodologies in which the software designers must wait for the hardware so that developers can execute their code result in unaccept ably long development times. More important, such a serial design methodology ensures that the hardware engine will have design flaws which introduce software performance problems. Hardware designers or synthesis tools must be able to make use of the results of a more detailed software design to refine the design of the engine and conversely, the software implementation can be affected by the details of the hardware engine. It may be possible to develop the code on a completely different platform, such as a personal computer or workstation. In other cases, it may be necessary to use the target processor but to use a standard development system in place of the final hardware engine. Once the first versions of the engine and application code are available, integration tests can begin. Integration testing must check for both functional bugs and performance bottlenecks. As mentioned in Section 111B, the events in an embedded computer system are not always easy to observe. It may not be possible to gather large enough traces to determine detailed system behavior on cached machines, behavior may not be extemally visible. Many modem microprocessors provide hooks for tracing during execution, which are useful in functional debugging but may not be feasible for systems which must be run at full speed. Sampling is often used to generate approximate performance measures the address bus can be sampled periodically to generate histograms of address execution rates the kemels scheduler can be used to generate a trace of active processes to determine how frequently each process was executed counters in the hardware engine can be programmed as event counters to measure certain perfor mance statistics by adding a small amount of measurement code to the system. 111. PERFORMANCE ANALYSIS Soft and hard performance goals are essential parts of the specifications of most embedded systems. Performance analysis is also critical to cost minimizationthe usual approach to designing a timecritical system in the absence of accurate performance analysis is to overdesign the hard ware engine, producing a system that is more expensive than may be necessary. As a result, performance analysis is critical at all stages of design. This section describes two categories of performance analysis methods those used during requirements analysis and architecture design and those used to measure the performance of software. We will not consider here how to determine the cycle time of hardware components, which is a relatively wellunderstood problem whose outlines can be found elsewhere lOO. Malik and Wolfe 64 argue that embedded system per formance analysis requires solving two problems modeling the underlying hardware engine and analyzing the behavior of the code running on that engine. Furthermore, per formance estimation tools are required at each level of abstraction through which the design proceeds. This section considers performance analysis of large systems in Section 111A, modeling of CPU performance in Section 111B, performance of a single task in Section 111C, performance of multiple tasks running on a shared processor in Section 111D, and cosimulation in Section 111E. A.  System Performance Analysis The goal of system performance analysis is to trans late performance specifications, which are typically given on userlevel functions, into constraints on the design of the hardware engine and the application software. System performance analysis includes several tasks determining the implications of performance specifications estimating the hardware costs of meeting performance constraints identifying key development bottlenecks and estimating development time. System performance analysis is not necessary for most ASICs due to the simple form of the performance constraints. It is, however, a necessary step in the design of a modem CPUthe sizes of queues and buffers, the number of hardware resources available, and the interconnections between those resources all determine the 914 PROCEEDINGS OF THE IEEE, VOL. 82, NO. 7, JULY 1994 , . . . . . . . . W I ....... , i ISAbus 2 1 data transfer Fig. 4. Data transfers and tone detection options in Tigerswitch. performance of the CPU. Similarly, memory, interconnect, and function units in the form of CPUs or specialpurpose processors all influence the overall performance of an embedded system. An example helps to show the role of system performance analysis in the design of an embedded computer system. Tigerswitch is a PCbased telephone switching system designed at Princeton University. As shown in Fig. 4, the PC system bus known as the ISA bus serves as the switching fabric. Line cards connect telephone lines to the switch an analogdigital converter connects to the telephone microphone, while a digitalanalog converter connects to the speaker. During a call between two phone lines, the PC first reads the current microphone sample from one line, then writes it to the other line it then reverses the procedure to provide a fullduplex connection. Each call must be sampled at 8 kHz, the sampling rate for telephonequality audio. Several factors influence the number of phone lines which can be supported by the switch. The ISA bus bandwidth certainly limits the number of calls which can be switched. However, bus bandwidth divided by sampling rate is only an upper bound on phone line capacity, since some bus operations are required for execution of the program which controls the switch. Furthermore, the CPU itself is used both to implement the switching fabric and for other switching functions an 8kHz timer interrupts to switch data between all active lines by executing VO instructions on the CPU a foreground process keeps track of call state other processes determine how to route calls and bill time as well as other functions. The function which caused the most concern in the design of Tigerswitch was tone detection. Dialing tones known as DTMF, for dualtone multifrequency must be detected at the start of the call each digit on the phone keypad is signaled by a pair of tones, where each row and each column on the keypad has its own distinct tone frequency. DTMF detection can be performed by a filter bank or by Fourier analysis. Because the two tones must be sustained for at least 0.1 s to make a valid signal, tone detection requires a great deal of computation. As shown in Fig. 4, we had three possible locations for DTMF detection in the architecture on each line card, using analog DTMF detectors on the main CPU, as a background process, using digital signal processing algorithms and on an auxiliary processor, using the same DSP algorithms, on a card plugged into the ISA bus. In most switching systems, DTMF detection is performed digitally by one of a few tone detection units, since DTMF detection is required for only a small fraction of the call. In this scheme, when a phone is taken off the hook, the switch searches for a free tonedetection unit and does not issue a dial tone until one is available. We decided not to implement a tonedetection unit on a separate card, because we could not design the additional hardware and meet our desired completion date the end of the semester. A test program was created to measure the amount of time required to run the DTMF detection algorithm on the main CPU. Experiments showed that DTMF detection took sufficiently long on a 386 processor that the switching fabric process did not have enough time left over to switch any calls at the 8 kHz rate. A Pentium processor was fast enough to execute the DTMF algorithm and still switch calls. However, we decided that we could add DTMF detection to our line card much more cheaply than the cost of a faster host processor, so we added analog DTMF detection to the line card. A similar project which had different requirements and manufacturing volumes would probably opt for one of the other two possible solutions the line card set is the single most expensive element of a large switching system. Design choices must be evaluated in light of the system requirements. Tigerswitch illustrates the typical architecture design process in an embedded system first, a candidate architecture must be proposed and potential performance bottlenecks in that architecture must be identified second, modifications to the architecture must be pro posed and the performance of each analyzed finally, one configuration must be chosen based on the results of performance analysis and other require ments, such as manufacturing cost, design time, and reliability. Performance analysis of an initial architecture, before a complete implementation of any part of the system is avail able, is critical because performance bottlenecks may not be obvious from the system specification. Performance ap proximations derived from simplified models of the system, providing that the approximations are sufficiently accurate, help us avoid completing an unsatisfactory implementation which must be thrown away. Morfits description of one embedded system design illustrates the role of performance analysis and optimization 67. After the design and implementation of a cellu lar telephone system, the design team used a software monitoring system, which recorded the active process at each scheduler interrupt, to measure which processes were dominating CPU utilization. Measurement showed that un expected processes were taking up most of the CPU and Pentium is a trademark of Intel WOLF HARDWARLSOFTWARE CODESIGN OF EMBEDDED SYSTEMS 915 that repartitioning operations between processes could sub stantially reduce CPU requirements. In one case, bundling display writes into a single processor reduced that processs utilization from 2050 to less than 10. In another case, modifying a process to write multiplebyte rather than 1byte records reduced the number of function calls to a critical routine in the range 20 1 to 300 1, depending on the data. While some performance data cannot be fully created without a complete implementation, a more detailed model with accurate analysis would allow such problems to be caught in time to change the design of both the software and the hardware engine. Queueing system models are useful for analyzing systems where inputs arrive sporadically or the processing time for a request may vary. In a queueing model, customers arrive at the queue at some rate the customer at the head of the queue is immediately taken by the processing node, but the amount of time spent by the customer in processing must be specified. Typically, both the customer arrival rate and processing time are modeled as Poisson random variables. Useful characteristics a queue include the average residence time, which is the amount of time a customer resides in the queue plus processing time, and the average queue length, which is given by Littles Law 54. Queues are assembled into networks to model systems the output of one processing center feeds into another queue to enter the next phase of processing. Computer system models have traditionally used for dataprocessing style applications stochastic models are appropriate not only for CPUs which must handle requests which may take varying amounts of time to process, but also disks whose access time depends on the disk state at the time of the request. Queueing network models are usually solved by simulation SESWorkbench is one wellknown queueing network analysis system. Kobayashi 54, Lazowska et al. 56, and Smith 91 survey computer system modeling using queueing networks. B .  CPU Pegormance and Modeling Advanced architectures usually include components, like caches, which provide high peak performance at the cost of greater variance in execution times. Hard realtime systems must meet their deadlines under worst case conditions. Some techniques exist for narrowing the variance of ex ecution times. Most CPUs are offered in several different models and the choice of model can substantially affect the cost of the CPU. Integrated circuits may be packaged in ceramic or plastic ceramic packages are much more expensive to make than injectionmolded plastic packages, but ceramic packages provide more pins and can run at faster rates. For example, a 1991 Intel catalog lists the price of a 20MHz i960KB in a plastic quad flat pack PQFP as 17 less than the same chip in a ceramic pingrid array PGA the SESWorkbench is a trademark of Scientific and Engineering Soft ware, Inc. 25MHz version of this processor is available only in the PGA package. In some cases, the processor can be packaged in plastic only by reducing the number of pins. In such cases, a modified bus is designed for the processor with a smaller number of data pins. For example, the Intel i386DX has a 32bit data bus, while the i386SX has a 16bit data bus. The smaller bus width is invisible to the software running on the CPU because the bus subsystem breaks a write into operations which can fit on the bus, and assembles the results of a read to produce a datum of the proper size. The smaller bus width also makes the memory system less expensive, since it requires fewer separate chips. The ability to use a plastic package at all, or to use a cheaper plastic package with fewer pins, can make a CPU substantially cheaper the 1991 Intel catalog prices a 16MHz i960SB, a variation of the KB with a 16bit bus, as 40 less expensive than the 20MHz chip in a ceramic package. While a 16bit bus on a 32bit processor requires two bus transactions to fetch a 32bit datum, the effect of reduced bus width on program performance cannot be simply calculated. Code executing from the intemal cache or data in registers runs at the same rate on the narrow and widebus systems if the program fetches smaller data values, such as bytes, the narrow bus will be as efficient. A study of the programs dynamics is required to determine the true performance penalty of a narrow bus. Instruction execution time is normally given in tabular form. For a nonpipelined processor, one entry per instruc tion is sufficient for simple instructions. More complex instructions may have execution times which depend on data values, just as program execution times depend on the trace taken through the program. Integer multiplication, floatingpoint, and especially transcendental functions are likely to have datadependent execution times. A transcen dental operation can take tens of thousands of clock cycles to execute. Execution behavior in a pipelined machine depends not just on one instruction, but on a set of instructions. For example, a processor may use a prefetch unit to fetch instructions in order after the present program counter location and store those instructions in a queue. When a branch is taken, the pending instruction queue is no longer valid, so the CPU must wait for the branch target to be fetched, which causes a longer interval between successive instruction completion times. Other pipelining mechanisms also cause the execution time of one instruction to depend on which other instructions are pending for example, the Intel i960KB manual gives the execution time for register operations depending on whether the processor can bypass a register access 45a bypass hit occurs if the source of one of the instructions operands was the result of the previous instruction, saving one clock cycle. Schmit 83 describes techniques for optimizing Pentium code to take advantage of multiple instruction issue. It is often not possible to obtain from the micropro cessor supplier a CPU simulator which accurately models performance. Simulation models which mimic only bus 976 PROCEEDINGS OF THE IEEE. VOL. 82, NO. 7, JULY 1994 behavior, known as buslevel models, are more common. Such a model accurately reflects the number of cycles required to perform a bus transaction, such as a read or write, but does not model the action of instructions. On the other hand, some manufacturers do not publish instruction performance data, even in tabular form. In such cases, the only recourse for accurate performance measurement is to measure execution times on a hardware system. Measurement may be difficult on cachebased systems, since not all CPU operations will be reflected on the bus. An incircuit emulator is a version of a CPU with the same pinout as the standard CPU but which keeps traces of instructions, allows breakpoints to be set, etc. While an emulator is useful, emulation suffers the same fate as simulation in that worst case performance is hard to elicit, and the emulator may not be able to execute the instruction stream at the full rate of the standard CPU. An emulator is often more useful for functional debugging than for performance analysis. Caches affect CPU performance even more than pipelin ing within the execution unit. Many texts, such as Patterson and Hennessy 38, describe cache organization and op eration. Since the static RAM SRAM used in cache is ten times or more faster than the dynamic RAM DRAM typically used in main memory, the penalty for a cache miss is very large. Interruptdriven systems are very poorly matched to the assumptions which typically justify caches. Rather than have a loop or another relatively small section of code which is executed repeatedly, an interruptdriven system switches at irregular intervals between routines residing in very different parts of memory. In a typical processor, an interrupt routine invalidates most or all of the cache not only does this slow down the initial execution of that routine, but it introduces contention for the cache between interrupt routines which slows down the entire system. The stochastic nature of cachebased systems presents a problem to the design of systems with hard realtime deadlines. While an operation may run fast if it happens to reside in the cache, it will run much slower if the routine is not in the cache. It is often difficult or impossible to predict from macroscopic program structure whether a particular piece of code can be guaranteed to be in the cache. As a result, realtime system designers often assume that a memory fetch will always miss the cache. While this assumption does ensure that the process will always meet its deadline, it is very pessimistic caches are one of the most effective means to the improvement of CPU performance. Larger caches provided by increasing SRAM density make it easier to reserve sections of the cache for crit ical code. Two schemesne hardware and one soft warehave been proposed to ensure that selected routines reside in the cache. Kirk proposed the SMART Strategic Memory Allocation for RealTime cache organization 5 13, 52,  which partitions the cache into a shared partition plus several partitions allocated for critical tasks, as shown in Fig. 5. Each timecritical routine may receive one or more segments of the cache. A processor flag determines address  partition ID  sharedflag  cache mapping 1 partition 3 1 Fig. 5. Address mapping in Kirks hardware cache partitioning scheme. whether the currently running process is mapped into the shared partition or into one of the private partitions. An ID register identifies which private partitions are owned by this process. Hardware ensures that a segment can be accessed only by the task to which it was allocated. Kirk and Strosnider 52 developed an algorithm to analyze instruction traces to choose sections of code which should be allocated their own cache segments. Wolfe  lo l l  proposed a partitioning scheme which re quires no additional hardware. His scheme chooses ad dresses for code and data during linking such that critical routines are the only addresses in the program which map into certain sections of the cache. Since no other routine can knock that code out of the cache, the routine is guaranteed to be cache resident. Figure 6 shows an example for which the cache has an 8byte line the first two lines are allocated contiguously to one process, the third line to another process, and the fourth line to yet another process. This scheme maps addresses into the cache into very small chunks, equal to the size of the cache linefrequently 16 bytes or smaller. As a result, a processs address space is broken into many small chunks, and it may not be possible to allocate a processs code to contiguous addresses it also requires widely separated addresses. Wolfe presented another scheme which allows contiguous addressing by extracting the tag from the middle of the address, not the top, larger blocks of contiguous memory are mapped into the cache. While this scheme requires that the cache hardware be redesigned to use different address bits, it does not add either area or delay to the cache implementation. Interrupt latencythe time required for the CPU to execute the first instruction of an interrupt handler after an interrupt is raisedcan significantly affect performance in two ways. First, interruptdriven or schedulingbased systems must add interrupt latency into their calculations of total processing time. Second, interrupt latency puts a lower bound on the time in which the system can respond to an interrupted request. Tasks which require very fast response to an event may not be implementable as interrupt routinesbusywait 10 or addition of a special hardware unit to handle the task are alternative implementations which decrease response time at the expense of added hardware cost either in the form of required additional WOLF HARDWARESOFTWARE CODESIGN OF EMBEDDED SYSTEMS 977 301f I process3 I 3018 2018 tag line index I I I 201 0 00 1 OOf 08 1008 I I   I I 1000 p 3 0 1  118 main memory cache Fig. 6. scheme. Address mapping in Wolfes software cache partitioning CPU capacity to make up for the lost time incurred by busy wait polling or for the specialpurpose hardware. When a CPU services an interrupt, it must typically reference interrupt vector tables, change the CPU state, and other assorted tasks. Responding to an interrupt usually takes much longer than simple instructions and the penalty generally grows with CPU size. For example, the Motorola MC68HC 16 16bit microcontroller requires 16 clock cycles to respond to an interrupt 68 the Motorola MC68020 requires a minimum of 26 cycles 69 the Intel i960KB requires a minimum of 85 cycles 45. While these times are not completely comparable, since these processors perform somewhat different actions on interrupts the i960KB, for instance, saves the current register set, but they do show that the penalty is significant and increases with archi tectural complexity. The time required to respond to an interrupt may depend on the state of the processor for example, multiplecycle instructions may not be interrupt ible. Interrupt latency is not the only cost of handling an interrupt interrupt latency is overhead incurred in addition to the execution time of the interrupt handler furthermore, the change in instruction flow induced by the interrupt changes the state of the cache. C .  Software Performance Estimation To estimate the performance of a concurrent system, we must be able to estimate the performance of a sin gle process. Software performance estimation estimates bounds on the running time of a singlethreaded code fragment when run on a specified processor. While CPU modeling concentrates on a stream of instructions small enough to fit in the processor pipeline and cache, software performance estimation analyzes larger sections of code. Software performance estimation can be broken down into two steps identifying legal paths through the code and determining the execution time of each path. Identifying all legal paths through a program with unbounded memory is equivalent to solving a halting problem, making exact path identification undecidable, but good identification of false paths through the program tightens the bounds on execution time. We would like to develop a hierarchy of performance estimation models, including at least highlevel language and assembly language descriptions of the program. Lower level models, such as assembly language, will obviously give more accurate information on the effects of register allocation, instruction interactions, and caching than will a highlevel language model. However, we often synthesize a program from some specification by creating a highlevel language description which is then passed to a compiler. We may not want to include compilation time in the interval required to generate an initial performance estimate fur thermore, we may want to compare the merits of potential target CPUs without purchasing the compilers for all those architectures. Therefore, in addition to path analysis, software performance estimation must also consider how to calculate the execution times of the primitive operations in the software description at whatever level of abstraction is available. The earliest techniques for software performance analysis were manual analysis methods developed for data process ing systems. Smith 91 gives a good overview of the analysis of program representations she calls execution graphs, which are flow charts which use fork and join operators to specify concurrent activity. Execution graph analysis is intended primarily for modifications to existing systems because it depends on performance measurement of code. The execution time of the graph is computed by reducing subgraphs. However, the accuracy of the execution time clearly depends on the accuracy of the performance estimates for the primitive operations, the estimates of the numbers of times loops are executed, etc. Smith de scribes techniques for obtaining accurate execution time and workload information from existing systems. However, performance estimates based on measurements must always be used with caution because the system tests may not have exercised worst case behavior. Automatic software performance estimation offers the promise of performance figures which are both conservative, i.e., guaranteed to be bounds on actual worst case performance, and more precise than can be generated by hand. EinDor and Feldmesser 24 performed an early ex periment in performance prediction. Their goal was to predict the relative performance of a computer system from basic characteristics of that system. They executed a set of benchmark programs on 209 computer systems and created a regression model of computer performance as a function of six variables cache memory size, minimum number of VO channels, maximum number of U0 channels, machine cycle time, minimum main memory, and maximum main memory. Their model could predict performance relatively accurate over a range of mediumperformance machines. Shaw developed techniques for reasoning about the ex ecution time of both single and communicating processes 86, 87. Shaw assumed that bounds tmin, t, could be found for the execution times of program statements. He 978 PROCEEDINGS OF THE IEEE. VOL. 82, NO. 7, JULY 1994 defined the execution times of code in terms of schema which describe the execution times of combinations of statements. He used Hoarestyle assertions to describe timing properties of the program given a statement S in the program, if a predicate P is true before S is executed, then Q is true after S is executed, which is written in the form P S Q. To reason about the realtime behavior of the program, P and Q can be functions of the real time if a statement Ss execution must be completed in the interval  t d l , m i n , t d l , m a   and rt represents the value of real time, then the deadline can be expressed in the form rt  I  , m a   tmaxSSrt  h , m w  r  when tdl,min  CO. Shaw used these techniques to, as one example, reason about programs which recognized single and double mouse clicks, behavior which relies intimately on real time. Puschner and Koza 79 used simple bounds declarations to capture user execution information which could not be directly derived from the program and more accurately estimate maximum execution time. Their declarations took the form of annotations in the program source code scope identifiers delimited a sequence of statements in the pro gram a marker statement specified the maximum number of times the program would pass through that marker between entering and leaving the scope which enclosed it a loop sequence declaration gave an upper bound on the total number of times a sequence of loops would be executed useful when the loop bounds of sequential loops are correlated but not independently fixed. They found that these declarations were sufficient to greatly improve the accuracy of execution time bounds in the examples they studied. Park and Shaw created a timing tool which combined performance models for C language statements with path analysis algorithms 71, 1721. Park developed his per formance model for one CPUcompiler pair namely, a 68010based Sun3 and Gnu C1.34. Parks model relies on instructions being executed deterministically instruction execution times do not depend on nearby instructions and neither instructions nor data are cached. He found that the most accurate means for estimating program times was to consider all the code in a basic block at once he extended the C compiler to mark boundaries of basic blocks for each basic block in the C program, he identified the assembly language generated by that block and looked up the execution times of each instruction in a table. He applied corrections to take into account two types of systemlevel interference in program execution clock interrupts and memory refresh. Park compared measured execution times to computed estimates to show that, in most cases, these techniques produced tight bounds and that most uncertainty could be removed by more accurate prediction of execution paths. While a programs control flow graph gives the set of all possible execution paths through the program, there may be paths which are never executed the data values supplied to the program may be restricted so as to, for example, limit the number of times through a loop relationships between variable values in the code may also make some paths infeasible. Parks model for execution paths was regular expressions extended with intersection and negation opera tors. To gather user execution information, he developed an information description language important statements in the program were given names, restrictions such as nopath A, B and loop A K times could be placed on feasible paths. This information can be used to ignore illegal paths during timing analysis. Experiments showed that adding path analysis information tightened execution bounds. Ye et al.  1021 developed a fast timing analysis technique for use in hardwaresoftware partitioning. They needed to accurately estimate the system performance even when the software partition executed on a highperformance CPU whose execution times depend on data dependencies, instruction order, etc. They extracted a basic block of the software and executed it once the measured execution time automatically takes into account processorspecific timing. They then used that time as one timing label in a control flowgraph along with annotations for execution times of the hardware units, the control flowgraph can be analyzed to predict the total execution time of the hardwaresoftware system. D. Peormance of Tasks on Shared CPUs It is not sufficient to analyze the performance of each process in isolation. When several processors are allocated to a system CPU, system performance depends on how the processes are scheduled on the CPU. The scheduling of processes on a CPU determines the CPUs utilization, a key measure of architectural efficiency. An underutilized CPU adds unnecessary cost to the system since it could be replaced with a smaller CPU. However, it can be shown that in many cases a CPU cannot both be fully utilized and meet all the deadlines on its processes. The processes executing on a CPU may be scheduled either statically in an order determined when the program was designed or dynamically during system execution. A cyclostatic scheduler is an example of a statically scheduled system a cyclostatic scheduler is called periodically by a timer and executes a set of tasks in a fixed order. A dynam ically scheduled set of processes may be scheduled either preemptively or nonpreemptively. In a nonpreemptively scheduled system, each process explicitly gives up control to the next process. System calls are spread periodically through the code which allow the next process to run, usually determined by a list of active processes maintained by the kernel. Microsoft Windows is an example of a nonpreemptively scheduled system. Nonpreemptive code must be carefully implemented to ensure that each task gives up control of the CPU in a bounded amount of time on any execution pathfailure to relinquish control causes the system to fail to respond to other inputs. A preemptively scheduled system uses a timer to periodically retum control of the CPU to a scheduling process in the kemel. The process with the highest priority is chosen to run in the next time slot. WOLF HARDWARESOFTWARE CODESIGN OF EMBEDDED SYSTEMS 979 D2 D1 0 2  D1 Fig. 7. Process priorities and deadlines. Each scheduling scheme has advantages and disadvan tages. A nonpreemptive scheduler allows the designer to verify properties such as deadlock because we do not know the exact order of execution of processes in a preemptively scheduled system, they cannot guarantee liveness. Chiodo et al. 12 use an FSMbased description to verify the properties of hardwaresoftware systems before choosing a hardwaresoftware partitioning for implementation. How ever, a nonpreemptively scheduled system requires a more powerful CPU to ensure that it meets all its deadlines than does a preemptive scheduler preemptive scheduling is more CPUefficient because a task with a closer deadline can be assigned a higher priority and preempt a lower priority task. Figure 7 shows a simple example of how process sched uling determines deadline satisfaction. The processes P1 and P2 have deadlines 0 1  and 0 2 ,  respectively. In the upper schedule, P1 has been scheduled first, for example because it was activated first by an outside event. Pls deadline is well after P2s, but P1 prevents P2 from executing and makes P2 miss its deadline. If process priorities are assigned to ensure that the process with the shortest deadline receives the highest priority, allowing it to start executing as soon as it is activated, then both processes are able to complete before their deadlines. The fundamental result in scheduling of hard realtime tasks was discovered by Liu and Layland, who introduced the ratemonotonic scheduling algorithm 62 for schedul ing periodic task sets. In their model, a system consists of a set of tasks, each of which has a deterministic computation time and a period. While those times are fixed, the phasing of the tasks relative to each other is not fixed. They showed that such a task set can be scheduled to meet all deadlines, irrespective of the phasing of task initiations in the period. Interestingly, only fixed priorities are required priorities are assigned inversely to task period, with the shortest period task receiving the highest priority. They also showed a worst case bound for CPU utilization of 69.3. Thus excess CPU capacity must be available to ensure that the CPU can respond to the worst possible combination of task phasings. However, for preemptive scheduling, the CPU capacity is determined by the task specifications, while in nonpreemptively scheduled systems, the CPU capacity required is determined by the structure of the code. This work has been extended in a number of ways to handle more general hard realtime systems. The priority ceiling protocol was developed by Sha, Rajkumar, and Lehoczky 85 for systems in which lowpriority tasks can obtain critical resources. When a process requires a resource 980 which must be shared by PV semaphore synchronization, a lower priority process can use the resources lock to block execution of a higher priority process which needs the resource, a situation known as priority inversion. Strosnider I961 introduced deferrable servers for aperiodic tasks, in which a collection of aperiodic tasks is modeled as a regularly scheduled process which periodically checks the status of the aperiodic requests. Leinbaugh 60 developed an algorithm to bound worst case performance for systems of processes which talked to devices and executed critical sections. E .  COSimulation Simulation will be an important codesign tool for the foreseeable future because of the complex nature of the embedded computing systems. Because embedded system components are so complex, it may be difficult to de velop comprehensive analytic models for their performance. Simulation also helps the designer verify that the system satisfies its requirements. Cosimulation mixes components which have different simulation models. COsimulation usually refers to some sort of mixed hardwaresoftware simulationfor example, one part of the system may be modeled as instructions executing on a CPU while another part may be modeled as logic gates. COsimulation is difficult because the systems components operate at different levels of abstractionanalog components operate over voltages, PLDs operate over binary values, and micro processors operate over instructionsand run at different rates one instruction in a microprocessor may take several cycles to execute, during which time analog components may have moved to a drastically state. Multimode simulators allow a system to be described as a mixture of components at different levels of abstrac tion. As shown in Fig. 8, two different techniques have been developed for multimode cosimulation. A simulation backplane provides a toplevel simulation model through which different types of simulators can interact, so long as their external behavior meets the modeling requirements of the backplane. A heterogeneous simulator does not require all simulation events to be reduced to the same level of abstraction. Ptolemy 9 is a wellknown framework for the construction of cosimulators. A simulation universe in Ptolemy consists of several domains, where each domain has a single simulation model. Ptolemy does not enforce a single simulation model domains may be combined arbitrarily and developers may create new domains. Several different domains have been implemented for Ptolemy synchronous data flow, dynamic data flow, discrete event, and a digital hardware modeling environment. Each domain has its own scheduler. Wormholes allow data to pass be tween domains. A wormhole between two domains includes an event horizon which translates events as they move from one domain to another. As an event moves between domains, it is first translated into a universal event type and then to the domain of the destination. Because wormholes hide the details of operations in other domains, a domains scheduler does not have to know the semantics of the other PROCEEDINGS OF THE IEEE, VOL. 82, NO. I, JULY 1994 n simulation hackplane w hetervgeneous simulation Fig. 8. Two techniques for multimode simulation. domains to execute its simulation. Ptolemy also supports interfaces to code synthesis for DSPs. Kalavade and Lee describe the use of Ptolemybased cosimulators to develop a hardwaresoftware system 49. Hierarchical simulators allow a design to be modeled and simulated at several different levels of abstraction, but with the same level of abstraction for all components in each model. ADAS Architecture Design and Assessment Sys tem 92 was an early codesign tool which was targeted to signal processing applications. ADAS could simulate a system at three levels of abstraction at an algorithm level, modeled by data flow at an architectural level, modeled by scheduled processes and at an implementation level, described as a registertransfer system. The designer could simulate the system at each level of abstraction and compare the system performance at two different levels of abstraction to guide the refinement of the design from one level of abstraction to the next. Roth et al. 82 created a custom simulator for a pair of graphics accelerator ASICs they designed. The design project needed a simulator which was both fast enough for software development and accurate enough to be used in debugging the hardware models. They developed a custom simulator in C which could simulate either of the two chips and provided a programming interface equivalent to the chips themselves. They extracted the simulated chips internal states during simulation and compared that state trace to a state trace generated by a Verilogbased register transfer or gatelevel simulation of the chips. Differences in the state traces indicated potential bugs. Because the ASICs had multiple function units and worked on an asynchronous memory, accurately comparing the two state traces required considerable effort. Iv. HARDWARE ENGINE AND SOFlWARE PROCESS DESIGN In this section, we will survey methods for the design of an embedded systems hardware and software. We do not yet fully understand how to jointly design the hardware and software for embedded applications. Most work has concentrated on the design of either the hardware or software, using a very simplified model for the other. Recent work on hardwaresoftware partitioning takes a more balanced view of the two elements, but existing algorithms still rely on restricted architectures for both the hardware and software components. Methodologies and algorithms for truly general hardwaresoftware codesign of embedded systems are a primary goal of research in this WOLF HARDWARESOITWARE CODESIGN OF EMBEDDED SYSTEMS w process data flow graph n processor graph Fig. 9. Graph models for hardware and software design. area. As a result, we will describe both previous work in co design proper and also related work in distributed system design, which takes the hardware engine as a given and designs a software architecture. Joint design of the hardware and software requires repre sentations for both the processes and the distributed engine, as shown in Fig. 9. An example of a software model is a data flowgraph to represent the software processes, which identifies sources and sinks of data between the processes. It may also be important to represent control flow between the processes, in which case the general form is called a process graph. The processor graph, which represents the hardware engine, has CPUs as nodes and communication links as edges. Some research considers processor graphs where all CPUs are identical, while other work allows each node to have different characteristics. Figure 10 illustrates how a process graph is mapped onto a processor graph. The figure can only easily depict the allocation of processes to CPUs, but the complete design process also entails scheduling those processes on their assigned CPUs, partitioning the process set to provide an efficient scheduling and allocation, and mapping the processes onto particular types of CPUs. In a traditional design flow, the processes and the processor network would be designed relatively separately. However, to obtain the highest performance, lowest cost solution, we must simul taneously design both the processes and processor system. We first consider altemative models for processes and their embodiment in programming languages. Section IVB describes techniques developed for the design of hard ware engines Section IVC describes recent work in hard waresoftware partitioning, which is the joint design of hardware engine and software architectures from a hard 98 1 , . , link Fig. 10. Mapping application processes onto a hardware engine. ware architecture template. The remaining subsections de scribe techniques developed by the distributed systems community for the scheduling, partitioning, and allocation of processes given the hardware architecture of a distributed system. A .  Process Models and Program Specification Since the systems function will be described as a system of communicating processes, the choice of a process model is fundamental. Given a process model poorly suited to the problem, the system description may become unwieldy or the system may not be describable at all. A number of different process formalisms have been developed over the years, each with its own advantages and disadvantages. The coarsest distinction between process models is their level of parallelism. A Petri net model 76 is a highly parallel model of computation. The synchronous dataflow model 59, a data flow model in which the number of samples consumed by a node at activation is specified a priori, is another highly parallel model of computation. A communicating sequential processes model describes each process as executing sequentially, but allows the processes to execute at different rates. There are many communicating sequential process mod els, which can be further classified according to the types of interprocess communication they support. Buchenrieder er al. 8 use the PRAM model, which is commonly used to model sharedmemory parallel algorithms, to describe the communicating processes in a machine. The Solar modeling language 70 is an example of a communicating pro cesses model for codesign. Hoares CSP 39 is one style of communicating sequential process model which uses unbuffered communication. In nonblocking or buffered communication, a queue holds data which have not been consumed by the receiver, allowing the sender to continue executing. A finitestate machinestyle model uses implicit communicationbecause an FSM can change its outputs at any time, communication is not separated from the rest of the machines computation. Eventdriven state machine models, including the BFSM 97 and the CFSM 12, have been proposed for use in codesign because they allow the systems to be described as a partial ordering. Software is much more than code, particularly when that software implements a system of concurrent processes. Representations for programs are important intermediate forms for system design. Software design models ensure that the software is correctly implemented. Because most design languages for concurrent processes also define inter process communication primitives, they provide documen tation on how the processes talk to each other and hooks for the analysis of interprocess communication. A number of concurrent programming languages have been developedthese languages allow computations to be expressed as systems of communicating processes but do not provide methods to specify deadlines or guarantee that they be met. A concurrent programming language provides primitives for interprocess communication. Interprocess communication primitives may also be provided by the operating system. The way in which the language models communication has a profound impact on the way the initial architecture is implemented in the language. Several different communication techniques are possible. A signal sent by one process forces another process to start executing at a specified location which should handle the signal a signal is a software version of an interrupt and is used in the Unix system. A mailbox is a variant of buffered commu nication usually reserved for schemes in which the names of mailboxes are known globally and any process may both send messages to and take messages from a mailbox. The language and operating system may also support blocking communication or finitesize queues, which can provide nonblocking communication given some assumptions about the maximum number of pending messages. The term realtime programming language has been used in various ways, but generally means that the language allows deadlines to be specified and provides mechanisms to ensure that the deadlines are met. Such a language must have some sort of representation of a process in the language. A realtime programming language may also restrict itself to statements whose execution times can be bounded other realtime languages are extensions of generalpurpose languages, which usually contain state ments with potentially unbounded execution times, such as while loops controlled by unrestricted input values. The statechart 34 is an extendedstate machine model for reactive systems. A statechart is a state transition graph in which a transitions source or sink may be a set of states, not just a single state another way to view this specification style is that a state which represents several different behaviors may be decomposed into states which implement pieces of that behavior. As shown in Fig. 11, OR and AND decompositions can be used to refine a states specification by decomposition. In the OR decomposition in the figure, the transition specifies that the system should go to state s when input i l  is received if the systems present state is either a or b the source of this transition munix is a trademark of Unix System Laboratories. 982 PROCEEDINGS OF THE IEEE, VOL. 82. NO. 7, JULY 1954 or state L l  0 and state Fig. 11. Composite states in a statechart. is the state or l ,  which represents the union of a and b. An AND decomposition represents concurrent activitiesin the figure, the i l  transition out of state t sets one part of the system state to c and another part to d, so that the total state is the product c x d. OR and AND decompositions allow exponentially fewer states and transitions than are required to describe the equivalent behavior in a state transition graph with a single level hierarchy of states. STATEMATE is a wellknown tool for manipulating statecharts 35. The tool integrates representations for block diagram structural descriptions and data flow diagrams with statecharts. It can simulate a specification and generate highlevel language code to implement a specification. A recent collection of papers in the PROCEEDINGS OF THE IEEE 5 described several reactive programming languages, where a reactive language interacts constantly with its environment, rather than viewing input and output as streams. For a detailed description of those languages, the reader is referred to those articles. One example of this approach, the Esterel language 6  promotes a specification style different from that used in statecharts an Esterel program is a network of communicating machines, rather than a single machine with a hierarchically decomposed set of states, as is a statechart. Processes communicate by emitting actions and waiting for actions to appear, with communication scheduled by the programmer. Esterel assumes that reactions to events are atomic and happen instantaneously. Because actions are atomic, the component machines communicate synchronously, which means that many analyses of communication behavior are much sim pler than with asynchronous systems. An Esterel program can be compiled into code by generating a product machine since in the product machine, communication between components is implemented as products of states of the component machines, the communication action does not generate any code, thus satisfying the atomicity hypothesis. B .  Hardware Engine Design ADAS, described in Section 111E, supported early func tional verification and evaluation of system performance at the first three stages of design, which the authors identified as algorithm definition, system architecture design, and detailed system design. In our terminology, the products of ADAS were an architecture for the hardware engine and an allocation of software processes onto processors. While ADAS did not provide synthesis algorithms to au tomatically generate the engine architecture and software partitioning, it did provide representations for the various stages of design and assessment tools to help the designer determine the best translation from one stage to the next. ADAS used three representations of the design, one for each stage of design. The highest level of abstraction was a data flowgraph, which they called a software graph nodes represented processes and edges represented data transfer. The algorithm to be implemented was specified as a software graph data flow is a sufficient representation for signal processing algorithms with little controldependent behavior. The mapping of processes to hardware compo nents was represented by a projected processing graph, which was constructed from the software graph by adding synchronization arcs which forced sequential execution of processes. Finally, the architecture of the hardware engine was represented by a hardware resources graph, which was a form of registertransfer machine. To design an application, the designer first specified a software graph, refined it to a projected processing graph, then added multiplexers and registers to create a hardware resources graph. The software graph could be executed to check that the desired function was properly specified. Performance analysis began with the projected processing graphPetri net analysis was used to determine whether the sequentiality introduced by the sequentiality constraints allowed the function to be executed at the required rate. ADAS had algorithms which could determine the utilization of a node and the latency of a computation. ADAS apparently did not include tools to verify that the hardware resources graph correctly implemented the projected processing graph. MICON 32 generates a boardlevel design of a micro processor system from a loose description of the boards re quirements. The systems specification includes information such as type of CPU required types and amounts of mem ory required IO ports required and the types of extemal connectors. MICON selected a complete set of components and interconnected them to produce a complete board design. Several different components may implement a particular requirement for example, different combinations of memory chips may be used to implement the required memory. Components may also have to be interpolated into the design to provide an interface between two required components. MICON uses AI techniques both to learn how to design boards from expert designers and to complete the design of a board from requirements. Parkash and Parker 78 used integer programming to design a multiprocessing architecture for an embedded hardware engine. Given a partitioning of an application into tasks, their algorithm designs a heterogeneous engine to run the application, allocates tasks to processors in the engine, and schedules those tasks. Their model for a system of tasks is a data flowgraph for which a task may start computation before all its data have arrived. They model the architecture of the engine to be designed as a set of processors with direct communication links. WOLF HARDWARESOITWARE CODESIGN OF EMBEDDED SYSTEMS 983 Each processor has local memory, communication occurs via messages over the links, and one application runs on a processor at a time. Their mathematical programming model includes both integervalued timing variables and binary decision variables timing variables represent data availability times, output av ,ability times, task execution times, and data transfer times decision variables represent allocation of tasks to processors and the direction of data transfer. The model includes ten types of constraints which determine how tasks are mapped onto processors, whether data transfer is local or remote, input and output availability, task execution start and end times, data transfer start and end times, and that each processor and communication link is not used for more than one operation at a time. Their model may be solved to satisfy a performance goal or to minimize total engine cost. They rewrite several of their constraints in linear form to create a mixed integer linear program, then solve the program using standard techniques. Srivastava et al. used templates to design realtime sub systems for a workstationbased embedded architecture 93, 94. Figure 12 shows a simple architectural template with two levels of hierarchy subsystems are connected by a bus each subsystem consists of a CPU and several ASICs all connected by their own bus. They defined a fourlevel hierarchy for their architecture template the top level is a workstation which communicates with the layer 2 processor custom boards form the third level of the hierarchy, with the CPU and peripherals in the subsystem forming the fourth level. They map a behavior described as a system of process onto the architecture template. After allocation, they generate the hardware and software components separately, using the bus as a framework for hardware design and a realtime kernel as the framework for the software components. They developed a large suite of reusable, parameterized subsystem generators to im plement functions ranging from memory subsystems to bus interfaces, to fiberoptics communications. Software components are generated as processes which operate under the control of a realtime executive. In addition, each hardware module has a wrapper software module to provide a software interface. To illustrate the use of their system, they designed a robot control system built from a Sun workstation as the level1 processor, a MC68020 as the level2 processor, and two subsystems each built from a TMS320C30 processor and a DSP32C slave software processes were distributed among the subsystem CPUs to make sure that the realtime controllers deadlines were satisfied. The subsystem CPUs also ran service processes for runtime 10 and data routing. Gabriel SX, a precursor of Ptolemy, is a design en vironment for DSP which supports both simulation and direct execution of functions on processors. The function under design is specified as a block diagram. Gabriels simulation scheduler can simulate the block diagram under synchronous data flow semantics. The same schedule can be used to guide the generation of code for the target DSP an individual operations has assembly language templates to implement the operation on the target machine. system bus L 7 I 1  Fig. 12. A simple hierarchical architecture template. C .  System and HardwareSoftware Partitioning A systems function must be partitioned when it is implemented on either multiple physical units chips or onto heterogeneous units CPUs and ASICs. System partitioning requires some performance information to be able to compute the systems critical performance path, but partitioning should use a simple timing model which can be quickly evaluated while analyzing large partitioning problems. Lagnese and Thomas 55 developed APARTY, a system partitioning tool which partitions a control data flow graph to minimize chip area and interconnect requirements. APARTY uses a multistage clustering algorithm which operates in several stages. Each stage has its own clustering objective, which it uses to cluster nodes in the design. At the end of the stage, clusters of a given size are selected as elements for the next stage of clustering. Ismail et al. U developed an interactive systemlevel partitioning tool. The design is specified as a set of communicating processes the user can specify a sequence of transformationsmove, merge, split, cut, and mapto redesign the process net work. Hardwaresoftware partitioning algorithms try to meet performance goals by implementing some operations in specialpurpose hardware. The hardware unit generally takes the form of a coprocessor, communicating with the CPU over its bus. In some cases, a fairly large set of routines may be implemented totally in hardware to avoid instruction interpretation overhead, but hardwaresoftware partitioning algorithms are targeted to systems in which only a few operations need specialized hardware. However, the computation performed in the coprocessor must be long enough to compensate for the time required to transfer data back and forth to the CPU. If the coprocessors computation is too short, the CPU may be able to perform the operation faster by keeping values in its registers and avoiding bus protocol overhead. Hardwaresoftware partitioning algorithms are closely related to the process scheduling model used for the software side of the implementation. Hardwaresoftware partitioning algorithms generally tar get their hardware design to highlevel synthesis algorithms. Highlevel synthesis generates a registertransfer implemen tation from a behavior description, which may be either a pure data flowgraph or a mixed controldata flowgraph. Synthesis algorithms schedule operations in time and per 9XJ PROCEEDINGS OF THE IEEE, VOL. X2. NO. 7, JULY 1994 form several allocations operations to hardware function units, values to registers, and data transfers to interconnect. Readers interested in highlevel synthesis algorithms can consult books by De Micheli 22, Gajski et al. 29, and Michel et al. 66. Most partitioning algorithms divide the behavior spec ification into a set of software processes running on one CPU and one coprocessor. Two styles of algorithms have been proposed ones which start with all operations in hardware and move some to software and ones which start with everything in software and move some operations to hardware. Gupta and De Micheli 33 developed an algorithm which migrates operations from the hardware partition to the software partition. Their algorithm accepts a behavior in the form of a controldata flowgraph and a set of rate constraints on the constituent operations. It divides the behavior into a set of threads bounded by operations with nondeterministic delays either IO or loops with datadependent bounds. The execution time of each thread depends on whether it will be implemented in hardware or software. Initially, threads which start with a datadependent loop are initially assigned to the software partition and all other threads are assigned to the software partition. Threads are then moved between partitions such that rate constraints are satisfied and CPU and bus utilization constraints are met. Emst et al. 26 developed a partitioning algorithm which identifies critical operations in an instruction stream and moves those operations to hardware. They measure the performance of compiled code to identify execution paths which do not meet their performance requirements. They iteratively refine the partition due to the difficulty of es timating the results of both instruction execution times and highlevel synthesis. At each step, they identify an operation to move to hardware and estimate the speedup gained by moving that operation to hardware. They use an operator table to estimate the hardware speed of the basic operation. Rescheduling an operation may not always result in instruction execution speedup if the next operation depends on other values or pipeline interlocks restrict the execution time of an instruction, the value may sit idle waiting for the instruction stream to catch up. The partitioning algorithm creates a local schedule of operations to check availabilities. Communication time overhead in the basic block is estimated using data flow analysis, counting a constant number of clock cycles per variable. It may also be desirable to map some functions onto existing specialized hardware. ASICs may be divided into two categories a catalog ASIC, such as a cache controller, is designed for a particular function but is described in a catalog a custom ASIC is one of the components being designed for the current system. If the designer is willing to partition parts of the system specification which can be implemented by catalog ASICs, the allocation of those functions to catalog ASIC components is relatively straightforward. If the function must be assembled from several ASICs, the synthesis task is more difficult. Haworth et al. 37 describe part selection algorithms. A related but distinct problem is the design of the hardware and software portions of a device interface given a microcontroller and a set of devices, generate the interface logic and associated driver routines. The main partitioning has been done in this case, but synthesis must determine where additional hardware is required and be able to generate efficient code to control that interface logic. Chou et al. 13 describe one synthesis algorithm for interface design. They use a program as the behavior specification and have models for the devices, the microcontroller, and additional interface components. Their synthesis algorithm recursively allocates operations to microcontroller ports and takes advantage of specialpurpose microcontroller or interface logic functions to improve the implementation. D.  Distributed System Scheduling The scheduling of the processes on the hardware engine clearly influences system cost. The schedule must be chosen to meet hard deadlines and soft performance constraints. If a feasible schedule cannot be found, the designer has several choices use a faster, more expensive hardware engine repartition the software reallocate processes to CPUs in the engine or some combination of the above. Process scheduling over the distributed engine is the measure of feasibility of our hardware engine and software architecture. Femandez and Bussel 27 gave bounds on two problems the number of processors required to execute the process data flowgraph in a given amount of time and the time required to complete a computation on a fixed number of processors. Adam et al.  l   experimentally compared several scheduling heuristics on both benchmark programs and randomly generated examples HFELT highest levels first with estimated times HLFNET highest levels first with no estimated times random SCFET smallest co level first with estimated times and SCFNET smallest colevel first with no estimated times. All these schemes except random are variations of list scheduling in their terminology, the level of a process is measured in the data flowgraph from the graphs sinks while the colevel is measured from the sources. Their experiments showed that HFELT gave the best results and performed close to optimally. Kasahara and Narita 50 proposed extensions on HFELT. Lee et al. 57, 43 proposed two algorithms for scheduling taking interprocessor communication delays into account. ElRewini and Lewis proposed other im provements to the HFELT strategy, taking into account interprocessor communication and contention. Leinbaugh and Yamani 61 developed algorithms to bound the amount of time required to execute a set of processes on a distributed system. Ramamritham et al. 80 developed a heuristic scheduling algorithm for real time multiprocessors. Their algorithm greedily chooses a schedule which ensures that all processes meet their deadlines and minimizes a heuristic cost function their experiments showed that minimizing the sum of minimum deadlinefirst and minimumearlieststarttimefirst gave the best results. WOLF HARDWARESOFTWARE CODESIGN OF EMBEDDED SYSTEMS 985 for k0 icN i sendw.a for iO icM i sendw,b procl La procZi,b P l  s  receivew  lor  id  icN i sendw,a for id icM i procZi.b r  receivew s  receivex P3 single p r w w  dmmpositian Fig. 13. How process partitioning affects distributed system per formance. E. Process Partitioning Process partitioning affects the implementation cost of a software architecturepoor partitioning may delay a computation on one node, causing another processor to be idle while it waits for the result. Figure 13 gives one example of the problem when process p l  computes two values in series, p3 must wait for both values to be computed, which may leave the CPU assigned to p3 idle. If pls computation is split into two parts which are assigned to different processors, p3s processor will be idle for less time. Stalls which reduce CPU utilization may also be introduced by waits for U0 devices, particularly devices like disks which take significant amounts of time to complete a transaction. Huang 41 studied process partitioning for distributed systems which have acyclic data flowgraphs. His algorithm merges dataflow nodes according to a simple set of rules a pair of nodes which both precede and succeed each other are put in the same process if a module Mi precedes all other modules in a process 9, has all preceding, adjacent models in process Pk, or has each noninclusive preceding adjacent module precede the module included in the task with highest precedence, then Mi is included in Pk. This work only considers interprocess communicating delay, not IO overhead. F .  Distributed Process Allocation Process allocation affects system performance in two ways by changing the cost of interprocess communica tion and by changing how tasks sharing a CPU can be scheduled. Figure 14 shows a simple example of allocation for communication. The given process graph shows that PI ,  P2, and P3 all communicate very closely, while P 4  has little communication with the other processes. If, for example, P1 and P4 are put on one processor and P 2  and P3 on another, the three tightly coupled processes will have to communicate over the link between CPU1 and CPU2. That link must have enough bandwidth to support the communication. If P1, P2, and P3 are put on the same CPU, they can communicate via shared memory, which is both faster and cheaper than the communication link. Process allocation can also affect the scheduling of processes on the CPUs, much as scheduling and allocation influence each other in highlevel synthesis. 986 dl process graph processor graph itm P1, P2, P3 P4 or P1, P4 P2, P3 Fig. 14. Process allocation for communication efficiency. Stone 95 developed the first algorithm for allocation of processes to processors on distributed systems. He modeled multiprocessor scheduling as a network flow problem. His formulation can be efficiently solved for two processors, but the formulation becomes more complex and its solution more difficult when there are more processors. Dasarathy and Feridun 19 developed extensions for realtime con straints. Work on distributed system allocation quickly moved to the examination of heuristics which were effective for larger networks. Chu et al. 15 developed heuristics for taking interprocess communication times into account during the allocation process. Chu and Tan 14 developed heuristics to include precedence relations between processes into the optimization task. They did not use the data flowgraph directly, but instead used process size as an approxima tion for important precedence relationshipstheir heuristic assumed that smaller and larger processes are often paired the smaller process precomputes data and smooths the load for the larger process when both are placed on the same CPU. Shen and Tsai 84 used a graphmatching heuristic to allocate processes their algorithm minimized interprocessor communication and balanced system load. Researchers have also studied more computation intensive algorithms for allocation. Ma et al. 63 developed a branchandbound algorithm for process partitioning which minimized the sum of processing and interprocess communication costs. They measured interprocess communication costs by counting the number of data objects sent from one process to another. Peng and Shin 75 developed a branchandbound partitioning algorithm whose objective function was minimization of the maximum normalized task response time. Their algorithm takes into account data dependencies between processes during execution. Gopinath and Gupta 31 applied a combination of static and dynamic techniques to improve processor utilization. They statically analyze process code and assign two predictabilityunpredictability and monotonic itynonmonotonicity values to each process. They estimate PROCEEDINGS OF THE IEEE. VOL. 82. NO. 7. JULY 1994 the mean and standard deviation of the execution time of each process and use that data to move less predictable code earlier in the schedule. They then use software monitors to keep track of actual execution time of processes and adjust the schedule online. V. SUMMARY Embedded computer system design requires intimate knowledge of the interactions between the hardware and software components, even if no custom chips are de signed for the system. In the mainframe world, system analysts constructed large systems for specialized tasks having relatively few choices for hardware i.e., IBM. Microprocessors and ASICs together provide a much larger range of choices for hardware engines than were available to early system analysts. At present, we have a much deeper understanding of the hardware and software design disciplines separately than we do about codesign. While it is possible to design embedded systems as separate hardware and software systems, failure to consider tradeoffs between choice of hardware engine and design of application software can lead to designs that are too expensive, too slow, and never perform as intended. A key element of our understanding of codesign is the study of system modeling in all its forms. We need a deeper understanding of the properties of CPUs, interconnect structures, and software modules. While we have many abstract models of the components of embedded systems, we do not have detailed, accurate models which reflect the idiosyncrasies of those components. It is the peculiarities of components which makes system design challenging and interesting certain properties may cause a certain design to fail to meet a requirement, while other properties may provide an unexpectedly efficient means to meet a goal. Because embedded systems are always designed to cost and performance requirements, a comprehensive understanding of modeling which includes both highlevel and detailed properties of components is essential to making the most of the components available to us. Embedded systems also give us the opportunity for higher level software synthesis than are provided by generalpurpose programming languages. Embedded ap plications give hard constraints, giving clear optimization goalswhile difficult optimization goals require sophisti cated optimization algorithms, it is impossible to optimize a system in the absence of goals. Embedded system designers are more willing than generic programmers to wait for synthesis tools to finish the compilation of embedded system software if those synthesis algorithms truly provide added value. While embedded system designers can get the job done today, they may not always complete new designs as quickly or converge on designs as costeffective as they could if more sophisticated design tools were available. And as powerful microprocessors become even cheaper and come into wider use, the need for tools will increase. A more comprehensive understanding of hardwaresoftware codesign is essential to making use of the computational power provided to us by VLSI. ACKNOWLEDGMENT I would like to thank S. Malik and A. Wolfe of Princeton for any number of lively discussions on embedded system design in general and performance analysis in particular, I would also like to thank to thank A. Dunlop and N. Woo of ATT Bell Laboratories, with whom the author collaborated on early codesign projects. The Tigerswitch design team includes S. Chinatti, R. Koshy, G. Slater and S. Sun. REFERENCES  11 T. L. Adam, K. M. Chandy. and J. R. Dickson, A comparison of list schedules for parallel processing systems, Commun. ACM, vol. 17, no. 2, pp. 685690, Dec. 1974. 2 A. V. Aho, R. Sethi, and J. D. Ullman, Compilers Priniciples, Techniques and Tools, Reading, MA AddisonWesley, 1986. 3 GPS when to buy, Aviation Consumer, pp. 1213, Apr. 1, 1993. 4 R. A. Ballance, A. B. Maccabe, and K. J. Ottenstein, The program dependence web a representation supporting control , data and demanddriven interpretation of imperative lan guages, in Proc. ACM SIGPDWYO Conf. on Programming Language Design and Implementation, pp. 257271, 1990.  5   A. Benveniste and G. Berry, The synchronous approach to reactive and realtime systems, Proc. IEEE, vol. 79, no. 9, pp. 1271282, Sept. 1991. 6  F. Boussinot and R. de Simone, The Esterel language, Proc. IEEE, vol. 79, no. 9, pp. 12931304, Sept. 1991. 7 F. Brooks, The Mythical ManMonth. Reading, MA Addison Wesley, 1975. 8 K. Buchenrieder and C. Veith, CODES A practical concurrent design environment, presented at the 1992 ACMIEEE Int. Workshop on HardwareSoftware CODesign, Estes Park CO, Oct. 1993. 9 J. Buck, S. Ha, E. A. Lee, and D. G. Messerschmitt, Ptolemy A platform for heterogeneous simulation and prototyping, in Proc. I991 European Simulation Conf., June, 1991.  101 M. Burke, An intervalbased approach to exhaustive and in cremental interprocedural dataflow analysis, ACM Trans. Pro gramming Languages and Systems, vol. 12, no 3, pp. 341395, July, 1990.  1 11 M. Chiodo and A. SangiovanniVincentelli, Design methods for reactive realtime systems codesign, presented at the 1992 ACMDEEE Int. WorkshoD on HardwareSoftware CODesign. Estes Park CO, Oct. 199j. 1121 M. Chiodo, P. Giusto. A. Jurecska. M. Marelli. L. Lavagno. H.    Hsieh, and A. SangiovanniVincentelli, A formal specikation model for hardwaresoftware codesign, presented at the Int. Workshop on Hardware Software CODesign, Cambridge MA, Oct. 1993.  131 P. Chou, R. Ortega, and G. Borriello, Synthesis of the hard warehoftware interface in microcontrollerbased systems, in Proc. ICCAD92. IEEE Computer Society Press, 1992, pp. 488495. 14 W. W. Chu and L. M.T. Tan, Task allocation and prece dence relations for distributed realtime systems, IEEE Trans. Comput., vol. C36, no. 6, pp. 667679, June 1987. 15 W. W. Chu, L. J. Holloway, M.T. Lan, and K. Efe, Task allocation in distributed data processing, IEEE Computer, pp. 5769, Nov. 1980. 16 M. A. Cusumano, Japans Software Factories A Challenge to U S .  Management. 17 R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck, An efficient method of computing static single assignment form, SIGPLAN Notices, 1989 from 1989 ACM Principles of Programming Languages Conf.. 18 J. G. DAmbrosio, S .  Hu, and A. Tang, The role of analysis in hardwarehoftware codesign, presented at the 1993 ACMIEEE Int. Workshop on HardwareSoftware CoDesign, Cambridge MA. Oct. 1993. Oxford, UK Oxford Univ. Press, 1991. WOLF HARDWARESOITWARE CODESIGN OF EMBEDDED SYSTEMS 987 19 B. Dasarathy and M. Feridun, Task allocation problems in the synthesis of distributed realtime systems, in Proc. IEEE 1984 RealTime Systems Symp., pp. 135144, 1984. 20 J. V. DAnniballe and P. J. Koopman, Jr., Towards execution models of distributed systems a case study of elevator design, presented at the 1993 ACMDEEE Int. Workshop on Hardware Software CODesign, Cambridge MA, Oct. 1993. 21 A. M. Davis, Software Requirements Analysis and Specifica tion. Englewood Cliffs, NJ Prentice Hall, 1990. 22 G. De Micheli, Synthesis of Digital Circuits. New York McGrawHill, 1994. 23 M. Dorfman and R. H. Thayer, Standards, Guidelines, and Examples on System and Software Requirements Engineering. IEEE Computer Society Press, 1990. 24 P. EinDor and J .  Feldmesser, Attributes of the performance of central processing units a relative performance prediction model, Commun. ACM, vol. 30, no. 4, pp. 308317, Apr. 1987. 25 H. ElRewini and T. G. Lewis, Scheduling parallel program tasks onto arbitrary target machines, J. Parallel Distrib. Com 26 R. Emst, J. Henkel, and Th. Benner, Hardwaresoftware co synthesis for microcontrollers, IEEE Des.  Test of Comput., put., vol. 9, pp. 138153, 1990    vol. 10, no. 4, pp. 6475, Dec. 1993. 1271 E. B. Femandez and B. Bussell, Bounds on the number of . processors and time for multiprocessor optimal schedules, IEEE Trans. Comput., vol. C22, no. 8, pp. 74575 1, Aug. 1973. 28 J. Ferrante, K. J. Ottenstein, and J. D. Warren, The program dependence graph and its use in optimization, ACM Trans. Programm. Languages Syst., vol. 9, no. 3, pp. 319349, July 1987. 29 D. Gajski, N. Dutt, A. Wu, and S. Lin, HighLevel Synthesis In troduction to Chip and System Design. Norwell, MA Kluwer, 1992. 30 N. Gehani and K. Ramamritham, Realtime concurrent C A language for programming dynamic realtime systems, J. RealTime Syst., vol. 3, no. 4, pp. 377405, Dec. 1991. 31 P. Gopinath and R. Gupta, Applying compiler techniques to scheduling in realtime systems, in Proc. 1990 IEEE RealTime Systems Symp., pp. 247256, 1990. 32 A. P. Gupta, W. P. Birmingham, and D. P. Siewiorek, Automating the design of computer systems, IEEE Trans. CADIICAS, vo. 12, no. 4, pp. 473487, Apr. 1993. 33 R. K. Gupta and G. De Micheli, Hardwaresoftware cosynthe sis for digital systems, IEEE Des.  Test Comput., vol. 10, no. 3, pp. 2941 ,  Sept. 1993. 34 D. Harel, Statecharts A visual formalism for complex sys tems, Sci. of Comput. Progr., vol. 8 ,  pp. 231274, 1987. 35 D. Harel, H. Lachover, A. Naamad, A. Pnueli, M. Politi, R. Sherman, A. ShtullTrauring, and M. Trakhtenbrot, STATEM ATE A working environment for the development of complex reactive systems, IEEE Trans. Sofnyare Eng., vol. 16, no. 4, pp. 403414, Apr. 1990. 36 D. J. Hatley and I. A. Pirbhai, Strategies for RealTime System Specification. Dorset House, 1988. 37 M. S. Haworth, W. P. Birmingham, and D. E. Haworth, Optimal part selection, IEEE Trans. CADIICAS, vol. 12, no. 38 J. Hennessy and D. Patterson, Computer Architecture A Quan titative Approach. 39 C. A. R. Hoare, Communicating Sequential Processes. Engle wood Cliffs, NJ PrenticeHall, 1985. 40 C. E. Houstis, Module allocation of realtime applications to distributed systems, IEEE Trans. Software Eng., vol. 16, no. 7, pp. 699709, July 1990. 41 J. P. Huang, Modeling of software partition for distributed realtime applications, IEEE Trans. Software Eng., vol. SEI I ,  no. 10, pp. 11131126, Oct. 1985. 42 R. Hunziker and P. G. Schreier, Field buses compete for en gineers attention. start gaining commercial support, Personal Eng. Instrum. News, vol. 10, no. 8, pp. 3546, Aug. 1993. 43 J.J. Hwang, Y.C. Chow, F. D. Anger, and C.Y. Lee, Sched uling precedence graphs in systems with interprocessor commu nication times, SIAM J. Comput., vol. 18, no. 2, pp. 244257, Apr 1989. 44 T. Ben Ismail, K. OBrien, and A. Jerraya, Interactive system level partitioning with PARTIF, in Proc. EDAC94. IEEE Computer Society Press, 1994. 10, pp. 16111617, Oct. 1993. Morgan Kaufman Pub. 1990. 45 Intel Corp., 80980KB Hardware Design Reference Manual, 46  ,80980KB Microprocessor Programmers Reference Man 47 , Intel Price List, Dec. 1991. 48 Y. Ishikawa, H. Tokuda, and C. W. Mercer, An objectoriented realtime programming language, IEEE Comput., pp. 6673, Oct. 1992. 49 A. Kalavade and E. A. Lee, A hardwaresoftware codesign methodology for DSP applications, IEEE Des.  Test, vol. 10, no. 3, pp. 1628 ,  Sept. 1993. 50 H. Kasahara and S. Narita, Practical multiprocessor schedul ing algorithms for efficient parallel processing, IEEE Trans. Comput., vol. C33, no. 11, pp. 10231029, Nov. 1984. 51 D. B. Kirk, Process dependent static cache partitioning for real time systems, in Proc. 1988 Real Time Systems Symp.. IEEE Computer Society Press, 1988, pp. 181190. 52 , SMART Strategic Memory Allocaiton for RealTime cache design, in Proc. 1989 Real Time Systems Symp., IEEE Computer Society Press, 1989, pp. 229237. 53 D. B. Kirk and J. K. Strosnider, SMART Strategic Mem ory Allocaiton for RealTime cache design using the MIPS R3000, in Proc. 11 th Real Time Systems Symp. IEEE Computer Society Press, 1990, pp. 322330. 54 H. Kobayashi, Modeling and Analysis An Introduction to System Performance Evaluation Methodology Reading, MA AddisonWesley, 1978. 55 E. Dirkes Lagnese and D. E. Thomas, Architectural partition ing of system level synthesis of integrated circuits, IEEE Trans. CADIICAS, vol. 10, no. 7, pp. 847860, July 1991. 56 E. D. Lazowska, J. Zahorjan, G. S. Graham, and K. C. Sev cik, Quantatitive System Performance Computer System Anal ysis Using Queueing Network Models. Englewood Cliffs, NJ PrenticeHall, 1984. 57 C.Y. Lee, J.J. Hwang, Y.C. Chow, and F. D. Anger, Mul tiprocessor scheduling with interprocessor communication de lays, Operations Res. Lett., vol. 7, no. 3, pp. 141147, June 1988. 58 E. A. Lee, W.H. Hu, E. E. Goei, J. C. Bien, and S. Bhat tacharyya, Gabriel A design environment for DSP, IEEE Trans. Acoust., Speech, Signal Process., vol. 37, no. 11, pp. 59 E. A. Lee and D. G. Messerschmitt, Synchronous data flow, Proc. IEEE, vol. 75, no. 9, pp. 12351245, Sept. 1987. 60 D. W. Leinbaugh, Guaranteed response times in a hardreal time environment, IEEE Trans. Software Eng., vol. SE6, no. 61 D. W. Leinbaugh and M. Reza Yamani, Guaranteed response times in a distributed hardrealtime environment, in Proc. 1982 RealTime Systems Symp.. IEEE Computer Society Press, 1982, pp. 157169. 62 C. L. Liu and J. W. Layland, Scheduling algorithms for multiprogramming in a hardrealtime environment, J .  ACM, vol. 20, no. 1, pp. 41, Jan. 1973. 63 P.Y. R. Ma, E. Y. S. Lee, and M. Tsuchiya, A task allocation model for computing systems, IEEE Trans. Comput., vol. C3 1, no. 1, pp. 4147 ,  Jan. 1982. 64 S. Malik and A. Wolfe, Tutorial on embedded systems perfor mance analysis, presented at ICCD93, Cambridge MA, Oct. 1993. 65 E. McRae, Avoiding microcontroller processing pileups, Dr. Dobbs J., pp. 8492, Oct. 1993. 66 P. Michel, U. Lauther, and P. Duzy, Eds., The Synthesis Approach to Digital System Design. Norwell, MA Kluwer, 1992. 67 J. Morfit, A simple software profiler yields big performance gains, Comput. Des., p. 68, Oct. 1992. 68 Motorola, Inc., CPU16 Reference Manual, rev. 1, 1991. 69  , MC68020 23Bit Microprocessor Users Manual, 2nd ed. Jkglewood Cliffs, NJ PrenticeHall, 1985. 70 K. OBrien, T. Ben Ismail, and A. Amine Jerraya, A flexible communication modeling paradigm for systemlevel synthesis, presented at the 1993 ACMIEEE Int. Workshop on Hardware Software CoDesign, Cambridge MA, Oct. 1993. 71 C. Y. Park, Predicting deterministic execution times of real time programs, Ph.D dissertation, Dept. Comput. Science and Eng., University of Washington, Seattle, Aug. 1992. Released as Tech. Rep. 920802. 1989. ual, 1991. 17511762, NOV. 1989. 1, pp. 8591, Jan. 1980. 988 PROCEEDINGS OF THE IEEE, VOL. 82, NO. 7, JULY 1994 72 C. Y. Park and A. C. Shaw, Experiments with a program timing tool based on sourcelevel timing scheme, IEEE Comput., vol. 24, no. 5, pp. 4857, May 1991. 73 M. C. McFarland, A. C. Parker, and R. Camposano, The high level synthesis of digital systems, Proc. IEEE, vol. 78, no. 2, pp. 301318, Feb. 1990. 74 P. Paulin, C. Liem, T. May, and S. Sutarwala, DSP design tool requirements for embedded systems, a telecommunications industrial perspective, accepted for publication in 1. VLSI Signal Process., Spring 1994. 75 D.T. Peng and K. G. Shin, Static allocation of periodic tasks with precedence constraints in distributed realtime systems, in Proc. 9th Int. Conf on Distributed Computing Systems. IEEE Computer Society Press, 1989, pp. 19198. 76 J. L. Peterson, Petri Net Theory and the Modeling of Systems. Englewood Cliffs, NJ PrenticeHall, 1981. 77 L. L. Pollock and M. L. Soffa, An incremental version of iterative data flow analysis, IEEE Trans. Software Eng., vol. 15, no. 12, pp. 15371549, Dec. 1989. 78 S. Prakash and A. C. Parker, SOS Synthesis of application specific heterogeneous multiprocessor systems, J .  Parallel Distributed Comput., vol. 16, pp. 338351, 1992. 79 P. Puschner and Ch. Koza, Calculating the maximum execution times of realtime programs, J. RealTime Syst., vol. 1, pp. 159176, 1989. 80 K. Ramamritham, J. A. Stankovic, and P.F. Shiah, Effi cient scheduling algorithms for realtime multiprocessor sys tems, IEEE Trans. Parallel Distributed Syst., vol. 1, no. 2, pp. 184194, Apr. 1990. 81 C. Rosebrugh and E.K. Kwang, Multiple microcontrollers in an embedded system, Dr. Dobbs J., pp. 4857, Jan. 1992. 82 R. Roth, J. Watkins, M. Hsieh, W. Radke, D. Hejna, R. Tom, and B. Kim, An integrated environment for concurrent devel opment of a pixel processor ASIC and application software, in Proc. ICCD93. IEEE Computer Society Press, 1993, pp. 116125. 83 M. Schmit, Optimizing Pentium code, Dr. Dobbs J., pp. 4049 ,  Jan. 1994. 84 C.C. Shen and W.H. Tsai, A graph matching approach to optimal task assignment in distributed computing systems using a minimax criterion, IEEE Trans. Comput., vol. C34, no. 3, 85 L. Sha, R. Rajkumar, and J. P. Lehoczky, Realtime syn chronization for multiprocessors, in Proc. 9th IEEE Real Time Systems Symp.. IEEE Computer Society Press, 1988, pp. 86 A. C. Shaw, Reasoning about time in higherlevel language software, IEEE Trans. Software Eng . ,  vol. 15, no. 7, July 1989. 87 , Deterministic timing schema for parallel programs, in Proc. 5th Int. Parallel Processing Symp.. IEEE Computer Society Press, 1991, pp. 5663. 88 S. Shlaer and S. J. Mellor, Object Lifecycles Modeling the World in States. Yourdon Press, 1992. 89 Signetics Corp., The 12Cbus and how to use it including specification, Jan. 1992. pp. 197203, Mar. 1985. 259269. 90 A. Smailagic and D. P. Siewiorek, A case study in embedded system design the VuMan 2 wearable computer, IEEE Des.  Test Comput., vol. 10, no. 3, pp. 5667, Sept. 1993. 91 C. U. Smith, Performance Engineering of Sofrware Systems. Reading, MA AddisonWesley, 1990. 92 C. U. Smith, G. A. Frank, and J. L. Cuadrado, An architecture design and assessment system for softwarehardware codesign, in Proc. 22nd Design Automation Conf.. IEEE Computer So ciety Press, 1985, pp. 417424. 93 M. B. Srivastava and R. W. Brodersen, Rapidprototyping of hardware and software in a unified framework, in Proc. ICCAD91. IEEE Computer Society Press, 1991, pp. 152155. 94 M. B. Srivastava, T. I. Blumenau, and R. W. Brodersen, Design and implementation of a robot control system using a unified hardwaresoftware rapidprototyping framework, in Proc. ICCD92. 95 H. S. Stone, Multiprocessor scheduling with the aid of network flow algorithms, IEEE Trans. Sofrware Eng., vol. SE3, no. 1, 96 J. K. Strosnider, Highlyresponsive realtime token rings, Ph.D. dissertation, Dep. Electrical Comput. Eng., Camegie Mellon University, Pittsburgh, PA, Aug. 1988. 97 A. Takach, M. Leeser, and W. Wolf, An automaton model for scheduling constraints in synchronous machines, accepted for publication in IEEE Trans. Comput.. 98 F. K. Teichmann, Airplane Design Manual, 4th ed. New York Pitman, 1958. 99 Texas Instruments, Inc.,TMS320C4x Users Guide, 1991.  1001 W. Wolf, Modern VLSI Design A Systems Approach. Engle wood Cliffs, NJ P T R PrenticeHall, 1994.  lo l l  , Software cache partitioning, accepted for publication in Int. J. Comput. Sofrware Eng.  1021 W. Ye, R. Emst, Th. Benner, and J. Henkel, Fast timing anal ysis for hardwaresoftware cosynthesis, in Proc. ICCD93. IEEE Computer Society Press, 1993. IEEE Computer Society Press, 1992. pp. 8593, Jan. 1977. Wayne H. Wolf Senior Member, IEEE re ceived the B.S., M.S., and Ph.D. degrees in electrical engineering from Stanford University, Stanford, CA, in 1980, 1981, and 1984, respec tively. He is Assistant Professor of Electrical Engi neering at Princeton University, Princeton, NJ. Before joining Princeton University he was with ATT Bell Laboratories, Murray Hill, NJ. His research interests include computeraided design for VLSI and embedded systems as well as Dr. Wolf is a member of Phi Beta Kappa and Tau Beta Pi, and a senior applicationdriven architecture. member of the ACM. WOLF HARDWARESOFTWARE CODESIGN OF EMBEDDED SYSTEMS 989
