IEEE TRANSACTION ON INFORMATION THEORY, VOL. 47, NO. 4, MAY 2001 1423Quantization Index Modulation A Class of ProvablyGood Methods for Digital Watermarking andInformation EmbeddingBrian Chen, Member, IEEE, and Gregory W. Wornell, Senior Member, IEEEAbstractWe consider the problem of embedding one signale.g., a digital watermark, within another host signal to forma third, composite signal. The embedding is designed to achieveefficient tradeoffs among the three conflicting goals of maximizinginformationembedding rate, minimizing distortion between thehost signal and composite signal, and maximizing the robustnessof the embedding.We introduce new classes of embedding methods, termed quantization index modulation QIM and distortioncompensatedQIM DCQIM, and develop convenient realizations in the formof what we refer to as dither modulation. Using deterministicmodels to evaluate digital watermarking methods, we show thatQIM is provably good against arbitrary bounded and fullyinformed attacks, which arise in several copyright applications,and in particular, it achieves provably better rate distortionrobustness tradeoffs than currently popular spreadspectrum andlowbits modulation methods. Furthermore, we show that forsome important classes of probabilistic models, DCQIM is optimal capacityachieving and regular QIM is nearoptimal. Theseinclude both additive white Gaussian noise AWGN channels,which may be good models for hybrid transmission applicationssuch as digital audio broadcasting, and meansquareerrorconstrained attack channels that model privatekey watermarkingapplications.Index TermsData hiding, digital audio broadcasting, dithermodulation, digital watermarking, hybrid transmission, information embedding, quantization index modulation QIM,steganography.I. INTRODUCTIONANUMBER of applications have emerged recently 1 thatrequire the design of systems for embedding one signal,sometimes called an embedded signal or watermark, withinanother signal, called a host signal. The embedding must bedone such that the embedded signal is hidden, i.e., causes noserious degradation to its host. At the same time, the embeddingmust be robust to common degradations of the watermarkedsignalthe watermark must survive whenever the host signalManuscript received June 14, 1999 revised September 20, 2000. This workwas supported in part by MIT Lincoln Laboratory Advanced Concepts Committee, the National Science Foundation under Grant CCR0073520, MicrosoftResearch, and a National Defense Science and Engineering Graduate Fellowship.The authors are with the Department of Electrical Engineering and ComputerScience, Massachusetts Institute of Technology MIT, Cambridge, MA 02139USA email bchenallegro.mit.edu gwwallegro.mit.edu.Communicated by T. E. Fuja, Associate Editor At Large.Publisher Item Identifier S 0018944801028346.does. In some applications these degradations are the result ofbenign processing and transmission in other cases they resultfrom deliberate attacks.Several of these applications relate to copyright notificationand enforcement for audio, video, and images that are distributed in digital formats. In these cases, the embedded signaleither notifies a recipient of any copyright or licensing restrictions or inhibits or deters unauthorized copying. For example,this embedded signal could be a digital fingerprint thatuniquely identifies the original purchaser of the copyrightedwork. If illicit copies of the work were made, all copies wouldcarry this fingerprint, thus identifying the owner of the copyfrom which all illicit copies were made. In another example,the embedded signal could either enable or disable copyingby some duplication device that checks the embedded signalbefore proceeding with duplication. Such a system has beenproposed for allowing a copyonce feature in digital video discrecorders 2. Alternatively, a standardscompliant player couldcheck the watermark before deciding whether or not to playthe disc 3.Other applications include automated monitoring of airplayof advertisements on commercial radio broadcasts. Advertiserscan embed a digital watermark within their ads and count thenumber of times the watermark occurs during a given broadcast period, thus ensuring that their ads are played as often aspromised. In other applications, the embedded signal may beused for authentication ofor detection of tampering withthehost signal. For example, a digital signature could be embeddedin a military map. A number of other national security applications are described in 4 and include covert communication,sometimes called steganography or low probability of detection communication, and socalled traitor tracing, a version ofthe digital fingerprinting application described above used fortracing the source of leaked information.One final application for which the digital watermarkingmethods developed in this paper are wellsuited is the backwardcompatible upgrading of an existing communicationsystem, an example of which is the socalled hybrid inbandonchannel digital audio broadcasting 5, 6. In this application, one would like to simultaneously transmit a digitalsignal with existing analog AM andor FM commercialbroadcast radio without interfering with conventional analogreception. Thus, the analog signal is the host signal and thedigital signal is the watermark. Since the embedding doesnot degrade the host signal too much, conventional analogreceivers can demodulate the analog host signal. In addition,001894480110.00  2001 IEEE1424 IEEE TRANSACTION ON INFORMATION THEORY, VOL. 47, NO. 4, MAY 2001nextgeneration digital receivers can decode the digital signalembedded within the analog signal, which may be all or partof a digital audio signal, an enhancement signal used to refinethe analog signal, or simply supplemental information such asstation identification or traffic information. More generally,the host signal in these hybrid transmission systems could besome other type of analog signal such as video 7, or even adigital waveformfor example, a digital pager signal could beembedded within a digital cellular telephone signal.In general, designers of information embedding systems forthese kinds of applications seek to achieve high embedding rateswith high levels of robustness and low levels of embeddinginduced distortion. However, in general, these three goals are conflicting. Thus, in this paper we characterize methods in termsof the efficiency with which they trade off rate, distortion, androbustness. For instance, for any minimum embedding rate requirement and maximum acceptable level of embedding distortion, the more efficient an embedding method is, the higher therobustness that can be achieved.A great many informationembedding algorithms have beenproposed 1 in this still emerging field. Some of the earliestproposed methods 8, 9, 7 employ a quantizeandreplacestrategy after first quantizing the host signal, these systemschange the quantization value to embed information. A simpleexample of such a system is the socalled lowbits modulationLBM, where the least significant bits in the quantization ofthe host signal are replaced by a binary representation of the embedded signal. More recently, additive spreadspectrumbasedmethods, which embed information by linearly combining thehost signal with a small pseudonoise signal that is modulatedby the embedded signal, have received considerable attention inthe literature as an alternative to LBMtype methods 1013.In this paper, we show that both LBMtype strategies andadditive spread spectrum are, in general, not good choices formost information embedding and digital watermarking applications. As an alternative, this paper introduces a new class ofinformationembedding strategies we refer to as quantizationindex modulation QIM that is, in general, preferable and inmany specific scenarios optimal. We further develop computationally efficient implementations of QIM in the form of whatwe refer to as dither modulation. We evaluate both specific realizations of uncoded and coded QIM, and the asymptotic performance limits of coded QIM using informationtheoretic analysis. Other emerging informationtheoretic results on the digitalwatermarking problem are developed in, e.g., 1420.The specific organization of the paper is as follows. In Section II, we develop two useful equivalent models for the informationembedding problem. In Section III, we classify traditional approaches to this problem, and in the process identify some of their shortcomings. Section IV introduces the QIMclass of embedding methods, and Section V develops practicalrealizations that are compared to corresponding implementations of traditional approaches. Next, Section VI establishesconditions under which different forms of QIM are optimal inan informationtheoretic sense. We then evaluate the methods ofthis paper in the context of Gaussian models for unintentionalattacks in Section VII, and in the context of some general intenFig. 1. General informationembedding problem model. A message m isembedded in the hostsignal vector using some embedding function   m.A perturbation vector corrupts the composite signal . The decoder extractsan estimate m of m from the noisy channel output .tional attack models in Section VIII. Finally, Section IX contains some concluding remarks.II. PROBLEM MODELTwo mathematically equivalent models for the informationembedding problem are useful in our development.A. DistortionConstrained Multiplexing ModelThe informationembedding problem is naturally and generally described by Fig. 1. In this figure, there is a hostsignalvector into which we wish to embed some information .1 We wish to embed at a rate of bits per dimensionhostsignal sample so we can think of as an integer in theset .An embedding function maps the host signal and embeddedinformation to a composite signal subject to somedistortion constraint. Various distortion measures may be of interest, an example of which is the squarederror distortion1or its expectation . The composite signal issubjected to various common signal processing manipulationssuch as lossy compression, addition of random noise, andresampling, as well as deliberate attempts to remove theembedded information. These manipulations occur in somechannel, which produces an output signal . For futureconvenience, we define a perturbation vector to be the difference , as shown in Fig. 1 we consider cases of bothsignalindependent and signaldependent perturbation vectorsin this paper.A decoder extractsi.e., forms an estimate ofthe embedded information based on the channel output . We focusprimarily on the hostblind case of interest in most applications, where is not available to the decoder, in contrast to theknownhost case, where the decoder can separately observe. See, e.g., 14 17 for informationtheoretic treatments ofsome aspects of the knownhost case. Our interest is in decoders that produce reliable estimates whenever the channel isnot too severe, where reliable means either that deterministically or that for sufficiently small . In1The vector is any convenient representation of all or part of the host signal.In the case of a host image, it could be a vector of pixel values or discrete cosinetransform DCT coefficients, for example. In the case of a host audio waveform,this vector could be a vector of samples, spectral parameters, or linear predictioncoding LPC coefficients, for example.CHEN AND WORNELL QUANTIZATION INDEX MODULATION 1425such cases, the tolerable severity of the channel degradations is ameasure of the robustness of an informationembedding system.B. Equivalent SuperChannel ModelAn alternative representation of the model of Fig. 1 isshown in Fig. 2. The two models are equivalent since anyembedding function can be written as the sum of thehost signal and a hostdependent distortion signal ,i.e., , simply by defining the distortionsignal to be . Thus, one can viewas the input to a superchannel that consists of the cascadeof an adder and the true channel. The host signal is astate of this superchannel that is known at the encoder. Themeasure of distortion between the composite andhost signals maps onto a hostdependent measure of the sizeof the distortion signal . For example,squarederror distortion 1 equals the power ofTherefore, one can view informationembedding problems aspowerlimited communication over a superchannel with a statethat is known at the encoder.2 As we will develop, this view willbe convenient for determining achievable rate distortionrobustness tradeoffs of various informationembedding and decodingmethods.C. Channel ModelsIn general, the channel model is either a characterization ofthe degradations that can actually occur to the composite signal,or alternatively, a description of the class of degradations towhich the embedder and decoder must be robust, i.e., the systemis designed to work against all degradations described by thisparticular model. The latter viewpoint is particularly useful inthe context of intentional attacks.We consider both probabilistic and deterministic channelmodels. In the probabilistic case, we specify the channelinputoutput relationship in terms of the conditional probability law . Implicitly, this specification also describes theconditional probability law of the perturbation vectors againstwhich the system must be robust sinceIn the deterministic case, the channel inputoutput relationshipis described most generally in terms of the set of possible outputs for every given input, or equivalently, in termsof the set of desired tolerable perturbation vectors forevery given input.III. CLASSES OF EMBEDDING METHODSAn extremely large number of embedding methods have beenproposed in the literature 22, 23, 1. Broadly, for our purposes these can be divided into two classes 1 hostinterference nonrejecting methods and 2 hostinterference rejectingmethods.2Cox et al. have also recognized that one may view watermarking as communications with side information known at the encoder 21.Fig. 2. Equivalent superchannel model for information embedding. Thecomposite signal is the sum of the host signal, which is the state of thesuperchannel, and a hostdependent distortion signal.Hostinterference nonrejecting methods have the generalproperty that the host signal is effectively a source of interference in the system, and generally result from system designsthat do not allow the encoder in Fig. 2 to sufficiently exploitknowledge of the host signal .The simplest of such methods have purely additive embedding functions of the form2where is typically a pseudonoise sequence. Such embedding methods are often referred to as additive spreadspectrum methods, and some of the earliest examples are describedin 24, 25, 10, 26, 11, 12. Typically, takes theform3where is a unitenergy spreading vector and is a scalarfunction of the message.3It is often convenient to view additive spreadspectrum as perturbation of a projection. In particular, substituting 3 into 2and using that has unit energy, we obtain4which when projected onto we obtain5where is the corresponding projection of the host signal, i.e.,6Finally, substituting 5 back into 4 yields the composite signalreconstruction from projections7From 2, we see that for this class of embedding methods,the host signal acts as additive interference that inhibits the decoders ability to estimate . Consequently, even in the absenceof any channel perturbations , one can usually embedonly a small amount of information. Thus, these methods areuseful primarily when either the host signal is available at thedecoder as assumed in, e.g., 26 or when the hostsignal interference is much smaller than the channel interference.3Technically, spreadspectrum systems 2 for which 3 applies are classifiedas amplitudemodulation additive spreadspectrum methods, but since there isno risk of confusion in this paper, we will use the term additive spreadspectrum to specifically mean those systems based on amplitude modulation.1426 IEEE TRANSACTION ON INFORMATION THEORY, VOL. 47, NO. 4, MAY 2001Information embedding systems can achieve hostinterference rejection when knowledge of the host signal at the encoder is adequately exploited in system design. Examples include LBM and, more generally, quantizeandreplace systems.In LBM systems, the least significant bits in the binary representation of a host sample are simply replaced with messagebits. A class of quantizeandreplace systems that we refer toas generalized LBM systems implement a vector generalizationof this embedding strategy. Generalized LBM embedding functions are of the form8where represents the coarse quantizer that determines themost significant bits, and is determined only by the modulated least significant bits. A defining characteristic of generalized LBM systems is that the embedding never alters the mostsignificant bits of the host signal, which is expressed in terms ofthe constraint9Without loss of generality, we may assume that good generalized LBM quantizers are unbiased, i.e.,10One example of a generalized LBM system is that developedin 7, where LBM is effectively applied to a pseudorandomprojection of the form 6. Thus, the embedding is of the form7 where is now of the form11with a uniform, scalar quantization function of step sizeand a perturbation value. It is convenient to think of thisclass of generalized LBM systems as spread LBM systems.While generalized LBM systems are hostinterference rejecting, they are unnecessarily constrained in a way that makesthem generally inefficient and vulnerable to various classes ofattacks, which in turn limits the range of applications for whichthey can be used. Avoiding these constraints in the process ofdeveloping optimal informationembedding systems naturallygives rise to a new and general class of hostinterferencerejecting embedding methods called QIM, which we developin the sequel.IV. QUANTIZATION INDEX MODULATIONTo develop the QIM concept, we begin by viewing the embedding function as an ensemble of functions of , indexedby . We denote the functions in this ensemble as toemphasize this view. If the embeddinginduced distortion is tobe small, each function in the ensemble must be close to an identity function in some sense so that12That the system needs to be robust to perturbations suggeststhat the points in the range of one function in the ensembleshould be far away in some sense from the points in the rangeFig. 3. QIM for information embedding. The points marked withs andsbelong to two different quantizers, each with its associated index. The minimumdistance d measures the robustness to perturbations, and the sizes of thequantization cells, one of which is shown in the figure, determine the distortion.If m  1, the host signal is quantized to the nearest . If m  2, the hostsignal is quantized to the nearest.of any other function. For example, one might desire at the veryleast that the ranges be nonintersecting. Otherwise, even in theabsence of any perturbations, there will be some values of fromwhich one will not be able to uniquely determine . In fact, it isprecisely the nonintersection property that leads to hostsignalinterference rejection.The nonintersection property along with the approximateidentity property 12, which suggests that the ranges of eachof the functions cover the space of possible or at least highlyprobable hostsignal values , suggests that the functions bediscontinuous. Quantizers are just such a class of discontinuous,approximateidentity functions. Then, QIM refers to embedding information by first modulating an index or sequence ofindices with the embedded information and then quantizing thehost signal with the associated quantizer or sequence of quantizers.Fig. 3 illustrates this QIM informationembedding technique.In this example, one bit is to be embedded so that .Thus, we require two quantizers, and their corresponding setsof reconstruction points in are represented in Fig. 3 withs and s. If , the host signal is quantized with thequantizer, i.e., is chosen to be the closest to . If ,is quantized with the quantizer.As varies, the composite signal value varies from onepoint   to another or from one point to another, but it never varies between a point and a point. Thus,even with an infinite energy host signal, one can determineif channel perturbations are not too severe. The points andpoints are both quantizer reconstruction points and signal constellation points,4 and we may view design of QIM systems asthe simultaneous design of an ensemble of source codes quantizers and channel codes signal constellations.Conveniently, properties of the quantizer ensemble can be related directly to the performance parameters of rate, distortion,and robustness. For example, the number of quantizers in theensemble determines the informationembedding rate . Thesizes and shapes of the quantization cells determine the embeddinginduced distortion, all of which arises from quantization4One set of points, rather than one individual point, exists for each value ofm.CHEN AND WORNELL QUANTIZATION INDEX MODULATION 1427error. Finally, for many classes of channels, the minimum distance13between the sets of reconstruction points of different quantizersin the ensemble effectively determines the robustness of the embedding.5It is important to emphasize that, in contrast to the case wherethe host signal is known at the receiver, the minimumdistancedecoder needs to choose from all reconstruction points of thequantizers, not just those corresponding to the actual host signal. In particular, the minimumdistance decoder makes decisionsaccording to the rule614If, which is often the case, the quantizers map to thenearest reconstruction point, then 14 can be rewritten as15While the minimumdistance decoder is especially convenientto implement and analyze, a variety of other potentially usefuldecoders are discussed in 27.Intuitively, the minimum distance measures the size of perturbation vectors that can be tolerated by the system. For example,if channel perturbations are bounded according to716then the minimumdistance decoder is guaranteed to not makean error as long as17In the case of a classical additive white Gaussian noise AWGNchannel with a noise variance of , at high signaltonoise ratioSNR the minimum distance also characterizes the error probability of the minimumdistance decoder 28,5When the host signal is known at the decoder, as is the case in some applications of interest, then the more natural minimum distance isd x  min ksx i sx jkord  min min ksx i sx jk6Alternatively, if the host signal x is known at the decoderm  x  argmin k  sx mk7We refer to this as the bounded perturbation channel and will revisit thisdeterministic channel in Section VIIIB1.where is the Gaussian function18A. DistortionCompensated QIMDistortion compensation is a type of postquantization processing that can improve the achievable rate distortionrobustness tradeoffs of QIM methods. To see this, we begin by notingthat for a fixed rate and a given quantizer ensemble, scaling8 allquantizers by increases by a factor of , therebyincreasing the robustness of the embedding. However, the embeddinginduced distortion also increases by a factor of .Adding back a fraction of the quantization error to thequantization value removes, or compensates for, this additionaldistortion. The resulting embedding function is19where is the th quantizer of an ensemblewhose reconstruction points have been scaled by so that tworeconstruction points separated by a distance before scalingare separated by a distance after scaling. The first term in19 represents normal QIM embedding. We refer to the secondterm as the distortioncompensation term.The quantization error added back is a source of interference to the decoder. Typically, the probability density functionspdfs of the quantization error for all quantizers in the QIM ensemble are similar. Therefore, the distortion compensation termin 19 is effectively statistically independent of and can betreated as independent noise. Thus, decreasing leads to greaterminimum distance, but for a fixed embeddinginduced distortion, the distortioncompensation interference at the decoder increases. One optimality criterion for choosing is to maximizethe following SNR at the decision deviceSNRwhere this SNR is defined as the ratio between the squaredminimum distance between quantizers and the total interference energy from both distortioncompensation interferenceand channel interference. Here, is the minimum distancewhen and is a characteristic of the particular quantizerensemble. One can easily verify that the optimal scalingparameter that maximizes this SNR isDNRDNR20where DNR is the embeddinginduced distortiontonoiseratio .As we will see, suitably coded versions of this distortioncompensated QIM with precisely the parameter setting 20 alsohave important asymptotic optimality properties. Before developing these properties, let us first investigate some constraints8If a reconstruction point is at q, it is scaled by  by moving it to q.1428 IEEE TRANSACTION ON INFORMATION THEORY, VOL. 47, NO. 4, MAY 2001that are useful to impose on QIM systems to facilitate implementation.V. DITHER MODULATION AN IMPLEMENTATION OF QIMA key aspect of the design of QIM systems involves thechoice of practical quantizer ensembles for such systems,which we now explore. In the process, we obtain additionalinsights into the design, performance evaluation, and implementation of QIM embedding methods, particularly those oflow complexity. A convenient structure to consider is thatof socalled dithered quantizers 29, 30, which have theproperty that the quantization cells and reconstruction pointsof any given quantizer in the ensemble are shifted versions ofthe quantization cells and reconstruction points of any otherquantizer in the ensemble. In nonwatermarking contexts, theshifts typically correspond to pseudorandom vectors calleddither vectors. For informationembedding purposes, the dithervector can be modulated with the embedded signal, i.e., eachpossible embedded signal maps uniquely onto a different dithervector . The host signal is quantized with the resultingdithered quantizer to form the composite signal. Specifically,we start with some base quantizer , and the embeddingfunction isWe call this type of information embedding dither modulation. We discuss several lowcomplexity realizations of suchdithermodulation methods in the sequel.A. Coded Binary Dither Modulation with Uniform ScalarQuantizationCoded binary dither modulation with uniform, scalar quantization is one such realization.9 We assume that .The dither vectors in a coded binary dither modulation systemare constructed as follows.i The information bits representing the embedded message are errorcorrectioncoded using a rate code to obtain a coded bit sequence , where21In the uncoded case, and . We divide the host signal into nonoverlapping blocks oflength and embed the th coded bit in the th block,as described below.ii Two length dither sequences and andone length sequence of uniform, scalar quantizerswith step sizes are constructed with theconstraint9By scalar quantization, we mean that the highdimensional base quantizerq is the Cartesian product of scalar quantizers.This constraint ensures that the two correspondingdimensional dithered quantizers are the maximumpossible distance from each other. For example, apseudorandom sequence of and its negativesatisfy this constraint. One could alternatively choosepseudorandomly with a uniform distribution over.10 Also, the two dither sequences neednot be the same for each length block.iii The th block of is quantized with the dithered quantizerusing the dither sequence .A detailed assessment of the complexity of this QIM realization is developed in 15, 27.The minimumdistance properties of coded binary dithermodulation are readily deduced. In particular, any two distinctcoded bit sequences differ in at least places, where isthe minimum Hamming distance of the errorcorrection code.For each of these blocks, the reconstruction points of thecorresponding quantizers are shifted relative to each other byin the th dimension. Thus, the square of the minimumdistance 13 over all dimensions is22where to obtain the second equality we have used 21, andwhere, in the third line, is the gain of the errorcorrectioncode23In the high signaltodistortion ratio SDR regime of primaryinterest for highfidelity applications, the quantization cells aresufficiently small that the host signal can be modeled as uniformly distributed within each cell. In this case, the expectedsquarederror distortion of a uniform, scalar quantizer with stepsize is the familiar24Thus, the overall average expected distortion 1 is25Combining 22 and 25 yields the distortionnormalizedsquared minimum distance2610A uniform distribution for the dither sequence implies that the quantizationerror is statistically independent of the host signal and leads to fewer falsecontours, both of which are generally desirable properties from a perceptualviewpoint 29.CHEN AND WORNELL QUANTIZATION INDEX MODULATION 1429Fig. 4. Dither modulation with uniform quantization step sizes.a quantity that can be used to characterize the achievable performance of QIM realizations more generally, as we will develop.B. SpreadTransform Dither ModulationOne special class of coded binary dither modulation methodsis what we refer to as spreadtransform dither modulationSTDM. We now develop its properties and quantify itsadvantages over other forms of dither modulation, over additivespreadspectrum methods, and over spread LBM.To introduce STDM, we begin by observing that the distortionnormalized squared minimum distance 26 of binarydither modulation with uniform scalar quantization does not depend on the sequence , i.e., on the distribution of the distortion across samples within the length block. Thus, one isfree to choose any distribution without sacrificing , so thes can be chosen to optimize other characteristics of the embedding.To understand this property, consider Figs. 46, each of whichshow the reconstruction points of two quantizers for embeddingone bit in a block of two samples. For each of the three systems,the minimum distance and the average squarederrordistortion per sampleare identical. Thus, the robustness against bounded perturbations is the same in each case.However, the quantization differs in each case. In Fig. 4, wherescalar quantization is applied to each sample separately, thequantization step sizes are the same for both samples. In Figs. 5and 6, the samples are first pretransformed and the resulting coefficients quantized unevenly. In particular, a unitary transformcoordinate rotation is applied to the pair of samples beforequantization the first transform coefficient is the component ofthe host signal in the direction of depicted. In Fig. 5, the stepsize for quantizing the first transform coefficient is larger thanthat used to quantize the second transform coefficient, whichlies in the direction orthogonal to . Finally, in the extreme caseof Fig. 6, the step size for the first coefficient is larger still, andthat for the second coefficient is zero, i.e., all embedding occursin the first coefficient. In this case, the reconstruction points become reconstruction lines, so to embed a bit, the host signalis quantized to the nearest point on a line labeled with a . Toembed a bit, the host signal is quantized to the nearest pointon a line labeled with a .Fig. 5. Transform dither modulation with nonuniform quantization step sizes.Fig. 6. Transform dither modulation with quantization of only a singletransform component. The quantization step size for the component of the hostsignal orthogonal to v is zero.While the three systems corresponding to Figs. 46 have thesame minimum distance, the number of perturbation vectors ofminimum length that cause decoding errors is higher for the caseof Fig. 4 than for the case of Fig. 6. For intermediate casessuch as the one shown in Fig. 5, where quantization step sizesin different dimensions are different but nonzero, the numberof perturbation vectors of minimum length that cause decodingerrors is the same as in Fig. 4, but these vectors are not orthogonal. Thus, for probabilistic channels, such as additive noisechannels, the probability of error is generally different in eachcase. For example, suppose a bit is embedded and the composite signal is the point labeled with in Figs. 4 and 6. If thechannel output lies in the decision region defined by the dashedbox in Fig. 4 and defined by the two dashed lines in Fig. 6, thenthe decoder will correctly determine that a bit was embedded.If the perturbation vector places the channel output outside thedecision region, however, the decoder will make an error withvery high probability. There is some possibility that the channeloutput is outside the decision region but is still closer to apoint other than than to the closest . These events, however,are very unlikely for many perturbation probability distributionsthat are of practical interest. Since the decision region of Fig. 61430 IEEE TRANSACTION ON INFORMATION THEORY, VOL. 47, NO. 4, MAY 2001contains the decision region of Fig. 4, it follows that the probability of a correct decision in the case of nonuniform quantization step sizes is higher.The unitary transform in the case of Fig. 6 not only facilitatesa comparison of Figs. 4 and 6, but also serves to spread any embeddinginduced distortion over frequency and timespace whena peak distortion constraint is imposed, for example. Althoughthe distortion is concentrated in only one transform coefficient,if the energy of is spread over spacetime and frequencyforexample, if is chosen pseudorandomlythen the distortionwill also be spread.As we will see in subsequent sections of this paper, dithermodulation methods have considerable performance advantagesover previously proposed additive spreadspectrum and spreadLBM methods in a variety of contexts. However, much effort hasalready been invested in optimizing both additive spreadspectrum and spread LBM systems, for example, by exploiting perceptual properties of the human visual and auditory systems ordesigning receiver frontends to mitigate effects of geometricand other distortions. An additional advantage of STDM specifically over other forms of dither modulation is that one can easilyconvert existing additive spreadspectrum and spread LBM systems into STDM systems while retaining the other optimizedcomponents of the system. In particular, it suffices to replace theaddition step of additive spread spectrum, i.e., 5, or the quantizeandreplace step of spread LBM, i.e., 11, with the ditheredquantization step of STDM, i.e.,27SNR Advantage of STDM In this section, we quantify theperformance gain of STDM over additive spread spectrum andspread LBM from an SNR perspective that applies to a broadrange of contexts. We focus our analysis on the representativecase of embedding one bit in a length block using a unitlength spreading vector . Because, as 5, 11, and 27 reflect, in each case the embedding occurs entirely in the projection of onto , a onedimensional problem results. In addition,because all of the embeddinginduced distortion occurs only inthe direction of , the distortion in each case also has the sametemporalspatial distribution and frequency distribution. Thus,one would expect that any perceptual effects due to timespacemasking or frequency masking are the same in each case. Therefore, squarederror distortion and SNRtype measures are moremeaningful measures of distortion when comparing these embedding methods than one might expect in other more generalcontexts where squarederror distortion may fail to capture certain perceptual effects.SNR avantage of STDM over additive spread spectrum Considering the case of additive spreadspectrum first,since in 5, we have28For STDM 2729where so that the expected distortion in bothcases is the same, and where we have used the fact thatand are chosen such that .The decoder in both cases makes a decision based on , theprojection of the channel output onto . In the case of additivespread spectrum, , while in the case of STDM,, where is the projection of the perturbationvector onto . We let be some measure of energy. Forexample, in the case of a deterministic variable , orwhen is random. The energy of the interferenceor noise is for additive spread spectrum, but onlyfor STDM, i.e., the hostsignal interference for STDM iszero. Thus, the SNR at the decision device isSNRfor additive spread spectrum andSNRfor STDM, where the signal energiesandare given by 28 and 29. Thus, the advantage of STDM overadditive spread spectrum isSNRSNR30which is typically very large since the channel perturbationsare usually much smaller than the host signal if the channeloutput is to be of reasonable quality. For example, if the hostsignaltochannelnoise ratio is 30 dB and and are uncorrelated, then the SNR advantage 30 of STDM over additivespread spectrum is 28.8 dB.11SNR advantage of STDM over spread LBM Spreadtransform dither modulation methods also have an SNR advantageover spread LBM methods. As we show in Appendix A, thedistortionnormalized squared minimum distance 26 of LBMis 2.43 dB worse than that of dither modulation in thecase of coded binary embedding with uniform, scalar quantization. Thus, for a fixed rate and embeddinginduced distortion,the squaredminimum distance, and hence the SNR at the decision device, for spread LBM will be 2.43 dB worse than that ofSTDM, i.e.,12SNRSNR2.43 dB 31This SNR advantage is illustrated in Fig. 7, where the quantizerreconstruction points and embedding intervals for both spread11Note that while the high SDR approximation 30 predicts that STDM isworse than additive spread spectrum by a factor of 43  1.25 dB when x  0as would be the case, for example, if the host signal had very little energy inthe direction of v, in fact, if one chooses dm  4 then it is straightforward to verify that STDM performs as well as additive spread spectrum in thislow SDR regime.12Appendix A also shows that for M ary embedding the SNR gain grows to2 3 dB as M  1.CHEN AND WORNELL QUANTIZATION INDEX MODULATION 1431Fig. 7. Spreadtransform dither modulation versus spread LBM. Theembedding interval boundaries of spread LBM, which are shown with solidlines, are the same for both  points and points. In contrast, in the case ofSTDM, the point embedding intervals, shown by solid lines, differ from thepoint embedding intervals, shown by dashed lines. An SNR advantage of74  2.43 dB for STDM results.LBM and STDM are shown, with the same embeddinginducedsquarederror distortion for both cases.The preceding analysis establishes some important advantages of QIM methods over common informationembeddingmethods. In fact, it turns out that QIM methods are asymptotically optimal in many key scenarios of interest. To develop theseresults, we next examine information embedding within an informationtheoretic framework.VI. INFORMATIONTHEORETIC OPTIMALITY OF QIMThis section explores the best possible ratedistortionrobustness performance that one could hope to achieve with any informationembedding system. Our analysis leads to insights aboutsome properties and characteristics of good informationembedding methods, i.e., methods that achieve performance closeto the informationtheoretic limits. In particular, a canonicalhidden QIM structure emerges for information embeddingthat consists of 1 preprocessing of the host signal, 2 QIM embedding, and 3 postprocessing of the quantized host signal toform the composite signal. One incurs no loss of optimalityby restricting ones attention to this simple structure. We alsoderive sufficient conditions under which only distortion compensation postprocessing is required. As we develop in Sections VII and VIII, these conditions are satisfied in several important cases of practical interest.A. Communication over Channels with Side InformationThe superchannel model of Section IIB and Fig. 2 facilitatesour analysis, i.e., we view information embedding as the transmission of a hostdependent distortion signal over a superchannel with side information or state that is known at the encoder. In this section, we also restrict our attention to a squarederror distortion constraintand a memoryless channel with known pdfwhere and are the th components of and , respectively.13Then, the superchannel is also memoryless and has probabilitylawThe capacity 31 of this superchannel is the reliable informationembedding rate that is asymptotically achievable withlong signal lengths .In nonwatermarking contexts, Gelfand and Pinsker 32 andHeegard and El Gamal 33 have determined the capacity ofsuch a channel in the case of a random state vector with independent and identically distributed i.i.d. components when theencoder sees the entire state vector before choosing the channelinput . In this case, the capacity is32where denotes mutual information and is an auxiliaryrandom variable. Since we can think ofin 32 as being generated from , and, in turn, from and .While the mapping from to is, in general, probabilistic, fromconvexity properties of mutual information, one can deduce thatthe maximizing distribution in 32 always has the property thatis a deterministic function of 32.In the case of watermarking, the maximization 32 is subjectto a distortion constraint . A formal proof of the extension of 32 to include this constraint is developed in 20.Other researchers 18, 19, 16 are working on extending orhave extended these results to the case where the channel lawis not fixed but rather is chosen by an attacker subject to adistortion constraint. A related informationtheoretic formulation can be found in 14.As we shall see in the next section, one way to interpret 32is that is the total number of bits per hostsignal samplethat can be transmitted through the channel, and is thenumber of bits per sample that are allocated to the host signal .The difference between the two is the number of bits per hostsignal sample that can be allocated to the embedded information.1 Hidden QIM As we show in this subsection, one canachieve the capacity 32 by a type of hidden QIM, i.e., QIMthat occurs in a domain represented by the auxiliary randomvariable . One moves into and out of this domain with preand postquantization processing.13Extension of results in this section to the case where the channel is onlyblockwise memoryless is straightforward by letting y and s be the ith blocks,rather than ith scalar components, of y and s. In this case, information rates aremeasured in bits per block, rather than bits per sample.1432 IEEE TRANSACTION ON INFORMATION THEORY, VOL. 47, NO. 4, MAY 2001Fig. 8. Capacityachieving hidden QIM. One embeds by choosing acodeword u that is jointly distortiontypical with from the mth quantizerscodebook. The distortion function is e u x. The decoder finds a codewordthat is jointly typical with . If this codeword is in the ith subset, then m  i.To develop this optimality of hidden QIM, we begin byadding an interpretation in terms of quantization sourcecoding to the proof of the achievability of capacity by Gelfandand Pinsker 32, the result of which is summarized as follows. Fig. 8 shows an ensemble of quantizers, where, where each source codewordquantizer reconstruction vector is randomly drawn fromthe i.i.d. distribution , which is the marginal distributioncorresponding to the hostsignal distribution and the maximizing conditional distribution from 32. Althoughthe source codebooks are, therefore, random, both the encoderand decoder, of course, know the codebooks. Each codebookcontains codewords so there arecodewords total.QIM embedding in this domain corresponds to finding avector in the th quantizers codebook that is jointly distortiontypical with and generatingBy distortiontypical, we mean that and are jointly typicaland , i.e., the function is thedistortion function in the domain. Since the th quantizerscodebook contains more than codewords, the probability that there is no that is jointly distortiontypical withis small.14 Thus, the selection of a codeword from the thquantizer is the quantization part of QIM, and the generation of, and, therefore, , from the codeword and is thepostquantization processing.The decoder finds a that is jointly typical with the channeloutput and declares if this is in the th quantizerscodebook. Because the total number of codewords, is less than, the probability that a other than is jointly typicalwith is small. Also, the probability that is jointly typical with14This principle is, of course, one of the main ideas behind the ratedistortiontheorem 31, Ch. 13.is close to .15 Thus, the probability of error issmall, and we can indeed achieve the capacity 32 with QIM inthe domain.The remaining challenge, therefore, is to determine the rightpreprocessing and postprocessing given a particular channelattack . As mentioned above, for a number of importantcases, it turns out that the only processing required is postquantization distortion compensation. We discuss these cases in thenext subsection.2 Optimality of DistortionCompensated QIM Whendistortioncompensated QIM DCQIM as introduced in Section IVA is viewed as an instance of hidden QIM, we obtainthat is a quantized version of . We show in this sectionthat suitably coded versions DCQIM can achieve capacitywhenever the maximizing distribution in 32 is of aform such that the postprocessing is linear, i.e., when, withoutloss of generality, is generated according to33To see that DCQIM can achieve capacity when the maximizing pdf in 32 satisfies 33, we show that one can constructan ensemble of random DCQIM codebooks that satisfy 33.First, we observe that quantizing is equivalent to quantizingwith a scaled version of the quantizer and scaling back theresult, i.e.,34where is as defined following 19. Then, rearrangingterms in the DCQIM embedding function 19 and substituting34 into the result, we obtain35We construct our random DCQIM codebooks by choosingthe codewords of from the i.i.d. distribution ,the one implied by the maximizing pdf in 32 together withthe host pdf . Equivalently, we choose the codewords ofin 19 from the distribution of . Our quantizers choose a codeword that is jointly distortiontypical with . The decoder looks for a codeword in allof the codebooks that is jointly typical with the channel output.Then, following the achievability argument of Section VIA1,we can achieve a rate . From 35, we see thatSince , we see that . Thus, ifthe maximizing distribution in 32 satisfies 33, our DCQIMcodebooks can also have this distribution and, hence, achievecapacity 32.As a final comment, it is worth emphasizing that QIM systems are optimal in other important scenarios as well. As one example, in the noisefree case , which arises, for example,15These principles are, of course, two of the main ideas behind the classicalchannel coding theorem 31, Ch. 8.CHEN AND WORNELL QUANTIZATION INDEX MODULATION 1433when a discretevalued composite signal is transmitted over adigital channel with no errors, QIM is optimal even without distortion compensation, and achieves capacity 2736As a second example, and as shown in 27, QIM is optimaleven when the host signal is also available at the decoderachieving the capacity37determined by Heegard and El Gamal 33.We next examine some key scenarios when the optimalitycondition 33 is met.VII. GAUSSIAN CHANNELSIn this section, we examine the ultimate performance limitsof informationembedding methods when both the host signal iswhite and Gaussian, the channel is an AWGN channel, and thehost and channel noise are independent of one another. Extensions to colored host andor colored channel cases are developedin 15, 27. Our main result of the section is that DCQIMis optimal for this class of channels, and that, in addition, theoptimum distortioncompensation parameter is also given by20, which maximized SNR in uncoded DCQIM systems.In general, the embedding strategies optimized for Gaussianchannel models can be expected to be good designs for a variety of applications in which one primarily requires robustnessagainst unintentional attacks.16 And while Gaussian host modelsare not always accurate, the better the hostsignal interferencerejection properties of an informationembedding system, thesmaller the role we might expect the hostsignal model to playin determining the ultimate performance of such systems.A. Capacities and the Optimality of DCQIMSpecializing the formulation of Section VIA to the Gaussianscenario of interest, with the zeromean, variance variablesdenoting elements of the dimensional hostsignal vector, and, similarly, the zeromean, variance variables denoting elements of the corresponding noise vector , the distortion constraint can be expressed aswith the corresponding constraint on in 32 being. We see that squarederror distortionconstrained,Gaussian information embedding is equivalent to powerconstrained communication over a Gaussian channel with Gaussianside information known at the encoder, a case for which Costa34 has determined the capacity to be, expressed in terms ofthe embedding induced DNRDNR DNR 3816Indeed, these models can even apply to optimal, i.e., ratedistortionachieving 31, lossy compression of a Gaussian source, as discussed in 27.Remarkably, the capacity is independent of the signal varianceand, in fact, as we shall discuss later in this section, is thesame as in the case when the host signal is known at thedecoder. Note that this implies that an infinite energy hostsignal causes no decrease in capacity in this Gaussian case, i.e.,good informationembedding systems can completely rejecthostsignal interference in the Gaussian case.Based on our earlier results, to establish the optimality ofDCQIM for this channel, it suffices to verify that 33 is satisfied. This follows from the proof 34 of 38. In particular, asshown in 34, the pdf that maximizes 32 is indeed one implied by 33, for some parameter , where is chosen as afunction of so that and so that the pair andare independent. To see this, note that for a fixed value of , anachievable rate is 34which can also be written in terms of the DNR and the host SNRSNR DNR DNR SNRDNR SNR DNR SNR39This rate is maximized by setting cf. 20DNRDNR40from which we conclude that the rate 38 is achievable. To establish that 38 is also the maximum achievable rate, it sufficesto show that it is the capacity when is known at the decoder,since one obviously cannot do better in the hostblind case.To develop the knownhost capacity, first recall that thecapacity is given by 37. Again, the maximization is subjectto a distortion constraint, which in the case of white noise is. Because subtracting a known constant fromdoes not change mutual information, we can equivalently writeNoting that , we immediately conclude thatin the case of an AWGN channel the knownhost capacity isindeed given by 38, where the maximizing distribution isa zeromean Gaussian distribution with variance .In the knownhost case, additive spread spectrum is optimal,and optimal additive spreadspectrum systems superimposezeromean i.i.d. Gaussian sequences with variance onto thehost signal. However, it is important to note that QIM is alsooptimal in this case as wellas discussed in 15, quantizersof optimal QIM systems have reconstruction sequenceschosen i.i.d. from a zeromean Gaussian distribution withvariance . Hence, yet another attractive property ofQIM methods is that they are optimal in more general Gaussianbroadcast scenarios, where some intended recipients of theembedded information know the host signal and some do not.As a final comment, several of the methods we have discussed can be optimal in the small hostsignal interference sce1434 IEEE TRANSACTION ON INFORMATION THEORY, VOL. 47, NO. 4, MAY 2001nario . In fact, the capacity 38 is rather immediatein this scenario Fig. 2 reduces to the classical communicationproblem considered in, e.g., 31, , so that the capacity isthe usual mutual information between and maximizedover all such that . In the AWGN channelcase, specifically, 38 results. Examining 39 in the associatedregime SNR , we see that distortioncompensated QIMwith any , including regular QIM, is optimal in thissmall host interference scenario. As one might expect, additivespreadspectrum systems can be capacityachieving in this limitas well, which we will see more explicitly in Section VIIC4.B. Capacities for Hybrid TransmissionIn this section, we consider scenarios corresponding toapplications in which information embedding is part of ahybrid transmission scheme. We investigate two classes ofsuch schemes analogdigital and digitaldigital transmission.In the former class, the host is an analog signal, as arises in,for example, the digital audio broadcasting application. In thelatter class, the host signal is itself a digital signal, which hasimplications for broadcast transmission and related applications31, Ch. 14.In both cases, one is generally most concerned with thequality of the received signals, i.e., the channel output, ratherthan the channel input composite signal.1 Analog Host Signals In this subsection, we determinehow reliable embedding at a given rate impacts the quality withwhich an analog host signal is received and can be decoded withits conventional receiver from a noisy channel.In general, the effect of the embedding is to create an additional noise source DNR times as strong as the channel noise,and, therefore, the received signal quality drops by a factor ofDNR orDNR dB 41For example, in the scenario analyzed in Section VIIA, optimum DCQIM results in an embeddinginduced distortion thatlooks like white noise with variance . With no embedding,one would have had a received host SNR of SNR .Due to the additional interference from the embeddinginduceddistortion, however, the received host SNR drops toSNRDNRa drop of DNR.Since the capacity in bits per dimension bits per hostsignalsample is given by 38, and there are two independent hostsignal samples per second for every hertz of hostsignal bandwidth 28, the capacity in bits per second per hertz bsHz isDNR bsHz 42Taking the ratio between 41 and 42, we see that the valuein embedded rate of each decibel drop in received hostsignalquality isDNRDNR0.3322 bsHzdB43Thus, the available embedded digital rate in bits per seconddepends only on the bandwidth of the host signal and the tolerable degradation in received hostsignal quality, and is approximately 13 bs for every hertz of bandwidth and every decibeldrop in received host SNR. It is worth noting that, as developedin 15, 27, these results carry over to the case of colored hostandor colored channel cases as well.Additional insights into the performance limits of such systems when the digital signal is specifically information for refining the analog signal, as arises in applications involving theupgrading of analog infrastructure, are developed in 20.2 Coded Digital Host Signals When the host signal is acoded digital signal, an alternative measure of the received hostsignal quality is the capacity of the corresponding host digitalchannel. For example, in the case of white noise and a white hostsignal,17 if there were no embedding, the capacity correspondingto a host digital signal power of and a noise variance ofwould beSNREmbedding an additional digital signal within the host digitalsignal drops the host digital capacity toSNRDNRdue to the drop in received host SNR of DNR. Unlike in thecase of an analog host signal, if one must actually lower the rateof the coded host digital signal as a result of the embedding, thenone may have to redesign both the digital encoder that generatesthis coded digital host signal and the corresponding decoder.Thus, depending on the designed noise margin of the originaldigital host signal, backward compatibility may or may not bepossible.However, even when digitaldigital transmission cannot bebackwardcompatible, using information embedding for simultaneous transmission of two digital signals is potentially attractive from the point of view of complexity and privacy. In particular, the decoder for the host signal need not decode nor knowhow to decode the embedded signal, and vice versa.As discussed further in 27, this is qualitatively different behavior from the superposition coding and successive cancellation decoding one might otherwise use for simultaneous transmission of two digital signals, where one of the receivers needsto decode both messages to receive its own.Interestingly, the informationembedding approach is equallyefficient. To see this, we note that the embedded digital channelrate is given by 38DNRso that the combined rate of the two channels isDNR SNRSince the associated expended power is , we concludethat this digitaloverdigital transmission strategy is indeed ef17As is well known 31, white Gaussian coded signals are capacityachievingfor transmission over AWGN channels, so this is a good model for the host signalin this case.CHEN AND WORNELL QUANTIZATION INDEX MODULATION 1435ficient the combined rate is as large as the achievablerate using a single digital signal with this same total power.C. Gaps to CapacityIn Section VIIA, we saw that DCQIM is a capacityachieving strategy. In this section, for comparison, we evaluate the degree to which specific strategies such as regularQIM i.e., without distortion compensation, coded additivespreadspectrum, uncoded STDM, and uncoded generalizedLBM can each approach capacityand hence the performanceof DCQIMwhen suitably optimized. We quantify the performance of these systems in terms of the additional DNR requiredto achieve the same rate as a capacityachieving system.1 Regular QIM Gap to Capacity As we now show, the performance of the best QIM methods without distortion compensation can approach the Gaussian capacity at high rates and iswithin 4.3 dB of capacity at low rates, indicating that the QIMclass is large enough to include very good embedding functionsand decoders.To develop a lower bound on the achievable rate of QIMwithout distortion compensation, we begin by specializing 39to the case , resulting inDNRDNR SNRDNR SNR44where to achieve this bound we choose reconstruction pointsfrom the pdf implied by 33.18 The righthand side of 44 isgenerally not the capacity of QIM, howeveri.e., QIM systemscan achieve a rate greater than the lower bound 44. Indeed, therighthand side of 44 actually approaches in the limit oflow DNR.A tighter lower bound is obtained by developing a different lower bound on the capacity of a particular subclassof QIM methods we refer to as spreadtransform QIM.In spreadtransform QIM, which is a generalization ofSTDM as developed in Section VB, the hostsignal vectoris projected onto orthonormal vectors to obtain transformed hostsignalsamples which are quantized using QIM.Because projection onto the vectors represents a change oforthonormal basis, the transformed hostsignal samples andthe transformed noise samples , which are theprojections of the original noise vector ontothe orthonormal vectors , are still independent, zeromean,Gaussian random variables with the same variance as theoriginal host signal and noise samples, respectively. However,if the distortion per original hostsignal sample is , then thedistortion per transformed hostsignal sample is . Thus,we obtain a spreading gain of in terms of DNR, but thenumber of bits embedded per original hostsignal sample isonly times the number of bits embedded per transformedhostsignal sample. Thus, one can determine an achievable rate18The pdf of the reconstruction points u  s in this case isN 0 D  ,which is not the same as the wellknown ratedistortion optimal pdf 31 forquantizing Gaussian random variables, which is N 0  D .of spreadtransform QIM by appropriately modifying44 to obtainDNRDNR SNRDNR SNRDNR 45To upperbound the gap between QIM and capacity we firstrecognize from 45 that the minimum DNR required for QIMto achieve a rate asymptotically with large isDNR 46which is minimized at .19 However,even in the limit of large to have . Thus, if onesets47then 46 remains a valid upper bound on the required DNRfor a QIM method to achieve a rate . From 38 we see thatthe minimum DNR required for a capacityachieving method toachieve a rate is , which when combinedwith 46 yields the following upper bound between QIM andthe Gaussian capacityDNRDNR48This expression is plotted in Fig. 9, where is given by 47.We now examine the asymptotic limits of 48 at low and highrates. Equation 47 implies in the limitof small , so in this limit 48 approachesDNRDNRasThus, the gap is at most a factor of approximately 4.3 dBin the limit of low rates. In the limit of large , 47 impliesso 48 approachesDNRDNRasThus, QIM asymptotically achieves capacity at high embeddingrates.As we described in Section VIIB, in hybrid transmission applications one may be concerned about the degradation to thereceived host signal, which is DNR rather than DNR. The19Note that sinceN 05NroundN 05one can, indeed, approach this optimum spreading gain L in the limit of largeN even though NL need be a positive integer less than or equal to N .1436 IEEE TRANSACTION ON INFORMATION THEORY, VOL. 47, NO. 4, MAY 2001Fig. 9. DNR gap between spreadtransform QIM and Gaussian capacityachieved by DCQIM. The maximum gap is a factor of e  4.3 dB.gap in DNR 48 is larger than the gap in DNR , which hasa corresponding upper boundDNRDNRThis gap is plotted in Fig. 10 as a function of , the rate inbsHz. Again, is given by 47 since minimizing DNRalso minimizes DNR . Thus, for example, at the nearworst case digital rate of 1 bsHz using QIM requires at most 1.6dB more drop in analog channel quality than the approximately3dB drop required for DCQIM Section VIIB1.2 Uncoded STDM Gap to Capacity The results above canbe compared to the achievable performance of uncoded binarySTDM with uniform scalar quantization as a minimalcomplexity realization of QIM.The gap between uncoded STDM and capacity can easilybe quantified for low rates , which are typical inmany applications, at a given probability of error. A straightforward union bound on the biterror probability of uncoded binarySTDM with uniform scalar quantization is see Fig. 6This bound is reasonably tight for low error probabilities, and from 26 we can write this probability of errorin terms of the ratenormalized distortiontonoise ratioDNR DNRDNRDNR 49A capacityachieving method can achieve arbitrarily low probability of error as long as , which using 38 canbe expressed asDNRFig. 10. Received host SNR gap 1  DNR between spreadtransform QIMand capacity achieved by DCQIM.Fig. 11. Uncoded STDM gap to Gaussian capacity. The solid curve showsthe biterror probability for uncoded STDM as a function of ratenormalizeddistortiontonoise ratio DNR . The dashed curve is the minimum requiredDNR for reliable information embedding for any embedding method.For low embedding rates , so theminimum required DNR for arbitrarily low probability oferror isDNR 1.4 dB 50The probability of error of STDM is plotted as a function ofDNR in Fig. 11. The required DNR for a given canbe compared to 50 to determine the gap to capacity. For example, at an error probability of , uncoded STDM is about13.6 dB from capacity. One can reduce this gap by at least 9.3 dBthrough channel coding, vector quantization, and nonditheredquantization. The remaining gap at most 4.3 dB is the gap between QIM and capacity and can be closed with distortion compensation. As shown in 15, 27, it is fairly easily to close thegap between uncoded STDM with uniform scalar quantizersand capacity by about 6 dB using practical channel codes anddistortion compensation.3 Uncoded Spread LBM Gap to Capacity The gap to capacity for uncoded binary spread LBM based on uniform, scalarCHEN AND WORNELL QUANTIZATION INDEX MODULATION 1437quantization also follows readily from the results of AppendixA, which shows that the distortionnormalized minimum distance for this form of spread LBM is a factor of 2.43 dBworse than that of STDM 26. Thus, the LBM counterpart to49 is that the biterror probability of uncoded spread LBM isDNR 51Thus, the gap to capacity of uncoded binary spread LBM at anerror probability of is about 16 dB, 2.4 dB more than the13.6dB gap of uncoded binary STDM. Furthermore, as alsodiscussed in Appendix A, for ary implementations the gapwidens by an additional 0.6 dB as .4 Coded Additive SpreadSpectrum Gap to Capacity Foradditive spread spectrum, where , the distortionsignal in Fig. 2 is not a function of the host signal. Thus, . The distortion constraintis still so that in the Gaussian case considered here,the achievable rate of an additive spreadspectrum method is thewellknown 31 Gaussian channel capacity, treating both andas interference sources20DNRSNR52where, again, SNR is the ratio between the hostsignal varianceand the channelnoise variance. Comparing 52 to 38, we seethat the gap to capacity of additive spread spectrum isDNRDNRSNR 53which is typically large, since SNR must be large so thatchannel noise will not excessively degrade signal quality.In fact, in the high signaltodistortion rastio SDR limitwhere , the achievable rate of additive spreadspectrum 52 clearly approaches zero, again reflecting the inabilityof additive spreadspectrum methods to reject hostsignalinterference like other methods.At the opposite extreme, when SNR the host interference is small so the gap 53 disappears, and, indeed, additive spread spectrum is an optimum embedding strategy for thiscase, along with both DCQIM and QIM as discussed at the endof Section VIIA.The other scenario in which additive spread spectrum can beoptimal is when the host is known at the decoder, which alsocorresponds to a noninterfering host situation.5 KnownHost Case As discussed at the end of Section VIIA, both capacityachieving QIM and capacityachieving additive spreadspectrum methods exist when the hostsignal is known at the decoder. Although QIM realizations inthe form of coded dither modulation with uniform, scalar quantization are not optimal in this case, for AWGN channels onecan achieve performance within 1.53 dB of capacityas we show below. We consider the case of dither signals with20This rate is also the capacity when n is nonGaussian, but still independentof s, and a correlation detector is used for decoding 35.a uniform distribution over the interval . In thiscasewhere the quantization error is uniformly distributed over theinterval and statistically independent of 29.Thus, the achievable rate is slightly lower than thecase where is Gaussian. The entropy power inequality can beused to show that the decrease in achievable rate is bounded by36DNRDNR54This gap approaches the upper limit of 0.2546bdimension as the DNR gets large. For any finite DNR, the gapis smaller. By subtracting the upper bound on the gap 54 fromthe capacity 38, one obtains a lower bound on the achievablerate of this type of dither modulationDNR 55Thus, dither modulation with uniform scalar quantization in thiscase is at most 1.53 dB from capacity.VIII. INTENTIONAL ATTACKSWe now turn our attention from AWGN channel models forunintentional attacks, to some alternative models for intentionalattacks. Intentional, distortionconstrained attacks may be encountered in copyright, authentication, and covert communication applications. In these kinds of applications, attackers generally attempt to remove or alter the embedded information, andface a distortion constraint on their signal manipulations so thatthe integrity of the host signal is not compromised.An attackers ability to prevent reliable watermark decodingdepends on the amount of knowledge that the attacker hasabout the embedding and decoding processes. To limit suchknowledge, some digital watermarking systems use keys, parameters that allow appropriate parties to embed andor decodethe embedded signal. The locations of the modulated bitsand the pseudonoise vectors in an additive spreadspectrumand generalized LBM systems are examples of keys. If onlycertain parties privately share the keys to both embed anddecode information, and no one else can do either of thesetwo functions, then the watermarking system is a privatekeysystem. Alternatively, if some parties possess keys that allowthem to either embed or decode, but not both, then the systemis a publickey system since these keys can be made availableto the public for use in one of these two functions withoutallowing the public to perform the other function. However, insome scenarios it may be desirable to allow everyone to embedand decode watermarks without the use of keys. For example,in a copyright ownership notification system, everyone couldembed the ASCII representation of a copyright notice such as,Property of  in their copyrightable works. Such a systemis analogous to the system currently used to place copyrightnotices in hardcopies of books, a system in which there is no1438 IEEE TRANSACTION ON INFORMATION THEORY, VOL. 47, NO. 4, MAY 2001need for a central authority to store, register, or maintain separate keysthere are noneor watermarksall watermarksare English messagesfor each user. The widespread use ofsuch a universally accessible nokey system requires onlystandardization of the decoder so that everyone will agree onthe decoded watermark, and hence, the owner of the copyright.We analyze both privatekey and nokey systems in the sequel, and establish the attractiveness of QIM in both cases.A. Attacks on PrivateKey SystemsAlthough the attacker does not know the key in a privatekeyscenario, he or she may know the basic algorithm used to embedthe watermark. In 16, Moulin and OSullivan model such ascenario by assuming that the attacker knows the codebook distribution, but not the actual codebook. As we now develop, exploiting results of Moulin and OSullivan in this privatekeyscenario, we determine that DCQIM methods are optimal capacityachieving against squarederror distortionconstrainedattackers.Moulin and OSullivan have derived both the capacityachieving distribution and an explicit expression for the capacity 32 in the case where the host is white and Gaussian andthe attacker faces an expected perturbation energy constraint. In this case, the capacity is 16DNRSNR DNRSNR DNRwhere DNR is the distortiontoperturbationratio and SNR is the hostsignaltoperturbation ratio. The maximizing distribution is such that 16with statistically independent of andDNRDNR56Since this distribution satisfies the condition 33, we can inferfrom our analysis in Section VIA2 that DCQIM can be usedto achieve capacity against these attacks. Moreover, 56 givesthe optimal distortioncompensation parameter.Moulin and OSullivan have also considered the case of hostsignals that are not necessarily Gaussian but that have zeromean, finite variance, as well as bounded and continuous pdfs.In the limit of small high SDR and , a limit of interestin highfidelity applications, the capacity approaches DNRand the capacityachieving distribution is such thatwhere, again, is statistically independent of16. Since this distribution satisfies the condition 33, we canagain conclude that distortioncompensated QIM can achievecapacity in this highfidelity limit. The capacityachieving distortioncompensation parameter is 16DNRDNRB. Attacks on NoKey SystemsIn contrast to the scenario above, in nokey systems an attacker has full knowledge of the embedding and decoding processes, including all codebooks. For this case, some deterministic models we develop in this section are better for characterizing the associated worst case intheclear i.e., fully informedattacks. With these models, we show that QIM methods in general, and dither modulation in particular, are robust and achieveprovably better rate distortionrobustness tradeoffs than bothadditive spreadspectrum and generalized LBM techniques.We consider two models for such attackers 1 a boundedperturbation channel model in which the squarederror distortion between the channel input and channel output is boundedand 2 a bounded hostdistortion channel model in which thesquarederror distortion between the host signal and channeloutput is bounded. In each case, we develop conditions underwhich errorfree decoding is possible with various implementations of QIM and DCQIM, and quantify their advantages overthe corresponding realizations of additive spread spectrum andgeneralized LBM.1 Bounded Perturbation Channel The bounded perturbation channel is one in which the attacker can perturb the composite signal in any way it desires based on its full knowledgeof the composite signal and the embedding algorithm, providedthe energy in the perturbation vector does not exceed a prescribed level, i.e., 16, which reflects a requirement that theattacker not excessively degrade the original composite signal.Thus, this channel model imposes only a maximum distortion21or minimum SNR constraint between the channel input andoutput.Binary dither modulation with uniform scalar quantization One can combine the guaranteed errorfree decoding condition 17 for a minimumdistance decoder 15 with the distortionnormalized minimum distance 26 of binary dither modulation with uniform scalar quantization to compactly express itsachievable performance as57or, equivalently, its achievable rate as58One can view the achievable rate 58 as the deterministic counterpart to the more conventional notions of achievable rates andcapacities of random channels discussed in Sections VI and VII.21Some types of distortion, such as geometric distortions, can be large interms of squared error, yet still be small perceptually. However, in some cases,these distortions can be mitigated either by preprocessing at the decoder or byembedding information in parameters of the host signal that are less affectedin terms of squared error by these distortions. For example, a simple delay orshift may cause large squared error, but the magnitude of the discrete Fouriertransform coefficients are relatively unaffected.CHEN AND WORNELL QUANTIZATION INDEX MODULATION 1439Additive spread spectrum The nonzero minimum distance of QIM methods offers quantifiable robustness to perturbations, even when the host signal is not known at thedecoder. In contrast, additive spreadspectrum methods offerrelatively little robustness if the host signal is not known at thedecoder. As discussed in Section III, these methods have linearembedding functions of the form59where is a pseudonoise vector. From the definition ofminimum distance 13i.e., the minimum distance is zero.Thus, although these methods may be effective when thehost signal is known at the decoder, when the host signal is notknown, they offer no guaranteed robustness to perturbations,i.e., no achievable rate expression analogous to 58 exists foradditive spread spectrum. As is evident from 59, in an additivespreadspectrum system, is an additive interference, whichis often much larger than due to the distortion constraint.In contrast, the quantization that occurs with QIM providesimmunity against this hostsignal interference, as discussed inSection IV.22Generalized LBM As shown in Appendix A, the distortionnormalized minimum distance of generalized binary LBMwith uniform scalar quantization is about 2.43 dB worse thanthat of the corresponding dithermodulation strategy. Therefore,its achievable ratedistortionrobustness performance is alsoabout 2.43 dB worse than 57. Again, as also developed in theappendix, for ary implementations, the gap grows to 3 dBfor large .2 Bounded HostDistortion Channel As an alternative tothe bounded perturbation channel, some attackers may workwith distortion constraint between the channel output and thehost signal, rather than the channel input, since this distortionis the most direct measure of degradation to the host signal. Forexample, if attackers have partial knowledge of the host signal,which may be in the form of a probability distribution, so thatthey can calculate this distortion, then it may be appropriate tobound the expected distortion , where this expectation is taken over the conditional probability density .23We refer to this as the bounded hostdistortion channel.For this channel, we measure robustness to attacks by theminimum expected distortion for a successful attack, where22Another way to understand this hostsignal interference rejection is to consider, for example, that a quantized random variable has finite entropy while acontinuous random variable has infinite entropy.23Note that if the attacker has full knowledge of the host signal, he or she cantrivially remove the embedded information by setting  , so D  0. Werestrict our attention to the more realistic scenario in which an attacker has onlypartial knowledge of the host, in the form of a conditional pdf.TABLE IATTACKERS DISTORTION PENALTIES. THE DISTORTION PENALTY IS THEADDITIONAL DISTORTION THAT AN ATTACKER MUST INCUR TO SUCCESSFULLYREMOVE A WATERMARK. A DISTORTION PENALTY LESS THAN 0 dB INDICATESTHAT THE ATTACKER CAN ACTUALLY IMPROVE THE SIGNAL QUALITY ANDREMOVE THE WATERMARK SIMULTANEOUSLYthe expectation is taken with respect to . The ratio betweenand the expected embeddinginduced distortion is thedistortion penalty that the attacker must pay to remove the watermark and, hence, is a figure of merit measuring the robustnessdistortion tradeoff at a given rate. Distortion penalties forthe primary methods of interest are derived below and summarized in Table I for the high SDR regime of primary interest.As this table reflects, among these methods considered, onlyQIM methods including binary dither modulation with uniformscalar quantization are robust enough such that the attackermust degrade the hostsignal quality to remove the watermark.Regular QIM We first consider the robustness of regularQIM. For any distortion measure, as long as each reconstruction point lies at the minimumdistortion point of its respectivequantization cell, the QIM distortion penalty is greater than orequal to since any output that an attacker generates must necessarily lie away from this minimumdistortion point. Equalityoccurs only if each quantization cell has at least two minimumdistortion points, one of which lies in the incorrect decoder decision region. For expected squarederror distortion, the minimumdistortion point of each quantization cell is its centroid,and one can express this distortion penalty in terms of the distortionnormalized minimum distance and the signal length ,as we show below.We use to denote the quantization cell containing andto denote the conditional pdf of given that .Again, for sufficiently small quantization cells, this pdf canoften be approximated as uniform over , for example. Sinceis the centroid of60Also, the expected squared error per letter embeddinginduceddistortion given is611440 IEEE TRANSACTION ON INFORMATION THEORY, VOL. 47, NO. 4, MAY 2001The most general attack can always be represented as, where may be a function of . The resulting distortioniswhere we have used 61, the fact that is a pdf and, thus,integrates to one, and 60 to obtain the last line. For a successfulattack, soAveraging both sides of this expression over all quantizationcells yields so that our figure of meritfor QIM methods is62Thus, for any QIM method of nonzero distortionnormalizedminimum distance , the attackers distortion penalty is always greater than 0 dB, indicating that to remove the watermark, the attacker must degrade the hostsignal quality beyondthe initial distortion caused by the embedding of the watermark.Binary dither modulation with uniform, scalar quantization In this case, 26 gives in 62. Moreover, due to theuniformity of the quantizers, the bound 62 is met with equalityso that the attackers distortion penalty specializes to63Because the Hamming distance of a block code cannot exceed the number of coded bitswhere the first equality follows from the definition 23 of .Thus, an upper bound for the distortion penalty 63 in this caseis2.43 dBAlthough this penalty may seem modest, it is larger than that obtainable by either additive spread spectrum or generalized LBM,as we show below. Larger distortion penalties are not possiblebecause intheclear attackers can concentrate all their distortionin the minimumdistance direction in dimensional space.As a final note, 63 implies that binary dither modulationwith uniform, scalar quantization can defeat any attacker as longasan expression whose counterpart for the bounded perturbationchannel was 57. Thus, the corresponding achievable rates aregiven byDistortioncompensated QIM An intheclear attacker ofa DCQIM system knows the quantizers and can determine thewatermark after observing the composite signal . If the quantization cells are contiguous so that the distortioncompensationterm in 19 does not move out of the cell containing , then anattacker can recover the original host signal with the followingattackwhere the final line follows simply by inverting 19. Thus, theattackers distortion penalty is decibels. We seethat although DCQIM is optimal against both independent additive Gaussian noise attacks and squarederrordistortionconstrained attacks in privatekey scenarios, it is in some sensemaximally suboptimal against intheclear attacks. RegularQIM, on the other hand, is almost as good as DCQIM againstadditive Gaussian noise attacks Section VII and also resistantto intheclear attacks as discussed above. Thus, regular QIMmethods may offer an attractive compromise when one requiresresistance to both intentional attacks and unintentional attacksin a nokey system.Additive spread spectrum Since the embedding functionof an additive spreadspectrum system is 2, the resulting distortion is . An attacker with full knowledgeof the embedding and decoding processes can decode the message , and hence, reproduce the corresponding pseudonoisevector . Therefore, the attacker can completely remove thewatermark by subtracting from to obtain the original hostsignal, i.e., . Hence, the resulting distortionpenalty is decibels.Because the additive spreadspectrum embedding functioncombines the host signal and watermark in a simplelinear way, anyone that can extract the watermark, can easily remove it. Thus, these methods are not suitable for universally accessible nokey digital watermarking applications. By contrast,the advantage of QIM is that it effectively hides the host signaleven when the embedded information is known.Generalized LBM Recall that the embedding function ofa generalized LBM system can be written as 8 with havingthe property 9. Good generalized LBM systems also have theproperty that the reconstruction points of are at the centroids of the quantization cells, as we shall assume. One attackthat completely removes information about is to output thesereconstruction points, i.e., . Since is at aminimum distortion point of the quantization cell,0 dB, with equality only if both and are minimumdistortion points. Thus, an attacker can remove the watermarkwithout causing additional distortion to the host signal. ThisCHEN AND WORNELL QUANTIZATION INDEX MODULATION 1441result applies regardless of whether errorcorrection coding isused. Thus, in contrast to dither modulation, errorcorrectioncoding does not improve LBM in this context.When, in addition, it is the least significant bit of a uniform,scalar quantizer that is modulated, the results in Appendix Aimply further thatwhileThus, 2.43 dB. Again, when many lesssignificant bits are modulated, the results of the appendix canbe used to establish that the penalty grows to 3 dB.IX. CONCLUDING REMARKSWe have seen that QIM methods are provably better than additive spread spectrum and generalized LBM against boundedperturbation and intheclear attacks and are nearoptimal forGaussian channels, for which DCQIM is optimal. Furthermore,dither modulation is a practical implementation of QIM thatexhibits many of the attractive performance properties of QIM.The convenient structure of dither modulation, which is easilycombined with errorcorrection coding, allows the system designer to achieve different rate distortionrobustness tradeoffsby tuning parameters such as the quantization step size. Also,one can conveniently upgrade previously developed additivespreadspectrum and spread LBM systems to spreadtransformdithermodulation systems by replacing the respective additionand quantizeandreplace steps with a dithered quantizationstep.In the course of our investigation, a number of ratherintriguing results have emerged. For example, the informationembedding capacity in the Gaussian case does not dependat all on whether the host signal is available during decoding,and DCQIM is optimal in both scenarios, and achieves perfectrejection of hostsignal interference, even in the highSDRregime.Also somewhat surprisingly, the optimal embedding strategyfor Gaussian channels and for typical attacks in privatekey systems, DCQIM is maximally suboptimal against intheclearattacks. On the other hand, regular QIM, which has performancewithin 4.3 dB of DCQIM in the Gaussian case, performs betterthan any other currently known method against intheclear attacks, which arise in copyright notification applications wherenokey architectures are used, for example. In particular, unlikeadditive spreadspectrum and generalized LBM methods, QIMand dithermodulation methods force an attacker to pay a distortion penalty. Thus, QIM emerges as a universally good embedding strategy against a wide variety of intentional and unintentional attacks.For hybrid transmission strategies, using DCQIM for digitaloveranalog transmission in, for example, digital audio broadcasting applications allows embedding rates of about 13 bsHzfor every decibel drop in analog signal quality. In digitaloverdigital transmission in broadcast applications, for example,DCQIM is as efficient as any single digital transmission, andthus as good as the alternative superposition coding and successive cancellationdecoding approach.Many important directions for further research remain. Atone end of the spectrum, further insights into the fundamentalprinciples and structure of information embedding and digitalwatermarking systems will come from the development of stillbetter general attack models. Those emerging from gametheoretic formulations and arbitrarily varying channel models appearto be an important starting point in this respect.At the same time, many of the results in this paper have important implications for practical applications, and the most effective implementations of QIM and DCQIM embedding systems for these applications will take into account, in detail, thespecific types of geometric distortions and other attacks that typically arise. For example, in image watermarking applications,embedders and decoders ultimately need to be robust to a widerange of often surprisingly challenging attacks, ranging fromscaling and rotation, to cropping and column replacement. Agreat deal of future work is needed in this area to enable the useof QIM techniques in watermarking applications, and indeedthese represent some especially interesting design challenges.APPENDIX ALBM DISTORTIONNORMALIZED MINIMUM DISTANCEIn this appendix we calculate the distortionnormalized minimum distance of binary LBM with uniform, scalar quantization. We assume that the host signal and embedded signal arestatistically independent.Since the embedding function of any good generalized LBMmethod can be written as 8 with 10, the expected distortionis64where we have used 10 and the independence of and toobtain the final line.We analyze coded binary LBM with uniform scalar quantization, an LBM system in which each in a sequence of coded bitsis repeated times and embedded in a length block with asequence of uniform, scalar quantizers.The embedding is accomplished by modulating the least significant bit of each quantizer. The th uniform, scalar quantizeris illustrated in Fig. 12. The coarse quantizer has a stepsize of , and the th least significant bit adjustment elementequals .Comparing this scheme to coded binary dither modulationwith uniform scalar quantization as described in Section VA,we see that this scheme has the same minimum distance, i.e.,22. Restricting attention to the high SDR regime in whichcan be modeled as uniformly distributed within each cell of ,1442 IEEE TRANSACTION ON INFORMATION THEORY, VOL. 47, NO. 4, MAY 2001Fig. 12. Lowbit modulation with a uniform, scalar quantizer. The quantizerhas a step size of  2, and the least significant bit lsb is modulated. Allreconstruction points marked with a have an lsb of 0. Points marked with ahave an lsb of 1. This process is equivalent to first quantizing using a quantizerwith a step size of  , whose reconstruction points are marked with a , andadding  4.as was used to develop 24 in Section VA, the first term in 64is65the same as the expected distortion 25 of the correspondingdither modulation system. The second term in 64, however, is66Thus, the overall expected distortion isand the distortionnormalized squared minimum distance isBy comparing with 26, we see that binary coded LBM withuniform scalar quantization is worse than the correspondingdither modulation system by2.43 dB 67Also, note that the result 67 is invariant to the actual distribution of the s, and invariant to any preprocessing of thehost signal by a unitary transformation. Thus, the gap betweenSTDM and spread LBM is also given by 67.In other variants of LBM, the gap can be worse. For instance, in the case of ary coded implementations of dithermodulation and LBM based on uniform scalar quantizationwhere the sets of reconstruction points together form aregular lattice, then the minimum distances of the two schemesremain equal but generally different from the binary case, andthe first term in 64 remains 65. However, as gets large,becomes effectively uniformly distributed over the range, so the second term in 64 changes from 66 tothe same as 65. Thus, the gap 67 grows to a factor of 3dB in this large limit.ACKNOWLEDGMENTThe authors thank Prof. A. Lapidoth for calling their attentionto the paper by Costa, and an anonymous reviewer for helpfulcomments that improved the clarity of the paper.REFERENCES1 M. D. Swanson, M. Kobayashi, and A. H. Tewfik, Multimedia dataembedding and watermarking technologies, Proc. IEEE, vol. 86, pp.10641087, June 1998.2 I. J. Cox and J.P. M. G. Linnartz, Some general methods for tamperingwith watermarks, IEEE J. Select. Areas Commun., vol. 16, pp. 587593,May 1998.3 J.P. Linnartz, T. Kalker, and J. Haitsma, Detecting electronic watermarks in digital video, in Proc. 1999 IEEE Int. Conf. Acoustics, Speech,and Signal Processing, vol. 4, Phoenix, AZ, Mar. 1999, pp. 20712074.4 G. Arce, C. G. Boncelet Jr., R. F. Graveman, and L. M. Marvel, Applications of information hiding, in Proc. 3rd Annu. Federated Laboratory Symp. Advanced Telecommunications  Information DistributionResearch Program, College Park, MD, Feb. 1999, pp. 423427.5 H. C. Papadopoulos and C.E. W. Sundberg, Simultaneous broadcasting of analog FM and digital audio signals by means of adaptiveprecanceling techniques, IEEE Trans. Commun., vol. 46, pp.12331242, Sept. 1998.6 B. Chen and C.E. W. Sundberg, Broadcasting data in the FM bandby means of adaptive contiguous band insertion and precancelling techniques, in Proc. 1999 IEEE Int. Conf. Communications, vol. 2, Vancouver, BC, Canada, June 1999, pp. 823827.7 M. D. Swanson, B. Zhu, and A. H. Tewfik, Data hiding for videoinvideo, in Proc. 1997 IEEE Int. Conf. Image Processing, vol. 2, Piscataway, NJ, 1997, pp. 676679.8 J. M. Barton, Method and apparatus for embedding authenticationinformation within digital data, United States Patent 5 646 997, July1997.9 K. Tanaka, Y. Nakamura, and K. Matsui, Embedding secret informationinto a dithered multilevel image, in Proc. 1990 IEEE Military Communications Conf., 1990, pp. 216220.10 W. Bender, D. Gruhl, N. Morimoto, and A. Lu, Techniques for datahiding, IBM Syst. J., vol. 35, no. 34, pp. 313336, 1996.11 I. J. Cox, J. Killian, T. Leighton, and T. Shamoon, A secure, robustwatermark for multimedia, in Information Hiding. 1st Int. WorkshopProc. , June 1996, pp. 185206.12 J. R. Smith and B. O. Comiskey, Modulation and information hiding inimages, in Information Hiding. 1st Int. Workshop Proc., June 1996, pp.207226.13 J. R. Hernandez, F. PerezGonzalez, J. M. Rodriguez, and G. Nieto, Performance analysis of a 2Dmultipulse amplitude modulation schemefor data hiding and watermarking of still images, IEEE J. Select. AreasCommun., pp. 510524, May 1998.14 J. A. OSullivan, P. Moulin, and J. M. Ettinger, Information theoreticanalysis of steganography, in Proc. 1998 IEEE Int. Symp. InformationTheory, Cambridge, MA, Aug. 1998, p. 297.15 B. Chen and G. W. Wornell, Implementations of quantization indexmodulation methods for digital watermarking and information embedding of multimedia, J. VLSI Signal Processing Syst. Signal, Image, andVideo Technol. Special Issue on Multimedia Signal Processing, vol. 27,pp. 733, Feb. 2001.16 P. Moulin and J. A. OSullivan, Informationtheoretic analysis of information hiding, preprint, Oct. 1999.17 N. Merhav, On random coding error exponents of watermarking systems, IEEE Trans. Inform. Theory, vol. 46, pp. 420430, Mar. 2000.18 A. Cohen and A. Lapidoth, On the Gaussian watermarking game, inProc. IEEE Int. Symp. Information Theory, Sorrento, Italy, June 2000,p. 48.19 P. Moulin and J. OSullivan, Informationtheoretic analysis of information hiding, in Proc. IEEE Int. Symp. Inform. Theory, Sorrento, Italy,June 2000, p. 19.20 R. J. Barron, B. Chen, and G. W. Wornell, The duality between information embedding and source coding with side information and someapplications, IEEE Trans. Inform. Theory, submitted for publication.21 I. J. Cox, M. L. Miller, and A. L. McKellips, Watermarking as communications with side information, Proc. IEEE, vol. 87, pp. 11271141,July 1999.22 F. Hartung and M. Kutter, Multimedia watermarking techniques, Proc.IEEE, vol. 87, pp. 10791107, July 1999.CHEN AND WORNELL QUANTIZATION INDEX MODULATION 144323 F. A. P. Petitcolas, R. J. Anderson, and M. G. Kuhn, InformationhidingA survey, Proc. IEEE, vol. 87, pp. 10621078, July 1999.24 A. Z. Tirkel, G. A. Rankin, R. van Schyndel, W. J. Ho, N. R. A. Mee,and C. F. Osborne, Electronic water mark, in Proc. Conf. Digital ImageComputing, Technology and Applications, Sydney, Australia, Dec. 1993,pp. 666672.25 R. van Schyndel, A. Z. Tirkel, and C. F. Osborne, A digital watermark,in Proc. 1st IEEE Int. Conf. Image Processing, vol. 2, Austin, TX, Nov.1994, pp. 8690.26 I. J. Cox, J. Killian, F. T. Leighton, and T. Shamoon, Secure spread spectrum watermarking for multimedia, IEEE Trans. Image Processing, vol.6, pp. 16731687, Dec. 1997.27 B. Chen, Design and analysis of digital watermarking, information embedding, and data hiding systems, Ph.D. dissertation, MIT, Cambridge,MA, June 2000.28 E. A. Lee and D. G. Messerschmitt, Digital Communication, 2nded. Boston, MA Kluwer Academic, 1994.29 N. S. Jayant and P. Noll, Digital Coding of Waveforms Principles andApplications to Speech and Video. Englewood Cliffs, NJ PrenticeHall, 1984.30 R. Zamir and M. Feder, On lattice quantization noise, IEEE Trans.Inform. Theory, vol. 42, pp. 11521159, July 1996.31 T. M. Cover and J. A. Thomas, Elements of Information Theory. NewYork Wiley, 1991.32 S. I. Gelfand and M. S. Pinsker, Coding for channel with random parameters, Probl. Contr. Inform. Theory, vol. 9, no. 1, pp. 1931, 1980.33 C. Heegard and A. A. E. Gamal, On the capacity of computer memorywith defects, IEEE Trans. Inform. Theory, vol. IT29, pp. 731739,Sept. 1983.34 M. H. M. Costa, Writing on dirty paper, IEEE Trans. Inform. Theory,vol. IT29, pp. 439441, May 1983.35 A. Lapidoth, Nearest neighbor decoding for additive nonGaussiannoise channels, IEEE Trans. Inform. Theory, vol. 42, pp. 15201529,Sept. 1996.36 F.W. Sun and H. C. A. van Tilborg, Approaching capacity by equiprobable signaling on the Gaussian channel, IEEE Trans. Inform. Theory,vol. 39, pp. 17141716, Sept. 1993.
