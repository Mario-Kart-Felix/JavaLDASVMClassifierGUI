Multimedia DataEmbedding andWatermarking TechnologiesMITCHELL D. SWANSON, MEMBER, IEEE, MEI KOBAYASHI, ANDAHMED H. TEWFIK, FELLOW, IEEEInvited PaperIn this paper, we review recent developments in transparentdata embedding and watermarking for audio, image, and video.Dataembedding and watermarking algorithms embed text, binarystreams, audio, image, or video in a host audio, image, or videosignal. The embedded data are perceptually inaudible or invisibleto maintain the quality of the source data. The embedded datacan add features to the host multimedia signal, e.g., multilingualsoundtracks in a movie, or provide copyright protection. We discussthe reliability of dataembedding procedures and their ability todeliver new services such as viewing a movie in a given ratedversion from a single multicast stream. We also discuss the issuesand problems associated with copy and copyright protections andassess the viability of current watermarking algorithms as a meansfor protecting copyrighted data.KeywordsCopyright protection, data embedding, steganography, watermarking.I. INTRODUCTIONThe past few years have seen an explosion in the useof digital media. Industry is making significant investmentsto deliver digital audio, image, and video information toconsumers and customers. A new infrastructure of digitalaudio, image, and video recorders and players, online services, and electronic commerce is rapidly being deployed.At the same time, major corporations are converting theiraudio, image, and video archives to an electronic form.Manuscript received July 15, 1997 revised January 15, 1998. TheGuest Editor coordinating the review of this paper and approving it forpublication was A. M. Tekalp. This work was supported in part by theAir Force Office of Scientific Research under Grant AFF496209410461 and in part by the Advanced Research Project Agency under GrantAFF496209310558.M. D. Swanson is with Cognicity, Inc., Minneapolis, MN 55344 USAemail swansoncognicity.com.M. Kobayashi is with the Graduate School of Mathematical Sciences,University of Tokyo and IBM Tokyo Research Laboratory, Yamatoshi,Kanagawaken 242 Japan email meitrl.ibm.co.jp.A. H. Tewfik is with Cognicity, Inc., Minneapolis, MN 55344 USAemail tewfikcognicity.com and the Department of Electrical andComputer Engineering, University of Minnesota, Minneapolis, MN 55455USA email tewfikece.umn.edu.Publisher Item Identifier S 0018921998035191.Digital media offer several distinct advantages over analog media the quality of digital audio, image, and videosignals is higher than that of their analog counterparts.Editing is easy because one can access the exact discretelocations that should be changed. Copying is simple withno loss of fidelity. A copy of a digital media is identicalto the original. Digital audio, image, and videos are easilytransmitted over networked information systems.These advantages have opened up many new possibilities.In particular, it is possible to hide data information withindigital audio, image, and video files. The information ishidden in the sense that it is perceptually and statisticallyundetectable. With many schemes, the hidden informationcan still be recovered if the host signal is compressed,edited, or converted from digital to analog format and back.As we shall see in Section II, pure analog datahidingtechniques had been developed in the past. However, thesetechniques are not as robust as most of the digital datahiding techniques that we review in this paper. Furthermore,they cannot embed as much data in a host signal as thedigital approaches.Digital data embedding has many applications. Foremostis passive and active copyright protection. Many of theinherent advantages of digital signals increase problemsassociated with copyright enforcement. For this reason, creators and distributors of digital data are hesitant to provideaccess to their intellectual property. Digital watermarkinghas been proposed as a means to identify the owner ordistributor of digital data.Data embedding also provides a mechanism for embedding important control, descriptive, or reference informationin a given signal. This information can be used for trackingthe use of a particular clip, e.g., for payperuse applications, including billing for commercials and video andaudio broadcast, as well as Internet electronic commerce ofdigital media. It can be used to track audio or visual objectcreation, manipulation, and modification history within agiven signal without the overhead associated with creating001892199810.00  1998 IEEE1064 PROCEEDINGS OF THE IEEE, VOL. 86, NO. 6, JUNE 1998a separate header or history file. It can also be used to trackaccess to a given signal. This information is important inrightsmanagement applications.Data embedding is also ideally suited for covert communications. Data embedding can securely hide large amountsof potentially encrypted information in audio, image, andvideo data.A most interesting application of data embedding isproviding different access levels to the data. For example,the amount of detail that can be seen in a given image canbe controlled. A person with a high access level can seedetails that another person with a lower access level wouldnot see. Similarly, data embedding allows users to tailor avideo to their needs, e.g., by watching a movie broadcastover a single channel in a particular rating or in a givenlanguage. In this case, data embedding is used to embedextra scenes and multilingual tracks in a given version ofthe movie that is broadcast 84. In a sense, data embeddingthen provides some of the capability of digital video discDVD in a broadcast environment with no extra bandwidthor storage requirements.Most dataembedding algorithms can extract the hiddendata from the host signal with no reference to the originalsignal. In some scenarios, an original is available to thedetection algorithm. Typically, dataembedding algorithmsthat use the original signal during detection are robust toa larger assortment of distortions. The detection algorithmmay subtract off the original signal from the receivedsignal prior to data detection. Registration may also beused by receivers to compare the received signal with theoriginal to correct scaling, rotation, and other distortionsprior to data detection. Some dataembedding algorithmsrequire access to the original data to derive parameters, e.g.,hash values, that are required during detection. As differentdataembedding applications have different requirements,we distinguish between these cases in this review.Note also that most dataembedding algorithms assumethat it is desirable to have secure dataembedding andextraction procedures. Specifically, a secret key typicallydetermines how the data are embedded in the host signal. A user needs to know that key to extract the data.Knowledge of that key and the embedding algorithm wouldalso allow the user to overwrite or erase the embeddedinformation. In some applications, e.g., copy control inDVD or fraud detection by a recipient of the signal, itis desirable to give all users access to the embedded datawithout enabling them to change or remove that data. Thisproblem has been addressed in cryptography. However,the solutions developed in cryptography cannot be applieddirectly in the watermarking or datahiding context. Infact, to date, no satisfactory solution to that problem hasbeen proposed within the dataembedding or watermarkingliterature. Some pioneering work in that area is describedin 33.The goal of this paper is to present an overview ofthe challenges and issues that need to be addressed bysuccessful watermarking and dataembedding techniquesand the current state of the art. Dataembedding and watermarking research builds on ideas and concepts developedin cryptography, communications theory, algorithm design,and signal processing. The dataembedding problem isinherently more difficult than any of the problems thathave traditionally been addressed in these fields. All dataembedding algorithms combine and extend in a sense manyof the solutions developed in these areas. Most of thepublished work on data embedding that has appeared intechnical journals and conferences focuses on image andvideo data. On the other hand, most of the publishedwork on audio data embedding has appeared in the patentliterature. The coverage of this review in the audio, image,and video areas is basically proportional to the existingjournal and conference literature in these three fields.In the next section, a brief historical overview of the fieldis given. In particular, we relate some of the techniques thathave been proposed recently in the areas of data embeddingand watermarking to older steganographical techniques.In Section III, the basic requirements of data embeddingand watermarking are addressed. We discuss the differentsecurity and robustness requirements of dataembedding applications. We also review the deadlock problem that arisesin ownership identification and describe two solutions. Dataembedding and watermarking in digital media are possiblebecause of the limitations of the human auditory and visualsystems. We review some properties of human auditory andvisual perception in Section IV. Following this review, wedescribe the principles that underlie current dataembeddingapproaches. We provide examples to illustrate the capability of todays technology. Sections VVII present image,audio, and video dataembedding techniques, respectively.We conclude the paper with a brief overview of visiblewatermarking approaches.II. HISTORYDataembedding and watermarking techniques are particular embodiments of steganography from the Greekwords or stegano for covered and graphos, towrite. In contrast to cryptography, which focuses on rendering messages unintelligible to any unauthorized personswho might intercept them, the heart of steganography liesin devising astute and undetectable methods of concealingthe messages themselves.Marking of documents may have evolved alongside human writing during the dawn of Western civilization. Sinceknowledge of writing was often restricted to a privilegedand powerful class, the need to conceal messages fromtraitors and enemies within these circles appears to havebeen a serious concern. In a historical text on coding43, Kahn traces the roots of secret writing back 4000years to the banks of the Nile, where hieroglyphic symbolsubstitutions were used to inscribe information in the tombof a nobleman, Khnumhotep II. The intent of the substitutions is ambiguous. The earliest allusion to secret writingin the West with concrete evidence of intent appears inHomers Iliad 35. Steganographic methods per se madetheir recorded debut a few centuries later in several talesSWANSON et al. MULTIMEDIA DATA EMBEDDING AND WATERMARKING 1065by Herodotus 34, although the term steganography doesnot come into use until many centuries later, in the 1500s,after the appearance of Trithemius book on the subject,Steganographia. Ancient references to secret writing andsteganography also appear in Asia. Indian literature isreplete with references as well as explicit formulas forsecret writing. Kautilyas Arthasastra which dates back to321300 B.C., the LalitaVistara, and Vatsayanas Kamasutra are a few of the more famous examples. In fact,the study of many different types or cryptography, not juststeganography, flourished in ancient India. In ancient China,military and diplomatic rulers wrote important messages onthin sheets of silk or paper. For secure transport, the sheetswere rolled into balls, covered with wax, and swallowedby or placed in the rectum of messengers. Less sensitive,routine messages were usually memorized, then transmittedorally by a messenger.It is interesting to note that many of the steganographicaltechniques that had been devised in the past have recentlyreappeared in the dataembedding and watermarking literature. For example, a class of steganographic techniquesrelies on using semagrams sema for sign and grammafor something written or drawn, i.e., very slight physicaldifferences in appearance such as special fonts, punctuationmarks, or very fine dots. A wellknown semagram approachconsists of marking text using barely visible pin pricks,small dots, and dashes. The technique was suggested byAenas the Tactician and used during the Renaissance andup through the twentieth century. A modern adaptationof the technique is used in WitnesSoft by Aliroo,1 whichmarks electronic documents during printout with barelyvisible dots, which can only be picked up by highresolutionscanners. Embedding of messages by lowering specifiedletters and varying spacing between words appears timeand again throughout history. Recently, the technique hasbeen revisited in a digital context by scientists who areinvestigating digital watermarking of text files 6, 49,56, 93, 98. Examples of nontextual semagrams areequally replete. Spies have embedded messages in Morsecode in drawings, e.g., landscapes with short and tall leavesof grass representing dots and dashes. Graphs have beendisguised in mazes in a puzzle book, as have images inautostereograms. A modern extension of these techniquesis the embedding of marks, such as VOID, in an image ordocument that appear only when photocopied 58. An earlyexample of copyright or authorship information in musicalscores was practiced by Bach. Bach embedded his namein many of his pieces e.g., his organ chorale Vor deinemThron using null cipher coding by spelling out BACHin notes where Bflat represents B, and B represents Hor by counting the number of occurrences of a note oneoccurrence for A, two for B, three for C, and eight for H.III. REQUIREMENTSAs mentioned in the introduction, data embedding canbe used in many different applications. Obviously, differ1 See httpwww.aliroo.com.ent applications will have different requirements. Therefore, there is no unique set of requirements that all dataembedding techniques must satisfy. Nevertheless, certainrequirements must be satisfied in several application areas.In this section, we shall review some of these requirementsand indicate when they are important.A. Perceptual TransparencyThe focus of this paper is on perceptually undetectable ortransparent dataembedding and watermarking techniques.In many applications, such as copyright and usage tracking,embedding metadata or additional information, the algorithms must embed data without affecting the perceptualquality of the underlying host signal. In some applications, such as lowquality browsing of signals prior topurchasing, perceptually detectable watermarks have beenused. We shall have more to say about such watermarks inSection VIII.A dataembedding procedure is truly imperceptible ifhumans cannot differentiate between the original host signaland a host signal with inserted data. Typically, blind testsare used to assess the perceptual transparency of dataembedding procedures. In such tests, subjects are presentedrandomly with signals with and without embedded dataand asked to determine which signal has a perceptuallyhigher quality. A probability of selecting the signal with noembedded data that is roughly equal to 50 is indicativeof perceptual transparency. Note that the blind tests mustassess also the effect of several of the typical modificationsthat the signal may undergo. For example, digital picturestypically undergo a sharpening or highpass filtering operations. Data embedding should not produce artifacts that areperceptually dissimilar from those that may be seen in anuntampered image.B. Recovery of Data with or WithoutAccess to Original SignalIn some applications, such as copy tracking and copyrightprotection, the dataextraction algorithms may use the original signal to decode the embedded data. However, in mostapplications, dataembedding algorithms do not have accessto the original audio, image, or video signal while extractingthe embedded signal. This inability to access the originalsignal limits the amount of data that can be embedded ina given host signal. It also renders data extraction moredifficult.Specifically, the embedded data may be considered asinformation transmitted on a communication channel andcorrupted by strong interference and channel effects. Thestrong interference consists of the host signal. Channeleffects correspond to postprocessing operations. Most dataextraction procedures are inherently projection techniqueson a given direction. Ideally, a larger projection valuewill indicate the presence of one type of data, e.g., abinary symbol or a watermark that represents an author.A segment of the host signal that is highly correlated withthe projection direction will provide a false detection. Fur1066 PROCEEDINGS OF THE IEEE, VOL. 86, NO. 6, JUNE 1998thermore, it may be impossible to modify that segment toreduce its correlation with the projection direction withoutaffecting the perceptual quality of the host signal. Hence,the algorithm may be unable to embed useful data into thatsegment.Note that the projection direction cannot be easilychanged since the decoder does not have access to theoriginal host signal. Any change in that direction must beaccomplished through an algorithm that uses the receivedmodified host signal. Note also that the probability ofgetting a high correlation between an arbitrary segment ofthe host signal and the projection direction decreases asthe size of the segment increases. However, as that sizeincreases, the amount of data that can be embedded in thehost signal decreases.Postprocessing effects can complicate the detectionprocess. For example, synchronization problems mayarise as a consequence of temporal and spatial rescaling,cropping, resampling, rotation, etc. Many modificationslead to new signals, which have a different number ofsamples than the original signal with embedded data.To extract the embedded information, the extractionalgorithm must adapt to the new signal with fewer samplesautomatically or access the original to register the signal.Note, however, that loss of synchronization does not implythat the embedded data have been erased. If complexity isnot an issue, the data can still be recovered.C. Bit Rate of DataEmbedding AlgorithmSome applications of data embedding, e.g., insertion ofa serial number or author identification or fraud detection,require that relatively small amounts of information be incorporated repeatedly in the signal. On the other hand, manyenvisioned applications of data embedding, e.g., embeddinga smaller image into a larger image or embedding multiplespeech signals into a video, require a lot of bandwidth.In these cases, the algorithms must be able to embed anamount of data that is a significant fraction of the amountof data in the host signal. As mentioned above, the ability toembed large quantities of data in a host signal will dependcritically on how the embedding algorithm can adapt itsinsertion strategy to the underlying host signal.D. RobustnessSome dataembedding applications may take place inan errorfree or lossless environment. For example, theembedded data may provide digital object identifiers foruse in clean signals residing in a controlled data base. Inthese situations, robustness to signal degradations is notimportant. In many cases, however, lossy signalprocessingoperations may be present in the system. For example, inmost applications involving storage or transmission of animage, a lossy coding operation is performed on the imageto reduce bit rates and increase efficiency. Digital dataare readily modified and manipulated using computers andwidely available software packages, e.g., Adobe Photoshopor Premiere. Operations that damage the host signal alsodamage the embedded data. Furthermore, third parties mayattempt to modify the host signal to thwart detection of theembedded data.Designers of robust dataembedding procedures havefocused on several types of malicious or incidental hostsignal modifications. These modifications include additive Gaussian or nonGaussian noise linear filtering, e.g., lowpass and highpass filtering nonlinear filtering, e.g., median filtering compression, e.g., Joint Photographic Experts GroupJPEG, Moving Picture Experts Group MPEG,wavelet local exchange of samples, e.g., permutations quantization of sample values rotation spatial or temporal scaling removal or insertion of samples, pixels, or videoframes temporal averaging, e.g., averaging of successive videoframes swapping of data, e.g., swapping of successive videoframes averaging multiple watermarked copies of a signal digitalanalog DA and analogdigital AD conversions, e.g., printing and scanning or tape recording andredigitization.Note that software to test robustness and remove dataembedded from images is widely available on the Internet.In particular, the UnZign2 and StirMark 45 programs haveshown remarkable success in removing data embedded bycommercially available programs. The algorithms generallyapply minor geometric distortions, e.g., slight stretching,shearing, shifting, andor rotations, to the image and thenresample the image using bilinear interpolation. The resulting image looks perceptually similar to the original signalwith embedded data.E. SecurityIn many applications, the embedding procedure must besecure in that an unauthorized user must not be able todetect the presence of embedded data, let alone removethe embedded data. Security requirements vary with application. The most stringent requirements arise in covertcommunication scenarios. The security of dataembeddingprocedures is interpreted in the same way as the security ofencryption techniques. A secure dataembedding procedurecannot be broken unless the unauthorized user has access toa secret key that controls the insertion of the data in the hostsignal. Hence, a dataembedding scheme is truly secure ifknowing the exact algorithm for embedding the data doesnot help an unauthorized party to detect the presence ofembedded data. An unauthorized user should also be unableto extract the data in a reasonable amount of time even if2 See httpaltern.orgwatermark.SWANSON et al. MULTIMEDIA DATA EMBEDDING AND WATERMARKING 1067he knows that the host signal contains data and is familiarwith the exact algorithm for embedding the data. Note thatin some applications, e.g., covert communications, the datamay also be encrypted prior to insertion in a host signal.F. Copyright Protection and Ownership DeadlockDataembedding algorithms may be used to establishownership and distribution of data. In fact, this is theapplication of data embedding or watermarking that hasreceived most attention in the literature. Unfortunately,most current watermarking schemes are unable to resolverightful ownership of digital data when multiple ownership claims are made, i.e., when a deadlock problemarises. The inability of many dataembedding algorithms todeal with deadlock, first described by Craver et al. 15,is independent of how the watermark is inserted in themultimedia data or how robust it is to various types ofmodifications.Today, no scheme can unambiguously determine ownership of a given multimedia signal if it does not use anoriginal or other copy in the detection process to at leastconstruct the watermark to be detected. A pirate can simplyadd his watermark to the watermarked data or counterfeita watermark that correlates well or is detected in thecontested signal. Current dataembedding schemes used ascopyrightprotection algorithms are unable to establish whowatermarked the data first. Furthermore, none of the currentdataembedding schemes has been proven to be immune tocounterfeiting watermarks that will correlate well with agiven signal as long as the watermark is not restricted todepend partially in a noninvertible manner on the signal.If the detection scheme can make use of the originalto construct the watermark, then it may be possible toestablish unambiguous ownership of the data regardless ofwhether the detection scheme subtracts the original from thesignal under consideration prior to watermark detection ornot. Specifically, 16 derives a set of sufficient conditionsthat watermarks and watermarking schemes must satisfy toprovide unambiguous proof of ownership. For example, onecan use watermarks derived from pseudorandom sequencesthat depend on the signal and the author. Reference 16establishes that this will work for all watermarking procedures regardless of whether they subtract the original fromthe signal under consideration prior to watermark detectionor not. Reference 85 independently derived a similar resultfor a restricted class of watermarking techniques that relyon subtracting a signal derived from the original from thesignal under consideration prior to watermark detection.The signaldependent key also helps to thwart the mixandmatch attack described in 16.An author can construct a watermark that depends on thesignal and the author and provides unambiguous proof ofownership as follows. The author has two random keysand i.e., seeds from which a pseudorandom sequencecan be generated using a suitable pseudorandom sequencegenerator 76. Popular generators include RSA, Rabin,BlumMicali, and BlumBlumShub 25. With the twoproper keys, the watermark may be extracted. Without thetwo keys, the data hidden in the signal are statisticallyundetectable and impossible to recover. Note that classicalmaximal length pseudonoise sequences i.e., sequencegenerated by linear feedback shift registers are not usedto generate a watermark. Sequences generated by shiftregisters are cryptographically insecure one can solve forthe feedback pattern i.e., the keys given a small numberof output bits .The noiselike sequence may be used to derive theactual watermark hidden into the signal or to control theoperation of the watermarking algorithm, e.g., to determinethe location of pixels that may be modified. The keyis author dependent. The key is signal dependent. Thekey is the secret key assigned to or chosen by theauthor. The key is computed from the signal that theauthor wishes to watermark. It is computed from the signalusing a oneway hash function. For example, the tolerableerror levels supplied by masking models see Section IVare hashed in 85 to a key . Any one of a number ofwellknown secure oneway hash functions may be used tocompute , including RSA, MD4 77, and SHA 60. Forexample, the BlumBlumShub pseudorandom generatoruses the oneway function , wherefor primes and so that . It canbe shown that generating or from partial knowledgeof is computationally infeasible for the BlumBlumShubgenerator.The signaldependent key makes counterfeiting verydifficult. The pirate can only provide key to the arbitrator. Key is automatically computed by the watermarkingalgorithm from the original signal. As it is computationallyinfeasible to invert the oneway hash function, the pirateis unable to fabricate a counterfeit original that generates adesired or predetermined watermark.Deadlock may also be resolved using the dual watermarking scheme of 85. That scheme employs a pairof watermarks. One watermarking procedure requires theoriginal data set for watermark detection. The second watermarking procedure does not require the original data set.A dataembedding technique that satisfies the restrictionsoutlined in 16 can be used to insert the second watermark.The above discussion clearly highlights the limitationof watermarking as an unambiguous mean of establishing ownership. Future clever attacks may show that theschemes described in 16 or 85 are still vulnerableto deadlock. Furthermore, all parties would need to usewatermarking techniques that have been proven or certifiedto be immune to deadlock to establish ownership of media.Note also that contentions of ownership can occur in toomany different forms. Copyright protection will probablynot be resolved exclusively by one group or even theentire technical community since it involves too manylegal issues, including the very definition of similarity andderived works. Many multidisciplinary efforts are currentlyinvestigating standards and rules for national and international copyright protection and enforcement in the digitalage.1068 PROCEEDINGS OF THE IEEE, VOL. 86, NO. 6, JUNE 1998Fig. 1. Diagram of a dataembedding algorithm. The informationis embedded into the signal using the embedding algorithm anda key. The dashed lines indicate that the algorithm may directlyexploit perceptual analysis to embed information.IV. SIGNAL INSERTION THE ROLE OF MASKINGThe first problem that all dataembedding and watermarking schemes need to address is that of inserting data in thedigital signal without deteriorating its perceptual quality.Of course, we must be able to retrieve the data from theedited host signal, i.e., the insertion method must alsobe invertible. Since the datainsertion and datarecoveryprocedures are intimately related, the insertion scheme musttake into account the requirement of the dataembeddingapplication. In many applications, we will need to be ableto retrieve the data even when the host signal has undergonemodifications, such as compression, editing, or translationbetween formats, including AD and DA conversions.Data insertion is possible because the digital mediumis ultimately consumed by a human. The human hearingand visual systems are imperfect detectors. Audio andvisual signals must have a minimum intensity or contrastlevel before they can be detected by a human. Theseminimum levels depend on the spatial, temporal, and frequency characteristics of the human auditory and visualsystems. Further, the human hearing and visual systems arecharacterized by an important phenomenon called masking.Masking refers to the fact that a component in a given audioor visual signal may become imperceptible in the presenceof another signal called the masker. Most signalcodingtechniques e.g., 41 exploit the characteristics of thehuman auditory and visual systems directly or indirectly.Likewise, all dataembedding techniques exploit the characteristics of the human auditory and visual systems implicitlyor explicitly see Fig. 1. In fact, embedding data would notbe possible without the limitations of the human visual andauditory systems. For example, it is not possible to modifya binary stream that represents programs or numbers thatwill be interpreted by a computer. The modification woulddirectly and adversely affect the output of the computer.A. The Human Auditory System HASAudio masking is the effect by which a faint but audiblesound becomes inaudible in the presence of another louderaudible sound, i.e., the masker 42. The masking effectdepends on the spectral and temporal characteristics of boththe masked signal and the masker.Frequency masking refers to masking between frequencycomponents in the audio signal. If two signals that occursimultaneously are close together in frequency, the strongermasking signal may make the weaker signal inaudible. Themasking threshold of a masker depends on the frequency,sound pressure level, and tonelike or noiselike characteristics of both the masker and the masked signal 61. It iseasier for a broadband noise to mask a tonal signal than fora tonal signal to mask out a broadband noise. Moreover,higher frequency signals are more easily masked.The human ear acts as a frequency analyzer and candetect sounds with frequencies that vary from 10 to 20 000Hz. The HAS can be modeled by a set of bandpass filterswith bandwidths that increase with increasing frequency.The bands are known as the critical bands. The criticalbands are defined around a center frequency in which thenoise bandwidth is increased until there is a just noticeabledifference in the tone at the center frequency. Thus, if afaint tone lies in the critical band of a louder tone, the fainttone will not be perceptible.Frequencymasking models are readily obtained from thecurrent generation of highquality audio codecs, e.g., themasking model defined in the International Standards Organization ISOMPEG Audio Psychoacoustic Model 1 forLayer I 40. The Layer I masking method is summarizedas follows for a 32kHz sampling rate. The MPEG modelalso supports sampling rates of 44.1 and 48 kHz.The frequency mask is computed on localized segmentsor windows of the audio signal. The first step consists ofcomputing the power spectrum of a short window 512 or1024 samples of the audio signal. Tonal sinusoidal andnontonal noisy components in the spectrum are identifiedbecause their masking models are different. A tonal component is a local maximum of the spectrum. The auditory system behaves as a bank of bandpass filters, with continuouslyoverlapping center frequencies. These auditory filters canbe approximated by rectangular filters with critical bandwidth increasing with frequency. In this model, the audibleband is therefore divided into 24 nonregular critical bands.Next, components below the absolute hearing thresholdand tonal components separated by less than 0.5 Barksare removed. The final step consists of computing individual and global masking thresholds. The frequency axisis discretized according to hearing sensitivity and expressfrequencies in Barks. Note that hearing sensitivity is higherat low frequencies. The resulting masking curves are almostlinear and depend on a masking index different for tonal andnontonal components. They are characterized by differentlower and upper slopes depending on the distance betweenthe masked and the masking component. We use todenote the set of frequencies present in the test signal. Theglobal masking threshold for each frequency takes intoaccount the absolute hearing threshold and the maskingcurves of the tonal components and nontonalcomponents1SWANSON et al. MULTIMEDIA DATA EMBEDDING AND WATERMARKING 1069Fig. 2. Example of frequency masking in an audio signal. The original spectrum of the signal,along with the corresponding masking threshold, is shown in the plot.The masking threshold is then the minimum of the localmasking threshold and the absolute hearing threshold ineach of the 32 equalwidth subbands of the spectrum. Anysignal that falls below the masking threshold is inaudible.An example plot of an original spectrum, along with themasking threshold, is shown in Fig. 2.Temporal masking refers to both pre and postmasking.Premasking effects render weaker signals inaudible beforethe stronger masker is turned on, and postmasking effectsrender weaker signals inaudible after the stronger masker isturned off. Premasking occurs 520 ms before the maskeris turned on while postmasking occurs from 50200 msafter the masker is turned off 61. Note that temporal andfrequency masking effects have dual localization properties.Specifically, frequencymasking effects are localized inthe frequency domain, while temporalmasking effects arelocalized in the time domain.Temporalmasking effects may be estimated using theenvelope of the host audio. The envelope is modeled as adecaying exponential. In particular, the estimated envelopeof signal increases with and decays as .A 32kHz audio signal, along with its estimated envelope,is shown in Fig. 3.B. The Human Visual System HVSVisual masking, which works in a fashion similar to audiomasking, refers to a situation where a signal raises thevisual threshold for other signals around it. As in audio,a spatial sinusoidal pattern will lower the detectability ofother sinusoidal patterns whose frequencies are close tothat of the sinusoidal pattern 48. This is referred to asfrequency masking. Similarly, spatial patterns can affect thevisibility of other features that are spatially close to them.For example, luminance edges and fine details reduce thevisibility of other signals around them.In our work, we have used a model for frequency maskingthat is directly based on measurements of the amounts bywhich the visual threshold for signal gratings around amasking frequency are raised due to a masking grating atthat frequency 48. In particular, a model we use 99,based on the discrete cosine transform DCT, expressesthe contrast threshold at frequency as a function of , themasking frequency , and the masking contrast2where is the detection threshold at frequency . Theweighting function centered about isshown in Fig. 4.To find the contrast threshold at a frequency inan image, we first use the DCT to transform the imageinto the frequency domain and find the contrast at eachfrequency. Then, we use a summation rule of the form. If the contrast error at isless than , the model predicts that the error is invisibleto human eyes.A spatial masking model based on the threshold visionmodel is proposed by Girod 22. The model accuratelypredicts the masking effects near edges and in uniformbackground. Assuming that the modifications to the imageare small, the upper channel of Girods model can belinearized 99 to obtain the tolerable error level for each1070 PROCEEDINGS OF THE IEEE, VOL. 86, NO. 6, JUNE 1998Fig. 3. Example of temporal masking in an audio signal. The original signal and the estimatedenvelope are plotted in the temporal domain.Fig. 4. Normalized image frequencymasking function.coefficient. This is a reasonable assumption for transparentwatermarking.Under certain simplifying assumptions, the tolerable errorlevel for a pixel can be obtained by first computingthe contrast saturation at3where the weight is a Gaussian centered atthe point and is a visual testbased threshold. Onceis computed, the luminance on the retina isobtained from4From , the tolerable error level for the pixelSWANSON et al. MULTIMEDIA DATA EMBEDDING AND WATERMARKING 1071is computed from5The weights and are based on Girodsmodel. The masking model predicts that changes to pixelless than introduce no perceptible distortion.V. IMAGE DATAEMBEDDING APPROACHESWe begin with a review of image dataembedding techniques since they are the most common in the literature.Audio and video dataembedding algorithms are reviewedin the following sections. The dataembedding algorithmsare classified into those that implicitly use masking andthose that explicitly employ masking to embed the data. Asdescribed in Section IV, all dataembedding algorithms implicitly employ limitations of the HAS and HVS to embeddata. However, some use advanced perceptual models todetermine the best way to embed data.A. Image Data Embedding Implicitly Based on MaskingOne of the simplest methods for inserting data into digitalsignals in noisefree environments is least significant bitLSB coding. The coding process begins with all of theLSBs of the host image set to zero or all to one zeroesand ones are then used to embed information in the LSBplane, e.g., a pattern or image in which 0 represents blackand 1 represents white, or words coded in binary form. Ananalogous procedure can be used for color images, whichare represented by three matrices for the intensities of thecolors e.g., red, green, and blue in the image. LSB codingintroduces noise of at most one unit, which, in practice, isimperceptible, so long as the host signal is not extremelylow or weak.LSB coding can be used to tag office memos onto digitaldata. For example, it has been used for the placement ofmarkers to detect enlargements or reductions of an imagethat may have taken place during photo editing and torecover the associated dilation factor. Transparent crossmarks are embedded in the LSB plane at fixed intervals inboth the horizontal and vertical directions prior to editing.Changes in the dimensions made during editing can bedetected and quantitatively measured by comparing thedistances between the cross marks before and after the edit27. If cropping of an image is also expected, horizontaland vertical line numbers can be embedded at fixed intervalsin the LSB plane to keep track of the pixel indexes fromwhich a crop is made. The pixel index information willremain with the cropped image and can be recoveredwithout a copy of the original, fullsize image.LSB coding has been practiced for decades however,proposed use of the method for intellectual propertyrightsmanagement is relatively new. The concept of a digitalsignature for authentication of electronic messages was introduced by Diffie and Hellman 19 and has since becomea major area of research. More than a decade later, Matsuiand Tanaka introduced the notion of video steganographyTable 1 Example of Cipher Key Tablein a series of conference papers that are surveyed in 54and 55. Embedding methods are proposed for grayscale,dithered binary, facsimile, and color still images and video.The first embedding scheme is for digitized grayscaleimage data, which consists of a set of integers between0 and 255, representing the gray levels of an image atsampled points. The digitized image data isconverted to a sequence in which the first element is andsubsequent elements are the differences between successivepoints, i.e., . Next, the persons embeddingand extracting the message agree on the use of a particularcipher key table, which assigns a value , either zero orone, to each see Table 1. To embed a binary sequenceor , look up the value ofcorresponding to in the table. If , then keepas is. If , go to the nearest such that andsubstitute in place of . The error introduced into theimage data during the th step is error , whichis usually on the same order as noise, i.e., negligible. Thehidden message can be retrieved by looking up the valuefor corresponding to .In a second scheme, which uses ordered dithering, animage is divided into 4by4 pixel blocks and brightnessthresholds  for each of the 16 pixelsin the block are assigned from top to bottom, left to right.Next, define sets6Let be a pair of output signals that pass through. Then is either , , , or, where 0 indicates that the pixel will be turned offand 1 indicates on. Only the pairs or willbe used to embed a sequence of bitsor . To embed , set .To embed , set . To decode,disregard the and outputs and simply reversethe procedure described above.Facsimile document signals serve as the host medium fora third messageembedding scheme. Documents are digitized following the international standard facsimile scanning rate of 8.23 pixelsmm in the horizontal direction 12.3The scanned data indicate whether a pixel is black or white,the two options. The messageembedding scheme is basedon the fact that the data will be compressed using runlengthcoding RLC and modified Huffman coding schemes. RLCreduces data by replacing repeated characters with threecharacters a flag character to signal that compression follows, the repeated character, and the number of repetitions.A binary message or isembedded by shortening or lengthening runs by one pixel atthe boundaries of the runs. In a simple illustrative example,3 See httpwww.infomedia.netscan.1072 PROCEEDINGS OF THE IEEE, VOL. 86, NO. 6, JUNE 1998runs are set to be even number length when byleaving it as is if it is already of even length and lengtheningit by one if it is odd and to an odd length whenby leaving it as is if it is already of odd length and byshortening it by one if it is even. Runs used for codingmust have a length greater than two.Van Schydel et al. 90 also propose LSB coding methods that rely on sequences for transparently embeddingmessages with greater security than straightforward LSBcoding. A binary sequence is mapped from to. In one method, the message is embedded in theLSB plane using sequences. The second is based on LSBaddition. Some disadvantages of the method are hostileparties will know that all pixels are changed by either 1knowledge of a string of repeating consecutive bits enablesthe recovery of the data and embedding is performedwithout regard to the DCT coefficients, so there is noguarantee of robustness with respect to JPEG.Wolfgang and Delp 96, 97 extend van Schyndel etal.s work to two dimensions. Localization, i.e., detectionof the presence of the data, is improved under the newscheme. Localization relies on use of the crosscorrelationfunction of two images and , defined as7Let be the original image, the watermark, thewatermarked image, and a possible forgery. The teststatistic defined as8can often detect whether or not is a forgery. If andare identical, then . In one implementation oftheir method, Wolfgang and Delp embed data consisting ofchanges by . In another, the changes are bipolar, i.e.,. The bipolar data are easier to detect using the teststatistic . Both types of marking are robust with respectto the test statistic under JPEG compression. Informationregarding the preservation of the data is not given.LSB coding can and should be used in contexts that donot require more sophisticated approaches however, it isnot robust enough for general distribution because binarysequences are embedded in a manner that requires perfectpreservation of the signal for successful extraction of thehidden message noisy transmission, filtering, cropping,color space conversion, or resampling would destroy themessage. A more serious concern with LSB coding is thepossibility of extraction of a binary message by hostileparties.To alert the user to contamination or tampering of LSBcoded data, Walton 95 suggests using check sums 78.To circumvent interception of an embedded message byhostile parties, Walton 95 and Matsui and Tanaka 55recommend controlling the embedding locations throughthe use of keys, e.g., the use of a pseudorandom numbergenerator to determine a pseudorandom walk on the imagepixel plane 44, 53. After a userspecified number ofsteps, say, , a check digit for the pixel values at thepreceding positions is embedded in the st pixel alongthe random walk. This procedure is repeated many times.Users should doublecheck that the path of the randomwalk does not cross over itself during the embedding of thecheck sums since it could lead to false alarms of tampering.If the possible discovery of the pseudorandom sequencegeneration mechanism by a hostile party is a consideration,variations that disguise the locations of the check sums canbe developed to prevent tampering with the check sumsthemselves.For color images, the basic checksum scheme can beapplied, straightforwardly, three times to the three colorplanes. More interesting variations that take advantage ofthe three dimensions from the three color planes can bedeveloped. The basis set for representing the images, forexample, can be changed from redgreenblue RGB tohuelightnesssaturation the check sum is then calculatedin the new coordinate system, and the checksum digitis encoded in the original coordinate system. For furtherdetails on standard bases for colorimage representationand conversion factors, see 79. Matsui and Tanakasembedding methods, with and without check sums, arenot robust with respect to cropping. In concluding ourdiscussion on LSB coding, we remark that steganographicfreeware for image marking is widely available over theInternet.In Ohnishi and Matsuis Haar wavelet transformbasedmethod, messages are embedded by adding or subtractingone from the transform coefficients of the image 64. LikeLSB coding, the technique is very fragile with respect tosimple tampering, e.g., cropping.Sanford et al. developed software BMPEMBED, ver.1.51 in the C programming language for embedding datainformation into and extracting the information from colorimages in bitmap format 80. The principles of the methodare outlined in the algorithm for grayscale images. Embedding consists of two main steps. First, an image is analyzedto identify pairs of elements i.e., pixel values and ,which are within a noise range9and such that and , the frequency of occurrenceof and , are fairly large and within a tolerance10Binary information will be embedded by using the valueto represent a zero and to represent a one or vice versa.The main principles used in marking grayscale images areextended to mark color images. Identification of pairs ofpixels within acceptable noise ranges is a more complicated process for colorimage data. Embedding in JPEGand wavelet transform compressed images is accomplishedthrough the use of the same technique in the DCT andwavelet transform domains. In the experiments describedin the report, robustness with respect to further JPEGcompression and restoration is not considered or tested.This embedding method suffers from other drawbacks, e.g.,SWANSON et al. MULTIMEDIA DATA EMBEDDING AND WATERMARKING 1073fragility with respect to cropping and multiple embeddingsand depending on the image limited available space forembedding. Since a fairly substantial amount of work isrequired to analyze images to determine suitable embeddinglocations, realtime image retrieval may only be possibleif the locations are determined ahead of time use ofpredetermined, fixed embedding locations for a given imageincreases the ease in tampering and extraction of embeddedinformation by hostile parties.Bender et al. propose texture block coding, in which ablock from a region with a random texture is copied andplaced in a region with similar texture 2. Extraction of thehidden block is easy. Slides of the original image and itsopposite in which each pixel is replaced by are overlayed. As one slide is moved across the other, asolid black region will appear when the embedded blockand the original region, from which it was taken, overlap.The method cannot be applied to all images and is notamenable to automatic embedding since images must beexamined one by one by a human to determine whethersuitable textured regions exist. The method is not robust tocropping. Although regular, twodimensional shapes e.g.,solid circles, rectangles can be readily embedded, thetechnique is not well suited for handling intricate designsand textual information. Furthermore, texture block codingis easy to detect since anyone can make slides of the originalimage and its opposite and extract the embedded block orregion.The same scientists also proposed patchwork, a statisticalapproach, in which a subset of the pixels in an image isdivided into two distinct sets. The brightness of one setof pixels is shifted by a positive number, and those fromthe other set are shifted by the corresponding negativenumber 2. Only a limited amount of information can beembedded in an image using this approach, even if theimage is divided into several regions and a different numberis embedded into each i.e., one number per region. Theinventors provide data that the recovery rate is 85 afterJPEG compression, with quality parameter 75, whichwould likely not stand up as credible evidence beyond areasonable doubt in a court of law.Pitas and Kaskalis use shifting in an approach that allowsslightly more information to be embedded 69, 70. Abinary signature that consists of equal numbers of zerosand ones is embedded in an image by assigning pixelsinto one of two sets. The intensity levels of the pixels in oneof the sets are altered. The intensity levels are not changedin the pixels in the other set. The method is limited tosignature embedding and cannot be used for embeddingtext messages. According to the inventors, the degree ofcertainty can be as low as 84 and as high as 92, whichwould likely not stand up as evidence in a court of lawfor copyright protection. In 94, toral automorphisms areused to chaotically mix binary logos or signatures, whichare added to a secret region in the image.In a similar method by Dautzenberg and Boland, imagesare partitioned into blocks, and the mean is shifted byone or zero to embed binary code 17. The code doesnot necessarily have to consist of equal numbers of zerosand ones. The authors claim robustness to lossy imagecompression, photocopying, color scanning, and dithering.The method suffers from at least two major drawbacks. Theamount of information that can be embedded depends onthe number of blocks in the image. The method cannotbe used to mark images that will be widely distributedusing different marks for each intended recipient becausecomparison of large numbers of differently marked imageswill allow hostile parties to recover the original image.Bruyndonckx et al. also use a block partitioning basedmethod but use the change in the mean values of theluminance in blocks for embedding 9. After an image isdivided into blocks, the embedding order and locations canbe found using a key. The blocks are classified into oneof three types of luminance hard, progressive, and noisecontrast. The pixels are then assigned to zones, which addan extra level of security for embedding. Two categoriesand are created in each zone. Each pixel is assignedto a category based on its block and zone assignment.Embedding of a bit in a block is carried out by changingthe differences in the mean in the luminance values of pixelsin categories and and zones 1 and 2ififwhere , , , and are the mean valuesafter embedding and is the embedding level. To renderthe embedding as transparent as possible, the inventorsrequire that the mean value in each zone be left unchanged.This requirement uniquely determines the values of ,, , and after embedding. To summarize, sixparameters are used to embed information the embeddinglevel , the categories grid size, the block size, the numberof bits to be embedded, the location of the blocks, and thelevel of redundancies with the option of errordetectioncodes if the message is short enough to allow a highlevel of redundant embedding. Robustness to JPEG depends strongly on the compression ratio, embedding level,and grid sizes. Redundant embedding with errorcorrectingcodes is very effective in reducing the error in extractedmessages. Depending on the amount of information tobe embedded which, in turn, determines if redundantembedding can be accommodated, the scheme may or maynot be robust to cropping.Langelaar et al. propose a blockbased method in whichembedding is carried out in the luminancehuesaturationYUV domain 46. The pixel values from 8 8 JPEGblocks of an image or multiples of them are convertedto the YUV domain. After embedding binary information,the blocks are converted back to the RGB domain. If anedgeenhancement filter is applied to the luminance pixelvalues, the error rate for bit extraction after JPEG filteringis reduced significantly from over 10 for JPEG qualityfactor 90 to well under 5. The error rate is under 51074 PROCEEDINGS OF THE IEEE, VOL. 86, NO. 6, JUNE 1998for JPEG quality factor 10060 in experiments describedin the paper by Langelaar et al.Koch and Zhaos dataembedding method, used in theproduct SysCop, is similar to direct sequence and frequencyhopping spreadspectrum communications 20, 68, 92and is compatible with JPEG compression quality parameter50 51. An image is partitioned into 8by8 blocks, andeight coefficients in the block are used for marking. Theblocks are pseudorandomly selected to minimize detection.Since the locations of the eight coefficients have beenpublished, hostile parties can use the information to corruptor destroy a message. Decoding by unauthorized parties ismore difficult because of the pseudorandom sequence usedfor embedding. Cropping of images may lead to difficultiesin extracting messages that were pseudorandomly embedded. And cropping along lines that cut through, rather thanalong, the 8by8 JPEG blocks may lead to an image thatis not robust to JPEG compression. Langelaar et al. reportthat image degradation is visible in their implementationstudies to assess Koch and Zhaos method, and results areshown in a paper 46. A variation on Koch and Zhaosmethod for image authentication is presented by Schneiderand Chang 11. The technique alters transform coefficientsto enforce a relationship between the coefficients.Spreadspectrum embedding spreads the watermark overa larger number of frequency ranges, the idea being that theenergy in any given frequency range will be undetectable.The watermark can still be checked since the spreadingpattern is known. Another spreadspectrum noise techniqueis described by Smith and Comiskey 82, where theauthors hide data by adding a fixedamplitude pseudonoisesequence to the image.Kutter et al. use amplitude modulation and a secret keyto embed a signature in color images 52. The signaturebits are repeatedly embedded in the blue channel to ensurerobustness. The blue channel is used because the HVS isrelatively less sensitive in this color domain. A single bitis embedded in a pseudorandomly selected pixelin an image by modifying the blue channelby a fraction of the luminance , i.e.,11Here, and is a constantthat represents the strength of the signature. is selectedto optimize robustness and invisibility. The embeddedmessage is retrieved using prediction of the original valueof the pixel based on a linear combination ofits neighboring pixel values. More precisely, the predictionis12where is the size of the crossshaped neighborhood. Theembedded bit is computed to be the difference of thepredicted and coded bit13To reduce the possibility of incorrect retrieval, the bitis embedded many times, and the computed differencesare averaged. Extension to an bit signature is straightforward. The inventors claim and discuss the extent towhich the algorithm is robust to translation, rotations, slightblurring, JPEG attack, and composition with other images.Puate and Jordan use fractal compression analysis to embed a signature in an image 74. In fractal analysis, similarpatterns are identified in an image. Domain blocks ,which represent patterns that appear frequently, are noted.The intent is to identify a set of domain blocks that canbe transformed i.e., contracted, isometrically transformed,luminance scaled, and luminance shifted to approximateblocks within an image. The goal is to cover the entireimage as much as possible with the transformed domainblocks. In fractal compression, the reduced informationconsists of domain blocks, appropriate transformations onthe blocks, and pointers to locations where the transformedblocks should be mapped. A binary signature, consisting ofthe set of bits , is embedded in an image by varying theregions in which patternmatching searches are performed.For a bit , range blocks are pseudorandomly chosen tobe somewhere in region if and in region if. The inventors present data that show that theirmethod is robust with respect to JPEG compression. If theimage is blurred before JPEG compression, the results arenot as good. The binary message can be encoded to increaseprotection from interception by unauthorized parties. Onlya limited amount of binary code can be embedded using thismethod. Since fractal analysis is computationally expensive,and some images do not have many large, selfsimilarpatterns, the technique may not be suitable for general use.Davern and Scott also propose a fractalbased steganographic method to embed binary messages, either plain orencrypted 18. Fractal image analysis is used to identifysimilar blocks. Then transformations are constructed so thatone similar block is transformed into an approximation foranother. These transformations enable visibly imperceptiblesubstitution of blocks. The set of blocks that can be usedas substitutes is divided in two. To embed a zero, substituteblocks from the first set are used, and to embed a one,blocks from the second set are used. Davern and Scottsembedding method suffers from two of the same problemsas that of Puate and Jordan. It is very slow, since fractalanalysis is computationally expensive, and only a limitedamount of information can be embedded. Additionally,Davern and Scotts method appears to be less robust toJPEG compression.ORuanaidh et al. 65 describe a technique where imageblocks are transformed using the DCT, Walsh transform, orwavelet transform. The data are embedded by incrementinga selected coefficient to encode a 1 and decrementing itto encode a 0. Coefficients are selected according to acriterion based on energy content. The watermark survived20  1 JPEG image compression on the standard 256 256Lena image. In a second approach 66, the authors describea technique to embed information in the discrete Fouriertransform phase.SWANSON et al. MULTIMEDIA DATA EMBEDDING AND WATERMARKING 1075Dataembedding techniques that require the original signal during detection are now reviewed. Some early algorithms for transparent marking, such as that by Cox etal. 14, require both the original and marked images forrecovering an embedded message. The differences in theimages is encrypted code. In the algorithm of Cox et al.14, watermarks are embedded in the largest magnitudeDCT coefficients to provide greater robustness to compression algorithms than LSBtype methods. Embeddingin the highest coefficients corresponds to placing marksin the most perceptually significant portions of the image,regions that will remain relatively intact when subjected tocompression. The marking algorithm consists of four steps. Compute the DCT and identify perceptually significantregions of the image suitable for watermark embedding. Construct the watermark , whereeach is chosen according to , wheredenotes a normal distribution with meanand variance . Insert the watermark in the DCT domain of the imageby setting the frequency component in the originalimage to14where is a scalar factor. Compute the inverse DCT of the sum from the previous step to recover a transparently marked image.Note that , the number of DCT coefficients affected bythe watermark, indicates the extent to which the watermarkwill be spread out among the components of the image.The authors choose to be 0.1 in their experiments. Abetter approach would be to set adaptively to differentvalues for different frequencies. A Gaussian type of watermark is used for watermarking because it is much morerobust to tampering than uniform embedding, particularlywhen is large. More specifically, the authors claim thatsimilar types of watermarks would have to beembedded to have any chance of destroying the image.The larger the , the greater the protection provided by thewatermark.Extraction of the watermark by Cox et al. consists offour steps. Compute the DCT of a possibly watermarked image. Compute the DCT of the original image. Compute the difference in the results from the previoustwo steps to a watermark . Compare the extracted mark with the originalwatermark .Comparison of the marks is conducted using a similaritymeasure defined by15Studies on the robustness of the watermarks by Coxet al. show that when i.e., 1000 perceptuallysignificant frequency components of the image spectrumare altered, the watermark is reliable after JPEG encodingquality factor 5, dithering, clipping, clipping with JPEGencoding quality factor 10, and the combination ofprinting, photocopying, subsequent rescanning, and rescaling. When five watermarks were embedded in an image,all were successfully identified. Successful identificationis also reported in averaging five separately watermarkedimages. Stone has published a report in which he showshow the strength of the technique proposed by Cox et al.can be diminished 83 when multiple watermarked copiesare available to a pirate.Ragusa et al. 75 devised and implemented a modification of the algorithm by Cox et al. in which regions ofinterest ROIs are identified from the DCT components.Ragusa et al. assume that for most images, ROIs thatneed to be watermarked for protection will have prominentedges. This assumption reduces the regions that will bemarked so that only 200 or so ROIs need to be marked,as opposed to the 1000 recommended by Cox et al. Theprimary advantage of the modified scheme is the reducedtime required for embedding and extraction and a decreasein the likelihood of noticeable perceptual differences. Thedisadvantage is that solid regions and regions withoutprominent edges will not be marked.Another algorithm that requires the original image isthat by Hsu and Wu 36. The signature is an image ofa seal with Chinese characters. Permutations of the middleband coefficients of the is DCT are used for encoding.The difference between the original and marked imageis used to retrieve the signature. Pseudorandom numbergenerators can be used to increase the security. They canserve several roles, such as designating the permutation andthe embedding location. The inventors claim that the signedimages are robust to general imageenhancement techniquesand JPEG lossy compression.In Fridrich 21, a lowfrequencybased scheme similarto that of Cox et al. is introduced. In the scheme, arandom blackandwhite pattern is processed by a cellularautomaton with the voting rule through several stages andsmoothed with a lowpass kernel. The resulting pattern isadded to the image. The robustness of the technique isreportedly slightly better than 14.In an approach, called tagging, by Caronni 10, imagesare partitioned into blocks, and the mean values of thebrightness of pseudorandomly selected blocks are altered toembed code. When very high security is required, betterrandom positionselection mechanisms should be used.The inventor claims that the tags can be recovered afterJPEG compression with quality parameter 30. And whena modulation strength of 2 and tag size of 16 16 pixelsare used, 75 of the tags from enlarged, colorprinted, andrescanned images can be recovered. In most cases, tags witha modulation strength of 2 are imperceptible. Letand represent the brightness of the original andtagged images and and represent their mean. Thenthe covariance between and variances , of the1076 PROCEEDINGS OF THE IEEE, VOL. 86, NO. 6, JUNE 1998original and marked image are16where . If two images are identical,then the correlation coefficient between the two images. As the images become moredissimilar from tagging, . Note that only imagesof the same size can be compared using this methodof measurement. The tag is recovered by comparing theoriginal and marked image and the key for determining theorder and positions of the tagged blocks.Many commercial image dataembedding algorithms areavailable. Digimarcs PictureMarc4 uses a spreadspectrumtechnique. Using a 32bit binary signature, the least significant bit of the 32 is aligned with the first pixel of the image.If the bit is a 1, the first random number is added to thefirst pixel if the bit is a 0, then it is subtracted. The sameprocess is applied to the second pixel using the secondbit of the signature number to choose whether to add orsubtract the second random number. This is continued untilall 32 bits have been used. The process is then repeated bystarting over at bit 0 while continuing across the image. Thealgorithm is terminated when all pixels have been marked.If the original is available during detection, it is subtractedfrom the signed image, resulting in a difference signal. Thesign of each pixel in the difference image is comparedwith the corresponding code pattern sign. If they match,then the identification signal bit is a one otherwise, it isa zero. This process is repeated over the entire image, andthe individual bits are summed. The sum of each bit isdivided by the number of repetitions of the signature. Theresult is the identification number. In the cases where thereis no original image or changes have occurred to the signedimage, smallsignal detection methods are used to read thesignature.Other commercial software include DICEs Argent technology5 and Aliroos ScarLet algorithm.1B. Image Data Embedding Explicitly Based on MaskingA technique based on spatial and frequency masking ispresented in 84. The data embedding works by breakingan image into small e.g., 8 8 blocks. Each block is thenrepresented as a vector in an dimensional space e.g., and projected onto a normalized pseudorandomauthordefined direction weighted by the masking valuesfor the particular block. With normalized, the projectionof the image block onto the userdefined direction is simplythe inner product .4 See httpwww.digimarc.com.5 See httpwww.digitalwatermark.com80.Fig. 5. Original 512  512 grayscale image.The scalar projection value is then quantized withrespect to the masking levels of that block , creatingthe value . The quantized value is perturbed byto embed the data, i.e., . The new projectioncontains the hidden data. To extract the hidden data,each recovered block is projected onto the appropriatepseudorandom direction, and a simple remainder operationis appliedifotherwise17where is the rounding operation and is the bit embedded in the block. The technique easily accommodates theinsertion of multiple bits per block. Figs. 5 and 6 provide anexample of the algorithm. The image in Fig. 6 was obtainedby embedding an 8192bit text file inside the original imageshown in Fig. 5. Note that the two images are perceptuallyidentical. The bit error rate for the embedded data afterdifferent levels of JPEG coding is shown in Fig. 7. Usingerror correction codes and bit repetition, the data are ableto survive low JPEG qualities. For example, one may use15  1 bit repetition reducing the effective embedded bit rateto about 500 bits for environments with a lot of distortion.Several maskingbased image dataembedding algorithmsthat require the original during detection have been proposed. Cox et al. 14 propose to set 14 adaptivelyaccording to masking values for different frequencies.A blockbased version of 14 that employs visual modelshas been developed by Podilchuk and Zeng 71. Thealgorithm employs the just noticeable difference paradigmemployed by perceptual coders. The watermarked DCTcoefficients are generated by 18, as shown atthe bottom of the next page, where refers to theDCT coefficients at location in block of the image,is the sequence of real valued watermark values,SWANSON et al. MULTIMEDIA DATA EMBEDDING AND WATERMARKING 1077Fig. 6. Image with embedded information.and is the computed just noticeable differencecalculated from the visual models. The detection is performed in the same manner as that of Cox et al. The authorsclaim that the watermark survives uniform noise, cropping,and JPEG compression with a quality factor of 20, as wellas printing, photocopying, rescanning, and rescaling of theimage. The results were slightly better than the originalCox et al. algorithm, indicating some of the advantages ofemploying masking for data embedding. Another efficientimage datahiding algorithm based on perceptual maskingis presented in 24.In 88, the authors present a technique that exploits HVSto guarantee that the embedded watermark is imperceptibleand robust. The watermark is generated by filtering apseudorandom sequence owner identification id with afilter that approximates the frequency and spatial maskingcharacteristics of the HVS. The watermark is generated bysegmenting the image into blocks of size , e.g.,8 8. For each block , there are the following steps.1 Compute the DCT of the image block .2 Compute the frequency mask of the DCT imageblock .3 Use the mask to weight the noiselike authorid for that image block, creating the shaped authorsignature .4 Create the watermark block by computing theinverse DCT of and weighting the result with thecorresponding spatial mask .5 Add the watermark to the block , creatingthe watermarked block .Detection of the watermark is accomplished via hypothesistesting 91 using the similarity measure defined by 15.To illustrate the algorithm, the technique was appliedto the original image shown in Fig. 8a. The resultingwatermarked image is shown in Fig. 8b, along withthe watermark shown in Fig. 8c. The watermark hasbeen rescaled to gray levels for display. The watermarkvalues corresponding to smoother background regions aregenerally smaller than watermark values near edge regions.This is to be expected, as edge regions have more favorable masking characteristics. The absolute values of thewatermark range from 2 smooth regions to 48 edgeregions.The robustness of the algorithm to JPEG coding is shownin Fig. 9. The plot indicates the similarity values of thePeppers test image with and without a watermark atseveral bit rates corresponding to JPEG qualities from 5to 95. To simulate additional attacks on the watermark,colored noise was added to the test image prior to JPEGcoding. Each coding quality was tested 100 times, with adifferent colored noise sequence used during each test. Theerror bars at each quality correspond to the maximum andminimum similarity values at each bit rate. Even at very lowimage quality, the similarity values are separated, allowingthe existence of a watermark to be easily determined.VI. AUDIO DATAEMBEDDING APPROACHESA. Audio Data Embedding Implicitly Based on MaskingSeveral techniques have been proposed in 2 and 28.Using a phasecoding approach, data are embedded by modifying the phase values of Fourier transform coefficients ofaudio segments. The authors also proposed embedding dataas spreadspectrum noise. A third technique, echo coding,employs multiple decaying echoes to place a peak in thecepstrum at a known location.Another audio dataembedding technique is proposed in89, where Fourier transform coefficients over the middlefrequency bands, 2.46.4 kHz, are replaced with spectralcomponents from a signature. The middle frequency bandwas selected so that the data remain outside of the moresensitive lowfrequency range. The signature is of shorttime duration and has a low amplitude relative to the localaudio signal. The technique is described as robust to noiseand the wow and flutter of analog tapes.Pruess et al. 73 embed data into audio by shaping apseudonoise sequence according to the shape of the originalsignal. The data are embedded within a preselected bandof the audio spectrum after proportionally shaping it bythe corresponding audiosignal frequency components. Inifotherwise181078 PROCEEDINGS OF THE IEEE, VOL. 86, NO. 6, JUNE 1998Fig. 7. Bit error rate versus JPEG quality factor for image shown in Fig. 6.particular, the frequency component in the original audiosignal is modified to19where is a sample of the spread data and is a scalarfactor. The inventors claim the composite audio signal is notreadily distinguishable from the original audio signal. Thedata may be recovered by essentially reversing the embedding operation using a whitening filter. As described above,a very similar embedding technique was later employed byCox et al. for image watermarking.Some commercial products are also available. The Identification Code Embedded system from Central ResearchLaboratories inserts a pair of very short tone sequencesinto an audio track.Solana Technology Development Corporation 47 embeds data into subbands of the audio signal. The data to beembedded modulate a pseudonoise spreadspectrum signal,each subband of which has a bandwidth corresponding tothose of the digital audio signal. The modulated data carriersequence is combined with the audio subband samplesto form a combined signal in which the embedded dataare carried. The combined signal is then combined intothe audio signal. At the decoder, the combined signalis demodulated to recover the auxiliary data signal. Therecovered auxiliary data signal is inaudible in the audiosignal and is spectrally shaped according to the audio signalto enhance concealment. Solana has an audio markingproduct called Electronic DNA EDNA and ScarLet byAliroo.Patents for audio data embedding have been filed byRadio Audit Systems, Inc., for a radiobroadcast signalprocessing system with an information encoder 26 and theDICE Company for an apparatus and method for encodinginformation into digital multimedia data 13.Very few audio dataembedding algorithms that use theoriginal audio signal during detection have been proposed.A few image watermarking schemes, e.g., 14, have beendescribed as generic and applicable to audio, although noresults have been reported. This is due to the fact that mostaudio embedding algorithms are designed for broadcast environments. As a result, most audio embedding algorithmsare required to retrieve the embedded information withoutaccess to the original.B. Audio Data Embedding Explicitly Based on MaskingAn audio dataembedding technique based on temporaland frequency masking is presented in 84. The data embedding works by extracting length 512 blocks of the audio.Sequential blocks of length 512 are extracted from the audiosignal and projected onto a pseudorandom authordefineddirection weighted by the masking values for the particularblock. The scalar projection value is then quantized withrespect to the masking levels of that block. To embeddata, the quantized projection value is perturbed to a newvalue. To extract the hidden data, each recovered block isprojected onto the appropriate pseudorandom direction anda simple remainder operation is applied see 17.Moses 57 proposes a technique to embed data byencoding it as one or more whitened direct sequence spreadspectrum signals andor a narrowband frequencyshiftkeying data signal and transmitted at the time, frequency,and level determined by a neural network NN such thatthe signal is masked by the audio signal. The NN monitorsthe audio channel to determine opportunities to insert thedata signal such that the inserted signals are masked.SWANSON et al. MULTIMEDIA DATA EMBEDDING AND WATERMARKING 1079abcFig. 8. An image a original and b watermarked. c Watermarkrescaled to gray levels for display.In 4 and 87, the authors present an audio watermarking algorithm that exploits temporal and frequency maskingsee Section IVA to embed robust and inaudible data.The watermark is constructed by breaking each audio clipinto smaller segments and adding a perceptually shapedpseudorandom sequence.An example showing the robustness of the watermarkingtechnique to MPEG coding is shown in Fig. 10. The audiosignal is the beginning of the third movement of thesonata in B flat major D 960 of Schubert piano, duration12.8 s, interpreted by Ashkenazy. The codingdecodingwas performed using a software implementation of theISOMPEG1 Audio Layer II coder with several differentbit rates 64, 96, and 128 kbitss. The plot shows thesimilarity measure of the audio piece with and withoutthe watermark. The increments on the axis correspond to1.16s segments of audio. For example, the similarity valuesfor block number 2 are measured over the piano signalfrom s to s. As expected, the similarityvalues vary over time as the power of the watermark variestemporally with the power of the host signal. Observe thatthe upper similarity curve for the audio piece is widelyseparated from the lower curve over the entire duration ofthe signal.VII. VIDEO DATAEMBEDDING APPROACHESA. Video Data Embedding Implicitly Based on MaskingFewer documents describing video data embedding areavailable in the public domain relative to image embedding.Most works are statements in papers to the effect thatstraightforward extension of a proposed stillimage markingtechnique would be effective, e.g., 18 and 51. For copyright protection, video data embedding must meet severalrequirements in addition to those for still images becausethe volume of data is of a much higher order and realtimeembedding may be required in some applications, such asvideoondemand systems. The remainder of this sectionwill focus on works that exploit the threedimensionalcharacter of video data i.e., twodimensional images inthe temporal domain and characteristics associated withMPEG compression. Approaches that involve explicit computation of upper and lower bounds for masking by theHVS will then be described.Video data embedding for copy protection has become avery pertinent issue. The Data Hiding Subgroup of the CopyProtection Technical Working Group is currently evaluatingproposals for DVD protection. A dataembedding systemis required to mark video content for the purposes ofidentifying marked material and preventing unauthorizedrecordingplayback. The goal of the technologies is to allowcontent providers to mark all copyrighted digital videomaterial NTSC, PAL, and SECAM with the watermark.Video recordersplayers would respond appropriately byrefusing to record or play improperly marked material.One of the earliest examples of video data embeddingwas proposed by Matsui and Tanaka 55. First, a framefrom the video is divided into 8 8 blocks, and the1080 PROCEEDINGS OF THE IEEE, VOL. 86, NO. 6, JUNE 1998Fig. 9. Detection of watermark in Peppers image after JPEG coding, with qualities from 5 to 95.twodimensional DCT is computed using the formula20where and21The coefficient matrix for the DCT is22where and is the pixel value of theth element in the block. The matrix is quantized by23where is the threshold factor, isspecified by a user to control the bit rate per pixel, and thevalues of are rounded to the nearest integer. Informationis embedded by converting it into a binary sequence, where and or . If ,then is set to be the nearest odd integer , andif , then is set to be the nearest eveninteger. We denote the operation by , the modifiedby , where24and the matrix of as25This dataembedding method is very fragile with respectto noise, cropping, and repeatedly embedding data, sincevalues are only changed incrementally up or down. Furthermore, if many copies of the same video frame withdifferent embedded marks are available, hostile partiescould compare them and might be able to determine theoriginal, unmarked video frame. Embedded messages mightbe extracted by hostile parties unless supplementary precautions e.g., message encryption prior to embedding,pseudorandom embedding locations are used. Since robustness with respect to MPEG video compression wasnot a consideration during the design and test phase of themethod, no data on the subject are given. It is unlikelythat the embedded messages would be preserved aftersubstantial MPEG video compression, but the level offragility is not known.Kinoshita et al. 50 have developed a method to embedinformation transparently in the MPEG motion vector invideo. North Carolina State Universitys SHANG Grouphas developed software called Secure MPEG, which isavailable for free over the Internet.6 Sanford et al. arecurrently investigating extensions of their dataembeddingmethod for still images to video data 80.In extensive studies to extend concepts from stillimage marking by Cox et al. 14, Hartung and Girod23, 2932 propose a spreadspectrum dataembeddingmethod for raw or uncompressed video data and a secondfor MPEG bitstream data. The marking of raw video datato produce a modified signal is described by266 See httpshang.csc.ncsu.edusmpeg.html.SWANSON et al. MULTIMEDIA DATA EMBEDDING AND WATERMARKING 1081Fig. 10. Detection of watermark in piano piece after MPEG coding at 64, 96, and 128 kbitss.where is the pseudonoise sequence, is the embeddedbit, and is a scaling factor. The information is recoveredusing a matched filter. Use of a variable scaling factori.e., use of a sequence rather than a constant  wouldimprove the level of security and robustness. Similar to Coxet al., the authors remark that can be varied according tolocal properties of the video frame or to spatial and temporalmasking properties associated with the HVS. A betterreceiver, which employs a prefilter before decorrelation, ispresented in 32.Hartung and Girod also have a dataembedding methodfor MPEG compressed video. The approach indirectlyexploits masking characteristics, as it is based on the MPEGstream. One of its explicit goals is to avoid an increase inthe bit rate. The embedding procedure consists of sevensteps.1 Compute the DCT of the data. Rescan the DCT coefficients using a zigzag scan to obtain a 1 64 vector.Let denote the zerofrequency DC coefficientand the highest frequency AC component.2 Let and denote the DCT coefficient of unmarked and marked signals and let .3 Find the next variablelength coder VLC in thebitstream and identify the runlevel pairbelonging to the code word and the position andamplitude of the AC DCT coefficient representedby the VLC code word.4 Let denote the candidate for newDCT coefficient. Check that the use of will notincrease the bit rate.5 Let and be the number of bits used for transmitting and , respectively.6 If , then transmit . Else transmit .7 Repeat steps 36 until an endofblock code wordis encountered.Hartung and Girod discuss the robustness of their methodwith respect to several types of attacks discussed inSection IIID. They remark that their data are robust tocompression, filtering, and modest rotations. A detectionand correction mechanism is needed for larger rotations.Removal and insertion of data lead to loss of synchronicityof the pseudonoise sequence between the sender andreceiver so that a mechanism for detecting the loss andfor resynchronizing the pseudonoise sequence is needed tothwart the attacks.Similar to the situation with audio dataembedding algorithms, almost no video dataembedding algorithms thatuse the original have been proposed. Again, a few imagewatermarking algorithms, e.g., 14, have been described asgeneric and applicable to video.B. Video Data Embedding Explicitly Based on MaskingIn 84, the authors present a projectionbased videowatermarking algorithm from an extension of their imagedataembedding algorithm see Section V. An example ofthe technique is shown in Fig. 11. In the example, a 311frame, 120 160 grayscale video of a Madonna videois embedded in an equallength sequence from the movieBroadcast News. The Madonna video is embedded for realtime playback along with the host video, i.e., 30 frames persecond. The Madonna video is encoded using MPEG at abit rate of 294 bytes per frame 8820 bytes per second.The frames of the Broadcast News video are of size 240360. Sample frames from each of the videos are shownin Fig. 11.1082 PROCEEDINGS OF THE IEEE, VOL. 86, NO. 6, JUNE 1998abcFig. 11. Videoinvideo application. a Original Broadcast News video. b Broadcast News videowith embedded c Madonna video. The Madonna video is embedded in real time.In 86, the authors propose an objectbased video watermarking technique. To address issues associated with videomotion and redundancy, individual watermarks are createdfor objects within the video. Similar strategies were discussed at the July 1997 MPEG4 meeting. Each object fromthe video is embedded with a unique watermark accordingits perceptual characteristics. As the object experiencestranslations and transformations over time, the watermarkremains embedded with it. Objects defined in the videoare collected into an object data base. As a result, thedetection algorithm does not require information regardingthe location i.e., index of the test frames in the video.The detection algorithm simply identifies the objects in thetest frames. Once objects are identified, their watermarksmay be retrieved from the data base and used to determineownership.Robustness to MPEG1 coding at very high compressionratios CRs was tested on a 32frame football video.The frame size of the sequence is 240 352. TheMPEG quantization tables were set to the coarsestpossible level to maximize compression. To simulateadditional attacks on the watermark, colored noise wasadded to the test video prior to MPEG coding. The testvideo was tested 100 times, with a different colorednoise sequence used during each run. The minimum,maximum, and mean framebyframe similarity valuesover the 100 runs are shown in Fig. 12. Even at verylow coding quality, the similarity values are widelyseparated, allowing the existence of a watermark to beeasily ascertained.In a second approach 85, the authors employ a watermark that consists of fixed and varying components. Awavelet transform is applied along the temporal axis of thevideo to generate a multiresolution temporal representationof the video. The lowpass frames consist of the static components in the video scene. The highpass frames capturethe motion components and changing nature of the videosequence. The watermark is designed and embedded in eachof these components. The watermarks embedded in the lowpass frames exist throughout the entire video scene due towavelet localization properties. The watermarks embeddedin the motion frames are highly localized in time and changerapidly from frame to frame. The resulting watermark is acomposite of static and dynamic components.For example, the plot in Fig. 13 shows the robustnessof the technique to frame dropping and averaging. In thetest, the odd index frames, i.e., were droppedfrom the test sequence. The missing frames were replacedwith the average of the two neighboring frames,. Colored noise of similar power to thewatermark was added to the result. The resulting detectioncurves in the figure are shown to be widely separated. Theerror bars indicate the maximum and minimum similarityvalues over 100 runs with different colored noise sequences.VIII. VISIBLE MARKING OF IMAGESSophisticated, attractive, and robust visible watermarking methods for enhancing digital documents have beendeveloped and patented 7 by Braudway et al. By robust,SWANSON et al. MULTIMEDIA DATA EMBEDDING AND WATERMARKING 1083Fig. 12. Framebyframe robustness of a football video to MPEG coding at 0.46 Mbitss, CR44  1. The error bars around each similarity value indicate the maximum and minimum similarityvalues over the 100 runs.Fig. 13. Framebyframe robustness of a football video to frame dropping and averaging. Theerror bars around each similarity value indicate the maximum and minimum similarity valuesover the 100 runs.we mean that the marks are difficult to remove withoutleaving a trace. The method of Braudway et al. for alteringpixel values in a still image was used to mark digitizedpages of manuscripts from the Vaticans archive and theBritish Library with a logo, in part for use in authenticatingthe images and in part for deterring any parties seeking topurloin or misappropriate the documents 8 samples ofmarked images can be found at IBM.77 See the IBM Digital Library home page, marked images fromthe Vatican Library Project httpwww.software.ibm.comisdiglibvatican.html and marked images from British Library projecthttpwww.rennard.demon. co.uktechtewamk.htm.1084 PROCEEDINGS OF THE IEEE, VOL. 86, NO. 6, JUNE 1998To be attractive and effective when applied to digitizedstillimage data representing works with artistic merit,according to Braudway et al., a visible watermark mustbe obvious to any person with normal or corrected visionincluding the color blind, be flexible enough that it canbe made as obtrusive or unobtrusive as desired, have boldfeatures that by themselves form a recognizable image,allow all features of the unmarked image to appear in themarked image, and be very difficult, if not impossible, toremove.The method designed by Braudway et al. to fulfill thesecriteria begins with the construction of a mask corresponding to the watermark. The mask determines which pixels inan image will remain unchanged and which will have theirintensity altered. The mask is then resized, if necessary,to dimensions appropriate for the image size and markingpurpose, and the location at which the watermark will beplaced is chosen. Last, the intensity in the pixels specifiedby the mask is altered. The scientists used a mathematicalmodel of the intensity in an image27where and represent the intensity of the thpixel in the original and marked images, respectively, theconstant is a function that reflects various properties ofthe specific image and watermark mask, and is theintensity i.e., the amount of light received by the eye,regardless of color 81. The appearance or obtrusivenessof the watermark is controlled by varying the intensity .If the same value of were used to alter all the pixelsthat fall under the mask, then the watermark could be easilyremoved by a hostile party. To render robustness to themark, randomness is introduced by using inplace of , where is a discrete randomvariable that if truly randomly distributed satisfies28A watermark needs to have bold features because theintroduction of the random variable , depending on itsvalues, can make fine details of the mark less discernible.As an addendum to their method, Braudway et al. remarkthat additional robustness can be achieved by introducingsmall random variations in the size as well as in thehorizontal and vertical placement of the watermark, assuggested by Pickerell and Child 67.REFERENCES1 R. Anderson, Ed., Information hiding, in Lecture Notes inComputer Science. Tokyo, Japan Springer, 1996.2 W. Bender, D. Gruhl, N. Morimoto, and A. Lu, Techniques fordata hiding, IBM Syst. J., vol. 35, nos. 3 and 4, pp. 313336,1996.3 H. Berghel and L. OGorman, Protecting ownership rightsthrough digital watermarking, IEEE Computer Mag., pp.101103, July 1996.4 L. Boney, A. Tewfik, and K. Hamdy, Digital watermarks foraudio signals, in Proceedings of Multimedia96. Piscataway,NJ IEEE Press, 1996, pp. 473480.5 L. Boney, A. Tewfik, K. Hamdy, and M. Swanson, submittedfor U.S. patent.6 J. Brassil, S. Low, N. Maxemchuk, and L. OGorman, Electronic marking and identification techniques to discourage document copying, IEEE J. Select. Areas Commun., vol. 13, pp.14951504, Oct. 1995.7 G. Braudway, K. Magerlein, and F. Mintzer, Color correctdigital watermarking of images, U.S. Patent 5 530 759, June25, 1996.8 , Protecting publicallyavailable images with a visibleimage watermark, IBM Research Rep. TC2033689918, Jan.15, 1996.9 O. Bruyndonckx, J. J. Quisquater, and B. Macq, Spatialmethod for copyright labeling of digital images, in Proc.IEEE Nonlinear Signal Processing Workshop, 1995, pp.456459.10 G. Caronni, Assuring ownership rights for digital images, inReliable IT Systems, H. H. Breggemann and W. GerhardtHackl,Eds. Vieweg, Germany, 1995.11 M. Schneider and S.F. Chang, A contentbased approachto image signature generation and authentication, in Proc.ICIP96, vol. III, pp. 227230.12 Facsimile coding schemes and coding control functions forgroup 4 facsimile apparatus for document transmission, CCITTRecommendation T.6, 1984.13 M. Cooperman and S. Moskowitz, Steganographic method anddevice, U.S. Patent 5 613 004, Mar. 1997. Available WWWhttpwww.digitalwatermark.compatents.htm.14 I. Cox, J. Kilian, T. Leighton, and T. Shamoon, Secure spreadspectrum watermarking for multimedia, IEEE Trans. ImageProcessing, vol. 6, no. 12, pp. 16731687, 1997 see also Proc.ICIP96, vol. III, pp. 243246.15 S. Craver, N. Memon, B.L. Yeo, and M. Yeung, Caninvisible watermarks resolve rightful ownership IBMResearch Rep. RC20509, July 1996. Available WWWhttpwww.research.ibm.com8080. See also Proc. SPIEStorage and Retrieval for Image and Video Databases V, Feb.1997, vol. 3022, pp. 310321.16 , Resolving rightful ownerships with invisible watermarking techniques Limitations, attacks, and implications, IBMResearch Rep. RC 20755, Mar. 1997.17 C. Dautzenberg and F. Boland, Watermarking images, Dept.of Electrical Engineering, Trinity College, Dublin, Tech. Rep.,1994.18 P. Davern and M. Scott, Fractal based image steganography, in R. Anderson, Ed., Lecture Notes in Computer Science.Tokyo, Japan Springer, 1996, pp. 279294.19 W. Diffie and M. Hellman, New directions in cryptography,IEEE Trans. Inform. Theory, vol. IT22, pp. 644654, 1976.20 P. Flikkema, Spreadspectrum techniques for wireless communications, IEEE Trans. Signal Processing, vol. 14, pp. 2636,May 1997.21 J. Fridrich, Methods for data hiding, Center for IntelligentSystems  Dept. of Systems Science and Industrial Engineering, State Univ. of New YorkBinghamton, preprint. Availablehttpssie.binghamton.edujirif.22 B. Girod, The information theoretical significance of spatialand temporal masking in video signals, in Proc. SPIE HumanVision, Visual Processing, and Digital Display, 1989, vol. 1077,pp. 178187.23 B. Girod and F. Hartung, submitted for U.S. patent.24 F. Goffin, J.F. Delaigle, C. D. Vleeschouwer, B. Macq, and J.J.Quisquater, Lowcost perceptive digital picture watermarkingmethod, in Proc. SPIE Storage and Retrieval for Image andVideo Databases, Jan. 1997, vol. 3022, pp. 264277.25 S. Goldwasser and M. Bellare. July 1996. Lecture noteson cryptography. Online. Available WWW httpwwwcse.ucsd.eduusersmihirpaperscryptopapers.html.26 B. Greenberg, Method and apparatus for the processing ofencoded data in conjunction with an audio broadcast, U.S.Patent 5 379 345, Jan. 199527 D. Gruhl. 1996. Examples of affine embedding. Online.Available WWW httpnif.www.media.mit.edu DataHidingaffineaffine.html.28 D. Gruhl, A. Lu, and W. Bender, Techniques for data hiding,IBM Syst. J., vol. 35, nos. 3 and 4, pp. 313336, 1996.29 F. Hartung and B. Girod, Digital watermarking of raw andcompressed video, in Proc. SPIE Digital Compression TechSWANSON et al. MULTIMEDIA DATA EMBEDDING AND WATERMARKING 1085nologies and Systems for Video Communication, Oct. 1996, vol.2945, pp. 205213.30 , Copyright protection in video delivery networks bywatermarking of precompressed video, in Multimedia Applications, Services and TechniquesECMAST97, Lecture Notesin Computer Science, S. Fdida and M. Morganti, Eds. Tokyo,Japan Springer, 1997, vol. 1242, pp. 423436.31 , Digital watermarking of MPEG2 coded video in the bitstream domain, in Proceedings of the International Conferenceon Acoustics, Speech and Signal Processing 1997. Piscataway,NJ IEEE Press, 1997, pp. 26212624.32 , Digital watermarking of uncompressed and compressedvideo, Signal Processing, to appear in 1997.33 , Fast publickey watermarking of compressed video,in Proceedings of the IEEE International Conference on ImageProcessing 1997. Piscataway, NJ 1997., vol. I, pp. 528531.34 Herodotus, The Histories trans. A. de Selincourt. Middlesex,England Penguin, 1972.35 Homer, The Iliad trans. R. Fagels. Middlesex, EnglandPenguin, 1990.36 C.T. Hsu and J.L. Wu, Hidden signatures in images, in Proceedings of the IEEE International Conference on Image Processing 1996. Piscataway, NJ IEEE Press, 1996, pp. 223226.37 Proceedings of the International Conference on Acoustics,Speech and Signal Processing 1997. Piscataway, NJ IEEEPress, 1997.38 Proceedings of the IEEE International Conference on ImageProcessing 1996. Piscataway, NJ IEEE Press, 1996.39 Proceedings of the IEEE International Conference on ImageProcessing 1997. Piscataway, NJ 1997.40 Information technologyCoding of moving pictures and associated audio for digital storage up to about 1.5 Mbitss,ISOIEC IS 11172, 1993.41 N. Jayant, J. Johnston, and R. Safranek, Signal compressionbased on models of human perception, Proc. IEEE, vol. 81,pp. 13851422, Oct. 1993.42 J. Johnston and K. Brandenburg, Wideband codingPerceptual considerations for speech and music, inAdvances in Speech Signal Processing, S. Furui and M. Sondhi,Eds. New York Marcel Dekker, 1992.43 D. Kahn, The Codebreakers. New York MacMillan, 1967.44 D. Knuth, The Art of Computer Programming, vol. 2, 2nd ed.Menlo Park, CA AddisonWesley, 1981.45 M. Kuhn. 1997. StirMark, Online. AvailableWWW httpwww.cl.cam.ac.uk fapp2 watermarkingimage watermarkingstirmark.46 G. Langelaar, J. van der Lubbe, and J. Biemond.1996. Copy protection for multimedia based onlabeling techniques. Available WWW httpwwwit.et.tudelft.nlpdasmashpublicbenelux cr. html.47 C. Lee, K. Moallemi, and J. Hinderling, Postcompressionhidden data transport, U.S. Patent 5 687 191, 1997.48 G. Legge and J. Foley, Contrast masking in human vision, J.Opt. Soc. Amer., vol. 70, no. 12, pp. 14581471, Dec. 1990.49 S. Low, N. Maxemchuk, J. Brassil, and L. OGorman,Document marking and identification using both line andword shifting, in Proc. Infocom95, Boston, MA, Apr.1995. Available WWW httpwww.research.att.com80lateinfoprojectsecom.html.50 Kinoshita, Inaba, and Kasahara, Digital watermarking ofvideo, in Proc. 1997 Symp. Cryptography and InformationSecurity, Jan. 1997, SCIS9731F in Japanese.51 E. Koch and J. Zhao, Embedding robust labels into imagesfor copyright protection, in Proc. Int. Congress IntellectualProperty Rights for Specialized Information, Knowledge, andNew Technologies, Vienna, Austria, Aug. 1995, pp. 242251.52 M. Kutter, F. Jordan, and F. Bossen, Digital signature of colorimages using amplitude modulation, in Proc. SPIEEI97, 1997,pp. 518526.53 M. Luby, Pseudorandomness and Cryptographic Applications.Princeton, NJ Princeton Univ. Press, 1996.54 K. Matsui and K. Tanaka, Gazo Shinso Ango. Morikita, 1993in Japanese.55 , Videosteganography How to embed a signature in apicture, in Proc. IMA Intellectual Property, Jan. 1994, vol. 1,no. 1, pp. 187206.56 N. Maxemchuk, Electronic document distribution, ATTTech. J., pp. 7380, Sept. 1994.57 D. Moses, Simultaneous transmission of data and audio signalsby means of perceptual coding, U.S. Patent 5 473 631, 1995.58 W. Mowry, Jr., M. McElligott, V. Tkalenko, J. Baran, and CIngalls, Protected document bearing watermark and method ofmaking, U.S. Patent 4 210 346, July 1, 1980.59 Proceedings of Multimedia96. Piscataway, NJ IEEE Press,1996.60 National Institute of Standards and Technology NIST, SecureHash Standard, NIST FIPS Pub. 1801, Apr. 1995.61 P. Noll, Wideband speech and audio coding, IEEE Commun.Mag., pp. 3444, Nov. 1993.62 R. Ohbuchi, H. Masuda, and M. Aono, Embedding data inthreedimensional models, in Proc. Eur. Workshop InteractiveDistributed Multimedia Systems and Telecommunication Services, Darmstadt, Germany, Lecture Notes in Computer Science,no. 1309. Tokyo, Japan Springer, 1997.63 , Watermarking threedimensional models, in Proc. 5thACM Int. Multimedia Conf., Seattle, WA, Nov. 913, 1997, pp.261272.64 J. Ohnishi and K. Matsui, Embedding a seal into a pictureunder orthogonal wavelet transform, in Proceedings of Multimedia96. Piscataway, NJ IEEE Press, 1996., pp. 514521.65 J. ORuanaidh, C. Dautzenberg, and F. Boland, Watermarkingdigital images for copyright protection, Proc. Inst. Elect. Eng.Vis. Image Signal Processing, Aug. 1996, vol. 143, no. 4, pp.250256.66 , Phase watermarking of digital images, in Proceedingsof the IEEE International Conference on Image Processing1996. Piscataway, NJ IEEE Press, 1996. pp. 239242.67 J. Pickerell and A. Child, Marketing photography in the digitalenvironment, DiSC, Rockville, MD, 1994.68 R. Pickholz, D. Schilling, and L. Milstein, Theory of spreadspectrum communications, IEEE Trans. Commun., vol. COM30, pp. 855884, May 1982.69 I. Pitas, A method for signature casting on digital images,in Proceedings of the IEEE International Conference on ImageProcessing 1996. Piscataway, NJ IEEE Press, 1996., vol. III,pp. 215218.70 I. Pitas and T. Kaskalis, Applying signatures on digital images, in Proc. 1995 IEEE Nonlinear Signal Processing Workshop, 1995, pp. 460463.71 C. Podilchuk and W. Zeng, Digital image watermarking using visual models, Multimedia Communication Lab, LucentTechnologies, Bell Labs, Tech. Memo, Sept. 1996. See alsoProc. SPIEIST Electronic Imaging97 Human Vision andElectronic Imaging, Feb. 1997, vol. 3022, pp. 310321.72 , Perceptual watermarking of still images, in Proc.IEEE Workshop Multimedia Signal Processing, June 1997, pp.363368.73 R. Preuss, S. Roukos, A. Huggins, H. Gish, M. Bergamo, and P.Peterson, Embedded signalling, U.S. Patent 5 319 735, 1994.74 J. Puate and F. Jordan. 1996. Using fractal compressionscheme to embed a digital signature into an image. Online.Available httplswww.epfl.ch jordanwatermarking.html.75 J. Ragusa, V. Badari, and J. Machuca. 1997.An adaptive spread spectrum approach. Online.Available WWW httpwww.csuglab.cornell.eduInfoPeoplevbadarics631wmrkprojproposal.html.76 R. Rivest, Cryptography, in Handbook of Theoretical Computer Science, vol. 1, J. van Leeuwen, Ed. Cambridge, MAMIT Press, 1990, ch. 13, pp. 717755.77 , The MD4 message digest algorithm, in Advances inCryptology, CRYPTO92. Tokyo, Japan Springer, 1991, pp.303311.78 K. Rosen, Elementary Number Theory and Its Applications, 3rded. Tokyo, Japan AddisonWesley, 1992.79 J. Russ, The Image Processing Handbook, 2nd ed. Tokyo,Japan CRC Press, 1995.80 M. Sanford, J. Bradley, and T. Handel, The dataembedding method, Los Alamos National LaboratoryRep. 9LA952246UR, Sept. 25, 1995. Available WWWhttpwww.lanl.govusersu078743embed1.htm.81 M. SidAhmed, Image Processing. Tokyo, Japan McGrawHill, 1995.82 J. Smith and B. Comiskey, Modulation and information hidingin images, in R. Anderson, Ed., Information hiding, inLecture Notes in Computer Science. Tokyo, Japan Springer,1996, pp. 207226.1086 PROCEEDINGS OF THE IEEE, VOL. 86, NO. 6, JUNE 199883 H. Stone, Analysis of attacks on image watermarks withrandomized coefficients, NEC Research Institute, Princeton, NJ, Tech. Rep., May 17, 1996. Available WWWhttpwww.neci.nj.nec.com.84 M. Swanson, B. Zhu, and A. Tewfik, Data hiding for videoin video, in Proceedings of the IEEE International Conferenceon Image Processing 1997. Piscataway, NJ 1997, vol. II, pp.676679.85 M. Swanson, B. Zhu, and A. Tewfik, Multiresolution videowatermarking using perceptual models and scene segmentation, IEEE J. Select. Areas Commun., to be published. Seealso Proceedings of the IEEE International Conference on ImageProcessing 1997. Piscataway, NJ 1997, vol. II, pp. 558561.86 M. Swanson, B. Zhu, and A. Tewfik, Objectbased transparentvideo watermarking, in Proc. 1997 IEEE Multimedia SignalProcessing Workshop, 1997, pp. 369374.87 M. Swanson, B. Zhu, A. Tewfik, and L. Boney, Robust audiowatermarking using perceptual masking, Signal Process., tobe published.88 M. Swanson, B. Zhu, and A. Tewfik, Transparent robustimage watermarking, in Proceedings of the IEEE InternationalConference on Image Processing 1996. Piscataway, NJ IEEEPress, 1996, vol. III, pp. 211214.89 J. Tilki and A. Beex, Encoding a hidden digital signature ontoan audio signal using psychoacoustic masking, in Proc. 19967th Int. Conf. Sig. Proc. Appls. Tech., 1996, pp. 476480.90 R. van Schyndel, A. Tirkel, and C. Osborne, A digital watermark, in Proceedings of ICASSP. Piscataway, NJ IEEEPress, 1994, vol. II, pp. 8690.91 H. van Trees, Detection, Estimation, and Modulation Theory,vol. I. New York Wiley, 1968.92 A. Viterbi, CDMA Principles of Spread Spectrum Communication. Tokyo, Japan AddisonWesley, 1995.93 P. Vogel, System for altering elements of a text file to markdocuments, U.S. Patent 5 388 194, Feb. 7, 1995.94 G. Voyatzis and I. Pitas, Applications of toral automorphismsin image watermarking, in Proceedings of the IEEE International Conference on Image Processing 1996. Piscataway, NJIEEE Press, 1996, vol. II, pp. 237240.95 S. Walton, Image authentication for a slippery new age, Dr.Dobbs J., pp. 1826 and 8287, Apr. 1995.96 R. Wolfgang and E. Delp, A watermark for digital images,in Proceedings of the IEEE International Conference on Image Processing 1996. Piscataway, NJ IEEE Press, 1996, pp.219222.97 , A watermarking technique for digital imagery Furtherstudies, in Proc. Int. Conf. Imaging Science, Systems andTechnology, Las Vegas, NV, June 30July 3, 1997.98 J. Zhao and Fraunhofer Inst. for Computer Graphics.1996. Online. Available WWW httpwww.igd.fhg.dezhaozhao.html.99 B. Zhu, A. Tewfik, and O. Gerek, Low bit rate neartransparentimage coding, in Proc. SPIE Int. Conf. Wavelet Appls. for DualUse, 1995, vol. 2491, pp. 173184.Mitchell D. Swanson Member, IEEE receivedthe B.S. summa cum laude, M.S., and Ph.D.degrees in electrical engineering from theUniversity of Minnesota, Minneapolis, in 1992,1995, and 1997, respectively.He was with Honeywell, Inc., and Medtronic,Inc., Minneapolis. He currently is with Cognicity, Inc., Minneapolis, and is a Visiting AssistantProfessor with the Department of ElectricalEngineering at the University of Minnesota.His research interests include multiscale signalprocessing, image and video coding for interactive retrieval, data hiding,and digital watermarking.Mei Kobayashi received the A.B. degree inchemistry from Princeton University, Princeton,NJ, in 1981 and the M.A. and Ph.D. degrees inpure and applied mathematics from the University of California at Berkeley in 1984 and 1988,respectively.During her undergraduate and graduate years,she was an Intern in the Chemistry and PhysicsDivisions at Lawrence Berkeley Laboratories.She has been with the IBM Tokyo ResearchLaboratory, Japan, since April 1988. From April1996 to March 1999, she will be a Visiting Associate Professor in theGraduate School of Mathematical Sciences at the University of Tokyo,Tokyo, Japan.Ahmed H. Tewfik Fellow, IEEE was born in Cairo, Egypt, on October21, 1960. He received the B.Sc. degree from Cairo University in 1982and the M.Sc., E.E., and Sc.D. degrees from the Massachusetts Instituteof Technology, Cambridge, in 1984, 1985, and 1987, respectively.He was with Alphatech, Inc., Burlington, MA, in 1987. He currentlyis the E. F. Johnson Professor of Electronic Communications with theDepartment of Electrical Engineering at the University of Minnesota,Minneapolis. He was a Consultant to MTS Systems, Inc., Eden Prairie,MN, and is a regular Consultant to Rosemount, Inc., Eden Prairie. Hiscurrent research interests are in signal processing for multimedia inparticular watermarking, data hiding, and contentbased retrieval, lowpower multimedia communications, adaptive search and dataacquisitionstrategies for World Wide Web applications, radar and dentalmedicalimaging, monitoring of machinery using acoustic emissions, and industrialmeasurements.Dr. Tewfik is a Distinguished Lecturer of the IEEE Signal ProcessingSociety for July 1997July 1999. He was a Principal Lecturer at the 1995IEEE EMBS summer school. He received a Taylor Faculty DevelopmentAward from the Taylor Foundation in 1992 and a National ScienceFoundation Research Initiation Award in 1990. He gave a plenary lectureat the 1994 IEEE International Conference on Acoustics, Speech, andSignal Processing and an invited tutorial on wavelets at the 1994 IEEEWorkshop on TimeFrequency and TimeScale Analysis. He became thefirst EditorinChief of IEEE SIGNAL PROCESSING LETTERS in 1993. He is apast Associate Editor of IEEE TRANSACTIONS ON SIGNAL PROCESSING andwas a Guest Editor of two special issues on wavelets and their applications.SWANSON et al. MULTIMEDIA DATA EMBEDDING AND WATERMARKING 1087
