Image registration methods a surveyBarbara Zitova, Jan FlusserDepartment of Image Processing, Institute of Information Theory and Automation, Academy of Sciences of the Czech RepublicPod vodarenskou vez 4, 182 08 Prague 8, Czech RepublicReceived 9 November 2001 received in revised form 20 June 2003 accepted 26 June 2003AbstractThis paper aims to present a review of recent as well as classic image registration methods. Image registration is the process of overlayingimages two or more of the same scene taken at different times, from different viewpoints, andor by different sensors. The registrationgeometrically align two images the reference and sensed images. The reviewed approaches are classified according to their nature areabased and featurebased and according to four basic steps of image registration procedure feature detection, feature matching, mappingfunction design, and image transformation and resampling. Main contributions, advantages, and drawbacks of the methods are mentioned inthe paper. Problematic issues of image registration and outlook for the future research are discussed too. The major goal of the paper is toprovide a comprehensive reference source for the researchers involved in image registration, regardless of particular application areas.q 2003 Elsevier B.V. All rights reserved.Keywords Image registration Feature detection Feature matching Mapping function Resampling1. IntroductionImage registration is the process of overlaying two ormore images of the same scene taken at different times,from different viewpoints, andor by different sensors. Itgeometrically aligns two imagesthe reference andsensed images. The present differences between imagesare introduced due to different imaging conditions. Imageregistration is a crucial step in all image analysis tasksin which the final information is gained from thecombination of various data sources like in image fusion,change detection, and multichannel image restoration.Typically, registration is required in remote sensingmultispectral classification, environmental monitoring,change detection, image mosaicing, weather forecasting,creating superresolution images, integrating informationinto geographic information systems GIS, in medicinecombining computer tomography CT and NMR datato obtain more complete information about the patient,monitoring tumor growth, treatment verification,comparison of the patients data with anatomical atlases,in cartography map updating, and in computer visiontarget localization, automatic quality control, to namea few.During the last decades, image acquisition devices haveundergone rapid development and growing amount anddiversity of obtained images invoked the research onautomatic image registration. A comprehensive survey ofimage registration methods was published in 1992 byBrown 26. The intention of our article is to cover relevantapproaches introduced later and in this way map the currentdevelopment of registration techniques. According to thedatabase of the Institute of Scientific Information ISI, inthe last 10 years more than 1000 papers were published onthe topic of image registration. Methods published before1992 that became classic or introduced key ideas, which arestill in use, are included as well to retain the continuity andto give complete view of image registration research. We donot contemplate to go into details of particular algorithms ordescribe results of comparative experiments, rather we wantto summarize main approaches and point out interestingparts of the registration methods.In Section 2 various aspects and problems of imageregistration will be discussed. Both areabased and featurebased approaches to feature selection are described inSection 3. Section 4 reviews the existing algorithms forfeature matching. Methods for mapping function design aregiven in Section 5. Finally, Section 6 surveys main0262885603  see front matter q 2003 Elsevier B.V. All rights reserved.doi10.1016S0262885603001379Image and Vision Computing 21 2003 9771000www.elsevier.comlocateimavis Corresponding author. Tel. 420266052390 fax 420284680730.Email address zitovautia.cas.cz B. Zitova, flusserutia.cas.czJ. Flussertechniques for image transformation and resampling.Evaluation of the image registration accuracy is coveredin Section 7. Section 8 concludes main trends in the researchon registration methods and offers the outlook for the future.2. Image registration methodologyImage registration, as it was mentioned above, is widelyused in remote sensing, medical imaging, computer visionetc. In general, its applications can be divided into four maingroups according to the manner of the image acquisitionDifferent viewpoints multiview analysis. Images of thesame scene are acquired from different viewpoints. The aimis to gain larger a 2D view or a 3D representation of thescanned scene.Examples of applications Remote sensingmosaicingof images of the surveyed area. Computer visionshaperecovery shape from stereo.Different times multitemporal analysis. Images of thesame scene are acquired at different times, often on regularbasis, and possibly under different conditions. The aim is tofind and evaluate changes in the scene which appearedbetween the consecutive image acquisitions.Examples of applications Remote sensingmonitoringof global land usage, landscape planning. Computervisionautomatic change detection for security monitoring, motion tracking. Medical imagingmonitoring of thehealing therapy, monitoring of the tumor evolution.Different sensors multimodal analysis. Images of thesame scene are acquired by different sensors. The aim is tointegrate the information obtained from different sourcestreams to gain more complex and detailed scenerepresentation.Examples of applications Remote sensingfusion ofinformation from sensors with different characteristics likepanchromatic images, offering better spatial resolution,colormultispectral images with better spectral resolution, orradar images independent of cloud cover and solarillumination. Medical imagingcombination of sensorsrecording the anatomical body structure like magneticresonance image MRI, ultrasound or CT with sensorsmonitoring functional and metabolic body activities likepositron emission tomography PET, single photon emission computed tomography SPECT or magnetic resonancespectroscopy MRS. Results can be applied, for instance, inradiotherapy and nuclear medicine.Scene to model registration. Images of a scene and amodel of the scene are registered. The model can be acomputer representation of the scene, for instance maps ordigital elevation models DEM in GIS, another scene withsimilar content another patient, average specimen, etc.The aim is to localize the acquired image in the scenemodelandor to compare them.Examples of applications Remote sensingregistrationof aerial or satellite data into maps or other GIS layers.Computer visiontarget template matching with realtimeimages, automatic quality inspection. Medical imagingcomparison of the patients image with digital anatomicalatlases, specimen classification.Due to the diversity of images to be registered and due tovarious types of degradations it is impossible to design auniversal method applicable to all registration tasks. Everymethod should take into account not only the assumed typeof geometric deformation between the images but alsoradiometric deformations and noise corruption, requiredregistration accuracy and applicationdependent datacharacteristics.Nevertheless, the majority of the registration methodsconsists of the following four steps see Fig. 1 Feature detection. Salient and distinctive objectsclosedboundary regions, edges, contours, line intersections, corners, etc. are manually or, preferably, automatically detected. For further processing, these featurescan be represented by their point representatives centersof gravity, line endings, distinctive points, which arecalled control points CPs in the literature. Feature matching. In this step, the correspondencebetween the features detected in the sensed image andthose detected in the reference image is established.Various feature descriptors and similarity measuresalong with spatial relationships among the features areused for that purpose. Transform model estimation. The type and parameters ofthe socalled mapping functions, aligning the sensedimage with the reference image, are estimated. Theparameters of the mapping functions are computed bymeans of the established feature correspondence. Image resampling and transformation. The sensedimage is transformed by means of the mappingfunctions. Image values in noninteger coordinatesare computed by the appropriate interpolationtechnique.The implementation of each registration step has itstypical problems. First, we have to decide what kind offeatures is appropriate for the given task. The featuresshould be distinctive objects, which are frequently spreadover the images and which are easily detectable. Usually,the physical interpretability of the features is demanded.The detected feature sets in the reference and sensed imagesmust have enough common elements, even in situationswhen the images do not cover exactly the same scene orwhen there are object occlusions or other unexpectedchanges. The detection methods should have good localization accuracy and should not be sensitive to the assumedimage degradation. In an ideal case, the algorithm should beable to detect the same features in all projections of thescene regardless of the particular image deformation.In the feature matching step, problems caused by anincorrect feature detection or by image degradations canB. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000978arise. Physically corresponding features can be dissimilardue to the different imaging conditions andor due to thedifferent spectral sensitivity of the sensors. The choice of thefeature description and similarity measure has to considerthese factors. The feature descriptors should be invariant tothe assumed degradations. Simultaneously, they have to bediscriminable enough to be able to distinguish amongdifferent features as well as sufficiently stable so as not to beinfluenced by slight unexpected feature variations and noise.The matching algorithm in the space of invariants should berobust and efficient. Single features without correspondingcounterparts in the other image should not affect itsperformance.The type of the mapping functions should bechosen according to the a priori known informationabout the acquisition process and expected imagedegradations. If no a priori information is available, themodel should be flexible and general enough to handleall possible degradations which might appear. Theaccuracy of the feature detection method, the reliabilityof feature correspondence estimation, and the acceptableapproximation error need to be considered too. Moreover,the decision about which differences between imageshave to be removed by registration has to be done. It isdesirable not to remove the differences we are searchingfor if the aim is a change detection. This issue is veryimportant and extremely difficult.Finally, the choice of the appropriate type of resamplingtechnique depends on the tradeoff between the demandedaccuracy of the interpolation and the computationalFig. 1. Four steps of image registration top rowfeature detection corners were used as the features in this case. Middle rowfeature matching by invariantdescriptors the corresponding pairs are marked by numbers. Bottom lefttransform model estimation exploiting the established correspondence. Bottomrightimage resampling and transformation using appropriate interpolation technique.B. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000 979complexity. The nearestneighbor or bilinear interpolationare sufficient in most cases however, some applicationsrequire more precise methods.Because of its importance in various application areas aswell as because of its complicated nature, image registrationhas been the topic of much recent research. The historicallyfirst survey paper 64 covers mainly the methods based onimage correlation. Probably the most exhaustive review ofthe generalpurpose image registration methods is in Ref.26. Registration techniques applied particularly in medicalimaging are summarized in Refs. 86,111,123,195. In Ref.9 the surface based registration methods in medicalimaging are reviewed. Volumebased registration isreviewed in Ref. 40. The registration methods appliedmainly in remote sensing are described and evaluated in 59,81,106. Big evaluation project of different registrationmethods was run in Vanderbilt university 206.Registration methods can be categorized with respect tovarious criteria. The ones usually used are the applicationarea, dimensionality of data, type and complexity ofassumed image deformations, computational cost, and theessential ideas of the registration algorithm. Here, theclassification according to the essential ideas is chosen,considering the decomposition of the registration into thedescribed four steps. The techniques exceeding this fourstep framework are covered according to their majorcontribution.3. Feature detectionFormerly, the features were objects manually selected byan expert. During an automation of this registration step,two main approaches to feature understanding have beenformed.3.1. Areabased methodsAreabased methods put emphasis rather on the featurematching step than on their detection. No features aredetected in these approaches so the first step of imageregistration is omitted. The methods belonging to this classwill be covered in sections corresponding to the otherregistration steps.3.2. Featurebased methodsThe second approach is based on the extraction of salientstructuresfeaturesin the images. Significant regionsforests, lakes, fields, lines region boundaries, coastlines,roads, rivers or points region corners, line intersections,points on curves with high curvature are understood asfeatures here. They should be distinct, spread all over theimage and efficiently detectable in both images. They areexpected to be stable in time to stay at fixed positions duringthe whole experiment.The comparability of feature sets in the sensed andreference images is assured by the invariance and accuracyof the feature detector and by the overlap criterion. In otherwords, the number of common elements of the detected setsof features should be sufficiently high, regardless of thechange of image geometry, radiometric conditions, presenceof additive noise, and of changes in the scanned scene. Theremarkableness of the features is implied by theirdefinition. In contrast to the areabased methods, thefeaturebased ones do not work directly with image intensityvalues. The features represent information on higher level.This property makes featurebased methods suitable forsituations when illumination changes are expected ormultisensor analysis is demanded.Region features. The regionlike features can be theprojections of general high contrast closedboundaryregions of an appropriate size 54,72, water reservoirs,and lakes 71,88, buildings 92, forests 165, urban areas161 or shadows 24. The general criterion of closedboundary regions is prevalent. The regions are oftenrepresented by their centers of gravity, which are invariantwith respect to rotation, scaling, and skewing and stableunder random noise and gray level variation.Region features are detected by means of segmentationmethods 137. The accuracy of the segmentation cansignificantly influence the resulting registration. Goshtasbyet al. 72 proposed a refinement of the segmentationprocess to improve the registration quality. The segmentation of the image was done iteratively together with theregistration in every iteration, the rough estimation of theobject correspondence was used to tune the segmentationparameters. They claimed the subpixel accuracy ofregistration could be achieved.Recently, selection of region features invariant withrespect to change of scale caught attention. Alhichri andKamel 2 proposed the idea of virtual circles, usingdistance transform. Affinely invariant neighborhoods weredescribed in 194, based on Harris corner detector 135and edges curved or straight going through detectedcorners. Different approach to this problem using Maximally Stable Extremal Regions based on homogeneity ofimage intensities was presented by Matas et al. 127.Line features. The line features can be the representationsof general line segments 92,132,205, object contours 36,74,112, coastal lines, 124,168, roads 114 or elongatedanatomic structures 202 in medical imaging. Linecorrespondence is usually expressed by pairs of line endsor middle points.Standard edge detection methods, like Canny detector28 or a detector based on the Laplacian of Gaussian 126,are employed for the line feature detection. The survey ofexisting edge detection method together with their evaluation can be found in 222. Li et al. 112 proposed toexploit the already detected features in the reference imageoptical data for the detection of lines in the sensed imagesSAR images with speckle noise, which is a typicalB. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000980degradation present in this type of data. They appliedelastic contour extraction. The comparison of differentoperators for the feature edge detection and the ridgedetection in multimodal medical images is presented byMaintz et al. 121,122.Point features. The point features group consists ofmethods working with line intersections 175,198, roadcrossings 79,161, centroids of water regions, oil and gaspads 190, high variance points 45, local curvaturediscontinuities detected using the Gabor wavelets 125,219, inflection points of curves 3,11, local extrema ofwavelet transform 58,90, the most distinctive points withrespect to a specified measure of similarity 115, andcorners 20,92,204.The core algorithms of feature detectors in most casesfollow the definitions of the point as line intersection,centroid of closedboundary region or local modulusmaxima of the wavelet transform. Corners form specificclass of features, because tobeacorner property is hardto define mathematically intuitively, corners are understood as points of high curvature on the region boundaries.Much effort has been spent in developing precise, robust,and fast method for corner detection. A survey of cornerdetectors can be found in Refs. 155,172,220 and the mostuptodate and exhaustive in Ref. 156. The latter alsoanalyzes localization properties of the detectors. Corners arewidely used as CPs mainly because of their invariance toimaging geometry and because they are well perceived by ahuman observer.Kitchen and Rosenfeld 101 proposed to exploit thesecondorder partial derivatives of the image function forcorner detection. Dreschler and Nagel 43 searched for thelocal extrema of the Gaussian curvature. However, cornerdetectors based on the secondorder derivatives of the imagefunction are sensitive to noise. Thus Forstner 62 developeda more robust, although time consuming, corner detector,which is based on the firstorder derivatives only. Thereputable Harris detector also referred to as the Plesseydetector 135 is in fact its inverse. The application of theForstner detector is described in Ref. 107, where it is usedfor the registration of dental implants images.More intuitive approach was chosen by Smith and Brady173 in their robust SUSAN method. As the criterion theyused the size of the area of the same color as that of thecentral pixel. Trajkovic and Hedley 192 designed theiroperator using the idea that the change of the imageintensity at the corners should be high in all directions.Recently, Zitova et al. 224 proposed a parametric cornerdetector, which does not employ any derivatives and whichwas designed to handle blurred and noisy data. Rohr et al.designed corner detectors, even for 3D data, allowing userinteraction 158.The number of detected points can be very high, whichincreases the computational time necessary for the registration. Several authors proposed methods for an efficientselection of a subset of points better than random whichdoes not degrade the quality of the resulting registration.Goshtasby 71 used only points belonging to a convex hullof the whole set. Lavine 104 proposed to use pointsforming the minimum spanning trees of sets. Ehlers 45merged points into clumpslarge dense clusters.3.3. SummaryTo summarize, the use of featurebased methods isrecommended if the images contain enough distinctive andeasily detectable objects. This is usually the case ofapplications in remote sensing and computer vision. Thetypical images contain a lot of details towns, rivers, roads,forests, room facilities, etc. On the other hand, medicalimages are not so rich in such details and thus areabasedmethods are usually employed here. Sometimes, the lack ofdistinctive objects in medical images is solved by theinteractive selection done by an expert or by introducingextrinsic features, rigidly positioned with respect to thepatient skin markers, screw markers, dental adapters, etc.123. The applicability of areabased and featurebasedmethods for images with various contrast and sharpness isanalyzed in Ref. 151. Recently, registration methods usingsimultaneously both areabased and featurebasedapproaches have started to appear 85.4. Feature matchingThe detected features in the reference and sensed imagescan be matched by means of the image intensity values intheir close neighborhoods, the feature spatial distribution, orthe feature symbolic description. Some methods, whilelooking for the feature correspondence, simultaneouslyestimate the parameters of mapping functions and thusmerge the second and third registration steps.In the following paragraphs, the two major categoriesareabased and featurebased methods, respectively, areretained and further classified into subcategories accordingto the basic ideas of the matching methods.4.1. Areabased methodsAreabased methods, sometimes called correlationlikemethods or template matching 59 merge the featuredetection step with the matching part. These methods dealwith the images without attempting to detect salient objects.Windows of predefined size or even entire images are usedfor the correspondence estimation during the secondregistration step, 4,12,145.The limitations of the areabased methods originate intheir basic idea. Firstly, the rectangular window, which ismost often used, suits the registration of images whichlocally differ only by a translation. If images are deformedby more complex transformations, this type of the windowis not able to cover the same parts of the scene inB. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000 981the reference and sensed images the rectangle can betransformed to some other shape. Several authors proposedto use circular shape of the window for mutually rotatedimages. However, the comparability of such simpleshapedwindows is violated too if more complicated geometricdeformations similarity, perspective transforms, etc. arepresent between images.Another disadvantage of the areabased methods refers tothe remarkableness of the window content. There is highprobability that a window containing a smooth area withoutany prominent details will be matched incorrectly with othersmooth areas in the reference image due to its nonsaliency.The features for registration should be preferably detected indistinctive parts of the image. Windows, whose selection isoften not based on their content evaluation, may not havethis property.Classical areabased methods like crosscorrelation CCexploit for matching directly image intensities, without anystructural analysis. Consequently, they are sensitive to theintensity changes, introduced for instance by noise, varyingillumination, andor by using different sensor types.4.1.1. Correlationlike methodsThe classical representative of the areabased methods isthe normalized CC and its modifications 146.CCi j PW W 2 EWIij 2 EIijffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiPW W 2 EW2q ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiPIij Iij 2 EIij2qThis measure of similarity is computed for window pairsfrom the sensed and reference images and its maximum issearched. The window pairs for which the maximum isachieved are set as the corresponding ones see Fig. 2. If thesubpixel accuracy of the registration is demanded, theinterpolation of the CC measure values needs to be used.Although the CC based registration can exactly alignmutually translated images only, it can also be successfullyapplied when slight rotation and scaling are present.There are generalized versions of CC for geometricallymore deformed images. They compute the CC for eachassumed geometric transformation of the sensed imagewindow 83 and are able to handle even more complicatedgeometric deformations than the translationusually thesimilarity transform. Berthilsson 17 tried to register in thismanner even affinely deformed images and Simper 170proposed to use a divide and conquer system and the CCtechnique for registering images differing by perspectivechanges as well as changes due to the lens imperfections.The computational load, however, grows very fast withthe increase of the transformation complexity. In case theimagesobjects to be registered are partially occluded theextended CC method based on increment sign correlation98 can be applied 99.Similar to the CC methods is the sequential similaritydetection algorithm SSDA 12. It uses the sequentialsearch approach and a computationally simpler distancemeasure than the CC. It accumulates the sum of absolutedifferences of the image intensity values matrix l1normand applies the threshold criterionif the accumulated sumexceeds the given threshold, the candidate pair of windowsfrom the reference and sensed images is rejected and thenext pair is tested. The method is likely to be less accuratethan the CC but it is faster. Sum of squared differencessimilarity measure was used in Ref. 211 for iterativeestimation of perspective deformation using piecewiseaffine estimates for image decomposed to small patches.Recently big interest in the area of multimodalregistration has been paid to the correlation ratio basedmethods. In opposite to classical CC, this similarity measurecan handle intensity differences between images due to theusage of different sensorsmultimodal images. It supposesthat intensity dependence can be represented by somefunction. Comparison of this approach to several otheralgorithms developed for multimodal data can be found inRef. 154. In case of noisy images with certain characteristic fixedpattern noise, projectionbased registration27, working with accumulated image rows and columns,respectively, outperforms classical CC.Huttenlocher et al. 95 proposed a method working withother type of similarity measure. They registered binaryimages the output of an edge detector transformed bytranslation or translation plus rotation, by means of theHausdorff distance HD. They compared the HD basedalgorithm with the CC. Especially on images with perturbedpixel locations, which are problematic for CC, HD outperforms the CC.Two main drawbacks of the correlationlike methods arethe flatness of the similarity measure maxima due to theselfsimilarity of the images and high computationalcomplexity. The maximum can be sharpened by preprocessing or by using the edge or vector correlation. Pratt 145applied, prior to the registration, image filtering to improvethe CC performance on noisy or highly correlated images.Van Wie 196 and Anuta 6 employed the edgebasedcorrelation, which is computed on the edges extracted fromthe images rather than on the original images themselves. Inthis way, the method is less sensitive to intensity differencesbetween the reference and sensed images, too. Extension ofthis approach, called vectorbased correlation, computes thesimilarity measures using various representations of thewindow.Despite the limitations mentioned above, the correlationlike registration methods are still often in use, particularlythanks to their easy hardware implementation, which makesthem useful for realtime applications.4.1.2. Fourier methodsIf an acceleration of the computational speed is needed orif the images were acquired under varying conditions orthey are corrupted by frequencydependent noise, thenFourier methods are preferred rather than the correlationlike methods. They exploit the Fourier representation ofB. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000982the images in the frequency domain. The phase correlationmethod is based on the Fourier Shift Theorem 23 and wasoriginally proposed for the registration of translated images.It computes the crosspower spectrum of the sensed andreference images and looks for the location of the peak in itsinverse see Fig. 2.Ff FgplFf Fgpl  e2piux0vy0The method shows strong robustness against the correlatedand frequency dependent noise and nonuniform, timevarying illumination disturbances. The computational timesavings are more significant if the images, which are to beregistered, are large.De Castro and Morandi 29 introduced an extensionof the phase correlation for additional rotation transform.If the change of image scale is present too, the imagescan be registered using the combination of polarlogmapping of the spectral magnitude which corresponds toFourierMellin transform and the phase correlation 31,150 or cepstrum filter 107. The applications of theextended algorithm in remote sensing SPOT images andmedical imaging MR images are described in Ref. 31.The testing of the accuracy of the method in simulatedconditions registration of deformed and noisy images ofocular fundus was performed with satisfying results 34.Affinely distorted images were registered by means ofphase correlation and logpolar mapping in Ref. 210.Application of phase correlation in 3D is described inRef. 119. Another application exploiting the Fouriertransform is described in Ref. 6. The authors proposedto compute the correlation in frequency domain. ThisFig. 2. Areabased matching methods registration of small template to the whole image using normalized crosscorrelation middle row and phase correlationbottom row. The maxima identify the matching positions. The template is of the same spectral band as the reference image the graphs on the left depict redred channel matching and of different spectral band the graphs on the right demonstrate redblue channel matching. In a general case the normalized crosscorrelation could fail in case of multimodal data.B. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000 983method can handle multimodal images when applied tothe edge representations instead of the original graylevelimages. Extension of phase correlation to subpixelregistration by means of the analytic expression ofphase correlation on down sampled images was introduced by Foroosh et al. 61.4.1.3. Mutual information methodsThe mutual information MI methods are the last groupof the areabased methods to be reviewed here. They haveappeared recently and represent the leading technique inmultimodal registration. Registration of multimodal imagesis the difficult task, but often necessary to solve, especiallyin medical imaging. The comparison of anatomical andfunctional images of the patients body can lead to adiagnosis, which would be impossible to gain otherwise.Remote sensing often makes use of the exploitation of moresensor types, too.The MI, originating from the information theory, is ameasure of statistical dependency between two data sets andit is particularly suitable for registration of images fromdifferent modalities. MI between two random variables Xand Y is given byMIXY  HY2 HY lX  HX  HY2 HXYwhere HX  2EXlogPX represents entropy of random variable and PX is the probability distribution of XThe method is based on the maximization of MI Fig. 3Often the speed up of the registration is implemented,exploiting the coarsetofine resolution strategy the pyramidal approach.One of the first articles proposing this technique is Violaand Wells 201. The authors described the application ofMI for the registration by magnetic resonance images aswell as for the 3D object model matching to the real scene.MI was maximized using the gradient descent optimizationmethod. Thevenaz and Unser 186188 tried to combinevarious approaches, solving individual steps of MI registration. They employed the Parzen window for the jointprobability computation and the Jeeves method 187 or theMarquardtLevenberg method 186 to maximize the MI.To speed up the computation, they used spline pyramidsFig. 3. Mutual information MI criterion bottom row computed in the neighborhood of point P between new and old photographs of the mosaic top row.Maximum of MI shows the correct matching position point A. Point B indicates the false matching position selected previously by the human operator. Themistake was caused by poor image quality and by complex nature of the image degradations.B. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000984188. Ritter et al. 152 used hierarchical search strategytogether with simulated annealing to find the maximum ofthe MI. Studholme et al. 177 compared three similarmeasures of information dependencythe joint entropy, theMI, and the normalized MI a new idea, claimed tooutperform the others. They applied discrete histogramestimates of the joint probability distribution instead ofapplication of the Parzen window used in previous work.Maximization was achieved by using a multiresolution hillclimbing algorithm. They registered MRCT and MRPETimages of a human brain. Maes et al. 120 optimized the MIby means of the Brents method and the Powells multidimensional direction set method to register MR, CT, andPET images of a human brain that differ by similaritytransform. MI applied to breast MR images is described inRef. 162. The authors proposed to model the globaldeformation present between the images by a combinationof the affine transformations and the splinebased free formdeformation. Likar and Pernus 116 studied the performance of different methods for the joint probability estimationin registration of muscle fibre images. The comparison ofthe basic MI registration with the version employing thecoarsetofine speed up was done in Ref. 143. Thecomparison of MI to six other registration methodsincluding the normalized CC and the gradient correlationis described in Ref. 142. The relation of MI to other areabased similarity correlation coefficients, correlation ratiomeasures is described in Ref. 153 using the formulation ofmaximum likelihood estimation problem.The above mentioned MI methods work with the entireimage data and directly with image intensities. Rangarajanet al. 149 applied MI on extracted features points of thearea borders, but this approach is still rare. Similar to MI,coming form the theory of information, is similaritymeasure based on crossentropy 221.4.1.4. Optimization methodsFinding the minimum of dissimilarity measure penaltyfunction or the maximum of similarity measure is amultidimensional optimization problem, where the numberof dimensions corresponds to the degrees of freedom of theexpected geometrical transformation. The only methodyielding global extreme solution is an exhaustive searchover the entire image. Although it is computationallydemanding, it is often used if only translations are to beestimated.In case of transformations with more degrees of freedomor in case of more complex similarity measures, sophisticated optimization algorithms are required, which help tolocalize the maxima or minima, respectively. The application of GaussNewton numerical minimization algorithmfor minimizing the sum of squared differences is describedin Ref. 166, where the projective geometric deformationwas used. In Ref. 201 maxima of MI was found using thegradient descent optimization method. LevenbergMarquardt optimization method was applied in Ref. 164 tominimize the variance in intensities of corresponding pixels.The images were registered by means of the projectivetransformation model plus the lens distortion model. Thecombination of the LevenbergMarquardt method and thesum of the squared differences metric is described in Ref.185. Similarly, Wolberg and Zokai 211 used thiscombination for registering of perspectively deformedimages. The Powells multidimensional direction setmethod 96 is applied in Maes et al. 120. Starink andBacker 174 tried to minimize a dissimilarity measuredefined on point pairs by means of simulated annealing.Another optimization method, suited for multimodal dataregistration was introduced in Ref. 97 and its applicabilitywas proved in combination with MI and correlation ratio.Again, the optimization methods can be speeded up by thepyramidal approach.There should be noted one thing with respect to theseoptimization methods. Sometimes next to the dissimilaritymeasure term the formula to be minimized contains as wellsocalled regularization or penalty term, which interconnects the transformation and data to be transformed 82.These two terms together form the cost function energyassociated with the registration and the aim of theoptimization methods is to minimize it. In literature suchmethods can be referred to as energy minimization methods.The regularization term is usually omitted in case of rigidbody transforms, but in nonrigid transformations such aselastic or fluid registration methods, described more indetail in Section 5, is present.4.2. Featurebased methodsWe assume that two sets of features in the reference andsensed images represented by the CPs points themselves,end points or centers of line features, centers of gravity ofregions, etc. have been detected. The aim is to find the pairwise correspondence between them using their spatialrelations or various descriptors of features.4.2.1. Methods using spatial relationsMethods based primarily on the spatial relations amongthe features are usually applied if detected features areambiguous or if their neighborhoods are locally distorted.The information about the distance between the CPs andabout their spatial distribution is exploited.Goshtasby in Ref. 71 described the registration basedon the graph matching algorithm. He was evaluating thenumber of features in the sensed image that, after theparticular transformation, fall within a given range next tothe features in the reference image. The transformationparameters with the highest score were then set as a validestimate.Clustering technique, presented by Stockman et al. 175,tries to match points connected by abstract edges or linesegments. The assumed geometrical model is the similaritytransform. For every pair of CPs from both the reference andB. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000 985sensed images, the parameters of the transformation whichmaps the points on each other are computed and representedas a point in the space of transform parameters. Theparameters of transformations that closely map the highestnumber of features tend to form a cluster, while mismatchesfill the parameter space randomly. The cluster is detectedand its centroid is assumed to represent the most probablevector of matching parameters. Mapping function parameters are thus found simultaneously with the featurecorrespondence. Local errors do not influence globally theregistration process. The clustering technique wasimplemented, for example, in Refs. 30,72.Barrow et al. 14 introduced the chamfer matching forimage registration. Line features detected in images arematched by means of the minimalization of the generalizeddistance between them. Borgefors 22 proposed animproved version, where better measure of correspondencethe sequential distance transform together with theroot mean square averagewas applied. The algorithmemploys also the pyramidal speedup.Even that this overview does not intend to cover 3Dregistration methods, here the wellknown Iterative ClosestPoint ICP algorithm, introduced by Besl and McKay 18is mentioned, because it represents a key approach forregistering 3D shapes including freeform curves andsurfaces.4.2.2. Methods using invariant descriptorsAs an alternative to the methods exploiting the spatialrelations, the correspondence of features can be estimatedusing their description, preferably invariant to theexpected image deformation see Fig. 4. The descriptionFig. 4. Featurebased method using invariant descriptors in these two satellite images, control points corners were matched using invariants based oncomplex moments 56. The numbers identify corresponding CPs. The bottom image shows the registration result.B. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000986should fulfill several conditions. The most important onesare invariance the descriptions of the correspondingfeatures from the reference and sensed image have to bethe same, uniqueness two different features should havedifferent descriptions, stability the description of afeature which is slightly deformed in an unknown mannershould be close to the description of the original feature,and independence if the feature description is a vector, itselements should be functionally independent. However,usually not all these conditions have to or can besatisfied simultaneously and it is necessary to find anappropriate tradeoff.Features from the sensed and reference images with themost similar invariant descriptions are paired as thecorresponding ones. The choice of the type of the invariantdescription depends on the feature characteristics and theassumed geometric deformation of the images. Whilesearching for the best matching feature pairs in the spaceof feature descriptors, the minimum distance rule withthresholding is usually applied. If a more robust algorithm isneeded, the matching likelihood coefficients 51, which canbetter handle questionable situations, can be an appropriatesolution. Guest et al. proposed to select features accordingto the reliability of their possible matches 80.The simplest feature description is the image intensityfunction itself, limited to the close neighborhood of thefeature 1,107. To estimate the feature correspondence,authors computed the CC on these neighborhoods. Othertypes of similarity measures can be used, too. Zheng andChellapa make use of the correlation coefficients 219.They assumed the similarity geometric deformation. In theirapproach, firstly the rotation between images was compensated by the estimation of the illuminant direction and thenthe coarsetofine correlation based registration was performed. In Ref. 223 the MI was used for the improvementof the feature correspondence.The following references are examples of the intuitivedescriptions, which usually do not fulfill some of thementioned criteria of invariant descriptors. Sester et al.165 proposed to describe forests, used as the regionfeatures, by elongation parameter, compactness, number ofholes, and several characteristics of the minimum boundingrectangle. To register stars with a catalog, Murtagh 133assigned to every point feature the description of the spatialdistribution of other features lying around. Vujovic andBrzakovic in Ref. 202 represented every detected featureelongated structure intersections by its signature formedby the longest structure and angles between all otherstructures, participating in the intersection. Similarly, Zana218 described each feature point by means of anglesbetween relevant intersecting lines. Montesinos et al. 131proposed to use differential descriptors of the imagefunction in the neighborhood of the detected CPs. Yangand Cohen 216 used border triangles generated by objectconvex hull and computed on them affine geometricinvariants.Many authors used closedboundary regions as thefeatures. In principle, any invariant and discriminativeenough shape descriptor can be employed in regionmatching. Peli 141 proposed simple and fast descriptionby radial shape vector but the usage of this method is limitedto starshape regions only. A generalized shape descriptionin a form of a binary matrix was proposed in Ref. 65,180.In Ref. 72, the shape matrices were used for registration ofrotated and scaled satellite images. In Ref. 112 a chaincode representation of contours was proposed as theinvariant description and a chain code correlationlikemeasure was used for finding the correspondence. Skea et al.171 represented noncollinear triplets of CPs by thesphericity. Suk 178 proposed the invariant shape description of the regions represented by polygons and furtherdeveloped this approach in Ref. 179.A large group of methods uses momentbased invariants for description of closedboundary region features.Considering the most often assumed deformations, Hu93 introduced moment invariants to the similaritytransform. Flusser and Suk derived the affine transforminvariants 53 and used them successfully for registrationof SPOT and Landsat images 54. Holm 88 extractedclosed boundary regions and proposed to represent themby their perimeter, area, compactness, moments, andmoment invariants. Bhattacharya 20 suggested theapplication of complex moments. Brivio et al. 24modeled shadow structures in mountain images bymeans of their inertia ellipses. The ellipses are heredescribed by their area, inclination of the main axis andellipticity. All these attributes are functions of moments.Li et al. 112 used first two Hus moments as preselectorsfor matching of closed contours. The candidate matcheswere tested using the chain code representation of thecontours. A similar method was described in Ref. 35,where the moment invariants are used together with thechain codes. Sato and Cipolla 163 computed directly,without correspondence estimation, the parameters of thepresent geometric deformations an affine transform wasexpected using the circular moments of distribution of theline features orientation. They combined moments and thescalespace representation of the images. Recently, Flusserand Suk 55 introduced a new class of moment invariantsthat are invariant to image blurring and demonstrated theirperformance in registering SPOT and AVHRR satelliteimages. Bentoutou et al. 16 registered mutually shiftedand blurred digital subtraction angiography images usingthese invariants. Flusser et al. further developed thisapproach in Ref. 56 by introducing the combined blurrotation invariants. In Ref. 52 they generalized theprevious invariants to register 3D images.Invariant combination of the basic geometric propertiesof features can form geometrically oriented descriptors.Govindu et al. 74 represented the extracted contoursfrom possibly rotated images by the slopes of tangents inthe contour points. They did not look for contourB. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000 987correspondence, but only for the distributions of theproposed descriptors. By comparison of the correspondingdistributions from the reference and sensed images themutual image rotation can be estimated. They derived asimilar type of descriptors for the affine transform, too. Adetailed study of the practical aspects of the proposedmethod can be found in Ref. 73. Wang and Chen 205computed the histogram of linelength ratios and thehistogram of angle differences of any two line segments inthe reference and sensed images. They assumed thesimilarity transform. Griffin and Alexopoulos 77 usedthe ratio of the smallest enclosing circle radii, the differenceof the locations of centroids of gravity, and the sorting of theneighbors lexicographically according to the angle with thex axis and the distance from the centroid. All these methodsskip the step of finding the feature correspondence andestablish directly the mapping function parameters.Hsieh et al. 91 used the angle histogram computed online feature points for the compensation of rotationdifference. After the removal of the rotation difference,the feature point correspondence is found by means of CC.They compared their rotation compensation with the onedescribed in Ref. 219.Shekhar et al. 167 combined different types of featuresand their descriptors. They decomposed the presentgeometric deformation into elementary steps and thenestimated transform parameters using the feature consensusevery type of feature descriptor votes for thecorresponding value of the parameter. The value of theparameter which maximizes the number of votes over alldescriptor types is then chosen.Ventura et al. 200 described image features byvarious descriptors ellipticity, angle, thinness, etc. andrepresented relations among them by a multivalue logicaltree MVLT. Then they compared the MVLTs of thereference and sensed images to find the featurecorrespondence. MVLTs are applied also in Ref. 24,together with moment invariants.Invariant descriptors can be used as well in situations,when no precedent feature detection was done and theinvariants are successively computed for the window slidingacross the whole image 55. For translated and rotatedimages, Goshtasby 66 proposed to calculate the momentinvariants 93 from the circularshaped windows and thento apply the CC criterion on the moment windowrepresentation. A similar idea was used earlier by Wongand Hall 213. Along with the momentbased windowdescription, they applied hierarchical search strategy tomatch radar and optical images.4.2.3. Relaxation methodsA large group of the registration methods is based on therelaxation approach, as one of the solutions to the consistentlabeling problem CLP to label each feature from thesensed image with the label of a feature from the referenceimage, so it is consistent with the labeling given to the otherfeature pairs 130. The process of recalculating the pairfigures of merit, considering the match quality of the featurepairs and of matching their neighbors, is iteratively repeateduntil a stable situation is reached. The reference work wasdone by Ranade and Rosenfeld 148. Here, the displacement of the feature sets transformed by a certain geometrictransformation defines the figures of merit of the featurepairs. This method can handle shifted images and it tolerateslocal image distortions.Wang et al. 204 extended the classical relaxation byincluding the description of the corner features. They usedcorner sharpness, contrast, and slope. This algorithm allowsto handle translation and rotation distortions in the images,but it is computationally demanding. Medioni and Nevatia128 used line features and their descriptors coordinates,orientation, average contrast. Cheng and Huang 33proposed a starbased registration which considers individual feature points along with all links to their neighbors. Tonand Jain 190 speeded up the algorithm by integrating theMergeSort concept. Their method works with shifted androtated images. Relaxation based method even for similaritytransformed images was proposed, for example, by Cheng32, Ogawa 136 and Li 113. Different relaxationmethods are compared in Ref. 147.Another solution to the CLP problem and consequentlyto the image registration is backtracking, where consistentlabeling is generated in recursive manner. A registrationmethod based on backtracking is described in Ref. 130.4.2.4. Pyramids and waveletsWe conclude the discussion about the feature matchingby mentioning some works that try to reduce thecomputational cost due to the large image size by meansof pyramidal approach.First attempts were done back in 1977. Vanderbrug andRosenfeld concentrated in their work on the amount ofcomputation needed for the window pair testing. In Ref.197, they used a subwindow first to find probablecandidates of the corresponding window in the referenceimage and then the fullsize window was applied. Theydiscussed the appropriate choice of the subwindow size tominimize the expected computational cost. In Ref. 160they proposed to use first both the sensed and the referenceimages at a coarser resolution and then, on locations withsmall error measure, to match higher resolution images.Althof et al. 4 proposed to decrease the necessarycomputational load by taking just a sparse regular grid ofwindows for which the cross correlation matching isperformed. These techniques are simple examples ofpyramidal methods.In general, this coarsetofine hierarchical strategyapplies the usual registration methods, but it starts withthe reference and sensed images on a coarse resolutiongenerated using Gaussian pyramids, simple averaging orwavelet transform coefficients, among others. Then theygradually improve the estimates of the correspondence or ofB. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000988the mapping function parameters while going up to the finerresolutions. At every level, they considerably decrease thesearch space and thus save the necessary computationaltime. Another important advantage resides in the fact thatthe registration with respect to largescale features isachieved first and then small corrections are made forfiner details. On the other hand, this strategy fails if a falsematch is identified on a coarser level. To overcome this, abacktracking or consistency check should be incorporatedinto the algorithms.Combining CC with the pyramidal approach thatexploits a summing pyramid the pixel value at a coarserlevel corresponds to the summation of the pixel valueson the previous level, a median pyramid, and anaveraging pyramid was proposed in Refs. 37,208,219,respectively. Wong and Hall 214 combined the SSDAmethod with pyramidal speedup. Wang and Chen 205extracted features centroids of closed boundary regionsat every resolution level and found the parameters ofgeometric deformation from the histogram of angledifferences and linelength ratios, as mentioned above.Thevenaz et al. applied a cubic spline based pyramidalong with the minimization of the mean square intensitydifference between the images 184 and the MImaximization 187, respectively. Sharma and Pavel166 used the multiresolution Laplacian pyramid forthe infrared and radar images registration. Kumar et al.102 combined different types of pyramids Laplacian,Gaussian with different similarity measures CC, sum ofsquared differences to register aerial video sequences.Nonlinear minmax filters applied in a pyramidalscheme was used in Ref. 169.Recently, wavelet decomposition of the images wasrecommended for the pyramidal approach due to its inherentmultiresolution character. Methods can differ in the type ofthe applied wavelet and the set of wavelet coefficients usedfor finding the correspondence. Most frequently usedmethods decompose the image recursively into four setsof coefficients LL, HL, LH, HH by filtering the imagesuccessively with two filters, a lowpass filter L and a highpass filter H, both working along the image rows andcolumns.Turcajova and Kautsky 193 tested various orthogonaland biorthogonal wavelets they used LL coefficientstogether with CC on a regular grid of points to registeraffine transformed images. Spline biorthogonal waveletsand Haar wavelet outperformed others. Fonseca and Costa58 detected the modulus maxima of LH and HLcoefficients and looked for the maxima of the correlationcoefficients, computed from LL coefficients in smallsurroundings of the detected maxima. Djamdji et al.41 use just HH coefficients. Le Moigne 105 applied theDaubechies wavelet to register Landsat images andAVHRR data. They extracted LH and HL frequencycoefficients and found the correspondence by means ofCC. Liu et al. 118 proposed the application of Gaborwavelet transform and Gaussian model of registrationresidua. You and Bhattacharya 217 use the maximumcompact fuzzy sets of wavelet coefficients as features andHD as similarity measure. The robustness of theregistration by means of the Daubechies and Haarwavelets was studied in Ref. 176.4.2.5. SummaryAreabased methods are preferably applied when theimages have not many prominent details and the distinctiveinformation is provided by graylevelscolors rather than bylocal shapes and structure. Areabased methods have twoprincipal limitations. Reference and sensed images musthave somehow similar intensity functions, either identicaland then correlationlike methods can be used or at leaststatistically dependent this typically occurs in multimodalregistration.From the geometric point of view, only shift and smallrotation between the images are allowed when using areabased methods although the areabased methods can begeneralized to full rotation and scaling, it is practicallymeaningless because of an extreme computational load. Tospeed up the searching, areabased methods often employpyramidal image representations and sophisticated optimization algorithms to find the maximum of the similaritymatrix.Featurebased matching methods are typically appliedwhen the local structural information is more significantthan the information carried by the image intensities. Theyallow to register images of completely different nature likeaerial photograph and map and can handle complexbetweenimage distortions. The common drawback of thefeaturebased methods is that the respective features mightbe hard to detect andor unstable in time. The crucial pointof all featurebased matching methods is to have discriminative and robust feature descriptors that are invariant to allassumed differences between the images.5. Transform model estimationAfter the feature correspondence has been establishedthe mapping function is constructed. It should transform thesensed image to overlay it over the reference one. Thecorrespondence of the CPs from the sensed and referenceimages together with the fact that the corresponding CPpairs should be as close as possible after the sensed imagetransformation are employed in the mapping functiondesign.The task to be solved consists of choosing the type ofthe mapping function see Fig. 5 and its parameterestimation. The type of the mapping function shouldcorrespond to the assumed geometric deformation of thesensed image, to the method of image acquisition e.g.scanner dependent distortions and errors and to therequired accuracy of the registration the analysis of errorB. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000 989for rigidbody pointbased registration was introduced inRef. 48.In special situations when the geometric deformation ispartially known, e.g. when there exists a model for thedistortion caused by the acquisition device andor thescene geometry, the precorrection based on the inverse ofthe deformation can be performed for example, in Refs.94,168,181, the authors model the Earths shape androtation, the satellite orbit and the scanning geometry ofthe sensor.Models of mapping functions can be divided into twobroad categories according to the amount of image datathey use as their support. Global models use all CPs forestimating one set of the mapping function parametersvalid for the entire image. On the other hand, the localmapping functions treat the image as a composition ofpatches and the function parameters depend on thelocation of their support in the image. It leads to thetessellation of the image, usually a triangulation, and tothe defining of parameters of the mapping function foreach patch separately.From another point of view, mapping functions can becategorized according to the accuracy of overlaying of theCPs used for computation of the parameters. Interpolatingfunctions map the sensed image CPs on the referenceimage CPs exactly, whereas approximating functions tryto find the best tradeoff between the accuracy of the finalmapping and other requirements imposed on the characterof the mapping function. Since the CP coordinates areusually supposed not to be precise, the approximationmodel is more common.5.1. Global mapping modelsOne of the most frequently used global models usesbivariate polynomials of low degrees. Similarity transformis the simplest modelit consists of rotation, translationand scaling onlyu  sx cosw2 y sinw  txv  sx sinw  y cosw  tyThis model is often called shapepreserving mappingbecause it preserves angles and curvatures and is unambiguously determined by two CPs.Slightly more general but still linear model is an affinetransformu  a0  a1x  a2yv  b0  b1x  b2ywhich can map a parallelogram onto a square. This modelis defined by three noncollinear CPs, preserves straightlines and straight line parallelism. It can be used formultiview registration assuming the distance of thecamera to the scene is large in comparison to the sizeof the scanned area, the camera is perfect a pinholecamera, the scene is flat, and the present geometricdistortion has no local factors.Fig. 5. Examples of various mapping functions similarity transform top left, affine transform top right, perspective projection bottom left, and elastictransform bottom right.B. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000990If the condition on the distance of the camera from thescene is not satisfied the perspective projection modelu  a0  a1x  a2y1  c1x  c2yv  b0  b1x  b2y1  c1x  c2yshould be used. This model exactly describes a deformationof a flat scene photographed by a pinhole camera theoptical axis of which is not perpendicular to the scene. It canmap a general quadrangle onto a square while preservingstraight lines and is determined by four independent CPs.Slight violations of these assumptions may lead to the useof the second or the thirdorder polynomial models. Higherorder polynomials usually are not used in practicalapplications because they may unnecessarily warp thesensed image in areas away from the CPs when aligningwith the reference image.In general, the number of CPs is usually higher than theminimum number required for the determination of themapping function. The parameters of the mapping functionsare then computed by means of the leastsquare fit, so thatthe polynomials minimize the sum of squared errors at theCPs. Such mapping functions do not map the CPs onto theircounterparts exactly. This approach was proved to be veryeffective and accurate for satellite images, for instance.5.2. Local mapping modelsHowever, a global polynomial mapping cannot properlyhandle images deformed locally. This happens, for instance,in medical imaging and in airborne imaging. The leastsquare technique averages out the local geometric distortionequally over the entire image which is not desirable. Localareas of the image should be registered with the availableinformation about the local geometric distortion in mind.Several authors have shown the superiority of the local orat least locally sensitive registration methods above theglobal ones in such situations Goshtasby 69, Ehlers andFogel 46, Wiemker 209, and Flusser 50, amongothers. The weighted least square and weighted meanmethods 69 gain the ability to register images locally byintroducing the slight variation to the original least squaremethod. The local methods called piecewise linear mapping67 and piecewise cubic mapping 68, together with theAkimas quintic approach 209, apply the combination ofthe CPbased image triangulation and of the collection oflocal mapping functions each valid within one triangle.These approaches belong to the group of the interpolatingmethods.5.3. Mapping by radial basis functionsRadial basis functions are representatives of the group ofglobal mapping methods but they are able to handle evenlocally varying geometric distortions. The resulting mapping function has a form of a linear combination oftranslated radially symmetric function plus a lowdegreepolynomialu  a0  a1x  a2y XNi1cigx xiand similarly for vOriginally they were developed for the interpolation ofirregular surfaces. Their name radial reflects an importantproperty of the function value at each pointit depends juston the distance of the point from the CPs, not on itsparticular position. Multiquadrics, reciprocal multiquadrics,Gaussians, Wendlands functions, and thinplate splines areseveral examples of the radial basis functions used in imageregistration.The application of the multiquadrics in the airborneremote sensing, together with the comparison to the thirdorder polynomial method, is described in Ref. 46. Itscomparison to the Akimas method is presented in Ref.209. The medical application of multiquadrics is shown inRef. 117. Wendlands functions applied in medical imageregistration appear in Ref. 60. These functions have verysmall global influence and even significant local deformations can be well registered by this approach. Thisproperty is advantageous for registering medical images,where changes occur mainly locally.The most often used representatives of the radial basisfunctions are the thinplate splines TPS, where the radialterms have the formgx xi  kx 2 xik2lnkx 2 xiksee Duchon 44 and Wahba 203 for the respectivemathematical background. Although they had been used inmechanics and engineering for decades 84, they wereintroduced to image analysis community by Grimson 78and Bookstein 21. The TPS can be viewed as a very thinplate, which is fixed at the positions determined by the CPsin the reference image in the heights given by the x or ycoordinates of the corresponding CPs in the sensed image70. The TPS minimizes the quadratic variation functionalof potential energy that reflects the amount of functionvariation and which should be small for a good mappingfunction. The type of registration can be chosenexactinterpolation 70, approximation 159 or generalizedapproximation taking into account that the anisotropiclandmark errors 157 are possible. A comprehensive studyfocused on TPSbased registration of medical images can befound in Ref. 156.The TPS registration gives good results but thecomputations can be very time consuming, namely if thenumber of CPs is high. Considerable attention has been paidto the methods decreasing the complexity of the TPSevaluation while preserving reasonable accuracy. Flusser50 proposed an adaptive approximation of the TPS onB. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000 991square or triangular regions by simpler functions. Beatsonand Newsam 15 adapted an earlier method by Greengard75 for multipole expansion of radial functions. Powell144 reduced the computational cost by the TPS tabulation.Barrodale et al. 13 paid attention to fast and robustcalculation of the TPS coefficients.Numerous papers have dealt with the comparison ofthe performance of thinplate splines and other mappingfunctions. In Refs. 57,70,209 they are compared withpolynomials and multiquadrics when registering aerialimages. The comparison of the TPS with the Gaussianradial basis functions and with multiquadrics consideringtheir local properties was done in Ref. 8. It wasconcluded that the TPS have favorable propertieswhen used as mapping functions for image registration,while the other radial basis functions are more convenientfor other applications such as image warping andmorphing 8.The TPS are not the only representatives of the splinefamily used for the mapping function design. A linearcombination of translated cubic Bsplines was used forthe registration of the echo planar images 103. Anothertype of splinebased function, the elastic body splineEBS, was proposed in 39. It evolved from thedescription of the equilibrium displacements of homogeneous isotropic elastic material subjected to a load.Body tissues depicted in the image data to be registeredoften have properties of elastic material. The EBS wasused for the registration of 3D MRI images of breasts.The authors claimed the EBS had outperformed the TPSin their experiments.5.4. Elastic registrationAnother approach to the registration of images withconsiderable complex andor local distortions is not to useany parametric mapping functions, where the estimation ofthe geometric deformation is reduced to the search for thebest parameters. This idea were introduced by Bajcsy et al.10 and is often called elastic registration.The images are viewed as pieces of a rubber sheet, onwhich external forces stretching the image and internalforces defined by stiffness or smoothness constraints areapplied to bring them into alignment with the minimalamount of bending and stretching. The feature matching andmapping function design steps of the registration are donesimultaneously. This is one of the advantages of elasticmethods, because feature descriptors invariant to complicated deformations are not known and the featurecorrespondence is difficult to establish in the traditionalway. The registration is achieved by locating the minimumenergy state in an iterative fashion. A pyramidal approach isoften applied. The external forces can be derived from thelocal optimization of the similarity function which isdefined by the intensity values or by the correspondenceof boundary structures 38, among others. In Ref. 140, noexternal forces were used and the prescribed displacements,derived from the correspondence of boundary structures,were incorporated to the elastic image deformation.Disadvantage of elastic registration is in situations whenimage deformations are very localized. This can be handledby means of fluid registration. Fluid registration methodsmake use of the viscous fluid model to control the imagetransformation. The reference image is here modelled as athick fluid that flows out to match the sensed image underthe control of the derivative of a Gaussian sensor model.This approach is mainly used in medical applications 25.The weakness of this approach is blurring introduced duringthe registration process. Lester and Arridge 110 proposedto use fluid model just for finding the correspondence of CPsand then process the very transformation by means of thethin plate splines. Comparison of three methods for fluidbased registration can be found in Ref. 212.Another examples of nonrigid methods are diffusionbased registration, level sets registration, and optical flowbased registration. The diffusion registration handles objectcontours and other features as membranes, setting thegeometrical constraints. Three variations of this approachare described in Ref. 189. Different solution was proposedby Andersen and Nielsen 5. Vemuri et al. 199 introducedelastic registration method, based on evolution of level sets,moving along their respective normals. Finally, the opticalflow approach was originally motivated by estimation ofrelative motion between images 19. The class of opticalflow registration covers very large number of methods and isbeyond the scope of this survey.6. Image resampling and transformationThe mapping functions constructed during the previousstep are used to transform the sensed image and thus toregister the images. The transformation can be realized in aforward or backward manner. Each pixel from the sensedimage can be directly transformed using the estimatedmapping functions. This approach, called a forward method,is complicated to implement, as it can produce holes andoroverlaps in the output image due to the discretization androunding. Hence, the backward approach is usually chosen.The registered image data from the sensed image aredetermined using the coordinates of the target pixel thesame coordinate system as of the reference image and theinverse of the estimated mapping function. The imageinterpolation takes place in the sensed image on the regulargrid. In this way neither holes nor overlaps can occur in theoutput image.The interpolation itself is usually realized via convolution of the image with an interpolation kernel. An optimalinterpolant2D sinc functionis hard to implement inpractice because of its infinite extent. Thus, many simplerinterpolants of bounded support have been investigated inthe literature. In order to reduce the computational cost,B. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000992preferably separable interpolants have been considered. Theseparability enables to replace an m  m 2D convolution bym  1 1D convolutions which is much faster.The nearest neighbor function, the bilinear and bicubicfunctions see Fig. 6, quadratic splines 42,191, cubic Bsplines 89, higherorder Bsplines 108, CatmullRomcardinal splines 100,184, Gaussians 7, and truncated sincfunctions 182 belong to the most commonly usedinterpolants. Meijering et al. 129 investigated higherorder polynomial kernels quintic and septic. However,their experiments showed only marginal improvement incomparison with cubic interpolation at an highly increasedcomputational cost.Several survey papers on resampling techniques havebeen published in the last years. A detailed investigation andcomparison of methods was carried out in Ref. 138 for 2Dimages and in Ref. 76 for 3D data. Thevenaz et al. 182paid attention to the elimination of undesired interpolationartifacts. Lehman et al. 109 published a survey articlecovering main interpolation methods various versions ofsinc functions, nearest neighbor, linear, quadratic, cubic,cubic Bspline, Lagrange and Gaussian kernels with theemphasis on medical imaging applications. They comparedthem using the spatial and Fourier analysis and tested thecomputational complexity as well as interpolation errors.Most recently, Thevenaz et al. 183 have proposed adifferent approach to image resampling. Unlike the othermethods, their resampling functions do not necessarilyinterpolate the image graylevels. They rather interpolatevalues calculated as certain functions of the graylevels. Theauthors have demonstrated this approach outperformstraditional interpolation techniques.Even though the bilinear interpolation is outperformedby higherorder methods in terms of accuracy and visualappearance of the transformed image, it offers probably thebest tradeoff between accuracy and computational complexity and thus it is the most commonly used approach.Cubic interpolation is recommended when the geometrictransformation involves a significant enlargement of thesensed image. Nearest neighbor interpolation should beFig. 6. Image interpolation methods the original image top left was enlarged five times using three different interpolation techniquesnearest neighbor topright, bilinear bottom left, and bicubic bottom right.B. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000 993avoided in most cases because of artifacts in the resampledimage. The only exclusion is when the image to betransformed contains low number of intensities and we donot want to introduce synthetic graylevelscolors by higherorder interpolation.7. Evaluation of the image registration accuracyRegardless of the particular images, the used registrationmethod, and the application area, it is highly desirable toprovide the user with an estimate how accurate theregistration actually is. The accuracy evaluation is a nontrivial problem, partially because the errors can be draggedinto the registration process in each of its stages andpartially because it is hard to distinguish between registration inaccuracies and actual physical differences in theimage contents. In this Section, we review basic errorclasses and methods for measuring the registrationaccuracy.Localization error. Displacement of the CP coordinatesdue to their inaccurate detection is called localization error.Being an intrinsic error of the detection method, thelocalization error cannot be measured directly on thegiven image. However, the mean precision of most CPdetection methods is known for various image types fromcomputer simulation studies and ground truth comparisons.This can be used for estimation of the expected localizationerror in the particular case. Localization error can bereduced by selecting an optimal feature detectionalgorithm for the given data but usually there is a tradeoff between the number of detected CP candidates and themean localization error. Sometimes we prefer to have moreCP with higher localization error rather than only few ofthem, yet detected more precisely.Matching error. Matching error is measured by thenumber of false matches when establishing the correspondence between CP candidates. It is a serious mistake whichusually leads to failure of the registration process and shouldbe avoided. Fortunately, in most cases it can be ensured byrobust matching algorithms. False match can be identifiedby consistency check, where two different matchingmethods are applied to the same set of the CP candidates.Only those pairs found by the both methods are consideredas valid CP pairs, the other candidate points are excludedfrom the further processing. In case there is no other reliablematching method, false CP pairs can be identified by crossvalidation. In each step, we exclude one pair from the set ofCPs and calculate the mapping parameters translationvector and rotation angle for instance. Then we check howwell the excluded points are mapped one to the other by thismodel. If their displacement is below a given threshold, theyare accepted as a valid CP pair.Alignment error. By the term alignment error we denotethe difference between the mapping model used for theregistration and the actual betweenimage geometricdistortion. Alignment error is always present in practicebecause of two different reasons. The type of the chosenmapping model may not correspond to the actual distortionandor the parameters of the model were not calculatedprecisely. The former case is caused by lack of a prioriinformation about the geometric distortion while the latteroriginates from the insufficient number of CPs andor theirlocalization errors.Alignment error can be evaluated in several ways. Thesimplest measure is a mean square error at the CPs CPE.Although commonly used, it is not good alignment errormeasure. In fact, it only quantifies how well the CPcoordinates can be fitted by the chosen mapping model. Forany CP set, zero CPE can be reached just by selection of amapping model with enough degrees of freedom this wellknown phenomenon is in numerical analysis called overfitting. On the other hand, large CPE can be caused by CPlocalization errors and does not necessarily reflect poorregistration accuracy.Very similar to the CPE is so called test point errorTPE. Test points are CPs that were deliberately excludedfrom the calculation of the mapping parameters. TPE cannotbe set to zero by overfitting which makes it moremeaningful than CPE. However, the localization error ofthe test points may negatively affect this measure. Thismethod can be used only if a sufficient number of the CPs isavailable. Otherwise, the exclusion of several CPs mayresult in inaccurate estimation of mapping parameters. Inmedical applications, CPs can be far from the region ofinterest. Thus, Fitzpatrick et al. 47,49 proposed to detectanatomical points within the region of interest and to usethem as test points the called them target points. Theconcept of TPE can be extended such that the distancebetween corresponding test lines or surfaces is measured134,139.Another approach to estimation of alignment accuracy isconsistency check using multiple cues. Here, the imageregistered by the method under investigation is comparedby a proper metric in the image space with the same imageregistered by another comparative method. As the comparative method we use preferably gold standard method,which is a method commonly believed to be the best in theparticular application area or for the given image type goldstandard method then plays a role similar to ground truth.This approach is often used in medical imaging 47,207. Inapplication areas where any gold standard does not exist,like in remote sensing, computer vision, and industrialinspection, we take as the comparative method any methodof different nature. Small difference between the registrationresults then indicates although does not guarantee goodregistration accuracy.Different consistency check can be employed when a setof at least two sensed images is registered to the samereference 34,63,87,215. The sensed images can be alsoregistered among themselves using the same set of CPs,which provides another set of mapping parameters. UsingB. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000994transitivity of mappings, we obtain for each sensed imagetwo sets of mapping parameters, i.e. two registered images,which should be theoretically the same. The displacement ofthe test points can serve as a quality measure.Finally, the oldest method of registration accuracyestimationvisual assessment by a domain expertshouldbe mentioned. It is still in use at least as a complement of theabove mentioned objective error measures.Estimation of accuracy of registration algorithms is ansubstantial part of registration process. Without quantitativeevaluation, no registration method can be accepted forpractical utilization. A lot of work has been done onvalidation of rigidbody registration the most comprehensive casestudy is probably the Vanderbilt Universityproject 207 while validation of nonlinear, local andelastic registration methods is still at the beginning.8. Current trends and outlook for the futureImage registration is one of the most important taskswhen integrating and analyzing information from varioussources. It is a key stage in image fusion, change detection,superresolution imaging, and in building image information systems, among others. This paper gives a survey ofthe classical and uptodate registration methods, classifying them according to their nature as well as according to thefour major registration steps. Although a lot of work hasbeen done, automatic image registration still remains anopen problem. Registration of images with complex nonlinear and local distortions, multimodal registration, andregistration of ND images where N . 2 belong to themost challenging tasks at this moment.When registering images with nonlinear, locally dependent geometric distortions, we are faced with two basicproblemshow to match the CPs and what mappingfunctions to use for registration. While the second one canbe solved at least on theoretical level by using appropriateradial basis functions, the first problem is generallyunsolvable due to its nature. Since the betweenimagedeformations can be arbitrary, we cannot use any automaticmatching method. Another conceptual question here is howcan we distinguish between image deformations and realchanges of the scene.In multimodal registration, MI technique has become astandard reference, mainly in medical imaging. However,being an areabased technique, the MI has principallimitations. To overcome them, some authors combinedthe MI with other, preferably featurebased, methods to gainhigher robustness and reliability. To speed up the computation, they often employed pyramidal image representationalong with fast optimization algorithms. Unfortunately,when the images have significant rotation andor scalingdifferences, these methods either fail or become extremelytime expensive. The future development on this field couldpay more attention to the featurebased methods, whereappropriate invariant and modalityinsensitive features canprovide good platform for the registration. Besides, we trustthat new applicationspecific methods utilizing particularsensor characteristics appear soon in remote sensing.The major difficulty of ND image registration residesin its computational complexity. Although the speed ofcomputers has been growing, the need to decrease thecomputational time of methods persists. The complexityof methods as well as the size of data still grows thehigher resolution, higher dimensionality, larger size ofscanned areas. Moreover, the demand for higher robustness and accuracy of the registration usually enforcessolutions utilizing the iterations or backtracking, whichalso produces increase of computational complexity of themethod.In the future, the idea of an ultimate registration method,able to recognize the type of given task and to decide byitself about the most appropriate solution, can motivate thedevelopment of expert systems. They will be based on thecombination of various approaches, looking for consensusof particular results.AcknowledgementsThis work has been supported by the grant No.10201P065 of the Grant Agency of the Czech Republic.References1 S. Abdelsayed, D. Ionescu, D. Goodenough, Matching andregistration method for remote sensing images, Proceedings of theInternational Geoscience and Remote Sensing SymposiumIGARSS95, Florence, Italy, 1995, pp. 10291031.2 H.S. Alhichri, M. Kamel, Virtual circles a new set of features for fastimage registration, Pattern Recognition Letters 24 200311811190.3 W.S.I. Ali, F.S. Cohen, Registering coronal histological 2D sectionsof a rat brain with coronal sections of a 3D brain atlas usinggeometric curve invariants and Bspline representation, IEEETransactions on Medical Imaging 17 1998 957966.4 R.J. Althof, M.G.J. Wind, J.T. Dobbins, A rapid and automaticimage registration algorithm with subpixel accuracy, IEEE Transactions on Medical Imaging 16 1997 308316.5 P.R. Andersen, M. Nielsen, Nonrigid registration by geometryconstrained diffusion, Medical Image Analysis 5 2001 8188.6 P.E. Anuta, Spatial registration of multispectral and multitemporaldigital imagery using Fast Fourier Transform, IEEE Transactions onGeoscience Electronics 8 1970 353368.7 C.R. Appledorn, A new approach to the interpolation of sampleddata, IEEE Transactions on Medical Imaging 15 1996 369376.8 N. Arad, N. Dyn, D. Reisfeld, Y. Yeshurun, Image warping by radialbasis functions application to facial expressions, CVGIP GraphicalModels and Image Processing 56 1994 161172.9 M.A. Audette, F.P. Ferrie, T.M. Peters, An algorithmic overview ofsurface registration techniques for medical imaging, Medical imageAnalysis 4 2000 201217.10 R. Bajcsy, S. Kovacic, Multiresolution elastic matching, ComputerVision, Graphics and Image Processing 46 1989 121.B. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000 99511 S. Banerjee, D.P. Mukherjee, D.D. Majumdar, Point landmarks forregistration of CT and NMR images, Pattern Recognition Letters 161995 10331042.12 D.I. Barnea, H.F. Silverman, A class of algorithms for fast digitalimage registration, IEEE Transactions on Computing 21 1972179186.13 I. Barrodale, D. Skea, M. Berkley, R. Kuwahara, R. Poeckert,Warping digital images using thin plate splines, Pattern Recognition26 1993 375376.14 H.G. Barrow, J.M. Tenenbaum, R.C. Bolles, H.C. Wolf., Parametriccorrespondence and chamfer matching Two new techniques forimage matching. Proceedings of the Fifth International JointConference on Artificial Intelligence, Cambridge, Massachusetts,1977, pp. 659663.15 R.K. Beatson, G.N. Newsam, Fast evaluation of radial basisfunctions, Computers Mathematical Applications 24 1992 719.16 Y. Bentoutou, N. Taleb, M. Chikr El Mezouar, M. Taleb, J. Jetto, Aninvariant approach for image registration in digital subtractionangiography, Pattern Recognition 35 2002 28532865.17 R. Berthilsson, Affine correlation. Proceedings of the InternationalConference on Pattern Recognition ICPR98, Brisbane, Australia,1998, p. 14581461.18 P.J. Besl, N.D. McKay, A method for registration of 3D shapes,IEEE Transactions on Pattern Analysis and Machine Intellinegce 141992 239254.19 S.S. Beuchemin, J.L. Barron, The computation of optical flow, ACMComputing Surveys 27 1995 433467.20 D. Bhattacharya, S. Sinha, Invariance of stereo images via theory ofcomplex moments, Pattern Recognition 30 1997 13731386.21 F.L. Bookstein, Principal warps Thinplate splines and thedecomposition of deformations, IEEE Transactions on PatternAnalysis and Machine Intelligence 11 1989 567585.22 G. Borgefors, Hierarchical chamfer matching a parametric edgematching algorithm, IEEE Transactions on Pattern Analysis andMachine Intelligence 10 1988 849865.23 R.N. Bracewell, The Fourier Transform and Its Applications,McGrawHill, New York, 1965.24 P.A. Brivio, A.D. Ventura, A. Rampini, R. Schettini, Automaticselection of control points from shadow structures, InternationalJournal of Remote Sensing 13 1992 18531860.25 M. BroNielsen, C. Gramkow, Fast fluid registration of medicalimages, In Proceedings Visualization in Biomedical ComputingVBC96, 1131, Springer Lecture Notes in Computer Science,Hamburg, Germany, 1996, pp. 267276.26 L.G. Brown, A survey of image registration techniques, ACMComputing Surveys 24 1992 326376.27 S.C. Cain, M.M. Hayat, E.E. Armstrong, Projectionbased imageregistration in the presence of fixedpattern noise, IEEE Transactionson Image Processing 10 2001 18601872.28 J. Canny, A computational approach to edge detection, IEEETransactions on Pattern Analysis and Machine Intelligence 8 1986679698.29 E.D. Castro, C. Morandi, Registration of translated and rotatedimages using finite Fourier transform, IEEE Transactions on PatternAnalysis and Machine Intelligence 9 1987 700703.30 S.H. Chang, F.H. Cheng, W.H. Hsu, G.Z. Wu, Fast algorithm forpoint pattern matching Invariant to translations, rotations and scalechanges, Pattern Recognition 30 1997 311320.31 Q. Chen, M. Defrise, F. Deconinck, Symmetric phaseonly matchedfiltering of FourierMellin transform for image registration andrecognition, IEEE Transactions on Pattern Analysis and MachineIntellingence 16 1994 11561168.32 F.H. Cheng, Point pattern matching algorithm invariant togeometrical transformation and distortion, Pattern RecognitionLetters 17 1996 14291435.33 J.K. Cheng, T.S. Huang, Image registration by matching relationalstructures, Pattern Recognition 17 1984 149159.34 A.V. Cideciyan, Registration of ocular fundus images, IEEEEngineering in Medicine and Biology 14 1995 5258.35 X. Dai, S. Khorram, A featurebased image registration algorithmusing improved chaincode representation combined with invariantmoments, IEEE Transactions on Geoscience and Remote Sensing 371999 23512362.36 X. Dai, S. Khorram, Development of a featurebased approach toautomated image registration for multitemporal and multisensorremotely sensed imagery, International Geoscience andRemote Sensing Symposium IGARSS97, Singapore, 1997, pp.243245.37 P. Dani, S. Chaudhuri, Automated assembling of images Imagemontage preparation, Pattern Recognition 28 1995 431445.38 C. Davatzikos, J.L. Prince, R.N. Bryan, Image registration based onboundary mapping, IEEE Transactions on Medical Imaging 151996 112115.39 M.H. Davis, A. Khotanzad, D.P. Flaming, S.E. Harms, A physicsbased coordinate transformation for 3D image matching, IEEETransactions on Medical Imaging 16 1997 317328.40 L. Ding, A. Goshtasby, M. Satter, Volume image registration bytemplate matching, Image and Vision Computing 19 2001821832.41 J.P. Djamdji, A. Bajaoui, R. Maniere, Geometrical registration ofimages the multiresolution approach, Photogrammetric Engineeringand Remote Sensing 53 1993 645653.42 N.A. Dodgson, Quadratic interpolation for image resampling, IEEETransactions on Image Processing 6 1997 13221326.43 L. Dreschler, H. Nagel, Volumetric model and 3D trajectory of amoving car derived from monocular TVframe sequence of a streetscene, Proceedings of the Interantional Joint Conference on ArtificialIntelligence, Vancouver, Canada, 1981, pp. 692697.44 J. Duchon, Interpolation des fonctions de deux variables suivant leprinciple de la flexion des plaques minces, RAIRO AnalyticalNumericals 10 1976 512.45 M. Ehlers, Regionbased matching for image registration in remotesensing databases, Proceedings of the International Geoscience andRemote Sensing Symposium IGARSS91, Espoo, Finland, 1991, pp.22312234.46 M. Ehlers, D.N. Fogel, Highprecision geometric correction ofairborne remote sensing revisited the multiquadric interpolation,Proceedings of SPIE Image and Signal Processing for RemoteSensing 2315 1994 814824.47 J.M. Fitzpatrik, Detection failure, assessing success, in J.V. Hajnal,D.L.G. Hill, D.J. Hawkes Eds., Medical Image Registration, CRCPress, Baton Rouge, Florida, 2001, pp. 117139.48 J.M. Fitzpatrik, J.B. West, The distribution of target registrationerror in rigidbody pointbased registration, IEEE Transactions onMedical Imaging 20 2001 917927.49 J.M. Fitzpatrik, J.B. West, C.R. Maurer Jr., Predicting error in rigidbody pointbased registration, IEEE Trasnactions on MedicalImaging 17 1998 694702.50 J. Flusser, An adaptive method for image registration, PatternRecognition 25 1992 4554.51 J. Flusser, Object matching by means of matching likelihoodcoefficients, Pattern Recognition Letters 16 1995 893900.52 J. Flusser, J. Boldys, B. Zitova, Moment forms invariant torotation and blur in arbitrary number of dimensions, IEEETransactions on Pattern Analysis and Machine Intelligence 252003 234246.53 J. Flusser, T. Suk, Pattern recognition by affine moment invariants,Pattern Recognition 26 1993 167174.54 J. Flusser, T. Suk, A momentbased approach to registration ofimages with affine geometric distortion, IEEE Transactions onGeoscience and Remote Sensing 32 1994 382387.55 J. Flusser, T. Suk, Degraded image analysis an invariant approach,IEEE Transactions on Pattern Analysis and Machine Intelligence 201998 590603.B. Zitova, J. Flusser  Image and Vision Computing 21 2003 977100099656 J. Flusser, B. Zitova, Combined invariants to linear filtering androtation, International Journal of Pattern Recognition and ArtificialIntelligence 13 1999 11231136.57 D.N. Fogel, Image rectification with radial basis functionsApplication to RSGIS data integration, Proceedings of the ThirrdInternational Conference on Integrating GIS and EnvironmentalModelling, CDROM, Santa Fe, New Mexico, 1996, 19 pp.58 L.M.G. Fonseca, M.H.M. Costa, Automatic registration of satelliteimages, Proceedings of the Brazilian Symposium on ComputerGraphic and Image Processing, Brazil, 1997, pp. 219226.59 L.M.G. Fonseca, B.S. Manjunath, Registration techniques formultisensor remotely sensed imagery, Photogrammetric Engineeringand Remote Sensing 62 1996 10491056.60 M. Fornefett, K. Rohr, H.S. Stiehl, Radial basis functions withcompact support for elastic registration of medical images, Imageand Vision Computing 19 2001 8796.61 H. Foroosh, J.B. Zerubia, M. Berthod, Extension of phase correlationto subpixel registration, IEEE Transactions on Image Processing 112002 188200.62 W. Forstner, E. Gulch, A fast operator for detection and preciselocation of distinct points, corners and centers of circular features,Proceedings of the ISPRS Workshop on Fast Processing ofPhotogrammetric Data, Interlaken, Switzerland, 1986, pp. 281305.63 P.A. Freeborough, R.P. Woods, N.C. Fox, Accurate registration ofserial 3D MR brain images and its application to visualizing changein neurodegenerative disorders, Journal of Computer AssistedTomography 20 1996 10121022.64 B.K. Ghaffary, A.A. Sawchuk, A survey of new techniques for imageregistration and mapping, Proceedings of the SPIE Applications ofDigital Image Processing 432 1983 222239.65 A. Goshtasby, Description and discrimination of planar shapes usingshape matrices, IEEE Transactions on Pattern Analysis and MachineIntelligence 7 1985 738743.66 A. Goshtasby, Template matching in rotated images, IEEETransactions on Pattern Analysis and Machine Intelligence 71985 338344.67 A. Goshtasby, Piecewise linear mapping functions for imageregistration, Pattern Recognition 19 1986 459466.68 A. Goshtasby, Piecewise cubic mapping functions for imageregistration, Pattern Recognition 20 1987 525533.69 A. Goshtasby, Image registration by local approximation methods,Image and Vision Computing 6 1988 255261.70 A. Goshtasby, Registration of images with geometric distortions,IEEE Transactions on Geoscience and Remote Sensing 26 19886064.71 A. Goshtasby, G.C. Stockman, Point pattern matching using convexhull edges, IEEE Transactions on Systems, Man and Cybernetics 151985 631637.72 A. Goshtasby, G.C. Stockman, C.V. Page, A regionbased approachto digital image registration with subpixel accuracy, IEEETransactions on Geoscience and Remote Sensing 24 1986390399.73 V. Govindu, C. Shekhar, Alignment using distributions of localgeometric properties, IEEE Transactions on Pattern Analysis andMachine Intelligence 21 1999 10311043.74 V. Govindu, C. Shekhar, R. Chellapa, Using geometric properties forcorrespondenceless image alignment, Proceedings of the International Conference on Pattern Recognition ICPR98, Brisbane,Australia, 1998, pp. 3741.75 L. Greengard, V. Rokhlin, A fast algorithm for particle simulations,Journal of Computers and Physics 73 1987 325348.76 G.J. Grevera, J.K. Udupa, An objective comparison of 3D imageinterpolation methods, IEEE Transactions an Medical Imaging 171998 642652.77 P.M. Griffin, C. Alexopoulos, Point pattern matching using centroidbounding, IEEE Transactions on Systems, Man and Cybernetics 191989 12741276.78 W.E.L. Grimson, A computational theory of visual surfaceinterpolation, Philosphical Transactions of the Royal Society ofLondon, B 298 1982 395427.79 S. Growe, R. Tonjes, A knowledge based approach to automaticimage registration, Proceedings of the IEEE International Conference on Image Processing ICIP97, Santa Barbara, California,1997, pp. 228231.80 E. Guest, E. Berry, R.A. Baldock, M. Fidrich, M.A. Smith, Robustpoint correspondence applied to two and threedimensional imageregistration, IEEE Transaction on Pattern Analysis and MachineIntelligence 23 2001 165179.81 E. Gulch, Results of test on image matching of ISPRS WG,ISPRS Journal of Photogrammetry and Remote Sensing 46 1991118.82 J.V. Hajnal, D.L.G. Hill, D.J. Hawkes, Medical Image Registration,CRC Press, Baton Rouge, Florida, 2001, ISBN 0849300649.83 H. Hanaizumi, S. Fujimura, An automated method for registration ofsatellite remote sensing images, Proceedings of the InternationalGeoscience and Remote Sensing Symposium IGARSS93, Tokyo,Japan, 1993, pp. 13481350.84 R.L. Harder, R.N. Desmarais, Interpolation using surface splines,Journal of Aircraft 9 1972 189191.85 P. Hellier, C. Barillot, Coupling dense and landmarkbasedapproaches for non rigid registration, IRISA research report, PI136830, France, 2000.86 D.L.G. Hill, P.G. Batchelor, M. Holden, D.J. Hawkes, Medicalimage registration, Physics in Medicine and Biology 46 2001R1R45.87 M. Holden, D.L.G. Hill, E.R.E. Denton, J.M. Jarosz, T.C.S. Cox, T.Rohlfing, J. Goodey, D.J. Hawkes, Voxel similarity measures for 3dserial mr brain image registration, IEEE Transactions on MedicalImaging 19 2000 94102.88 M. Holm, Towards automatic rectification of satellite images usingfeature based matching, Proceedings of the International Geoscienceand Remote Sensing Symposium IGARSS91, Espoo, Finland, 1991,pp. 24392442.89 H.S. Hou, H.C. Andrews, Cubic splines for image interpolation anddigital filtering, IEEE Transactions on Acoustic, Speech and SignalProcessing 26 1978 508517.90 J.W. Hsieh, H.Y.M. Liao, K.C. Fan, M.T. Ko, A fast algorithm forimage registration without predetermining correspondence, Proceedings of the International Conference on Pattern RecognitionICPR96, Vienna, Austria, 1996, pp. 765769.91 J.W. Hsieh, H.Y.M. Liao, K.C. Fan, M.T. Ko, Y.P. Hung, Imageregistration using a new edgebased approach, Computer Vision andImage Understanding 67 1997 112130.92 Y.C. Hsieh, D.M. McKeown, F.P. Perlant, Performance evaluationof scene registration and stereo matching for cartographic featureextraction, IEEE Transactions on Pattern Analysis and MachineIntelligence 14 1992 214237.93 M.K. Hu, Visual pattern recognition by moment invariants, IRETransactions on Information Theory 8 1962 179187.94 R.B. Huseby, O.M. Halck, R. Solberg, A modelbased approach forgeometrical correction of optical satellite images, Proceedings of theInternational Geoscience Remote Sensing Symposium IGARSS99,Hamburg, Germany, 1999, pp. 330332.95 D.P. Huttenlocher, G.A. Klanderman, W.J. Rucklidge, Comparingimages using the Hausdorff distance, IEEE Transactions on PatternAnalysis and Machine Intellinence 15 1993 850863.96 Numerical Recipes in C, The art of scientific computing, httpwww.nr.com.97 M. Jenkinson, S. Smith, A global optimisation method for robustaffine registration of brain images, Medical Image Analysis 5 2001143156.98 S. Kaneko, I. Murase, S. Igarashi, Robust image registration byincrement sign correlation, Pattern Recognition 35 200222232234.B. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000 99799 S. Kaneko, Y. Satoh, S. Igarashi, Using selective correlationcoefficient for robust image registration, Pattern Recognition 362003 11651173.100 R.G. Keys, Cubic convolution interpolation for digital imageprocessing, IEEE Transactions on Acoustics, Speech and SignalProcessing 29 1981 11531160.101 L. Kitchen, A. Rosenfeld, Graylevel corner detection, PatternRecognition Letters 1 1982 95102.102 R. Kumar, H.S. Sawhney, J.C. Asmuth, A. Pope, S. Hsu, Registrationof video to georeferenced imagery, Proceedings of the InternationalConference on Pattern Recognition ICPR98, Brisbane, Australia,1998, pp. 13931399.103 J. Kybic, P. Thevenaz, M. Unser, Multiresolution spline warping forEPI registration, Proceedings of the SPIE Mathematical ImagingWavelet Applications in Signal and Image Processing, Denver,Colorado, 1999, pp. 571579.104 D. Lavine, B. Lambird, L. Kanal, Recognition of spatial pointpatterns, Pattern Recognition 16 1983 289295.105 J. le Moigne, Parallel registratin of multisensor remotely sensedimagery using wavelet coefficients, Proceedings of the SPIEWavelet Applications, Orlando, Florida, 2242, 1994, pp. 432443.106 J. le Moigne, First evaluation of automatic image registrationmethods, Proceedings of the International Geoscience and RemoteSensing Symposium IGARSS98, Seattle, Washington, 1998, pp.315317.107 T.M. Lehmann, A two stage algorithm for modelbased registrationof medical images, Proceedings of the Interantional Conference onPattern Recognition ICPR98, Brisbane, Australia, 1998, pp. 344352.108 T.M. Lehmann, C. Gonner, K. Spitzer, Addendum Bsplineinterpolation in medical image processing, IEEE Transaction onMedical Imaging 20 2001 660665.109 T.M. Lehmann, C. Gonner, K. Spitzer, Survey interpolationmethods in medical image processing, IEEE Transactions onMedical Imaging 18 1999 10491075.110 H. Lester, S.R. Arridge, Summarising fluid registration by thinplatespline warps with many landmarks, In Proceedings of Medical ImageUnderstanding and Analysis MIUA97, Oxford, 1997.111 H. Lester, S.R. Arridge, A survey of hierarchical nonlinear medicalimage registration, Pattern Recognition 32 1999 129149.112 H. Li, B.S. Manjunath, S.K. Mitra, A contourbased approach tomultisensor image registration, IEEE Transactions on ImageProcessing 4 1995 320334.113 S.Z. Li, Matching Invariant to translations, rotations and scalechanges, Pattern Recognition 25 1992 583594.114 S.Z. Li, J. Kittler, M. Petrou, Matching and recognition of roadnetworks from aerial images, Proceedings of the Second EuropeanConference on Computer Vision ECCV92, St Margherita, Italy,1992, pp. 857861.115 B. Likar, F. Pernus, Automatic extraction of corresponding points forthe registration of medical images, Medical Physics 26 199916781686.116 B. Likar, F. Pernus, A hierarchical approach to elastic registrationbased on mutual information, Image and Vision Computing 192001 3344.117 J.A. Little, D.L.G. Hill, D.J. Hawkes, Deformations incorporatingrigid structures, Computer Vision and Image Understanding 661997 223232.118 J. Liu, B.C. Vemuri, J.L. Marroquin, Local frequency representations for robust multimodal image registration, IEEE Transactionson Medical Imaging 21 2002 462469.119 L. Lucchese, G. Doretto, G.M. Cortelazzo, A frequency domaintechnique for range data registration, IEEE Transactions on PatternAnalysis and Machine Intelligence 24 2002 14681484.120 F. Maes, A. Collignon, D. Vandermeulen, G. Marchal, P. Suetens,Multimodality image registration by maximization of mutualinformation, IEEE Transactions on Medical Imaging 16 1997187198.121 J.B.A. Maintz, P.A. van den Elsen, M.A. Viergever, Comparison ofedgebased and ridgebased registration of CT and MR brain images,Medical Image Analysis 1 1996 151161.122 J.B.A. Maintz, P.A. van den Elsen, M.A. Viergever, Evaluation onridge seeking operators for multimodality medical image matching,IEEE Transactions on Pattern Analysis and Machine Intelligence 181996 353365.123 J.B.A. Maintz, M.A. Viergever, A survey of medical imageregistration, Medical Image Analysis 2 1998 136.124 H. Maitre, Y. Wu, Improving dynamic programming to solve imageregistration, Pattern Recognition 20 1987 443462.125 B.S. Manjunath, C. Shekhar, R. Chellapa, A new approach to imagefeature detection with applications, Pattern Recognition 29 1996627640.126 D. Marr, E. Hildreth, Theory of edge detection, Proceedings of theRoyal Society of London, B 207 1980 187217.127 J. Matas, S. Obdrzalek, O. Chum, Local affine frames for widebaseline stereo, in R. Kasturi, D. Laurendeau, C. Suen Eds., 16thInternational Conference on Pattern Recognition ICPR 2002, vol. 4,2002, pp. 363366.128 G. Medioni, R. Nevatia, Matching images using linear features,IEEE Transactions on Pattern Analysis and Machine Intellingence 61984 675685.129 E.H.W. Meijering, K.J. Zuiderveld, M.A. Viergever, Imagereconstruction by convolution with symmetrical piecewise nthorder polynomial kernels, IEEE Transactions on Image Processing 81999 192201.130 R.S. Mitra, N.N. Murthy, Elastic maximal matching, PatternRecognition 24 1991 747753.131 P. Montesinos, V. Gouet, R. Deriche, D. Pele, Matching coloruncalibrated images using differential invariants, Image and VisionComputing 18 2000 659671.132 S. Moss, E.R. Hancock, Multiple linetemplate matching with EMalgorithm, Pattern Recognition Letters 18 1997 12831292.133 F. Murtagh, A feature based ON2 approach to point patternmatching, Proceedings of the Internatinal Confernce on PatternRecognition ICPR92, Hague, The Netherlands, 1992, pp. 174177.134 S.J. Nelson, M.R. Day, P. Buffone, L.L. Wald, T.F. Budinger, R.Hawkins, W. Dillon, S. Huhn, M. Prados, S. Chang, D.B. Vigneron,Alignment of volume mri and high resolution f18 flurodeoxyglucose pet images for evaluation of patients with brain tumors, Journalof Computed Assisted Tomography 21 1997 183191.135 A. Noble, Finding corners, Image and Vision Computing 6 1988121128.136 H. Ogawa, Labeled point pattern matching by fuzzy relaxation,Pattern Recognition 17 1984 569573.137 N.R. Pal, S.K. Pal, A review on image segmentation techniques,Pattern Recognition 26 1993 12771294.138 J.A. Parker, R.V. Kenyon, D.E. Troxel, Comparison of interpolatingmethods for image resampling, IEEE Transactions on MedicalImaging 2 1983 3139.139 E.I. Parsai, K.M. Ayyangar, R.R. Dobelbower, J.A. Siegel, Clinicalfusion of threedimensional images using bremsstrahlung spect andct, Journal of Nuclear Medicine 38 1997 319324.140 W. Peckar, C. Schnorr, K. Rohr, H.S. Stiehl, Two step parameterfree elastic image registration with prescribed point displacements, Journal of Mathematical Imaging and Vision 10 1999143162.141 T. Peli, An algorithm for recognition and localization of rotated andscaled objects, Proceedings of the IEEE 69 1981 483485.142 G.P. Penney, J. Weese, J.A. Little, P. Desmedt, D.L.G. Hill, D.J.Hawkes, A comparison of similarity measures for use in 2D3Dmedical image registration, IEEE Transactions on Medical Imaging17 1998 586595.B. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000998143 J.P.W. Pluim, J.B.A. Maintz, M.A. Viergever, Mutual informationmatching in multiresolution contexts, Image and Vision Computing19 2001 4552.144 M.J.D. Powell, Tabulation of thin plate splines on a very fine twodimensional grid, Numerical Analysis Report of University ofCambridge, DAMTP1992NA2, Cambridge, UK, 1992.145 W.K. Pratt, Correlation techniques of image registration, IEEETransactions on Aerospace and Electronic Systems 10 1974353358.146 W.K. Pratt, Digital Image Processing, 2nd ed., Wiley, New York,1991.147 K.E. Price, Relaxation matching techniquesa comparison, IEEETransactions on Pattern Analysis and Machine Intellingence 71985 617623.148 S. Ranade, A. Rosenfeld, Point pattern matching by relaxation,Pattern Recognition 12 1980 269275.149 A. Rangarajan, H. Chui, J.S. Duncan, Rigid point feature registrationusing mutual information, Medical Image Analysis 4 1999 117.150 B.S. Reddy, B.N. Chatterji, An FFTbased technique for translation,rotation and scaleinvariant image registration, IEEE Transactionson Image Processing 5 1996 12661271.151 B. Rezaie, M.D. Srinath, Algorithms for fast image registration,IEEE Transactions on Aerospace and Electronic Systems 20 1984716728.152 N. Ritter, R. Owens, J. Cooper, R.H. Eikelboom, P.P. van Saarloos,Registration of stereo and temporal images of the retina, IEEETransactions on Medical Imaging 18 1999 404418.153 A. Roche, G. Malandain, N. Ayache, Unifying maximum likelihoodapproaches in medical image registration, International Journal ofImaging Systems and Technology 11 2000 7180.154 A. Roche, G. Malandain, X. Pennec, N. Ayache, The correlationratio as a new similarity measure for multimodal image registration,Proceedings of the First International Conference on Medical ImageComputing and ComputerAssisted Intervention MICCAI98,Lecture Notes in Computer Science, Cambridge, USA, vol. 1496,1998, pp. 11151124.155 K. Rohr, Localization properties of direct corner detectors, Journal ofMathematical Imaging and Vision 4 1994 139150.156 K. Rohr, LandmarkBased Image Analysis Using Geometric andIntensity Models, Computational Imaging and Vision Series, vol. 21,Kluwer Academic Publishers, Dordrecht, 2001.157 K. Rohr, H.S. Stiehl, T.M. Buzug, J. Weese, M.H. Kuhn, Landmarkbased elastic registration using approximating thinplate splines,IEEE Transactions on Medical Imaging 20 2001 526534.158 K. Rohr, H.S. Stiehl, R. Sprengel, W. Beil, T.M. Buzug, J. Wees,M.H. Kuhn, Point based elastic registration of medical image datausing approximating thinplate splines, Proceedings of the Visualization in Biomedical Computing VBC96, Hamburg, Germany,1996, pp. 297306.159 K. Rohr, H.S. Stiehl, R. Sprengel, W. Beil, T.M. Buzug, J. Weese,M.H. Kuhn, Nonrigid registration of medical images based onanatomical point landmarks and approximating thinplate splines,Proceedings of the Aacheren Workshop Bildverarbeiterung fur dieMedizin, Aachen, Germany, 1996, pp. 4146.160 A. Rosenfeld, G.J. Vanderbrug, Coarsefine template matching,IEEE Transactions on Systems, Man and Cybernetics 7 1977104107.161 M. Roux, Automatic registration of SPOT images and digitizedmaps, Proceedings of the IEEE International Conference on ImageProcessing ICIP96, Lausanne, Switzerland, 1996, pp. 625628.162 D. Rueckert, C. Hayes, C. Studholme, P. Summers, M. Leach, D.J.Hawkes, Nonrigid registration of breast MR images using mutualinformation, Proceedings of the Medical Image Computing andComputerAssisted Intervention MICCAI98, Cambridge, Massachusetts, 1998, pp. 11441152.163 J. Sato, R. Cipolla, Image registration using multiscale texturemoments, Image and Vision Computing 13 1995 341353.164 H.S. Sawhney, R. Kumar, True multiimage alignment and itsapplications to mosaicing and lens distortion correction, IEEETransactions on Pattern Analysis and Machine Intellingece 211999 235243.165 M. Sester, H. Hild, D. Fritsch, Definition of ground control featuresfor image registration using GIS data, Proceedings of theSymposium on Object Recognition and Scene Classification fromMultispectral and Multisensor Pixels, CDROM, Columbus, Ohio,1998, 7 pp.166 R.K. Sharma, M. Pavel, Multisensor image registration, Proceedingsof the Society for Information Display XXVIII 1997 951954.167 C. Shekhar, V. Govindu, R. Chellapa, Multisensor image registrationby feature consensus, Pattern Recognition 32 1999 3952.168 D. Shin, J.K. Pollard, J.P. Muller, Accurate geometric correction ofATSR images, IEEE Transactions on Geoscience and RemoteSensing 35 1997 9971006.169 Y. Shinagawa, T.L. Kunii, Unconstrained automatic image matchingusing multiresolutional criticalpoint filters, IEEE Transactions onPattern Analysis and Machine Intelligence 20 1998 9941010.170 A. Simper, Correcting general bandtoband misregistrations,Proceedings of the IEEE International Conference on ImageProcessing ICIP96, Lausanne, Switzerland, 1996, 2, pp. 597600.171 D. Skea, I. Barrodale, R. Kuwahara, R. Poeckert, A control pointmatching algorithm, Pattern Recognition 26 1993 269276.172 S.M. Smith, SUSAN low level image processing, httpwww.fmrib.ox.ac.ukspacestevesusan.173 S.M. Smith, J.M. Brady, SUSANa new approach to low levelimage processing, International Journal of Computer Vision 231997 4578.174 J.P.P. Starink, E. Baker, Finding point correspondence usingsimulated annealing, Pattern Recognition 28 1995 231240.175 G. Stockman, S. Kopstein, S. Benett, Matching images to models forregistration and object detection via clustering, IEEE Transactionson Pattern Analysis and Machine Intelligence 4 1982 229241.176 H.S. Stone, J. le Moigne, M. McGuire, The translation sensitivity ofwaveletbased registration, IEEE Transactions on Pattern Analysisand Machine Intelligence 21 1999 10741081.177 C. Studholme, D.L.G. Hill, D.J. Hawkes, An overlap invariantentropy measure of 3D medical image alignment, Pattern Recognition 32 1999 7186.178 T. Suk, J. Flusser, Vertexbased features for recognition ofprojectively deformed polygons, Pattern Recognition 29 1996361367.179 T. Suk, J. Flusser, Pointbased projective invariants, PatternRecognition 33 2000 251261.180 A. Taza, C.Y. Suen, Description of planar shapes using shapematrices, IEEE Transactions on Systems, Man, and Cybernetics 191989 12811289.181 O. Thepaut, K. Kpalma, J. Ronsin, Automatic registration of ERSand SPOT multisensor images in a data fusion context, ForestEcology and Management 128 2000 93100.182 P. Thevenaz, T. Blu, M. Unser, Image interpolation and resampling,Handbook of Medical Image Processing, Academic Press, NewYork, 2003, in press.183 P. Thevenaz, T. Blu, M. Unser, Interpolation revisited, IEEETransactions on Medical Imaging 19 2000 739758.184 P. Thevenaz, U.E. Ruttimann, M. Unser, A pyramidal approach tosubpixel registration based on intensity, IEEE Transactions on ImageProcessing 7 1998 2741.185 P. Thevenaz, U.E. Ruttimann, M. Unser, Iterative multiscaleregistration without landmarks, Proceedings of the IEEE International Confernece on Image Processing ICIP95, Washington DC,1995, pp. 228231.186 P. Thevenaz, M. Unser, An efficient mutual information optimizerfor multiresolution image registration, Proceedings of the IEEEInternational Conference on Image Processing ICIP98, Chicago, IL,1998, pp. 833837.B. Zitova, J. Flusser  Image and Vision Computing 21 2003 9771000 999187 P. Thevenaz, M. Unser, A pyramid approach to subpixel imagefusion based on mutual information, Proceedings of the IEEEInterantional Conference on Image Processing ICIP96, Lausanne,Switzerland, 1996, pp. 265268.188 P. Thevenaz, M. Unser, Spline pyramids for intermodal imageregistration using mutual information, Proceedings of SPIE WaveletApplications in Signal and Image Processing, San Diego, CA, 1997,pp. 236247.189 J.P. Thirion, Image matching as a diffusion process an analogy withMaxwells demons, Medical Image Analysis 2 1998 243260.190 J. Ton, A.K. Jain, Registering landsat images by point matching,IEEE Transactions on Geoscience and Remote Sensing 27 1989642651.191 K. Toraichi, S. Yang, R. Mori, Twodimensional spline interpolationfor image reconstruction, Pattern Recognition 21 1988 275284.192 M. Trajkovic, M. Hedley, Fast corner detection, Image and VisionComputing 16 1998 7587.193 R. Turcajova, J. Kautsky, A hierarchical multiresolution techniquefor image registration, Proceedings of SPIE Mathematical ImagingWavelet Applications in Signal and Image Processing, Colorado,1996.194 T. Tuytelaars, L.V. Gool, Matching widely separated views based onaffinely invariant neighbourhoods, International Journal of ComputerVision 2003 to appear.195 P.A. van den Elsen, E.J.D. Pol, M.A. Viergever, Medical imagematchinga review with classification, IEEE Engineering inMedicine and Biology 12 1993 2639.196 P. van Wie, M. Stein, A landsat digital image rectification system,IEEE Transactions on Geoscience Electronics 15 1977 130136.197 G.J. Vanderbrug, A. Rosenfeld, Two stage template matching, IEEETransactions on Computers 26 1977 384393.198 A.S. Vasileisky, B. Zhukov, M. Berger, Automated image coregistration based on linear feature recognition, Proceedings of theSecond Conference Fusion of Earth Data, Sophia Antipolis, France,1998, pp. 5966.199 B.C. Vemuri, J. Ye, Y. Chen, C.M. Leonard, Image registration vialevelset motion Applications to atlasbased segmentation, MedicalImage Analysis 7 2003 120.200 A.D. Ventura, A. Rampini, R. Schettini, Image registration byrecognition of corresponding structures, IEEE Transactions onGeoscience and Remote Sensing 28 1990 305314.201 P. Viola, W.M. Wells, Alignment by maximization of mutualinformation, International Journal of Computer Vision 24 1997137154.202 N. Vujovic, D. Brzakovic, Establishing the correspondence betweencontrol points in pairs of mammographic images, IEEE Transactionson Image Processing 6 1997 13881399.203 G. Wahba, Spline Models for Observational Data, SIAM, Philadelphia, 1990.204 C.Y. Wang, H. Sun, S. Yadas, A. Rosenfeld, Some experiments inrelaxation image matching using corner features, Pattern Recognition 16 1983 167182.205 W.H. Wang, Y.C. Chen, Image registration by control points pairingusing the invariant properties of line segments, Pattern RecognitionLetters 18 1997 269281.206 J. West, J.M. Fitzpatrik, M.Y. Wang, B.M. Dawant Jr., C.R. Maurer,R.M. Kessler, R.J. Maciunas, Retrospective intermodalityregistration techniques for images of the head surfacebased versusvolumebased, IEEE Transactions on Medical Imaging 18 1999144150.207 J. West, et al., Comparison and evaluation of retrospectiveintermodality brain image registration techniques, Journal ofComputer Assisted Tomography 21 1997 554566.208 A.P. Whichello, H. Yan, Document image mosaicing, Proceedingsof the International Conference on Pattern Recognition ICPR98,Brisbane, Australia, 1998, pp. 10811084.209 R. Wiemker, K. Rohr, L. Binder, R. Sprengel, H.S. Stiehl,Application of elastic registration to imaginery from airbornescanners, International Archives for Photogrammetry and RemoteSensing XXXIB4 1996 949954.210 G. Wolberg, S. Zokai, Robust image registration using logpolartransform, Proceedings of the IEEE International Conference onImage Processing, Canada, September 2000.211 G. Wolberg, S. Zokai, Image registration for perspective deformation recovery, SPIE Conference on Automatic Target RecognitionX, Orlando, Florida, USA, April 2000, p. 12.212 G. Wollny, F. Kruggel, Computational cost of nonrigid registrationalgorithms based on fluid dynamics, IEEE Transactions on MedicalImaging 21 2002 946952.213 R.Y. Wong, E.L. Hall, Scene matching with invariant moments,Computer Graphics and Image Processing 8 1978 1624.214 R.Y. Wong, E.L. Hall, Sequential hierarchical scene matching, IEEETransactions on Computers 27 1978 359366.215 R.P. Woods, S.T. Grafton, C.J. Holmes, S.R. Cherry, J.C. Mazziotta,Automated image registration I. General methods and intrasubject,intramodality validation, Journal of Computer Assisted Tomography22 1998 141154.216 Z. Yang, F.S. Cohen, Image registration and object recognition usingaffine invariants and convex hulls, IEEE Transactions on ImageProcessing 8 1999 934946.217 Y. You, M. Kaveh, A regularization approach to joint bluridentification and image restoration, IEEE Transactions on ImageProcessing 5 1996 416428.218 F. Zana, J.C. Klein, A multimodal registration algorithm of eyefundus images using vessels detection and Hough transform, IEEETransactions on Medical Imaging 18 1999 419428.219 Q. Zheng, R. Chellapa, A computational vision approach to imageregistration, IEEE Transactions on Image Processing 2 1993311325.220 Z. Zheng, H. Wang, E.K. Teoh, Analysis of gray level cornerdetection, Pattern Recognition Letters 20 1999 149162.221 Y.M. Zhu, Volume image registration by crossentropy optimization,IEEE Transactions on Medical Imaging 21 2002 174180.222 D. Ziou, S. Tabbone, Edge detection techniquesan overview,httpciteseer.nj.nec.comziou97edge.html, 1997.223 B. Zitova, J. Flusser, F. Sroubek, Application of image processingfor the conservation of the medieval mosaic, Proceedings of theIEEE International Conference on Image Processing ICIP02,Rochester, MI, 2002, pp. 993996.224 B. Zitova, J. Kautsky, G. Peters, J. Flusser, Robust detection ofsignificant points in multiframe images, Pattern Recognition Letters20 1999 199206.B. Zitova, J. Flusser  Image and Vision Computing 21 2003 97710001000
