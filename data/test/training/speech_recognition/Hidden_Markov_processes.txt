1518 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002Hidden Markov ProcessesYariv Ephraim, Fellow, IEEE, and Neri Merhav, Fellow, IEEEInvited PaperAbstractAn overview of statistical and informationtheoreticaspects of hidden Markov processes HMPs is presented. AnHMP is a discretetime finitestate homogeneous Markov chainobserved through a discretetime memoryless invariant channel.In recent years, the work of Baum and Petrie on finitestatefinitealphabet HMPs was expanded to HMPs with finite as wellas continuous state spaces and a general alphabet. In particular,statistical properties and ergodic theorems for relative entropydensities of HMPs were developed. Consistency and asymptoticnormality of the maximumlikelihood ML parameter estimatorwere proved under some mild conditions. Similar results were established for switching autoregressive processes. These processesgeneralize HMPs. New algorithms were developed for estimatingthe state, parameter, and order of an HMP, for universal codingand classification of HMPs, and for universal decoding of hiddenMarkov channels. These and other related topics are reviewed inthis paper.Index TermsBaumPetrie algorithm, entropy ergodic theorems, finitestate channels, hidden Markov models, identifiability,Kalman filter, maximumlikelihood ML estimation, order estimation, recursive parameter estimation, switching autoregressiveprocesses, Ziv inequality.I. INTRODUCTIONAhidden Markov process HMP is a discretetime finitestate homogeneous Markov chain observed through a discretetime memoryless invariant channel. The channel is characterized by a finite set of transition densities indexed by thestates of the Markov chain. These densities may be members ofany parametric family such as Gaussian, Poisson, etc. The initialdistribution of the Markov chain, the transition matrix, and thedensities of the channel depend on some parameter that characterizes the HMP. The process is said to be a finitealphabetHMP if the output alphabet of the channel is finite. It is said tobe a general HMP when the output alphabet of the channel isnot necessarily finite.HMPs are more commonly referred to as hidden Markovmodels. The term HMP was chosen since it emphasizes theprocess itself rather than its use as a model. HMPs comprisea rich family of parametric processes that was found usefulManuscript received July 20, 2000 revised December 30, 2001.Y. Ephraim is with the Department of Electrical and Computer Engineering,George Mason University, Fairfax, VA 22030 USA email yephraimgmu.edu.N. Merhav is with the Department of Electrical Engineering, TechnionIsrael Institute of Technology, Haifa 32000, Israel email merhavee.technion.ac.il.Communicated by S. Shamai, Guest EditorPublisher Item Identifier S 0018944802040142.in many applications. HMPs are closely related to mixtureprocesses, switching autoregressive processes, dynamical systems in the sense of control theory, Markovmodulated Poissonprocesses, composite sources, and unifilar sources. HMPs arefairly general processes that are amenable to mathematicalanalysis.HMPs have been widely studied in statistics. An HMP isviewed as a discretetime bivariate parametric process. The underlying process is a finitestate homogeneous Markov chain.This process is not observable and is often referred to as theregime. The second process is a sequence of conditionally independent random variables given the Markov chain. At any giventime, the distribution of each random variable depends on theMarkov chain only through its value at that time. This distribution is timeinvariant and it may be a member of any parametricfamily. The sequence of conditionally independent random variables is often referred to as the observation sequence.HMPs are commonly encountered in information theory.Markov chains are common models for information sourceswith memory, and memoryless invariant channels are amongthe simplest models for communication channels. The hookupof Markov chains with memoryless channels yields a familyof processes that are far more complex than the Markov chainsources. For example, there is no closedform singleletterexpression for the entropy rate of an HMP. Also, the method oftypes does not apply to HMPs unless they are unifilar sources.The state sequence of a unifilar source depends deterministically on the observation sequence and the initial state.In recent years, the theory of HMPs has been substantiallyadvanced and a wealth of new results was developed. In addition, numerous new applications have emerged. In the statistical literature, the main focus has been on HMPs with finiteas well as continuousstate spaces and a general alphabet. Identifiability of an HMP, consistency and asymptotic normality ofthe maximum likelihood ML parameter estimator, as well asalgorithms for estimating the state, parameter, number of states,and the Fisher information matrix, were developed. The numberof states of an HMP is called the order. In information theory,the main focus has been on finitestate finitealphabet HMPswhere order estimation, universal coding and classification ofHMPs, and universal decoding of finitestate channels, whichare hidden Markov channels, were studied.Our goal is to present an overview of HMPs from the statistical and informationtheoretic viewpoints. Our primary focusis on the theory of HMPs as it evolved in recent years. We alsoprovide a brief survey of many applications of HMPs. Some001894480217.00  2002 IEEEEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1519sections of the paper require some background in probabilitytheory. To facilitate reading, we have collected preliminary measuretheoretic material in one section. This manuscript is divided into fifteen sections. The plan for each of the remainingsections is outlined below.II. A Brief History Provides a brief history of HMPs anda review of the main theoretical results developed inrecent years.III. Preliminaries Sets up the notation and provides somepreliminary background material.IV. Statistical Properties Defines HMPs and their relations to mixture processes, switching autoregressiveprocesses, dynamical systems, MarkovmodulatedPoisson processes, composite sources, and unifilarsources. Also defines hidden Markov channels.Summarizes statistical properties of HMPs such asstationary, mixing, and ergodic properties. Theseproperties are inherited from the Markov chains.Provides ergodic theorems for the sample entropy andrelative entropy densities of HMPs.V. State Estimation Presents numerically stable andcomputationally efficient recursions for prediction,filtering, and fixedinterval smoothing of the state sequence of the HMP. The recursions coincide with theKalman filter and smoother, respectively, under linearGaussian assumptions. The recursions are naturallystable, and they differ from those traditionally usedin signal processing and communication applicationssuch as automatic speech recognition and decoding ofturbo codes, respectively.VI. ML Parameter Estimation Deals with several aspectsof ML parameter estimation. Provides conditions foridentifiability of an HMP. States theorems for consistency and asymptotic normality of the ML parameterestimator of an HMP with a finite as well as continuousstate space and a general alphabet. Provides similar theorems for switching autoregressive processes.Outlines the principles of the Baum algorithm for localML parameter estimation, and Louiss formula for estimating the Fisher information matrix. States the Zivinequality which provides a tight upper bound on themaximum value of the likelihood function for any finitealphabet HMP.VII. Joint State and Parameter Estimation Focuses on jointestimation of the state sequence and parameter of anHMP. Presents the BaumViterbi algorithm and its relations to the Baum algorithm and to the generalizedLloyd algorithm for designing vector quantizers. Thealgorithm is useful when a sufficiently long vector ofobservations is generated from each state. Otherwise, itdoes not provide a consistent estimate of either the parameter or the state sequence. Describes a noniterativealgorithm for global maximization of the joint likelihood function of states and observations of a leftrightHMP. Discusses Bayesian estimation of the state sequence and parameter, and asymptotic properties of theestimator.VIII. Order Estimation Presents consistent estimators for afinitealphabet HMP, and an estimator which does notunderestimate the order of a general HMP.IX. Dynamical System Approach The HMP is seen as adynamical system in the sense of control theory, andits parameter is estimated using the expectationmaximization algorithm. Conditional mean estimators ofseveral statistics of the HMP, required by the expectationmaximization algorithm, are developed using thegeneralized Bayes rule. The approach is demonstratedfor HMPs with Gaussian densities. The approach isparticularly useful for continuoustime HMPs but thisextension is not reviewed here.X. Recursive Parameter Estimation Describes algorithms for recursive estimation of the parameter of anHMP. A consistent asymptotically normal estimator isprovided.XI. Signal Classification Deals with several classificationproblems involving HMPs including universal classification.XII. Signal Estimation The HMP is seen as a desired signaland its estimation from a noisy signal is discussed.XIII. Hidden Markov Channels Reviews some properties offinitestate channels such as capacity and the channelcoding theorem. Presents the LapidothZiv asymptotically optimal universal decoding algorithm for finitestate channels.XIV. Selected Applications Briefly describes selectedapplications in communications, information theory,and signal processing. Also presents special forms ofHMPs and nonML parameter estimation procedureswhich were found useful in practice.XV. Concluding Remarks.II. A BRIEF HISTORYHMPs were introduced in full generality in 1966 by Baumand Petrie 25 who referred to them as probabilistic functions ofMarkov chains. Indeed, the observation sequence depends probabilistically on the Markov chain. During 19661969, Baumand Petrie studied statistical properties of stationary ergodic finitestate finitealphabet HMPs. They developed an ergodic theorem for almostsure convergence of the relative entropy density of one HMP with respect to another. In addition, they provedconsistency and asymptotic normality of the ML parameter estimator 25, 251. In 1969, Petrie 251 provided sufficient conditions for identifiability of an HMP and relaxed some of theassumptions in 25. In 1970, Baum, Petrie, Soules, and Weiss28, 29 developed forwardbackward recursions for calculating the conditional probability of a state given an observationsequence from a general HMP. They also developed a compu1520 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002tationally efficient iterative procedure for ML estimation of theparameter of a general HMP using the forwardbackward recursions. This procedure is the wellknown expectationmaximization EM algorithm of Dempster, Laird, and Rubin 80 appliedto HMPs. Local convergence of the algorithm was establishedin 28, 29. The algorithm is often referred to as the Baum algorithm, or the BaumPetrie algorithm, or the BaumWelch algorithm in honor of Lloyd Welch 311. Similar forwardbackward recursions were developed earlier by Chang and Hancock56 in their work on optimal decoding of intersymbol interference channels.Prior to the introduction of probabilistic functions of Markovchains, deterministic functions of Markov chains were extensively studied. They are often referred to as aggregatedMarkov processes in the statistical literature since a functionmay collapse several states of the Markov chain onto a singleletter. Deterministic and probabilistic functions of finitestateMarkov chains are related when the alphabet of the HMP isfinite. Any deterministic function of a Markov chain can bedescribed as a trivial finitealphabet HMP, and any finitealphabet HMP can be described as a deterministic functionof Markov chain with an augmented state space 25, 251,116. Deterministic functions of Markov chains were usedby Shannon in 1948 290 as models for information sources.Ash 14, p. 185 refers to them as Markov sources but theterm has more often been associated with unifilar sourcesintroduced by Gallager 133, Sec. 3.6. Shannon developed thefundamental ergodic theorem for convergence in probability ofthe sample entropy of a stationary ergodic Markov chain 290.The theorem was proved for stationary ergodic finitealphabetprocesses, for and almost sure convergence, by McMillanand Breiman, respectively. It is commonly referred to as theShannonMcMillanBreiman theorem or as the aymptoticequipartition property 152, Ch. 3. The theorem applies toany stationary ergodic finitealphabet HMP. Deterministicfunctions of Markov chains were also intensively studied in thestatistical literature, notably by Blackwell 41, Blackwell andKoopmans 42, Burke and Rosenblatt 52, Gilbert 136, Fox125, Dharmadhikari 8386, Heller 160, and Carlyle 54,who investigated identifiability and conditions for deterministicfunctions of Markov chains to be Markov chains.HMPs comprise a rich family of parametric random processes. In the context of information theory, we have alreadyseen that an HMP is a Markov chain observed through amemoryless channel. More generally, consider a finitestatechannel 133, Sec. 4.6. The transition density of the channeldepends on a nonobservable Markov chain. This channel issometimes called a hidden Markov channel. An HMP observedthrough a finitestate channel is an HMP with an augmentedstate space. The GilbertElliott channel is an important example of a finitestate channel 137, 97, 14, 243, 204.This channel introduces a binary additive hidden Markovnoise process which is independent of the input process. TheGilbertElliott channel is a good model for fading channels.Finitestate channels are also known as stochastic sequentialmachines SSMs or probabilistic automata 250. A subclassof SSMs is formed by partially observable Markov decisionprocesses 242.HMPs are also related to a number of random processes commonly encountered in engineering, statistics, and econometrics.We first point out the obvious relation to mixture processes212, 109, 232, 266, 301. Each observation of an HMPhas a mixture distribution, but contrary to mixture processes,HMP observations need not be statistically independent. HMPsare special cases of switching autoregressive processes withMarkov regimes 156, Ch. 22. These are autoregressive processes whose dynamics at each time instant depend on the stateof a Markov chain at that time. When the autoregressive orderis zero, the switching autoregressive process degenerates to anHMP. HMPs may be cast as dynamical systems in the senseof control theory. When the state space is finite or countablyinfinite, each state is represented by a unit vector in a Euclideanspace. Another relation is to Markovmodulated Poissonprocesses 117, 273, 276. These are Poisson processeswhose rate is controlled by a nonobservable continuoustimeMarkov chain. A Markovmodulated Poisson process may beviewed as a Markov renewal process and as an HMP. In bothcases, a discretetime Markov chain is defined by samplingthe continuoustime chain at the Poisson event epochs, and theobservation sequence is given by the interevent time durations.One of the earliest applications of HMPs was to automaticcharacter recognition. Raviv 265 studied the problem in 1967at the IBM T. J. Watson Research Center. The characters of thelanguage were represented by states of the Markov chain andthe measurements constituted the observation process. Recognition in the minimum character error rate sense was performed.For that purpose, Raviv developed a new recursion for the conditional probability of a state given the observations.In the mid1970s, another major application of HMPs wastaking place at the IBM T. J. Watson Research Center. Jelinek172, Baker 21, Jelinek, Bahl, and Mercer 171, Bahl andJelinek 18, along with their coworkers, developed a phoneticspeech recognition system that relies on hidden Markov modeling of speech signals. The model for each word in the vocabulary was composed of individual phonetic models which weredesigned using the Baum algorithm. Linguistic decoding of anacoustic utterance was performed using the Viterbi algorithm308, 124, 285 or the Stack graphsearch algorithm of Jelinek 170. In the early 1980s, applications of HMPs to automatic speech recognition were further studied primarily by Ferguson and his colleagues at the Institute for Defense Analysis115, 256, and by Rabiner and his group at ATT Bell Laboratories 262. These studies popularized the theory of HMPswhich have since become widespread in many applications. InFerguson 115, probabilistic functions of Markov chains wereprobably first referred to as hidden Markov models.In recent years, HMPs have been widely studied by statisticians and information theorists. Significant progress hasbeen made in the theory of HMPs where the work of Baumand Petrie on finitestate finitealphabet HMPs was expandedto HMPs with finite as well as continuousstate spaces anda general alphabet. In particular, new ergodic theorems forrelative entropy densities of HMPs were developed by Leroux214, Finesso 116, Le Gland and Mevel 210, and Doucand Matias 90. Consistency and asymptotic normality ofthe ML estimator of the parameter of an HMP was provedEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1521by Leroux 214, Bickel, Ritov, and Rydn 36, Le Glandand Mevel 210, Jensen and Petersen 174, and Douc andMatias 90. The ergodic theorems and asymptotic optimalityof the ML parameter estimator were also proved for switchingautoregressive processes with Markov regime by Francq andRoussignol 127, Krishnamurthy and Rydn 198, and Douc,Moulines, and Rydn 91. Similar results were developed fora Markovmodulated Poisson process by Rydn 273, 276.Exponential forgetting and geometric ergodicity in HMPs werestudied by Le Gland and Mevel 210 and Douc and Matias90. A complete solution to identifiability of deterministicfunctions of nonstationary Markov chains was given by Ito,Amari, and Kobayashi 167. Conditions for identifiabilityof a general HMP were developed by Leroux 214 andRydn 274, 277. Conditions for identifiability of a Markovmodulated Poisson process were given by Rydn 278. Newstable recursions for prediction, filtering, and fixedintervalsmoothing of the state sequence from an observation sequencewere developed by Lindgren 219 and Askar and Derin15. These recursions provide conditional mean filters andsmoothers for Markov chains observed through channels thatare not necessarily Gaussian 203.In addition to expanding the work of Baum and Petrie, otherapproaches to HMPs were developed in recent years. A comprehensive dynamical system approach to general HMPs wasdeveloped by Elliott, Aggoun, and Moore 99. In particular, finitedimensional recursions for conditional mean estimators ofstatistics of a general HMP were developed, and used in ML estimation of the parameter of the process. HMPs with discreteas well as continuoustime state and observation processes, thathave finite or continuous alphabet, were studied in 99. Informationtheoretic approaches for strongly consistent order estimation of a finitealphabet HMP were developed by Finesso116, Kieffer 187, and Liu and Narayan 223. An order estimator for a general HMP that does not underestimate the trueorder was developed by Rydn 277. A consistent asymptotically normal recursive estimator for the parameter of a general HMP was developed by Rydn 279. A Gibbs samplingBayesian approach for estimating the parameter of a generalHMP was developed by Robert, Celeux, and Diebold 269.In communications and information theory, several aspectsof HMPs were studied in recent years. Minimum symbolerrorrate decoding of convolutional and linear codes usingthe forwardbackward recursions of Chang and Hancock 56was proposed by Bahl, Cocke, Jelinek, and Raviv 17. Thealgorithm has since been referred to as the BCJR algorithm,and a stabilized version of the recursions is commonly usedin decoding turbo codes 32, 33. Turbo codes use severalconcatenated convolutional codes and a feedback mechanismthat allow iterative reduction of the bit error rate. They almostachieve the Shannon capacity in communication over memoryless Gaussian channels. Properties of composite sources,which are generalizations of HMPs, were studied by Fontana119, and Fontana, Gray, and Kieffer 120. The LempelZivuniversal data compression algorithm introduced in 1978 326is applicable to universal coding of finitealphabet HMPs. Thisalgorithm asymptotically outperforms any finitestate codingscheme in compressing sequences from any source, not necessarily an HMP. Largedeviations properties of the LempelZivalgorithm for HMPs were developed by Merhav 236. Significant progress in universal classification of Markov chainsof any order using empirically observed sequences was madeby Ziv 328, Gutman 155, and Zeitouni, Ziv, and Merhav325. Universal classification of HMPs using empiricallyobserved training sequences was developed by Merhav 235,Merhav and Ephraim 238, and Kieffer 187. A universaldecoding algorithm for finitestate channels was developedby Ziv 327, and Lapidoth and Ziv 204. An algorithm fordecoding unknown intersymbol interference channels using theBaum algorithm was developed by Kaleh and Vallet 179.Along with the advances in the theory of HMPs, numerousnew applications of HMPs have emerged in recent years in areassuch as neurophysiology, biology, economics, control, spectralestimation, radar, sonar and image signal processing, fault detection, computer vision, robotics, and metrology.III. PRELIMINARIESIn this section, we provide some preliminary background material. We also describe the notation that we use throughout themanuscript. Some additional notation will be introduced in Section IVA where the specifics of the HMP are discussed.A. General DefinitionsAll random variables in a given discussion are defined on acommon probability space . We use capital letters todenote random variables, lower case letters to denote realizations of random variables, and script letters to denote sets withinwhich the random variables take values. For example, a randomvariable takes values in . We write to denote theprobability of an event . We also write todenote the probability of the event  .A random variable defined on the underlying probabilityspace induces a probability space . The randomvariable takes values in the sample space . The fielddenotes the Borel field of open subsets of with respect toa given metric. The probability measure denotes the distribution of . Usually is the real line or a subset of the realline. The probability space is referred to as the associated probability space of 152, p. 11. We shall usuallywork with this probability space rather than with the underlyingprobability space. The sample space may also be referred toas the alphabet of and members of may be referred to asletters of the alphabet. We assume that all distributions are absolutely continuous with respect to some finite measure, say, and hence possess densities or RadonNikodym derivatives38, Theorem 32.2. We denote absolute continuity of withrespect to by . We denote the density of withrespect to by . We shall not stress the role of in the notation of the density and use instead of . When thedominating measure is the Lebesgue measure we may refer tothe density as the probability density function pdf. When thedominating measure is the counting measure we may use theterm probability mass function pmf instead of density. Thesetwo dominating measures are of particular interest in applications of HMPs.1522 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002A discretetime random process, say , is denoted bywhere is the index set or a subset of all integers.For onesided random processes, is usually the set of allpositive integers. In some discussions, is more naturallychosen to be the set of all nonnegative integers. For twosidedrandom processes, is the set of all integers. When the indexset is clear from the context, we use the simpler notation of. Assume that for all . The random processis defined on the underlying probability space andhas an associated measurable product space . Weare particularly interested in a random process defined bya distribution on which is a member of a givenparametric family. Let denote the parameter of theprocess distribution where is the parameter set. Usuallywhere is a dimensional Euclidean space.Let denote the parametric distribution of the process. Theassociated sequence probability space of the random process is. We denote by the true parameter usedto generate a given realization of the process.A sequence of random variables of the process,, , is denoted by . A realizationof is denoted by . Most commonly, we will consider asequence of random variables, , which, for simplicity, wedenote by . Let denote the dimensional distributionof induced by . For each , the distribution isassumed absolutely continuous with respect to some finitemeasure and its density with respect to that measure isdenoted by . The explicit dependency of this densityon may be suppressed when notation may be simplified. Theexpected value of a measurable function with respect tothe probability measure is denoted by . Ofparticular interest is the expected value of withrespect to given byThe usual notation for conditional probabilities and densitiesis adopted here. For example, the density of given isdenoted by .In some sections of the paper we report results that are applicable to standard measurable spaces . The definition and properties of standard spaces can be found in 151,Ch. 2, 152, p. 12. Standard spaces include discrete spaces, thereal line, Euclidean vector spaces, Polish spaces which are complete separable metric spaces, among other examples. Standardspaces form a general class of measurable spaces for which theKolmogorov extension theorem holds, regular conditional probability measure exist, and the ergodic decomposition theoremholds 152, p. 12.We shall also make the following conventions. We say that astochastic matrix satisfies if all of its entries are largerthan . Let and be two stochastic matrices of possibly different order. Suppose that . We say that ifboth and . The transpose of a vector, say , is denoted by . The gradient and Hessian of a function withrespect to are denoted by and , respectively.All logarithms in a given discussion are taken to the same arbitrarily chosen base. The most common choices are the naturalbase and the base .B. EntropyConsider a random process with parametricdistribution , . Let be the induced dimensional density of the process with respect to whereis some finite measure. The sample entropy is definedfor finitealphabet processes. Suppose is the countingmeasure. Then, the sample entropy of is defined as152, p. 58. The relative entropy densityis defined for processes with finite as well as continuousalphabet. Suppose is any finite measure which couldpossibly be the Lebesgue measure. The relative entropy densityof is defined as 152, p. 150. We shalluse this term for as well, where may bedifferent from the true parameter . These quantities havewelldefined limits for HMPs when . The limits andconditions for their existence are given in Section IVD.C. Martingale Difference SequenceLet be a random variable on the probability space, and let be a sub field of . The conditionalmean exists if 154, p. 348. Letdenote a sequence of sub fields of .The sequence is called a filtration if for all . Letdenote a random process on the probabilityspace. The process is said to be adapted to the filtration ifis measurable for all 154, p. 473. For example, ifdenotes the smallest field generated by thenis a filtration and is adapted to . Suppose is a filtrationand is adapted to . The pairis called a martingale if for all , , and154, p. 474. Suppose is a martingale. The sequence , where ,is a called a martingale difference sequence. In particular,is measurable, , and for all154, p. 476. The class of zeromean independent processesis a subsest of the class of martingale difference sequences, andthe class of martingale difference sequences is a subset of theclass of zeromean noncorrelated processes when secondordermoments exist 288. Under these conditions, a martingaledifference sequence comprises noncorrelated random variableswhich may also be statistically independent. A martingale difference sequence enjoys a central limit theorem 38, Theorem35.12.D. Ergodicity and Asymptotically Mean StationarityConsider a random process with associated sequence probability space . Assume that this is a onesidedprocess with index set . Letdenote a member of . Define the leftshift transformation by . The measureis called stationary if for allwhere  . Stationary measures correspond to stationary random processes 154, p. 398. An eventEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1523is called invariant if or when ifand only if . The stationary measure is called ergodic if each invariant event has probability either zero or one,i.e., or for all invariant events 154,p. 398. Define . The randomprocess is called asymptotically mean stationary AMS withrespect to the leftshift if the limit of the Cesro mean3.1exists for all 152, p. 16. The limit is a stationaryprobability measure on . It is called the stationarymean of 152, p. 16. The stationary mean asymptotically dominates in the sense that implies151, Corollary 6.3.2. Conversely, ifis asymptotically dominated by a stationary measure thenis AMS 148, Theorem 2. These properties demonstrateintuitive aspects of AMS processes gained by consideringevents determinable by samples of the process in the distantfuture. Asymptotic mean stationarity is necessary and sufficientfor an ergodic theorem to hold 151, Corollary 7.2.2.Note that the leftshift transformation for onesided processesis not invertible. Some of the results discussed in this paperwere derived for twosided processes. For that case, an invertible onetoone shift transformation can be defined.E. MixingA process with distribution is saidto be mixing if for every set and set, ,3.2where is independent of and and38, p. 363. Thus, and are approximately independent for large . The process is said to be mixing if3.3where is independent of and and37, p. 166. This is a nonsymmetric measure of approximateindependence.F. ChannelsA channel is defined as follows 152, Sec. 9.2. Consideran input probability space and an output measurable space . Assume that the two measurable spacesare standard. A channel is a family of probability measureson such that for every outputevent , is a measurable function of . For everyrectangle , the set function3.4is well defined, and it extends to a probability measure on thejoint inputoutput space which is sometimes called the hookupof the source and channel . Thus, a channel is simply a regular conditional probability 152, p. 5.Let and be the shift transformations on the input sequence space and output sequence space , respectively. Achannel is said to be stationary with respect to and , orsimply stationary if the shifts are clear from the context, if 152,p. 1843.5Intuitively, a rightshift of an output event yields the same probability as a leftshift of an input event. Two shifts are requiredsince in general and may not exist. If the shiftsare invertible, as for twosided processes, then the definition isequivalent to3.6Thus, shifting the input sequence and output sequence in thesame direction does not change the probability. In that case, asingle shift may be used for both input and output sequences.A channel is said to be output strongly mixing, or asymptotically output memoryless, if for all output rectangles andand all input sequences 152, p. 1963.7More generally, the channel is said to be output weakly mixingif3.8Of particular interest for our discussion are memoryless invariant channels. Suppose that is a probability measureon for all and that is a measurable functionof for fixed . Let denote a sequence of output events.The channel is said to be memoryless if3.9for any finite index set 152, p. 193. The channelis said to be invariant if is independent of . Whendensities exist, the channel is defined by its transition density orby the dimensional conditional density for all finite. Memoryless invariant channels satisfyand is timeinvariant, i.e., for any and ,the probability of given is the same for all .IV. STATISTICAL PROPERTIESIn this section, we define HMPs and discuss their relationsto mixture processes, switching autoregressive processes, dynamical systems, Markovmodulated Poisson processes, com1524 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002Fig. 1. An HMP.posite sources, deterministic functions of Markov chains, andunifilar sources. We state conditions for HMPs to be stationary,ergodic, and mixing processes. We provide ergodic theoremsfor almostsure convergence of the sample entropy and relativeentropy densities of stationaryergodic general HMPs. Similarergodic theorems for switching autoregressive processes withfinite and continuous state spaces are also reviewed.A. Definitions and StructureLet denote a discretetime Markov chain thattakes values in a finite set called the state space. Let denote the number of states. We assume without loss of generalitythat . Let denote a value that cantake. Let denote the probability that the initialstate is . Let be a vector representing the initial distribution. The Markov chain is always assumed homogeneous unless stated otherwise. Letdenote the transition probability. Let denote thetransition matrix. Consider a discretetime channelwith input and output . For each ,takes values in an observation space . The nature of willbe discussed shortly. Let denote a value that cantake. Assume that the channel is memoryless and invariant. Fora given , let , , denote a transition density of thechannel with respect to some finite measure . Of particularinterest are the Lebesgue and counting measures. The countingmeasure is denoted by . The channel is characterized by a setof transition densities . We shallrefer to as an observation conditional density 210.In information theory, an HMP is viewed as a discretetimefinitestate homogeneous Markov chain observed through a discretetime memoryless invariant channel as described in Fig. 1.In the statistical literature, see, e.g., 36, an HMP is viewed as adiscretetime bivariate random process with Markovregime and conditionally independent random variables. The distribution of is timeinvariant and it depends ononly through .The dimensional density of with respect tocan be written as4.1where4.2The convention for all is often convenient.The dimensional density of with respect to is given by4.3This function is often referred to as the likelihood function ofthe HMP. Note that the saummation in 4.3 is over productterms.The likelihood function may also be expressed in an alternative useful form in terms of and . It is easy tocheck, see, e.g., Ott 248, Lindgren 219, and Devijver 81,that4.4We refer to as the predictive density of given90. Thus, properties of the likelihood function of the HMP aredetermined by the predictive density sequence and by the observation conditional densities. These properties will be discussedin Section IVC3. A computationally efficient recursion for calculating is provided in 4.30.It follows from 4.4 that each observation of the HMP has amixture densityIf the Markov chain is stationary, then forall , and the observations are identically distributed withmixture density given by4.5Conditions for stationarity of the Markov chain are given in Section IVC. The observations are generally dependent butthey may also be independent. For example, let denotea sequence of independent and identically distributed i.i.d.random variables and define a Markov chain by. Let for some deterministicfunction . The sequence is an HMP with i.i.d.observations. A stationary HMP is thus a sequence of possiblyEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1525dependent identically distributed random variables with a marginal mixture density. Each mixture density is overdispersed relative to any given single density . Leroux 212 referredto HMPs as mixture processes with Markov dependence.It also follows from 4.4 that if the density has zeromean for all , then almost surely4.6Under this condition, is a martingale difference sequence,as pointed out by Francq and Roussignol 126. As such, anHMP is a sequence of noncorrelated random variables that mayalso be statistically independent. This implies that the observations of an HMP are not useful in predicting inthe minimum mean square error MMSE sense 288.If the regime of an HMP is i.i.d. instead of Markov, theobservations are necessarily i.i.d. From 4.3 we have4.7An HMP with i.i.d. regime is a mixture process. Mixture processes have been extensively studied and a wealth of results isavailable, see, e.g., 109, 266, 301, 232. The close relation between HMPs and mixture processes is often exploited inproving properties of HMPs using similar properties of mixtureprocesses.When the observation space is finite, the HMP is referredto as a finitealphabet HMP. When is not necessarily finite,the HMP is referred to as a general HMP 36. For a finitealphabet HMP, we assume without loss of generality that. Letdenote the timeinvariant statetoobservation transition probability. Let denote the statetoobservationtransition matrix. The parameter of the channel is denoted by. For a general HMP, is usually a subset of a Euclideanspace for some . Other higher dimensional spaces are alsopossible. The parameter of the observation conditional densityfor state is denoted by for some . The parameter of the channel is denoted by . We shall sometimesemphasize the dependency of the observation conditional density on its parameter. We may write or use the morecustomary notation of .The parameter of the HMP is given by . For astationary Markov chain with a unique stationary distributionthe parameter of the HMP is simply . Conditions for uniqueness of a stationary distribution are givenin Section IVC1. In some applications, the tripletdepends on a parameter in some parameter set and wehave the parametrization . The parameteris a particular case obtained using coordinateprojections, i.e., , , and . Thisis the most common parametrization of the HMP which isreferred to as the usual parametrization. Throughout this paper,is referred to as the parameter of the HMP where in generalit need not represent the usual parametrization.We shall sometimes emphasize the dependency of the dimensional density of the HMP on its parameter by rewriting4.3 as4.8In some discussions, such as in ML parameter estimation, wemust distinguish between the true parameter that was used toproduce a given sequence of observations, say , and any othervalue of the parameter of the HMP. We denote the true parameter by . For the usual parametrization, . Astationary HMP is said to be identifiable if for each suchthat , a.e. for some 274.Note that states may always be permuted without affecting thedistribution of the HMP. This ambiguity can be removed by ordering the states, for example, according to their .Two parameters and in are said to be equivalentif they induce the same stationary law for . We denote thisrelation by . The parameter set can be partitionedinto the equivalence classes of . The equivalence class of aparameter of an identifiable HMP comprises all points inobtained by permutations of the states of the HMP 214, Lemma2.In some applications such as modeling of speech signals173, and representing Markov modulated Poisson processesas HMPs 273, the assumption 4.2 is replaced by4.9Since pairs of states in 4.9 may be renamed as new states in4.2, the two assumptions are equivalent 36, 173. Finitealphabet HMPs that obey 4.9 were referred to as finitestatesources in 236, 325, 330.There are many extensions of the HMP as defined in this section. Some of them will be discussed in the next subsection.Throughout this paper, we refer to the discretetime finitestateprocess with finite or general alphabet defined by 4.1 and 4.2as an HMP or even more specifically as a standard HMP. Thisis not to be confused with an HMP that has standard alphabet.Other forms of HMPs such as HMPs with a countably infinitestate space, a continuous state space, or continuoustime HMPswill be specifically noted.B. ExamplesHMPs appear in many forms. In this subsection we providesome examples to demonstrate the scope of this rich family ofprocesses.1 Gaussian Mixture Processes With Markov DependenceHMPs with multivariate Gaussian observation conditional densities are commonly used in automatic speech recognition applications. Gaussian densities are suitable when modeling is applied to representations of the signal for which a central limittheorem holds 47. This indeed is the case in automatic speechrecognition applications where modeling is applied to vectors of1526 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002spectral or cepstral components of the signal 19, 262, 106.Let denote the dimension of each vector. Parametrization ofeach covariance matrix as a matrix of an autoregressiveprocess of order 149 was studied in 254, 255, 175.HMPs with zeromean Gaussian observation conditional densities also appear in the form of , where is aMarkov chain that takes values , is a sequence of i.i.d. standard Gaussian random variables, andand are statistically independent. This model was thoroughly studied by Francq and Roussignol 126. Another popular form of HMPs with Gaussian observation conditional densities is given by , where is a Markov chainthat takes values , is a sequence of zeromean i.i.d. Gaussian random variables with variance , andand are statistically independent 59, 194, 197.2 Poisson Mixture Processes With Markov DependenceHMPs with Poisson observation conditional densities are usedfor modeling counting processes. Here given is aPoisson random variable with rate . Such HMPs are oftenencountered in biomedical applications, for example, in monitoring epileptic seizure counts 6, 207.3 Switching Processes With Markov Regime A switchingprocess with Markov regime is a random process whosedynamics at any given time depend on the state of a Markovchain at that time. Examples include switching regression 219and switching autoregressive processes 156, Ch. 22, 164. Inthis subsection, we focus on switching autoregressive processesonly. Let denote the process and let denote itsMarkov regime of states. Consider first a switching autoregressive process that is linear in its parameter when the statesequence is given. Assume that all states have the sameautoregressive order . Letdenote the autoregressive parameter for state , where denotes the gain and are the autoregressivecoefficients. Let denote the i.i.d. sequence of innovations when the Markov chain is in state . It is assumed thatare mutually statisticallyindependent. Assuming that the Markov chain is in stateat time , then the process can be described by the differenceequation4.10The conditional dimensional density of is given by4.114.12where is a realization of a vector of initial conditions which is assumed independent of , the density is determined by the distribution of, and is the parameter of the process. Let, , anddenote the companion matrix of the autoregression associated with state . The process has the followingstatespace representation, see, e.g., 258, p. 797, 2404.13The switching autoregressive process 4.10 is not guaranteedto be secondorder stationary even if each individual autoregressive process is stable. Conversely, the switching autoregressiveprocesses 4.10 may be secondorder stationary even if someindividual autoregressive processes are not 164. A sufficientcondition for the switching autoregressive process 4.10 to besecondorder stationary was given by Holst, Lindgren, Holst,and Thuvesholmen 164. Assume that for eachthe innovation process has zero mean and unit variance. Let denote the transition probability from state tostate . For each , define the matrixwhere denotes the Kronecker product.Let denote the resulting matrix and denote by its spectral radius. The switching autoregressiveprocess 4.10 is secondorder stationary if .A more general form of the switching autoregressive processwith Markov regime 4.13 was studied by Francq and Roussignol 127. The process is defined by4.14where is a sequence of dimensional random vectors,is a finitestate Markov chain, is a sequence ofi.i.d. dimensional random vectors independent of ,and and are measurable functions fromto and from to , respectively.In general, the driving i.i.d. noise need not be Gaussian.The standard HMP 4.3 is a special case of 4.14 whichcorresponds to . Krishnamurthy and Rydn 198studied an even more general class of switching autoregressiveprocess characterized by4.15where is a scalar process, is an arbitrary measurable function, and is a scalar i.i.d. process. The conditional dimensional densities of 4.14 and 4.15 may be written similarly to 4.11 and 4.12. The scalar case was chosen in 198 fornotational convenience only. Douc, Moulines, and Rydn 91studied general forms of switching autoregressive processes, ofwhich the above functional forms are special cases, when theMarkov chain takes values in a separable compact statespace that is not necessarily finite. For example, the state spacemay be a compact set in a Euclidean space. Sufficient conditions for the existence of a stationary ergodic solution for thedifference equation 4.14 will be detailed in Section IVC4. Ergodic theorems for switching autoregressive processes will bepresented in Section IVD. Theorems for asymptotic optimalityof their ML parameter estimators will be given in Section VIB.The switching autoregressive process 4.13 is a special caseof the dimensional vector process defined by the difference equation4.16EPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1527where and are sequences of random matrices.When and are statistically independent sequencesof i.i.d. random matrices, the Markov process is referredto as random coefficient autoregressive RCA process. Conditions for stationarity and secondorder stationarity as well asalgorithms for parameter estimation of RCA processes weregiven by Nicholls and Quinn 245. Conditions for geometricergodicity and existence of moments of RCA processes wereprovided by Feigin and Tweedie 114. The important conceptof geometric ergodicity will be defined in 4.28 for finitestateMarkov chains. For more general cases see Meyn and Tweedie240. Conditions for existence of moments of a scalar processsatisfying 4.16, when is a stationarysequence of random variables, were given by Karlsen 181.A sufficient condition for existence of a unique stationaritysolution of 4.16, when is a stationaryergodic sequence of random matrices, was given by Brandt 46and by Bougerol and Picard 45. The condition was shown tobe necessary in 45.Note that the switching autoregressive process 4.13 differsfrom the HMP with autoregressive observation conditional densities of the example in Section IVB1. In that example, observations are conditionally independent given the state sequence.Applications of switching autoregressive processes of the form4.10 in econometrics were studied by Hamilton 156. See alsoKrolzig 202 and the references therein. Firstorder switchingautoregressive processes of the form 4.10 were used in automatic speech recognition applications by Wellekens 312 andin speech enhancement applications by Ephraim 103.4 Communication Channels Driven by HMPs Considera communication channel with input , output, and a state sequence . Assumethat for each , takes values in an input space , takesvalues in an output space , and takes values in a statespace . The channel is called a finitestate channel FSC ifthe following conditions are met 133, Sec. 4.6. i is finite.ii The state sequence is a Markov chain given ,and the distribution of depends on only through .iii The observations are conditionally independent given, and the distribution of depends ononly through . An FSC is characterized bythe timeinvariant transition density and bythe initial state . The conditional dimensional transitiondensity of the channel is given by4.17where4.18Equation 4.18 is an example of a Markov channel 186, 150.FSCs play an important role in information theory, see 133,205. Properties and universal decoding of FSCs will be discussed in Section XIII. It is easy to check that if isan HMP with state space , then is an HMP withan augmented state space . A special case of this exampleis an HMP observed through a memoryless invariant channel17. Note also that an FSC with a degenerate input sequence of, , is an HMP.5 The GilbertElliott Channel The GilbertElliott channel is a special FSC 137, 97, 14, 243, 204. For this example, , , and are binary. In additionandThe channel introduces an additive twostate hidden Markovnoise process that is statistically independent of the inputprocess . For each , where denotesmodulotwo addition. The two states of the channel representlow and high error conditions. The channel is particularlysuitable for modeling communications under fading conditionscharacterized by irregular patterns of burst errors. Propertiesof the GilbertElliott channel depend on its memory lengthcharacterized by the parameter whichsatisfies 243. When , the Markov regimebecomes an i.i.d. regime and the channel is memoryless.When , the Markov chain is reducible and the state ofthe channel is determined by its initial distribution. This is adegenerate channel whose underlying state can be inferredfrom the observed sequence . When , the chainis periodic and the states constantly alternate. Additionalproperties of this channel are given in Section XIII.6 Dynamical Systems HMPs have dynamical systemrepresentations in the sense of control theory. A dynamicalsystem representation for discretetime point processes was firstgiven by Segall 289. These processes are briefly described inSection IVB7. A dynamical system representation of an HMPwas developed by Hamilton 156, Ch. 22. Elliott, Aggoun, andMoore 99 applied this representation to a range of generalHMPs. In this example, we demonstrate the approach for afinitealphabet HMP with states and letters. We willrevisit this representation in Section IX which is dedicated tothe dynamical system approach to HMPs. Our presentationfollows 99, Sec.2.2.Let denote a unit vector representing the th state of theHMP in an dimensional Euclidean space . The th component of is one while all other components are zero. Thestate space of the HMP is given by . Similarly,let denote a unit vector in representing the th letter fromthe alphabet of the HMP. The observation space of the HMPis given by . Letdenote the state transition probability and let . Letdenote the statetoobservation transition probability and let . The unit delaybetween the state and output variables indicates a noninstantaneous response of the system to . Let denotethe smallest field generated by the random variables . Letdenote the smallest field generated by therandom variables . Note that and. Define and note that. Similarly, define and1528 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002note that . The HMP can now be written as adynamical system that has the same probability law. This systemis given by4.19The martingale difference processes and may be statistically dependent as in 289. They are statistically independent for the HMP defined in Section IVA.7 MarkovModulated Poisson Processes MMPPs Consider a Poisson process whose rate is controlled by a nonobservable continuoustime finitestate homogeneous Markov chain.Such process is called a Markovmodulated Poisson process.Markovmodulated Poisson processes have many applicationsin medicine 295, Ch. 7, computer networks 158, 159, andqueueing theory 117. A survey of this class of processes canbe found in Fischer and MeierHellstern 117. Some propertiesof Markovmodulated Poisson processes and their relation toHMPs are discussed in this subsection. Our presentation followsRydn 273. Additional results will be given in Sections IVD,VIAVIC, and X.Let be the continuoustime Markov chain withstate space . Letdenote the transition probability from state to state in seconds. Assume that for any pair of states, for some. This implies that for all 154, p. 260.A Markov chain with this property is called irreducible. Letand assume that the entries of are continuousfunctions of . This assumption is equivalent to aswhere denotes the identity matrix 154, p. 257. The transition probability is approximately linear in for sufficientlysmall . There exist constants , such that4.20where for , and andfor all . The matrix is called the generator of thechain 154, p. 256. The matrix satisfies Kolmogorovs forward and backward equations, and, respectively, where . These equations often have aunique solution given by 154, p. 259. Next, letdenote the Markovmodulated Poisson process.Let denote the rate of the process when the chain is in state. Assume that at least one . Let denote a diagonal matrix of rates . Let denote the parameter of theMarkovmodulated Poisson process satisfying the above conditions.The process may be regarded as a Markov renewalprocess. To see this, let denote the state of the continuoustime chain at the time of the th Poisson event. Introducean initial state with distribution . Define as the timeuntil the first event, and let , , denote the timebetween event and event . It follows that4.21Note that there is a onetoone correspondence betweenand . Also, is a discretetime Markov chain, and is a sequence of conditionallyindependent random variables given . The distribution ofdepends on only through and . This suggests that the Markovmodulated Poisson process may also beviewed as an HMP with Markov chain and observations. The density of this HMP is given by 4.1 and 4.9.The formulations of the Markovmodulated Poisson processas a Markov renewal process and as an HMP are similar butthere is a subtle conceptual difference. For a Markov renewalprocess, the discretetime Markov chain and the observationsevolve sequentially in time, i.e., is first chosen according tothe initial distribution , then and are chosen accordingto 4.21, and so on. For an HMP, the entire Markov chain firstevolves and only then the observations follow 273.Let and. The transition density matrix which corresponds tois given by 130, 1174.22The transition matrix of is given by . Integrating 4.22 with respect to over gives4.23The likelihood function of an observation sequence is givenby4.24where is a row vector of and denotes a columnvector of s. Conditions for stationarity and ergodicityof Markov modulated Poisson processes will be given inSection IVC2.When the Markovmodulated Poisson process has only twostates it is called a switched Poisson process. If the rate of oneof the states is zero, the process is referred to as an interruptedPoisson process. These processes were studied in 130, 233,and 273, where more explicit results could be derived. In particular, Freed and Shepp 130 considered interrupted Poissonprocesses, and derived a simple formula for the asymptotic likelihood ratio for estimating the state at any instant from a streamof past events. Bounds on the likelihood ratio were given for aswitched Poisson process.Related to Markovmodulated Poisson processes are discretetime point processes. A discretetime point process isa binary process with rate determined by anotherrandom process, such as a Markov chain, and possibly by pastobservations. signifies the occurrence of an event attime , e.g., emission of an electron, while indicates thatEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1529no such occurrence has taken place at that time. A recursion forestimating was developed by Segall 289.8 Composite Sources A composite source comprises acollection of discretetime stationary ergodic subsources and arandom switch. At any given time, a single observation or multiple observations are drawn from a subsource selected by theswitch. Composite sources become HMPs when the switch iscontrolled by a firstorder discretetime homogeneous Markovchain, the number of subsources is finite, and the subsourcesare statistically independent i.i.d. random processes. Compositesources with i.i.d. switch processes and finite number ofstatistically independent i.i.d. subsources were first introducedby Berger 31. When the switch position is randomly chosenat time minus infinity, and the switch remains in that positionforever, a stationary ergodic process from one of the subsourcesis observed. The identity or the index of the subsource isnot known. The frozen switch position composite source is amixture process. The ergodic decomposition theorem showsthat discretetime standard alphabet stationary nonergodicprocesses are composite sources with a switch soldered to itsrandomly chosen initial position 151, Ch. 7.4. The specialcase of discretealphabet sources was developed by Gray andDavisson 147.Composite sources have been found useful in applicationssuch as coding and enhancement of speech signals 93, 9,104. A composite source with about 50 stationary subsources,and a switch that may change position every 10400 ms, canadequately represent the modes of speech signals and theirdurations 9, 10. Most of the information in a speech waveform lies in the sequence of modes. The set of modes is essentially independent of the speaker while the switch processis characteristic of the speaker 119. A collection of universalmodes may therefore be used to describe all speech signalsas it is done in vector quantization 135. Composite sourceswith a switch soldered to its randomly chosen initial positionare natural models in universal source coding 75, 147. Thecomposite source represents a family of possible sources forwhich a coder is designed. The coder is universal in the sensethat it must perform well for all subsources while the identityof the subsource selected by nature is not known. Existenceof universal codes for composite sources was proved in 75,118, 121.A summary of properties of twosided composite sourceswith finite number of subsources was given by Fontana 119.A composite source is said to be decomposable if the switchprocess is statistically independent of the collection of subsources, i.e., the switch only chooses a subsource but doesnot otherwise affect its output. Any decomposable compositesource has a regular conditional probability whereis a set in the field of the observation sequence spaceand denotes a switch sequence. The existence of isguaranteed for any alphabet of the subsources. If the subsourcesare jointly stationary then is stationary in the sensethat where denotes the shift transformation on any twosided infinite product space. Stationary,mixing, and ergodic properties of a composite source areinherited from the switch process much like what we shall seein Section IVC for HMPs.The entropy rate of a sequence of finitealphabet stationarydecomposable composite sources with statistically independentsubsources and slowly varying switch processes was studied in119, Theorem 12. It is given by a weighted sum of the entropyrates of the individual subsources where the weights are theasymptotic probabilities of the switch process. Limit theoremsfor the distortionrate function of a sequence of compositesources with vanishingly slow switch processes were alsodeveloped in 119. Ratedistortion functions for compositesources with an i.i.d. switch process and under varying degreesof knowledge of the switch process at the encoder and decoderwere determined by Berger 31. A correct version of 31,Theorem 6.1.1 was given by Wyner and Ziv 318 where theratedistortion function of sources with side information at thedecoder was developed.9 The Telegraph Signal The telegraph signal is an exampleof a continuoustime binary Markov process. The state spaceand the generator of the chain is given byfor 315. When this signal isobserved in white noise, it becomes a continuoustime HMP. Finitedimensional causal MMSE estimation of an state continuoustime Markov chain observed in white noise was first developed by Wonham 315. Noncausal estimation of the stateswas studied by Yao 323.C. Stationarity and ErgodicityStatistical properties of an HMP such as stationarity, ergodicity, mixing, and asymptotic stationarity, are inherited fromsimilar properties of the underlying Markov chain. In the firstand second parts of this subsection, we review these conceptsfor Markov chains and HMPs, respectively. Our presentationin Section IVC1 follows Grimmett and Stirzaker 154 andBillingsley 38. In the third part, we discuss exponential forgetting and geometric ergodicity in HMPs. In the fourth part, weprovide conditions for stationarity and ergodicity of a switchingautoregressive process of the form 4.14. We conclude this section with a local limit theorem for HMPs.1 The Markov Chain Consider a discretetime homogeneous Markov chain with finite or countablyinfinite state space . Let denote the probability that the chain starts from some state . Let denotea row vector with entries . This vector represents the initialdistribution of the chain. Let denote the transition probability for states . Letdenote the transition matrix of the chain. Letdenote the probability of the chain to be in state attime . Let denote a row vector with entries .Let denote the step transitionprobability for states . Let denote a matrix withentries . We have that and . TheChapmanKolmogorov theorem establishes that ,the th power of . Furthermore, 154, p. 215.To establish conditions for stationarity and ergodicity ofMarkov chains we need to characterize states and subsets ofstates within the chain. A state is said to be recurrent,or persistent, if for some .1530 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002If this probability is smaller than one then the state is calledtransient. Intuitively, the probability that a recurrent state willbe revisited infinitely many times is one. The probability that atransient state will be revisited infinitely many times is zero.More formally, define the event . The eventthat infinitely many of the occur, written as infinitelyoften or i.o. , satisfiesi.o.It is shown in Billingsley 38, Theorem 8.2 that persistence ofa state is equivalent to i.o. and to. Transience is equivalent to i.o. and to.Suppose that a chain starts in state . Let denote the probability that the first visit of the chain to state occurs aftersteps. This probability is given by4.25Let denote the time of the first visit to state , i.e., . If the visit never occurs then . Theprobability if and only if is transient,and in this case . The mean recurrence timeof a state is defined asif is recurrentif is transient.4.26Note that the mean recurrence time may be infinite even if isrecurrent. A recurrent state is said to be positive recurrent, ornonnull recurrent, if . Otherwise, the state is called nullrecurrent.The period of a state is defined as ,or as the greatest common divisor of the epochs at which returnsto are possible. A state is called periodic if andaperiodic if . A state is called ergodic if it is positiverecurrent and aperiodic.A set of states is called irreducible if for every pair of statesand in , for some . Thus, is irreducible if thereis a positive probability of ever visiting a state in the set havingstarted from another state in the set. A set of states is calledclosed if for all and . Thus, the probabilityof leaving the set is zero. A state is called absorbing if the chainnever leaves that state. The decomposition theorem for Markovchains establishes that the state space of a Markov chain can beuniquely partitioned as where isthe set of transient states, and are irreducible closed setsof recurrent states 154, Theorem 6.3.4. If for some, then the chain never leaves and that set may be takento be the whole state space. On the other hand, if , thechain will either stay in forever or move eventually to oneof the where it subsequently resides. Thus, if the Markovchain is irreducible, then all states are either transient or recurrent 38, Theorem 8.3. In an irreducible chain, all states areeither positive recurrent or null recurrent. Also, all states are either aperiodic or periodic with the same period 154, Lemma6.3.2. When is finite, the chain cannot stay in forever, andthere exists at least one recurrent state. Furthermore, all recurrent states are positive recurrent 154, Lemma 6.3.5. Thus, allstates of an irreducible finitestate Markov chain are positive recurrent.A homogeneous Markov chain is a stationary process if andonly if for all . Since , theprocess is stationary if and only if the initial distributionsatisfies . This equation may not have a solution,and when it has one, it may not be unique. Any distributionthat satisfies is called a stationary distribution. Thefollowing summarizes conditions for existence and uniquenessof a stationary distribution 162, Corollary 7, p. 68. Letdenote the set of positive recurrent states of a Markov chain. Ifis empty, the chain has no stationary distributions. Ifis a nonempty irreducible set, the chain has a unique stationarydistribution given by for and byotherwise. If is nonempty but not irreducible, the chain hasan infinite number of distinct stationary distributions. For example, suppose that . Any convex combination of the unique stationary distributions of and of isa stationary distribution for . For a finitestate Markov chain,is a nonempty set, and the chain has a unique stationarydistribution if and only if is irreducible. If the finitestateMarkov chain itself is irreducible then it has a unique positivestationary distribution.Consider next the asymptotic behavior of 154, Theorem6.4.17. If the Markov chain is irreducible and aperiodic, thenfor all and . If the chain is transient ornull recurrent, for all and since . If theMarkov chain is irreducible, aperiodic, and positive recurrent,convergence is to the unique stationary distribution, say , forall states and in4.27For a finitestate irreducible aperiodic Markov chain, 4.27holds, convergence is at an exponential rate4.28where and , and the chain is an ergodicprocess, see Billingsley 38, Theorem 8.9 and Lemma 2, p. 315.An ergodic Markov chain satisfying 4.28 is called geometrically ergodic 114. This concept usually applies to a muchmore general situation of a Markov chain with a continuous statespace, see Meyn and Tweedie 240. Note that the aperiodic condition for ergodicity of the chain is sufficient but not necessary.For example, consider a Markov chain with and ,. This periodic chain has a unique stationary distribution, 4.27 does not hold for this chain, but the chain is anergodic process.The transition matrix of a Markov chain is called primitiveif there exists some positive integer such that the step transition matrix has positive entries, i.e., .The smallest such integer is called the index of primitivity of. The transition matrix of an irreducible aperiodic finitestateEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1531Markov chain is primitive 38, Lemma 2, p. 125. A finitestatechain with primitive transition matrix has a unique positive stationary distribution and the chain is geometrically ergodic 38,Theorem 8.9. A corollary of these results is that the chain has aunique positive stationary distribution and is geometrically ergodic when .An state Markov chain with is mixing withfor . Moreover, any deterministic function of the chain is mixing with the same coefficients 38, p.363. Since mixing implies ergodicity 38, p. 325, a stationaryfinitestate Markov chain with positive transition probabilitiesis stationary ergodic as we have seen before under weaker conditions.2 The HMP HMPs are Markov chains observed throughchannels. Statistical properties of sources observed throughchannels were developed by Adler 1 for twosided processesand by Gray 152 for onesided processes. In particular, whena stationary source is connected to a stationary channel thenthe sourcechannel hookup is stationary 152, Lemma 9.3.1.When a stationary ergodic source is connected to a stationaryoutput weakly mixing channel then the sourcechannel hookupis stationary and ergodic 152, Lemma 9.4.3. The channelassociated with an HMP is a memoryless invariant channel.As such, it is stationary and output strongly mixing. Hence,an HMP is stationary and ergodic if the Markov chain isstationary, irreducible, and aperiodic. A similar result wasdirectly proved by Leroux 214, Lemma 1 without resorting tothe informationtheoretic model of the process.When a stationary mixing source is observed through astationary output strongly mixing channel, the sourcechannelhookup is stationary mixing 1. Hence, an HMP is stationarymixing if the Markov chain is stationary and its transitionprobabilities are positive. Mixing properties of the twosidedHMP in Section IVB1 were demonstrated byFrancq and Roussignol 126.An additional result showing that when an AMS source isobserved through a stationary channel then the sourcechannelhookup is AMS was developed by Fontana, Gray, and Kieffer120, Theorem 4, see also 152, Lemma 9.3.2. FinitestateMarkov chains and deterministic functions of such chains areAMS, see Kieffer and Rahe 186, Theorem 9. Hence, HMPsare AMS.Conditions for stationarity and ergodicity of a Markovmodulated Poisson process, defined in Section IVB7, were given byRydn 273, Lemma 1. Consider a process with an irreduciblecontinuoustime Markov chain, a generator , and a diagonalmatrix of rates with at least one . Letdenote the parameter of the process. A vector is a stationarydistribution of the chain if , , andfor all . This equation is satisfied for all if and only if154, p. 261. If a stationary distributionexists, then it is unique and for all 154,p. 261. Recall that is the transition matrixof the discretetime Markov chain embedded at event epochs.Let  denote the subset of states withcorresponding positive Poisson rate. It was shown that for eachparameter , is the only set of recurrent aperiodic states. Theremaining states are transient. The discretetime Markov chainhas therefore a unique stationary distribution which is positivefor all states in and zero otherwise. The stationary distribution of is given by 117, eq. 64.29Stationarity and ergodicity of the Markov modulated Poissonprocess are inherited from the Markov chain.3 Exponential Forgetting and Geometric Ergodicity Wehave seen in 4.4 that the likelihood function of anHMP is determined by the state predictive densities and theobservation conditional densities. Recall that is thevector representing the initial distribution of the Markov chain.Let denote the state predictive density vector at time . For, the th component of this vector is given byfor and by for. Let denote a column vector whose th elementis given by . Recall that denotes theparameter of and . Let denote a diagonalmatrix whose element is . The state predictivedensity vector satisfies the following recursion which will bediscussed in more details in Section VA4.30The loglikelihood function is given by4.31Assume the usual parametrization for theHMP in 4.30 and 4.31. Let denote the true value ofused to produce the observation sequence . Assume that isnot known. For identification of , is expected totake different values for different pairs of . The effects ofon is expected to be rapidly forgotten so that anarbitrary initial distribution can be used in the recursion 4.30with no lasting effect. Conditions for identifiability of an HMPare given in Section VIA.Le Gland and Mevel 210, Theorem 2.2 proved exponentialforgetting of the initial distribution for the prediction recursion4.30 when is not known. They referred to this situation asthat of a misspecified HMP. They assumed that the transitionmatrix and its true value are primitive, but no restrictionswere imposed either on or on its true value . To emphasizethe dependence of on the observation sequence and on theinitial distribution , we rewrite it as . Let beanother initial distribution. It was shown thata.s. 4.32where denotes the norm, denotes the index of primitivity of , and is a constant depending on the observation conditional densities of the HMP. An implication of this1532 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002property is that the loglikelihood function is Lipschitz continuous with respect to some parameter of the model, uniformly intime 210.For a misspecified HMP, the predictive density vector sequence is not a Markov chain under , but the tripletstate, observation, wrong predictive density is a Markov chain.Let denote that extended Markovchain. Le Gland and Mevel 210, Theorem 3.5, Corollary 3.6proved geometric ergodicity of the extended Markov chainand showed existence of a unique invariant distribution underthe assumption that the true and unknown transition matricesare primitive. In particular, this theorem implies an ergodic theorem for the relative entropy density of the HMP 210. Thislimit theorem is key to proving consistency of the ML parameter estimator. These subjects are discussed in Sections IVDand VIB, respectively.Exponential forgetting, geometric ergodicity, and existenceof a unique invariant distribution for an extended Markov chaindefined similarly to above, for an HMP with a separablecompact state space that is not necessarily finite, were provedby Douc and Matias 90, Proposition 1, Corollaries 1, 2.A recursion for the gradient of the predictive density vectorwith respect to a scalar parameter of the HMP can be obtainedfrom 4.30. Exponential forgetting of the initial condition forthis recursion were established by Le Gland and Mevel 210,Theorem 4.6. This result implies that the score function of theHMP is Lipschitz continuous with respect to some parameter ofthe model, uniformly in time 210. Let denote the gradient sequence. Geometric ergodicity of the extended Markovchainand existence of a unique invariant distribution, were proved byLe Gland and Mevel 210, Theorem 5.4, Corollary 5.5 undersome integrability assumptions. The implications of this resultare that a central limit theorem for the score function and a lawof large numbers for the Hessian matrix follow 210. Theselimit theorems are key in proving asymptotic normality of theML parameter estimator. This subject will be discussed in Section VIB.Exponential forgetting and geometric ergodicity for similarlydefined extended Markov chains, involving the score functionand Hessian of a misspecified HMP with a separable compactstate space that is not necessarily finite, were proved by Doucand Matias 90, Appendix D.Another form of exponential forgetting was demonstrated byDouc, Moulines, and Rydn 91 for switching autoregressiveprocesses with a separable compact state space that is not necessarily finite. Let denote the order of the autoregressive processand let be the true parameter. They showed that for anyand , the state sequence given anobservation sequence , is an inhomogeneous Markovchain under the stationary measure 91, Lemma 1. Exponential forgetting of the initial distribution for this inhomogeneous Markov chain was shown in 91, Corollary 1. This property is key in proving consistency and asymptotic normality ofthe ML parameter estimator of .4 Switching Autoregressive Processes Conditions for stationarity and ergodicity of a switching autoregressive processof the form 4.14 were given by Francq and Roussignol 127,Theorem 1. Recall that an HMP is a special case of this process.Let denote the true parameter of the switching autoregressive process. It was assumed that i the Markov chainis irreducible and aperiodic, ii forall where denotes the usual Euclideannorm, and iii there exist constants such that for alland all4.33and the matrix , whereand is the true transition matrix of , has spectral radius smaller than . Under these conditions, it was shown thatthe Markov chain on admits a unique stationary probability . The second marginal of is equal to thestationary probability of . Moreover, a stationary Markovchain satisfying 4.14 with as initial distribution isan aperiodic ergodic Harris process 114, 240.5 A Local Limit Theorem A local limit theorem forzeromean stationary ergodic general HMPs with finitesecondorder moment that satisfy some mild conditions wasproven by Maxwell and Woodroofe 231. Let denote thedistribution of the HMP. For the partial sum of HMP observations, , it was shown that4.34for some positive constant and , and4.35D. Entropy Ergodic TheoremsIn this subsection, we review ergodic theorems for thesample entropy and relative entropy densities of an HMP.The fundamental ergodic theorem for the sample entropy of astationary ergodic finitealphabet process, not necessarily anHMP, is given by the ShannonMcMillanBreiman theorem68, Theorem 15.7.1. Let denote such a process and letdenote its distribution. Let denote the dimensionalpmf induced by . The theorem states thata.s. 4.36where4.37is the entropy rate of 152, p. 24. Another common notation for the entropy rate is .EPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1533Let denote a stationary ergodic HMP with distribution for some parameter . This onesided processmay be considered part of a twosided stationary ergodic processwith the index set of all integers. The dimensional density ofthe HMP with respect to is the density given by4.8. For a finitealphabet HMP, is the counting measure .For a general HMP, is any finite measure. For a finitealphabet HMP we have from 4.36a.s. 4.38Leroux 214, Theorem 1 proved 4.38 for a stationary ergodicgeneral HMP. He assumed an irreducible aperiodic Markovchain and observation conditional densities that satisfyforThis extension is in fact a special case of Barrons ergodic theorem 23 which we discuss shortly.Let , , denote a distribution of the HMP and letdenote the induced dimensional density with respectto as given by 4.8. The parameters and are not necessarily equivalent. We are now interested in ergodic theoremfor when is the stationary ergodic HMPwith distribution . Baum and Petrie 25, Theorem 3.2 andPetrie 251, Theorem 2.1 developed the theorem for a finitealphabet HMP. Petrie 251 relaxed the assumption thatmade in 25. Leroux 214, Theorem 2 proved the theorem fora general HMP. The ergodic theorem states thata.s. 4.39where4.40Define4.41and note that . Baum and Petrie 25,Theorem 3.1, Petrie 251, Proposition 2.2, Theorem 2.5, andLeroux 214, Lemma 6 proved thatwith equality iff 4.42This important property provides a criterion for distinguishingbetween the equivalence classes of and , and is key inproving consistency of the ML estimator of . For an identifiable HMP, the equivalence class of comprises all points inobtained by permutations of the states of the HMP. A similarstatement holds for the equivalence class of .Leroux showed that theorem 4.39 holds for any choiceof positive initial distribution and is the samefor any such choice. may possibly be equal to. He proved the theorem using Kingmans 188 ergodictheorem for subadditive processes assuming an irreducibleaperiodic Markov chain and observation conditional densitiesthat satisfyfor some where denotes the Euclidean distance and. Theorems 4.39 and 4.42 hold for anyin the onepoint compactified parameter space . Compactification extends the parameter set into a compact set . Forthe usual parametrization, is obtained from compactificationof the parameter space . The latter is done by attaching toa point denoted , and extending to by defining. For example, if is the Poisson densitywith mean then . A regularity condition assumedin 214 ensures continuity of over . For any otherparametrization of the HMP, for .In proving 4.42, the assumption quoted after 4.38 was alsomade.If we assume that in addition to our earlier assumption that , then the two measures are equivalent, and4.43For this case, 4.38 and 4.39 imply an ergodic theorem forthe relative entropy density of one general HMP with respect toanothera.s. 4.44In addition, we may now call the relative entropyrate 152, p. 150.Similar ergodic theorems for relative entropy densities of several extensions of standard HMPs were recently proved undersuitable conditions. Francq and Roussignol 127 studied stationary ergodic switching autoregressive processes with finitestate Markov regime given by 4.14. They proved an ergodictheorem similar to 4.39 for the normalized conditional loglikelihood 127, eq. 11. They expressedthe conditional density as a product of random matrices and applied Furstenberg and Kesten 132 ergodic theorem. The sequence converges almost surely to the upper Lyapunov exponentof the sequence of random matrices. They also proved 4.42127, Theorem 2. Conditions for a switching autoregressiveprocess of the form 4.14 to be stationary ergodic were givenin Section IVC4. For the matrix product form of the likelihoodfunction of a standard HMP see 5.12.Krishnamurthy and Rydn 198, Lemma 1 studied stationaryergodic switching autoregressive processes with finitestateMarkov regime described by 4.15 and arrived at a similarergodic theorem for the normalized conditional log likelihood.They used Kingmans ergodic theorem following Leroux 214.They also showed in 198, Lemma 4 that butthe implications of are not as explicit as forthe process studied in 127, Theorem 2.1534 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002Le Gland and Mevel 210 proved an ergodic theorem similar to 4.39 for a finitestate general HMP using geometricergodicity of an extended Markov chain as described in Section IVC3. Douc and Matias 90 extended this approach to ageneral HMP with a separable compact state space that is notnecessarily finite. They developed an ergodic theorem similar to4.39 for an HMP with arbitrary initial state density not necessarily a stationary density 90, Proposition 4. They also proved4.42 90, Theorem 1. It was noted in 90 that Lerouxs approach does not immediately apply to HMPs with a continuousstate space.Douc, Moulines, and Rydn 91 studied general forms ofswitching autoregressive processes with a separable compactstate space that is not necessarily finite. They proved an ergodictheorem similar to 4.39 for almost sure and convergence ofthe normalized conditional log likelihood of the observation sequence 91, Proposition 1. They also proved 4.42 91, Proposition 3. They relied on uniform exponential forgetting of theinitial distribution of the inhomogeneous Markov chain representing the states given the observation sequence. It was notedin 91 that application of the approach used in 90 would haverequired stronger assumptions.Rydn 273, Lemmas 5, 8 proved an ergodic theorem similar to 4.39 and the conclusion 4.42 for a Markovmodulated Poisson process. The main difference between the HMPsin Leroux 214 and Rydn 273 is that for the former case4.2 holds while in the latter 4.9 holds as explained in Section IVB7. In addition, compactification of the parameter set isnot possible since does not always vanish at infinity.We turn now to the general ergodic theorem for relative entropy density developed by Barron 23. See also 152, Theorem8.2.1. Consider a standard alphabet random processdescribed by a stationary ergodic distribution on a sequence measurable Borel space 152, p. 12. Let be a finite Markov measure of order that has stationary transition probabilities and is defined on the same measurable space.Let and denote the dimensional distributions induced by and , respectively. Assume that forall . Let denote the RadonNikodymderivative or density of with respect to . LetforandAssume thatfor some . This condition is automatically satisfied ifis a finite measure or a probability measure. In the lattercase, . The theorem states thata.e. and in 4.45where is the relative entropy rate defined similarlyto 4.414.46Theorem 4.38 for a general HMP could be obtained from4.45 if and . Ifthen and the theorem holds. This condition resultsfrom application of Jensens inequality to 4.4.An ergodic theorem for when is AMS andis the same Markov measure as above was proved byBarron 23, Theorem 3. See also Gray 152, Theorem 8.4.1.Let denote a stationary distribution that asymptoticallydominates . This may be the stationary mean of the AMSprocess. Let . It was shown that ifa.e. for some shiftinvariant measurable function then also a.e.Ergodic theorems for when is stationary but notergodic were proved by Barron 23, Theorem 2 and Gray 152,Corollary 8.3.1.Without the Markov property for the dominating measure ,convergence of is not guaranteed 23. When andare two stationary ergodic general HMP distributions, 4.44provides a version of Barrons theorem with an HMP dominating measure. For finitealphabet processes, an HMP dominating measure may replace the Markov measure in 4.45 provided that its parameter . This result was first shownby Finesso 116, Theorem 2.3.3 and then by Kehagias 183,Lemma 1. In particular, Finesso 116, Sec. 2.4 proved that ifunder the process is stationary ergodic, andis an HMP distribution with corresponding dimensional pmf, thena.s. 4.47where is defined similarly to 4.40 and convergence is uniformly in . This theorem is particularly usefulwhen one wishes to model a stationary ergodic processby an HMP and performs ML estimation of its parameter by maximizing over . In addition,is the asymptoticallyminimum average length of a source code designed for the stationary ergodic source assuming that this source is the HMP68, Theorem 5.4.3.E. FiniteAlphabet HMPsIn this subsection, we summarize results for finitealphabetHMPs and deterministic functions of finitestate Markov chains.We first show that the two classes of processes are closely related. Then we focus on an important subclass of finitealphabetHMPs known as unifilar sources. This class is amenable to theEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1535method of types and hence is particularly attractive. We conclude with some bounds on the entropy rate and ratedistortionfunction of finitealphabet HMPs.Consider an HMP with states and letters. Define theCartesian product of observation and state spaces,and a deterministic function  by .Rewriting 4.1 redundantly, we have4.48Hence, is a Markov chain with states,and . Thus, any finitealphabet HMP is a deterministic function of a Markov chain with augmented state space25. Conversely, if for some function and Markovchain , then is an HMP withif and zero otherwise 161. Thus, any deterministicfunction of finitestate Markov chain is a trivial HMP.Let for some manytoone function and Markovchain . The function may collapse one or more states ofonto a single letter of . The process is therefore referred to as aggregated Markov process 278, 206.The process is not in general a Markov chain and it exhibits long statistical dependencies. It inherits stationarity andergodicity from the Markov chain 25. Necessary and sufficient conditions for to be a Markov chain were developed by Burke and Rosenblatt 52. Conditions for stationaryprocesses to be functions of Markov chains were developed byDharmadhikari 8386, Heller 160, and Erickson 107. Apartial summary of these results appears in 272, pp. 7778.These results are not constructive in the sense that they do notlead to an algorithm for producing the Markov chain andfunction for a given stationary process . Identifiability ofa function of Markov chain was first studied by Blackwell andKoopmans 42, Gilbert 136, and Carlyle 54. Identifiabilityof a finitealphabet HMP was studied by Petrie 251. Identifiability of a function of a nonstationary Markov chain was studiedby Ito, Amari, and Kobayashi 167, Rydn 278, and Larget206. These results will be further discussed in Section VIA.See 167 for additional references.A deterministic function of Markov chain which producesdistinct letters when the chain transits from each state to allstates with was referred to as a unifilar sourceby Ash 14. For unifilar sources, the state is uniquely determined by the previous state and the current letter .The entire state sequence can be read from the observationsequence provided that the initial state is known. An important special case of unifilar sources is the thorder Markovchain with states defined as .A more general source was introduced by Gallager who referred to it as Markov source 133, Sec. 3.6. The source ischaracterized by an initial state , a transition pmf ,and a deterministic nextstate function for. Given the initial state , an observation isgenerated according to and a new stateis chosen. Next, is generated according to , and soon. The dimensional pmf of the source is given by4.49By construction, is uniquely determined by and the initial state as we have seen for unifilar sources. The observation , however, is a not a deterministic function of unlessis a onetoone function given . We shall not impose this restriction on . We shall refer to this source as theunifilar source. Other authors have used the more explicit nameof unifilar finitestate source.Unifilar sources are mathematically tractable since they areamenable to the method of types much like i.i.d. sources andMarkov chains. The method of types for i.i.d. sources was developed by Csiszr and Krner 70, 73. Consider an i.i.d. finitealphabet source with letters and pmf . The methodof types characterizes the sample space of length source sequences by an exhaustive set of empirical distributions calledtypes. The set of all length source sequences having the sametype forms a type class. The set of all type classes forms a partition of the sample space of all length source sequences. Letdenote an observation sequence with empirical pmf .Letdenote the empirical entropy. Letdenote the relative entropy between and . The following facts were established. We use to denote approximations up to polynomial factors. The pmf of the sequence canbe written as4.50Hence, all sequences within a given type class are equally likely.There is a polynomial number of types that does not exceed. There is an exponential number of sequences ineach type class given by . The probability of a typeclass is given by .A summary of the method of types for unifilar sources, whichis similar to that for Markov chains, can be found in Csiszr 73.Let denote an observation sequence from a unifilar sourceand let denote the state sequence recovered from and. Let denote the pmf of the joint type of .The joint type is given by the relative frequency of appearance ofamong the pairs . Letdenote the empirical transition pmf induced by the joint type.Let4.51denote the empirical conditional entropy, and let4.521536 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002denote the conditional relative entropy. The following facts wereestablished. The pmf 4.49 has the form of 4.50 withand given by 4.51 and 4.52, respectively. All sequences within a given type class are equally likely. There is apolynomial number of joint types that is larger thanfor some constant but does not exceed . Thelower bound is due to Alon, cited in 309, Lemma 2. The cardinality of a type class is and the probability of a typeclass is .No extension of the method of types to HMPs is known.Hence, the analysis of HMPs is generally much harder as theirstatistics cannot be summarized by types. In some problems, thisdifficulty may be circumvented by defining a conditional typeclass and lowerbounding its cardinality using the LempelZivuniversal codeword length instead of the empirical entropy asfor the joint type above. This approach was demonstrated byZiv and Merhav 330 and Merhav 236. In addition, any finitealphabet HMP for which for alland can be approximated by a unifilarsource having sufficiently large number of states as was shownby Zeitouni, Ziv, and Merhav 325, Appendix.The entropy rate of a unifilar source was given by Gallager 133, Theorem 3.6.1. Let andLetbe the conditional entropy of given that the chain is in state. The entropy rate of the unifilar source is given by4.53If the Markov chain is irreducible aperiodic with stationary distribution then .No explicit singleletter expression for the entropy rate of anHMP is known 41. Sequences of asymptotically tight boundsfor the entropy rate of a deterministic function of a stationaryMarkov chain were first developed by Birch 40. The samebounds appear in Cover and Thomas 68, p. 69. Gallager 133,Problem 3.23 provides the same bounds for a finitealphabetstationary HMP. The bounds are given in terms of conditionalentropies of the process. For a process with dimensionalpmf , the conditional entropy is defined by68, p. 164.54For a stationary process, this conditional entropy is a monotonically nonincreasing sequence which converges to the entropyrate of the process. Hence, provides anupper bound for . For the lower bound, the conditionalentropy is used. This conditional entropy isa monotonically nondecreasing sequence which also convergesto the entropy rate . In addition,68, p. 27. Thus, for each4.55and4.56The difference between the upper and lower bounds in 4.55 isthe conditional mutual information 68, p. 224.57It signifies the amount of information that can be gained aboutfrom given . The rate at which this differenceapproaches zero is of theoretical and practical importance.Birch 40 showed that if the transition matrix , thenconverges to zero exponentially fast with .A lower bound on the ratedistortion function of a finitealphabet HMP was developed by Gray 146. The ratedistortionfunction provides the minimum possible bit rate required by any encoder to encode the source with average distortion that does not exceed 68, p. 341. Consider an HMPwith alphabet of size , dimensional pmf , and entropyrate . Let be a distortion measure between a letterand its encoded version . Assume that  isindependent of . Such a distortion measure is called balanced.The Hamming measure , where is theKronecker delta, has this property. Letbe the distortion between and . Define the set of conditional pmfs for all possible encoders that provide average distortion smaller than or equal to as4.58where expectation is taken with respect to the joint pmf. Let denote themutual information between the HMP observation sequenceand its encoded version4.59The rate distortion function is defined as 68, p. 3414.60The bound on the ratedistortion function is given by4.61where is a constant and4.62The optimal value of that maximizes the bound is obtainedfrom4.63EPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1537The bound is the same for all HMPs having the same alphabetsize and entropy rate. There exists a distortion intervalover which the bound is tight provided that the initial distribution of the Markov chain is positive and either the state transition matrix or the statetoobservation transition matrix. The value of depends on the number of states.V. STATE ESTIMATIONEstimation of the state sequence from an observation sequence is of considerable theoretical and practical importance. Estimation of the state from is a prediction problemwhen , a filtering problem when , and a smoothingproblem when . The state sequence may be estimatedunder various criteria. The most common criteria are minimumsymbol error probability and minimum sequence error probability. In the first case, an estimate is chosen by minimizing the probability of error . This results inthe maximum a posteriori MAP symbol decision rule5.1and the sequence is estimated as . Computationallyefficient forwardbackward recursions for calculatingwere developed by Chang and Hancock 56, Ott 248, Raviv265, Baum, Petrie, Soules, and Weiss 28, Forney 124,Bahl, Cocke, Jelinek, and Raviv 17, Lindgren 219, Askarand Derin 15, Devijver 81, and Kitagawa 189. Theserecursions will be presented in Section VA. Estimation of thestate sequence using the second criterion results in the MAPsequence estimate given by5.2This problem is solved using dynamic programming 30 or bythe wellknown Viterbi algorithm 308, 124, 285.When the states are considered unit vectors in an dimensional space, as was done in Section IVB, they can beestimated in the MMSE sense. The conditional mean estimate in this case is the vector of conditional probabilities. This approach enables application of nonlinear estimation techniques 99 and will bepresented in Section IX. In a related approach, Golubev 143studied causal conditional mean estimation of given whenthe finite number of values that can take were assumed realnumbers rather than integers. If , then theMMSE estimator of is given byBoguslavskii and Borodovskii 44 proposed rounding the conditional mean estimate of given to the nearest neighborinteger.Note that the two schemes 5.1 and 5.2 are smoothing approaches except when estimating the th state from . Whilethe error probability of the MAP symbol decision rule 5.1cannot exceed that of the MAP sequence decision rule 5.2,there is no guarantee that the sequence estimate is admissible since it may contain transitions that are a priori impossible. Both estimators 5.1 and 5.2 require the entire sequenceof observations for estimating a state at time .A lowdelay symbol MAP decoder was proposed in 249. Ahybrid of the two approaches 5.1 and 5.2 was proposed byBrushe, Mahony, and Moore 50. A forwardbackward recursion that depends on a softdecision parameter was developedsuch that symbol decoding 5.1 is obtained when andsequence decoding 5.2 is obtained when . In particular, this approach shows that the Viterbi algorithm can be implemented in a forwardbackward manner.The forwardbackward recursions of Chang and Hancock56 as well as the Viterbi algorithm were shown by Aji andMcEliece 3 to be special cases of a generalized distributivelaw which is used to marginalize a product function such as aproduct of pdfs. Many other algorithms, such as the turbo decoding algorithm, fall into this category 3.In some applications, such as automatic speech recognition, itis often desirable to find several state sequences that mostly contribute to the likelihood function . Analgorithm that accomplishes this task was proposed by Foreman123. In other applications, lumpable HMPs are encountered.These are generalizations of lumpable Markov chains, whereasstates can be grouped together in disjoint sets, and the probability of being in a state in one set is independent of the previousstate as long as that state lies in another set. The state filteringproblem for lumpable HMPs was studied by White, Mahony,and Brushe 314.Asymptotic performance of the MAP symbol estimator offrom , for an HMP with rare transitions, was studied byKhasminskii and Zeitouni 185. They assumed a finitestate irreducible aperiodic Markov chain with transition matrixwhere when , , and. Let denote the stationary distribution of thechain and let denote the divergence between the observation conditional densities associated with states and where. Let denote the infimum of over allpossible estimators . Under some mild assumptions on theobservation conditional densities of the HMP, and for any initial distribution, they showed that as5.3A similar result holds for a continuoustime HMP. When thestates are considered real numbers , Golubev143 showed under similar assumptions as in 185 that theaverage MSE5.4associated with the conditional mean estimator is given by5.5as .Asymptotically optimal recursive estimators for the states of afinitealphabet HMP, in the minimum probability of error sense,that do not depend on the transition matrix, were derived in142, 184, and 185.1538 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002A. Prediction, Filtering, and Smoothing RecursionsIn this subsection, we present recursions for the conditionalprobabilities , and , .We begin with the forwardbackward recursions of Changand Hancock 56, eqs. 10, 18 which were later rediscovered by Baum, Petrie, Soules, and Weiss 28, 29. These recursions rely on the conditional statistical independence ofand given , . This property leadsto a simple decomposition of . Define the forwarddensity by and the backward densityby with . Forwe have5.6The forward and backward densities satisfy the following recursions5.75.8The conditional probability , , can be calculated as5.9Furthermore, for5.10The likelihood function of the observation sequence can beefficiently calculated using the forward recursion as follows5.11Evaluation of 5.11 requires an order of operations whiledirect calculation of the likelihood function 4.3 requires anorder of operations.The forwardbackward recursions can be compactly writtenusing matrix notation. Let denote the vector whoseth element is . Let denote the vector whoseth element is . Let denote an diagonalmatrix whose element is . Let representan vector of s. Recall that denotes the transitionmatrix and denotes a vector representing the initialdistribution. Let and . The matrix forms of5.7, 5.8 and 5.11, respectively, are given by ,, and . In particular, we have5.12It is well known that the forwardbackward recursions 5.7and 5.8 are not numerically stable. This has often been observed in practice, see, e.g., 215, 263, 81. These observations are supported by the ergodic theorem 4.39 as argued byLeroux 212. For sufficiently largewith high probability. Furthermore, are typically of the same order of magnitude. Hence, eachtends to zero or infinity exponentially fast as .An embedded iterative scaling procedure for stabilizing theforwardbackward recursions was developed by Levinson, Rabiner, and Sondhi 215. They proposed usingas a normalizing factor for the forward and backward densities.Starting with a normalized forward density function, say, the recursion 5.7 is executed and normalized by to produce a new normalized updated density. For , we have . Similarly,starting with a normalized backward density function, say, the recursion 5.8 is executed and normalized by to produce a new normalized updated density. For , we have . The conditional probabilities 5.9 and 5.10 may be calculated using thescaled forward and backward densities. Devijver 81, eq. 17showed that the scaled forward recursion provides a stablerecursion for the conditional probability . The scaledbackward recursion does not enjoy such an intuitive interpretation. The recursion for is, in fact, a recursion for81, eqs. 9, 16. Furthermore, thestate conditional probability can be obtained from5.13Similar stable recursions were later developed for turbo codesby Barrou, Glavieux, and Thitimajshima 32.The stable forward recursion for was provided muchearlier than 215 and 81 by Ott 248, eq. 4, Raviv 265, eqs.5, 8, and Lindgren 219, Lemma 2.1. Denoting, this recursion is given by5.14EPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1539where and5.15Lindgren 219, Lemma 2.1 and Askar and Derin 15, Theorem 1 developed equivalent alternative stable backward recursions for calculating and using only theforward recursions for and . See also comments in Devijver 81, eq. 21. We present here the recursionsfrom 15, Theorem 1 as follows5.165.17for , where . Therecursions 5.16, 5.17 are computationally more efficient than5.9, 5.10 which use Chang and Hancocks forwardbackward recursions 81.The recursions for in 5.15, in 5.14,and in 5.16 are, respectively, prediction, filtering,and fixedinterval smoothing recursions for estimating from. A recursion for the step predictor , ,can be found in Knsch 203, Lemma 3.1. These recursions,with sums replaced by integrals, are applicable to discretetimecontinuousrange state and observation processes, describedby general statespace models of the formand where and are arbitrary measurablefunctions and and are statistically independent i.i.d.processes 169, eq. 7.84, 15, 189, 192, 203. Theyprovide conditional mean estimators for estimation problemsthat are not necessarily linear or Gaussian. For linear Gaussianstatespace models with Gaussian initial conditions, the recursions 5.145.16 are equivalent to the Kalman filter andfixedinterval Kalman smoother, respectively, 169, Example7.8, 189, 76, 203, Sec. 3.4.2. This is easily checkedsince , , and are Gaussian andhence characterized by their conditional means and covariancematrices 286, p. 308. Exponential stability of the filtering andfixedlag smoothing recursions in finitealphabet HMPs wasdemonstrated by Anderson 11.The stable forwardbackward recursions have compact vector forms. Let denote the vector whose th element isgiven by . Let denote the vector whoseth element is given by . Let denote, as usual, thevector of initial distribution. Let denote termbytermmultiplication of two vectors and let denote termbytermdivision of two vectors. The vector forms of 5.14 and 5.15are, respectively, given by 156, eqs. 22.4.56,5.18where and5.19The vector form of 5.16 is given by 156, eq. 22.4.145.20The recursions 5.185.20 hold for the switching autoregressive process 4.10 of which HMPs are special cases, see, e.g.,156, Ch. 22.We close this subsection with a relation that follows fromLindgren 219, Lemma 2.1. We have that5.21This demonstrates the wellknown fact that is a conditionally inhomogeneous Markov chain given . The transition probabilities are given by 5.21. This important property is often used in analysis of HMPs, see, e.g., 166, 36,and 174, Lemma 4.1. Properties of the conditionally inhomogeneous Markov chain for switching autoregressive processes,with Markov regime in a separable compact state space that isnot necessarily finite, were given by Douc, Moulines, and Rydn91, Lemma 1.VI. ML PARAMETER ESTIMATIONIn this section, we address several important aspects of parameter estimation of an HMP. We begin with conditions foridentifiability of an HMP and proceed with consistency andasymptotic normality of the ML estimator. This is followed bya brief presentation of the Baum algorithm for local ML estimation of the parameter of an HMP. Next, Louiss formula forestimating the observed information matrix whose inverse provides an estimate of the error covariance of the ML estimator ispresented. We conclude this section with Zivs inequality whichprovides a tight upper bound on the maximum of the likelihoodfunction of any finitealphabet HMP.A. Identifiability of HMPsConsider a stationary HMP with the usual parametrizationwhere . Letdenote the dimensional density of the HMP. An HMP withtrue parameter is said to be identifiable if for eachsuch that , a.e. forsome 274. Consider the sourcechannel informationtheoretic model of an HMP. If the Markov chain is reducible,there might be infinitely many stationary distributions. In addition, some components of the parameter of the HMP, relatedto the Markov chain and observation conditional densities, willhave no effect on the likelihood function. Similarly, if someof the are identical, there might be an infinite number ofstochastic matrices that induce the same dimensional stationary distribution as does. In both cases, the HMP cannotbe identifiable 214, 274. Note that the states of the HMP canbe permuted without affecting its distribution. This trivial ambiguity can be resolved if the states are ordered.Leroux 214 and Rydn 274, 277 studied identifiabilityof a general HMP. Leroux observed that the problem is essen1540 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002tially that of identifiability of finite mixtures of product densities, since from 4.8, the density of the HMP can be written as6.1where . Leroux invoked a result byTeicher 297, Theorem 2 which shows that if the family of allfinite mixtures of is identifiable, thenfor every , the family of finite mixtures of product densities of the form 6.1 is identifiable. The family of finite mixtures of is identifiable if the mixingcoefficients can be identified, i.e., ifa.s.6.2where denotes the point mass at , and and aredistributions. This condition holds, for example, whenis Poisson, Gaussian with fixed variance, exponential, and negative exponential. Teichers theorem combined with the earliercomments lead to the following conclusion. An HMP with theusual parametrization is identifiable for if the Markovchain is irreducible, all are distinct, and finitemixtures of the parametric family are identifiable.In that case, is uniquely determined from ,, up to permutations of the states. It should be noted thatthe finitedimensional distributions of are uniquely determined by the dimensional distribution even when not all ofthe are distinct, Rydn 274, 277, Theorem 1.Conditions for identifiability of a Markovmodulated Poissonprocess, defined in Section IVB7, were given by Rydn 278,Corollary 1. A Markovmodulated Poisson process is identifiable, up to state permutations, if and only if all Poisson rates aredistinct.Petrie 251, Theorem 1.3 provided conditions for identifiability, up to permutations of the states, of a stationary ergodicfinitealphabet HMP see also Finesso 116, Theorem 1.4.1. Acomplete solution to the identifiability problem of a deterministic function of discretetime, possibly nonstationary, Markovchain, was developed by Ito, Amari, and Kobayashi 167.An algebraic approach was used to develop necessary andsufficient conditions for two aggregated Markov processes to beequivalent, i.e., to have equal finitedimensional distributions.An algorithm for deciding equivalence was also developed.This approach was used by Rydn 278 and Larget 206to determine equivalence of two continuoustime aggregatedMarkov processes. These are deterministic functions of continuoustime Markov chains. A unique canonical representationof each equivalence class of aggregated Markov processesthat satisfy some mild regularity conditions was developed in206 for both continuoustime and discretetime processes.This representation contains a minimal parametrization of allidentifiable information for the equivalence class. Equivalenceof aggregated Markov processes may be checked in a singledirect computation by converting the standard representationof the process to its canonical representation 206.B. Consistency and Asymptotic NormalitySuppose that an observation sequence was generatedby an identifiable HMP with true parameter . Letdenote the loglikelihood function ofthe HMP where is given by 4.8 for any . TheML estimator of is obtained from6.3This maximization is performed over all such thatis a distribution, is a stochastic matrix, and satisfy appropriate constraints implied by the nature of the observation conditional densities of the HMP. The additional constraintmust be imposed when represents a stationarydistribution of the Markov chain. This constraint, however, significantly complicates the maximization problem and is usuallyignored since the effect of is asymptotically negligible as wehave seen in Section IVC3.An estimator of is said to be strongly consistent ifa.s. 6.4Convergence in 6.4 is interpreted in the quotient topology generated by . This means that any open subset whichcontains the equivalence class of must also contain the equivalence class of for sufficiently large a.s. 214. Foran identifiable HMP with parameter , the equivalence class ofthe parameter comprises all points in induced by permutations of the states of the HMP. The equivalence relation wasdefined in Section IVA, and the compactified parameter setwas defined in Section IVD.Strong consistency of the ML estimator of the parameter of a finitealphabet stationary ergodic HMP was proved byBaum and Petrie 25, Theorem 3.4 and by Petrie 251, Theorem 2.8. Petrie relaxed the assumption that made in25. Strong consistency of the ML estimator of the parameter of a general stationary ergodic HMP was proved by Leroux214, Theorem 3. He assumed an irreducible aperiodic Markovchain and observation conditional densities that satisfy the mildregularity conditions noted in Section IVD.Consistency of the ML estimator was also proved for several extensions of standard HMPs under suitable conditions. Ineach case, consistency was shown using the corresponding ergodic theorem from Section IVD. Strong consistency of the MLestimators of the parameters of switching autoregressive processes satisfying 4.14 and 4.15, respectively, was proved byFrencq and Roussignol 127, Theorem 3 and Krishnamurthyand Rydn 198, Theorem 1. Recall that for a switching autoregressive process, the ML estimator is obtained from maximization of the conditional likelihood function noted in Section IVD. Weak consistency of the ML estimator of the parameter of an HMP, with a separable compact state space that is notnecessarily finite, was proved by Douc and Matias 90, Theorem2. The result applies to an HMP with arbitrary initial density,not necessarily a stationary density. Strong consistency of theML estimator of the parameter of a switching autoregressiveEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1541process, with a separable compact state space that is not necessarily finite, was proved by Douc, Moulines, and Rydn 91,Theorem 1. The switching autoregressive process need not bestationary. Strong consistency of the ML estimator of the parameter of a Markovmodulated Poisson process was proved byRydn 273, Theorem 1.Consistency of the ML estimator of the parameter of a finitealphabet HMP, when observations are drawn from a stationary ergodic process that is not necessarily the HMP, wasproved by Finesso 116, Theorem 2.2.1. This situation is described in the last paragraph of Section IVD. The parameter ofthe HMP was assumed to satisfy . Almost sure convergence of the set of maximizers of over , to theset of parameter values that minimize the relativeentropy rate between the observation processand the HMP , was proved. The relative entropy rate is defined similarly to 4.46 with replaced by .We turn now to asymptotic normality of the ML estimator. Assume that is consistent. Asymptotic normality ofthe ML estimator of the parameter of a stationary ergodicfinitealphabet HMP was proved in 1966 by Baum and Petrie25 assuming that . Asymptotic normality of the MLestimator of the parameter of a stationary ergodic generalHMP was proved in 1998 by Bickel, Ritov, and Rydn 36, Theorem 1. They assumed an irreducible aperiodic Markov chainand observation conditional densities that satisfy some mild regularity conditions. They showed thatweakly as6.5where is the Fisher information matrix which is assumednonsingular. This matrix is defined in terms of the score functionby 36, eqs. 5 and 6, Lemma 6where 6.6The ML estimator is therefore asymptotically efficient inthe sense of Lehmann 211, p. 404. The crux of the proof in36 is in establishing a central limit theorem for the score function and a law of large numbers for the observed information . The proof then followsfrom the classical approach introduced by Cramr. In provingthe limit theorems, the Markov chain given the observation sequence is seen as an inhomogeneous Markov chain,see, e.g., 5.21, and its mixing coefficients are bounded in termsof .Asymptotic normality of the ML parameter estimator ofa general HMP, using geometric ergodicity of an extendedMarkov chain, follows from the work of Le Gland and Mevel210 as described in Section IVC3. Asymptotic normalityof the ML parameter estimator of a general HMP with aseparable compact state space that is not necessarily finite,was proved by Jensen and Petersen 174, Theorem 3.3 andby Douc and Matias 90, Theorem 3. Jensen and Petersenassumed a stationary ergodic HMP and followed the proof ofBickel, Ritov, and Rydn 36. Douc and Matias relaxed thestationarity assumption by following the approach of Le Glandand Mevel 210. Asymptotic normality of the conditional MLparameter estimator, of a possibly nonstationary switchingautoregressive process, with a separable compact state spacethat is not necessarily finite, was proved by Douc, Moulines,and Rydn 91, Theorem 4 following the approach of Bickel,Ritov, and Rydn 36.Asymptotic normality of the ML estimator of the parameterof a general HMP was established only recently in 36 afterbeing an open problem for over 30 years. Local asymptotic normality of an ML estimator defined on a grid of the parameter setwas shown in 35. Consistency and asymptotic normality of apseudo ML parameter estimator of a stationary ergodic generalHMP were proved by Lindgren 219 and Rydn 274. The estimator maximizes a pseudo likelihood function obtained underthe assumption that consecutive blocks of consecutive observations are statistically independent. This likelihood function isgiven by6.7where is the density of given by 4.3. For an identifiable HMP, any can be chosen. Rydn refers to this estimator as the maximum split data likelihood estimator MSDLE.For an HMP with irreducible aperiodic Markov chain that satisfies some regularity conditions, the MSDLE is consistent andasymptotic normal for fixed and , and it performs asgood as the ML estimator 274. Lindgren 219 used butdid not consider estimation of the transition matrix. Francq andRoussignol 126 specialized these results to HMPs of the formdescribed in Section IVB1. A similar MSDLE estimator was proposed by Rydn 276 for estimating the parameter of a Markovmodulated Poisson process, and proved to beconsistent and asymptotically normal. Asymptotic block i.i.d.approximation of the HMP likelihood function was also founduseful in 238.C. The Baum AlgorithmThe Baum algorithm is a computationally efficient iterativealgorithm for local maximization of the loglikelihood functionin 6.3. It was developed and proved to converge byBaum, Petrie, Soules, and Weiss 28, 29 in the early 1970s. Itis the expectationmaximization EM algorithm of Dempster,Laird, and Rubin 80 when applied to HMPs. In this section,we present the Baum algorithm, discuss its relation to the EMalgorithm, and provide conditions for local convergence. We assume a general HMP with the usual parametrization.The rationale of the Baum algorithm is as follows 28, Theorem 2.1. Suppose that an estimate of the parameteris available at the end of the th iteration. Let denotesome other estimate of . Define an auxiliary function for thegiven observation sequence and any pair of parameters andin as follows6.81542 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002Using Jensens inequality6.9where expectations are taken over given . Equality in 6.9holds if and only ifa.e.A new estimate of at the iteration is obtained from6.10Since , the procedure results inas can be seen from 6.9. When , a fixed pointis reached and . The Baum algorithmstarts with an initial estimate and alternates between 6.8and 6.10 until a fixed point is reached or some other stoppingcriterion is met.Let  denote the mapping defined by 6.8 and6.10. Baum, Petrie, Soules, and Weiss 28, Theorem 3.1 andBaum 29 showed that if is strictly concave infor each and all , then is a singlevalued continuousmapping, and unless is a stationarypoint of or equivalently a fixed point of . Furthermore, all limit points of are stationary points of 28,Proposition 2.1. The logconcavity condition holds for normal,Poisson, binomia,l and gamma distributions among others, but itfails for the Cauchy distribution. Liporace 221 extended theseresults to elliptically symmetric multivariate densities which essentially are mixtures of Gaussian densities of which the Cauchydensity is a special case.The Baum algorithm is a particular instance of the EM algorithm of Dempster, Laird, and Rubin 80. The expectation stepEstep is given by 6.8 and the maximization step Mstepby 6.10. In the EM terminology, the state and observation sequences are the complete data while the observationsequence alone is the incomplete data. The likelihood function is written as6.11where6.12A wellknown consequence of Jensens inequality is thatfor any and in with equalityif and only if a.s. 80, Lemma 1.Hence, if maximizesover .Convergence of the EM algorithm was established by Wu316 using the global convergence theorem 226, p. 187. Inparticular, it was assumed that i the level set is compact for any with  iiis continuous in and differentiable in the interior of iii is continuous in both and  and iv all EMinstances are in the interior of . Under these conditions,it was shown in 316, Theorem 2 that all the limit points ofany instance of the EM algorithm are stationary points of, and converges monotonically tofor some stationary point . There exists at least one suchlimit point. The compactness assumption may be restrictivewhen no realistic compactification of the original parameterspace is possible. Continuity of is satisfied in mostpractical situations. It is guaranteed for the important familyof exponential KoopmanDarmois pdfs 211, p. 26, 316.Wu 316 provided conditions for other convergence theorems,in particular, convergence of limit points of to localmaxima of .The strict maximization of over in 6.10 isrelaxed in the generalized EM algorithm. Any that satisfiesthe weaker condition of is admissible. Conditions for local convergence of the generalized EMalgorithm were given in Wu 316, Theorem 1. The generalizedEM algorithm was found useful in estimating the parameter ofa Markovmodulated Poisson process 273. An EM algorithmwith an explicit Mstep for estimating the parameter of aMarkovmodulated Poisson process was developed by Rydn275.Note that in Section VIB we were concerned with convergence of the ML estimate sequence to the true parameterwhen the number of observations . Consistency theorems were provided for observation sequences generated by theHMP or by any other stationary ergodic process in the case of afinitealphabet HMP. In this section, we considered convergenceof an instance of the Baum algorithm, , for fixed andobservation sequence , when the iteration number .In this discussion, the observation sequence need not begenerated by the HMP as the EM algorithm can be applied toany observation sequence. When is generated by an HMPwith parameter , convergence of an EM instance asmay not be to the ML estimate of , since onlylocal convergence is guaranteed.1 The ReEstimation Formulas Maximization of the auxiliary function in 6.8 for a given observation sequence results in reestimation formulas for the parameter ofthe HMP. They generate a new parameter estimate from an oldparameter estimate. To demonstrate how the Baum algorithmworks, we shall provide here the reestimation formulas for twoimportant HMPs, those with Gaussian and Poisson observationconditional densities. In both cases, maximization of 6.8 overfor a given results in an explicit estimate at the endof the st iteration. The reestimation formulas require theconditional probabilities andwhich can be efficiently calculated as shown in Section V.EPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1543Using 4.8, the auxiliary function in 6.8 iswritten as 296.13Maximization of 6.13 over the distribution and thestochastic matrix gives6.146.15These reestimation formulas are intuitively appealing. The initial state probability estimate 6.14 is the conditional probability of the state given the observations. The estimate of thetransition probability in 6.15 is the ratio of the Cesro meanof the conditional probabilities of visiting state and then andthe Cesro mean of the conditional probabilities of visiting state. The conditional probabilities are calculated under the currentestimate of the HMP.The stationary distribution of the Markov chain is commonlyestimated as 2196.16For an HMP with Gaussian observation conditional densities,the reestimation formula for the mean vector is given by6.17The reestimation formula for the covariance matrix is givenby 6.18 shown at the bottom of the page. For an HMP withPoisson observation conditional pmfs, the reestimation formulafor the mean parameter is given by 6.17.D. Observed Information MatrixUnlike the Kalman filter, the Baum algorithm does notprovide the error covariance matrix of the estimated parameterin each iteration. While this matrix is an integral part of theKalman recursion, it is not needed by Baums reestimationformulas. An estimate of this matrix can provide some ideaabout the quality of parameter estimates obtained by the Baumalgorithm. The actual error covariance associated with theBaum algorithm is not known. For consistent ML estimation,however, it is known from 6.5 that the asymptotic errorcovariance is given by the inverse of the Fisher informationmatrix . An estimate of this matrix is given by the observedinformation matrix which is the negative Hessian matrix6.19Under some mild regularity conditions, the observed information matrix of a stationary ergodic HMP was shown by Bickel,Ritov, and Rydn 36, Lemma 2 to be a consistent estimate ofthe Fisher information matrix. Specifically, for any consistentestimate of it holds thatin probability6.20Louis 225 developed a formula for calculating from thecomplete data comprising the state and observation sequences.Let denote the complete data observed information matrixgiven by6.21Let denote the conditional complete data observed information matrix given by6.22The formula is given by6.23The formula follows from a relation between the score functionof the incomplete data and the scorefunction of the complete data .This relation is given by6.24where expectation is over given . The second term in6.23 can be written as6.25which implies its nonnegative definiteness. Hencein nonpositive definite.A method for calculating the observed information matrixof an HMP from 6.23 and 6.25 was proposed by Hughes166. The term was evaluated similarly toBaums auxiliary function 6.13 using the forwardbackwardformulas. From 6.24, for any local MLestimate of . The remaining term in 6.25is the hardest to calculate since it involves double summations6.181544 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002of crossproduct terms over pairs of states at distinct timeinstants. Hughes used the fact that the state sequence is a conditionally inhomogeneous Markov chain given the observationsequence, and provided some mild conditions for the sequenceto be mixing with exponentially decreasing coefficients. Thisenabled dropping crossproduct terms involving state variablesthat are well separated in time.The observed information matrix was calculated using MonteCarlo simulations by Diebolt and Ip 88 for general EM applications and by Turner and Cameron 303 for HMPs.E. Upper Bound on Likelihood of FiniteAlphabet HMPsAlgorithms for global maximization of the likelihood function over are not known for most interestingHMPs. An upper bound on the global maximum of the likelihood function exists for any finitealphabet HMP. The bounduses universal coding of the observation sequence and its nonvanishing term is independent of the number of states and theunderlying parameter . The bound is tight with high probabilityand hence can be used to assess the closeness of tothe global maximum of for any estimator .The upper bound is provided by the Ziv inequality which wasfirst derived for Markov chains in 329, see also 68, Lemma12.10.3. The bound was extended to finitealphabet HMPs byPlotnik, Weinberger, and Ziv in 253, p. 68. The bound is essentially given by where is the length of the binary codeword for in the LempelZiv universal data compression algorithm 326. This algorithm sequentially parses thesequence into distinct phrases of variablelength, and an additional, possibly incomplete, phrase thatmay coincide with one of the other phrases. Each phrasecomprises a concatenation of a phrase that appeared previouslyin the sequence and an additional symbol that distinguishes thenewly created phrase from any previously defined phrase. Forexample, the binary sequenceis parsed as whereand the first nine phrases are distinct. The number of phrasesdepends on the sequence and may be expressed more explicitly as . The length of the codeword for , or thenumber of bits required to represent in the LempelZiv algorithm, is given by . The algorithmasymptotically outperforms any finitestate coding scheme incompressing any individual sequence not necessarily from anHMP. It asymptotically achieves the entropy rate in compressing any stationary ergodic finitealphabet source, i.e., with probability as326, see also 68, Theorem 12.10.2. LempelZiv is the standard compression algorithm in UNIX and operating systems forPCs.The upper bound for any stationary ergodic finitealphabetHMP with states, letters, and parameter , and for anyobservation sequence , is given by 253, p. 686.26where denotes the binary entropy function given byforSince the number of phrases satisfies 326, eq. 4, 68, Lemma12.10.16.27where , the bound can be written as6.28where . Hence, uniformly for everyas . For , the bound becomes . Since6.28 holds for any , it also holds for the maximizingas follows6.29A partial converse to Zivs inequality is obtained as follows. Let6.30for some . From the Kraft inequality 68, Sec. 5.26.31Hence and the probability thatapproaches one as . Zivs inequality was used in manyapplications including order estimation 330 and source coding236 of finitealphabet HMPs. These applications are reviewedin Sections VIII and XIV, respectively.A stronger result holds for unifilar sources defined in Section IVE. From the analog of 4.50 for unifilar sources6.32where is the conditional empirical entropy defined in4.51 for a given nextstate function . If is not known, thelefthand side of 6.32 is maximized over . There aresuch functions for a unifilar source with states and letters330.VII. JOINT STATE AND PARAMETER ESTIMATIONIn this section, we review joint estimation of the state sequence and the parameter of an HMP. We first describe theBaumViterbi algorithm and its relations to the Baum algorithmand to the generalized Lloyd algorithm for designing vectorquantizers. The relation of the BaumViterbi algorithm to theminimum discrimination information parameter estimation approach is given in Section XIVB. We then present a noniterativealgorithm for global maximization of the joint likelihood function of a leftright HMP. We conclude by reviewing BayesianGibbs sampling approaches.EPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1545A. The BaumViterbi AlgorithmThe BaumViterbi algorithm jointly estimates the parameterand state sequence of an HMP. The state sequence is estimated inthe minimum probability of error sense by the Viterbi algorithm.Recall that the Baum algorithm uses the state conditional probabilities in estimating the parameter. When the states are considered unit vectors in a Euclidean space, these conditional probabilities are the MMSE estimate of the state. The BaumViterbialgorithm was proven useful when the observations are vectorsof sufficiently high dimension. In that case, the BaumViterbialgorithm provides parameter estimates that are almost as goodas those obtained by the Baum algorithm. The algorithm hasan intuitive appeal and is computationally more stable than theBaum algorithm. The two algorithms require about the sameamount of computation.When the observations of the HMP are scalar, or vectors offixed dimension, say , the BaumViterbi algorithm providesinconsistent estimates of the state sequence and parameter asthe number of observations . This was shown in 51,299 for mixture processes which are special cases HMPs. Theasymptotic mode considered here of and fixed is motivated by applications in automatic speech recognition whereHMPs with vector observations of relatively large dimensionsare often used and estimation is performed from a fixed numberof observations. The reason for using vector observations is thatstates representing articulatory cues mix at significantly lowerrate than the sampling rate of the signal itself which is typicallyabout 8000 Hz. Thus, the state process of a speech signal hassignificantly lower bandwidth than that of the signal itself.The BaumViterbi algorithm was first introduced in 1976by Jelinek and his colleagues at IBM 172 and was termedViterbi extraction. The algorithm was further studied byRabiner, Wilpon, and Juang 261, 262, 176, where it wasreferred to as segmental means. Asymptotic equivalenceof parameter estimates obtained by the Baum algorithm andby the BaumViterbi algorithm for fixed and wasshown by Merhav and Ephraim 234. We opted for the nameBaumViterbi since each iteration of the algorithm involvesBaums reestimation iteration and application of the Viterbialgorithm.Consider an HMP with vector observations , ,and true parameter . The BaumViterbi algorithm estimates from7.1where the double maximization is alternately performed overand . For a given parameter estimate at the endof the th iteration, the most likely state sequence is estimatedby maximizing over . This maximization isperformed using the Viterbi algorithm. Let denote themaximizing state sequence. Next, a new estimate of theparameter is obtained by maximizing over. The alternate maximization procedure produces a sequence of estimates with nondecreasing joint likelihoodvalues. The algorithm is terminated if a fixed point is reachedor when a stopping criterion is met. Local convergence of thealgorithm can be established in a manner similar to that usedfor the EM algorithm 316, 176. Note that a byproduct ofthe algorithm is an estimate of the most likely state sequence.This is analogous to the byproduct of conditional state probabilities given the observation sequence provided by the Baumalgorithm.Maximization of over is equivalent tomaximizing the auxiliary function7.2where is the Kronecker delta function that is equal to onewhen and is zero otherwise. Recall that in theBaum algorithm, a new estimate is obtained from maximization over of the auxiliary function7.3Comparing 7.2 with 7.3 shows that in the BaumViterbi algorithm can be obtained from the reestimationformulas of the Baum algorithm by substitutingby . These formulas are given by 6.14, 6.15and by 6.17, 6.18 for HMPs with Gaussian observationconditional densities. The reestimation formulas for theBaumViterbi algorithm are rather intuitive. For example, theestimate for is the ratio between the number of transitionsfrom state to and the number of transitions from state toany other state on the most likely sequence . Similarly,the new estimate for the mean and covariance matrices of theGaussian density in the th state are obtained from sampleaverages of observation vectors assigned to state by .Alternatively, the observation vectors in are clusteredinto subsets by the most likely sequence and theparameter of the observation conditional densities are obtainedfrom these clusters.It follows from 7.2 and 7.3 that the Baum algorithm andthe BaumViterbi algorithm yield the same sequence of estimates when started from the same initial estimate if7.4for every . Convergence of toa.s., when , was proved in 234. It was assumedthat the transition matrix satisfies , and an ergodictheorem holds for for any . The required ergodic property was demonstrated in 234 for HMPswith Gaussian observation conditional densities. The requiredergodic theorem under more general conditions is implied from4.39. The result is not surprising since states are detectablewhen a sufficient number of consecutive observations is available from each state. When , the most likely state sequence is given by7.5for any parameter .Bounds on the loglikelihood difference resulting from 6.3and 7.1 were derived in 234. Let denote the maximizer overof and let denote the maximizer over1546 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002of . Let denote a sequence of dimensionalobservation vectors and let denote the total number ofobservations. Then7.67.7Thus the difference between the normalized likelihood valuesassociated with and can never exceed . Thisbound can be made sufficiently small compared to the likelihoodvalues if . This is often the situation in isolatedwordspeech recognition applications where typically  and 234. Note that these inequalities are not sufficient to guarantee closeness of the parameter estimates obtainedby the Baum and the BaumViterbi algorithms, since both algorithms perform local rather than global maximization. Moreover, these inequalities do not imply that a dominant state sequence exists since they hold even when all state sequences areequally likely.A theoretical approach for a sequential BaumViterbi algorithm was proposed by Kogan 191. The approach is based onthe observations that stopping times for the most likely state sequence appear infinitely often if the Markov chain is irreducibleand aperiodic, and the most likely state sequence at time instantssmaller than the stopping time is independent of future observations.B. The Generalized Lloyd AlgorithmThe BaumViterbi algorithm is closely related to the generalized Lloyd algorithm for designing vector quantizers for parametric processes 135, 234. The generalized Lloyd algorithmis also known as the LindeBuzoGray LBG algorithm 218.A vector quantizer partitions the parameter set of a process into afinite number of cells, say , and chooses a parameter representative from each cell. The design of vector quantizers requires adistortion measure that quantifies the similarity of one parameter with respect to another. In the context of this section, thedistortion measure is between a vector of the process, whichhas some underlying parameter, and a parameter . Avector quantizer is designed by minimizing the expected valueof the distortion measure over all partitions and parameter representatives. The generalized Lloyd algorithm performs this minimization iteratively, once over the partition for a given set ofparameter representatives, and then over the parameter representatives using the estimated partition. The process proceedsuntil a fixed point is reached or otherwise a stopping criterion issatisfied. In practice, the expected value of the distortion measure is replaced by the sample mean of a training sequence ofobservations. Convergence properties of the generalized Lloydalgorithm were established by Sabin and Gray 283. A comprehensive overview of quantization theory and its applicationscan be found in Gray and Neuhoff 153.An important application of vector quantization is in codingof speech signals in cellular communication. The signal is modeled as an autoregressive process with a timevarying parameter.A finite number of parameter representatives is estimated andused in encoding the speech signal at a relatively low bit rate135, pp. 387393, 259, Sec. 10.4.The relation of the BaumViterbi algorithm to the generalized Lloyd algorithm becomes clear when is large andis interpreted as the distortion measurebetween the vector and a parameter . Almost sureconvergence of when is impliedfrom 4.39. It was demonstrated in 234 for HMPs withGaussian observation conditional densities where explicitexpressions for the limit were given. This distortion measuremay take negative values but this does not affect the generalized Lloyd algorithm as long as the distortion is greater than. Let denote a training sequence of dimensionalobservation vectors. Assuming and large , thesample mean of the distortion measure is given by7.8Estimation of by the iterative BaumViterbi algorithm is equivalent to estimating these components of theparameter by minimizing the average distortion in the lefthand side of 7.8. The most likely state sequence 7.5 in theBaumViterbi algorithm provides the optimal partition or classification of the vectors in the generalized Lloyd algorithm.This, in turn, provides the optimal partition of the underlying parameter space of these vectors. This partition rule is referred toas the nearest neighbor rule in vector quantization terminology.Estimation of each by minimizing the average of the distortion measure over all vectors assigned to the th state, as in theBaumViterbi algorithm, provides the best parameter representative in the generalized Lloyd algorithm. This estimate is referred to as the centroid of the partition cell in vector quantization terminology. Thus, each iteration of the BaumViterbi algorithm parallels an iteration of the generalized Lloyd algorithm.Note that the generalized Lloyd algorithm provides estimates ofthe parameter of the observation conditional densities only. Anestimate of the transition matrix can be found from the nearestneighbor state sequence 7.5 as in the BaumViterbi algorithm.C. Initialization of the Baum AlgorithmThe likelihood function of an HMP may have multiple localmaxima while the Baum algorithm converges at best to a localmaximum in the neighborhood of the initial guess of the parameter. Local convergence was demonstrated in 95 for a binaryHMP with a binary Markov chain. Initialization of the Baum algorithm has therefore a significant impact on the optimality ofthe parameter estimate.Several initialization strategies were proposed. For HMPswith ordered states that are allowed selftransitions and nextstate transitions only, commonly used in automatic speechrecognition applications, it was suggested to segment theacoustic signal from each word into segments of approximately equal length, and to estimate the parameter of each statefrom the observations in the corresponding segment 262.For HMPs with , the generalized Lloyd algorithm maybe used to cluster the observations into sets from whichthe parameter of the HMP can be estimated. The generalizedEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1547Lloyd algorithm applies to scalar as well as vector observationprocesses. Similar clustering techniques for initialization ofthe Baum algorithm were proposed in 212 and 232, Sec.1.7. Simulated annealing may also be used as discussed inSection VIIE.D. Global Likelihood Maximization for LeftRight HMPsAn HMP is said to be leftright if its transition matrix isan upper triangular matrix. An HMP is said to be linear if itstransition matrix has nonzero entries only on the main diagonaland first offdiagonal. In this subsection, we present a noniterative algorithm for global maximization of overand for a leftright HMP. The algorithm was developedby Fareg and Lugosi 111 in 1989 for a finitealphabet HMPbut it applies to a general HMP as well. Parameter estimationfor a leftright HMP can be reduced to parameter estimationof a linear HMP 111. Hence it suffices to describe the algorithm for a linear HMP. The practical importance of leftrightHMPs is discussed in Section XIVA. The rationale for maximizing was detailed in Section VIIA. The keyidea of this algorithm is that the state sequence in a linear HMPis uniquely determined by the state occupancy durations. Globalnoniterative maximization is achieved by explicit estimation ofthe parameter of the HMP for a given state sequence, and substituting that estimate back in the likelihood function. The resulting likelihood function depends only on the state occupancy durations. This function is maximized by the Viterbi algorithm which is applied to a specially constructed trellis scheme.Assume that the number of states is smaller than thelength of the observation sequence  otherwise, the estimationproblem is trivial. Furthermore, consider only state sequencesthat start in the first state and end in the last state ,since higher likelihood cannot be achieved with partial statesequences. For a linear HMP, if . Let. Let denote the number of time units the chainspends in state . The probability of spending time units instate and then moving to state is .Hence, the pmf of a state sequence is given by7.9Let denote the total number of time unitsspent in the first states. Thus, , where. The sequence of observations from state is given by, and by assumption, these random variablesare statistically independent. In addition, observations fromdifferent states are also statistically independent. Hence7.10From 7.9 and 7.107.11The parameter is estimated from maximization of 7.11, firstover , and then over . The maximization over can beindependently performed for each . Maximizing over gives7.12where . Estimation of depends on the specific formof the observation conditional density. For an HMP with finitealphabet of letters, maximization of 7.11 over the statetoobservation transition matrix gives7.13where denotes the relative frequency of occurrences of the symbol in the sequence . Substituting 7.12 and 7.13 in 7.11 gives7.14Maximization of 7.14 over provides the optimal valuesthat can be used in 7.12 and 7.13 to obtain the parameterthat globally maximizes . A detailed algorithm isprovided in 111 that shows how maximization of 7.14 canbe performed using the Viterbi algorithm.The algorithm extends to parameter estimation from multiple statistically independent training sequences that share acommon state sequence. Parameter estimation from multipletraining sequences with no restrictions on their individual statesequences does not appear feasible with this noniterative approach. Estimation from multiple training sequences is essential for leftright HMPs and is commonly performed when theBaumViterbi algorithm is used in applications such as automatic speech recognition.E. Bayesian Parameter EstimationBayesian estimation of the parameter of an HMP was studiedby Robert, Celeux, and Diebold 269. The approach generalizes Bayesian estimation of mixture processes 87, 270. It isbased on Gibbs sampling of the parameter which is assumedrandom with a given prior. Usually conjugate priors are used.In 269, the rows of the transition matrix were assumedstatistically independent and a product of Dirichlet priorswas assumed. The observation conditional densitieswere assumed members of the exponential family for whicha conjugate prior for each exists. The parameter can, inprinciple, be estimated by sampling from the conditional density of the parameter . This, however, appears impractical as this conditional density involves the sum of an exponentially growing number of terms with . On the other hand,sampling from is much simpler since this densityconstitutes only one term of that sum. Thus, the Gibbs samplingapproach proposed in 269 is based on alternative samplingsfrom and from . The first sampling produces an estimate of the parameter which is then used in the1548 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002second sampling to estimate the state sequence . Further simplification was obtained by performing samplings for eachfrom7.15instead of a single sampling from which requiresforwardbackward recursions. The Gibbs sampling algorithmproduces a sequence where and denote, respectively, the parameter and state sequence estimatesat the end of the th iteration.Convergence properties of the Gibbs sampler were studiedin 269 and a summary of the results was also given byRydn and Titterington 280. It was shown that the sequenceis geometrically ergodic mixing homogeneousMarkov chain with a unique stationary distribution given by. The sequence is geometrically ergodicmixing Markov chain with a unique stationary distributiongiven by . The sequence , which is not a Markovchain, is ergodic, mixing, and converges weakly asat geometric rate to a stationary distribution given by .It follows from 269, Theorem 1 that the conditional expectation of any function of the parameter , given , canbe approximated by the corresponding sample average froma realization of . A central limit theorem for such anaverage is given in 269, Corollary 2.A simulated annealing approach for estimating the parameterof an HMP was developed byAndrieu and Doucet 13. Eachiteration of the algorithm includes the above described iteration and an additional step which aims at accepting or rejectingthe new parameter estimate. The decision is based on a probabilistic scheme involving a deterministic cooling schedule. Convergence in probability of to where is aMAP estimate of was shown under some mild regularity conditions.A Bayesian approach for iterative estimation of the parameterof a switching autoregressive moving average ARMA processwas developed by Billio, Monfort, and Robert 39. Several versions of the Gibbs sampler presented earlier, that are particularlysuitable for hidden Markov fields, were studied by Qian and Titterington 260 and by Rydn and Titterington 280. Here sampling is performed from a tractable pseudolikelihood functionof the underlying Markov process. Reparametrization of HMPswith Gaussian and Poisson observation conditional densities,using less informative priors, was studied by Robert and Titterington 271.VIII. ORDER ESTIMATIONThe order is the number of states of the HMP. Algorithms forestimating the parameter of an HMP assume that the order isknown. In many applications this is not the case. For example,in blind deconvolution of unknown communication channels,the received signal is an HMP, but its order determined by thememory length of the channel is not known. This application isfurther discussed in Section XIVC. In addition, HMPs are notidentifiable if their order is overestimated 116, 156, Ch. 22,282. Informationtheoretic approaches for order estimation ofa finitealphabet HMP were developed by Finesso 116, Zivand Merhav 330, Kieffer187, and Liu and Narayan 223. Anorder estimation approach for a general HMP was developed byRydn 277. These approaches are reviewed in this section.Let be the true order and let be the true parameter ofan HMP . Let denote an estimate of from an observation sequence . Let denote the parameter of an HMPwith assumed order . Let denote the parameter set. For afinitealphabet HMP of assumed order and parameter in ,we denote the parameter set by . Also, denotes the sizeof the alphabet. Let , , denote the sequence ofnested HMP densities. All but the order estimator of 223 usethe ML estimate of . Let8.1The order estimator for a finitealphabet HMP proposed byFinesso is given by 1168.2where is the ML estimator over andThis penalized ML estimator was proved strongly consistent when and , whereis defined in 4.40 116, Theorem 4.5.2. Theorder estimator uses an estimate of the rate of growth of themaximized loglikelihood ratio whichwas found to be in the order of a.s. 116, Theorem 4.4.1.The order estimator for a finitealphabet HMP proposed byZiv and Merhav was derived using a NeymanPearson typecriterion 330. It minimizes the underestimation probability, uniformly for all HMPs in , subject to anexponential decay of the overestimation probability given by8.3for all HMPs in . The estimator is given by8.4where is the length of the binary codeword for in theLempelZiv universal data compression scheme. This lengthfunction was defined in Section VIE. If is interpreted as a modelbased codeword length for 68, p. 85, then8.4 seeks the shortest modelbased binary codeword lengththat is sufficiently close to the universal codeword length .Alternatively, using Zivs inequality 6.28, the order estimator8.4 is a likelihood ratio test in which is replaced by . Unlike some other estimators presented in thissection, 8.4 does not require knowledge of an upper bound onthe order .It was pointed out in 223, 187 that the estimator 8.4tends to underestimate the order of the HMP and hence is notconsistent. Liu and Narayan 223 proposed a slightly modified estimator and proved its consistency for a stationary ergodic HMP that satisfies some mild regularity conditions. Theestimator assumes knowledge of an upper bound on .It uses the binary codeword length for encoding inEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1549the WynerZiv asymptotically optimal universal compressionscheme 319. The estimator is given by8.5provided the set is not empty, otherwise, . The sequencemust satisfy and . Theestimator is strongly consistent if and isweakly consistent otherwise.Liu and Narayan 223 proposed another strongly consistentorder estimator for a stationary ergodic finitealphabet HMP.They assumed that the parameter is random with prior , andthe pmf of is the mixture8.6Dirichlet priors were assumed for the entries of and . Estimation of in terms of relative frequencies of states andobservation symbols is outlined in 223, Appendix. AvoidingML estimation is desirable since only local ML estimation procedures are available. The mixture model 8.6, however, is nottrivial to estimate. Aspects of data modeling in the minimum description length MDL sense using mixture densities and MLestimated parameters were studied by Barron, Rissanen, and Yu24. They provided sufficient conditions for asymptotic equivalence of the two approaches. The order estimator of Liu andNarayan 223 is given by8.7where and . If the setin 8.7 is empty then . This estimator provides exponentially decaying underestimation probability and polynomially as  decaying overestimation probability.Kieffer 187, Theorem 2 proposed a codebased order estimator for a class of stationary ergodic constrained finitestatesources and proved strong consistency of the estimator. Stationary ergodic finitealphabet HMPs are special cases of thatclass. Let denote a code designed for source sequences.The code is a mapping of source sequences into binarystrings such that is not a prefix of if andare two distinct sequences. Let denote the length ofthe binary string . Kieffer used ML codes whoselengths are determined by . The estimator isgiven by8.8where is a subsequence of the positive integers that satisfies and forand all . For sufficiently large , this estimatortakes the approximate form8.9where is a nondecreasing sequence of positive constantsthat is determined from the model classes . This estimator resembles the MDL codebased order estimator of Rissanen 267 or the Bayesian information criterion BIC basedorder estimator derived independently by Schwarz 287. TheMDL order estimator uses a code for the class whose expected redundancy grows at the minimum possible rate for almost all sequences modeled by members of . This resultsin positive constants for all . It is noted that relativelysmall penalty terms may not provide consistent order estimatorsas overfitting of the data may prevail. Sufficient conditions forconsistency of the MDL order estimator and examples of modelclasses for which the MDL estimator is consistent were givenby Kieffer 187, Barron, Rissanen, and Yu 24 and Csiszr andShields 74.Rydn 277 proposed an order estimator for a stationaryergodic general HMP. The estimator is based on the MSDLEobtained from maximization of in 6.7. When theHMP is identifiable, in particular, when all are distinct,any may be used and there is no need for an estimateof the largest possible order of the HMP. Otherwise, an upperbound on is required, and must be used, sincefinitedimensional distributions of the HMP are uniquely determined by the dimensional distribution 277, Theorem 1.The order estimator is given by8.10where is the maximizer of over , andis a nondecreasing sequence of real numbers that penalize thelikelihood and thus prevent overestimation of the model order.When is required, maximization in 8.10 is overwhere denotes an integer part. The sequence satisfies for all and . Underthese and some additional regularity conditions, it was shownin 277, Theorem 2 that the estimator 8.10 does not underestimate the order of the HMP asymptotically as ,with probability one. The regularity conditions hold, for example, for HMPs with observation conditional densities fromthe Poisson, negative exponential, and normal with fixed variance families. The conditions on are satisfied by the penalizing terms used in the Akaike information criterion AIC 4and in MDL 267 or BIC 287. Thus, these estimators neverunderestimate the HMP order when is sufficiently large. TheAIC choice is and the BIC choice iswhere denotes the dimensionof the parameter space of the thorder HMP. An earlier similarresult on order estimation of mixture processes obtained frommaximization of a penalized likelihood function was proved byLeroux 213, Theorem 4. Additional references on consistentorder estimators for mixture processes can be found in Rydn277.IX. DYNAMICAL SYSTEM APPROACHWe have seen in Section IVB6 that a finitealphabet HMP hasa dynamical system representation in the sense of control theory.Similar representations exist for other types of HMPs with discrete as well as continuous time and discrete as well as continuous range state and observation processes. Elliott, Aggoun, andMoore 99 provide a comprehensive study of HMPs in the dynamical system setup. They develop conditional mean estimators for the states, the number of jumps from one state to another,the state occupation time, and for some statistics reflecting the1550 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002assignment of observations among the various states. The estimators are then used in the EM algorithm for ML estimationof the parameter of the HMP. As is well known, conditionalmean estimation of continuoustime signals usually results in infinitedimensional filters for nonlinear nonGaussian problems.The book 99 contains almost all known estimation problemsfor which finitedimensional conditional mean estimators exist.In this section, we demonstrate the approach for a discretetimeHMP with Gaussian observation conditional densities. The approach requires forward recursions only. Its main advantage isthat it generalizes to continuoustime HMPs.Application of the EM algorithm for estimating the parameterof a discretetime dynamical system using Kalman smootherswas first performed by Shumway and Stoffer 292. The approach was then expanded by several authors. Zeitouni andDembo 324 studied finitestate continuoustime Markovchains observed in white noise. They developed a finitedimensional conditional mean causal estimator for the numberof jumps from one state to another. The estimator was used inan extended EM algorithm for ML estimation of the transitionmatrix of the Markov chain. The extension of the EM algorithmto continuoustime processes and its convergence propertieswere established by Dembo and Zeitouni 77. They also appliedthe EM algorithm to a wide class of diffusion processes whichresulted in iterative applications of finitedimensional Kalmansmoothers. A finitedimensional conditional mean causal estimator for the states of the chain was first developed by Wonham315. Finitedimensional conditional mean estimators for thestate occupation time and for a stochastic integral related to thedrift in the observation process were derived by Elliott 98.MAP estimators of a randomly, slowly varying parameter, ofa continuoustime and a discretetime ARMA processes, weredeveloped by Dembo and Zeitouni in 78 and 79, respectively.ML estimation of the parameter of a discretetime dynamicalsystem using Kalman filters rather than smoothers in conjunctionwith the EM approach was developed by Elliott and Krishnamurthy 100. Robust time discretization of the continuoustimefilters and smoothers for estimating the parameter of an HMPwas studied by James, Krishnamurthy, and Le Gland 168.The central theme in 99 is to derive conditional mean estimators for statistics of the HMP which are required for MLestimation of its parameter by the EM algorithm. The conditional mean estimators are developed using a generalized Bayesrule. This is a standard technique used, for example, in 324.This rule, or formula, enables evaluation of a conditional meanunder one probability measure using another more convenientprobability measure. This is done as follows. Let betwo probability measures on the measurable space . Let, , denote the RadonNikodymderivative or density of with respect to . Let denote a sub field of . Let denote a random variable on. Let denote the desired conditional mean ofunder . Let denote the conditional mean ofunder . The generalized Bayes rule 247, Lemma 8.6.2, orthe KallianpurStriebel formula 222, Lemma 7.4, is given by9.1for all such that , otherwise, canbe arbitrarily chosen. The approach can be applied when isthe probability measure of the HMP and is the probabilitymeasure of an i.i.d. process that is independent of the Markovchain. The approach is demonstrated here for a discretetimeHMP with Gaussian observation conditional densities. Our discussion follows 99, Ch. 3.Let denote a sequence measurable space whereis the set of all state and observation sequences, and denotes the Borel product field. Let bethe distribution of the HMP on . For the Markovchain we use the same representation as in 4.19. Specifically,we assume a Markov chain with state spacewhere is a unit vector in , a transition matrix , and a stationary martingale difference sequence .The observation process is characterized by a sequenceof i.i.d. standard Gaussian random variables independentof , and two dimensional vectors and representingthe means and standard deviations of the Gaussian observationconditional densities in the states. All components of areassumed positive. The dynamical system representation of theHMP under is given by9.2Let denote a second distribution on . Under ,has the same distribution as under , is an i.i.d.sequence of standard Gaussian random variables, and andare statistically independent. The dynamical system representation of the HMP under is given by9.3Let and denote the dimensional distributionsinduced by and , respectively. Clearly, andpossess densities with respect to , where here isthe Lebesgue measure, and . Let anddenote the dimensional densities corresponding to and, respectively. Assume that . The RadonNikodym derivative of with respect to is given by9.4where anddenotes the standard normal pdf.To state the generalized Bayes rule for the systems 9.2 and9.3 let denote the smallest field generated by . The sequence forms a filtration.EPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1551Similarly, let denote the smallest field generated by . Let be a sequence of scalar integrable randomvariables adapted to . From 9.19.5This equation can be verified using the first line of 9.4 without resorting to measure theoretic arguments. We emphasizethat and are statistically independent under . In amore general situation of a finiteenergy continuoustime continuousrange signal observed in white noise, the RadonNikodym derivative of with respect to is given by Girsanov theorem 222, Theorem 6.3, 247, Theorem 8.6.3. Thisform involves a stochastic integral.Let9.6be the nonnormalized version of and rewrite 9.5as9.7It is easier to derive recursions for than for. Hence, 9.7 is the basic equation we shallbe working with.Of interest are special cases of that provide sufficient statistics for an EM iteration in ML estimation of the HMP parameter. These are as follows.i . This is the number of jumps from state tostate during transitions of the chain. It is given by9.8ii . This is the occupation time of state inchain transitions given by9.9iii , for some deterministic function .This random variable represents the sum of elementsof assigned to state duringtransitions of the chain. Of interest here are the functionsand . is defined by9.10It turns out that a recursion for the dimensional vectorcan be developed from which the desiredcan be obtained simply by taking the inner productwhere denotes an vector of s. We shall thereforefocus on the development of the recursions for calculatingfrom for . This will alsoprovide a recursion for estimating the state vector at timesimply by assigning in . A general recursionfor when is any of the above definedfour random variables was given in 99, Theorem 3.5.3. Therecursion is given in terms of and9.11Note that depends on the observation aswell as the parameter of the HMP. It constitutes the productof the thunit vector and the last multiplicative term offor . The identity wasfound useful in deriving the recursions. For example, using thisidentity and the state equation from 9.3, it is easy to verify thefollowing recursion for estimating the state vector9.12The recursions for estimating the other statistics represented byare given by9.139.149.15These recursions can now be used to obtain the conditionalmean estimates . For we use 9.12to recursively calculate9.16Note that is the vector of nonnormalized conditional probabilities of given since is thedimensional vector whose th component is. Equations 9.12 and 9.16 coincide with 5.14. Asmoothed estimator for was derived in 99, eq. 3.6.2. Forwe use 9.13 to recursively calculate9.171552 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002Estimation of the other two random variables andcan be performed similarly from 9.14 and 9.15,respectively.Estimation of the parameter of the HMP 9.2 from observations can be iteratively performed using the EM algorithm.In the context of this section, the parameter in each iteration canbe estimated from maximization of the following function over779.18This function is analogous to the righthand side of 6.9. Theusual parametrization is assumed. Maximization of 9.18 subject to natural constraints gives the following estimates at theth iteration. For9.199.209.21The recursions for estimating , , , andare calculated based on the available parameter and a fixednumber of observations . These reestimation formulas maybe interpreted similarly to the reestimation formulas 6.15,6.17, and 6.18, respectively. Note that only forward recursions are used in 9.199.21. Furthermore, the parameter estimates can be straightforwardly updated when the number ofobservations is increased from to .X. RECURSIVE PARAMETER ESTIMATIONRecursive estimation of the parameter of an HMP is of greatpractical and theoretical importance since one always wishesto be able to update the parameter estimate when new observations become available. Consider, for example, hidden Markovmodeling of speech signals in automatic speech recognitionapplications. Here, an affirmative human feedback can be usedby the recognizer to improve the modeling of a particular wordusing the speech utterance entered by the user. This, of course,could not be done with the Baum algorithm which requires theentire observation sequence in each iteration. Recursive estimation is also desired when adapting to timevarying parameter ofan HMP. This situation occurs in automatic speech recognition,neurophysiology, and data communications when the underlyingHMP changes with time. These applications are discussed inSection XIV. Recursive estimation may also be computationallymore efficient and require less storage than the Baum algorithm.Recursive estimation of the parameter of an HMP was studiedas early as 1970 by Kashyap 182. A stochastic descent recursion was developed for estimating the transition matrix ofa Markov chain observed through arbitrary noise with independent samples and some unknown finite variance. Convergenceof the recursion with probability one and in mean square wasshown under some conditions.With the introduction of the EM algorithm in 1977 there hasbeen renewed interest in recursive estimation from incompletedata. Although HMPs fall into this category, recursions for general incomplete data models are not immediately applicable toHMPs. Recursions for parameter estimation from incompletedata often aim at least at local minimization of the relative entropy10.1over where is the true parameter. The relative entropyattains its global minimum of zero for . To describe arecursion with this goal, letdenote the score function and let denote a matrix of suitabledimension. The recursion has the form of10.2where the specific form of the adaptive matrix significantlyaffects convergence properties of the recursion. Of particular interest is the inverse of the information matrix for the incompletedata given by . For, and under suitable regularity conditions, the recursion can be shown to be consistent asymptotically normal andefficient in the sense of achieving equality in the CramrRaoinequality 110, 281. Rydn 281 showed that some of theseconditions, however, do not hold for mixture processes andhence cannot hold for HMPs. The recursion 10.2 withis also difficult to implement since explicit form ofthe incomplete data information matrix is rarely available.Titterington 300, eq. 9 proposed to use instead the information matrix for the complete data. The recursion was relatedto an EM iteration and proved under some conditions to beconsistent and asymptotically normal for i.i.d. data. Thisrecursion, however, is never efficient and its convergence formixture processes was not proved 281. Weinstein, Feder, andOppenheim 310, eqs. 1921 derived a similar EM relatedrecursion for stationary ergodic processes but did not study itsproperties.Another recursion with the same goal of minimizing the relative entropy 10.1 proposed in 310, eq. 4 is given by10.3where the sequence satisfiesandEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1553It was suggested that may be calculated from thecomplete data using a onedimensional version of the identity6.24 given by10.4For HMPs, the alternative 10.4 does not offer computationalsavings over direct calculation of using 4.5, particularly when estimating the transition matrix of the Markovchain. Another form for calculating , presentedbelow, is more suitable for HMPs. It was argued in 310 thatthe recursion 10.4 is consistent in the strong sense and in themeansquare sense for stationary ergodic processes that satisfysome regularity conditions. Some of these conditions, however,are in general violated for i.i.d. observations from a finitemixture density and hence by HMPs 279, 281. This problemcan be circumvented if minimization of is constrained toa compact convex subset by projecting onto ineach iteration 279, 281. Of course, . The estimator10.3 with , , is asymptotically efficient if postaveraging of parameter estimates is applied 281.A consistent asymptotically efficient estimator in the sense of211, p. 404 for i.i.d. data with better finitesample propertieswas proposed by Rydn 281, Theorem 3. The estimator hasthe form of 10.2, where is an empirical estimate of theincomplete data information matrix and parameter estimatesare recursively projected onto . These ideas were also founduseful for HMPs as will be seen shortly.Holst and Lindgren 163, eq. 16 first proposed a recursionof the form of 10.2 for estimating the parameter of an HMP.They used10.5and an empirical estimate of the incomplete data informationmatrix in the form of the adaptive matrix10.6The conditional expectation in 10.5 is overgiven , and it can be efficiently calculated using a forwardrecursion form Section VA. Note that does not equaland hence is not a score function. Evaluation of is done recursively from andwithout matrix inversion 163, eq. 14. Rydn 279 argued thatthe recursion of Holst and Lindgren aims at local minimizationof the relative entropy rate defined in 4.41. Moreover, he showed that if , then isasymptotically normal with zero mean and covariance matrixgiven by the inverse of .Lindgren and Holst 220 applied the recursion for estimatingthe parameter of a Markov modulated Poisson process. Holst,Lindgren, Holst, and Thuvesholmen 164 applied the recursionfor estimating the parameter of a switching autoregressiveprocess with Markov regime. Krishnamurthy and Moore 195,eq. 3.18 applied similar ideas to recursive estimation of aMarkov chain observed in white Gaussian noise.Rydn 279 proposed a recursion for estimating the parameter of an HMP which does not use the adaptive matrix .The recursion uses vectors ofsuccessive observations, and a projection into a set .Let denote the score function whereis the dimensional density of the HMP given in 4.3.The recursion is given by10.7where for some and . The setis assumed a compact convex subset of which contains ,it is the closure of its interior, can be written asfor some finite set of continuously differentiable functions, and at each , the gradients of the activeconstraints i.e., those functions with  are linearlyindependent. The simplest that satisfies these requirements isa simplex whereas all functions are linear.Rydn 279 studied statistical properties of 10.7 assuminga stationary irreducible aperiodic Markov chain and some additional mild regularity conditions. These conditions are satisfied by many important parametric densities including normaldensities with positive variances. The sequence generatedby 10.7 was shown to converge almost surely to the set ofKuhnTucker points for minimizing the relative entropy10.8over the set 279, Corollary 1. The relative entropy attainsits global minimum at provided that the HMP is identifiable. Conditions for identifiability were given in Section VIAwhere in particular is required. The behavior of the relative entropy is otherwise not known and the set may containother points. If the procedure is initialized sufficiently close tothe true parameter then is expected to converge to withhigh probability. Assuming that , and some mild regularity conditions are satisfied, it was shown in 279, Lemma 2,Theorem 2 that the averaged estimator10.9converges at rate and has similar asymptotic propertiesas the offline MSDLE obtained from maximization of 6.7.The latter estimator is asymptotically normal and it performssimilarly to the ML estimator 274.A recursion for HMP parameter estimation using predictionerror techniques was proposed by Collings, Krishnamurthy, andMoore 64 and demonstrated empirically to provide fast convergence.1554 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002XI. SIGNAL CLASSIFICATIONIn recent years, a series of papers on universal classificationof Markov chains was published. Ziv 328 studied testing of asimple hypothesis from which a training sequence is availableagainst a composite hypothesis in the set of all Markov chainsup to a given order. He developed an asymptotically optimaltest in the NeymanPearson sense. Gutman 155 characterizedthe tradeoffs between the best exponents of the two kinds oferrors. He also extended the approach to multiple hypothesesfrom which training sequences are available and allowed rejection of all hypotheses. He developed a test with asymptoticallyvanishing error and reject probabilities. The generalized likelihood ratio test GLRT, which relies on ML estimates of theunknown sources, was used in 155. This test was implementedusing empirical entropies. Merhav 237 developed a Bayesianapproach for multiple hypotheses testing of firstorder Markovchains using estimates of their transition matrices and studiedits performance.Optimality of the GLRT in testing a simple hypothesis, say, against a composite hypothesis, say ,where is a subset of all stationary ergodic thorderMarkov measures, was studied by Zeitouni, Ziv, and Merhav325. A version of the NeymanPearson criterion was used inwhich both error probabilities approach zero exponentially fastwith the number of observations. It was shown that if isclosed with respect to exponential combinations of and ,i.e., if for every , and everywhere is a normalization factor that makes a pmf, thenthe GLRT is asymptotically optimal in the above describedsense 325, Theorem 2. A closely related condition developedby Gutman cited in 325 is necessary and sufficient forasymptotic optimality of the GLRT. Whether the GLRT isoptimal for classification of HMPs even with a finite alphabetis still an open problem.Classification problems involving HMPs were studied byseveral authors. Merhav 235 studied a binary hypothesistesting problem for two statistically independent observationsequences to emerge from the same general HMP or from twodifferent general HMPs. The observation conditional densitiesof the HMPs were assumed members of the exponential familyKoopmanDarmois. A modified GLRT was developed andwas shown to be asymptotically optimal in a NeymanPearsonsense. Kieffer 187 provided a strongly consistent codebasedapproach for identifying whether or not a given observationsequence with unknown distribution was generated by amember of a finite class of constrained finitestate sources .Finitealphabet HMPs are special cases of that class.Ndas 244 studied a classification problem in which a testsequence is generated by one out of possible generalHMPs whose parameters are not explicitlyknown. A set of training sequences , ,from the HMPs is assumed available. The goal is to identifythe HMP that generated with minimum probability of error.Ndas developed a Bayesian approach assuming that the parameters are statistically independent random variables. Inaddition, are statistically independent given , andand are statistically independent given and the active source. All hypotheses were assumed equally likely. Heshowed that the optimal decision rule is given by11.1Merhav and Ephraim 238 proposed an approximation to thisdecision rule that does not require integration and explicit priorsfor the parameters. The approximate Bayesian decision rule isgiven by11.2The ratio of the two maxima comprises a similarity measure between the test and training data. The ratio is likely to be largerfor and emerging from the same HMP than for andoriginating from different HMPs. This decision rule is similarto universal decision rules developed by Ziv 328 and Gutman155. It was shown in 238, Theorem 1, under some regularity conditions, that the decision rules 11.1 and 11.2 havethe same asymptotic behavior as the length of the test sequence. Furthermore, for HMPs with positive transition probabilities and a set of training sequences whose lengths growat least linearly with the length of the test sequence, the decision rule 11.1, and hence 11.2, provides exponentially decaying probability of error as . The error exponent inboth cases is the same. Whenand 11.2 can be further approximated as11.3where maximizes over . This is thestandard plugin decision rule used in HMPbased classificationsuch as in automatic speech recognition applications, see, e.g.,14.6. The condition of is commonly satisfied in classification problems that are based on offline training. Withoutthis simplification, implementation of the decision rule 11.2is hard since it requires online global maximization of the twolikelihood functions.Kehagias 183 studied a sequential classification problem. Aset of HMPs is assumed given but the test sequence is a samplefrom a stationary ergodic process that is not necessarily an HMP.The goal is to recursively identify the HMP that is closest tothe test sequence in the minimum relative entropy sense. A recursive algorithm was developed for associating a test sequencewith an HMP from a given set of finite orcountably infinite HMPs. The algorithm was derived under theassumption that the test sequence was produced by one of theHMPs. The analysis of the algorithm, however, does not makethis assumption. Let be a discrete random variable takingEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1555values in . Let . Let denotethe th HMP selected at time according to11.4The conditional probability is recursively calculated using11.5where is the parameter of the HMP associated with the thhypothesis and can be recursively calculatedusing 4.4 and 4.30.In analyzing the algorithm, the test sequence was assumed tobe a sample from a finitealphabet stationary ergodic process.The HMPs were assumed to have a finite alphabet and for eachthe parameter . Almost sure convergence of therecursive classification approach, as , to the hypothesiswhose HMP is closest to the test sequence in the relative entropyrate sense was proved in 183, Theorem 2. If there is more thanone HMP that achieves the same minimum relative entropy ratewith respect to the test sequence, then convergence is to the setof all such HMPs. This situation may occur when the HMPs arenot identifiable.Giudici, Rydn, and Vandekerkhove 139 applied standardasymptotic theory to the GLRT for two composite hypotheses testing problems involving the parameterof an HMP. They used the asymptotic results of Bickel, Ritov,and Rydn 36. Let denote the true parameter. In thefirst problem, a simple null hypothesis  and analternative hypothesis  were tested. Next, letand assume that is characterized by a set of constraints, , where . In the second problem,a composite null hypothesis  and an alternativehypothesis  were tested. Letbe the log likelihood of the HMP and let denote the MLestimate of as obtained from a sample of observations.The likelihood ratio test used for the simple null hypothesis isgiven by11.6Under , and for large , has approximately a distribution with degrees of freedom. Hence, a test with sizeapproximately equal to is obtained if is rejected when, where is the quantile of thedistribution with degrees of freedom. The likelihood ratioused for the composite null hypothesis problem is given by11.7Under , and for large , has approximately a distribution with degrees of freedom. Hence, a test with sizeapproximately equal to is obtained if is rejected when.XII. SIGNAL ESTIMATIONLet and denote observation sequences from twostatistically independent general HMPs. Assume that is adesired signal and is a noise process. Letfor . In this section, we review MMSE estimationof from , . The problem arises in applications suchas enhancement of noisy speech signals 105, channel decoding252, and forecasting in econometrics 156, Ch. 22.It is easy to check that the noisy signal is an HMP 105,313. Let and denote the state spaces of and ,respectively. The state space of is given by .Let and denote the state sequences of and ,respectively. Let denote the state sequence of. We refer to as a composite state of the noisy processat time . The MMSE estimator of given a realization ofthe noisy signal is given by 10512.1The conditional probabilities can be calculated using aforwardbackward recursion from Section VA. A similar estimator was developed by Magill 229 for a mixture of stationaryergodic processes where the state remains constant in its initially chosen value. Suppose that and are dimensionalvectors in , and that the observation conditional densities ofand are Gaussian with zero mean and covariancematrices and , respectively. Then, the observationconditional densities of are also Gaussian with zero meanand covariance matrices . Furthermore12.2which is the Wiener estimator for given .The causal MMSE estimator was analyzed byEphraim and Merhav 104. The MMSE given by12.3was expressed as the sum of two terms denoted by and .The first term represents the average MMSE of the estimatorthat is informed of the exact composite state of the noisy signaland is given by12.4The term represents a sum of cross error terms for which noexplicit expression is known. Tight lower and upper bounds onwere developed. For signal and noise HMPs with Gaussianobservation conditional densities, these bounds were shown toapproach zero at the same exponential rate as . Theexponential rate is the same as that of the error probability fordistinguishing between pairs of composite states.Several other estimators for the signal from were developed 105. We note, in particular, the detectorestimatorscheme proposed by Ephraim and Merhav 104 in which thecomposite state of the noisy signal is first estimated and then1556 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002MMSE signal estimation is performed. This estimator is givenby where . TheMSE of this estimator approaches when and hencethe estimator is asymptotically optimal in the MMSE sense.An estimator similar to 12.1 and 12.2 was used by Crouse,Nowak, and Baraniuk 69 for wavelet denoising of signals contaminated by white noise.XIII. HIDDEN MARKOV CHANNELSFSCs were defined in Section IVB4. An FSC with input, output , and state sequence has a conditionaltransition density given by13.1The memory of the channel is captured by the Markov chain. The states may represent fading levels as in wireless communications 205, previous channel inputs as in intersymbolinterference channels, or a tendency of the channel to persist ina given mode as for bursty channels 133, Sec. 4.6. FSCs arealso encountered when a buffer exists at the input of a channel,in which case the states correspond to the buffer contents 89.FSCs may be interpreted as hidden Markov channels since thestate sequence is not known at the encoder and decoder. Posterior probabilities of the states can be calculated using recursionssimilar to those given in Section VA 133, eq. 4.6.1, 141.In this section, we focus on FSCs with finite input and outputspaces, and , respectively, and review some of their properties and the LapidothZiv universal decoding algorithm 204. Athorough discussion on reliable communication under channeluncertainties can be found in Lapidoth and Narayan 205.The channel coding theorem for FSCs was derived by Gallager 133 and by Blackwell, Breiman, and Thomasian 43.FSCs for which the effect of the initial state is rapidly forgottenare said to be indecomposable. A necessary and sufficient condition for an FSC to be indecomposable is that for some fixedand each there exists a choice for the th state, say, such that for all 133, Theorem4.6.3. If the FSC is indecomposable or if for every, the capacity of the channel is given by 133, Theorem4.6.4, 205, Theorem 813.2where denotes the conditional mutual information between the input and output of the channel for a giveninitial state . Sequences of upper and lower bounds for ,which can be used to approximate the capacity to an arbitrarydegree, were provided in 133, Theorem 5.9.2. For any FSC,code rate , and sufficiently large , there exists acode of codewords of length each that provides exponentially decaying probability of decoding error forany input message and initial state 133, Theorem 5.9.2. If, the probability of error cannot be made arbitrarysmall, independent of the initial state 133, Theorem 4.6.2.The GilbertElliott channel defined in Section IVB5 is anexample of an FSC. The capacity of this channel was calculatedby Mushkin and BarDavid 243, Proposition 4. Recall that thechannel introduces an additive hidden Markov noise process,say . Let denote the entropy rate of . Assumethat the parameter characterizes the memory of the channel satisfies . The capacity of the channel is given by13.3Convergence of occurs at an exponential rate asshown in 40, 161, see also Section IVE. The capacityincreases monotonically with . It ranges from thecapacity of a memoryless channel to the capacity ofa channel informed about its Markov state . A decisionfeedback decoder that achieves capacity was developed in 243.A class of channels related to FSCs was studied by Ziv 327.A channel in that class is described by the conditional transitionpmf13.4and a deterministic nextstate functionZiv developed an asymptotically optimal universal decoding approach for these channels. The same algorithm was shown byLapidoth and Ziv 204 to be asymptotically optimal for FSCsdescribed by 13.1. These results and the universal decoder aredescribed next.Let denote the parameter space of all FSCs with commonspaces . The parameter of each channel comprises aninitial state and all transition probabilities of the form. Consider an FSC with parameter . Letdenote a permutation invariant subset of in thesense that if then any permutation of the components ofresults in a vector in . Assume that a set of lengthcodewords are drawn uniformly and independently fromwhere denotes the rate of the code. The collection of thesecodewords is referred to as a codebook. Let error denote the probability of error of the ML decoder for the FSCaveraged over all messages and possible codebooks. Similarly, let error denote the average probability of errorwhen Zivs decoder is applied to the same channel without explicitly knowing its parameter . From 204, Theorem 1errorerror13.5Let be a deterministic code of length codewords in. Let error and error denote, respectively, the probabilities of error for the particular code usingZivs decoder and the ML decoder. These error probabilities areaveraged over the messages only. It was shown in 204, Theorem1 that there exists such a deterministic code for whicherrorerror13.6Admissibility of universal decoding for channels with memory,and in particular for FSCs, was studied by Feder and Lapidoth112, Theorem 3.EPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1557Assume that a codebook of length codewords was drawn at random by the encoder and that a copy ofthe codebook is available at the decoder. The ML decoder for agiven FSC decodes the received signal as comingfrom the th message if13.7where is the channels pmf 4.17 specified forthe given . If the maximum is not unique an error is declared.Zivs decoder does not explicitly use in decoding the channel.Instead, a length function is calculated for each ofthe codewords and the received signal . The observedsignal is decoded as coming from the th message if13.8If the minimum is not unique an error is declared. The lengthfunction is calculated from joint parsing of muchlike the parsing in the LempelZiv universal data compressionalgorithm described in Section VIE. This length function is described next.Let denote the number of distinct phrases in .The joint parsing of induces parsing of into phrasesthat are not necessarily distinct. Let denote the number ofdistinct phrases in the induced parsing of . Let ,, denote th distinct phrase in the induced parsing of . Letbe parsed identically to in the sense that ifthenwhere is the total number of phrases in parsing of whichat least phrases are distinct, i.e., . Letdenote the number of distinct phrases in the parsing ofthat appear jointly with . We have that13.9The length function required by the decision rule 13.8is defined as13.10These concepts are well demonstrated by the following exampleborrowed from 204. Let , , and .Consider and . The joint parsing ofyields distinct phrases as shown below.13.11The induced parsing of and is given by13.12There are distinct phrases for . These phrases andtheir joint occurrences are given by13.13From 13.10, when the logarithms base is .An analogue of Zivs inequality for FSCs can be inferred fromMerhav 239, eqs. 79. Let denote the parameter ofan FSC with finite spaces . It holds that13.14where is some integer that divides , and areindependent of and , andand . This result was used in 239 in a binaryhypothesis testing problem for deciding whether a given channeloutput sequence was produced by a prescribe input sequence orby an alternative sequence. A decision rule similar to 8.4 wasused.A composite hypothesis testing approach applicable for decoding of unknown channels from a given family, in the relative minimax sense, was developed by Feder and Merhav 113.FSCs are particular cases of that family. In this approach, theratio of the probability of error of a decoder that is independentof the unknown channel parameter, and the minimum achievableprobability of error for the channel, is optimized in the minimaxsense. The optimal decision rule is obtained from minimizationof the maximum of this ratio over all possible channel parameters. Asymptotically optimal decoders that are easier to implement were also derived in 113.XIV. SELECTED APPLICATIONSOne of the earliest applications of HMPs and their theory wasin ecology. In 1967, Baum and Eagon 26 developed an iterativeprocedure for local maximization of the likelihood function of afinitealphabet HMP. This procedure predated the EM approachdeveloped in 1970 by Baum, Petrie, Soules, and Weiss 28.Baum and Eagon observed that the likelihood functionis a homogeneous polynomial of degree in the components of the parameter whereas in 4.9. In estimating , for example, they showed thatthe mapping from the domaininto itself defined by14.1increases the likelihood function unless a stationary point inis reached 26, 29, Theorem 2. The transformation 14.1 wasnamed growth transformation by Baum and Sell 27 and itsproperties were studied. The recursion 14.1 turned out to besimilar to a recursion developed in ecology for predicting therate of population growth. Baum 29 showed that 14.1 andthe reestimation formula 6.15 for coincide. Similar conclusions hold for the reestimation formulas for and .Concurrently with the above application, a new applicationin the area of automatic character recognition emerged at IBM.1558 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002Raviv 265 studied this problem and developed the stable forward recursion 5.14 as well as a stable recursion similar to5.9 for calculating . Subsequently, a major application of HMPs to automatic speech recognition was undertaken atIBM. Jelinek, Bahl, Mercer, and Baker 171, 18, 172, 21,along with their colleagues, developed the first automatic speechrecognition system based on hidden Markov modeling of speechsignals. They also studied language modeling using Markovchains 173. Language modeling using HMPs was studied byCave and Neuwirth 55. Numerous papers and several bookswere published on automatic speech recognition, see, e.g., 19,262, 165, 263, 209, 173, 65, 230 and the referencestherein. Moreover, HMPbased automatic speech recognitionsoftware packages running on personal computers are now commercially available, see, e.g., Via Voice by IBM and NaturallySpeaking by Dragon Systems. In the process of studying applications of HMPs to automatic speech recognition, several extensions of HMPs and new parameter estimation approaches weredeveloped. These are briefly discussed in Sections XIVA andXIVB, respectively. In Section XIVA, we also mention extensions of HMPs developed for other nonspeech processing applications.In recent years, numerous new applications of HMPs haveemerged in many other areas, particularly in communicationsand information theory, econometrics, and biological signal processing. In some applications, the underlying processes are naturally HMPs. In others, HMPs were found reasonable statistical models for the underlying processes. In either cases, thereadily available theory of HMPs provides elegant and often intuitive solutions. We briefly review these applications in Sections XIVCXIVE. Additional applications can be found in66 and 228. For each application, we attempted to providethe original references as well as papers of tutorial nature. Unfortunately, it is impractical to provide an exhaustive list of references for each application due to the huge number of publications in each area.A. Special HMPsIn some applications, the data associated with each state isoverdispersed relative to any single density such as Gaussian orPoisson. Using an observation conditional density that is a mixture of densities for each state may circumvent this problem221, 256, 175, 262. Such modeling results in two regimevariables, for the state at time and for the mixture component in state . Using the standard conditional independenceassumption 4.1 of observations given states we have14.2Let denote the probability of choosingthe th mixture component in the th state. Multiplying 14.2by and summing over , and using 4.7, we obtain14.3Comparing 14.3 with 4.3 reveals that there is no principaldifference between HMPs with a single or multiple mixturecomponents per state. The use of multiple mixture componentsper state allows one to increase the number of observation conditional densities of the HMP without incurring a quadratic increase in the number of components of .It has often been found useful to restrict the allowable transitions of the Markov chain. For example, leftright HMPs arecommonly used in automatic speech recognition 262, 111. Inthis case, the transition matrix is upper triangular or has nonzeroelements only on the main diagonal and first offdiagonal. For aleftright HMP, all but the last state are transient states. The laststate is absorbing. It constitutes a degenerate irreducible Markovchain. Leftright Markov chains are used for two reasons. First,this choice is natural in modeling speech signals, as states evolvein a manner that parallels the evolvement of the acoustic signalin time. Second, an HMP with a leftright Markov chain andthe usual parametrization is characterized by a lower dimensional parameter compared to that of an HMP with positive transition probabilities. Such reduction in the parameter size helpspreventing overfitting of the model to training data. LeftrightHMPs are also mathematically tractable as was shown in Section VIID.Inherent to an HMP is a geometric distribution for the numberof consecutive time periods that the process spends in a givenstate before leaving that state. This distribution is given by. In some applications it was founduseful to turn off selfstate transitions and introduce explicit distribution for that suits better the problem athand, see Ferguson 115. This approach was applied to automatic speech recognition 216, DNA sequencing 227, detection of ECG events 298, and seismic signal modeling 145.Examples of possible distributions used for include Poisson,binomial, and gamma 115, 216. The resulting hidden component of the model is referred to as semiMarkov chain 145.Let denote a possible occupation time of state and defineand for some integer . Using standardconditional independence assumptions, and the simplifying assumption that an integer number of state transitions occurred intime periods, we have14.4where . This model can be seen as astandard HMP with an extended state space of elements,where is the largest possible duration. Extension of the Baumalgorithm for estimating the parameter and state sequence ofthis model was proposed by Ferguson 115. An alternative MLapproach was provided by Goutsias and Mendel 145.The next two extensions of HMPs were developed in biological signal processing and image processing, respectively. Wehave seen in Section IVB3 that the observation conditional densities of HMPs may be dependent on past observations in addition to the current state of the Markov chain. A stronger assumption was necessary in a neurophysiology application where ionchannel currents observed in colored noise were recorded fromEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1559living cells 306, 307. The model used for that application resulted in dependency of on as well as on .The HMP is seen as a vector HMP and the sequence of statesis commonly referred to as a metastate. Note that avector HMP is different from an HMP with vector observationsas in Section IVB1. In the latter case, vector observations arestatistically independent given the state sequence.Applications in coding of finitealphabet images motivatedthe definition of a partially hidden Markov model by Forchhammer and Rissanen 122. The hidden states of this processare supplemented by the socalled contexts which are subsequences of the observed signal. The partially hidden Markovmodel is defined by14.5where is a state sequence and and are the contexts. The forwardbackward and Baum algorithms extend tothe processes mentioned above as was shown in the referencedpapers.B. Parameter Estimation in Speech RecognitionIn this subsection, we briefly review three nonML parameterestimation approaches that were tailored primarily to automaticspeech recognition applications. We focus on the maximum mutual information MMI approach of Bahl, Brown, de Souza, andMercer 20, the minimum discrimination information MDIapproach of Ephraim, Dembo, and Rabiner 101, and the minimum empirical error rate MEER approach of Ephraim andRabiner 102, Ljolje, Ephraim, and Rabiner 224, Juang andKatagiri 177, Chou, Juang, and Lee 58, 178, and Erlich108. See also Amari 8.To motivate these approaches it is useful to review the roleof HMPs in automatic speech recognition applications 173,263, 165. For simplicity, we discuss isolated word recognition only. Consider a vocabulary of words. The densityof the acoustic signal from each word is modeled as an HMP,and the parameter of the HMP is estimated from a training sequence of acoustic signals from that word. Let denotethe density of an HMP with parameter . Let denote a training sequence of length from the th word. Letdenote the parameters of the HMPs forthe words. Let denote an estimate of from . WhenML estimation is used, . All wordsare assumed a priori equally likely. A test acoustic signal isassociated with the th word in the vocabulary if the signal ismost likely to have been produced by the th HMP, i.e.,14.61 Maximum Mutual Information MMI MMI is a trainingapproach in which the parameters of the HMPs are simultaneously estimated, by minimizing the average empirical mutualinformation between the data and the hypotheses. The approachattempts to reduce the recognition error rate obtained when MLestimation is applied for individual estimation of each HMP. TheMMI estimate of is obtained from14.7A reestimation approach for MMI estimation was developed in144. It is based on a generalization of the growth transformation of Baum and Eagon 26 for maximization of homogeneouspolynomials with nonnegative coefficients to maximization ofrational functions. This approach requires specification of anexogenous constant whose practical value may result in slowconvergent of the iterative approach 246. Often this approachis implemented using generalpurpose optimization proceduressuch as the steepest descent algorithm.2 Minimum Discrimination Information MDI Discrimination information is synonymous to relative entropy, cross entropy, divergence, and the KullbackLeibler number. The MDIapproach is suitable for modeling one random process such asa speech signal by another parametric process such as an HMP.The distribution of the first process is not explicitly known. Theprocess is characterized by a partial set of moments. The MDIapproach attempts to choose the HMP that provides MDI withrespect to the set of all distributions of the first process that satisfy the given moments. The MDI approach is a generalizationof the maximum entropy inference approach 68, Ch. 11. Shoreand Johnson 291 showed that MDI is a logically consistentaxiomatic modeling approach. See also Csiszr 72 for furtherjustification.Let , , denote a set of vectorsfrom a source whose distribution is not explicitly known. Suppose that a set of moment constraints is available for these vectors. For example, let and denote the true mean and covariance of . Suppose that and a band of are availablefor each . The band may comprise an upper leftblock of or the main diagonal and some offdiagonals of .Let denote the set of all dimensional distributionsthat satisfy the given moment constraints. Let denote thedimensional distribution of an HMP with parameter .Let and denote the pdfs corresponding toand , respectively. Let14.8denote the discrimination information between and .The HMP is estimated from14.9There is no closedform solution for this optimization problem even for HMPs with Gaussian observation conditionaldensities and secondorder moment constraints consideredin 101. An iterative approach for alternate minimization ofover and was developed in101 following a similar approach due to Csiszr and Tusnadyin 71. Given an HMP with parameter at the end ofthe th iteration, a new estimate of the process distribution1560 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002can, in principle, be obtained from the solution of aset of nonlinear equations for the Lagrange multipliers. Let thecomplete data density of the new estimate of be denotedby . Next, a new estimate of the HMPparameter can be obtained from maximization over ofthe auxiliary function14.10The procedure is repeated until a fixed point is reached or somestopping criterion is met. Local convergence of to a stationary point of the MDI measure was demonstrated in 101.The general convergence proof from 71 is not applicable tothis problem since the set of HMP distributions of a given orderis not a convex set of probability measures.While maximization of the auxiliary function in 14.10results in reestimation formulas similar to those obtained inthe Baum algorithm, estimation of the distributionis a hard problem. If a single state sequence dominates theMDI measure, then the MDI approach coincides with theBaumViterbi algorithm.3 Minimum Empirical Error Rate MEER The MEER approach simultaneously estimates the parameters of the HMPsby minimizing the empirical error rate of the recognizer forthe given training sequences. This criterion is directly related to the goal of automatic speech recognition. The theoryof empirical risk minimization and the design of optimal separating hyperplanes using support vector machines has recentlyattracted much attention, see Vapnik 304, 305. The extensionof Vapniks work to HMPs is still an open problem.In the MEER approach, the nondifferentiable indicator functions of the error rate expression are approximated by smoothdifferentiable functions and minimization is performed usingnumerical procedures such as the steepest descent algorithm.Let denote the pdf of an observation sequence fromthe acoustic signal of the th word. Assume that the decisionrule is based on estimates of the HMPs. The th word is recognized if the acoustic signal is in the set14.11The probability of correct decision is given by14.12where denotes an indicator function defined byifotherwise.14.13Let14.14For large14.15and the decision rule can be approximated as14.16The indicator function 14.13 can similarly be approximated asifotherwise.14.17This approximation makes the argument of the indicator function differentiable in . Next, the indicator functionitself is approximated by the differentiable sigmoid function asfollows14.18If is assumed to be concentrated on the training sequencefrom the th word, i.e., and denotesthe Dirac function, we obtain from 14.12 and 14.18 the desired differentiable approximation for the probability of correctdecision as14.19This estimate approximates the empirical correct decision countof the HMPbased recognizer. The parameter of the HMPs isestimated from14.20C. Communications and Information TheoryIn this subsection, we review applications of HMPs in communications and information theory that we have not discussedpreviously in this paper.1 Source Coding Ott 248 proposed in 1967 a uniquelydecodable code for a sequence from a finitealphabet HMP.The coder assumes zero channel errors. At each time , identical Huffmantype codes are produced at the transmitter andreceiver for encoding . The codes are based on the conditionalpmf which is calculated using 4.4 and the recursion4.30. This recursion was originally developed for that purposeby Ott.Merhav 236 studied in 1991 lossless blocktovariablelength source coding for finitealphabet HMPs. He investigatedthe probability of codeword length overflow and competitiveoptimality of the LempelZiv data compression algorithm326. Consider an HMP with observation space andentropy rate . He proved asymptotic optimality of theEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1561LempelZiv algorithm for any HMP, among all uniquelydecodable codes, in the sense that the normalized length of itscodeword has the lowest probability of exceedinga constant , as , for any .For , the problem is not feasible and it is trivialfor . This probability was shown to vanish exponentially fast for unifilar sources. The LempelZiv code forHMPs was demonstrated to be asymptotically optimal in thecompetitive sense of Cover and Thomas 68, Sec. 5.11. Inparticular, the LempelZiv algorithm provides most of the timea codeword shorter than that of any other competing algorithmwithin a normalized redundancy term of . This result wasfirst proved for Rissanens MDL universal code 268 forunifilar sources using the method of types, and then inferred forthe LempelZiv code for HMPs using Zivs inequality 6.29. Itshould also be noted that the LempelZiv algorithm compressesany observation sequence from any finitealphabet HMP withessentially the same efficiency as any arithmetic coder whichexplicitly uses the pmf of the HMP. This observation followsfrom the Ziv inequality.Goblirsch and Farvardin 140 studied in 1992 the designof switched scalar quantizers for a stationary composite sourcewith known transition matrix and densities. The encoder comprises a set of scalar quantizers and a nextquantizer distribution.This distribution is indexed by the quantizers and codewords.Upon quantization of each observation, a quantizer is selectedfor the next observation by sampling from the nextquantizerdistribution using a pseudorandom generator. The decoder hasexact copies of the code books and the nextquantizer distribution and is fully synchronized with the encoder. Quantizationof sources which are not necessarily HMPs, using finitestatequantizers with deterministic nextstate functions, was studiedby Dunham and Gray 94. See also 135, Ch. 14.2 Channel Coding Drake 92 studied in 1965 decodingof a binarysymmetric Markov chain observed through abinarysymmetric memoryless channel. A decoder is called singlet if it estimates the source symbol as the received symbolregardless of past observations . Drake providednecessary and sufficient conditions for the singlet decoder to beoptimal in the minimum probability of symbol error sense. Thework was extended by Devore 82 to decoding from a sampled observation sequence, dataindependent decoding, nonsequential decoding, and decoding through channels with binomial distributed noise. A singlet sequence decoder estimates thesource symbol sequence as the received symbol sequence. Phamdo and Farvardin 252 provided necessary and sufficient conditions for the singlet sequence decoder to be optimal in the minimum probability of sequence error sense whena binary symmetric Markov chain source is observed througha binary symmetric memoryless channel. Alajaji, Phamdo, Farvardin, and Fuja 5 extended the results from 252 to decodingof binary asymmetric Markov chains observed through binaryMarkov channels.Bahl, Cocke, Jelinek, and Raviv 17 used in 1974 the forwardbackward recursions 5.7 and 5.8 for estimating thestates of an HMP in the minimum symbol error rate sense. TheHMP was observed through a memoryless channel and thus resulted in another HMP with the same Markov chain. The sameapproach was used for decoding of convolutional and linearblock codes in the minimum symbol error rate sense. The decoding algorithm is commonly referred to as the BCJR decoder,and stabilized recursions have been used for decoding of turbocodes 32, 33. Turbo decoding of a finitealphabet HMP withunknown parameter transmitted over a Gaussian memorylesschannel was developed by GarciaFrias and Villasenor 131.Kaleh and Vallet 179 studied blind deconvolution of an i.i.d.data sequence transmitted across a finite memory channel withunknown transfer function. We shall demonstrate the approachfor linear channels. Nonlinear channels are treated similarly. Letdenote the input i.i.d. sequence where the randomvariable takes values in a finitealphabet set . Let denotethe vector of the finite impulse response of the channel.Let . Let denote a sequence of i.i.d. Gaussian random variables with zero mean andvariance representing the white noise in the channel. The observed signal at the channels output at time is .Since is a firstorder Markov chain with state space ,is an HMP. The parameter of the channel isunknown but assumed constant during observations, say .The memory length of the channel is assumed known. The parameter is estimated from observations using the Baumalgorithm and then used to decode these observations. Letdenote the estimate of at the end of the th iteration. A new estimate is obtained from the solution of theset of linear normal equations14.21The noise variance reestimation formula is14.22Given an estimate of , the symbol is decoded in the minimum symbol error rate using the decision rule14.23A problem similar to blind deconvolution arises in decodingpulse amplitude modulation PAM signals using a receiver thatis not synchronized with the transmitter. Kaleh 180 formulatedthis problem as a decoding problem of an HMP and applied theabove approach for estimating the parameter and for decodingthe signal. The parameter comprises the clock offset betweenthe receiver and transmitter and the white noise variance. Cirpanand Tsatsanis 62 used an approach similar to that of Kalehand Vallet 179 for semiblind channel deconvolution. The finiteimpulse response of the channel is estimated from the receiveddata as well as from an embedded training data. The presence1562 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002of training data improves the channel estimation accuracy at theexpanse of lowering the bit rate.Krishnamurthy, Dey, and LeBlanc 196 studied blind equalization of linear channels with infinite impulse response allpoletransfer functions. Phamdo and Farvardin 252 and Millerand Park 241 studied decoding of vector quantized sourcesobserved through finitealphabet memoryless noisy channelsusing a causal approximate MMSE estimator similar to 12.1.Brushe and White 48 and Brushe, Krishnamurthy, and White49 studied demodulation of a number of convolutional codedsignals impinging on an antenna array assuming unknownchannel and direction of arrival. Krishnamurthy and Logothetis199 studied estimation of codedivision multipleaccessCDMA signals in the presence of a narrowband interference signal and white additive noise. The CDMA signal wasassumed a Markov chain with states representing quantizedsignal levels. Chao and Yao 57 proposed hidden Markovmodeling of the burst error sequence in Viterbi decoding ofconvolutional codes. Turin 302 studied MAP decoding forHMP observed through an FSC.D. Signal ProcessingIn this subsection, we describe some applications of HMPs inprocessing audio, biomedical, radar, sonar, and image signals.1 Audio Mixture processes were found useful in modelingspeech signals in speaker identification applications 138, 209.HMPs were used in modeling speech signals and noise sources innoisy speech enhancement applications 105. HMPs were alsoused in environmental sound recognition whereas a recordedacoustic signal is classified as being produced by a subset ofnoise sources that are simultaneously active at a given time 67,134. The noise sources were assumed statistically independentHMPs. The observed signal is a mixture of these HMPs 67.2 Biomedical Characterization of currents flowingthrough a single ion channel in living cell membranes hasattracted significant research effort. An overview of stochasticmodels and statistical analysis applied to ion channels, andan extensive list of references, can be found in 22. This isa rich and challenging area of current research. Ion channelcurrents are believed to be well represented by a finitestatecontinuoustime Markov process where the states representconductance levels. Recordings are made using the patch clamptechnique where substantial nonwhite noise and deterministicinterferences may be added. In addition, several conductancelevels may be aggregated into a single state representing afunction of the Markov process. The sampled signal constitutesa noisy function of a finitestate discretetime Markov chainor an HMP. The theory of HMPs was applied to ion channelsin 59, 60, 129, 128, 306, 307. The parameter of theHMP is estimated in the ML sense using the Baum as wellas other optimization algorithms. Parameter estimation in thepresence of deterministic interferences was studied in 60,194, 197. The states representing the conductance levelsare estimated using the Viterbi algorithm or a forwardbackward recursion. Of particular importance are estimations ofthe channel kinetics and mean dwell time within each state.Characterization of multichannel patch clamp recordings usingHMPs with appropriate parametrization of the transition matrixwas studied in 7, 190.DNA sequencing based on hidden Markov modeling wasstudied in 61, 227. The states represented different regionsor segments of the DNA. Segmentation was inferred fromMAP estimates of state sequences as obtained from the Viterbialgorithm or the forwardbackward recursions. In anotherapplication 200, HMPs were applied to statistical modeling ofprotein families for database searching and multiple sequencealignment. In 53, neuron firing patterns were characterized bythe most likely state sequence of an appropriately trained HMP.In 264, classification of neuronal responses to visual stimulibased on hidden Markov modeling was studied.HMPs were also used in automated analysis and classification of ECG signals 63, 298, 193. ECG wave patterns wereassociated with states and detected from the most likely state sequence of appropriately trained HMPs. In another application,HMPs were used to model epileptic seizure counts with varyingPoisson rates 6, 207.3 Spectral Estimation A sinusoidal signal with a timevarying frequency observed in white noise comprises an HMPwhen the unknown frequency is assumed a Markov process.Algorithms for tracking quantized versions of the frequencyusing the Viterbi algorithm were developed in 296, 320,313, 321, 322.4 Radar and Sonar A problem related to frequency tracking is that of maneuvering source tracking in sonar and radarsystems 208. The relative location and velocity of the sourcewith respect to an observer comprised the state vector in adynamical system. A quantized version of the state variableswere tracked using the Viterbi algorithm. Due to the observersmotion, optimal control was designed using the theory ofpartially observed Markov decision processes. In 201, 12,ML target localization using overthehorizon radar systemswas studied. The uncertainties in the ionospheric propagationconditions were modeled as an HMP. The states representedray mode types. The parameter of the HMP was estimatedusing smoothed bootstrap Monte Carlo resampling 96.5 Image Restoration from corrupted images modeled ashidden Markov random fields was studied by Besag 34. Theimage was represented by a Markov field and its pixels were alternatively estimated in the ML sense. Classification of imagesrepresented by hidden Markov random fields or by onedimensional HMPs was studied in 157, 257, 317, 217. Partiallyhidden Markov processes were studied in 122 and applied toimage compression.E. Other ApplicationsIn this subsection, we briefly review applications of HMPs inthe area of fault detection, economics, and metrology.1 Fault Detection Fast failure detection and prediction incommunication networks was studied in 16. An HMP with twostates representing good and bad conditions of the network, anda binary alphabet representing good and bad checksums in eachEPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1563state was assumed for the fault detection process. ML estimation of the networks condition state was performed using theViterbi algorithm. In 293, 294, an HMPbased realtime faultdetection system for NASAs deep space network antennas isdescribed. Here multifaults are monitored by estimating theirconditional probabilities at any given time using the forward recursion or the Viterbi algorithm. In 2, an HMP was constructedfor inventory system with perishable items.2 Economics HMPs and switching autoregressive processes appear particularly suitable to model macroeconomicor financial time series over sufficiently long periods 156.The regime of the process provides a convenient way to reflecton events that may affect the underlying statistics of the timeseries such as wars, changes in government policies, etc. Asummary of many properties of HMPs and their application ineconomics is given by Hamilton 156, Ch. 22. In 282, HMPswith Gaussian pdfs were used to model subseries of the SP500 return series as registered from 1928 to 1991. Explicitexpressions for the secondorder statistics of these HMPs werealso given. Expressions for secondorder statistics of HMPswith discrete observations such as HMPs with Poisson andbinomial pmfs were derived in 228.3 Metrology HMPs were used in 331, 284 to modelrainfall records assuming some climate states which weremodeled as a Markov chain.XV. CONCLUDING REMARKSAn overview of HMPs was presented in this paper. Clearly,the theory of HMPs is very rich with many results derived fromstatistics, probability theory, information theory, control theory,and optimization theory. While HMPs are fairly general processes, they are still amenable to mathematical analysis. Manyof these results were developed only in the past few years. Manyingenious approaches have been invented to study and provelargesample properties of HMPs. We have attempted to presentthe principles of the main theoretical results and to point out todifferences in alternative proofs. The emphasis of the paper is onthe new results even though some more classical material wasincluded for completeness and proper perspective.We have collected a large number of results primarily fromthe mathematical literature and described a range of selectedapplications. We have seen how results developed in one areaare useful in another area. For example, the sourcechannel informationtheoretic model for an HMP enables quick inferenceof their statistical properties using existing results, which otherwise are harder to prove directly. The forwardbackward recursions are useful in decoding of turbo codes in data communications. Ergodic theorems for relative entropy densities of HMPshave significance in coding, estimation, and hypothesis testingof HMPs. The Ziv inequality which proved useful in order estimation and hypothesis testing can also be used in assessing thequality of a local ML estimator for finitealphabet HMPs. Theforwardbackward recursions for HMPs become the Kalmanfilter and smoother under appropriate conditions. Otherwise,they provide optimal filters and smoothers for nonGaussiannonlinear discretetime signals.Some aspects of HMPs were inevitably left out. Our primary focus was on discretetime general HMPs. Some resultsconcerning HMPs with separable compact state spaces wereincluded. We did not cover continuoustime HMPs, nor didwe treat hidden Markov fields which play an important role inimage processing. Some references to these areas were provided in this paper. In addition, dynamical system approachesto these two areas can be found in 99.HMPs have attracted significant research effort in recentyears which has resulted in substantial gain in understandingtheir statistical properties and in designing asymptoticallyoptimal algorithms for parameter estimation and for universalcoding and classification. The intuitive appeal of HMPs inmany applications combined with their solid theory and theavailability of fast digital signal processors are expected toattract further significant research effort in years to come.ACKNOWLEDGMENTThe authors are grateful to Amir Dembo, Robert J. Elliott,Robert M. Gray, Amos Lapidoth, Tobias Rydn, William Turin,Tsachy Weissman, and the anonymous referees for helpful comments and suggestions. They also thank Randal Douc, CatherineMatias, ric Moulines, and Tobias Rydn for making availablepreprints of their most recent work. The authors thank ShlomoShamai for coordinating the review process.REFERENCES1 R. L. Adler, Ergodic and mixing properties of infinite memory channels, Proc. Amer. Math. Soc., vol. 12, no. 6, pp. 924930, 1961.2 L. Aggoun, L. Benkherouf, and L. Tadj, A hidden Markov model foran inventory system with perishable items, J. Appl. Math. StochasticAnal., vol. 10, no. 4, pp. 423430, 1997.3 S. M. Aji and R. J. McEliece, The generalized distributive law, IEEETrans. Inform. Theory, vol. 46, pp. 325343, Mar. 2000.4 H. Akaike, A new look at the statistical model identification, IEEETrans. Automat. Contr., vol. AC19, pp. 716723, 1974.5 F. Alajaji, N. Phamdo, N. Farvardin, and T. E. Fuja, Detection of binaryMarkov sources over channels with additive Markov noise, IEEE Trans.Inform. Theory, vol. 42, pp. 230239, Jan. 1996.6 P. S. Albert, A twostate Markov mixture model for a time series ofepileptic seizure counts, Biometrics, vol. 47, pp. 13711381, Dec.1991.7 A. Albertsen and U.P. Hansen, Estimation of kinetic rate constantsfrom multichannel recordings by a direct fit of the time series, Biophys.J., vol. 67, pp. 13931403, Oct. 1994.8 S. Amari, A theory of adaptive pattern classifiers, IEEE Trans. Electron. Comput., vol. EC16, pp. 299307, June 1967.9 J. B. Anderson and J. B. Bodie, Tree encoding of speech, IEEE Trans.Inform. Theory, vol. IT21, pp. 379387, July 1975.10 J. B. Anderson and C.W. Law, Realnumber convolutional codes forspeechlike quasistationary sources, IEEE Trans. Inform. Theory, vol.IT23, pp. 778782, Nov. 1977.11 B. D. O. Anderson, From Wiener to hidden Markov models, IEEEContr. Syst. Mag., vol. 19, pp. 4151, June 1999.12 R. H. Anderson and J. L. Krolik, Overthehorizon radar target localization using a hidden Markov model estimated from ionosonde data,Radio Sci., vol. 33, no. 4, pp. 11991213, JulyAug. 1998.13 C. Andrieu and A. Doucet, Simulated annealing for maximum a posteriori parameter estimation of hidden Markov models, IEEE Trans.Inform. Theory, vol. 46, pp. 9941004, May 2000.14 R. B. Ash, Information Theory. New York Dover, 1965.15 M. Askar and H. Derin, A recursive algorithm for the Bayes solutionof the smoothing problem, IEEE Trans. Automat. Contr., vol. AC26,pp. 558561, Apr. 1981.16 E. Ayanoglu, Robust and fast failure detection and prediction for faulttolerant communication network, Electron. Lett., vol. 28, no. 10, pp.940941, May 1992.1564 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 200217 L. R. Bahl, J. Cocke, F. Jelinek, and J. Raviv, Optimal decoding of linearcodes for minimizing symbol error rate, IEEE Trans. Inform. Theory,vol. IT20, pp. 284287, Mar. 1974.18 L. R. Bahl and F. Jelinek, Decoding for channels with insertions, deletions, and substitutions with applications to speech recognition, IEEETrans. Inform. Theory, vol. IT21, pp. 404411, July 1975.19 L. R. Bahl, F. Jelinek, and R. L. Mercer, A maximum likelihood approach to continuous speech recognition, IEEE Trans. Pattern Anal.Machine Intel., vol. PAMI5, pp. 179190, Mar. 1983.20 L. R. Bahl, P. F. Brown, P. V. de Souza, and R. L. Mercer, Maximummutual information estimation of hidden Markov model parameters forspeech recognition, in Proc. IEEE Int. Conf. Acoustics, Speech, andSignal Processing, Apr. 1986, pp. 4952.21 J. K. Baker, The DRAGON systemAn overview, IEEE Trans.Acoust., Speech Signal Processing, vol. ASSP23, pp. 2429, Feb. 1975.22 F. G. Ball and J. A. Rice, Stochastic models for ion channels Introduction and bibliography, Math. Biosci., vol. 112, pp. 189206, 1992.23 A. R. Barron, The strong ergodic theorem for densities GeneralizedShannonMcMillanBreiman theorem, Ann. Probab., vol. 13, no. 4, pp.12921303, 1985.24 A. Barron, J. Rissanen, and B. Yu, The minimum description lengthprinciple in coding and modeling, IEEE Trans. Inform. Theory, vol.44, pp. 27432760, Oct. 1998.25 L. E. Baum and T. Petrie, Statistical inference for probabilistic functions of finite state Markov chains, Ann. Math. Statist., vol. 37, pp.15541563, 1966.26 L. E. Baum and J. A. Eagon, An inequality with applications to statistical estimation for probabilistic functions of Markov processes and to amodel for ecology, Bull. Amer. Math. Soc., vol. 73, pp. 360363, 1967.27 L. E. Baum and G. R. Sell, Growth transformations for functions onmanifolds, Pacific J. Math., vol. 27, no. 2, pp. 211227, 1968.28 L. E. Baum, T. Petrie, G. Soules, and N. Weiss, A maximization technique occurring in the statistical analysis of probabilistic functions ofMarkov chains, Ann. Math. Statist., vol. 41, pp. 164171, 1970.29 L. E. Baum, An inequality and associated maximization technique instatistical estimation for probabilistic functions of Markov processes,in Inequalities, III Proc. 3rd Symp., Univ. Calif., Los Angeles, Calif.,1969 dedicated to the memory of Theodore S. Motzkin. New YorkAcademic, 1972, pp. 18.30 R. Bellman, Dynamic Programming. Princeton, NJ Princeton Univ.Press, 1957.31 T. Berger, Rate Distortion Theory. Englewood Cliffs, NJ PrenticeHall, 1971.32 C. Berrou, A. Glavieux, and P. Thitimajshima, Near Shannon limiterrorcorrecting coding and decoding Turbocodes, in Proc. ICC93,May 1993, pp. 10641070.33 C. Berrou and A. Glavieux, Near optimum error correcting codingand decoding Turbocodes, IEEE Trans. Commun., vol. 44, pp.12611271, Oct. 1996.34 J. Besag, On the statistical analysis of dirty pictures, J. Roy. Statist.Soc. B, vol. 48, no. 3, pp. 259302, 1986.35 P. J. Bickel and Y. Ritov, Inference in hidden Markov models I Localasymptotic normality in the stationary case, Bernoulli, vol. 2, no. 3, pp.199228, 1996.36 P. J. Bickel, Y. Ritov, and T. Rydn, Asymptotic normality of the maximumlikelihood estimator for general hidden Markov models, Ann.Statist., vol. 26, no. 4, pp. 16141635, 1998.37 P. Billingsley, Convergence of Probability Measures. New YorkWiley, 1968.38 , Probability and Measure. New York Wiley, 1995.39 M. Billio, A. Monfort, and C. P. Robert, Bayesian estimation ofswitching ARMA models, J. Econometrics, vol. 93, pp. 229255, 1999.40 J. J. Birch, Approximations for the entropy for functions of Markovchains, Ann. Math. Statist., vol. 33, pp. 930938, 1962.41 D. Blackwell, The entropy of functions of finitestate Markov chains,in Trans. 1st Prague Conf. Information Theory, Statistical DecisionFunctions, Random Processes. Prague, Czechoslovakia Pub. HouseCzechoslovak Acad. Sci., 1957, pp. 1320.42 D. Blackwell and L. Koopmans, On the identifiability problem forfunctions of finite Markov chains, Ann. Math. Statist., vol. 28, pp.10111015, 1957.43 D. Blackwell, L. Breiman, and A. J. Thomasian, Proof of Shannonstransmission theorem for finitestate indecomposable channels, Ann.Math. Stat., vol. 29, pp. 12091220, 1958.44 I. A. Boguslavskii and M. Y. Borodovskii, On identification of statesof a sequence generated by a hidden Markov model, J. Comput. Syst.Sci. Int., vol. 37, no. 4, pp. 551556, 1998.45 P. Bougerol and N. Picard, Strict stationarity of generalized autoregressive processes, Ann. Probab., vol. 20, no. 4, pp. 17141730, 1992.46 A. Brandt, The stochastic equation Y  A Y  B with stationary coefficients, Adv. Appl. Probab., vol. 18, pp. 211220, 1986.47 D. R. Brillinger, Time SeriesData Analysis and Theory. New YorkHolt, Rinehart Winston, 1975.48 G. D. Brushe and L. B. White, Spatial filtering of superimposed convolutional coded signals, IEEE Trans. Commun., vol. 45, pp. 11441153,Sept. 1997.49 G. D. Brushe, V. Krishnamurthy, and L. B. White, A reducedcomplexity online state sequence and parameter estimator for superimposedconvolutional coded signals, IEEE Trans. Commun., vol. 45, pp.15651574, Dec. 1997.50 G. D. Brushe, R. E. Mahony, and J. B. Moore, A soft output hybridalgorithm for MLMAP sequence estimation, IEEE Trans. Inform.Theory, vol. 44, pp. 31293134, Nov. 1998.51 P. Bryant and J. A. Williamson, Asymptotic behavior of classificationmaximum likelihood estimates, Biometrika, vol. 65, no. 2, pp. 273281,1978.52 C. J. Burke and M. Rosenblatt, A Markovian function of a Markovchain, Ann. Math. Statist., vol. 29, pp. 11121122, 1958.53 A.C. Camproux, F. Saunier, G. Chouvet, J.C. Thalabard, and G.Thomas, A hidden Markov model approach to neuron firing patters,Biophys. J., vol. 71, pp. 24042412, Nov. 1996.54 J. W. Carlyle, Identification of statecalculable functions of finiteMarkov chains, Ann. Math. Statist., vol. 38, pp. 201205, 1967.55 R. L. Cave and L. P. Neuwirth, Hidden Markov models for English, inProc. Symp. Application of Hidden Markov Models to Text and Speech,J. D. Ferguson, Ed. Princeton, NJ IDACRD, 1980, pp. 1656.56 R. W. Chang and J. C. Hancock, On receiver structures for channelshaving memory, IEEE Trans. Inform. Theory, vol. IT12, pp. 463468,Oct. 1966.57 C.C. Chao and Y.L. Yao, Hidden Markov models for the burst errorstatistics of Viterbi decoding, IEEE Trans. Commun., vol. 44, pp.16201622, Dec. 1996.58 W. Chou, B.H. Juang, and C. H. Lee, Segmental GPD training ofHMM based speech recognizer, in Proc. IEEE Int. Conf. Acoustics,Speech and Signal Processing, 1992, pp. I473I476.59 S. H. Chung, J. B. Moore, L. Xia, L. S. Premkumar, and P. W. Gage,Characterization of single channel currents using digital signal processing techniques based on hidden Markov models, Phil. Trans. Roy.Soc. London B, vol. 329, pp. 265285, 1990.60 S. H. Chung, V. Krishnamurthy, and J. B. Moore, Adaptive processingtechniques based on hidden Markov models for characterizing verysmall channel currents buried in noise and deterministic interferences,Phil. Trans. Roy. Soc. London B, vol. 334, pp. 357384, 1991.61 G. A. Churchill, Stochastic models for Heterogeneous DNA sequences, Bull. Math. Biology, vol. 51, no. 1, pp. 7994, 1989.62 H. A. Cirpan and M. K. Tsatsanis, Stochastic maximum likelihoodmethods for semiblind channel estimation, IEEE Signal ProcessingLett., vol. 5, pp. 2124, Jan. 1998.63 D. A. Coast, G. G. Cano, and S. A. Briller, Use of hidden Markovmodels for electrocardiographic signal analysis, J. Electrocardiol., vol.23 Suppl., pp. 184191, 1990.64 I. B. Collings, V. Krishnamurthy, and J. B. Moore, Online identification of hidden Markov models via recursive prediction error techniques,IEEE Trans. Signal Processing, vol. 42, pp. 35353539, Dec. 1994.65 R. Comerford, J. Makhoul, and R. Schwartz, The voice of the computeris heard in the land and it listens too, IEEE Spectrum, vol. 34, pp.3943, Dec. 1997.66 C. Couvreur, Hidden Markov models and their mixtures, Dept. Math.,Universit Catholique de Louvain, Louvain, Belgium, 1996.67 , Enviromental sound recognition A statistical approach, D.Sc.dissertation, Facult Polytechnique De Mons, June 1997.68 T. M. Cover and J. A. Thomas, Elements of Information Theory. NewYork Wiley, 1991.69 M. S. Crouse, R. D. Nowak, and R. G. Baraniuk, Waveletbased statistical signal processing using hidden Markov models, IEEE Trans.Signal Processing, vol. 46, pp. 886902, Apr. 1998.70 I. Csiszr and J. Krner, Information Theory Coding Theorems for Discrete Memoryless Systems. New York Academic, 1981.71 I. Csiszr and G. Tusnady, Information geometry and alternating maximization procedures, Statist. Decisions Suppl., vol. 1, pp. 205237,1984.72 I. Csiszr, Why least squares and maximum entropy An axiomaticapproach to inference for linear inverse problems, Ann. Statist., vol.19, no. 4, pp. 20322066, 1991.EPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 156573 , The method of types, IEEE Trans. Inform. Theory, vol. 44, pp.25052523, Oct. 1998.74 I. Csiszr and P. C. Shields, The consistency of the BIC Markov orderestimator, Ann. Statist., vol. 28, no. 6, pp. 16011619, 2000.75 L. D. Davisson, Universal noiseless coding, IEEE Trans. Inform.Theory, vol. IT19, pp. 783795, Nov. 1973.76 B. Delyon, Remarks on linear and nonlinear filtering, IEEE Trans.Inform. Theory, vol. 41, pp. 317322, Jan. 1995.77 A. Dembo and O. Zeitouni, Parameter estimation of partially observedcontinuous time stochastic processes via the EM algorithm, StochasticProcesses Their Applic., vol. 23, no. 1, pp. 91113, 1986.78 , On the parameters estimation of continuoustime ARMAprocesses from noisy observations, IEEE Trans. Automat. Contr., vol.AC32, pp. 361364, Apr. 1987.79 , Maximum a posteriori estimation of timevarying ARMA processes from noisy observations, IEEE Trans. Acoust., Speech, SignalProcessing, vol. 36, pp. 471476, Apr. 1988.80 A. P. Dempster, N. M. Laird, and D. B. Rubin, Maximum likelihoodfrom incomplete data via the EM algorithm, J. Roy. Statist. Soc. B, vol.39, no. 1, pp. 138, 1977.81 P. A. Devijver, Baums forwardbackward algorithm revisited, Pattern Recogn. Lett., vol. 3, pp. 369373, 1985.82 J. L. Devore, A note on the observation of a Markov source through anoisy channel, IEEE Trans. Inform. Theory, vol. IT20, pp. 762764,Nov. 1974.83 S. W. Dharmadhikari, Functions of finite Markov chains, Ann. Math.Statist., vol. 34, pp. 10221032, 1963.84 , Sufficient conditions for a stationary process to be a functionof a finite Markov chain, Ann. Math. Statist., vol. 34, pp. 10331041,1963.85 , Exchangeable processes which are functions of stationaryMarkov chain, Ann. Math. Statist., vol. 35, pp. 429430, 1964.86 , A characterization of a class of functions of finite Markovchains, Ann. Math. Statist., vol. 36, pp. 524528, 1965.87 J. Diebolt and C. P. Robert, Estimation of finite mixture distributionsthrough Bayesian sampling, J. Roy. Statist. Soc. B, vol. 56, no. 2, pp.363373, 1994.88 J. Diebolt and E. H. S. Ip, Stochastic EM Method and application,in Markov Chain Monte Carlo In Practice, W. R. Gilks, S. Richardson,and D. J. Spiegelhalter, Eds. London, U.K. Chapman  Hall, 1996,pp. 259273.89 S. N. Diggavi and M. Grossglauser, Information transmission over afinite buffer channel, in Proc. IEEE Int. Symp. Information Theory ISIT2000, Sorrento, Italy, June 2000, p. 52.90 R. Douc and C. Matias, Asymptotics of the maximum likelihood estimator for general hidden Markov models, Bernoulli, vol. 7, no. 3, pp.381420, 2001.91 R. Douc, . Moulines, and T. Rydn, Asymptotic properties of themaximum likelihood estimator in autoregressive models with Markovregime, Ann. Statist., submitted for publication.92 A. W. Drake, Observation of a Markov source through a noisy channel,in Proc. IEEE Symp. Signal Transmission and Processing, ColumbiaUniv., New York, 1965, pp. 1218.93 H. Drucker, Speech processing in a high ambient noise environment,IEEE Trans. Audio Electroacoust., vol. AU16, pp. 165168, June 1968.94 M. O. Dunham and R. M. Gray, An algorithm for the design of labeledtransition finitestate vector quantizers, IEEE Trans. Commun.,vol. COM33, pp. 8389, Jan. 1985.95 A. P. Dunmur and D. M. Titterington, The influence of initialconditions on maximum likelihood estimation of the parameters of abinary hidden Markov model, Statist. Probab. Lett., vol. 40, no. 1,pp. 6773, 1998.96 B. Efron, The Jackknife, the Bootstrap and Other ResamplingPlans. Philadelphia, PA SIAM, 1982.97 E. O. Elliott, Estimates of error rates for codes on burstnoise channels,Bell Syst. Tech. J., vol. 42, pp. 19771997, Sept. 1963.98 R. J. Elliott, New finitedimensional filters and smoothers for noisilyobserved Markov chains, IEEE Trans. Inform. Theory, vol. 39, pp.265271, Jan. 1993.99 R. J. Elliott, L. Aggoun, and J. B. Moore, Hidden Markov Models Estimation and Control. New York SpringerVerlag, 1994.100 R. J. Elliott and V. Krishnamurthy, New finitedimensional filters forparameter estimation of discretetime linear Gaussian models, IEEETrans. Automat. Contr., vol. 44, pp. 938951, May 1999.101 Y. Ephraim, A. Dembo, and L. R. Rabiner, A minimum discriminationinformation approach for hidden Markov modeling, IEEE Trans. Inform. Theory, vol. IT35, pp. 10011013, Sept. 1989.102 Y. Ephraim and L. R. Rabiner, On the relations between modelingapproaches for speech recognition, IEEE Trans. Inform. Theory, vol.IT36, pp. 372380, Mar. 1990.103 Y. Ephraim, Speech enhancement using state dependent dynamicalsystem model, in Proc. IEEE Int. Conf. Acoustics, Speech, and SignalProcessing, Mar. 1992, pp. 289292.104 Y. Ephraim and N. Merhav, Lower and upper bounds on the minimummean square error in composite source signal estimation, IEEE Trans.Inform. Theory, vol. 38, pp. 17091724, Nov. 1992.105 Y. Ephraim, Statistical modelbased speech enhancement systems,Proc. IEEE, vol. 80, pp. 15261555, Oct. 1992.106 Y. Ephraim and M. Rahim, On secondorder statistics and linear estimation of cepstral coefficients, IEEE Trans. Speech Audio Processing,vol. 7, pp. 162176, Mar. 1999.107 R. V. Erickson, Functions of Markov chains, Ann. Math. Statist., vol.41, no. 3, pp. 843850, 1970.108 Y. Erlich, On HMM based speech recognition using MCE approach,M.Sc. thesis, Dept. Elec. Eng., TechnionIsrael Inst. Technol., Haifa, Israel, 1996.109 B. S. Everitt and D. J. Hand, Finite Mixture Distributions. LondonNew York Chapman and Hall, 1981.110 V. Fabian, On asymptotically efficient recursive estimation, Ann.Statist., vol. 4, pp. 854866, 1978.111 A. Farag and G. Lugosi, An algorithm to find the global optimum oflefttoright hidden Markov model parameters, Probl. Contr. Inform.Theory, vol. 18, no. 6, pp. 435444, 1989.112 M. Feder and A. Lapidoth, Universal decoding for channels withmemory, IEEE Trans. Inform. Theory, vol. 44, pp. 17261745, Sept.1998.113 M. Feder and N. Merhav, Universal composite hypothesis testing Acompetitive minimax approach, IEEE Trans. Inform. Theory, vol. 48,pp. 15041517, June 2002.114 P. D. Feigin and R. L. Tweedie, Random coefficient autoregressive processes A Markov chain analysis of stationarity and finiteness of moments, J. Time Ser. Anal., vol. 6, no. 1, pp. 114, 1985.115 J. D. Ferguson, Ed., Proc. Symp. Application of Hidden Markov Modelsto Text and Speech. Princeton, NJ IDACRD, 1980.116 L. Finesso, Consistent estimation of the order for Markov and hiddenMarkov chains, Ph.D. dissertation, Univ. Maryland, College Park,1990.117 W. Fischer and K. MeierHellstern, The Markovmodulated Poissonprocess MMPP cookbook, Perf. Eval., vol. 18, pp. 149171, 1992.118 R. J. Fontana, Universal codes for a class of composite sources, IEEETrans. Inform. Theory, vol. IT26, pp. 480482, July 1980.119 , Limit theorems for slowly varying composite sources, IEEETrans. Inform. Theory, vol. IT26, pp. 702709, Nov. 1980.120 R. J. Fontana, R. M. Gray, and J. C. Kieffer, Asymptotically mean stationary channels, IEEE Trans. Inform. Theory, vol. IT27, pp. 308316,May 1981.121 R. J. Fontana, On universal coding for classes of composite and remote sources with memory, IEEE Trans. Inform. Theory, vol. IT27,pp. 784786, Nov. 1981.122 S. Forchhammer and J. Rissanen, Partially hidden Markov models,IEEE Trans. Inform. Theory, vol. 42, pp. 12531256, July 1996.123 L. A. Foreman, Generalization of the Viterbi algorithm, IMA J. Math.Applied in Business  Industry, vol. 4, pp. 351367, 1993.124 G. D. Forney, Jr., The Viterbi algorithm, Proc. IEEE, vol. 61, pp.268278, Mar. 1973.125 M. Fox, Conditions under which a given process is a function of aMarkov chain Abstract, Ann. Math. Statist., vol. 33, p. 1206, 1962.126 C. Francq and M. Roussignol, On white noises driven by hiddenMarkov chains, J. Time Ser. Anal., vol. 18, no. 6, pp. 553578, 1997.127 , Ergodicity of autoregressive processes with Markovswitchingand consistency of the maximumlikelihood estimator, Statistics, vol.32, pp. 151173, 1998.128 D. R. Fredkin and J. A. Rice, Maximum likelihood estimation andidentification directly from singlechannel recordings, Proc. Roy. Soc.London B, vol. 249, pp. 125132, 1992.129 , Bayesian restoration of single channel patch clamp recordings,Biometrics, vol. 48, pp. 427448, 1992.130 D. S. Freed and L. A. Shepp, A Poisson process whose rate is a hiddenMarkov process, Adv. Appl. Probab., vol. 14, no. 1, pp. 2136, 1982.131 J. GarciaFrias and J. Villasenor, Turbo decoding of hidden Markovsources with unknown parameters, in Proc. IEEE Data CompressionConf., Utah, Mar. 1998, pp. 159168.132 H. Furstenberg and H. Kesten, Products of random matrices, Ann.Math. Statist., vol. 31, pp. 457469, 1960.1566 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002133 R. G. Gallager, Information Theory and Reliable Communication. New York Wiley, 1968.134 P. Gaunard, C. G. Mubikangiey, C. Couvreur, and V. Fontaine, Automatic classification of environmental noise events by hidden Markovmodels, in IEEE Proc. Int. Conf. Acoustics, Speech, and Signal Processing, 1998, pp. 36093612.135 A. Gersho and R. M. Gray, Vector Quantization and Signal Compression. Boston, MA Kluwer, 1991.136 E. J. Gilbert, On the identifiability problem for functions offinite Markov chains, Ann. Math. Statist., vol. 30, pp. 688697,1959.137 E. N. Gilbert, Capacity of a burstnoise channel, Bell Syst. Tech. J.,vol. 39, pp. 12531265, Sept. 1960.138 H. Gish and M. Schmidt, Textindependent speaker identification,IEEE Signal Processing Mag., vol. 11, pp. 1832, Oct. 1994.139 P. Giudici, T. Rydn, and P. Vandekerkhove, Likelihoodratio testsfor hidden Markov models, Biometrics, vol. 56, pp. 742747, Sept.2000.140 D. M. Goblirsch and N. Farvardin, Switched scalar quantizers forhidden Markov sources, IEEE Trans. Inform. Theory, vol. 38, pp.14551473, Sept. 1992.141 A. J. Goldsmith and P. P. Varaiya, Capacity, mutual information, andcoding for finitestate Markov channels, IEEE Trans. Inform. Theory,vol. 42, pp. 868886, May 1996.142 G. Golubev and R. Khasminskii, Asymptotically optimal filtering fora hidden Markov model, Math. Methods Statist., vol. 7, no. 2, pp.192209, 1998.143 G. K. Golubev, On filtering for a hidden Markov chain under squareperformance criterion, Probl. Inform. Transm., vol. 36, no. 3, pp.213219, 2000.144 P. S. Gopalakrishnan, D. Kanevsky, A. Ndas, and D. Nahamoo, Aninequality for rational functions with applications to some statistical estimation problems, IEEE Trans. Inform. Theory, vol. 37, pp. 107113,Jan. 1991.145 J. Goutsias and J. M. Mendel, Optimal simultaneous detection and estimation of filtered discrete semiMarkov chains, IEEE Trans. Inform.Theory, vol. 34, pp. 551568, May 1988.146 R. M. Gray, Rate distortion functions for finitestate finitealphabetMarkov sources, IEEE Trans. Inform. Theory, vol. IT17, pp. 127134,Mar. 1971.147 R. M. Gray and L. D. Davisson, The ergodic decomposition of stationary discrete random processes, IEEE Trans. Inform. Theory, vol.IT20, pp. 625636, Sept. 1974.148 R. M. Gray and J. C. Kieffer, Asymptotically mean stationary measures, Ann. Probab., vol. 8, no. 5, pp. 962973, 1980.149 R. M. Gray, A. H. Gray, Jr., G. Rebolledo, and J. E. Shore, Ratedistortion speech coding with a minimum discrimination information distortion measure, IEEE Trans. Inform. Theory, vol. IT27, pp. 708721,Nov. 1981.150 R. M. Gray, M. O. Dunham, and R. L. Gobbi, Ergodicity of Markovchannels, IEEE Trans. Inform. Theory, vol. IT33, pp. 656664, Sept.1987.151 R. M. Gray, Probability, Random Processes, and Ergodic Properties. New York SpringerVerlag, 1988.152 , Entropy and Information Theory. New York SpringerVerlag,1990.153 R. M. Gray and D. L. Neuhoff, Quantization, IEEE Trans. Inform.Theory, vol. 44, pp. 23252383, Oct. 1998.154 G. R. Grimmett and D. R. Stirzaker, Probability and Random Processes. Oxford, U.K. Oxford Univ. Press, 2001.155 M. Gutman, Asymptotically optimal classification for multiple testswith empirically observed statistics, IEEE Trans. Inform. Theory, vol.35, pp. 401408, Mar. 1989.156 J. D. Hamilton, Time Series Analysis. Princeton, NJ Princeton Univ.Press, 1994.157 Y. He and A. Kundu, 2D shape classification using hidden Markovmodels, IEEE Trans. Pattern Anal. Machine Intell., vol. 13, pp.11721184, Nov. 1991.158 H. Heffes, A class of data traffic processescovariance function characterization and related queuing results, Bell Syst. Tech. J., vol. 59, no.6, pp. 897929, JulyAug. 1980.159 H. Heffes and D. M. Lucantoni, A Markov modulated characterizationof packetized voice and data traffic and related statistical multiplexerperformance, IEEE J. Select. Areas Commun., vol. 4, pp. 856868,Sept. 1986.160 A. Heller, On stochastic processes derived from Markov chains, Ann.Math. Statist., vol. 36, pp. 12861291, 1965.161 B. M. Hochwald and P. R. Jelenkovic, State learning and mixing inentropy of hidden Markov processes and the GilbertElliott channel,IEEE Trans. Inform. Theory, vol. 45, pp. 128138, Jan. 1999.162 P. G. Hoel, S. C. Port, and C. J. Stone, Introduction to Stochastic Processes. Boston, MA Houghton Mifflin, 1972.163 U. Holst and G. Lindgren, Recursive estimation in mixture models withMarkov regime, IEEE Trans. Inform. Theory, vol. 37, pp. 16831690,Nov. 1991.164 U. Holst, G. Lindgren, J. Holst, and M. Thuvesholmen, Recursive estimation in switching autoregressions with a Markov regime, J. TimeSer. Anal., vol. 15, no. 5, pp. 489506, 1994.165 X. D. Huang, Y. Ariki, and M. A. Jack, Hidden Markov Models forSpeech Recognition. Edinburgh, Scotland Edinburgh Univ. Press,1990.166 J. P. Hughes, Computing the observed information in the hiddenMarkov model using the EM algorithm, Statist. Probab. Lett., vol. 32,pp. 107114, 1997.167 H. Ito, S.I. Amari, and K. Kobayashi, Identifiability of HiddenMarkov information sources and their minimum degrees of freedom,IEEE Trans. Inform. Theory, vol. 38, pp. 324333, Mar. 1992.168 M. R. James, V. Krishnamurthy, and F. Le Gland, Time discretization ofcontinuoustime filters and smoothers for HMM parameter estimation,IEEE Trans. Inform. Theory, vol. 42, pp. 593605, Mar. 1996.169 A. H. Jazwinski, Stochastic Processes and Filtering Theory. NewYork Academic, 1970.170 F. Jelinek, A fast sequential decoding algorithm using a stack, IBM J.Res. Develop., vol. 13, pp. 675685, Nov. 1969.171 F. Jelinek, L. R. Bahl, and R. L. Mercer, Design of a linguistic statistical decoder for recognition of continuous speech, IEEE Trans. Inform.Theory, vol. IT21, no. 3, pp. 250256, May 1975.172 F. Jelinek, Continuous speech recognition by statistical methods, Proc.IEEE, vol. 64, pp. 532556, Apr. 1976.173 F. Jelinek, Statistical Methods for Speech Recognition. Cambridge,MA MIT Press, 1998.174 J. L. Jensen and N. V. Petersen, Asymptotic normality of the maximumlikelihood estimator in state space models, Ann. Statist., vol. 27, no. 2,pp. 514535, 1999.175 B.H. Juang and L. R. Rabiner, Mixture autoregressive hidden Markovmodels for speech signals, IEEE Trans. Acoust., Speech, Signal Processing, vol. ASSP23, pp. 14041413, Dec. 1985.176 , The segmental kmeans algorithm for estimating parametersof hidden Markov models, IEEE Trans. Acoust., Speech, SignalProcessing, vol. 38, pp. 16391641, Sept. 1990.177 B.H. Juang and S. Katagiri, Discriminative learning for minimum errorclassification, IEEE Trans. Signal Processing, vol. 40, pp. 30433054,Dec. 1992.178 B.H. Juang, W. Chou, and C.H. Lee, Statistical and discriminativemethods for speech recognition, in Automatic Speech and SpeakerRecognition, C.H. Lee, F. K. Soong, and K. K. Paliwal, Eds. Boston,MA Kluwer , 1996, pp. 109132.179 G. K. Kaleh and R. Vallet, Joint parameter estimation and symbol detection for linear or nonlinear unknown channels, IEEE Trans. Commun.,vol. 42, pp. 24062413, July 1994.180 G. K. Kaleh, The BaumWelch algorithm for the detection of timeunsynchronized rectangular PAM signals, IEEE Trans. Commun., vol.42, pp. 260262, Feb.Mar.Apr. 1994.181 H. A. Karlsen, Existence of moments in a stationary stochastic difference equation, Adv. Appl. Probab., vol. 22, pp. 129146, 1990.182 R. L. Kashyap, Identification of a transition matrix of a Markov chainfrom noisy measurements of state, IEEE Trans. Inform. Theory, vol.IT16, pp. 161166, Mar. 1970.183 A. Kehagias, Bayesian classification of hidden Markov models,Mathl. Comput. Modelling, vol. 23, no. 5, pp. 2543, 1996.184 R. Khasminskii, B. Lazareva, and J. Stapleton, Some procedures forstate estimation of a hidden Markov chain with two states, in StatisticalDecision Theory and Related Topics. New York Springer, 1994, vol.V West Lafayette, IN, 1992, pp. 477487.185 R. Khasminskii and O. Zeitouni, Asymptotic filtering for finite stateMarkov chains, Stochastic Processes Their Applic., vol. 63, pp. 110,1996.186 J. C. Kieffer and M. Rahe, Markov channels are asymptotically meanstationary, SIAM J. Math. Anal., vol. 12, no. 3, pp. 293305, May 1981.187 J. C. Kieffer, Strongly consistent codebased identification and orderestimation for constrained finitestate model classes, IEEE Trans. Inform. Theory, vol. 39, pp. 893902, May 1993.188 J. F. C. Kingman, Subadditive ergodic theory, Ann. Probab., vol. 1,no. 6, pp. 883909, 1973.EPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1567189 G. Kitagawa, NonGaussian statespace modeling of nonstationarytime series, J. Amer. Statist. Assoc., vol. 82, no. 400, pp. 10321041,Dec. 1987.190 S. Klein, J. Timmer, and J. Honerkamp, Analysis of multichannel patchclamp recordings by hidden Markov models, Biometrics, vol. 53, pp.870884, Sept. 1997.191 J. A. Kogan, Hidden Markov models estimation via the most informative stopping times for the Viterbi algorithm, in Image Modelsand Their Speech Model Cousins. New York Springer, 1996.Minneapolis, MN, 19931994, IMA Vol. Math. Appl., 80.192 R. Kohn and C. F. Ansley, Comments on Kitagawa 189, J. Amer.Statist. Assoc., vol. 82, no. 400, pp. 10411044, Dec. 1987.193 A. Koski, Modeling ECG signals with hidden Markov models, Artificial Intell. in Medicine, vol. 8, pp. 453471, 1996.194 V. Krishnamurthy, J. B. Moore, and S.H. Chung, Hidden Markovmodel signal processing in presence of unknown deterministic interferences, IEEE Trans. Automat. Contr., vol. 38, pp. 146152, Jan.1993.195 V. Krishnamurthy and J. B. Moore, Online estimation of hiddenMarkov model parameters based on the KullbackLeibler informationmeasure, IEEE Trans. Signal Processing, vol. 41, pp. 25572573,Aug. 1993.196 V. Krishnamurthy, S. Dey, and J. P. LeBlanc, Blind equalizationof IIR channels using hidden Markov models and extended leastsquares, IEEE Trans. Signal Processing, vol. 43, pp. 29943006,Dec. 1995.197 V. Krishnamurthy and R. J. Elliott, A filtered EM algorithm for jointhidden Markov model and sinusoidal parameter estimation, IEEETrans. Signal Processing, vol. 43, pp. 353358, Jan. 1995.198 V. Krishnamurthy and T. Rydn, Consistent estimation of linear andnonlinear autoregressive models with Markov regime, J. Time Ser. Anal,vol. 19, no. 3, pp. 291307, 1998.199 V. Krishnamurthy and A. Logothetis, Adaptive nonlinear filters fornarrowband interference suppression in spreadspectrum CDMAsystems, IEEE Trans. Commun., vol. 47, pp. 742753, May 1999.200 A. Krogh, M. Brown, I. S. Mian, K. Sjlander, and D. Haussler, HiddenMarkov models in computational biology applications to protein modeling, J. Molec. Biol., vol. 235, pp. 15011531, 1994.201 J. L. Krolik and R. H. Anderson, Maximum likelihood coordinate registration for overthehorizon radar, IEEE Trans. Signal Processing, vol.45, pp. 945959, Apr. 1997.202 H.M. Krolzig, MarkovSwitching Vector Autoregressions Modelling,Statistical Inference, and Applications to Business Cycle AnalysisLecture Notes in Economics and Mathematical Systems. Berlin,Germany Springer Verlag, 1997, vol. 454.203 H. R. Knsch, State space and hidden Markov models, in ComplexStochastic Systems, O. E. BarndorffNielsen, D. R. Cox, and C. Kluppelberg, Eds. Boca Raston, FL Chapman  HallCRC Press, 2001,pp. 109173.204 A. Lapidoth and J. Ziv, On the universality of the LZbased decodingalgorithm, IEEE Trans. Inform. Theory, vol. 44, pp. 17461755, Sept.1998.205 A. Lapidoth and P. Narayan, Reliable communication under channeluncertainty, IEEE Trans. Inform. Theory, vol. 44, pp. 21482177, Oct.1998.206 B. Larget, A canonical representation for aggregated Markov processes, J. Appl. Probab., vol. 35, pp. 313324, 1998.207 N. D. Le, B. G. Leroux, and M. L. Puterman, Exact likelihood evaluation in a Markov mixture model for time series of seizure counts,Biometrics, vol. 48, pp. 317323, Mar. 1992.208 J.P. Le Cadre and O. Tremois, Bearingonly tracking for maneuveringsources, IEEE Trans. Aerosp. Electron. Syst., vol. 34, pp. 179193, Jan.1998.209 C.H. Lee, F. K. Soong, and K. K. Paliwal, Eds., Automatic Speech andSpeaker Recognition. Boston, MA Kluwer, 1996.210 F. Le Gland and L. Mevel, Exponential forgetting and geometric ergodicity in hidden Markov models, Math. Contr. Signals Syst., vol. 13, pp.6393, 2000.211 E. L. Lehmann, Theory of Point Estimation. Pacific Grove, CAWadsworth  BrooksCole, 1991.212 B. G. Leroux and M. L. Puterman, Maximumpenalizedlikelihood estimation for independent and Markovdependent mixture models, Biometrics, vol. 48, pp. 545558, June 1992.213 B. G. Leroux, Consistent estimation of a mixing distribution, Ann.Statist., vol. 20, no. 3, pp. 13501360, 1992.214 , Maximumlikelihood estimation for hidden Markov models,Stochastic Processes Their Applic., vol. 40, pp. 127143, 1992.215 S. E. Levinson, L. R. Rabiner, and M. M. Sondhi, An introduction to theapplication of the theory of probabilistic functions of a Markov processto automatic speech recognition, Bell Syst. Tech. J., vol. 62, no. 4, pp.10351074, Apr. 1983.216 S. E. Levinson, Continuously variable duration hidden Markov modelsfor automatic speech recognition, Comput., Speech Language, vol. 1,pp. 2945, 1986.217 J. Li, A. Najmi, and R. M. Gray, Image classification by twodimensional hidden Markov model, IEEE Trans. Signal Processing, vol. 48,pp. 517532, Feb. 2000.218 Y. Linde, A. Buzo, and R. M. Gray, An algorithm for vector quantizerdesign, IEEE Trans. Commun., vol. COM28, pp. 8495, Jan. 1980.219 G. Lindgren, Markov regime models for mixed distributions andswitching regressions, Scan. J. Statist., vol. 5, pp. 8191, 1978.220 G. Lindgren and U. Holst, Recursive estimation of parameters inMarkovmodulated Poisson processes, IEEE Trans. Commun., vol. 43,pp. 28122820, Nov. 1995.221 L. A. Liporace, Maximum Likelihood estimation for multivariate observations of Markov sources, IEEE Trans. Inform. Theory, vol. IT28,pp. 729734, Sept. 1982.222 R. S. Liptser and A. N. Shiryayev, Statistics of Random Processes, PartI. New York SpringerVerlag, 1977.223 C.C. Liu and P. Narayan, Order estimation and sequential universaldata compression of a hidden Markov source by the method ofmixtures, IEEE Trans. Inform. Theory, vol. 40, pp. 11671180, July1994.224 A. Ljolje, Y. Ephraim, and L. R. Rabiner, Estimation of hidden Markovmodel parameters by minimizing empirical error rate, in Proc. IEEEInt. Conf. Acoustics, Speech, and Signal Processing, Albuquerque, NM,Apr. 1990, pp. 709712.225 T. A. Louis, Finding the observed information matrix when using theEM algorithm, J. Roy. Statist. Soc. B, vol. 44, no. 2, pp. 226233, 1982.226 D. G. Luenberger, Linear and Nonlinear Programming. Reading, MAAddisonWesley, 1984.227 A. V. Lukashin and M. Borodovsky, GeneMark.hmm New solutionsfor gene finding, Nucleic Acids Res., vol. 26, no. 4, pp. 11071115,1998.228 I. L. MacDonald and W. Zucchini, Hidden Markov and Other Models forDiscreteValued Time Series. London, U.K. Chapman  Hall, 1997.229 D. T. Magill, Optimal adaptive estimation of sampled stochastic processes, IEEE Trans. Automat. Contr., vol. AC10, no. 4, pp. 434439,Oct. 1965. Cf. Authors reply, IEEE Trans. Automat. Contr., vol. AC14,pp. 216218, Apr. 1969.230 J. Makhoul and R. Schwartz, What is a hidden Markov model, IEEESpectrum, vol. 34, pp. 4447, Dec. 1997.231 M. Maxwell and M. Woodroofe, A local limit theorem for hiddenMarkov chains, Statist. Probab. Lett., vol. 32, pp. 125131, 1997.232 G. J. McLachlan and K. E. Basford, Mixture Models Inference and Applications to Clustering. New York Marcel Dekker, 1988.233 K. S. MeierHellstern, A fitting algorithm for MarkovmodulatedPoisson processes having two arrival rates, Europ. J. Opt. Res., vol.29, pp. 370377, 1987.234 N. Merhav and Y. Ephraim, Hidden Markov modeling using a dominant state sequence with application to speech recognition, Computer,Speech, and Language, vol. 5, pp. 327339, Oct. 1991.235 N. Merhav, Universal classification for hidden Markov models, IEEETrans. Inform. Theory, vol. 37, pp. 15861594, Nov. 1991.236 , Universal coding with minimum probability of codewordlength overflow, IEEE Trans. Inform. Theory, vol. 37, pp. 556563,May 1991.237 N. Merhav and J. Ziv, A Bayesian approach for classification of Markovsources, IEEE Trans. Inform. Theory, vol. 37, pp. 10671071, July1991.238 N. Merhav and Y. Ephraim, A Bayesian classification approach withapplication to speech recognition, IEEE Trans. Signal Processing, vol.39, pp. 21572166, Oct. 1991.239 N. Merhav, Universal detection of messages via finitestate channels,IEEE Trans. Inform. Theory, vol. 46, pp. 22422246, Sept. 2000.240 S. P. Meyn and R. L. Tweedie, Markov Chains and Stochastic Stability. New York SpringerVerlag, 1996.241 D. J. Miller and M. Park, A sequencebased approximate MMSEdecoder for source coding over noisy channels using discrete hiddenMarkov models, IEEE Trans. Commun., vol. 46, pp. 222231, Feb.1998.242 G. E. Monahan, A survey of partially observable Markov decision processes Theory, models, and algorithm, Manag. Sci., vol. 28, no. 1, pp.116, 1982.1568 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 48, NO. 6, JUNE 2002243 M. Mushkin and I. BarDavid, Capacity and coding for the GilbertElliott channels, IEEE Trans. Inform. Theory, vol. 35, pp. 12771290,Nov. 1989.244 A. Ndas, Optimal solution of a training problem in speech recognition, IEEE Trans. Acoust., Speech, Signal Processing, vol. ASSP33,pp. 326329, Feb. 1985.245 D. F. Nicholls and B. G. Quinn, Random Coefficients AutoregressiveModels An Introduction. Lecture Notes in Statist.. Berlin, GermanySpringerFerlag, 1982, vol. 11.246 Y. Normandin, R. Cardin, and R. De Mori, Highperformance connected digit recognition using maximum mutual information estimation, IEEE Trans. Speech Audio Processing, vol. SAP2, pp. 299311,Apr. 1994.247 B. ksendal, Stochastic Differential Equations, 5th ed. Berlin, Germany SpringerVerlag, 1998.248 G. Ott, Compact encoding of stationary Markov sources, IEEE Trans.Inform. Theory, vol. IT13, pp. 8286, Jan. 1967.249 M. Park and D. J. Miller, Lowdelay optimal MAP state estimation inHMMs with application to symbol decoding, IEEE Signal ProcessingLett., vol. 4, pp. 289292, Oct. 1997.250 A. Paz, Introduction to Probabilistic Automata. New York Academic,1971.251 T. Petrie, Probabilistic functions of finite state Markov chains, Ann.Math. Statist., vol. 40, no. 1, pp. 97115, 1969.252 N. Phamdo and N. Farvardin, Optimal detection of discrete Markovsources over discrete memoryless channelsApplications to combinedsourcechannel coding, IEEE Trans. Inform. Theory, vol. 40, pp.186193, Jan. 1994.253 E. Plotnik, M. J. Weinberger, and J. Ziv, Upper bounds on the probability of sequences emitted by finitestate sources and on the redundencyof the LempelZiv algorithm, IEEE Trans. Inform. Theory, vol. 38, pp.6672, Jan. 1992.254 A. B. Poritz, Linear predictive hidden Markov models, in Proc. Symp.Application of Hidden Markov Models to Text and Speech, J. D. Ferguson, Ed. Princeton, NJ IDACRD, 1980, pp. 88142.255 A. B. Poritz, Linear predictive hidden Markov models and the speechsignal, in Proc. IEEE Int. Conf. Acoustics, Speech, and Signal Processing, 1982, pp. 12911294.256 , Hidden Markov models A guided tour, in Proc. IEEE Int. Conf.Acoustics, Speech, and Signal Processing, 1988, pp. 713.257 B. R. Povlow and S. M. Dunn, Texture classification using noncausalhidden Markov models, IEEE Trans. Pattern Anal. Machine Intell., vol.17, pp. 10101014, Oct. 1995.258 M. B. Priestley, Spectral Analysis and Time Series. New York Academic, 1994.259 J. G. Proakis and M. Salehi, Communication Systems Engineering, 2nded. Upper Saddle River, NJ PrenticeHall, 2002.260 W. Qian and D. M. Titterington, Estimation of parameters in hiddenMarkov models, Phil. Trans. Roy. Soc., vol. 337, pp. 407428, 1991.London Series A.261 L. R. Rabiner, J. G. Wilpon, and B.H. Juang, A segmental kmeanstraining procedure for connected word recognition, ATT Tech. J., vol.65, pp. 2140, MayJune 1986.262 L. R. Rabiner, A tutorial on hidden Markov models and selected applications in speech recognition, Proc. IEEE, vol. 77, pp. 257286, Feb.1989.263 L. R. Rabiner and B.H. Juang, Fundamentals of Speech Recognition. Englewood Cliffs, NJ PrenticeHall, 1993.264 G. Radons, J. D. Becker, B. Dlfer, and J. Krger, Analysis, classification, and coding of multielectrode spike trains with hidden Markovmodels, Biol. Cybern., vol. 71, pp. 359373, 1994.265 J. Raviv, Decision making in Markov chains applied to the problemof pattern recognition, IEEE Trans. Inform. Theory, vol. IT3, pp.536551, Oct. 1967.266 R. A. Redner and H. F. Walker, Mixture densities, maximum likelihoodand the EM algorithm, SIAM Rev., vol. 26, no. 2, pp. 195239, Apr.1984.267 J. Rissanen, Modeling by shortest data description, Automatica, vol.14, pp. 465471, 1978.268 , Universal coding, information, prediction, and estimation, IEEETrans. Inform. Theory, vol. IT30, pp. 629636, July 1984.269 C. P. Robert, G. Celeux, and J. Diebolt, Bayesian estimation of hiddenMarkov chains A stochastic implementation, Statist. Probab. Lett., vol.16, pp. 7783, 1993.270 C. P. Robert, Mixtures of distributions Inference and estimation, inMarkov Chain Monte Carlo In Practice, W. R. Gilks, S. Richardson,and D. J. Spiegelhalter, Eds. London, U.K. Chapman  Hall, 1996.271 C. P. Robert and D. M. Titterington, Reparameterization strategies forhidden Markov models and Bayesian approaches to maximum likelihood estimation, Statist. Comput., vol. 8, pp. 145158, 1998.272 M. Rosenblatt, Markov Processes, Structure and Asymptotic Behavior. New York SpringerVerlag, 1971.273 T. Rydn, Parameter estimation for Markov modulated Poissonprocesses, Commun. Statist. Stochastic Models, vol. 10, no. 4, pp.795829, 1994.274 , Consistency and asymptotically normal parameter estimates forhidden Markov models, Ann. Statisti., vol. 22, no. 4, pp. 18841895,1994.275 , An EM algorithm for estimation in Markovmodulated Poissonprocesses, Comput. Statist. Data Anal., vol. 21, pp. 431447, 1996.276 , Consistent and asymptotically normal parameter estimates forMarkov modulated Poisson processes, Scand. J. Statist., vol. 22, pp.295303, 1995.277 , Estimating the order of hidden Markov models, Statistics, vol.26, pp. 345354, 1995.278 , On identifiability and order of continuoustime aggregatedMarkov chains, Markovmodulated Poisson processes, and phasetypedistributions, J. Appl. Probab., vol. 33, pp. 640653, 1996.279 , On recursive estimation for hidden Markov models, StochasticProcesses Their Applic., vol. 66, pp. 7996, 1997.280 T. Rydn and D. M. Titterington, Computational Bayesian analysis ofhidden Markov models, J. Comput. Graph. Statist., vol. 7, no. 2, pp.194211, 1998.281 T. Rydn, Asymptotically efficient recursive estimation for incompletedata models using the observed information, Metrika, vol. 47, pp.119145, 1998.282 T. Rydn, T. Tersvirta, and S. Asbrink, Stylized facts of daily returns series and the hidden Markov model, J. Appl. Econ., vol. 13, pp.217244, 1998.283 M. J. Sabin and R. M. Gray, Global convergence and empirical consistency of the generalized Lloyd algorithm, IEEE Trans. Inform. Theory,vol. IT32, pp. 148155, Mar. 1986.284 J. Sansom, A hidden Markov model for rainfall using breakpoint data,J. Climate, vol. 11, pp. 4253, Jan. 1998.285 L. L. Scharf, D. D. Cox, and C. J. Masreliez, Modulo2 phasesequence estimation, IEEE Trans. Inform. Theory, vol. IT26, pp.615620, Sept. 1980.286 L. L. Scharf, Statistical Signal Processing. New York AddisonWesley, 1991.287 G. Schwarz, Estimating the dimension of a model, Ann. Statisti., vol.6, no. 2, pp. 461464, 1978.288 A. Segall, Stochastic processes in estimation theory, IEEE Trans. Inform. Theory, vol. IT22, pp. 275286, May 1976.289 , Recursive estimation from discretetime point processes, IEEETrans. Inform. Theory, vol. IT22, pp. 422431, July 1976.290 C. E. Shannon, A mathematical theory of communication, Bell Syst.Tech. J., vol. 27, pp. 379423, 623656, 1948.291 J. E. Shore and R. W. Johnson, Axiomatic derivation of the principle ofmaximum entropy and the principle of minimum crossentropy, IEEETrans. Inform. Theory, vol. IT26, pp. 2637, Jan. 1980. Cf. commentsand corrections, IEEE Trans. Inform. Theory, vol. IT29, pp. 942943,Nov. 1983.292 R. H. Shumway and D. S. Stoffer, An approach to time series smoothingand forecasting using the EM algorithm, J. Time Ser. Anal., vol. 3, no.4, pp. 253264, 1982.293 P. Smyth, Hidden Markov models for fault detection in dynamic systems, Pattern Recogn., vol. 27, no. 1, pp. 149164, 1994.294 , Markov monitoring with unknown states, IEEE J. Select. AreasCommun., vol. 12, pp. 16001612, Sept. 1994.295 D. L. Snyder and M. I. Miller, Random Point Processes in Time andSpace. New York Springer, 1991.296 R. L. Streit and R. F. Barrett, Frequency line tracking using hiddenMarkov models, IEEE Trans. Acoust., Speech, Signal Processing, vol.38, pp. 586598, Apr, 1990.297 H. Teicher, Identifiability of mixtures of product measures, Ann. Math.Statist., vol. 38, no. 4, pp. 13001302, 1967.298 L. Thoraval, G. Carrault, and J. J. Bellanger, Heart signal recognitionby hidden Markov modelsThe ECG case, Methods Inform. Medicine,vol. 33, pp. 1014, 1994.299 D. M. Titterington, Comments on Application of the conditional populationmixture model to image segmentation, IEEE Trans. PatternAnal. Machine Intell., vol. PAMI6, pp. 656657, Sept. 1984.300 , Recursive parameter estimation using incomplete data, J. Roy.Statist. Soc. B, vol. 46, no. 2, pp. 257267, 1984.EPHRAIM AND MERHAV HIDDEN MARKOV PROCESSES 1569301 D. M. Titterington, A. F. M. Smith, and U. E. Makov, Statistical Analysisof Finite Mixtures Distributions. New York Wiley, 1985.302 W. Turin, MAP symbol decoding in channels with error bursts, IEEETrans. Inform. Theory, vol. 47, pp. 18321838, July 2001.303 T. R. Turner, M. A. Cameron, and P. J. Thomson, Hidden Markovchains in generalized linear models, Canad. J. Statist., vol. 26, no. 1,pp. 107125, 1998.304 V. N. Vapnik, Estimation of Dependencies Based on EmpiricalData. New York SpringerVerlag, 1982.305 , The Nature of Statistical Learning Theory. New York SpringerVerlag, 1995.306 L. Venkataramanan, J. L. Walsh, R. Kuc, and F. J. Sigworth, Identification of hidden Markov models for ion channel currentsPart I Colored background noise, IEEE Trans. Signal Processing, vol. 46, pp.19011915, July 1998.307 L. Venkataramanan, R. Kuc, and F. J. Sigworth, Identification of hiddenMarkov models for ion channel currentsPart II Statedependent excess noise, IEEE Trans. Signal Processing, vol. 46, pp. 19161929, July1998.308 A. J. Viterbi, Error bounds for convolutional codes and an asymptotically optimum decoding algorithm, IEEE Trans. Inform. Theory, vol.IT13, pp. 260269, Apr. 1967.309 M. J. Weinberger, N. Merhav, and M. Feder, Optimal sequentialprobability assignment for individual sequences, IEEE Trans. Inform.Theory, vol. 40, pp. 384396, Mar. 1994.310 E. Weinstein, M. Feder, and A. V. Oppenheim, Sequential algorithmsfor parameter estimation based on the KullbackLeibler informationmeasure, IEEE Trans. Acoust., Speech, Signal Processing, vol. 38, pp.16521654, Sept. 1990.311 L. R. Welch, unpublished work.312 C. J. Wellekens, Explicit time correlation in hidden Markov models forspeech recognition, in Proc. IEEE Int. Conf. Acoustics, Speech, andSignal Processing, Apr. 1987, pp. 384386.313 L. B. White, Cartesian hidden Markov models with applications, IEEETrans. Signal Processing, vol. 40, pp. 16011604, June 1992.314 L. B. White, R. Mahony, and G. D. Brushe, Lumpable hidden MarkovmodelsModel reduction and reduced complexity filtering, IEEETrans. Automat. Contr., vol. 45, pp. 22972306, Dec. 2000.315 W. M. Wonham, Some applications of stochastic differential equationsto optimal nonlinear filtering, SIAM J. Contr., ser. A, vol. 2, no. 3, pp.347369, 1965.316 C. F. J. Wu, On the convergence properties of theEM algorithm, Ann.Statist., vol. 11, no. 1, pp. 95103, 1983.317 W. R Wu and S.C. Wei, Rotation and Grayscale transforminvarianttexture classification using spiral resampling, subband decomposition,and hidden Markov models, IEEE Trans. Image Processing, vol. 5, pp.14231434, Oct. 1996.318 A. D. Wyner and J. Ziv, The ratedistortion function for source codingwith side information at the decoder, IEEE Trans. Inform. Theory, vol.IT22, pp. 110, Jan. 1976.319 , Some asymptotic properties of the entropy of a stationary ergodicdata source with applications to data compression, IEEE Trans. Inform.Theory, vol. 35, pp. 12501258, Nov. 1989.320 X. Xie and R. J. Evans, Multiple target tracking and multiple frequencyline tracking using hidden Markov models, IEEE Trans. Signal Processing, vol. 39, pp. 26592676, Dec. 1991.321 , Multiple frequency line tracking with hidden MarkovmodelsFurther results, IEEE Trans. Signal Processing, vol. 41, pp.334343, Jan. 1993.322 , Frequencywavenumber tracking using hidden Markov models,IEEE Trans. Signal Processing, vol. 41, pp. 13911394, Mar. 1993.323 Y.C. Yao, Estimation of noisy telegraph processes Nonlinear filteringversus nonlinear smoothing, IEEE Trans. Inform. Theory, vol. IT31,pp. 444446, May 1985.324 O. Zeitouni and A. Dembo, Exact filters for the estimation of thenumber of transitions of finitestate continuoustime Markov processes, IEEE Trans. Inform. Theory, vol. 34, pp. 890893, July 1988.325 O. Zeitouni, J. Ziv, and N. Merhav, When is the generalized likelihood ratio test optimal, IEEE Trans. Inform. Theory, vol. IT38, pp.15971602, Sept. 1992.326 J. Ziv and A. Lempel, Compression of individual sequences via variablerate coding, IEEE Trans. Inform. Theory, vol. IT24, pp. 530536,Sept. 1978.327 J. Ziv, Universal decoding for finitestate channels, IEEE Trans. Inform. Theory, vol. IT31, pp. 453460, July 1985.328 , On classification with empirically observed statistics anduniversal data compression, IEEE Trans. Inform. Theory, vol. 34, pp.278286, Mar. 1988.329 , Compression, tests for randomness, and estimating the statisticalmodel of an individual sequence, in Proc. Sequences, R. M. Capocelli,Ed. New York SpringerVerlag, 1990, pp. 366373.330 J. Ziv and N. Merhav, Estimating the number of states of a finitestatesource, IEEE Trans. Inform. Theory, vol. 38, pp. 6165, Jan. 1992.331 W. Zucchini and P. Guttorp, A hidden Markov model for spacetimeprecipitation, Water Resources Res., vol. 27, no. 8, pp. 19171923,Aug. 1991.
