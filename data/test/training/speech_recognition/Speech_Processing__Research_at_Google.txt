Speech Processing - Research at Google     {{link.text}} {{link.text}} Home Publications People Teams   Blog Work at Google     More Google Scholar YouTube Tech Talks Follow Us Google+ Twitter Google Google About Google Privacy Policy Terms       Speech Processing Our goal in Speech Technology Research is twofold: to make speaking to devices around you (home, in car), devices you wear (watch), devices with you (phone, tablet) ubiquitous and seamless. Our research focuses on what makes Google unique: computing scale and data. Using large scale computing resources pushes us to rethink the architecture and algorithms of speech recognition, and experiment with the kind of methods that have in the past been considered prohibitively expensive. We also look at parallelism and cluster computing in a new light to change the way experiments are run, algorithms are developed and research is conducted. The field of speech recognition is data-hungry, and using more and more data to tackle a problem tends to help performance but poses new challenges: how do you deal with data overload? How do you leverage unsupervised and semi-supervised techniques at scale? Which class of algorithms merely compensate for lack of data and which scale well with the task at hand? Increasingly, we find that the answers to these questions are surprising, and steer the whole field into directions that would never have been considered, were it not for the availability of significantly higher orders of magnitude of data. We are also in a unique position to deliver very user-centric research. Researchers have the wealth of millions of users talking to Voice Search or the Android Voice Input every day. and can conduct live experiments to test and benchmark new algorithms directly in a realistic controlled environment. Whether these are algorithmic performance improvements or user experience and human-computer interaction studies, we keep our users very close to make sure we solve real problems and have real impact. We have a huge commitment to the diversity of our users, and have made it a priority to deliver the best performance to every language on the planet. We currently have systems operating in more than 55 languages and we keep expanding our reach to more and more users. The challenges of internationalizing at scale is immense and rewarding. Many speakers of the languages we reach never had the experience of speaking to a computer before, and breaking this new ground brings up new research on how to better serve this wide variety of users. Combined with the unprecedented translation capabilities of Google Translate, we are now at the forefront of research in speech-to-speech translation and one step closer to a universal translator. In terms of a challenge, indexing and transcribing the webâ€™s audio content is another challenge we have set for ourself, and is nothing short of gargantuan, both in scope and difficulty. The videos uploaded every day on YouTube range from lectures, to newscasts, music videos and of course... cat videos. Making sense of them takes the challenges of noise robustness, music recognition, speaker segmentation, language detection to new levels of difficulty. The payoff is immense: imagine making every lecture on the web accessible to every language; this is the kind of impact we are striving for. 197 Publications   AN ACOUSTIC KEYSTROKE TRANSIENT CANCELER FOR SPEECH COMMUNICATION TERMINALS USING A SEMI-BLIND ADAPTIVE FILTER MODEL Herbert Buchner, Simon Godsill, Jan Skoglund ICASSP (2016)       AutoMOS: Learning a non-intrusive assessor of naturalness-of-speech Brian Patton, Yannis Agiomyrgiannakis , Michael Terry, Kevin Wilson , Rif A. Saurous, D. Sculley NIPS 2016 End-to-end Learning for Speech and Audio Processing Workshop (to appear)       Automatic Optimization of Data Perturbation Distributions for Multi-Style Training in Speech Recognition Mortaza Doulaty, Richard Rose , Olivier Siohan Proceedings of the IEEE 2016 Workshop on Spoken Language Technology (SLT2016)   BI-MAGNITUDE PROCESSING FRAMEWORK FOR NONLINEAR ACOUSTIC ECHO CANCELLATION ON ANDROID DEVICES Yiteng (Arden) Huang, Jan Skoglund , Alejandro Luebs International Workshop on Acoustic Signal Enhancement 2016 (IWAENC2016) (to appear)       Building Statistical Parametric Multi-speaker Synthesis for Bangladeshi Bangla Alexander Gutkin , Linne Ha, Martin Jansche , Oddur Kjartansson, Knot Pipatsrisawat, Richard Sproat SLTU-2016 5th Workshop on Spoken Language Technologies for Under-resourced languages, 09-12 May 2016, Yogyakarta, Indonesia; Procedia Computer Science, Elsevier B.V., pp. 194-200       Complex Linear Projection (CLP): A Discriminative Approach to Joint Feature Extraction and Acoustic Modeling Ehsan Variani , Tara N. Sainath , Izhak Shafran , Michiel Bacchiani Interspeech 2016 (2016)     Contextual prediction models for speech recognition Yoni Halpern, Keith Hall , Vlad Schogol, Michael Riley , Brian Roark , Gleb Skobeltsyn , Martin Baeuml Proceedings of Interspeech 2016 (to appear)       Cross-lingual projection for class-based language models Beat Gfeller, Vlad Schogol, Keith Hall ACL2016       Directly Modeling Voiced and Unvoiced Components in Speech Waveforms by Neural Networks Keiichi Tokuda, Heiga Zen Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE (2016), pp. 5640-5644       Distributed representation and estimation of WFST-based n-gram models Cyril Allauzen , Michael Riley , Brian Roark Proceedings of the ACL Workshop on Statistical NLP and Weighted Automata (StatFSM) (2016), pp. 32-41       End-to-End Text-Dependent Speaker Verification Georg Heigold , Ignacio Moreno , Samy Bengio , Noam M. Shazeer International Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE (2016)     Factored Spatial and Spectral Multichannel Raw Waveform CLDNNs Tara N. Sainath , Ron J. Weiss , Kevin W. Wilson , Arun Narayanan , Michiel Bacchiani International Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE (2016)       Fast, Compact, and High Quality LSTM-RNN Based Statistical Parametric Speech Synthesizers for Mobile Devices Heiga Zen , Yannis Agiomyrgiannakis , Niels Egberts, Fergus Henderson , PrzemysÅ‚aw Szczepaniak Proc. Interspeech, San Francisco, CA, USA (2016)   GLOBALLY OPTIMIZED LEAST-SQUARES POST-FILTERING FOR MICROPHONE ARRAY SPEECH ENHANCEMENT Yiteng (Arden) Huang, Alejandro Luebs, Jan Skoglund , W. Bastiaan Kleijn ICASSP (2016)       High quality agreement-based semi-supervised training data for acoustic modeling FÃ©lix de Chaumont Quitry , Asa Oines, Pedro Moreno , Eugene Weinstein 2016 IEEE Workshop on Spoken Language Technology   Learning Compact Recurrent Neural Networks Zhiyun Lu, Vikas Sindhwani , Tara Sainath IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2016       Learning N-gram Language Models from Uncertain Data Vitaly Kuznetsov , Hank Liao , Mehryar Mohri , Michael Riley , Brian Roark Interspeech (2016)       Learning Personalized Pronunciations for Contact Names Recognition Tony Bruguier , Fuchun Peng , Francoise Beaufays Interspeech 2016 (to appear)       Listen, Attend and Spell: A Neural Network for Large Vocabulary Conversational Speech Recognition William Chan, Navdeep Jaitly , Quoc V. Le , Oriol Vinyals ICASSP (2016)       Lower Frame Rate Neural Network Acoustic Models Golan Pundak , Tara Sainath Interspeech (2016)       Modeling Time-Frequency Patterns with LSTM vs. Convolutional Architectures for LVCSR Tasks Tara N. Sainath , Bo Li Proc. Interspeech, ISCA (2016) (to appear)       Multi-Language Multi-Speaker Acoustic Modeling for LSTM-RNN based Statistical Parametric Speech Synthesis Bo Li , Heiga Zen Proc. Interspeech, ISCA (2016) (to appear)       Neural Network Adaptive Beamforming for Robust Multichannel Speech Recognition Bo Li , Tara N. Sainath , Ron J. Weiss , Kevin W. Wilson , Michiel Bacchiani Proc. Interspeech, ISCA (2016)     Neural Speech Recognizer: Acoustic-to-Word LSTM Model for Large Vocabulary Speech Recognition Hagen Soltau, Hank Liao , Hasim Sak ArXiv e-prints (2016)   ON PRE-FILTERING STRATEGIES FOR THE GCC-PHAT ALGORITHM Hong-Goo Kang, Michael Graczyk, Jan Skoglund International Workshop on Acoustic Signal Enhancement 2016 (IWAENC 2016) (to appear)     On The Compression Of Recurrent Neural Networks With An Application To LVCSR Acoustic Modeling For Embedded Speech Recognition Rohit Prabhavalkar , Ouais Alsharif , Antoine Bruguier , Ian McGraw Proceedings of International Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE (2016)       On the Efficient Representation and Execution of Deep Acoustic Models Raziel Alvarez , Rohit Prabhavalkar , Anton Bakhtin Proceedings of Annual Conference of the International Speech Communication Association (Interspeech) (2016)     Personalized Speech Recognition On Mobile Devices Ian McGraw, Rohit Prabhavalkar , Raziel Alvarez , Montse Gonzalez Arenas, Kanishka Rao , David Rybach, Ouais Alsharif , Hasim Sak , Alexander Gruenstein , FranÃ§oise Beaufays , Carolina Parada Proceedings of International Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE (2016)       Pynini: A Python library for weighted finite-state grammar compilation Kyle Gorman Proceedings of the ACL Workshop on Statistical NLP and Weighted Automata (2016), pp. 75-80       Recent Advances in Google Real-time HMM-driven Unit Selection Synthesizer Xavi Gonzalvo , Siamak Tazari, Chun-an Chan, Markus Becker, Alexander Gutkin , Hanna Silen INTERSPEECH 2016, Sep 8-12, San Francisco, USA, pp. 2238-2242     Reducing the Computational Complexity of Multimicrophone Acoustic Models with Integrated Feature Extraction Tara N. Sainath , Arun Narayanan , Ron J. Weiss , Ehsan Variani , Kevin W. Wilson , Michiel Bacchiani , Izhak Shafran Proc. Interspeech, ISCA (2016)       Robust Estimation of Reverberation Time Using Polynomial Roots Ian Kelly , Francis Boland, Jan Skoglund AES 60th Conference on Dereverberation and Reverberation of Audio, Music, and Speech, Google Ireland Ltd. (2016)       Selection and Combination of Hypotheses for Dialectal Speech Recognition Victor Soto, Olivier Siohan , Mohamed Elfeky , Pedro J. Moreno ICASSP 2016       Semantic Model for Fast Tagging of Word Lattices Leonid Velikovich IEEE Spoken Language Technology (SLT) Workshop (2016) (to appear)       THE MATCHING-MINIMIZATION ALGORITHM, THE INCA ALGORITHM AND A MATHEMATICAL FRAMEWORK FOR VOICE CONVERSION WITH UNALIGNED CORPORA. Yannis Agiomyrgiannakis ICASSP, IEEE (2016)       TTS for Low Resource Languages: A Bangla Synthesizer Alexander Gutkin , Linne Ha, Martin Jansche , Knot Pipatsrisawat, Richard Sproat 10th edition of the Language Resources and Evaluation Conference, 23-28 May 2016, PortoroÅ¾ (Slovenia), European Language Resources Association (ELRA), Paris, France, pp. 2005-2010    
