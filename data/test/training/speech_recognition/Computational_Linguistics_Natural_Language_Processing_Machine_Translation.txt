International Journal of  Computa t iona l  Lingu is t ics    Ch inese  Language  Process ing      Aims and Scope International Journal of Computational Linguistics and Chinese Language Processing IJCLCLP is an international journal published by the Association for Computational Linguistics and Chinese Language Processing ACLCLP. This journal was founded in August 1996 and is published four issues per year since 2005. This journal covers all aspects related to computational linguistics and speechtext processing of all natural languages. Possible topics for manuscript submitted to the journal include, but are not limited to   Computational Linguistics  Natural Language Processing  Machine Translation  Language Generation  Language Learning  Speech AnalysisSynthesis  Speech RecognitionUnderstanding  Spoken Dialog Systems  Information Retrieval and Extraction  Web Information ExtractionMining  Corpus Linguistics  MultilingualCrosslingual Language Processing  Membership  Subscriptions If you are interested in joining ACLCLP, please see appendix for further information.  Copyright  The Association for Computational Linguistics and Chinese Language Processing International Journal of Computational Linguistics and Chinese Language Processing is published four issues per volume by the Association for Computational Linguistics and Chinese Language Processing. Responsibility for the contents rests upon the authors and not upon ACLCLP, or its members. Copyright by the Association for Computational Linguistics and Chinese Language Processing. All rights reserved. No part of this journal may be reproduced, stored in a retrieval system, or transmitted, in any form or by any means, electronic, mechanical photocopying, recording or otherwise, without prior permission in writing form from the Editorin Chief.  Cover Calligraphy by Professor ChingChun Hsieh, founding president of ACLCLP Text excerpted and compiled from ancient Chinese classics, dating back to 700 B.C. This calligraphy honors the interaction and influence between text and language     International Journal of Computational Linguistics and Chinese Language Processing vol. 17, no. 4, December 2012  Contents Special Issue Articles  Selected Papers from ROCLING XXIV Forewords... ........LiangChih Yu, Richard TzongHan Tsai, ChiaPing Chen, ChengZen Yang, and ShuKai Hsieh, Guest Editor i Papers Detecting and Correcting Syntactic Errors in Machine Translation Using FeatureBased Lexicalized Tree Adjoining Grammars.........WeiYun Ma, and Kathleen McKeown  1   TQDL Integrated Models for CrossLanguage Document Retrieval.......................................................................................LongYue Wang, Derek F. Wong, and Lidia S. Chao  15    ................. 33   ... 49    ..... 69     Reviewers List  2012 Index.. 85       The Association for Computational Linguistics and Chinese Language Processing                                                                               i Forewords The 24th Conference on Computational Linguistics and Speech Processing ROCLING 2012 was held at Yuan Ze University, on September 2122, 2012. ROCLING is the leading and most comprehensive conference on computational linguistics and speech processing in Taiwan, bringing together researchers, scientists and industry participants to present their work and discuss recent trends in the field. This special issue presents extended and reviewed versions of five papers meticulously selected from ROCLING 2012. The first paper Detecting and Correcting Syntactic Errors in Machine Translation Using FeatureBased Lexicalized Tree Adjoining Grammars proposes the use of tree adjoining grammars TAG to simultaneously detect and correct multiple ungrammatical types for machine translation. The second paper TQDL Integrated Models for CrossLanguage Document Retrieval proposes a framework integrating four statistical methods Translation model, Query generation model, Document retrieval model and Length Filter model for crosslanguage information retrieval CLIR. The four independent methods work together to deal with the term disambiguation, query generation and document retrieval. The third paper Domain Dependent Word Polarity Analysis for Sentiment Classification explores the polarity of words in the corpora from three different application domains real estate, hotel and restaurant, and then proposes a method to capture their sentiment differences. The fourth paper Exploiting Machine Learning Models for Chinese Legal Documents Labeling, Case Classification, and Sentencing Prediction discusses various interesting topics for Chinese legal document processing such as robbery and intimidation case classification. The fifth paper Speech Recognition Leveraging Histogram Equalization Methods uses a histogram equalization HEQ method for speech feature normalization to reduce the word error rate in speech recognition. The Guest Editors of this special issue would like to thank all of the authors and reviewers for their contributions. We would also like to thank all the researchers and participants for sharing their knowledge and experience at the conference.  Guest Editors LiangChih Yu Department of Information Management, Yuan Ze University, Taiwan, R.O.C. Richard TzongHan Tsai Department of Computer Science and Engineering, Yuan Ze University, Taiwan, R.O.C. ChiaPing Chen Department of Computer Science and Engineering, National Sun YatSen University, Taiwan, R.O.C. ChengZen Yang Department of Computer Science and Engineering, Yuan Ze University, Taiwan, R.O.C. ShuKai Hsieh Graduate Institute of Linguistics, National Taiwan University, Taiwan, R.O.C.  Computational Linguistics and Chinese Language Processing Vol. 17, No. 4, December 2012, pp. 114                                       1  The Association for Computational Linguistics and Chinese Language Processing Detecting and Correcting Syntactic Errors in   Machine Translation Using FeatureBased   Lexicalized Tree Adjoining Grammars WeiYun Ma, and Kathleen McKeown Abstract Statistical machine translation has made tremendous progress over the past ten years. The output of even the best systems, however, is often ungrammatical because of the lack of sufficient linguistic knowledge. Even when systems incorporate syntax in the translation process, syntactic errors still result. To address this issue, we present a novel approach for detecting and correcting ungrammatical translations. In order to simultaneously detect multiple errors and their corresponding words in a formal framework, we use featurebased lexicalized tree adjoining grammars, where each lexical item is associated with a syntactic elementary tree, in which each node is associated with a set of featurevalue pairs to define the lexical items syntactic usage. Our syntactic error detection works by checking the feature values of all lexical items within a sentence using a unification framework. In order to simultaneously detect multiple error types and track their corresponding words, we propose a new unification method which allows the unification procedure to continue when unification fails and also to propagate the failure information to relevant words. Once error types and their corresponding words are detected, one is able to correct errors based on a unified consideration of all related words under the same error types. In this paper, we present some simple mechanism to handle part of the detected situations. We use our approach to detect and correct translations of six single statistical machine translation systems. The results show that most of the corrected translations are improved. Keywords Machine Translation, Syntactic Error, Post Editing, Tree Adjoining Grammar, Unification.                                                   Department of Computer Science, Columbia University, New York, USA Email ma, kathycs.columbia.edu   2                                           WeiYun Ma and Kathleen McKeown 1. Introduction Statistical machine translation has made tremendous progress over the past ten years. The output of even the best systems, however, is often ungrammatical because of the lack of sufficient linguistic knowledge. Even when systems incorporate syntax in the translation process, syntactic errors still result. We have developed a novel, postediting approach which features 1 the use of XTAG grammar, a rulebased grammar developed by linguists, 2 the ability to simultaneously detect multiple ungrammatical types and their corresponding words by using unification of feature structures, and 3 the ability to simultaneously correct multiple ungrammatical types based on the detection information. To date, we have developed the infrastructure for this approach and demonstrated its utility for agreement errors. As illustrative examples, consider the following three ungrammatical English sentences  1. Many young student play basketball. 2. John play basketball and Tom also play basketball. 3. John thinks to play basketball.  In 1 and 2 above, number agreement errors between the subjects and verbs and quantifier cause the sentences to be ungrammatical, while in 3, the infinitive following the main verb makes it ungrammatical. One could argue that an existing grammar checker could do the error detection for us, but if we use Microsoft Word 2010 MS Words grammar checker Heidorn, 2000 to check the three sentences, the entire first sentence will be underlined with green wavy lines without any indication of what should be corrected, while no errors are detected in 2 and 3. The grammar we use is based on a featurebased lexicalized tree adjoining grammars FBLTAG English grammar, named XTAG grammar XTAG group, 2001. In FBLTAG, each lexical item is associated with a syntactic elementary tree, in which each node is associated with a set of featurevalue pairs, called Attribute Value Matrices AVMs. AVMs define the lexical items syntactic usage. Our syntactic error detection works by checking the AVM values of all lexical items within a sentence using a unification framework. Thus, we use the feature structures in the AVMs to detect the error type and corresponding words. In order to simultaneously detect multiple error types and track their corresponding words, we propose a new unification method which allows the unification procedure to continue when unification fails and also to propagate the failure information to relevant words. We call the modified unification a fail propagation unification.                      Detecting and Correcting Syntactic Errors in                  3 Machine Translation Using FeatureBased Lexicalized Tree Adjoining Grammars 2. Related Work Grammar checking is mostly used in word processors as a writing aid. Three methods are widely used for grammar checking given a sentence statisticbased checking, rulebased checking and syntaxbased checking. In statisticbased checking, POS tag sequences Atwell  Elliot, 1987 or an Ngram language model Alam et al., 2006 Wu et al., 2006 is trained from a training corpus and uncommon sequences in the training corpus are considered incorrect. Huang et al. 2010 extracted erroneous and correct patterns of consecutive words from the data of an onlineediting diary website. In rulebased checking, a set of hand crafted rules out of words, POS tags and chucks Naber, 2003 or parsing results Heidorn, 2000 are designed to detect errors. In syntaxbased checking, Jensen et al. 1993 utilize a parsing procedure to detect errors each sentence must be syntactically parsed a sentence is considered incorrect if parsing does not succeed. Focusing on machine translations grammar checking, Stymne and Ahrenberg 2010 utilized an existing rulebased Swedish grammar checker, as a postprocessing tool for their EnglishSwedish translation system. They tried to fix the ungrammatical translation parts by applying the grammar checkers correction suggestions. In contrast of their using an existing grammar checker, we developed our own novel grammar checker for translated English in order to better controlling the quality of error detection, error types, and the directions of error correction in translation context. Our approach is a mix of rulebased checking and syntaxbased checking The XTAG English grammar is designed by linguists while the detecting procedure is based on syntactic operations which dynamically reference the grammar. The work could be regarded as an extension of Ma  McKeown, 2011, in which grammatical error detection based on XTAG English grammar is carried out to filter out ungrammatical combined translations in their framework of system combination for machine translation. In contrast of Ma  McKeown, 2011, our approach is not only capable to detect grammatical errors, but also has the capability of identifying error types and errors causes, and correcting certain cases of errors. 3. Background We briefly introduce the FBLTAG formalism and XTAG grammar in this section. 3.1 FeatureBased Lexicalized Tree Adjoining Grammars FBLTAG is based on tree adjoining grammar TAG proposed in Joshi et al., 1975. The TAG formalism is a formal tree rewriting system, which consists of a set of elementary trees, corresponding to minimal linguistic structures that localize the dependencies, such as specifying the predicateargument structure of a lexeme. Elementary trees are divided into   4                                           WeiYun Ma and Kathleen McKeown initial and auxiliary trees. Initial trees are those for which all nonterminal nodes on the frontier are substitutable, marked with . Auxiliary trees are defined as initial trees, except that exactly one frontier, nonterminal node must be a foot node, marked with , with the same label with the root node. Two operations  substitution and adjunction are provided in TAG to adjoin elementary trees. FBLTAG has two important characteristics First, it is a lexicalized TAG Schabes, 1988. Thus each elementary tree is associated with at least one lexical item. Second, it is a featurebased lexicalized TAG VijayShanker  Joshi, 1988. Each node in an elementary tree is constrained by two sets of featurevalue pairs two AVMs. One AVM top AVM defines the relation of the node to its supertree, and the other AVM bottom AVM defines the relation of the node to its descendants. We use Fig1 and Fig21 to illustrate the substitution and adjunction operations with the unification framework respectively. Ytrbr XYt   XYt U trbrtfbftbYtrbrX XYt U trbrYYYtfb U bf Figure 1. Substitution of FBLTAG     Figure 2. Adjunction of FBLTAG In Fig 1, we can see that the feature structure of a new node created by substitution inherits the union of the features of the original nodes. The top feature of the new node is the union of the top features of the two original nodes, while the bottom feature of the new node is simply the bottom feature of the top node of the substituting tree. In Fig 2, we can see that the node being adjoined into splits, and its top feature unifies with the top feature of the root adjoining node, while its bottom feature unifies with the bottom feature of the foot adjoining node. 3.2 XTAG English Grammar XTAG English grammar XTAG group, 2001 is designed using the FBLTAG formalism, released2 by UPENN in 2001. The range of syntactic phenomena that can be handled is large. It defines 57 major elementary trees tree families and 50 feature types, such as agreement, case, mode mood, tense, passive, etc, for its 20027 lexical entries. Each lexical entry is                                                  1 The two figures and their descriptions are based on the XTAG technical report XTAG group, 2001 2 httpwww.cis.upenn.eduxtaggramrelease.html                      Detecting and Correcting Syntactic Errors in                  5 Machine Translation Using FeatureBased Lexicalized Tree Adjoining Grammars associated with at least one elementary tree, and each elementary tree is associated with at least one AVM. For example, Fig 3 shows the simplified elementary tree of saw. number indicates the same feature value. For example, the feature  arg3rdsing in bottom AVM of root S should have the same feature value of arg3rdsing in top AVM of VP. In our implementation, it is coded using the same object in an objectoriented programming language. Since the feature value of mode in top AVM of S is base, we know that saw can only be followed by a sentence with a base verb. For example, He saw me do that shown in Fig 4a is a grammatical sentence while He saw me to do that shown in Fig 4b is an ungrammatical sentence because saw is not allowed to be followed by an infinitive sentence.   SNP VPsaw S2mode1gagr3rdsin indmodegagr3rdsin   basemode2mode1gagr3rdsin4mode3gagr3rdsin4mode3gagr3rdsin 4mode3gagr3rdsin  Figure 3. Elementary tree for saw               Figure 4a. Grammatical sentence of saw b Ungrammatical sentence of saw    6                                           WeiYun Ma and Kathleen McKeown But if we look at the simplified elementary tree of asked shown in Fig 5, we can find that asked can only be followed by a sentence with an infinitive sentence inf. For example, He asked me to do that shown in Fig 6a is a grammatical sentence while He asked me do that shown in Fig 6b is an ungrammatical sentence because asked is not allowed to be followed by a sentence with a base verb.  SNP VPasked S2mode1gagr3rdsin indmodegagr3rdsin  infmode2mode1gagr3rdsin4mode3gagr3rdsin4mode3gagr3rdsin 4mode3gagr3rdsin NP   Figure 5. Elementary tree for asked                       Figure 6a. Grammatical sentence of askedb Ungrammatical sentence of asked                      Detecting and Correcting Syntactic Errors in                  7 Machine Translation Using FeatureBased Lexicalized Tree Adjoining Grammars 4. Syntactic Error Detection Our procedure for syntactic error detection includes 1. decomposing each sentence hypothesis parse tree into elementary trees, 2. associating each elementary tree with AVMs through lookup in the XTAG grammar, and 3. reconstructing the original parse tree out of the elementary trees using substitution and adjunction operations along with AVM unifications. When unification of the AVMs fails, a grammatical error has been detected and its error type is also identified by the corresponding feature in the AVM. In order to simultaneously detect multiple error types and their corresponding words, we adjust the traditional unification definition to allow the unification procedure to continue after an AVM failure occurs and also propagate the failure information to relevant words. We call the modified unification fail propagation unification. Each step is illustrated in this section. 4.1 Decomposing to Elementary trees Given a translation sentence, we first get its syntactic parse using the Stanford parser Klein  Manning, 2003 and then decompose the parse to multiple elementary trees by using an elementary tree extractor, a modification of Chen  VijayShanker, 2000. After that, each lexical item in the sentence will be assigned one elementary tree. Taking the sentence  Many young student play basketball as an example, its parse and extracted elementary trees are shown in Fig 7 and Fig 8, respectively. In Fig 8, the arrows represent relations among the elementary trees and the relations are either substitution or adjunction. In this example, the two upper arrows are substitutions and the two bottom arrows are adjunctions.  Figure 7. Parse of Many young student play basketball   8                                           WeiYun Ma and Kathleen McKeown NPmany NPNPyoung NPNPstudentSNP1 VPplay NP2NPbasketball Figure 8. The elementary trees of Many young student play basketball and their relations 4.2 Associating AVMs to Elementary trees Each elementary tree is associated with AVMs through lookup in the XTAG English grammar. Using the same example of the sentence  Many young student play basketball, its elementary trees, relations and one set of AVMs simplified version are shown in Fig 9. To keep tracing what words that a feature value relates to for the next step of reconstruction, we design a new data structure of word set, named word trace. It is represented by  and attached with each feature value except the value of null, such as agrnumplplay in Fig 9. NPmany NP plagrnum many    NPyoung NP 1agrnum      1agrnumNPstudent  2agrnum   2agrnumindmodeplagrnumplayplaySNP1 VPplay NP24mode3agrnum4mode3agrnum  6mode5agrnum 6mode5agrnum   5agrnumNPbasketball  7agrnum  singagrnum basketball singagrnum student plagrnum many plagrnum many  7agrnum Figure 9. The elementary trees of Many young student play basketball, their relations and AVMs simplified version.                      Detecting and Correcting Syntactic Errors in                  9 Machine Translation Using FeatureBased Lexicalized Tree Adjoining Grammars When we loop up the XTAG English Grammar, sometimes one elementary tree could have multiple possible AVM associations. For example, for the verb are, one of its elementary trees is associated with three different AVMs, one for 2nd person singular, one for 2nd person plural, and one for 3rd person plural. Unless we can reference the context for are e.g., its subject, we are not sure which AVM should be used in the reconstruction. So we postpone this decision until later in the reconstruction process. At this point, we associate each elementary tree with its all possible AVMs defined in the XTAG English Grammar. 4.3 Reconstruction Framework Once the elementary trees are associated with AVMs, they will be used to reconstruct the original parse tree through substitution and adjunction operations which are indicated during the process of decomposing a parse tree to elementary trees. The reconstruction process is able to decide if there is any conflict with the AVMs values. When a conflict occurs, it will cause an AVM unification failure, referring to a certain grammatical error. We already illustrated how substitution and adjunctions along with AVM unifications work in section 3.1 one implementation complement is, once the original parse is constructed, it is necessary to unify every nodes top and bottom AVMs in the constructed tree. This is because, in XTAG grammar, most AVM values are assigned in the anchor nodes of elementary trees and were not unified with others yet. This end step will assure that all related AVMs are unified. As we stated in Section 4.2, sometimes we are not sure which AVM association for one elementary tree should be used in the reconstruction. So our strategy is to carry out reconstruction process for all sets out of every elementary trees each possible AVM association. We choose the set that causes the minimal grammatical errors as the detection result. 4.4 Fail Propagation Unification Our system detects grammatical errors by identifying unification fails. However, traditional unification does not define how to proceed after fails occur, and also lacks an appropriate structure to record error traces. So we extend it as follows        10                                           WeiYun Ma and Kathleen McKeown fx t1     U  fx t2        fx t1 union t2              1 fx t1     U  fnull          fx t1                         2 fnull       U  fnull          fnull                           3 fx t1     U  fy t2        ffail t1 union t2             4 ffail t1   U  fnull          ffail t1                        5 ffail t1   U  fy t2        ffail t1 union t2             6 ffail t1   U  ffail t2      ffail t1 union t2             7  Where f is a feature type, such as argnum x and y are two different feature values U represents the unify operation t1 and t2 are word traces introduced in section 4.2. fail is also defined as a kind of value. 14 are actually traditional unification definitions except that the word trace union operations and the characteristic of fail have been added. When a unification failure occurs in 4, the unification procedure does not halt but only assigns f a value of fail and proceeds. 57 propagate the fail value to the related words AVMs. We use the following two unifications occurring in order in Fig 9s adjoining operations to illustrate the procedure of fail propagation unification  argnumplmany U argnumsingstudent   argnum failmany,student  argnumfailmany, student U argnumplplay   argnum failmany,student,play  By the feature value of fail and the word trace, we identify that there is an agrnum error related to three words  many, student and play. All AVMs in Fig 9 after unifications along with reconstruction operations are shown in Fig 10.                         Detecting and Correcting Syntactic Errors in                  11 Machine Translation Using FeatureBased Lexicalized Tree Adjoining Grammars NPAyoungNP SNPDManyNNstudentVPVplayNPbasketball sing argnum basketball  ,,fail argnum playstudentmany sing argnum basketball ,,fail argnum playstudentmany ,,fail argnum playstudentmany ,,fail argnum playstudentmany ,,fail argnum playstudentmany ,,fail argnum playstudentmany ,,fail argnum playstudentmany ,,fail argnum playstudentmany ,,fail argnum playstudentmany ,,fail argnum playstudentmany ,,fail argnum playstudentmany ,,fail argnum playstudentmany ,,fail argnum playstudentmany ,,fail argnum playstudentmany ,,fail argnum playstudentmany ,,fail argnum playstudentmany  Figure 10. Reconstructed parse of the sentence Many young student play basketball after unifications with fail propagation 5. Syntactic Error Correction Once error types and their corresponding words are detected, one is able to correct errors based on an unified consideration of all related words under the same error types. Given a set of related ungrammatical words, there are two tasks for the correction process which words should be corrected and how to correct them To date, we have developed the following simple mechanism to handle the agreement problem First, the words whose feature value is in the minority will be selected to be corrected. We call this featurevalue voting. Take the above example student should be corrected since its agrnum is sing and the other two words agrnum is plural. When facing cases of equal votes, we tend to correct nouns if there are nouns. Once the corrected words are selected, we replace them with their variations but with the same elementary tree type, such as replacing the above student with students. 6. Experiment Among the 57 major elementary trees and 50 feature types that XTAG defines, we have implemented 26 major elementary trees and 4 feature types  agrpers, argnum, arg3rdsing and several cases of modemood at this point The first three belong to agreement features. We apply our syntactic error detection and correction on 422 translation sentences of six ChineseEnglish machine translation systems AF from the DARPA Global Autonomous Language Exploitation GALE 2008 evaluation. Every source sentence is provided along   12                                           WeiYun Ma and Kathleen McKeown with four target references. The six systems are described in Table 1, and the results of syntactic error detection for agreement and mode errors and correction for agreement errors are shown in Table 2. Table 1. Six MT systems  System name Approach A NRC phrasebased SMT B RWTHPBT phrasebased SMT C RWTHPBTAML phrasebased SMT  source reordering D RWTHPBTJX phrasebased SMT  Chinese word segmentation E RWTHPBTSH phrasebased SMT  source reordering  rescoring F SRIHPBT hierarchical phrasebased SMT  Table 2. The results of syntactic error detection and correction  Detected sentences arg error  mode errorCorrected sentences arg error Bleu for all sentences before Bleu for all sentences after Bleu for corrected sentences before Bleu for corrected sentences after A 23 9 32.99 32.99 26.75 27.80 B 23 14 27.95 27.97 22.08 23.03 C 18 7 34.40 34.41 32.13 32.67 D 25 14 32.96 32.99 31.49 32.17 E 30 11 34.64 34.68 29.31 30.61 F 18 8 34.13 34.14 29.15 28.83 From Table 2, even the overall Bleu score for all sentences is not significantly improved, but if we take a close look at those corrected sentences for agreement errors and calculate their Bleu scores, we can see the corrected translations are improved for every system except for one F, which shows the effectiveness and potential of our approach. 7. Conclusion This paper presents a new FBLTAGbased syntactic error detection and correction mechanism along with a novel AVM unification method to simultaneously detect multiple ungrammatical types and their corresponding words for machine translation. The mechanism can also be applied to other languages if the grammar is well defined in the FBLTAG structure of certain languages.                      Detecting and Correcting Syntactic Errors in                  13 Machine Translation Using FeatureBased Lexicalized Tree Adjoining Grammars While the basic design philosophy and algorithm are fully described in this paper, we are continuing to implement more elementary trees and feature types defined in the XTAG grammar, and we are extending our correction mechanism as our future work. Acknowledgments We would like to thank the anonymous reviewers for their helpful comments. This work is supported by the National Science Foundation via Grant No. 0910778 entitled Richer Representations for Machine Translation. All views expressed in this paper are those of the authors and do not necessarily represent the view of the National Science Foundation. Reference Alam, M. J., UzZaman, N.  Khan, M. 2006. Ngram based Statistical Grammar Checker for Bangla and English. In Proceedings of ninth International Conference on Computer and Information Technology ICCIT 2006, Dhaka, Bangladesh. Atwell, E. S.  Elliot, S. 1987. Dealing with Illformed English Text. In R. Garside, G. Leech and G. Sampson Eds. The Computational Analysis of English A Corpusbased Approach. London Longman. Chen, J.  VijayShanker, K. 2000. Automated extraction of TAGs from the Penn treebank. In Proceedings of the Sixth International Workshop on Parsing Technologies. Heidorn, G. E. 2000. Intelligent writing assistance. In R. Dale, H. Moisl and H. Somers eds., A Handbook of Natural Language Processing Techniques and Applications for the Processing of Language as Text. Marcel Dekker, New York. 181207. Huang, A., Kuo, T. T., Lai, Y. C.  Lin, S. D. 2010. Identifying Correction Rules for Auto Editing. In Proceedings of the 22nd Conference on Computational Linguistics and Speech Processing ROCLING, 251265. Jensen, K., Heidorn, G. E.  Richardson, S. D. Eds. 1993. Natural Language Processing The PLNLP Approach, Kluwer Academic Publishers. Joshi, A. K., Levy, L. S.  Takahashi M. 1975. Tree Adjunct Grammars. Journal of Computer and System Science, 10, 136163. Klein, D.  Manning, C. D. 2003. Accurate Unlexicalized Parsing. In Proceedings of the 41st Meeting of the Association for Computational Linguistics, 423430. Ma, W. Y.  McKeown, K. 2011. System Combination for Machine Translation Based on TexttoText Generation. In Proceedings of Machine Translation Summit XIII. Xiamen, China. Naber, D. 2003. A RuleBased Style and Grammar Checker. Diploma Thesis. University of Bielefeld, Germany.   14                                           WeiYun Ma and Kathleen McKeown Schabes, Y., Abeille, A.  Joshi, A. K. 1988. Parsing strategies with lexicalized grammars Application to tree adjoining grammars. In Proceeding of 12th International Conference on Computational Linguistics COLING88, Budapest, Hungary. Stymne, S.  Ahrenberg, L. 2010. Using a Grammar Checker for Evaluation and Postprocessing of Statistical Machine Translation. In Proceedings of International Conference on Language Resources and Evaluation LREC. VijayShanker, K.  Joshi, A. K. 1988. Feature structure based tree adjoining grammar, In Proceeding of 12th International Conference on Computational Linguistics COLING88, 714719. Wu, S. H., Su, C. Y., Jiang, T. J.   Hsu, W. L. 2006. An Evaluation of Adopting Language Model as the Checker of Preposition Usage. In Proceedings of the Conference on Computational Linguistics and Speech Processing ROCLING. XTAG Group. 2001. A Lexicalized Tree Adjoining Grammar for English. Technical Report IRCS 0103, University of Pennsylvania.    Computational Linguistics and Chinese Language Processing Vol. 17, No. 4, December 2012, pp.1532                                    15  The Association for Computational Linguistics and Chinese Language Processing TQDL Integrated Models for CrossLanguage Document Retrieval LongYue WANG, Derek F. WONG, and Lidia S. CHAO Abstract This paper proposed an integrated approach for CrossLanguage Information Retrieval CLIR, which integrated with four statistical models Translation model, Query generation model, Document retrieval model and Length Filter model. Given a certain document in the source language, it will be translated into the target language of the statistical machine translation model. The query generation model then selects the most relevant words in the translated version of the document as a query. Instead of retrieving all the target documents with the query, the lengthbased model can help to filter out a large amount of irrelevant candidates according to their length information. Finally, the left documents in the target language are scored by the document searching model, which mainly computes the similarities between query and document. Different from the traditional parallel corporabased model which relies on IBM algorithm, we divided our CLIR model into four independent parts but all work together to deal with the term disambiguation, query generation and document retrieval. Besides, the TQDL method can efficiently solve the problem of translation ambiguity and query expansion for disambiguation, which are the big issues in CrossLanguage Information Retrieval. Another contribution is the length filter, which are trained from a parallel corpus according to the ratio of length between two languages. This can not only improve the recall value due to filtering out lots of useless documents dynamically, but also increase the efficiency in a smaller search space. Therefore, the precision can be improved but not at the cost of recall.                                                   Natural Language Processing  PortugueseChinese Machine Translation Laboratory, Department of Computer and Information Science, University of Macau, Macau S. A. R., China Email vincentwang0229hotmail.com The author for correspondence is LongYue Wang.   16                                                      LongYue WANG et al. In order to evaluate the retrieval performance of the proposed model on crosslanguages document retrieval, a number of experiments have been conducted on different settings. Firstly, the Europarl corpus which is the collection of parallel texts in 11 languages from the proceedings of the European Parliament was used for evaluation. And we tested the models extensively to the case that the lengths of texts are uneven and some of them may have similar contents under the same topic, because it is hard to be distinguished and make full use of the resources. After comparing different strategies, the experimental results show a significant performance of the method. The precision is normally above 90 by using a larger query size. The lengthbased filter plays a very important role in improving the Fmeasure and optimizing efficiency. This fully illustrates the discrimination power of the proposed method. It is of a great significance to both crosslanguage searching on the Internet and the parallel corpus producing for statistical machine translation systems. In the future work, the TQDL system will be evaluated for Chinese language, which is a big changing and more meaningful to CLIR. Keywords CrossLanguage Document Retrieval, Statistical Machine Translation, TFIDF, Document TranslationBased, LengthBased Filter. 1. Introduction With the flourishing development of the Internet, the amount of information from a variety of domains is rising dramatically. Especially after the advent of the World Wide Web WWW in the 1900s, the amount of online information from the government, scientific and business communities has risen dramatically. Although much word has been done to develop effective and efficient retrieval systems for monolingual resources, the diversity and the explosive growth of information in different languages drove a great need for information retrieval that could cross language boundaries Ballesteros et al., 1988. The issues of CLIR have been discussed for several decades. Its task addresses a situation in which a user tries to search a set of documents written in one language using a query in a different language Kishida, 2005. It is of great significance, allowing people access information resources written in nonnative languages and aligning documents for statistical machine translation SMT systems, of which quality is heavily dependent upon the amount of parallel sentences used in constructing the system. In this paper, we focus on the problems of translation ambiguity, query generation and searching score which are keys to the retrieval performance. First of all, in order to increase the probability that the best translation can be selected from multiple ones, which occurs in the             TQDL Integrated Models for CrossLanguage Document Retrieval         17 target documents, the context and the most likely probability of the whole sentence should be considered. So we apply document translation approach using SMT model instead of query translation, although the latter one may require fewer computational resources. After the source documents are translated into the target language, the problem is transformed from bilingual environment to monolingual one, where conventional IR techniques can be used for document retrieval. Secondly, some terms in a certain document will be selected as query, which can distinguish the document from others. However, some of the words occur too frequently to be useful, which cannot distinguish target documents. This mostly includes two cases one is that the word frequency is high in all the documents of a set, which is usually classified as stop word the other one is that the frequency is moderate in several documents of a set. These words are poor in the ability of distinguishing documents. Thus, the query generation model should pick the words that occur more frequently in a certain document while less frequently in other documents. Finally, the document searching model evaluates the similarity between the query and each document. This model should give a higher score to the target document which covers the most relevant words in the given query. However, another problem is that word overlap between a query and a wrong document is more probable when the document and the query are expressed in the same language. For example, Document A is larger and contains another smaller document B. So the retrieval system would be confused with a query including the information of B. In order to solve this problem, the length ratio of a language pair is considered. As the search space is reduced, both the speed efficiency and the recall value will be improved clearly. There are two cases to be considered when we investigated the method. In one case, the lengths of documents are uneven, which are hard to balance the scores between large and small documents. In the other case, the contents of the documents are very similar, which are not easy to distinguish for retrieval. The results of experiments reveal that the proposed model shows a very good performance in dealing with both cases. The paper is organized as follows. The related works are reviewed and discussed in Section 2. The proposed CLIR approach based on statistical models is described in Section 3. The resources and configurations of experiments for evaluating the system are detailed in Section 4. Results, discussion and comparison between different strategies are given in Section 5 followed by a conclusion and future improvements to end the paper. 2. Related Work The issues of CLIR have been discussed from different perspectives for several decades. In this section, we briefly describe some related methods. From a statistical perspective, the CLIR problem can be treated as document alignment. Given a set of parallel documents, the alignment that maximizes the probability over all   18                                                      LongYue WANG et al. possible alignments is retrieved Gale  Church, 1991 as follows ALLtstsAtstsLLLLDDAPrmaxarg,Prmaxarg  1 where A is an alignment, Ds and Dt are the source and target documents, respectively L1 and L2 are the documents of two languages, LsLt is an individual aligned pairs, an alignment A is a set consisting of LsLt  pairs. On the matching strategies for CLIR, query translation is most widely used method due to its tractability Gao et al., 2001. However, it is relatively difficult to resolve the problem of term ambiguity because queries are often short and short queries provide little context for disambiguation Oard  Diekema, 1998. Hence, some researchers have used document translation method as the opposite strategies to improve translation quality, since more varied context within each document is available for translation Braschler  Schauble, 2001 Franz et al., 1999. However, another problem introduced based on this approach is word term disambiguation, because a word may have multiple possible translations Oard  Diekema, 1998. Significant efforts have been devoted to this problem. Davis and Ogden 1997 applied a partofspeech POS method which requires POS tagging software for both languages. Marcello et al. presented a novel statistical method to score and rank the target documents by integrating probabilities computed by querytranslation model and querydocument model Federico  Bertoldi, 2002. However, this approach cannot aim at describing how users actually create queries which have a key effect on the retrieval performance. Due to the availability of parallel corpora in multiple languages, some authors have tried to extract beneficial information for CLIR by using SMT techniques. SnchezMartnez et al. SnchezMartnez  Carrasco, 2011 applied SMT technology to generate and translate queries in order to retrieve long documents. Some researchers like Marcello, SnchezMartnez et al. have attempted to estimate translation probability from a parallel corpus according to a wellknown algorithm developed by IBM Brown et al., 1993. The algorithm can automatically generate a bilingual term list with a set of probabilities that a term is translated into equivalents in another language from a set of sentence alignments included in a parallel corpus. The IBM Model 1 is the simplest among the five models and often used for CLIR. The fundamental idea of the Model 1 is to estimate each translation probability so that the probability represented is maximized liijmjm stPlstP011   2 where t is a sequence of terms t1, , tm in the target language, s is a sequence of terms s1, , sl in the source language, Ptjsi is the translation probability, and  is a parameter  Pme,             TQDL Integrated Models for CrossLanguage Document Retrieval         19 where e is target language and m is the length of source language. Eq. 2 tries to balance the probability of translation, and the query selection, in which problem still exists it tends to select the terms consisting of more words as query because of its less frequency, while cutting the length of terms may affect the quality of translation. Besides, the IBM model 1 only proposes translations wordbyword and ignores the context words in the query. This observation suggests that a disambiguation process can be added to select the correct translation words Oard  Diekema, 1998. However, in our method, the conflict can be resolved through contexts. If translated sentences share cognates, then the character lengths of those cognates are correlated Yang  Li, 2004. Brown et al. 1991 and Gale and Church 1991 have developed the models based on relationship between the lengths of sentences that are mutual translations. Although it has been suggested that lengthbased methods are languageindependent Gale  Church, 1991, they really rely on length correlations arising from the historical relationships of the languages being aligned. The lengthbased model assumes that each term in Ls is responsible for generating some number of terms in Lt. This leads to a further approximation that encapsulates the dependence to a single parameter . ls,lt is function of ls and lt, which can be designed according to different language pairs. The lengthbased method is developed based on the following approximation to Eq. 3 ,Pr,Pr tstststs llLLLLLL   3 3. Proposed Models TQDLSMTTranslationModelSourceDocumenttargetlanguageQueryGenerationModelQuerytargetlanguageDocumentSearchingModelSourceDocumentsourcelanguageTargetDocumenttargetlanguageTargetDocumentsSetBilingualCorporaLengthFilterModelDocumentLengthlsSubsetlt ls, ls Figure 1. The proposed approach for CLIR   20                                                      LongYue WANG et al. The approach relies on four models translation model which generates the most probable translation of source documents query generation model which determines what words in a document might be more favorable to use in a query length filter model dynamically create a subset of candidates for retrieval according to the length information and document searching model, which evaluates the similarity between a given query and each document in the target document set. The workflow of the approach for CLIR is shown in Fig. 1. 3.1 Translation Model Currently, the good performing statistical machine translation systems are based on phrasebased models which translate small word sequences at a time. Generally speaking, translation model is common for contiguous sequences of words to translate as a whole. Phrasal translation is certainly significant for CLIR Ballesteros  Croft, 1997, as stated in Section 1. It can do a good job in dealing with term disambiguation. In this work, documents are translated using the translation model provided by Moses, where the loglinear model is considered for training the phrasebased system models Och  Ney, 2002, and is represented as  IeMmJImmMmJImmJIfehfehfep1 11111111,exp,exp 4 where hm indicates a set of different models, m means the scaling factors, and the denominator can be ignored during the maximization process. The most important models in Eq. 4 normally are phrasebased models which are carried out in source to target and target to source directions. The source document will maximize the equation to generate the translation including the words most likely to occur in the target document set. 3.2 Query Generation Model After translating the source document into the target language of the translation model, the system should select a certain amount of words as a query for searching instead of using the whole translated text. It is for two reasons, one is computational cost, and the other is that the unimportant words will degrade the similarity score. This is also the reason why it often responses nothing from the search engines on the Internet when we choose a whole text as a query. In this paper, we apply a classical algorithm which is commonly used by the search engines as a central tool in scoring and ranking relevance of a document given a user query. Term FrequencyInverse Document Frequency TFIDF calculates the values for each word in a document through an inverse proportion of the frequency of the word in a particular             TQDL Integrated Models for CrossLanguage Document Retrieval         21 document to the percentage of documents where the word appears Ramos, 2003. Given a document collection D, a word w, and an individual document d  D, we calculate ,log,,DwfDdwfdwP   5 where fw, d denotes the number of times w that appears in d, D is the size of the corpus, and fw,D indicates the number of documents in which w appears in D Berger et al., 2000. In implementation, if w is an OutofVocabulary term OOV, the denominator fw,D becomes zero, and will be problematic divided by zero. Thus, our model makes log D fw,D1 IDF1 when this situation occurs. Additionally, a list of stopwords in the target language is also used in query generation to remove the words which are high frequency but less discrimination power. Numbers are also treated as useful terms in our model, which also play an important role in distinguishing the documents. Finally, after evaluating and ranking all the words in a document by their scores, we take a portion of the nbest words for constructing the query and are guided by  dpercentq LenSize    6 Sizeq is the number of terms. percent is the percentage and is manually defined, which determines the Sizeq according to Lend, the length of the document. The model uses the first Sizeqth words as the query. In another word, the larger document, the more words are selected as the query. 3.3 Document Retrieval Model In order to use the generated query for retrieving documents, the core algorithm of the document retrieval model is derived from the Vector Space Model VSM. Our system takes this model to calculate the similarity of each indexed document according to the input query. The final scoring formula is given by ,,,, dtnormbsttidfdttfdqcoorddqScoreqtin  7 where tft,d is the term frequency factor for term t in document d, idft is the inverse document frequency of term t, while coordq,d is frequency of all the terms in query occur in a document. bst is a weight for each term in the query. Normt,d encapsulates a few indexing time boost and length factors, for instance, weights for each document and field. As a summary, many factors that could affect the overall score are taken into account in this model.      22                                                      LongYue WANG et al. 3.4 Length Filter Model In order to obtain a suitable filter, we firstly analyzed the golden data1 of ACL Workshop on SMT 2011, which includes Spanish, English, French, German and Czech 5 languages and 10 language pairs. EnglishSpanish language pair was used for analyzing and the data of the corpus are summarizes in Table 1. Table 1. Analytical Data of Corpus of ACL Workshop on SMT 2011 Dataset Size of corpus No. of Sentences No. of Characters Ave. No. Characters English 3,003 74,753 25 Spanish 3,003 79,426 26 Fig. 2 plots the distribution of word number in each aligned sentences. lt is the length of English sentence while ls is the length of sentence in Spanish. So the expectation is c E ltls 1.0073, with the correlation R2  0.9157. This shows that the data points are not substantially scatter in the plot and many data points are along with the regression line. Therefore, it is suitable to design a filter based on length ratio. 0204060801001200 20 40 60 80 100 120TheLengthofEachSpanishSentenceTheLengthofEachEnglishSentence Figure 2. The length ratio of SpanishEnglish sentences. To obtain an estimated lengththreshold  for filter model, the function  ls, lt can be designed as follows sstts lllll ,   8 where ls and lt respectively stand for the length of a certain aligned sentence in the corpus we used. Finally, we got the average  of around 0.15. In implementation, we choose 4 instead of  to avoid some unnormal cases, where the right document would be discarded by the filter.                                                  1 It can be download from httpwww.statmt.orgwmt11             TQDL Integrated Models for CrossLanguage Document Retrieval         23 Filter F describes the relation between bilingual sentences based on the length ratio. Since western languages are similar in terms of word representation, the length ratio can be simply estimated as a 11. Given a certain document in source language, F can collect a subset for retrieval according to the average length ratio. So F is designed as follows ,,,0,1  sstt lengthlengthCClengthClengthF  9 where lengths is the length of source document, and lengtht is the length of target document.  is an average threshold obtained through Eq. 8, C is a confidence interval. If lengtht is included in C, F is 1, which has a chance to be retrieved, otherwise set as 0, which will be skipped during searching. 4. Model Evaluation 4.1 Datasets In order to evaluate the retrieval performance of the proposed model on text of cross languages, we use the Europarl corpus2 which is the collection of parallel texts in 11 languages from the proceedings of the European Parliament Koehn, 2005. The corpus is commonly used for the construction and evaluation of statistical machine translation. The corpus consists of spoken records held at the European Parliament and are labeled with corresponding IDs e.g. CHAPTER id, SPEAKER id. The corpus is quite suitable for use in training the proposed probabilistic models between different language pairs e.g. EnglishSpanish, EnglishFrench, EnglishGerman, etc., as well as for evaluating retrieval performance of the system. Table 2. Analytical Data of Corpus Dataset Size of corpus Documents Sentences Words Ave. words in document Training Set 2,900 1,902,050 23,411,545      50 TestSet 23,342 80,000 7,217,827     309 The datasets training and test set are collected for this evaluation. The chapters from April 1998 to October 2006 were used as a training set for model construction, both for training the Language Model LM and Translation Model TM. While the chapters from April 1996 to March 1998 were considered as the testing set for evaluating the performance of the model. Besides, each paragraph split by SPEAKER id label is treated as a document, for dealing with the low discrimination power. The analytical data of the corpus are presented                                                  2 Available online at httpwww.statmt.orgeuroparl.   24                                                      LongYue WANG et al. in Table 2. The TestSet contains 23,342 documents, of which length is 309 in average. Actually 30 of documents are much more or less than the average number. Table 1 summarizes the number of documents, sentences, words and the average word number of each document. 4.2 Evaluation Metrics The most frequent and basic evaluation metrics for information retrieval are precision and recall, which are defined as follows Manning et al., 2008 Pritemsretrievedretrieveditemsrelevantecison                                   10 Reitemsrelevantretrieveditemsrelevantcall                                    11 For reporting the evaluation of our method, we used the F1 measure, the recall and the precision values. F1measure F is formulated by Van Rijsbergen as a combination of recall R and precision P with an equal weight in the following form RPPRF 2                                                            12 4.3 Experimental Setup In order to evaluate our proposed model, the following tools have been used. The probabilistic LMs are constructed on monolingual corpora by using the SRILM Stolcke et al., 2002. We use GIZA Och  Ney, 2003 to train the word alignment models for different pairs of languages of the Europarl corpus, and the phrase pairs that are consistent with the word alignment are extracted. For constructing the phrasebased statistical machine translation model, we use the open source Moses Koehn et al., 2007 toolkit, and the translation model is trained based on the loglinear model, as given in Eq. 4. The workflow of constructing the translation model is illustrated in Fig. 3 and it consists of the following main steps3 1 Preparation of aligned parallel corpus. 2 Preprocessing of training data tokenization, case conversion, and sentences filtering where sentences with length greater than fifty words are removed from the corpus in order to comply with the requirement of Moses. 3 A 5gram LM is trained on Spanish data with the SRILM toolkits.                                                  3 See httpwww.statmt.orgwmt09baseline.html for a detailed description of MOSES training options.             TQDL Integrated Models for CrossLanguage Document Retrieval         25 4 The phrasedbased STM model is therefore trained on the prepared parallel corpus EnglishSpanish based on loglinear model of by using the ninesteps suggested in Moses. WordTableSourceTextBilingualCorpusGIZAPhraseTablePhraseExtractionDecodingLanguageModelLMToolkitTargetTextMonolingualCorpus Figure 3. Main workflow of training phase Once LM and TM have been obtained, we evaluate the proposed method with the following steps 1 The source documents are first translated into target language using the constructed translation model. 2 The words candidates are computed and ranked based on a TFIDF algorithm and the nbest words candidates then are selected to form the query based on Eq. 5 and 6. 3 All the target documents are stored and indexed using Apache Lucene4 as our default search engine. 4 In retrieval, target documents are scored and ranked by using the document retrieval model to return the list of most related documents with Eq. 7. 5. Results and Discussion A number of experiments have been performed to investigate our proposed method on different settings. In order to evaluate the performance of the three independent models, we firstly conducted experiments to test them respectively before whole the TQDL platform. The performance of the method is evaluated in terms of the average precision, that is, how often the target document is included within the first Nbest candidate documents when retrieved.                                                    4 Available at httplucene.apache.org.   26                                                      LongYue WANG et al. 5.1 Monolingual Environment Information Retrieval In this experiment, we want to evaluate the performance of the proposed system to retrieve documents monolingual environment given the query. It supposes that the translations of source documents are available, and the step to obtain the translation for the input document can therefore be neglected. Under such assumptions, the CLIR problem can be treated as normal IR in monolingual environment. In conducting the experiment, we used all of the source documents of TestSet. The steps are similar to that of the testing phase as described in Section 4.2, excluding the translation step. The empirical results based on different configurations are presented in Table 3, where the first column gives the number of documents returned against the number of wordsterms used as the query. Table 3. The average precision in Monolingual Environment Retrieved Documents NBest Query Size Sizeq in  2 4 8 10 14 18 20 1 0.794 0.910 0.993 0.989 0.986 1.000 0.989 5 0.921 0.964 1.000 1.000 1.000 1.000 0.996 10 0.942 0.971 1.000 1.000 1.000 1.000 0.996 20 0.946 0.978 1.000 1.000 1.000 1.000 0.996 The results show that the proposed method gives very high retrieval accuracy, with precision of 100, when the top 18 of the words are used as the query. In case of taking the top 5 candidates of documents, the approach can always achieve a 100 of retrieval accuracy with query sizes between 8 and 18. This fully illustrates the effectiveness of the retrieval model. 5.2 Translation Quality The overall retrieval performance of the system will be affected by the quality of translation. In order to have an idea the performance of the translation model we built, we employ the commonly used evaluation metric, BLEU, for such measure. The BLEU Bilingual Evaluation Understudy is a classical automatic evaluation method for the translation quality of an MT system Papineni et al., 2002. In this evaluation, the translation model is created using the parallel corpus, as described in Section 4. We use another 5,000 sentences from the TestSet1 for evaluation5.                                                   5 See httpwww.statmt.orgwmt09baseline.html for a detailed description of MOSES evaluation options.             TQDL Integrated Models for CrossLanguage Document Retrieval         27 The BLEU value, we obtained, is 32.08. The result is higher than that of the results reported by Koehn in his work Koehn, 2005, of which the BLEU score is 30.1 for the same language pair we used in Europarl corpora. Although we did not use exactly the same data for constructing the translation model, the value of 30.1 was presented as a baseline of the EnglishSpanish translation quality in Europarl corpora. The BLEU score shows that our translation model performs very well, due to the large number of the training data we used and the preprocessing tasks we designed for cleaning the data. On the other hand, it reveals that the translation quality of our model is good. 5.3 TQDL without Filter for CLIR In this section, the proposed model without length filter model is tested. Table 4 presents the Fmeasure given by TQDL system without length filter model. As illustrated, the it can only achieve up to 94.7, counting that the desired document is returned as the most relevant document among the candidates. Although it has achieved a very good performance in the experiments, the 6.6 of documents have been discarded in the preprocessing. Table 4. The Fmeasure of our system without length filter model Retrieved Documents NBest Query Size Sizeq in  2.0 4.0 6.0 8.0 10.0 1 0.905 0.943 0.942 0.947 0.941 2 0.922 0.949 0.949 0.953 0.950 5 0.932 0.950 0.953 0.963 0.960 10 0.936 0.954 0.960 0.968 0.971 20 0.941 0.958 0.974 0.979 0.981 To investigate the changes of the performance with removing abnormal documents too lager or too small, query size Sizeq was set as a constant value 8.0, which can achieve the best precision as shown in Table 4. We believed that the abnormal document is the main obstacle to develop the performance of the system. Therefore, we removed the documents, of which length are out of a certain threshold.   28                                                      LongYue WANG et al. 0.70.750.80.850.90.9514010.5k 8010.3k 20010.1k 4009.9k 6009.7kEvaluationLengthLimitationofRetrievedDocumentPrecisionRecallFvalue Figure 4. The changes of evaluation when removing data Fig. 4 plots the variations of P, R and F with the length scope increasing. As we expected, the precision increase when the more abnormal documents are discarded from the dataset. However, the recall declines sharply, which also lead to the falling of Fmeasure. When the precision is closed to 100, nearly 15 documents are removed from the dataset. So the high precision is often at the cost of reducing the recall rate. Fmeasure is only 95 at its top, so it is hard to improve the performance of CLIR using traditional methods. 5.4 TQDL with Filter for CLIR In order to obtain a higher retrieval rate, our model has been improved from different points. Firstly, we generate the query with dynamic size, which can do better in dealing with the problem of similar documents both in length and content. In another words, the longer the document, the more words will be used for retrieval of the target documents. So the Sizeq is considered as a hidden variable in our document retrieval model. Besides, all the indexed documents can be filtered with F formula in Eq. 9, and it can alleviate the scarcity of tending to select longer documents when occurring the word overlap between shorter and longer documents, because a certain source document are only searched in a subset defined by its length. It can improve the precision without discard any socalled abnormal documents from dataset, so the P, R and F values will always be the same. Table 5 presents the F values given by TQDL with length filter model.                  TQDL Integrated Models for CrossLanguage Document Retrieval         29 Table 5. The Fmeasure of our system with length filter model Retrieved Documents NBest Query Size Sizeq in  2.0 4.0 6.0 8.0 10.0 1 0.958 0.975 0.983 0.990 0.992 2 0.967 0.979 0.986 0.993 0.996 5 0.971 0.982 0.987 0.993 0.996 10 0.974 0.983 0.988 0.995 0.996 20 0.974 0.983 0.990 0.995 0.996 Compared with the results presented in Tables 4 and 5, it shows that the length filter model is able to give a high improvement by 4.5 in Fmeasure and achieve more than 99 of successful rate, in the case that the desired candidate is ranked in the first place. Above all, there is no documents waste in the dataset. 0.90.910.920.930.940.950.960.970.980.9911 2 3 10 20EvaluationRetrievedDocumentsNBestF P R Length FilterP Value No FilterR Value No FilterF Value No Filter Figure 5. The changes of evaluation with NBest Fig. 5 presents an ideal distribution of evaluation, of which P and R should be closed to the F line. In this comparison, query size Sizeq was still set as a constant value 8.0. With the increasing of N, evaluations without filter are in a low level, while the one with this filter can achieve a good and stable performance. Finally, the precision and recall values are closed to F measure, which can all keep in a high level 99100. 6. Conclusion This article presents a TQDL statistical approach for CLIR which has been explored for both large and similar documents retrieval. Different from the traditional parallel corporabased model which relies on IBM algorithm, we divided our CLIR model into four independent parts but all work together to deal with the term disambiguation, query generation and document   30                                                      LongYue WANG et al. retrieval. The performances showed that this method can do a good job of CLIR for not only large documents but also the similar documents. This fully illustrates the discrimination power of the proposed method. It is of a great significance to both crosslanguage searching on the Internet and the parallel corpus producing for statistical machine translation systems. In the future work, the TQDL system will be evaluated for Chinese language, which is a big changing and more meaningful to CLIR. In the further work, we plan to make better use of the proposed models between significantly different languages such as PortugueseChinese. Acknowledgement This work was partially supported by the Research Committee of University of Macau under grant UL019B09Y3EEELYP01FST, and also supported by Science and Technology Development Fund of Macau under grant 0572009A2. References Ballesteros, L.,  Croft, W. B. 1988. Statistical methods for crosslanguage information retrieval. Crosslanguage information retrieval, 2340. Ballesteros, L.  Croft, W. B. 1997. Phrasal translation and query expansion techniques for crosslanguage information retrieval. ACM SIGIR Forum, 31SI, 8491. Braschler, M.,  Schauble, P. 2001. Experiments with the eurospider retrieval system for clef 2000. CrossLanguage Information Retrieval and Evaluation, 140148. Brown, P. F., Lai, J. C.  Mercer, R. L. 1991. Aligning sentences in parallel corpora. In Proceedings of the 29th annual meeting on Association for Computational Linguistics, 169176. Brown, P. F., Pietra, V. J. D., Pietra, S. A. D.  Mercer, R. L. 1993. The mathematics of statistical machine translation Parameter estimation. Computational linguistics, 192, 263311. MIT Press. Berger, A., Caruana, R., Cohn, D., Freitag, D.  Mittal, V. 2000. Bridging the lexical chasm statistical approaches to answerfinding. In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, 192199. Davis, M. W.  Ogden, W. C. 1997. Quilt Implementing a largescale crosslanguage text retrieval system. ACM SIGIR Forum, 31SI, 9298. Federico, M.  Bertoldi, N. 2002. Statistical crosslanguage information retrieval using nbest query translations. In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval, 167174. Franz, M., McCarley, J. S.  Ward, R. T. 1999. Ad hoc, crosslanguage and spoken document information retrieval at IBM. NIST Special Publication The 8th Text Retrieval Conference TREC8.             TQDL Integrated Models for CrossLanguage Document Retrieval         31 Gale, W. A.  Church, K. W. 1991. Identifying word correspondences in parallel texts. In Proceedings of the workshop on Speech and Natural Language, 152157. Gao, J., Nie, J. Y., Xun, E., Zhang, J., Zhou, M.,  Huang, C. 2001. Improving query translation for crosslanguage information retrieval using statistical models.In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, 96104. Kishida, K. 2005. Technical issues of crosslanguage information retrieval a review. Information processing  management, 413, 433455. Koehn, P. 2005. Europarl A parallel corpus for statistical machine translation. MT summit, 5. Koehn, P., Hoang, H., Birch, A., CallisonBurch, C., Federico, M., Bertoldi, N., Cowan, B., et al. 2007. Moses Open source toolkit for statistical machine translation. Annual meetingassociation for computational linguistics, 452, 2. Manning, C. D., Raghavan, P.  Schtze, H. 2008. Introduction to information retrieval Vol. 1. Cambridge University Press Cambridge, 140159. Oard, D. W.,  Diekema, A. R. 1998. Crosslanguage information retrieval. Annual review of Information science, 33, 223256. Och, F. J.  Ney, H. 2002. Discriminative training and maximum entropy models for statistical machine translation.In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, 295302. Och, F. J.  Ney, H. 2003. A systematic comparison of various statistical alignment models. Computational linguistics, 291, 1951. MIT Press. Papineni, K., Roukos, S., Ward, T.  Zhu, W. J. 2002. BLEU a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics, 311318. Ramos, J. 2003. Using tfidf to determine word relevance in document queries. In Proceedings of the First Instructional Conference on Machine Learning. SnchezMartnez, F.  Carrasco, R. C. 2011. Document translation retrieval based on statistical machine translation techniques. Applied Artificial Intelligence, 255, 329340. Stolcke, A.  others. 2002. SRILMan extensible language modeling toolkit. In Proceedings of the international conference on spoken language processing, 2, 901904. Yang, C. C.  Wing Li, K. 2004. Building parallel corpora by automatic title alignment using lengthbased and textbased approaches. Information processing  management, 406, 939955.   32                                                      LongYue WANG et al.   Computational Linguistics and Chinese Language Processing Vol. 17, No. 4, December 2012, pp. 3348                                      33  The Association for Computational Linguistics and Chinese Language Processing  Domain Dependent Word Polarity Analysis for Sentiment Classification  HoCheng Yu, TingHao Kenneth Huang, and HsinHsi Chen   LIBSVM 5  TFSSIDF  TFIDFSO t   Abstract The researches of sentiment analysis aim at exploring the emotional state of writers. The analysis highly depends on the application domains. Analyzing sentiments of   Department of Computer Science and Information Engineering, National Taiwan University Email p98922004, r96944003, hhchenntu.edu.tw   34                                                                 the articles in different domains may have different results. In this study, we focus on corpora from three different domains in Traditional and Simplified Chinese including real estate, hotel and restaurant, then examine the polarity degrees of vocabularies in these three domains, and propose methods to capture sentiment differences. Finally, we apply the results to sentiment classification with LIBSVM linear kernel. The experiments show that the proposed method TFSSIDF which integrates TFIDF, NTU Sentiment Dictionary, and word sentiment orientation degree in each specific domain can effectively improve the sentiment classification performance. Keywords Document Sentiment Classification, Word Polarity Analysis, Machine Learning. 1.    Web 2.0 , 2012 Tang  Chen, 2011, 2012Pang  Lee, 2008 1. 81 2. 20Review 3.  73 87 4.  20  99   SVM                                     35 2.   Ku  Chen, 2007 Ku, Huang  Chen, 2009, 2010Seki et al., 2007Turney  Littman, 2003 Turney, 2002 Chaovalit  Zhou, 2005Sautera, Eisner, Ekman,  Scott, 2010Lu, 2010 Unsupervised LearningSupervised LearningChaovalit and Zhou2005POS taggerRealTime Tan and Zhang2008SVMLan et al.,2005 SVM  TFRF  Martineau and Finin 2009 SVM  DELTA TFIDF  SVM  TFIDF  3.  3.1   3.1.1  Chin, 2010 2001  2010  2,389  1   1.   66  11 1998  5 5 32 11  66   36                                                                 3.1.2  1 2  2.   , 3.1.3  2 2006  2009  2,000 3   3.      135       8  10  23  10  5 ...... 1 httpwww.searchforum.org.cntansongbosenticorpus.jsp 2 httpwww.ipeen.com.tw                                    37  4   4.                        130   70   300       1,418  971   2,000   4000   2,000   4000    20012010  20062009 3.2  mmseg4j3mmseg4jmmseg Tsai, 1996  SimpleComplexmaximum matching algorithmChen  Liu, 1992 95 98mmseg4jNTUSDKu  Chen, 2007CKIP4 1 Mmseg4j   CKIP 3 httpcode.google.compmmseg4j 4 httpckipsvr.iis.sinica.edu.tw  1.  Mmseg   38                                                                  5   5.     , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,   , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,  4.  4.1  Document FrequencySentiment Orientation123      w in PPDPSOD 1                                                1     N w in NNDSOD 1                                                2 log  ePSOSONSO                                                   3 PSO Positive Sentiment Orientation     1 PSO  0NSO Negative Sentiment Orientation   w in PD    w in PD  1  PD   w in PD     PD                                   39  PSO  NSO  PSO  NSO  PSONSO 1  PSO  NSO log  ePSONSO 0 log  ePSONSOSentiment OrientationSO 4.2   6 7 8  SO    6.  SO  5  SO  5   SO    w in PD      w in ND   SO   w in PD      w in ND   2.99 28 0  3.64 0 25  2.82 25 0  3.39 2 60  2.64 43 1  3.37 1 39  2.54 19 0  3.21 0 16  2.49 18 0  3.09 0 14   40                                                                  7.  SO  5  SO  5  SO    w in PD      w in ND   SO   w in PD      w in ND   3.47 31 0  3.99 0 53  3.00 19 0  3.95 1 103  3.00 19 0  3.33 0 27  2.94 18 0  3.26 1 51  2.94 18 0  3.22 0 24   8.  SO  5  SO  5  SO    w in PD      w in ND   SO   w in PD      w in ND   3.22 24 0  3.14 0 22  3.09 21 0  3.04 0 20  3.04 20 0  2.97 1 38  3.00 19 0  2.94 0 18  3.00 19 0  2.83 0 16   9.          2.32 1.45 0.13  1.48 2.04 0.31  0.00 1.10 2.40  0.00 1.53 2.08  0.00 2.20 0.71  2.58 0.92 0.16  1.48 1.12 1.61  0.00 1.10 2.08  1.76 1.10 1.01  1.29 1.10 1.53  9  9 domain relatedness                                   41 domain dependency 10  11   10.    1  ,,,,,,,,,,      0   .   ...  3  5     .......  11.                        23  2010  1  56.6 .17.16V  M    42                                                                 5.  5.1  UnigramNTUSDBigram Term FrequencySO1212   12.     TFSO  1TFSO TF SO    TFSO5SVMSO0TFSO1 TFSOIDF SO 1TFSOIDF TFIDF    SO TFIDF  IDF  SO  TFIDF  TFSDIDF       NTUSD        otherwiseTFSDIDFTFIDF k if w inTFIDF  TFIDF  k Bigram  TFSSIDF       NTUSD        otherwiseTFSSIDFTFSOIDF k if w inTFSOIDF TFSOIDF  k Bigram  TFSDIDFTFSSIDFkkkk13  13.  k  k 1.0 1.5 2.0 3.0 5.0 10.0 Accuracy 0.848 0.851 0.852 0.840 0.816 0.7972 5  SVM  TFIDF                                    43 k  2.0  3.0  5.0  10.0  k  k  2.0  TFIDFTFRFLan, Sung, Low,  Tan, 2005DELTA TFIDF Martineau  Finin, 200914  14.     TFIDF   eDTFIDF TF logDF   TFDDF TFRF   ,          log     w in Pt d ew in NTFRFDC eD Ct,d                         e 2  2 log  e  e    w in PD  w inD   NDelta TFIDF   N,       log    P w int d ew in P NDelta TFIDFD DCD D  Ct,d                              w in PD  w inD  PD NNDLIBSVM6Linear Kernel FunctionCostLan, Sung, Low,  Tan, 2005Cost  5 5Fold Cross ValidationInside TestAccuracy t  6.  6.1 Unigram 15 TTFSSIDF 95 99 99.5TFSOTFIDFIDF6 httpwww.csie.ntu.edu.twcjlinlibsvm   44                                                                 SOTFSOIDFTFSOIDFTFSSIDFTFSOIDFTFSDIDFTFIDFUnigramTFSSIDFTFSOIDFTFSDIDFTFIDF  15. Unigram  T Accuracy  TFIDF TFRF Delta TFSO TFSOIDF TFSDIDF TFSSIDF 0.848 0.849 0.853 0.847 0.854 0.852 0.863  0.916 0.906 0.914 0.915 0.924 0.918 0.923  0.861 0.839 0.849 0.854 0.871 0.869 0.875 6.2  16 TFSOIDFT15DeltaTFSOIDFTFIDF  16. Unigram Accuracy  TFIDF TFRF Delta TFSO TFSOIDF  0.784 0.786 0.796 0.784 0.787  0.883 0.877 0.878 0.880 0.887  0.806 0.795 0.792 0.783 0.804 6.3 Bigram 17 BigramTFSOIDFTTFIDFTFSOIDF  17. Bigram Accuracy  TFIDF TFRF Delta TFSO TFSOIDF  0.777 0.769 0.756 0.767 0.767  0.879 0.858 0.879 0.883 0.886  0.805 0.778 0.766 0.793 0.811                                    45 7.   1.    2.  3. Unigram Unigram Unigram  TFIDF  TFSDIDFTFIDF  TFSOIDF  TFSSIDFTFSOIDF  4.  SO  TFIDFSVM  IDF  SO  5.  TFSSIDF  TFIDF SO 6.    46                                                                  Research of this paper was partially supported by National Science Council Taiwan under the contract NSC 982221E002175MY3 and 2012 Google Research Award.  Chaovalit, P.  Zhou, L. 2005. Movie review mining a comparison between supervised and unsupervised. In Proceedings of the 38th Hawaii International Conference on System Sciences. Chin, Y.L. 2010 A review and discussion of real estate cycle indicators analysis and publication method. Research Project Report. Architecture and Building Research Institute, Ministry of the Interior, Taiwan. httpwww.abri.gov.tw Ku, L.W.  Chen, H.H. 2007. Mining opinions from the web beyond relevance retrieval. Journal of American Society for Information Science and Technology, 5812, 1838850. Ku, L.W., Huang, T.H.,  Chen, H.H. 2009. Using Morphological and Syntactic Structures for Chinese Opinion Analysis. In Proceedings of Conference on Empirical Methods in Natural Language Processing, 1260269. Ku, L.W., Huang, T.H.,  Chen, H.H. 2010. Construction of Chinese Opinion Treebank. In Proceedings of the Seventh International Conference on Language Resources and Evaluation, 1315319. Lan, M., Sung, S.Y., Low, H.B.,  Tan, C.L. 2005. A comparative study on term weighting schemes for text categorization. In Proceedings of International Joint Conference on Neural Networks, 1032033. Lu, Y., Kong, X., Quan, X., Liu, W.,  Xu, Y. 2010. Exploring the sentiment strength of user reviews. In Proceedings of 11th International Conference on WebAge Information Management, 471482. Martineau, J.  Finin, T. 2009 Delta TFIDF An improved feature space for sentiment analysis. In Proceedings of the Third AAAI International Conference on Weblogs and Social Media, 258261. Pang, Bo  Lee, Lillian 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 212 1135 Sautera, D. A., Eisner, F., Ekman, P.,  Scott, S. K. 2010. Crosscultural recognition of basic emotions through nonverbal emotional vocalizations. In Proceedings of the National Academy of Sciences, 1076, 2010. Tan, S.  Zhang, J. 2008. An empirical study of sentiment analysis for Chinese documents. Expert System with Applications, 344, 26222629. Tang, Y.J.  Chen, H.H. 2011. Emotion modeling from writerreader perspectives using a Microblog dataset. In Proceedings of IJCNLP Workshop on Sentiment Analysis where AI Meets Psychology, 1119.                                    47 Tang, Y.J.  Chen, H.H. 2012. Mining sentiment words from microblogs for predicting writerreader emotion transition. In Proceedings of 8th International Conference on Language Resources and Evaluation, 12261229. Tsai, C.H. 1996. MMSEG A word identification system for Mandarin Chinese text based on two variants of the maximum matching algorithm. Available at httptechnology.chtsai.orgmmseg. Turney, P. D. 2002. Thumbs up or thumbs down semantic orientation applied to unsupervised classification of reviews. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, 417424. Turney, P. D.  Littman, M. L. 2003. Measuring praise and criticism inference of semantic orientation from association. ACM Transactions on Information Systems, 21, 315346. Seki, Y., Evans, D.K., Ku, L.W., Chen, H.H., Kando, N.,  Lin, C.Y. 2007. Overview of Opinion Analysis Pilot Task at NTCIR6. In Proceedings of the 6th NTCIR Workshop Meeting on Evaluation of Information Access Technologies, 265278.  2012NCP Newsletter, 38, 1116.    48                                                                  Computational Linguistics and Chinese Language Processing Vol. 17, No. 4, December 2012, pp. 4968                                      49  The Association for Computational Linguistics and Chinese Language Processing   Exploiting Machine Learning Models for  Chinese Legal Documents Labeling,  Case Classification, and Sentencing Prediction  WanChen Lin, TsungTing Kuo, TungJia Chang,  ChuehAn Yen, ChaoJu Chen and Shoude Lin   21       Department of Computer Science and Information Engineering, National   Taiwan University Email myownstuffhotmail.com d97944007csie.ntu.edu.tw sdlincsie.ntu.edu.tw   College of Law, National Taiwan University   Email d97a21003ntu.edu.tw filawsofntu.edu.tw tanchiaujuntu.edu.tw   50                                                                 Abstract This paper exploits machine learning methods to separate robbery and intimidation cases, and predicting their sentencing by considering defined legal factors. We introduce a framework to fetch 21 legal factor labels of robbery and intimidation cases, then use the labels for case classification and sentencing prediction. Our experiments show that the legal factor labels can indeed improve the results of case classification and sentencing prediction. We then discuss the influence of these legal factors in both case classification and sentencing prediction tasks. Keywords Case Classification, Sentencing Prediction, Robbery, Intimidation 1.  civil lawcommon law  328  1  346 1                           51   2.   Ashley Bruninghaus, 2009 SMILE Lame Lame, 2001Term frequencyinverse document frequency TFIDF Support vector machine SVMLiu LIU, 2004 Case based reasoning CBR 12  knearest neighbor algorithm kNN TFIDF  TFIDF  Schild SCHILD, 1998 CBR  2011 Kuo et al., 2006  Wei Jiang Jiang, 2006 HMMMEMMCRF  SVM  CRF  Zhang Chengmin Zhang, 2008 CRF  3.    52                                                                  21   Global labels 5  Local labels 16   2006  2010  21 2113  140  1Hotho et al., 2003  1.                  0 2 17 11 1 6 9 3 2 9 4 3 0 67  1 5 13 6 1 4 4 6 7 8 7 2 9 73  1.      D          1,2iD i  d m  L        1,2L   jl n,n  number of  labels  di  iW  di   iW  kw k N  d Wnew new Wnew  kw  lj  1  x  n y                         53  Conditional random fields CRF     FZ j jjexp x,yp y xx,    F   Z x, exp x,yj jy j    1, ,F  j j i iix,y f y y x,i  i x   CRF  CRF  3.1   Global  Local labels  Hotho et al., 2003   13  13  13  Cosinenormalized tfidf k i,jtf  j  i  k  idf  i  k iD    iidf log df  i,j i,j itfidf tf idf   i,ji,j2i,jk all labelstfidfCosNorm tfidftfidf  Local labels  Global labels       54                                                                 3.2   CRFWibowo  Williams, 20025fold cross validation F1 score  2  3 global label  local label   2.  Global label      0.577 0.515  13 0.626 0.557  14 0.624 0.555  15 0.619 0.546  110 0.595 0.542  Cosinenormalized TFIDF 0.741 0.782  13 Cosinenormalized TFIDF 0. 818 0.834   3.  Local label      0.350 0.307  13 0.366 0.323  14 0.375 0.328  15 0.396 0.353  110 0.403 0.361  Global label  0.352 0.310  Cosinenormalized TFIDF 0.540 0.562  110 Cosinenormalized TFIDF  Global label  0.604 0.615 4.                          55  F1 score  0.852 4.1    Facttfidf TFIDF   Local label  local label  label  Local label  local label  4fold cross validation F1 score  Liblinear  Logistic model tree LMT  4  5Facttfidflocal label  Local label  LMT  F1 score  0.943 Facttfidf  6 FacttfidfLocal label  Local label  LMT  F1 score  0.721  4. Liblinear   F1 scoreFacttfidf Ftfidf 10034 0.834 Local label frequency LF 16 0.615 Local label order LO 256 0.695 Ftfidf  LF 10050 0.702 Ftfidf  LO 10290 0.769 LF  LO 272 0.642 Ftfidf  LF  LO 10306 0.698   56                                                                  5. LMT   F1 scoreFacttfidf Ftfidf 10034 0.929 Local label frequency LF 16 0.654 Local label order LO 256 0.693 Ftfidf  LF 10050 0.936 Ftfidf  LO 10290 0.921 LF  LO 272 0.678 Ftfidf  LF  LO 10306 0.943  6.      Facttfidf Local label  7Leave one out LOO Forward selection  89  1010  F1 score  0.957  7.   Facttfidf ftfidf  TFIDF  10034 Behaviortfidf btfidf  TFIDF  2897 bkey  23 vkey  23 actor 12 35 6  3 afeature  4 accomplice 0 12 35 6  4 victim 12 35 6  3 after  3                         57  property  14 tool  17 Local label   local label  label  16 Local label   local label  256  8.  F1 scoreFacttfidf 10034 0.929 Local label  16 0.654 Local label  256 0.693  3 0.374  4 0.584  3 0.557 Behaviortfidf 2897 0.785  23 0.779  23 0.751  3 0.367  4 0.512  14 0.603  17 0.670   58                                                                  9. LOO    F1 scoreFacttfidf 3263 0.850 Local label  13281 0.921 Local label  13041 0.936  13294 0.936  13293 0.936  13294 0.936 Behaviortfidf 10400 0.929  13274 0.957  13274 0.943  13294 0.929  13293 0.943  13283 0.936  13280 0.943  10. Forward selection   F1 score  13297 0.936 FacttfidfBehaviortfidfLocal label  12970 0.957 4.2   11 20  TFIDF  TFIDF  12  TFIDF  TFIDF  13                         59  11.  10     16.2 ftfidf 5.22 ftfidf 15.41 ftfidf 2.84 bkey 12.93 ftfidf 2.71 vkey 10.7 ftfidf 2.68 ftfidf 9.56 ftfidf 2.63 ftfidf 9.26 ftfidf 2.58 ftfidf 7.71 btfidf 2.28 btfidf 6.81 vkey 2.13 after 5.47 ftfidf 2.05 ftfidf 5.4 ftfidf 2.01 btfidf   12. TFIDF  10     6.81 vkey 2.84 bkey 4.54 bkey 2.71 vkey 4.44 tool 2.13 after 3.42 bkey 1.57 bkey 2.85 tool 1.31 bkey 2.33 tool 0.68 tool 1.88 bkey 0.62 bkey 1.86 bkey 0.6 vkey 1.85 property 0.59 vkey 1.82 property 0.57 tool   60                                                                  13.    72.3 90.2  93.8 80.4ex 79.6 85.7ex 76.6 77.3  75 53.4  61.55.   155  66.94  6.96                            61 5.1  4fold cross validation Pearson correlation coefficient PCCrootmeansquare error RMSE  Additive regression  Additive regression  Y X  k   lowess  Additive regression   Y A   kj j jj1f B X   14.  PCC  RMSEFacttfidf 10034 0.941 13.9824Local label  16 0.838 22.8940Local label  256 0.913 16.9355 4 0.474 36.4526 3 0.478 36.3674Behaviortfidf 2897 0.945 13.5303 23 0.825 23.3904 23 0.302 39.4695 3 0.295 39.5495 4 0.126 41.0622 14 0.490 36.0889 17 0.607 32.9075   62                                                                  15. LOO   PCC RMSEFacttfidf 3270 0.934 14.745Local label  13288 0.957 11.960Local label  13048 0.947 13.708 13300 0.947 13.708 13301 0.947 13.708Behaviortfidf 10407 0.940 13.708 13281 0.949 13.615 13281 0.947 13.708 13301 0.947 13.708 13300 0.947 13.708 13290 0.947 13.708 13287 0.947 13.708  16.  Forward selection   PCC RMSE  13304 0.947 13.708 BehaviortfidfFacttfidf 12961 0.954 11.476  17.   PCC RMSEFacttfidf 10034 0.996 1.688 Local label  16 0.809 11.060Local label  256 0.994 2.105  4 0.480 16.363 3 0.136 18.482Behaviortfidf 2897 0.996 1.776                         63  23 0.947 5.998  23 0.797 11.258 3 0.225 18.178 4 0.151 18.442 14 0.627 14.705 17 0.597 14.968 18. LOO   PCC RMSEFacttfidf 3270 0.987 1.978 Local label  13288 0.996 1.634 Local label  13048 0.995 1.935  13300 0.995 1.935  13301 0.995 1.935 Behaviortfidf 10407 0.995 1.935  13281 0.995 1.935  13281 0.995 1.935  13301 0.995 1.935  13300 0.995 1.935  13290 0.995 1.935  13287 0.995 1.935  19. Forward selection   PCC RMSE  13304 0.995 1.935 FacttfidfBehaviortfidf 12954 0.996 1.602 Leave one out LOO Forward selection 1415  16 16PCC  0.954  RMSE  11.4761   64                                                                  1718  19 19 PCC  0.996  RMSE  1.6022  5.2   20 TFIDF  21  TFIDF TFIDF  22  20. 10       30.7969 bkey 56.62879 ftfidf 27.9362 ftfidf 53.65348 ftfidf 15.52409 ftfidf 11.02504 accomplice35 13.78044 ftfidf 8.084648 ftfidf 13.12859 ftfidf 4.883647 ftfidf 12.0484 ftfidf 3.959793 ftfidf 10.61914 ftfidf 3.877146 ftfidf 7.996218 ftfidf 2.892254 ftfidf 7.991696 ftfidf 2.532131 ftfidf 7.470467 ftfidf 2.511225 ftfidf   21. TFIDF  10        30.7969 bkey 11.02504 accomplice35 0.555235 bkey 0.719344 victim12 0.504492 bkey 6.15E01 vkey 0.503787 property 5.80E01 vkey                         65 0.439038 bkey 5.48E01 bkey 0.406706 tool 5.32E01 bkey 0.38426 property 0.509546 tool 0.351021 property 0.328142 property 0.325931 tool 0.110464 property 0.322338 property 5.92E02 bkey  22.      100.5   7.26    97.1   53.3   10.35   7.45    81.08   11.5    71.62   10.91    72.07   15.52    72.23  9.95   5 13  49   35 13  8.46   1235  74   12  8.53    66                                                                 6.  2113  140  1973  Local label  4fold cross validation  F1 scorePCC  RMSE  2324   23.   F1 scoreFacttfidf 10034 0.797 Behaviortfidf 2897 0.592  23 0.513  12954 0.801  24.     PCC RMSE PCC RMSE Facttfidf 10034 0.073 114.251 0.019 45.812 Behaviortfidf 2897 0.067 117.284 0.016 49.533  23 0.015 127.017 0.003 51.074  12954 0.085 112.144 0.022 44.823 7.  1  local label 2 3                          67    Andreas, H., Staab, S.  Stumme, G. 2003. Ontologies Improve Text Document Clustering. IEEE International Conference on Data Mining. Ashley, K. D.  Bruninghaus, S. 2009. Automatically Classifying Case Texts and Predicting Outcomes. AI and Law, 17. Jiang, W., Wang, X.L.  Guan, Y. 2006. Improving Sequence Tagging using Machine Learning Techniques. International Conference on Machine Learning and Cybernetics. Kuo, H.C., Tsai, T.H.  Huang, J.P. 2006. Building a Concept Hierarchy by Hierarchical Clustering with JoinMerge Decision. Joint Conference on Information Sciences. Lame, G. 2001. A Categorization Method for French Legal Documents on the Web. International Conference on Artificial Intelligence and Law, 21920. Liu, C.L., Chang, C.T.  Ho, J.J. 2004. Case Instance Generation and Refinement for CaseBased Criminal Summary Judgments in Chinese. Journal of Information Science and Engineering, 20, 783800. Schild, U. 1998. Criminal Sentencing and Intelligent Decision Support. AI and Law, 6, 151202. Wibowo, W.  Williams, H. E. 2002. Simple and Accurate Feature Selection for Hierarchical Categorisation. ACM Symposium on Document Engineering. Zhang, C., Xu, X.  Zhang, C. 2008. Analysis of the Factors Affecting the Performance of CRFbased Keywords Extraction Model. New Technology of Library and Information Service, 24, 3440.     68                                                                   Computational Linguistics and Chinese Language Processing Vol. 17, No. 4, December 2012, pp. 6984                                      69  The Association for Computational Linguistics and Chinese Language Processing  Speech Recognition Leveraging  Histogram Equalization Methods  HsinJu Hsieh, Jeihweih Hung, and Berlin Chen  Histogram Equalization, HEQ SpatialTemporal Contextual StatisticsDifferencingAveragingDimensionWiseRandom Noise Aurora2      Department of Computer Science  Information Engineering, National Taiwan Normal University Email hsinjuntnu.edu.tw berlinntnu.edu.tw                 Department of Electrical Engineering, National Chi Nan University Email jwhungncnu.edu.tw   70                                                                 Abstract Histogram equalization HEQ of speech features has received considerable attention in the field of robust speech recognition due to its simplicity and excellent performance. This paper is a continuation of this general line of research, presenting a novel HEQbased feature normalization framework which takes advantage of joint equalization of spatialtemporal contextual statistics of speech features. In doing so, we explore the use of simple differencing and averaging operations to capture the contextual statistics of feature vector components for speech feature normalization. All experiments are conducted on the Aurora2 database and task. Experimental results show that for cleancondition training, the methods instantiated from this framework achieve considerable word error rate reductions over the baseline system, which are indeed quite comparable to other conventional methods. Keywords Speech Recognition, Noise Robustness, Histogram Equalization, Feature Contextual Statistics. 1.    Automatic Speech Recognition, ASR Background NoiseChannel EffectMismatch                                                 71 Noise Robustness  1Additive Noise2Convolutional Noise 1   Gong, 1995 1 Speech Enhancement Spectral Subtraction, SS Boll, 1979Voice Activity Detection, VAD ITU, 1996 2 Robust Speech Feature Cepstrum Mean Subtraction, CMS Furui, 1981Cepstrum Mean     nt ht ytsthtnt  1.  st   72                                                                 and Variance Normalization, CMVN Viikki  Laurila, 1998                   Cepstral Mean and Variance Normalization plus AutoRegressiveMoving Averaging Filtering, MVA Chen  Bilmes, 2006 3 Acoustic Model Adaptation Maximum a Posteriori, MAP Gauvain  Lee, 1994Maximum Likelihood Linear Regression, MLLR Leggetter  Woodland, 1995Parallel Model Combination, PMC Hung et al., 2001 MelFrequency Cepstral Coefficients, MFCCs Davis  Mermelstein, 1980Linear Prediction Cepstral Coefficients, LPCC Atal, 1974Perceptual Linear Prediction Cepstral Coefficients, PLPCC Hermansky, 1991 CMSCMVNHEQ                                                    73 2.  2.1 Relative Spectral, RASTA Hermansky  Morgan, 1994  1Hz  12Hz NonSpeechBandPass FilterTransfer Function 2110.1   1RASTAz zH zz                     1 1Infinite Impulse Response, IIR z   0.94 0 2.2 Moment Normalization  11 , , 1Td ddd dtt ttX x x x X d DT                    2 21 11 1,   , , 1ddT Td d dd d d ttt t dt tx XX x x X x d DT T             3  dtx  d  t T dX  d  d MeanVariance dtx 23Suk et al., 1999     74                                                                 2.3 HEQ  Acharya  Ray, 2005 De la Torre et al., 2005 Hilger  Ney, 2006 Lin et al., 2009 Chen et al., 2011Speech Feature RepresentationProbability Distribution Function, PDF 1  , 1d dt refx F F x d D                           4 4 dx  d   dF x  x  d   refF   Ddtx  2.4 Cepstral Gain Normalization, CGNYoshizawa et al., 2001  11 , , 1max  min ddTd dd ttt d dtx XX x x d DT x x                            5  max   min   dx dX  2.5 MVA Chen et al., 2002 ARMA LowPass FilterNonStationary Noise Sharp PeakValleySmoothing                                                  75 , ,0 11 , 12 1M Md d dt CMVN t m CMVN t mm mx x x t TM                         6  M  ARMA  2 CMVNx  3. STHEQ 1Hz  16Hz Kanedera et al., 1997 Discrete Cosine Transform, DCTUncorrelated Logarithmic SpectrumCepstrm DomainMonotonic OverallTemporal DomainSpatial DomainLocal  t  dtx 1dtx FullBand   76                                                                 1,, 22, 1d dt tds diff tdtx xd Dxx d                   7 1,, 220, 1d dt tds avg tx xd Dxd                   8   ,ds diff tx   ,ds avg tx            dtx            HighFrequencyLowFrequency dtx  ,dt diff tx   ,dt avg tx   2  2.   STHEQ          Weighted SpatialTemporal Contextual Statistics Histogram HP LP HEQ HEQ MFCC HEQ HP LP HEQ HEQ Temporal Filtering Spatial Filtering STHEQ                                                  77 Equalization, WSTHEQ STHEQ STHEQ  WSTHEQ  1 all diff avgx x x                          9  diffx  avgx  allx  1  Hung  Fan, 2009 Joshi et al., 2011 4.   ETSI Advanced FrontEnd Standard, AFE Macho et al., 2002 4.1   Aurora2ETSI, 2005Aurora2 Set A Set B  Set C Set A SubwayBabblecarExhibition G.712 Set B RestaurantStreetAirportTrain StationG.712  Set C SubwayStreetMIRS SignaltoNoise Ratios, SNRs Clean dB20dB15dB10dB5dB0dB 5dB   10 log snESNR dBE                                 10   78                                                                  sE  nE Aurora2             CleanCondition Training         MultiCondition Training 8,440  G.712  Set C  1.   8000 Hz  25 ms  10 ms  1 0.97     256  23  13MFCCC0C12 13MFCCC0C12 13 MFCC C0 C1239 4.2   13  0  12 DeltaDeltaDelta 39  1 Hidden Markov Model Tool Kit, HTKCUED, n.d. 11 zero, one, two, , nine  oh 16  20  4.3  Word Accuracy             11  Aurora2  20 dB  0 dB 5 dB                                                   79 2.  Method Set A Set B Set C Avg. MFCC 54.87 48.87 63.95 54.29 ARMA 60.00 55.94 69.87 60.35 RASTA 67.44 71.90 68.45 69.43 CMS 66.81 71.79 67.64 68.97 CMVN 75.93 76.76 76.82 76.44 HEQ 80.03 82.05 80.10 80.85 CGN 80.08 81.48 80.20 80.66 MVA 80.89 82.00 81.49 81.45 SHEQ 82.16 84.44 81.12 82.87 THEQ 80.42 82.53 80.73 81.33 STHEQ 82.52 84.90 81.81 83.33 TSHEQ 81.85 84.41 81.11 82.72 4.4  STHEQ 2  34  STHEQ AFE 5   2 1.  HEQ All Moments CMSCMVNCGN  2.  SHEQ  THEQ  STHEQ TSHEQ STHEQ 54.29 83.33 64 3. SHEQTHEQ HEQ   80                                                                    3.  3  3  WSHEQ  0.3  0.4  0.4  82.8784.07 1.20 WTHEQ  0.6  0.8  0.7  81.33 82.94 HEQ  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9WSHEQ 81.91 82.65 83.61 84.07 82.87 80.76 78.44 75.93 74.43WTHEQ 80.81 80.81 80.99 80.91 81.33 81.94 82.94 82.51 75.7873757779818385AlphaWSHEQWTHEQ                                                 81   4.    5. AFESTHEQ 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9WSTHEQ 83.88 83.72 83.82 84.20 84.42 85.05 84.79 81.97 73.10 WTSHEQ 82.87 83.55 84.42 84.58 84.04 82.03 79.79 77.41 76.07 7274767880828486AlphaWSTHEQWTSHEQ0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1AFESTHEQ 87.17 87.20 87.39 87.40 87.79 87.84 88.03 88.22 88.17 87.71 85.9685.58686.58787.58888.589Alpha  82                                                                  4  3  WSTHEQ   0.4  SHEQ  THEQ   4  WSTHEQ   0.4  0.7  0.6   WTSHEQ   0.2  0.5  0.4   WSTHEQ  WTSHEQ AFE  AFE STHEQ  MFCC STHEQ  MFCC  STHEQ  AFE AFE  AFE Frames Dropping STHEQ  AFE  AFE  5  1 STHEQ  AFE  0  AFE  5  0.1  0.9  AFE  0.7  8 5.   Aurora2  STHEQ  STHEQ  HEQSHEQTHEQ  TSHEQ                                                  83  101J1A0900 101J1A0901NSC 1012221E003 024 MY3  NSC 99 2221E003 017 MY3  Acharya, T.  Ray, A. K. 2005. Image processing principles and applications, WileyInterscience. Atal, B. S. 1974. Effectiveness of linear prediction characteristics of the speech wave for automatic speaker identification and verification. Journal of the Acoustical Society of America, 55, 13041312. Boll, S. F. 1979. Suppression of acoustic noise in speech using spectral subtraction. IEEE Transactions on Acoustics, Speech and Signal Processing, 272, 133120. Chen, B., Chen, W. H., Lin, S. H.  Chu, W. Y. 2011. Robust speech recognition using spatialtemporal feature distribution characteristics. Pattern Recognition Letters, 327, 919926. Chen, C. P., Bilmes, J.  Kirchhoff, K. 2002. Lowresource noiserobust feature postprocessing on Aurora 2.0. In 7th International Conference on Spoken Language Processing ICSLP. Chen, C.  Bilmes, J. 2006. MVA processing of speech features. IEEE Transactions on Audio, Speech, and Language Processing, 151, 257270. CUED. n.d.. The hidden Markov model toolkit. Available from httphtk.eng.cam.ac.uk. Davis, S. B.  Mermelstein, P. 1980. Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences. IEEE Transactions on Acoustics, Speech, and Signal Processing, 284, 357366. De la Torre, A., Peinado, A. M., Segura, J. C., PerezCordoba, J. L., Benitez, M. C.  Rubio, A. J. 2005. Histogram equalization of speech representation for robust speech recognition. IEEE Transactions on Speech and Audio Processing, 133, 355366. ETSI. 2005. ETSI standard documentation, Speech processing, transmission and quality aspects STQ distributed speech recognition extended advanced frontend feature extraction algorithm compression algorithms backend speech reconstruction algorithm, ETSI ES 202 212 ver.1.1.2, 2005. Furui, S. 1981. Cepstral analysis technique for automatic speaker verification. IEEE Transactions on Acoustics, Speech and Signal Processing, 292, 254272. Gauvain, J. L.  Lee, C. H. 1994. Maximum a posteriori estimation for multivariate Gaussian mixture observations of Markov chains. IEEE Transactions on Speech and Audio Processing, 22, 291298. Gong, Y. 1995. Speech recognition in noisy environments A survey. Speech communication, 163, 261291.   84                                                                 Hermansky, H. 1991. Perceptual linear predictive PLP analysis of speech. Journal of the Acoustical Society of America, 874, 17381752. Hermansky, H.  Morgan, N. 1994. RASTA processing of speech. IEEE Transactions on Speech and Audio Processing, 24, 578589. Hilger, F.  Ney, H. 2006. Quantile based histogram equalization for noise robust large vocabulary speech recognition. IEEE Transactions on Speech and Audio Processing, 143, 845854. Hung, J. W.  Fan, H. T. 2009. Subband feature statistics normalization techniques based on a discrete wavelet transform for robust speech recognition. Signal Processing Letters, IEEE, 169, 806809. Hung, J. W., Shen, J. L.  Lee, L. S. 2001. New approaches for domain transformation and parameter combination for improved accuracy in parallel model combination PMC techniques. IEEE Transactions on Speech and Audio Processing, 98, 842855. ITU. 1996. ITUT Recommendation G.729Annex B A silence compression scheme for G.729 optimized for terminals conforming to recommendation V.70. Joshi, V., Bilgi, R., Umesh, S., Garcia, L.  Benitez, C. 2011. Subband level histogram equalization for robust speech recognition. In 12th Annual Conference of the International Speech Communication Association ICSLP. Kanedera, N., Arai, T., Hermansky, H.  Pavel, M. 1997. On the importance of various modulation frequencies for speech recognition. In European Conference on Speech Communication and Technology Eurospeech. Leggetter, C. J.  Woodland, P. C. 1995. Maximum likelihood linear regression for speaker adaptation of continuous density hidden Markov models. Computer Speech and Language, 9, 171185. Lin, S. H., Chen, B.  Yeh, Y. M. 2009. Exploring the use of speech features and their corresponding distribution characteristics for robust speech recognition. IEEE Transactions on Audio, Speech and Language Processing, 171, 8494. Macho, D., Mauuary, L., No, B., Cheng, Y. M., Ealey, D., Jouvet, D., Kelleher, H., Pearce, D.,  Saadoun, F. 2002. Evaluation of a noiserobust DSR frontend on Aurora databases. In 7th International Conference on Spoken Language Processing ICSLP. Suk, Y. H., Choi, S. H.  Lee, H. S. 1999. Cepstrum thirdorder normalization method for noisy speech recognition. Electronics Letters, 357, 527528. Viikki, O.  Laurila, K. 1998. Cepstral domain segmental feature vector normalization for noise robust speech recognition. Speech Communication, 2513, 133147. Yoshizawa, S., Hayasaka, N., Wada, N.,  Miyanaga, Y. 2004. Cpestral gain normalization for noise robust speech recognition. IEEE International Conference on Acoustics, Speech and Signal Processing, 1, 209212.   Reviewers List                                 85 The individuals listed below are reviewers of this journal during the year of 2012. The IJCLCLP Editorial Board extends its gratitude to these volunteers for their important contributions to this publication, to our association, and to the profession.      GuoWei Bian Jeihweih Hung Chun Chang JuneJei Kuo TaoHsing Chang YiChun Kuo RuYng Chang WenHsing Lai YuYun Chang BorShen Lin YiHsiang Chao ShuYen Lin ChaoJan Chen ChengJye Luh Limei Chen WeiYun Ma ChiaPing Chen Philips Kokoh Prasetyo TaiShih Chi WeiHo Tsai Chaochang Chiu GinDer Wu ChihYi Chiu JiunShiung Wu Donghui Feng ChengZen Yang ChihHsien Huang JuiFeng Yeh     2012 Index International Journal of Computational Linguistics                    Chinese Language Processing         IJCLCLP 2012 Index1 Vol. 17 This index covers all technical itemspapers, correspondence, reviews, etc.that appeared in this periodical during 2012. The Author Index contains the primary entry for each item, listed under the first authors name. The primary entry includes the coauthors names, the title of paper or other item, and its location, specified by the publication volume, number, and inclusive pages. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first authors name, the publication volume, number, and inclusive pages. AUTHOR INDEX C Chang, ChiaHui ShuYen Lin, MengFeng Tsai, ShuPing Li, HsiangMei Liao, and Norden E. Huang. Phonetic Component Ranking and Pronunciation Rules Discovery for PictoPhonetic Chinese Characters 173 2944 Chang, JingShin see Chuang, YiHsuan, 173 128 Chang, TungJia see Lin, WanChen, 174 4968 Chang, YuYun see Wang, ShengFu, 172 3754 Evaluation of TTS Systems in Intelligibility and Comprehension Tasks a Case Study of HTS2008 and Multisyn Synthesizers 173 109128 Chao, Lidia S. see Wang, LongYue, 174 1532 Chen, Berlin see Lin, ShihHsiang, 171 6586 see Hsieh, HsinJu, 174 6984 Chen, ChaoJu see Lin, WanChen, 174 4968 Chen, HsinHsi see Li, ChengRu, 172 2136 see Yu, HoCheng, 174 3348 Chen, KehJiann see Chung, Youshan, 172 120 Chen, SinHorng see Chiang, ChenYu, 171 2742 Chen, YenHeng see Lin, ChuanJie, 173 87108     Chiang, ChenYu QiQuan Huang, YihRu Wang, HsiuMin Yu, and SinHorng Chen. Variable Speech Rate Mandarin Chinese TexttoSpeech System 171 2742 Chuang, YiHsuan ChaoLin Liu, and JingShin Chang. Effects of Combining Bilingual and Collocational Information on Translation of English and Chinese VerbNoun Pairs 173 128 Chung, Youshan and KehJiann Chen. Transitivity of a Chinese VerbResult Compound and Affected Argument of the Result Verb 172 120 G Galmar, Bruno Using Kohonen Maps of Chinese Morphological Families to Visualize the Interplay of Morphology and Semantics in Chinese 172 5568 H Hsieh, HsinJu Jeihweih Hung, and Berlin Chen. Speech Recognition Leveraging Histogram Equalization Methods 174 6984 Hsieh, ShuKai see Wang, ShengFu, 172 3754 Hsu, ChiungWen see Ruan, JiaCing, 171 126 Hsu, WenLian see Jiang, Mike TianJian, 173 4586 Huang, Norden E. see Chang, ChiaHui, 173 2944 Huang, QiQuan see Chiang, ChenYu, 171 2742 Huang, TingHao Kenneth see Yu, HoCheng, 174 3348 Hung, Jeihweih see Hsieh, HsinJu, 174 6984 J Jiang, Mike TianJian ChengWei Shih, TingHao Yang, ChanHung Kuo, Richard TzongHan Tsai, and WenLian Hsu. Enhancement of Feature Engineering for Conditional Random Field Learning in Chinese Word Segmentation Using Unlabeled Data 173 4586 K Kuo, ChanHung see Jiang, Mike TianJian, 173 4586 Kuo, TsungTing see Lin, WanChen, 174 4968   IJCLCLP 2012 Index2 L Li, ChengRu ChiHsin Yu, and HsinHsi Chen. Predicting the Semantic Orientation of Terms in EHowNet 172 2136 Li, ShuPing see Chang, ChiaHui, 173 2944 Liao, HsiangMei see Chang, ChiaHui, 173 2944 Lin, ChuanJie JiaCheng Zhan, YenHeng Chen, and ChienWei Pao. Strategies of Processing Japanese Names and Character Variants in Traditional Chinese Text 173 87108 Lin, ShihHsiang and Berlin Chen. A Comparative Study of Methods for Topic Modeling in Spoken Document Retrieval 171 6586 Lin, Shoude see Lin, WanChen, 174 4968 Lin, ShuYen see Chang, ChiaHui, 173 2944 Lin, WanChen TsungTing Kuo, TungJia Chang, ChuehAn Yen, ChaoJu Chen, and Shoude Lin. Exploiting Machine Learning Models for Chinese Legal Document Labeling, Case Classification, and Sentencing Prediction 174 4968 Lin, YihJeng see Yu, MingShing, 171 4364 Liu, ChaoLin see Chuang, YiHsuan, 173 128 Liu, YuWen see Wang, ShengFu, 172 3754 M Ma, WeiYun and Kathleen McKeown. Detecting and Correcting Syntactic Errors in Machine Translation Using FeatureBased Lexicalized Tree Adjoining Grammars 174 114 McKeown, Kathleen see Ma, WeiYun, 174 114 Myers, James see Ruan, JiaCing, 171 126 P Pao, ChienWei see Lin, ChuanJie, 173 87108    R Ruan, JiaCing ChiungWen Hsu, James Myers, and Jane S. Tsay. Development and Testing of Transcription Software for a Southern Min Spoken Corpus 171 126 S Shih, ChengWei see Jiang, Mike TianJian, 173 4586 T Tsai, MengFeng see Chang, ChiaHui, 173 2944 Tsai, Richard TzongHan see Jiang, Mike TianJian, 173 4586 Tsay, Jane S. see Ruan, JiaCing, 171 126 W Wang, LongYue Derek F. Wong, and Lidia S. Chao. TQDL Integrated Models for CrossLanguage Document Retrieval 174 1532 Wang, ShengFu JingChen Yang, YuYun Chang, YuWen Liu, and ShuKai Hsieh. Frequency, Collocation, and Statistical Modeling of Lexical Items A Case Study of Temporal Expressions in Two Conversational Corpora 172 3754 Wang, YihRu see Chiang, ChenYu, 171 2742 Wong, Derek F. see Wang, LongYue, 174 1532 Y Yang, JingChen see Wang, ShengFu, 172 3754 Yang, TingHao see Jiang, Mike TianJian, 173 4586 Yen, ChuehAn see Lin, WanChen, 174 4968 Yu, ChiHsin see Li, ChengRu, 172 2136 Yu, HoCheng TingHao Kenneth Huang, and HsinHsi Chen. Domain Dependent Word Polarity Analysis for Sentiment Classification 174 3348 Yu, HsiuMin see Chiang, ChenYu, 171 2742 Yu, MingShing and YihJeng Lin. The Polysemy Problem, an Important Issue in a Chinese to Taiwanese TTS System 171 4364                                    IJCLCLP 2012 Index3 Z Zhan, JiaCheng see Lin, ChuanJie, 173 87108 SUBJECT INDEX A Accessor Variety Enhancement of Feature Engineering for Conditional Random Field Learning in Chinese Word Segmentation Using Unlabeled Data Jiang, M. T.J., 173 4586 Association Rule Phonetic Component Ranking and Pronunciation Rules Discovery for PictoPhonetic Chinese Characters Chang, C.H.,173 2944 B Break Prediction Variable Speech Rate Mandarin Chinese TexttoSpeech System Chiang, C.Y., 171 2742 C Case Classification Exploiting Machine Learning Models for Chinese Legal Document Labeling, Case Classification, and Sentencing Prediction Lin, W.C., 174 4968 Character Variants Strategies of Processing Japanese Names and Character Variants in Traditional Chinese Text Lin, C.J.,173 87108 Chinese to Taiwanese TTS System The Polysemy Problem, an Important Issue in a Chinese to Taiwanese TTS System Yu, M.S., 171 4364 Clustering Frequency, Collocation, and Statistical Modeling of Lexical Items A Case Study of Temporal Expressions in Two Conversational Corpora Wang, S.F., 172 3754 Collocation Frequency, Collocation, and Statistical Modeling of Lexical Items A Case Study of Temporal Expressions in Two Conversational Corpora Wang, S.F., 172 3754 Componentbased Teaching Method Phonetic Component Ranking and Pronunciation Rules Discovery for PictoPhonetic Chinese Characters Chang, C.H.,173 2944 Comprehension Evaluation Evaluation of TTS Systems in Intelligibility and Comprehension Tasks a Case Study of HTS2008 and Multisyn Synthesizers Chang, Y.Y., 173 109128 Computational Morphology and Semantics Using Kohonen Maps of Chinese Morphological Families to Visualize the Interplay of Morphology and Semantics in Chinese Galmar, B., 172 5568 Conditional Random Fields Enhancement of Feature Engineering for Conditional Random Field Learning in Chinese Word Segmentation Using Unlabeled Data Jiang, M. T.J., 173 4586 Corpus Linguistics Frequency, Collocation, and Statistical Modeling of Lexical Items A Case Study of Temporal Expressions in Two Conversational Corpora Wang, S.F., 172 3754 CrossLanguage Document Retrieval TQDL Integrated Models for CrossLanguage Document Retrieval Wang, L.Y., 174 1532 D Document Sentiment Classification Domain Dependent Word Polarity Analysis for Sentiment Classification Yu, H.C., 174 3348 Document Topic Models A Comparative Study of Methods for Topic Modeling in Spoken Document Retrieval Lin, S.H., 171 6586 Document TranslationBased TQDL Integrated Models for CrossLanguage Document Retrieval Wang, L.Y., 174 1532 E EHowNet Predicting the Semantic Orientation of Terms in EHowNet Li, C.R., 172 2136 Effects of Combining Bilingual and Collocational Information on Translation of English and Chinese VerbNoun Pairs Chuang, Y.H., 173 128 F Feature Comparison Effects of Combining Bilingual and Collocational Information on Translation of English and Chinese VerbNoun Pairs Chuang, Y.H., 173 128 Feature Contextual Statistics Speech Recognition Leveraging Histogram Equalization Methods Hsieh, H.J., 174 6984       IJCLCLP 2012 Index4 Feature Unification Detecting and Correcting Syntactic Errors in Machine Translation Using FeatureBased Lexicalized Tree Adjoining Grammars Ma, W.Y., 174 114 G Gerontology Frequency, Collocation, and Statistical Modeling of Lexical Items A Case Study of Temporal Expressions in Two Conversational Corpora Wang, S.F., 172 3754 H Histogram Equalization Speech Recognition Leveraging Histogram Equalization Methods Hsieh, H.J., 174 6984 HTS2008 Evaluation of TTS Systems in Intelligibility and Comprehension Tasks a Case Study of HTS2008 and Multisyn Synthesizers Chang, Y.Y., 173 109128 Human Judgments Effects of Combining Bilingual and Collocational Information on Translation of English and Chinese VerbNoun Pairs Chuang, Y.H., 173 128 I Information Retrieval A Comparative Study of Methods for Topic Modeling in Spoken Document Retrieval Lin, S.H., 171 6586 Intelligibility Evaluation Evaluation of TTS Systems in Intelligibility and Comprehension Tasks a Case Study of HTS2008 and Multisyn Synthesizers Chang, Y.Y., 173 109128 Intimidation Exploiting Machine Learning Models for Chinese Legal Document Labeling, Case Classification, and Sentencing Prediction Lin, W.C., 174 4968 J Japanese Name Identification Strategies of Processing Japanese Names and Character Variants in Traditional Chinese Text Lin, C.J.,173 87108 K Keyin Systems Development and Testing of Transcription Software for a Southern Min Spoken Corpus Ruan, J.C., 171 126  L Layered Approach The Polysemy Problem, an Important Issue in a Chinese to Taiwanese TTS System Yu, M.S., 171 4364 Learning Curve Phonetic Component Ranking and Pronunciation Rules Discovery for PictoPhonetic Chinese Characters Chang, C.H.,173 2944 LengthBased Filter TQDL Integrated Models for CrossLanguage Document Retrieval Wang, L.Y., 174 1532 Lexicalsemantics Transitivity of a Chinese VerbResult Compound and Affected Argument of the Result Verb Chung, Y.s., 172 120 M Machine Learning Domain Dependent Word Polarity Analysis for Sentiment Classification Yu, H.C., 174 3348 Machine Translation Effects of Combining Bilingual and Collocational Information on Translation of English and Chinese VerbNoun Pairs Chuang, Y.H., 173 128 Detecting and Correcting Syntactic Errors in Machine Translation Using FeatureBased Lexicalized Tree Adjoining Grammars Ma, W.Y., 174 114 Mandarin Prosody Variable Speech Rate Mandarin Chinese TexttoSpeech System Chiang, C.Y., 171 2742 Meaning Prediction Transitivity of a Chinese VerbResult Compound and Affected Argument of the Result Verb Chung, Y.s., 172 120 Multisyn Evaluation of TTS Systems in Intelligibility and Comprehension Tasks a Case Study of HTS2008 and Multisyn Synthesizers Chang, Y.Y., 173 109128 N Near Synonyms in Chinese Effects of Combining Bilingual and Collocational Information on Translation of English and Chinese VerbNoun Pairs Chuang, Y.H., 173 128 Noise Robustness Speech Recognition Leveraging Histogram Equalization Methods Hsieh, H.J., 174 6984                                    IJCLCLP 2012 Index5 P Pictophonetic Character Phonetic Component Ranking and Pronunciation Rules Discovery for PictoPhonetic Chinese Characters Chang, C.H., 173 2944 Polysemy The Polysemy Problem, an Important Issue in a Chinese to Taiwanese TTS System Yu, M.S., 171 4364 Post Editing Detecting and Correcting Syntactic Errors in Machine Translation Using FeatureBased Lexicalized Tree Adjoining Grammars Ma, W.Y., 174 114 Pronunciation Strength of Phonetic Component Phonetic Component Ranking and Pronunciation Rules Discovery for PictoPhonetic Chinese Characters Chang, C.H., 173 2944 R Robbery Exploiting Machine Learning Models for Chinese Legal Document Labeling, Case Classification, and Sentencing Prediction Lin, W.C., 174 4968 Romanization Development and Testing of Transcription Software for a Southern Min Spoken Corpus Ruan, J.C., 171 126 S SelfOrganizing Maps Using Kohonen Maps of Chinese Morphological Families to Visualize the Interplay of Morphology and Semantics in Chinese Galmar, B., 172 5568 Semantic Chinese Word Segmentation Strategies of Processing Japanese Names and Character Variants in Traditional Chinese Text Lin, C.J.,173 87108 Semantic Orientation Predicting the Semantic Orientation of Terms in EHowNet Li, C.R., 172 2136 Sentencing Prediction Exploiting Machine Learning Models for Chinese Legal Document Labeling, Case Classification, and Sentencing Prediction Lin, W.C., 174 4968 Sentiment Analysis Predicting the Semantic Orientation of Terms in EHowNet Li, C.R., 172 2136 Sentiment Dictionary Predicting the Semantic Orientation of Terms in EHowNet Li, C.R., 172 2136   Southern Min Development and Testing of Transcription Software for a Southern Min Spoken Corpus Ruan, J.C., 171 126 Speech Rate Variable Speech Rate Mandarin Chinese TexttoSpeech System Chiang, C.Y., 171 2742 Speech Recognition Speech Recognition Leveraging Histogram Equalization Methods Hsieh, H.J., 174 6984 Speech Synthesizers Evaluation of TTS Systems in Intelligibility and Comprehension Tasks a Case Study of HTS2008 and Multisyn Synthesizers Chang, Y.Y., 173 109128 Speech Transcription Development and Testing of Transcription Software for a Southern Min Spoken Corpus Ruan, J.C., 171 126 Spoken Document Retrieval A Comparative Study of Methods for Topic Modeling in Spoken Document Retrieval Lin, S.H., 171 6586 Statistical Machine Translation TQDL Integrated Models for CrossLanguage Document Retrieval Wang, L.Y., 174 1532 SVM Predicting the Semantic Orientation of Terms in EHowNet Li, C.R., 172 2136 Syntactic Error Detecting and Correcting Syntactic Errors in Machine Translation Using FeatureBased Lexicalized Tree Adjoining Grammars Ma, W.Y., 174 114 T Taiwanese Development and Testing of Transcription Software for a Southern Min Spoken Corpus Ruan, J.C., 171 126 The Polysemy Problem, an Important Issue in a Chinese to Taiwanese TTS System Yu, M.S., 171 4364 Temporal Expression Frequency, Collocation, and Statistical Modeling of Lexical Items A Case Study of Temporal Expressions in Two Conversational Corpora Wang, S.F., 172 3754 Termcontributed Boundary Enhancement of Feature Engineering for Conditional Random Field Learning in Chinese Word Segmentation Using Unlabeled Data Jiang, M. T.J., 173 4586   IJCLCLP 2012 Index6 Termcontributed Frequency Enhancement of Feature Engineering for Conditional Random Field Learning in Chinese Word Segmentation Using Unlabeled Data Jiang, M. T.J., 173 4586 TexttoSpeech System Variable Speech Rate Mandarin Chinese TexttoSpeech System Chiang, C.Y., 171 2742 TFIDF TQDL Integrated Models for CrossLanguage Document Retrieval Wang, L.Y., 174 1532 Transitivity Transitivity of a Chinese VerbResult Compound and Affected Argument of the Result Verb Chung, Y.s., 172 120 Tree Adjoining Grammar Detecting and Correcting Syntactic Errors in Machine Translation Using FeatureBased Lexicalized Tree Adjoining Grammars Ma, W.Y., 174 114 V Verbresult Compound Transitivity of a Chinese VerbResult Compound and Affected Argument of the Result Verb Chung, Y.s., 172 120 W Word Polarity Analysis Domain Dependent Word Polarity Analysis for Sentiment Classification Yu, H.C., 174 3348 Word Segmentation Enhancement of Feature Engineering for Conditional Random Field Learning in Chinese Word Segmentation Using Unlabeled Data Jiang, M. T.J., 173 4586 Word Topic Models A Comparative Study of Methods for Topic Modeling in Spoken Document Retrieval Lin, S.H., 171 6586  The Association for Computational Linguistics and  Chinese Language Processing         new members are welcomed Aims 1. To conduct research in computational linguistics. 2. To promote the utilization and development of computational linguistics. 3. To encourage research in and development of the field of Chinese computational linguistics both domestically and internationally. 4. To maintain contact with international groups who have similar goals and to cultivate academic exchange. Activities 1. Holding the Republic of China Computational Linguistics Conference ROCLING annually. 2. Facilitating and promoting academic research, seminars, training, discussions, comparative evaluations and other activities related to computational linguistics. 3. Collecting information and materials on recent developments in the field of computational linguistics, domestically and internationally. 4. Publishing pertinent journals, proceedings and newsletters. 5. Setting of the Chineselanguage technical terminology and symbols related to computational linguistics. 6. Maintaining contact with international computational linguistics academic organizations. 7. Dealing with various other matters related to the development of computational linguistics. To Register Please send application to The Association for Computational Linguistics and Chinese Language Processing Institute of Information Science, Academia Sinica 128, Sec. 2, Academy Rd., Nankang, Taipei 11529, Taiwan, R.O.C.  payment Credit cardsplease fill in the order form, cheque, or money orders. Annual Fees regularoverseas member NT 1,000 US50. group membership     NT20,000 US1,000. life memberten times the annual fee for regular group overseas members Contact Address The Association for Computational Linguistics and Chinese Language Processing Institute of Information Science, Academia Sinica 128, Sec. 2, Academy Rd., Nankang, Taipei 11529, Taiwan, R.O.C. Tel.886227883799 ext. 1502     Fax886227881638 Email aclclphp.iis.sinica.edu.tw   Web Site httpwww.aclclp.org.tw Please address all correspondence to Miss Qi Huang, or Miss Abby Ho The Association for Computational Linguistics and Chinese Language Processing Membership Application Form Member ID  Name  Date of Birth  Country of Residence  ProvinceState      Passport No.   Sex           Educationhighest degree obtained        Work Experience                   Present Occupation    Address   Email Add Tel. No  Fax No     Membership Category Regular Member  Life Member Date    YMD Applicants Signature    Remarks Please indicated clearly in which membership category you wish to register,           according to the following scale of annual membership dues Regular Member  US 50. NT 1,000 Life Member       US500.NT10,000 Please feel free to make copies of this application for others to use. Committee Assessment                       Rocling                           1. Email 2. 19166251               10,000. US 500.        1,000.     US 50.     500.              20,000.  US 1,000.      115128       02 27883799  ext.1502  02 27881638      Emailaclclphp.iis.sinica.edu.tw  httpwww.aclclp.org.tw                                                                   EMail                                                                                                                                                                1.    10,000.      1,000.   500.      20,000. 2.  128     02 27883799  ext.1502 02 27881638    Emailaclclphp.iis.sinica.edu.tw  httpwww.aclclp.org.tw    3.  The Association for Computational Linguistics and Chinese Language Processing ACLCLP PAYMENT FORM  Name                Please print  Date                       Please debit my credit card as follows US     VISA CARD   MASTER CARD  JCB CARD Issue Bank       Card No.                                               Exp. Date             3digit code                on the back card, inside the signature area, the last three digits CARD HOLDER SIGNATURE     Tel.   Email                                    Add     PAYMENT FOR US     Computational Linguistics  Chinese Languages Processing CLCLP              Quantity Wanted  US     Publications             US     Text Corpora         US     Speech Corpora            US     Others          US     Life Member Fee   New Member  Renew US      Total  Fax  886227881638 or Mail this form to   ACLCLP   Institute of Information Science, Academia Sinica R502, 128, Sec.2, Academia Rd., Nankang, Taipei 115, Taiwan Email aclclphp.iis.sinica.edu.tw Website httpwww.aclclp.org.tw                                   VISA CARD  MASTER CARD  JCB CARD                                                                     Email              NT          IJCLCLP NT     NT     NT     NT     NT     NT     NT     NT     NT                       NT         NT              NT        0227881638  1152128  Email aclclphp.iis.sinica.edu.tw Website httpwww.aclclp.org.tw Publications of the Association for  Computational Linguistics and Chinese Language Processing    Surface AIR USEURP AIR ASIA VOLUME AMOUNT 1. no.9201, no. 9204  ICG  A Conceptual    Structure for Parsing Mandarin  Its Frame and General Applications    US 9 US 19 US15   2. no.9202  VN   9203  VR   12 21 17   3. no.9301   8 13 11   4. no.9302   18 30 24   5. no.9303    10 15 13   6. no.9305                        10 15 13   7. no.9306                   5 10 8   8. no.9401   18 30 24   9. no.9402   11 16 14   10. no.9501   8 13 10   11. no.95029804   3 8 6   12. no.9503   3 8 6   13. no.9601  8 13 11   14. no.9701    19 31 25   15. no.9702   9 14 12   16. no.9801   18 30 26   17. no.9802  Accumulated Word Frequency in CKIP Corpus 15 25 21   18. no.9803   4 9 7   19. no.0201   8 13 11   20. Computational Linguistics  Chinese Languages Processing One year Back issues of IJCLCLP US 20 per copy  100 100   21. Readings in Chinese Language Processing  25 25 21       TOTAL              10 member discount Total Due  OVERSEAS USE ONLY  PAYMENT  Credit Card  Preferred   Money Order or Check payable to The Association for Computation Linguistics and Chinese Language Processing  or   Emailaclclphp.iis.sinica.edu.tw  Name please print                              Signature                                 Fax                                           Email                                   Address                                                                                       1. no.9201, no. 9204   ICG    A conceptual Structure for Parsing Mandarinits Frame and General Applications NT 80 NT 100   2.  no.9202, no. 9203            VN  VR  120 150   3. no.9301                120 130   4. no.9302   360 400   5. no.9303    180 200   6. no.9305                        185 205   7. no.9306                   40 50   8. no.9401   380 450   9. no.9402    180 200   10. no.9501   75 85   11. no.95029804   75 85   12. no.9503   75 80   13. no.9601  110 120   14. no.9701    400 450   15. no.9702   90 100   16 no.9801   395 440   17. no.9802  Accumulated Word Frequency in CKIP Corpus 340 380   18. no.9803  90 100   19. no.0201  75 85   20  COLING 2002  100 200   21.  COLING 2002  300 400   22.  COLING 2002 Workshop  300 400   23.  ISCSLP 2002  300 400   24.  1997 130 150   25.     500  2,500   26. Readings of Chinese Language Processing 675 675   27.  1990 150 165                 19166251    02 27883799 1502                  Emailaclclphp.iis.sinica.edu.tw                                                                                                                                                                      Email
