RealTime Dynamic Voltage Scaling for LowPowerEmbedded Operating SystemsPadmanabhan Pillai and Kang G. ShinRealTime Computing LaboratoryDepartment of Electrical Engineering and Computer ScienceThe University of MichiganAnn Arbor, MI 481092122, U.S.A.pillai,kgshineecs.umich.eduABSTRACTIn recent years, there has been a rapid and wide spread of nontraditional computing platforms, especially mobile and portable computing devices. As applications become increasingly sophisticatedand processing power increases, the most serious limitation on thesedevices is the available battery life. Dynamic Voltage Scaling DVShas been a key technique in exploiting the hardware characteristicsof processors to reduce energy dissipation by lowering the supplyvoltage and operating frequency. The DVS algorithms are shown tobe able to make dramatic energy savings while providing the necessary peak computation power in generalpurpose systems. However, for a large class of applications in embedded realtime systems like cellular phones and camcorders, the variable operatingfrequency interferes with their deadline guarantee mechanisms, andDVS in this context, despite its growing importance, is largelyoverlookedunderdeveloped. To provide realtime guarantees, DVSmust consider deadlines and periodicity of realtime tasks, requiring integration with the realtime scheduler. In this paper, we presenta class of novel algorithms called realtime DVS RTDVS thatmodify the OSs realtime scheduler and task management serviceto provide significant energy savings while maintaining realtimedeadline guarantees. We show through simulations and a workingprototype implementation that these RTDVS algorithms closelyapproach the theoretical lower bound on energy consumption, andcan easily reduce energy consumption 20 to 40 in an embeddedrealtime system.1. INTRODUCTIONComputation and communication have been steadily moving toward mobile and portable platformsdevices. This is very evidentin the growth of laptop computers and PDAs, but is also occurring in the embedded world. With continued miniaturization andincreasing computation power, we see ever growing use of powerThe work reported in this paper is supported in part by theU.S. Airforce Office of Scientific Research under Grant AFOSRF496200110120.This paper will appear in SOSP01ful microprocessors running sophisticated, intelligent control software in a vast array of devices including digital camcorders, cellular phones, and portable medical devices.Unfortunately, there is an inherent conflict in the design goals behind these devices as mobile systems, they should be designed tomaximize battery life, but as intelligent devices, they need powerfulprocessors, which consume more energy than those in simpler devices, thus reducing battery life. In spite of continuous advances insemiconductor and battery technologies that allow microprocessorsto provide much greater computation per unit of energy and longertotal battery life, the fundamental tradeoff between performanceand battery life remains critically important.Recently, significant research and development efforts have beenmade on Dynamic Voltage Scaling DVS 2, 4, 7, 8, 12, 19, 21,22, 23, 24, 25, 26, 28, 30. DVS tries to address the tradeoffbetween performance and battery life by taking into account twoimportant characteristics of most current computer systems 1the peak computing rate needed is much higher than the averagethroughput that must be sustained and 2 the processors are basedon CMOS logic. The first characteristic effectively means that highperformance is needed only for a small fraction of the time, whilefor the rest of the time, a lowperformance, lowpower processorwould suffice. We can achieve the low performance by simplylowering the operating frequency of the processor when the fullspeed is not needed. DVS goes beyond this and scales the operating voltage of the processor along with the frequency. This ispossible because static CMOS logic, used in the vast majority ofmicroprocessors today, has a voltagedependent maximum operating frequency, so when used at a reduced frequency, the processorcan operate at a lower supply voltage. Since the energy dissipatedper cycle with CMOS circuitry scales quadratically to the supplyvoltage     2, DVS can potentially provide a very largenet energy savings through frequency and voltage scaling.In timeconstrained applications, often found in embedded systemslike cellular phones and digital video cameras, DVS presents a serious problem. In these realtime embedded systems, one cannotdirectly apply most DVS algorithms known to date, since changing the operating frequency of the processor will affect the execution time of the tasks and may violate some of the timelinessguarantees. In this paper, we present several novel algorithms thatincorporate DVS into the OS scheduler and task management services of a realtime embedded system, providing the energy savings of DVS while preserving deadline guarantees. This is in sharp1contrast with the average throughputbased mechanisms typical ofmany current DVS algorithms. In addition to detailed simulationsthat show the energyconserving benefits of our algorithms, we alsopresent an actual implementation of our mechanisms, demonstrating them with measurements on a working system. To the best ofour knowledge, this is one of the first working implementations ofDVS, and the first implementation of RealTime DVS RTDVS.In the next section, we present details of DVS, realtime scheduling, and our new RTDVS algorithms. Section 3 presents the simulation results and provides insight into the system parameters thatmost influence the energysavings potential of RTDVS. Section 4describes our implementation of RTDVS mechanisms in a working system and some measurements obtained. Section 5 presentsrelated work and puts our work in a larger perspective before weclose with our conclusions and future directions in Section 6.2. RTDVSTo provide energysaving DVS capability in a system requiringrealtime deadline guarantees, we have developed a class of RTDVS algorithms. In this section, we first consider DVS in general,and then discuss the restrictions imposed in embedded realtimesystems. We then present RTDVS algorithms that we have developed for this timeconstrained environment.2.1 Why DVSPower requirements are one of the most critical constraints in mobile computing applications, limiting devices through restricted powerdissipation, shortened battery life, or increased size and weight.The design of portable or mobile computing devices involves atradeoff between these characteristics. For example, given a fixedsize or weight for a handheld computation deviceplatform, onecould design a system using a lowspeed, lowpower processor thatprovides long battery life, but poor performance, or a system witha literally more powerful processor that can handle all computational loads, but requires frequent battery recharging. This simplyreflects the cost of increasing performance  for a given technology, the faster the processor, the higher the energy costs both overall and per unit of computation.The discussion in this paper will generally focus on the energy consumption of the processor in a portable computation device for twomain reasons. First, the practical size and weight of the deviceare generally fixed, so for a given battery technology, the available energy is also fixed. This means that only power consumptionaffects the battery life of the device. Secondly, we focus particularly on the processor because in most applications, the processor is the most energyconsuming component of the system. Thisis definitely true on small handheld devices like PDAs 3, whichhave very few components, but also on large laptop computers 20that have many components including large displays with backlighting. Table 1 shows measured power consumption of a typicallaptop computer. When it is idle, the display backlighting accountsfor a large fraction of dissipated power, but at maximum computational load, the processor subsystem dominates, accounting fornearly 60 of the energy consumed. As a result, the design problem generally boils down to a tradeoff between the computationalpower of the processor and the systems battery life.One can avoid this problem by taking advantage of a feature verycommon in most computing applications the average computational throughput is often much lower than the peak computationalcapacity needed for adequate performance. Ideally, the processorScreen CPU subsystem Disk PowerOn Idle Spinning 13.5 WOn Idle Standby 13.0 WOff Idle Standby 7.1 WOff Max. Load Standby 27.3 WTable 1 Power consumption measured on HewlettPackardN3350 laptop computerwould be sized to meet the average computational demands, andwould have low energy costs per unit of computation, thus providing good battery life. During the relatively rare times when peakcomputational load is imposed, the higher computational throughput of a more sophisticated processor would somehow be configured to meet the high performance requirement, but at a higherenergy cost per unit of computation. Since the highcost cyclesare applied for only some, rather than all, of the computation, theenergy consumption will be lower than if the more powerful processor were used all of the time, but the performance requirementsare still met.One promising mechanism that provides the best of both lowpowerand highperformance processors in the same system is DVS 30.DVS relies on special hardware, in particular, a programmable DCDC switching voltage regulator, a programmable clock generator,and a highperformance processor with wide operating ranges, toprovide this bestofbothworlds capability. In order to meet peakcomputational loads, the processor is operated at its normal voltage and frequency which is also its maximum frequency. Whenthe load is lower, the operating frequency is reduced to meet thecomputational requirements. In CMOS technology, used in virtually all microprocessors today, the maximum operating frequencyincreases within certain limits with increased operating voltage,so when the processor is run slower, a reduced operating voltagesuffices 2. A second important characteristic is that the energyconsumed by the processor per clock cycle scales quadraticallywith the operating voltage     2, so even a small changein voltage can have a significant impact on energy consumption.By dynamically scaling both voltage and frequency of the processor based on computation load, DVS can provide the performanceto meet peak computational demands, while on average, providingthe reduced power consumption including energy per unit computation benefits typically available on lowperformance processors.2.2 Realtime issuesFor timecritical applications, however, the scaling of processor frequency could be detrimental. Particularly in realtime embeddedsystems like portable medical devices and cellular phones, wheretasks must be completed by some specified deadlines, most algorithms for DVS known to date cannot be applied. These DVS algorithms do not consider realtime constraints and are based on solelyaverage computational throughput 7, 23, 30. Typically, they use asimple feedback mechanism, such as detecting the amount of idletime on the processor over a period of time, and then adjust the frequency and voltage to just handle the computational load. This isvery simple and follows the load characteristics closely, but cannotprovide any timeliness guarantees and tasks may miss their execution deadlines. As an example, in an embedded camcorder controller, suppose there is a program that must react to a change ina sensor reading within a 5 ms deadline, and that it requires up to3 ms of computation time with the processor running at the maximum operating frequency. With a DVS algorithm that reacts only2EDF test if            return trueelse return falseRM test if                        return trueelse return falseselect frequencyuse lowest frequency             such that RM test  or EDF test  is true.Figure 1 Static voltage scaling algorithm for EDF and RMschedulersto average throughput, if the total load on the system is low, theprocessor would be set to operate at a low frequency, say half ofthe maximum, and the task, now requiring 6 ms of processor time,cannot meet its 5 ms deadline. In general, none of the averagethroughputbased DVS algorithms found in literature can providerealtime deadline guarantees.In order to realize the reduced energyconsumption benefits of DVSin a realtime embedded system, we need new DVS algorithms thatare tightlycoupled with the actual realtime scheduler of the operating system. In the classic model of a realtime system, there is aset of tasks that need to be executed periodically. Each task,  , hasan associated period,, and a worstcase computation time,.1.The task is released put in a runnable state periodically once every time units actual units can be seconds or processor cyclesor any other meaningful quanta, and it can begin execution. Thetask needs to complete its execution by its deadline, typically defined as the end of the period 18, i.e., by the next release of thetask. As long as each task   uses no more than cycles in eachinvocation, a realtime scheduler can guarantee that the tasks willalways receive enough processor cycles to complete each invocation in time. Of course, to provide such guarantees, there are someconditions placed on allowed task sets, often expressed in the formof schedulability tests. A realtime scheduler guarantees that taskswill meet their deadlines given thatC1. the task set is schedulable passes schedulability test, andC2. no task exceeds its specified worstcase computation bound.DVS, when applied in a realtime system, must ensure that both ofthese conditions hold.In this paper, we develop algorithms to integrate DVS mechanismsinto the two moststudied realtime schedulers, Rate MonotonicRM and EarliestDeadlineFirst EDF schedulers 13, 14, 17,18, 27. RM is a static priority scheduler, and assigns task priority according to period  it always selects first the task with theshortest period that is ready to run released for execution. EDFis a dynamic priority scheduler that sorts tasks by deadlines and always gives the highest priority to the released task with the mostAlthough not explicit in the model, aperiodic and sporadic taskscan be handled by a periodic or deferred server 16 For nonrealtime tasks, too, we can provision processor time using a similarperiodic server approach.0 5 10 150 5 10 150 5 10 150.500.751.000.500.751.000.500.751.00deadlineT3 missesT1 T2 T3 T1 T2T2T2 T3T1 T1 T3T1 T1T2 T2msmsmsfrequencyfrequencyfrequencyStatic EDFuses 0.75Static RMuses 1.0Static RMfails at 0.75Figure 2 Static voltage scaling exampleTask Computing Time Period1 3 ms 8 ms2 3 ms 10 ms3 1 ms 14 msTable 2 Example task set, where computing times are specifiedat the maximum processor frequencyimminent deadline. In the classical treatments of these schedulers18, both assume that the task deadline equals the period i.e., thetask must complete before its next invocation, that scheduling andpreemption overheads are negligible,2 and that the tasks are independent no task will block waiting for another task. In our designof DVS to realtime systems, we maintain the same assumptions,since our primary goal is to reduce energy consumption, rather thanto derive general scheduling mechanisms.In the rest of this section, we present our algorithms that performDVS in timeconstrained systems without compromising deadlineguarantees of realtime schedulers.2.3 Static voltage scalingWe first propose a very simple mechanism for providing voltagescaling while maintaining realtime schedulability. In this mechanism we select the lowest possible operating frequency that will allow the RM or EDF scheduler to meet all the deadlines for a giventask set. This frequency is set statically, and will not be changedunless the task set is changed.To select the appropriate frequency, we first observe that scalingthe operating frequency by a factor    effectivelyresults in the worstcase computation time needed by a task to bescaled by a factor , while the desired period and deadline remains unaffected. We can take the wellknown schedulability testsfor EDF and RM schedulers from the realtime systems literature,and by using the scaled values for worstcase computation needsof the tasks, can test for schedulability at a particular frequency.The necessary and sufficient schedulability test for a task set underideal EDF scheduling requires that the sum of the worstcase utilizations computation time divided by period be less than one, i.e.,           18. Using the scaled computationtime values, we obtain the EDF schedulability test with frequencyWe note that one could account for preemption overheads bycomputing the worstcase preemption sequences for each task andadding this overhead to its worstcase computation time.30 5 10 150.500.751.00msfrequencyT1 T2T3T1T2 T30.5460.621 0.421 0.2960.421 0.496 0.296 0.296i U  0.746Figure 3 Example of cycleconserving EDFTask Invocation 1 Invocation 21 2 ms 1 ms2 1 ms 1 ms3 1 ms 1 msTable 3 Actual computation requirements of the example taskset assuming execution at max. frequencyscaling factor            Similarly, we start with the sufficient but not necessary conditionfor schedulability under RM scheduling 13 and obtain the testfor a scaled frequency see Figure 1. The operating frequency selected is the lowest one for which the modified schedulability testsucceeds. The voltage, of course, is changed to match the operating frequency. Assume that the operating frequencies and thecorresponding voltage settings available on the particular hardwareplatform are specified in a table provided to the software. Figure 1summarizes the static voltage scaling for EDF and RM scheduling, where there are  operating frequencies      such that   .Figure 2 illustrates these mechanisms, showing sample worstcaseexecution traces under staticallyscaled EDF and RM scheduling.The example uses the task set in Table 2, which indicates eachtasks period and worstcase computation time, and assumes thatthree normalized, discrete frequencies are available 0.5, 0.75, and1.0. The figure also illustrates the difference between EDF andRM i.e., deadline vs. rate for priority, and shows that staticallyscaled RM cannot reduce frequency and therefore reduce voltageand conserve energy as aggressively as the EDF version.As long as for some available frequency, the task set passes theschedulability test, and as long as the tasks use no more than theirscaled computation time, this simple mechanism will ensure thatfrequency and voltage scaling will not compromise timely execution of tasks by their deadlines. The frequency and voltage setting selected are static with respect to a particular task set, and arechanged only when the task set itself changes. As a result, thismechanism need not be tightlycoupled with the task managementfunctions of the realtime operating system, simplifying implementation. On the other hand, this algorithm may not realize the fullpotential of energy savings through frequency and voltage scaling.In particular, the static voltage scaling algorithm does not deal withsituations where a task uses less than its worstcase requirement ofprocessor cycles, which is usually the case. To deal with this common situation, we need more sophisticated, RTDVS mechanisms.2.4 Cycleconserving RTDVSAlthough realtime tasks are specified with worstcase computationrequirements, they generally use much less than the worst case onmost invocations. To take best advantage of this, a DVS mechanismcould reduce the operating frequency and voltage when tasks useless than their worstcase time allotment, and increase frequencyselect frequencyuse lowest freq.             such that      upon task release set to select frequencyupon task completion set to     is the actual cycles used this invocation select frequencyFigure 4 Cycleconserving DVS for EDF schedulersto meet the worstcase needs. When a task is released for its nextinvocation, we cannot know how much computation it will actually require, so we must make the conservative assumption that itwill need its specified worstcase processor time. When the taskcompletes, we can compare the actual processor cycles used tothe worstcase specification. Any unused cycles that were allotted to the task would normally or eventually be wasted, idlingthe processor. Instead of idling for extra processor cycles, we candevise DVS algorithms that avoid wasting cycles hence cycleconserving by reducing the operating frequency. This is somewhat similar to slack time stealing 15, except surplus time is usedto run other remaining tasks at a lower CPU frequency rather thanaccomplish more work. These algorithms are tightlycoupled withthe operating systems task management services, since they mayneed to reduce frequency on each task completion, and increasefrequency on each task release. The main challenge in designingsuch algorithms is to ensure that deadline guarantees are not violated when the operating frequencies are reduced.For EDF scheduling, as mentioned earlier, we have a very simpleschedulability test as long as the sum of the worstcase task utilizations is less than  , the task set is schedulable when operatingat the maximum frequency scaled by factor  . If a task completesearlier than its worstcase computation time, we can reclaim theexcess time by recomputing utilization using the actual computingtime consumed by the task. This reduced value is used until thetask is released again for its next invocation. We illustrate this inFigure 3, using the same task set and available frequencies as before, but using actual execution times from Table 3. Here, eachinvocation of the tasks may use less than the specified worstcasetimes, but the actual value cannot be known to the system until afterthe task completes execution. Therefore, at each scheduling pointtask release or completion the utilization is recomputed using theactual time for completed tasks and the specified worst case for theothers, and the frequency is set appropriately. The numerical values in the figure show the total task utilizations computed using theinformation available at each point.The algorithm itself Figure 4 is simple and works as follows. Suppose a task   completes its current invocation after using   cycleswhich are usually much smaller than its worstcase computationtime. Since task   uses no more than   cycles in its currentinvocation, we treat the task as if its worstcase computation boundwere   . With the reduced utilization specified for this task, we cannow potentially find a smaller scaling factor  i.e., lower operatingfrequency for which the task set remains schedulable. Trivially,40.500.751.000 5 10 15frequencyms0.500.751.000 5 10 15frequencyms0.500.751.000 5 10 15frequencymsabcD1D1 D2D3D3D2D1 D2 D3time0time2time0T1T2 T3T1 T2 T3T3T2T1T3T2T1T1 T2 T3 T1 T2 T30.500.751.000 5 10 15frequencyms0.500.751.000 5 10 15frequencyms0.500.751.000 5 10 15defD2 D3D1D2 D3time16time8frequencymstime3.33T1 T3T1T1T1T2T3T1T2T3T2 T3T2T2T3T2T3T1Figure 5 Example of cycleconserving RM a Initially use staticallyscaled, worstcase RM schedule as target b Determineminimum frequency so as to complete the same work by D1 rounding up to the closest discrete setting requires frequency 1.0c After T1 completes early, recompute the required frequency as 0.75 d Once T2 completes, a very low frequency 0.5 sufficesto complete the remaining work by D1 e T1 is rereleased, and now, try to match the work that should be done by D2 f Executiontrace through time 16 ms.assume  is frequency set by static scaling algorithmselect frequencyset  max cycles until next deadlineuse lowest freq.         such that       upon task release set  leftset   max cycles until next deadlineset  allocate cycles  select frequencyupon task completion set  left 0set    0select frequencyduring task execution decrement  leftand  allocate cycleskfor   1 to  ,             tasks sorted by period if   left set     leftset  leftelseset   set 0Figure 6 Cycleconserving DVS for RM schedulersgiven that the task set prior to this change was schedulable, the EDFschedulability test will continue to hold, and   which has completed execution will not violate its lowered maximum computingbound for the remainder of time until its deadline. Therefore, thetask set continues to meet both conditions C1 and C2 imposed bythe realtime scheduler to guarantee timely execution, and as a result, deadline guarantees provided by EDF scheduling will continueto hold at least until   is released for its next invocation. At thispoint, we must restore its computation bound to to ensure thatit will not violate the temporarilylowered bound and compromisethe deadline guarantees. At this time, it may be necessary to increase the operating frequency. At first glance, this algorithm doesnot appear to significantly reduce frequencies, voltages, and energyexpenditure. However, since multiple tasks may be simultaneouslyin the reducedutilization state, the total savings can be significant.We could use the same schedulabilitytestbased approach to designing a cycleconserving DVS algorithm for RM scheduling, butas the RM schedulability test is significantly more complex   ,where  is the number of tasks to be scheduled, we will take a different approach here. We observe that even assuming tasks alwaysrequire their worstcase computation times, the staticallyscaledRM mechanism discussed earlier can maintain realtime deadlineguarantees. We assert that as long as equal or better progress for alltasks is made here than in the worst case under the staticallyscaledRM algorithm, deadlines can be met here as well, regardless ofthe actual operating frequencies. We will also try to avoid gettingahead of the worstcase execution pattern this way, any reductionin the execution cycles used by the tasks can be applied to reducingoperating frequency and voltage. Using the same example as before, Figure 5 illustrates how this can be accomplished. We initiallystart with worstcase schedule based on staticscaling a, which forthis example, uses the maximum CPU frequency. To keep thingssimple, we do not look beyond the next deadline in the system. Wethen try to spread out the work that should be accomplished beforethis deadline over the entire interval from the current time to thedeadline b. This provides a minimum operating frequency value,but since the frequency settings are discrete, we round up to theclosest available setting, frequency1.0. After executing , we50.500.751.000 5 10 15frequencyms0.500.751.000 5 10 15frequencyms0.500.751.000 5 10 15frequencymsT1time0abcD1D1 D2D3D3D2D1 D2 D3Reserved for T2Reserved for T2Reserved for T2Reserved for future T1Reserved for future T1Reserved for future T1time0T1 T2T2T3T3T3time2.670.500.751.000 5 10 15frequencyms0.500.751.000 5 10 15frequencyms0.500.751.000 5 10 15frequencymsT1T2T2 T3T1defD2 D3D1D2 D3Reserved for future T1Reseved for T2Reserved for T2time16time8T3T1T1T2 T3 T1 T2 T3time4.67Figure 7 Example of lookahead EDF a At time 0, plan to defer T3s execution until after D1 but by its deadline D3, and likewise,try to fit T2 between D1 and D2 b T1 and the portion of T2 that did not fit must execute before D1, requiring use of frequency 0.75c After T1 completes, repeat calculations to find the new frequency setting, 0.5 d Repeating the calculation after T2 completesindicates that we do not need to execute anything by D1, but EDF is workconserving, so T3 executes at the minimum frequencye This occurs again when T1s next invocation is released f Execution trace through time 16 ms.repeat the exercise of spreading out the remaining work over theremaining time until the next deadline c, which results in a loweroperating frequency since completed earlier than its worstcasespecified computing time. Repeating this at each scheduling pointresults in the final execution trace f.Although conceptually simple, the actual algorithm Figure 6 forthis is somewhat complex due to a number of counters that mustbe maintained. In this algorithm, we need to keep track of theworstcase remaining cycles of computation,  left, for each task . When task   is released,  leftis set to . We then determinethe progress that the static voltage scaling RM mechanism wouldmake in the worst case by the earliest deadline for any task in thesystem. We obtain  and  , the number of cycles to this nextdeadline, assuming operation at the staticallyscaled and the maximum frequencies, respectively. The  cycles are allocated to thetasks according to RM priority order, with each task   receiving anallocation   leftcorresponding to the number of cycles thatit would execute under the staticallyscaled RM scenario over thisinterval. As long as we execute at least   cycles for each task  or if   completes by the next task deadline, we are keeping pacewith the worstcase scenario, so we set execution speed using thesum of the  values. As tasks execute, their  left and  values aredecremented. When a task   completes,  leftand   are both setto 0, and the frequency and voltage are changed. Because we usethis pacing criteria to select the operating frequency, this algorithmguarantees that at any task deadline, all tasks that would have completed execution in the worstcase staticallyscaled RM schedulewould also have completed here, hence meeting all deadlines.These algorithms dynamically adjust frequency and voltage, reacting to the actual computational requirements of the realtime tasks.At most, they require 2 frequencyvoltage switches per task per invocation once each at release and completion, so any overheadsfor hardware voltage change can be accounted in the worstcasecomputation time allocations of the tasks. As we will see later, thealgorithms can achieve significant energy savings without affectingrealtime guarantees.2.5 LookAhead RTDVSThe final and most aggressive RTDVS algorithm that we introduce in this paper attempts to achieve even better energy savings using a lookahead technique to determine future computation needand defer task execution. The cycleconserving approaches discussed above assume the worst case initially and execute at a highfrequency until some tasks complete, and only then reduce operating frequency and voltage. In contrast, the lookahead scheme triesto defer as much work as possible, and sets the operating frequencyto meet the minimum work that must be done now to ensure allfuture deadlines are met. Of course, this may require that we willbe forced to run at high frequencies later in order to complete allof the deferred work in time. On the other hand, if tasks tend touse much less than their worstcase computing time allocations,the peak execution rates for deferred work may never be needed,and this heuristic will allow the system to continue operating at alow frequency and voltage while completing all tasks by their deadlines.Continuing with the example used earlier, we illustrate how a lookahead RTDVS EDF algorithm works in Figure 7. The goal is todefer work beyond the earliest deadline in the system  so thatwe can operate at a low frequency now. We allocate time in theschedule for the worstcase execution of each task, starting withthe task with the latest deadline,   . We spread out  s work between and its own deadline,  , subject to a constraint reserving capacity for future invocations of the other tasks a. We repeatthis step for , which cannot entirely fit between and afterallocating   and reserving capacity for future invocations of .Additional work for and all of are allotted before b. Wenote that more of could be deferred beyond if we moved allof   after , but for simplicity, this is not considered. We usethe work allocated before to determine the operating frequency.Once has completed, using less than its specified worstcase execution cycles, we repeat this and find a lower operating frequencyc. Continuing this method of trying to defer work beyond thenext deadline in the system ultimately results in the execution traceshown in f.6select frequencyuse lowest freq.             such that upon task release set  leftdeferupon task completion set  left 0deferduring task execution decrement  leftdeferset         set   0for   1 to  ,               Note reverse EDF order of tasks set  set   max0,  left   set  left  set     select frequency current timeFigure 8 LookAhead DVS for EDF schedulersThe actual algorithm for lookahead RTDVS with EDF schedulingis shown in Figure 8. As in the cycleconserving RTDVS algorithmfor RM, we keep track of the worstcase remaining computation leftfor the current invocation of task   . This is set to on taskrelease, decremented as the task executes, and set to 0 on completion. The major step in this algorithm is the deferral function. Here,we look at the interval until the next task deadline, try to push asmuch work as we can beyond the deadline, and compute the minimum number of cycles, , that we must execute during this intervalin order to meet all future deadlines. The operating frequency is setjust fast enough to execute  cycles over this interval. To calculate, we look at the tasks in reverse EDF order i.e., latest deadlinefirst. Assuming worstcase utilization by tasks with earlier deadlines effectively reserving time for their future invocations, wecalculate the minimum number of cycles,  , that the task must execute before the closest deadline, , in order for it to complete byits own deadline. A cumulative utilizationis adjusted to reflectthe actual utilization of the task for the time after . This calculation is repeated for all of the tasks, using assumed worstcaseutilization values for earlierdeadline tasks and the computed values for the laterdeadline ones.  is simply the sum of the  valuescalculated for all of the tasks, and therefore reflects the total number of cycles that must execute by in order for all tasks to meettheir deadlines. Although this algorithm very aggressively reducesprocessor frequency and voltage, it ensures that there are sufficientcycles available for each task to meet its deadline after reservingworstcase requirements for higherpriority earlier deadline tasks.2.6 Summary of RTDVS algorithmsAll of the RTDVS algorithms we presented thus far should be fairlyeasy to incorporate into a realtime operating system, and do notrequire significant processing costs. The dynamic schemes all reRTDVS method energy usednone plain EDF 1.0staticallyscaled RM 1.0staticallyscaled EDF 0.64cycleconserving EDF 0.52cycleconserving RM 0.71lookahead EDF 0.44Table 4 Normalized energy consumption for the exampletracesquire  computation assuming the scheduler provides an EDFsorted task list, and should not require significant processing overthe scheduler. The most significant overheads may come from thehardware voltage switching times. However, in all of our algorithms, no more than two switches can occur per task per invocationperiod, so these overheads can easily be accounted for, and addedto, the worstcase task computation times.To conclude our series of examples, Table 4 shows the normalizedenergy dissipated in the example task Table 2 set for the first 16ms, using the actual execution times from Table 3. We assumethat the 0.5, 0.75 and 1.0 frequency settings need 3, 4, and 5 volts,respectively, and that idle cycles consume no energy. More generalevaluation of our algorithms will be done in the next section.3. SIMULATIONSWe have developed a simulator to evaluate the potential energy savings from voltage scaling in a realtime scheduled system. Thefollowing subsection describes our simulator and the assumptionsmade in its design. Later, we show some simulation results andprovide insight into the most significant system parameters affecting RTDVS energy savings.3.1 Simulation MethodologyUsing C, we developed a simulator for the operation of hardwarecapable of voltage and frequency scaling with realtime scheduling.The simulator takes as input a task set, specified with the period andcomputation requirements of each task, as well as several systemparameters, and provides the energy consumption of the system foreach of the algorithms we have developed. EDF and RM schedulers without any DVS support are also simulated for comparison.3Parameters supplied to the simulator include the machine specification a list of the frequencies and corresponding voltages availableon the simulated platform and a specification for the actual fraction of the worstcase execution cycles that the tasks will requirefor each invocation. This latter parameter can be a constant e.g.,0.9 indicates that each task will use 90 of its specified worstcasecomputation cycles during each invocation, or can be a randomfunction e.g., uniformlydistributed random multiplier for each invocation.The simulation assumes that a constant amount of energy is required for each cycle of operation at a given voltage. This quantumis scaled by the square of the operating voltage, consistent with energy dissipation in CMOS circuits    . Only the energy consumed by the processor is computed, and variations due to differWithout DVS, energy consumption is the same for both EDF andRM, so EDF numbers alone would suffice. However, since sometask sets are schedulable under EDF, but not under RM, we simulateboth to verify that all task sets that are schedulable under RM arealso schedulable when using the RMbased RTDVS mechanisms.7ent types of instructions executed are not taken into account. Withthis simplification, the task execution modeling can be reduced tocounting cycles of execution, and execution traces are not needed.The softwarecontrolled halt feature, available on some processorsand used for reducing energy expenditure during idle, is simulatedby specifying an idle level parameter. This value gives the ratio between energy consumed during a cycle while halted and that duringa cycle of normal operation e.g., a value of 0.5 indicates a cyclespent idling dissipates one half the energy of a cycle of computation. For simplicity, only task execution and idle halt cyclesare considered. In particular, this does not consider preemptionand task switch overheads or the time required to switch operatingfrequency or voltages. There is no loss of generality from thesesimplifications. The preemption and task switch overheads are thesame with or without DVS, so they have no effect on relative powerdissipation. The voltage switching overheads incur a time penalty,which may affect the schedulability of some task sets, but incur almost no energy costs, as the processor does not operate during theswitching interval.The realtime task sets are specified using a pair of numbers foreach task, indicating its period and worstcase computation time.The task sets are generated randomly as follows. Each task has anequal probability of having a short 110ms, medium 10100ms,or long 1001000ms period. Within each range, task periods areuniformly distributed. This simulates the varied mix of short andlong period tasks commonly found in realtime systems. The computation requirements of the tasks are assigned randomly using asimilar 3 range uniform distribution. Finally, the task computationrequirements are scaled by a constant chosen such that the sum ofthe utilizations of the tasks in the task set reaches a desired value.This method of generating realtime task sets has been used previously in the development and evaluation of a realtime embeddedmicrokernel 31. Averaged across hundreds of distinct task setsgenerated for several different total worstcase utilization values,the simulations provide a relationship of energy consumption toworstcase utilization of a task set.3.2 Simulation ResultsWe have performed extensive simulations of the RTDVS algorithms to determine the most important and interesting system parameters that affect energy consumption. Unless specified otherwise, we assume a DVScapable platform that provides 3 relativeoperating frequencies 0.5, 0.75, and 1.0 and corresponding voltages 3, 4, and 5, respectively.In the following simulations, we compare our RTDVS algorithmsto each other and to a nonDVS system. We also include a theoretical lower bound for energy dissipation. This lower bound reflectsexecution throughput only, and does not consider any timing issuese.g., whether any task is active or not. It is computed by takingthe total number of task computation cycles in the simulation, anddetermining the absolute minimum energy with which these can beexecuted over the simulation time duration with the given platformfrequency and voltage specification. No real algorithms can do better than this theoretical lower bound, but it is interesting to see howclose our mechanisms approach this bound.Number of tasksIn our first set of simulations, we determine the effects of varying the number of tasks in the task sets. Figure 9 shows the energy consumption for task sets with 5, 10, and 15 tasks for all ofour RTDVS algorithms as well as unmodified EDF. All of thesesimulations assume that the processor provides a perfect softwarecontrolled halt function so idling the processor will consume noenergy, thus showing scheduling without any energy conservingfeatures in the most favorable light. In addition, we assume thattasks do consume their worstcase computation requirements during each invocation. With these extremes, there is no difference between the staticallyscaled and cycleconserving EDF algorithms.We notice immediately that the RTDVS algorithms show potential for large energy savings, particularly for task sets with midrange worstcase processor utilization values. The lookahead RTDVS mechanism, in particular, seems able to follow the theoreticallower bound very closely. Although the total utilization greatly affects energy consumption, the number of tasks has very little effect.Neither the relative nor the absolute positions of the curves for thedifferent algorithms shift significantly when the number of tasks isvaried. Since varying the number of tasks has little effect, for allfurther simulations, we will use a single value.Varying idle levelThe preceding simulations assumed that a perfect softwarecontrolledhalt feature is provided by the processor, so idle time consumes noenergy. To see how an imperfect halt feature affects power consumption, we performed several simulations varying the idle levelfactor, which is the ratio of energy consumed in a cycle while theprocessor is halted, to the energy consumed in a normal executioncycle. Figure 10 shows the results for idle level factors 0.01, 0.1,and 1.0. Since the absolute energy consumed will obviously increase as the idle state energy consumption increases, it is moreinsightful to look at the relative energy consumption by plottingthe values normalized with respect to the unmodified EDF energyconsumption.The most significant result is that even with a perfect halt featurei.e., idle level is 0, where the nonenergy conserving schedulersare shown in the best light, there is still a very large percentageimprovement with the RTDVS algorithms. Obviously, as the idlelevel increases to 1 same energy consumption as in normal operation, the percentage savings with voltage scaling improves. Therelative performance among the energyaware schedulers is not significantly affected by changing the idle power consumption level,although the dynamic algorithms benefit more than the staticallyscaled ones. This is evident as the cycleconserving EDF mechanism results diverge from the staticallyscaled EDF results. This iseasily explained by the fact that the dynamic algorithms switch tothe lowest frequency and voltage during idle, while the static onesdo not with perfect idle, this makes no difference, but as idle cycleenergy consumption approaches that of execution cycles, the dynamic algorithms perform relatively better. For the remainder ofthe simulations, we assume an idle level of 0.Varying machine specificationsAll of the previous simulations used only one set of available frequency and voltage scaling settings. We now investigate the effects of varying the simulated machine specifications. The following summarizes the hardware voltage and frequency settings, whereeach tuple consists of the relative frequency and the correspondingprocessor voltagemachine 00.5, 3, 0.75, 4, 1.0, 5 machine 10.5, 3, 0.75, 4, 0.83, 4.5, 1.0, 5 machine 20.36, 1.4, 0.55, 1.5, 0.64, 1.6,0.73, 1.7, 0.82, 1.8, 0.91, 1.9, 1.0, 2.0 805101520250 0.2 0.4 0.6 0.8 1EnergyUtilization5 tasksEDFStaticRMStaticEDFccEDFccRMlaEDFbound05101520250 0.2 0.4 0.6 0.8 1EnergyUtilization10 tasksEDFStaticRMStaticEDFccEDFccRMlaEDFbound05101520250 0.2 0.4 0.6 0.8 1EnergyUtilization15 tasksEDFStaticRMStaticEDFccEDFccRMlaEDFboundFigure 9 Energy consumption with 5, 10, and 15 tasks00.20.40.60.810 0.2 0.4 0.6 0.8 1Energy normalizedUtilization8 tasks, idle level 0.01EDFStaticRMStaticEDFccEDFccRMlaEDFbound00.20.40.60.810 0.2 0.4 0.6 0.8 1Energy normalizedUtilization8 tasks, idle level 0.1EDFStaticRMStaticEDFccEDFccRMlaEDFbound00.20.40.60.810 0.2 0.4 0.6 0.8 1Energy normalizedUtilization8 tasks, idle level 1EDFStaticRMStaticEDFccEDFccRMlaEDFboundFigure 10 Normalized energy consumption with idle level factors 0.01, 0.1, and 1.000.20.40.60.810 0.2 0.4 0.6 0.8 1Energy normalizedUtilization8 tasks, machine 0EDFStaticRMStaticEDFccEDFccRMlaEDFbound00.20.40.60.810 0.2 0.4 0.6 0.8 1Energy normalizedUtilization8 tasks, machine 1EDFStaticRMStaticEDFccEDFccRMlaEDFbound00.20.40.60.810 0.2 0.4 0.6 0.8 1Energy normalizedUtilization8 tasks, machine 2EDFStaticRMStaticEDFccEDFccRMlaEDFboundFigure 11 Normalized energy consumption with machine 0, 1, and 200.20.40.60.810 0.2 0.4 0.6 0.8 1Energy normalizedUtilization8 tasks, c0.9EDFStaticRMStaticEDFccEDFccRMlaEDFbound00.20.40.60.810 0.2 0.4 0.6 0.8 1Energy normalizedUtilization8 tasks, c0.7EDFStaticRMStaticEDFccEDFccRMlaEDFbound00.20.40.60.810 0.2 0.4 0.6 0.8 1Energy normalizedUtilization8 tasks, c0.5EDFStaticRMStaticEDFccEDFccRMlaEDFboundFigure 12 Normalized energy consumption with computation set to fixed fraction of worstcase allocation900.20.40.60.810 0.2 0.4 0.6 0.8 1Energy normalizedUtilization8 tasks, uniform cEDFStaticRMStaticEDFccEDFccRMlaEDFboundFigure 13 Normalized energy consumption with uniform distribution for computationFigure 11 shows the simulation results for machines 0, 1, and 2.Machine 0, used in all of the previous simulations, has frequencysettings that can be expected on a standard PC motherboard, although the corresponding voltage levels were arbitrarily selected.Machine 1 differs from this in that it has the additional frequencysetting, 0.83. With this small change, we expect only slight differences in the simulation results with these specifications. Themost significant change is seen with cycleconserving EDF andstaticallyscaled EDF, since the two are identical here. With theextra operating point in the region near the crossover point between ccEDF and ccRM, the ccEDF algorithm benefits, shiftingthe crossover point closer to full utilization.Machine 2 is very different from the other two, and reflects the settings that may be available on a platform incorporating an AMDK6 processor with AMDs PowerNow mechanism 1. Again, thevoltage levels are only speculated here. As it has many more settings to select from, the plotted curves tend to be smoother. Also,since the relative voltage range is smaller with this specification,the maximum savings is not as good as with the other two machinespecifications. More significant is the fact that the cycleconservingEDF outperforms the lookahead EDF algorithm. ccEDF and staticEDF benefit from the large number of settings, since this allowsthem to more closely match the task set and reduce energy expenditure. In fact, they very closely approximate the theoreticallower bound over the entire range of utilizations. On the otherhand, laEDF sets the frequency trying to defer processing which,in the worst case, would require running at full speed later. Withmore settings, the low frequency setting is closely matched, requiring highvoltage, highfrequency processing later, hurting performance. With fewer settings, the frequency selected would be somewhat higher, so less processing is deferred, lessening the likelihoodof needing higher voltage and frequency settings later, thus improving performance. In a sense, the error due to a limited number offrequency steps is detrimental in the ccEDF scheme, but beneficialwith laEDF. These results, therefore, indicate that the energy savings from the various RTDVS algorithms depend greatly on theavailable voltage and frequency settings of the platform.Varying computation timeIn this set of experiments, we vary the distribution of the actualcomputation required by the tasks during each invocation to seehow well the RTDVS mechanisms take advantage of task sets thatdo not consume their worstcase computation times. In the preceding simulations, we assumed that the tasks always require theirworstcase computation allocation. Figure 12 shows simulation results for tasks that require a constant 90, 70, and 50 of theirworstcase execution cycles for each invocation. We observe thatthe staticallyscaled mechanisms are not affected, since they scalevoltage and frequency based solely on the worstcase computationtimes specified for the tasks. The results for the cycleconservingRM algorithm do not show significant change, indicating that itdoes not do a very good job of adapting to tasks that use less thantheir specified worstcase computation times. On the other hand,both the cycleconserving and lookahead EDF schemes show greatreductions in relative energy consumption as the actual computation performed decreases.Figure 13 shows the simulation results using tasks with a uniformdistribution between 0 and their worstcase computation. Despitethe randomness introduced, the results appear identical to settingcomputation to a constant one half of the specified value for eachinvocation of a task. This makes sense, since the average executionwith the uniform distribution is 0.5 times the worstcase for eachtask. From this, it seems that the actual distribution of computationper invocation is not the critical factor for energy conservation performance. Instead, for the dynamic mechanisms, it is the averageutilization that determines relative energy consumption, while forthe static scaling methods, the worstcase utilization is the determining factor. The exception is the ccRM algorithm, which, albeitdynamic, has results that primarily reflect the worstcase utilizationof the task set.4. IMPLEMENTATIONThis section describes our implementation of a realtime scheduledsystem incorporating the proposed DVS algorithms. We will discuss the architecture of the system and present measurements of theactual energy savings with our RTDVS algorithms.4.1 Hardware PlatformAlthough we developed the RTDVS mechanisms primarily for embedded realtime devices, our prototype system is implemented onthe PC architecture. The platform is a HewlettPackard N3350notebook computer, which has an AMD K62 1 processor witha maximum operating frequency of 550 MHz. Some of the powerconsumption numbers measured on this laptop were shown earlierin Table 1. This processor features PowerNow, AMDs extensionsthat allow the processors clock frequency and voltage to be adjusted dynamically under software control. We have also lookedinto a similar offering from Intel called SpeedStep 10, but thiscontrols voltage and frequency through hardware external to theprocessor. Although it is possible to adjust the settings under software control, we were not able to determine the proper output sequences needed to control the external hardware. We do not haveexperience with the Transmeta Crusoe processor 29 or with various embedded processors such as Intel XScale 9 that are nowsupporting DVS.The K62 processor specification allows system software to select one of eight different frequencies from its builtin PLL clockgenerator 200 to 600 MHz in 50 MHz increments, skipping 250,limited by the maximum processor clock rate 550 MHz here. Theprocessor has 5 control pins that can be used to set the voltagethrough an external regulator. Although 32 settings are possible,there is only one that is explicitly specified the default 2.0V setting the rest are left up to the individual manufacturers. HP choseto incorporate only 2 voltage settings 1.4V and 2.0V. The volt10PowerNowModulePeriodic RTTask ModuleRT Schedulerw RTDVSScheduler HookUserKernelLevelLinux KernelRT Task SetDVSNonRTLevelFigure 14 Software architecture for RTDVS implementationage and frequency selectors are independently set, so we need afunction to map each frequency to the appropriate available voltage level. As there are no such specifications publicly available,we determined this experimentally. The processor was stable up to450 MHz at 1.4 V, and needed the 2.0 V setting for higher frequencies. Stability was checked using a set of CPUintensive benchmarks mpg123 in a loop and Linux kernel compile, and verifyingproper behavior. We note that this empirical study used a samplesize of one, so the actual frequency to voltage mappings may varyfor other machines, even of the same model.The processor has a mandatory stop interval associated with everychange of the voltage or frequency transition, during which the processor halts execution. This mandatory halt duration is meant to ensure that the voltage supply and clock have time to stabilize beforethe processor continues execution. As the characteristics of different hardware implementations of the external voltage regulatorscan vary greatly, this stop duration is programmable in multiples of41 s 4096 cycles of the 100 MHz system bus clock. Accordingto our experience, it takes negligible time for frequency changesto occur. Using the CPU timestamp register basically a cyclecounter, which continues to increment during the halt duration,we observed that around 8200 cycles occur during any transition to200 MHz, and around 22500 cycles for a transition to 550 MHz,both with the minimum interval of 41 s. This indicates that thefrequency of the CPU clock changes quickly and that most of thehalt time is spent at the target frequency. We do not know the actualtime required for voltage transition to occur, but in our experimentsusing a halt duration value of 10 approximately 0.4 ms resulted inno observable instability. The switching overheads in our system,therefore, are 0.4 ms when voltage changes, and 41 s when onlyfrequency changes. As mentioned earlier, we can account for thisswitching overhead in the computation requirements of the tasks,since at most only two transitions are attributable to each task ineach invocation.4.2 Software ArchitectureWe implemented our algorithms as extension modules to the Linux2.2.16 kernel. Although it is not a realtime operating system,Linux is easily extended through modules and provides a robust development environment familiar to us. The highlevel view of oursoftware architecture is shown in Figure 14. The approach takenfor this implementation was to maximize flexibility and ease of use,rather than optimize for performance. As such, this implementationserves as a good proofofconcept, rather than the ideal model. Byimplementing our kernellevel code as Linux kernel modules, weavoided any code changes to the Linux kernel, and these modulesshould be able to plug into unmodified 2.2.x kernels.Digital OscilloscopeCurrent ProbeDC Adapterbattery removedLaptopFigure 15 Power measurement on laptop implementationThe central module in our implementation provides support for periodic realtime tasks in Linux. This is done by attaching callbackfunctions to hooks inside the Linux scheduler and timer tick handlers. This mechanism allows our modules to provide tight timingcontrol as well as override the default Unix scheduling policy forour realtime tasks. Note that this module does not actually definethe realtime scheduling policy or the DVS algorithm. Instead, weuse separate modules that provide the realtime scheduling policyand the RTDVS algorithms. One such RT schedulerDVS modulecan be loaded on the system at a time. By separating the underlying periodic RT support from the scheduling and DVS policies, thisarchitecture allows dynamic switching of these latter policies without shutting down the system or the running RT tasks. Of course,during the switchover time between these policy modules, a realtime scheduler is not defined, and the timeliness constraints of anyrunning RT tasks may not be met. The last kernel module in ourimplementation handles the access to the PowerNow mechanismto adjust clock speed and voltage. This provides a clean, highlevelinterface for setting the appropriate bits of the processors specialfeature register for any desired frequency and voltage level.The modules provide an interface to userlevel programs throughthe Linux procfs filesystem. Tasks can use ordinary file readand write mechanisms to interact with our modules. In particular, atask can write its required period and maximum computing boundto our module, and it will be made into a periodic realtime task thatwill be released periodically, scheduled according to the currentlyloaded policy module, and will receive static priority over nonRTtasks on the system. The task also uses writes to indicate the completion of each invocation, at which time it will be blocked until thenext release time. As long as the task keeps the file handle open, itwill be registered as a realtime task with our kernel extensions. Although this highlevel, filesystem interface is not as efficient as direct system calls, it is convenient in this prototype implementation,since we can simply use cat to read from our modules and obtain status information in a human readable form. The PowerNowmodule also provides a procfs interface. This will allow for auserlevel, nonRT DVS demon, implementing algorithms found inother DVS literature, or to manually deal with operating frequencyand voltage through simple Unix shell commands.4.3 Measurements and ObservationsWe performed several experiments with our RTDVS implementation and measured the actual energy consumption of the system.Figure 15 shows the setup used to measure energy consumption.The laptop battery is removed and the system is run using the external DC power adapter. Using a special current probe, a digitaloscilloscope is used to measure the power consumed by the laptop as the product of the current and voltage supplied. This basicmethodology is very similar to the one used in the PowerScope 6,110510152025300 0.2 0.4 0.6 0.8 1Power WattsUtilization5 tasks, real platform, c0.9EDFStaticRMccEDFlaEDFFigure 16 Power consumption on actual platformbut instead of a slow digital multimeter, we use an oscilloscope thatcan show the transient behavior and also provide the true averagepower consumption over long intervals. Using the long durationacquisition capability of the digital oscilloscope, our power measurements are averaged over 15 to 30 second intervals.Figure 16 shows the actual power consumption measured for ourRTDVS algorithms while varying worstcase CPU utilization fora set of 5 tasks which always consume 90 of their worstcasecomputation allocated for each invocation. The measurements reflect the total system power, not just the CPU energy dissipation.As a result, there is a constant, irreducible power drain from thesystem board consumption the display backlighting was turnedoff for these measurements with this on, there would have beenan additional constant 6 W to each measurement. Even with thisoverhead, our RTDVS mechanisms show a significant 20 to 40reduction in power consumption, while still providing the deadlineguarantees of a realtime system.Figure 17 shows a simulation with identical parameters includingthe 2 voltagelevel machine specification to these measurements.The simulation only reflects the processors energy consumption,so does not include any energy overheads from the rest of the system. It is clear that, except for the addition of constant overheads inthe actual measurements, the results are nearly identical. This validates our simulation results, showing that the results we have seenearlier really hold in real systems, despite the simplifying assumptions in the simulator. The simulations are accurate and may beuseful for predicting the performance of RTDVS implementations.We also note two interesting phenomena that should be considered when implementing a system with RTDVS. First, we noticedthat the very first invocation of a task may overrun its specifiedcomputing time bound. This occurs only on the first invocation,and is caused by cold processor and operating system state. Inparticular, when the task begins execution, many cache misses,translationlookaside buffer TLB misses, and page faults occurin the system the last may be due to the copyonwrite page allocation mechanism used by Linux. These processing overheadscount against the tasks execution time, and may cause it to exceedits bound. On subsequent invocations, the state is warm, and thisproblem disappears. This is due to the large difference betweenworstcase and averagecase performance on generalpurpose platforms, and explains why realtime systems tend to use specializedplatforms to decrease or eliminate such variations in performance.0123450 0.2 0.4 0.6 0.8 1Power arbitrary unitUtilization5 tasks, simulated platform, c0.9EDFStaticRMccEDFlaEDFFigure 17 Power consumption on simulated platformThe second important observation is that the dynamic addition ofa task to the task set may cause transient missed deadlines unlessone is very careful. Particularly with the more aggressive RTDVSschemes, the system may be so closely matched to the current taskset load that there may not be sufficient processor cycles remainingbefore the task deadlines to also handle the new task. One solutionto this problem is to immediately insert the task into task set, soDVS decisions are based on the new system characteristics, butdefer the initial release of the new task until the current invocationsof all existing tasks have completed. This ensures that the effectsof past DVS decisions, based on the old task set, will have expiredby the time the new task is released.5. RELATED WORKRecently, there have been a large number of publications describing DVS techniques. Most of them present algorithms that are verylooselycoupled with the underlying OS scheduling and task management systems, relying on average processor utilization to perform voltage and frequency scaling 7, 23, 30. They are basicallymatching the operating frequency to some weighted average of thecurrent processor load or conversely, idle time using a simplefeedback mechanism. Although these mechanisms result in closeadaptation to the workload and large energy savings, they are unsuitable for realtime systems. More recent DVS research 4, 19have shown methods of maintaining good interactive performancefor generalpurpose applications with voltage and frequency scaling. This is done through prediction of episodic interaction 4 orby applying soft deadlines and estimating task work distributions19. These methods show good results for maintaining short response times in humaninteractive and multimedia applications, butare not intended for the stricter timeliness constraints of realtimesystems.Some DVS work has produced algorithms closely tied to the scheduler 22, 24, 26, with some claiming realtime capability. These,however, take a very simplistic view of realtime tasks  only taking into account a single execution and deadline for a task. Assuch, they can only handle sporadic tasks that execute just once.They cannot handle the most important, canonical model of realtime systems, which uses periodic realtime tasks. Furthermore, itis not clear how new tasks entering the system can be handled in atimely manner, especially since all of the tasks are singleshot, andsince the system may not have sufficient computing resources afterhaving adapted so closely to the current task set.12To the best of our knowledge, there are only four recent papers12, 28, 21, 8 that deal with DVS in a true realtime systemsperspective. The first paper 12 uses a combined offline and online scheduling technique. A worstcase execution time WCETschedule, which provides the ideal operating frequency and voltageschedule assuming that tasks require their worstcase computationtime, is calculated offline. The online scheduler further reduces frequency and voltage when tasks use less than their requested computing quota, but can still provide deadline guarantees by ensuringall invocations complete no later than in the WCET schedule. Thisis much more complicated than the algorithms we have presented,yet cannot deal effectively with dynamic task sets.The second, a workinprogress paper 28, presents two mechanisms for RTDVS. One mechanism attempts to calculate the bestfeasible schedule this is a computationallyexpensive process andcan only be done offline. The other is a heuristic based aroundEDF that tests schedulability at each scheduling point. The detailsof this online mechanism were not presented in 28. Moreover,the assumption of a common period for all of the tasks is somewhat unrealistic  even if a polynomial transformation is used toproduce common periods, they may need to schedule over an arbitrarily long planning cycle in their algorithm.The third paper 21 looks at DVS from the application side. Itpresents a mechanism by which the application monitors the progressof its own execution, compares it to the profiled worstcase execution, and adjusts the processor frequency and voltage accordingly.The compiler inserts this monitoring mechanism at various pointsin the application. It is not clear how to determine the locationsof these points in a taskapplication, nor how this mechanism willscale to systems with multiple concurrent tasksapplications.The most recent 8 RTDVS paper combines offline analysis withonline slacktime stealing 15 and dynamic, probabilitybased voltage scaling. Offline analysis provides minimum operating rates foreach task based on worstcase execution time. This is used in conjunction with a probability distribution for actual computation timeto change frequency and voltage without violating deadlines. Excess time is used to run remaining tasks at lower CPU frequencies.These papers, and indeed almost all papers dealing with DVS, onlypresent simulations of algorithms. In contrast, we present fairlysimple, online mechanisms for RTDVS that work within the common models, assumptions, and contexts of realtime systems. Weimplemented and demonstrated RTDVS in a real, working system.A recent paper 25 also describes a working DVS implementation,using a modified StrongARM embedded system board, which isused to evaluate a DVS scheduler in 26.In addition to DVS, there has been much research regarding otherenergyconserving issues, including work on application adaptation5 and communicationoriented energy conservation 11. Theseissues are orthogonal to DVS and complementary to our RTDVSmechanisms.6. CONCLUSIONS AND FUTUREDIRECTIONSIn this paper, we have presented several novel algorithms for realtime dynamic voltage scaling that, when coupled with the underlying OS task management mechanisms and realtime scheduler,can achieve significant energy savings, while simultaneously preserving timeliness guarantees made by realtime scheduling. Wefirst presented extensive simulation results, showing the most significant parameters affecting energy conservation through RTDVSmechanisms, and the extent to which CPU power dissipation canbe reduced. In particular, we have shown that the number of tasksand the energy efficiency of idle cycles do not greatly affect therelative savings of the RTDVS mechanisms, while the voltage andfrequency settings available on the underlying hardware and thetask set CPU utilizations profoundly affect the performance of ouralgorithms. Furthermore, our lookahead and cycleconserving RTDVS mechanisms can achieve close to the theoretical lower boundon energy. We have also implemented our algorithms and, usingactual measurements, have validated that significant energy savingscan be realized through RTDVS in real systems. Additionally, oursimulations do predict accurately the energy consumption characteristics of real systems. Our measurements indicate that 20 to40 energy savings can be achieved, even including irreduciblesystem energy overheads and using task sets with high values forboth worst and average case utilizations.In the future, we would like to expand this work beyond the deterministicabsolute realtime paradigm presented here. In particular,we will investigate DVS with probabilistic or statistical deadlineguarantees. We will also explore integration with other energyconserving mechanisms, including application energy adaptationand energyadaptive communication both realtime and besteffort.Additionally, although developed for portable devices, RTDVS isapplicable widely in general realtime systems. The energy savings works well for extending battery life in portable applications,but can also reduce the heat generated by the realtime embeddedcontrollers in various factory or home automation products, or evenreduce cooling requirements and costs in largescale, multiprocessor supercomputers.7. REFERENCES1 ADVANCED MICRO DEVICES CORPORATION. MobileAMDK62 Processor Data Sheet, June 2000. Publication 23446.2 BURD, T. D., AND BRODERSEN, R. W. Energy efficientCMOS microprocessor design. In Proceedings of the 28thAnnual Hawaii International Conference on SystemSciences. Volume 1 Architecture Los Alamitos, CA, USA,Jan. 1995, T. N. Mudge and B. D. Shriver, Eds., IEEEComputer Society Press, pp. 288297.3 ELLIS, C. S. The case for higherlevel power management.In Proceedings of the 7th IEEE Workshop on Hot Topics inOperating Systems HotOSVIII Rio Rico, AZ, Mar. 1999,pp. 162167.4 FLAUTNER, K., REINHARDT, S., AND MUDGE, T.Automatic performancesetting for dynamic voltage scaling.In Proceedings of the 7th Conference on Mobile Computingand Networking MOBICOM01 Rome, Italy, July 2001.5 FLINN, J., AND SATYANARAYANAN, M. Energyawareadaptation for mobile applications. In Proceedings of the17th ACM Symposium on Operating System PrinciplesKiawah Island, SC, Dec. 1999, ACM Press, pp. 4863.6 FLINN, J., AND SATYANARAYANAN, M. PowerScope atool for profiling the energy usage of mobile applications. InProceedings of the Second IEEE Workshop on Mobile13Computing Systems and Applications New Orleans, LA,Feb. 1999, pp. 210.7 GOVIL, K., CHAN, E., AND WASSERMANN, H. Comparingalgorithms for dynamic speedsetting of a lowpower CPU.In Proceedings of the 1st Conference on Mobile Computingand Networking MOBICOM95 Mar. 1995.8 GRUIAN, F. Hard realtime scheduling for low energy usingstochastic data and DVS processors. In Proceedings of theInternational Symposium on LowPower Electronics andDesign ISLPED01 Huntington Beach, CA, Aug. 2001.9 INTEL CORPORATION.httpdeveloper.intel.comdesignintelxscal.10 INTEL CORPORATION. Mobile Intel Pentium III Processorin BGA2 and MicroPGA2 Packages, 2000. Order Number245483003.11 KRAVETS, R., AND KRISHNAN, P. Power managementtechniques for mobile communication. In Proceedings of the4th Annual ACMIEEE International Conference on MobileComputing and Networking MOBICOM98 New York,Oct. 1998, ACM Press, pp. 157168.12 KRISHNA, C. M., AND LEE, Y.H. Voltageclockscalingtechniques for low power in hard realtime systems. InProceedings of the IEEE RealTime Technology andApplications Symposium Washington, D.C., May 2000,pp. 156165.13 KRISHNA, C. M., AND SHIN, K. G. RealTime Systems.McGrawHill, 1997.14 LEHOCZKY, J., SHA, L., AND DING, Y. The rate monotonicscheduling algorithm exact characterization and averagecase behavior. In Proceedings of the IEEE RealTimeSystems Symposium 1989, pp. 166171.15 LEHOCZKY, J., AND THUEL, S. Algorithms for schedulinghard aperiodic tasks in fixedpriority systems using slackstealing. In Proceedings of the IEEE RealTime SystemsSymposium 1994.16 LEHOCZKY, J. P., SHA, L., AND STROSNIDER, J. K.Enhanced aperiodic responsiveness in hard realtimeenvironments. In Proc. of the 8th IEEE RealTime SystemsSymposium Los Alamitos, CA, Dec. 1987, pp. 261270.17 LEUNG, J. Y.T., AND WHITEHEAD, J. On the complexityof fixedpriority scheduling of periodic, realtime tasks.Performance Evaluation 2, 4 Dec. 1982, 237250.18 LIU, C. L., AND LAYLAND, J. W. Scheduling algorithmsfor multiprogramming in a hard realtime environment.J. ACM 20, 1 Jan. 1973, 4661.19 LORCH, J., AND SMITH, A. J. Improving dynamic voltagescaling algorithms with PACE. In Proceedings of the ACMSIGMETRICS 2001 Conference Cambridge, MA, June2001, pp. 5061.20 LORCH, J. R., AND SMITH, A. J. Apple Macintoshs energyconsumption. IEEE Micro 18, 6 Nov. 1998, 5463.21 MOSSE, D., AYDIN, H., CHILDERS, B., AND MELHEM, R.Compilerassisted dynamic poweraware scheduling forrealtime applications. In Workshop on Compilers andOperating Systems for LowPower COLP00 Philadelphia,PA, Oct. 2000.22 PERING, T., AND BRODERSEN, R. Energy efficient voltagescheduling for realtime operating systems. In Proceedingsof the 4th IEEE RealTime Technology and ApplicationsSymposium RTAS98, Work in Progress Session Denver, CO,June 1998.23 PERING, T., AND BRODERSEN, R. The simulation andevaluation of dynamic voltage scaling algorithms. InProceedings of the International Symposium on LowPowerElectronics and Design ISLPED98 Monterey, CA, Aug.1998, pp. 7681.24 PERING, T., BURD, T., AND BRODERSEN, R. Voltagescheduling in the lpARM microprocessor system. InProceedings of the International Symposium on LowPowerElectronics and Design ISLPED00 Rapallo, Italy, July2000.25 POUWELSE, J., LANGENDOEN, K., AND SIPS, H. Dynamicvoltage scaling on a lowpower microprocessor. InProceedings of the 7th Conference on Mobile Computing andNetworking MOBICOM01 Rome, Italy, July 2001.26 POUWELSE, J., LANGENDOEN, K., AND SIPS, H. Energypriority scheduling for variable voltage processors. InProceedings of the International Symposium on LowPowerElectronics and Design ISLPED01 Huntington Beach, CA,Aug. 2001.27 STANKOVIC, J., ET AL. Deadline Scheduling for RealTimeSystems. Kluwer Academic Publishers, 1998.28 SWAMINATHAN, V., AND CHAKRABARTY, K. Realtimetask scheduling for energyaware embedded systems. InProceedings of the IEEE RealTime Systems Symp.WorkinProgress Session Orlando, FL, Nov. 2000.29 TRANSMETA CORPORATION. httpwww.transmeta.com.30 WEISER, M., WELCH, B., DEMERS, A., AND SHENKER,S. Scheduling for reduced CPU energy. In Proceedings ofthe First Symposium on Operating Systems Design andImplementation OSDI Monterey, CA, Nov. 1994,pp. 1323.31 ZUBERI, K. M., PILLAI, P., AND SHIN, K. G.EMERALDS A smallmemory realtime microkernel. InProceedings of the 17th ACM Symposium on OperatingSystem Principles Kiawah Island, SC, Dec. 1999, ACMPress, pp. 277291.14
