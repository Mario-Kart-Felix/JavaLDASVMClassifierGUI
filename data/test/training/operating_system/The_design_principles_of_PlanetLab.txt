The Design Principles of PlanetLabLarry Peterson Timothy RoscoePrinceton University Intel Research  BerkeleyABSTRACTPlanetLab is a geographically distributed platform fordeploying, evaluating, and accessing planetaryscale network services. PlanetLab is a shared community effortby a large international group of researchers, each ofwhom gets access to one or more isolated slices of PlanetLabs global resources. Because we deployed PlanetLab and started supporting users before we fully understood what its architecture would be, being able toevolve the system became a requirement. This paperexamines the set of design principles that guided thisevolution. Some of these principles were explicit at theproject outset, and others have become crystallized asthe platform has developed.1. INTRODUCTIONPlanetLab is a globally distributed computing platform shared, built, and maintained by a community ofresearchers at 300 sites in more than 30 countries. Inexchange for hosting a small number of nodes servers,participants obtain access to a share of resources acrossthe entire platform for deploying and evaluating planetaryscale network services 4. In addition, the platform itself, including the essential services required to operateit, is a communal design work in progress and an interesting research area in its own right.In this paper we concentrate on the design principles of PlanetLab. By design principles, we meanthe rules we have come to recognize and formulate thatguide our decisions about how to put the platform together. In contrast, we use the term architecture todenote the composition of the platform itself, in otherwords the end result of these decisions. We do not describe PlanetLabs architecture in this paper other thanto illustrate the consequences of our design principles.The architecture of the platform at time of writing isdescribed in several PlanetLab Design Notes PDNsand academic publications 1.Of course, the boundary between design principlesand highlevel architectural features is somewhat arbitrary. Nonetheless, we have found it useful to try totease the two apart. It is comparatively rare for the documentation of large systems to include an attempt toreflect on the thought processes of its architects, DavidClarks description of the Internet design philosophy 2being one notable example.The evolving design of PlanetLab has been an attempt at principled pragmatism. The principles wepresent here did not, in general, predate the implementation of PlanetLab, though some were explicit from theoutset. Instead, they have coevolved with the architecture itself, and thus we expect them, like the architecture itself, to continue to change over time.2. GOALSUnderlying the design principles are the highlevelgoals of PlanetLab. From the beginning 4, we haveidentified three to provide a platform for researchers to experimentwith planetaryscale network services to provide a platform for novel network services tobe deployed and serve a real user community and to catalyze the evolution of the Internet into aserviceoriented architecture.It should be clear that these goals are highly synergistic and reinforcing early experiments with ideaslead to the deployment of new network services, andthe availability of a rich set of network services effectively changes the nature of the Internet. There are,however, subtle tensions between the three. For example, a platform that supports only shortterm experiments would likely be designed differently than onethat must also support continuouslyrunning services.We hope to support both workloads, but with a biastowards the latter. Similarly, a platform that supportsa collection of services developed by the research community need not necessarily consider the full range ofscalability, security, and autonomy issues that must beaddressed by a platform which aspires to become theconduit through which users interact with the Internet.The balancepoint between these two goals is difficult todefine we must continue to push the scalability, security, robustness, and decentralization that an Internetscale architecture requires, but at the same time, ensurethat the evolution of the architecture is driven by therequirements of the running system rather some idealized vision.3. TERMINOLOGYThe design principles guiding the evolution of PlanetLab as a platform have been formulated at the sametime as the architecture itself has crystallized. Consequently, while nominally independent of the current architecture of PlanetLab, it is convenient to describe andillustrate the design principles in the context of PlanetLab as it currently exists. For that reason, we describebriefly here how PlanetLabs architecture looks todayreaders familiar with PlanetLab internals may observethat the current architecture does not always adhere tothe principles we describe here.PlanetLab users who wish to deploy applications acquire a slice, which is a collection of virtual machinesVMs spread around the world. The VMs are implemented on physical machines by some OS mechanism orvirtual machine monitor VMM, and controlled by another entity, the node manager, which is responsible forcreating and destroying slices. We sometimes call usethe term sliver to refer to the instantiation of a slice ona give node. There are also special infrastructure sliceswhich perform essential functions on each node suchas providing a local site administrators interface to thenode.Collectively, the node managers and infrastructureservices, together with the currently centralized account management and node installation functions, formthe control plane of PlanetLab.Of course, PlanetLab is at least two things the entireensemble of contributed services and running applications on the platform, and the narrower set of maintained facilities that support the entire ensemble. Byarchitecture in this paper we mean the structure ofthe core subset, maintained by the PlanetLab supportteam. However, we feel the design principles we outlinehere are applicable to other services above this layer inthe platform.4. DISTRIBUTED VIRTUALIZATIONPlanetLab services and applications run in a slice ofthe platform a set of nodes on which the service receives a fraction of each nodes resources, in the form ofa virtual machine VM. Virtualization and virtual machines are, of course, wellestablished concepts. Whatis new in PlanetLab is distributed virtualization theacquisition of a distributed set of VMs that are treatedas a single, compound entity by the system.Slices are underspecified. While PlanetLab must prescribe lowlevel facilities forcreating, manipulating, and destroying slices,much of the process is left unspecified, andcan be performed by a variety of other services.By giving slices as much flexibility as possible in defining a suitable environment for a service, as well as theprocess by which that environment is instantiated, weminimize the extent to which future users are constrainedin what they do with the platform. We also hopefullyencourage users to implement functions useful to otherslices. For example, PlanetLab does not provide tunnelsthat connect a slices constituent VMs into an overlay,but allows a slicespecific overlay to be created, eitherby the slice itself, or by another service which createsand populates the slice in the first place.Similarly, the actual contents of a sliverwithin thebox of the VMare of little concern to the PlanetLab. For example, it should not matter whether a sliveris running in a Java virtual machine JVM or is written in assembly language, and if it is a JVM, it is up tothe slice to decide whether it uses version 1.5.0 or 1.4.2.The platform provides the means by which slices caninstall whatever software they need, but little more.PlanetLab aims to isolate services and applicationsfrom each other, thereby maintaining the illusion thateach service runs on a distributed set of private machines. The slice, or strictly speaking the sliver, is thebasic abstraction for this.The unit of isolation is the sliver. Whatever base functionality the platform provides,it must be possible for the platform to isolate slices from each other as they invoke thisfunctionality. The platform must strive tominimize the effect one slice can have on another.This principle has three corollaries. First, the platform must deliver isolation of slivers, by allocating andscheduling node resources, partitioning or contextualizing system namespaces, and enforcing stability and security, between slivers sharing a node. Early methodsfor achieving this in PlanetLab are discussed in 1.Second, care must be exercised when multiplexingany VMMprovided resources between slices, not onlylowlevel resource abstractions like CPU time. It ismost straightforward to achieve isolation by keepingthe underlying VMM as thin as possible, and providing most of the system functionality within a slicefor example, using Xen  as a virtual machine monitor and running a complete operating system kernel ineach slice. Where an implementation uses a more highlevel VMM, such as the LinuxVServer kernel 1, it isimportant to avoid as far as possible crosstalk betweenapplications competing for kernel resources such as theprotocol stack, routing tables, filing system datastructures, open file descriptors, and so on..Third, it should not concern the platform how resources allocated to a sliver are multiplexed among thevarious activities of the sliver, for example by intraslicethread scheduling policies. It is, however, desirable thatthe platform provide in the execution environment itpresents to each virtual machine, the mechanisms toallow a slice to perform this internal multiplexing effectively.5. UNBUNDLED MANAGEMENTPlanetaryscale services are a relatively recent andongoing subject of research in particular, this includesthe services required to manage a global platform suchas PlanetLab. Moreover, it is an explicit goal of PlanetLab to allow independent organizations in this case,research groups to deploy alternative services in parallel, allowing users to pick which ones to use. This applies to applicationlevel services targeted at endusers,as well as infrastructure services used to manage andcontrol PlanetLab itself e.g., slice creation, resourceand topology discovery, performance monitoring, andsoftware distribution. The key to unbundled management is to allow parallel infrastructure services to runin their own slices of PlanetLab and evolve over time.This is a new twist on the traditional problem ofhow to evolve a system, where one generally wants totry a new version of some service in parallel with anexisting version, and roll back and forth between thetwo versions. In our case, multiple competing servicesare simultaneously evolving. The desire to support unbundled management leads to two requirements for thePlanetLab architecture.Support only local abstractions directlyin the OS. In other words, the only abstractions that the lowlevel VMM should dealwith are local to the node. Implement allglobal networkwide abstractions by infrastructure services.Perhaps the most notable example of this principleis slices themselves they are a global abstraction, andneither the VMM on a PlanetLab node nor the nodemanager on the node deal with anything other thansingle virtual machines. The slice abstraction itself asa distributed collection of VMs is implemented by slicecreation services.We want to maximize the opportunity for services tocompete with each other on a level playing field. Inother words, rather than have a single privileged application controlling a particular aspect of the OS, thePlanetLab OS potentially supports many such management services. One implication of this interface beingsharable is that it must be welldefined, explicitly exposing the state of the underlying OS. In contrast, theinterface between an OS and a privileged control program running in user space is often ad hoc since thecontrol program is, in effect, an extension of the OSthat happens to run in user space.Make all interfaces exported by the OSor control plane sharable. Any functionality which has to be implemented by a uniquepiece of code should be accessible by multipleinfrastructure services, none of which shouldrequire unique privilege.Again, this principle applies to slice creation as muchas to other infrastructure services. While the lowlevelmechanism for creating VMs on a node resides in thenode manager, there can be and are multiple slicecreation services that can instantiate slivers on a node.The bottom line is that OS design often faces a tension between implementing functionality in the kerneland running it in user space, the objective often being tominimize kernel code. Like many VMM architectures,the PlanetLab OS faces an additional, but analogous,tension between what can run in a slice or VM, andfunctionality such as slice user authentication that requires extra privilege or access but is not part of the kernel. In addition, there is a third aspect to the problemthat is peculiar to PlanetLab functionality that can beimplemented by parallel, competing subsystems, versusmechanisms which by their very nature can only be implemented once such as bootstrapping slice creation.The PlanetLab OS strives to minimize the latter, butthere remains a small core of nonkernel functionalitythat has to be unique on a node.6. CHAIN OF RESPONSIBILITYThe way slices interact with the rest of the world hashas turned out to be important factor in PlanetLabsdesign, much more so than we thought at the inception of the project. It is also a novel requirement, aconsequence of PlanetLabs giving applications so manypointsofpresence on the network.Each interaction between PlanetLab andthe rest of the network must be attributable to a PlanetLab user. We mustalways consider PlanetLabs interaction withthe rest of the network unlike many systems projects, PlanetLab is and has alwaysbeen inextricably embedded in the real Internet, and its behavior has consequently often been felt in the Internet. Moreover, eachsuch interaction with the real Internet can,and should be attributed to the responsibleuser.Effectively limiting and auditing legitimate users hasbeen as significant an issue as securing the PlanetLab toprevent malicious users from hijacking machines. Experience shows that the Internet, and the design of intrusion detection systems in particular, is highly sensitiveto the kinds of traffic that experimental planetaryscaleservices tend to generate, and this has had to be reflected in the design of PlanetLabs filtering, rate limiting, and packet auditing functionality.However, our experience is that that simply limitingslices is not sufficient since even a single unexpected orunwanted packet can trigger an incident report. Thus,an important responsibility of PlanetLab is to preservethe chain of responsibility among all the relevant principals. That is, it must be possible to map externallyvisible activity e.g., a transmitted packet to the usersresponsible for that packet. Note that PlanetLab doesnot attempt to eliminate the possibility that bad thingsmight happen, it just requires that the system be ableto identify the responsible party when something doesgo wrong.Preserving the chain of responsibility is not just amatter of being able to respond to security complaintsit is also essential to preserving the implicit trust relationships. Consider that on the one hand, nearly 300autonomous organizations have contributed nodes toPlanetLab. They each require autonomous control overthe nodes they own. On the other hand, 375 researchgroups want to deploy their services across PlanetLab.The node owners need assurances that these serviceswill not be disruptive. Clearly, establishing 300375pairwise trust relationships is an unmanageable taska researcher would have to obtain permission to create VMs on nodes owned by 300 organizations, while ahosting site would need to approve requests for use ofits nodes from 375 independent research groups 5.A wellunderstood way to reduce such a N N problem into a N  N problem is to use a trusted intermediary. The PlanetLab Consortium PLC is one suchtrusted intermediary Node owners trust PLC to manage the behavior of slivers that run on their nodes whilepreserving their autonomy, and researchers slice userstrust it to provide access to a set of nodes that are capable of hosting their services. In general, we observeKeep explicit the trust relationships between node owners, authorities, and sliceusers. PlanetLab is a decentralized systemthat spans multiple autonomous organizations.To have longterm viability, it must identifythe critical trust relationships among the principals, and provide mechanisms that give theseprincipals the control and assurances they require.For example, as described elsewhere 3, PlanetLab provides an auditing mechanism that ensures that the chainof responsibility is preserved. It also provides mechanisms that allows principals the ability to dictate howtheir resources are used.7. EVOLUTION VS. CLEAN SLATESPlanetLab has never aimed to start from a cleanslate. Moreover, architectural features of PlanetLabhave always been designed with a view to their eventualreplacement.This is partly because the research community wasready to use PlanetLab the moment the first nodes weredeployed the lengthy process of designing a completelynew architecture from scratch was never an option. Asa result, the first version of PlanetLab had to be builtquickly from preexisting ideas and technologies. Wehad a strong intuition that much of what we originallydesigned would have to be reworked as we gained experience with the system, since for for the first versionthere was very little usage data or requirements dataavailable.The approach of evolving preexisting technology asopposed to pursuing a clean slate design is also motivated by our experience with previous testbeds, inwhich application writers exhibited two strong biases1 they are seldom willing to port their applications toa new API, and 2 they expect a fullfeatured systemrather than a minimalist API tuned for someone elsesOS research agenda. Again, since PlanetLabs value isdefined by the applications that run on it, a clean slatedesign was simply not an option.While the concept of builtin obsolescence of buildingblocks has been explicit in PlanetLab from the verybeginning, it is only recently that the consequences ofthese decisions have been codified as design principlesAvoid clean slate designs. When designing a large piece of infrastructure thatis closely related to existing technology inthe way PlanetLab is deeply embedded inthe current Internet and commodity operating systems, a clean slate, topdown architecture cannot be developed in the time available, once the need for the infrastructure isrecognized. In contrast, a bottomup, evolutionary design will immediately gain momentum.However, any new architecture, whether bottomupor topdown, is always in danger of atrophy, particularlyif it is not designed with the evolutionary process inmind.Design the architecture with an openended view of future evolution. Designdecisions must always be taken with a viewto the future evolution of the architecture,in possibly unforeseen ways. Architecturaloptions should be kept as open as possible.This second principle is subtle, in that it goes beyondmere extensibility of interfaces. We expect few currentfeatures of PlanetLabs architecture to be recognizablein a few years time. Above all, PlanetLab has beendesigned to efficiently evolve.Two other principles follow from these in the specificcontext of PlanetLabs evolution. They are not orthogonal, but rather overlap and mutually reinforce eachother. The first is a direct consequence of eschewingthe clean slate approach in favor of producing a usable but highly evolvable system as soon as possible.Leverage existing software and hardware infrastructure. Wherever possible,avoid modifying existing packages and thereafter having to track changes if they can beused asis.Adapting rather than simply using an offtheshelfsoftware package takes time, and raises the questionof who now supports the modified package. Typically,the PlanetLab development team has to track changesto the mainstream package, and keep their own modified version in sync. This can result in considerableextra work, on an ongoing basis, and is to be avoided ifpossible.For example, PlanetLab makes use of standard, readily available software such as OpenSSH, Linux, XMLRPC libraries and bindings, and a variety of Unix utilities. When PlanetLab does modify existing software,such as patching the Linux kernel, this leads to anincreased maintenance burden as we must then trackchanges in the kernel more closely and port our modifications. However, we mitigate this burden somewhat byusing patches which are themselves maintained by othergroups wherever possible most notably the Vserverspatch, and by using loadable kernel modules VNET.When adding new functionality to a PlanetLab nodeover and above that provided by the node operatingsystem, the question inevitably arises as to where thefunctionality should be implemented as a service, inthe control plane, or as a kernel extension.Implement any new system function atthe highest level possible. Running aservice in a slice with limited privileged capabilities is preferred to a slice with widespreadprivileges, which in turn is preferred to augmenting the node manager, all of which arepreferable to adding the function to the VMMor operating system. This leads to a PlanetLab version of the principle of least privilegePrivileged slices should be granted the minimal privileges necessary to support the desired behavior. They should not be grantedblanket superuser privileges.8. OS AND CONTROL PLANEMaintaining a split between the operating system andthe control plane enables us to separate the executionenvironment of an application, which we keep as nonPlanetLabspecific as possible, from the interface to PlanetLab itself.Keep the Control Plane and the Operating System orthogonal. Dont pollutethe OS interface by adding new functionalityto it, when this can be added to the outofband control plane interface instead.The control plane essentially, the node manager andassociated services appears to a VM to be separatefrom the OS proper. Adding functionality to the controlplane interface means that new features or capabilitiesare added to a PlanetLab node in an OSindependentway. A good example of this is the use of PlanetLabsensors to obtain information about node status.This also means that the operating system interfacechanges little, facilitating crossdevelopment and testing between PlanetLab nodes, clusters, and users development machines. We can extend this principle furtherto a version of the traditional idea of least surpriseUse existing interface semantics as faras possible Any OS operation, initiated ina VM, should have an effect that is as closeas possible to the effect it would have on thecorresponding dedicate machine, subject tothe external policies limiting the capabilitiesof the slice. No operations should be added tothe PlanetLab control plane or OS interfacesif the desired functionality can already be accessed through the existing OS interfaces.For example, access to raw sockets on PlanetLab wasoriginally restricted to administrative programs. Normal slices used a new, PlanetLabspecific address family to open safe raw sockets, which could only send orreceive packets that might have been sent or receivedon an existing socket owned by the slice. A better approach has now been implemented safe raw sockets areaccessed in exactly the same away as real raw socketsare. Whether the client program receives all packetsdepends on the privileges granted to the slice.A final principle, closely related to those above, hasbeen identified as PlanetLab begins to consider botha transition to a more heterogeneous deployment inOS and processor terms, and the federation issues thatarise when a slice can span multiple PlanetLablike platforms.Dont tackle porting issues. Use the orthogonality of control plane and OS to ensurethat the overhead of porting an application isthe same when running on PlanetLab or ona native operating system.This captures PlanetLabs position on portability ofapplications and support for heterogeneity moving forward, even though at present PlanetLab provides a single OSinstruction set environment. Specifically, thecost of porting an application from one operating system or processor architecture to another should be thesame on PlanetLab as it would be in a conventionalenvironment.Put another way, we deliberately hide nothing of theoperating system or processor architecture under a layerof abstractions. Porting between environments is orthogonal to porting to or from PlanetLab, since featuresspecific to PlanetLab are added in an OSneutral wayto the control plane interface. Our goal is to decouplethose aspects of the PlanetLab API that are unique toPlanetLab from the underlying execution environment.9. ACKNOWLEDGEMENTSThe development of PlanetLab, and of these principles, has been a highly communal effort. We would liketo acknowledge the contribution of the large number ofpeople too many to mention here who have shapedour way of thinking about PlanetLab and continue todo so as the platform evolves.10. REFERENCES1 A. Bavier, M. Bowman, D. Culler, B. Chun,S. Karlin, S. Muir, L. Peterson, T. Roscoe,T. Spalink, and M. Wawrzoniak. Operating SystemSupport for PlanetaryScale Network Services. InProc. 1st NSDI, San Francisco, California, Mar.2004.2 D. D. Clark. The Design Philosophy of theDARPA Internet Protocols. In Proceedings of theSIGCOMM 88 Symposium, pages 106114,Stanford, 1988.3 M. Huang, A. Bavier, and L. Peterson. PlanetFlowMaintaining Accountability for Network Services.In Operating Systems Review, Jan. 2006.4 L. Peterson, T. Anderson, D. Culler, andT. Roscoe. A Blueprint for Introducing DisruptiveTechnology into the Internet. In Proc. of ACMHotNetsI, Princeton, New Jersey, Oct. 2002.5 L. Peterson, A. Bavier, M. Fiuczynski, S. Muir,and T. Roscoe. Towards a ComprehensivePlanetLab Architecture. Technical ReportPDN05030, PlanetLab Consortium, June 2005.
