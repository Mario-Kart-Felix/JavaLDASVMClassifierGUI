Revisiting the Design of Systems for HighConfidenceEmbedded and CyberPhysical Computing EnvironmentsRichard West and Gabriel Parmerrichwest,gabep1cs.bu.edu Tel 161735320651 IntroductionAs the complexity of emerging realtime and embedded software systems increases, new challenges beyond those focusing solely on timeliness guarantees are becoming increasingly significant. It is expected that embedded devices such as mobile phones and personal digital assistantswill support tens of millions of lines of code in the foreseeable future. Web services, videoondemand and multimedia databases are already appearing on handheld devices and so it makessense that software complexity will only increase over time. Avionics, automotive and medicalapplication domains clearly dictate the need for software dependability in addition to traditionalgoals of timeliness constraints. Should unforeseen faults during software execution occur, it isparamount that potentially adverse consequences are limited in scope. The inevitable complexityof future cyberphysical systems CPS software will make it impossible to statically verify complete correctness. Formal methods, model checking and exhaustive testing of all possible controlpaths will either not be possible, or will not reveal all reachable system states e.g., due to sideeffects of cache activity or asynchronous events as a consequence of interrupts during runtime.A system should therefore be designed from the ground up to be resilient to unexpected controlflow patterns and resource interactions. Central to our argument is that existing commercial offtheshelf COTS systems have limitations in their designs that require a complete rethink in howthey should be organized to support complex CPS software. A new approach to system design isnecessary, to address challenges both in terms of software dependability and predictability.For a system to be truly dependable it must guarantee that any unexpected behaviors, or software faults, do not manifest in a way that violates contracts between service providers and users.Here, a service user may be an application issuing a request to a system via an API that allowsboth functional and temporal constraints to be specified. Given a service request of this nature, itis the duty of the provider here, the system to ensure the application receives the desired service,even when unexpected situations arise. Such unexpected behaviors could be in terms of memory,CPU, andor IO protection violations. Examples include stray pointer dereferences, infinite loops,starvation, deadlocks, or uncontrolled access to IO devices. Asynchronous control flow e.g., dueto interrupts, signal handling mechanisms, and multiple threads of execution, as well as resourcesharing can lead to violations in performance guarantees and, hence, predictability. Other architectural factors, such as cache sharing, hyperthreading, and TLB design can affect the executionrates and, therefore, interference patterns between unrelated threads. Although static analysis techniques have been developed e.g., in the design of typesafe languages to address many forms ofprotection issues, this position paper suggests that additional runtime system support is necessaryif software is to be made truly dependable.We focus on two major OS challenges that need to be addressed in order to provide highconfidence computing platforms that are resilient to inevitable unpredictable behavior. Specifically, we propose that i time be treated as a firstclass entity, not only in the specification of taskexecution properties, but in the APIs of the system itself, and ii the memory protection structure of the system be adaptable so as to maximize fault isolation which adds execution overhead,while meeting application and system timing constraints.2 Time as a FirstClass System PropertyThe treatment of time as a firstclass resource has been severely neglected even in operatingsystems that claim to be RTOSes. For the most part, these tend to provide static priority preemptive thread scheduling policies via which ratemonotonic scheduling 4 and analysis can beperformed, priority inheritance 6 for synchronization objects and critical sections, limited or novirtual memorypaging, and offline profilingworstcase execution time WCET analysis tools.Even relatively simple timebased scheduling policies such as earliestdeadlinefirst EDF havenot wholly replaced static priority policies due to the added cost of managing dynamic priorities,and the potentially negative impact on task deadlines in unexpected overload situations. Eventhe POSIX.4 standard for realtime computing specifies SCHED FIFO and SCHED RR for firstinfirstout nonpreemptive and roundrobin preemptive scheduling of tasks with fixed priorities. Nowhere is there any specification of timing requirements in the API to the underlyingsystem scheduler. Furthermore, the added costs of system services e.g., as a result of scheduling and contextswitching overheads, blocking delays due to synchronization on shared resources,and the impacts of interrupts from IO devices are not properly accounted in the timely execution of realtime tasks. It is no wonder, then, that systems designed for realtime computing stillhave significant areas of unpredictability. As further evidence, it is common for RTOSes to offernonrealtime network services via protocols such as TCPIP, for compatibility with preexistingapplications rather than to ensure timing guarantees.To better manage time so that predictable service execution is ensured, we propose to designa system interface that explicitly captures temporal constraints. That is, any requests from applications andor higherlevel services for a designated lowerlevel service will specify their timingrequirements. Throughout the system, this timing information can be used to detect and possiblycorrect for deviant execution e.g. due to unintended priority inversion. The inherent unpredictability of asynchronous events such as interrupts should be addressed by defining a unifiedscheduling hierarchy on every form of system event. Specifically, scheduling decision pointsneed to be placed at all locations in the system where control flow changes may impact the timingguarantees of tasks and their corresponding services. For example, one could devise a system thatschedules interrupts in accordance with the priorities and timing requirements of tasks affected bythose interrupts, rather than having interrupts always preempt potentially more important tasks.New device driver interfaces are needed to determine as early as possible which task is waiting ona given IO response. When a device interrupt arises, it is essential that the urgencyimportance ofhandling that interrupt is matched accordingly with the waiting process. Similarly, interrupts thatare not associated with specific processes e.g., interprocessor interrupts for TLB management,and clock interrupts to update system time need to be correctly accounted in the timing requirements of tasks. None of these issues are adequately addressed by existing systems supportingexisting APIs e.g., POSIX. Only when time is treated as a firstclass entity can true performanceisolation guarantees be made.3 Mutable Protection DomainsTo limit the scope of adverse sideeffects caused by errant or untrusted software, it makes senseto leverage, where appropriate, hardware and softwarebased memory fault isolation i.e., protection mechanisms 5, 3, 2, 1, thus allowing more predictable and controlled fault recovery. However, fault isolation overheads e.g., due to pagetable management, or runtime software safetychecks impact the granularity at which they can be imposed. They in turn impact the predictability of software execution, because factors such as TLBcache misses, page replacement policies,garbage collection, and memorybounds checks impose variable costs.Fault isolation provisions of modern systems e.g., Linux are typically limited to coarsegrainedentities, such as user versus kernellevel protection domains and pagebased process addressspaces. kernels 3 provide a minimal set of trusted services upon which higherlevel servicescan be implemented at userlevel. Both applications and userlevel services typically map to separate processes which communicate via the kernel if they need to interact. Consequently, kernelsprovide finergrained fault isolation than monolithic systems at the cost of increased communication overheads. Virtual machines 1 allow multiple legacy OSs to be isolated from each other,while being able to coexist on the same physical machine. Such a structuring provides verycoarsegrained isolation boundaries, yet can impose significant communication overheads betweenVMs, and between VMs and the trusted virtual machine monitor. Regardless of the organizationof the operating system, softwarebased fault isolation techniques can be employed to interceptreferences to invalid memory locations 5. Similarly, typesafe languages can be used to detectpotential software faults at compile and runtime. Common to all techniques for fault isolationis the notion of a fault domain, such that one domain is isolated to some degree from another distinct domain, and an appropriately chosen method of communication is necessary for interdomaincommunication. Significantly, all existing systems impose a static system structure, that is largelyinflexible to changes in the granularity at which fault isolation can be applied. In turn, the methodof interdomain communication is static e.g., a software trap for system calls, or an IPC messagetechnique for interprocess communication. The efficiency and predictability of the system, then,is limited by the amount of overhead due to communication between isolation domains.For the purposes of ensuring behavioral correctness of a complex software system, it is desirable to provide fault isolation techniques at the smallest granularity possible, while still ensuringpredictable software execution. For example, while it may be desirable to assign the functionalcomponents of various system services to separate protection domains, the communication costsmay be prohibitive in a realtime setting. That is, the costs of marshaling and unmarshaling message exchanges between component services, the scheduling and dispatching of separate addressspaces and the impacts on cache hierarchies amongst other overheads may be unacceptable insituations where deadlines must be met. Conversely, multiple component services mapped to asingle protection domain experience minimal communication overheads but lose the benefits ofisolation from one another.Given the above, we propose the design of a system with mutable protection domains MPDs,that is flexible in its placement of fault isolation boundaries around various application and system components. Where possible, we attempt to maximize fault isolation, by mapping finegrainedsoftware components to separate hardware protection domains, at the expense of increased communication overheads. In situations where such finegrained isolation violates the acceptable endtoend communication costs through a series of component services that are required to meet specificdeadlines, we strategically increase the isolation granularity. The system, then, must decide wherefault isolation boundaries are placed, using a combination of isolation benefit values applied tothe boundaries between software components, and the communication costs between components.The objective essentially involves the runtime adaptation of a system configuration to maximizefault isolation benefit while guaranteeing task timeliness constraints. Such benefit would ordinarily be gauged in terms of the otherwise adverse consequences that may arise if the correspondinglevel of isolation did not exist.4 SummaryGiven the increasing complexity of software systems, it will be almost impossible to staticallyverify their correct behavior. To ensure software dependability and predictability, existing COTSsystems are deficient in several key areas that necessitate a rethink in their design. We propose asystem design that considers two key factors for predictability and dependability. First, time shouldbe treated as a firstclass entity, requiring a revised API specification and a series of scheduling decision points to be placed at all locations where control flow changes may occur. Second, a flexiblesystem structure that adapts protection domain boundaries and communication costs should be considered, so as to maximize fault isolation where possible while still ensuring predictabilitytimingguarantees.5. Brief BiographiesRichard West received an MEng 1991 from the University of NewcastleuponTyne, England,as well as both MS 1998 and PhD 2000 degrees in computer science from the Georgia Institute of Technology. He is currently an associate professor in the Computer Science Department atBoston University, where his research interests include operating systems, realtime systems, distributed computing and QoS management. Gabriel Parmer is a PhD student at Boston University,working on topics related to operating systems especially their structure, service composition andextensibility, realtime systems and resource management. He currently holds a BA degree 2003from Boston University.References1 B. Dragovic, K. Fraser, S. Hand, T. Harris, A. Ho, I. Pratt, A. Warfield, P. Barham, and R. Neugebauer. Xen and the art of virtualization. In Proceedings of the ACM Symposium on Operating SystemsPrinciples, October 2003.2 M. Fhndrich, M. Aiken, C. Hawblitzel, O. Hodson, G. C. Hunt, J. R. Larus, , and S. Levi. Language support for fast and reliable messagebased communication in Singularity OS. In Proceedings of EuroSys,pages 177190, April 2006.3 J. Liedtke. On microkernel construction. In Proceedings of the 15th ACM Symposium on OperatingSystem Principles. ACM, December 1995.4 C. Liu and J. Layland. Scheduling algorithms for multiprogramming in a hard realtime environment.JACM, 1973.5 T. A. R. Wahbe, S. Lucco and S. Graham. Softwarebased fault isolation. In Proceedings of the 14thSOSP, Asheville, NC, USA, December 1993.6 L. Sha, R. Rajkumar, and J. P. Lehoczky. Priority inheritance protocols An approach to realtimesynchronization. IEEE Trans. Comput., 39911751185, 1990.
