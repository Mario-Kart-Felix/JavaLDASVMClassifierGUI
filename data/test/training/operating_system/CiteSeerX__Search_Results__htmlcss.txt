CiteSeerX — Search Results — html/css Documents Authors Tables Log in Sign up MetaCart Donate Documents: Advanced Search Include Citations Tools Sorted by: Relevance Citation Count Year (Descending) Year (Ascending) Recency Try your query at: Results 1 - 10 of 604,321 Next 10 → Maximum likelihood from incomplete data via the EM algorithm by A. P. Dempster, N. M. Laird, D. B. Rubin - JOURNAL OF THE ROYAL STATISTICAL SOCIETY, SERIES B , 1977 "... A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situat ..." Abstract - Cited by 11827 (17 self) - Add to MetaCart A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis. Partial Functions by Czes Law Byli&apos;nski "... this article we prove some auxiliary theorems and schemes related to the articles: [1] and [2]. MML Identifier: PARTFUN1. WWW: http://mizar.org/JFM/Vol1/partfun1.html The articles [4], [6], [3], [5], [7], [8], and [1] provide the notation and terminology for this paper. We adopt the following rules ..." Abstract - Cited by 494 (10 self) - Add to MetaCart this article we prove some auxiliary theorems and schemes related to the articles: [1] and [ 2 ]. MML Identifier: PARTFUN1. WWW: http://mizar.org/JFM/Vol1/partfun1. html The articles [4], [6], [3], [5], [7], [8], and [1] provide the notation and terminology for this paper. We adopt the following The fundamental properties of natural numbers by Grzegorz Bancerek - Journal of Formalized Mathematics , 1989 "... Summary. Some fundamental properties of addition, multiplication, order relations, exact division, the remainder, divisibility, the least common multiple, the greatest common divisor are presented. A proof of Euclid algorithm is also given. MML Identifier:NAT_1. WWW:http://mizar.org/JFM/Vol1/nat_1.h ..." Abstract - Cited by 683 (77 self) - Add to MetaCart . html The articles [4], [6], [1], [ 2 ], [5], and [3] provide the notation and terminology for this paper. A natural number is an element of N. For simplicity, we use the following convention: x is a real number, k, l, m, n are natural numbers, h, i, j are natural numbers, and X is a subset of R Web usage mining: Discovery and applications of usage patterns from web data by Jaideep Srivastava, Robert Cooley - SIGKDD Explorations , 2000 "... ..." Abstract - Cited by 506 (15 self) - Add to MetaCart Abstract not found Tarski Grothendieck Set Theory by Andrzej Trybulec , 1989 "... ..." Abstract - Cited by 1308 (127 self) - Add to MetaCart Abstract not found Resource Description Framework (RDF) Model and Syntax Specification by Ora Lassila, Ralph R. Swick, World Wide, Web Consortium , 1998 "... This document is a revision of the public working draft dated 1998-08-19 incorporating suggestions received in review comments and further deliberations of the W3C RDF Model and Syntax Working Group. With the publication of this draft, the RDF Model and Syntax Specification enters "last call.&q ..." Abstract - Cited by 922 (6 self) - Add to MetaCart This document is a revision of the public working draft dated 1998-08-19 incorporating suggestions received in review comments and further deliberations of the W3C RDF Model and Syntax Working Group. With the publication of this draft, the RDF Model and Syntax Specification enters "last call." The last call period will end on October 23, 1998. Comments on this specification may be sent to www-rdf-comments@w3.org. The archive of public comments is available at http://www.w3.org/Archives/Public/www-rdf-comments. Significant changes from the previous draft are highlighted in Appendix E. While we do not anticipate substantial changes, we still caution that further changes are possible. Therefore while we encourage active implementation to test this specification we also recommend that only software that can be easily field-upgraded be implemented to this specification at this time. This is a W3C Working Draft for review by W3C members and other interested parties. Publication as a working draft does not imply endorsement by the W3C membership. The RDF Model and Syntax Working Group will not allow early implementation to constrain their ability to make changes to this specification prior to final release. This is a draft document and may be updated, replaced or obsoleted by other documents at any time. It is inappropriate to cite W3C Working Drafts as other than "work in progress". This work is part of the W3C Metadata Activity. Topic-Sensitive PageRank by Taher Haveliwala , 2002 "... In the original PageRank algorithm for improving the ranking of search-query results, a single PageRank vector is computed, using the link structure of the Web, to capture the relative "importance" of Web pages, independent of any particular search query. To yield more accurate search resu ..." Abstract - Cited by 536 (10 self) - Add to MetaCart In the original PageRank algorithm for improving the ranking of search-query results, a single PageRank vector is computed, using the link structure of the Web, to capture the relative "importance" of Web pages, independent of any particular search query. To yield more accurate search results, we propose computing a set of PageRank vectors, biased using a set of representative topics, to capture more accurately the notion of importance with respect to a particular topic. By using these (precomputed) biased PageRank vectors to generate query-specific importance scores for pages at query time, we show that we can generate more accurate rankings than with a single, generic PageRank vector. For ordinary keyword search queries, we compute the topic-sensitive PageRank scores for pages satisfying the query using the topic of the query keywords. For searches done in context (e.g., when the search query is performed by highlighting words in a Web page), we compute the topic-sensitive PageRank scores using the topic of the context in which the query appeared. Monitors: An Operating System Structuring Concept by C. A. R Hoare - Communications of the ACM , 1974 "... This is a digitized copy derived from an ACM copyrighted work. It is not guaranteed to be an accurate copy of the author's original work. This paper develops Brinch-Hansen's concept of a monitor as a method of structuring an operating system. It introduces a form of synchronization, descri ..." Abstract - Cited by 562 (0 self) - Add to MetaCart This is a digitized copy derived from an ACM copyrighted work. It is not guaranteed to be an accurate copy of the author's original work. This paper develops Brinch-Hansen's concept of a monitor as a method of structuring an operating system. It introduces a form of synchronization, describes a possible rnctltotl of implementation in terms of semaphorcs and gives a suitable proof rule. Illustrative examples include a single rcsourcc scheduler, a bounded buffer, an alarm clock, a buffer pool, a disk head optimizer, and a version of the problem of readers and writers. Key Words and Phrases: monitors, operating systems,schcduling, mutual exclusion, synchronization, system implementation langua yes, structured multiprogramming CR Categories: Ontologies: Silver Bullet for Knowledge Management and Electronic Commerce by Dieter Fensel , 2007 "... Currently computers are changing from single isolated devices to entry points into a world wide network of information exchange and business transactions called the World Wide Web (WWW). Therefore support in the exchange of data, information, and knowledge exchange is becoming the key issue in cur ..." Abstract - Cited by 643 (46 self) - Add to MetaCart Currently computers are changing from single isolated devices to entry points into a world wide network of information exchange and business transactions called the World Wide Web (WWW). Therefore support in the exchange of data, information, and knowledge exchange is becoming the key issue in current computer technology. Ontologies provide a shared and common understanding of a domain that can be communicated between people and application systems. Therefore, they may play a major role in supporting information exchange processes in various areas. This book discusses the role ontologies will play in knowledge management and in electronic commerce. In addition, I show how arising web standards such as RDF and XML can be used as Optimizing Search Engines using Clickthrough Data by Thorsten Joachims , 2002 "... This paper presents an approach to automatically optimizing the retrieval quality of search engines using clickthrough data. Intuitively, a good information retrieval system should present relevant documents high in the ranking, with less relevant documents following below. While previous approaches ..." Abstract - Cited by 1253 (23 self) - Add to MetaCart This paper presents an approach to automatically optimizing the retrieval quality of search engines using clickthrough data. Intuitively, a good information retrieval system should present relevant documents high in the ranking, with less relevant documents following below. While previous approaches to learning retrieval functions from examples exist, they typically require training data generated from relevance judgments by experts. This makes them difficult and expensive to apply. The goal of this paper is to develop a method that utilizes clickthrough data for training, namely the query-log of the search engine in connection with the log of links the users clicked on in the presented ranking. Such clickthrough data is available in abundance and can be recorded at very low cost. Taking a Support Vector Machine (SVM) approach, this paper presents a method for learning retrieval functions. From a theoretical perspective, this method is shown to be well-founded in a risk minimization framework. Furthermore, it is shown to be feasible even for large sets of queries and features. The theoretical results are verified in a controlled experiment. It shows that the method can effectively adapt the retrieval function of a meta-search engine to a particular group of users, outperforming Google in terms of retrieval quality after only a couple of hundred training examples. Next 10 → Results 1 - 10 of 604,321 Powered by: About CiteSeerX Submit and Index Documents Privacy Policy Help Data Source Contact Us Developed at and hosted by The College of Information Sciences and Technology © 2007-2016 The Pennsylvania State University
