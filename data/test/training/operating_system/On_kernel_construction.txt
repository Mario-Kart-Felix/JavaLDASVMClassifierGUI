On Kernel ConstructionJochen LiedtkeGMD  German National Research Center for Information Technology jochenliedtkegmddeAbstractth ACM Symposium on Operating System Principles SOSPDecember  Copper Mountain Resort ColoradoFrom a softwaretechnology point of view the kernel concept is superior to large integrated kernelsOn the other hand it is widely believed that a kernel based systems are inherently inecient and bthey are not suciently exible Contradictory to thisbelief we show and support by documentary evidencethat ineciency and inexibility of current kernels isnot inherited from the basic idea but mostly from overloading the kernel andor from improper implementationBased on functional reasons we describe some concepts which must be implemented by a kernel andillustrate their exibility Then we analyze the performance critical points We show what performanceis achievable that the eciency is sucient with respect to macrokernels and why some published contradictory measurements are not evident Furthermore wedescribe some implementation techniques and illustratewhy kernels are inherently not portable althoughthey improve portability of the whole system Rationalekernel based systems have been built long before theterm itself was introduced eg by Brinch Hansen and Wulf et al  Traditionally the word kernelis used to denote the part of the operating system that ismandatory and common to all other software The basicGMD SETRS  Sankt Augustin GermanyCopyright c  by the Association for Computing MachineryInc Permission to make digital or hard copies of part or all of thiswork for personal or classroom use is granted without fee providedthat copies are not made or distributed for prot or commercial advantage and that new copies bear this notice and the full citationon the rst page Copyrights for components of this WORK ownedby others than ACM must be honored Abstracting with credit ispermitted To copy otherwise to republish to post on servers orto redistribute to lists requires prior specic permission andor afee Request Permissions from Publications Dept ACM Inc Fax   or permissionsacmorgidea of the kernel approach is to minimize this partie to implement outside the kernel whatever possibleThe software technological advantages of this approach are obviousa A clear kernel interface enforces a more modularsystem structureb Servers can use the mechanisms provided by thekernel like any other user program Server malfunction is as isolated as any other user programsmalfunctionc The system is more exible and tailorable Dierent strategies and APIs implemented by dierentservers can coexist in the systemAlthough much eort has been invested in kernelconstruction the approach is not yet generally accepted This is due to the fact that most existing kernels do not perform suciently well Lack of eciency also heavily restricts exibility since importantmechanisms and principles cannot be used in practicedue to poor performance In some cases the kernelinterface has been weakened and special servers havebeen reintegrated into the kernel to regain eciencyIt is widely believed that the mentioned ineciencyand thus inexibility is inherent to the kernel approach Folklore holds that increased userkernel modeand addressspace switches are responsible At a rstglance published performance measurements seem tosupport this viewIn fact the cited performance studies measured theperformance of a particular kernel based system without analyzing the reasons which limit eciency We canonly guess whether it is caused by the kernel approachby the concepts implemented by this particular kernelor by the implementation of the kernel Since it isknown that conventional IPC one of the traditional kernel bottlenecks can be implemented an order of magnitude faster than believed before the question is stillAlthough many macrokernels tend to be less modular thereare exceptions from this rule eg Chorus Rozier et al  andPeace SchroderPreikschat Short usertouser crossaddress space IPC in L Liedtkeopen It might be possible that we are still not applyingthe appropriate construction techniquesFor the above reasons we feel that a conceptualanalysis is needed which derives kernel concepts frompure functionality requirements section  and that discusses achievable performance section  and exibilitysection  Further sections discuss portability section  and the chances of some new developments section  Some Kernel ConceptsIn this section we reason about the minimal conceptsor primitives that a kernel should implement Thedetermining criterion used is functionality not performance More precisely a concept is tolerated inside thekernel only if moving it outside the kernel ie permitting competing implementations would prevent theimplementation of the systems required functionalityWe assume that the target system has to supportinteractive andor not completely trustworthy applications ie it has to deal with protection We furtherassume that the hardware implements pagebased virtual memoryOne inevitable requirement for such a system is thata programmer must be able to implement an arbitrarysubsystem S in such a way that it cannot be disturbed orcorrupted by other subsystems S This is the principleof independence S can give guarantees independent ofS The second requirement is that other subsystemsmust be able to rely on these guarantees This is theprinciple of integrity there must be a way for S toaddress S and to establish a communication channelwhich can neither be corrupted nor eavesdropped bySProvided hardware and kernel are trustworthy further security services like those described by Gasseret al  can be implemented by servers Their integrity can be ensured by system administration or byuserlevel boot servers For illustration a key servershould deliver publicsecret RSA key pairs on demandIt should guarantee that each pair has the desired RSAproperty and that each pair is delivered only once andonly to the demander The key server can only berealized if there are mechanisms which a protect itscode and data b ensure that nobody else reads ormodies the key and c enable the demander to checkwhether the key comes from the key server Finding thekey server can be done by means of a name server andchecked by public key based authentication is  times faster than in Mach both running on a On the R the specialized Exotlrpc Engler et al  is times faster than Machs general RPCProving minimality necessarity and completeness would benice but is impossible since there is no agreedupon metric andall is Turingequivalent Address SpacesAt the hardware level an address space is a mappingwhich associates each virtual page to a physical pageframe or marks it nonaccessible For the sake ofsimplicity we omit access attributes like readonly andreadwrite The mapping is implemented by TLB hardware and page tablesThe kernel the mandatory layer common to allsubsystems has to hide the hardware concept of addressspaces since otherwise implementing protection wouldbe impossible The kernel concept of address spacesmust be tamed but must permit the implementation ofarbitrary protection and nonprotection schemes ontop of the kernel It should be simple and similar tothe hardware conceptThe basic idea is to support recursive constructionof address spaces outside the kernel By magic thereis one address space  which essentially represents thephysical memory and is controlled by the rst subsystem S  At system start time all other address spacesare empty For constructing and maintaining furtheraddress spaces on top of   the kernel provides threeoperationsGrant The owner of an address space can grant anyof its pages to another space provided the recipientagrees The granted page is removed from the grantersaddress space and included into the grantees addressspace The important restriction is that instead of physical page frames the granter can only grant pages whichare already accessible to itselfMap The owner of an address space canmap any of itspages into another address space provided the recipientagrees Afterwards the page can be accessed in bothaddress spaces In contrast to granting the page is notremoved from the mappers address space Comparableto the granting case the mapper can only map pageswhich itself already can accessFlush The owner of an address space can ush any ofits pages The ushed page remains accessible in theushers address space but is removed from all otheraddress spaces which had received the page directly orindirectly from the usher Although explicit consentof the aected addressspace owners is not required theoperation is safe since it is restricted to own pages Theusers of these pages already agreed to accept a potentialushing when they received the pages by mapping orgrantingAppendix A contains a more precise denition ofaddress spaces and the above three operationsReasoningThe described addressspace concept leaves memorymanagement and paging outside the kernel only thegrant map and ush operations are retained inside thekernel Mapping and ushing are required to implementmemory managers and pagers on top of the kernelThe grant operation is required only in very specialsituations consider a pager F which combines two underlying le systems implemented as pagers f and foperating on top of the standard pager into one unied le system see gure  In this example f mapsuser A       user XFf fstd pagermapHHHHHYgrantHHHHHYmapAAAAAAAAAAdiskFigure  A Granting Exampleone of its pages to F which grants the received pageto user A By granting the page disappears from F sothat it is then available only in f and user A the resulting mappings are denoted by the thin line the pageis mapped in user A f and the standard pager Flushing the page by the standard pager would aect f anduser A ushing by f only user A F is not aected byeither ush and cannot ush itself since it used thepage only transiently If F had used mapping insteadof granting it would have needed to replicate most ofthe bookkeeping which is already done in f and fFurthermore granting avoids a potential addressspaceoverow of F In general granting is used when page mappingsshould be passed through a controlling subsystem without burdening the controllers address space by all pagesmapped through itThe model can easily be extended to access rightson pages Mapping and granting copy the source pagesaccess right or a subset of them ie can restrict theaccess but not widen it Special ushing operations mayremove only specied access rightsIOAn address space is the natural abstraction for incorporating device ports This is obvious for memorymappedIO but IO ports can also be included The granularity of control depends on the given processor The and its successors permit control per port one verysmall page per port but no mapping of port addressesit enforces mappings with v v the PowerPC usespure memorymapped IO ie device ports can be controlled and mapped with K granularityControlling IO rights and device drivers is thus alsodone by memory managers and pagers on top of the kernel Threads and IPCA thread is an activity executing inside an address spaceA thread  is characterized by a set of registers including at least an instruction pointer a stack pointer anda state information A threads state also includes theaddress space  in which  currently executes Thisdynamic or static association to address spaces is the decisive reason for including the thread concept or something equivalent in the kernel To prevent corruptionof address spaces all changes to a threads address space   must be controlled by the kernel This implies that the kernel includes the notion of some  thatrepresents the above mentioned activity In some operating systems there may be additional reasons for introducing threads as a basic abstraction eg preemptionNote that choosing a concrete thread concept remainssubject to further OSspecic design decisionsConsequently crossaddressspace communicationalso called interprocess communication IPC must besupported by the kernel The classical method istransferring messages between threads by the kernelIPC always enforces a certain agreement betweenboth parties of a communication the sender decidesto send information and determines its contents thereceiver determines whether it is willing to receive information and is free to interpret the received messageTherefore IPC is not only the basic concept for communication between subsystems but also together withaddress spaces the foundation of independenceOther forms of communication remote procedurecall RPC or controlled thread migration between address spaces can be constructed from messagetransferbased IPCNote that the grant and map operations section need IPC since they require an agreement betweengrantermapper and recipient of the mappingSupervising IPCArchitectures like those described by Yokote  andKuhnhauser  need not only supervise the memoryof subjects but also their communication This can bedone by introducing either communication channels orClans Liedtke  which allow supervision of IPC byuserdened servers Such concepts are not discussedhere since they do not belong to the minimal set ofconcepts We only remark that Clans do not burdenthe kernel their base cost is  cycles per IPCInterruptsThe natural abstraction for hardware interrupts is theIPC message The hardware is regarded as a set ofthreads which have special thread ids and send emptymessages only consisting of the sender id to associatedsoftware threads A receiving thread concludes from themessage source id whether the message comes from ahardware interrupt and from which interruptdriver threaddowait for msg sender if sender  my hardware interruptthen readwrite io ports reset hardware interruptelse   od Transforming the interrupts into messages must bedone by the kernel but the kernel is not involved indevicespecic interrupt handling In particular it doesnot know anything about the interrupt semantics Onsome processors resetting the interrupt is a device specic action which can be handled by drivers at user levelThe iretinstruction then is used solely for popping status information from the stack andor switching back touser mode and can be hidden by the kernel However ifa processor requires a privileged operation for releasingan interrupt the kernel executes this action implicitlywhen the driver issues the next IPC operation Unique IdentiersA kernel must supply unique identiers uid forsomething either for threads or tasks or communicationchannels Uids are required for reliable and ecient local communication If S wants to send a message toS it needs to specify the destination S or some channel leading to S Therefore the kernel must knowwhich uid relates to S On the other hand the receiverS wants to be sure that the message comes from STherefore the identier must be unique both in spaceand timeIn theory cryptography could also be used In practice however enciphering messages for local communication is far too expensive and the kernel must betrusted anyway S can also not rely on purely usersupplied capabilities since S or some other instancecould duplicate and pass them to untrusted subsystemswithout control of S FlexibilityTo illustrate the exibility of the basic concepts wesketch some applications which typically belong to thebasic operating system but can easily be implementedon top of the kernel In this section we show theprincipal exibility of a kernel Whether it is reallyas exible in practice strongly depends on the achievedeciency of the kernel The latter performance topicis discussed in section Memory Manager A server managing the initialaddress space  is a classical main memory managerbut outside the kernel Memory managers can easilybe stacked M maps or grants parts of the physicalmemory  to  controlled by M other parts to  controlled by M Now we have two coexisting mainmemory managersPager A Pager may be integrated with a memorymanager or use a memory managing server Pagers usethe kernels grant map and ush primitives Theremaining interfaces pager  client pager  memoryserver and pager  device driver are completely basedon IPC and are userlevel denedPagers can be used to implement traditional pagedvirtual memory and ledatabase mapping into user address spaces as well as unpaged resident memory for device drivers andor real time systems Stacked pagersie multiple layers of pagers can be used for combining access control with existing pagers or for combiningvarious pagers eg one per disk into one composed object Usersupplied paging strategies Lee et al Cao et al  are handled at the user level and are inno way restricted by the kernel Stacked le systemsKhalidi and Nelson  can be realized accordinglyMultimedia Resource Allocation Multimediaand other realtime applications require memory resources to be allocated in a way that allows predictableexecution times The above mentioned userlevel memory managers and pagers permit eg xed allocationof physical memory for specic data or locking data inmemory for a given timeNote that resource allocators for multimedia and fortimesharing can coexist Managing allocation conictsis part of the servers jobsDevice Driver A device driver is a process whichdirectly accesses hardware IO ports mapped into itsaddress space and receives messages from the hardware interrupts through the standard IPC mechanismDevicespecic memory eg a screen is handled bymeans of appropriate memory managers Compared toother userlevel processes there is nothing special abouta device driver No device driver has to be integratedinto the kernelIn general there is no reason for integrating boot drivers intothe kernel The booter eg located in ROM simply loads a bitimage into memory that contains the microkernel and perhapsSecond Level Cache and TLB Improving the hitrates of a secondary cache by means of page allocation orreallocation Kessler and Hill  Romer et al can be implemented by means of a pager which appliessome cachedependent hopefully conict reducing policy when allocating virtual pages in physical memoryIn theory even a software TLB handler could beimplemented like this In practice the rstlevel TLBhandler will be implemented in the hardware or in thekernel However a secondlevel TLB handler eghandling misses of a hashed page table might be implemented as a userlevel serverRemote Communication Remote IPC is implemented by communication servers which translate localmessages to external communication protocols and viceversa The communication hardware is accessed by device drivers If special sharing of communication buersand user address space is required the communicationserver will also act as a special pager for the client Thekernel is not involvedUnix Server Unix system calls are implemented byIPC The Unix server can act as a pager for its clientsand also use memory sharing for communicating withits clients The Unix server itself can be pageable orresidentConclusion A small set of kernel concepts lead toabstractions which stress exibility provided they perform well enough The only thing which cannot be implemented on top of these abstractions is the processorarchitecture registers rstlevel caches and rstlevelTLBs Performance Facts  Rumors Switching OverheadIt is widely believed that switching between kernel anduser mode between address spaces and between threadsis inherently expensive Some measurements seem tosupport this belief KernelUser SwitchesOusterhout  measured the costs for executing thenull kernel call getpid Since the real getpid operation consists only of a few loads and stores this methodmeasures the basic costs of a kernel call Normalized toa hypothetical machine with  MIPS rating  VAXsome set of initial pagers and drivers running at user mode andnot linked but simply appended to the kernel Afterwards theboot drivers are no longer usedUnix is a registered trademark of UNIX System Laboratories or roughly a  at  MHz he showed thatmost machines need  s per getpid one requiredeven  s Corroborating these results we measured s per Mach kernel call get self thread In factthe measured kernelcall costs are highFor analyzing the measured costs our argument isbased on a   MHz processor We take an x processor because kerneluser mode switches are extremelyexpensive on these processors In contrast to the worstcase processor we use a bestcase measurement for discussion  s for Mach on a The measured costs per kernel call are   cycles The bare machine instruction for entering kernelmode costs  cycles followed by an additional  cycles for returning to user mode These two instructionsswitch between the user and kernel stack and pushpopag register and instruction pointer  cycles about s is therefore a lower bound on kerneluser modeswitches The remaining  or more cycles are purekernel overhead By this term we denote all cycleswhich are solely due to the construction of the kernelnevermind whether they are spent in executing instructions  cycles   instructions or in cache andTLB misses  cycles   primary cache misses  TLB misses We have to conclude that the measuredkernels do a lot of work when entering and exiting thekernel Note that this work by denition has no neteectIs an  cycle kernel overhead really necessary Theanswer is no Empirical proof L Liedtke  has aminimal kernel overhead of  cycles If the kernel callis executed infrequently enough it may increase by upto  additional cycles  TLB misses  cache missesThe complete L kernel call costs are thus  to cycles mostly less than  sThe L kernel is process oriented uses a kernelstack per thread and supports persistent user processesie the kernel can be exchanged without aecting theremaining system even if a process actually resides inkernel mode Therefore it should be possible for anyother kernel to achieve comparably low kernel calloverhead on the same hardwareOther processors may require a slightly higher overhead but they oer substantially cheaper basic operations for entering and leaving kernel mode Froman architectural point of view calling the kernel fromuser mode is simply an indirect call complemented bya stack switch and setting the internal kernelbit topermit privileged operations Accordingly returningfrom kernel mode is a normal return operation complemented by switching back to user stack and resetting thekernelbit If the processor has dierent stack pointerregisters for user and kernel stack the stack switchingcosts can be hidden Conceptually entering and leavingMach  NORMA MK kernel mode can perform exactly like a normal indirectcall and return instruction which do not rely on branchprediction Ideally this means   cycles on a issue processorConclusion Compared to the theoretical minimumkerneluser mode switches are costly on some processors Compared to existing kernels however they canbe improved  to  times by appropriate kernel construction Kerneluser mode switches are not a seriousconceptual problem but an implementational one Address Space SwitchesFolklore also considers addressspace switches as costlyAll measurements known to the author and related tothis topic deal with combined thread and addressspaceswitch costs Therefore in this section we analyze onlythe architectural processor costs for pure addressspaceswitching The combined measurements are discussedtogether with thread switchingMost modern processors use a physically indexedprimary cache which is not aected by addressspaceswitching Switching the page table is usually verycheap  to  cycles The real costs are determinedby the TLB architectureSome processors eg Mips R use tagged TLBswhere each entry does not only contain the virtual pageaddress but also the addressspace id Switching theaddress space is thus transparent to the TLB and costsno additional cycles However addressspace switchingmay induce indirect costs since shared pages occupyone TLB entry per address space Provided that the kernel shared by all address spaces has a small workingset and that there are enough TLB entries the problemshould not be serious However we cannot support thisempirically since we do not know an appropriate kernel running on such a processorMost current processors eg  Pentium PowerPC and Alpha include untagged TLBs An addressspace switch thus requires a TLB ush The real costsare determined by the TLB load operations which arerequired to reestablish the current working set laterIf the working set consists of n pages the TLB is fullyassociative has s entries and a TLB miss costs m cyclesat most minn s m cycles are required in totalApparently larger untagged TLBs lead to a performance problem For example completely reloadingthe Pentiums data and code TLBs requires at least       cycles Therefore intercepting aprogram every s could imply an overhead of up to Although using the complete TLB is unrealisticBoth TLBs are way setassociative Working sets whichare not compact in the virtual address space usually imply someconicts so that only about half of the TLB entries are used simultaneously Furthermore a working set of  data pages willthis worstcase calculation shows that switching pagetables may become critical in some situationsFortunately this is not a problem since on Pentiumand PowerPC addressspace switches can be handleddierently The PowerPC architecture includes segmentregisters which can be controlled by the kernel andoer an additional address translation facility from thelocal byte address space to a global byte spaceIf we regard the global space as a set of one million localspaces addressspace switches can be implemented byreloading the segment registers instead of switching thepage table With  cycles for  GB or  cycles for GB segment switching the overhead is low comparedto a no longer required TLB ush In fact we have atagged TLBThings are not quite as easy on the Pentium or the Since segments are mapped into a byte spacemapping multiple user address spaces into one linearspace must be handled dynamically and depends on theactually used sizes of the active user address spacesThe according implementation technique Liedtke is transparent to the user and removes the potentialperformance bottleneck Address space switch overheadthen is  cycles on the Pentium and  cycles on For understanding that the restriction of a byteglobal space is not crucial to performance one has tomention that address spaces which are used only forvery short periods and with small working sets are effectively very small in most cases say  MB or less for adevice driver For example we can multiplex one  GBuser address space with  user spaces of  MB and additionally  user spaces of  MB The trick is to sharethe smaller spaces with all large  GB spaces Then anyaddressspace switch to a medium or small space is always fast Switching between two large address spacesis uncritical anyway since switching between two largeworking sets implies TLB and cache miss costs nevermind whether the two programs execute in the same orin dierent address spacesTable  shows the page table switch and segmentswitch overhead for several processors For a TLB missthe minimal and maximal cycles are given providedthat no referenced or modied bits need updating Inthe case of  Pentium and PowerPC this depends onwhether the corresponding page table entry is found inthe cache or not As a minimal working set we assume pages For the maximum case we exclude  pagesfrom the addressspace overhead costs because at most pages are required by the kernel and thus would aswell occupy TLB entries when the address space wouldnot be switchedmost likely lead to cache thrashing in best case the cache supports    bytes per page Since the cache is only way setassociative probably only  or  cache entries can be used perpage in practiceTLB TLB miss Page Table Segmententries cycles switch cycles          Pentium          PowerPC     Alpha      a     naMips R     a b naaAlpha and Mips TLB misses are handled by softwarebR has a tagged TLBTable  Address Space Switch OverheadConclusion Properly constructed addressspaceswitches are not very expensive less than  cycles onmodern processors On a  MHz processor the inherited costs of addressspace switches can be ignoredroughly up to  switches per second Special optimizations like executing dedicated servers in kernelspace are superuous Expensive context switching insome existing kernels is due to implementation andnot caused by inherent problems with the concept Thread Switches and IPCOusterhout  also measured context switching insome Unix systems by echoing one byte back and forththrough pipes between two processes Again normalizedto a  Mips machine most results are between  andSystem CPU MHz RPC time cyclesIPCround trip onewayfull IPC semanticsL    s QNX    s Mach R   s SRC RPC CVAX   s Mach    s Amoeba    s Spin Alpha    s Mach Alpha    s restricted IPC semanticsExotlrpc R   s Spring SparcV   s DPMach    s LRPC CVAX   s Table  byteRPC performance s per pingpong one was  s All existing kernels are at least  times faster but it is proved byconstruction that  s ie a  to  times faster RPCis achievable Table  gives the costs of echoing one byteby a round trip RPC ie two IPC operationsThe respective data is taken from Liedtke  Hildebrand Schroeder and Burroughs  Draves et al  vanAll times are user to user crossaddress spaceTheyinclude system call argument copy stack and addressspace switch costs Exokernel Spring and L show thatcommunication can be implemented pretty fast and thatthe costs are heavily inuenced by the processor architecture Spring on Sparc has to deal with register windows whereas L is burdened by the fact that a trap is  cycles more expensive than a Sparc trapThe eect of using segment based addressspaceswitch on Pentium is shown in gure  One long running application with a stable working set  to data pages executes a short RPC to a server witha small working set  pages After the RPC theapplication reaccesses all its pages Measurement isdone by  repetitions and comparing each runagainst running the application  time accessing all pages without RPC The given times are roundtrip RPC times user to user plus the required time forreestablishing the applications working setapplication data working set pagesRPCtimeworkingsetreestablishsby pagetable switch   by segment switchFigure  Segmented Versus Standard AddressSpaceSwitch in L on Pentium  MHzConclusion IPC can be implemented fast enough tohandle also hardware interrupts by this mechanism Memory EectsChen and Bershad  compared the memory systembehaviour of Ultrix a large monolithic Unix systemwith that of the Mach kernel which was complementedwith a Unix server They measured memory cycle overhead per instruction MCPI and found that programsrunning under Mach  Unix server had a substantiallyRenesse et al  Liedtke  Bershad et al  Engleret al  Hamilton and Kougiouris  Bryce and Muller Bershad et al higher MCPI than running the same programs under Ultrix For some programs the dierences were up to cycles per instruction averaged over the total programuser  system Similar memory system degradationof Mach versus Ultrix is noticed by others Nagle et al The crucial point is whether this problem is dueto the way that Mach is constructed or whether it iscaused by the kernel approachChen and Bershad  p  state This suggests that microkernel optimizations focussing exclusively on IPC     without considering other sourcesof system overhead such as MCPI will have a limitedimpact on overall system performance Although onemight suppose a principal impact of OS architecturethe mentioned paper exclusively presents facts as isabout a specic implementation without analyzing thereasons for memory system degradationCareful analysis of the results is thus required According to the original paper we comprise under system either all Ultrix activities or the joined activitiesof the Mach kernel Unix emulation library and Unixserver The Ultrix case is denoted by U the Machcase by M We restrict our analysis to the samples thatshow a signicant MCPI dierence for both systemssed egrep yacc gcc compress espresso and the andrew benchmark abIn gure  we present the results of Chens gure in a slightly reordered way We have colored MCPIsed U M egrep U M yacc U M gcc U M compress U M ab U M espresso U M other MCPIsystem cache miss MCPIFigure  Baseline MCPI for Ultrix and Machblack that are due to system icache or dcache missesThe white bars comprise all other causes system writebuer stalls system uncached reads user icache anddcache misses and user write buer stalls It is easyto see that the white bars do not dier signicantlybetween Ultrix and Mach the average dierence is the standard deviation is  MCPIWe conclude that the dierences in memory systembehaviour are essentially caused by increased system cache misses for Mach They could be conict misses themeasured system used direct mapped caches or capacity misses A large fraction of conict misses wouldsuggest a potential problem due to OS structureChen and Bershad measured cache conicts by comparing the direct mapped to a simulated way cacheThey found that system selfinterference is more important than usersystem interference but the data alsoshow that the ratio of conict to capacity misses inMach is lower than in Ultrix Table  shows the conictblack and capacity white system cache misses bothin an absolute scale left and as ratio rightsed U M egrep U M yacc U M gcc U M compress U M ab U M espresso U M conict missescapacity missesFigure  MCPI Caused by Cache MissesFrom this we can deduce that the increased cachemisses are caused by higher cache consumption of thesystem Mach  emulation library  Unix server notby conicts which are inherent to the systems structureThe next task is to nd the component which is responsible for the higher cache consumption We assumethat the used Unix single server behaves comparablyto the corresponding part of the Ultrix kernel Thisis supported by the fact that the samples spent evenfewer instructions in Machs Unix server than in thecorresponding Ultrix routines We also exclude Machsemulation library since Chen and Bershad report thatonly  or less of system overhead is caused by itWhat remains is Mach itself including trap handling IPC and memory management which thereforemust induce nearly all of the additional cache missesTherefore the mentioned measurements suggestthat memory system degradation is caused solely byhigh cache consumption of the kernel Or in otherwords drastically reducing the cache working set of akernel will solve the problemSince a kernel is basically a set of procedures whichare invoked by userlevel threads or hardware a highcache consumption can only be explained by a largenumber of very frequently used kernel operations orAlthough this method does not determine all conict missesas dened by Hill and Smith  it can be used as a rstlevelapproximationWe do not believe that the Mach kernel ushes the cache explicitly The measured system was a uniprocessor with physicallytagged caches The hardware does not even require explicit cacheushes for DMAby high cache working sets of a few frequently used operations According to section  the rst case has to beconsidered as a conceptual mistake Large cache working sets are also not an inherent feature of kernelsFor example L requires less than  K for short IPCRecall voluminous communication can be made by dynamic or static mapping so that the cache is not oodedby copying very long messagesMogul and Borg  reported an increase in cachemisses after preemptivelyscheduled context switchesbetween applications with large working sets This depends mostly on the application load and the requirement for interleaved execution timesharing The typeof kernel is almost irrelevant We showed section and  that kernel context switches are not expensive in the sense that there is not much dierencebetween executing application  servers in one or inmultiple address spacesConclusion The hypothesis that kernel architectures inherently lead to memory system degradation isnot substantiated On the contrary the quoted measurements support the hypothesis that properly constructed kernels will automatically avoid the memorysystem degradation measured for Mach NonPortabilityOlder kernels were built machineindependently ontop of a small hardwaredependent layer This approachhas strong advantages from the software technologicalpoint of view programmers did not need to know verymuch about processors and the resulting kernels couldeasily be ported to new machines Unfortunately thisapproach prevented these kernels from achieving thenecessary performance and thus exibilityIn retrospective we should not be surprised sincebuilding a kernel on top of abstract hardware has serious implications Such a kernel cannot take advantage of specichardware It cannot take precautions to circumvent or avoidperformance problems of specic hardware The additional layer per se costs performancekernels form the lowest layer of operating systemsbeyond the hardware Therefore we should accept thatthey are as hardware dependent as optimizing code generators We have learned that not only the coding but even the algorithms used inside a kernel and itsinternal concepts are extremely processor dependent Compatible ProcessorsFor illustration we briey describe how a kernel hasto be conceptually modied even when ported from to Pentium ie to a compatible processorAlthough the Pentium processor is binary compatible to the  there are some dierences in the internal PentiumTLB entries ways u  i  d Cache size ways Ku  Ki  Kd line write B through B backfast instructions  cycle  cyclesegment register  cycles  cyclestrap  cycles  cyclesTable    Pentium Dierenceshardware architecture see table  which inuence theinternal kernel architectureUseraddressspace implementation As mentioned in section  a Pentium kernel should usesegment registers for implementing user address spacesso that each byte hardware address space shares allsmall and one large user address space Recall that thiscan be implemented transparently to the userFord  proposed a similar technique for the and table  also suggests it for the  Neverthelessthe conventional hardwareaddressspace switch is preferrable on this processor Expensive segment registerloads and additional instructions at various places inthe kernel sum to roughly  cycles required in addition Now look at the relevant situation an addressspace switch from a large space to a small one and backto the large Assuming cache hits the costs of the segment register model would be  cycleswhereas the conventional addressspace model would require    cycles in the theoretical case ofTLB use  cycles for the more probable case that the large address space uses only  ofthe TLB and only  cycles in the best case In totalthe conventional method winsOn the Pentium however the segment registermethod pays The reasons are several a Segment register loads are faster b Fast instructions are cheaperwhereas the overhead by trap and TLB misses remainnearly constant c Conict cache misses which relative to instruction execution are anyway more expensive are more likely because of reduced associativityAvoiding TLB misses thus also reduces cache conictsd Due to the three times larger TLB the ush costscan increase substantially As a result on Pentium thesegment register method always pays see gure As a consequence we have to implement an additional useraddressspace multiplexer we have to modify addressspace switch routines handling of user supplied addresses thread control blocks task controlblocks the IPC implementation and the addressspacestructure as seen by the kernel In total the mentionedchanges aect algorithms in about half of all kernelmodulesIPC implementation Due to reduced associativitythe Pentium caches tend to exhibit increased conictmisses One simple way to improve cache behaviourduring IPC is by restructuring the thread control blockdata such that it prots from the doubled cache linesize This can be adopted to the  kernel since it hasno eect on  and can be implemented transparentlyto the userIn the  kernel thread control blocks includingkernel stacks were page aligned IPC always accesses control blocks and kernel stacks simultaneously Thecache hardware maps the according data of both control blocks to identical cache addresses Due to itsway associativity this problem could be ignored onthe  However Pentiums data cache is only waysetassociative A nice optimization is to align threadcontrol blocks no longer on K but on K boundariesK is the lower bound due to internal reasons Thenthere is a  chance that two randomly selected control blocks do not compete in the cacheSurprisingly this aects the internal bitstructure ofunique thread identiers supplied by the kernel seeLiedtke  for details Therefore the new kernelcannot simply replace the old one since persistent userprograms already hold uids which would become invalid Incompatible ProcessorsProcessors of competing families dier in instruction setregister architecture exception handling cacheTLBarchitecture protection and memory model Especiallythe latter ones radically inuence kernel structureThere are systems with multilevel page tables hashed page tables no reference bits no page protection strange page protection singlemultiple page sizes    and byte address spaces at and segmented address spaces various segment models taggeduntagged TLBs virtuallyphysically tagged cacheseg the  ignores write protection in kernel mode the PowerPC supports read only in kernel mode but this implies that thepage is seen in user mode as wellThe dierences are orders of magnitude higher than between  and Pentium We have to expect that a newprocessor requires a new kernel designFor illustration we compare two dierent kernels ontwo dierent processors the Exokernel Engler et al running on an R and L running on a  Although this is similar to comparing apples with orangesa careful analysis of the performance dierences helpsunderstanding the performancedetermining factors andweighting the dierences in processor architecture Finally this results in dierent kernel architecturesWe compare Exokernels protected control transferPCT with Ls IPC ExoPCT on the R requiresabout  cycles whereas L takes  cycles on a processor for an byte message transfer If this difference cannot be explained by dierent functionalityandor average processor performance there must bean anomaly relevant to kernel designExoPCT is a substrate for implementing ecientIPC mechanisms It changes the program counter toan agreedupon value in the callee donates the currenttimeslice to the callees processor environment and installs required elements of the callees processor context LIPC is used for secure communication between potentially untrusted partners it therefore additionally checks the communication permission whetherthe partner is willing to receive a message from thesender and whether no clan borderline is crossed synchronizes both threads supports error recovery by sendand receive timeouts and permits complex messages toreduce marshaling costs and IPC frequency From ourexperience extending ExoPCT accordingly should require no more than  additional cycles Note thatusing PCT for a trusted LRPC already costs an additional  cycles see table  Therefore we assumethat a hypothetical Lequivalent ExoIPC would costabout  cycles on the R Finally we must take intoconsideration that the cycles of both processors are notequivalent as far as mostfrequentlyexecuted instructions are concerned Based on SpecInts roughly cycles appear to do as much work as one Rcycle comparing the ve instructions most relevant inthis context opalu opalu load branch taken andnot taken gives  for welloptimized code Thus weestimate that the ExoIPC would cost up to approx cycles being denitely less than Ls  cyclesThis substantial dierence in timing indicates anisolated dierence between both processor architecturesthat strongly inuences IPC and perhaps other kernel mechanisms but not average programsIn fact the  processor imposes a high penaltyon enteringexiting the kernel and requires a TLB ushper IPC due to its untagged TLB This costs at least     cycles On the other hand the Rhas a tagged TLB ie avoids the TLB ush and needsless than  cycles for entering and exiting the kernelFrom the above example we learn two lessons For wellengineered kernels on dierent processor architectures in particular with dierentmemory systems we should expect isolated timing dierences that are not related to overall processor performance Dierent architectures require processorspecicoptimization techniques that even aect the globalkernel structureTo understand the second point recall that the mandatory TLB ush requires minimization of the number of subsequent TLB misses The relevant techniques Liedtke  pp  are mostly basedon proper address space construction concentratingprocessorinternal tables and heavily used kernel data inone page there is no unmapped memory on then implementing control blocks and kernel stacks as virtualobjects lazy scheduling In toto these techniques save TLB misses ie at least  cycles on the  and arethus inevitableDue to its unmapped memory facility and taggedTLB the mentioned constraint disappears on theR Consequently the internal structure addressspace structure page fault handling perhaps controlblock access and scheduling of a corresponding kernelcan substantially dier from a kernel If other factors also imply implementing control blocks as physicalobjects even the uids will dier between the R no pointer size x and  kernel no  control blocksize xConclusion kernels form the link between a minimal set of abstractions and the bare processor Theperformance demands are comparable to those of earliermicroprogramming As a consequence kernels are inherently not portable Instead they are the processordependent basis for portable operating systems Synthesis Spin DPMachPanda Cache and ExokernelSynthesis Henry Massalins Synthesis operating system Pu et al  is another example of a high performing and nonportable kernel Its distinguishingfeature was a kernelintegrated compiler which generated kernel code at runtime For example when issuinga read pipe system call the Synthesis kernel generatedspecialized code for reading out of this pipe and modiedthe respective invocation This technique was highlysuccessful on the  However a good example fornonportability it would most probably no longer payon modern processors because a code ination willdegrade cache performance and b frequent generationof small code chunks pollutes the instruction cacheSpin Spin Bershad et al  Bershad et al is a new development which tries to extend the Synthesisidea usersupplied algorithms are translated by a kernel compiler and added to the kernel ie the user maywrite new system calls By controlling branches andmemory references the compiler ensures that the newlygenerated code does not violate kernel or user integrityThis approach reduces kerneluser mode switches andsometimes address space switches Spin is based onMach and may thus inherit many of its ineciencieswhich makes it dicult to evaluate performance resultsRescaling them to an ecient kernel with fast kerneluser mode switches and fast IPC is needed The mostcrucial problem however is the estimation of how anoptimized kernel architecture and the requirementscoming from a kernel compiler interfere with each otherKernel architecture and performance might be eg affected by the requirement for larger kernel stacks Apure kernel needs only a few hundred bytes per kernelstack Furthermore the costs of safetyguaranteeingcode have to be related to kernel overhead and to optimal userlevel codeThe rst published results Bershad et al  cannot answer these questions On an Alpha  MHz a Spin system call needs nearly twice as many cycles  s as the already expensive Mach systemcall  s The application measurements showthat Mach can be substantially improved by using akernel compiler however it remains open whether thistechnique can reach or outperform a pure kernel approach like that described here For example a simpleuserlevel pagefault handler  s under Mach executes in  s under Spin However we must take intoconsideration that in a traditional kernel the kernelis invoked and left only twice page fault enter message to pager exit reply map message enterexitThe Spin technique can save only one system call whichon this processor should cost less than  s ie with s the actual Spin overhead is far beyond the idealtraditional overhead of  sFrom our experience we expect a notable gain ifa kernel compiler eliminates nested IPC redirectioneg when using deep hierarchies of Clans or Custodians Hartig et al  Ecient integration of thekernel compiler technique and appropriate kernel design might be a promising research directionUtahMach Ford and Lepreau  changed MachIPC semantics to migrating RPC which is based onthread migration between address spaces similar to theClouds model BernabeuAuban et al  Substantial performance gain was achieved a factor of  to DPMach DPMach Bryce and Muller  implements multiple domains of protection within one useraddress space and oers a protected interdomain callThe performance results see table  are encouragingHowever although this interdomain call is highly specialized it is twice as slow as achievable by a generalRPC mechanism In fact an interdomain call needstwo kernel calls and two addressspace switches A general RPC requires two additional thread switches andargument transfers Apparently the kernel call andaddressspace switch costs dominate Bryce and Mullerpresented an interesting optimization for small interdomain calls when switching back from a very smalldomain the TLB is only selectively ushed Althoughthe eects are rather limited on their host machine a with only  TLB entries it might become morerelevant on processors with larger TLBs To analyzewhether kernel enrichment by interdomain calls payswe need eg a Pentium implementation and then compare it with a general RPC based on segment switchingPanda The Panda systems Assenmacher et al kernel is a further example of a small kernelwhich delegates as much as possible to user space Besides its two basic concepts protection domain and virtual processor the Panda kernel handles only interruptsand exceptionsCacheKernel The Cachekernel Cheriton andDuda  is also a small and hardwaredependent kernel In contrast to the Exokernel it relies on a smallxed non extensible virtual machine It caches kernels threads address spaces and mappings The termcaching refers to the fact that the kernel never handles the complete set of eg all address spaces but onlya dynamically selected subset It was hoped that thistechnique would lead to a smaller kernel interface andalso to less kernel code since it no longer has to dealwith special but infrequent cases In fact this couldbe done as well on top of a pure kernel by means ofaccording pagers Kernel data structures eg threadcontrol blocks could be held in virtual memory in thesame way as other dataExokernel In contrast to Spin the Exokernel Engler et al  Engler et al  is a small andhardwaredependent kernel In accordance with ourprocessordependency thesis the exokernel is tailoredto the R and gets excellent performance valuesfor its primitives In contrast to our approach it isbased on the philosophy that a kernel should not provide abstractions but only a minimal set of primitivesSometimes the argument transfer can be omitted For implementing interdomain calls a pager can be used which sharesthe address spaces of caller and callee such that the trusted calleecan access the parameters in the caller space Eg LRPC Bershad et al  and NetWare Major et al  use a similartechniqueConsequently the Exokernel interface is archtecture dependent in particular dedicated to softwarecontrolledTLBs A further dierence to our driverless kernelapproach is that Exokernel appears to partially integrate device drivers in particular for disks networksand frame buersWe believe that dropping the abstractional approachcould only be justied by substantial performance gainsWhether these can be achieved remains open see discussion in section  until we have wellengineered exoand abstractional kernels on the same hardware platform It might then turn out that the right abstractionsare even more ecient than securely multiplexing hardware primitives or on the other hand that abstractionsare too inexible We should try to decide these questions by constructing comparable kernels on at leasttwo reference platforms Such a coconstruction willprobably also lead to new insights for both approaches ConclusionsA kernel can provide higher layers with a minimal setof appropriate abstractions that are exible enough to allow implementation of arbitrary operating systems andallow exploitation of a wide range of hardware Thepresented mechanisms address space with map ushand grant operation threads with IPC and unique identiers form such a basis Multilevelsecurity systemsmay additionally need clans or a similar reference monitor concept Choosing the right abstractions is crucialfor both exibility and performance Some existing kernels chose inappropriate abstractions or too manyor too specialized and inexible onesSimilar to optimizing code generators kernelsmust be constructed per processor and are inherently notportable Basic implementation decisions most algorithms and data structures inside a kernel are processor dependent Their design must be guided byperformance prediction and analysis Besides inappropriate basic abstractions the most frequent mistakescome from insucient understanding of the combinedhardwaresoftware system or inecient implementationThe presented design shows that it is possible toachieve well performing kernels through processorspecic implementations of processorindependent abstractionsAvailabilityThe source code of the L kernel a successor of the Lkernel is available for examination and experimentation through the webhttpborneogmddeRSLAcknowledgementsMany thanks to Hermann Hrtig for discussion and RichUhlig for proofreading and stylistic help Further thanksfor reviewing remarks to Dejan Milojicic some anonymous referees and Sacha Krakowiak for shepherdingA Address SpacesAn Abstract Model of Address SpacesWe describe address spaces as mappings  V Rfg is the initial address space where V is the setof virtual pages R the set of available physical realpages and  the nilpage which cannot be accessed Further address spaces are dened recursively as mappings  V    V fg where  is the set of addressspaces It is convenient to regard each mapping as a onecolumn table which contains v for all v V and canbe indexed by v We denote the elements of this tableby vAll modications of address spaces are based on thereplacement operation we write v  x to describe achange of  at v preciselyush  v  v  x A page potentially mapped at v in  is ushed and thenew value x is copied into v This operation is internalto the kernel We use it only for describing the threeexported operationsA subsystem S with address space  can grant anyof its pages v to a subsystem S with address space provided S agreesv v  v   Note that S determines which of its pages should begranted whereas S determines at which virtual addressthe granted page should be mapped in  The grantedpage is transferred to  and removed from A subsystem S with address space  can map anyof its pages v to a subsystem S with address space provided S agreesv  v In contrast to grant the mapped page remains in themappers space  and a link to the page in the mappers address space  v is stored in the receiving address space  instead of transferring the existing linkfrom v to v  This operation permits to constructaddress spaces recursively ie new spaces based on existing onesFlushing the reverse operation can be executedwithout explicit agreement of the mappees since theyagreed implicitly when accepting the prior map operation S can ush any of its pagesv v  v  Note that and ush are dened recursively Flushingrecursively aects also all mappings which are indirectlyderived from vNo cycles can be established by these three operations since  ushes the destination prior to copyingImplementing the ModelAt a rst glance deriving the phyical address of page vin address space  seems to be rather complicated andexpensivev  v if v   vr if v  r if v Fortunately a recursive evaluation of v is never required The three basic operations guarantee that thephysical address of a virtual page will never changeexcept by ushing For implementation we thereforecomplement each  by an additional table P  where Pvcorresponds to v and holds either the physical addressof v or  Mapping and granting then includeP v Pvand each replacement v   invoked by a ush operation includesPv   Pv can always be used instead of evaluating v Infact P is equivalent to a hardware page table kerneladdress spaces can be implemented straightforward bymeans of the hardwareaddresstranslation facilitiesThe recommended implementation of  is to use onemapping tree per physical page frame which describesall actual mappings of the frame Each node containsP v where v is the according virtual page in the address space which is implemented by the page table P Assume that a grant map or ushoperation dealswith a page v in address space  to which the pagetable P is associated In a rst step the operation selects the according tree by Pv the physical page In thenext step it selects the node of the tree that containsP v This selection can be done by parsing the treeor in a single step if Pv is extended by a link to thenode Granting then simply replaces the values storedin the node and map creates a new child node for storing P  v Flush lets the selected node unaected butparses and erases the complete subtree where P v is executed for each node P  v in the subtreeReferencesAssenmacher H Breitbach T Buhler P Hubsch V andSchwarz R  The Panda system architecture  a picokernel approach In th Workshop on Future Trends of Distributed Computing Systems Lisboa Portugal pp BernabeuAuban J M Hutto P W and Khalidi Y A The architecture of the Ra kernel Tech Rep GITICSJan Georgia Institute of Technology Atlanta GABershad B N Anderson T E Lazowska E D and Levy H M Lightweight remote procedure call In th ACM Symposium on Operating System Principles SOSP Licheld ParkAR pp Bershad B N Chambers C Eggers S Maeda C McNameeD Pardyak P Savage S and Sirer E G  Spin  anextensible microkernel for applicationspecic operating system services In th SIGOPS European Workshop SchloDagstuhl Germany pp Bershad B N Savage S Pardyak P Sirer E G FiuczynskiM Becker D Eggers S and Chambers C  Extensibility safety and performance in the Spin operating systemIn th ACM Symposium on Operating System PrinciplesSOSP Copper Mountain Resort CO pp Brinch Hansen P  The nucleus of a multiprogramming system Commun ACM   April Bryce C and Muller G  Matching microkernels to modernapplications using negrained memory protection In IEEESymposium on Parallel Distributed Systems San AntonioTXCao P Felten E W and Li K  Implementation and performance of applicationcontrolled le caching In st USENIXSymposium on Operating Systems Design and Implementation OSDI Monterey CA pp Chen J B and Bershad B N  The impact of operating system structure on memory system performance In thACM Symposium on Operating System Principles SOSPAsheville NC pp Cheriton D R and Duda K J  A caching model of operating system kernel functionality In st USENIX Symposiumon Operating Systems Design and Implementation OSDIMonterey CA pp Digital Equipment Corp  DECChip AA Risc Microprocessor Data Sheet Digital Equipment CorpDraves R P Bershad B N Rashid R F and Dean R W Using continuations to implement thread management andcommunication in operating systems In th ACM Symposium on Operating System Principles SOSP Pacic GroveCA pp Engler D Kaashoek M F and OToole J  The operating system kernel as a secure programmable machine In thSIGOPS European Workshop Schlo Dagstuhl Germany ppEngler D Kaashoek M F and OToole J  Exokernelan operating system architecture for applicationlevel resourcemanagement In th ACM Symposium on Operating SystemPrinciples SOSP Copper Mountain Resort CO pp Ford B  private communicationFord B and Lepreau J  Evolving Mach  to a migratingthread model In Usenix Winter Conference CA pp Gasser M Goldstein A Kaufmann C and Lampson B The Digital distributed system security architecture In thNational Computer Security Conference NISTNCSC Baltimore pp Hamilton G and Kougiouris P  The Spring nucleus A microkernel for objects In Summer Usenix Conference Cincinnati OH pp Hartig H Kowalski O and Kuhnhauser W  The Birlixsecurity architecture Journal of Computer Security   Hildebrand D  An architectural overview of QNX In stUsenix Workshop on Microkernels and Other Kernel Architectures Seattle WA pp Hill M D and Smith A J  Evaluating associativity inCPU caches IEEE Transactions on Computers   DecIntel Corp  i Microprocessor Programmers ReferenceManual Intel CorpIntel Corp  Pentium Processor Users Manual Volume Architecture and Programming Manual Intel CorpKane G and Heinrich J  MIPS Risc Architecture PrenticeHallKessler R and Hill M D  Page placement algorithms forlarge realindexed caches ACM Transactions on ComputerSystems   Nov Khalidi Y A and Nelson M N  Extensible le systems inSpring In th ACM Symposium on Operating System Principles SOSP Asheville NC pp Kuhnhauser W E  A paradigm for userdened security policies In Proceedings of the th IEEE Symposium on ReliableDistributed Systems Bad Neuenahr GermanyLee C H Chen M C and Chang R C  HiPEC highperformance external virtual memory caching In st USENIXSymposium on Operating Systems Design and Implementation OSDI Monterey CA pp Liedtke J  Clans  chiefs In  GIITGFachtagung Architektur von Rechensystemen Kiel pp  SpringerLiedtke J  Improving IPC by kernel design In thACM Symposium on Operating System Principles SOSPAsheville NC pp Liedtke J  Improved addressspace switching on Pentiumprocessors by transparently multiplexing user address spacesArbeitspapiere der GMD No  Sept GMD  GermanNational Research Center for Information Technology SanktAugustinMajor D Minshall G and Powell K  An overview of theNetWare operating system InWinter Usenix Conference SanFrancisco CAMogul J C and Borg A  The eect of context switches oncache performance In th International Conference on Architectural Support for Programming Languages and OperatingSystems ASPLOS Santa Clara CA pp Motorola Inc  PowerPC  RISC Microprocessor UsersManual Motorola IncNagle D Uhlig R Mudge T and Sechrest S  Optimalallocation of onchip memory for multipleAPI operating systems In th Annual International Symposium on ComputerArchitecture ISCA Chicago IL pp Ousterhout J K  Why arent operating systems gettingfaster as fast as hardware In Usenix Summer ConferenceAnaheim CA pp Pu C Massalin H and Ioannidis J  The Synthesis kernelComputing Systems   Jan Romer T H Lee D L Bershad B N and Chen B Dynamic page mapping policies for cache conict resolution onstandard hardware In st USENIX Symposium on OperatingSystems Design and Implementation OSDI Monterey CApp Rozier M Abrossimov A Armand F Boule I Gien MGuillemont M Herrmann F Kaiser C Langlois SLeonard P and Neuhauser W  Chorus distributed operating system Computing Systems   SchroderPreikschat W  The Logical Design of Parallel Operating Systems Prentice HallSchroeder M D and Burroughs M  Performance of theFirey RPC In th ACM Symposium on Operating SystemPrinciples SOSP Licheld Park AR pp van Renesse R van Staveren H and Tanenbaum A S Performance of the worlds fastest distributed operating system Operating Systems Review   Oct Wulf W Cohen E Corwin W Jones A Levin R Pierson Cand Pollack F  Hydra The kernel of a multiprocessingoperating system Commun ACM   July Yokote Y  Kernelstructuring for objectoriented operatingsystems The Apertos approach In International Symposiumon Object Technologies for Advanced Software Springer
