
Chapter 9:  Virtual Memory
9.2 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
De la mémoire vers la mémoire virtuelle
 So far: various memory management strategies
 Keep many processes in memory → multiprogramming
 Require that the entire process is in memory
 Virtual memory allows the execution of a process not completely in
memory
 Programs >> main memory size
 Abstracts main memory into extremely large uniform array
 Allows processes to share files, to implement shared memory
9.3 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Chapter 9:  Virtual Memory
1. Background
2. Demand Paging
3. CopyonWrite
4. Page Replacement
5. Allocation of Frames
6. Thrashing
7. Memory-Mapped Files
8. Allocating Kernel Memory
9. Other Considerations
10. Operating-System Examples
Objectives
To describe the benefits of a
virtual memory system
To explain the concepts of
demand paging, page
replacement algorithms, and
allocation of page frames
To discuss the principle of the
working-set model
9.4 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
1. Background
 Memory management (previous chapter
 Instruction being executed must be in physical memory
 Place the entire logical memory in physical memory
 Dynamic loading may help
 Special precaution / extra work
 Seems necessary & reasonable
 Unfortunate
 Limits the size of a program
 Entire program is not needed in many cases
 Code for unusual error condition
 Array / lists allocate more memory than needed
 Some options / features rarely used
9.5 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Background cont
 Benefits
 No constraint by the limit of the physical memory
 More programs could be run at the same time
 Increase in CPU utilization, throughput
 Same response time or turnaround
 Less I/O to load/swap each user program / run faster
9.6 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Background cont
 Virtual memory – separation of user logical memory from
physical memory
 Only part of the program needs to be in memory for execution
 Logical address space can therefore be much larger than
physical address space
 Programming task much more easier
 Allows address spaces to be shared by several processes
 Allows for more efficient process creation
 Virtual memory can be implemented via
 Demand paging
 Demand segmentation
9.7 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Virtual Memory That is Larger Than Physical Memory

9.8 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Virtual Address Space
 Refers to the logical view of how a process is
stored in memory
 In fact physical memory may be organized in
page frames
 Pages frames may be assigned to a process in
a non contiguous way
 The MMU maps logical pages to physical pages
 Hole (sparse address space) is part of the
virtual address space
 Require physical addresses only if the
heap/stack grows
 Allows also sharing of files, memory, process
creation, libraries
9.9 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Shared Library Using Virtual Memory
Mapped Read only
9.10 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
2. Demand Paging
 Bring a page into memory only when it is needed
 Less I/O needed
 Less memory needed
 Faster response
 More users
 Page is needed → reference to it
 Invalid reference → abort
 Not-in-memory → bring to memory
 Lazy swapper – never swaps a page into memory unless
page will be needed
 Swapper that deals with pages is a pager
9.11 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Transfer of a Paged Memory to Contiguous Disk Space
9.12 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Basic concept
 Pager “guesses” which pages will be used before the process is
swapped out again
 Need support to distinguish between the pages that are
 In memory
 On the disk
9.13 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Valid-Invalid Bit
 With each page table entry, a valid–invalid bit is associated
(v → in-memory, i → notinmemory
 Initially valid–invalid bit is set to i on all entries
 Example of a page table snapshot
 During address translation, if valid–invalid bit in page table entry
is i → page fault
v
v
i
v
i
i
i

Frame # valid-invalid bit
page table
9.14 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Page Table When Some Pages Are Not in Main
Memory
 Page marked invalid has no effect
if the process never attempts to
access that page
 If we guess right, the process will
run exactly as though we have
brought in all pages
 While pages are memory
resident, execution proceeds
normally
9.15 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Page Fault
 If there is a reference to a page, first reference to that
page will trap to operating system
page fault
1. Operating system looks at another table to decide
 Invalid reference → abort process
 Just not in memory → page it in
2. Get empty frame
3. Swap page into frame
4. Update page table: set validation bit = v
5. Restart the instruction that caused the page fault
Extreme case: start executing a process with no page in memory
 pure demand paging
9.16 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Page Fault Cont
 Restart instruction
 Must save the state of the interrupt process
 restart the process in exactly the same place
 If page fault when writing result, restart the whole instruction
 Problems, for instance with block move
Solution: check locations before start or use registers
Some programs could access several new pages of memory with each
instruction execution
 poor performance
 locality of reference results in reasonable performance from demand paging
9.17 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Steps in Handling a Page Fault
9.18 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Performance of Demand Paging
 Page fault rate 0 ≤ p ≤
 if p = 0, no page faults
 if p = 1, every reference is a fault
 Effective Access Time EAT
EAT = (1 – p) x (memory access time
+ p x (page fault overhead
+ swap page out
+ swap page in
+ restart overhead
9.19 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Demand Paging Example
 Memory access time = 200 nanoseconds
 Average page-fault service time = 8 milliseconds
 EAT = (1 – p) x 200 + p x (8 milliseconds)
= (1 – p) x 200 + p x 8,000,000
= 200 + p x
 If one access out of 1,000 causes a page fault, then
EAT = 8.2 microseconds.
This is a slowdown by a factor of
 Performance degradation <
→ p <
9.20 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Process Creation
 Virtual memory allows other benefits during process creation
 CopyonWrite
 Memory-Mapped Files later
 fork() system call creates a child process as a duplicate of its parent
 Many child call exec() system call immediately after creation
 Unnecessary code copy… waste of time
9.21 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
3. CopyonWrite
 Copy-on-Write (CoW) allows both parent and child processes to
initially share the same pages in memory
If either process modifies a shared page, only then is the page
copied
 Only pages that can be modified are marked CoW (not the
code
 CoW allows more efficient process creation as only modified pages
are copied
 Free pages are allocated from a pool of zeroed-out pages
9.22 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Before Process 1 Modifies Page C
Copy of
page C
After Process 1 Modifies Page C




9.23 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
What happens if there is no free frame
 Page replacement – find some page in memory, but not
really in use, swap it out
 algorithm
 performance – want an algorithm that will result in
minimum number of page faults
 Same page may be brought into memory several times
9.24 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
4. Page Replacement
 Prevent over-allocation of memory by modifying page-fault
service routine to include page replacement
 Use modify (dirty) bit to reduce overhead of page transfers –
only modified pages are written to disk
 Page replacement completes separation between logical
memory and physical memory – large virtual memory can be
provided on a smaller physical memory
 Need
 Frame allocation algorithm
 Page replacement algorithm
9.25 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Need For Page Replacement
9.26 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Basic Page Replacement
1. Find the location of the desired page on disk
2. Find a free frame
-  If there is a free frame, use it
-  If there is no free frame, use a page replacement
algorithm to select a victim frame
3. Bring the desired page into the (newly) free frame;
update the page and frame tables
4. Restart the process
9.27 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Page Replacement
9.28 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Page Replacement Algorithms
 Want lowest page-fault rate
 Evaluate algorithm by running it on a particular
string of memory references (reference string) and
computing the number of page faults on that string
 In all our examples, the reference strings are

1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4,
and

9.29 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Graph of Page Faults Versus The Number of Frames
9.30 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
First-In-First-Out (FIFO) Algorithm
 Reference string: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4,
 3 frames (3 pages can be in memory at a time per process
 4 frames












9 page faults
9.31 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
First-In-First-Out (FIFO) Algorithm
 Reference string: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4,
 3 frames (3 pages can be in memory at a time per process
 4 frames
 Belady’s Anomaly: more frames → more page faults












9 page faults










5 10 page faults
44
9.32 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
FIFO Illustrating Belady’s Anomaly
9.33 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
FIFO Page Replacement
15 faults
9.34 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Optimal Algorithm
 Replace page that will not be used for longest period of time
 4 frames example
1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4,
 How do you know this
 Used for measuring how well your algorithm performs




6 page faults
4
9.35 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Optimal Page Replacement
9 faults (vs 15 for FIFO
9.36 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Least Recently Used (LRU) Algorithm
 Reference string:  1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4,
 Counter implementation
 Every page entry has a counter; every time page is
referenced through this entry, copy the clock into the counter
 When a page needs to be changed, look at the counters to
determine which are to change




















9.37 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
LRU Page Replacement
12 faults (vs 15 for FIFO
9.38 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
LRU Algorithm Cont
 Stack implementation – keep a stack of page numbers in a double
link form
 Page referenced
 move it to the top
 requires 6 pointers to be changed
 No search for replacement
 Neither implementation (counter or stack) conceivable without
hardware support
 Interrupt to update clock or stack
 Slow every memory reference by a factor at least
 Overhead that cannot be tolerated
9.39 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Use Of A Stack to Record The Most Recent Page References
9.40 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
LRU Approximation Algorithms
 Reference bit
 With each page associate a bit, initially =
 When page is referenced bit set to
 Replace one that is 0 (if one exists
 We do not know the order, however
 Additional reference bit
 Shift register to record reference bit periodically
 Second chance
 Need reference bit
 Clock replacement
 If page to be replaced (in clock order) has reference bit = 1 then
 set reference bit
 leave page in memory
 replace next page (in clock order), subject to same rules
9.41 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Second-Chance (clock) Page-Replacement Algorithm
9.42 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Counting Algorithms
 Keep a counter of the number of references that have been
made to each page
 LFU Algorithm:  replaces page with smallest count
(Least Frequently Used
 MFU Algorithm: based on the argument that the page with
the smallest count was probably just brought in and has yet
to be used
(Most Frequently Used
9.43 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
5. Allocation of Frames
 How do we allocate the fixed amount of free memory among the
various processes
 Each process needs minimum  number of pages
 Example:  IBM 370 – 6 pages to handle SS MOVE instruction
 instruction is 6 bytes, might span 2 pages
 2 pages to handle from
 2 pages to handle to
 Two major allocation schemes
 fixed allocation
 priority allocation
9.44 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Fixed vs Priority Allocation
 Equal allocation – For example, if there are 100 frames and 5
processes, give each process 20 frames
 Proportional allocation – Allocate according to the size of process
 si = size of process pi , S = ∑ si
 m = total number of frames
 ai : number of frames allocated to pi :   ai = (si / S) x m
 Example with m = 64, s1 = 10, s2 =
• We obtain a1 = 5, a2 = 59
 Priority allocation – Use a proportional allocation scheme using
priorities rather than size
9.45 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Global vs. Local Allocation
 Global replacement – process selects a replacement
frame from the set of all frames; one process can take a
frame from another
 Local replacement – each process selects from only its
own set of allocated frames
 With global replacement, a process cannot control its
own page fault behavior
 Priority allocation (cont): If process Pi  generates a page fault
 select for replacement one of its frames
 select for replacement a frame from a process with lower
priority number
9.46 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
6. Thrashing
 If a process does not have “enough” frames, the page-fault rate is
very high. This leads to
 low CPU utilization
 operating system thinks that it needs to increase the degree of
multiprogramming
 another process added to the system
 Thrashing = a process is busy swapping pages in and out
9.47 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Thrashing Cont
Limit the trashing by using local replacement algorithm / priority replacement
process trashing  in paging queue most of the time  access time will increase
We need to provide a process with as many frames as it needs
How do we know how many frames it “needs”
9.48 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Demand Paging and Thrashing
 Why does demand paging work
Locality model
 Process migrates from one locality to another
 Localities may overlap
 Allocate enough frames to a process to accommodate its
current locality
 Why does thrashing occur
∑ size of locality > total memory size
Limit effects by using local or priority page replacement
9.49 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Locality In A Memory-Reference Pattern
Locality model == unstated
principle behind several concepts
If accesses to any type of data
were random rather than
patterned, caching would be
useless
9.50 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Working-Set Model
 Δ = working-set window = a fixed number of page references
Example:  10,000 instructions
 WSSi (working-set size of process Pi)
total number of pages referenced in the most recent Δ (varies in time
 If Δ too small: will not encompass entire locality
 if Δ too large: will encompass several localities
 if Δ = ∞ : will encompass entire program
 D = ∑  WSSi = total demand frames
 If D > m: Thrashing
 Policy if D > m, then suspend one of the processes
9.51 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Working-set model
9.52 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Keeping Track of the Working Set
 Approximate with interval timer + a reference bit
 Example: Δ =
 Timer interrupts every 5000 time units
 Keep in memory 2 bits for each page
 Whenever a timer interrupts: copy and set the values of all
reference bits to
 If one of the bits in memory = 1: page in working set
 Why is this not completely accurate
 Improvement = 10 bits and interrupt every 1000 time units
9.53 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Page-Fault Frequency Scheme
 Establish “acceptable” page-fault rate
 If actual rate too low, process loses frame
 If actual rate too high, process gains frame
9.54 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
7. Memory-Mapped Files
 Memory-mapped file I/O allows file I/O to be treated as routine
memory access by mapping a disk block to a page in memory
 A file is initially read using demand paging. A page-sized
portion of the file is read from the file system into a physical
page. Subsequent reads/writes to/from the file are treated as
ordinary memory accesses
 Simplifies file access by treating file I/O through memory rather
than read() write() system calls
 Also allows several processes to map the same file allowing the
pages in memory to be shared
9.55 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Memory Mapped Files
9.56 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Memory-Mapped Shared Memory in Windows
9.57 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
8. Allocating Kernel Memory
 Treated differently from user memory
 Often allocated from a free-memory pool
 Kernel requests memory for structures of varying sizes:
should limit waste due to fragmentation
 Some kernel memory needs to be contiguous
9.58 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Buddy System
 Allocates memory from fixed-size segment consisting of
physically-contiguous pages
 Memory allocated using power-of-2 allocator
 Satisfies requests in units sized as power of
 Request rounded up to next highest power of
 When smaller allocation needed than is available, current
chunk split into two buddies of next-lower power of
 Continue until appropriate sized chunk available
 Pros and cons
 Coalescing to quickly combine adjacent buddies
 Rounding up to next highest power of 2 causes fragmentation
9.59 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Buddy System Allocator
9.60 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Slab Allocator
 Alternate strategy
 Slab is one or more physically contiguous pages
 Cache consists of one or more slabs
 Single cache for each unique kernel data structure
 Each cache filled with objects – instantiations of the data
structure
 When cache created, filled with objects marked as free
 When structures stored, objects marked as used
 If slab is full of used objects, next object allocated from empty slab
 If no empty slabs, new slab allocated
 Benefits include no fragmentation, fast memory request satisfaction
9.61 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Slab Allocation
9.62 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
9. Other Issues – Prepaging
 Prepaging
 To reduce the large number of page faults that occur at process
startup
 Prepage all or some of the pages a process will need, before they
are referenced (e.g., pages from working set
  But if prepaged pages are unused, I/O and memory were wasted
 Assume s pages are prepaged and α of the pages are used
 Is cost of s x α  saved pages faults greater or less than the cost
of prepaging s x (1- α) unnecessary pages?
 α close to zero (resp. one): prepaging loses (resp. win
9.63 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Other Issues – Page Size
 Page size selection must take into consideration
 fragmentation
 table size
 I/O overhead (latency + transfer rate
 locality
 number of page faults
9.64 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Other Issues – TLB Reach
 TLB Reach - The amount of memory accessible from the TLB
 TLB Reach = (TLB Size) X (Page Size
 Ideally, the working set of each process is stored in the TLB
 Otherwise there is a high degree of page faults
 Increase the Page Size
 This may lead to an increase in fragmentation as not all
applications require a large page size
 Provide Multiple Page Sizes
 This allows applications that require larger page sizes the
opportunity to use them without an increase in
fragmentation
9.65 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Other Issues – Program Structure
 Program structure
 Int[128,128] data
 Each row is stored in one page
 Program 1
for (j = 0; j <128; j
for (i = 0; i < 128; i
data[i,j] =
128 x 128 = 16,384 page faults
 Program 2
for (i = 0; i < 128; i
for (j = 0; j < 128; j
data[i,j] =
128 page faults
9.66 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Other Issues – I/O interlock
 I/O Interlock – Pages must sometimes be locked into
memory
 Consider I/O - Pages that are used for copying a file
from a device must be locked from being selected for
eviction by a page replacement algorithm
9.67 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Reason Why Frames Used For I/O Must Be In Memory
9.68 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
10a. Windows XP
 Uses demand paging with clustering. Clustering brings in
pages surrounding the faulting page
 Processes are assigned working set minimum (50) and
working set maximum
 Working set minimum is the minimum number of pages the
process is guaranteed to have in memory
 A process may be assigned as many pages up to its working
set maximum
 When the amount of free memory in the system falls below a
threshold, automatic working set trimming is performed to
restore the amount of free memory
 Working set trimming removes pages from processes that
have pages in excess of their working set minimum
10. Operating System Examples
9.69 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
10b. Solaris
 Maintains a list of free pages to assign faulting processes
 lotsfree – threshold parameter (amount of free memory) to begin
paging (1/64 of the size of the physical memory
 desfree – threshold parameter to increasing paging
 minfree – threshold parameter to begin swapping
 Paging is performed by pageout process
 pageout scans pages using modified clock algorithm
 scanrate is the rate at which pages are scanned. This ranges from
slowscan to fastscan
 pageout is called more frequently depending upon the amount of
free memory available
9.70 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Solaris 2 Page Scanner
9.71 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Rsum
 Mémoire virtuelle: mapper un large espace d'adressage logique sur
une mémoire physique plus petite – permet de faire tourner des
gros processus, et d'augmenter le degré de multiprogrammation
 Pagination à la demande: table des pages, et faute de page si la
page n'est pas en mémoire; mettre la page en mémoire et relancer
l'instruction qui a provoqué la faute
 Remplacement de pages lorsque la mémoire est pleine; attention à
l'anomalie de Belady
 Politique d'allocation des cadres de page; remplacement local
(interne à un processus) ou global (avec priorité par exemple);
modèle du working-set pour éviter le thrashing
 Fichiers mappés en mémoire: accès fichier = accès mmoire
 Mémoire système: allocation buddy ou slab
9.72 Silberschatz, Galvin and Gagne ©2005Operating System Concepts – 7th Edition, Feb 22,
Exercices
1. Demand-paged memory. Page table: in registers.
* 8 millisec to service page fault if there is an empty page, or
the replaced page is not modified
* 20 millisec if the replaced page is modified
* Memory access time: 100 nanosec
If the page to be replaced is modified 70% of the time, what is the
maximum acceptable page-fault rate for an effective access time
of no more than 200 nanosec?
2. What is the cause of thrashing? How does the system detect
thrashing? Once it detects thrashing, what can the system do to
eliminate this problem

