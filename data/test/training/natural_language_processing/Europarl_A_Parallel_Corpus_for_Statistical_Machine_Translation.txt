Europarl A Parallel Corpus for Statistical Machine TranslationPhilipp KoehnSchool of InformaticsUniversity of Edinburgh, Scotlandpkoehninf.ed.ac.ukAbstractWe collected a corpus of parallel text in 11 languages from the proceedings of the European Parliament, which are published on the web1. This corpus has found widespread use in the NLP community. Here, we focus on its acquisition and its application as training data for statistical machine translation SMT. We trained SMT systems for 110 language pairs, which reveal interesting clues into thechallenges ahead.1 IntroductionIn many ways, progress in natural language researchis driven by the availability of data. This is particularly true for the field of statistical machine translation, which thrives on the emergence of large quantities of parallel text text paired with its translationinto a second language.The source for these parallel texts are often multinational institutions such as the United Nations orthe European Union, but also the governments ofmultilingual countries such as Canada French, English or the Hong Kong English, Chinese. Harvesting these resources allowed the continued improvement of statistical machine translation systemsthat challenge the state of the art in MT for manylanguage pairs.One contribution to this endeavour is the acquisition of the Europarl corpus, which we describe inthis paper. It is a collection of the proceedings ofthe European Parliament, dating back to 1996. Altogether, the corpus comprises of about 30 millionwords for each of the 11 official languages of theEuropean Union Danish da, German de, Greekel, English en, Spanish es, Finnish fi, Frenchfr, Italian it, Dutch nl, Portuguese pt, andSwedish sv. With the enlargement of the European Union to 25 member countries in May 2004,the European Union has begun to translate texts intoeven more languages.1Available online at httpwww.statmt.orgeuroparlWe collected the Europarl corpus mainly to aidour research in statistical machine translation, butsince we made it available in its initial releasein 2001, it has been used for many other natural language problems word sense disambiguation,anaphora resolution, information extraction, etc.This paper describes the acquisition of the corpus and its application to the task of statistical machine translation. We used the corpus to build 110machine translation systems for all the possible language pairs. The resulting systems and their performances demonstrate the different challenges forstatistical machine translation for different languagepairs.The field has been dominated by efforts to buildMT systems for a handful of languages Arabic,Chinese, German, French, Spanish into English.We hope that this contribution stimulates researchon nontraditional language pairs.2 Corpus CollectionAcquisition of a parallel corpus for the use in a statistical machine translation system typically takesfive steps obtain the raw data e.g., by crawling the web extract and map parallel chunks of text document alignment break the text into sentences sentence splitting prepare the corpus for SMT systems normalisation, tokenisation map sentences in one language sentences in theother language sentence alignmentIn the following, we will describe in detail theacquisition of the Europarl corpus from the websiteof the European Parliament. These proceedings arepublished in all of the 11 former official languagesof the European Union. This means that we cannot only extract a conventional parallel corpus, butCHAPTER ID1Resumption of the sessionSPEAKER ID1 NAMEPresidentI declare resumed the session of the European Parliament ...PAlthough, as you will have seen, the dreaded millennium bug ...Figure 1 Format of the released corpus beginning of file deenenep000117.txt, the English halfof the GermanEnglish corpus from January 17, 2000.a multilingual corpus of 11 languages, or 10 parallelcorpora for each language.2.1 CrawlingThe website of the European Parliament2 providesthe Proceedings of the European Parliament in formof HTML files. At the time of our most recent crawl,each file contains the utterances of one speaker inturn. The format has changed this year. The URLfor each file contains relevant information for identification, such as its language, the day and numberof the thread of discussion and number of the utterance.Crawling this web resource with a web spider isdone by starting at an index page and following certain links based on inclusion and exclusion rules.Since the corpus consists of many small parts, thecrawling process is time consuming. Per language,it took several days to obtain the roughly 80,000files each. Although such crawls are slow, it is typically easier than contacting directly the technicalstaff of the website and negotiate a transfer procedure.Usually, there are also copyright concerns, although less so for information from governmentsources. The European Parliament web site statesExcept where otherwise indicated, reproduction isauthorised, provided that the source is acknowledged. Such liberal copyright policy can not necessarily expected. Often a longer legal process isrequired to get permission and access to the data.Besides identifying sources for parallel corporamanually, it is also possible to mine the web for suchdata. Resnik 1999 proposes such a system, calledSTRAND.2.2 Document AlignmentEach sitting of the European Parliament covers anumber of topics. A first step is to identify the textsbelonging to each topic, and matching these between languages. To obtain the maximum amountof data, we match these topics for each of the language pairs.2Online at httpwww.europarl.eu.intLarge data collections such as the Proceedings ofthe European Parliament are created over the periodof many years, often with changing formatting standards and other sources of error. For instance, partof the English part of the proceedings contain actually French texts 2124 May 1996 at the time ofour crawl.The extraction of relevant text from noisy HTMLis a cumbersome enterprise that requires constantrefinement and adaptation. We process the HTMLdata with a Perl program that uses pattern matchingto detect and extract the identity of the speaker andher statements including paragraph markers.There is work on automatically learning systems that extract structured information from websources or other forms of unstructured data. Thistask is called wrapper induction. See for instancework by Muslea et al. 1999. For a single datasource, however, a manual approach is often moreefficient.For each day, we store the data in one file perlanguage with some meta information, as shown inFigure 1.We created parallel corpora involving Englishin this format. We also provide corpora in sentence aligned format, which we will describe below.Scripts are provided to generate the other parallelcorpora.The document alignment is done without tokenisation and sentence splitting. The motivation behindthis is that these are error prone processes for whichmultiple standards could be applied, and we do notwant to force any specific standard at this step.2.3 Sentence Splitting and TokenisationSentence splitting and tokenisation require specialised tools for each language. Unfortunately, wedo not have such tools available for all the languagesunder consideration.One problem of sentence splitting is the ambiguity of the period . as either a end of sentencemarker, or as a marker for an abbreviation. For English, French and German, we semiautomaticallycreated a list of known abbreviations that are typically followed by a period. One clue is a lowercasedLanguage Days Chapters Speaker Turns Sentences WordsDanish da 492 4,120 90,017 1,032,764 27,153,424German de 492 4,119 90,135 1,023,115 27,302,541Greek el 398 3,712 66,928 746,834 27,772,533English en 488 4,055 88,908 1,011,476 28,521,967Spanish es 492 4,125 90,305 1,029,155 30,007,569French fr 492 4,125 90,335 1,023,523 32,550,260Finnish fi 442 3,627 81,370 941,890 18,841,346Italian it 492 4,117 90,030 979,543 28,786,724Dutch nl 492 4,122 90,112 1,042,482 28,763,729Portuguese pt 492 4,125 90,329 1,014,128 29,213,348Swedish sv 492 3,627 81,246 947,493 23,535,265Table 1 Size of the released corpus version 2. The numbers of sentences and words is after tokenisationand sentencealignment with English or German, in the case of English.word following a period ca. three thousand men,which indicates an abbreviation and not an end of asentence.There has been extensive work on empiricalmethods to learn sentence breaking. See for instance the work on SATZ Palmer and Hearst,1997. Various machine learning methods can beapplied to this problem, such as decision trees Riley, 1989 and maximum entropy Reynar and Ratnaparkhi, 1997.Issues with tokenisation include the Englishmerging of words such as in cant which wetransform to can not, or the separation of possessive markers the mans becomes the man s.We do not perform any specialised treatment forother languages than English at this point. In future,we would like to employ a tokenisation scheme thatmatches the Penn treebank standard. Currently, ourprovided scripts allow external tokenisation methods.For training a statistical machine translation system, usually all words are lowercased to eliminatethe differences between different spelling of wordsdepending on their occurrence at the beginning ofa sentence The, in the middle the, or in a headline THE. A more sophisticated approach is truecasing, which allows the distinction names Mr.Black and regular words black.2.4 Sentence AlignmentSentence alignment is usually a hard problem, but inour case it is simplified by the fact that the texts arealready available in paragraph aligned format. Eachparagraph consists typically of only 25 sentences.If the number of paragraphs of a speaker utterance differs in the two languages, we discard thisdata for quality reasons. The alignment of sentencesin the corpus is done with an implementation of thealgorithm by Gale and Church 1993. This algorithms tries to match sentences of similar length insequence and merges sentences if necessary e.g.two short sentences in one language to one long sentence in the other language, based on the number ofwords in the sentence. Since there are so few sentences per paragraph, alignment quality is very high.There is considerable work on better sentencealignment algorithms. One obvious extension is tonot only consider sentence length, but also potentialword correspondences within sentence pairs. Workby Melamed 1999 is an example for such an approach.The sentence aligned data is stored in one fileper day per language, so that lines with the sameline number in a file pair are mappings of eachother. The markup from the document aligned filesis stripped out. In the current release, the size ofthe sentence aligned corpus is roughly 30 millionwords in one million sentences per language. Foremore detailed statistics, see Table 1.2.5 Extraction of a Common Test SetTo allow the comparison of machine translation system, it is necessary not only to define a commontraining set as the Europarl corpus, but also a common test set. We suggest to reserve the last quarter of 2000 NovemberDecember 2000 as test set,and to use the rest of the corpus as training data.This portion of the corpus comprises of over onemillion words in over 40,000 sentences.To be able to compare system performance ondifferent language pairs, we also extracted a set ofsentences that are aligned to each other across all11 languages. Figure 2 is one of the sentences fromthis collection.Danish det er nsten en personlig rekord for mig dette efterar .German das ist fur mich fast personlicher rekord in diesem herbst .GreekEnglish that is almost a personal record for me this autumn Spanish es la mejor marca que he alcanzado este otono .Finnish se on melkein minun ennatykseni tana syksyna French c  est pratiquement un record personnel pour moi , cet automne Italian e  quasi il mio record personale dell  autunno .Dutch dit is haast een persoonlijk record deze herfst .Portuguese e quase o meu recorde pessoal deste semestre Swedish det ar nastan personligt rekord for mig denna host Figure 2 One sentence aligned across 11 languagesNote that this data is also lowercased, which isnot done for the released sentence aligned data. Alternatively, true casing could be applied, althoughthis is a more difficult task.2.6 Releases of the CorpusThe initial release of this corpus consisted of data upto 2001. The second release added data up to 2003,increasing the size from just over 20 million wordsto up to 30 million words per language. A forthcoming third release will include data up to early 2005and will have better tokenisation. For more details,please check the website.3 110 SMT SystemsThe prevailing methodology in statistical machinetranslation SMT has progressed from the initialwordbased IBM Models Brown et al., 1993 tocurrent phrasebased models Koehn et al., 2003.To describe the latter quickly When translating asentence, source language phrases any sequencesof words are mapped into phrases in the target language, as specified by a probabilistic phrase translation table. Phrases may be reordered, and a language model in the target language supports fluentoutput.The core of this model is the probabilistic phrasetranslation table that is learned from a parallel corpora. There are various methods to train this, severalstart with a automatically obtained word alignmentand then collect phrase pairs of any length that areconsistent with the word alignment.Decoding is a beam search over all possible segmentation of the input into phrases, any translationfor each phrase, and any reordering. Additionalcomponent models aid in scoring alternative translations. Translation speed in our case is a few secondsper sentence.Fuelled by annual competitions and an active research community, we can observe rapid progressin the field. Due to the involvement of US fundingagencies, most research groups focus on the translation from Arabic to English and Chinese to English.Next to texttotext translation, there is increasinginterest in speechtotext translation.Most systems are largely languageindependent,and building a SMT system for a new languagepair is mostly a matter of availability of paralleltexts. Our efforts to explore opendomain GermanEnglish SMT led us to collecting data from the European Parliament. Incidentally, the existence oftranslations in 11 languages now enabled us to buildtranslation systems for all 110 language pairs.Our SMT system Koehn et al., 2003 includesthe decoder Pharaoh Koehn, 2004, which is freelyavailable for research purposes3. Training 110 systems took about 3 weeks on a 16node Linux cluster. We evaluated the quality of the system with thewidely used BLEU metric Papineni et al., 2002,which measures overlap with a reference translation.We tested on a 2000 sentences heldout test set,which is drawn from text from sessions that tookpart the last quarter of the year 2000. These sentences are aligned across all 11 languages, so whentranslation the, say, French sentences into Danish,we can compare the output against the Danish set ofsentences. The same test set was used in a sharedtask at the 2005 ACL Workshop on Parallel TextsKoehn, 2005.The scores for the 110 systems are displayed inTable 2. According to these numbers, the easiesttranslation direction is Spanish to French BLEUscore of 40.2, the hardest Dutch to Finnish 10.3.3Available online at httpwww.isi.edulicensedswpharaohSource Target LanguageLanguage da de el en es fr fi it nl pt svda  18.4 21.1 28.5 26.4 28.7 14.2 22.2 21.4 24.3 28.3de 22.3  20.7 25.3 25.4 27.7 11.8 21.3 23.4 23.2 20.5el 22.7 17.4  27.2 31.2 32.1 11.4 26.8 20.0 27.6 21.2en 25.2 17.6 23.2  30.1 31.1 13.0 25.3 21.0 27.1 24.8es 24.1 18.2 28.3 30.5  40.2 12.5 32.3 21.4 35.9 23.9fr 23.7 18.5 26.1 30.0 38.4  12.6 32.4 21.1 35.3 22.6fi 20.0 14.5 18.2 21.8 21.1 22.4  18.3 17.0 19.1 18.8it 21.4 16.9 24.8 27.8 34.0 36.0 11.0  20.0 31.2 20.2nl 20.5 18.3 17.4 23.0 22.9 24.6 10.3 20.0  20.7 19.0pt 23.2 18.2 26.4 30.1 37.9 39.0 11.9 32.0 20.2  21.9sv 30.3 18.9 22.8 30.2 28.6 29.7 15.3 23.9 21.9 25.9 Table 2 BLEU scores for the 110 translation systems trained on the Europarl corpusFigure 3 Clustering of languages based on systemscores Language families emerge4 Language ClusteringIntuitively, languages that are related are easier totranslate into each other. We can underscore thiswith our SMT system scores. When clustering languages together based on their translation score, the11 languages group together roughly along the linesof their language families, as shown in Figure 3.One the one side, you can find the Romancelanguages Spanish, French, Portuguese and Italian,on the other side the Germanic languages Danish,Swedish, English, Dutch and German. The closelanguages Danish and Swedish, as well as Dutchand German are group together first. The graph isnot perfect One would suspect Spanish and Portuguese to be joined first, but Spanish is first joinedwith French.The clustering algorithm greedily groups languages together that translate into each other mosteasily. In the first step, Spanish and French aregrouped together, since they have the highest translation score 38.4 and 40.2. In the next step Portuguese is added 37.9 and 35.9 with Spanish, 39.0Language From Into DiffDanish da 23.4 23.3 0.0German de 22.2 17.7 4.5Greek el 23.8 22.9 0.9English en 23.8 27.4 3.6Spanish es 26.7 29.6 2.9French fr 26.1 31.1 5.1Finnish fi 19.1 12.4 6.7Italian it 24.3 25.4 1.1Dutch nl 19.7 20.7 1.1Portuguese pt 26.1 27.0 0.9Swedish sv 24.8 22.1 2.6Table 3 Average translation scores for systemswhen translating from and into a language. Notethat German de and English en are similarly difficult to translate from, but English is much easier totranslate into.and 35.3 with French. Always, the two clusters oflanguages are joined that have the highest averagetranslation score. A bias term of c1  c22 isadded to the score to bias toward the emergence ofsmaller clusters c is the size of the cluster c.5 Translation DirectionSome language are more difficult to translate intothan from. See Table 3 for details on this. The average score for systems that translate from Germaninto the each of the other 10 languages is 22.2, verysimilar for systems translating from English, 23.8.However, the scores for translating into these language is vastly different 17.7 for German vs. 27.4for English.One apparent reason for the difficulty of translating into a language is morphological richness. Nounphrases in German are marked with case, whichFigure 4 Vocabulary size vs. BLEU score when translating into English which has about 65,000 distinctword formsmanifests itself as different word endings at determiners, adjectives and nouns. Generating the rightcase markings is hard, especially since nothing inthe translation model keeps track of the role of nounphrases and the trigram language model is fairlyweak in this respect, since it only considers a threeword window.The poor performance of systems involvingFinnish can also partly be attributed to its morphology, which is very agglutinative Some elementsthat form individual words in English determiners,prepositions are included in the morphology. Thisincreases the size of the vocabulary the Finnish vocabulary is about five times as big as the English,leading to sparse data problems when collectingstatistics for word and phrase translation. See Figure 4 for a comparison of BLEU scores when translating into into English and vocabulary size.Intuitively, translating from an informationrichinto an informationpoor language is easier than theother way around. Researchers have made similar observations about the better performance ofArabicEnglish SMT systems vs. ChineseEnglishSMT systems, that are trained on similar amount oftraining data and tested on news wire Translatingfrom Arabic with its rich morphology is easier thantranslating from Chinese, which is even more frugalthan English, often lacking determiners and pluralor tense markers.Note that translating into English is among theeasiest. However, since the research community isprimarily occupied with translation into English, interesting problems associated with translating intomorphologically rich languages have largely beenneglected.6 Back TranslationThe quality of machine translation systems is difficult to assess. This is especially true for monolingual speakers, who only know one language. Whenmainstream journalists report on the progress of machine translation systems, they frequently resort toa seemingly clever trick They use a MT system totranslate a sentence from English into a foreign language, and then use a reverse MT system to translatethe sentence back into English. They then judge theLanguage From Into Backda 28.5 25.2 56.6de 25.3 17.6 48.8el 27.2 23.2 56.5es 30.5 30.1 52.6fi 21.8 13.0 44.4it 27.8 25.3 49.9nl 23.0 21.0 46.0pt 30.1 27.1 53.6sv 30.2 24.8 54.4Table 4 Scores for monodirectional systems andback translation Translating from English to Greeksystem score 27.2 and back to English systemscore 23.2 results in a BLEU score of 56.5 forthe combined translation. The score is higher thanfor the combination EnglishPortugueseEnglish53.6, although the monodirectional systems arebetter 30.1, 27.1.quality of the MT systems by how well the Englishsentence is preserved.This method is inspired by an urban legend involving a pair of MT systems between Russian andEnglish. The legend proclaims that once someonefed a EnglishRussian MT system the bible verseThe spirit is willing, but the flesh is weak. Whenback translating the sentence with the RussianEnglish system, the system returned The vodka isgood but the meat is rotten.How well does back translation indicate the translation performance of the MT systems involved AsTable 4 shows, not much.First of all, while one would suspect a degradation of the quality of a sentence when translatedinto a foreign language, and a further degradationwhen translated back, the BLEU scores tell a different story For instance, the quality of the EnglishGreek system is 27.2 and 23.2 for the GreekEnglish system. However, translating the test setfrom English into Greek and back into English,gives a BLEU score of 56.5, much higher than either system.Note that this high score is an artifact of howthe BLEU score works It measures overlap with areference translation. In the monodirectional systems the reference translation is a human translation. While the system output may be correct,the system may get punished for valid translationchoices that differ from the ones by the human. Inback translation, however, we compare against exactly the input sentence, which will be easier tomatch.The more interesting point of Table 4 is Theback translation scores do not correlate well withthe monodirectional system scores. Again, theEnglishGreekEnglish combination has systemscores of 27.2 and 23.2, and a back translationscore of 56.5. This is higher than 53.6, the scorefor the EnglishPortugueseEnglish combination,which has better monodirectional system scores30.1 and 27.2.In conclusion, back translation does not only provide a false sense of the capabilities of MT systems,it is also a lazy and flawed method to compare systems. Back translation unfairly benefits from theability to reverse errors, which only show up in theforeign language. To drive the point home a systempair that does nothing, meaning, leaving all Englishwords in place will do perfectly in back translation,while being utterly useless in practise.7 ConclusionsWe described the acquisition of the Europarl corpusand its application in building statistical machinetranslation systems for 110 language pairs, maybethe largest number of machine translation systemsbuilt within three weeks, and the first serious effortat building such a system for, say, Greek to Finnish.Some sample output is in Figure 5.The widely ranging quality of the different SMTsystems for the different language pairs demonstratethe many different challenges for SMT research,which we have only touched upon. The fields primary occupation with translating a few languagesinto English ignores many of these challenges.Finally, we hope that the availability of resourcescorpora, tools continues to make statistical machine translation an exciting and productive field.ReferencesBrown, P. F., Pietra, S. A. D., Pietra, V. J. D., andMercer, R. L. 1993. The mathematics of statistical machine translation. Computational Linguistics, 192263313.Gale, W. and Church, K. 1993. A program foraligning sentences in bilingual corpora. Computational Linguistics, 191.Koehn, P. 2004. Pharaoh a beam search decoderfor statistical machine translation. In 6th Conference of the Association for Machine Translationin the Americas, AMTA, Lecture Notes in Computer Science. Springer.Koehn, P. 2005. Shared task Statistical machinetranslation for european languages. In ACL Workshop on Parallel Texts.SpanishEnglishwe all know very well that the current treaties are insufficient and that , in the future , it will be necessary todevelop a better structure and different for the european union , a structure more constitutional also makeit clear what the competences of the member states and which belong to the union .messages of concern in the first place just before the economic and social problems for the present situation, and in spite of sustained growth , as a result of years of effort on the part of our citizens .the current situation , unsustainable above all for many selfemployed drivers and in the area of agriculture, we must improve without doubt .in itself , it is good to reach an agreement on procedures , but we have to ensure that this system is notlikely to be used as a weapon policy .now they are also clear rights to be respected .i agree with the signal warning against the return , which some are tempted to the intergovernmentalmethods .there are many of us that we want a federation of nation states .FinnishEnglishthe rapporteurs have drawn attention to the quality of the debate and also the need to go further  of course, i can only agree with them .we know very well that the current treaties are not enough and that in future , it is necessary to developa better structure for the union and , therefore perustuslaillisempi structure , which also expressed moreclearly what the member states and the union is concerned .first of all , kohtaamiemme economic and social difficulties , there is concern , even if growth is sustainableand the result of the efforts of all , on the part of our citizens .the current situation , which is unacceptable , in particular , for many carriers and responsible for agriculture , is in any case , to be improved .agreement on procedures in itself is a good thing , but there is a need to ensure that the system cannot beused as a political lyomaaseena .they also have a clear picture of the rights of now , in which they have to work .i agree with him when he warned of the consenting to return to intergovernmental methods .many of us want of a federal state of the national member states .Figure 5 Sample output of the trained systemsKoehn, P., Och, F. J., and Marcu, D. 2003. Statistical phrase based translation. In Proceedings ofthe Joint Conference on Human Language Technologies and the Annual Meeting of the NorthAmerican Chapter of the Association of Computational Linguistics HLTNAACL.Melamed, D. 1999. Bitext maps and alignment viapattern recognition. Computational Linguistics,251107130.Muslea, I., Minton, S., and Knoblock, C. 1999. Ahierarchical approach to wrapper induction. InEtzioni, O., Muller, J. P., and Bradshaw, J. M.,editors, Proceedings of the Third InternationalConference on Autonomous Agents Agents99,pages 190197, Seattle, WA, USA. ACM Press.Palmer, D. D. and Hearst, M. A. 1997. Adaptivemultilingual sentence boundary detection. Computational Linguistics, 232241267.Papineni, K., Roukos, S., Ward, T., and Zhu, W.J.2002. BLEU a method for automatic evaluation of machine translation. In Proceedings of the40th Annual Meeting of the Association of Computational Linguistics ACL.Resnik, P. 1999. Mining the web for bilingual text.In Proceedings of the International Conference ofthe Association of Computational Linguistics.Reynar, J. C. and Ratnaparkhi, A. 1997. A maximum entropy approach to identifying sentenceboundaries. In Proceedings of the Firth Conference on Applied Natural Language Processing,pages 803806.Riley, M. D. 1989. Some applications of treebased modeling to speech and language. In Proceedings of the DARPA Speech and LanguageTechnology Workshop, pages 339352.
