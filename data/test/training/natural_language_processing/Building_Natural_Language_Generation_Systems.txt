arXivcmplg9605002v1  2 May 1996Building Natural Language Generation SystemsEhud ReiterDepartment of Computing ScienceUniversity of AberdeenKings CollegeAberdeen AB9 2UE, BRITAINemail ereitercsd.abdn.ac.uk1 IntroductionNatural Language Generation NLG systems generate texts in English or other human languages, such as French from computeraccessible data. NLG systems are currently most oftenused to help human authors write routine documents, including business letters SBW91 andweather reports GDK94. They also have been used as interactive explanation tools whichcommunicate information in an understandable way to nonexpert users, especially in softwareengineering eg, RK92 and medical eg, BMF94 contexts.From a technical perspective, almost all applied NLG systems perform the following threetasks Rei94Content Determination and Text Planning Decide what information should be communicated to the user content determination, and how this information should be rhetorically structured text planning. These tasks are usually done simultaneously.Sentence Planning Decide how the information will be split among individual sentences andparagraphs, and what cohesion devices eg, pronouns, discourse markers should be addedto make the text flow smoothly.Realization Generate the individual sentences in a grammatically correct manner.In the rest of this paper, I shall briefly discuss different ways of performing each of these tasks2 Content Determination and Text PlanningContent determination deciding what information to communicate in the text and textplanningorganizing the information into a rhetorically coherent structure are done simultaneously inmost applied NLG systems Rei94. These tasks can be done at many different levels of sophistication. One of the simplest and most common approaches is simply to write a hardcodedcontenttextplanner in a standard programming language C, Lisp, etc. The resultantsystem may lack flexibility, but if the texts being produced have a standardized content andstructure which is true in many technical domains, then this can be the most effective way toperform these tasks.On the other end of the sophistication spectrum, many standard AI techniques have beenadopted for content determination and text planning, including rulebased systems RML95 andplanning Hov88. Systems built in this way are in principal very flexible and powerful, althoughin practice they have sometimes not been robust enough for realworld use.An intermediate approach which has been quite popular is to use a special schema or textplanning language McK85, KKR91. Such languages typically allow the developer to represent1text plans as transition networks of one sort or another, with the nodes giving the informationcontent and the arcs giving the rhetorical structure In many cases textplanning languagesare implemented as macro packages, which gives the developer access to the full power of theunderlying programming language whenever necessary.3 Sentence PlanningSentence planning includes Conjunction and other aggregation. For example, transforming 1 into 21 Sam has high blood pressure. Sam has low blood sugar.2 Sam has high blood pressure and low blood sugar. Pronominalization and other reference. For example, transforming 3 into 43 I just saw Mrs. Black. Mrs Black has a high temperature.4 I just saw Mrs. Black. She has a high temperature. Introducing discourse markers. For example, transforming 5 into 65 If Sam goes to the hospital, he should go to the store.6 If Sam goes to the hospital, he should also go to the store.The common theme behind these operations is they do not change the information content ofthe text, but they do make it more fluent and easily readable.Sentence planning is important if the text needs to read fluently and, in particular, if it shouldlook like it was written by a human which is usually the case for business letters, for example.If it doesnt matter if the text sounds stilted and was obviously produced by a computer, thenit may be possible to deemphasize sentence planning, and perform minimal aggregation, use nopronouns, etc.If the text does need to look fluent, then a good job of sentence planning is essential. Thereare formal models of all of the operations mentioned above, and some applied NLG systemshave incorporated them, eg, MKS94. It is also possible to do effective sentenceplanning in anadhoc manner, at least in a limited domain Knowledge Points Performance Now system is agood example of this.4 RealizationARealizer generates individual sentences typically from a deep syntactic representation Rei94.The realizer needs to make sure that the rules of English are obeyed, including Point absorption and other punctuation rules. For example, the sentence I saw HelenJones, my sisterinlaw should end in ., not ,. Morphology. For example, the plural of box is boxes, not boxs. Agreement. For example, I am here instead of I is here. Reflexives. For example, John saw himself, instead of John saw John.There are numerous linguistic formalisms and theories which can be incorporated into anNLG Realizer, far too many to describe here. There are also some generalpurpose engineswhich can be programmed with various linguistic rules, such as FUF Elh92 and PENMANPen89.In many cases, acceptable performance can be achieved without using complex linguisticmodules. In particular, if only a few different types of sentences are being generated, then itmay be simpler and cheaper to use fillintheblank templates for realization, instead of propersyntactic processing.5 ConclusionMany different techniques are available for performing the three NLG tasks of content determination and text planning, sentence planning, and realization. These techniques range from thesimplistic to the extremely sophisticated, and it is impossible to say that one is always betterthan another. It all depends on the characteristics of the application, such as whether extensivefiltering and summarization of information is needed, whether texts need to look like they werewritten by a person, and how much syntactic variety is expected to occur in the generated texts.A good NLG engineer will choose the most appropriate set of techniques, given the needs of theapplication RM93 and the available resources.ReferencesBMF94 B. Buchanan, J. Moore, D. Forsythe, G. Carenini, and S. Ohlsson. Using medical informaticsfor explanation in a clinical setting. Technical Report 9316, Intelligent Systems Laboratory,University of Pittsburgh, 1994.Elh92 Michael Elhadad. Using Argumentation to Control Lexical Choice A Functional UnificationImplementation. PhD thesis, Columbia University, 1992.GDK94 Eli Goldberg, Norbert Driedger, and Richard Kittredge. Using naturallanguage processingto produce weather forecasts. IEEE Expert, 924553, 1994.Hov88 Eduard Hovy. Planning coherent multisentential text. In Proceedings of 26th Annual Meetingof the Association for Computational Linguistics ACL88, pages 163169, 1988.KKR91 Richard Kittredge, Tanya Korelsky, and Owen Rambow. On the need for domain communication language. Computational Intelligence, 74305314, 1991.McK85 Kathleen McKeown. Text Generation. Cambridge University Press, 1985.MKS94 Kathleen McKeown, Karen Kukich, and James Shaw. Practical issues in automatic documentgeneration. In Proceedings of the Fourth Conference on Applied NaturalLanguage ProcessingANLP1994, pages 714, 1994.Pen89 Penman Natural Language Group. The Penman user guide. Technical report, InformationSciences Institute, Marina del Rey, CA 90292, 1989.RK92 Owen Rambow and Tanya Korelsky. Applied text generation. In Proceedings of the ThirdConference on Applied Natural Language Processing ANLP1992, pages 4047, 1992.Rei94 Ehud Reiter. Has a consensus NL Generation architecture appeared, and is it psycholinguistically plausible In Proceedings of the Seventh International Workshop on Natural LanguageGeneration INLGW1994, pages 163170, 1994.RM93 Ehud Reiter and Chris Mellish. Optimising the costs and benefits of natural language generation. In Proceedings of the 13th International Joint Conference on Artificial IntelligenceIJCAI1993, volume 2, pages 11641169, 1993.RML95 Ehud Reiter, Chris Mellish, and John Levine. Automatic generation of technical documentation. Applied Artificial Intelligence, 93259287, 1995.SBW91 Stephen Springer, Paul Buta, and Thomas Wolf. Automatic letter composition for customerservice. In Reid Smith and Carlisle Scott, editors, Innovative Applications of Artificial Intelligence 3 Proceedings of CAIA1991. AAAI Press, 1991.
