The Semantic Software Lab, Concordia University, Montréal, Canada Skip navigation . semanticsoftware.info Semantic Software Lab Concordia University Montréal, Canada Research Projects Tools & Resources Publications Blogs Forums Semantic Assistants Durm Wiki Open Positions Contact Search this site: Site Menu Home Research SSL for Students Projects Tools & Resources Publications Blogs Forums Contact User login Log in using OpenID: What is OpenID? Username: * Password: * Log in using OpenID Cancel OpenID login To prevent automated spam submissions leave this field empty. Request new password Upcoming events No upcoming events available more Popular content Today's: The Durm Corpus Semantic Assistants Zeeva: A Collaborative Semantic Literature Management System All time: Using OwlExporter: various questions The Durm Project The Durm German Lemmatizer Last viewed: The Fifth International Conference on Advances in Semantic Processing (SEMAPRO 2011) Enhancing the OpenOffice.org Word Processor with Natural Language Processing Capabilities The Biofuel Process Current weather Montréal, Canada Overcast, mist, light rain Temperature: 3 °C , feels like 0.4 °C Wind: Northwest, 9.3 km/h Pressure: 1008 hPa Rel. Humidity: 93 % Visibility: 8 km Sunrise: 06:23 -0500 Sunset: 17:50 -0500 Reported on: Wed, 2017-03-08 02:21 The Semantic Software Lab The Semantic Software Lab was founded in 2008 by René Witte at Concordia University in Montréal, Québec, Canada. Our lab focuses on research and applications of Semantic Computing, Text Mining, Linked Data, Natural Language Processing (NLP), Information Extraction, Intelligent Information Systems, and related technologies. We are committed to providing free, open source software and open research data to the community. This website provides information about the lab's research activities and our published tools and resources. It also provide information for students interested in course or research work, as well as career opportunities for researchers. It also aims to serve as a community portal for selected topics and events in the area of semantic systems within (north-east) America in general and Montréal in particular. You can also follow us on Twitter @SemSoft , on LinkedIn or connect with us on Google+ . In addition to the resources published on this site, we have code repositories on SourceForge and GitHub . » READ MORE Rhetector: Automatic Dection of Rhetorical Entities in Scientific Literature Semantic Publishing Semantic Publishing Text Mining Rhetector is a GATE plugin for the automatic detection of Rhetorical Entities (REs) in scientific literature. Rhetorical Entities are spans of text (sentences, passages, sections, etc.) in a document, where authors convey their findings, like Claims or Arguments , to the readers. We designed a lightweight pipeline to automatically detect rhetorical entities in scientific literature, currently limited to Claims and Contributions . The motivation and application behind Rhetector is described in our publication, Sumner, T. (Eds.), Sateli, B. , and R. Witte , " Semantic representation of scientific literature: bringing claims, contributions and named entities onto the Linked Open Data cloud ", PeerJ Computer Science , vol. 1, no. e37 PeerJ, 12/2015. » READ MORE The GATE LODtagger component GATE Components Linked Open Data Text Mining The LODtagger is a GATE component that provides linking entities from a document to their corresponding resource on the Linked Open Data (LOD) cloud. LODtagger relies on external tools to perform the actual content tagging and hides the complexity of communicating with LOD taggers, such as DBpedia Spotlight, from the perspective of pipeline developers. » READ MORE Zeeva: A Collaborative Semantic Literature Management System Literature Management Semantic Publishing Semantic Wiki Text Mining This overabundance of literature available in online repositories is an ongoing challenge for scientists that have to efficiently manage and analyze content for their information needs. Most of the existing literature management systems merely provide support for storing bibliographical metadata, tagging, and simple annotation capabilities. We go beyond these approaches by demonstrating how an innovative combination of semantic web technologies with natural language processing can mitigate the information overload by helping in curating and organizing scientific literature. Zeeva is our research prototype for demonstrating how we can turn existing papers into a queryable knowledge base. » READ MORE Tutorial: Adding Natural Language Processing Support to your (Semantic) MediaWiki Semantic Assistants Semantic Web Semantic Wiki NLP Text Mining Wikis have become powerful knowledge management platforms, offering high customizability while remaining relatively easy to deploy and use. With a majority of content in natural language, wikis can greatly benefit from automated text analysis techniques. Natural Language Processing is a branch of computer science that employs various Artificial Intelligence (AI) techniques to process content written in natural language. NLP-enhanced wikis can support users in finding, developing and organizing knowledge contained inside the wiki repository. Rather than relying on external NLP applications, we developed an approach that brings NLP as an integrated feature to wiki systems, thereby creating new human/AI collaboration patterns, where human users work together with automated "intelligent assistants" on developing, structuring and improving wiki content. This is achieved with our open source Wiki-NLP integration, a Semantic Assistants add-on that allows to incorporate NLP services into the MediaWiki environment, thereby enabling wiki users to benefit from modern text mining techniques. This tutorial has two main parts: In the first part, we will present an introduction into NLP and text mining, as well as related frameworks, in particular the General Architecture for Text Engineering and the Semantic Assistants framework. Building on the foundations covered in the first part, we will then look into the Wiki-NLP integration and show how you can add arbitrary text processing services to your (Semantic) MediaWiki instance with minimal effort. Throughout the tutorial, we illustrate the application of NLP in wikis with a number of applications examples from various domains we developed in our research within the last decade, such as cultural heritage data management, collaborative software requirements engineering, and biomedical knowledge management. These showcases of the Wiki-NLP integration highlight a number of integration patterns that will help you to adopt this technology for your own domain. » READ MORE Semantic MediaWiki Conference (SMWCon) Spring 2014: 2nd call for contributions Semantic Wiki Save the dates! SMWCon Spring 2014 will be held at Concordia University this year in the vibrant and culturally-fascinating city of Montréal, from May 21-23. We are inviting you to submit your contributions to assemble the conference program. Registration is now open, with early bird rates applicable until April 30th. This twice-yearly conference brings together researchers, users, developers and enthusiasts of Semantic MediaWiki and related projects, such as Wikidata. Semantic MediaWiki is a family of extensions to the open-source wiki software MediaWiki (best known for powering Wikipedia) that allow a wiki to store structured data in addition to textual content, thereby, turning a wiki into a flexible, collaborative knowledge repository. » READ MORE Natural Language Processing for Web Portals: First release of the Semantic Assistants-Liferay Integration Semantic Assistants Semantic Computing NLP A data portal is a web-based software application, which provides a central entry point to an enormous amount of heterogeneous data sources. These mostly heterogeneous information are aggregated from various sources and presented to users based on their assigned roles. Ideally, an intelligent portal must be able to offer content to users, taking into account contextual information beyond their roles and permissions. Our integration of Semantic Assistants for Liferay allows portals to automatically process textual content using state-of-the-art techniques from the Natural Language Processing (NLP) domain. The SA-Liferay integration aims at bringing the NLP power to this popular portal system and its users in a seamless, user-friendly manner, realized as a ready-to-deploy custom portlet . » READ MORE Proceedings of the 4th Canadian Semantic Web Symposium (CSWS 2013) now at CEUR Semantic Web The complete proceedings of the 4th Canadian Semantic Web Symposium (CSWS 2013) are now available on the CEUR-WS.org website as Volume 1054 . The complete volume contains abstracts for the two invited talks, two full papers, two short papers, five early career track papers, and four systems papers. Individual papers can be downloaded from the CEUR-WS.org site, where you can also find a BibTeX file with all references. » READ MORE » Add new comment 4th Canadian Semantic Web Symposium (CSWS 2013), Montréal, Canada Submitted by rene on Mon, 2013-03-18 11:25 2013 Concordia CSWS Montréal Semantic Web symposium Start: 2013-07-10 Timezone: America/Montreal The Fourth Canadian Semantic Web Symposium will be held at Concordia University, Montreal, Quebec, on July 10, 2013. CSWS 2013 aims to bring together Canadian and international researchers in semantic technologies and knowledge management to discuss issues related to the Semantic Web. The event is part of the Semantic Trilogy 2013 featuring: International Conference on Biomedical Ontologies (ICBO 2013) Canadian Semantic Web Symposium (CSWS 2013) Data Integration in the Life Sciences (DILS 2013) For more information, please refer to: Web: http://www.unbsj.ca/sase/csas/data/ws/csws2013/index.html Twitter: https://twitter.com/CSWS2013 ( @CSWS2013 ) Google+: https://plus.google.com/events/cdkiqq1fuatjplirn5gcvm2i31c Registration: http://www.unbsj.ca/sase/csas/data/ws/semantic-trilogy-2013/registration... » READ MORE » Calendar Wiki-NLP Integration Research in Concordia NOW Newsletter Semantic Assistants Semantic Wiki NLP Our research on Natural Language Processing (NLP) for wiki systems has been featured in Concordia University's NOW newsletter . Explaining the technology and its applications to a general audience, it quickly become one of the most read and shared articles of the week. » READ MORE 1 2 3 4 next › last » Tag Cloud AI Bioinformatics Coreference Resolution Corpora Cultural Heritage Data Fuzzy Sets & Systems German Information Systems Lemmatization Linked Open Data Literature Management NLP Noun Phrase Chunking Ontology Process Modeling Reported Speech Requirements Engineering Semantic Computing Semantic Desktop Semantic Publishing Semantic Web Semantic Wiki Software Engineering Software Evolution Summarization System Architecture Teaching Text Mining Textual Entailment Recognition Traceability more tags @SemSoft's tweets RT @GateAcUk : Early bird registration to GATE training course still available: https://t.co/3zmjIX28E3 — 44 weeks 5 days ago Link up with us during @www2016ca #www2016 https://t.co/xw43mCrzjR — 46 weeks 6 days ago RT @alegonbel : #savesd2016 #www2016 I've created a #storify story for the workshop https://t.co/fpNpSiP2UN — 47 weeks 10 hours ago RT @savesdworkshop : #savesd2016 #www2016 Bahar Sateli on "Semantic User Profiles: Learning Scholars’ Competences by Analyzing [...] " https://t.co/uLs0rWgjqa — 47 weeks 1 day ago RT @shawnmjones : #savesd2016 #www2016 @BaharSateli presents open source workflow for semantic pub experiments https://t.co/t68r1kYRTz https://t.co/INWWpxLu93 — 47 weeks 1 day ago   1 of 23 ›› New Publications Semantic User Profiles: Learning Scholars' Competences by Analyzing their Publications From Papers to Triples: An Open Source Workflow for Semantic Publishing Experiments Semantic representation of scientific literature: bringing claims, contributions and named entities onto the Linked Open Data cloud Automated Quality Assurance of Non-Functional Requirements for Testability Automatic Construction of a Semantic Knowledge Base from CEUR Workshop Proceedings More... Recent blog posts OpenTrace Showcased at the WCRE'12 Conference Wiki-NLP Integration at the WikiSym'12 Conference mycoMINE au 80ème congrès de l'Acfas Text Mining Assistants in Wikis at Biocuration2012 DTMBIO2011 Talk Semantic Assistants at IBM CASCON 2011 mycoMINE at DTMBIO/CIKM 2011 Glasgow NLP Frameworks 2010 Workshop Proceedings now Online Running MutationFinder in GATE using the TaggerFramework PR NLDB 2010 more New forum topics NFR Classifier Pipeline Installation problem OWLExporterDemo Needed Concordia RE corpus How to use Mutation Miner Questions more Blogroll EWRL and NIPS 2016 Ethics, logistic regression, and 0-1 loss Vowpal Wabbit version 8.3 and tutorial Triplifying a real dictionary Visualize PoolParty project data with SKOS Play! in four steps Web 2: But Wait, There's More (And More....) - Best Program Ever. Period. Help Me Interview Reid Hoffman, Founder, LinkedIn (And Win Free Tix to Web 2) Help Me Interview the Founders of Quora (And Win Free Tix to Web 2) Help Me Interview Ross Levinsohn, EVP, Yahoo (And Win Free Tix to Web 2) I Just Made a City... more Syndicate Search Search this site: Research Projects Tools & Resources Publications Blogs Forums Semantic Assistants Durm Wiki Open Positions Contact Semantics for the Masses Except where otherwise noted, all original content on this site is copyright by its author and licensed under a Creative Commons Attribution-Share Alike 2.5 Canada License .
