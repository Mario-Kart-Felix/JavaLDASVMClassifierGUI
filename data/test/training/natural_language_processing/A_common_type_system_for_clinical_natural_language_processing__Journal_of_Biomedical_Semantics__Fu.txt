A common type system for clinical natural language processing | Journal of Biomedical Semantics | Full Text Skip to main content Advertisement Login to your account Search Search BioMed Central articles Search Journal of Biomedical Semantics Impact Factor 1.620 Main menu Home About Articles Submission Guidelines We'd like your opinion about BioMed Central, help us by answering 3 questions Research Open Access A common type system for clinical natural language processing Stephen T Wu 1 Email author , Vinod C Kaggal 1 , Dmitriy Dligach 2 , James J Masanz 1 , Pei Chen 2 , Lee Becker 3 , Wendy W Chapman 4 , Guergana K Savova 2 , Hongfang Liu 1 and Christopher G Chute 1 Journal of Biomedical Semantics 2013 4 :1 DOI: 10.1186/2041-1480-4-1 ©  Wu et al.; licensee BioMed Central Ltd. 2013 Received: 26 June 2012 Accepted: 23 December 2012 Published: 3 January 2013 Abstract Background One challenge in reusing clinical data stored in electronic medical records is that these data are heterogenous. Clinical Natural Language Processing (NLP) plays an important role in transforming information in clinical text to a standard representation that is comparable and interoperable. Information may be processed and shared when a type system specifies the allowable data structures. Therefore, we aim to define a common type system for clinical NLP that enables interoperability between structured and unstructured data generated in different clinical settings. Results We describe a common type system for clinical NLP that has an end target of deep semantics based on Clinical Element Models (CEMs), thus interoperating with structured data and accommodating diverse NLP approaches. The type system has been implemented in UIMA (Unstructured Information Management Architecture) and is fully functional in a popular open-source clinical NLP system, cTAKES (clinical Text Analysis and Knowledge Extraction System) versions 2.0 and later. Conclusions We have created a type system that targets deep semantics, thereby allowing for NLP systems to encapsulate knowledge from text and share it alongside heterogenous clinical data sources. Rather than surface semantics that are typically the end product of NLP algorithms, CEM-based semantics explicitly build in deep clinical semantics as the point of interoperability with more structured data types. Keywords Natural Language Processing Standards and interoperability Clinical information extraction Clinical Element Models Common type system Background Electronic medical records (EMRs) hold immense promise for improving both practice and research. Area 4 of the Strategic Healthcare IT Advanced Research Project (SHARP 4, or SHARPn) aims to reuse data from the EMR, analyzing records on a large scale – an effort known as high throughput phenoytyping. Many large-scale applications are dependent on high throughput phenotyping, such as characterizing the prevalence of a disease, or finding patients who fit the criteria for a clinical or epidemiological study. A prerequisite is that information across patients, areas of practice, and institutions must be comparable and interoperable. SHARP 4 has adopted Intermountain Healthcare’s Clinical Element Models (CEMs) as the standardized format for information aggregation and comparison. This representation is both concrete and specific, yet allows for some of the ambiguity that is inherent in clinicians’ explanation of a clinical situation. However, a significant amount of information in the EMR is not available in any form that could be easily mapped to CEMs. It is no surprise that health care professionals prefer to record a significant proportion of their information in the format of human language, rather than more structured formats like CEMs. Therefore, Natural Language Processing (NLP) techniques are necessary to tap into this extensive source of clinical information. The goals for NLP in SHARPn are to normalize information from clinical text into the structured CEMs, which are more conducive to computation at a large scale. A type system specifies data structures that may be used for the processing and sharing of information. In this work, we define a type system whose key innovation is that it implements a comprehensive model of clinical semantics types, based on CEMs. This deep semantic target is integrated with a comprehensive brush of types for existing language analysis tools, allowing the type system to be used for arbitrary clinical use cases and to be compatible with a diversity of underlying NLP approaches. Therefore, we call it a common type system, with highly structured output semantics intended to interoperate with structured data from the EMR. Additionally, NLP components that use the type system will be interchangeable with each other. The type system was initially designed for practical NLP use in UIMA (Unstructured Information Management Architecture [ 1 ]), which allows for flexible passing of input and output data types between components of an NLP system. Our preliminary work [ 2 ] has been fully adopted by Mayo Clinic’s popular open source NLP tool, cTAKES (clinical Text Analysis and Knowledge Extraction System [ 3 ]), as of cTAKES 2.0. The current work presents a full picture of the type system, alongside a thorough example of how the type system may be used in practice to house SHARPn-style CEMs. Our description is consistent with the implementation in cTAKES v2.5 ( http://sourceforge.net/projects/ohnlp/files/cTAKES/ ). UIMA and type systems UIMA was originally designed by IBM to process text, speech, or video [ 1 ]. Here, we concern ourselves with clinical text as our domain of input. Each clinical document that is processed within UIMA is automatically marked up (annotated) by components called Analysis Engines, which are often arranged in a pipeline. Analysis Engines may be interchanged if they solve the problems and annotate the data in the same way. However, the structure of the markup must be defined in order for Analysis Engines to be interoperable. A type system defines the structure for possible markup, providing the necessary data types for downstream components to make use of partially processed text, and gives upstream components a target representation for markup data. For example, after sentence detection, a document will have identified types called Sentence ; after tokenization, a document will have identified types called WordToken . Each type may have associated features , which give additional information about the structure. For example, a WordToken could have an associated part-of-speech VB (verb). In this article, we will use “feature” and a related term, “attribute,” interchangeably. The data are then passed between Analysis Engines in an efficient framework, the Common Analysis Structure (CAS), which includes the original document, the results of the analysis, and indices for efficient searching of these results. To facilitate outputs from and inputs to UIMA, the CAS can also be efficiently serialized and de-serialized. With this architecture, UIMA enables interoperability between Analysis Engines and encourages a development of “best-of-breed” components. All UIMA-based techniques will have a type system [ 4 – 6 ], and other tools (such as the General Architecture for Text Engineering (GATE) [ 7 ]) typically have analogous schemata for artifacts. Most of these type systems encode the same basic information as our common type system, including types for storing text span annotations, syntax, and document annotations. In a few cases, types and features (e.g., a List structure) were introduced into our common type system based on an analysis of these systems. The reported work within SHARP 4 is an attempt to provide a common type system for diverse NLP use cases centering around clinical texts and domain semantics. Therefore, the our most significant contributions are the extensive semantic model based on CEMs and the separation between textual semantic types and referential (referring to the real-world) semantic types. These contributions enable a development of diverse technologies that serve different clinical use cases. Deep semantics with clinical element models From a linguistic perspective, this common type system embeds a deep semantic representation analogous to those that have been used in the computational semantics and dialogue systems communities [ 8 , 9 ]. It distinguishes between semantic content that refers to real-world phenomena and the textual surface form used to communicate the semantics. However, we might expect the impact of a mature, deep semantic representation for Clinical NLP to be much greater, since this is an enabling technology for many downstream tasks like patient classification and high-throughput phenotyping. Designing the type system to account for these deep semantics as output gives room for technological innovations around the CEM structure. In addition to providing a well-developed semantic data model, the common type system provides a wide range of data types to bridge from text and linguistic structure to deep semantics. In doing so, it allows for downstream access to both the more raw, textual data types and the deeper semantic representation. For SHARPn, six “core CEMs” have been identified and are under continuing development: Anatomical Sites, Diseases and Disorders, Signs and Symptoms, Procedures, Medications, and Labs. A specific CEM for “cough” would have the same basic structure as any other Signs and Symptoms, as defined by the Signs and Symptoms core CEM: <<cetype kind="statement" name="CoughAssert" xmlns=""> <key code="Assertion_KEY_ECID" /> <data domain="CoughType_VALUESET_ECID" type="cwe" /> … <qual card="0-M" name="periodicity" type="Periodicity" /> <qual card="0-1" name="course" type="Course" /> <qual card="0-1" name="severity" type="Severity" /> … <mod card="0-1" name="subject" type="Subject" /> <mod card="0-1" name="negationInd" type="NegationInd" /> <mod card="0-1" name="uncertainty" type="Uncertainty" /> <att card="0-1" name="observed" type="Observed" /> <att card="0-1" name="reportedReceived" type="ReportedReceived" /> <att card="0-1" name="verified" type="Verified" /> </cetype> The basic structure of a CEM consists of a type, a key, and a value choice; qualifiers, modifiers, and attributions give further detail. The Type is a coded value that represents the constraints to which all instances of a given model will conform (e.g., cwe – coded with extensions, or pq – physical quantity). The key is a coded value for the real world concept that is important to what an instance is attempting to describe (e.g., since we are modeling text, Assertion is a common key). Finally, the value choice is a choice between a “data property” or “items,” where the former is a derivative of the HL7 version 3 data type “ANY,” and the latter is a sequence of one or more clinical elements (e.g., “CoughType” is a data property, constraining data values). A qualifier captures information that does not change the meaning of the value choice (e.g., the “periodicity” of a cough). A modifier adds information that changes the meaning of the value choice (e.g., “negationInd” may reverse the asserted CoughType). An attribution defines an action and the contextual information for the action (e.g., “observed” gives the context of the Cough). In the end, this work reports, alongside other NLP-relevant types, a casting of CEMs from the above structure into a UIMA type system. Methods To define our common type system, we began with the types in the cTAKES v1.1 type system. These types had primarily been developed ad hoc while doing information extraction tasks in UIMA. They were therefore loosely arranged around a typical information extraction pipeline (including components such as sentence detection, tokenization, lemmatization, named entity recognition (NER), and negation/status detection). We analyzed a number of existing UIMA type systems to find useful types that caused us to augment or modify the original type definitions. We eventually modified existing types and categorized them into 4 groupings: Utilities, Text Spans, Syntax, and Text Semantics. We also created 3 new groupings: Structured Data, Relations, and Referential Semantics. In this breakdown of 7 groupings, we have ensured that the resulting semantic model distinguishes clearly between text semantics and referential semantics. This distinction is important for several reasons. The NLP task of Named Entity Recognition may define semantics in terms of a semantic type or even a mapping to an ontology code (possible with text semantics types), but additional structure is necessary when populating post-coordination or attribute templates (possible with referential semantics types). Furthermore, there is no clear interpretation for the results of coreference resolution with only text semantics. Especially in the clinical context, a chain of related text mentions does not define an event; for example, if a patient has a severe cough with sputum, but coreferring mentions in the text do not mention the sputum, this does not mean that there is no sputum. Finally, deep semantic structure is necessary because it enables interoperability with all other types of medical information. With this CEM-based referential semantic model, structured data and NLP results can then be used together seamlessly in high-throughput phenotyping efforts. The effort in the type system definition was that of creating types for the referential semantics grouping, in which our goal was to represent the core CEM templates. Notably, we created a separate type for each of the 6 core CEMs. The distinction between qualifiers, modifiers, and attributions in the core CEMs was dropped, and all were considered to be features. Common features between the core CEMs were moved into the Element supertype. The text semantic model was adjusted to complement the referential semantic model. Outside of the semantic model, new types were also created for standard NLP tasks, such as constituent and dependency parsing, relation extraction, and temporal relations. Overall, the type system design attempts to follow best practices for UIMA type systems, as recommended by UIMA’s original developers. These have to do with ease and completeness of representation, as well as computational cost. For example, defining a subtype is an efficient way to subset data because indices for types are reliably calculated. However, we do not put locally used (component-specific) types in the CAS, as there is no garbage collection in UIMA and extra types only bloat the type system. Where possible, we assumed existing standards for NLP tasks (e.g., types for constituent parses should be consistent with Treebank II). Results We present the SHARPn common type system in its entirety, as released with cTAKES 2.5. This type system is an extensive update of the cTAKES type system, with modifications, restructuring, and additions. While there are carry-over types from previous iterations of the cTAKES type systems, use case specific types were dropped, as they would be local to custom components at the end of a pipeline. The type system’s seven groups correspond to 7 namespaces. We will thoroughly describe these groups, focusing especially on syntax, text semantics, relations, and referential semantics with examples to highlight our contribution. Notationally, we introduce types with small caps and in their namespaces (e.g., textspan.Sentence ), but refer to them informally by just capitalizing just the first letter (e.g., Sentence). Features (attributes) of each type are introduced with colons (e.g., Sentence :begin). Using the equivalent data structures outside of UIMA do not strictly require these namespaces or groupings. Also, in the following figures, dark gray boxes indicate types are in a different namespace, but are necessary to fully describe the inheritance of another type (e.g., uima.tcas.Annotation ). Structured data types Unstructured clinical text is generated in the wider context of clinical settings. Structured data can provide useful information about the clinical context, both to improve information extraction and to more easily retrieve results. Structured data types are shown on the left side of Figure 1 . Figure 1 Types and features for 3 namespaces. Structured data types, Utility types, and Text span types. Dark gray background coloring indicates types that are not in the namespace but are included to show inheritance. Arrows indicate inheritance. Utility types This minimal grouping (bottom right, Figure 1 ) replaces a type from cTAKES v1.1 called Property with the util.Pair type. Each Pair: attribute corresponds with some Pair :value, and a util.Pairs type stores multiple ones. This is tacitly a brute-force implementation of a probability distribution as well, hence the util.ProbabilityDistribution type. More efficient means of defining probability distributions are possible, but this is not easily done in a generalizable type system to be used with UIMA. Text span types Text span types shown on the top-right side of Figure 1 are typically discourse-level subdivisions of a text document into organizational components. The type Document spans a whole document and subsumes other text span types. In UIMA implementations of the type system, this Document type is by default available from the UIMA itself (hence the gray box); non-UIMA implementations would need Document to be introduced explicitly. Other types break down the text into spans of decreasing size: textspan.Segment (e.g., sections of a clinical note) , textspan.Paragraph, textspan.List, and textspan.Sentence. Syntactic types The syntax namespace in Figure 2 shows two major groupings: Morphology (light blue) and Syntactic Structure (darker blue). The Morphology grouping deals with the internal characteristics of words and borders between words. It centers around Syntax.BaseToken, a supertype for word, punctuation, symbol, newline, contraction, or number tokens. It includes parts of speech in BaseToken :partOfSpeech, which are grammatical categories, e.g., noun (NN) or preposition (IN) that use Penn Treebank tags a with a few additions. BaseToken :normalizedForm stores a final normalized form, including processes such as lemmatization and abbreviation expansion. Figure 2 The syntax namespace: types for morphology and syntax. Because syntactic processing has been well studied in NLP, the common type system adopts established standards for the majority of its grammatical types. Phrase-level syntactic categories found by the process of shallow parsing (chunking) are stored in Syntax.Chunk types. The Chunk :chunkType feature draws from phrasal Penn Treebank II categories. Many of these phrasal tags ( syntax .ADJP, syntax .NP, syntax .VP, etc.) are included as child types to syntax.Chunk for ease of indexing. More robust syntactic structure is embodied in syntax.ConllDependencyNode, a dependency parse node spanning a single BaseToken. This follows the CONLL-X Shared Task [ 10 ] format with 10 features. Dependency parses are produced sentence-by-sentence. Each node of a parsed sentence refers to its syntactic head, i.e., another ConllDependencyNode pointed to from ConllDependencyNode :head. Like shallow parses, deep (constituent) parses can be represented consistently with Penn Treebank II standards [ 11 ]. Here, we use Syntax.TreebankNode and two convenience subtypes, Syntax.TerminalTreebankNode and Syntax.TopTreebankNode . The syntactic constituent can be found in TreebankNode :nodeType or TreebankNode :nodeValue. Stanford dependencies [ 12 ] are formally triples of two tokens plus the relationship between them. Thus, they are represented as Syntax.StanfordDependency, binary relation types that relate heads to dependents, where the inherited StanfordDependency: arg1 is the head, StanfordDependency: arg2 is the dependent, and StanfordDependency: category stores the type of relation (e.g., nsubj). Textual semantic types The main intent of textual semantic types is for spans of text to house a shallow sense meaning or function. These types are shown in Figure 3 , progressing from simpler meaning on the left to more complex meaning on the right. Figure 3 The textsem namespace: spanned types for shallow semantics. Context-sensitive annotations On the left of Figure 3 , several simple types indicate spans of text that are of use in clinical context. The Textsem.ContextAnnotation type is a lightweight, spanned type that tags the context surrounding an entity or event. It may be used for quick iteration and search. The feature ContextAnnotation: Scope has example values like “left,” “right,” or “both,” indicating on which side of a ContextAnnotation: FocusText the entity or event might be found.
