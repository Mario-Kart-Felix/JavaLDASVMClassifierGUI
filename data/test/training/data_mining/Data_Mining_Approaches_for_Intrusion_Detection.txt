Data Mining Approaches for Intrusion DetectionWenke Lee Salvatore J. StolfoComputer Science DepartmentColumbia University500 West 120th Street, New York, NY 10027wenke,salcs.columbia.eduAbstractIn this paper we discuss our research in developing general and systematic methods for intrusion detection. Thekey ideas are to use data mining techniques to discoverconsistent and useful patterns of system features that describe program and user behavior, and use the set of relevant system features to compute inductively learnedclassifiers that can recognize anomalies and known intrusions. Using experiments on the sendmail system calldata and the network tcpdump data, we demonstrate thatwe can construct concise and accurate classifiers to detect anomalies. We provide an overview on two generaldata mining algorithms that we have implemented theassociation rules algorithm and the frequent episodes algorithm. These algorithms can be used to compute theintra and inter audit record patterns, which are essentialin describing program or user behavior. The discoveredpatterns can guide the audit data gathering process andfacilitate feature selection. To meet the challenges ofboth efficient learning mining and realtime detection,we propose an agentbased architecture for intrusion detection systems where the learning agents continuouslycompute and provide the updated detection models tothe detection agents.1 IntroductionAs networkbased computer systems play increasinglyvital roles in modern society, they have become the targets of our enemies and criminals. Therefore, we needto find the best ways possible to protect our systems.The security of a computer system is compromised whenThis research is supported in part by grants from DARPAF306029610311 and NSF IRI9632225 and CDA9625374an intrusion takes place. An intrusion can be definedHLMS90 as any set of actions that attempt to compromise the integrity, confidentiality or availability ofa resource. Intrusion prevention techniques, such asuser authentication e.g. using passwords or biometrics,avoiding programming errors, and information protection e.g., encryption have been used to protect computer systems as a first line of defense. Intrusion prevention alone is not sufficient because as systems becomeever more complex, there are always exploitable weakness in the systems due to design and programming errors, or various socially engineered penetration techniques. For example, after it was first reported manyyears ago, exploitable buffer overflow still exists insome recent system software due to programming errors. The policies that balance convenience versus strictcontrol of a system and information access also make itimpossible for an operational system to be completelysecure.Intrusion detection is therefore needed as another wallto protect computer systems. The elements central tointrusion detection are resources to be protected in atarget system, i.e., user accounts, file systems, systemkernels, etc models that characterize the normal orlegitimate behavior of these resources techniques thatcompare the actual system activities with the establishedmodels, and identify those that are abnormal or intrusive.Many researchers have proposed and implemented different models which define different measures of systembehavior, with an ad hoc presumption that normalcy andanomaly or illegitimacy will be accurately manifestedin the chosen set of system features that are modeled andmeasured. Intrusion detection techniques can be categorized into misuse detection, which uses patterns of wellknown attacks or weak spots of the system to identifyintrusions and anomaly detection, which tries to determine whether deviation from the established normal usage patterns can be flagged as intrusions.Misuse detection systems, for example KS95 andSTAT IKP95, encode and match the sequence of signature actions e.g., change the ownership of a file ofknown intrusion scenarios. The main shortcomings ofsuch systems are known intrusion patterns have to behandcoded into the system they are unable to detectany future unknown intrusions that have no matchedpatterns stored in the system.Anomaly detection subsystems, such asIDES LTG92, establish normal usage patternsprofiles using statistical measures on system features,for example, the CPU and IO activities by a particularuser or program. The main difficulties of these systemsare intuition and experience is relied upon in selectingthe system features, which can vary greatly amongdifferent computing environments some intrusions canonly be detected by studying the sequential interrelationbetween events because each event alone may fit theprofiles.Our research aims to eliminate, as much as possible, themanual and adhoc elements from the process of building an intrusion detection system. We take a datacentricpoint of view and consider intrusion detection as a dataanalysis process. Anomaly detection is about finding thenormal usage patterns from the audit data, whereas misuse detection is about encoding and matching the intrusion patterns using the audit data. The central theme ofour approach is to apply data mining techniques to intrusion detection. Data mining generally refers to theprocess of automatically extracting models from largestores of data FPSS96. The recent rapid developmentin data mining has made available a wide variety of algorithms, drawn from the fields of statistics, pattern recognition, machine learning, and database. Several types ofalgorithms are particularly relevant to our researchClassification maps a data item into one of several predefined categories. These algorithms normally output classifiers, for example, in the form of decision trees or rules. An ideal application in intrusiondetection will be to gather sufficient normal andabnormal audit data for a user or a program, thenapply a classification algorithm to learn a classifierthat will determine future audit data as belongingto the normal class or the abnormal classLink analysis determines relations between fields inthe database. Finding out the correlations in auditdata will provide insight for selecting the right setof system features for intrusion detectionSequence analysis models sequential patterns. Thesealgorithms can help us understand what timebased sequence of audit events are frequently encountered together. These frequent event patternsare important elements of the behavior profile of auser or program.We are developing a systematic framework for designing, developing and evaluating intrusion detection systems. Specifically, the framework consists of a set ofenvironmentindependent guidelines and programs thatcan assist a system administrator or security officer to select appropriate system features from audit datato build models for intrusion detection architect a hierarchical detector system from component detectors update and deploy new detection systems asneeded.The key advantage of our approach is that it can automatically generate concise and accurate detection models from large amount of audit data. The methodologyitself is general and mechanical, and therefore can beused to build intrusion detection systems for a wide variety of computing environments.The rest of the paper is organized as follows Section 2 describes our experiments in building classification models for sendmail and network traffic. Section 3presents the association rules and frequent episodes algorithms that can be used to compute a set of patternsfrom audit data. Section 4 briefly highlights the architecture of our proposed intrusion detection system. Section 5 outlines our future research plans.2 Building Classification ModelsIn this section we describe in detail our experimentsin constructing classification models for anomaly detection. The first set of experiments, first reported inLSC97, is on the sendmail system call data, and thesecond is on the network tcpdump data.2.1 Experiments on sendmail DataThere have been a lot of attacks on computer systemsthat are carried out as exploitations of the design andprogramming errors in privileged programs, those thatcan run as root. For example, a flaw in the finger daemon allows the attacker to use buffer overflow to trickthe program to execute his malicious code. Recent research efforts by Ko et al. KFL94 and Forrest et al.FHSL96 attempted to build intrusion detection systemsthat monitor the execution of privileged programs anddetect the attacks on their vulnerabilities. Forrest et al.discovered that the short sequences of system calls madeby a program during its normal executions are very consistent, yet different from the sequences of its abnormalexploited executions as well as the executions of otherprograms. Therefore a database containing these normal sequences can be used as the self definition of thenormal behavior of a program, and as the basis to detect anomalies. Their findings motivated us to search forsimple and accurate intrusion detection models.Stephanie Forrest provided us with a set of traces of thesendmail program used in her experiments FHSL96.We applied machine learning techniques to produceclassifiers that can distinguish the exploits from the normal runs.2.1.1 The sendmail System Call TracesThe procedure of generating the sendmail traces weredetailed in FHSL96. Briefly, each file of the tracedata has two columns of integers, the first is the processids and the second is the system call numbers. Thesenumbers are indices into a lookup table of system callnames. For example, the number 5 represents systemcall open. The set of traces includeNormal traces a trace of the sendmail daemon and aconcatenation of several invocations of the sendmail programAbnormal traces 3 traces of the sscp sunsendmailcpattacks, 2 traces of the syslogremote attacks, 2traces of the sysloglocal attacks, 2 traces of the decode attacks, 1 trace of the sm5x attack and 1 traceof the sm565a attack. These are the traces of various kinds of abnormal runs of the sendmail program.2.1.2 Learning to Classify System Call SequencesIn order for a machine learning program to learn the classification models of the normal and abnormal system call sequences, we need to supply it with a set ofSystem Call Sequences length 7 Class Labels4 2 66 66 4 138 66 normal... ...5 5 5 4 59 105 104 abnormal... ...Table 1 Prelabeled System Call Sequences of Length 7training data containing prelabeled normal and abnormal sequences. We use a sliding window to scanthe normal traces and create a list of unique sequencesof system calls. We call this list the normal list. Next,we scan each of the intrusion traces. For each sequenceof system calls, we first look it up in the normal list. Ifan exact match can be found then the sequence is labeledas normal. Otherwise it is labeled as abnormal notethat the data gathering process described in FHSL96ensured that the normal traces include nearly all possiblenormal short sequences of system calls, as new runs of  failed to generate new sequences. Needlessto say all sequences in the normal traces are labeled asnormal. See Table 1 for an example of the labeled sequences. It should be noted that an intrusion trace contains many normal sequences in addition to the abnormalsequences since the illegal activities only occur in someplaces within a trace.We applied RIPPER Coh95, a rule learning program,to our training data. The following learning tasks wereformulated to induce the rule sets for normal and abnormal system call sequences Each record has  positional attributes,  ,   , . . . ,  , one for each of the system calls in a sequence oflength  plus a class label, normal or abnormal The training data is composed of normal sequencestaken from  of the normal traces, plus the abnormal sequences from 2 traces of the  attacks,1 trace of the sysloglocal attack, and 1 trace of thesyslogremote attack The testing data includes both normal and abnormaltraces not used in the training data.RIPPER outputs a set of ifthen rules for the minorityclasses, and a default true rule for the remaining class.The following exemplar RIPPER rules were generatedfrom the system call datanormal    ,    . meaning if  is 104    and   is 112   thenthe sequence is normalnormal    ,    . meaning if  is 19  and   is 105   then thesequence is normal. . .abnormal true. meaning if none of theabove, the sequence is abnormalThese RIPPER rules can be used to predict whether a sequence is abnormal or normal. But what the intrusion detection system needs to know is whether the tracebeing analyzed is an intrusion or not. We use the following postprocessing scheme to detect whether a giventrace is an intrusion based on the RIPPER predictions ofits constituent sequences1. Use a sliding window of length  , e.g., 7, 9, 11,13, etc., and a sliding shift step of , to scan thepredictions made by the RIPPER rules on systemcall sequences.2. For each of the length    regions of RIPPERpredictions generated in Step , if more than  predictions are abnormal then the current region ofpredictions is an abnormal region. Note that  isan input parameter.3. If the percentage of abnormal regions is above athreshold value, say  , then the trace is an intrusion.This scheme is an attempt to filter out the spurious prediction errors. The intuition behind this scheme is thatwhen an intrusion actually occurs, the majority of adjacent system call sequences are abnormal whereas theprediction errors tend to be isolated and sparse. InFHSL96, the percentage of the mismatched sequencesout of the total number of matches lookups performedfor the trace is used to distinguish normal from abnormal. The mismatched sequences are the abnormal sequences in our context. Our scheme is different in thatwe look for abnormal regions that contain more abnormal sequences than the normal ones, and calculate thepercentage of abnormal regions out of the total numberof regions. Our scheme is more sensitive to the temporal information, and is less sensitive to noise errors.RIPPER only outputs rules for the minority class. Forexample, in our experiments, if the training data hasfewer abnormal sequences than the normal ones, theoutput RIPPER rules can be used to identify abnormalsequences, and the default everything else predictionis normal. We conjectured that a set of specific rulesfor normal sequences can be used as the identity ofa program, and thus can be used to detect any knownand unknown intrusions anomaly intrusion detection.Whereas having only the rules for abnormal sequencesonly gives us the capability to identify known intrusionsmisuse intrusion detection. abn.  abn. in experimentTraces FHSL96 A B C Dsscp1 5.2 41.9 32.2 40.0 33.1sscp2 5.2 40.4 30.4 37.6 33.3sscp3 5.2 40.4 30.4 37.6 33.3syslogr1 5.1 30.8 21.2 30.3 21.9syslogr2 1.7 27.1 15.6 26.8 16.5syslogl1 4.0 16.7 11.1 17.0 13.0syslogl2 5.3 19.9 15.9 19.8 15.9decode1 0.3 4.7 2.1 3.1 2.1decode2 0.3 4.4 2.0 2.5 2.2sm565a 0.6 11.7 8.0 1.1 1.0sm5x 2.7 17.7 6.5 5.0 3.0  0 1.0 0.1 0.2 0.3Table 2 Comparing Detection of Anomalies. The column FHSL96 is the percentage of the abnormal sequences of the traces. Columns A, B, C, and D arethe percentages of abnormal regions as measured bythe postprocessing scheme of the traces. is the  normal traces not used in the training data.Traces in bold were included in the training data, theother traces were used as testing data only.We compare the results of the following experiments thathave different distributions of abnormal versus normalsequences in the training dataExperiment A  normal and  abnormal, sequence length is 11Experiment B  normal and  abnormal, sequence length is 7Experiment C  abnormal and  normal, sequence length is 11Experiment D  abnormal and  normal, sequence length is 7.Table 2 shows the results of using the classifiers fromthese experiments to analyze the traces. We report herethe percentage of abnormal regions as measured by ourpostprocessing scheme of each trace, and compare ourresults with Forrest et al., as reported in FHSL96.From Table 2, we can see that in general, intrusion tracesgenerate much larger percentages of abnormal regionsthan the normal traces. We call these measured percentages the scores of the traces. In order to establish athreshold score for identifying intrusion traces, it is desirable that there is a sufficiently large gap between thescores of the normal sendmail traces and the lowendscores of the intrusion traces. Comparing experimentsthat used the same sequence length, we observe that sucha gap in A,  , is larger than the gap in C,   and  in B is larger than   in D. The RIPPER rules fromexperiments A and B describe the patterns of the normal sequences. Here the results show that these rulescan be used to identify the intrusion traces, includingthose not seen in the training data, namely, the decodetraces, the sm565a and sm5x traces. This confirms ourconjecture that rules for normal patterns can be used foranomaly detection. The RIPPER rules from experimentsC and D specify the patterns of abnormal sequences inthe intrusion traces included in the training data. Theresults indicate that these rules are very capable of detecting the intrusion traces of the known types thoseseen in the training data, namely, the sscp3 trace, thesyslogremote2 trace and the sysloglocal2 trace. Butcomparing with the rules from A and B, the rules in Cand D perform poorly on intrusion traces of unknowntypes. This confirms our conjecture that rules for abnormal patterns are good for misuse intrusion detection, butmay not be as effective in detecting future unknownintrusions.The results from Forrest et al. showed that their methodrequired a very low threshold in order to correctly detectthe  and   intrusions. While the resultshere show that our approach generated much strongersignals of anomalies from the intrusion traces, itshould be noted that their method used all of the normaltraces but not any of the intrusion traces in training.2.1.3 Learning to Predict System CallsUnlike the experiments in Section 2.1.2 which requiredabnormal traces in the training data, here we wanted tostudy how to compute an anomaly detector given just thenormal traces. We conducted experiments to learn thenormal correlation among system calls the  th systemcalls or the middle system calls in normal sequences oflength  .The learning tasks were formulated as follows Each record has    positional attributes,  ,   ,. . . ,  , each being a system call plus a class label, the system call of the th position or the middleposition The training data is composed of normal sequences taken from  of the normal sendmailtraces The testing data is the traces not included in thetraining data, namely, the remaining  of thenormal sendmail traces and all the intrusion traces.RIPPER outputs rules in the following form38     ,    . meaning if   is 40 and   is 4   , then the 7th systemcall is 38 .. . .5 true. meaning if none of the above, thenthe 7th system calls is 5  .Each of these RIPPER rules has some confidence information the number of matched examples recordsthat conform to the rule and the number of unmatchedexamples records that are in conflict with the rule in thetraining data. For example, the rule for 38  covers 12 matched examples and 0 unmatched examples.We measure the confidence value of a rule as the number of matched examples divided by the sum of matchedand unmatched examples. These rules can be used to analyze a trace by examining each sequence of the trace. Ifa violation occurs the actual system call is not the sameas predicted by the rule, the score of the trace is incremented by 100 times the confidence of the violatedrule. For example, if a sequence in the trace has    and    , but     instead of 38, the total scoreof the trace is incremented by 100 since the confidencevalue of this violated rule is 1. The averaged score bythe total number of sequences of the trace is then usedto decide whether an intrusion has occurred.Table 3 shows the results of the following experimentsExperiment A predict the 11th system callExperiment B predict the middle system call in a sequence of length 7Experiment C predict the middle system call in a sequence of length 11Experiment D predict the 7th system call.We can see from Table 3 that the RIPPER rules fromexperiments A and B are effective because the gap between the score of normal sendmail and the lowendscores of intrusion traces, 3.9, and 3.3 respectively, arelarge enough. However, the rules from C and D performpoorly. Since C predicts the middle system call of a sequence of length 11 and D predicts the 7th system call,we reason that the training data the normal traces hasno stable patterns for the 6th or 7th position in systemcall sequences.averaged score of violationsTraces Exp. A Exp. B Exp. C Exp. Dsscp1 24.1 13.5 14.3 24.7sscp2 23.5 13.6 13.9 24.4sscp3 23.5 13.6 13.9 24.4syslogr1 19.3 11.5 13.9 24.0syslogr2 15.9 8.4 10.9 23.0syslogl1 13.4 6.1 7.2 19.0syslogl2 15.2 8.0 9.0 20.2decode1 9.4 3.9 2.4 11.3decode2 9.6 4.2 2.8 11.5sm565a 14.4 8.1 9.4 20.6sm5x 17.2 8.2 10.1 18.0  5.7 0.6 1.2 12.6Table 3 Detecting Anomalies using Predicted SystemCalls. Columns A, B, C, and D are the averaged scoresof violations of the traces.   is the  normaltraces not used in the training data. None of the intrusiontraces was used in training.2.1.4 DiscussionOur experiments showed that the normal behavior of aprogram execution can be established and used to detect its anomalous usage. This confirms the results ofother related work in anomaly detection. The weaknessof the model in FHSL96 may be that the recorded rotelearned normal sequence database may be too specificas it contains     entries. Here we show that a machine learning program, RIPPER, was able to generalizethe system call sequence information, from  of thenormal sequences, to a set of concise and accurate rulesthe rule sets have 200 to 280 rules, and each rule has2 or 3 attribute tests. We demonstrated that these ruleswere able to identify unseen intrusion traces as well asnormal traces.We need to search for a more predictive classificationmodel so that the anomaly detector has higher confidence in flagging intrusions. Improvement in accuracycan come from adding more features, rather than justthe system calls, into the models of program execution.For example, the directories and the names of the filestouched by a program can be used. In Fra94, it is reported that as the number of features increases from 1 to3, the classification error rate of their network intrusiondetection system decreases dramatically. Furthermore,the error rate stabilizes after the size of the feature setreaches 4, the optimal size in their experiments. Manyoperating systems provide auditing utilities, such as theBSM audit of Solaris, that can be configured to collectabundant information with many features of the activities in a host system. From the audit trails, information about a process program or a user can then beextracted. The challenge now is to efficiently computeaccurate patterns of programs and users from the auditdata.A key assumption in using a learning algorithm foranomaly detection and to some degree, misuse detection is that the training data is nearly complete withregard to all possible normal behavior of a programor user. Otherwise, the learned detection model can notconfidently classify or label an unmatched data as abnormal since it can just be an unseen normal data.For example, the experiments in Section 2.1.3 used of normal system call sequences whereas the experiments in Section 2.1.2 actually required all normal sequences in order to prelabel the abnormal sequencesto create the training data. During the audit data gathering process, we want to ensure that as much differentnormal behavior as possible is captured. We first needto have a simple and incremental continuously learning summary measure of an audit trail so that we canupdate this measure as each new audit trail is processed,and can stop the audit process when the measure stabilizes. In Section 3, we propose to use the frequent intraand inter audit record patterns as the summary measureof an audit trail, and describe the algorithms to computethese patterns.2.2 Experiments on tcpdump DataThere are two approaches for network intrusion detection one is to analyze the audit data on each host of thenetwork and correlate the evidence from the hosts. Theother is to monitor the network traffic directly using apacket capturing program such as tcpdump JLM89. Inthis section, we describe how classifiers can be inducedfrom tcpdump data to distinguish network attacks fromnormal traffic.2.2.1 The tcpdump DataWe obtained a set of tcpdump data, available viahttp at iris.cs.uml.edu8080network.html, that ispart of an Information Exploration Shootout seehttpiris.cs.uml.edu8080. tcpdump was executed onthe gateway that connects the enterprise LAN and theexternal networks. It captured the headers not the userdata of the network packets that passed by the networkinterface of the gateway. Network traffic between theenterprise LAN and external networks, as well as thebroadcast packets within the LAN were therefore collected. For the purposes of the shootout, filters wereused so that tcpdump only collected Internet Transmission Control Protocol TCP and Internet User DatagramProtocol UDP packets. The data set consists of 3 runsof tcpdump on generated network intrusions1 and onetcpdump run on normal network traffic with no intrusions. The output of each tcpdump run is in a separate file. The traffic volume number of network connections of these runs are about the same. Our experimentsfocused on building an anomaly detection model fromthe normal dataset.Since tcpdump output is not intended specifically for security purposes, we had to go through multiple iterationsof data preprocessing to extract meaningful features andmeasures. We studied TCPIP and its security relatedproblems, for example Ste84, Pax97, ABH96, Pax98,Bel89, PV98, for guidelines on the protocols and theimportant features that characterize a connection.2.2.2 Data PreprocessingWe developed a script to scan each tcpdump data fileand extract the connection level information about thenetwork traffic. For each TCP connection, the script processes packets between the two ports of the participatinghosts, and checks whether 3way handshake has been properlyfollowed to establish the connection. The following errors are recorded connection rejected, connection attempted but not established the initiatinghost never receives a SYN acknowledgment, andunwanted SYN acknowledgment received no connection request, a SYN packet, was sent first, monitors each data packet and ACK packet, keepsa number of counters in order to calculate thesestatistics of the connection resent rate, wrong resent rate, duplicate ACK rate, hole rate, wrongdata packet size rate, data bytes sent in each direction, percentage of data packet, and percentageof control packet, and watches how connection is terminated normalboth sides properly send and receive FINs, abortone host sends RST to terminate, and all data pack1Note that, to this date, the organizers of the shootout have notprovided us with information, i.e., the times, targets, and actions, ofthese network intrusions.ets are properly ACKed, half closed only one hostsends FIN, and disconnected.Since UDP is connectionless no connection state, wesimply treat each packet as a connection.A connection record, in preparation of data mining, nowhas the following fields features start time, duration,participating hosts, ports, the statistics of the connectione.g., bytes sent in each direction, resent rate, etc., flagnormal or one of the recorded connectionterminationerrors, and protocol TCP or UDP. From the ports, weknow whether the connection is to a wellknown service,e.g., http port 80, or a user application.We call the host that initiates the connection, i.e., theone that sends the first SYN, as the source, and the otheras the destination. Depending on the direction from thesource to the destination, a connection is in one of thethree types outgoing  from the LAN to the external networks incoming  from the external networksto the LAN and interLAN  within the LAN. Takingthe topologies of the network into consideration is important in network intrusion detection. Intuitively, intrusions which come from outside may first exhibit someabnormal patterns e.g., penetration attempts in the incoming connections, and subsequently in the interLANe.g., doing damage to the LAN andor the outgoinge.g., stealinguploading data connections. Analyzingthese types of connections and constructing corresponding detection models separately may improve detectionaccuracy.2.2.3 Experiments and ResultsFor each type direction of the connections, we formulated the classification experiments as the following Each connection record uses the destination service port as the class label, and all the other connection features as attributes The training data is  of the connections fromthe normal tcpdump data file, while the test dataincludes the remaining  from the normal tcpdump data file, and all the connections from the 3tcpdump data files marked as having embedded attacks 5fold cross validation evaluation is reported here.The process training and testing is repeated 5times, each time using a different  of the normal data as the training data and accordingly the misclassification by traffic typeData outgoing incoming interLANnormal 3.91 4.68 4intrusion1 3.81 6.76 22.65intrusion2 4.76 7.47 8.7intrusion3 3.71 13.7 7.86Table 4 Misclassification Rate on Normal and Intrusion Data. Separate classifiers were trained and testedon connection data of each traffic type. normal is the data set aside from the training data. No intrusiondata was used for training.different remaining  of the normal data as partof the test data, and the averaged accuracy of theclassifiers from the 5 runs is reported.We again applied RIPPER to the connection data. Theresulting classifier characterizes the normal patterns ofeach service in terms of the connection features. Whenusing the classifier on the testing data, the percentage ofmisclassifications on each tcpdump data set is reported.Here a misclassification is the situation where the theclassifier predicts a destination service according to theconnection features that is different from the actual.This misclassification rate should be very low for normal connection data and high for intrusion data. Theintuition behind this classification model is straightforward when intrusions take place, the features characteristics of connections to certain services, for example,ftp, are different from the normal traffic patterns of thesame service.The results from the first round of experiments, as shownin Table 4, were not very good the differences in themisclassification rates of the normal and intrusion datawere small, except for the interLAN traffic of some intrusions.We then redesigned our set of features by adding somecontinuous and intensity measures into each connectionrecord Examining all connections in the past  seconds,and counting the number of connection establishment errors e.g., connection rejected, all othertypes of errors e.g., disconnected, connectionsto designated system services e.g., ftp, connections to user applications, and connections to thesame service as the current connection Calculate for the past  seconds, the perconnectionaverage duration and data bytes on both directionsof all connections, and the same averages of con misclassification by traffic typeData outgoing incoming interLANnormal 0.88 0.31 1.43intrusion1 2.54 27.37 20.48intrusion2 3.04 27.42 5.63intrusion3 2.32 42.20 6.80Table 5 Using TemporalStatistical Measures to Improve Classification Accuracy. Here the time interval is30 seconds.00.050.10.150.20.250.30.350.40.450 10 20 30 40 50 60 70 80 90Misclassification rateWindow sizenormal   intrusion1   intrusion2   intrusion3   Figure 1 Effects of Window Sizes on MisclassificationRatesnections to the same service.These additional temporalstatistical features provideadditional information of the network activity from acontinuous perspective, and provide more insight intoanomalies. For example, a low rate of error due to innocent attempts and network glitches in a short time span isexpected, but an excess beyond the averaged norm indicates anomalous activity. Table 5 shows the improvement of adding these features. Here, using a time interval of 30 seconds i.e.,   , we see that the misclassification rates on the intrusion data are much higherthan the normal data, especially for the incoming traffic.The RIPPER rule set the classifier has just 9 rules and25 conditions. For example, one rule says if the averagenumber of bytes from source to destination of the connections to the same service is 0, and the percentage ofcontrol packets in the current connection is  , thenthe service is auth.To understand the effects of the time intervals on themisclassification rates, we ran the experiments usingvarious time intervals 5s, 10s, 30s, 60s, and 90s. Theeffects on the outgoing and interLAN traffic were verysmall. However, as Figure 1 shows, for the incomingtraffic, the misclassification rates on the intrusion dataincrease dramatically as the time interval goes from 5sto 30s, then stabilizes or tapers off afterwards.2.2.4 DiscussionWe learned some important lessons from the experiments on the tcpdump data. First, when the collecteddata is not designed specifically for security purposes orcan not be used directly to build a detection model, aconsiderable amount of iterative data preprocessing isrequired. This process fundamentally requires a lot ofdomain knowledge, and may not be easily automated.Second, in general, adding temporalstatistical featurescan improve the accuracy of the classification model.There are also much needed improvements to our currentapproach First, deciding upon the right set of featuresis difficult and time consuming. For example, many trials were attempted before we came up with the currentset of features and time intervals. We need useful toolsthat can provide insight into the patterns that may be exhibited in the data. Second, we should provide tools thatcan help administrative staff understand the nature of theanomalies.2.3 Combining Multiple ClassifiersThe classifiers described in this section each models asingle aspect of the system behavior. They are what wecall the base single level classifiers. Combining evidence from multiple base classifiers that each modelsdifferent aspect of the target system is likely to improvethe effectiveness in detecting intrusions. For example, inaddition to the classifier for network traffic using tcpdump data, we can include the classifiers on the commands issued during the connection sessions of wellknown services, e.g. ftp, telnet etc. The combined evidence of anomalous traffic patterns and session behaviorleads to a more accurate assertion that the network isunder attack. A priority in our research plan is to studyand experiment with inductively learned classificationmodels that combine evidence from multiple base detection models. The general approach in learning such ametadetection model can be summarized as follows Build base classifiers that each models different aspect of the target system Formulate the meta learning task each record inthe training data is a collection of the evidencegenerated at the same time period from the baseclassifiers each attribute value in a record is 1 or 0,the prediction evidence from a base classifier thatthe modeled behavior is normal or abnormali.e., it fits the model or not. Apply a learning algorithm to produce the metaclassifier.The meta detection model is actually a hierarchy of detection models. At the bottom, the base classifiers takeaudit data as input and output evidence to the meta classifier, which in turn outputs the final assertion.Our research activities in JAM SPT97, which focuson the accuracy and efficiency of meta classifiers, willcontribute significantly to our effort in building meta detection models.3 Mining Patterns from Audit DataIn order to construct an accurate effective base classifier, we need to gather a sufficient amount of trainingdata and identify a set of meaningful features. Both ofthese tasks require insight into the nature of the auditdata, and can be very difficult without proper tools andguidelines. In this section we describe some algorithmsthat can address these needs. Here we use the term audit data to refer to general data streams that have beenproperly processed for detection purposes. An exampleof such data streams is the connection record data extracted from the raw tcpdump output.3.1 Association RulesThe goal of mining association rules is to derive multifeature attribute correlations from a database table.A simple yet interesting commercial application of theassociation rules algorithm is to determine what itemsare often purchased together by customers, and usethat information to arrange store layout. Formally,given a set of records, where each record is a setof items, an association rule is an expression   SA95.andare subsets of the items in a record, support is the percentageof records that contain, whereas confidence is     . For example, an association rule from theshell command history file which is a stream of commands and their arguments of a user is        which indicates that  of the time when the user invokes  , he or she is reading the news in    ,and reading this newsgroup accounts for  of the activities recorded in his or her command history file. Here  is the confidence and   is the  .The motivation for applying the association rules algorithm to audit data are Audit data can be formatted into a database tablewhere each row is an audit record and each columnis a field system feature of the audit records There is evidence that program executions and useractivities exhibit frequent correlations among system features. For example, one of the reasons thatprogram policies, which codify the access rightsof privileged programs, are concise and capable todetect known attacks KFL94 is that the intendedbehavior of a program, e.g.,  and    filesfrom certain directories with specific permissions,is very consistent. These consistent behaviors canbe captured in association rules We can continuously merge the rules from a newrun to the aggregate rule set of all previous runs.Our implementation follows the general associationrules algorithm, as described in Sri96.3.2 Frequent EpisodesWhile the association rules algorithm seeks to find intraaudit record patterns, the frequent episodes algorithm, asdescribed in MTV95, can be used to discover inter audit record patterns. A frequent episode is a set of eventsthat occur frequently within a time window of a specified length. The events must occur together in at leasta specified minimum frequency,    , sliding timewindow. Events in a  episode must occur in partialorder in time whereas for a   episode there is nosuch constraint. Forandwhereis a frequentepisode,  with       and       is called a frequentepisode rule. An example frequent serial episode rulefrom the log file of a departments Web site is        which indicates that when the home page and the research guide are visited in that order, in  of thecases the theory groups page is visited subsequentlywithin the same 30s time window, and this sequence ofvisits occurs  of the total the 30s time windows inthe log file that is, approximately  of all the records.We seek to apply the frequent episodes algorithm toanalyze audit trails since there is evidence that thesequence information in program executions and usercommands can be used to build profiles for anomaly detection FHSL96, LB97. Our implementation followedthe description in MTV95.3.3 Using the Discovered PatternsThe association rules and frequent episodes can be usedto guide the audit process. We run a program manytimes and under different settings. For each new run,we compute its rule set that consists of both the association rules and the frequent episodes from the audittrail, and update the existing aggregate rule sets usingthe following merge process For each rule in the new rule set find a match in theaggregate rule set. A match is defined as the exactmatches on both the LHS and RHS of the rules,plus  matches using ranges, on the   or  and   values If a match is found, increment the  of the matched rule in the aggregate rule set.Otherwise, add the new rule and initialize its to be 1.When the rule set stabilizes there are no new rulesadded, we can stop the data gathering process since wehave produced a near complete set of audit data for thenormal runs. We then prune the rule set by eliminatingthe rules with low  , according to a userdefined threshold on the ratio of   over thetotal number of audit trails. The system builders canthen use the correlation information in this final profile rule set to select a subset of the relevant features forthe classification tasks. We plan to build a support environment to integrate the process of user selection offeatures, computing a classifier according to the feature set, and presenting the performance of the classifier. Such a support system can speed up the iterativefeature selection process, and help ensure the accuracyof a detection model.We believe that the discovered patterns from the extensively gathered audit data can be used directly foranomaly detection. We compute a set of association0501001502002503000 20 40 60 80 100 120 140 160 180 200Number of Frequent EpisodesWindow sizeraw episode      serial episode rule 0.8      serial episode rule 0.6      Figure 2 Effects of Window Sizes on the Number ofFrequent Episodes.rules and frequent episodes from a new audit trail, andcompare it with the established    rule set. Scoringfunctions can be used to evaluate the deviation scoresfor missing rules with high  , violation sameantecedent but different consequent of rules with high and  , new unseen rules, and significant changes in   of rules.3.3.1 tcpdump Data RevisitedWe ran some preliminary experiments using our association rules and frequent episodes programs on the tcpdump data that was used in the experiments described inSection 2.2.We wanted to study how the frequent episodes algorithmcan help us determine the time window used in gathering temporalstatistical features. We ran the algorithmon the normal incoming connection records withoutthe temporalstatistical features. We set the programto produce two types of output  serial and parallel episodes no rules were generated and serial episoderules. For  episodes, we used      . Andfor serial episode rules, we used       and    and  . We used different time window sizes   2s, 5s, 10s, 15s, 30s, 45s, 60s, 90s,120s, 150s, and 200s and recorded the number of frequent episodes generated on each   . In Figure 2 wesee that the number of frequent episodes  episodesor serial episode rules increases sharply as   goesfrom 2s to 30s, it then gradually stabilizes note that bythe nature of the frequent episodes algorithm, the number of episodes can only increase as   increases. Thisphenomenon coincides with the trends in Figure 1. Notethat here we made the particular choice of the parameters i.e.,    ,    only for the purpose ofcontrolling the maximum size of the episode rule set.Different settings exhibited the same phenomenon. Weconjecture and will verify with further experiments onother data sets that we can use this technique to analyze data streams and automatically discover the mostimportant temporal measure the time window size, i.e.,the period of time within which to measure appropriatestatistical features to maximize classifier accuracy. Intuitively, the first requirement of a time window size isthat its set of sequence patterns is stable, that is, sufficient patterns are captured and noise is small.We also ran both the association rules and frequentepisodes programs on all the incoming connection data,and compared the rule sets from the normal data with theintrusion data. The purpose of this experiment was to determine how these programs can provide insight into thepossible patterns of intrusions. The frequent episodesgenerated were serial episode rules with    ,     and     . The associationsrules were generated using       and    . We manually examined andcompared the rule sets to look for unique patterns thatexist in the intrusion data but not in the normal data.Here are some resultsintrusion1 the unique serial rules are related to ftpdata as the source application, for example,src srv  ftpdata, src srv  userapps src srv  ftpdata 0.96,0.11, 30sThis rule means when a connection with a user application as the source service follows a connectionwith ftpdata, of the cases, a connection withftpdata follows and falls into the same time window 30s and this patterns occur  of the time.The unique association rules are related to destination service is a user application, for example,dst srv  userapps duration  0,dst to src bytes  0 0.9, 0.33This rule means when the destination service of aconnection is a user application, of the cases,the duration and the number of data bytes from thedestination to the source are both 0 and this patternoccurs  of the time.intrusion2 the results are nearly identical to in terms of the unique serial rules andassociation rules.intrusion3 the unique serial rules are related to authas the destination service, for example,dst srv  auth flag  unwanted syn ack 0.82, 0.1, 30sanddst srv  auth dst srv  userapps, dst srv  auth 0.82, 0.1,30sThere are a significant number of unique association rules in regard to smtp is the source application. Many of these rules suggest connection errorof smtp, for example,src srv  smtp duration  0, flag unwanted syn ack, dst srv  userapps 1.0, 0.38These rules may provide hints about the intrusions.For example, the unique not normal serial episodesin    and  reveal that there are alarge number of   data transfer activities whereasthe unique serial episodes in  suggest that alarge number of connections to the   service wereattempted.4 Architecture SupportThe biggest challenge of using data mining approachesin intrusion detection is that it requires a large amount ofaudit data in order to compute the profile rule sets. Andthe fact that we may need to compute a detection modelfor each resource in a target system makes the data mining task daunting. Moreover, this learning mining process is an integral and continuous part of an intrusion detection system because the rule sets used by the detectionmodule may not be static over a long period of time. Forexample, as a new version of a system software arrives,we need to update the normal profile rules. Given thatdata mining is an expensive process in time and storage, and realtime detection needs to be lightweight tobe practical, we cant afford to have a monolithic intrusion detection system.We propose a system architecture, as shown in Figure 3,that includes two kinds of intelligent agents the learning agents and the detection agents. A learning agent,which may reside in a server machine for its computing power, is responsible for computing and maintaining the rule sets for programs and users. It producesboth the base detection models and the meta detectionmodels. The task of a learning agent, to compute accurate models from very large amount of audit data, isan example of the scaleup problem in machine learning. We expect that our research in agentbased metalearning systems SPT97 will contribute significantlyto the implementation of the learning agents. Briefly,we are studying how to partition and dispatch data to ahost of machines to compute classifiers in parallel, andreimport the remotely learned classifiers and combinean accurate final metaclassifier, a hierarchy of classifiers CS93.A detection agent is generic and extensible. It isequipped with a learned and periodically updated ruleset i.e., a classifier from the remote learning agent. Itsdetection engine executes the classifier on the inputaudit data, and outputs evidence of intrusions. The maindifference between a base detection agent and the metadetection agent is the former uses preprocessed auditdata as input while the later uses the evidence from allthe base detection agents. The base detection agents andthe meta detection agent need not be running on the samehost. For example, in a network environment, a metaagent can combine reports from base detection agentsrunning on each host, and make the final assertion on thestate of the network.The main advantages of such a system architecture are It is easy to construct an intrusion detection systemas a compositional hierarchy of generic detectionagents. The detection agents are lightweight since theycan function independently from the heavyweightlearning agents, in time and locale, so long as it isalready equipped with the rule sets. A detection agent can report new instances of intrusions by transmitting the audit records to the learning agent, which can in turn compute an updatedclassifier to detect such intrusions, and dispatchthem to all detection agents. Interestingly, the capability to derive and disseminate antivirus codesfaster than the virus can spread is also considered akey requirement for antivirus systems KSSW97.5 Conclusion and Future WorkIn this paper we proposed a systemic framework thatemploys data mining techniques for intrusion detection.This framework consists of classification, associationrules, and frequence episodes programs, that can be usedAudit RecordPreprocessorAudit RecordsInductiveLearning EngineDecision EngineDecision  TableRule Basesclassifiersactionsreportsevidenceactivity datamodels basedetectionengineevidence from otherbase detection agentsmetadetection agentdetection agentbasemeta detection enginefinal assertion  metaremote learning agentFigure 3 An Architecture for AgentBased Intrusion Detection Systemto automatically construct detection models. The experiments on sendmail system call data and network tcpdump data demonstrated the effectiveness of classification models in detecting anomalies. The accuracy of thedetection models depends on sufficient training data andthe right feature set. We suggested that the associationrules and frequent episodes algorithms can be used tocompute the consistent patterns from audit data. Thesefrequent patterns form an abstract summary of an audittrail, and therefore can be used to guide the audit datagathering process provide help for feature selection anddiscover patterns of intrusions. Preliminary experimentsof using these algorithms on the tcpdump data showedpromising results.We are in the initial stages of our research, much remainsto be done including the following tasks Implement a support environment for systembuilders to iteratively drive the integrated process ofpattern discovering, system feature selection, andconstruction and evaluation of detection models Investigate the methods and benefits of combiningmultiple simple detection models. We need to usemultiple audit data streams for experiments Implement a prototype agentbased intrusion detection system. JAM SPT97 already provides abase infrastructure Evaluate our approach using extensive audit datasets, some of which is presently under constructionat Rome Labs.6 AcknowledgmentsWe are very grateful to Stephanie Forrest and Steven A.Hofmeyr, both of University of New Mexico, for providing us with the system call data and explaining the details of their experiments. We also wish to thank PhilipK. Chan of Florida Institute of Technology and DavidWei Fan of Columbia University for their helpful advice.ReferencesABH96 D. Atkins, P. Buis, C. Hare, R. Kelley,C. Nachenberg, A. B. Nelson, P. Phillips,T. Ritchey, and W. Steen. Internet SecurityProfessional Reference. New Riders Publishing, 1996.Bel89 S. M. Bellovin. Security problems in thetcpip protocol suite. Computer Communication Review, 1923248, April 1989.Coh95 W. W. Cohen. Fast effective rule induction. In Machine Learning the 12th International Conference, Lake Taho, CA, 1995.Morgan Kaufmann.CS93 P. K. Chan and S. J. Stolfo. Toward paralleland distributed learning by metalearning.In AAAI Workshop in Knowledge Discoveryin Databases, pages 227240, 1993.FHSL96 S. Forrest, S. A. Hofmeyr, A. Somayaji, andT. A. Longstaff. A sense of self for unixprocesses. In Proceedings of the 1996 IEEESymposium on Security and Privacy, pages120128, Los Alamitos, CA, 1996. IEEEComputer Society Press.FPSS96 U. Fayyad, G. PiatetskyShapiro, andP. Smyth. The KDD process of extracting useful knowledge from volumes of data.Communications of the ACM, 39112734, November 1996.Fra94 J. Frank. Artificial intelligence and intrusion detection Current and future directions. In Proceedings of the 17th National Computer Security Conference, October 1994.HLMS90 R. Heady, G. Luger, A. Maccabe, andM. Servilla. The architecture of a networklevel intrusion detection system. Technicalreport, Computer Science Department, University of New Mexico, August 1990.IKP95 K. Ilgun, R. A. Kemmerer, and P. A. Porras.State transition analysis A rulebased intrusion detection approach. IEEE Transactions on Software Engineering, 213181199, March 1995.JLM89 V. Jacobson, C. Leres, and S. McCanne.tcpdump. available via anonymous ftp toftp.ee.lbl.gov, June 1989.KFL94 C. Ko, G. Fink, and K. Levitt. Automateddetection of vulnerabilities in privilegedprograms by execution monitoring. In Proceedings of the 10th Annual Computer Security Applications Conference, pages 134144, December 1994.KS95 S. Kumar and E. H. Spafford. A software architecture to support misuse intrusion detection. In Proceedings of the 18th National Information Security Conference, pages 194204, 1995.KSSW97 J. O. Kephart, G. B. Sorkin, M. Swimmer,and S. R. White. Blueprint for a computer immune system. Technical report,IBM T. J. Watson Research Center, Yorktown Heights, New York, 1997.LB97 T. Lane and C. E. Brodley. Sequence matching and learning in anomaly detection forcomputer security. In AAAI Workshop AIApproaches to Fraud Detection and RiskManagement, pages 4349. AAAI Press,July 1997.LSC97 W. Lee, S. J. Stolfo, and P. K. Chan. Learning patterns from unix process executiontraces for intrusion detection. In AAAIWorkshop AI Approaches to Fraud Detection and Risk Management, pages 5056.AAAI Press, July 1997.LTG92 T. Lunt, A. Tamaru, F. Gilham, R. Jagannathan, P. Neumann, H. Javitz, A. Valdes,and T. Garvey. A realtime intrusion detection expert system IDES  final technicalreport. Technical report, Computer ScienceLaboratory, SRI International, Menlo Park,California, February 1992.MTV95 H. Mannila, H. Toivonen, and A. I.Verkamo. Discovering frequent episodes insequences. In Proceedings of the 1st International Conference on Knowledge Discovery in Databases and Data Mining, Montreal, Canada, August 1995.Pax97 Vern Paxon. Endtoend internet packet dynamics. In Proceedings of SIGCOMM 97,September 1997.Pax98 Vern Paxon. Bro A system for detectingnetwork intruders in realtime. In Proceedings of the 7th USENIX Security Symposium, San Antonio, TX, 1998.PV98 Phillip A. Porras and Alfonso Valdes. Livetraffic analysis of tcpip gateways. In Proceedings of the Internet Society Symposiumon Network and Distributed System Security, March 1998.SA95 R. Srikant and R. Agrawal. Mining generalized association rules. In Proceedings of the21st VLDB Conference, Zurich, Switzerland, 1995.SPT97 S. J. Stolfo, A. L. Prodromidis, S. Tselepis, W. Lee, D. W. Fan, and P. K. Chan.Jam Java agents for metalearning over distributed databases. In Proceedings of the3rd International Conference on KnowledgeDiscovery and Data Mining, pages 7481,Newport Beach, CA, August 1997. AAAIPress.Sri96 R. Srikant. Fast Algorithms for MiningAssociation Rules and Sequential Patterns.PhD thesis, University of Wisconsin  Madison, 1996.Ste84 W. R. Stevens. TCPIP Illustrated, volume 1. AddisonWesley Publishing Company, 1984.
