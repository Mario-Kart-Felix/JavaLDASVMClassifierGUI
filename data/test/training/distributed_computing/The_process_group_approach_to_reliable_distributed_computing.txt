The Process Group Approachto Reliable Distributed ComputingKenneth P. Birman TE  ,TR 911216 ,, 3July 1991Revised September 1992 F 7Department of Computer ScienceCornell UniversityIthaca, NY 148537501The author is in the Department of Computer Science, Cornell University, and wassupported under DARPAJNASA grant NAG 2593 and by grants from IBM, HP,Siemens, GTE and Hitachi.The Process Group Approach to Reliable Distributed Computing Kenneth P. BirmanSeptem 26, 1992AbstractThe difficulty of developing reliable distributed softwme is an impediment to applying distributedcomputing technology in many settings. Expeti with the Isis system suggests that a structuredapproach based on virtually synchronous  groups yields systems that are substantially easier todevelop, exploit sophisticated forms of cooperative computation, and achieve high reliability. This paperreviews six years of resemr,.hon Isis, describing the model, its implnentation challenges, and the typesof applicatiom to which Isis has been appfied.1 In oducfionOne might expect the reliability of a distributed system to follow directly from the reliability of its constituents, but this is not always the case. The mechanisms used to structure a distributed system and toimplement cooperation between components play a vital role in determining how reliable the system will be.Many contemporary distributed operating systems have placed emphasis on communication performance,overlooking the need for tools to integrate components into a reliable whole. The communication primitivessupported give generally reliable behavior, but exhibit problematic semantics when transient failures orsystem configuration changes occur. The resulting building blocks are, therefore, unsuitable for facilitatingthe construction of systems where reliability is impotant.This paper reviews six years of research on Isis, a syg,,m that provides tools  support the construction ofreliable distributed software. The thesis underlying l.lS is that development of reliable distributed softwarecan be simplified using process groups and group programming too. This paper motivates the approachtaken, surveys the system, and discusses our experience with real applications.The author is in the Department of Computer Science, Comell Unive3ity, and was supported under DARPANASA grantNAG2593, tad by grants from IBM, liP, Siemens, GTE and Hitachi.I IIll m  1Jm I II11 1o  11.14OEC .m I IFi I Brokers trading systemIt will be helpful to iglustrate group programming and Isls in a setting where the system has found rapidacceptancebrokerage and wading systems. These systems integrate large numbers of demanding applications and  timely reaction to high volumes of pricing and trading information, l It is not uncommonfor brokers to coordinate trading activities across multiple markets. Trading strategies rely on accuratepricing and market volatility data, dynamically changing  giving the firms holdings in variousequities, news and analysis data, and elaborate firumcial and economic models based on relationships between financial instruments. Any distributed system in support of this application must serve multiplecommunities the firm as a whole, where reliability and security are key considerations the brokers, whodepend on speed and the ability to customize the trading environment and the system administrators, whoseek uniformity, ease of monitoring and control. A theme of the paper will be that all of these issues revolvearound the technology used to glue the system together. By endowing the corresponding software layerwith predictable, faulttolerant behavior, the flexibility and reliability of the overall system can be greatlyenhanced.Figme 1 illustrates a possible interface to a wading system. The display is centered around the currentposition of the account being traded, showing purchases and sales as they occur. A broker typicallyauthorizes purchases or sales of shares in a stock, specifying limits on the price and the number of shares.These instructions are communicated to the trading floor, where agents of the brokerage or bank trade asmany shares as possible, remaining within this authorized window. The display illustrates several points Information backplane. The broker would construct such a display by interconnecting elementarywidgets graphical windows, computational ones, etc. so that the output of one becomes the inputto another. Seen in the large, this implies the ability to publish messages and subscribe to messagesIAlthough this class of sys.ms  demancls high performance, the lime cons0ms lhere are no realne deadnes, suchthe FAAs Advanced Automation System CO90. This issue iz discussed further in ec. 7.2Figure2 Makingananalyticservice faulttolerantsent from program to program on topics that make up the corporate information backplane of thebrokerage. Such a backplane would support a naming structure, communication interfaces, accessrestrictions, and some sort of selective history mechanism. For example, upon subscribing to a topic,an application will often need key messages posted to that topic in the past.C.s.dzu6on. The display suggests that the system must be easily customized. The informationbackplane must be organized in a systematic way so that the broker can easily track down the nameof communication streams of interest and flexible aLlowing the introduction of new communicationstreams while the system is active.Hierarchical structure. Although the trader will treat the widearea system in a seamless way,communication disruptions are far more common on widearea links say, from New York to Tokyoor Zurich than on localarea ones. This gives the system a hierarchical structure composed of localarea systems which are closely coupled and rich in services, interconnected by less reliable and higherlatency widearea communication links.What about the reliability implications of such an architecture In Fig. l, the trader has introduceda computed index of technology stocks against the price of IBM, and it is easy to imagine that suchcustomization could include computations critical to the trading strategy of the firm. In Figure 2, theanalysis widget is shadowed by additional copies, to indicate that it has been made faulttolerant i.e. itwould remain available even if the brokers workstation failed. A broker is unlikely to be a sophisticatedprogrammer, so faulttolerance such as this would have to be introduced by the system  the traders onlyaction being to request it, pedmps by specifying a faulttolerance computational property associated with theanalyticicon.This means thesystemmust automadcaliyreplicateor checkpointthecomputation,placingthereplicason prs thatfailindependentlyfrom thebrokersworkstation,and activatinga backup ifthe primary falls.Therequirementsof modemtradingenvironmentsarenotuniqueto theapplication.It is easyto rephrasethis example in terms of the issues confronted by a team of seismologists cooperating to interpret the resultsof a seismic survey underway in some remote and inaccessible region, a doctor reviewing the status ofpatients in a hospital from a workstation at home, a design group collaborating to develop a new product,or application programs cooperating in a factoryfloor process control setting. The sofF, vare of a modemtelecommunications switching product is faced with many of the same issues, as is software implementing adatabase that win be used in a large distributed setting. To build applications for the networked environmentsof the future, a tedmology is needed that will make it as easy to solve these sorts of problems as it is to buildgraphical interfac today.A central premise of the Isls project, shared with several other effom ILL86, CD90, Pet87, KTHB89,ADKM91, is that support for programming with disleibuted groups of cooperating programf is the keyto solving problems such as the ones seen above. For example, a faulttolerant data analysis servicecan be implemented by a group of programs that adapt transparently to failures and recoveries. Thepublicationsubscription style of interaction involves an implicit use of process groups here, the groupconsists of a set of publishers and subscribers that vary dynamically as brokers change the instrumentsthat they trade. Although the processes publishing or subscribing to a topic do not cooperate directly,when this stctute is employed, the reliability of the application will depend on the reliability of groupcommunication. It is easy to see how problems could arise if, for example, two brokers monitoring the samestock see different pricing information.Process groups of various kinds arise naturally throughout a distributed system. Yet, current distributedcomputing environments provide little support for group communication patterns and programming. Theseissues have been left to the application programmer, and application programmers have been largely unableto respond to the challenge. In short, contemporary distributed computing environments prevent users fromrealizing the potential of the distributed computing infrastructure on which their applications run.The aainder of the paper is organized into three parts. The first defines the group programming paradigmmore arefuny and discusses the algorithmic issues it raises. This leads into the Isis computational model,called virtual synchrony. The next part discusses the tools from which Isls users construct applications. Thelast part reviews applications that have been built over Isls. The paper concludes with a brief discussion offunae directions for the project.2 Process groupsTWo styles of process group usage are seen in most Isis applications Anonymous groups Anonymous groups arise when an application publishes data under some topic,and other processes subscribe to that topic. For an application to operate automatically and reliably,anonymous groups should provide certain properties1. It should be possible to send messages to the group using a group address. The highlevelprogrammer should not be involved in expanding the group address into a list of destinations.2. If the sender and subscribers remain operational, messages should be delivered exactly once ifthe sender fails, a message should be delivered to all or none of the subscribers. The applicationprogrammer should not need to worry about message loss or duplication.3. Messages should be delivered to subscribem in some sensible order. For example, one wouldexp messages to be delivered in an order consistent with causal dependencies if a messagem is published by a program that first tecved m...mi, then m might be dependent on theseprior messages. If some other subscriber will receive m as wen as one or more of these priormessages, one would expect them to be delivered first. Stronger ordering properties might alsobe desired, as discussed later.4. It should be possible for a subscriber to obtain a history of the group  a log of key events andthe order in which they were received. 2 If n messages are posted and the first message seen by anew subscriber will be message m, one would expect messages ml...ml tObe reflected in thehistory, and that messages m...m,, will all be delivered to the new process. If some messagesam missing from the history, or included both in the history and in the subsequent postings,incorrect behavior might result.Expltcit groups A group is explicit when its members cooperate directly they know themselves tobe members of the group, and employ algorithms that employ the list of members, relative rankingswithin the list, or in which responsibility for responding to requests is shared. Explicit groupshave additional needs stemming from their use of group membership information in some sense,membership changes are among the information being published to an explicit group. For example,a faulttolerant service might have a primary member that takes some action and an ordered set ofbackups that take over, one by one, if the current primary fails. Here, group membership changesfailure of the primary trigger actions by group members. Unless the same changes are seen inthe same order by all members, situations could arise in which there are no primaries, or several.Similarly, a parallel database search might be done by ranking the group members and then dividingthe database into n parts, where n is the humor 0f group members. Each member would do nthof the work, with the ranking determining which member handles which fragment of the database.The members need consistent views of the group membership to perform such a search correctlyotherwise, two processes might search the same part of the database while some other part remainsunscanned, or they might partition the database inconsistently.he spplicaflon itself would distinguish messqes that need to be retained fTom those th can be discarded.5Thus, a number of technical problems must be considered in developing software for implementing distributed process groupsSupport for group communication, including addressing, failure atomicity, and message deliveryordering.Use of group membership as an input. It should be possible to use the group membership or changesin membership as input to a distributed algorithm one run cortomently by multiple group members.Synchronization. To obtain globally corre behavior from group applications, it is necessary to synchronize the order in which actions are taken, particularly when group members will act independentlyon the basis of dynamically changing, shared information.The first and last of these problems have received considerable study. However, the problems cited are notindependent their integration within a single framework is nontrivial. This integration issue underlies ourvirtual synchrony execution model.3 Building distributed services over conventional technologiesIn this section we review the technical issues raised above. In each case, we start by describing the problemas it might be approached by a developer working over a contemporary computing system, with no specialtools for group programming. Obstacles to solving the problems are identified, and used to motivate ageneral approach to overcoming the problem in question. Where appropriate, we then comment on theactual approach used in solving the problem within Isls.3.1 Conventional message passing technologiesContemporary operating systems offer three classes of communication services Tan88Unreliable datagrams These services automatically discard corrupted messages, but do little additional processing. Most messages get through, but under some conditions messages might be lost intransmission, duplicated, or delivered out of order.Remote procedure call In this approach, communication results from a procedure invocation thatreturns a result. RPC is a relatively reliable service, but when a failure does occur, the sender isunable to distinguish between many possible outcomes the destination may have failed before orafter receiving the request, or the network may have prevented or delayed delivery of the request orthe reply.6Reliable data streams Here, communication is performed over channels that provide flow controland reliable, sequenced message delivery. Standard stream protocols include TCP, the ISO protocols,and TP4. Because of pipelining, streams generally outperform Ri when an application sends largevolumes of data. However, the standards also prescribe rules under which a stream will be broken,using conditions based on timeout or excessive retransmissions. For example, suppose that processesA, B and C have connections with one another and the connection from A to B breaks due to acommunication failure, while all three processes and the other two connections remain operational.Much like the situation after a failed RPC, A and B will now be uncertain regarding oneanothersstatus. Worse, C is totally unaware of the problem. In such a situation, the application may easilybehave in an inconsistent manner. From this, one sees that a reliable data stream has guarantees littlestronger than an unreliable one when channels break, it is not safe to infer that either endpoint hasfailed, channels may not break in a consistent manner, and data in transit may be lost. Because theconditions under which a  break are defined by the standards, one has a situation in whichpotentially inconsistent behavior is unavoidable.These considerations lead us to make a collection of ptions about the network and message communication in the remainder of the paper. First, we will e that the system is structured as a wideareanetwork WAN composed of localareanetworks LANs interconnectedby wideareacommunicationlinks.WAN issueswillnot be consideredinthispaperforreasonsofbrevity.We assume thateach LANconsistsofa collentionofmachines asfew astwo orthree,orasmany asone ortwo hundred,conneaed bya collectionofhighspeed,low latencycommunication devices.Ifsharedmemory isemployed, we assumethat it is not used over the network. Clocks are not assumed to be closely synchronized.Within a LAN, we assume that messages may be lost in transit, arrive out of order, be duplicated, or bediscarded because of inadequate buffering capacity. We also assume that LAN communication partitionsare rare. The algorithms describedbelow,and the Isis system itself, may pause or make progressinonly the largest partition during periods of partition failure, resuming normal operation only when normalcommunication is restored.We will assume that the lowest levels of the system are responsible for flow control and for overcomingmessage loss and unordered delivery. In ISls, these tasks are accomplished using a windowed acknowledgement protocol similar to the one used in TCP, but integrated with a failure detection subsystem. With thisnonstandard approach, a consistent systemwide view of the state of components in the system and of thestateofcommunication channelsbetween them be presentedtohigherlayersofsoftware.For example,the ISlS transport layer will only break a communication channel to a process in situations where it wouldalso report to any application monitoring that process that the process has failed. Moreover, if one channelto a process is broken, all channels are broken.  43.2 Failure modelThroughout this paper, processes and psors are assumed to fail by haring, without initiating erroneousactions or sending incorrect messages. This raises a problem transient problems  such as an unresponsiveswapping device or a temporary communication outage  can mimic halting failures. Because we wiUwant to build systems guaranteed to make progess when failures occur, this introduces a conflict betweenaccurate and timely failure detection.One way to overcome this problem, supported by ISLS, integrates the communication transport layer withthe failure detection layer to make processes appear to fail by halting, even when this may not be thecase a failstop model SS83. To implement such a model, a system uses an agreement protocol tomaintain a system membership list only processes included in this list are permitted to participate in thesystem, and nonresponsive or failed processes are dropped CriB8, RB91. If a process dropped fromthe list later resumes communication, the application is forced to either shut down gracefully or to run areconnection protocol The message transport layer plays an important role, both by breaking connectionsand by intercepting messages from faulty processes.Inthe remainder of this paper we assume a message transport and failuredetection layer with the propertiesof the one used by Isis. To summarize, a process stars execution by joining the system, interacts with itover a period of time during which messages are delivered in the order sent, without loss or duplication, andthen terminates flit terminates by halting detectably. Once a process terminates, we will consider it to bepermanently gone from the system, and assume that any state it may have recorded say, on a disk ceasesto be relevant, If a process experiences a transient problem and then recovers and rejoins the system, it istreated as a completely new entity  no attempt is made to automatically reconcile the state of the systemwith its state prior to the failure.3.3 Building groups over conventional technologiesGroup addressingConsider the problem of mapping a group address to a membership list, in an application where themembership could change dynamically due to processes joining the group or leaving. The obvious wayto approach this problem involves a membership service BJ87, Cri88. Such a service maintains a mapfrom group names to membership lists. Deferring faulttolerance issues, one could implement such aservice using a simple program that supports remotely callable procedures to register a new group or groupmember, obtain the membership of a group, and perhaps to forward a message to the group. A process couldthen transmit a message either by forwarding it via the naming service, or by looking up the membershipinformation, caching it, and transmitting messages directly. 3 The first approach will perform better forIn the  case, one would also need a mechanism for invalidating cached addressing information when the group membershipchanges this is not  trivial problem, bet the need for brevity precludes cliscemng it in detail.onetime imemctions the second would be preferable in an application that sends a stream of messages tothe group.This form Of group addressing also raises a scheduling question. The designer of a distributed applicationwillwant tosend messages toallmembers of thegroup,under some reasonableinterpretationf thetermall. The question, then, is how to schedule the delivery of messages so that the delivery is to a reasonableset of processes. For example, suppose that a process group contains three processes, and a process sendsmany messages to it. One would expect  messages to reach all three members, not some other setreflecting a stale view of the group composition e.g. including processes that have left the group, oromitting some of the current members.The solution to this problem favored in our work can be understood by thinking of the group membershipas data in a database shared by the sender of a multidestination message a muticast4, and the algorithmused to add new members to thegroup. A multicastreads the membership of thegroup towhich itissent,holdinga form of readlockuntilthedeliveryof themessage occurs.A change of membership thataddsa new member would be treatedlikea writeoperation,requiringa writelockthatpreventssuchanoperationfrom executingwhileapriormulticastisumicnvay. Itwillnow appearthatmessages arcdeliveredtogroupsonlywhen themembership isnot changing.A problem with using locking to implement address expansion is cost. Accordingly, IslS uses this idea, butdoes not employ a database or any sort of locking. And, rather than implement a membership server, whichcould present a single point of failure, Isis replicates knowledge of the membership among the membersof the group itself. This is done in an integrated manner so as to perform address expansion with no extramessages or unnecessary delays and guarantee the logical instantaneity property that the user expects. Forpractical purIxses, any message sent to a group can be thought of as reaching all of its members at the sametime.Logical time and causal dependencyThe phrasereaching all ofitsmembers atthesame timeraisesan issue that willprovetobe fundamentaltomessagedeliveryordering.Such astatementpresupposesatemporalmodel. What notionoftime appliesto distributed processgroup applicationsIn 1978, Leslie Lamport published a seminal paper that considered the role of time in distributed algorithms Lain78. Lamport asked how one might assign timestamps to the events in a distributed system soas to correctly capture the order in which events . Realtime is not suitable for this each machinewill have its own clock, and clock synchronization is at best imprecise in distributed systems. Moreover,4In this paper the term mutcast refers to whaling  single message to  members of  process group. The term broadcast,common in the literature, is sometimes confused with the hardwm boadcast capabilities of devices like EtherneL While a mulficastmightmake useofhardwarebroadcast,hiswouldsimplyrepresentone possleimplementationsurategy.9operating systems introduce unpnulictable software delays, processor execution speeds can vary widelydue to cache finity effects, and scheduling is often unpredictable. These factors make it hard to comparetimestamps assigned by different machines.As an alternative,Lampon suggested,one coulddiscussdistributedalgorithmsintermsofthedependenciesbetween the events making up thesystem execution. For example, suppose that a processfirst sets somevariable z to 3, and then sets y  z. The event corresponding to the latter operation would depend uponthe former one  an example of aocadependency. Similarly, receiving a message depends upon sending it.Thisview of asystemleadsone todefoe thepotent causalityrelationshipbetween eventsin system.Itistheirreflexivewmsitiveclosureofthemessage sendreceiverelationand thelocaldependency relationforprocessesinthesystem.Ifeventa happensbeforeeventb ina distributedsystem,thecausalityrelationwillcapturethis.In tampons view of time, we would say that two events am concurrent iff they are not causally relatedthe issue is not whether they actualy executed simultaneously in some run of the system, but whether thesystem was sensitive to their respective ordering. Given an execution of a system, there exists a large setof equivalent executions arrived at by re.w.heduling conaxrrent events while retaining the event orderingconstraints represented by causality relation. The key observation is that the causal event ordering capturesall the essential ordering Informationneeded to describe the execution any two physical executions withthe same causal event ordering describe indistinguishable runs of the system.Recallouruse ofthephrasereachingallofitsmembers atthesame time.Lampon has suggestedthatforasystemdescribedintermsofacausaleventordering,any setofconcunr.ntevents,one perp, can bethoughtof asrepresentingalogicalinstantintime.Thus,when we saythatallmembers of a group receivea message atthe same time,we mean thatthemessage deliveryeventsareconcurrentand totallyorderedwithrespecttogroup mcmbenJ1ipchange events.Causaldependency providesthefundamentalnotionoftimeinadistributedsystem,and playsan importantroleintheremainderofthissection.Message delivery orderingConsider Figure 3A, in which messages mt m2 m3 and m4 are sent to a group consisting of processesSl 82 and s3. Messages ml and m2 are sent concurrently and are received in different orders by s2 and a3.In many applications, s2 and 83 would behave in an uncoordinated or inconsistent manner if this occurred.A designer must, therefore, anticipate possible inconsistent message ordering. For example, one mightdesign the application to tolerate such mixups, or explicitly prevent them from occurring by delaying theprocessing of ml and m2 within the program until an ordering has been established. The real danger is thatan designer could overlook the whole issue  aRer all, two simultaneous messages to the program that arrivein different orders may seem like an improbable scenario  yielding an application that usually is correct,but may exhibit abnormal behavior when unlikely sequences of events occur, or under periods of heavy10thmtgFigure 3 Message ordering problemsload. Under load, multicast delivery latencies rise, ing the probability that concurrent multicastscould overlap.This is only one of several delivery ordering problems illusuamd in the Figure 3. Consider the situationwhen s3 receives message ms. Message ms was sent by st after receiving m2, and might refer to or dependupon m2. For example, m2 might authorize a certain broker to trade a particular account, and m3 couldbe a trade that the broker has initiated on behalf of that account. Our execution is such that s3 has not yetreceived m2 when m3 is delivered. Perhaps m2 was discarded by the operating system due to a lack ofbuffering space. It will be retransmitted, but only after a brief delay during which m3 might be received.Why might this maer Imagine that 3 is displaying buysell orders on the trading floor, s3 will considerms invalid, since it will not be able to confirm that the trade was authorized. An application with thisproblem might fail to carry out valid trading requests. Again, although the problem is solvable, the questionis whether the application designer will have anticipated the problem and programmed a correct mechanismto compensate when it occurs.In our work on Isis, this problem is solved by including a context record on each message. If a messagearrives out of order, this record can be used to detect the condition, and to delay delivery until prior messagesarrive. The context representation we employ has size linear in the number of members of the group withinwhich the message is sent actually, in the worst case a message might carry multiple such context records,but this is extremely rare. However, the average size can be greatly reduced by taking advantage ofrepetitious communication patterns, such as the tendency of a process that sends to a group to send multiplemessages in succession BSS91. The imposed overhead is variable, but on the average small. Othersolutions to this problem are described in PBS89, BJ87.Message m4 exhibits a situation that combines several of these issues, m4 iS sent by a pmc.as that previouslysent mt and is concurrent with m2, m3, and a membership change oftbe group. One sccs here a situation11in which all of the ordering issues cited thus far arise simultaneously, and in which failing to address any ofthem could lead to errors within an important class of applications. As shown, only the group addressingproperty proposed in the previous section is violated were m4 to trigger a concurrent database search,processs would searchthefirsthirdofthedatabase,while 82 thesecondhaf one sixthof thedatabasewould not be searched.However, the figurecouldeasilybe changed to simultaneouslyviolateother ordering properties.State transferFigure 3B illustrates a slighdy different problem. Here, we wish to transfer the state of the service to process3 perhaps s3 represents a program that has restarted after a failure having lost prior state or a server thathas been added to redistribute load. Inmitivdy, the state of the server will be a data structure reflecting thedata managed by the service, as modified by the messages received prior to when the new member joinedthe group. However, in the execution shown, a message has been sent to the server concurrent with themembership change. A consequence is that s3 receives a state which does not reflect message ms, leaving itinconsistent with 81 and 82. Solving this problem involves a complex synchronization algorithm we wontpresent it here, probably beyond the ability of a typical distributed applications programmer.Fault toleranceUp to now, our discussion has ignored failures. Failures cause many problems here, we consider just one.Suppose that the sender of a message were to crash after some, but not all, destinations receive the message.The destinations that do have a copy will need to complete the transmission or discard the message. Theprotocol used should achieve exactlyonce delivery of each message to those destinations that remainoperational, with hounded overhead and storage. On the other hand, we need not be concerned with deliveryto a process that fails during the protocol, since such a process will never be heard from again recall thefailstop model.Protocols to solve this problem can be complex, but a fairly simple solution will illustrate the basictechniques. This protocol uses three rounds of RPCs as illustrated in Figure 4. During the first round, thesender sends the message to the destinations, which acknowledge receipt. Although the destinations candeliver the message at this point, they need to keep a copy should the sender fail during the first round, thedestination p have received copies will need to finish the protocol on the senders behalf. If nofailure occurs, then the sender tells all destinations that the first round  finished. They acknowledge smessage and make a note that the sender is entering the third round. During the third round, each destinationdiscards all information about the message  it deletes the saved copy of the message and any other data itwas maintaining.12RoundIRound2RoundsOKtocleilvwmuleJLAcknowledge,nootherutlonOKIogud0agecollutFigure 4 Threeround reliable mulficastWhen a failure occurs, a process that has received a first or secondround message can terminate theprotocol. The basic idea is to have some member of  on set take over the round that the senderwas running when it failed processes that have already received messages in that round detect duplicatesand respond to them as they responded after the original reception. The protocol is straightforward, and weleave the details to the reader.RecaU that in Sec. 3.1, we indicated that systemwide agreement on membership was an importznt propertyof our overall approach. It is interesting to realize that a protocol such as this is greatly simplified becausefailures are reported consistently to all processes in the system. If failure detection were by an inconsistentmechanism it would be very difficult to convince oneself that the protocol is correct indeed, as stated, theprotocol could deliver duplicates if failu ate reported inaccurately. The merit of solving such a problemat a low level is that we can then make use of the coistency properties of the solution to in reasoning aboutprotocols that react to failures.This threeround multicast protocol does not obtain any form of pipelined or asynchronous data flow wheninvoked many times in succession, and the use of RPC limits the degree of communication concurrencyduring each round it would be better to send all the messages at once, and to collect the replies in parallel.These features make the protocol expensive. Much better solutions have been described in the literaturesee BSSgl, BJ87 for more detail on the approach used in Isis, and for a summary of other work in thearea.Summary of issuesThe above discussion pointed to some of the potential pitfalls that confront the developer of group softwarewho works over a conventional operating system 1 weak support for reliable communication, notably13inconsistency in the situations in which channels break, 2 group address expansion, 3 delivery orderingfor concurrent messages, 4 delivery ordering for sequences of related messages, 5 state transfer, and 6failure atomicity. This llst is not exhaustive we have overlooked questions involving realtime deliveryguarantees, and persistent databases and files. However, our work on Isis treats process group issues underthe assumption that any realtime deadlines axe long compared to communication latencies, and that processstates are volatile, hence we view these issues as beyond the scope of the current paper. 5 The list does coverthe major issues that arise in this more restrictive domain. BC90At the start of this section, we asserted that modem operating systems lack the tools needed to developgrouphased software. This assertion goes beyond standardsch  UNIX to include nextgenerationsystems such as NT, Mach, Chorus and Ameoba. 6 A basic premise of this paper is that, although all of theseproblems can be solved, the complexity associated with working out the solutions and integrating them in asingle system will be a significant barrier to application developers. The only practical approach is to solvethese problems in the distributed computing environment itself, or in the operating system. This permits asolution to be englneew.l in a way that will give good, predictable performance and that takes  advantageof hardware and operating systems features. Furthermore, providing p groups as an underlying toolpermits the programmer to concentrate on the problem at hand. If the implementation of process groups isleft to the application designer, nonexperts are unlikely to use the approach. The brokerage application ofthe on would be extremely difficult to build using the tools provided by a conventional operatingsystem.4 Virtual synchronyEarlier, it was observed that integration of multiple group programming mechanisms into a single environment is also an important problem. Our work addresses this issue through an execution model calledvirtual synchrony, motivated by prior work on transaction serializabUity. We will present the approach intwo stages. First, we discuss an execution model called close synchrony. This model is then relaxed toarrive at the virtual synchrony model. A comparison of our work with the serializability model appears inSec. 7.The basic idea is to encourage programmers to assume a closely synchronized style of distributed execution BJg9, SchgS ..............SThese issues can be addressedwithin the tools layer of  andin fact thecurrentsystem includes an optional subsystem formanagement of persistent data.qn fairness, it should be noted that Math IPC provides strong guarantees of reliability in its communication subsystem.However, Math may experience unbounded delay when a node failure occurs. Chorus includes a portgroup mechanism, but withweak semantics, patlernod aft earlier work on the V system CZ83. Ameoba, which initially lacked group support, has recentlybeen extended to  mechanism apparentlymotivatedby our workon Isis KTHB891.14I St Ss S StHgure 5 Closely synchronous execution Execution of a process consists of a sequence of events, which may be internal computation, messagetransmissions, message deliveries, or changes to the membership of groups that it creates or joins. A global execution of the system consists of a set of process executions. At the global level, one cantalk aboutmessages sent as mutcaa to p groups. Any two processes that receive the same multi casts or observe the same group membership changessee the corresponding local events in the same relative order. A multicast to a process group is delivered to its full membership. The send and delivery events areconsidered m occur as a single, instantaneous event.Close synchrony is a powerful guarantee. In fact, as seen in Fig. 5, it eliminates all the problems identifiedin the preceding section Weak communication reliability guarantees A closely synchronous communication subsystem appears to the programmer as completely reliable. Group address expansion In a closely synchronous execution, the membership of a process group isfixed at the logical instant when a multicast is delivered. Delivery ordering for concurrent messages In a closely synchronous execution, concurrently issuedmulficasts are distinct events. They would, therefore, be seen in the same order by any destinationsthat they have in common. Delivery ordering for sequences of related messages In Figure 5a, process st sent message m3after receiving m2 hence m3 may be causally dependent upon m2. Processes executing in a closelysynchronous model would never see anything inconsistent with this causal dependency relation.15Figure6 Asynchronous pipeHnlng State transfer. State transfer occurs at a well defined instant in time in the model. If a group memberints the group state at the instant when a new member is added, or sends something based onthe state to the new member, the state will be well defined and complete. Failure atomicity The close synchrony model treats a multicast as a single logical event, and reportsfailures through group membership changes which are ordered with respect to multicast. The all ornothing behavior of an atomic multicast is thus implied by the model.Unfommately, although closely synchronous execution simplifies distributed application design, the approach cannot be applied directly in a practical setting. First, achieving close synchrony is impossible inthe presense of failures. Say that processes sl and s2 are in group G and message m is multicast to G.Consider 81 at the instant before it delivers m. According to the close synchrony model, it can only deliverrrt if 82 will do so also. But, 81 has no way to be sure that s2 is still operational, hence .91 will be unable tomake progress TS92. Fortunately, we can finesse this issue if 82 has failed, it will hardly be in a positionto dispute the assertion that m was delivered to it firstA second concern is that maintaining close synchtony is expensive. The simplicity of the approach stemsfrom the fact that the entire process group advances in lock step. But, this also means that the rate ofprogress each group member can make is limited by the speed of the other members, and this could have ahuge performance impact. Needed is a model with the conceptual simplicity of close synchrony, but that iscapable of efficiently supporting very high throughput applications.In distributed systems, high throughput comes from asynchronous interactions patterns of executionin which the sender of a message is permitted to continue executing without waiting for delivery. Anasynchronous approach treats the communications system like a bounded buffer, blocking the sender onlywhen the rate of data production exceeds the rate of consumption, or when the sender needs to wait for a16reply or some other input Figure 6. The advantage of this approach is that the latency delay betweenthe sender and the destination does not affect the data transmission rate  the system operates in a pipelinedmanner, permitting both the sender and destination to remain continuously active. Closely synchronousexecution precludes such pipelining, delaying execution of the sender until the message can be delivered.This motivates the virtual synchrony approach. A virtually synchronous system permits asynchronous executions for which there exists some closely synchronous execution indistinguishable from the asynchronousone. In general, this means that for each appficadon, events need be synchronized only to the degree thatthe application is sensitive to event ordering. In some situations, this approach will be identical to closesynchrony. In others, it is possible to deliver messages in different orders at different processes, withoutthe application noticing. When such a relaxation of order is permissable, a more asynchronous executionresults.Order sensitivity in distributed systems.We are, thus, lead to a final technical question when can synchronization be relaxed in a virtuallysynchronous distributed system7 Suppose that we wish to develop a service to manage the trading historyfor a set of commodities. A set of tickerplants 7 monitor pflces of futures contracts for soybeans, porkbeLlies,and other commodities. Each price change causes a multicast by the tickerplant to the applications trackingthis data. Initially, assume that appfications track a single commodity at a time.One can imagine two styles of tickerplant. In the first, quotes might originate in any of several tickerplants,hence two different quotes perils, one for Oficago and one for New York could be multicast concurrentlyby two different processes. In a second design, only one tickerplant would actively multicast quotes fora given commodity at a time. Other tickeplants might buffer recent quotes to enable recovery from thefailure of the primary server, but would never multicast them unless the primary fails. Now, suppose that akey correctness constraint on the system is that any pair of programs that monitor the same commodity seethe same sequence of values. Close synchrony would guarantee this.How sensitive are the applications to event ordering in this example The answer depends on the tickerplamprotocol Using the fut tickerplant protocol, the multicast primitive must deliver concurrent messages inthe same order at all overlapping destinations. This is normally called an atomic delivery ordering, and isdenoted ABCAST.The second style of system has a simpler ordering requirement. Here, as long as the primary tickerplantfor a given commodity is not changed it suffi to deriver messages in the order they were sent messagessent concurrently concern different commodities, and since the data for different commodities is destinedto independent application programs, the order in which updates are done for different commodities shouldnot be noticable. The ordering requirement for such an application would be first in, first out FIFO.7A tickerplant is  program or device that receives telemelx 7 input directly fxom  stock exchange or some similar source.1711ES I SFigure 7 Causal orderingNow, suppose that it were desirable to dynamically change the primary in response to a failure or to balanceload. For example, perhaps one tickerplant is handling both soybeans and porkbellies in a heated market,while another is monitoring a slow day in petroleum products. The latency on reporting quotes could bereduced by sharing the load more evenly. However, even during the reconflguration, it remains important todeliver messages in the order they were sent, and this ordering might span multiple processes. If tickerplantsl sends quote ql, and then sends a message to tickerplant  telling it to take over, tickerplant 82 mightsend quote q2 figure 7. Logically, q2 follows ql, but the delivery order is determined by a transmissionorder that arises on a causal chain of events spanning multiple processes. A FIFO order would not ensurethat all applications receive the quotes in the order they were sent. Thus, a sufficient ordering property forthe second style of system is that if ql causally precedes , then ql should be delivered before q2 at shareddestinations. A multicast with this property achieves causal delivery ordering, and is denoted CBCAST.Notice that CnCAST is weaker than ABCAST, because it permits messages that were sent concurrendy to bedelivered to overlapping destinations in different orders, sOn the other hand, consider the implications of introducing an application that combines both pork andbeans quotes as part of its analysis. With such an application in the system actually, with two or more suchapplications, . there exists a type of observer that could detect the type of inconsistent ordering CBCASTpermits. Thus, CI.AST would no longer be adequate to ensure consistency when such an application is intl.In effect, C.AST can be used when any conflicting multicasts are uniquely ordered along a single causalchain. In such cases, the CBCASTguarantee is strong enough to ensure that all the conflicting mulficasts areSThe statement that CBCAST is weaker than ABCAST may seem imprecise as we have stated the problem, the two protocolssimply provide diffe.mforms of onlering.However,   venion ofABCASr acnmlly ex.nds the pardalcl.Axr orderingimo mud one it is acausaatondc mulficaat primitive. An argument can be made that an ABCAST protocol that is not causal cannotbe used asynchronously, hence we see strong reasons for implemenffLng ABC.ASTin this manner.18seenin thesameorderby all recipients specifically, the causal dependency order. If concurren multicastsarise in such a system, the data multicast on each independent causal chain will be independent of datamulticast on other causal chains the operations performed when the corresponding messages are deliveredwill commute. Thus, the interleaving permitted by CBCAST is not noticable within the application.Efficient load sharing during surges of activity in the porkbeUies pit may not seem like a compelling reasonto employ causal multicasL However, the same communication pauem also arises in a different context aprocess group that manages replicated or coherently cached data. Pmceases that update such data typicallyacquire a lock, then issue a stream of asynchronous updates, and then release the lock. There will generallybe one update lock for each class of related data items, so that acquisition of the update lock rules out anypossible conflicting updates. 9 Indeed, mutual exclusion can sometimes be inferred from other propertiesof an algorithm, hence such a pattern may arise even without an explicit locking stage. By using CBCASTfor this communication, an efficient, pipelined data flow is achieved. In particular, there will be no need toblock the sender ofa multicast, even momentarily, unless the group membership is changing at the time themessage is sent.The tremendous performance advantage of CBCA3Tover ABCASTmay not be immediately evidenL However,when one considers bow fast modem processors are in comparison with communication devices, it shouldbe clear that any primitive that unnecessarily waits for a reply to a message could introduce substantialoverhead. This occurs when ABC.ASTis used asynchronously, but where the sender is sensitive to messagedelivery order. For example, it is common for an application that replicates a table of pending requestswithin a group to use multicast each new request, so  all members can maintain the same table. In suchcases, if the way that a request is handled is sensitive to the contents of the table, the sender of the multicastmust wait until the muiticast is delivered before acting on the request. Using ABCAST the sender will needto wait until the delivery order can be determined. Using , the update can be issued asynchronously,and applied immediately to the copy maintained by the sender. The sender thus avoids a potentially longdelay, and can immediately continue computation or reply to the request. When a sender generates burstsof updates, also a common pattern, the advantage of CScAsr over ABCAST is even greater.The disadvantage to using CBCAST is that the sender needs mutual exclusion on the part of the table beingupdated. However, our experience suggests that if mutual exclusion has strong benefits, it is not hardto design applications to have this property. A single locking operation may suffice for a whole seriesof multicasts, and in some cases locking can be entirely avoided just by appropriate structuring the dataitself. This translates to a huge benefit for many asynchronous applications, as seen in the performance datapresented in BSS91 .The distinction between causal and total event orderings CBCAST and ABCAST has parallels in othersettings. Although ISis was the first distributed system to enforce a causal delivery ordering as part of.n Isis applications,locks areused primarilyfor mutualexclusion on possiblyconflictingoperations,such asupdateson relateddata items. In the case of replicateddata.thisresults in an algoriln similarto  primmycopy updatein which the primary copychanges dynamically.The execution model is nontransactionaLand theeis no needforresdlocks or for  twophase locking rule.This is discussed furtherin Sec. 7.19a communication subsystem Bir85. the approach draws on Lampons prior work on logical notions oftime. Moreover, the approach was in some respects anticipated by work on primary copy replicationin database systems BHG87. Similarly, close synchrony is related both to Lamports state machineapproach to developing distributed software SclO0 and to the database serializability model, discussedfurther below. Work on parallel processor archi has yielded a memory update model called weakconsistency DSB86, TH90, which uses a causal dependency principle to increase parallelism in the cacheof a parallel processo And, a causal convxme property has been used in work onazy update in sharedmemory mtdtiprocessors ABHN91 and distributed database systems JB89, LLS90. A more detaileddiscussion of the conditions under which  can be used in place of AIVr appea in Sch88, BJ89.4.1 Summary of benefits due to virtual synchronyBrevity precludes a more detailed discussion of virtual synchrony, or how it is used in developing distributedalgorithms within ISLS. However, it may be useful to summarize the benefits of the model. Allows code to be developed assuming a simplified, closely synchronous execution model. Supports a meaningful notion of group state and state transfer, both when groups manage replicateddata, and when a computation is dynamically partitioned among group members. Asynchronous, pipelined communica6o Treatment of communication, process group membership changes and failures through a single,eventoriented execution model.Failme handling through a consistently presented system membership list integrated with the communication subsystem. This is in contrast to the usual approach of sensing failures through timeoutsand channels breaking, which would not guarantee consistency.The approach also has limitations Reduced availability during LAN partition failures only allows progress in a single partition, andrequires that a majority of sites be available in that partition.s Risks incorrectly classifying an operational site or process as faulty.The virtual synchrony model is unusual in offering these benefits within a single framework. Moreover,theoretical arguments exist that no system that provides consistent distributed behavior can completely evadethese limitations. Our experience has been that the issues addressed by virtual synchrony are encounteredin even the simplest distributed applications, and that the approach is general, complete, and theoreticallysotmxi.2O The Isis ToolkitHgure 8 Styles of groupsThe ISlS toolkit provides a collection of higherlevel msms for forming and managing process groupsand implementing groupbased software. This section illustrates the specifics of the approach by discussingthe styles of prnce. group supported by the system and giving a simple example of a distributed databaseapplication.ISlS is not the first system to use process groups as a programming tool at the time the system was initiallydeveloped, Cheritons V system had received wide visibility CZ83. More recently, group mechanisms havebecome common, exemplified by the Ameoba system KTHB89, the Chorus operating system RAA88,the Psync system PBS9, a high availability system developed by Ladin and Liskov LLSg0, IBMs AASsystem CDg0, and Transis ADKM91. Nonetheless, Isis was first to propose the virtual synchrony modeland to offer high performance, consistent solutions to a wide variety of problems through its toolkit. Theapproach is now gaining wide acceptance i5.1 Styles of groupsThe efficiency of a distributed system is limited by the information available to the protocols employed forcommunication. This was a consideration in developing the Isis process group interface, where a trade, offhad to be made between simplicity of the interface and the availability of accurate information aboutgroup membership for use in multicast address expansion. As a consequence, the Isls application interfaceintroduces four styles of process groups that differ in how processes interact with the group, illustrated inteAt the time of  writing our group is working with the ftware Foundation on integration of a new version of thetechnology into Mach the OSF 1AD version and with Unix International, which plans a reliable group mechanism for UI Atlas.21Fig. 8 anonymousgroupsarenotdistinguishedfTomexplicitgroupsat this levelof thesystem.Isis isoptimizedto detectandhandleeachof thesecases efficiently.Peer groups These arise where a set of p cooperate closely, for example to replicate data. Themembenhip is often used as an input to the algorithm used in handling requests, as for the concurrentdatabase search described earlier.Clientserver groups In Isis, any process can communicate with any group given the groups name andappropriate permissions. However, if a nonmember of a group will multicast to it repeatedly, betterperformance is obtained by lust registering the sender as a cent of the group this permits the systemto optimize the group addressing protocol.Diffusion groups A diffusion group is a clientserver group in which the clients register themselves but inwhich the members of the group send messages to the full client set and the clients are passive sinks.Hierarchical groups A hiecal group is a structure built from multiple component groups, forreasons of scale. Applications that use the hierarchical group initially contact its root group, butare subsequently redirected to one of the constituent subgroups. Group data would normally bepartitioned among the subgroups. Although tools are provided for multicasting to the full membershipof the hierarchy, the most common communication pattern involves interaction between a client andthe members of some subgroup.There is no requirement that the members of a group be identical, or even coded in the same language orexecuted on the same architecture. Moreover, multiple groups can be overlapped and an individual processcan belong to as many as several hundred diffenmt groups, although this is uncommon. Scaling is discussedfurther below.5.2 The toolkit interfaceAs noted earlier, the performance of a distributed system is often limited by the degree of communicationpipelining achieved. The development of asynchronous solutions to distributed problems can be tricky, andmany Isis users would rather employ less efficient solutions than risk errors. For this reason, the toolkitincludes asynchronous implementations of the more important distributed programming paradigms. Theseinclude a synchronization tool that supports a form of locking based on distributed tokens, a replication toolfor managing replicated data, a tool for faulttolerant primarybackup server design that loadbalances bymaking different group members act as the primary for different requests, and so forth a partial list appearsin Table I. Using these tools, and following programming examples in dc ISIS manual, even nonexpertshavc been successful in developing faulttolerant, highly asynchronous distributed software.22 Process groups create, delete, join transferring state. Group multicast CBCAST, ABCAST, collecting 0, 1 QUORUM or ALL replies 0 replies gives anasynchronousmulticas0. Synchronization Locking, with symbolic strings to represent locks. Deadlock detection or avoidancemust be addressed at the application level. Token passing.Replicated data Implemented by broadcasting updates to group having copies. Transfer values toprocesses that join using state transfer facihty. Dynamic system reconfiguration using replicatedconfiguration data. intupdate logging, spooling for state recovery after failure.Monitoring facilities Watch a process or site, trigger actions after failures and recoveries. Monitorchanges to process group membership, site failures, etc.Distributed execution facilities Redundant computation all take same action. Subdivided amongmultiple servers. Coordinatorcohort primarybackup.Automated recovery When site recovers, program automatically restarted. If first to recover, stateloaded from logs or initialized by soRwar. Ise, atomically join active process group and transferstate.WAN communication Reliablc longhaul message passing and file transfer facility.Table I ISIS tools at process group levelFigures 9 and 10 show a complete, faulttoleram database server for maintaining a mapping from namesascii strings to salaries Cmtegers. The example is in standard C. The server initializes Isis and declaresthe procedures that will handle update and inquiry requests. The ssman.oop dispatches incomingmessages to these procedures as needed other styles of main loop are also supported. The formattedIOstyle of message generation and scanning is specific to the C interface, where type information is notavailable at mntime.The state transfer routines are concerned with sending the current contents of the database to a server thathas just been started and is joining the group. In this situation, Isis arbitrarily selects an existing server todo a state transfer, invoking its state sending pure. Each call that this procedure makes to xgeroutwill cause to an invocation of zcvstate on the receiving side in our example, the latter simply passesthe message to the update procedure the same mes.ge format is used by sendstate and update. Ofcourse, there are many variants on this basic scheme for example, it is possible to indicate to the system thatonly certain servers should be allowed to handle state transfer requests, to refuse to allow certain processesto join, and so forth.The client program does a pglookup to find the server. Subsequently, calls to its query and updateproceduresaremapped intomessages totlmserver.The nCAST callsaremapped to theappropriatedefault23include isis.hdefine UPDATEdefine QUERYmain isisinit 0 isisentry UPDATE, update, update isisentry QUERY, query, query pgjoindemossalaries, PGXFER, sendstate, rcvstate, 0isismainloop 0 update.register message mpIchar name32int salarysgget rap, s, d, name, salary setsalaryname, salary query rapregister message mpchar name32int salarymsggetmp, s,d, namesalary  getsalarynamereplymp, d, salarysend statestruct sdbentry spforsp  sdbhead sp  sdbtail sp  spsnextxfer out s, d, spsname, spssalary rcvstate mpregister message mpupdatempFigure 9 A simple database servcr24include isis. hdefine UPDATE 1define QUERY 2address servermain isisinit 0 Lookup database and register as a client for better performance server  pglookupdemossalaries pgclient server geeupdate name, salarychar namebcast server, UPDATE, s, d, name, salary, 0get salary namechar nameAnt salarybcastserver, QUERY, s, name, 1, d, salaryreturn salary Figun I0 A clicnt of the simple database service251RAIERQATAFEEDSFignm 11 Process group architecture of brokerage systemfor the group  ABCAST in this case.The database server of Hgure 9 uses a redundant style of execution in which the client broadcasts eachrequest and will receive multiple, identical replies from all copies. In practice, the client will wait for thefirst reply and ignore all others. Such an approach provides the fastest possible reaction to a failure, but hasthe disadvantage of consuming n times the wurces of a faultintolerant solution, where n is the size of theprocess group. An alternative would have been to subdivide the search so that each server performs nthof the work. Here, the client would combine responses from all the servers, repeating the request ifa serverfails instead of replying, a condition readily detected in Isls.Isis interfaces have been developed forC, C, Fortran, Common Lisp, Ada and Smalhalk, and ports of Isisexist for UNIXworkstations and mainframes from all major vendors, as well as for Mach, Chorus, ISC andSCO UNIX, the DEC VMS system, and Honeywells Lynx OS. Data within messages is represented in thebinary format used by the sending machine, and converted to the format of the destination upon receptionif necessary, automatically and transparently.6 Who uses Isis, and howThis section briefly reviews several Isls applications, looking at the roles that Isis plays.6.1 Brokerage26A numberof ISls users are concerned with financial computing systems such as the one cited in theintroduction. Hgure 11 illustrates such a system, now seen from an internal perspective in which groupsunderlying the services employed by the broker become evident. The architecture is a clientserver one,in which the servers filter and analyze streams of data. Faulttolerance here refers to two very differentaspects of the application. Hrst, financial systems must rapidly restart failed components and reorganizethemselves so that service is not interrupted by softw or hardware failures. Second, there are specificsystem functions that require faulttolerance at the level of files or database, such as a guarantee that afterrebooting a file or database manager will be able to recover local data files at low cost. ISlS was designedto address the first sort of problem, but includes several tools for solving the latter one.Generally, the approach taken is to represent key services using process groups, replicating service stateinformation so that even if one server process fails the other can respond to requests on its behalf. Duringperiods when n service programs are operational, one can often exploit the redundancy to improve responsetime thus, rather than asking how much such an application must pay for faulttolerance, more appm.pilate questions concern the level of replication at which the overhead begins to outweigh the benefits ofconcurrency, and the minimum acceptable performance assuming k component failures. Faulttolerance issomething of a sideeffect of the replication approach.A significant theme in financial computing is use of a subscriptionpublication style. The basic ISlscommunication primitives do not spool messages for future replay, hence an application numing over thesystem, the NEWS facility, has been developed to support tisfunctionality.A final aspect of brokerage systems ts that they re a dynamically varying collection of services. Afirm may work with dozens or hundreds of financial models, predicting market behavior for the financialinstruments being waded under varying market conditions. Only a small subset of these services will beneeded at any time. Thus, systems of this sort generally consist of a processor pool on which servicescan be started as necessary, and this creates a need to support an automatic remote execution and loadbalancing mechanism. The heterogeneity of typical networks complicates this problem, by introducing apattern matching aspect i.e., certain programs may be subject to licensing restrictions, or require specialprocessors, or may simply have been compiled for some specific hardware configuration. This problem issolved using the Isis network resourcemanager, an application described later in this section.6.2 Database replication and database triggersAlthough the Isls computation model differs from a transactional model see also See. 7, Isis is useful inconstructingdistributeddatabaseapplications.In fact,asmany ashalfof theapplicationswith which weare familiar are concerned with this problem.Typical uses of Isls in database applications focus on replicating a database for faulttolerance or to supportconcurrent searches for improved performance. In such an architecture, the database system need not be27aware thatIslsispresent.Databaseclientsaccessthedatabasethrougha layerofsoftwarethatmulticastsupdates using AA to the set of servers, while issuing queries directly to the least loaded server. Theservers are supervised by a process group Oat informs clients of load changes in the server pool, andsupervises the restart of a failed server from a checkpoint and log of subsequent updates. It is interestingto realize that even such an unsophisticated approach to database replication addresses a widely perceivedneed among database users.  the long run, of course, compwensive support for applications such as thiswould require extending Isls to support a transactional execution model and to implement the XAXOpenstandants.Beyond database replication, IsIs users have developed WAN databases by placing a local database systemon each LAN in a WAN system. By monitoring the update traffic on a LAN, updates of importance toremote users can be intercepted and distributed through the IsIs WAN architecture. On each LAN, a servermonitors for incoming updates and applies them to the database server as necessary. To avoid a costlyconcurrency control problem, developers of applications such as these normally partition the database sothat the data associated with each LAN is directly updated only from within that LAN. On remote LANs,such data can only be queried and could be stale, but this is still sufficient for many applications.A final use of Isls in database settings is to implement database ggers. A trigger is a query thatis incrementally evaluated against the database as updates occur, causing some action immediately if aspecified condition becomes true. For example, a broker might request that an alarm to be sounded ifthe risk associated with a financial position exceeds some threshold. As data enters the financial databasem by the brokerage, such a query would be evaluated repeatedly. The role of ISlS is in providingtools for reliably notifying applications when such a trigger becomes enabled, and for developing programscapable of taking the desired actions despite failures.6.3 Major Isis.based utilitiesIn the above subsection, we alluded to some of the faulttolerant utilities that have been built over Isis.There are currently five such systemsNEws This application supports a collection of communication topics to which users can subscribeobtaining a replay of recent postings or post messages. Topics are identified with filesystem stylenames, and it is possible to post to topics on a remote network using a mail address notationthus, a Swiss brokerage firm might post some quotes to GENEVAQUOTIBMNEWYORK. Theapplication creates a process group for each topic, monitoring each such group to maintain a historyof messages posted to it for replay to new subscribers, using a state transfer when a new memberjoins.NMGR This program manages batchstyle jobs and performs load sharing in a distributed setting.This involves monitoring candidate machines, which are collected into a processor pool, and then28schedulingjobs on thepool. A pattern matching mechanism is used for job placement if severalmachines are suitable for a given job, a criteria based on load and available memory is used to selectone this criteria can readily be changed. When employed to manage critical system services asopposed to running batchstyle jobs, the program monitors each service and automatically restartsfailed components. Parallel make is an example of a distributed application program that usesNMGR for job placement it compiles appficatiom by fanning out compilation subtasks to compatiblemachine Dg2EIT. This system SBM89 provides faulttoerant NFScompatible file storage. Ffles are replicated both to increase performance by supporting parallel reads on different replicas and for fatdttolerance the level of replication is varied depending on the style of access detected by the system atmntime. After a failed node recovers, any filesit mmmged are automatically brought up to date. Theapproach conceals file replication fzom the user, who sees an NFcompatible filesystem interface. MErALOMrrA META is an extensive system for building faulttolerant reactive control applicalions MCWB91, Woo91. It consists of a layer for instrumenting a distributed application orenvironment, by defining sensors and actuators. A sensor is any typed value that can be polled ormonitored by the system an actuator is any entity capable of taking an action on request. Builtinsensors include the load on a machine, the status of software and hardware components of the system,and the set of users on each machine. Userdefined sensors and actuators extend this initial set.The raw sensors and actuators of the lowest layer are mapped to abstract sensors by an intermediatelayer, which also supports a simple databasestyle interface and a triggering facility. This layersupports an entityrelation data model and conceals many of the details of the physical sensors, suchas polling flueney and faulttolerance. Sensors can be aggregated, for example by taking theaverage load on the servers that manage a replicated database. The interface supports a simple triggerlanguage, which will initiate a prespecified action when a specified condition is detected.Running over MmA is a distributed language for specifying control actions in highlevel terms, calledLoMrrA. LOMITA code i imbedded into the UNIX CSH command interpretor. At runtime, LoMrrAcontrol statements are expanded into distributed finite state machines triggered by events that canbe sensed local to a sensor or system component a process group is used to implement aggregates,perform these state transition, and to notify applications when a monitored condition arises. SPOOLERIIqoHAUL F.rrY This subsystem is responsible for widearea communication MB90and for saving messages to groups that are only active periodically. It conceals link failures andpresents an exactlyonce communication interface.6.4 Other Isis applicationsAlthough this section covered a variety of Isis applications, brevity precludes a systematic review of the fullrange of soRwate that has been developed over the system. In addition to the problems cited above, Isis has29beenapplied to telecommunications switching and inteLligent networking applications, military systems,such as a proposed replacement for the AEGIS aircraft tracking and combat engagement system, medicalsystems, graphics and virtual reality applications, seismology, factory automation and production control,reliable management and resource scheduling for shared computing facilities, and a widearea weatherprediction and storm tracking system 1oh93, Thog0. ASC92. Isxs has also proved popular for scientificcomputing at laboratories such as CERN and Los Alamos, and has been applied to such problems as a beamfocusing system for a particle accelerator, a weathersimulation that combines a highly parallel ocean modelwith a vectorized atmospheric model and displays output on advanced graphics workstations, and resourcemanagement sotware for shared supercomputing facilities.It should also be noted that although the paper has focused on LAN issues, Isls aLso supports a WANarchitecture and has been used in WANs composed of up to ten LANs. It Many of the applications citedabove are structmed as LAN solutions intew.onnected by a reliable, but less responsive, WAN layer.7 Isis and other distributed computing technologiesOur discussion has overlooked the sorts of realthne issues that arise in the Advanced Automation System,a nextgeneration airtraffic control system being developed by IBM for the FAA CD90, CASD85, whichalso uses a processgroup based computing model. SimUarly, one might wonder how the Isis executionrondel compares with transactional database execution models. Unfommately, these are complex issues,and it would be difficult to do justice to them without a lengthy digression. Briefly, a technology like theone used in AAS differs from ISlS in providing strong realtime guarantees provided that timing assumptionsare tespecte However, a process that experiences a timing fault in the AAS model could receive messagesthat other processes reject, or reject messages others accept, because the criteria for accepting or rejectinga message uses the value of the local clock. This can lead to comistency violations. Moreover, if faultis transient e.g. the clock is subsequently resynchmnized with other clocks, the inconsistency of sucha process could spread nothing prevents it from initiating new multicasts, which other processes willaccepL ISIS, on the other hand, guarantees that consistency will be maintained, but not that reaJtime deliverydeadlin will be achieved.The relationship between Isis and transactional systems originates in the fact that both virtual synchronyand transactional serializability are orderbased execution models BHG87. However, where the toolsoffered by a database system focus on isolation of concurrent transactions from one another, persistentdata and rollback abort mechanisms, those offered in Isls are concerned with direct cooperation betweenmembers of groups, failure handling, and ensuring that a system can dynamically reconfigure itself to maketiThe WAN ttchiteclare of isis ii similar to the I,AN structure, bet because WAN partilionJ are more common, encourages amore uyncinous programming style. WAN communication and link state is logged 1odisk files unlike I.AN communication,which enables LSLSto retrammit messages lost when  WAN partition oexm and to suppressduplicate messages. WAN issues arediscuued in more detail in MB90.3Oforward progress when partial failures occur. Persistency of data is a big issue in database systems, butmuch less so in Isis. For example, the commit problem is a form of reliable multicast, but a commit impliesserializabUity and permanence of the transaction being committed, while delivery of a multicast in isisprovides much weaker guarantees.8 ConclusionsWe have argued that the next generation of distributed computing systems will benefit from support forprocess groups and group programming. Arriving at an appropriate semantics for a process group mechanismis a difficult problem, and implementing those semantics would exceed the abRities of many distributedapplication develope. Either the operating system must implement these mechanisms or the reliability andperformance of groupstructured applications is unlikely to be acceptable.The Isis system provides tools for programming with process groups. A review of research on the systemleads us to the following conclusionss Process groups should embody strong semantics for group membership, communication, and synchronization. A simple and powerful model can be based on closely sync.hronized distributed execution,but high performance requires a more asynchronous style of execution in which communication isheavily pipelined. The vrtuasynchrony approach combines these benefits, using a closely synchronous execution model, but deriving a substantial performance benefit when message ordering cansafely be relaxed. Efficient protocols have been developed for supporting virtual synchmny. Nonexperts find the resulting system relatively easy to use.This paper is being written as the first phase of the ISlS effort approaches its conclusion. We feel that the initialsystem has demonstrated the feasibility of a new style ofdistributed computing. As reported in BSS91, Isisachieves levels of performance comparable to those afforded by standard technologies RPC and streamson the same platforms. Looking to the future, we are now developing an ISls microkemer suitable forintegration into nextgeneration operating systems such as Mach and Chorus. This new system will alsoincorporate a security architecture RBG92 and a real time communication suite. The programming model,however, will be unchanged.Proce group programming could ignite a wave of advances in reliable distributed computing, and ofapplications that operate on distributed platforms. Using current technologies, it is impractical for typicaldevelopers to implement high reliability software, selfmanaging distributed systems, to employ replicateddata or simple coarsegrained parallelism, or to develop software that reconfigures automatically after a31failureor recovery.Consequently,althoughcurrent networks embody tremendously powerful computingresources, the programmers who develop software for these environments are severely constrained by adeficient software infrastructure. By removing these unnecessary obstacles, a vast groundswell of reliabledistributed application development can be unleaslr.d.9 AcknowledgementsThe IslS effort would not have been possible without extensive contributions by many past and presentmembers of the project, users of the system, and wacawrs in the field of distributed computing. Thanksare due to Micah Beck, Tim Clark, Robert Cooper, Brad Glade, Barry Gleeson. Holger Herzog, GuemeyHunt, Tommy Joseph. Ken Kane, Jacob Levy, Messac Makpangou, Keith Marzullo, Mike Reiter, AletaRicciardi, Fred Schneider, Andre Schiper, Frank Schmuck, Stefan Sharkansky, Alex Siegel, Pat Stephenson,Robbert van Renes., and Mark Wood. In addition, the author also gratefutly acknowledges the help ofMauren Robinson, who prepared the figures for this paper, and the anonymous referees, whose carefuland constructive comments on an initial version of this paper lead to a substantial improvements in thepesentation.32ReferencesABHN91 KM91, .qC92BHG87Bir85BJ87BJ89BSS91CASD85CD90Mustaque Ahamad, James Bums, Phillip Hutto, and Gil Neiger. Causal memory. Technicalreport, College of Computing, Georgia Institute of Technology, Atlanta, GA, July 1991.Yair Amir, Danny Dolev, Shlomo Kramer, and Dalia Malki. Transis A communicationsubsystem for high availability. Technical Report TR 9113, Computer Science Department,The Hebrew University of Jerusalem, November 1991.T. Anthony Allen, Wdliam Sbeppard, and Steve Condon. Imis A distributed query and reportformatting system. In Proceedings of the SUN Users Group Meeting, pages 94101. SunIficnxstems Inc., 1992.Ken Birman and Robert Cooper. The ISIS project Real experience with a fault tolerantprogramming system. European SIGOPS Workshop, September 1990. To appear in Operating Systems Review, April 1991 also available as Comer University Computer ScienceDepartment Technical Report TR901138.Pldlip A. Bemstein, Vassm Hadzilacos, and Nathan Goodman. Concurrency Control andRecovery In Database Systems. AddisonWesley, 1987.Kemth P. Birman. Replication and availability in the ISIS system. In Proceedings of the TenthACM Symposium on Operating Systems Principles, pages 7986, Orcas Island, Washington,December 1985. ACM SIGOPS.Kenneth P. Birman and Thomas A. Joseph. Exploiting virtual synchrony in distributed systems.In Proceedings of the Eleventh ACM Symposium on Operating Systems Principles, pages 123138, Austin, Texas, November 1987. ACM SIGOPS.Ken Birman and Tommy Joseph. Exploiting replication in distributed systems. In Sape Mullender, editor, Distributed Systems, pages 319368, New York, 1989. ACM Press, AddisonWesley.Kenneth Birman, Andre Schiper, and Patrick Stephenson. Lightweight causal and atomicgroup multicast. ACM Transactions on Computer Systems, 93, August 1991.Haviu Cristian, Houtan Aghili, H. Ray Strong, and Danny Dolev. Atomic broadcast Fromsimple message diffusion to Byzantine agreement. In Proceedings of the Fifteenth InternationalSymposium on FaultTolerant Computing, pages 200206, Ann Arbor, Michigan, June I985.Institution of Electrical and Electronic Engineers. A revised version appears as IBM TechnicalReport RJ5244.FlaviuCristian and Robert Dy. Faulttolerance in the advanced automation system.Technical Report RJ7424, IBM Research Laboratory, San Jose, California, April 1990.33CriSSCZ83DSB86ms9Joh93KTHB89LamTSILL86MB90MCWB91PBS89PetS7Flaviu Cristian. Reaching agreement on processor group membership in synchronous distributed systems. Technical Report RJ5964, IBM Research Laboratory, March 1988.David Cheriton and Wflly Zwaenepoel. The distributed V kernel and its performance fordiskless workstations. In Proceedings of the Ninth ACM Symposium on Operating SystemsPrinciples, pages 129140, Bretton Woods, New Hampshire, October 1983. ACM SIGOPS.M. Dubois, C. Schettdch and E Briggs. Memory access buffering in multiprocessors. InProceedings of the 13th Annual International Symposium on Computer Architecture, pages434442, June 1986.Thomas Joseph and Kenneth Binnan. Low cost management of triplicated data in faulttolerantdistributed systems. A CM Transactions on Computer Systems, 415470, February 1989.Dag Johansen. Stormcast Yet another exercise in distributed computing. In Dagohansen andF Brazier, editors, Distributed Open Systems in Perspective. IEEE, New York, 1993.M. Frmm Kaashoek, Andrew S. Tanenbaum, Susan Flynn Hummel, and Henri E. Bal. Anent reliable broadcast protocol. Operating Systons Review, 234519, October 1989.Leslie Lamport. Tune, docks, and the ordering of events in a distributed system. Commwffcations oftheACM, 217558565, July 1978.Barbara Liskov and Rivka Ladin. Highlyavailable distributed services and faulttolerantdistributed garbage collection. In Proceedings of the Ffth ACM Symposium on Principles ofDistributed Computing, pages 2939, Calgary, Alberta, August 1986. ACM SIGOPSSIGACT.Rivka Ladin, Barbara Liskov, and Liuba Shrira. Lazy replication Exploring the semantics offistributed services. In Proceedings of the Tenth A CM Symposium on Principles of DistributedComputing, pages 4358, Qeubec City, Quebec, August 1990. ACM SIGOPSSIGACT.Messac Makpangou and Kenneth Birman. Designing application software in wide area networksettings. Technical Report 901165, Department of Computer Science, Comell University,1990.Keith Marzullo, Robert Cooper, Mark Wood, and Kenneth Birman. Tools for distributedapplication management. IEEE Computer, August 1991.Larry L. Peterson, Nick C. Bucholz, and Richard Schlichting. Preserving and using context informationin interprocesscommunication. ACM Transactionson Computer Systems,73217246,August 1989.LarryPcterson. Preservingcontextinformationinan ipcabstraction.In SixthSymposium onReliabilityinDistributedSoftwareand Database Systems,pages 2231.IEEE, March 1987.34RAA88RB91tReG92SBM89Sch88SChg0SS83Tan88THg0Tho90TS92Woo91M. Rozier, V. Abrossimov, M. Armand, E Hermann, 2. Kaiser, S. Langlois, P. Leonard, andW. Neuhauser. The chorus distributed system. Computer Systems, pages 299328, Fall 1988.Aleta Ricciardi and Kenneth Birman. Using process groups to implement failure detection inasynchronous environments. In Proceedings of the Eleventh ACM Symposium on Principlesof Distributed Computing, Montreal, Quebec, August 1991. ACM SIGOPSSIGACT.Michael Reiter, Kenneth R Birman, and Li Gong. Integrating security in a group orientedcfmtributedsystem. In Proceedingsof theIEEE Symposium on Research In SecurityandPrvacy,pages 1832,May 1992.Alex Siegel,Kenneth Birman, and KeithMarzuIIo.DeceitA flexibledistributedfilesystem.TechnicalReport891042,Departmentof Computer Science,Comell University,1989.Frank Schmuck. The Use of Efficient Broadcast Primitives in Asynchronous DistributedSystems. PhD thesis, Comell University, 1988.Fred B. Schneide Implementing faulttolerant services using the state machine approach Atutorial. ACM Computing Surveys, 224299319, December 1990.Richard D. Schlichting and Fred B. Schneider. Failstop processors an approach to designingfaulttolerant computing systems. ACM Transactions on Computer Systems, 13222238,August 1983.Andrew Tanenbaum. Computer Networks. Prentice Hall, second edition, 1988.Josep TorreRas and ohn Hennessey. Estimating the performance advantages of relaxingconsistency in a shared memory multiprocessm Technical Report CSLTN90365, ComputerSystems Laboratory, Stanford University, February 1990.Thomas C. Bache et. a. The intelligent monitoring system. Bulletin of the SeismologicalSociety of America, 8065977, December 1990.John Turek and Dennis Shasha. The many faces of Consensus in distributed systems. IEEEComputer, 25681 1992.Mark Wood. Constructing reliable reactive systems. PhD thesis, Comer University, Department of Computer Science, December 1991.
