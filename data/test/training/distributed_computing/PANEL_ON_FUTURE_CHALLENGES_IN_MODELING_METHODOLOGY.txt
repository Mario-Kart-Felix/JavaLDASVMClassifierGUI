Proceedings of the 2004 Winter Simulation Conference
R .G. Ingalls, M. D. Rossetti, J. S. Smith, and B. A. Peters, eds.



PANEL ON FUTURE CHALLENGES IN MODELING METHODOLOGY


Simon J. E. Taylor (Convener)

Centre for Applied Simulation Modeling
Department of Information Systems and Computing
Brunel University
Uxbridge, Middx UB8 3PH, U.K.
Peter Lendermann

Production and Logistics Planning Group
Singapore Institute of Manufacturing Technology
71 Nanyang Drive, Singapore 638075, SINGAPORE


Ray J. Paul

Centre for Applied Simulation Modeling
Department of Information Systems and Computing
Brunel University
Uxbridge, Middx UB8 3PH, U.K.
Steven W. Reichenthal

Boeing
3370 Miraloma Ave.
Anaheim, CA 92803, U.S.A.


Steffen Straßburger

Fraunhofer Institute for Factory Operation
and Automation
Department Virtual Development
Sandtorstraße 22, 39106 Magdeburg, GERMANY
Stephen J. Turner

Parallel & Distributed Computing Centre
School of Computer Engineering
Nanyang Technological University
Singapore 639798, SINGAPORE



ABSTRACT
This panel paper presents the views of six researchers and
practitioners of simulation modeling.  Collectively we at
tempt to address a range of key future challenges to model
ing methodology.  It is hoped that the views of this paper,
and the presentations made by the panelists at the 2004
Winter Simulation Conference will raise awareness and
stimulate further discussion on the future of modeling
methodology in areas such as modeling problems in busi
ness applications, human factors and geographically dis
persed networks; rapid model development and mainte
nance; legacy modeling approaches; markup languages;
virtual interactive process design and simulation; stan
dards; and Grid computing.
1 INTRODUCTION
Each year at the Winter Simulation Conference there are
panels that convene to discuss various fascinating, for
ward-looking topics.  In 2003 these included (in no particu
lar order) the future of simulation, the future of simulation
technology, distributed simulation, education and the ROI
of simulation.  All of these have some impact on modeling
methodology. To contribute to this set of annual stimulat

ing discussions, and to consider these from the perspective
of modeling methodology, this panel has been convened.
Each of the panelists was given the task of considering
what to them are the future challenges in modeling meth
odology.  These include modeling problems in business
applications, human factors and geographically dispersed
networks; rapid model development and maintenance; leg
acy modeling approaches; markup languages; virtual inter
active process design and simulation; standards; and Grid
computing.  It is hoped that this will provide a wide per
spective on the future of modeling methodology.
2 POSITION STATEMENT OF
PETER LENDERMANN
This contribution is specifically looking from the point of
view of discrete event simulation as a tool for virtual ex
perimentation to enable design and performance enhance
ment in manufacturing and logistics. In a world of increas
ing complexity and customization it will be very important
to make sure that the complexity of the systems that simu
lations are supposed to represent does not develop faster
than the capability to model these systems. To achieve this,
modeling techniques will have to meet five major require
ments as described in the following sections.

Taylor, Lendermann, Paul, Reichenthal, Straßburger, and Turner

2.1 Representation of Business Applications
Firstly, modeling techniques have to take into account the
specific characteristics of today’s pull-environments, in
which operational execution plans are the result of a trans
lation from frequently-changing customer demand into ma
terial quantities to be released into and moved within the
manufacturing and logistics systems at pre-specified times.
These complex operational decisions are increasingly taken
over by scheduling systems. Therefore, high-fidelity mod
els can be created only if these scheduling systems are in
corporated into the simulation. Researchers at the Singa
pore Institute of Manufacturing Technology (SIMTech)
have previously highlighted the importance of this issue
and described relevant research achievements at the Winter
Simulation Conference (see e.g. Lendermann 2003).
2.2 Representation of Human Factors
Secondly, in complex manufacturing and logistics environ
ments there will always remain some operational decisions
that are taken by humans. Therefore it will be necessary to
be able to represent, model and analyze human intelligence
and behavior, and sometimes even effects such as fatigue.
On the application level, agent-based simulation could play
a more important role in the future to achieve this.
2.3 Representation of Geographically
Dispersed Networks
Thirdly, in today’s complex supply networks, events often
depend on what is happening at geographically distant lo
cations. This is where distributed simulation technology
comes into the picture. An example of how distributed
simulation can be applied to study complex scenarios to
enhance the performance of a semiconductor supply chain
is given in (Chong 2004).
2.4 Rapid Model Development
Also, today’s manufacturing and logistics systems have to
be designed fast: Many initiatives such as MDA
(<www.omg.org/docs/omg/03-06-01.pdf>), RM
ODP (<www.dstc.edu.au/Research/Projects/
ODP/ref_model.html>), DEVS (<www.sce.carl
ton.ca/faculty/wainer/standard/devs-tor.
pdf>), or OASIS (<www.oasis-open.org /home/
index.php>) have been pursued to develop the required
information technology standards. Other initiatives such as
the HLA-CSPIF (<www.cspif.com>), a worldwide fo
rum consisting of users, vendors and researchers to integrate
and enable interoperability between commercial offthe
shelf (COTS) simulation packages are under way. However,
a really significant reduction of the cycle time for simulation
modeling will only be possible if standardization also takes
place on the application level that would result in archived, re-usable simulation model components that require much
less customization effort.
2.5 Flexible Model Maintenance
Lastly, once manufacturing and logistics systems are de
signed they will continuously change throughout their life
time. Therefore it is necessary to be able to catch up with
simulation model maintenance in as a flexible manner as
possible. This could be enabled through symbiotic systems
that interact with the business application in a mutually
beneficial way and has been classified as a Grand Chal
lenge by the research community (see Dagstuhl 2003): A
symbiotic system is highly adaptive in a sense that the
simulation system not only performs what-if experiments
that are used to enhance the physical system, but also ac
cepts and responds to data from the physical system. The
physical system benefits from the optimized performance
that is obtained from the analysis of simulation experi
ments. In turn, the simulation system benefits from the
continuous supply of the latest input data and the automatic
validation of its outputs.
3 POSITION STATEMENT OF RAY J PAUL
My position is the “Problem Solving Minus the Simulation
Diversionary Triathlon.” A future challenge in modeling
methodology is to rid ourselves of the major limiting factor
in problem solving – legacy thinking!  Problem solving
will be improved by disavowing ourselves of these diver
sionary modeling activities.  This position selects three
from this Triathlon for attention.

• Model accuracy as exemplified by VV&A.  The
problem to be solved becomes forgotten in the pur
suit of modeling accuracy.  Model accuracy diverts
thinking from problem solving activities to model
ing activities.  The problem becomes a victim of
model – the model is highly accurate but solves the
wrong problem.  This point is lost by those who
have created the model as they are convinced that
the accuracy of the model will solve the problem
that is now a distant memory.
• Statistical output analysis. There is a vast litera
ture that feeds itself and there is little evidence of
practical use.  Anecdotally, the overwhelming re
sponse to “what I did with my simulation” is “I ran
it 10/20/100 times and calculated the mean of the
response.”  Theory and practice might eventually
come together if it was not for the observation that
the theory is intrinsically wrong.  For example, out
put streams from simulation models are not inde
pendently identically distributed (IID).  The only
way to make them so is to throw away most of the
output.  Also, models are constructed with great in
tellectual effort to capture the interactions in a sys
Taylor, Lendermann, Paul, Reichenthal, Straßburger, and Turner
tem.  All this knowledge is cheerfully thrown away,
ignored, or wasted in the analysis of the output.
• Bigger is better. Bigger models better represent
the real world.  Who needs this?  The real world is
complex and misunderstood.  Modeling attempts to
simplify this for understanding.  A big model there
fore adds to the complexity and misunderstanding
of the real world and extra misunderstanding in the
model itself.  The net gain is twice the pain!  Single
models well understood might explain something
about the complex real world.  Any model that is
not understood is helping us keep problem under
standing at bay.  A possible approach to this is grab
and glue, a quick and dirty approach that empha
sizes appropriate input/output mechanisms so that
the right problem is solved and not the right model
(Paul and Taylor 2002).

I hope the examples of the Triathlon challenge con
temporary views on “legacy modeling.”  I again remind
those who have forgotten, and introduce those who have
not heard, the words of the great Kiviat who at the 1990
Winter Simulation Conference brought to us the concept of
SINSFIT – Simulation is No Substitute for Intelligent
Thinking.  I urge readers of this panel paper to again go
forth and think!
4 POSITION STATEMENT OF
STEVE REICHENTHAL
My position regarding future challenges in modeling and
simulation pertains to markup languages developed for
simulation modeling. While this is still a relatively open
frontier for the simulation community, lessons may be
learned by observing the evolutions of HTML, web brows
ers, and XML.
Markup, as we know it today, was created in the
1970’s with SGML and was used in the narrow field of
high-end electronic publishing for about 20 years until the
creation of the web and HTML brought it into a broader
audience. Yet, even today, end users generally don’t care
much about HTML, because all browsers support a single
standard - imagine if that was not the case. Nevertheless,
web developers today do care about HTML, but don’t try
to build their own web browsers. It took several years,
however, for web browsers to become generally useful in
application development, and during that time the earlier
ways of providing user interfaces dominated:

• They were created from scratch
• Their basic features were well understood but
loosely integrated
• They were hard-coded to their applications
• Their development required a high degree of pro
gramming skill and high cost
• Their building blocks were significantly different
when using one vendor’s tool vs. another We can say the same things about developing simula
tions today, but no longer about user interfaces. Early
HTML was weak in that it could only provide text, graph
ics, and hyperlinks, so several significant features were
added over time which eliminated its shortcomings: behav
ior through scripts, plug-ins, the Document Object Model,
etc. Now, functionality scripted in HTML is balanced with
that provided by the web browser and plug-ins.
Leveraging the popularity of HTML, XML arrived
several years later as an easier-than-SGML way to create
an HTML-like markup language. The XML phenomenon
has spawned the creation of many markup languages and
particularly in the area processes modeling, where several
have emerged. What would have happened if XML was
popularized before HTML? Could it have been made popu
lar without HTML? Would there have been several
HTMLs? These are rhetorical questions. However, I be
lieve that the future technical challenges for any useful
simulation modeling language would be to provide a simi
lar utility as that afforded by HTML, with its added script
ing, plug-ins, and a general purpose object model. In an ef
fort to understand the challenges surrounding such a
language, The Simulation Reference Markup Language
(SRML) was developed to have HTML-like capabilities
specifically targeted for simulation model interchange, and
a study is underway at the Simulation Interoperability
Standards Organization (SISO) to evaluate the standardiza
tion issues for such a language.
Communities of interest have formed at standards or
ganizations which promote interoperability and inter
change through a consensus-based approach. One promis
ing XML modeling standard, which is currently under
definition at SISO, is called Encapsulated Base Object
Models (ECAP-BOMs). The basic goal of BOMs is to fa
cilitate modeling and simulation interoperability, reuse,
and composability through XML. Once developed, BOMs
would offer a standard way to define the communication
patterns which would be required among components, as
well as to provide a means for encapsulating packages of
data and behavior (objects) that could be shared among di
verse simulation tools - hence Encapsulated BOMs. The
technical challenges facing ECAP-BOMs are not difficult,
given that basic interchange problems have been solved by
the groups building web browsers, web servers, and other
applicable web technologies, like SRML. However BOMs
can only go so far in that an interest group will need to be
established in order to standardize the specific communica
tion patterns needed for process-oriented BOMs (P-BOMs)
to interact. Encapsulated P-BOMs could potentially be a
useful standard that would enable various simulation pack
ages to interchange models. A more difficult challenge fac
ing BOM standards in the near term will be that of gaining
broad support of an interested set of developers and ven
dors which could influence and support future BOM de
velopment and use.
Taylor, Lendermann, Paul, Reichenthal, Straßburger, and Turner

5 POSITION STATEMENT OF
STEFFEN STRAßBURGER
My position is based on the challenge of Virtual
Interactive Process Design and Simulation.  Looking at the
advances in simulation methodology in the past years
many scientists share the author’s opinion that no major
breakthroughs have been invented in the past years (Barton
et al. 2003). One exception could be seen in the develop
ment of the HLA standard which for the first time provides
a standardized architecture for simulation interoperability
which is in principle applicable in the entire simulation
community. Although far from being applied widely in in
dustry, HLA is certainly a success in an area where previ
ous attempts have failed (Straßburger 2001).
Although simulation methodology apparently has not
changed so much in the past years, many advances have
been made in the area of simulation tools (so-called com
mercial off-the-shelf simulation software). On the one hand
these advances promise easier simulation model creation.
The extent of fulfillment of this promise is another issue,
which is not discussed here, see (Rehn 2004) for some inter
esting insights on this issue. On the other hand much effort
has been put into the area of simulation output visualization.
For simulation systems with no built-in graphics capa
bilities, the animation system Proof Animation (Henriksen
2000) has been a reliable partner over the years for 2D
visualization. It offers post-processed and concurrent ani
mation capabilities on the Windows platform. For many
simulation problems 2D-visualisation is still the most effi
cient visualization method considering the effort needed to
build the animation and the benefit gained from it.
Increasingly more simulation systems tend to offer dif
ferent variants of 3D-animation. Some tools offer D
capabilities on-top of the normal simulation model genera
tion (e.g. Automod, eM-Plant), in other tools the modeling
process is directly done in a 3D environment (e.g.
QUEST). The general trend in industry towards the re
quirement of 3D visualization is connected to the rise of
the vision of the Digital Factory, heavily promoted by the
automotive industry.
The next logical step in this development is the intro
duction of immersive and interactive environments based
on Virtual Reality (VR) techniques. In such environments
users can experience their simulation model, they can walk
through their virtual factories, they can visually inspect the
different stations, analyze bottlenecks, etc.
Most importantly these environments can provide in
teractivity in different ways.

• The user can obtain additional information by in
teracting with the visualization component, e.g.,
by selecting a station and requesting a detailed
statistics about its usage. • The user can interactively modify the simulation
run by changing routings, processing times,
worker allocations, etc. Thus the user can experi
ment with the model in an immersive environ
ment as if he was standing in a real factory.
• The user can interactively modify the simulation
model. This case is partially similar to the previ
ous alternative, with the difference that the users
actions indeed change the simulation model of the
simulator permanently.
• The user can be inserted into the simulation, e.g.,
take over tasks of workers which are normally
part of the simulation. This can be done for train
ing purposes, e.g., to show workers which effects
certain actions will have.

The technical basis for enabling such virtual environ
ments is typically achieved by coupling one or more simu
lation systems with a virtual reality system. This can be
based on standards like HLA or simple network interfaces
like TCP/IP. Using standards like HLA has the advantage
that issues like synchronization between the VR and the
simulation are automatically taken care of. In pilot projects
at the Fraunhofer IFF different simulators and VR envi
ronments have been connected.
The overall objective of the described concept is to es
tablish VR as a command and control tool for factory de
sign and factory operation. The virtual world could act as
the integration platform for different simulation models
(e.g. OEM supplier models developed in different simula
tion tools). In the design phase of the factory, the processes
of the planned factory could be tested and optimized within
the VR world.
In the operation phase of the factory, the VR world
could act as the virtual representation of the real factory.
Based on on-line simulation concepts (Schulze et al. 1999)
and a connection to the shop-floor systems, the state of the
VR world (and the connected simulations) would reflect
the state of the real factory. In case of emergencies (e.g.
machine failure) the factory operator could plan and test
different plans of action (fast-forward simulation) and se
lect the best option. Even for daily work planning the vir
tual factory could provide the optimal basis since it is ini
tialized with the right initial conditions for all work
stations and it could have the connection to the relevant
ERP (enterprise resource planning) and order systems.
In summary, the topic of virtual-interactive process de
sign and simulation in immersive environments can be re
garded the next logical step in the development of visual 3D
simulation and is a logical consequence derived from the re
quirements of the Digital Factory. The vision of VR based
integration platforms is supported by technologies like HLA,
which help to integrate different simulation systems.
Taylor, Lendermann, Paul, Reichenthal, Straßburger, and Turner

6 POSITION STATEMENT OF
SIMON J E TAYLOR
In our discussion of “Future Challenges in Modeling
Methodology” I would like to consider whether or not
standards have any worth in the domain of simulation
modeling represented by users of the range of so-called
COTS Simulation Packages (CSPs) used to analyze prob
lems in dynamic, discrete event-based systems (e.g. Arena,
Witness, Simul8, etc.)  The CSPs are used to aid simula
tion modeling tasks such as model building, experimenta
tion, visualization, and reporting in a wide range of areas
including commerce, health and manufacturing.  A CSP is
therefore technology used by a simulation modeller to
solve a problem.  However, it also influences the concepts
and methods that the simulation modeller is able to bring to
bear on a problem.
Arguably, there are two current standards in simulation
modeling: the IEEE 1278 standard Distributed Interactive
Simulation (DIS) and the IEEE 1516 High Level Architec
ture (HLA).  The first of these is inappropriate for CSP
based simulation modeling as it deals with various domain
specific aspects of warfare simulation in a distributed envi
ronment. The second also concerns simulation in a distrib
uted environment but is domain-neutral (i.e. any information
to be exchanged between simulations (federates) can be
specified). In support of the type of simulation modeling de
scribed above, only the HLA standard is relevant – and then
only to the execution of CSPs and their models over a net
worked environment.  Issues concerning the use of the HLA
to support CSP interoperability have been the subject of a
previous panel at the Winter Simulation Conference (Taylor
et al. 2003).  The Simulation Interoperability Standards Or
ganization (SISO) seeks to further the “cause” of interopera
bility standards through its Standards Activity Committee
(SAC). In SISO terms, new standards are termed “products”
and it is the role of Product Development Groups (PDGs) to
develop new products.  When a product matures it is bal
loted, i.e. the community in which the product sits votes on
whether or not the product is appropriate.  In this respect
SISO and its practices are similar to the body responsible for
standards development in the World Wide Web recommen
dations and the W3C).  For example, the CSP Interoperabil
ity Forum (<www.cspif.com>) has existed as an interna
tional body since August 2002.  This forum is dedicated to
creating standard approaches to CSP interoperability. SISO
oversees the development of interoperability standards. If
the CSPIF is to have “credibility” for their work, the natural
choice is for the CSPIF to become a PDG as SISO is a rec
ognized body linked to an IEEE standard.
From the above, there is a clear “home” for simulation
interoperability standards and that one facet of emerging
CSP use is well supported by that organization.  However,
interoperability standards arise from a requirement of dis
tributed computing and not from simulation modeling.  Do
formal, organizationally “accredited” standards therefore have a significant role to play in the life of the practitioner
who uses a CSP to develop a single “standalone” models?
As indicated above, a CSP is not just a visual interactive
tool – it also strongly influences the concepts and methods
that the simulation modeller brings to bear on a problem.
For example, each CSP is typically based on some variant of
the discrete event simulation paradigm.  Models change state
at discrete points in time by scheduled or conditional events
and typically represent entities or objects (documents, pa
tients, parts, trains, etc.) in some form that pass through net
works of queues and workstations (work queuing at a desk
in an office, patients waiting to see a doctor, parts buffered
for machining, trains waiting at a station, etc.)  Each CSP
essentially does what its competitor CSPs do.  However,
each does its own tasks in its own way.  Consider the entity.
Across the range of CSPs, an entity is identifiable as an en
tity, an element, an item, an object, a transaction, etc.  Arte
facts such as queues and workstations are recognizable be
tween CSPs but differ in name and slightly in functionality.
Further, the simulation engine differs between CSPs, thereby
enforcing different behavioural rules between models.
Overall, there are few standard conventions across packages.
This has led to a polarization of the CSP practitioner com
munity starting in education at degree-level courses at Uni
versity and on in to industry.
Does this matter?  The current status quo appears to be
that practitioners are happy with their lot but subdivided
into user-based communities.  Models developed in differ
ent packages cannot be interchanged and occasionally this
can be a problem when larger organizations have not
“standardized” on which CSP should be used throughout
the organization.  However, this will be further exacerbated
with increasing attempts to use simulation modeling to
study larger inter-organization problems such as supply
chains.  Additionally, expensive skills developed based
around one CSP can be transferred to another but at a cost.
Surely it would be a beneficial for practitioners to have a
“universal” set of “standard” simulation approaches that
are “mapped” onto a CSP?
While this is important, the real problem is this.  In the
simulation interoperability community there is a standard
“language” based around the HLA that allows large com
munity discussions (such as those at the Simulation Inter
operability Workshops) over a wide range of tool, concep
tual and methodological issues.  This critical mass has
allowed that community to make substantial advances in a
relatively short period of time.  In the CSP world, separate,
polarized CSP-based communities exist.  Methodological
and technological advances are determined by the evolu
tion of the CSP and therefore by the vendor of that CSP.
Would the pace of change of methodology and technology
be better led by the community and not the software ven
dor, much as the World Wide Web has developed under
the auspices of the W3C?
If this is true, would a formal, organizationally accred
ited” standard concerning a range of issues from a formal
Taylor, Lendermann, Paul, Reichenthal, Straßburger, and Turner

definition of “entity” to a common simulation project lifecy
cle therefore have a significant impact on simulation practi
tioners?  If the achievements of those involved in the simula
tion interoperability community is evidence of what can
happen if a common “standard” ground is achievable, then I
believe that if practitioners, vendors and academics of the
various CSP communities can pull together to produce such
a standard, under an existing or new organization, then the
critical mass engendered by this new commonality could
usher in a new era in simulation modeling and be a worthy
future challenge in modeling methodology.
7 POSITION STATEMENT OF
STEPHEN J TURNER
My position on the future of modeling methodology is taken
from the viewpoint of large scale distributed simulation on
the Grid.  Simulation plays an important role in many areas
of industrial production, business, education, engineering
and science. It is a powerful tool for investigating and evalu
ating complex scenarios such as predicting the behavior of
new industrial systems or for analyzing the effects of ad
verse weather conditions on air traffic. Nowadays, the de
velopment of complex simulation applications usually re
quires collaborative effort from analysts with different
domain knowledge and expertise, possibly at different loca
tions.  Furthermore, these simulation systems often require
huge computing resources and the data sets required by the
simulation may also be geographically distributed.  In order
to support collaborative model development and to cater for
the increasing complexity of such systems, it is necessary to
harness distributed resources over the Internet.
In recent years, there has been an explosion of interest
in large scale distributed simulation.  Much of this activity
has centered around the High Level Architecture (HLA)
for simulation (Dahmann et al. 1998), an IEEE standard to
facilitate interoperability among simulations and promote
reuse of simulation models. Using HLA, a large-scale dis
tributed simulation can be constructed by linking together a
number of geographically distributed simulation models
(or federates) into an overall simulation (or federation).
However, the HLA does not provide any support for col
laborative development of simulation applications, neither
does it provide any mechanism for managing the resources
where the simulation is being executed.
Grid technology (Foster 2004a) enables collaboration
and the use of distributed computing resources, while also
facilitating access to geographically distributed data sets.
Our vision is a “Grid plug-and-play distributed simulation
system”, a collaborative distributed simulation environment
where analysts at different locations develop, modify, as
semble and execute distributed simulations over the Grid
(Theodoropoulos et al. 2003).  However, a number of impor
tant new research challenges need to be addressed before
this vision is realized.  First, a basic infrastructure providing
services to support model discovery and composition is es-sential in the development of collaborative distributed simu
lations.  Secondly, to conduct simulation experiments easily
over distributed resources from different organizations,
mechanisms that can provide coordinated and secured simu
lation executions are required. In addition, to meet the per
formance requirements demanded by large scale distributed
simulations, resource management mechanisms that balance
the load and provide fault-tolerance capabilities are needed.
A Grid computing environment consists of a collection
of heterogeneous, dynamic, shared resources. These re
sources may be located at different geographical places and
may belong to different administrative domains. The emer
gence of Grid services (Foster 2004b) and the potential for
seamless aggregation, integration and interaction makes it
possible to combine computations, experiments, observa
tions, and data to form a powerful simulation environment.
Zong et al. (2004) describes a framework for executing
HLA-based distributed simulations using Grid services.
The RTI control process is managed by an RTI Service and
can be dynamically discovered. Simulation models are en
capsulated within Federate Services and are assembled
through their Grid interface to form a large scale distrib
uted simulation. As different models can be dynamically
located, it provides great flexibility. Reusability is inher
ently provided by the nature of Grid services.
Service composition offers a new and evolving para
digm for building simulation applications. Suppose that
semantic meta-data, expressed for example by means of
ontologies, is associated with the models and accessed via
a Grid index service. Then a user could locate a model or
models that provided certain capabilities by searching the
semantic meta-data of the models registered with the index
service.  Ideally, once a set of component models has been
discovered, the semantic meta-data could be checked to de
termine if the models could be composed in a meaningful
way.  However, while there is much ongoing research into
the interoperability and composability of simulation mod
els (Weisel et al. 2004), achieving this kind of semantic
composability is a challenging task.
To provide effective resource management, a number of
research issues must be considered. These include resource
discovery, federate deployment, load monitoring, dynamic
load-balancing, check-pointing and fault-tolerance. We can
make use of Grid services to perform the tasks of resource
monitoring, coordination of simulation execution and secu
rity, while the RTI is used to perform simulation related
tasks such as synchronization and time management.  Cai et
al. (2002) describes a prototype Load Management System
(LMS) developed to support the execution of HLA-based
simulations over geographically distributed computing re
sources. Using Grid services, the LMS will match-make the
resource requirements of an HLA-based simulation and the
resources managed by the resource sharing system, carry out
authentication and authorization, schedule the simulation
and provide mechanisms for load-balancing and fault
tolerance during the simulation.
Taylor, Lendermann, Paul, Reichenthal, Straßburger, and Turner

Future directions of research include mechanisms to
facilitate the discovery, composition and deployment of
component simulation models using Grid services.  Chal
lenges remain to explore suitable formal approaches to the
visual construction, validation and verification of compos
ite simulation applications and to develop techniques (e.g.,
mobile agents) for automating the deployment and execu
tion of such systems.  New workflow languages are re
quired that describe the various component models that
constitute the simulation application together with the in
teractions between them.
8 SUMMARY
This panel paper has presented six different views on the
future of modeling methodology.  We hope that this will
provoke a stimulating debate at this year’s WSC and high
light priority research areas that will benefit our commu
nity at large.
REFERENCES
Barton, R., P. Fishwick, J.O. Henriksen, R.G. Sargent,
and J.M. Twomey. 2003. Panel: Simulation – Past,
Present and Future. In Proceedings of the 2003 Win
ter Simulation Conference, ed. S. Chick, P. J.
Sánchez, D. Ferrin, and D. J. Morrice, 2044-2050.
New York, N.Y.: Association for Computing Ma
chinery Press. Available online via <http://www.
informs-cs.org/wsc03papers/264.pdf>
[accessed August 20, 2004].
BOM. 2003. Base Object Model (BOM) Template Specifi
cation Volume I - Interface BOM, SISOSTD
DRAFT-V0.9
Cai, W., S.J. Turner, and H.F. Zhao. 2002. A Load Man
agement Systsem for Running HLA-based Distributed
Simulations over the Grid, Proc. 6th IEEE Interna
tional Workshop on Distributed Simulation and Real
Time Applications, 7-14. Piscataway. New Jersey: In
stitute of Electrical and Electronics Engineers.
Chong, C.S., P. Lendermann, B.P. Gan, B.M. Duarte, J.W.
Fowler, and T.E. Callarman. 2004. Analysis of a Cus
tomer-Demand Driven Semiconductor Supply Chain
in a Distributed Simulation Testbed. Accepted for the
2004 Winter Simulation Conference.
Dagstuhl. 2003. <http://www.informatik.
uni-rostock.de/~lin/GC/report/
PADS.html> [accessed July 5, 2004].
Dahmann, D., F. Kuhl, and R. Weatherly. 1998. Standards
for Simulation: As Simple As Possible But Not Sim
pler - The High Level Architecture for Simulation.
Simulation 71(6): 378-387.
Foster I. and C. Kesselman. 2004a. Concepts and Architec
ture, The Grid 2: Blueprint for a New Computing In-frastructure. ed. I. Foster and C. Kesselman. 37-64.
Morgan Kaufmann.
Foster I., C. Kesselman, and S. Tuecke. 2004b. The Open
Grid Service Architecture, The Grid 2: Blueprint for a
New Computing Infrastructure. ed. I. Foster and C.
Kesselman. 215-258. Morgan Kaufmann.
Henriksen, J.O. 2000 Adding Animation to a Simulation Us
ing Proof™. In Proceedings of the 2000 Winter Simula
tion Conference, ed. S. Andradóttir, J. A. Joines, R. R.
Barton, K. Kang, and P. A. Fishwick, 191-196. New
York, N.Y.: Association for Computing Machinery
Press. Available online via <http://www.
informs-cs.org/wsc00papers/028.pdf>
[accessed August 20, 2004].
Lendermann, P., N. Julka, L.P. Chan, and B.P. Gan. 2003.
Integration of Discrete Event Simulation Models with
Framework-Based Business Applications. In Proceed
ings of the 2003 Winter Simulation Conference, ed. S.
Chick, P. J. Sánchez, D. Ferrin, and D. J. Morrice,
1797-1804.  New York, N.Y.: Association for Com
puting Machinery Press. Available online via <http:
//www.informs-cs.org/wsc03papers/230.
pdf> [accessed August 20, 2004].
Paul, R.J. and S.J.E. Taylor. 2002. What Use is Model Re
use: Is There a Crook at the End of the Rainbow? In
Proceedings of the 2002 Winter Simulation Conference,
ed. E. Yücesan, C.-H. Chen, J. L. Snowdon, and J. M.
Charnes, 648-652.  New York, N.Y.: Association for
Computing Machinery Press. Available online via
<http://www.informs-cs.org/wsc02
papers/083.pdf> [accessed August 20, 2004].
Rehn, G. D. 2004. Future Trends in the Application and
Execution of Simulation in US Industry. In Proceed
ings of the Conference “Simulation und Visualisierung
2004”, ed. T. Schulze, S. Schlechtweg, V. Hinz, SCS
Europe Publishing House, Erlangen, San Diego, 1-14..
Schulze, T., S. Straßburger, and U. Klein. 1999. On-line
Data Processing in Simulation Models: New Ap
proaches and Possibilities through HLA. In Proceedings
of the 2002 Winter Simulation Conference, ed. P. A.
Farrington, H. B. Nembhard, D. T. Sturrock, and G. W.
Evans, 1602-1609.  New York, N.Y.: Association for
Computing Machinery Press. Available online via
<http://www.informs-cs.org/wsc99
papers/232.pdf> [accessed August 20, 2004].
SRML. 2002.  SRML - Simulation Reference Markup Lan
guage W3C Note, <http://www.w3.org/TR/
SRML/> [accessed December 18, 2002].
Straßburger, S. 2001. Distributed Simulation Based on the
High Level Architecture in Civilian Application Do
mains. Ghent: Society for Computer Simulation Inter
national, ISBN 1-56555-218-0.
Taylor, S.J.E., B.P. Gan, S. Straßburger, and A. Verbraeck.
2003.  HLA-CSPIF Technical Panel on Distributed
Simulation.  In Proceedings of the 2003 Winter Simula
tion Conference, ed. S. Chick, P. J. Sánchez, D. Ferrin,
Taylor, Lendermann, Paul, Reichenthal, Straßburger, and Turner

and D. J. Morrice, 881-887.  New York, N.Y.: Associa
tion for Computing Machinery Press. Available online
via <http://www.informs-cs.org/wsc03
papers/107.pdf> [accessed August 20, 2004].
Theodoropoulos, G., S.J. Turner, W. Cai, and B. Logan.
2003. Large Scale Distributed Simulation on the Grid,
EPSRC e-Science Sister Project GR/S82862/01.
Weisel E.W., M.D. Petty, and R.R. Mielke. 2004. A Sur
vey of Engineering Approaches to Composability. In
Proceedings of the 2004 Spring Interoperability
Workshop, 04S-SIW-105. Orlando, Florida:
Simulation Interoperability Standards Organization.
Zong, W., Y. Wang, W. Cai and S.J. Turner. 2004. Grid
Services and Service Discovery for HLA-based Dis
tributed Simulation, submitted to 8th IEEE Interna
tional Symposium on Distributed Simulation and Real
Time Applications.  Piscataway. New Jersey: Institute
of Electrical and Electronics Engineers.
AUTHOR BIOGRAPHIES
PETER LENDERMANN is a Senior Scientist at the Sin
gapore Institute of Manufacturing Technology (SIMTech)
where he currently leads the D-SIMLAB Research Pro
gramme. He holds a concurrent appointment as Adjunct
Senior Research Fellow at the Department of Industrial and
Systems Engineering at the National University of Singa
pore. Previously he was a Managing Consultant with agi
Consult in Germany where his focus was on the areas of
supply chain management and production planning. He
also worked as a Research Associate at the European
Laboratory for Particle Physics CERN in Geneva Switzer
land) and Nagoya University (Japan). He obtained a Di
ploma in Physics from the University of Munich Ger
many), a Doctorate in Applied Physics from Humboldt
University in Berlin (Germany) and a Master in Interna
tional Economics and Management from Bocconi
University in Milan (Italy). His research interests include
modeling and analysis of manufacturing and logistics sys
tems as well as distributed simulation. His email address is
<peterl@SIMTech.a-star.edu.sg>.
RAY J. PAUL (Creative Discombobulator) is a Professor
of Simulation Modeling, Director of the Centre for Applied
Simulation Modeling, creator of the Centre for Living In
formation Systems Thinking, all at Brunel University, UK.
He received a B.Sc. in Mathematics, and an M.Sc. and a
Ph.D. in Operational Research from Hull University.  He
has published widely, in books, journals and conference
papers, many in the area of simulation modeling and soft
ware development.  He has acted as a consultant for a vari
ety of United Kingdom government departments, software
companies, and commercial companies in the tobacco and
oil industries.  He is the editor of the Springer-Verlag Prac
titioner book  series.  His research interests are in methods of automating the process of modeling, and the general ap
plicability of such methods and their extensions to the
wider arena of information systems.  He is currently work
ing on wider aspects of simulation, in particular in Web
Based Simulation and the new G2R3 modeling technique.
His email and web addresses are <ray.paul@brunel.
ac.uk> and <www.brunel.ac.uk/~csstrjp>.
Professor Paul has Parkinsonism, but insists on working
part-time because he enjoys it.
STEVE REICHENTHAL Steven W. Reichenthal is an
Associate Technical Fellow at the Boeing Company. He
develops simulations and software applications as a mem
ber of the Logistics Engineering organization in
Anaheim, California. He has a Masters degree in Com
puter Science and an MBA, and teaches software devel
opment courses at the California State University in Full
erton as an adjunct professor.
STEFFEN STRAßBURGER is head of the department
“Virtual Development” at the Fraunhofer Institute for Fac
tory Operation and Automation in Magdeburg, Germany.
Previous professional experience includes two years as re
searcher at the DaimlerChrysler Research Center in Ulm,
Germany, where he was involved with research topics in
the Digital Factory and Digital Engineering context, espe
cially in the area of simulation integration and distributed
simulation. He holds a PhD and a Master’s degree in Com
puter Science from the Otto-von-Guericke University in
Magdeburg, Germany. His international experience in
cludes a one-year stay at the University of Wisconsin, Ste
vens Point and a stay at the Georgia Institute of Technol
ogy, Atlanta. He actively participates in several
international conferences. His main research interests lie in
distributed and web-based simulation, virtual reality, and
middleware technologies like the High Level Architecture,
CORBA, DCOM, and Web Services. His email address is
<strassburger@iff.fraunhofer.de>.
SIMON J. E. TAYLOR is the convener of this panel.  He
is also Information Director of ACM SIGSIM, ACM
SIGSIM PADS Liaison Officer and Chair of the Simula
tion Study Group of the UK Operational Research Society.
He is a steering committee member of PADS and general
co-chair of the UK Simulation Workshop Series.  He cur
rently leads the international COTS simulation package in
teroperability forum (HLA-CSPIF) through SISO (<www.
cspif.com>).  He is a Senior Lecturer in the Department
of Information Systems and Computing and is a member of
the Centre for Applied Simulation Modeling, both at
Brunel University, UK.  He is also a Visiting Associate
Professor at the Parallel and Distributed Computing Cen
tre, Nanyang Technological University (Singapore).  He
was previously part of the Centre for Parallel Computing at
the University of Westminster. He has an undergraduate
Taylor, Lendermann, Paul, Reichenthal, Straßburger, and Turner

degree in Industrial Studies (Sheffield Hallam), a M.Sc. in
Computing Studies (Sheffield Hallam) and a Ph.D. in Par
allel and Distributed Simulation (Leeds Metropolitan). His
main research interests are distributed simulation and ap
plications of ICT to simulation modeling.  He is also a
member of the Purple Theatre Company. His email is
<simon.taylor@brunel.ac.uk>.
STEPHEN J. TURNER joined Nanyang Technological
University (Singapore) in 1999 and is Director of the Par
allel and Distributed Computing Centre in the School of
Computer Engineering. Previously, he was a Senior Lec
turer in Computer Science at Exeter University (UK). He
received his MA in Mathematics and Computer Science
from Cambridge University (UK) and his MSc and PhD in
Computer Science from Manchester University (UK). His
current research interests include: parallel and distributed
simulation, distributed virtual environments, grid comput
ing and multi-agent systems. He is steering committee
chair and program co-chair of the Workshop on Principles
of Advanced and Distributed Simulation and advisory
committee member and general chair of the Distributed
Simulation and Real Time Applications Symposium. His e
mail address is <ASSJTurner@ntu.edu.sg>.

