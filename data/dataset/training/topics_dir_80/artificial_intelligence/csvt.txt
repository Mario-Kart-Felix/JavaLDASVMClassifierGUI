IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY, VOL. 14, NO. 1, JANUARY 2004 21
How Iris Recognition Works
John Daugman
Invited Paper
Abstract—Algorithms developed by the author for recognizing
persons by their iris patterns have now been tested in many
field and laboratory trials, producing no false matches in several
million comparison tests. The recognition principle is the failure
of a test of statistical independence on iris phase structure encoded
by multi-scale quadrature wavelets. The combinatorial complexity
of this phase information across different persons spans about
249 degrees of freedom and generates a discrimination entropy
of about 3.2 b mm2 over the iris, enabling real-time decisions
about personal identity with extremely high confidence. The high
confidence levels are important because they allow very large
databases to be searched exhaustively (one-to-many “identification
mode”) without making false matches, despite so many chances.
Biometrics that lack this property can only survive one-to-one
(“verification”) or few comparisons. This paper explains the
iris recognition algorithms and presents results of 9.1 million
comparisons among eye images from trials in Britain, the USA,
Japan, and Korea.
Index Terms—Biometrics, decision theory, demodulation, focus
assessment, Gabor wavelets, iris recognition.
I. INTRODUCTION
RELIABLE automatic recognition of persons has long beenan attractive goal. As in all pattern recognition problems,
the key issue is the relation between inter-class and intra-class
variability: objects can be reliably classified only if the vari-
ability among different instances of a given class is less than the
variability between different classes. For example, in face recog-
nition, difficulties arise from the fact that the face is a change-
able social organ displaying a variety of expressions, as well
as being an active three-dimensional (3-D) object whose image
varies with viewing angle, pose, illumination, accoutrements,
and age [1], [2]. It has been shown that, for “mug shot” images
taken at least one year apart, even the best current algorithms can
have error rates of 43%–50% [14]–[16]. Against this intra-class
(same face) variability, inter-class variability is limited because
different faces possess the same basic set of features, in the same
canonical geometry.
For all of these reasons, iris patterns become interesting as
an alternative approach to reliable visual recognition of persons
when imaging can be done at distances of less than a meter, and
especially when there is a need to search very large databases
without incurring any false matches despite a huge number of
possibilities. Although small (11 mm) and sometimes problem-
Manuscript received November 1, 2002; revised June 13, 2003.
The author is with The Computer Laboratory, University of Cambridge, Cam-
bridge CB3 0FD, U.K. (e-mail: John.Daugman@CL.cam.ac.uk).
Digital Object Identifier 10.1109/TCSVT.2003.818350
Fig. 1. Example of an iris pattern, imaged monochromatically at a distance of
about 35 cm. The outline overlay shows results of the iris and pupil localization
and eyelid detection steps. The bit stream in the top left is the result of
demodulation with complex-valued two-dimensional (2-D) Gabor wavelets to
encode the phase sequence of the iris pattern.
atic to image, the iris has the great mathematical advantage
that its pattern variability among different persons is enormous.
In addition, as an internal (yet externally visible) organ of the
eye, the iris is well protected from the environment and stable
over time. As a planar object its image is relatively insensitive
to angle of illumination, and changes in viewing angle cause
only affine transformations; even the nonaffine pattern distor-
tion caused by pupillary dilation is readily reversible. Finally,
the ease of localizing eyes in faces, and the distinctive annular
shape of the iris, facilitate reliable and precise isolation of this
feature and the creation of a size-invariant representation.
The iris begins to form in the third month of gestation [13]
and the structures creating its pattern are largely complete by
the eighth month, although pigment accretion can continue into
the first postnatal years. Its complex pattern can contain many
distinctive features such as arching ligaments, furrows, ridges,
crypts, rings, corona, freckles, and a zigzag collarette, some of
which may be seen in Fig. 1. Iris color is determined mainly
by the density of melanin pigment [4] in its anterior layer and
stroma, with blue irises resulting from an absence of pigment:
long-wavelength light penetrates while shorter wavelengths are
scattered by the stroma. The striated trabecular meshwork of
elastic pectinate ligament creates the predominant texture under
visible light, whereas in the near-infrared (NIR) wavelengths
used for unobtrusive imaging at distances of up to 1 m deeper
and somewhat more slowly modulated stromal features domi-
1051-8215/04$20.00 © 2004 IEEE
22 IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY, VOL. 14, NO. 1, JANUARY 2004
nate the iris pattern. In NIR wavelengths, even darkly pigmented
irises reveal rich and complex features.
The author’s algorithms [8]–[10] for encoding and recog-
nizing iris patterns have been the executable software used in
all iris recognition systems so far deployed commercially or in
tests, including those by British Telecom, Sandia Labs, U.K.
National Physical Lab, Panasonic, LG, Oki, EyeTicket, Sensar,
Sarnoff, IBM, SchipholGroup, Siemens, Sagem, IriScan, and
Iridian. All testing organizations have reported a false match rate
of 0 in their tests, some of which involved millions of iris pair-
ings. This paper explains how the algorithms work and presents
new data on the statistical properties and singularity of iris pat-
terns based on 9.1 million comparisons.
II. FINDING AN IRIS IN AN IMAGE
To capture the rich details of iris patterns, an imaging system
should resolve a minimum of 70 pixels in iris radius. In the field
trials to date, a resolved iris radius of 80–130 pixels has been
more typical. Monochrome CCD cameras (480 640) have
been used because NIR illumination in the 700–900-nm band
was required for imaging to be unintrusive to humans. Some
imaging platforms deployed a wide-angle camera for coarse lo-
calization of eyes in faces, to steer the optics of a narrow-angle
pan/tilt camera that acquired higher resolution images of eyes.
There exist many alternative methods for finding and tracking
facial features such as the eyes, and this well-researched topic
will not be discussed further here. In these trials, most imaging
was done without active pan/tilt camera optics, but instead
exploited visual feedback via a mirror or video image to enable
cooperating Subjects to position their own eyes within the field
of view of a single narrow-angle camera.
Image focus assessment is performed in real time (faster than
video frame rate) by measuring spectral power in middle and
upper frequency bands of the 2-D Fourier spectrum of each
image frame and seeking to maximize this quantity either by
moving an active lens or by providing audio feedback to Sub-
jects to adjust their range appropriately. The video rate execu-
tion speed of focus assessment (i.e., within 15 ms) is achieved
by using a bandpass 2-D filter kernel requiring only summa-
tion and differencing of pixels, and no multiplications, within
the 2-D convolution necessary to estimate power in the selected
2-D spectral bands. Details are provided in the Appendix.
Images passing a minimum focus criterion are then analyzed
to find the iris, with precise localization of its boundaries using a
coarse-to-fine strategy terminating in single-pixel precision es-
timates of the center coordinates and radius of both the iris and
the pupil. Although the results of the iris search greatly constrain
the pupil search, concentricity of these boundaries cannot be as-
sumed. Very often the pupil center is nasal, and inferior, to the
iris center. Its radius can range from 0.1 to 0.8 of the iris radius.
Thus, all three parameters defining the pupillary circle must be
estimated separately from those of the iris. A very effective in-
tegrodifferential operator for determining these parameters is
(1)
Fig. 2. The phase demodulation process used to encode iris patterns. Local
regions of an iris are projected (2) onto quadrature 2-D Gabor wavelets,
generating complex-valued coefficients whose real and imaginary parts specify
the coordinates of a phasor in the complex plane. The angle of each phasor is
quantized to one of the four quadrants, setting two bits of phase information.
This process is repeated all across the iris with many wavelet sizes, frequencies,
and orientations to extract 2048 bits.
where is an image such as Fig. 1 containing an eye. The
operator searches over the image domain ( ) for the max-
imum in the blurred partial derivative with respect to increasing
radius , of the normalized contour integral of along a
circular arc of radius and center coordinates ( ). The
symbol denotes convolution and is a smoothing func-
tion such as a Gaussian of scale . The complete operator be-
haves as a circular edge detector, blurred at a scale set by ,
searching iteratively for the maximal contour integral derivative
at successively finer scales of analysis through the three param-
eter space of center coordinates and radius ( ) defining
a path of contour integration.
The operator in (1) serves to find both the pupillary boundary
and the outer (limbus) boundary of the iris, although the initial
search for the limbus also incorporates evidence of an interior
pupil to improve its robustness since the limbic boundary itself
usually has extremely soft contrast when long wavelength NIR
illumination is used. Once the coarse-to-fine iterative searches
for both these boundaries have reached single-pixel precision,
then a similar approach to detecting curvilinear edges is used to
localize both the upper and lower eyelid boundaries. The path
of contour integration in (1) is changed from circular to arcuate,
with spline parameters fitted by statistical estimation methods
to model each eyelid boundary. Images with less than 50% of
the iris visible between the fitted eyelid splines are deemed in-
adequate, e.g., in blink. The result of all these localization op-
erations is the isolation of iris tissue from other image regions,
as illustrated in Fig. 1 by the graphical overlay on the eye.
III. IRIS FEATURE ENCODING BY 2-D WAVELET
DEMODULATION
Each isolated iris pattern is then demodulated to extract its
phase information using quadrature 2-D Gabor wavelets [6], [7],
[11]. This encoding process is illustrated in Fig. 2. It amounts
to a patch-wise phase quantization of the iris pattern, by iden-
tifying in which quadrant of the complex plane each resultant
DAUGMAN: HOW IRIS RECOGNITION WORKS 23
phasor lies when a given area of the iris is projected onto com-
plex-valued 2-D Gabor wavelets:
(2)
where can be regarded as a complex-valued bit whose
real and imaginary parts are either 1 or 0 (sgn) depending on
the sign of the 2-D integral; is the raw iris image in a
dimensionless polar coordinate system that is size- and transla-
tion-invariant and which corrects for pupil dilation as explained
in a later section; and are the multiscale 2-D wavelet size
parameters, spanning an eight-fold range from 0.15 to 1.2 mm
on the iris; is wavelet frequency, spanning three octaves in
inverse proportion to ; and ( ) represent the polar coor-
dinates of each region of iris for which the phasor coordinates
are computed. Such a phase quadrant coding sequence
is illustrated for one iris by the bit stream shown graphically in
Fig. 1. A desirable feature of the phase code portrayed in Fig. 2 is
that it is a cyclic, or gray code: in rotating between any adjacent
phase quadrants, only a single bit changes, unlike a binary code
in which two bits may change, making some errors arbitrarily
more costly than others. Altogether, 2048 such phase bits (256
bytes) are computed for each iris, but in a major improvement
over the author’s earlier [8] algorithms, now an equal number
of masking bits are also computed to signify whether any iris
region is obscured by eyelids, contains any eyelash occlusions,
specular reflections, boundary artifacts of hard contact lenses,
or poor signal-to-noise ratio (SNR) and thus should be ignored
in the demodulation code as artifact.
Only phase information is used for recognizing irises be-
cause amplitude information is not very discriminating, and it
depends upon extraneous factors such as imaging contrast, illu-
mination, and camera gain. The phase bit settings which code
the sequence of projection quadrants as shown in Fig. 2 cap-
ture the information of wavelet zero-crossings, as is clear from
the sign operator in (2). The extraction of phase has the further
advantage that phase angles remain defined regardless of how
poor the image contrast may be, as illustrated by the extremely
out-of-focus image in Fig. 3. Its phase bit stream has statistical
properties such as run lengths similar to those of the code for
the properly focused eye image in Fig. 1. (Fig. 3 also illus-
trates the robustness of the iris- and pupil-finding operators, and
the eyelid detection operators, despite poor focus.) The benefit
which arises from the fact that phase bits are set also for a poorly
focused image as shown here, even if based only on random
CCD thermal noise, is that different poorly focused irises never
become confused with each other when their phase codes are
compared. By contrast, images of different faces look increas-
ingly alike when poorly resolved and can be confused with each
other by appearance-based face recognition algorithms.
IV. THE TEST OF STATISTICAL INDEPENDENCE:
COMBINATORICS OF PHASE SEQUENCES
The key to iris recognition is the failure of a test of statistical
independence, which involves so many degrees-of-freedom that
Fig. 3. Illustration that even for poorly focused eye images, the bits of a
demodulation phase sequence are still set, primarily by random CCD noise.
This prevents poorly focused eye images from being falsely matched, as they
may be in amplitude-based representations.
this test is virtually guaranteed to be passed whenever the phase
codes for two different eyes are compared, but to be uniquely
failed when any eye’s phase code is compared with another ver-
sion of itself.
The test of statistical independence is implemented by the
simple Boolean Exclusive-OR operator (XOR) applied to the
2048 bit phase vectors that encode any two iris patterns, masked
(AND’ed) by both of their corresponding mask bit vectors to
prevent noniris artifacts from influencing iris comparisons.
The XOR operator detects disagreement between any cor-
responding pair of bits, while the AND operator ensures that
the compared bits are both deemed to have been uncorrupted
by eyelashes, eyelids, specular reflections, or other noise. The
norms ( ) of the resultant bit vector and of the AND’ed mask
vectors are then measured in order to compute a fractional
Hamming Distance (HD) as the measure of the dissimilarity
between any two irises, whose two phase code bit vectors
are denoted {codeA, codeB} and whose mask bit vectors are
denoted {maskA, maskB}:
(3)
The denominator tallies the total number of phase bits that mat-
tered in iris comparisons after artifacts such as eyelashes and
specular reflections were discounted, so the resulting HD is a
fractional measure of dissimilarity; 0 would represent a perfect
match. The Boolean operators and are applied in vector
form to binary strings of length up to the word length of the
CPU, as a single machine instruction. Thus, for example on an
ordinary 32-b machine, any two integers between 0 and 4 billion
can be XOR’ed in a single machine instruction to generate a third
such integer, each of whose bits in a binary expansion is the XOR
of the corresponding pair of bits of the original two integers.
This implementation of (3) in parallel 32-b chunks enables ex-
tremely rapid comparisons of iris codes when searching through
a large database to find a match. On a 300-MHz CPU, such ex-
haustive searches are performed at a rate of about 100 000 irises
per second.
24 IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY, VOL. 14, NO. 1, JANUARY 2004
Fig. 4. Distribution of HDs from all 9.1 million possible comparisons between
different pairs of irises in the database. The histogram forms a perfect binomial
distribution with p = 0:5 and N = 249 degrees-of-freedom, as shown by the
solid curve (4). The data implies that it is extremely improbable for two different
irises to disagree in less than about a third of their phase information.
Because any given bit in the phase code for an iris is equally
likely to be 1 or 0 and different irises are uncorrelated, the
expected proportion of agreeing bits between the codes for two
different irises is . The histogram in Fig. 4 shows
the distribution of HDs obtained from 9.1 million comparisons
between different pairings of iris images acquired by licensees
of these algorithms in the U.K., the U.S.A., Japan, and Korea.
There were 4258 different iris images, including 10 each of
one subset of 70 eyes. Excluding those duplicates of (700 9)
same-eye comparisons, and not double-counting pairs, and not
comparing any image with itself, the total number of unique
pairings between different eye images whose HDs could be
computed was .
Their observed mean HD was with standard devia-
tion ; their full distribution in Fig. 4 corresponds to a
binomial having degrees-of-freedom,
as shown by the solid curve. The extremely close fit of the the-
oretical binomial to the observed distribution is a consequence
of the fact that each comparison between two phase code bits
from two different irises is essentially a Bernoulli trial, albeit
with correlations between successive “coin tosses.”
In the phase code for any given iris, only small subsets of
bits are mutually independent due to the internal correlations,
especially radial, within an iris. (If all phase bits
were independent, then the distribution in Fig. 4 would be very
much sharper, with an expected standard deviation of only
and so the HD interval between 0.49
and 0.51 would contain most of the distribution.) Bernoulli
trials that are correlated [18] remain binomially distributed
but with a reduction in , the effective number of tosses, and
hence an increase in the of the normalized HD distribution.
The form and width of the HD distribution in Fig. 4 tell us that
the amount of difference between the phase codes for different
irises is distributed equivalently to runs of 249 tosses of a fair
coin (Bernoulli trials with , ). Expressing this
Fig. 5. Quantile–quantile plot of the observed cumulatives under the left tail
of the histogram in Fig. 4 versus the predicted binomial cumulatives. The close
agreement over several orders of magnitude strongly confirms the binomial
model for phase bit comparisons between different irises.
variation as a discrimination entropy [5] and using typical iris
and pupil diameters of 11 and 5 mm respectively, the observed
amount of statistical variability among different iris patterns
corresponds to an information density of about 3.2 b mm on
the iris.
The theoretical binomial distribution plotted as the solid
curve in Fig. 4 has the fractional functional form
(4)
where and is the outcome frac-
tion of Bernoulli trials (e.g., coin tosses that are “heads” in
each run). In our case, is the HD, the fraction of phase bits
that happen to agree when two different irises are compared.
To validate such a statistical model we must also study the be-
havior of the tails, by examining quantile–quantile plots of the
observed cumulatives versus the theoretically predicted cumu-
latives from 0 up to sequential points in the tail. Such a “Q–Q”
plot is given in Fig. 5. The straight line relationship reveals very
precise agreement between model and data, over a range of more
than three orders of magnitude. It is clear from both Figs. 4 and
5 that it is extremely improbable that two different irises might
disagree by chance in fewer than at least a third of their bits.
(Of the 9.1 million iris comparisons plotted in the histogram of
Fig. 4, the smallest HD observed was 0.334.) Computing the cu-
mulative of from 0 to 0.333 indicates that the probability
of such an event is about 1 in 16 million. The cumulative from
0 to just 0.300 is 1 in 10 billion. Thus, even the observation of
a relatively poor degree of match between the phase codes for
two different iris images (say, 70% agreement or )
would still provide extraordinarily compelling evidence of iden-
tity, because the test of statistical independence is still failed so
convincingly.
The author also compared genetically identical eyes in the
same manner in order to discover the degree to which their tex-
tural patterns were correlated and hence genetically determined.
A convenient source of genetically identical irises are the right
DAUGMAN: HOW IRIS RECOGNITION WORKS 25
Fig. 6. Distribution of Hamming Distances between genetically identical
irises, in 648 paired eyes from 324 persons. The data are statistically
indistinguishable from that shown in Fig. 4 comparing unrelated irises. Unlike
eye color, the phase structure of iris patterns therefore appears to be epigenetic,
arising from random events and circumstances in the morphogenesis of this
tissue.
and left pair from any given person; such pairs have the same ge-
netic relationship as the four irises of monozygotic twins, or in-
deed the prospective irises of clones. Although eye color
is of course strongly determined genetically, as is overall iris
appearance, the detailed patterns of genetically identical irises
appear to be as uncorrelated as they are among unrelated eyes.
Using the same methods as described above, 648 right/left iris
pairs from 324 persons were compared pairwise. Their mean
HD was 0.497 with standard deviation 0.031, and their distribu-
tion (Fig. 6) was statistically indistinguishable from the distri-
bution for unrelated eyes (Fig. 4). A set of six pairwise compar-
isons among the eyes of actual monozygotic twins also yielded
a result (mean ) expected for unrelated eyes. It ap-
pears that the phenotypic random patterns visible in the human
iris are almost entirely epigenetic [12].
V. RECOGNIZING IRISES REGARDLESS OF SIZE,
POSITION, AND ORIENTATION
Robust representations for pattern recognition must be in-
variant to changes in the size, position, and orientation of the
patterns. In the case of iris recognition, this means we must
create a representation that is invariant to the optical size of
the iris in the image (which depends upon the distance to the
eye, and the camera optical magnification factor); the size of
the pupil within the iris (which introduces a nonaffine pattern
deformation); the location of the iris within the image; and the
iris orientation, which depends upon head tilt, torsional eye rota-
tion within its socket (cyclovergence), and camera angles, com-
pounded with imaging through pan/tilt eye-finding mirrors that
introduce additional image rotation factors as a function of eye
position, camera position, and mirror angles. Fortunately, invari-
ance to all of these factors can readily be achieved.
For on-axis but possibly rotated iris images, it is natural to
use a projected pseudopolar coordinate system. The polar co-
ordinate grid is not necessarily concentric, since in most eyes
the pupil is not central in the iris; it is not unusual for its nasal
displacement to be as much as 15%. This coordinate system
can be described as doubly dimensionless: the polar variable,
angle, is inherently dimensionless, but in this case the radial
variable is also dimensionless, because it ranges from the pupil-
lary boundary to the limbus always as a unit interval [0, 1]. The
dilation and constriction of the elastic meshwork of the iris when
the pupil changes size is intrinsically modeled by this coordinate
system as the stretching of a homogeneous rubber sheet, having
the topology of an annulus anchored along its outer perimeter,
with tension controlled by an (off-centered) interior ring of vari-
able radius.
The homogeneous rubber sheet model assigns to each point
on the iris, regardless of its size and pupillary dilation, a pair of
real coordinates ( ) where is on the unit interval [0, 1] and
is angle [0, ]. The remapping of the iris image from
raw cartesian coordinates ( ) to the dimensionless noncon-
centric polar coordinate system ( ) can be represented as
(5)
where and are defined as linear combinations of
both the set of pupillary boundary points ( , ) and
the set of limbus boundary points along the outer perimeter of
the iris ( , ) bordering the sclera, both of which are
detected by finding the maximum of the operator (1) as
(6)
(7)
Since the radial coordinate ranges from the iris inner boundary
to its outer boundary as a unit interval, it inherently corrects for
the elastic pattern deformation in the iris when the pupil changes
in size.
The localization of the iris and the coordinate system de-
scribed above achieve invariance to the 2-D position and size
of the iris, and to the dilation of the pupil within the iris. How-
ever, it would not be invariant to the orientation of the iris within
the image plane. The most efficient way to achieve iris recogni-
tion with orientation invariance is not to rotate the image itself
using the Euler matrix, but rather to compute the iris phase code
in a single canonical orientation and then to compare this very
compact representation at many discrete orientations by cyclic
scrolling of its angular variable. The statistical consequences
of seeking the best match after numerous relative rotations of
two iris codes are straightforward. Let be the raw den-
sity distribution obtained for the HDs between different irises
after comparing them only in a single relative orientation; for ex-
ample, might be the binomial defined in (4). Then ,
the cumulative of from 0 to , becomes the probability of
getting a false match in such a test when using HD acceptance
criterion
(8)
or, equivalently,
(9)
26 IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY, VOL. 14, NO. 1, JANUARY 2004
Fig. 7. Distribution of HDs for the same set of 9.1 million comparisons shown
in Fig. 4, but allowing for seven relative rotations and preserving only the best
match found for each pair. This “best of n” test skews the distribution to the left
and reduces its mean from about 0.5 to 0.458. The solid curve is the theoretical
prediction for such “extreme-value” sampling, as described by (4) and (8)–(11).
Clearly, then, the probability of not making a false match when
using criterion is after a single test, and it is
after carrying out such tests independently at
different relative orientations. It follows that the probability
of a false match after a “best of ” test of agreement, when
using HD criterion , regardless of the actual form of the raw
unrotated distribution , is
(10)
and the expected density associated with this cumulative
is
(11)
Each of the 9.1 million pairings of different iris images whose
HD distribution was shown in Fig. 4, was submitted to further
comparisons in each of seven relative orientations. This gener-
ated 63 million HD outcomes, but in each group of seven asso-
ciated with any one pair of irises, only the best match (smallest
HD) was retained. The histogram of these new 9.1 million best
HDs is shown in Fig. 7. Since only the smallest value in each
group of seven samples was retained, the new distribution is
skewed and biased to a lower mean value ( ), as
expected from the theory of extreme value sampling. The solid
curve in Fig. 7 is a plot of (11), incorporating (4) and (8) as its
terms, and it shows an excellent fit between theory (binomial
extreme value sampling) and data. The fact that the minimum
HD observed in all of these millions of rotated comparisons was
about 0.33 illustrates the extreme improbability that the phase
sequences for two different irises might disagree in fewer than a
third of their bits. This suggests that in order to identify people
by their iris patterns with high confidence, we need to demand
only a very forgiving degree of match (say, ).
Fig. 8. Calculated cumulatives under the left tail of the distribution seen in
Fig. 7, up to sequential points, using the functional analysis described by (4)
and (8)–(11). The extremely rapid attenuation of these cumulatives reflects the
binomial combinatorics that dominate (4). This accounts for the astronomical
confidence levels against a false match, when executing this test of statistical
independence.
VI. UNIQUENESS OF FAILING THE TEST OF
STATISTICAL INDEPENDENCE
The statistical data and theory presented above show that we
can perform iris recognition successfully just by a test of sta-
tistical independence. Any two different irises are statistically
“guaranteed” to pass this test of independence; and any two im-
ages that fail this test must be images of the same iris. Thus, it
is the unique failure of the test of independence, that is the basis
for iris recognition.
It is informative to calculate the significance of any observed
HD matching score, in terms of the likelihood that it could have
arisen by chance from two different irises. These probabilities
give a confidence level associated with any recognition decision.
Fig. 8 shows the false match probabilities marked off in cumu-
latives along the tail of the distribution presented in Fig. 7 (same
theoretical curve (11) as plotted in Fig. 7 and with the justifica-
tion presented in Figs. 4 and 5). Table I enumerates false match
probabilities, the cumulatives of (11), as a more fine-grained
function of HD decision criterion between 0.26 and 0.35.
Calculation of the large factorial terms in (4) was done with
Stirling’s approximation which errs by less than 1% for
(12)
The practical importance of the astronomical odds against
a false match when the match quality is better than about
, as shown in Fig. 8 and in Table I, is that such high
confidence levels allow very large databases to be searched
exhaustively without succumbing to any of the many op-
portunities for suffering a false match. The requirements of
operating in one-to-many “identification” mode are vastly more
demanding than operating merely in one-to-one “verification”
mode (in which an identity must first be explicitly asserted,
DAUGMAN: HOW IRIS RECOGNITION WORKS 27
TABLE I
CUMULATIVES UNDER (11) GIVING SINGLE FALSE MATCH
PROBABILITIES FOR VARIOUS HD CRITERIA
which is then verified in a yes/no decision by comparison
against just the single nominated template).
If is the false match probability for single one-to-one veri-
fication trials, then clearly , the probability of making at least
one false match when searching a database of unrelated pat-
terns, is
(13)
because ( ) is the probability of not making a false match
in single comparisons; this must happen independent times;
and so is the probability that such a false match never
occurs.
It is interesting to consider how a seemingly impressive bio-
metric one-to-one “verifier” would perform in exhaustive search
mode once databases become larger than about 100, in view
of (13). For example, a face recognition algorithm that truly
achieved 99.9% correct rejection when tested on nonidentical
faces, hence making only 0.1% false matches, would seem to
be performing at a very impressive level because it must con-
fuse no more than 10% of all identical twin pairs (since about
1% of all persons in the general population have an identical
twin). But even with its , how good would it be for
searching large databases?
Using (13), we see that when the search database size has
reached merely unrelated faces, the probability of at
least one false match among them is already 18%. When the
search database is just unrelated faces, the proba-
bility of at least one false match has reached 86%. Clearly, iden-
tification is vastly more demanding than one-to-one verification,
and even for moderate database sizes, merely “good” verifiers
are of no use as identifiers. Observing the approximation that
for small , when searching a data-
base of size an identifier needs to be roughly times better
than a verifier to achieve comparable odds against making false
matches.
The algorithms for iris recognition exploit the extremely
rapid attenuation of the HD distribution tail created by binomial
combinatorics, to accommodate very large database searches
without suffering false matches. The HD threshold is adaptive,
to maintain regardless of how large the search
database size is. As Table I illustrates, this means that if the
search database contains 1 million different iris patterns, it is
Fig. 9. The Decision Environment for iris recognition under relatively
unfavorable conditions, using images acquired at different distances and by
different optical platforms.
only necessary for the HD match criterion to adjust downwards
from 0.33 to 0.27 in order to maintain still a net false match
probability of for the entire database.
VII. DECISION ENVIRONMENT FOR IRIS RECOGNITION
The overall “decidability” of the task of recognizing persons
by their iris patterns is revealed by comparing the HD distribu-
tions for same versus for different irises. The left distribution in
Fig. 9 shows the HDs computed between 7070 different pairs
of same-eye images at different times, under different condi-
tions, and usually with different cameras, and the right distri-
bution gives the same 9.1 million comparisons among different
eyes shown earlier. To the degree that one can confidently de-
cide whether an observed sample belongs to the left or the right
distribution in Fig. 9, iris recognition can be successfully per-
formed. Such a dual distribution representation of the decision
problem may be called the “decision environment,” because it
reveals the extent to which the two cases (same versus different)
are separable and thus how reliably decisions can be made, since
the overlap between the two distributions determines the error
rates.
Whereas Fig. 9 shows the decision environment under less
favorable conditions (images acquired by different camera plat-
forms), Fig. 10 shows the decision environment under ideal (al-
most artificial) conditions. Subjects’ eyes were imaged in a lab-
oratory setting using always the same camera with fixed zoom
factor and at fixed distance, and with fixed illumination. Not sur-
prisingly, more than half of such image comparisons achieved
an HD of 0.00, and the average HD was a mere 0.019. It is clear
from comparing Figs. 9 and 10 that the “authentics” distribution
for iris recognition (the similarity between different images of
the same eye, as shown in the left-side distributions), depends
very strongly upon the image acquisition conditions. However,
the measured similarity for “imposters” (the right-side distribu-
tion) is almost completely independent of imaging factors. In-
stead, it just reflects the combinatorics of Bernoulli trials, as bits
28 IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY, VOL. 14, NO. 1, JANUARY 2004
Fig. 10. The Decision Environment for iris recognition under very favorable
conditions, using always the same camera, distance, and lighting.
from independent binary sources (the phase codes for different
irises) are compared.
For two-choice decision tasks (e.g., same versus different),
such as biometric decision making, the “decidability” index
is one measure of how well separated the two distributions are,
since recognition errors would be caused by their overlap. If
their two means are and , and their two standard deviations
are and , then is defined as
(14)
This measure of decidability is independent of how liberal or
conservative is the acceptance threshold used. Rather, by mea-
suring separation, it reflects the degree to which any improve-
ment in (say) the false match error rate must be paid for by a
worsening of the failure-to-match error rate. The performance
of any biometric technology can be calibrated by its score,
among other metrics. The measured decidability for iris recog-
nition is for the nonideal (crossed platform) conditions
presented in Fig. 9, and it is for the ideal imaging
conditions presented in Fig. 10.
Based on the left-side distributions in Figs. 9 and 10, one
could calculate a table of probabilities of failure to match, as a
function of HD match criterion, just as we did earlier in Table I
for false match probabilities based on the right-side distribution.
However, such estimates may not be stable because the “authen-
tics” distributions depend strongly on the quality of imaging
(e.g., motion blur, focus, noise, etc.) and would be different for
different optical platforms. As illustrated earlier by the badly
defocused image of Fig. 3, phase bits are still set randomly with
binomial statistics in poor imaging, and so the right distribu-
tion is the stable asymptotic form both in the case of well im-
aged irises (Fig. 10) and poorly imaged irises (Fig. 9). Imaging
quality determines how much the same-iris distribution evolves
and migrates leftward, away from the asymptotic different-iris
distribution on the right. In any case, we note that for the 7070
same-iris comparisons shown in Fig. 9, their highest HD was
TABLE II
EXECUTION SPEEDS OF VARIOUS STAGES IN THE IRIS RECOGNITION
PROCESS ON A 300-MHZ RISC PROCESSOR
0.327 which is below the smallest HD of 0.329 for the 9.1 mil-
lion comparisons between different irises. Thus a decision cri-
terion slightly below 0.33 for the empirical data sets shown can
perfectly separate the dual distributions. At this criterion, using
the cumulatives of (11) as tabulated in Table I, the theoretical
false match probability is 1 in 4 million.
Notwithstanding this diversity among iris patterns and their
apparent singularity because of so many dimensions of random
variation, their utility as a basis for automatic personal iden-
tification would depend upon their relative stability over time.
There is a popular belief that the iris changes systematically with
one’s health or personality, and even that its detailed features
reveal the states of individual organs (“iridology”); but such
claims have been discredited (e.g., [3], [17]) as medical fraud. In
any case, the recognition principle described here is intrinsically
tolerant of a large proportion of the iris information being cor-
rupted, say up to about a third, without significantly impairing
the inference of personal identity by the simple test of statistical
independence.
VIII. SPEED PERFORMANCE SUMMARY
On a 300-MHz RISC processor, the execution times for the
critical steps in iris recognition are as shown in Table II, using
optimized integer code.
The search engine can perform about 100 000 full compar-
isons between different irises per second on such a CPU, or
1 million in 1.7 s on a 2-GHz server, because of the efficient
implementation of the matching process in terms of elemen-
tary Boolean operators and acting in parallel on the com-
puted phase bit sequences. If a database contained many mil-
lions of enrolled persons, then the inherent parallelism of the
search process should be exploited for the sake of speed by di-
viding up the full database into smaller chunks to be searched
in parallel. The confidence levels shown in Table I indicate how
the decision threshold should be adapted for each of these par-
allel search engines, in order to ensure that no false matches
were made despite several large-scale searches being conducted
independently. The mathematics of the iris recognition algo-
rithms, particularly the binomial-class distributions (4) and (11)
that they generate when comparing different irises, make it clear
that databases the size of an entire country’s population could
be searched in parallel to make confident and rapid identifica-
tion decisions using parallel banks of inexpensive CPUs, if such
iris code databases existed.
DAUGMAN: HOW IRIS RECOGNITION WORKS 29
APPENDIX
2-D FOCUS ASSESSMENT AT THE VIDEO FRAME RATE
The acquisition of iris images in good focus is made diffi-
cult by the optical magnification requirements, the restrictions
on illumination, and the target motion, distance, and size. All of
these factors act to limit the possible depth of field of the optics,
because they create a requirement for a lower F number to ac-
commodate both the shorter integration time (to reduce motion
blur) and the light dilution associated with long focal length.
The iris is a 1-cm target within a roughly 3-cm-wide field that
one would like to acquire at a range of about 30–50 cm, and with
a resolution of about five line pairs per mm. In a fixed-focus op-
tical system, the acquisition of iris images almost always begins
in poor focus. It is therefore desirable to compute focus scores
for image frames very rapidly, either to control a moving lens
element or to provide audible feedback to the subject for range
adjustment, or to select which of several frames in a video se-
quence is in best focus.
Optical defocus can be fully described as a phenomenon of
the 2-D Fourier domain. An image represented as a 2-D function
of the real plane has a 2-D Fourier transform
defined as
(15)
In the image domain, defocus is normally represented as convo-
lution of an in-focus image by the 2-D point-spread function of
the defocused optics. This point-spread function is often mod-
eled as a Gaussian whose space constant is proportional to the
degree of defocus. Thus for perfectly focused optics, the op-
tical point-spread function shrinks almost to a delta function,
and convolution with a delta function has no effect on the image.
Progressively defocused optics equates to convolving with ever
wider point-spread functions.
If the convolving optical point-spread function causing de-
focus is an isotropic Gaussian whose width represents the de-
gree of defocus, it is clear that defocus is equivalent to multi-
plying the 2-D Fourier transform of a perfectly focused image
with the 2-D Fourier transform of the “defocusing” (convolving)
Gaussian. This latter quantity is itself just another 2-D Gaussian
within the Fourier domain, and its spread constant there ( ) is
the reciprocal of that of the image-domain convolving Gaussian
that represented the optical point-spread function. Thus the 2-D
Fourier transform of an image defocused to degree
is related to , the 2-D Fourier transform of the corre-
sponding in-focus image, by a simple model such as
(16)
This expression reveals that the effect of defocus is to atten-
uate primarily the highest frequencies in the image and that
lower frequency components are virtually unaffected by defocus
since the exponential term approaches unity as the frequencies
( ) become small. (For simplicity, this analysis has assumed
isotropic optics and isotropic blur, and the optical point-spread
function has been described as a Gaussian just for illustration.
But the analysis can readily be generalized to non-Gaussian and
to anisotropic optical point-spread functions.)
Fig. 11. The (8 8) convolution kernel for fast focus assessment.
This spectral analysis of defocus suggests that an effective
way to estimate the quality of focus of a broadband image is
simply to measure its total power in the 2-D Fourier domain at
higher spatial frequencies, since these are the most attenuated
by defocus. One may also perform a kind of “contrast normal-
ization” to make such a spectrally based focus measure indepen-
dent of image content, by comparing the ratio of power in higher
frequency bands to that in slightly lower frequency bands. Such
spectrally based measurements are facilitated by exploiting Par-
seval’s theorem for conserved total power in the two domains:
(17)
Thus, high-pass filtering or bandpass filtering an image within a
ring of high spatial frequency (requiring only a 2-D convolution
in the image domain), and integrating the power contained in it,
is equivalent to computing the actual Fourier transform of the
image (a more costly operation) and making the corresponding
explicit measurement in the selected frequency band. Since the
computational complexity of a fast Fourier transform on
data is , some three million floating-point opera-
tions are avoided which would be otherwise be needed to com-
pute the spectral measurements explicitly. Instead, only about
6000 integer multiplications (squarings) per image are needed
by this algorithm, and no floating-point operations. Computa-
tion of focus scores is based only on simple algebraic combi-
nations of pixel values within local closed neighborhoods, re-
peated across the image.
Pixels are combined according to the (8 8) convolution
kernel shown in Fig. 11. The simple weights mean that the
sum of the central (4 4) pixels can just be tripled, and then
the outer 48 pixels subtracted from this quantity; the result
is squared and accumulated as per (17); and then the kernel
moves to the next position in the image, selecting every fourth
row and 4th column. This highly efficient discrete convolution
has a simple 2-D Fourier analysis.
The above kernel is equivalent to the superposition of two
centered square box functions, one of size (8 8) and ampli-
tude , and the other one of size (4 4) and amplitude .
(For the central region in which they overlap, the two therefore
sum to .) The 2-D Fourier transform of each of these square
functions is a 2-D “sinc” function, whose size parameters differ
30 IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY, VOL. 14, NO. 1, JANUARY 2004
Fig. 12. The 2-D Fourier power spectrum of the convolution kernel used for
rapid focus assessment.
by a factor of two in each of the dimensions and whose am-
plitudes are equal but opposite, since the two component boxes
have equal but opposite volumes. Thus the overall kernel has a
2-D Fourier transform which is the difference of two,
differently sized, 2-D sinc functions
(18)
The square of this function of and in the 2-D Fourier do-
main is plotted in Fig. 12, revealing , the convolution
kernel’s 2-D power spectrum.
Clearly low spatial frequencies (near the center of the
power spectral plot in Fig. 12) are ignored, reflecting the
fact that the pixel weights in the convolution kernel sum to
zero, while a bandpass ring of upper frequencies are selected
by this filter. The total power in that band is the spectral
measurement of focus. Finally, this summated 2-D spectral
power is passed through a compressive nonlinearity of the
form: (where parameter is the
half-power corresponding to a focus score of 50%), in order
to generate a normalized focus score in the range of 0 to
100 for any image. The complete execution time of this 2-D
focus assessment algorithm, implemented in C using pointer
arithmetic, operating on a (480 640) image, is 15 ms on a
300-MHz RISC processor.
REFERENCES
[1] Y. Adini, Y. Moses, and S. Ullman, “Face recognition: the problem of
compensating for changes in illumination direction,” IEEE Trans. Pat-
tern Anal. Machine Intell., vol. 19, pp. 721–732, July 1997.
[2] P. N. Belhumeur, J. P. Hespanha, and D. J. Kriegman, “Eigenfaces vs.
Fisherfaces: Recognition using class-specific linear projection,” IEEE
Trans. Pattern Anal. Machine Intell., vol. 19, pp. 711–720, July 1997.
[3] L. Berggren, “Iridology: A critical review,” Acta Ophthalmol., vol. 63,
no. 1, pp. 1–8, 1985.
[4] M. R. Chedekel, “Photophysics and photochemistry of melanin,”
in Melanin: Its Role in Human Photoprotection. Overland Park:
Valdenmar, 1995, pp. 11–23.
[5] T. Cover and J. Thomas, Elements of Information Theory. New York:
Wiley, 1991.
[6] J. Daugman, “Uncertainty relation for resolution in space, spatial fre-
quency, and orientation optimized by two-dimensional visual cortical
filters,” J. Opt. Soc. Amer. A, vol. 2, no. 7, pp. 1160–1169, 1985.
[7] , “Complete discrete 2D gabor transforms by neural networks for
image analysis and compression,” IEEE Trans. Acoust., Speech, Signal
Processing, vol. 36, pp. 1169–1179, July 1988.
[8] , “High confidence visual recognition of persons by a test of statis-
tical independence,” IEEE Trans. Pattern Anal. Machine Intell., vol. 15,
pp. 1148–1161, Nov. 1993.
[9] , “Biometric Personal Identification System Based on Iris Anal-
ysis,” U.S. Patent 291 560, 1994.
[10] , “Statistical richness of visual phase information: Update on rec-
ognizing persons by their iris patterns,” Int. J. Computer Vision, vol. 45,
no. 1, pp. 25–38, 2001.
[11] J. Daugman and C. Downing, “Demodulation, predictive coding, and
spatial vision,” J. Opt. Soc. Amer. A, vol. 12, no. 4, pp. 641–660, 1995.
[12] , “Epigenetic randomness, complexity, and singularity of human
iris patterns,” Proc. Royal Soc.: Biological Sciences, vol. 268, pp.
1737–1740, 2001.
[13] P. Kronfeld, “Gross anatomy and embryology of the eye,” in The Eye,
H. Davson, Ed. London, U.K.: Academic, 1962.
[14] A. Pentland and T. Choudhury, “Face recognition for smart environ-
ments,” Computer, vol. 33, no. 2, pp. 50–55, 2000.
[15] P. J. Phillips, A. Martin, C. L. Wilson, and M. Przybocki, “An intro-
duction to evaluating biometric systems,” Computer, vol. 33, no. 2, pp.
56–63, 2000.
[16] P. J. Phillips, H. Moon, S. A. Rizvi, and P. J. Rauss, “The FERET evalua-
tion methodology for face-recognition algorithms,” IEEE Trans. Pattern
Anal. Machine Intell., vol. 22, no. 10, pp. 1090–1104, 2000.
[17] A. Simon, D. M. Worthen, and J. A. Mitas, “An evaluation of iridology,”
J. Amer. Med. Assoc., vol. 242, pp. 1385–1387, 1979.
[18] R. Viveros, K. Balasubramanian, and N. Balakrishnan, “Binomial and
negative binomial analogues under correlated bernoulli trials,” Amer.
Statistician, vol. 48, no. 3, pp. 243–247, 1984.
John Daugman received the A.B. and Ph.D. degrees
from Harvard University, Cambridge, MA, in 1976
and 1983, respectively.
He subsequently taught on the faculty at Harvard.
He is currently a Faculty Member at Cambridge
University, Cambridge, U.K., where he teaches
courses in Information Theory, Computer Vision,
Continuous Mathematics, and Neural Computing.
During 2003-2004 he holds the Johann Bernoulli
Chair in Mathematics and Informatics at the
University of Groningen. He is the inventor of iris
recognition for personal identification, for which he received a U.S. patent in
1994.
Dr. Daugman has served as an Editor of several journals including IEEE
TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, Network
Computation in Neural Systems, Cognitive Brain Research, and Journal of Com-
putation and Mathematics. His academic awards include the U.S. National Sci-
ence Foundation’s Presidential Young Investigator Award, the inaugural Toshiba
Endowed Chair of the Tokyo Institute of Technology, and the Order of the British
Empire from Her Majesty Queen Elizabeth II. He also won the 1997 Informa-
tion Technology Award and Medal of the British Computer Society, the 2000
Technology Innovation Award of the US Smithsonian Museum, and the “Mil-
lennium Product” designation by the U.K. Design Council, for his work on iris
recognition for personal identification.

