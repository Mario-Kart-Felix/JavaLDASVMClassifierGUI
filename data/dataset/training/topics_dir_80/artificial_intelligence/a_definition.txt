A General Definition of an Attribute Reduct
Y. Zhao, F. Luo, S.K.M. Wong and Y.Y. Yao
Department of Computer Science, University of Regina
Regina, Saskatchewan, Canada S4S 0A2
E-mail: {yanzhao, luo202, yyao}@cs.uregina.ca, skmwong@rogers.com
Abstract. A reduct is a subset of attributes that are jointly sufficient
and individually necessary for preserving a particular property of a given
information table. A general definition of an attribute reduct is presented.
Specifically, we discuss the following issues: First, there are a variety of
properties that can be observed in an information table. Second, the
preservation of a certain property by an attribute set can be evaluated
by different measures, defined as different fitness functions. Third, by
considering the monotonicity property of a particular fitness function, the
reduct construction method needs to be carefully examined. By adopting
different heuristics or fitness functions for preserving a certain property,
one is able to derive most of the existing definitions of a reduct. The
analysis brings new insight into the problem of reduct construction, and
provides guidelines for the design of new algorithms.
Keywords: attribute reducts, property preservation functions, mono-
tonicity of evaluation function
1 Introduction
In many data analysis applications, information and knowledge are stored and
represented in an information table, where a set of objects is described by a set
of attributes. We are faced with one practical problem: for a particular property,
whether all the attributes in the attribute set are always necessary to preserve
this property. Using the entire attribute set for describing the property is time-
consuming, and the constructed rules may be difficult to understand, to apply
or to verify. In order to deal with this problem, attribute selection is required.
The theory of rough sets has been applied to data analysis, data mining and
knowledge discovery. A fundamental notion supporting such applications is the
concept of reducts [4]. The objective of reduct construction is to reduce the
number of attributes, and at the same time, preserve the property that we want.
In the literature of rough set theory, there are many definitions of a reduct,
and each focuses on preserving one specific type of property. This results in
two problems: first, all these existing definitions have the same structure, and
there is a lack of a higher level of abstraction. Second, along with the increasing
requirements of data analysis, we need to find more properties of an information
table. This naturally leads to more definitions in different forms. For these two
reasons, a general definition of an attribute reduct is necessary and useful [5]. A
Zhao, Y., Luo, F., Wong, S.K.M. and Yao, Y.Y., A general definition of an attribute reduct, 
Rough Sets and Knowledge Technology, Second International Conference, RSKT 2007, Proceedings, 
LNAI 4481, pp. 101-108, 2007.
1
general definition is suggested in Section 2. After that, three issues are discussed
in detail.
2 A Definition of a Reduct
An information table provides a convenient way to describe a finite set of ob-
jects called a universe by a finite set of attributes [4]. It represents all available
information and knowledge. That is, objects are only perceived, observed, or
measured by using a finite number of attributes.
Definition 1. An information table is the following tuple:
S = (U,At, {Va | a ∈ At}, {Ia | a ∈ At}),
where U is a finite nonempty set of objects, At is a finite nonempty set of at-
tributes, Va is a nonempty set of values of a ∈ At, and Ia : U → Va is an
information function that maps an object of U to exactly one value in Va.
A general definition of an attribute reduct is given as follows.
Definition 2. Given an information table S = (U,At, {Va | a ∈ At}, {Ia | a ∈
At}), consider a certain property P of S and R ⊆ A ⊆ At. An attribute set R is
called a reduct of A ⊆ At if it satisfies the following three conditions:
(1.) Evaluability condition: the property can be represented by an evaluation func-
tion e : 2At −→ (L,¹);
(2.) Jointly sufficient condition: e(A) ¹ e(R);
(3.) Individually necessary condition: for any R′ ⊂ R, ¬(e(A) ¹ e(R′)).
An evaluation or fitness function, e : 2At −→ (L,¹), maps an attribute set
to an element of a poset L equipped with the partial order relation ¹, i.e., ¹
is reflexive, anti-symmetric and transitive. For each property, we can use an
evaluation function as its indicator. Normally, the fitness function is not unique.
By applying the function e, we are able to pick the attribute set that preserves
the property P. Suppose we target the attribute set A, then the evaluation of
a candidate reduct R (e(R)) should be the same or superior to e(A). In many
cases, we have e(R) = e(A).
There are many properties that can be observed in an information table.
The discovery of a certain property allows us to describe the information of the
universe, or to predict the unseen data in the future. A property can be well-
defined and easy to be observed, for example, the size of the dataset and the
dimension of the description space. Alternatively, a property can be understood
as a previously unknown pattern to be discovered by a data analysis task, for
example, an association of attributes, a cluster of objects, a set of classification
rules, a preference ordering of objects, or the similarities or differences among
objects.
Zhao, Y., Luo, F., Wong, S.K.M. and Yao, Y.Y., A general definition of an attribute reduct, 
Rough Sets and Knowledge Technology, Second International Conference, RSKT 2007, Proceedings, 
LNAI 4481, pp. 101-108, 2007.
2
3 Interpretations of Properties
To classify the properties of an information table is not an easy task, as properties
have internal relationships, and there is no clear cut between different properties.
In addition, the number of properties is huge. Therefore, we only list some of
the well-known properties.
3.1 Property P1: Descriptions of object relations
A binary object relation (i.e., a subset of U × U) represents associations of one
object with other objects (perhaps the same one). Pawlak defines the indiscerni-
bility relation to summarize all indiscernible object pairs [4]. Given an attribute
set A ⊆ At, the indiscernibility relation is defined as:
IND(A) = {(x, y) ∈ U × U | ∀a ∈ A, Ia(x) = Ia(y)}. (1)
If (x, y) ∈ IND(A), then x and y are indiscernible with respect to A. We can
also define a discernibility relation as:
DIS(A) = {(x, y) ∈ U × U | ∀a ∈ A, Ia(x) 6= Ia(y)}. (2)
If (x, y) ∈ DIS(A), then x and y are different, and are discernible by any at-
tribute in A. It is easy to relax the indiscernibility or the discernibility relation
to define a similarity relation. For the indiscernibility relation IND, IND(At)
is finest, and IND(∅) is the coarsest. All relations form a poset under the set in-
clusion relation, which is embedded in (2U×U ,⊆). For the discernibility relation
DIS, the order is reversed.
Skowron and Rauszer suggest a discernibility matrix that stores all the at-
tributes that differentiate between any two objects of the universe [6]. Given an
information table S, its discernibility matrix dm is a |U |× |U | matrix with each
element dm(x, y) defined as:
dm(x, y) = {a ∈ At | Ia(x) 6= Ia(y), x, y ∈ U},
where |.| indicates cardinality of a set. The discernibility matrix dm is symmetric
and dm(x, x) = ∅. It is easy to verify that:
∀(x, y) ∈ IND(A), A ∩ dm(x, y) = ∅;
∀(x, y) ∈ DIS(A), A ⊆ dm(x, y).
3.2 Property P2: Descriptions of relative object relations
The indiscernibility, discernibility relations can be defined regarding to the labels
of the objects. That is, we concern the indiscernibility relation of two objects if
and only if they have the same label, and we concern the discernibility relation
of two objects if and only if their labels are different.
Zhao, Y., Luo, F., Wong, S.K.M. and Yao, Y.Y., A general definition of an attribute reduct, 
Rough Sets and Knowledge Technology, Second International Conference, RSKT 2007, Proceedings, 
LNAI 4481, pp. 101-108, 2007.
3
Given an attribute that labels objects, an information table can be written
as S = (U,At = C ∪ D, {Va | a ∈ At}, {Ia | a ∈ At}), where D is called the
set of decision attributes, and C is called the set of conditional attributes. The
D-relative indiscernibility and discernibility relations can be defined as:
INDD(A) = {(x, y) ∈ U × U | ∀a ∈ A, Ia(x) = Ia(y) ∧ ID(x) = ID(y)},
DISD(A) = {(x, y) ∈ U × U | ∀a ∈ A, Ia(x) 6= Ia(y) ∧ ID(x) 6= ID(y)}.
Skowron and Rauszer’s discernibility matrix can be used to store all the D-
relative discernibility relations.
3.3 Property P3: Partitions of an information table
An indiscernibility relation induces a partition of the universe, denoted as πA or
U/IND(A) . Each block of the partition,
[x]A = {y ∈ U | ∀a ∈ A, Ia(x) = Ia(y)}, (3)
is an equivalence class containing x. For any two objects x, y ∈ [x]A, (x, y) ∈
IND(A).
One can obtain a finer partition by further dividing the equivalence classes of
a partition. A partition π1 is a refinement of another partition π2, or equivalently,
π2 is a coarsening of π1, denoted by π1 ¹ π2, if every block of π1 is contained
in some block of π2. The partition U/IND(At) is the finest partition and the
partition U/IND(∅) is the coarsest partition. All partitions form a poset under
the refinement relation, denoted as (Π(U),¹).
3.4 Property P4: Descriptions of concepts
To describe a concept, rough set theory introduces a pair of lower approximation
(apr) and upper approximation (apr). Given an attribute set A ⊆ At, the lower
and upper approximations of X ⊆ U induced by A are defined by:
apr
A
(X) =
⋃
{[x]A | [x]A ⊆ X} =
⋃
{[x]A | |[x]A ∩X||[x]A| = 1}; (4)
aprA(X) =
⋃
{[x]A | [x]A ∩X 6= ∅} =
⋃
{[x]A | 0 < |[x]A ∩X||[x]A| ≤ 1}, (5)
Probabilistic rough set models [9, 11] relax the precision threshold from 1 to
β ∈ (0.5, 1]. The β-level lower and upper approximations are defined as:
aprβ
A
(X) =
⋃
{[x]A | |[x]A ∩X||[x]A| ≥ β},
aprβA(X) =
⋃
{[x]A | 0 < |[x]A ∩X||[x]A| < β}.
Zhao, Y., Luo, F., Wong, S.K.M. and Yao, Y.Y., A general definition of an attribute reduct, 
Rough Sets and Knowledge Technology, Second International Conference, RSKT 2007, Proceedings, 
LNAI 4481, pp. 101-108, 2007.
4
A pair of approximation operators (aprβ
1
, aprβ1 ) is larger than another pair
of approximation operators (aprβ
2
, aprβ2 ), or equivalently, (apr
β
2
, aprβ2 ) is smaller
than (aprβ
1
, aprβ1 ), denoted by (apr
β
1
, aprβ1 ) ¹ (aprβ2 , apr
β
2 ), if apr
β
2
(X) ⊆ aprβ
1
(X)
for all X ⊆ U . The approximation operator pair (aprβ
At
, aprβAt) is the largest one,
and the approximation pair (aprβ∅ , apr
β
∅ ) is the smallest one. All approximation
operators form a poset under the set inclusion relation, which is embedded in
((apr : 2U −→ 2U , apr : 2U −→ 2U ),¹).
3.5 Property P5: Classification of a set of concepts
The decision attribute of an information table classifies the universe into a family
of classes U/IND(D). The union of all the lower approximations of those classes
can be defined as the positive region, and the rest is called the boundary region.
That is:
POSA(D) =
⋃
Xi∈U/IND(D)
apr
A
(Xi); (6)
BNDA(D) = U − POSA(D). (7)
Based on the β-lower and upper approximations, the β-positive and boundary
regions can be defined. For example, POSβA(D) =
⋃
Xi∈U/IND(D) apr
β
A
(Xi). If
β ∈ (0.5, 1], we have POSβA(D) ≥ POSA(D).
A positive region POS1(D) is larger than another positive region POS2(D),
or equivalently, POS2(D) is smaller than POS1(D), if POS2(D) ⊆ POS1(D).
The positive region POSAt(D) is the largest positive region, and the positive
region POS∅(D) is the smallest one. All positive regions form a poset under the
subset relation, which is embedded in (2U ,⊆).
4 Evaluation Functions for Property Preservation
For a certain property P, we can use various fitness functions to evaluate the
degree of satisfiability of the property by an attribute set. Some functions reflect
the definition of the property directly; some reflect the definition of the property
indirectly.
4.1 Evaluate the description of an object relation
According to properties P1 and P2, we can directly use the following function to
evaluate the property preservation by a set of attributes:
eP : 2At −→ (2U×U ,⊆).
A property P ∈ {P1,P2} can be one of the IND(A), DIS(A) and SIM(A) re-
lations and the D-relative relations. The standard reduct construction method
Zhao, Y., Luo, F., Wong, S.K.M. and Yao, Y.Y., A general definition of an attribute reduct, 
Rough Sets and Knowledge Technology, Second International Conference, RSKT 2007, Proceedings, 
LNAI 4481, pp. 101-108, 2007.
5
implements the IND relation as the evaluation function [4]. Yao and Zhao ex-
plore the DIS relations and the IND−DIS relations for reduct construction [10].
A property P ∈ {P1,P2} can also be quantified using the function:
eP : 2At −→ (<,≤),
where < is the set of real numbers. We use the cardinality of the set of object
pairs satisfying a certain relation. Owing to the fact that the relations can be rep-
resented as a discernibility matrix, to count the number of dm(x, y) ∈ dm such
that A ∩ dm(x, y) = ∅ is equivalent to counting the cardinality of IND(A). At
the meantime, to count the number of dm(x, y) ∈ dm such that A ⊆ dm(x, y)
is equivalent to counting the cardinality of DIS(A).
4.2 Evaluate a partition of the universe
According to this property, we can use the following function to evaluate the
property preservation by a set of attributes directly:
eP3 : 2
At −→ (Π(U),¹).
Since only the indiscernibility relation is an equivalence relation and be able to
partition the universe, this type of property can be considered as a variation of
property P1.
A partition of the universe changes the information entropy of the configura-
tion. That means, we can evaluate the partition by calculating the information
entropy. The evaluation function can be defined as:
eP3 : 2
At −→ (<,≤).
For A ⊆ At, the information entropy is defined as H(A) = −∑ p(φA) log p(φA)
where φA is a configuration defined by an attribute set A, and p(φA) is the
probability of a configuration in the information table. The entire information
table contains H(At) bits of information.
4.3 Evaluate the description of a concept
According to this property, we can use the following function to evaluate the
property preservation by a set of attributes directly:
eP4 : 2
At −→ ((apr : 2U −→ 2U , apr : 2U −→ 2U ),¹).
This type of functions map a set A of attributes to a pair of approximation
operators.
A function representing this property can also be defined as a mapping from
an attribute set A to the lower approximation operator apr
A
. In the probabilistic
cases, it can be defined as a mapping to aprβ
A
. Therefore, the function is written
as:
eP4 : 2
At −→ (apr : 2U −→ 2U ,¹).
Zhao, Y., Luo, F., Wong, S.K.M. and Yao, Y.Y., A general definition of an attribute reduct, 
Rough Sets and Knowledge Technology, Second International Conference, RSKT 2007, Proceedings, 
LNAI 4481, pp. 101-108, 2007.
6
4.4 Evaluate a classification
According to this property, we can use the following function to evaluate the
property preservation by a set of attributes directly:
eP5 : 2
At −→ (2U ,⊆).
The positive and the boundary regions can be directly used. The positive region
is defined for reduct construction by Pawlak [4]. Practically, POSβA(D) has been
applied for constructing reducts by many researchers [2, 7, 11].
It is natural to extend the above function to the following form:
eP5 : 2
At −→ (<,≤).
The function e can be interpreted as the counting of POSA(D) or BNDA(D), or
its extension. For example, a classification accuracy measure γ(A,D) has been
studied to evaluate the ratio of the positive region with respect to the cardinality
of the universe:
γβ(A,D) =
|POSβA(D)|
|U | .
The γ criterion is widely applied for reduct construction. The γβ criterion is also
applied for computing reducts by many authors [2, 3, 11].
The conditional entropy reflects the classification accuracy from the information-
theoretic viewpoint. The conditional entropy of D given an attribute set A ⊆ C
is defined as:
H(D|A) = −
∑
Xi∈U/IND(D)
p(Xi)p(Xi|φA) log p(Xi|φA),
The conditional entropy can be used as a quantitative measure of this property,
and is applied for reduct construction [3]. Other information theoretic approach
has been studied by many researchers [1, 8].
5 The Monotonicity of Property Evaluation Functions
It is important to note that some functions are monotonic with respect to the
set inclusion, while some are not. For example, the relations IND, DIS and the
information entropy H have the monotonicity property with respect to the set
inclusion, however, the γβ measure does not have the monotonicity property.
If the function e is monotonic with respect to the set inclusion of attribute
sets, according to the definition, we need to check all the subsets of a candidate
reduct, in order to confirm that a candidate reduct is a reduct. On the other
hand, if e is not monotonic regarding the set inclusion, we need to search more
attribute sets, and the situation is more complicated.
The non-monotonicity property of the fitness function has not received enough
attention by the rough set community. Due to a lack of consideration of this is-
sue, some of the reduct construction strategies are not entirely reasonable. For
Zhao, Y., Luo, F., Wong, S.K.M. and Yao, Y.Y., A general definition of an attribute reduct, 
Rough Sets and Knowledge Technology, Second International Conference, RSKT 2007, Proceedings, 
LNAI 4481, pp. 101-108, 2007.
7
example, the measure γβ(P, D) = γβ(C,D) has been inappropriately used by
many researchers [2, 3, 11]. By emphasizing the equality relation, one might miss
some attribute sets that also are reducts, and with the γβ value greater than or
equal to γβ(C, D).
6 Conclusion
This paper introduces a general definition of an attribute reduct, and presents
a critical review of the existing reduct construction algorithms. It is found that
the differences among different definitions of a reduct, and associated reduct
construction algorithms, lie in the properties they try to preserve. Various quali-
tative and quantitative functions can be used to evaluate the degree of preserva-
tion of a certain property. The monotonicity property of an evaluation function
needs to be emphasized. When the monotonicity property holds, the equality re-
lation can be simply used to verify a candidate reduct; otherwise, a partial order
relation ¹ needs to be used. The analysis provides new insight of the existing
studies, points out common insufficient consideration of monotonicity in some of
the existing algorithms, and gives guidelines for the design of new algorithms.
References
1. Beaubouef, T., Petry, F.E., Arora, G.: Information-theoretic measures of uncer-
tainty for rough sets and rough relational databases. Information Sciences 109
(1998) 185-195
2. Beynon, M.: Reducts within the variable precision rough sets model: a further
investigation. European Journal of Operational Research 134 (2001) 592-605
3. Hu, Q., Yu D., Xie, Z.: Information-preserving hybrid data reduction based on
fuzzy-rough techniques. Pattern Recognition Letters 27 (2006) 414-423
4. Pawlak, Z.: Rough sets. International Journal of Computer Information and Science
11 (1982) 341-356
5. Qiu, G.F., Zhang, W.X., Wu, W.Z.: Charaterization of attributes in generalized
approximation representation spaces. LNAI 3461 (2005) 84-93
6. Skowron, A., Rauszer, C.: The discernibility matrices and functions in informa-
tion systems. In: Slowiński, R. (ed.): Intelligent Decision Support, Handbook of
Applications and Advances of the Rough Sets Theory. Dordrecht, Kluwer (1992)
7. Swiniarski, R.W.: Rough sets methods in feature reduction and classification. Inter-
national Journal of Applied Mathematics and Computer Science 11 (2001) 565-582
8. Wang, G.Y., Zhao, J., Wu, J.: A comparitive study of algebra viewpoint and in-
formation viewpoint in attribute reduction. Foundamenta Informaticae 68 (2005)
1-13
9. Yao, Y.Y., Wong, S.K.M.: A decision theoretic framework for approximating con-
cepts. International Journal of Man-machine Studies 37 (1992) 793-809
10. Yao, Y.Y., Zhao, Y.: Conflict analysis based on discernibility and indiscernibility.
Proceedings of 2007 IEEE Symposium on Foundations of Computational Intelli-
gence (2007)
11. Ziarko W.: Variable precision rough set model. Journal of Computer and System
Sciences 46 (1993) 39-59
Zhao, Y., Luo, F., Wong, S.K.M. and Yao, Y.Y., A general definition of an attribute reduct, 
Rough Sets and Knowledge Technology, Second International Conference, RSKT 2007, Proceedings, 
LNAI 4481, pp. 101-108, 2007.
8

