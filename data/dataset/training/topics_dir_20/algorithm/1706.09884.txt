Towards Understanding the Dynamics of
Generative Adversarial Networks
Jerry Li
MIT
jerryzli@mit.edu
Aleksander Mądry
MIT
madry@mit.edu
John Peebles
MIT
jpeebles@mit.edu
Ludwig Schmidt
MIT
ludwigs@mit.edu
June 30, 2017
Abstract
Generative Adversarial Networks (GANs) have recently been proposed as a promising avenue
towards learning generative models with deep neural networks. While GANs have demonstrated
state-of-the-art performance on multiple vision tasks, their learning dynamics are not yet well
understood, both in theory and in practice. To address this issue, we take a first step towards
a rigorous study of GAN dynamics. We propose a simple model that exhibits several of the
common problematic convergence behaviors (e.g., vanishing gradient, mode collapse, diverging or
oscillatory behavior) and still allows us to establish the first convergence bounds for parametric
GAN dynamics. We find an interesting dichotomy: a GAN with an optimal discriminator
provably converges, while a first order approximation of the discriminator leads to unstable GAN
dynamics and mode collapse. Our model and analysis point to a specific challenge in practical
GAN training that we call discriminator collapse.
1 Introduction
Generative modeling is a fundamental learning task of growing importance. As we apply machine
learning to increasingly sophisticated problems, we often aim to learn functions with an output domain
that is far more complex than simple class labels. Common examples include image “translation”
[14], speech synthesis [19], and robot trajectory prediction [7]. Due to progress in deep learning, we
now have access to powerful architectures that can represent generative models over such complex
domains. However, training these generative models is a key challenge. Simpler learning problems
such as classification have a clear notion of “right” and “wrong,” and the approaches based on
minimizing the corresponding loss functions have been tremendously successful. In contrast, training
a generative model is far more nuanced because it is often unclear how “good” a sample from the
model is.
Generative Adversarial Networks (GANs) have recently been proposed to address this issue [10].
In a nutshell, the key idea of GANs is to learn both the generative model and the loss function at the
same time. The resulting training dynamics are usually described as a game between a generator (the
generative model) and a discriminator (the loss function). The goal of the generator is to produce
1
ar
X
iv
:1
70
6.
09
88
4v
1 
 [
cs
.L
G
] 
 2
9 
Ju
n 
20
17
realistic samples that fool the discriminator, while the discriminator is trained to distinguish between
the true training data and samples from the generator. GANs have shown promising results on a
variety of tasks, and there is now a large body of work that explores the power of this framework
[11].
Unfortunately, training GANs turns out to be a challenging problem that often hinders further
research in this area. Practitioners have encountered a variety of obstacles such as vanishing
gradients, mode collapse, and diverging or oscillatory behavior [11]. At the same time, the theoretical
underpinnings of GAN dynamics are not yet well understood. To date, there were no convergence
proofs for GAN models even in very simple settings. A key challenge is that the overall loss function
driving the GAN dynamics is usually non-convex. As a result, the root cause of failing GAN dynamics
is often unclear.
In this paper, we take a first step towards a principled understanding of GAN dynamics. We
propose and examine a problem setup that exhibits all common failure cases of GAN dynamics while
remaining sufficiently simple to allow for a rigorous analysis. Concretely, we introduce and study
the GMM-GAN: a variant of GAN dynamics that captures learning a mixture of two univariate
Gaussians. We first show experimentally that standard gradient dynamics of the GMM-GAN often
fail to converge due to mode collapse or oscillatory behavior. Interestingly, this also holds for
techniques that were recently proposed to improve GAN training such as unrolled GANs [17]. In
contrast to these findings, we then show that GAN dynamics with an optimal discriminator do
converge, both experimentally and provably. To the best of our knowledge, our theoretical analysis
of the GMM-GAN is the first global convergence proof for concrete and non-trivial GAN dynamics.
Our results show a clear dichotomy between the GAN dynamics arising from applying simultaneous
gradient descent and the one that is able to use an optimal discriminator. The GAN with optimal
discriminator converges from (essentially) any starting point. On the other hand, the simultaneous
gradient GAN often fails to converge, even when the discriminator is allowed many more gradient
update steps than the generator. Importantly, our model allows us to understand the root cause
of this dichotomy, which we call discriminator collapse. In regions where the generator is fooling
the discriminator well, the gradient updates for the discriminator are stuck in a local minimum.
As a result, the discriminator loses much of its capacity and is thus unable to properly guide the
GAN dynamics, which then fails to converge to a good solution as a result. In particular, these
findings go against the common wisdom that first order methods are sufficiently strong for all deep
learning applications. We conjecture that this wisdom might not be correct in the context of saddle
point problems underlying GANs, and that discriminator collapse is also an important issue in more
complex GANs. We also believe that studying simple models like our GMM-GAN in more detail
will also lead to better methods for training more general GANs.
Paper outline. In Section 2, we introduce our framework for studying GAN dynamics and describe
some of its properties. Section 3 states our main theoretical results and describes the discriminator
collapse phenomenon in more detail. Section 4 then gives an overview of our convergence proof. In
Section 5, we provide experiments. We defer the proof details to the supplementary material.
2 Generative Adversarial Dynamics
Generative adversarial networks are commonly described as a two player game [10]. Given a true
distribution P , a set of generators G = {Gu, u ∈ U}, a set of discriminators D = {Dv, v ∈ V}, and a
2
monotone measuring function m : R→ R, the objective of GAN training is to find a generator u in
arg min
u∈U
max
v∈V
Ex∼P [m(Dv(x))] + Ex∼Gu [m(1−Dv(x))] . (1)
In other words, the game is between two players called the generator and discriminator, respectively.
The goal of the discriminator is to distinguish between samples from the generator and the true
distribution. The goal of the generator is to fool the discriminator by generating samples that are
similar to the data distribution.
By varying the choice of the measuring function and the set of discriminators, one can capture a
wide variety of loss functions. Typical choices that have been previously studied include the KL
divergence and the Wasserstein distance [10, 2]. Moreover, this formulation can also encode other
common objectives: most notably, as we will show later, the total variation distance.
To optimize the objective (1), the most common approaches are variants of simultaneous gradient
descent on the generator u and the discriminator v. But despite its attractive theoretical grounding,
GAN training is plagued by a variety of issues in practice. Two major problems are mode collapse
and vanishing gradients. Mode collapse corresponds to situations in which the generator only learns
a subset (a few modes) of the true distribution P [11, 4]. For instance, a GAN trained on an image
modeling task would only produce variations of a small number of images. Vanishing gradients
[2, 1, 3] are, on the other hand, a failure case where the generator updates become vanishingly
small, thus making the GAN dynamics not converge to a satisfying solution. Despite many proposed
explanations and approaches to solve the vanishing gradient problem, it is still often observed in
practice [11].
2.1 Towards a principled understanding of GAN dynamics
GANs provide a powerful framework for generative modeling. However, there is a fundamental
gap between these theoretical explanations and practice. Specifically, to the best of the authors’
knowledge, all theoretical studies of GAN dynamics for parametric models simply consider global
optima and stationary points of the dynamics, and there has been no rigorous study of the actual
GAN dynamics. In practice, GANs are always optimized using first order methods, and the current
theory of GANs cannot tell us whether or not these methods converge to a meaningful solution.
This raises a natural question, also posed as an open problem in [11]:
Can we understand the convergence behavior of GANs?
This problem has proved difficult to understand, because of the non-convexity of the objective
function, and of the generator and discriminator sets. Even simpler dynamics, for instance, when we
assume we have access to optimal discriminators, but still take gradient steps for the generator, have
proven challenging to understand. In fact, there is no consensus whether or not optimal discriminator
steps improve the convergence behavior.
In this work, we want to change this state of affairs and initiate the study of GAN dynamics
from an algorithmic perspective. Specifically, as a first step towards crystallizing a more general
picture, we define a principled model that captures many of the difficulties of real-world GANs but
is still simple enough to make a full analysis tractable. We present it below.
3
2.2 A Simple Model of Generative Adversarial Dynamics
Perhaps a tempting starting place for coming up with a simple but meaningful set of GAN dy-
namics is to consider the generators being univariate Gaussians with fixed variance. Indeed, in the
supplementary material we give a short proof that simple GAN dynamics always converge for this
class of generators. However, it seems that this class of distributions is insufficiently expressive to
exhibit many of the interesting phenomena such as mode collapse mentioned above. In particular,
the distributions in this class are all unimodal, and it is unclear what mode collapse would even
mean in this context.
Generators. The above considerations motivate us to make our model slightly more complicated.
That is, to assume that the true distribution and the generator distributions are all mixtures of two
univariate Gaussians with unit variance, and uniform mixing weights. Formally, our generator set is
G, where
G =
{
1
2
N (µ1, 1) +
1
2
N (µ2, 1) | µ1, µ2 ∈ R
}
. (2)
For any µ ∈ R2, we let Gµ(x) denote the distribution in G with means at µ1 and µ2. While this is a
simple change compared to a single Gaussian case, it makes a large difference in the behavior of
the dynamics. In particular, many of the pathologies present in real-world GAN training begin to
appear.
Loss function. While GANs are usually viewed as a generative framework, they can also be
viewed as a general method for density estimation. We want to set up learning an unknown generator
Gµ∗ ∈ G as a generative adversarial dynamics. To this end, we must first define the loss function
for the density estimation problem. A well-studied goal in this setting is to recover Gµ∗(x) in total
variation (also known as L1 or statistical) distance, where the total variation distance between two
distributions P,Q is defined as
dTV(P,Q) =
1
2
∫
Ω
|P (x)−Q(x)|dx = max
A
P (A)−Q(A) , (3)
where the maximum is taken over all measurable events A.
Such finding the best-fit distribution in total variation distance can indeed be naturally phrased
as generative adversarial dynamics. Unfortunately, for arbitrary distributions, this is algorithmically
problematic, simply because the set of discriminators one would need is intractable to optimize over.
However, for distributions that are structurally simple, like mixtures of Gaussians, it turns out we
can consider a much simpler set of discriminators. In Appendix A.1 in the supplementary material,
by using well-known connections to VC theory, we show that for two generators Gµ1 , Gµ2 ∈ G, we
have
dTV(Gµ1 , Gµ2) = max
E=I1∪I2
Gµ1(E)−Gµ2(E) , (4)
where the maxima is taken over two disjoint intervals I1, I2 ⊆ R. In other words, instead of
considering the difference of measure between the two generators Gµ1 , Gµ2 on arbitrary events,
we may restrict our attention to unions of two disjoint intervals in R. This is a special case of a
well-studied distance measure for structured distributions, known as the Ak-distance, for k = 2 [6, 5].
Moreover, this class of subsets has a simple parametric description.
4
Discriminators. Now, the above discussion motivates our definition of discriminators to be
D = {I[`1,r1] + I[`2,r2] |`, r ∈ R
2 s.t. `1 ≤ r1 ≤ `2 ≤ r2} . (5)
In other words, the set of discriminators is taken to be the set of indicator functions of sets which
can be expressed as a union of at most two disjoint intervals. With this definition, we have that the
finding the best fit in total variation distance to some unknown Gµ∗ ∈ G is equivalent to finding µ̂
minimizing
µ̂ = arg min
µ
max
`,r
L(µ, `, r) , where
L(µ, `, r) = Ex∼Gµ∗ [D(x)] + Ex∼Gµ [1−D(x)] (6)
can be shown to be a simple, smooth function of all three parameters (see the supplementary material
for details).
Dynamics. The objective in (6) is easily amenable to optimization at parameter level. A natural
approach for optimizing this function would be to define G(µ̂) = max`,r L(µ̂, `, r), and to perform
(stochastic) gradient descent on this function. This corresponds to, at each step, finding the the
optimal discriminator, and updating the current µ̂ in that direction. We call these dynamics the
optimal discriminator dynamics. Formally, given µ̂(0) and a stepsize ηg, and a true distribution
Gµ∗ ∈ G, the optimal discriminator dynamics for Gµ∗ ,G,D starting at µ̂(0) are given iteratively as
`(t), r(t) = arg max
`,r
L(µ̂(t), `, r) , (7)
µ̂(t+1) = µ̂(t) − ηg∇µL(µ̂(t), `(t), r(t)) , (8)
where the maximum is taken over `, r which induce two disjoint intervals.
For more complicated generators and discriminators such as neural networks, these dynamics
are computationally difficult to perform. Therefore, instead of the updates as in (8), one resorts
to simultaneous gradient iterations on the generator and discriminator. These dynamics are called
the first order dynamics. Formally, given µ̂(0), `(0), r(0) and a stepsize ηg, ηd, and a true distribution
Gµ∗ ∈ G, the first order dynamics for Gµ∗ ,G,D starting at µ̂(0) are specified as
µ̂(t+1) = µ̂(t) − ηg∇µL(µ̂(t), `(t), r(t)) (9)
r(t+1) = r(t) + ηd∇rL(µ̂(t), `(t), r(t)) , (10)
`(t+1) = `(t) + ηd∇`L(µ̂(t), `(t), r(t)) . (11)
Even for our relatively simple setting, the first order dynamics can exhibit a variety of behaviors,
depending on the starting conditions of the generators and discriminators. In particular, in Figure 1,
we see that depending on the initialization, the dynamics can either converge to optimality, exhibit
a primitive form of mode collapse, where the two generators collapse into a single generator, or
converge to the wrong value, because the gradients vanish. This provides empirical justification for
our model, and shows that these dynamics are complicated enough to model the complex behaviors
which real-world GANs exhibit. Moreover, as we show in Section 5 below, these behaviors are not
just due to very specific pathological initial conditions: indeed, when given random initial conditions,
the first order dynamics still more often than not fail to converge.
5
0 1000 2000 3000 4000 5000
3
2
1
0
1
2
3
First order dynamics, converging behavior
(a) Converging behavior
0 1000 2000 3000 4000 5000 6000 7000 8000
4
2
0
2
4
left0
left1
right0
right1
muhat0
muhat1
First order dynamics, mode collapse
(b) Mode collapse and oscillation
0 20 40 60 80 100
3
2
1
0
1
2
3
Optimal discriminator dynamics
(c) Optimal discriminator
0 1000 2000 3000 4000 5000
1.2
1.0
0.8
0.6
0.4
0.2
0.0
0.2
First order dynamics, vanishing gradient
(d) Vanishing gradient
Figure 1: A selection of different GAN behaviors. In all plots the true distribution was Gµ∗ with
µ∗ = (−0.5, 0.5), and step size was taken to be 0.1. The solid lines represent the two coordinates
of µ̂, and the dotted lines represent the discriminator intervals. In order: (a) first order dynamics
with initial conditions that converge to the true distribution. (b) First order dynamics with initial
conditions that exhibit wild oscillation before mode collapse. (c) Optimal discriminator dynamics.
(d) First order dynamics that exhibit vanishing gradients and converge to the wrong distribution.
Observe that the optimal discriminator dynamics converge, and then the discriminator varies wildly,
because the objective function is not differentiable at optimality. Despite this it remains roughly at
optimality from step to step.
3 Optimal Discriminator vs. First Order Dynamics
The difference between the optimal discriminator dynamics and the first order dynamics is an
important question in GAN training. While to the best of our knowledge, nobody has rigorously
analyzed either set of dynamics, the question of whether or not training the discriminator to
6
optimality is the right approach has received considerable attention. The optimal discriminator
dynamics are in general algorithmically infeasible and it is not clear to what extent these first order
methods can hope to match the performance of the optimal discriminator. Somewhat orthogonal to
these computational issues, there is also theoretical evidence [1] that using the optimal discriminator
at each step may not even be desirable in certain settings, though their setting is different from than
we consider. All these considerations lead us to the question:
Can we understand the impact of using optimal discriminators on convergence, and how do these
dynamics differ from the first order dynamics?
Our main theoretical result is1:
Theorem 3.1. Fix δ > 0 sufficiently small and C > 0. Let µ∗ ∈ R2 so that |µ∗i | ≤ C, and
|µ∗1−µ∗2| ≥ δ. Then, for all initial points µ̂(0) so that |µ̂
(0)
i | ≤ C for all i and so that |µ̂
(0)
1 − µ̂
(0)
2 | ≥ δ,
if we let η = poly(1/δ, e−C2) and T = poly(1/δ, e−C2), then if µ̂(T ) is specified by the optimal
discriminator dynamics, we have dTV(Gµ∗ , Gµ̂(T )) ≤ δ.
In other words, if the µ∗ are bounded by a constant, and not too close together, then in time
which is polynomial in the inverse of the desired accuracy δ and e−C2 , where C is a bound on how
far apart the µ∗ and µ̂ are, the optimal discriminator dynamics converge to the ground truth in total
variation distance. Note that the dependence on e−C2 is necessary, as if the µ̂ and µ∗ are initially
very far apart, then the initial gradients for the µ̂ will necessarily be of this scale as well.
On the other hand, we provide simulation results that demonstrate that first order updates, or
more complicated heuristics such as unrolling, all fail to consistently converge to the true distribution,
even under the same sorts of conditions as in Theorem 3.1. In Figure 1, we gave some specific
examples where the first order dynamics fail to converge. In Section 5 we show that this sort of
divergence is common, even with random initializations for the discriminators. In particular, the
probability of convergence is generally much lower than 1, for both the regular GAN dynamics,
and unrolling. In general, we believe that this phenomena should occur for any natural first order
dynamics for the generator. In particular, one barrier we observed for any such dynamics is something
we call discriminator collapse, that we describe below.
3.1 Discriminator Collapse: A Barrier for First Order Methods
As discussed above, our simple GAN dynamics are able to capture the same undesired behaviors
that more sophisticated GANs exhibit. In addition to these behaviors, our dynamics enables us to
discern another degenerate behavior which does not seem to have previously been observed in the
literature. We call this behavior discriminator collapse.
We first explain this phenomenon using language specific to our GMM-GAN dynamics. In our
dynamics, discriminator collapse occurs when a discriminator interval which originally had finite
width is forced by the dynamics to have its width converge to 0. This happens whenever this interval
1We actually analyze a minor variation on the optimal discriminator dynamics. In particular, we do not rule
out the existence of a measure zero set on which the dynamics are ill-behaved. Thus, we will analyze the optimal
discriminator dynamics after adding an arbitrarily small amount of Gaussian noise. It is clear that by taking this
noise to be sufficiently small (say exponentially small) then we avoid this pathological set with probability 1, and
moreover the noise does not otherwise affect the convergence analysis at all. For simplicity, we will ignore this issue
for the rest of the paper.
7
(a) Initial Configuration (b) Optimal Discriminator for Initial Configuration
(c) After 1000 Discriminator Steps
(d) After 1000 Simultaneous
Generator and Discriminator Steps
(e) After 1000 Simultaneous
Generator and Discriminator
Steps with 100x Unrolling
Figure 2: Example of Discriminator Collapse. The initial configuration has µ∗ = {−2, 2}, µ̂ =
{−1, 2.5}, left discriminator [−1, 0.2], and right discriminator [−1, 2.5]. The (multiplicative) step
size used to generate (c), (d), and (e) was 0.3. These plots are discussed in Subsection 3.1.
lies entirely in a region where the generator PDF is much larger than the discriminator PDF. We
will shortly argue why this is undesirable.
In Figure 2, we show an example of discriminator collapse in our dynamics. Each plot in the
figure shows the true PDF minus the PDF of the generators, where the regions covered by the
discriminator are shaded. Plot (a) shows the initial configuration of our example. Notice that the
leftmost discriminator interval lies entirely in a region for which the true PDF minus the generators’
PDF is negative. Since the discriminator is incentivized to only have mass on regions where the
difference is positive, the first order dynamics will cause the discriminator interval to collapse to
have length zero if it is in a negative region. We see in Plot (c) that this discriminator collapses if
we run many discriminator steps for this fixed generator. In particular, these steps do not converge
to the globally optimal discriminator shown in Plot (b).
This collapse also occurs when we run the dynamics. In Plots (d) and (e), we see that after
running the first order dynamics – or even unrolled dynamics – for many iterations, eventually both
discriminators collapse. When a discriminator interval has length zero, it can never uncollapse, and
moreover, its contribution to the gradient of the generator is zero. Thus these dynamics will never
converge to the ground truth.
For general GANs, we view discriminator collapse as a situation when the local optimization
landscape around the current discriminator encourages it to make updates which decrease its
representational power. For instance, this could happen because the first order updates are unable
to wholly follow the evolution of the optimal discriminator due to attraction of local maxima, and
thus only capture part of the optimal discriminator’s structure. We view understanding the exact
nature of discriminator collapse in more general settings and interesting research problem to explore
further.
8
4 Analyzing the Optimal Discriminator Dynamics
We provide now a high level overview of the proof of Theorem 3.1.
The key element we will need in our proof is the ability to quantify the progress our updates
make on converging towards the optimal solution. This is particularly challenging as our objective
function is neither convex nor smooth. The following lemma is our main tool for achieving that.
Roughly stated, it says that for any Lipschitz function, even if it is non-convex and non-smooth, as
long as the change in its derivative is smaller in magnitude than the actual value of the derivative,
gradient descent makes actual progress on the function value. Note that this change of derivative
condition is much weaker than typical assumptions one makes to analyze gradient descent.
Lemma 4.1. Let g : Rk → R be a Lipschitz function that is differentiable at some fixed x ∈
Rk. For some η > 0, let x′ = x − η∇f(x). Suppose there exists c < 1 so that almost all
v ∈ L(x, x′), where L(x, y) denotes the line between x and y, g is differentiable, and moreover,
we have ‖∇g(x)−∇g(v)‖2 ≤ c‖∇g(x)‖2. Then g(x′)− g(x) ≤ −η(1− c)‖∇g(x)‖22 .
Here, we will use the convention that µ∗1 ≤ µ∗2, and during the analysis, we will always assume
for simplicity of notation that µ̂1 ≤ µ̂2. Also, in what follows, let f(µ̂) = fµ∗(µ̂) = dTV(Gµ̂, Gµ∗)
and F (µ̂, x) = Gµ∗(x)−Gµ̂(x) be the objective function and the difference of the PDFs between the
true distribution and the generator, respectively.
For any δ > 0, define the sets
Rect(δ) = Rect(µ∗, δ) = {µ̂ : |µ̂i − µ∗j | < δ for some i, j}
Opt(δ) = Opt(µ∗, δ) = {µ̂ : |µ̂i − µ∗i | < δ for all i} .
to be the set of parameter values which have at least one parameter which is not too far from
optimality, and the set of parameter values so that all parameter values are close. We also let B(C)
denote the box of sidelength C around the origin, and we let Sep(γ) = {v ∈ R2 : |v1 − v2| > γ} be
the set of parameter vectors which are not too close together.
Our main work lies within a set of lemmas which allow us to instantiate the bounds in Lemma
4.1. We first show a pair of lemmas which show that, explicitly excluding bad cases such as mode
collapse, our dynamics satisfy the conditions of Lemma 4.1. We do so by establishing a strong (in
fact, nearly constant) lower bound on the gradient when we are fairly away from optimality (Lemma
4.2). Then, we show a relatively weak bound on the smoothness of the function (Lemma 4.3), but
which is sufficiently strong in combination with Lemma 4.2 to satisfy Lemma 4.1. Finally, we rule
out the pathological cases we explicitly excluded earlier, such as mode collapse or divergent behavior
(Lemmas 4.4 and 4.5). Putting all these together appropriately yields the desired statement.
Our first lemma is a lower bound on the gradient value:
Lemma 4.2. Fix C ≥ 1 ≥ γ ≥ δ > 0. Suppose µ̂ 6∈ Rect(0), and suppose µ∗, µ̂ ∈ B(C) and
µ∗ ∈ Sep(γ), µ̂ ∈ Sep(δ). Then, there is some K = K(δ, C) = Ω(1) · (δe−C2/C)O(1) so that
‖∇fµ∗(µ̂)‖2 ≥ K.
The above lemma statement is slightly surprising at first glance. It says that the gradient is
never 0, which would suggest there are no local optima at all. To reconcile this, one should note
that the gradient is not continuous (defined) everywhere. In fact, one could show that points near
the local optima of our problem actually have some of the largest derivatives compared to other
points, while the local optima themselves all have an undefined gradient.
The second states a bound on the smoothness of the function:
9
Lemma 4.3. Fix C ≥ 1 and γ ≥ δ > 0 so that δ is sufficiently small. Let µ∗, µ̂, µ̂′ be such
that L(µ̂, µ̂′) ∩ Opt(δ) = ∅, µ∗ ∈ Sep(γ), µ̂′, µ̂ ∈ Sep(δ), and µ∗, µ̂, µ̂′ ∈ B(C). Let K = Ω(1) ·
(δe−C
2
/C)O(1) be the K for which Lemma 4.2 holds with those parameters. If we have ‖µ̂′ − µ̂‖2 ≤
Ω(1) · (δe−C2/C)O(1) for appropriate choices of constants on the RHS, we get
‖∇fµ∗(µ̂′)−∇fµ∗(µ̂)‖2 ≤ K/2 ≤ ‖∇fµ∗(µ̂)‖2/2.
These two lemmas almost suffice to prove progress as in Lemma 4.1, however, there is a major
caveat. Specifically, Lemma 4.3 needs to assume that µ̂ and µ̂′ are sufficiently well-separated, and
that they are bounded. While the µ̂i start out separated and bounded, it is not clear that it does
not mode collapse or diverge off to infinity. However, we are able to rule these sorts of behaviors out.
Formally:
Lemma 4.4 (No mode collapse). Fix γ > 0, and let δ ≤ γ/100 be sufficiently small. Let η ≤ δ/C
for some C sufficiently large. Suppose µ∗ ∈ Sep(γ). Then, if µ̂ ∈ Sep(δ), and µ̂′ = µ̂− η∇fµ∗(µ̂),
we have µ̂′ ∈ Sep(δ).
Lemma 4.5 (No diverging to infinity). Let C > 0 be sufficiently large, and let η > 0 be sufficiently
small. Suppose µ∗ ∈ B(C), and µ̂ ∈ B(2C). Then, if we let µ̂′ = µ̂− η∇fµ∗(µ̂), then µ̂′ ∈ B(2C).
Together, these four lemmas together suffice to prove Theorem 3.1 by setting parameters
appropriately. We now pause to make some remarks on the proof techniques for these Lemmas. At
a high level, Lemmas 4.2, 4.4, 4.5 all follow from involved case analyses. Specifically, we are able to
deduce structure about the possible discriminator intervals by reasoning about the structure of the
current mean estimate µ̂ and the true means. From there we are able to derive bounds on how these
discriminator intervals affect the derivatives and hence the update functions.
To prove Lemma 4.3, we carefully study the evolution of the optimal discriminator as we make
small changes to the generator. The key idea is to show that when the generator means are far from
the true means, then the zero crossings of F (µ̂, x) cannot evolve too unpredictably as we change µ̂.
We do so by showing that locally, in this setting F can be approximated by a low degree polynomial
with large coefficients, via bounding the condition number of a certain Hermite Vandermonde matrix.
This gives us sufficient control over the local behavior of zeros to deduce the desired claim. By being
sufficiently careful with the bounds, we are then able to go from this to the full generality of the
lemma. We defer further details to Appendix B.
5 Experiments
To illustrate more conclusively that the phenomena demonstrated in Figure 1 are not particularly
rare, and that first order dynamics do often fail to converge, we also conducted the following heatmap
experiments. We set µ∗ = (−0.5, 0.5) as in Figure 1. We then set a grid for the µ̂, so that each
coordinate is allowed to vary from −1 to 1. For each of these grid points, we randomly chose a set of
initial discriminator intervals, and ran the first order dynamics for 3000 iterations, with constant
stepsize 0.3. We then repeated this 120 times for each grid point, and plotted the probability that
the generator converged to the truth, where we say the generator converged to the truth if the
TV distance between the generator and optimality is < 0.1. The choice of these parameters was
somewhat arbitrary, however, we did not observe any qualitative difference in the results by varying
these numbers, and so we only report results for this specific set of parameters. We also did the
10
same thing for the optimal discriminator dynamics, and for unrolled discriminator dynamics with 5
unrolling steps, as described in [17], which attempt to match the optimal discriminator dynamics.
The results of the experiment are given in Figure 3. Qualitatively, we see that all three methods
fail when we initialize the two generator means to be the same. This makes sense, since in that
regime, the generator starts out mode collapsed and it is impossible for it to un-“mode collapse”, so
it cannot fit the true distribution well.
Ignoring this pathology, we see that the optimal discriminator otherwise always converges to
the ground truth, as our theory predicts. On the other hand, both regular first order dynamics and
unrolled dynamics often times fail, although unrolled dynamics do succeed more often than regular
first order dynamics. This suggests that the pathologies encountered in Figure 1 are not so rare,
and that indeed, these first order methods are quite often unable to emulate optimal discriminator
dynamics.
1.0 0.5 0.0 0.5 1.0
1.0
0.5
0.0
0.5
1.0 0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
Regular training
1.0 0.5 0.0 0.5 1.0
1.0
0.5
0.0
0.5
1.0 0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
Unrolled Training
1.0 0.5 0.0 0.5 1.0
1.0
0.5
0.0
0.5
1.0 0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
Optimal training
Figure 3: Heatmap of success probability for random discriminator initialization for regular GAN
training, unrolled GAN training, and optimal discriminator dynamics.
11
6 Related Work
GANs have received a tremendous amount of attention in the deep learning community over the
past two years [11]. Hence we only compare our results to the most closely related papers here.
The recent paper [3] studies generalization aspects of GANs and the existence of equilibria in
the two-player game. In contrast, our paper focuses on the dynamics of GAN training. We provide
the first rigorous proof of global convergence and show that a GAN with an optimal discriminator
always converges to an approximate equilibrium.
One recently proposed method for improving the convergence of GAN dynamics is the unrolled
GAN [17]. The paper proposes to “unroll” multiple discriminator gradient steps in the generator loss
function. The authors argue that this improves the GAN dynamics by bringing the discriminator
closer to an optimal discriminator response. However, our experiments show that this is not a perfect
approximation: the unrolled GAN still fails to converge in multiple initial configurations (however,
it does converge more often than a “vanilla” one-step discriminator).
The authors of [1] also take a theoretical view on GANs. They identify two important properties of
GAN dynamics: (i) Absolute continuity of the unknown population distribution, and (ii) overlapping
support between the population distribution and the generator distribution. If these conditions do
not hold, they show that the GAN dynamics fail to converge in some settings. However, they do
not prove that the GAN dynamics do converge under such assumptions. We take a complementary
view: we give a convergence proof for a concrete GAN dynamics. Moreover, our simple model shows
that absolute continuity and support overlap are not the only important aspects in GAN dynamics:
although our 2-GMM distributions clearly satisfy both of their conditions, the first-order dynamics
still fail to converge.
The paper [18] studies the stability of equilibria in GAN training. The authors invoke stability
arguments for dynamical systems based on differential equations. In contrast to our work, the results
focus on local stability while we establish global convergence results. Moreover, their theorems rely on
fairly strong assumptions. While the authors give a concrete model for which these assumptions are
satisfied (the linear quadratic Gaussian GAN), the corresponding target and generator distributions
are unimodal. Hence this model cannot exhibit mode collapse. We propose the GMM-GAN specifically
because it is rich enough to exhibit mode collapse.
The recent work [12] views GAN training through the lens of online learning. The paper
establishes results for the game-theoretic minimax formulation based on results from online learning
(the well-known Follow-the-Regularized-Leader approach). The authors give results that go beyond
the convex-concave setting, but do not address generalization questions. Moreover, their theoretical
algorithm is not based on gradient descent (in contrast to essentially all practical GAN training)
and relies on an oracle for minimizing the highly non-convex generator loss. This viewpoint is
complementary to our approach. We establish results for learning the unknown distribution and
analyze the commonly used gradient descent approach for learning GANs.
There is also a growing literature on non-convex optimization, e.g., [9, 15]. However, prior work
with general results on non-convex optimization does not apply to our setting. For instance, our loss
function is not smooth and the gradient does not vanish near minima (it is not even defined there).
12
7 Conclusions
We haven taken a step towards a principled understanding of GAN dynamics. We define a simple
yet rich model of GAN training and prove convergence of the corresponding optimization dynamics.
To the best of our knowledge, our work is the first to establish global convergence guarantees for a
parametric GAN model. We find an interesting dichotomy: If we always take optimal discriminator
steps, the training dynamics provably converge from any starting point. In contrast, we show
experimentally that the training dynamics often fail if we take first order discriminator steps instead.
We also identify discriminator collapse as a candidate barrier in GAN training and show that it
often prevents our first order dynamics from converging. We believe that our results provide new
insights into GAN training and point towards a rich algorithmic landscape that is to be explored in
order to further understand GAN dynamics.
Acknowledgements
Jerry Li was supported by NSF CAREER Award CCF-1453261, a Google Faculty Research Award,
and an NSF Fellowship. Aleksander Mądry was supported by the NSF Grant No. 1553428, a Google
Research Fellowship, and a Sloan Research Fellowship. John Peebles was supported by the NSF
Graduate Research Fellowship under Grant No. 1122374 and by the NSF Grant No. 1065125. Ludwig
Schmidt was supported by a Google PhD Fellowship.
References
[1] Martin Arjovsky and Leon Bottou. Towards principled methods for training generative adver-
sarial networks. In ICLR, 2017.
[2] Martin Arjovsky, Soumith Chintala, and Léon Bottou. Wasserstein GAN. arXiv preprint
arXiv:1701.07875, 2017.
[3] Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang. Generalization and
equilibrium in generative adversarial nets (GANs). arXiv preprint arXiv:1703.00573, 2017.
[4] Sanjeev Arora and Yi Zhang. Do gans actually learn the distribution? an empirical study.
arXiv preprint arXiv:1706.08224, 2017.
[5] Siu-On Chan, Ilias Diakonikolas, Rocco A Servedio, and Xiaorui Sun. Efficient density estimation
via piecewise polynomial approximation. In Proceedings of the 46th Annual ACM Symposium
on Theory of Computing, pages 604–613. ACM, 2014.
[6] Luc Devroye and Gábor Lugosi. Combinatorial methods in density estimation. Springer Science
& Business Media, 2012.
[7] Chelsea Finn, Paul Christiano, Pieter Abbeel, and Sergey Levine. A connection between
generative adversarial networks, inverse reinforcement learning, and energy-based models.
CoRR, abs/1611.03852, 2016.
[8] Walter Gautschi. How (un) stable are Vandermonde systems? Lecture Notes in Pure and
Applied Mathematics, 124:193–210, 1990.
13
[9] Rong Ge, Furong Huang, Chi Jin, and Yang Yuan. Escaping from saddle points - online
stochastic gradient for tensor decomposition. In COLT, 2015.
[10] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil
Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural
information processing systems, pages 2672–2680, 2014.
[11] Ian J. Goodfellow. NIPS 2016 tutorial: Generative adversarial networks. CoRR, abs/1701.00160,
2017.
[12] Paulina Grnarova, Kfir Y. Levy, Aurelien Lucchi, Thomas Hofmann, and Andreas Krause. An
online learning approach to generative adversarial networks. arXiv preprint arXiv:1706.03269,
2017.
[13] R.A. Hummel and B.C. Gidas. Zero Crossings and the Heat Equation. New York University.,
1984.
[14] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with
conditional adversarial networks. In CVPR, 2017.
[15] Jason D. Lee, Max Simchowitz, Michael I. Jordan, and Benjamin Recht. Gradient descent only
converges to minimizers. In COLT, 2016.
[16] VA Markov. On functions deviating least from zero in a given interval. Izdat. Imp. Akad. Nauk,
St. Petersburg, pages 218–258, 1892.
[17] Luke Metz, Ben Poole, David Pfau, and Jascha Sohl-Dickstein. Unrolled generative adversarial
networks. In ICLR, 2017.
[18] Vaishnavh Nagarajan and J. Zico Kolter. Gradient descent gan optimization is locally stable.
arXiv preprint arXiv:1706.04156, 2017.
[19] Aäron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves,
Nal Kalchbrenner, Andrew W. Senior, and Koray Kavukcuoglu. Wavenet: A generative model
for raw audio. CoRR, abs/1609.03499, 2016.
A Omitted details from Section 2
A.1 Equivalence of A2 and TV for G
Here we formally prove (4). In fact, we will prove a slight generalization of this fact which will be
useful later on.
We require the following theorem from Hummel and Gidas:
Theorem A.1 ([13]). Let f be any analytic function with at most n zeros. Then f ◦ N (0, σ2) has
at most n zeros.
This allows us to prove:
14
Theorem A.2. Any linear combination F (x) of the probability density functions of k Gaussians
with the same variance has at most k − 1 zeros, provided at least two of the Gaussians have different
means. In particular, for any µ 6= ν, the function F (x) = Dµ(x)−Dν(x) has at most 3 zeroes.
Proof. If we have more than 1 Gaussian with the same mean, we can replace all Gaussians having
that mean with an appropriate factor times a single Gaussian with that mean. Thus, we assume
without loss of generality that all Gaussians have distinct means. We may also assume without loss
of generality that all Gaussians have a nonzero coefficient in the definition of F .
Suppose the minimum distance between the means of any of the Gaussians is δ. We first prove the
statement when δ is sufficiently large compared to everything else. Consider any pair of Gaussians
with consecutive means ν, µ. WLOG assume that µ > ν = 0. Suppose our pair of Gaussians has the
same sign in the definition of F . In particular they are both strictly positive. For sufficiently large
δ, we can make the contribution of the other Gaussians to F an arbitrarily small fraction of the
whichever Gaussian in our pair is largest for all points on [ν, µ]. Thus, for δ sufficiently large, that
there are no zeros on this interval.
Now suppose our pair of Gaussians have different signs in the definition of F . Without loss of
generality, assume the sign of the Gaussian with mean ν is positive and the sign of the Gaussian
with mean µ is negative. Then the PDF of the first Gaussian is strictly decreasing on (ν, µ] and
the PDF of the negation of the second Gaussian is decreasing on [ν, µ). Thus, their sum is strictly
decreasing on this interval. Similarly to before, by making δ sufficiently large, the magnitude of the
contributions of the other Gaussians to the derivative in this region can be made an arbitrarily small
fraction of the magnitude of whichever Gaussian in our pair contributes the most at each point in
the interval. Thus, in this case, there is exactly one zero in the intervale [µ, ν].
Also, note that there can be no zeros of F outside of the convex hull of their means. This follows
by essentially the same argument as the two positive Gaussians case above.
The general case (without assuming δ sufficiently large) follows by considering sufficiently skinny
(nonzero variance) Gaussians with the same means as the Gaussians in the definition of F , rescaling
the domain so that they are sufficiently far apart, applying this argument to this new function,
unscaling the domain (which doesn’t change the number of zeros), then convolving the function with
an appropriate (very fat) Gaussian to obtain the real F , and invoking Theorem A.1 to say that the
number of zeros does not increase from this convolution.
A.2 The function L
in this section, we derive the form of L. By definition, we have
√
2πL(µ̂, `, r) =
√
2π
(
Ex∼Gµ∗ [D(x)] + Ex∼Gµ [1−D(x)]
)
=
√
2π
(∫
I
Gµ∗(x)−Gµ̂(x)dx
)
+
√
2π
=
√
2π
∑
i=1,2
∫ ri
`i
Gµ∗(x)−Gµ̂(x)dx
+√2π
=
∑
i=1,2
∑
j=1,2
∫ ri
`i
e−(x−µ
∗
j )
2/2 − e−(x−µ̂j)2/2dx+
√
2π . (12)
15
It is not to hard to see from the Fundamental theorem of calculus that L is indeed a smooth function
of all parameters.
B Omitted Proofs from Section 4
This appendix is dedicated to a proof of Theorem 3.1.
B.1 Setup
By inspection on the form of (12), we see that the gradient of the function fµ∗(µ̂) if it is defined
must be given by
∂fµ∗
∂µ̂i
=
1√
2π
∑
i=1,2
(
e−(µ̂i−ri)
2/2 − e−(µ̂i−`i)2/2
)
.
Here Ii = [`i, ri] are the intervals which achieve the supremum in (4). While these intervals may not
be unique, it is not hard to show that this value is well-defined, as long as µ̂ 6= µ∗, that is, when the
optimal discriminator intervals are unique as sets.
Recall Fµ∗(µ̂, x) = Gµ∗(x)−Gµ̂(x).
B.2 Basic Math Facts
Before we begin, we require the following facts.
We first need that the Gaussian, and any fixed number of derivatives of the Gaussian, are
Lipschitz functions.
Fact B.1. For any constant i, there exists a constant B such that for all x, µ ∈ R, di
dxi
N (x, µ, σ2 =
1) ≤ B.
Proof. Note that every derivative of the Gaussian PDF (including the 0th) is a bounded function.
Furthermore, all these derivatives eventually tend to 0 whenever the input goes towards ∞ or −∞.
Thus, any particular derivative is bounded by a constant for all R. Furthermore, shifting the mean
of the Gaussian does not change the set of values the derivatives of its derivative takes (only their
locations).
We also need the following bound on the TV distance between two Gaussians, which is folklore,
and is easily proven via Pinsker’s inequality.
Fact B.2 (folklore). If two univariate Gaussians with unit variance have means within distance at
most ∆ then their TV distance is at most O(1) ·∆.
This immediately implies the following, which states that fµ∗ is Lipschitz.
Corollary B.3. There is some absolute constant C so that for any µ, ν, we have |fµ∗(µ)−fµ∗(ν)| ≤
C‖µ− ν‖2.
We also need the following basic analysis fact:
Fact B.4 (folklore). Suppose g : Rd → R is B-Lipschitz for some B. Then g is differentiable almost
everywhere.
This implies that fµ∗ is indeed differentiable except on a set of measure zero. As mentioned
previously, we will always assume that we never land within this set during our analysis.
16
B.3 Proof of Theorem 3.1 given Lemmata
Before we prove the various lemmata described in the body, we show how Theorem 3.1 follows from
them.
Proof of Theorem 3.1. Set δ′ be a sufficiently small constant multiple of δ. Provided we make the
nonzero constant factor on the step size sufficiently small (compared to δ′/δ), and the exponent on δ
in the magnitude step size at least one, the magnitude of our step size will be at most δ′. Thus, in
any step where µ̂ ∈ Opt(δ′), we end the step outside of this set but still in Opt(2δ′). By Lemma B.2,
for a sufficiently small choice of constant in the definition of δ′, the TV-distance at the end of such a
step will be at most δ.
Contrapositively, in any step where the TV-distance at the start is more than δ, we will have
at the start that µ̂ 6∈ Opt(δ′). Then, it suffices to prove that the step decreases the total variation
distance additively by at least 1/ poly(C, eC2 , 1/δ) in this case. For appropriate choices of constants
in expression for the step size (sufficiently small multiplicative and sufficiently large in the exponent),
this is immediately implied by Lemma 4.3 and Lemma 4.1 provided that µ∗, µ̂, µ̂′ ∈ B(2C) and
|µ̂1 − µ̂2| ≥ δ at the beginning of each step. The condition that we always are within B(2C) at the
start of each step is proven in Lemma 4.5 and the condition that the means are separated (ie., that
we don’t have mode collapse) is proven in Lemma 4.4.
It is interesting that a critical component of the above proof involves proving explicitly that
mode collapse does not occur. This suggests the possibility that understanding mode collapse may
be helpful in understanding convergence of Generative Adversarial Models and Networks.
B.4 Proof of Lemma 4.2
In this section we prove Lemma 4.2. We first require the following fact:
Fact B.5 ([16]). Let p(x) =
∑d
i=0 cjx
j be a degree d polynomial so that |p(x)| ≤ 1 for all x ∈
[−1, 1]. Then max0≤j≤d |cj | ≤ (
√
2 + 1)d. More generally, if |p(x)| ≤ α for all x ∈ [−ρ, ρ], then
max0≤j≤d |cjρj | ≤ O(α).
We also have the following, elementary lemma:
Lemma B.6. Suppose µ̂2 > µ∗i for all i. Then there is some x > µ̂2 so that Fµ∗(µ̂, x) < 0.
We are now ready to prove Lemma 4.2
Proof of Lemma 4.2. We proceed by case analysis on the arrangement of the µ̂ and µ∗.
Case 1: µ∗1 < µ̂1 and µ
∗
2 < µ̂2 In this case we have Fµ∗(µ̂, x) ≤ 0 for all x ≥ µ̂2. Hence the
optimal discriminators are both to the left of µ̂2. Moreover, by a symmetric logic we have
Fµ∗(µ̂, x) ≥ 0 for all x ≤ µ∗1, so the optimal discriminator has an interval of the form
I1 = [−∞, r1] and possibly I2 = [l2, r2] where r1 < l2 < r2 < µ̂2. Then it is easy to see that
∂f
∂µ̂2
(µ̂2) ≥ 1√2πe
−(µ̂2−r2)2/2 ≥ 1√
2π
e−2C
2 .
Case 2: µ̂1 < µ∗1 and µ̂2 < µ
∗
2 This case is symmetric to Case (1).
17
Case 3: µ̂1 < µ∗1 < µ
∗
2 < µ̂2 By Lemma B.6, we know that Fµ∗(µ̂, x) < 0 for some x ≥ µ̂2, and
similarly Fµ∗(µ̂, x) < 0 for some x ≤ µ̂1. Since clearly F (µ∗)(µ̂, x) > 0 for x ∈ [µ∗1, µ∗2], by
Theorem A.2 and continuity, the optimal discriminator has one interval. Denote it by I = [`, r],
so that we have ` ≤ µ∗1 and r ≥ µ∗2. Suppose ` ≥ µ̂1. Then
∂f
∂µ̂1
(µ̂1) =
1√
2π
(
e−(µ̂1−`)
2/2 − e−(µ̂1−r)2/2
)
=
1√
2π
e−(µ̂1−`)
2/2
(
1− e−(µ̂1−`)(r−`)e−(r−`)2/2
)
≥ 1√
2π
e−2C
2
(
1− e−δ2/2
)
.
We get the symmetric bound on ∂fµ∗∂µ̂2 (µ̂2) if r ≤ µ̂2. The final case is if ` < µ̂1 < µ̂2 < r.
Consider the auxiliary function
H(µ) = e−(`−µ)
2/2 − e−(r−µ)2/2 .
On the domain [`, r], this function is monotone decreasing. Moreover, for any µ ∈ [`, r], we
have
H ′(µ) = (`− µ)e−(`−µ)2/2 − (r − µ)e−(r−µ)2/2
≤ −r − `
2
e−(r−`)
2/8
≤ −γ
2
e−γ
2/8 .
In particular, this implies that H(µ̂1) < H(µ̂2)−γ2e−γ
2/8/2, so at least one of H(µ̂2) or H(µ̂1)
must be γ2e−γ2/8/4 in absolute value. Since ∂fµ∗∂µ̂i (µ̂i) = H(µ̂i), this completes the proof in this
case.
Case 4: µ∗1 < µ̂1 < µ̂2 < µ
∗
2 By a symmetric argument to Case 3, we know that the optimal dis-
criminator intervals are of the form (−∞, r] and [`,∞) for some r < µ̂1 < µ̂2 < `. The form of
the derivative is then exactly the same as in the last sub-case in Case 3 with signs reversed, so
the same bound holds here.
B.5 Proof of Lemma 4.3
We now seek to prove Lemma 4.3. Before we do so, we need to get lower bounds on derivatives of
finite sums of Gaussians with the same variance. In particular, we first show:
Lemma B.7. Fix γ ≥ δ > 0 and C ≥ 1. Suppose we have µ∗, µ̂ ∈ B(C), µ∗, µ̂ ∈ Sep(γ), with
µ̂ 6∈ Rect(δ), where all these vectors have constant length k. Then, for any x ∈ [−C,C], we have
that | di
dxi
Fµ∗(µ̂, x)| ≥ Ω(1) · (δ/C)O(1)e−C
2/2 for some i = 0, . . . , 2k − 1.
Proof. Observe that the value of the ith derivative of Fµ∗(µ̂, x) for any x is given by
di
dxi
Fµ∗(µ̂, x) =
1√
2π
2k∑
j=1
wj(−1)iHi(zj)e−z
2
j /2 ,
18
where wj ∈ {−1/k, 1/k}, the zj is either x − µ∗j or x − µ̂j , and Hi(z) is the ith (probabilist’s)
Hermite polynomial. Note that the (−1)iHi are orthogonal with respect to the Gaussian measure
over R, and are orthonormal after some finite scaling that depends only on i and is therefore
constant. Hence, if we form the matrix Mij = (−1)iHi(x− zj), if we define ui = d
i
dxi
Fµ∗(µ̂, x) for
i = 0, . . . , 2k − 1, we have that Mv = u, where vj = 1√2πwje
−(x−zj)2/2. By assumption, we have
‖v‖2 ≥ Ω(
√
k · e−C2/2) = Ω(e−C2/2). Thus, to show that some ui cannot be too small, it suffices to
show a lower bound on the smallest singular value of M . To do so, we leverage the following fact,
implicit in the arguments of [8]:
Theorem B.8 ([8]). Let pr(z) be family of orthonormal polynomials with respect to a positive
measure dσ on the real line for r = 1, 2, . . . , t and let z1, . . . , zt be arbitrary real numbers with zi 6= zj
for i 6= j. Define the matrix V given by Vij = pi(zj). Then, the smallest singular value of V , denoted
σt(V ), is at least
σmin(V ) ≥
(∫
R
t∑
r=1
`r(y)
2dσ(y)
)−1/2
,
where `r(y) =
∏
s 6=r
y−zs
zr−zs is the Langrange interpolating polynomial for the zr.
Set pr = Hr−1 t = 2k, and σ as the Gaussian measure; then apply the theorem. Observe that for
any i, j, we have |zi− zj | ≥ min(δ, γ) ≥ δ and |zi| ≤ C. Hence the largest coefficient of any Lagrange
interpolating polynomial through the zi is at most (Cδ )
2k−1 with degree 2k − 1. So, the square of
any such polynomial has degree at most 2(2k − 1) and max coefficient at most 2k(Cδ )
2(2k−1) This
implies that ∫
R
2k∑
r=1
`r(y)
2 dσ(y) =
2k∑
r=1
∫
R
`r(y)
2 dσ(y)
≤
2k∑
r=1
2(2k − 1) · 2k
(
C
δ
)2(2k−1)
max
s∈[2(2k−1)]
∫
R
ysdσ(y)
≤ O(1) ·
(
C
δ
)4k
max
s∈[4k]
∫ ∞
−∞
yse−y
2/2 dy
≤ O(1) ·
(
C
δ
)O(1)
.
Hence by Theorem B.8 we have that σmin(V ) ≥ Ω(1) ·
(
δ
C
)O(1). Therefore, we have that ‖u‖2 ≥
Ω(1) · (δ/C)O(1)e−C2/2, which immediately implies the desired statement.
We next show that the above Lemma can be slightly generalized, so that we can replace the
condition µ̂ 6∈ Rect(δ) with µ̂ 6∈ Opt(δ).
Lemma B.9. Fix C ≥ 1 ≥ γ ≥ δ ≥ Ξ > 0. Suppose we have µ∗, µ̂ ∈ B(C), µ∗, µ̂ ∈ Sep(γ), with
µ̂ 6∈ Opt(δ). Then for any x ∈ [−C,C], we have that | di
dxi
Fµ∗(µ̂, x)| ≥ Ω(1) · (δe−C
2
/C)O(1) for some
i = 0, . . . , 3.
19
Proof. Let Ξ be of the form Ω(1)·(δe−C2/C)O(1), where we will pick its precise value later. Lemma B.7
with δ in that Lemma set to Ξ and k = 2 proves the special case when µ̂ 6∈ Rect(Ξ). Thus, the
only remaining case is when µ̂i is close to µ∗i for some i and far away for the other i. Without
loss of generality, we assume the first entries are the close pair. Then we have |µ̂1 − µ∗1| ≤ Ξ and
|µ̂2 − µ∗2| ≥ δ.
There are four terms in the expression for d
i
dxi
Fµ∗(µ̂, x) corresponding to each of µ̂1, µ̂2, µ∗1, µ∗2.
Lemma B.7 with δ = Ξ and k = 1 implies that the contribution of the µ̂2 and µ∗2 terms to at
least one of the 0th through 3rd derivatives has magnitude at least Ω(1) · (δe−C2/C)O(1). Fact B.2
and Lemma B.10 (below) imply that the contribution of the µ̂1 and µ∗1 terms to these derivatives
has magnitude at most O(1) · Ξ4. Thus, there exists a Ξ = Ω(1) · (δ/C)O(1)e−C2/2 such that the
magnitude of the contribution of these second two terms is less than half that of the first two, which
gives a lower bound on the magnitude of the sum of all the terms of Ω(1) · (δ/C)O(1)e−C2/2.
We now show that any function which always has at least one large enough derivative—including
its 0th derivaive—on some large enough interval must have a nontrivial amount of mass on the
interval.
Lemma B.10. Let 0 < ξ < 1 and t ∈ N. Let F (x) : R → R be a (t + 1)-times differentiable
function such that at every point x on some interval I of length |I| ≥ ξ, F (x) ≥ 0 and there exists
an i = i(x) ∈ 0, . . . , t such that | di
dxi
F (x)| ≥ B′ for some B′. Also suppose | dt+1
dxt+1
F (x)| ≤ B for some
B. Then, ∫ y
z
F (x)dx ≥
(
B′ · (Ω(1) · ξ)t+1 ·min[(B′/B)t+2, 1]
(t+ 1)! · (t+ 1)
)
.
Proof. Let 0 < a < 1 be a non-constant whose value we will choose later. If I has length more
than aξ, truncate it to have this length. Let z denote the midpoint of I. By assumption, we know
that there is some i ∈ 0, . . . , t such that | di
dxi
F (x)| > ξ. Thus, by Taylor’s theorem, we have that
F (µ̂, x) ≥ p(x− z)− (B/(t+ 1)!) · |x− z|t+1 for some degree t polynomial p that has some coefficient
of magnitude at least B′/t!.
Thus, if we let G(y) =
∫ y
z p(x)dx, then G(y) is a degree t+ 1 polynomial with some coefficient
which is at least B′/(t! · t). By the nonnegativity of F on I, we have that G is nonnegative on
[−aξ/2, aξ/2]. By this and the contrapositive of Fact B.5 (invoked with α set to a sufficiently
small nonzero constant multiple of B), we have for some such y and some constant B′′ > 0 that
G(y) = |G(y)| ≥ B′′(|I|/2)t+1B′/(t! · t). Therefore, at this point, we have∫ y
z
F (x)dx ≥ G(y)−
∫ y
z
(B/(t+ 1)!) · |x− z|t+1dx
≥ B
′′at+1(ξ/2)t+1B′
t! · t
− B(aξ/2)
t+2
(t+ 1)! · (t+ 1)
≥
(
at+1(ξ/2)t+1(B′′B′ −Bξa/2)
(t+ 1)! · (t+ 1)
)
≥
(
at+1(ξ/2)t+1(B′′B′ −Ba/2)
(t+ 1)! · (t+ 1)
)
.
If B′B′′ ≤ B, we set a = B′B′′/B ≤ 1 which gives∫ y
z
F (x)dx ≥
(
(B′)t+2(Ω(1) · ξ/B)t+1
(t+ 1)! · (t+ 1)
)
.
20
Otherwise, B′B′′ ≥ B and we perform this substitution along with a = 1 which gives the similar
bound ∫ y
z
F (x)dx ≥
(
B′(Ω(1) · ξ)t+1
(t+ 1)! · (t+ 1)
)
.
Together, these bounds imply that we always have∫ y
z
F (x)dx ≥
(
B′ · (Ω(1) · ξ)t+1 ·min[(B′/B)t+2, 1]
(t+ 1)! · (t+ 1)
)
.
This allows us to prove the following lemma, which lower bounds how much mass F can put on
any interval which is moderately large. Formally:
Lemma B.11. Fix C ≥ 1 ≥ γ ≥ δ > 0. Let K = Ω(1) · (δe−C2/C)O(1) be the K for which
Lemma 4.2 is always true with those parameters. Let µ∗, µ̂ be so that µ̂ 6∈ Opt(δ), µ̂, µ∗ ∈ Sep(γ),
and µ∗, µ̂ ∈ B(C). Then, there is a ξ = Ω(1) · (δ/C)O(1)e−C2)O(1) such that for any interval I of
length |I| ≥ ξ which satisfies I ∩ [−C − 2
√
log(100/K), C + 2
√
log(100/K)] 6= ∅ and on which
F (µ̂, x) is nonnegative, we have∫
I
|F (µ̂, x)|dx ≥ Ω(1) · (δe−C2/C)O(1)ξO(1) .
Proof. By Lemma B.9 with C in that lemma set to C + 2
√
log(100/K), we get a lower bound of
Ω(1) · (δe−C2/C)O(1) on the magnitude of at least one of the 0th through 3rd derivatives of F (µ̂, x)
with respect to x. Set ξ equal to a sufficiently small (nonzero) constant times this value.
By Fact B.1 there exists a constant B such that the magnitude of the fifth derivative of F (µ̂, x)
with respect to x—which is a linear combination of four fifth derivatives of Gaussians with constant
coefficients—is at most B.
By Lemma B.10 applied to F (µ̂, x) as a function of x, we have
∫
I F (µ̂, x)dx ≥ Ω(1) · ξ
6.
Now we can prove Lemma 4.3.
Proof of Lemma 4.3. LetA = [C−2
√
log(100/K), C+2
√
log(100/K)] whereK = Ω(1)·(δe−C2/C)O(1)
is the K for which Lemma 4.2 is always true with those parameters.
Let Z± denote the set of all x ∈ A for which F (µ̂′, x) and F (µ̂, x) have different nonzero signs.
Let Z+ denote the subset of Z± where F (µ̂′, x) > 0 > F (µ̂, x) and Z− denote the subset where
F (µ̂′, x) < 0 < µ̂, x). Then Z± = Z+ ∪ Z− and Z+, Z− are disjoint and Lebesgue-measurable. If
vol(Z+) ≤ vol(Z−), switch µ̂ and µ̂′ so that vol(Z+) ≥ vol(Z−).
Note that Z+ can be obtained by making cuts in the real line at the zeros of F (µ̂′, x), F (µ̂, x),
and F (µ̂′, x)− F (µ̂, x), then taking the union of some subset of the open intervals induced by these
cuts. By Theorem A.2, the total number of such intervals is O(1). Thus, Z+ is the union of a
constant number of open intervals. By similar arguments, Z− is also the union of a constant number
of open intervals.
We now prove that vol(Z+), Z−1 ≤ O(1)·‖µ̂′−µ̂‖Θ(1)1 ·(δe−C
2
/C)−O(1). Since vol(Z+) ≥ vol(Z−),
it suffices to prove vol(Z+) ≤ O(1) · ‖µ̂′ − µ̂‖Θ(1)1 · (δe−C
2
/C)−O(1). Note also that by Lemma B.2,
each of these intervals has mass under F (µ̂′, x) at most
∫
R |F (µ̂
′, x)− F (µ̂, x)|dx ≤ O(1) · ‖µ̂′ − µ̂‖1.
21
By Lemma B.11 and Lemma 4.2, each of these intervals has length at most O(1) · ‖µ̂′ − µ̂‖Θ(1)1 ·
(δe−C
2
/C)−O(1). Since there are at most a constant number of such intervals, this is also a bound
on vol(Z+) (and vol(Z−)).
Let Y denote the set of x ∈ A on which both F (µ̂, x) and F (µ̂′, x) are nonnegative. Let X,X ′
denote the x 6∈ A for which F (µ̂, x) and F (µ̂′, x) are respectively positive. Let W,W ′ denote,
respectively, the sets of endpoints of the union of the optimal discriminators for µ̂, µ̂′. Then the
union of the optimal discriminators for µ̂, µ̂′ are respectively Y ∪Z− ∪X ∪W and Y ∪Z+ ∪X ′ ∪W ′.
Furthermore, each of these two unions is given by some constant number of closed intervals and
more specifically, that X,X ′ each contain at most two intervals by Lemma A.2. Thus, we have for
any i that ∣∣∣∣∣ ∂∂µ̂iTV(µ∗, µ̂)
∣∣∣∣µ̂′
µ̂
∣∣∣∣∣
=
∣∣∣∣∣∣
∫
Y ∪Z+∪W ′∪X′
d
dx
e(x−µ̂
′
i)
2/2dx−
∫
Y ∪Z−∪W∪X
d
dx
e(x−µ̂i)
2/2dx
∣∣∣∣∣∣
≤
∣∣∣∣∣∣
∫
Y ∪Z+∪W ′∪X′
d
dx
e(x−µ̂i)
2/2dx−
∫
Y ∪Z−∪W∪X
d
dx
e(x−µ̂i)
2/2dx
∣∣∣∣∣∣
+O(1) · |µ̂′i − µ̂i| ,
by Lipschitzness, and so∣∣∣∣∣ ∂∂µ̂iTV(µ∗, µ̂)
∣∣∣∣µ̂′
µ̂
∣∣∣∣∣
=
∣∣∣∣∣∣
∫
Z+∪X′
d
dx
e(x−µ̂i)
2/2dx−
∫
Z−∪X
d
dx
e(x−µ̂i)
2/2dx
∣∣∣∣∣∣
+O(1) · |µ̂′i − µ̂i|
≤
∣∣∣∣∣∣
∫
Z+
d
dx
e(x−µ̂i)
2/2dx± 4
100
·K −
∫
Z−
d
dx
e(x−µ̂i)
2/2dx± 4
100
·K
∣∣∣∣∣∣
+O(1) · |µ̂′i − µ̂i|
≤
∣∣∣∣∣∣
∫
Z+
d
dx
e(x−µ̂i)
2/2dx
∣∣∣∣∣∣+
∣∣∣∣∣∣
∫
Z−
d
dx
e(x−µ̂i)
2/2dx
∣∣∣∣∣∣
+
8
100
·K +O(1) · |µ̂′i − µ̂i|
≤ 2vol(Z+)
∣∣∣∣sup
x∈R
d
dx
e(x−µ̂i)
2/2
∣∣∣∣+ 8100 ·K +O(1) · |µ̂′i − µ̂i|
≤ O(1) · ‖µ̂′ − µ̂‖Θ(1)2 · (δe
−C2/C)−O(1) +
8
100
·K .
22
This bound also upper bounds ‖∇fµ∗(µ̂′) − ∇fµ∗(µ̂)‖2 up to a constant factor. Thus, if we
choose our step to have magnitude ‖µ̂′ − µ̂‖2 ≤ Ω(1) · (δe−C
2
/C)O(1) with appropriate choices of
constants, we get
‖∇fµ∗(µ̂′)−∇fµ∗(µ̂)‖2 ≤ K/2 ≤ ‖∇fµ∗(µ̂)‖2/2 ,
as claimed
B.6 Proof of Lemma 4.4
We now prove Lemma 3.4, which forbids mode collapse.
Proof of Lemma 4.4. Since η ≤ δ, if |µ̂1 − µ̂2| > 2δ then clearly µ̂′ ∈ Sep(δ), since the gradient is at
most a constant since the function is Lipschitz. Thus assume WLOG that |µ̂1 − µ̂2| ≤ 2δ ≤ γ/50.
There are now six cases:
Case 1: µ̂1 ≤ µ∗1 ≤ µ∗2 ≤ µ̂2 This case cannot happen since we assume |µ̂1 − µ̂2| ≤ 2δ ≤ γ/50.
Case 2: µ∗1 ≤ µ̂1 ≤ µ̂2 ≤ µ∗2 In this case, by Lemma B.6, we know F is negative at −∞ and at
+∞. Since clearly F ≥ 0 when x ∈ [µ∗1, µ∗2], by Theorem A.2 and continuity, the discriminator
intervals must be of the form (−∞, r], [`,∞) for some r ≤ µ̂1 ≤ µ̂2 ≤ `. Thus, the update
to µ̂i is (up to a constant factor of
√
2π) given by e−(`−µ̂i)2/2 − e−(r−µ̂i)2/2. The function
Q(x) = e−(`−x)
2/2 − e−(r−x)2/2 is monotone on x ∈ [r, `], and thus µ̂i must actually move away
from each other in this scenario.
Case 3: µ∗1 ≤ µ̂1 ≤ µ∗2 ≤ µ̂2 In this case we must have |µ∗2 − µ̂1| ≤ 2δ and similarly |µ∗2 − µ̂2| ≤ 2δ.
We claim that in this case, the discriminator must be an infinitely long interval (−∞,m] for
some m ≤ µ̂1. This is equivalent to showing that the function F (µ̂, x) has only one zero, and
this zero occurs at some m ≤ µ̂1. This implies the lemma in this case since then the update to
µ̂1 and µ̂2 are then in the same direction, and moreover, the magnitude of the update to µ̂1 is
larger, by inspection.
We first claim that there are no zeros in the interval [µ̂1, µ̂2]. Indeed, in this interval, we have
that
√
2πDµ̂(x) ≥ 2e−(γ/50)
2/2
= 2e−γ
2/5000
≥ 2
(
1− γ
2
5000
+O(γ4)
)
≥ 2
(
1− γ
2
10
)
,
but
√
2πDµ∗(x) ≤ 1 + e−(γ−2δ)
2/2
= 1 + e−(49γ/50)
2/2
≤ 2− γ
2
2
.
23
Hence Gµ̂(x) ≥ Gµ∗(x) for all x ∈ [µ̂1, µ̂2], and so there are no zeros in this interval. Clearly
there are no zeros of F when x ≥ µ̂2, because in that regime e−(x−µ̂i)
2/2 ≥ e−(x−µ∗i )2/2 for
i = 1, 2. Similarly there are no zeros of F when x ≤ µ∗1. Thus all zeros of F must occur in the
interval [−µ∗1, µ̂1].
We now claim that there are no zeroes of F on the interval [α+ 10δ, µ̂1], where α = (µ∗1 + µ̂1)/2.
Indeed, on this interval, we have
√
2πF (µ̂, x) = e−(x−µ
∗
1)
2/2 − e−(x−µ̂2)2/2 + e−(x−µ∗1)2/2 − e−(x−µ̂1)2/2
≤ e−(x−µ∗1)2/2 − e−(x−µ̂2)2/2 < 0 ,
where the first line follows since moving µ∗2 to µ̂1 only increases the value of the function on
this interval, and the final line is negative as long as x > (µ∗1 + µ̂2)/2, which is clearly satisfied
by our choice of parameters. By a similar logic (moving µ̂2 to µ∗2), we get that on the interval
[µ∗1, α− 10δ], the function is strictly positive. Thus all zeros of F must occur in the interval
[α− 10δ, α+ 10δ].
We now claim that in this interval, the function F is strictly decreasing, and thus has exactly
one zero (it has at least one zero because the function changes sign). The derivative of F with
respect to x is given by
√
2π
∂F
∂x
(µ̂, x)
= (µ∗1 − x)e−(x−µ
∗
1)
2/2 − (µ̂2 − x)e−(x−µ̂2)
2/2
+ (µ∗2 − x)e−(x−µ
∗
2)
2/2 − (µ̂2 − x)e−(x−µ̂1)
2/2 .
By Taylor’s theorem, we have
(µ∗1 − x)e−(x−µ
∗
1)
2/2 − (µ̂2 − x)e−(x−µ̂2)
2/2
= −2re−α2/2 +O
(
H2(δ)e
−(r−10δ)2/2δ2
)
,
where H2 is the second (probabilist’s) Hermite polynomial, and r = |µ∗1 − α|. On the other
hand, by another application of Taylor’s theorem, we also have
(µ∗2 − x)e−(x−µ
∗
2)
2/2 − (µ̂2 − x)e−(x−µ̂1)
2/2
= O
(
δH2(δ)e
−(r−10δ)2/2
)
.
Thus, altogether we have
√
2π
∂F
∂x
(µ̂, x)
≤ −2re−α2/2
+O
(
δH2(δ)e
−(r−10δ)2/2
)
< 0
by our choice of δ, and since r = γ/2 > δ/25.
24
Case 4: µ̂1 ≤ µ∗1 ≤ µ̂2 ≤ µ∗2 This case is symmetric to Case 3, and so we omit it.
Case 5: µ∗1 ≤ µ∗2 ≤ µ̂1 ≤ µ̂2 In this case, we proceed as in the proof of Theorem A.2. If the Gaussians
were sufficiently skinny, then by the same logic as in the proof of Theorem A.2, there is exactly
one zero crossing. The lemma then follows in this case by Theorem A.1.
Case 6: µ̂1 ≤ µ̂2 ≤ µ∗1 ≤ µ∗2 This case is symmetric to Case 5.
This completes the proof.
B.7 Proof of Lemma 4.5
We also show that no terribly divergent behavior can occur. Formally, we show that if the true
means are within some bounded box, then the generators will never leave a slightly larger box.
Proof of Lemma 4.5. If µ̂ ∈ B(C), then since f is Lipschitz and η is sufficiently small, clearly
µ̂′ ∈ B(C). Thus, assume that there is an i = 1, 2 so that |µ̂i| > C, and let µ̂1 be the largest such i
in magnitude. WLOG take µ̂2 > 0. In particular, this implies that µ̂2 > µ∗i for all i = 1, 2. There
are now 3 cases, depending on the position of µ̂1.
Case 1: µ̂1 ≥ µ∗2: Here, as in Case 2 in Lemma 4.4, the optimal discriminator is of the form (−∞, r]
for some r ≤ µ̂1, µ̂2. In particular, the update step will be
µ̂′i = µ̂i − ηe−(r−µ̂i)
2/2 < µ̂i .
Thus, in this case our update moves us in the negative direction. By our choice of η, this
implies that 0 ≤ µ̂′2 < µ̂′2. Moreover, since µ̂1 ≥ µ∗2, this implies that |µ̂1| ≤ C, and thus
|µ̂′1| ≤ 2C. Therefore in this case we stay within the box.
Case 2: µ∗1 ≤ µ̂1 ≤ µ∗2: As in Case 1, we know that µ̂1 cannot leave the box after a single update,
as |µ̂1| ≤ C. Thus it suffices to show that µ̂2 moves in the negative direction. By Lemma B.6,
we know there is a discriminator interval at −∞, and there is no discriminator interval at ∞.
Moreover, in this case, we know that F (µ̂, x) ≥ 0 for all x ≥ µ̂2. Thus, all discriminators must
be to the left of µ̂2. Therefore, the update to µ̂2 is given by
µ̂′2 = µ̂2
− η
(
e−(r2−µ̂2)
2/2 − e−(`2−µ̂2)2/2 + e−(r1−µ̂2)2/2
)
,
for some r1 ≤ `2 ≤ r2 ≤ µ̂′2. Clearly this update has the property that 0 ≤ µ̂′2 < µ̂2, and so
the new iterate stays within the box.
Case 3: µ̂1 ≤ µ∗2 In this case we must prove that neither µ̂1 nor µ̂2 leave the box. The two arguments
are symmetric, so we will focus on µ̂2. Since η is small, we may assume that µ̂2 > 3C/2, as
otherwise µ̂′2 cannot leave the box. As in Case 1, it suffices to show that the endpoints of the
discriminator intervals are all less than µ̂2. But in this case, we have that for all x ≥ µ̂′2, the
value of the true distribution at x is at most 2e−(x−C)2/2, and the value of the discriminator
is at e−(x−µ̂′2)2/2 ≥ e−(x−1.5C)2/2. By direct calculation, this is satisfied for any choice of C
satisfying 2e5C2/8 < e3C2/4, which is satisfied for C ≥ 3.
25
C Single Gaussian
Although our proof of the two Gaussian case implies the single Gaussian case, it is possible to
prove the single Gaussian case in a somewhat simpler fashion, while still illustrating several of the
high-level components of the overall proof structure. Therefore, we sketch how to do so, in hopes
that it provides additional intuition for the proof for a mixture of two Gaussians.
In order to prove convergence, we can use the following.
1. The fact that the gradient is only discontinuous on a measure 0 set of points.
2. An absolute lower bound on the magnitude of the gradient from below over all points that are
not close to the optimal solution that we might encounter over the course of the algorithm
3. An upper bound on how much the gradient can change if we move a certain distance.
Then, as long as we take steps that are small enough to guarantee that the gradient never changes
by more than half the absolute lower bound, we will get by Lemma 4.1 that we always make progress
towards the optimum solution in function value unless we are already close to the optimal solution.
The proof of these facts is substantially simplified in the single Gaussian case. Suppose we have
a true univariate Gaussian distribution with unit variance and mean µ∗, along with a generator
distribution with unit variance and mean µ̂. Then the optimal discriminator for this pair of
distributions starts at the midpoint between their means and goes in the direction of the true
distribution off to ∞ or −∞. Therefore, unless the generator mean is within one step length of
the true mean, it cannot move away from the true mean. One can also argue that the gradient of
µ̂ with respect to the optimal discriminator (ie., the gradient of total variation distance) is only
discontinuous when µ̂ = µ∗, and has magnitude roughly e(µ̂−(µ̂+µ∗)/2)2/2 for µ̂ 6= µ∗. This implies
the first two items. For the last item, note that the midpoint ez2/2, which implies the gradient
is Lipschitz as long as we are not at the optimal solution, which gives bounds on how much the
gradient can change if we move a certain distance.
The preceding discussion implies convergence for an appropriately chosen step size, and all this
can be made fully quantitative if one works out the quantitative versions of the statements in the
preceding argument.
This analysis is simpler the the two Gaussians analysis in several respects. In particular, the
proofs of the second two items are substantially more involved and require many separate steps.
For example, in the two Gaussian case, the gradient can be 0 if mode collapse happens, so we have
to directly prove both that mode collapse does not happen and that the gradient is large if mode
collapse doesn’t happen and we aren’t too close to the optimal solution, which is a substantially
more involved condition to prove. Additionally, the gradient in the two Guassian case does not
seem to be Lipschitz away from the optimum like it is in the single Gaussian case. Instead, we will
have to use a weaker condition which is considerably more difficult to reason about. This is further
complicated by the fact that the optimal discriminators can move in a discontinuous fashion when
we vary the generator means.
26

