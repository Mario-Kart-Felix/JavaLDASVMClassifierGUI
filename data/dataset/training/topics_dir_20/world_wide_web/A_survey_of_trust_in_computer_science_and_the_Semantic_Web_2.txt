A
c
a
a
T
©
K
1
[
t
e
i
e
t
s
I
u
o
t
e
a
b
t
a
w
e
v
u
1
d
Web Semantics: Science, Services and Agents
on the World Wide Web 5 (2007) 58–71
A survey of trust in computer science and the Semantic Web
Donovan Artz, Yolanda Gil ∗
Information Sciences Institute, University of Southern California, 4677 Admiralty Way, Marina del Rey, CA 90292, United States
Received 9 February 2006; accepted 23 March 2007
Available online 31 March 2007
bstract
Trust is an integral component in many kinds of human interaction, allowing people to act under uncertainty and with the risk of negative
onsequences. For example, exchanging money for a service, giving access to your property, and choosing between conflicting sources of information
ll may utilize some form of trust. In computer science, trust is a widely used term whose definition differs among researchers and application
reas. Trust is an essential component of the vision for the Semantic Web, where both new problems and new applications of trust are being studied.
his paper gives an overview of existing trust research in computer science and the Semantic Web.
2007 Published by Elsevier B.V.
r
n
t
o
a
s
i
s
a
w
a
w
i
T
w
n
v
w
a
a
r
eywords: Trust; Web of trust; Policies; Reputation
. Introduction
Trust is a central component of the Semantic Web vision
1–3]. The Semantic Web stack [3,4] has included all along a
rust layer to assimilate the ontology, rules, logic, and proof lay-
rs. Trust often refers to mechanisms to verify that the source of
nformation is really who the source claims to be. Signatures and
ncryption mechanisms should allow any consumer of informa-
ion to check the sources of that information. In addition, proofs
hould provide a tractable way to verify that a claim is valid.
n this sense, any information provider should be able to supply
pon request a proof that can be easily checked that certifies the
rigins of the information, rather than expect consumers to have
o generate those proofs themselves through a computationally
xpensive process. The web motto “Anyone can say anything
bout anything” makes the web a unique source of information,
ut we need to be able to understand where we are placing our
rust.
Trust has another important role in the Semantic Web, as
gents and automated reasoners need to make trust judgements
hen alternative sources of information are available. Comput-rs will have the challenge to make judgements in light of the
arying quality and truth that these diverse “open” (unedited,
ncensored) sources offer. Today, web users make judgments
∗ Corresponding author. Tel.: +1 310 822 1511; fax: +1 310 823 6714.
E-mail addresses: dono@isi.edu (D. Artz), gil@isi.edu (Y. Gil).
w
W
j
n
n
a
570-8268/$ – see front matter © 2007 Published by Elsevier B.V.
oi:10.1016/j.websem.2007.03.002outinely about which sources to rely on since there are often
umerous sources relevant to a given query, ranging from insti-
utional to personal, from government to private citizen, from
bjective report to editorial opinion, etc. These trust judgements
re made by humans based on their prior knowledge about a
ource’s perceived reputation, or past personal experience about
ts quality relative to other alternative sources they may con-
ider. Humans also bring to bear vast amounts of knowledge
bout the world they live in and the humans that populate the
eb with information about it. In more formal settings, such
s e-commerce and e-science, similar judgments are also made
ith respect to publicly available data and services. All of these
mportant trust judgments are currently in the hands of humans.
his will not be possible in the Semantic Web, where humans
ill not be the only consumers of information. Agents will
eed to automatically make trust judgments to choose a ser-
ice or information source while performing a task. Reasoners
ill need to judge which of the many information sources avail-
ble, at times contradicting one another, are more adequate for
nswering a question. In a Semantic Web where content will be
eflected in ontologies and axioms, how will a computer decide
hat sources to trust when they offer contradictory information?
hat mechanisms will enable agents and reasoners to make trust
udgments in the Semantic Web?
Trust is not a new research topic in computer science, span-
ing areas as diverse as security and access control in computer
etworks, reliability in distributed systems, game theory and
gent systems, and policies for decision making under uncer-
s and
t
i
S
a
s
d
p
f
b
t
t
s
c
S
2
i
n
m
m
s
p
f
r
“
d
a
c
l
t
o
u
p
a
b
o
t
a
i
i
n
a
d
v
h
d
t
c
t
e
m
c
w
r
c
e
w
o
f
(
(
(
D. Artz, Y. Gil / Web Semantics: Science, Service
ainty. The concept of trust in these different communities varies
n how it is represented, computed, and used. While trust in the
emantic Web presents unique challenges, prior work in these
reas is relevant and should be the basis for future research.
This paper provides an overview of trust research in computer
cience relevant to the Semantic Web. We focus on relating how
ifferent areas define and use trust in a variety of contexts. The
aper begins with a general discussion and definitions of trust
rom the literature. It describes reputation and policies as two
road categories of research to model trust. It then discusses a
hird category of trust research in designing general computa-
ional models of trust. The fourth and final category of research
urveyed is trust in information sources. Along the way, we dis-
uss the relevance of the work presented to ongoing and future
emantic Web research.
. Modeling and reasoning about trust
Many have recognized the value of modeling and reason-
ng about trust computationally. A wide of variety of literature
ow exists on trust, ranging from specific applications to general
odels. However, as many authors in the field have noted, the
eaning of trust as used by each researcher differs across the
pan of existing work. In order to give the reader a reference
oint for understanding trust, we offer three general definitions
rom existing research. The first definition, from Mui et al. [5],
efers to past encounters, and may be thought of by some as
reputation-based” trust:
“[Trust is] a subjective expectation an agent has about
another’s future behavior based on the history of their
encounters.”
The next definition, from Grandison and Sloman [6], intro-
uces context and is unique in referring to the “competence” to
ct (instead of actions, themselves):
“[Trust is] the firm belief in the competence of an entity to act
dependably, securely, and reliably within a specified context.”
The third definition, from Olmedilla et al. [7], applies to many
ases in this survey, and it refers to actions and not competence
ike the previous definition:
“Trust of a party A to a party B for a service X is the measur-
able belief of A in that B behaves dependably for a specified
period within a specified context (in relation to service X).”
A unifying theme is that trust is only worth modeling when
here is a possibility of deception, that is, when there is a chance
f a different outcome than what is expected or has been agreed
pon.
Two common ways of determining trust are through using
olicies or reputation. We adopt these categories from Bon-
tti et al. [8], as they best describe the distinction we observe
etween the “hard evidence” used in policies, and the estimation
f trust used in reputation systems. Policies describe the condi-
ions necessary to obtain trust, and can also prescribe actions
nd outcomes if certain conditions are met. Policies frequently
nvolve the exchange or verification of credentials, which areAgents on the World Wide Web 5 (2007) 58–71 59
nformation issued (and sometimes endorsed using a digital sig-
ature) by one entity, and may describe qualities or features of
nother entity. For example, having the credential of a university
egree means its holder has been recognized by the issuing uni-
ersity as having a certain education level. This associates the
older with the university and to those educated in his field. Cre-
entials can be used when trust in the entity itself is unknown, but
here is existing trust in what is associated through the entity’s
redentials.
Reputation is an assessment based on the history of interac-
ions with or observations of an entity, either directly with the
valuator (personal experience) or as reported by others (recom-
endations or third party verification). How these histories are
ombined can vary, and recursive problems of trust can occur
hen using information from others (i.e., can I trust an entity’s
ecommendation about another entity?). At a basic level, both
redentials and reputation involve the transfer of trust from one
ntity to another, but each approach has its own unique problems
hich have motivated much of the existing work in trust.
Table 1 is a roadmap for this survey, and gives an overview
f research areas and references. We organize trust research in
our major areas:
1) Policy-based trust. Using policies to establish trust, focused
on managing and exchanging credentials and enforc-
ing access policies. Work in policy-based trust generally
assumes that trust is established simply by obtaining a suf-
ficient amount of credentials pertaining to a specific party,
and applying the policies to grant that party certain access
rights. The recursive problem of trusting the credentials is
frequently solved by using a trusted third party to serve as
an authority for issuing and verifying credentials.
2) Reputation-based trust. Using reputation to establish trust,
where past interactions or performance for an entity
are combined to assess its future behavior. Research
in reputation-based trust uses the history of an entity’s
actions/behavior to compute trust, and may use referral-
based trust (information from others) in the absence of (or in
addition to) first-hand knowledge. In the latter case, work is
being done to compute trust over social networks (a graph
where vertices are people and edges denote a social rela-
tionship between people), or across paths of trust (where
two parties may not have direct trust information about each
other, and must rely on a third party). Recommendations are
trust decisions made by other users, and combining these
decisions to synthesize a new one, often personalized, is
another commonly addressed problem.
3) General models of trust. There is a wealth of research on
modeling and defining trust, its prerequisites, conditions,
components, and consequences. Trust models are useful for
analyzing human and agentized trust decisions and for oper-
ationalizing computable models of trust. Work in modeling
trust describes values or factors that play a role in computing
trust, and leans more on work in psychology and sociol-
ogy for a decomposition of what trust comprises. Modeling
research ranges from simple access control polices (which
specify who to trust to access data or resources) to anal-
60 D. Artz, Y. Gil / Web Semantics: Science, Services and Agents on the World Wide Web 5 (2007) 58–71
Table 1
A categorization of major areas of trust research
Policy-based trust
Network security credentials
(Kohl and Neuman, 1993) [9]
Trust negotiation
(Yu et al., 2001) [10]
(Yu and Winslett, 2003) [11]
(Winslett et al., 2002) [13]
(Li et al., 2003) [14]
(Nejdl et al., 2004) [15]
(Bonatti and Olmedilla, 2005) [16]
(Gandon and Sadeh, 2004) [17]
(Winsborough et al., 2000) [12]
(Seigneur and Jensen, 2004) [18]
Security policies and trust languages
(Tonti et al., 2003) [19]
(Uszok et al., 2003) [20]
(Kagal et al., 2003) [21]
(Nielsen and Krukow, 2003) [22]
(Carbone et al., 2003) [23]
(EHR Policy, 2001) [24]
(XACML, 2005) [26]
(SAML, 2005) [27]
(WS-Trust, 2005) [28]
(Becker and Sewell, 2004) [25]
(Leithead et al., 2004) [29]
Distributed trust management
(Blaze et al., 1996) [31]
(Blaze et al., 1999) [32]
(Chu et al., 1997) [33]
(Kagal et al., 2002) [34]
Effect of credential type
(Zheng et al., 2002) [36]
Reputation-based trust
Decentralization and referral trust
(Abdul-Rahman and Hailes, 1997a) [37]
(Abdul-Rahman and Hailes, 1997b) [38]
(Yu and Singh, 2000) [39]
(Yu and Singh, 2002) [40]
(Yu and Singh, 2003) [41]
(Sabater and Sierra, 2002) [42]
(Beth et al., 1994) [43]
(Xiao and Benbasat, 2003) [44]
(O’Donovan and Smyth, 2005) [45]
Trust metrics in a web of trust
(Goldbeck and Hendler, 2004a) [51]
(Goldbeck and Hendler, 2004b) [52]
(Stewart, 1999) [53]
(Stewart and Zhang, 2003) [54]
(Richardson et al., 2003) [55]
(Masa and Avesani, 2005) [56]
(Guha et al., 2004) [57]
(Advogato, 2000) [58]
(Chirita et al., 2004) [59]
(Ding et al., 2004) [60]
Trust in P2P networks and grids
(Kamvar et al., 2003) [47]
(Cornelli et al., 2002) [48]
(Aberer and Despotovic, 2001) [49]
(Damiani et al., 2002) [50]
(Olmedilla et al., 2005) [7]
Application-specific reputation
(Pirzada and McDonald, 2004) [61]
(Dash et al., 2004) [62]
(Josang and Ismail, 2002) [63]
Table 1 (Continued )
General models of trust
General characteristics of trust
(McKnight and Chervany, 1996) [64]
(Gefen, 2002) [65]
(Acrement, 2002) [66]
(Mui et al., 2002) [5]
(Staab et al., 2004) [67]
Computational and online trust models
(Marsh, 1994) [68]
(Ziegler and Lausen, 2005) [69]
(Resnick et al., 2000) [70]
(Friedman et al., 2000) [71]
(Falcone and Castelfranchi, 2004) [72]
(Jonker et al., 2004) [73]
Game theory and agents
(Buskens, 1998) [74]
(Brainov and Sandholm, 1999) [75]
(Ashri et al., 2005) [76]
(Ramchurn et al., 2003) [77]
(Huynh et al., 2004) [78]
Software engineering
(Viega et al., 2001) [82]
Trust in information resources
Trust concerns in the Web
(Khare and Rifkin, 1997) [83]
(Grandison and Sloman, 2000) [6]
Trust concerns in the Semantic Web
(Bizer and Oldakowski, 2004) [84]
(Berners-Lee, 1999) [1]
(O’Hara et al., 2004) [85]
Trust using hyperlinks
(Gyongy et al., 2004) [86]
(Massa and Hayes, 2005) [87]
(Brin and Page, 1998) [46]
(Kleinberg, 1999) [88]
Filtering information based on trust
(Ciolek, 1996) [89]
(Clarke et al., 2001) [90]
(Downey et al., 2005) [91]
Filtering the Semantic Web
(Bizer et al., 2005) [92]
(Ding et al., 2003) [93]
(Ding et al., 2005) [94]
(Ziegler, 2004) [95]
Subjectivity analysis
(Riloff et al., 2005) [97]
(Stoyanov et al., 2005) [98]
(Cardie et al., 2004) [99]
Provenance information
(McGuinness, 2005) [100]
(Golbeck, 2006) [101]
(Zhao et al., 2004) [102]
(Wong et al., 2005) [103]
(Kim et al., 2007) [104]
Content trust
(Gil and Ratnakar, 2002) [107,108]
(Chklovski et al., 2003) [109]
(Castelfranchi et al., 2003) [110]
(Gil and Artz, 2006) [111]
Site design and human factors
(Sillence et al., 2004) [112]
(Stephens, 2004) [113]
(Corritore et al., 2001) [114]
s and
(
c
v
b
e
c
i
i
s
i
a
w
t
3
t
h
3
s
i
d
a
w
u
t
t
p
t
“
t
i
o
m
r
i
v
t
i
w
m
y
t
c
t
t
i
c
t
u
b
c
3
a
m
t
i
a
i
t
p
b
e
c
e
t
s
e
d
c
t
d
d
f
s
t
c
a
p
s
m
D. Artz, Y. Gil / Web Semantics: Science, Service
yses of competence, beliefs, risk, importance, utility, etc.
These subcomponents underlying trust help our understand-
ing of the more subtle and complex aspects of composing,
capturing, and using trust in a computational setting.
4) Trust in information resources. Trust is an increasingly com-
mon theme in Web related research regarding whether Web
resources and Web sites are reliable. Moreover, trust on
the Web has its own range of varying uses and meanings,
including capturing ratings from users about the quality
of information and services they have used, how web site
design influences trust on content and content providers,
propagating trust over links, etc. With the advent of the
Semantic Web, new work in trust is harnessing both the
potential gained from machine understanding, and address-
ing the problems of reliance on the content available in the
web so that agents in the Semantic Web can ultimately make
trust decisions autonomously. Provenance of information is
key to support trust decisions, as is automated detection of
opinions as distinct from objective information.
In the rest of the paper, we devote a section to each of the
ategories in turn, and we provide a section each on related sur-
eys and concluding remarks. We begin with policies, followed
y reputation, due to dependencies in some of the concepts
xplained. Likewise, the section on general models uses con-
epts from both policies and reputation research. We cover
nformation sources and the Web last, as we believe research
n this area is best explained with knowledge of the previous
ections. In categorizing existing work, we do not focus on the
ndividual key contributions, but instead on how trust is used
nd defined. Many papers may fit under multiple categories, but
e have organized references in a way we think is most useful
o readers.
. Policy-based trust
This section summarizes work using policies to establish
rust. Policies allow the expression of when, for what, and even
ow to determine trust in an entity.
.1. Network security credentials
The application of a policy is performed by considering some
et of information about an entity with regard to trust, and this
nformation is commonly a credential. Although the word “cre-
ential” is frequently used to refer to “signed” statements about
n entity, it lacks a precise common definition across existing
ork. Many policies rely on credentials, but in general they may
tilize a broader range of information that can be used to make
rust decisions. An illustrative example of a common alternative
o a signed credential occurs in the process of logging into a com-
uter. A valid user name with a correct password must be given
o gain access. According to the system’s policy, this information
proves” the user is trusted by the computer’s administrator. At
he same time, a user must keep his password secret, as reveal-
ng it to anything other than the computer system will allow
thers to use the same credential. In more complex examples, it
o
W
t
i
Agents on the World Wide Web 5 (2007) 58–71 61
ay be undesirable to reveal credentials to another party. When
evealing a credential, an entity may sacrifice privacy and reveal
nformation that may be used by others to the entity’s disad-
antage. For example, most users implicitly trust the computer
hey log into, but the need to establish trust in both directions
s essential for entities providing services on the Web. Evolving
ork in policies highlight a more complex problem in trust: how
uch to trust another entity to see your own credentials when
ou wish to earn that entity’s trust.
Credentials are sometimes implemented using security cer-
ificates with digital signatures. Typically in research, a security
ertificate has the primary role of having one entity vouch for
he identity of another, but does not necessarily include creden-
ial information. A certificate can be used as a credential if it
ncludes properties about an entity.
The well-known Kerberos protocol [9] is used to exchange
redentials. The Kerberos system uses a third party to facili-
ate the exchange of credentials (digital signatures) between a
ser and a computer. Kerberos does not determine access rights,
ut instead enables two parties to securely exchange verifiable
redentials.
.2. Trust negotiation
An important problem in establishing trust is that revealing
credential may incur a loss of privacy or control of infor-
ation. Winslett and co-workers [10–12] have focused on the
rade-off between privacy and earning trust. In this work, trust
n a particular context is earned by revealing a certain number
nd type of credentials, and privacy of credential information
s lost as the credentials are revealed. An implemented archi-
ecture based on these principles is TrustBuilder [13], which
rovides mechanisms for addressing this trade-off. This work
uilds on a “hard security” view of trust, which means trust is
stablished using traditional security techniques (e.g., authenti-
ation, access control, encryption, etc.). In TrustBuilder, trust is
arned when sufficient credentials are revealed (but not too many
o sacrifice privacy). Making trust decisions requires under-
tanding the risk of revealing a credential, and the benefit of
arning trust. Also in TrustBuilder, is the concept of a “cre-
ential chain”, where trust is transferred transitively through
redentials (e.g., if A trusts the credentials of B, and B trusts
he credentials of C, then A may have some trust in the cre-
entials of C). The trust management language RT0 [14] is
esigned explicitly to perform credential chaining, and allows
or an efficient distributed search to find such chains. Another
ystem is PeerTrust [15], a more recent policy and trust nego-
iation language that facilitates the automatic negotiation of a
redential exchange. Following PeerTrust, is PROTUNE [16],
provisional trust negotiation framework. PROTUNE allows
olicies with “provisional predicates”, where actions may be
pecified that will satisfy (currently unsatisfied) conditions. In a
ore specific view, Gandon and Sadeh [17] have proposed usingntologies to enable context-aware applications on the Semantic
eb. Context-aware applications will only reveal credentials in
he correct context. Others working in this area have contributed
deas on client–server credential exchange [12], and protect-
6 s and
i
[
3
a
m
t
d
l
a
t
t
I
i
o
i
T
s
e
g
s
e
s
t
a
m
s
K
r
e
u
e
d
f
b
q
t
O
r
T
a
p
m
s
l
r
c
s
f
p
h
p
r
W
i
g
e
a
h
n
h
s
t
p
3
j
t
v
a
i
f
i
p
a
i
s
s
s
g
K
a
o
H
s
c
w
r
d
3
t
[
T
u
a
t
4
2 D. Artz, Y. Gil / Web Semantics: Science, Service
ng privacy through generalizing or categorizing credentials
18].
.3. Security policies and trust languages
Security research is responsible for many of the first models
nd descriptions of trust in computer science. Trust is frequently
otivated by work in security and policy representation, and
rust and security are related, interdependent concepts with
ifferent purposes. In Tonti et al. [19], several current policy
anguages, designed for use in the Semantic Web, are compared
nd contrasted. A key point in this work is that policy specifica-
ion for negotiating interactions is essential for building trust, as
he rules of negotiation determine how and if trust is achieved.
n most trust-related policy languages, the type of trust in mind
s typically related to access control. A notable system designed
riginally for agents, Uszok et al. [20] describes the KAoS pol-
cy language and KAoS “services” used to enforce its policies.
he major drive for KAoS has been to enable the use of the
ame policy in distributed heterogeneous environments and to
nable dynamic policy changes. In Kagal et al. [21], a policy lan-
uage (subsequently known as Rei) is described which addresses
ecurity and privacy issues in the Semantic Web, while allowing
ach entity to specify their own policy. The Rei language uses
emantic representations to separate policy from implementa-
ion, and models “speech acts” (to programmatically “discuss”
policy at runtime) as a means of negotiation and dynamic policy
anipulation.
Several recent efforts in creating security policies have con-
idered how to represent and express trust. In Nielsen and
rukow [22], the authors propose trust replaces key-based secu-
ity, based on the fact that we cannot ever know everything about
veryone. Trust in this work is comprised by observations of a
ser, recommendations from others about that user, and refer-
nces to other sources of trust on that user. Access control is
etermined by a user’s level of trust, and this work provides a
ormal policy language in which trust can be proved. In Car-
one et al. [23], trust is decomposed into different types and
ualities, yielding a policy language that allows fine-tuned con-
rol over trust decisions using lattices of relative trust values.
ne example of trust in policy form is the electronic health
ecords policy [24] generated for use with Cassandra [25].
his policy exemplifies Cassandra’s role-based access control
pproach to trust. Keeping trust and security separate, some
olicy languages, such as the OASIS extensible access control
arkup language [26], still assume trust is established through
ome external system. The OASIS security assertion markup
anguage [27], provides a means for authentication and autho-
ization, but is not able to represent or suggest trust. As a
onsequence, SAML has the prerequisite that some external
ystem is trusted.
To facilitate the exchange of credentials, several standards
or representation of policies and credentials have been pro-
osed. WS-Trust [28], an extension of WS-Security, specifies
ow trust is gained through proofs of identity, authorization, and
erformance. This work literally views trust from a hard secu-
ity perspective, issuing a “security token” when trust is earned.
r
a
Agents on the World Wide Web 5 (2007) 58–71
S-Trust does not address the trust negotiation process, only
ts representation.
The Cassandra system [25] uses a policy specification lan-
uage that enforces how trust may be earned through the
xchange of credentials. This work is inspired by role-based
ccess control, a context-based system for authorization. Leit-
ead et al. [29] uses ontologies to flexibly represent trust
egotiation policies (rules used to negotiate trust). Ontologies
ave more flexibility than set standards, they simplify policy
pecification, and they enable more information to be specified
o control privacy during trust negotiation.
Olmedilla [30] provides a comprehensive overview and com-
arison of policy languages.
.4. Distributed trust management
A problem in using credentials, is that they are also sub-
ect to trust decisions (i.e., can you believe a given credential
o be true?). A trusted third party may sign credentials if it has
erified or issued them, and in practice, certificate authorities
re used to verify signatures. Even with this limited capabil-
ty, it can be undesirable to have a single authority responsible
or deciding who and when someone is trusted. This problem
s broadly described as trust management. Early work on this
roblem is found in PolicyMaker [31], which called for the sep-
ration of security and trust, recognizing the problems allowing
ndividual systems to have separate and different trust policies
eparate from the common, global authentication and security
ystem. Following PolicyMaker, Blaze et al. [32] presents a
ystem called KeyNote, which provides a standard policy lan-
uage, which is independent of the programming language used.
eyNote provides more application features than PolicyMaker,
nd the authors compare their idea of trust management with
ther existing systems at the time, including REFEREE [33].
owever, as seen in more recent work [34], some researchers in
ecurity still take a hard security approach to trust (i.e., trust is
ompletely present or absent). Trust in this work is defined as
hat is earned after identity and authorization are verified, or
ather, after credentials and their claimed association is verified.
Ruohomaa and Kutvonen [35] provides a detailed survey and
iscussion of alternative approaches for trust management.
.5. Effect of credential type
Some types of credentials affect trust more than others in cer-
ain scenarios, and this phenomenon is examined by Zheng et al.
36] for agents playing in a variation of the prisoner’s dilemma.
rust is measured as the amount of cooperation between two
sers, and the types of credentials include resumes, text-chats,
nd pictures of players. The results of this study show that the
ype of credential affects the amount of trust or distrust received.
. Reputation-based trustReputation-based trust uses personal experience or the expe-
iences of others, possibly combined, to make a trust decision
bout an entity. This section explores work in reputation-
s and
b
s
4
w
t
q
m
f
m
m
v
t
m
i
i
c
r
m
a
b
m
a
h
e
f
t
a
r
h
f
a
b
t
p
o
s
b
r
4
p
m
n
n
a
g
t
b
r
t
c
s
u
w
D
r
i
W
t
c
t
m
w
t
t
l
p
r
4
o
i
b
m
W
t
t
u
b
f
s
o
T
t
t
a
a
t
e
a
d
t
t
o
t
e
B
a
o
t
D. Artz, Y. Gil / Web Semantics: Science, Service
ased trust, a well-defined area of trust research in computer
cience.
.1. Decentralization and referral trust
Just as in policy-based trust, one solution to obtaining trust-
orthy reputation information is to consult a central, trusted
hird party that has had prior experience with the entity in
uestion and can provide an assessment of its reputation. The
ajority of existing work avoids this solution, and most research
ocuses explicitly on decentralization for reputation manage-
ent. Citing the problems with hard security in traditional
echanisms, Abdul-Rahman and Hailes [37,38] focus on pro-
iding a system in which individuals are empowered to make
rust decisions rather than rely on a centralized process. The
ain contribution of this work is to describe a system where
t can be acknowledged that malicious entities coexist with the
nnocent, achieved through a decentralized trust decision pro-
ess. Yu and Singh [39–41] describe a decentralized solution to
eputation management, which allows agents to actively deter-
ine trust using reputation information they receive from other
gents. Reputation management avoids a hard security approach
y distributing reputation information, allowing individuals to
ake trust decisions instead of a single, centralized trust man-
gement system making the decisions for them. Singh and Yu
ave provided approaches to using reputation information from
xternal sources, weighting it by the reputation of those sources
or providing good information. In this work, a peer that provides
rust information about another peer is referred to as a witness,
nd this type of information is more commonly referred to as
eferral trust. Sabater and Sierra [42] also give an approach on
ow to combine reputation information from the individual and
rom others while paying attention to context. This enables an
gent to specify both who can be trusted and for what they can
e trusted. The idea of using referral trust is presented early in
rust work in “open networks” by Beth et al. [43]. This work
rovides methods for computing degrees of trust in the presence
f conflicting information, also departing from the view of hard
ecurity. Other work with referral trust includes Xiao and Ben-
asat [44] and O’Donovan and Smyth [45] for describing how
eputation is applied to and affects recommenders.
.2. Trust in P2P networks and grids
A target application of reputation-based trust is to address
roblems of data quality in peer-to-peer (P2P) networks. There
ay be no barriers or requirements to publish a file in a P2P
etwork, thus allowing anyone to publish anything under any
ame with any level (or lack) of quality. Moreover, the avail-
bility and reliability of any given node in the network is not
uaranteed, thus possibly precluding reliable transfer of data. In
he wake of the PageRank algorithm [46] for ranking Web sites
y authority, the EigenTrust algorithm [47] computes a global
eputation value (using PageRank) for each entity. Reputation in
his work is the quality of a peer’s uploads (e.g., did the file suc-
essfully upload?) within a peer-to-peer network. The P2PRep
ystem [48] gives protocols and an algorithm for sharing rep-
w
a
b
h
Agents on the World Wide Web 5 (2007) 58–71 63
tation information with peers in a peer-to-peer network. This
ork also uses the idea of referral trust in its approach.
Contrasting with the work of Singh and Yu, Aberer and
espotovic [49] claim a more scalable approach, as other
eputation-based approaches require the maintenance of a grow-
ng performance history to maintain reputation information.
hile still using reputation information, this approach uses sta-
istical analysis to characterize trust and reputation so that the
omputation remains scalable. Embracing the qualities of a peer-
o-peer network to provide a more robust method of reputation
anagement, Damiani et al. [50] present the XRep protocol,
hich allows for an automatic vote using user’s feedback for
he best host for a given resource.
Olmedilla et al. [7] describes the requirements in supporting
rust in “virtual organizations of shared resources”, discusses the
imitations of existing work on trust in the context of grid com-
uting, and argues that Semantic representations can address the
equirements outlined.
.3. Trust metrics in a web of trust
A trust decision can be a transitive process, where trusting
ne piece of information or information source requires trust-
ng another associated source. For example, one might trust a
ook and its author because of the publisher, and the publisher
ay be trusted only because of the recommendation of a friend.
inslett’s work in policy-based trust uses (or refers to) “creden-
ial chains” (the issuer of one credential is the subject of another),
he majority of transitive trust computation has been focused on
sing reputation. A key recent example of this approach is Gol-
eck and Hendler [51,52], which describe how trust is computed
or the application TrustMail. Reputation is defined as a mea-
ure of trust, and each entity maintains reputation information on
ther entities, thus creating a “web”, that is called a web of trust.
he work by Golbeck and Hendler uses ontologies to express
rust and reputation information, which then allows a quantifica-
ion of trust for use in algorithms to make a trust decision about
ny two entities. The quantification of this trust and associated
lgorithms are called trust metrics.
Given an existing quantification of trust, approaches exist to
ransfer that trust to other entities, which may not have been
valuated for trust. One area of research assumes we are given
web of trust, where a link between two entities mean a trust
ecision has been made and the value of that trust is known. How
rust decisions are made do not matter, as long as the resulting
rust values can be quantified. If there is no link between a pair
f entities, it means no trust decision has yet been made. This is
he case in which trust transitivity can be applied, a simplified
xample being if A trusts B and B trusts C, then A trusts C.
uilding on work in reputation management (described earlier
s empowering individual agents to make trust decisions instead
f a single, central authority making decisions for them), mul-
iple researchers are exploring ways to transfer trust within a
eb of trust. In Stewart and Zhang [53,54], a set of hypotheses
nd experiments are described for testing how trust is transferred
etween hyperlinks on the web. Specifically, this work examines
ow much trust (in the context of a consumer trusting a busi-
6 s and
n
r
s
o
h
o
w
t
c
o
T
c
p
s
t
t
a
a
u
t
H
u
G
b
t
f
u
d
d
A
[
o
t
a
p
t
t
r
w
d
b
D
o
a
a
a
e
e
i
a
a
4
r
w
t
b
r
p
n
i
r
a
w
t
a
d
5
o
d
c
5
p
q
n
c
l
o
t
a
(
t
a
w
t
d
o
v
s
a
o
t
T
n
s
c
(
t
a
f
r
4 D. Artz, Y. Gil / Web Semantics: Science, Service
ess for purchasing a product) is transferred from a trusted Web
esource to an unevaluated one. The transfer is evaluated con-
idering differing types of links, types of resources, and types
f trust in the known source. Other more recent work looks at
ow to compute trust transitivity given actual quantities for trust
r distrust. A key work in this area is Richardson et al. [55],
hose goal is to provide a means of merging trust that is robust
o noise. Emphasizing personalized trust, as opposed to globally
omputed values, this approach is described as a generalization
f PageRank [46] to the Semantic web. In contrast to the Eigen-
rust approach described earlier, Richardson et al. [55] avoids
omputing global values by altering the algorithm to produce
ersonalized results for each entity. Likewise, EigenTrust uses
pecifically computed reputation values, and not with an arbi-
rarily given quantification of trust. In Massa and Avesani [56],
he problem of controversial users (those who are both trusted
nd distrusted) is addressed. This work shows that the glob-
lly computed trust value (in a web of trust) for a controversial
ser may not be as accurate as a locally computed value due
o the global disagreement on trust for that user. Golbeck and
endler’s TrustMail also performs a local computation of rep-
tation within a web of trust. A difficult problem addressed in
uha et al. [57] is the transitivity of distrust, the main problem
eing if A distrusts B and B distrusts C, we cannot say if A
rusts C. This work also evaluates and ranks several methods
or propagating trust and distrust in a given web of trust. Eval-
ation is performed using data from Epinions.com, a common
ata set used in trust research, where users have provided trust or
istrust information about each other’s ability to write reviews.
nother approach to computing trust transitivity is Advogato
58], in which maximum network flow is computed over a web
f trust to find trust between any pair of entities. An advantage
o this approach, is that it is very robust to noise and even attacks
ltering the given web of trust. In Chirita et al. [59], the authors
resent a method that performs a global computation on reputa-
ion values (like EigenTrust) but considers the individual’s input
o the evaluation as well. This approach uses “personalized page
anks” to disseminate reputation information from individuals
hile considering referral trust (like P2PRep).
All of these approaches to computation over a web of trust
o not consider context, and as a result do not differentiate
etween “topic specific trust” and referral trust. In contrast,
ing et al. [60], presents a method of computing within a web
f trust that also considers the domain of knowledge (context),
nd does so separately from referral trust. This work enumer-
tes several kinds of referral (trust in ability to recommend) and
ssociative (two agents being similar) trust as a result: domain
xpert (trust in an agent’s domain knowledge), recommendation
xpert (trust in an agent’s ability to refer other agents), sim-
lar trusting (two agents having similar trust in other agents),
nd similar cited (two agents being similarly trusted by other
gents)..4. Application-specific reputation
Some applications allow for unique ways to harness or use
eputation. For the application of routing in ad hoc networks
w
r
a
r
Agents on the World Wide Web 5 (2007) 58–71
here some nodes may be more trustworthy for routing packets
han others, Pirzada and McDonald [61] present a reputation-
ased system for deciding which nodes in a network to use for
outing traffic. Nodes in the network can indirectly monitor the
erformance of other nodes nearby, and in this application, a
ode will only ever need to select a nearby host to trust. This
s a good example of a case to apply local computation of
eputation. Another specific application is Dash et al. [62] for
llocating tasks to the best performing agent (instead of agent
ith best specifications, noting the difference). Using statistics
o determine reputation from past performance history, Josang
nd Ismail [63] present a method to combine reputation feedback
ata using a beta probability distribution.
. General models of trust
This section summarizes work that presents a broader view
n models of trust and the properties of trust. Work in multiple,
iffering fields is presented, as it is relevant to and frequently
ited by computer scientists.
.1. General considerations and properties of trust
Several papers in social sciences, similar to this survey, have
ut forth an interpretation of existing research in trust. A fre-
uently cited work is Mcknight and Chervany [64], which is
oted for its effort to integrate existing work and for its resulting
lassification of types of trust. The goal of this work was to high-
ight and find common ground between the many different uses
f the word “trust” in social sciences research. Of key impor-
ance, are the four qualities that McKnight and Chervany identify
s being significant when making a trust decision: competence
ability to give accurate information), benevolence (willingness
o expend the effort), integrity (adherence to honest behavior),
nd predictability (evidence to support that the desired outcome
ill occur). Alternatively cited, is Gefen [65], which simplifies
he trust decision to three of these qualities, leaving out pre-
ictability and keeping the others. Gefen stresses the importance
f these dimensions in different uses of trust online (e.g., how
ulnerable is the agent: is he just window-shopping, or is he a
erious buyer), citing a definition from relevant research in man-
gement: “trust is a willingness to be vulnerable to the actions
f another person or people.” In Acrement [66], seven quali-
ies of trust are given from a business management perspective.
hese qualities share predictability and integrity with McK-
ight and Chervany’s set, and add five more new characteristics
pecific to the management domain: congruity (actions match
laims), reliability, openness (do not keep secrets), acceptance
equal respect among diversity), and sensitivity (pay attention
o individuals). An “integrated account” of trust and reputation
cross disciplines is given in Mui et al. [5], which explicitly
ocuses on deriving a computational model accounting for cur-
ent work. A key concept used is reciprocity: “be nice to others
ho are nice to you”. This work also differentiates trust and
eputation, describes how trust can be inferred from reputation,
nd proposes a probabilistic mechanism for inferring trust given
eputation and reciprocity. Staab et al. [67] is an edited series
s and
o
m
5
c
t
u
l
p
t
1
p
m
a
o
t
a
t
t
h
n
o
i
p
D
i
t
a
t
l
a
C
d
s
m
i
h
o
a
f
b
t
m
n
t
d
i
f
w
k
(
a
h
e
r
f
t
5
u
t
t
s
u
p
u
t
i
t
a
c
s
c
a
t
t
d
e
t
t
t
i
o
a
(
r
F
d
v
J
n
5
d
a
m
t
m
r
6
D. Artz, Y. Gil / Web Semantics: Science, Service
f short articles about different ways to represent, manage, and
anipulate the properties of trust.
.2. Computational and online trust models
The widely cited 1994 Ph.D. dissertation by Marsh [68] is
onsidered the first prominent, comprehensive, formal, compu-
ational model of trust. His intent was to address “an imperfect
nderstanding, a plethora of definitions, and informal use in the
iterature and in everyday life” with regard to trust. Marsh pro-
osed a set of (subjectively set) variables, and a way to combine
hem to arrive at one continuous value of trust in the range [−1,
]. While the intuitive explanation of this range may be com-
lete distrust to full trust, Marsh actually argues against these
eanings at the extremes, saying neither full trust or distrust is
ctually possible. Marsh identified three types of trust: basic,
ver all contexts; general, between two people and all their con-
exts occurring together; and situational, between two people in
specific context. In addition to context, Marsh also identified
ime as being relevant to each of the variables used to comprise
rust. Authors who cite Marsh frequently use a simplification of
is work (e.g., trust is a continuous value, and its composition is
ot of concern) or do not follow his model due to the difficulty
f finding values for some variables used to compute trust (e.g.,
mportance, utility, competence, risk, etc.).
Many researchers have endeavored to model and explain the
roperties of trust and reputation in a computational setting.
ifferent trust metrics are compared against several features
n Ziegler and Lausen [69], where the concept of “local group
rust computation” is advocated (a compromise between local
nd global trust computation). The authors make the claim that
rust is a “subjective expectation”. A method for performing
ocal group trust computation, Appleseed, is proposed, and the
uthors also discuss the meaning and propagation of distrust.
reating a clearer picture for reputation, Resnick et al. [70]
escribes reputation as “important for fostering trust among
trangers”. This work outlines the qualities of reputation that
ake it valuable for us on the Internet, and identifies issues
n applying reputation (e.g., what reputation does a new user
ave?). In Friedman et al. [71], a general discussion of trust
n the Internet is given, outlining 10 characteristics of trust in
n online interaction. A key point presented is that simply per-
orming a task is not the same as providing good service or
eing high quality, which is a problem with automated repu-
ation systems that fail to capture this subtle difference. Also
ade prominent is the idea that people trust people, not tech-
ology, which itself earns (or loses) our trust as an extension of
rust in people. In Falcone and Castelfranchi [72], a key idea is
ealing with the dynamic nature of trust, and making the real-
zation that an agent that knows he’s trusted may act differently
rom one who does not know his level of trust. As a result, this
ork attempts to show that “good” reputation is useless without
nowledge of the context in which that reputation was earned
e.g., was the agent behaving just to “look good”?). Looking at
nother aspect of trust dynamics, Jonker et al. [73] reports on
uman experiments showing how positive and negative experi-
nces can change negative and positive trust, respectively. Key
m
i
c
Agents on the World Wide Web 5 (2007) 58–71 65
esults from this work suggest that trust does change with dif-
erent experiences, and that distrust may be harder to overcome
han one would expect.
.3. Game theory and agents
Autonomous agents and multi-agent systems have several
ses for trust, and one perspective in related research is game
heory. In Buskens [74], the author is a sociologist using a game
heoretic approach to show that his proposed heuristics can mea-
ure a type of trust from the graph of a social network. Buskens
ses a variant of the Trust Game, which is analogous to the
risoner’s dilemma, but set in a market scenario. Another work
sing game theory is Brainov and Sandholm [75], which shows
hat underestimating trust hurts all agents involved, and utility
s maximized if the level of trust is mutual. The game defined by
his work is again a market-based scenario, where the players
re a buyer and a seller. This is another work in which trust is
laimed to be a way to deal with uncertainty. Using relation-
hips between agents, Ashri et al. [76] claims that rules of trust
an be determined from the context and the roles of interacting
gents. Specifically mentioned are the general relationships of
rade, dependency, competition, and collaboration. In this work,
rust exists when it is believed that one agent will not gain at the
isadvantage of another agent. Trust in Ramchurn et al. [77] is an
xpectation of agents to exhibit a specific behavior in an interac-
ion based on reputation from various sources. The main focus of
his work is combining the sources of reputation, and they refer
o direct experience as confidence. The FIRE model, presented
n Huynh et al. [78], is designed for combining multiple sources
f trust (reputation, context-based rules, and credentials) in an
gent system. A key part of this model is the use of “references”
endorsements of trust from other agents), in cases where no
eputation or other sources of trust exist. This feature enables
IRE to provide a trust metric in cases where other models fail
ue to ignorance about an agent.
Sabater and Sierra [79] and Ramchurn et al. [80] both pro-
ide excellent in-depth surveys of trust in multi-agent systems.
osang et al. [81] provides an overview of trust in web commu-
ities interacting through market-like systems and services.
.4. Software engineering
In the domain of software engineering, Viega et al. [82]
eclares that trust is a critical consideration citing the trust
ssumptions (e.g., that a user will enter a certain input) com-
only made when developing software. This work also notes
hat trust is used to deal with uncertainty, when specific require-
ents are unknown, and the contribution is to describe where
equirements can fail to make trust explicit.
. Trust in information resourcesThis section summarizes relevant work in web and docu-
ent retrieval, information filtering, representing the sources of
nformation as its provenance trail, and other factors in trusting
ontent of information resources.
6 s and
6
a
T
t
a
T
d
w
i
t
a
s
w
T
t
i
w
6
O
i
m
e
o
c
c
A
i
c
t
w
5
T
f
r
a
t
“
[
o
O
c
i
t
“
6
l
s
a
t
c
t
a
t
G
a
H
t
t
a
i
t
P
h
a
6
p
g
l
C
c
i
a
g
m
s
l
T
f
g
s
a
i
o
m
6
a
c
i
c
r
d
a
i
s
o
m
6 D. Artz, Y. Gil / Web Semantics: Science, Service
.1. Trust concerns on the web
“Trust on the Web” may refer to several different problems,
nd one perspective on this is given in Khare and Rifkin [83].
his work begins by noting a flawed assumption that cryp-
ography provides trust, and continues to point out various
pplications on the Web that require different kinds of trust.
he main contribution of Khare and Rifkin is identifying the
istinctions between types of agents, policies, and applications
ith regard to trust management on the Web. Focusing on trust
n Internet applications, which exchange or display informa-
ion, Grandison and Sloman [6] give a provisional definition
nd discussion of trust across a wide set of literature, and explore
olutions and applications of trust management (which in their
ork essentially means the implementation of security policies).
he authors make an interesting deviation from the definition of
rust we offered in the introduction; they define trust as a belief
n an entity’s ability and not directly a belief in how an entity
ill perform.
.2. Trust concerns on the Semantic Web
Declaring that there is more to trust than reputation, Bizer and
ldakowski [84] make several claims with the Semantic Web
n mind. First, any statements contained in the Semantic Web
ust be considered as claims rather than facts until trust can be
stablished. Second, this work makes the case that it is too much
f a burden to provide trust information that is current. Third,
ontext-based trust matters; in this case, context refers to the
ircumstances and associations of the target of the trust decision.
n example of context is an agent providing a description for an
tem, where the agent may be a vendor selling that item, or as a
onsumer advocate reporting on that item. Fourth, it is possible
o use “content-based trust”, using common sense rules of the
orld to make a trust decision (e.g., do no trust prices below
0% of the average price). Finally, Bizer and Oldakowski recall
im Berners-Lee’s “Oh yeah?” button [1], where he envisioned
unctionality in Web browsers that when invoked would give
easons why a Web page or service should be believed. Bizer
nd Oldakowski build on this idea to provide the justification for
rust, which will be needed on the Semantic Web. Noting that
trust is at the heart of the Semantic Web vision”, O’Hara et al.
85] name five trust strategies for agents using the Semantic Web:
ptimism, pessimism, centralized, investigation, and transitivity.
ptimism is to assume trust, pessimism is to assume distrust,
entralized is to trust through a single third party, investigation
s to collect trust information from others, and transitivity is
o use a web of trust. This work refers to trust generally as a
method of dealing with uncertainty”.
.3. Trust using hyperlinks
Work exists in learning users’ trust in Web sources using the
ink structure of the Web to transfer trust. Given a small data
et of decisions made by users about whether or not Web sites
re spam, TrustRank [86] uses the link structure to other pages
o determine whether or not they are also spam. The decision
s
u
t
c
Agents on the World Wide Web 5 (2007) 58–71
an be interpreted as a trust decision in the context of finding
rue and accurate sources of information. Massa and Hayes [87]
ddress the problem of assuming that all Web links are posi-
ive endorsements (and indications of trust). Algorithms such as
oogle’s PageRank [46] make this assumption, which does not
lways hold true. Massa and Hayes propose a minor addition to
TML, enabling the author to specify whether a link is posi-
ive, negative, or neither. Kleinberg [88] makes the observation
hat links encode a human judgment that one page is related to
nother. Kleinberg describes the concepts of a hub and an author-
ty, the former being a page that points to many authorities, and
he latter being a page that is pointed to by many hubs. The
ageRank algorithm exploits Kleinberg’s ideas of using links as
uman encoded judgments of relevance and uses the concept of
uthorities to compute a heuristic of popularity.
.4. Filtering information based on trust
Work in information filtering has addressed some of the same
roblems as work in trust. The concept of quality is a common
oal (i.e., “high quality information”), as quality often corre-
ates with trust. Quality on the Web is discussed in detail in
iolek et al. [89], highlighting that massive amounts of Web
ontent are becoming outdated with the rapid pace of change
n the Web. More recently, the field of question answering is an
rea of research that may use the Web as a source of answers for
iven queries. In Clarke et al. [90], it is noted that many answers
ay be returned for a given query, and one of these must be
elected as the answer. While trust is not mentioned, the prob-
em can be characterized as determining which answer to trust.
he proposed solution is to assume the answer occurring most
requently is correct. In the field of information extraction, the
oal is to extract information from unlabeled text (i.e., without
emantic markup). One question arising from this work is “can
n automatically determined label be trusted?”. A model given
n Downey et al. [91] shows that the magnitude of redundancy
f information (i.e., the frequency of occurrence) can be used as
etric for the accuracy (or trustworthiness) of a computed label.
.5. Filtering the Semantic Web
Information filtering is becoming an increasingly significant
rea of research as the amount of information available, specifi-
ally on the Web, continues to grow. After relevant information
s filtered, there is still a question of whether that information
an be trusted. In many cases, filtering still results in too much
elevant information, and the most trusted source or content is
esired. For the Semantic Web, Bizer et al. [92] have created
browser, which filters content based on a user specified pol-
cy. These policies, written in the TriQL.P query language, allow
pecification of requirements for the context, content, and source
f information. The implementation of this browser includes a
echanism that displays to the user justification of why a Webite should be trusted. In Ding et al. [93], agents are enabled to
se both context and reputation to determine what information
o trust in the Semantic Web. This work employs referral trust to
ollect reputation, and it relies on the richness of the Semantic
s and
W
a
w
m
a
m
s
c
R
i
e
“
u
w
i
6
a
t
t
b
d
a
o
c
a
q
a
w
q
t
6
(
n
r
i
t
r
u
G
t
b
s
a
t
r
e
p
L
s
6
m
[
c
u
t
e
s
t
t
t
i
f
a
a
i
i
a
o
s
d
o
a
m
d
k
a
6
t
A
t
d
h
“
d
e
l
R
a
e
o
r
m
c
p
7
D. Artz, Y. Gil / Web Semantics: Science, Service
eb to determine context. The result is the ability to ask another
gent “which agent can I trust to get the weather?”. In related
ork, Ding et al. [94] provides a method for picking infor-
ation sources using both provenance and computation over
web of trust. Assuming that provenance can be determined, a
ethod is given for using this information to filter more trusted
ources. The work from this group also incorporates the con-
ept of ignorance (i.e., not having any information about trust).
ecommender systems are common on the Web, and may filter
nformation based on recommendations and/or trust ratings. An
xample considering the Semantic Web is Ziegler [95], where a
taxonomy” is used to score the similarity between profiles of
sers’ interests. Trust values, or recommendations, are computed
ithin a group of “similar” users, and the resulting information
s filtered accordingly.
.6. Subjectivity analysis
Although information retrieval pioneered some of the
pproaches used now on the Web for locating relevant informa-
ion sources, trust-based retrieval is a relatively recent focus in
hat area of research. Trust in information retrieval is motivated
y the need for not just relevant documents, but high-quality
ocuments as well [96]. One approach to this is subjectivity
nalysis, which aims at distinguishing true facts from subjective
pinions [97].
Trust is also an important area in question answering, since
ontradictory answers can be obtained from diverse sources in
nswer to a question. Sometimes opinions are often filtered out in
uestion answering tasks so that only objective facts are returned
s answers [98]. In other contexts, detecting opinions is useful
hen no single ground truth can be provided in answer to a
uestion, and instead multiple perspectives are summarized as
he answer provided [99].
.7. Provenance of information
The details regarding the sources and origins of information
e.g., author, publisher, citations, etc.) are referred to as prove-
ance, and they serve as a means to evaluate trust. Provenance
epresentation and tracking has been studied in the context of
nformation sources. McGuinness [100] uses semantic anno-
ations to represent the provenance of any results inferred by
easoners, including explanations of reasoning steps and axioms
tilized, as well as descriptions of the original data sources. In
olbeck [101], both provenance and the Semantic Web are used
o infer trust relationships. Provenance establishes a relationship
etween people and information, and the Semantic Web contains
ocial network data used to compute trust between people.
Provenance has been studied in the context of scientific data
nalysis, especially when generated by simulation and computa-
ion. Semantic Web technologies have shown to be effective in
epresenting application-relevant provenance information that
xplains how results are obtained through workflows of com-
utations [102–104]. Simmhan et al. [105] and Moreau and
udaescher [106] provide overviews of provenance research in
cientific applications.
a
s
t
Agents on the World Wide Web 5 (2007) 58–71 67
.8. Content trust
Trust on the Web is needed to make decisions when infor-
ation conflicts or is non-authoritative. In Gil and Ratnakar
107–109], a system called Trellis is introduced, which derives
onsensus trust on information resources in a community of
sers as they use or dismiss sources for information analysis
asks. Also examining trust in information sources, Castelfranchi
t al. [110] proposes a model for making trust decisions about
ources, differentiating internal and external attributes affecting
rust in a source. The authors note that the composition of inputs
o a trust decision affects the outcome of the decision, and thus
he decision itself cannot be characterized by a final probabil-
ty. This observation might be restated that the inputs together
orm part of the context in which trust is being determined. Also
cknowledged is that “attribution of trust is a very complex task”,
problem that is exemplified on the Web, as the sources behind
nformation are not always clear or correct. Specifically for trust
n information sources, four types of inputs to a trust decision
re given: direct experience, categorization (generalization to
r from something known), reasoning (application of common
ense or rules to verify truth), and reputation. Gil and Artz [111]
ifferentiates trust in a given source from trust in a specific piece
f content provided by that source, where trust in one does not
lways indicate trust in the other. For example, a trusted source
ay inadvertently issue a patently false statement, or a typically
istrusted source may post information that is trustworthy. A
ey focus of this work is content trust, how it may be derived,
nd how it may be captured and used on the Semantic Web.
.9. Site design and user interaction
The elements of a Web site considered by users when making
rust decisions on the Web is explored in Sillence et al. [112].
key finding is that in spite of the personal risk and instruc-
ions to do otherwise, users in this study consistently examined
esign factors when making a trust judgment. Focusing on small
otels, Stephens [113] performs experiments to test a proposed
Integrated Trust Model” for Web sites, which includes multiple
esign elements (e.g., page layout, style, graphics, etc.). Sev-
ral factors are shown to be more important for earning trust, at
east in the context of gaining customers (seeking a small hotel).
elated to Web design, researchers in human–computer inter-
ction have outlined in Corritore et al. [114] the importance of
stablishing trust with users online. In this context, the authors
bserve that trust is multi-dimensional, which is a cause of a cur-
ent lack of agreement on trust issues, citing trust research across
ultiple fields. The authors note that trust is used to decrease
omplexity, and identify existing work in human factors that
oints to trust as necessary for users to believe computers.
. DiscussionTrust has been studied in social sciences, business and man-
gement, and psychology, before it became central to computer
cience research. Considering the research we have reviewed,
here are several dimensions to describe trust:
6 s and
(
(
(
(
(
(
m
s
8
c
o
h
a
h
a
A
v
a
R
R
8 D. Artz, Y. Gil / Web Semantics: Science, Service
1) Target. The entity, which is being evaluated or given trust
varies with the perspective of the problem. Users are the tar-
get of trust in access control systems. Networks are trusted
by agents or users when using communication channels.
When seeking a reliable service, agents or services become
the target of trust. On the Web, we can trust agents provid-
ing content, on even make trust judgements on the content
itself.
2) Representation. There are many ways that trust can be dig-
itally encoded. Credentials include digital signatures and
tokens. Agents may carry histories of past interactions with
other agents. Users may employ social networks, or webs
of trust, to determine trust in an unknown correspondent.
Semantic web work includes detailed ontologies for trust
policies, trust negotiation, access control, and data prove-
nance.
3) Method. Determining trust can be accomplished through
many methods. Hard security uses identification and autho-
rization alone to decide complete trust in a user. Many
Internet applications use the exchange of credentials (i.e.,
digital signatures) to establish trust before engaging in a
transaction. Agents may use their histories of past interac-
tions, or other agents’ histories to determine trust through
reputation. In many applications, including information
retrieval, trust may be determined through transfer of trust
from associated entities.
4) Management. The entity or entities that determine trust can
vary with the application. In many traditional systems, a
single service acts as a trusted third party to mediate the
establishment of trust between two unknown agents or users.
In more recent work, there is a push for decentralization
of control of the trust decision, including the enablement
of individual agents to make their own trust decisions. For
system-wide or global trust, voting mechanisms or other
forms of consensus may be used to collect individual trust
decisions.
5) Computation. Trust may be quantified and computed in
many ways. Some approaches, including those harness-
ing the Semantic Web, choose discrete trust values (e.g.,
trust, distrust, or neutral), while others, especially when
computation is needed, choose a continuous numerical
range. Algorithms for how trust is transferred, combined,
or resolved can range from a simple average, to com-
puting eigenvalues on graph adjacency matrices. Many
approaches compute trust assuming time is static, while oth-
ers may account for the changes in trust over time. In cases
where trust information is large or always changing, several
approaches argue for local computation of trust, rather than
a globally consistent value.
6) Purpose. The need for trust spans all aspects of computer
science, and each situation places different requirements on
trust. Human users, software agents, and increasingly, the
machines that provide services all need to be trusted in vari-
ous applications or situations. The communication channels
between computers and users, and the content exchanged
between computers and users also require trust, in both
directions, for real world use. Trust can be used to protectAgents on the World Wide Web 5 (2007) 58–71
data, to find accurate information, to get the best quality
service, and even to bootstrap other trust evaluations.
Trust may be better seen as a motivating concept underlying
any problems and contexts rather than as a precise idea to be
tudied under a uniform framework.
. Conclusions
Trust research in the Semantic Web poses new challenges that
an be better met by building on the diverse but significant body
f work in modeling trust in computer science. In this paper, we
ave identified four broad categories of existing work in trust
nd given a brief overview of literature in each category. We
ave discussed the relevance of each of these areas to important
spects of ongoing and future Semantic Web research.
cknowledgements
We would like to thank the anonymous reviewers for their
aluable comments and feedback on this work. We gratefully
cknowledge support from the US Air Force Office of Scientific
esearch (AFOSR) with grant number FA9550-06-1-0031.
eferences
[1] T. Berners-Lee, Weaving the Web, Harper, 1999.
[2] T. Berners-Lee, J. Hendler, O. Lassila, The semantic web, Sci. Am.
(2001).
[3] T. Berners-Lee, W. Hall, J. Hendler, K. O’Hara, N. Shadbolt, D. Weitzner,
A framework for web science, Found. Trends Web Sci. 1 (1) (2006).
[4] T. Berners-Lee, Semantic web on XML, Presentation at XML, 2000,
available from http://www.w3.org/2000/Talks/1206-xml2k-tbl/slide10-
0.html.
[5] L. Mui, M. Mohtashemi, A. Halberstadt, A computational model of trust
and reputation, in: Proceedings of the 35th International Conference on
System Science, 2002, pp. 280–287.
[6] T. Grandison, M. Sloman, A survey of trust in internet applications, IEEE
Commun. Surv. Tutorials 4 (4) (2000) 2–16.
[7] D. Olmedilla, O. Rana, B. Matthews, W. Nejdl, Security and trust issues in
semantic grids, in: Proceedings of the Dagsthul Seminar, Semantic Grid:
The Convergence of Technologies, vol. 05271, 2005.
[8] P. Bonatti, C. Duma, D. Olmedilla, N. Shahmehri, An integration of
reputation-based and policy-based trust management, in: Proceedings of
the Semantic Web Policy Workshop, 2005.
[9] J. Kohl, B.C. Neuman, The Kerberos network authentication service,
IETF RFC 1510, 1993.
[10] T. Yu, M. Winslett, K.E. Seamons, Interoperable strategies in automated
trust negotiation, in: CCS ’01: Proceedings of the 8th ACM Conference
on Computer and Communications Security, ACM Press, New York, NY,
USA, 2001, pp. 146–155.
[11] T. Yu, M. Winslett, Policy migration for sensitive credentials in trust
negotiation, in: WPES ’03: Proceedings of the 2003 ACM Workshop on
Privacy in the Electronic Society, ACM Press, New York, NY, USA, 2003,
pp. 9–20.
[12] W.H. Winsborough, K.E. Seamons, V.E. Jones, Automated trust negotia-
tion, in: Proceedings of the DARPA Information Survivability Conference
and Exposition, IEEE Press, 2000, pp. 88–102.[13] M. Winslett, T. Yu, K.E. Seamons, A. Hess, J. Jacobson, R. Jarvis, B.
Smith, L. Yu, Negotiating trust on the web, IEEE Internet Comput. 6 (6)
(2002) 30–37.
[14] N. Li, W.H. Winsborough, J.C. Mitchell, Distributed credential chain
discovery in trust management, J. Comput. Secur. 11 (1) (2003) 35–86.
s andD. Artz, Y. Gil / Web Semantics: Science, Service
[15] W. Nejdl, D. Olmedilla, M. Winslett, Peertrust: automated trust nego-
tiation for peers on the semantic web, in: Proceedings of Workshop on
Secure Data Management in a Connected World in Conjunction with
the 30th International Conference on Very Large Data Bases, 2004, pp.
118–132.
[16] P. Bonatti, D. Olmedilla, Driving and monitoring provisional trust negoti-
ation with metapolicies, in: POLICY ’05: Proceedings of the Sixth IEEE
International Workshop on Policies for Distributed Systems and Networks
(POLICY’05), IEEE Computer Society, Washington, DC, USA, 2005, pp.
14–23.
[17] F.L. Gandon, N.M. Sadeh, Semantic web technologies to reconcile pri-
vacy and context awareness, in: UbiMob ’04: Proceedings of the 1st
French-speaking Conference on Mobility and Ubiquity Computing, ACM
Press, New York, NY, USA, 2004, pp. 123–130.
[18] J.-M. Seigneur, C.D. Jensen, Trust enhanced ubiquitous payment without
too much privacy loss, in: SAC ’04: Proceedings of the 2004 ACM Sym-
posium on Applied Computing, ACM Press, New York, NY, USA, 2004,
pp. 1593–1599.
[19] G. Tonti, J.M. Bradshaw, R. Jeffers, R. Montanari, N. Suri, A. Uszok,
Semantic web languages for policy representation and reasoning: a com-
parison of kaos, rei, and ponder, in: Proceedings of the 2003 International
Semantic Web Conference, 2003, pp. 419–437.
[20] A. Uszok, J. Bradshaw, R. Jeffers, N. Suri, P. Hayes, M. Breedy, L. Bunch,
M. Johnson, S. Kulkarni, J. Lott, Kaos policy and domain services: toward
a description-logic approach to policy representation, deconfliction, and
enforcement policy, 2003, 00, 93.
[21] L. Kagal, T.W. Finin, A. Joshi, A policy-based approach to security for
the semantic web, in: Proceedings of the 2nd International Semantic
Web Conference, Lecture Notes in Computer Science, Springer, 2003,
pp. 402–418.
[22] M. Nielsen, K. Krukow, Towards a formal notion of trust, in: PPDP ’03:
Proceedings of the 5th ACM SIGPLAN International Conference on Prin-
ciples and Practice of Declaritive Programming, ACM Press, New York,
NY, USA, 2003, pp. 4–7.
[23] M. Carbone, M. Nielsen, V. Sassone, A formal model for trust in dynamic
networks, in: Proceedings of International Conference on Software Engi-
neering and Formal Methods, IEEE Computer Society, 2003.
[24] EHR Policy, Electronic health records policy, 2001, http://www.show.
scot.nhs.uk/sehd/publications/DC20011220IMTEHRPol.pdf.
[25] M.Y. Becker, P. Sewell, Cassandra: distributed access control policies
with tunable expressiveness, in: Proceedings of the 5th IEEE International
Workshop on Policies for Distributed Systems and Networks, 2004.
[26] XACML, 2005, http://www.oasis-open.org/committees/tc home.php?wg
abbrev=xacml.
[27] SAML, 2005, http://www.oasis-open.org/committees/tc home.php?wg
abbrev=security.
[28] WS-Trust, 2005, http://www-128.ibm.com/developerworks/library/
specification/ws-trust/.
[29] T. Leithead, W. Nejdl, D. Olmedilla, K.E. Seamons, M. Winslett, T. Yu,
C.C. Zhang, How to exploit ontologies for trust negotiation, in: ISWC
Workshop on Trust, Security, and Reputation on the Semantic Web,
volume 127 of CEUR Workshop Proceedings, Technical University of
Aachen (RWTH), Hiroshima, Japan, 2004.
[30] D. Olmedilla, Security and privacy on the semantic web, in: M. Petkovic,
W. Jonker (Eds.), Security, Privacy and Trust in Modern Data Manage-
ment, Springer, 2006.
[31] M. Blaze, J. Feigenbaum, J. Lacy, Decentralized trust management, in:
Proceedings of IEEE Symposium on Security and Privacy, 1996, pp.
164–173.
[32] M. Blaze, J. Feigenbaum, J. Ioannidis, A.D. Keromytis, The role of trust
management in distributed system security, Lect. Notes Comput. Sci.
1603 (1999) 185–210.
[33] Y.-H. Chu, J. Feigenbaum, B. LaMacchia, P. Resnick, M. Strauss, Referee:
trust management for web applications, World Wide Web J. 2 (1997).
[34] L. Kagal, T. Finin, A. Joshi, Developing secure agent systems using del-
egation based trust management, in: Workshop on Security of Mobile
MultiAgent Systems held at Autonomous Agents and MultiAgent Sys-
tems, 2002.Agents on the World Wide Web 5 (2007) 58–71 69
[35] S. Ruohomaa, L. Kutvonen, Trust management survey, in: Proceedings
of Trust 2005, Lecture Notes in Computer Science, Springer, 2005, pp.
77–92.
[36] J. Zheng, E. Veinott, N. Bos, J.S. Olson, G.M. Olson, Trust without
touch: jumpstarting long-distance trust with initial social activities, in:
CHI ’02: Proceedings of the SIGCHI Conference on Human Factors in
Computing Systems, ACM Press, New York, NY, USA, 2002, pp. 141–
146.
[37] A. Abdul-Rahman, S. Hailes, A distributed trust model, in: Proceedings
of the New Security Paradigms Workshop, ACM, 1997, pp. 48–60.
[38] A. Abdul-Rahman, S. Hailes, Using recommendations for managing trust
in distributed systems, in: Proceedings of IEEE International Conference
on Communication, 1997.
[39] B. Yu, M.P. Singh, A social mechanism of reputation management in
electronic communities, in: CIA ’00: Proceedings of the 4th International
Workshop on Cooperative Information Agents IV, The Future of Infor-
mation Agents in Cyberspace, Springer-Verlag, London, UK, 2000, pp.
154–165.
[40] B. Yu, M.P. Singh, An evidential model of distributed reputation man-
agement, in: AAMAS ’02: Proceedings of the First International Joint
Conference on Autonomous Agents and Multiagent Systems, ACM Press,
New York, NY, USA, 2002, pp. 294–301.
[41] B. Yu, M.P. Singh, Detecting deception in reputation management, in:
AAMAS ’03: Proceedings of the Second International Joint Conference
on Autonomous Agents and Multiagent Systems, ACM Press, New York,
NY, USA, 2003, pp. 73–80.
[42] J. Sabater, C. Sierra, Reputation and social network analysis in multi-
agent systems, in: AAMAS ’02: Proceedings of the First International
Joint Conference on Autonomous Agents and Multiagent Systems, ACM
Press, New York, NY, USA, 2002, pp. 475–482.
[43] T. Beth, M. Borcherding, B. Klein, Valuation of trust in open networks, in:
Proceedings of the 3rd European Symposium on Research in Computer
Security, 1994, pp. 3–18.
[44] S. Xiao, I. Benbasat, The formation of trust and distrust in recommen-
dation agents in repeated interactions: a process-tracing analysis, in:
ICEC ’03: Proceedings of the 5th International Conference on Elec-
tronic Commerce, ACM Press, New York, NY, USA, 2003, pp. 287–
293.
[45] J. O’Donovan, B. Smyth, Trust in recommender systems, in: IUI ’05:
Proceedings of the 10th International Conference on Intelligent User
Interfaces, ACM Press, New York, NY, USA, 2005, pp. 167–174.
[46] S. Brin, L. Page, The anatomy of a large-scale hypertextual Web search
engine, Comput. Networks ISDN Syst. 30 (1–7) (1998) 107–117.
[47] S.D. Kamvar, M.T. Schlosser, H. Garcia-Molina, The eigentrust algorithm
for reputation management in P2P networks, in: WWW ’03: Proceedings
of the 12th International Conference on World Wide Web, ACM Press,
New York, NY, USA, 2003, pp. 640–651.
[48] F. Cornelli, E. Damiani, S.D. Capitani, Choosing reputable servents in a
P2P network, in: Proceedings of the 11th International World Wide Web
Conference, 2002.
[49] K. Aberer, Z. Despotovic, Managing trust in a peer-2-peer information
system, in: H. Paques, L. Liu, D. Grossman (Eds.), Proceedings of the
Tenth International Conference on Information and Knowledge Manage-
ment (CIKM01), ACM Press, 2001, pp. 310–317.
[50] E. Damiani, D.C. di Vimercati, S. Paraboschi, P. Samarati, F. Violante,
A reputation-based approach for choosing reliable resources in peer-to-
peer networks, in: CCS ’02: Proceedings of the 9th ACM Conference on
Computer and Communications Security, ACM Press, New York, NY,
USA, 2002, pp. 207–216.
[51] J. Golbeck, J. Hendler, Accuracy of metrics for inferring trust and reputa-
tion, in: Proceedings of the 14th International Conference on Knowledge
Engineering and Knowledge Management, 2004.
[52] J. Golbeck, J. Hendler, Inferring reputation on the semantic web, in:
Proceedings of the 13th International World Wide Web Conference, 2004.
[53] K.J. Stewart, Transference as a means of building trust in world wide web
sites, in: ICIS ’99: Proceedings of the 20th International Conference on
Information Systems, Association for Information Systems, Atlanta, GA,
USA, 1999, pp. 459–464.
7 s and0 D. Artz, Y. Gil / Web Semantics: Science, Service
[54] K.J. Stewart, Y. Zhang, Effects of hypertext links on trust transfer, in:
ICEC ’03: Proceedings of the 5th International Conference on Electronic
Commerce, ACM Press, New York, NY, USA, 2003, pp. 235–239.
[55] M. Richardson, R. Argawal, P. Domingos, Trust management for the
semantic web, in: Proceedings of the Second International Semantic Web
Conference, Spring-Verlag, 2003, pp. 351–368.
[56] P. Massa, P. Avesani, Controversial users demand local trust metrics: an
experimental study on epinions.com community, in: Proceedings of the
25th American Association for Artificial Intelligence Conference, 2005.
[57] R. Guha, R. Kumar, P. Raghavan, A. Tomkins, Propagation of trust and
distrust, in: WWW ’04: Proceedings of the 13th International Confer-
ence on World Wide Web, ACM Press, New York, NY, USA, 2004, pp.
403–412.
[58] Advogato, Advogato’s trust metric, 2000, http://www.advogato.org/trust-
metric.html.
[59] P.-A. Chirita, W. Nejdl, M. Schlosser, O. Scurtu, Personalized reputa-
tion management in P2P networks, in: Proceedings of the Trust, Security
and Reputation Workshop Held at the 3rd International Semantic Web
Conference, 2004.
[60] L. Ding, P. Kolari, S. Ganjugunte, T. Finin, A. Joshi, Modeling and eval-
uating trust network inference, in: Proceedings of the 7th International
Workshop on Trust in Agent Societies at AAMAS, 2004.
[61] A.A. Pirzada, C. McDonald, Establishing trust in pure ad-hoc networks,
in: CRPIT ’04: Proceedings of the 27th Conference on Australasian Com-
puter Science, Australian Computer Society Inc., Darlinghurst, Australia,
2004, pp. 47–54.
[62] R.K. Dash, S.D. Ramchurn, N.R. Jennings, Trust-based mechanism
design, in: AAMAS ’04: Proceedings of the Third International Joint Con-
ference on Autonomous Agents and Multiagent Systems, IEEE Computer
Society, Washington, DC, USA, 2004, pp. 748–755.
[63] A. Josang, R. Ismail, The beta reputation system, in: Proceedings of the
15 Bled Conference on Electronic Commerce, 2002.
[64] D.H. McKnight, N.L. Chervany, The meanings of trust, Technical Report
94-04, Carlson School of Management, University of Minnesota, 1996.
[65] D. Gefen, Reflections on the dimensions of trust and trustworthiness
among online consumers, SIGMIS Database 33 (3) (2002) 38–53.
[66] B. Acrement, Elements for building trust: do your manage-
ment skills measure up? 2002, http://www.imakenews.com/smei/e
article000051474.cfm.
[67] S. Staab, B. Bhargava, L. Lilien, A. Rosenthal, M. Winslett, M. Sloman,
T.S. Dillon, E. Chang, F.K. Hussain, W. Nejdl, D. Olmedilla, V. Kashyap,
The pudding of trust, IEEE Intell. Syst. 19 (5) (2004) 74–88.
[68] S.P. Marsh, Formalising trust as a computational concept, PhD thesis,
University of Stirling, 1994.
[69] C.-N. Ziegler, G. Lausen, Propagation models for trust and distrust in
social networks, Inform. Syst. Front. 7 (4–5) (2005) 337–358.
[70] P. Resnick, K. Kuwabara, R. Zeckhauser, E. Friedman, Reputation sys-
tems, Commun. ACM 43 (12) (2000) 45–48.
[71] B. Friedman, H. Peter, J. Khan, D.C. Howe, Trust online, Commun. ACM
43 (12) (2000) 34–40.
[72] R. Falcone, C. Castelfranchi, Trust dynamics: how trust is influenced
by direct experiences and by trust itself, in: AAMAS ’04: Proceedings
of the Third International Joint Conference on Autonomous Agents and
Multiagent Systems, IEEE Computer Society, Washington, DC, USA,
2004, pp. 740–747.
[73] C.M. Jonker, J.J. Schalken, J. Theeuwes, J. Treur, Human experiments in
trust dynamics, Lect. Notes Comput. Sci. 2995 (2004) 206–220.
[74] V. Buskens, The social structure of trust, Social Networks 20 (1998)
265–289.
[75] S. Brainov, T. Sandholm, Contracting with uncertain level of trust, in: EC
’99: Proceedings of the 1st ACM Conference on Electronic Commerce,
ACM Press, New York, NY, USA, 1999, pp. 15–21.
[76] R. Ashri, S.D. Ramchurn, J. Sabater, M. Luck, N.R. Jennings, Trust
evaluation through relationship analysis, in: Proceedings of the 4th
International Joint Conference on Autonomous Agents and MultiAgent
Systems, 2005, pp. 1005–1012.
[77] S.D. Ramchurn, C. Sierra, L. Godo, N.R. Jennings, A computational trust
model for multi-agent interactions based on confidence and reputation,Agents on the World Wide Web 5 (2007) 58–71
in: Proceedings of the 6th International Workshop of Deception, Fraud
and Trust in Agent Societies, 2003, pp. 69–75.
[78] T.D. Huynh, N.R. Jennings, N.R. Shadbolt, FIRE: an integrated trust and
reputation model for open multi-agent systems, in: Proceedings of the
16th European Conference on Artificial Intelligence, 2004.
[79] J. Sabater, C. Sierra, Review on computational trust and reputation mod-
els, Artif. Intell. Rev. 24 (1) (2005) 33–60.
[80] S.D. Ramchurn, D. Huynh, N.R. Jennings, Trust in multi-agent systems,
Knowl. Eng. Rev. 19 (1) (2004) 1–25.
[81] A. Josang, R. Ismail, C. Boyd, A survey of trust and reputation systems
for online service provision. Decis. Support Syst., 2006.
[82] J. Viega, T. Kohno, B. Potter, Trust (and mistrust) in secure applications,
Commun. ACM 44 (2) (2001) 31–36.
[83] R. Khare, A. Rifkin, Weaving a web of trust, J. World Wide Web 2 (3)
(1997) 77–112.
[84] C. Bizer, R. Oldakowski, Using context- and content-based trust policies
on the semantic web, in: WWW Alt. ’04: Proceedings of the 13th Interna-
tional World Wide Web Conference on Alternate Track Papers & Posters,
ACM Press, New York, NY, USA, 2004, pp. 228–229.
[85] K. O’Hara, H. Alani, Y. Kalfoglou, N. Shadbolt, Trust strategies for the
semantic web, in: Proceedings of Workshop on Trust, Security, and Repu-
tation on the Semantic Web, 3rd International Semantic Web Conference,
2004.
[86] Z. Gyongyi, H. Garcia-Molina, J. Pedersen, Combating web spam with
trustrank, in: Proceedings of the 30th International Conference on Very
Large Data Bases, 2004, pp. 271–279.
[87] P. Massa, C. Hayes, Page-rerank: using trusted links to re-rank author-
ity, in: WI ’05: Proceedings of the 2005 IEEE/WIC/ACM International
Conference on Web Intelligence (WI’05), IEEE Computer Society, Wash-
ington, DC, USA, 2005, pp. 614–617.
[88] J.M. Kleinberg, Authoritative sources in a hyperlinked environment, J.
ACM 46 (5) (1999) 604–632.
[89] M.T. Ciolek, The six quests for the electronic grail: current approaches
to information quality in WWW resources, Rev. Inform. Stat. Sci. Hum.
(RISSH) 1–4 (1996) 45–71.
[90] C.L.A. Clarke, G.V. Cormack, T.R. Lynam, Exploiting redundancy in
question answering, in: SIGIR ’01: Proceedings of the 24th Annual
International ACM SIGIR Conference on Research and Development
in Information Retrieval, ACM Press, New York, NY, USA, 2001, pp.
358–365.
[91] D. Downey, O. Etzioni, S. Soderland, A probabilistic model of redundancy
in information extraction, in: Proceedings of the 19th International Joint
Conference on Artificial Intelligence, 2005.
[92] C. Bizer, R. Cyganiak, T. Gauss, O. Maresch, The TriQL.P browser: filter-
ing information using context-, content- and rating-based trust policies,
in: Proceedings of the Semantic Web and Policy Workshop at the 4th
International Semantic Web Conference, 2005.
[93] L. Ding, L. Zhou, T. Finin, Trust based knowledge outsourcing for seman-
tic web agents, in: Proceedings of the 2003 IEEE/WIC International
Conference on Web Intelligence, 2003.
[94] L. Ding, P. Kolari, T. Finin, A. Joshi, Y. Peng, Y. Yesha, On homeland
security and the semantic web: a provenance and trust aware inference
framework, in: Proceedings of the AAAI Spring Symposium on AI Tech-
nologies for Homeland Security, AAAI Press, 2005.
[95] C.-N. Ziegler, Semantic web recommender systems, in: W. Lindner, M.
Mesiti, C. Türker, Y. Tzitzikas, A. Vakali (Eds.), EDBT 2004 Workshops
(PhD, DataX, PIM, P2P&DB, and ClustWeb), volume 3268 of LNCS,
Springer-Verlag, Heraklion, Greece, 2004, pp. 78–89.
[96] X. Zhu, S. Gauch, Incorporating quality metrics in centralized/distributed
information retrieval on the world wide web, in: SIGIR ’00: Proceedings
of the 23rd Annual International ACM SIGIR Conference on Research
and Development in Information Retrieval, ACM Press, New York, NY,
USA, 2000, pp. 288–295.[97] E. Riloff, J. Wiebe, W. Phillips, Exploiting subjectivity classification to
improve information extraction, in: Proceedings of the 20th National
Conference on Artificial Intelligence, 2005.
[98] V. Stoyanov, C. Cardie, J. Wiebe, Multi-perspective question answering
using the opqa corpus, in: Proceedings of the Human Language Tech-
s andD. Artz, Y. Gil / Web Semantics: Science, Service
nology Conference and Conference on Empirical Methods in Natural
Language, 2005.
[99] C. Cardie, J. Wiebe, T. Wilson, D. Litman, Low-level annotations
and summary representations of opinions for multiperspective question
answering, in: M. Maybury (Ed.), New Directions in Question Answering,
AAAI Press/MIT Press, 2004.
[100] D.L. McGuinness, Question answering on the semantic web, IEEE Intell.
Syst. 19 (1) (2004).
[101] J. Golbeck, Combining provenance with trust in social networks for
semantic web content filtering, in: Proceedings of the International Prove-
nance and Annotation Workshop, 2006.
[102] J. Zhao, C. Wroe, C. Goble, R. Stevens, D. Quan, M. Greenwood, Using
semantic web technologies for representing e-science provenance, in:
Proceedings of the 3rd International Semantic Web Conference, 2004.
[103] S.C. Wong, S. Miles, W. Fang, P. Groth, L. Moreau, Provenance-based val-
idation of e-science experiments, in: Proceedings of the 4th International
Semantic Web Conference, volume 3729 of Lecture Notes in Computer
Science, 2005, pp. 801–815.
[104] J. Kim, E. Deelman, Y. Gil, G. Mehta, V. Ratnakar, Provenance trails in
the Wings/Pegasus workflow system. J. Comput. Concurr.: Pract. Expe-
rience, Special issue on the First Provenance Challenge, L. Moreau, B.
Ludaescher (Eds), 2007.
[105] Y. Simmhan, B. Plale, D. Gannon, A survey of data provenance in e-
science, Spec. Interest Group Manage. Data Record 34 (3) (2005) 31–36.
[106] L. Moreau, B. Ludaescher (Eds.), Special issue on the first provenance
challenge, J. Comput. Concurr.: Pract. Experience, 2007.
[107] Y. Gil, V. Ratnakar, Trellis: an interactive tool for capturing informa-
tion analysis and decision making, in: EKAW ’02: Proceedings of theAgents on the World Wide Web 5 (2007) 58–71 71
13th International Conference on Knowledge Engineering and Knowl-
edge Management. Ontologies and the Semantic Web, Springer-Verlag,
London, UK, 2002, pp. 37–42.
[108] Y. Gil, V. Ratnakar, Trusting information sources one citizen at a time,
in: ISWC ’02: Proceedings of the First International Semantic Web Con-
ference on The Semantic Web, Springer-Verlag, London, UK, 2002, pp.
162–176.
[109] T. Chklovski, Y. Gil, V. Ratnakar, J. Lee, Trellis: Supporting decision
making via argumentation in the semantic web, in: Proceedings of the
2nd International Semantic Web Conference, 2003.
[110] C. Castelfranchi, R. Falcone, G. Pezzulo, Trust in information sources
as a source for trust: a fuzzy approach, in: AAMAS ’03: Proceedings
of the Second International Joint Conference on Autonomous Agents
and Multiagent Systems, ACM Press, New York, NY, USA, 2003,
pp. 89–96.
[111] Y. Gil, D. Artz, Towards content trust of web resources, in: Proceedings
of the 15th International World Wide Web Conference, 2006.
[112] E. Sillence, P. Briggs, L. Fishwick, P. Harris, Trust and mistrust of online
health sites, in: CHI ’04: Proceedings of the SIGCHI Conference on
Human Factors in Computing Systems, ACM Press, New York, NY, USA,
2004, pp. 663–670.
[113] R.T. Stephens, A framework for the identification of electronic commerce
design elements that enable trust within the small hotel industry, in: ACM-
SE 42: Proceedings of the 42nd Annual Southeast Regional Conference,
ACM Press, New York NY, USA, 2004, pp. 309–314.
[114] C.L. Corritore, S. Wiedenbeck, B. Kracher, The elements of online trust,
in: CHI ’01: CHI ’01 Extended Abstracts on Human Factors in Computing
Systems, ACM Press, New York, NY, USA, 2001, pp. 504–505.

