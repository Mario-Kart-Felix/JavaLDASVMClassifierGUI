1204 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 46, NO. 4, JULY 2000
Network Information Flow
Rudolf Ahlswede, Ning Cai, Shuo-Yen Robert Li, Senior Member, IEEE, and
Raymond W. Yeung, Senior Member, IEEE
Abstract—We introduce a new class of problems called network
information flow which is inspired by computer network applica-
tions. Consider a point-to-point communication network on which
a number of information sources are to be mulitcast to certain sets
of destinations. We assume that the information sources are mu-
tually independent. The problem is to characterize the admissible
coding rate region. This model subsumes all previously studied
models along the same line. In this paper, we study the problem
with one information source, and we have obtained a simple char-
acterization of the admissible coding rate region. Our result can be
regarded as the Max-flow Min-cut Theorem for network informa-
tion flow. Contrary to one’s intuition, our work reveals that it is in
general not optimal to regard the information to be multicast as a
“fluid” which can simply be routed or replicated. Rather, by em-
ploying coding at the nodes, which we refer to as network coding,
bandwidth can in general be saved. This finding may have signifi-
cant impact on future design of switching systems.
Index Terms—Diversity coding, multicast, network coding,
switching, multiterminal source coding.
I. INTRODUCTION
L ET be the set of nodes of a point-to-point communica-tion network. Such a network is represented by a directed
graph , where is the set of edges, such that in-
formation can be sent noiselessly from node to node for all
. An example of this type of networks is the Internet
backbone, where with proper data link protocols information
can be sent between nodes essentially free of noise.
Let be mutually independent information
sources. The information rate (in bits per unit time) of is
denoted by , and let . Let
and be arbitrary mappings. The source
is generated at node , and it is multicast to node for
all . The mappings and the vector specify a set
of multicast requirements.
In this model, the graph may represent a physical network,
while the set of multicast requirements may represent the aggre-
Manuscript received February 25, 1998; revised March 6, 2000. This work
was supported in part under Grants CUHK95E/480 and CUHK332/96E from
the Research Grant Council of the Hong Kong Special Administrative Region,
China. The material in this paper was presented in part at the IEEE International
Symposium on Information Theory, MIT, Cambridge, MA, August 16–21, 1998
R. Ahlswede is with Fakultät für Mathematik, Universität Bielefeld, 33501
Bielefeld, Germany (e-mail: hollmann@Mathematik.uni-Bielefeld.de).
N. Cai was with Fakultät für Mathematik, Universität Bielefeld, 33501
Bielefeld, Germany. He is now with the Department of Information Engi-
neering, The Chinese University of Hong Kong, N.T., Hong Kong (e-mail:
ncai@ie.cuhk.edu.hk).
S.-Y. R. Li and R. W. Yeung are with the Department of Information En-
gineering, The Chinese University of Hong Kong, N.T., Hong Kong (e-mail:
syli@ie.cuhk.hk; whyeung@ie.cuhk.hk).
Communicated by R. L. Cruz, Associate Editor for Communication Net-
works.
Publisher Item Identifier S 0018-9448(00)05297-4.
gated traffic pattern the network needs to support. In other sit-
uations, the graph may represent a subnetwork in a physical
network, while the set of multicast requirements may pertain to
a specific application on this subnetwork, e.g., a video-confer-
ence call.
In existing computer networks, each node functions as a
switch in the sense that it either relays information from an
input link to an output link, or it replicates information received
from an input link and sends it to a certain set of output links.
From the information-theoretic point of view, there is no
reason to restrict the function of a node to that of a switch.
Rather, a node can function as an encoder in the sense that
it receives information from all the input links, encodes, and
sends information to all the output links. From this point of
view, a switch is a special case of an encoder. In the sequel, we
will refer to coding at a node in a network as network coding.
Let be a nonnegative real number associated with the
edge , and let . For a fixed set of mul-
ticast requirements, a vector is admissible if and only if there
exists a coding scheme satisfying the set of multicast require-
ments such that the coding rate from node to node (i.e., the
average number of bits sent from node to node per unit time)
is less than or equal to for all . (At this point we
leave the details of a coding scheme open because it is extremely
difficult to define the most general form of a coding scheme. A
class of coding schemes called -codes will be studied in Sec-
tion III.) In graph theory, is called the capacity of the edge
. Our goal is to characterize the admissible coding rate re-
gion , i.e., the set of all admissible , for any graph and
multicast requirements and .
The model we have described includes both multilevel diver-
sity coding (without distortion) [12], [8], [13] and distributed
source coding [14] as special cases. As an illustration, let us
show how the multilevel diversity coding system in Fig. 1 can
be formulated as a special case of our model. In this system,
there are two sources, and . Decoder 1 reconstructs
only, while all other decoders reconstruct both and . Let
be the coding rate of Encoder , . In our model, the
system is represented by the graph in Fig. 2. In this graph,
node 1 represents the source, nodes 2, 3, and 4 represent the in-
puts of Encoders 1, 2, and 3, respectively, nodes 5, 6, and 7 rep-
resent the outputs of Encoders 1, 2, and 3, respectively, while
nodes 8, 9, 10, and 11 represent the inputs of Decoders 1, 2, 3,
and 4, respectively. The mappings and are specified as
and
0018–9448/00$10.00 © 2000 IEEE
Authorized licensed use limited to: Univ of Calif Davis. Downloaded on April 30, 2009 at 16:11 from IEEE Xplore.  Restrictions apply.
AHLSWEDE et al.: NETWORK INFORMATION FLOW 1205
Fig. 1. A multilevel diversity coding system.
Fig. 2. The graph G representing the coding system in Fig. 1.
and represents the information rates of and .
Now all the edges in except for corre-
spond to straight connections in Fig. 1, so there is no constraint
on the coding rate in these edges. Therefore, in order to deter-
mining , the set of all admissible for the graph (with the
set of multicast requirements specified by and , we set
for all edges in except for to
obtain the admissible coding rate region of the problem in Fig. 1.
A major finding in this paper is that, contrary to one’s in-
tuition, it is in general not optimal to consider the information
to be multicast in a network as a “fluid” which can simply be
routed or replicated at the intermediate nodes. Rather, network
coding has to be employed to achieve optimality. This fact is il-
lustrated by examples in the next section.
In the rest of the paper, we focus our discussion on problems
with , which we collectively refer to as the single-source
problem. For problems with , we refer to them collec-
tively as the multisource problem. The rest of the paper is orga-
nized as follows. In Section II, we propose a Max-flow Min-cut
theorem which characterizes the admissible coding rate region
of the single-source problem. In Section III, we formally state
the main result in this paper. The proof is presented in Sections
IV and V. In Section VI, we show that very simple optimal codes
do exist for certain networks. In Section VII, we use our results
for the single-source problem to solve a special case of the mul-
tisource problem which has application in video conferencing.
In this section, we also show that the multisource problem is
extremely difficult in general. Concluding remarks are in Sec-
tion VIII.
II. A MAX-FLOW MIN-CUT THEOREM
In this section, we propose a theorem which characterizes the
admissible coding rate region for the single-source problem. For
this problem, we let , and . In
Fig. 3. A single-level diversity coding system.
Fig. 4. The graph representing the coding system in Fig. 3.
other words, the information source is generated at node
and is multicast to nodes . We will call the source
and the sinks of the graph . For a specific , the
problem will be referred to as the one-source -sink problem.
Let us first define some notations and terminology which will
be used in the rest of the paper. Let be a graph with
source and sinks . The capacity of an edge
is given by , and let . The subgraph of
from to , , refers to the graph ,
where
is on a directed path from to
is a flow in from to if for all
such that for all except for and
i.e., the total flow into node is equal to the total flow out of
node . is referred to as the value of in the edge .
The value of is defined as
which is equal to
is a max-flow from to in if is a flow from to
whose value is greater than or equal to any other flow from to
Authorized licensed use limited to: Univ of Calif Davis. Downloaded on April 30, 2009 at 16:11 from IEEE Xplore.  Restrictions apply.
1206 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 46, NO. 4, JULY 2000
(a) (b) (c)
Fig. 5. A one-source one-sink network.
. Evidently, a max-flow from to in is also a max-flow
from to in . For a graph with one source and one sink
(for example, the graph ), the value of a max-flow from the
source to the sink is called the capacity of the graph.
We begin our discussion by first reviewing a basic result of
diversity coding by considering the single-level diversity system
in Fig. 3. In this system, is the only information source (with
rate ), and it is reconstructed by all the decoders. Henceforth,
we will drop the subscripts of and when there is only
one information source. Let be the coding rate of encoder ,
and let . In order for a decoder to reconstruct ,
it is necessary that the sum of the coding rates of the encoders
accessible by this decoder is at least . Thus the conditions
(1)
(2)
(3)
(4)
are necessary for to be admissible. On the other hand, these
conditions are seen to be sufficient by the work of Singleton [10]
(also cf. [12]).
We now give a graph-theoretic interpretation of the above re-
sult. The graph corresponding to the system in Fig. 3 is given
in Fig. 4, where we use to label the source and to label a
sink. Now , and correspond to , and
, respectively. So the edges and are
labeled accordingly. The quantities and are inter-
preted as the capacity (in the sense of graph theory) of the cor-
responding edges. For the other edges in the graph, each one
of them corresponds to a straight connection in the system in
Fig. 3. Since there is no constraint on the coding rate in these
edges, we interpret the capacity of each of them as infinity. To
keep the graph simple, we do not label these edges. By consid-
ering the subgraph from to in Fig. 4, the condition in (1) can
be interpreted as the value of the max-flow from to being
greater than or equal to , the information rate of the source.
Similar interpretations can be made for the conditions in (2)-(4).
Based on the graph-theoretic interpretation of the above
diversity coding problem (which is a one-source four-sink
problem), we make the following conjecture.
Conjecture 1: Let be a graph with source and
sinks , and the capacity of an edge be denoted
by . Then is admissible if and only if the values of
a max-flow from to are greater than or equal
to , the rate of the information source.
The spirit of our conjecture resembles that of the celebrated
Max-flow Min-cut Theorem in graph theory [1]. Before we end
this section, we give a few examples to illustrate our conjecture.
We first illustrate by the example in Fig. 5 that the conjecture is
true for . Fig. 5(a) shows the capacity of each edge. By the
Max-flow Min-cut Theorem [1], the value of a max-flow from
to is , so the flow in Fig. 5(b) is a max-flow. In Fig. 5(c), we
show how we can send three bits from to based
on the max-flow in Fig. 5(b). The conjecture is trivially seen
to be true for , because when there is only one sink, we
only need to treat the raw information bits as physical entities.
The bits are routed at the intermediate nodes according to any
fixed routing scheme, and they will all eventually arrive at the
sink. Since the routing scheme is fixed, the sink knows which
bit is coming in from which edge, and the information can be
recovered accordingly.
Next we illustrate by the example in Fig. 6 that the conjecture
is true for . Fig. 6(a) shows the capacity of each edge. It
is easy to check that the value of a max-flow from to and
to are and , respectively. So the conjecture asserts that we
can send 5 bits to and simultaneously, and
Fig. 6(b) shows such a scheme. Note that in this scheme, bits
only need to be replicated at the nodes to achieve optimality.
We now show another example in Fig. 7 to illustrate that the
conjecture is true for . Fig. 7(a) shows the capacity of each
edge. It is easy to check that the value of a max-flow from to
is , . So the conjecture asserts that we can send 2 bits
to and simultaneously, and Fig. 7(b) shows such a
scheme, where “ ” denotes modulo addition. At , can be
recovered from and . Similarly, can be recovered at
. Note that when there is more than one sink, we can no longer
think of information as a real entity, because information needs
to be replicated or transformed at the nodes. In this example,
information is coded at the node 3, which is unavoidable. For
, network coding is in general necessary in an optimal
multicast scheme.
Finally, we illustrate by the example in Fig. 8 that the con-
jecture is true for . Fig. 8(a) shows the capacity of each
edge. It is easy to check that the values of a max-flow from to
all the sinks are . In Fig. 8(b), we show how we can multicast
2 bits to all the sinks.
Authorized licensed use limited to: Univ of Calif Davis. Downloaded on April 30, 2009 at 16:11 from IEEE Xplore.  Restrictions apply.
AHLSWEDE et al.: NETWORK INFORMATION FLOW 1207
(a) (b)
Fig. 6. A one-source two-sink network without coding.
(a) (b)
Fig. 7. A one-source two-sink network with coding.
The advantage of network coding can be seen from the ex-
amples in Figs. 7 and 8. As an illustration, we will quantify this
advantage for the example in Fig. 8 in two ways. First, we inves-
tigate the saving in bandwidth when network coding is allowed.
For the scheme in Fig. 8(b), a total of 9 bits are sent. If network
coding is not allowed, then it is easy to see that at least one more
bit has to be sent in order that for and to recover both
and . Thus we see that a very simple network code can
save 10% in bandwidth. Second, we investigate the increase in
throughput when network coding is allowed. Using the scheme
in Fig. 8(b), if 2 bits are sent in each edge, then 4 bits can be
multicast to all the sinks. If network coding is not allowed (and
2 bits are sent in each edge), we now show that only 3 bits can
be multicast to all the sinks. Let be the set
of bits to be multicast to all the sinks. Let the set of bits sent in
the edge be , where , . At node , the
received bits are duplicated and sent in the two out-going edges.
Thus 2 bits are sent in each edge in the network. Since network
coding is not allowed, for any .
Then we have
Therefore,
which implies . In Fig. 8(c), we show how 3 bits
and can be multicast to all the sinks by sending 2 bits in each
edge. Therefore, the throughput of the network can be increased
by one-third using a very simple network code.
III. MAIN RESULT
In this section, we formally present the main result in this
paper. Let be a directed graph with source and
sinks , and be the capacity of an edge in
. Since our conjecture concerns only the values of max-flows
from the source to the sinks, we assume without loss of gener-
ality that there is no edge in from a node (other than ) to ,
because such an edge does not increase the value of a max-flow
Authorized licensed use limited to: Univ of Calif Davis. Downloaded on April 30, 2009 at 16:11 from IEEE Xplore.  Restrictions apply.
1208 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 46, NO. 4, JULY 2000
(a) (b)
(c) (d)
Fig. 8. A one-source three-sink network.
from to a sink. Further, we assume for all for
the same reason.
Let us consider a block code of length . We assume that ,
the value assumed by , is obtained by selecting an index from
a set with uniform distribution. The elements in are called
messages. For , node can send information to node
which depends only on the information previously received by
node . Since the graph is arbitrary and may contain (directed)
cycles, a network code can in general be very complicated. In
this paper, we confine our discussion to a class of block codes,
called the -code, which is defined in the next paragraph.
An -code on a graph is defined by
the following components (the construction of an -code from
these components will be described after their definitions are
given):
1) a positive integer .
2) , , such that
.
3) , , such that
where
4) If , then , otherwise
where
and
5) , , where
such that for all , for all ,
where denotes the value of as a function of .
The -code is constructed from these
components as follows. At the beginning of the coding ses-
sion, the value of is available to node . In the coding ses-
sion, there are transactions which take place in chronological
order, where each transaction refers to a node sending informa-
tion to another node. In the th transaction, node encodes
according to and sends an index in to node . The do-
main of is the information received by node so far, and
we distinguish two cases. If , the domain of is . If
, gives the indices of all previous transactions for
which information was sent to node , so the domain of
is . The set gives the indices of all transactions
for which information is sent from node to node , so is the
number of possible index-tuples that can be sent from node to
node during the coding session. Finally, gives the indices
of all transactions for which information is sent to , and is
the decoding function at .
Authorized licensed use limited to: Univ of Calif Davis. Downloaded on April 30, 2009 at 16:11 from IEEE Xplore.  Restrictions apply.
AHLSWEDE et al.: NETWORK INFORMATION FLOW 1209
We remark that the -code is not the most general possible
definition of a block code. For example, the order of transac-
tions can depend on the value of . Also, coding can be done
probabilistically. (However, we prove in the Appendix that prob-
abilistic coding does not improve performance.) Instead of a
block code, it is also possible to use a variable-length code.
Let . A tuple is -admis-
sible if for any there exists, for sufficiently large , an
-code on such that
for all . (Note that -admissibility implies admissi-
bility.) Define
is -admissible
The problem is to characterize for any and .
For a directed graph with source , sinks
, and the capacity of an edge equals , let
be the set consisting of all such that the values of a
max-flow from to are greater than or equal to
The following theorem is the main result in this paper.
Theorem 1: .
IV. THE CONVERSE
In this section, we prove that , i.e., if for any
there exists for sufficiently large an
-code on such that
for all , then the values of a max-flow from to
are greater than or equal to .
Consider any and any such that
and . Let
and
Let
where and denotes the value of as a function of
. is all the information known by during the whole
coding session when the message is . Since for an -code,
is a function of the information previously received by
node , we see inductively that is a function of
Since can be determined at node , we have
Thus
Minimizing the right-hand side over all , we have
By the Max-flow Min-cut Theorem [1], the first term on the
right-hand side is equal to the value of a max-flow from to .
Letting , we obtain the desired conclusion.
As a remark, even if we allow an arbitrarily small probability
of decoding error in the usual Shannon sense, by modifying our
proof by means of a standard application of Fano’s inequality
[2], it can be seen that it is still necessary for the value of a
max-flow from to , to be greater than or equal
to . The details are omitted here.
V. ADMISSIBILITY
In this section, we prove that . In Section V-A,
we first prove the result when the graph is acyclic. Then this
result will be used to prove the general case in Section V-B.
A. Acyclic Networks
Assume the graph is acyclic. Let the vertices in be la-
beled by in the following way. The source has
the label . The other vertices are labeled in a way such that for
, implies . Such a labeling is
possible because is acyclic. We regard as aliases
of the corresponding vertices.
We will consider an -code on the
graph defined by
for all such that , where
for all such that , and
for all such that for all (re-
call that denotes the value of as a function of ). In
the above, is the encoding function for the edge , while
is the decoding function for the sink . In the coding ses-
sion, is applied before if , and is applied
Authorized licensed use limited to: Univ of Calif Davis. Downloaded on April 30, 2009 at 16:11 from IEEE Xplore.  Restrictions apply.
1210 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 46, NO. 4, JULY 2000
before if . This defines the order in which the en-
coding functions are applied. Since if , all
the necessary information is available when encoding at node
is done. If the set is empty, we adopt the
convention that is an arbitrary constant taken from the set
. An -code is a special
case of an -code defined in Section III.
Now assume that the vector is such that, with being the
capacity of the edge in , for all , the values of
a max-flow from to is greater than or equal to . It suffices
for us to show that for any , there exists for sufficiently
large an -code on such that
for all . Instead, we will show the existence of an
-code satisfying the same set of con-
ditions, and this will be done by a random procedure. For the
time being, let us replace by , where
is any constant greater than . Thus the domain of is ex-
panded from to for .
We now construct the encoding functions as follows. For all
such that , for all , is defined
to be a value selected independently from the set
with uniform distribution. For all , and for all
is defined to be a value selected independently from the
set with uniform distribution.
Let , and for , let
, where and denotes the
value of as a function of . is all the information
received by node during the coding session when the message
is . For distinct , and are indistinguishable at
the sink if and only if . For all , define
if
for some and
otherwise.
is equal to if and only if cannot be uniquely determined
at at least one of the sinks. Now fix and .
Consider any not equal to and define the sets
Obviously, and .
Now suppose . Then for some
, where and . For any
Therefore,
where
Let be any fixed positive real number. For all ,
take such that
for some . Then
In the second inequality above, we have used , and the
last inequality follows from the Max-flow Min-cut Theorem [1].
Note that this upper bound does not depend on . Since has
subsets, and is some subset of
Further,
for some
Therefore,
Let . Then as .
Hence, there exists a deterministic code for which the number
of messages which can be uniquely determined at all sinks is at
least
which is greater than for sufficiently large . Let to be
any set of such messages in . Upon defining
where such that , and
we have obtained a desired -code. The
theorem is proved.
B. Cyclic Networks
For cyclic networks, there is no natural ordering of the nodes
which allows coding in a sequential manner as in our discussion
on acyclic networks in the last section. In this section, we will
Authorized licensed use limited to: Univ of Calif Davis. Downloaded on April 30, 2009 at 16:11 from IEEE Xplore.  Restrictions apply.
AHLSWEDE et al.: NETWORK INFORMATION FLOW 1211
prove our result in full generality which involves the construc-
tion of a more elaborate code.
Consider any graph (acyclic or cyclic) with
source and sinks , and the capacity of an edge
given by . Assume for all , the value
of a max-flow from to is greater than or equal to . We will
prove that is -admissible.
We first construct a time-parametrized graph
from the graph . The set consists of layers of nodes,
each of which is a copy of . Specifically,
where
As we will see later, is interpreted as the time parameter. The
set consists of the following three types of edges:
1) ;
2) ;
3) .
For , let be the source, and let be a sink
which corresponds to the sink in , . Clearly,
is acyclic because each edge in ends at a vertex in a layer
with a larger index.
Let the capacities of the edges in be given by
. Let be the capacity of an
edge , where
if
for some and
otherwise
(5)
and let .
Lemma 1: Let and be the source and the sink of a graph ,
respectively. Then there exists a max-flow in expressible
as the sum of a number of flows for which each of them consists
of a simple path (i.e., a directed path without cycle) from to
only.
Proof: Let be a max-flow from to in which does
not contain a positive directed cycle (cf. [1, p. 45]). Let be
any positive path from to in (evidently is simple), and
let be the minimum value of in an edge along . Let
be the flow from to along with value . Subtracting
from , is reduced to , a flow from to which does
not contain a positive directed cycle. Apply the same procedure
repeatedly until is reduced to the zero flow. The lemma is
proved.
Lemma 2: For if the value of a max-flow from
to in is greater than or equal to , then the value of a
max-flow from to in is greater than or equal to
, where is the maximum length of a simple path from
to .
Proof: Let be fixed. Let be a max-flow
from to in with value such that does not contain
a positive directed cycle. Using the last lemma, we can write
, where , contains a
positive simple path from to only. Specifically
if
otherwise
(6)
where
(7)
Let be the length of . For an edge , let
be the distance of node from along . Clearly,
Now for , define
where
if
if
where
if
otherwise.
(8)
Since
the third case in (8) and hence is well defined for
. is a flow from to in derived
from the flow in as follows. A flow of is generated at
and enters the th layer of nodes from . Then the flow
traverses consecutive layers of nodes by emulating the path
in until it eventually reaches , and it finally leaves
at the sink . Based on , we construct
and
We will prove that componentwise. Then is a flow
from to in , and from (7), its value is given by
This implies that the value of a max-flow from to in is
at least , and the lemma is proved.
Toward proving that , we only need to consider
such that for some
and , because is infinite otherwise (cf. (5)).
Authorized licensed use limited to: Univ of Calif Davis. Downloaded on April 30, 2009 at 16:11 from IEEE Xplore.  Restrictions apply.
1212 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 46, NO. 4, JULY 2000
For notational convenience, we will adopt the convention that
for . Now for and
In the above, the third equality follows from (8), and the first
inequality is justified as follows. First, the inequality is justified
for since for . For ,
we distinguish two cases. From (8) and (6), if , we
have
If , we have
Thus the inequality is justified for all cases. Hence we conclude
that , and the lemma is proved.
From Lemma 2 and the result in Section V-A, we see that
is -admissible, where .
Thus for every , there exists for sufficiently large a
-code on such that
for all . For this -code on , let us use to
denote the encoding function for an edge , and use
to denote the decoding function at the sink , .
Without loss of generality, we assume that for
for all in
and
for all in
Note that if the -code does not satisfy these assumptions, it can
readily be converted into one.
Let be a positive integer, and let . Using the -code
on , we now construct an
-code on , where
which is defined by the following components:
1) for such that , a constant taken from
the set ;
2) for
for all such that , where
and for
for all such that (if the set
is empty, we adopt the convention that is a con-
stant taken from ;
3) for
such that for all (recall that
denotes the value of as a function of );
where
1) for such that , (
is an arbitrary constant in since
is empty);
2) for , for all , ,
and for and all such that ,
for all in
3) for , for all in
The coding process of the -code consists of phases:
1) In Phase 1, for all such that , node sends
to node , and for all such that ,
node send to node .
2) In Phase , , for all , node sends
to node , where denotes the value of
as a function of , and it depends only on
Authorized licensed use limited to: Univ of Calif Davis. Downloaded on April 30, 2009 at 16:11 from IEEE Xplore.  Restrictions apply.
AHLSWEDE et al.: NETWORK INFORMATION FLOW 1213
for all such that , i.e., the information
received by node during Phase .
3) In Phase , for , the sink uses to
decode .
From the definitions, we see that an
-code on is a special case of an
-code on . For the -code we have constructed
for all . Finally, for any , by taking a sufficiently
large , we have
Hence, we conclude that is -admissible.
VI. AN EXAMPLE
Despite the complexity of our proof of Theorem 1 in the last
two sections, we will show in this section that very simple op-
timal codes do exist for certain cyclic networks. Therefore, there
is much room for further research on how to design simple op-
timal codes for (single-source) network information flow. The
code we construct in this section can be regarded as a kind of
convolutional code, which possesses many desirable properties
of a practical code.
Consider the graph in Fig. 9, where
and contains the following types of edges for :
1) ;
2) ;
3) and ;
4) ;
5) ;
where denotes modulo addition. Here is the source and
are the sinks. In the graph , the edges ,
, and form a cycle.
In this example, we let the information rate be . Without
loss of generality, we assume that the information source gen-
erates three symbols at time
where are elements of some finite field GF . For the
purpose of our discussion, we can regard the sequence of sym-
bols as deterministic. Consider the rate tuple ,
the vector whose components are all equal to . Then the value
of a max-flow from to is , and Theorem 1 as-
serts that is admissible.
Fig. 9. An example of a cyclic network.
We now show that is admissible by presenting a coding
scheme which can multicast from the
source to all the sinks. To simplify notation, we adopt the con-
vention that for . At time , information
transactions occur in the following order:
T1. sends to ,
T2. sends to , , and ,
T3. sends to
T4. sends to
T5. sends to
T6. sends to
T7. sends to
T8. sends to
T9. decodes
T10. decodes
T11. decodes
where “ ” denotes addition in GF . Note that the coding rate
in each edge is equal to , since exactly one symbol is sent in
each edge in one unit time.
We now show that these information transactions can actually
be performed. Let us start at . At , T1 and T2 can
obviously be performed. T3 and T4 can be performed because
. T5 and T6 can be performed since
and have been sent to from and , respectively. T7
and T8 can be performed since and have
been sent to from and , respectively. T9 can obviously
be performed since . T10 can be performed since
, , and have been sent to from ,
, and , respectively. Finally, T11 can be performed since
, , and have been sent to
from , , and , respectively.
Now assume that T1-T11 can be performed up to time
for some , and we will show that they can be performed at
time . T1 and T2 can obviously be performed. Just before T3
is performed, has been sent to from at time , and
and have been sent
to from and , respectively, at time . Therefore, at
time , can determine , and T3
Authorized licensed use limited to: Univ of Calif Davis. Downloaded on April 30, 2009 at 16:11 from IEEE Xplore.  Restrictions apply.
1214 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 46, NO. 4, JULY 2000
and T4 can be performed accordingly. By similar arguments, we
see that T5–T8 can be performed. Just before T9 is performed,
and have been sent to
from and , respectively, at time , and has been
sent to from at time . Therefore, at time , T9 can be
performed. By similar arguments, we see that T10 and T11 can
be performed.
At time , and are sent to from and
, respectively, . With T9–T11, at time , and
can recover and for all , while
can recover and for all , and for
all . Note the unit time delay for to recover .
Thus our coding scheme can multicast to
all the sinks, and hence is admissible.
It is also possible to design convolutional codes for an acyclic
network. Compared with the block code we used in proving
Theorem 2, it seems that a convolution code has the advantage
that the code can be very simple, and both the memory at each
node and the end-to-end decoding delay can be very small.
VII. MULTIPLE SOURCES
In the classical information theory for point-to-point com-
munication, if two information sources are independent, opti-
mality can be achieved (asymptotically) by coding the sources
separately. This coding method is referred to as coding by su-
perposition [12]. If this coding method is always optimal for
multisource network information flow problems, then in order
to solve the problem, we only need to solve the subproblems
for the individual information sources separately, where each of
these subproblems is a single-source problem. However, as we
will see shortly, the multisource problem is not a trivial exten-
sion of the single-source problem, and it is extremely difficult
in general.
Let us consider the multilevel diversity coding system in Fig.
1. Assume that . Since the sources and are
independent, if coding by superposition is always optimal, then
for any admissible coding rate triple , for ,
we can write
where and are the subrates associated with sources and
, respectively. Since is multicast to all the decoders, from
the discussion in Section II, we have the following constraints
for :
Similarly, since is multicast to Decoders 2, 3, and 4, we have
the following constraints for :
However, it was shown in [12] that the rate triple is ad-
missible, but it cannot be decomposed into two sets of subrates
as prescribed above. Therefore, coding by superposition is not
optimal in general, even when the two information sources are
generated at the same node.
In [5],1 it was found that coding by superposition is optimal
for 86 out of all 100 configurations of multilevel diversity
coding systems with three encoders. In [8] and [13] it was
shown that coding by superposition is optimal for all sym-
metrical multilevel diversity coding systems. However, how
to characterize multilevel diversity coding systems for which
coding by superposition is always optimal is still an open
problem.
Although the multisource problem in general is extremely
difficult, there exist special cases which can be readily solved
by the results for the single-source problem. Consider a net-
work information flow problem with information sources.
Let , and suppose , .
Here, each information source is multicast from to sinks
. It turns out that this problem can be reduced to a
single-source problem by adding the following components to
the graph :
1) a node ;
2) edges .
Set to , the information rate of , , and call
this augmented graph . Then we can regard all information
sources as one information source (with rate
) generated at node , where is sent to node via
edge at rate . Then the problem can be regarded as a
one-source -sink problem on the graph with source and
sinks .
In video-conferencing, the information generated by each
participant is multicast to all other participants on the network.
This is a special case of the situation described in the last
paragraph.
VIII. DISCUSSION
In this paper, we have proposed a new class of problems called
network information flow which is inspired by computer net-
work applications. This class of problems consolidates all pre-
vious work along this line [12], [8], [14] into a new direction in
multiterminal source coding.
In the past, most results in multiterminal source coding are
generalizations of either the Slepian–Wolf problem [9] or the
multiple descriptions problem [3]. The class of problems we
have proposed are generalizations of neither of these problems.
Further, they distinguish themselves from most classical multi-
terminal source coding problems in the following ways:
1) there is no rate-distortion consideration;
2) the sources are mutually independent;
3) the network configuration, described by a graph, is arbi-
trary;
4) the reconstruction requirements are arbitrary.
Our formulation covers a large class of problems instead of
one particular problem. For most classical multiterminal source
1The reader can contact Raymond Yeung for a copy of this reference.
Authorized licensed use limited to: Univ of Calif Davis. Downloaded on April 30, 2009 at 16:11 from IEEE Xplore.  Restrictions apply.
AHLSWEDE et al.: NETWORK INFORMATION FLOW 1215
coding problems, the problem degenerates if there is no rate-dis-
tortion consideration and the sources are mutually independent.
For our class of problems, neither of these assumptions is made.
Yet they are highly nontrivial problems.
In this paper, we have characterized the admissible coding
rate region of the single-source problem. Our result can be re-
garded as the Max-flow Min-cut Theorem for network informa-
tion flow. We point out that our discussion is based on a class of
block codes called -codes. Therefore, it is possible, though not
likely, that our result can be enhanced by considering more gen-
eral coding schemes. Nevertheless, we prove in the Appendix
that probabilistic coding does not improve performance.
In analog telephony, when a point-to-point call is established,
there is a physical connection between the two parties. When
a conference call is established, there is a physical connection
among all the parties involved. In computer communication
(which is digital), we used to think that for multicasting, there
must be a logical connection among all the parties involved
such that raw information bits are sent to the destinations
via such a connection. The notion of a logical connection
in computer communication is analogous to the notion of a
physical connection in analog telephony. As a result, multi-
casting in a computer network is traditionally being thought
of as replicating bits at the nodes, so that each sink eventually
receive a copy of all the bits. The most important contribution
of the current paper is to show that the traditional technique for
multicasting in a computer network in general is not optimal.
Rather, we should think of information as being “diffused”
through the network from the source to the sinks by means
of network coding. This is a new concept in multicasting in a
point-to-point network which may have significant impact on
future design of switching systems.
In classical information theory for point-to-point communi-
cation, we can think of information as a “fluid” or some kind of
physical entity. For network information flow with one source,
this analogy continues to hold when there is one sink, because
information flow conserves at all the intermediate nodes in an
optimal scheme. However, the analogy fails for multicasting be-
cause information needs to be replicated or coded at the nodes.
The problem becomes more complicated when there are
more than one source. In the classical information theory for
point-to-point communication, if two sources are independent,
optimality can be achieved (asymptotically) by coding the
sources separately. However, it has been shown by a simple
example in [12] that for simultaneous multicast of two sources,
it may be necessary to code the sources jointly in order to
achieve optimality. A special case of the multisource multisink
problem which finds application in satellite communication
has been studied in [14]. In this work, they obtained inner and
outer bounds on the admissible coding rate region.
For future research, the multisource multisink problem is a
challenging problem. For the single-source problem, there are
still many unresolved issues which are worth further investiga-
tion. In proving our result for acyclic graphs, we have used a
random block code. Recently, Li and Yeung [4] have devised a
systematic procedure to construct linear codes for acyclic net-
works. Along another line, the example in Section V shows
that convolutional codes are good alternatives to block codes.
It seems that convolutional codes have the advantage that the
code can be very simple, and the memory at each node and the
end-to-end decoding delay can be very small. These are all de-
sirable features for practical codes.
Finally, by imposing the constraint that network coding is not
allowed, i.e., each node functions as a switch in existing com-
puter networks, we can ask whether a rate tuple is admis-
sible. Also, we can ask under what condition can optimality be
achieved without network coding. These are interesting prob-
lems for further research.
Recently, there has been a lot of interest in factor graph
[7], a graphical model which subsumes Markov random field,
Bayesian network, and Tanner graph. In particular, the problem
of representing codes in graphs [11], [6] has received much
attention. The codes we construct for a given network in this
paper can be regarded as a special type of codes in a graph.
APPENDIX
PROBABILISTIC CODING DOES NOT IMPROVE PERFORMANCE
For an -code, the th transaction of the coding process is
specified by a mapping . Suppose instead of the mapping ,
the th transaction is specified by a transition matrix from the
domain of to the range of . Also, instead of the mapping ,
decoding at sink is specified by a transition matrix from the
domain of to the range of , . Then the code be-
comes a probabilistic code, and we refer to such a code as a prob-
abilistic -code. With a slight abuse of notation, we continue to
use to denote the code in the th transaction (where is a
random variable), and we use to denote .
In general, one can use probabilistic coding schemes in-
stead of deterministic coding schemes. By using probabilistic
schemes, it may be possible to multicast information from
to , at a rate higher than that permitted by
deterministic schemes. Before showing that this is impossible,
however, we first discuss a subtlety of probabilistic coding.
For a probabilistic -code on a graph , it seems intuitively
correct that for any and any such that
and , the information source , ,
and form a Markov chain because all the information sent
from to has to go through the set of nodes
. If this is the case, then by the Data Processing Theorem
[2], we have
where the last equality holds because can be recovered at sink
. However, we show next by an example that the Markov chain
asserted is not valid in general.
Consider the graph in Fig. 10 with three nodes and .
Let be uniformly distributed on GF , and
be independent of and uniformly distributed on GF . Con-
sider the following probabilistic -code with five transactions:
Authorized licensed use limited to: Univ of Calif Davis. Downloaded on April 30, 2009 at 16:11 from IEEE Xplore.  Restrictions apply.
1216 IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 46, NO. 4, JULY 2000
Fig. 10. A three-node network.
Note that the fourth transaction is possible because upon
knowing and , can be determined. For ,
. Then
and
Now from , both and can be recovered. However,
from , it is impossible to recover .
Therefore, the Markov chain asserted in the last paragraph is
invalid.
We now show that the use of probabilistic coding cannot re-
duce coding rates. Consider any probabilistic coding scheme,
and let be the random parameter (assumed to be real) of the
scheme with distribution function . Without loss of gen-
erality, we assume that is independent of . This assumption
can be justified by showing that if is not independent of ,
then we can construct an equivalent probabilistic coding scheme
whose random parameter is independent of . Define an in-
dependent random vector , where denotes
the alphabet set of ; , are mutually independent;
and has marginal distribution function . We then
use as the random parameter of the coding scheme when the
message is . This coding scheme, which uses as the random
parameter, is equivalent to the original scheme using as the
random parameter.
Let be the coding rate tuple
incurred when the message is and the random parameter takes
the value . (Here the coding scheme can be variable-length, so
may depend on .) Since and are independent, the average
coding rate tuple of this coding scheme is given by
Now observe that for a fixed , the coding scheme becomes de-
terministic. Therefore, the probabilistic coding scheme is actu-
ally a mixture of deterministic coding schemes. By time-sharing
these deterministic coding schemes according to (use
approximation if necessary), we obtain a deterministic coding
scheme. Hence, any coding rate tuple achievable by a proba-
bilistic coding scheme can be achieved asymptotically by a se-
quence of deterministic coding schemes.
ACKNOWLEDGMENT
Raymond Yeung would like to thank Ho-leung Chan and
Lihua Song for their useful inputs.
REFERENCES
[1] B. Bollobas, Graph Theory, An Introductory Course. New York:
Springer-Verlag, 1979.
[2] T. M. Cover and J. A. Thomas, Elements of Information Theory. New
York: Wiley, 1991.
[3] A. El Gamal and T. M. Cover, “Achievable rates for multiple descrip-
tions,” IEEE Trans. Inform. Theory, vol. IT–28, pp. 851–857, Nov. 1982.
[4] S.-Y. R. Li and R. W. Yeung, “Linear network coding,” IEEE Trans.
Inform. Theory, submitted for publication.
[5] K. P. Hau, “Multilevel diversity coding with independent data streams,”
M.Phil. thesis, The Chinese Univ. Hong Kong, June 1995.
[6] R. Koetter and A. Vardy, “Factor graphs, trellis formations, and gen-
eralized state realizations,” presented at the Institute for Mathematics
and Its Applications, Aug. 6, 1999, available at http://www/ima.umn.
edu/talks/workshops/aug12-13.99/koetter.html.
[7] F. R. Kschischang, B. J. Frey, and H.-A. Loeliger, “Factor graphs and
the sum-product algorithm,” IEEE Trans. Inform. Theory, submitted for
publication.
[8] J. R. Roche, R. W. Yeung, and K. P. Hau, “Symmetrical multilevel di-
versity coding,” IEEE Trans. Inform. Theory, vol. 43, pp. 1059–1064,
May 1997.
[9] D. Slepian and J. K. Wolf, “Noiseless coding of correlated information
sources,” IEEE Trans. Inform. Theory, vol. IT-19, pp. 471–480, July
1973.
[10] R. C. Singleton, “Maximum distance q-nary codes,” IEEE Trans. In-
form. Theory, vol. IT-10, pp. 116–118, Apr. 1964.
[11] N. Wiberg, H.-A. Loileger, and R. Koetter, “Codes and iterative
decoding on general graphs,” Euro. Trans. Telecommun., vol. 6, pp.
513–526, Sept. 1995.
[12] R. W. Yeung, “Multilevel diversity coding with distortion,” IEEE Trans.
Inform. Theory, vol. 41, pp. 412–422, Mar. 1995.
[13] R. W. Yeung and Z. Zhang, “On symmetrical multilevel diversity
coding,” IEEE Trans. Inform. Theory, vol. 45, pp. 609–621, Mar. 1999.
[14] , “Distributed source coding for satellite communications,” IEEE
Trans. Inform. Theory, vol. 45, pp. 1111–1120, May 1999.
Authorized licensed use limited to: Univ of Calif Davis. Downloaded on April 30, 2009 at 16:11 from IEEE Xplore.  Restrictions apply.

