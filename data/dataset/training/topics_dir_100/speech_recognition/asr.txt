1
Automatic Speech Recognition 1Advanced Natural Language Processing (6.864)
A Brief Introduction to
Automatic Speech Recognition
Jim Glass (glass@mit.edu)
MIT Computer Science and Artificial Intelligence Laboratory
November 13, 2007
Automatic Speech Recognition 2Advanced Natural Language Processing (6.864)
Overview
• Introduction
• Speech
• Models
• Search
• Representations
2
Automatic Speech Recognition 3Advanced Natural Language Processing (6.864)
Speech
Text
Recognition
Speech
Text
Synthesis
UnderstandingGeneration
Communication via Spoken Language
Meaningeaning
Human
Computer
Input Output
Automatic Speech Recognition 4Advanced Natural Language Processing (6.864)
Speech interfaces are ideal for information access and 
management when:
• The information space is broad and complex,
• The users are technically naive, or
• Only telephones are available.
Speech interfaces are ideal for infor ation access and 
anage ent hen:
• The infor ation space is broad and co plex,
• The users are technically naive, or
• nly telephones are available.
Virtues of Spoken Language
Natural: Requires no special training 
Flexible: Leaves hands and eyes free
Efficient: Has high data rate
Economical: Can be transmitted/received inexpensively
video
3
Automatic Speech Recognition 5Advanced Natural Language Processing (6.864)
Syntactic: Meet her at the end of Main Street
Meter at the end of Main Street
Semantic: Is the baby crying
Is the bay bee crying
Discourse Context: It is easy to recognize speech
It is easy to wreck a nice beach
Others: I'm flying to Chicago tomorrow  
I'm flying to Chicago tomorrow
Diverse Sources of Knowledge for 
Spoken Language Communication
Acoustic-Phonetic: Let us pray
Lettuce spray
Automatic Speech Recognition 6Advanced Natural Language Processing (6.864)
Automatic Speech Recognition
• An ASR system converts the speech signal into words
• The recognized words can be
– The final output, or
– The input to natural language processing
ASR
Systemt
Speech
Signal
Recognized
Words
4
Automatic Speech Recognition 7Advanced Natural Language Processing (6.864)
Application Areas for Speech Interfaces 
• Mostly input (recognition only)
– Simple command and control
– Simple data entry (over the phone)
– Dictation
• Interactive conversation (understanding needed)
– Information kiosks 
– Transactional processing
– Intelligent agents
Automatic Speech Recognition 8Advanced Natural Language Processing (6.864)
Parameters that Characterize the 
Capabilities of ASR Systems
Parameters Range
Speaking Mode: Isolated word to continuous speech
Speaking Style: Read speech to spontaneous speech
Enrollment: Speaker-dependent to speaker-independent
Vocabulary: Small (<20 words) to large (>50,000 words)
Language Model: Finite-state to context-sensitive
Perplexity: Low (<10) to high (>200)
SNR: High (>30dB) to low (<10dB)
Transducer: Noise-canceling microphone to cell phone
r t r
i  : I l t  r  t  ti  
i  t l :   t  t  
r ll t: r- t t  r-i t
l r : ll (  r ) t  l r  ( ,  r )
 l: i it - t t  t  t t- iti
r l it :  ( ) t  i  ( )
: i  ( ) t  l  ( )
r r: i - li  i r  t  ll 
5
Automatic Speech Recognition 9Advanced Natural Language Processing (6.864)
Read versus Spontaneous Speech
Filled and unfilled pauses: read, spontaneous
Lengthened words: read, spontaneous
False starts: read, spontaneous
Automatic Speech Recognition 10Advanced Natural Language Processing (6.864)
Speech Recognition: Where Are We Now?
• High performance, speaker-independent speech recognition 
is now possible
– Large vocabulary (for cooperative speakers in benign environments)
– Moderate vocabulary (for spontaneous speech over the phone)
• Commercial recognition systems are now available
– Dictation (e.g., IBM, Microsoft, Nuance, etc.)
– Telephone transactions (e.g., AT&T, Nuance, VST, etc.)
• When well-matched to applications, technology is able to 
help perform real work
• Demos:
– Speaker-independent, medium-vocabulary, small footprint ASR
– Dynamic vocabulary speech recognition with constrained grammar 
(http://web.sls.csail.mit.edu/city)
– Academic spoken lecture transcription and retrieval 
(http://web.sls.csail.mit.edu/lectures)
video
video
6
Automatic Speech Recognition 11Advanced Natural Language Processing (6.864)
Examples of ASR Performance
• Telephone digit recognition has 
word error rates of 0.3%
• Error rate for spontaneous 
speech twice that of read speech
• Error rate cut in half every two 
years for moderate vocabularies 
• Corpora range in size from tens 
to thousands of hours
• Conversational speech from 
many speakers with noise 
remains a research challenge
– Current focus on meetings & lectures
0.1
1
10
100
19
87
19
89
19
91
19
93
19
95
19
97
19
99
20
01
20
03
20
05
20
07
Year
W
or
d 
Er
ro
r 
R
at
e 
(%
)
Digits 1K, Read
2K, Sponaneous 20K, Read
Broadcast Conversational
Meetings Lectures
Automatic Speech Recognition 12Advanced Natural Language Processing (6.864)
The Importance of Data
• We need data for analysis, modeling, training, and evaluation
– “There is no data like more data”
• However, we need to have the right kind of data
– From real users
– Solving real problems
• Conduct research within the context of real application domains
– Forces us to confront critical technical issues (e.g., rejection, new word 
problem)
– Provides a rich and continuing source of useful data
– Demonstrates the usefulness of the technology
– Facilitates technology transfer
7
Automatic Speech Recognition 13Advanced Natural Language Processing (6.864)
(Real) Data Improves Performance
• Longitudinal evaluations show improvements
• Collecting real data improves performance:
– Enables increased complexity and improved robustness for acoustic 
and language models
– Better match than laboratory recording conditions
• Users come in all kinds
0
5
10
15
20
25
30
35
40
45
Apr May Jun Jul Aug Nov Apr Nov May
Er
ro
r R
at
e 
(%
)
1
10
100
Tr
ai
ni
ng
 D
at
a 
(x
10
00
)Word
Data
‘97 ‘99‘98
Automatic Speech Recognition 14Advanced Natural Language Processing (6.864)
Real Data will Dictate Technology Needs
TECHNOLOGY REQUIRED EXAMPLE
Simple word spotting Um, Braintree
Complex word spotting Eh yes, Avis rent-a-car in 
Boston
Hello, please Brighton, uh, 
can I have the number of 
Earthscape, in, uh, on 
Nonantum Street
Speech understanding Woburn, uh, Somerville. I'm 
sorry 
8
Automatic Speech Recognition 15Advanced Natural Language Processing (6.864)
Important Lessons Learned
• Statistical modeling and data-driven approaches have 
proved to be powerful
• Research infrastructure is crucial:
– Large amounts of linguistic data
– Evaluation methodologies
• Availability and affordability of computing power lead to 
shorter technology development cycles and real-time 
systems 
• Performance-driven paradigm accelerates technology 
development
• Interdisciplinary collaboration produces enhanced 
capabilities (e.g., spoken language understanding)
Automatic Speech Recognition 16Advanced Natural Language Processing (6.864)
* There are, of course, many exceptions.
ASR Trends*: Then and Now
before mid 70's mid 70’s - mid 80’s after mid 80’s
Recognition whole-word and sub-word units sub-word units
Units: sub-word units
Modeling heuristic and template matching mathematical 
Approaches: ad hoc and formal
rule-based and deterministic and probabilistic 
declarative data-driven and data-driven
Knowledge heterogeneous homogeneous homogeneous 
Representation: and complex and simple and simple
Knowledge intense knowledge embedded in automatic 
Acquisition: engineering simple structure learning
ef re i  70's i  70’s - i  80’s after i  80’s
ec iti le- r  a s - r  its s - r  its
its: s - r  its
eli e ristic a te late atc i at e atical 
r aches: ad c a  f r al
r le- ase  a eter i istic a  r a ilistic 
eclarative ata- rive a  ata- rive
le e eter e e s e e s e e s 
e rese tati : a  c lex a  si le a  si le
le e i te se k le e e e e  i  auto atic 
c isiti : e i eeri  si le str ct re lear i
9
Automatic Speech Recognition 17Advanced Natural Language Processing (6.864)
But We Are Far from Done!
Corpus                               Speech            Lexicon  Word Error   Human Error       
Type                Size Rate (%)         Rate (%)
Digit Strings (phone) spontaneous 10 0.3 0.009
Resource Management read 1000 3.6 0.1
ATIS spontaneous 2000 2 --
Wall Street Journal read ~20K 6.6 1
Broadcast News mixed ~64K 9.4 --
Switchboard (phone) conversation ~25K 13.1 4
Meetings conversation ~25K 30 --
r s                               eec             exic   r  rr r   a  rr r        
y e                ize ate ( )         ate ( )
i it tri s ( e) s ta e s 10 0.3 0.009
es rce a a e e t rea 1000 3.6 0.1
I s ta e s 2000 2 --
all treet J r al rea ~20 6.6 1
r a cast e s ixe ~64 9.4 --
itc ar  ( e) c versati ~25 13.1 4
eeti s c versati ~25 30 --
*
* Lippmann, 1997
Automatic Speech Recognition 18Advanced Natural Language Processing (6.864)
What Makes Speech Recognition Hard?
• Phonological variations
– Local and global contexts, …
• Individual differences
– Anatomy, socio-linguistic factors, …
• Environmental factors
– Transducers, noise, …
• Diversity of language use
– Syntax, semantics, discourse, …
• Real-world issues
– Disfluencies, new words, …
• . . .
10
Automatic Speech Recognition 19Advanced Natural Language Processing (6.864)
ASR Is All About Utilizing Constraints
• Acoustic
– Speech signal is generated by the human vocal apparatus
• Phonetic
– /s/ in word initial /st/ cluster is unaspirated (e.g. “stay”)
• Phonological
– /s/-/S/ sequence can turn into a long /S/ (e.g., “gas shortage”)
• Lexical
– Words in a language are limited (e.g., “blit” and “vnuk” are not English 
words)
• Language
– Probability of a word depends on its predecessors (e.g., “you” is the 
most likely word to follow “thank”)
– A sentence must be syntactically and semantically well formed (e.g., 
subject-verb agreement)
• . . .
Automatic Speech Recognition 20Advanced Natural Language Processing (6.864)
Lexical
Models
Acoustic
Models
Language
Models
Applying    Constraints
Recognized
Words
Search
Major Components in a Speech Recognizer
• Speech recognition is the problem of deciding on
– How to represent the signal
– How to model the constraints
– How to search for the most optimal answer
Representationi
Speech
Signal
Training Data
11
Automatic Speech Recognition 21Advanced Natural Language Processing (6.864)
Speech
Automatic Speech Recognition 22Advanced Natural Language Processing (6.864)
Speech Production
• Speech produced via coordinated movement of articulators
• Spectral characteristics of speech influenced by source, 
vocal tract shape, and radiation characteristics
• Speech articulation characterized by manner and place 
– Vowels: No significant constriction in the vocal tract; usually voiced
– Fricatives: turbulence produced at a narrow constriction
– Stops: complete closure in the vocal tract; pressure build up
– Nasals: velum lowering results in airflow through nasal cavity
– Semivowels: constriction in vocal tract, no turbulence
12
Automatic Speech Recognition 23Advanced Natural Language Processing (6.864)
A Wide-Band Spectrogram 
Automatic Speech Recognition 24Advanced Natural Language Processing (6.864)
• The acoustic realization of a phoneme depends strongly on 
the context in which it occurs
TEA BEATENTREE STEEP CITY
Phonological Variation
13
Automatic Speech Recognition 25Advanced Natural Language Processing (6.864)
Waveform
Signal Processing
Frequency
E
ne
rg
y
• Frame-based spectral 
feature vectors (typically 
every 10 milliseconds)
• Efficiently represented 
with Mel-frequency scale 
cepstral coefficients 
– Typically ~13 MFCCs used 
per frame
Automatic Speech Recognition 26Advanced Natural Language Processing (6.864)
Models
14
Automatic Speech Recognition 27Advanced Natural Language Processing (6.864)
Statistical Approach to ASR
Linguistic
Decoder
Language
Model
Acoustic
ModelSpeech
* argmax ( | )
W
W P W A=
W
P W( )
P A W( | )
Signal
Processor
A
Words W *
• Given acoustic observations, A, choose word sequence, W*, 
which maximizes a posteriori probability, P(W |A)
( | ) ( )( | )
( )
P A W P WP W A
P A
=
• Bayes rule is typically used to decompose P(W |A) into 
acoustic and linguistic terms
Automatic Speech Recognition 28Advanced Natural Language Processing (6.864)
Lexical
Graph
Probabilistic Framework
• Words are typically represented as sequence of phonetic units
• Using phonetic units, U, expression expands to:
,
max ( | ) ( | ) ( )
U W
P A U P U W P W
Acoustic 
Model
Pronunciation
Model
Language
Model
• Search must efficiently find most likely U and W
• Pronunciation and language models encoded in a graph
15
Automatic Speech Recognition 29Advanced Natural Language Processing (6.864)
Language Modeling
• ASR systems constrain possible word combinations by way 
of simple, but powerful, language models:
– Finite-state network
– Deterministic, sequential constraints (e.g., word-pair)
– Probabilistic, sequential constraints (e.g., bigram, trigram)
• Trigram is the dominant language model for ASR:
– Much effort has gone into smoothing techniques for sparse data
• Task difficulty is measured by perplexity
P( wn | wn-2  , wn-1 )
Automatic Speech Recognition 30Advanced Natural Language Processing (6.864)
• Feature vector scoring:
• Each phonetic unit modeled 
w/ a mixture of Gaussians:
Waveform
Acoustic Modeling
ix
r
)| ji uxp(
r
)| ki uxp(
r
…..
∏
N
i i
i=0
P(A | U) = P(x | u )r
∑
=
Σ=
M
0j
jjj |xN(wu)|xP( ),μ
rr
16
Automatic Speech Recognition 31Advanced Natural Language Processing (6.864)
Hidden Markov Models
• Dominant modeling framework used for speech recognition
• Generative model that predicts likelihood of observation 
sequence O being generated by state sequence Q
– Either discrete or continuous observation models can be used
• HMMs can model words or sub-words (e.g., phones)
– Sub-word HMMs concatenated to create larger word-based HMMs
States
Observation
Models
Automatic Speech Recognition 32Advanced Natural Language Processing (6.864)
• Words described by phonemic baseforms
• Phonological rules expand baseforms into graph, e.g.,
– Deletion of stop bursts in syllable coda (e.g., laptop)
– Deletion of /t/ in various environments (e.g., intersection, crafts)
– Gemination of fricatives and nasals (e.g., this side, in nome)
– Place assimilation (e.g., did you (/d ih jh uw/))
• Arc probabilities can be trained (i.e., P(U|W) )
Phonological Modeling
batter : b ae tf er
This can be realized phonetically as:
bcl b ae tcl t er
or as:
bcl b ae dx er
Standard /t/
Flapped /t/
17
Automatic Speech Recognition 33Advanced Natural Language Processing (6.864)
Phonological Example
• Example of “what you” expanded with phonological rules
– Final /t/ in “what” can be realized as released, unreleased, palatalized, 
or glottal stop, or flap
“what” “you”
Automatic Speech Recognition 34Advanced Natural Language Processing (6.864)
Search
18
Automatic Speech Recognition 35Advanced Natural Language Processing (6.864)
Acoustic models generate phonetic likelihoods
Frame-based measurements
Waveform
A Simple View of Speech Recognition
ao
-m - aedh- k
p
uw
er
z t k-ax dx
Probabilistic search finds most likely phone & word strings
computers                                that                  talk
Automatic Speech Recognition 36
• Viterbi search typically used in first-pass to find best path
Viterbi Search Example
Le
xi
ca
l N
od
es
-
m
z
r
a
Time
t0 t1 t2 t3 t4 t5 t6 t7 t8
• Relative and absolute thresholds used to speed-up search
19
Automatic Speech Recognition 37
Le
xi
ca
l N
od
es
-
m
z
r
a
Time
t0 t1 t2 t3 t4 t5 t6 t7 t8
• Second pass uses backwards A* search to find N-best paths
• Viterbi backtrace is used as future estimate for path scores
A* Search Example
Automatic Speech Recognition 38Advanced Natural Language Processing (6.864)
Search Issues
• Search often uses forward and backward passes, e.g., 
– Forward Viterbi search using bigram
– Backwards A* search using bigram to create a word graph
– Rescore word graph with trigram (i.e., subtract bigram scores)
– Backwards A* search using trigram to create N-best outputs
• Search relies on two types of pruning:
– Pruning based on relative likelihood score
– Pruning based maximum number of hypotheses
– Pruning provides tradeoff between speed and accuracy
• Multiple searches is a form of successive refinement
– More sophisticated models can be used in each iteration
20
Automatic Speech Recognition 39Advanced Natural Language Processing (6.864)
Representations
Automatic Speech Recognition 40Advanced Natural Language Processing (6.864)
Finite-State Transducers
• Most speech recognition constraints and results can be 
represented as finite-state automata:
– Language models (e.g., n-grams and word networks)
– Lexicons
– Phonological rules
– N-best lists
– Word graphs
– Recognition paths
• Common representation and algorithms desirable
– Consistency
– Powerful algorithms can be employed throughout system
– Flexibility to combine or factor in unforeseen ways
• Finite-state transducers (FSTs) are effective for defining 
weighted relationships between regular languages
– Extend FSAs by enabling transduction between input and output strings
– Pioneered by researchers at AT&T for use in speech recognition
21
Automatic Speech Recognition 41Advanced Natural Language Processing (6.864)
Example FST Operations
• Construction (produce new functionality)
– Union: A U B
– Composition: A o B
• Optimization (retain original functionality)
– Determinization
– Minimization
Automatic Speech Recognition 42Advanced Natural Language Processing (6.864)
Speech Recognition as Cascade of FSTs
• Cascade of FSTs
O o (M o P o L o G)
– G: language model (weighted words ← words)
– L: lexicon (phonemes ← words)
– P: phonological rule application (phones ← phonemes)
– M: model topology (e.g., HMM) (states ← phones)
– O: observations with acoustic model scores
• (M o P o L o G) is single FST seen by search
• Search performs composition of O with (M o P o L o G)
• Gives great flexibility in how components are combined
22
Automatic Speech Recognition 43Advanced Natural Language Processing (6.864)
Expanded FST Representation
Acoustic Model Labels
Phonetic Units
Phonemic Units
Spoken Words
Multi-Word Units
Canonical Words
C : CD Model Mapping
P: Phonological Model
L : Lexical Model
G : Language Model
R : Reductions Model
M : Multi-word Mapping
give me new_york_city
give me new york city
gimme new york city
g ih m iy n uw y ao r kd s ih tf iy
gcl g ih m iy n uw y ao r kcl s ih dx iy
• FST representation can be expanded for more efficient 
representation of lexical variation 
Automatic Speech Recognition 44Advanced Natural Language Processing (6.864)
Related Areas of Research
• Speech understanding and spoken dialogue
• Multimodal interaction
• Audio-visual analysis (e.g., AVSR)
• Spoken document retrieval
• Speaker identification and verification
• Paralinguistic analysis (e.g., emotion)
• Acoustic scene analysis (e.g., CASA)
• …

