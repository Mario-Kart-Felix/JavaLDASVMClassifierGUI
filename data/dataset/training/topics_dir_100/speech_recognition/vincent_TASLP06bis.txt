Performance measurement in blind audio source
separation
Emmanuel Vincent, Rémi Gribonval, Cédric Févotte
To cite this version:
Emmanuel Vincent, Rémi Gribonval, Cédric Févotte. Performance measurement in blind audio
source separation. IEEE Transactions on Audio, Speech and Language Processing, Institute of
Electrical and Electronics Engineers, 2006, 14 (4), pp.1462–1469.
HAL Id: inria-00544230
https://hal.inria.fr/inria-00544230
Submitted on 7 Dec 2010
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
1
Performance Measurement in
Blind Audio Source Separation
Emmanuel Vincent?, Rémi Gribonval and Cédric Févotte
Abstract— In this article, we discuss the evaluation of Blind
Audio Source Separation (BASS) algorithms. Depending on the
exact application, different distortions can be allowed between an
estimated source and the wanted true source. We consider four
different sets of such allowed distortions, from time-invariant
gains to time-varying filters. In each case we decompose the
estimated source into a true source part plus error terms
corresponding to interferences, additive noise and algorithmic
artifacts. Then we derive a global performance measure using
an energy ratio, plus a separate performance measure for each
error term. These measures are computed and discussed on the
results of several BASS problems with various difficulty levels.
Index Terms— Audio source separation, performance, quality,
evaluation, measure.
I. INTRODUCTION
BLIND Audio Source Separation (BASS) has been a topicof intense work during the last years. Several successful
models have emerged, such as Independent Component Anal-
ysis (ICA) [1], Sparse Decompositions (SD) [2] and Com-
putational Auditory Scene Analysis (CASA) [3]. However, it
is still hard to evaluate an algorithm or to compare several
algorithms because of the lack of appropriate performance
measures and common test sounds, even in the very simple
case of linear instantaneous mixtures. In this article we design
new numerical performance criteria that can help evaluate and
compare algorithms when applied on usual BASS problems.
Before we present these, let us first describe the problems
considered and discuss the existing performance measures and
their drawbacks.
A. BASS general notations
The BASS problem arises when one or several microphones
record a sound that is the mixture of sounds coming from
several sources. For simplicity, we consider here only linear
time-invariant mixing systems. If we denote by sj(t) the signal
emitted by the j-th source (1 ≤ j ≤ n), xi(t) the signal
recorded by the i-th microphone (1 ≤ i ≤ m) and aij(τ)
the (causal) source-to-microphone filters, we have xi(t) =∑n
j=1
∑+∞
τ=0 aij(τ)sj(t − τ) + ni(t), where ni(t) is some
Submitted to IEEE Transactions on Speech and Audio Processing on June
9th 2004. Revised on February 1st 2005. Accepted on May 3rd 2005.
Emmanuel Vincent is with Queen Mary, University of London, Elec-
tronic Engineering Department, Mile End Road, London E1 4NS (United
Kingdom) (Phone: +44 20 7882 5528, Fax: +44 20 7882 7997, Email:
emmanuel.vincent@elec.qmul.ac.uk). Rémi Gribonval is with IRISA, Campus
de Beaulieu, F-35042 Rennes Cedex (France) (Phone: +33 2 9984 2506,
Fax: +33 2 9984 7171, Email: remi.gribonval@irisa.fr). Cédric Févotte is
with Cambridge University Engineering Department, Trumpington Street,
Cambridge CB2 1PZ (United Kingdom) (Phone: +44 12 2376 5582, Fax:
+44 12 2333 2662, Email: cf269@eng.cam.ac.uk)
additive sensor noise. This m × n mixture is expressed more
conveniently using the matrix of filters formalism as
x = A ? s + n. (1)
where ? denotes convolution. In the following, variables
without time index will denote batch sequences, e.g. x =
[x(0), . . . ,x(T−1)]. Bold letters will be used for multichannel
variables, such as the vector of observations x, the vector
of sources s, or the mixing system A, and plain letters for
monochannel variables, such as the j-th source sj .
B. BASS applications and difficulty levels
BASS covers many applications [4], and the criteria used
to assess the performance of an algorithm depend on the
application. Sometimes the goal is to extract source signals
that are listened to, straight after separation or after some
post-processing audio treatment. Sometimes, it is to retrieve
source features and/or mixing parameters to describe complex
audio scenes in a way related to human hearing. In this
paper, we focus on the most common task addressed by BASS
algorithms: Source Extraction.
Source Extraction consists in extracting from a mixture
one or several mono source signals sj . Examples include
the denoising and dereverberation of speech for auditory
protheses and the extraction of interesting sounds in musical
excerpts for electronic music creation. Without specific prior
information about the sources s or the mixing system A this
problem suffers from well-known theoretical indeterminacies
[1], [5]. Generally the sources can only be recovered up to
a permutation and arbitrary gains, but further indeterminacies
may exist in convolutive mixtures (e.g. up to a filter).
Source Extraction can be addressed at various difficulty
levels depending on the structure of the mixing system [6],
[7]. A first difficulty criterion is the respective number of
sources and sensors. In noiseless determined instantaneous
mixtures (i.e. when m = n) there exists a time-invariant
linear demixing system W = A−1. After W has been
estimated, the sources can be simply recovered as s = Wx. In
noiseless under-determined mixtures (i.e. when m < n), this
is not possible anymore since the equation x = As has an
affine set of solutions. This non trivial indeterminacy can be
removed using knowledge about the sources, such as sparse
priors [2]. A second difficulty criterion is the length of the
mixing filters. Many algorithms for instantaneous noiseless
determined mixtures provide near perfect results [1], [2], [8].
But convolutive mixtures still raise challenging theoretical
issues such as the identifiability of the sources up to gain and
technical difficulties like the estimation of long mixing filters
in short duration mixtures.
2
C. Existing performance measures and their limitations
Some performance measures for Source Extraction have
already been defined in the literature. A first kind of measure
assumes that the estimated sources ŝ have been recovered
by applying a time-invariant linear demixing system W to
the observations x. The global system B = W ? A verifies
ŝ = B ? s. The quality of ŝj is then measured by the row
Inter-Symbol Interference [7]
ISIj :=
∑
j′,τ |Bjj′(τ)|
2 − maxj′,τ |Bjj′(τ)|
2
maxj′,τ |Bjj′(τ)|2
. (2)
ISIj is always positive and equal to zero only when ŝj is
equal to the true source sj′ up to a gain and a delay τ
with (j′, τ) = arg maxj′,τ |Bjj′(τ)|2. This criterion and other
similar ones [9] are relevant, but cannot be applied to under-
determined BASS problems because a perfect time-invariant
demixing system W does not exist generally. Moreover even
in determined BASS it is possible to use other separation
schemes than time-invariant linear demixing. A second kind
of measure consists in comparing directly ŝj and sj , paying
attention to the indeterminacies of the task. The gain indeter-
minacy can be handled by comparing L2-normalized versions
of the sources with the relative square distance [6], [10], [2]
D := min
=±1
∥∥∥∥
ŝj
‖ŝj‖
− 
sj
‖sj‖
∥∥∥∥
2
. (3)
This measure is also relevant since it is always positive and
equal to zero only when ŝj equals sj up to a gain. However
D takes at most the value D = 2, even in the worst case
where the permutation indeterminacy has been badly solved
and where ŝj equals another source sj′ orthogonal to sj . One
would then desire a distortion D = +∞. More generally D
evaluates bad results rather coarsely. For example ŝj = sj′
and ŝj = sj′/‖sj′‖ + 0.02 sj/‖sj‖ lead to similar measures
D = 2 and D ≈ 1.96 but are perceived quite differently.
These performance measures suffer from further limitations.
Both consider only the case where ŝj has to be recovered
up to a permutation and a gain. But in some applications
it may be relevant to allow more or less distortions, not
necessarily related to the theoretical indeterminacies of the
problem. For example in hi-fi musical applications it may be
important to recover the sources up to a simple gain since
arbitrary filtering modifies the timbre of musical instruments.
On the contrary in speech applications some filtering distortion
may be allowed because low-pass filtered speech is generally
still intelligible. Moreover both measures provide a single
performance criterion containing all estimation errors. But
in audio applications it is important to measure separately
the amount of interferences from non-wanted sources, the
amount or remaining sensor noise and the amount of “bur-
bling” artifacts (also termed “musical noise”). Such artifacts
are often considered as a more annoying kind of error than
interferences, that are themselves more annoying than sensor
noise. Many separation methods for under-determined BASS
problems produce few interferences but many artifacts [11],
[12], [13], and this cannot be described by a single criterion.
D. Overview of our proposals
The goal of this article is to design new performance criteria
that can be applied on all usual BASS problems and overcome
the limitations above. The only assumptions we make is that
• the true source signals and noise signals (if any) are
known,
• the user chooses a family of allowed distortions F
according to the application (but independently of the
kind of mixture or the algorithm used).
The mixing system and the demixing technique do not need
to be known.
Separate performance measures are computed for each
estimated source ŝj by comparing it to a given true source
sj . Note that the measures do not take into account the
permutation indeterminacy of BASS. If necessary, ŝj may
be compared with all the sources (sj′)1≤j′≤n and the “true
source” may be selected as the one that gives the best results.
The computation of the criteria involves two successive
steps. In a first step, we decompose ŝj as
ŝj = starget + einterf + enoise + eartif , (4)
where starget = f(sj) is a version of sj modified by an
allowed distortion f ∈ F , and where einterf , enoise and
eartif are respectively the interferences, noise and artifacts
error terms. These four terms should represent the part of ŝj
perceived as coming from the wanted source sj , from other
unwanted sources (sj′)j′ 6=j , from sensor noises (ni)1≤i≤m,
and from other causes (like forbidden distortions of the sources
and/or “burbling” artifacts). In a second step, we compute
energy ratios to evaluate the relative amount of each of these
four terms either on the whole signal duration or on local
frames.
E. Structure of the article
The rest of the article has the following structure. In
Section II we show how to decompose ŝj and compute the per-
formance measures when F is the set of time-invariant gains
distortions (this covers our preliminary proposals introduced
in [14]). In Section III we extend these results to the case
where F contains time-varying and/or filtering distortions. In
Section IV we test the measures on several BASS problems. In
Section V we discuss their relevance for algorithm evaluation
and comment their correlation with subjective performance on
informal listening tests. Finally we conclude in Section VI by
pointing out further perspectives about BASS evaluation and
introducing our on-line evaluation database BASS-dB [15].
II. PERFORMANCE CRITERIA FOR TIME-INVARIANT GAINS
ALLOWED DISTORTIONS
We propose in this section performance criteria for the most
usual case when the only allowed distortions on ŝj are time-
invariant gains. We first show how to decompose ŝj into four
terms as in (4) and then we define relevant energy ratios
between these terms.
3
Let us denote in the following 〈a, b〉 :=
∑T−1
t=0 a(t)b(t) the
inner product between two possibly complex-valued1 signals
a and b of length T , where b is the complex conjugate of b,
and ‖a‖2 := 〈a, a〉 the energy of a.
A. Estimated source decomposition by orthogonal projections
When A is a time-invariant instantaneous matrix and when
the mixture is separated by applying a time-invariant instan-
taneous matrix W, ŝj can be decomposed as
ŝj = (WA)jjsj +
∑
j′ 6=j
(WA)jj′sj′ +
m∑
i=1
Wjini. (5)
Since (WA)jj is a time-invariant gain, it seems natural to
identify the three terms of this sum with starget, einterf and
enoise respectively (eartif = 0 here). However (5) cannot be
used as a definition of starget, einterf , enoise and eartif since
the mixing and demixing systems are unknown. Also the two
first terms of (5) may not be perceived as separate sound
objects when a nonwanted source sj′ is highly correlated
with the wanted source sj .
Instead, the decomposition we propose is based on orthog-
onal projections. Let us denote Π{y1, . . . , yk} the orthogonal
projector onto the subspace spanned by the vectors y1, . . . , yk.
The projector is a T ×T matrix, where T is the length of these
vectors. We consider the three orthogonal projectors
Psj := Π{sj}, (6)
Ps := Π{(sj′)1≤j′≤n}, (7)
Ps,n := Π{(sj′)1≤j′≤n, (ni)1≤i≤m}. (8)
And we decompose ŝj as the sum of the four terms
starget := Psj ŝj , (9)
einterf := Psŝj − Psj ŝj , (10)
enoise := Ps,nŝj − Psŝj , (11)
eartif := ŝj − Ps,nŝj . (12)
The computation of starget is straightforward since it in-
volves only a simple inner product: starget = 〈ŝj , sj〉sj/‖sj‖2.
The computation of einterf is a bit more complex. If
the sources are mutually orthogonal, then einterf =∑
j′ 6=j〈ŝj , sj′〉sj′/‖sj′‖
2. Otherwise, if we use a vector c
of coefficients such that Psŝj =
∑n
j′=1 cj′sj′ = c
H
s
(where (·)H denotes Hermitian transposition), then c =
R
−1
ss
[〈ŝj , s1〉, . . . , 〈ŝj , sn〉]
H , where Rss is the Gram matrix of
the sources defined by (Rss)jj′ = 〈sj , sj′〉. The computation
of Ps,n proceeds in a similar fashion, however most of the
time we can make the assumption that the noise signals are
mutually orthogonal and orthogonal to each source, so that
Ps,nŝj ≈ Psŝj +
∑m
i=1〈ŝj , ni〉ni/‖ni‖
2.
1Audio signals are real-valued, but it is costless to express our performance
criteria in the slightly more general complex setting which might be useful
for other types of signals.
B. From estimated source decomposition to global perfor-
mance measures
Starting from the decomposition of ŝj in (6-12), we now
define numerical performance criteria by computing energy
ratios expressed in decibels (dB). We define the Source to
Distortion Ratio
SDR := 10 log10
‖starget‖
2
‖einterf + enoise + eartif‖2
, (13)
the Source to Interferences Ratio
SIR := 10 log10
‖starget‖
2
‖einterf‖2
, (14)
the Sources to Noise Ratio
SNR := 10 log10
‖starget + einterf‖
2
‖enoise‖2
, (15)
and the Sources to Artifacts Ratio
SAR := 10 log10
‖starget + einterf + enoise‖
2
‖eartif‖2
. (16)
These four measures are inspired by the usual definition
of the SNR, with a few modifications. For instance the
definition of the SNR involving the term starget + einterf at
the numerator aims at making it independent of the SIR.
Indeed consider the case of an instantaneous noisy 2 × 2
mixture where ŝ1 =  s1 + s2 + enoise with ‖ s1‖  ‖s2‖
and ‖enoise‖ ≈ ‖ s1‖. Then ŝ1 is perceived as dominated
by the interfering signal, with the noise energy making an
insignificant contribution. This is consistent with SIR ≈ −∞
and SNR ≈ +∞ using our definitions. A SNR defined by
10 log10(‖starget‖
2/‖enoise‖
2) would give SNR ≈ 0 instead.
Similarly, the SAR is independent of the SIR and the SNR
since the numerator in (16) includes the interferences and noise
terms as well.
Note that the numerical precision of the measures is lower
for high performance values than for low ones. For example a
high SDR means that the denominator in (13) is very small, so
that small constant-amplitude errors in starget (due to signal
quantization) result in large SDR deviations. In particular,
when the signals correspond to sound files, the precision of
the results depends on the number of bits per sample.
C. Local performance measures
When the powers of starget, einterf , enoise and eartif vary
across time, the perceived separation quality also varies ac-
cordingly. We take this into account by defining local numer-
ical performance measures in the following way.
First we compute starget, einterf , enoise and eartif as in (6-
12). Then, denoting w a finite length centered window, we
compute the windowed signals srtarget, e
r
interf , e
r
noise and e
r
artif
centered in r, where srtarget(t) = w(t − r)starget(t) and so
on. Finally, for each r we compute the local measures SDRr,
SIRr, SNRr and SARr as in (13-16) but replacing the original
terms by the windowed terms centered in r.
SDRr, SIRr, SNRr and SARr thus measure the separation
performance on the time frame centered in r. All these values
4
can be visualized more globally by plotting them against r or
by summarizing them into cumulative histograms [13]. Global
performance measures can also be defined in the spirit of
segmental SNR [16]. The shape of the window w has not
much importance generally, only its duration is relevant. Thus
a rectangular window may be used for simplicity.
D. Comparison with existing performance measures
The new performance measures solve most of the problems
encountered with existing measures discussed in Section I-C.
First the computation does not rely on the assumption that
a particular type of demixing system or algorithm is used.
The only assumption is that ŝj has to be recovered up to a
time-invariant gain. Measures for other allowed distortions are
proposed in Section III.
Secondly the SDR has better properties than D. Simple
calculus shows that both measures are identical up to a one-
to-one mapping 10−SDR/10 = D(4 − D)/(2 − D)2. However,
contrary to −10 log10 D, the SDR is not lower-bounded:
SDR = −∞ when starget = 0 and evaluation of bad results
is less coarse [14].
Thirdly four criteria are proposed instead of a single one.
The SIR, SNR and SAR allow to distinguish between estima-
tion errors that are mostly dominated by interferences, noise
or artifacts. This is verified on test mixtures in Section IV.
III. PERFORMANCE CRITERIA FOR OTHER ALLOWED
DISTORTIONS
A. Which equations have to be modified ?
After having defined performance measures for time-
invariant gains allowed distortions, we consider now similar
measures for other allowed distortions. Much of the work
done in the previous section is still relevant here and only
the definitions of the orthogonal projectors in (6-8) have to be
modified.
Indeed the two steps consisting in decomposing ŝj in four
terms and in computing energy ratios between these terms do
not depend on each other. Since the kind of allowed distortion
is not used in the second step, the performance measures are
always defined by (13-16), whatever the allowed distortion is.
Moreover the decomposition of ŝj can also often be defined
by (9-12), but using other orthogonal projectors depending
on the allowed distortions. In the following we present suc-
cessively the projectors used to decompose ŝj when filtering
and/or time-varying distortions are allowed.
B. Time-invariant filters allowed distortions
When time-invariant filters are allowed, starget is not a
scaled version of sj anymore, but a filtered version expressed
as starget(t) =
∑L−1
τ=0 h(τ) × sj(t − τ). If we express this
in terms of subspaces, starget does not generally belong to
the subspace spanned by sj but to the subspace spanned by
delayed versions of sj . So we can define starget by projecting
ŝj on this new subspace.
We denote by sτj and n
τ
i the source signal sj and the noise
signal ni delayed by τ , so that sτj (t) = sj(t− τ) and n
τ
i (t) =
ni(t−τ). To avoid multiple definitions due to boundary effects,
we consider the support of all signals to be [0, T +L−2] where
[0, T −1] is the original support of the signals and L−1 is the
maximum delay allowed. We define the decomposition using
the three projectors
Psj := Π{(s
τ
j )0≤τ≤L−1}, (17)
Ps := Π{(s
τ
j′)1≤j′≤n,0≤τ≤L−1}, (18)
Ps,n := Π{{(s
τ
j′)1≤j′≤n, (n
τ
i )1≤i≤m}0≤τ≤L−1}, (19)
The computation of the projections again involves inversion
of Gram matrices. The Gram matrix corresponding to Psj
is the empirical auto-correlation matrix of sj defined by
(Rsjsj )ττ ′ = 〈s
τ
j , s
τ ′
j 〉. The Gram matrix associated with Ps
has a symmetric block-Toeplitz structure, where the blocks
on the τ -th diagonal are the empirical auto-correlation matrix
of the sources at lag τ defined by (Rss(τ))jj′ = 〈sj , sτj′〉.
C. Time-varying gains allowed distortions
When time-varying gains distortions are allowed, starget
is equal to sj multiplied by a slowly time-varying gain. We
parameterize this gain as g(t) =
∑U−1
u=0 αuv(t − uT
′), where
v is a positive kernel (i.e. a window) of length L′ and T ′
the hopsize in samples between two successive “breakpoints”.
When v is a rectangular window and L′ = T ′, this parameteri-
zation yields piecewise constant gains with breakpoints at uT ′,
but choosing a smoother kernel makes it possible to get more
smoothly varying gains. This gives starget(t) = g(t)sj(t) =∑U−1
u=0 αu × v(t − uT
′)sj(t). Thus starget belongs to the
subspace spanned by versions of sj windowed by the kernel
v. Note that this use of windowed source signals has no link
with the the computation of local performance measures from
windowed decomposed signals in Section II-C. We emphasize
again that the decomposition of ŝj and the computation of
energy ratios are separate steps.
We define the windowed source signals (suj )0≤u≤U−1 and
the windowed noise signals (nui )0≤u≤U−1 of support [0, T−1]
by suj (t) = v(t−uT
′)sj(t) and nui (t) = v(t−uT
′)ni(t). The
projectors for decomposition are given by
Psj := Π{(s
u
j )0≤u≤U−1}, (20)
Ps := Π{(s
u
j′)1≤j′≤n,0≤u≤U−1}, (21)
Ps,n := Π{{(s
u
j′)1≤j′≤n, (n
u
i )1≤i≤m}0≤u≤U−1}. (22)
In order to guarantee the natural property Psj sj = sj
(i.e. SDR = +∞ as expected in the particular case where
ŝj = sj), we enforce the condition that
∑U−1
u=0 v(t − uT
′)
is a constant for all t. When this is verified, sj belongs
to the subspace spanned by (suj )0≤u≤U−1 because sj =∑U−1
u=0 s
u
j /
∑U−1
u=0 v(t−uT
′). This condition always holds true
when T ′ = 1, but other values of T ′ may work depending on
the kernel v. For example if v is a triangular window and L′
is a multiple of 2, then T ′ = L′/2 also works.
D. Time-varying filters allowed distortions
Finally, when time-varying filters distortions are allowed,
the decomposition of ŝj is made by combining the ideas of
5
the two previous subsections. The estimated source starget is
expressed as a version of sj “convolved” by a slowly time-
varying filter. Using the notations of the previous subsec-
tions, this results in starget(t) =
∑L−1
τ=0 h(τ, t)sj(t − τ) =∑L−1
τ=0
∑U−1
u=0 ατu ×v(t−uT
′)sj(t− τ). Thus starget belongs
to the subspace spanned by delayed versions of sj windowed
by the kernel v.
We compute the windowed delayed source signals
(sτuj )0≤τ≤L−1,0≤u≤U−1 and the windowed delayed noise
signals (nτui )0≤τ≤L−1,0≤u≤U−1 of support [0, T + L − 2]
by windowing delayed signals: sτuj (t) = v(t − uT
′)sτj (t)
and nτui (t) = v(t − uT
′)nτi (t). Note that the reverse order
computation (passing windowed signals through delay lines)
is not equivalent and results in other projections generally. We
define the decomposition by the projectors
Psj := Π{(s
τu
j )0≤τ≤L−1,0≤u≤U−1}, (23)
Ps := Π{(s
τu
j′ )1≤j′≤n,0≤τ≤L−1,0≤u≤U−1}, (24)
Ps,n := Π{{(s
τu
j′ )1≤j′≤n, (n
τu
i )1≤i≤m}0≤τ≤L−1,0≤u≤U−1}.
(25)
IV. EVALUATION EXAMPLES
In order to assess the relevance of our performance mea-
sures, we made tests on a few usual BASS problems. The
separated sources were either simulated from a known decom-
position or extracted from the mixtures with existing BASS
algorithms.
In this section we present the results of performance mea-
surement on three noiseless mixtures of three musical sources.
The sources are 16 bits sound files of 2.4 s, sampled at 8 KHz
(T = 19200) and normalized. s1 is cello, s2 drums and s3
piano. The three mixtures are 16 bits sound files containing
an instantaneous 2×2 mixture, a convolutive 2×2 mixture and
an instantaneous 2 × 3 mixture. These mixtures were chosen
because they have very different difficulty levels and they act
as typical mixtures within the large amount of usual audio
mixtures. We also chose some typical existing algorithms to
separate these mixtures to show that the performance measures
are relevant on “real life” data.
For each mixture and each algorithm the (non quantized)
estimated sources are decomposed using different allowed
distortions and the performance measures are computed. The
results are summarized in Tables II, III and IV. The different
kinds of allowed distortions and corresponding decompositions
are denoted TI Gain, TI Filt, TV Gain and TV Filt respectively.
The values of the decomposition parameters are listed in
Table I. Their choice is discussed in Section V based on
informal listening tests.
The sound files corresponding to these examples are avail-
able for listening on http://www.irisa.fr/metiss/
demos/bssperf/. This demo web page provides the sound
files of the mixture x, the sources s, the first estimated source
ŝ1, and also the sound files of starget, einterf , enoise and eartif
from the decomposition of ŝ1. Sound files of ŝ2, ŝ3 and their
decompositions are not provided for the sake of legibility. We
emphasize that listening to these sounds and comparing with
the related performance figures is the best way to evaluate the
meaningfulness of our proposals.
TABLE I
PARAMETER VALUES USED FOR DECOMPOSITION (8 KHZ SAMPLE RATE).
Allowed Delays Time frames
distortion L v L′ T ′
TI Gain N/A N/A
TI Filt 256 N/A
TV Filt 64 Rect 1600 1600
A. Instantaneous 2 × 2 mixture
Our first example is a stereo instantaneous mixture of s1
and s2, obtained with the mixing matrix
A =
[
0.5 1
1 0.5
]
.
We solve this problem by estimating a demixing matrix
with two different ICA methods : by using non Gaussian
distributions and mutual independence of the sources with
JADE [1], and by finding zones in the time-frequency plane
where only one source is present with TFBSS [8] (used with
64 time frames and 1024 frequency bins as input parameters).
The performance measures are shown in Table II for TI
Gain decompositions. Results with other decompositions
differ from less than 2 dB. Since the global mixing-unmixing
system WA is known, we also compute for comparison the
System SIR (SSIR) which is the power ratio between the two
first terms of (5).
As expected with sources estimated by time-invariant linear
demixing, no artifacts come into play: SAR ≈ +∞ up to
numerical precision. The estimation error is dominated by
interferences and SDR ≈ SIR. Moreover, the SIR is higher for
TFBSS than for JADE. This result is corroborated by the fact
that the demixing matrix estimated with TFBSS is closer to the
true demixing matrix than with JADE. Also, as expected the
SSIR is very close to the SIR, because the correlation between
the sources 〈s1, s2〉 = −0.0055 is small.
TABLE II
EVALUATION OF AN INSTANTANEOUS 2 × 2 MIXTURE.
Method
Allowed SDR (dB) SIR (dB) SAR (dB) SSIR (dB)
distortion bs1 bs2 bs1 bs2 bs1 bs2 bs1 bs2
JADE TI Gain 26 25 26 25 72 73 26 25
TFBSS TI Gain 37 34 37 34 73 73 37 34
B. Convolutive 2 × 2 mixture
Our second example is a convolutive mixture of s1 and
s2 made with 256 tap filters. The problem is solved by a
frequential domain ICA method using 256 sub-bands and
separating the mixture with JADE [1] in each sub-band.
The usual “permutation problem” [5] is encountered when
building estimated sources from extraction results in each
sub-band. We test two methods to address this problem:
the method outlined in [5] and an oracle (i.e. choice of
the optimal permutations knowing the true sources). The
6
corresponding algorithms are named Frequential ICA (FICA)
or Oracle Frequential ICA (OFICA). Both methods do not
aim at recovering the sources s1 and s2 but their images on
the first channel a11 ? s1 and a12 ? s2. Thus the estimated
sources may be at best filtered versions of the true sources.
The performance measures are shown in Table III for three
different decompositions. We compute again the SSIR from
(5), with WA now containing filters instead of gains.
Different conclusions arise depending on the decomposition.
The TI Gain decomposition results in low SDRs for both
methods and SDR ≈ SAR. Many artifacts arise due to
forbidden (filter) distortions of the sources. On the contrary
the TI Filt decomposition outputs a high SDR for OFICA
and a medium SDR for FICA with SDR ≈ SIR. Artifacts are
smaller because filter distortions are allowed, and interferences
are larger for FICA than for OFICA because the use of oracle
information in OFICA prevents bad pairing of sub-bands. The
TV Filt decomposition leads to intermediate results. Short (64-
tap) filter distortions are allowed, but longer filter distortions
are not, thus some of the filter distortions on the estimated
sources are counted towards artifacts. Again the SSIR is very
close the SIR computed using the TI Filt decomposition,
because the correlation between delayed versions of different
sources is also small.
It is also interesting to study the evolution of the perfor-
mance measures across time. For example Fig. 1 plots the
local SIR for ŝ1 (estimated with FICA) using TI Filt. We see
that the actual performance measure varies a lot, which cannot
be explained by a single global SIR.
TABLE III
EVALUATION OF A CONVOLUTIVE 2 × 2 MIXTURE.
Method
Allowed SDR (dB) SIR (dB) SAR (dB) SSIR (dB)
distortion bs1 bs2 bs1 bs2 bs1 bs2 bs1 bs2
FICA
TI Gain -11 -16 7 12 -10 -16
6 16TI Filt 6 14 6 17 19 17
TV Filt 3 -2 8 9 5 -1
OFICA
TI Gain -10 -13 15 22 -10 -13
10 17TI Filt 10 16 10 18 19 19
TV Filt 5 -2 15 10 5 -1
C. Instantaneous 2 × 3 mixture
Our third example is an instantaneous mixture of s1, s2 and
s3 computed with the mixing matrix
A ≈
[
0.92 1.40 1.05
0.36 1.30 2.36
]
.
To solve this problem, we represent the two mixture channels
in a domain where the sources exhibit a sparse behavior,
and then the mixing matrix and the sources are estimated
by (nonlinear) clustering of the ratios of the representation
coefficients between the channels. Two algorithms are tested:
a clustering of the Short Time Fourier Transform (STFT)
called DUET [12] (using a 256 sample Hanning window and
a 192 sample hopsize for STFT computation) and a Matching
0 0.5 1 1.5 2
−20
0
20
time (s)
S
IR
 (d
B
)
−20 0 20
0
50
100
SIR (dB)
pe
rc
en
t
Fig. 1. Local SIR for bs1 estimated by FICA and TI Filt decomposition
in the 2 × 2 convolutive mixture. Hanning windows of length 100 ms and
overlapping 75 ms are used. The SIR is plotted against time in the upper plot
and summarized in a cumulative histogram in the lower plot.
Pursuit Clustering (MPC) [11] (using 10 000 Gabor atoms
with truncated Gaussian envelope). The performance measures
are shown in Table IV for two different decompositions.
Unlike in the previous experiments, it does not seem possible
to display any sort of “System SIR” for the MPC algorithm,
since the result of the separation is not a linear function of the
input sources. In a sense, this perfectly illustrates a situation
where it is necessary to have at hand performance measures
such as the ones we define, that is to say measures which
do not rely on a particular type of separation algorithm, but
simply try to compare the estimated signals with the target
ones.
This time the choice of the decomposition has less influence
on the results. Both methods estimate the sources essentially
without filter distortions but with “burbling” artifacts due to
source overlap in the representation domain. Thus SDRs are
low for both methods and SDR ≈ SAR. Note that MPC
leads to better performance than DUET, particularly for ŝ3.
Indeed the use of an overcomplete dictionary in MPC makes
the source representations sparser and limits source overlap.
TABLE IV
EVALUATION OF AN INSTANTANEOUS 2 × 3 MIXTURE.
Method
Allowed SDR (dB) SIR (dB) SAR (dB)
distortion bs1 bs2 bs3 bs1 bs2 bs3 bs1 bs2 bs3
STFTC
TI Gain 2 4 4 15 9 29 3 7 4
TI Filt 5 4 6 14 7 19 6 8 6
TV Filt 6 5 8 11 7 15 8 11 9
MPC
TI Gain 4 8 15 19 27 31 4 8 15
TI Filt 5 9 16 13 17 27 5 9 16
TV Filt 6 9 16 14 14 23 7 11 17
V. DISCUSSION
Before we conclude, let us summarize in this section the
results of the evaluation examples. We discuss the relevance of
7
the proposed performance measures for algorithm evaluation
and comparison. Then we describe how they could possibly
be modified to explain subjective auditory assessments.
A. Relevance for algorithm evaluation and comparison
The main result of the previous section is that the SDR,
SIR, SNR and SAR were found to be relevant for the
evaluation of an algorithm and the comparison of several
algorithms. Indeed, given a family of allowed distortions, the
SIR and SAR were shown to be valid performance measures
regarding two separate goals: rejection of the interferences
and absence of forbidden distortions and “burbling” artifacts.
Other experiments proved that the SNR was also valid for a
third goal: rejection of the sensor noise. Finally the SDR was
shown to be valid as a global performance measure in case
these three goals are equally important.
Another important result is that the measures were found
to depend a lot on the number of delays and time frames
chosen for decomposition. Experimentally the more distortions
are allowed the higher the SDRs are. More rigorously, when
F and F ′ are two families with F ⊂ F ′, the SDR of a given
estimated source ŝj is higher allowing distortions in F ′ than in
F . Indeed the projection subspaces verify {f(sj), f ∈ F} ⊂
{f(sj), f ∈ F
′} and thus ‖ŝj − Psj ŝj‖ is smaller allowing
distortions in F ′ than in F .
This confirms our main postulate that the evaluation of
the performance of an algorithm only makes sense given a
family of allowed distortions. This can be seen as a nice
property if the distortions allowed for the desired application
correspond to one of the families presented in sections II and
III with a precisely known number of frequency sub-bands
and time frames. But this is annoying when one has no
idea about which distortions to allow. In that case, we
cannot “recommend” a family of allowed distortions more
than another one: the “best” choice really depends on the
application.
Finally an interesting result is that in the previous section
the results of algorithm classification according to mean SDR
were always the same whatever decomposition was used. We
make the hypothesis that this is not a coincidence and that
the classification order is rather independent of the family of
allowed distortions. Of course this hypothesis is based on very
few experiments actually, but we think it would be interesting
to validate or infirm it using more data. If it was true then
algorithm classification would be greatly simplified. Indeed
it would be unnecessary to test many families of allowed
distortions before providing a global result: a single one would
suffice.
B. Relevance towards subjective performance measures
Another interesting question is to study the relationship
between the proposed measures and subjective auditory
performance assessments. In theory this should be done
using carefully calibrated psycho-acoustical listening tests.
We could first ask the listeners how they describe the results
with their own words, and check whether they use synonyms
of “interferences” and “artifacts” or not. Then we could go
on with more constrained tests, such as broadcasting pairs
of results and asking listeners if they hear more or less
“interferences” and “artifacts” in the first sound of each pair.
Because performing these listening tests is not a trivial task,
we give here only a few remarks based on our own listening
experience.
If we admit that the ear splits estimated sources into the
same four components than our analytical decomposition, we
may define interferences, noise and artifacts as “what I hear
coming from the other sources”, “what I hear coming from
sensor noise” and “what I hear to be burbling artifacts”. With
this definition of auditory performance measures, we remark
that the SIR, SNR and SAR seem to be better related to the au-
ditory notion of interferences, noise and artifacts using the TV
Filt decomposition. Indeed decompositions using very few de-
lays and time frames are not always able to extract all the per-
ceived interferences inside einterf but split them between einterf
and eartif . On the contrary decompositions with too many de-
lays and/or time frames sometimes put “burbling” artifacts into
einterf and nothing into eartif . The parameters we chose for the
TV Filt decomposition (F = 64 and L′ = 200 ms) appear to
be a good compromise in many experiments. When the TI Filt
decomposition is used, a higher number of delays (L = 256)
seems preferable. Of course these choices cannot be proved
using physical or mathematical arguments, but readers may
check this partially by listening to the previous examples on
http://www.irisa.fr/metiss/demos/bssperf/.
If we also admit that the ear associates energy prioritarily to
the true source rather than to interferences in the case where
some sources are similar, then the components starget, einterf ,
enoise and eartif estimated by the “greedy” decomposition of
(9-12) should be closer to the perceptual components than
those estimated by the simultaneous decomposition of (5).
Indeed the “greedy” decomposition scheme takes into account
similarity between sources as measured by correlation. We
think that this measures part of the perceptual similarity
between sources, but not all. For instance two white noises
sound the same even when they are orthogonal.
Some other auditory properties cannot be explained by
the proposed measures. First the high values of SIR, SNR
and SAR have limited auditory signification. For example
the two instantaneous mixtures of Section IV-A have very
different SIRs but can hardly be distinguished. Also the SDR
does not measure the total perceived distortion. In the case
where ŝj is a slightly low-pass filtered version of sj , then
SDR ≈ +∞ using TV Filt decomposition but low-pass
filtering is perceived as timbre distortion. This fourth kind
of error (besides interferences, noise and “burbling” artifacts)
could be dealt with using an additional performance measure,
such as Itakura-Saito distance or cepstral distortion [16].
An interesting idea to mimic the auditory treatments would
be to pass the sources and noises through an auditory filter
bank. Then each estimated source could be decomposed on
subspaces spanned by the auditory sub-bands by handling
differently sinusoidal and noise-like zones and by taking into
8
account auditory masking phenomena. Similar performance
measures already exist in the fields of denoising and com-
pression [13], [17].
VI. CONCLUSION AND PERSPECTIVES
In this article we discussed the question of performance
measurement in BASS. Given a set of allowed distortions,
we evaluated the quality of an estimated source by four
measures called SDR, SIR, SNR and SAR. Experiments
involving typical mixtures and existing algorithms showed
that these measures were relevant for algorithm evaluation
and comparison. With respect to other existing performance
measures, the main improvement is that we do not assume a
particular separation algorithm nor a limited set of allowed
distortions. Moreover we evaluate separately the amount of
interferences, remaining sensor noise and artifacts, which is
a crucial point for evaluation in under-determined mixtures.
Our performance measures are implemented within a
MATLAB toolbox named BSS EVAL distributed online under
the GNU Public License [18].
The main application of this work is to rank existing BASS
algorithms according to their performance on the same test
data. To help this we built a web database called BASS-
dB [15] that classifies the test mixtures according to the
Source Extraction subtasks [4]. These subtasks corresponds
to different structures of the mixing system defined by the
number of sources and sensors (2×2, 2×5, 5×5, 7×5, etc)
and the kind of mixing filters (gain, delay, gain+delay, live-
recorded room impulse responses). BASS-dB already provides
some test mixtures and performance results, but we encourage
people to feed it with their own mixtures and results.
We hope the BASS community will consider this issue,
so that BASS methods can be compared within a shared
framework. Among the results, the best BASS methods
could be identified and selected for further improvement.
Or objective difficulty criteria could be defined to determine
for example whether the difficulty in an under-determined
convolutive mixture rather comes from convolution or
from under-determination. Our hypothesis that algorithm
classification results are rather independent of allowed
distortions could also be validated or infirmed.
Among the possible generalizations to this work, we are
currently studying the derivation of psycho-acoustical perfor-
mance measures and performance measures for the similar
BASS tasks of Source Spatial Image Extraction and Remixing
[4], that also involve listening to the extracted sources.
ACKNOWLEDGMENTS
This work was part of the Junior Researchers Project
“Resources for Audio Signal Separation” funded by GdR
ISIS (CNRS) and was mainly performed when Emmanuel
Vincent was with IRCAM, Paris (France). Cédric Févotte
acknowledges support of the European Commission funded
Research Training Network HASSIP (HPRN-CT-2002-00285).
The authors would like to thank Laurent Benaroya, Frédéric
Bimbot, Xavier Rodet, Axel Röbel and Éric Le Carpentier for
their helpful comments.
REFERENCES
[1] J.-F. Cardoso, “Blind source separation : statistical principles,” in Pro-
ceedings of the IEEE, vol. 9, no. 10, oct. 1998, pp. 2009–2025, special
issue on blind identification and estimation.
[2] M. Zibulevsky and B. Pearlmutter, “Blind source separation by sparse
decomposition in a signal dictionnary,” Neural Computation, vol. 13,
no. 4, 2001.
[3] D. Ellis, “Prediction-driven computational auditory scene analysis,”
Ph.D. dissertation, MIT, june 1996.
[4] E. Vincent, C. Févotte, R. Gribonval, L. Benaroya, A. Röbel, X. Rodet,
F. Bimbot, and E. Le Carpentier, “A tentative typology of audio source
separation tasks,” in Proc. Int. Symposium on ICA and BSS (ICA 03),
Nara, apr. 2003, pp. 715–720.
[5] N. Murata, S. Ikeda, and A. Ziehe, “An approach to blind source sepa-
ration based on temporal structure of speech signals,” Neurocomputing,
vol. 41, no. 1-4, pp. 1–24, 2001.
[6] D. Schobben, K. Torkkola, and P. Smaragdis, “Evaluation of blind signal
separation methods,” in Proc. Int. Symposium on ICA and BSS (ICA 99),
Aussois, jan. 1999, pp. 261–266.
[7] R. Lambert, “Difficulty measures and figures of merit for source
separation,” in Proc. Int. Symposium on ICA and BSS (ICA 99), Aussois,
jan. 1999, pp. 133–138.
[8] C. Févotte and C. Doncarli, “Two contributions to blind source separa-
tion using time-frequency distributions,” IEEE Signal Processing Letters,
vol. 11, no. 3, pp. 386–389, mar. 2004.
[9] T. Takatani, T. Nishikawa, H. Saruwatari, and K. Shikano, “SIMO-
model-based Independent Component Analysis for high-fidelity blind
separation of acoustic signals,” in Proc. Int. Symposium on ICA and
BSS (ICA 03), Nara, apr. 2003, pp. 993–998.
[10] M. V. Hulle, “Clustering approach to square and non-square blind source
separation,” in Proc. IEEE Workshop on Neural Networks for Signal
Processing (NNSP99), aug. 1999, pp. 315–323.
[11] R. Gribonval, “Sparse decomposition of stereo signals with matching
pursuit and application to blind separation of more than two sources from
a stereo mixture,” in Proc. Int. Conf. Acoust. Speech Signal Process.
(ICASSP 02), Orlando, may 2002.
[12] A. Jourjine, S. Rickard, and O. Yilmaz, “Blind separation of disjoint
orthogonal signals: Demixing n sources from 2 mixtures,” in Proc. Int.
Conf. Acoust. Speech Signal Process. (ICASSP 00), vol. 5, Istanbul, june
2000, pp. 2985–2988.
[13] O. Cappé, “Techniques de réduction de bruit pour la restauration
d’enregistrements musicaux,” Ph.D. dissertation, Télécom Paris, 1993.
[14] R. Gribonval, L. Benaroya, E. Vincent, and C. Févotte, “Proposals for
performance measurement in source separation,” in Proc. Int. Symposium
on ICA and BSS (ICA 03), Nara, apr. 2003, pp. 763–768.
[15] R. Gribonval, E. Vincent, and C. Févotte, “BASS-dB: Blind
Audio Source Separation evaluation database.” [Online]. Available:
http://www.irisa.fr/metiss/BASS-dB/
[16] J. Deller, J. Hansen, and J. Proakis, Discrete-time processing of speech
signals. IEEE Press, 2000.
[17] C. Colomes, C. Schmidmer, T. Thiede, and W. Treurniet, “Perceptual
quality assessment for digital audio (PEAQ) : the new ITU standard
for objective measurement of perceived audio quality,” in Proc. AES
17th Int. Conf. on High Quality Audio Coding, Firenze, sept. 1999, pp.
337–351.
[18] C. Févotte, R. Gribonval, and E. Vincent, “BSS EVAL Toolbox
User Guide,” IRISA, Tech. Rep. 1706, 2005. [Online]. Available:
http://www.irisa.fr/metiss/bss eval/
9
Emmanuel Vincent graduated from École Normale
Supérieure, Paris, France in 2001. He obtained the
Ph.D. degree in acoustics, signal processing and
computer science applied to music from the Univer-
sity of Paris-VI Pierre et Marie Curie, Paris, France,
in 2004. He is currently a Research Assistant with
the Centre for Digital Music at Queen Mary, Univer-
sity of London, Electronic Engineering Department,
London, United Kingdom. His research focuses on
structured probabilistic modeling of audio signals
applied to blind source separation, indexing and
object coding of musical audio.
Rémi Gribonval graduated from École Normale
Supérieure, Paris, France in 1997. He received the
Ph.D. degree in applied mathematics from the Uni-
versity of Paris-IX Dauphine, Paris, France, in 1999.
From 1999 until 2001 he was a visiting scholar at the
Industrial Mathematics Institute (IMI) in the Depart-
ment of Mathematics, University of South Carolina,
SC. He is currently a Research Associate with the
French National Center for Computer Science and
Control (INRIA) at IRISA, Rennes, France. His
research interests are in adaptive techniques for the
representation and classification of audio signals with redundant systems, with
a particular emphasis in blind audio source separation.
Cédric Févotte was born in Laxou, France, in 1977
and lived in Tunisia, Senegal and Madagascar until
1995. He graduated from the French engineering
school École Centrale de Nantes and obtained the
Diplôme d’Études Appronfondies en Automatique et
Informatique Appliquée in 2000. He then received
the Diplôme de Docteur en Automatique et Infor-
matique Appliquée de l’École Centrale de Nantes et
de l’Université de Nantes in 2003. Since november
2003 he is a Research Associate with the Signal
Processing Laboratory of Cambridge University En-
gineering Department, United Kingdom. His current research interests concern
statistical signal processing and time-frequency signal representations with
application to blind source separation.

