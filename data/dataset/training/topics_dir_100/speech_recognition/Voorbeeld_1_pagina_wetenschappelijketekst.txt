Intelligent environments, based on computer vision, speech recognition and motion detection 
Abstract. Intelligent environments, also referred to as “smart rooms”, intend to capture, through 
computer vision, speech recognition and motion detection, the intentions and commands of humans 
in the environment. This short paper presents an overview of recent achievements in this area.  
1. Introduction. Today, most interactions with computers are based on communication through a 
mouse and a keyboard. The natural communication channels of humans, be them through speech, 
movement, gesture or facial expression, are most often left unexploited as input to a computer. In 
living environments, such as rooms or cars, intelligent computer systems can support the users to a 
far richer extent. By exploiting novel techniques from Artificial Intelligence, they can enable rich 
forms of communication. This paper surveys the latest breakthroughs on smart rooms developed in 
the Media Laboratory of MIT. 
2. Preliminaries. We assume familiarity with the basic concepts of speech recognition, including 
Hidden Markov Models [2], of computer vision, in particular blob-based detection of humans in 
images [4] and face recognition through Eigenfaces [1], and of maximum likelihood analysis [3], as 
applied in state of the art machine learning. 
3. A five component system for smart rooms. The central component of a smart room is the Person 
Finder. Its function is to detect the presence and determine the location of humans in video streams. 
The system is based on standard blob-based object detection techniques from computer vision. 
However, the accuracy of such techniques is significantly enhanced using models of human 
movement. Based on such models, future locations of the blobs can be accurately predicted, using 
maximum likelihood analysis.  
The second most important component of a smart room is the speech recognition system. Standard 
speech recognition techniques require the human to speak directly into the microphone. In order to 
apply speech recognition for humans moving freely in a noisy room, the smart room uses a large 
number of targetable microphones. The location of the human, determined by Person Finder, targets 
the microphones, resulting in near to optimal speech recognition. 
A next component is the face detection and recognition system. Standard techniques based on 
Eigenfaces are at the heart of this component. However, locating faces is greatly facilitated by Person 
Finder and face models are combined with maximum likelihood analysis to further improve the 
identification. In addition to mere identification of the human, the smart room determines the 
human’s emotional state based on models of facial expressions. This is done in the emotion 
interpretation system. 
Finally, the smart room also interprets the gestures of the human. A novel approach was designed, 
building on techniques from speech recognition. Complex gestures are decomposed into elementary 
movements. Then, methods from speech recognition, where words are identified from sequences of 
phonemes, are transposed to sequences of elementary movements, to identify full gestures.  
4. Conclusions. Currently, five fully operational smart rooms have been developed. Each of these is 
targeted on a different application, ranging from virtual reality, over American Sign Language 
understanding, smart office assistance and patient surveillance, to car driver support. In all 
applications, high accuracy in human computer communication has been demonstrated.  
 
References. 
[1] Belhumeur P. N., Hespanha J.P., Kriegman D., Eigenfaces vs. fisherfaces: Recognition using class 
specific linear projection, Pattern Analysis and Machine Intelligence, IEEE Transactions on 19 (7),  
711-720, 1997, IEEE. 
[2] Rabiner L., A tutorial on hidden Markov models and selected applications in speech recognition, 
Proceedings of the IEEE 77 (2), 257-286, 1989, IEEE. 
[3] Redner R. A., Walker H.F., Mixture densities, maximum likelihood and the EM algorithm, SIAM 
review 26 (2), 195-239, 1984, SIAM. 
[4] Wu B., Nevatia R., Detection and tracking of multiple, partially occluded humans by bayesian 
combination of edgelet based part detectors, International Journal of Computer Vision 75(2), 247-
266, 2007, Springer. 

