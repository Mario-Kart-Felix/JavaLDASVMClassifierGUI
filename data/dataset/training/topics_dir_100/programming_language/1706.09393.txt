Default Logic and Bounded Treewidthâˆ—
Johannes K. Fichteâ€ , Markus Hecherâ€ , and Irene Schindler
TU Wien, Austria and Leibniz UniversitaÌˆt Hannover, Hannover, Germany
lastname@dbai.tuwien.ac.at
Abstract
In this paper, we study Reiters propositional default logic when the treewidth of a certain graph representa-
tion (semi-incidence graph) of the input theory is bounded. We establish a dynamic programming algorithm
on tree decompositions that decides whether a theory has a consistent stable extension or can even be used
to enumerate all generating defaults that lead to stable extensions. We show that, for input theories whose
semi-incidence graph has bounded treewidth, our algorithm decides whether a theory has a stable extension in
linear time and enumerates all characteristic generating defaults with linear delay.
1 Introduction
Reiterâ€™s default logic (DL) is one of the most fundamental formalisms to non-monotonic reasoning where
reasoners draw tentative conclusions that can be retracted based on further evidence [16, 13]. DL augments
classical logic by rules of default assumptions (default rules). Intuitively, a default rule expresses â€œin the
absence of contrary information, assume . . . â€. Formally, such rule is a triple P :JC of formulas P , J , and C
expressing â€œif prerequisite P can be deduced and justification J is never violated then assume conclusion Câ€.
For an initial set of facts, beliefs supported by default rules are called an extension of this set of facts. The
default rules must not lead to an inconsistency if conflicting rules are present, instead such rules should be
avoided. If the default rules can be â€œfiredâ€ consistently until a fixed point, the extension is a maximally
consistent view (consistent stable extension) with respect to the facts together with the default rules. In
DL stable extensions involve the construction of the deductive closure, which can be generated from the
conclusions C of the defaults and the initial facts by means of so-called generating defaults. If a generating
default also leads to a consistent stable extension, we call it a characteristic generating default. Even
though formulas in DL can be used for various classical logics, we consider only propositional formulas
in conjunctive normal form (cnf). Our problems of interest are deciding whether a default theory has a
consistent stable extension (Ext), counting the number of characteristic generating defaults (CompSE),
and enumerating all generating defaults (EnumSE). The computational complexity of various problems
arising in default logic has been subject of several studies. Gottlob [11] established that the problem Ext
is Î£p2-complete and thus are of high intractability. Beyersdorff et al. considered the complexity of fragments
for default logic in the sense of Postâ€™s lattice [1].
Parameterized algorithms [8] have attracted considerable interest in recent years and allow to tackle
hard problems by directly exploiting certain structural properties present in input instances (the parameter).
When conducting a complexity analysis the computational complexity of the problem is then considered
in dependency of the parameter. Problems where the complexity drops and where we have an algorithm
that solves the problem in polynomial time when the parameter is fixed are of particular interest. Such
problems are called fixed-parameter tractable and fixed-parameter linear, if the runtime bounds are linear in
âˆ—This is the authors self-archived copy including detailed proofs.
â€ Also affiliated with the Institute of Computer Science and Computational Science at University of Potsdam, Germany.
1
ar
X
iv
:1
70
6.
09
39
3v
1 
 [
cs
.A
I]
  2
8 
Ju
n 
20
17
the program size. Recently, a parameter for DL has been gained from backdoors [10] and fixed-parameter
tractability results have been established for the problem Ext. Another parameter is treewidth, which has
been researched extensively [4] and widely applied in knowledge representation and reasoning [5, 9, 12, 17].
Treewidth is the parameter of our interest. A classical way to establish fixed-parameter tractability results
when the problem is parameterized by the width of a given TD is to encode the problem in monadic second
order logic and apply Courcelleâ€™s theorem [6]. In that way, Meier et al. [14] established that the extension
existence problem Ext is fixed-parameter tractable when parameterized by treewidth of a certain graph
representation of the default theory (incidence graph). However, in many settings dynamic programming
on tree decompositions is more feasible when we are not just interested in the complexity result, but also
aim to implement and use the algorithm in a practical setting [2, 3, 5, 9].
Contributions. In this paper, we introduce dynamic programming algorithms on tree decompositions
to solve the problems Ext and EnumSE. Our algorithms are fixed-parameter linear and fixed-parameter
linear for a pre-computation step followed by linear delay for outputting the solutions (Output-FPT [7]),
respectively.
2 Formal Background
We assume familiarity with standard notions in computational complexity, the complexity classes P and
NP as well as the polynomial hierarchy. For more detailed information, we refer to other standard sources .
For parameterized (decision) problems we refer to work by Cygan et al. [8].
A literal is a propositional variable or its negation and a clause is a finite set of literals. A CNF formula
is a finite set of clauses. A (truth) assignment is a mapping Î¸ : X â†’ {0, 1} defined for a set X of variables.
For x âˆˆ X we put Ï„(Â¬x) = 1âˆ’ Ï„(x). By A(X) we denote the set of all truth assignments Î¸ : X â†’ {0, 1}.
The truth assignment reduct of a CNF formula F with respect to Î¸ âˆˆ A(X) is the CNF formula FÎ¸ obtained
from F by first removing all clauses c that contain a literal set to 1 by Î¸, and second removing from the
remaining clauses all literals set to 0 by Î¸. Î¸ satisfies F if FÎ¸ = âˆ…, and F is satisfiable if it is satisfied by
some Î¸. Let F and G be CNF formulas and X = Vars(F ) âˆª Vars(G). We write F  G if and only if for
all assignments Î¸ âˆˆ A(X) it holds that all assignments Î¸ that satisfy F also satisfy G. Further, we define
the deductive closure of F as Th(F ) := {G âˆˆ cnf | F  G } and let for formula F and a family M of
sets of variables be Mod(M, F ) = {M |,M âˆˆ M,M  F )}. We denote with Sat the problem, given a
propositional formula F asking whether F is satisfiable. The problem Taut is defined over a given formula
F asking whether F tautological.
We define for CNF formulas P , J , and C a default rule Î´ as a triple P :JC ; P is called the prerequisite, J
is called the justification, and C is called the conclusion; we set Î±(d) := P , Î²(d) := J , and Î³(d) := C. We
follow the definitions by Reiter [16]. A default theory ã€ˆW,Dã€‰ consists of a set W of propositional CNF
formulas (knowledge base) and a set of default rules. A default theory D is a set of default rules. Let
ã€ˆW,Dã€‰ be a default theory and E be a set of formulas. Then, Î“(E) is the smallest set of formulas such
that: (i) W âŠ† Î“(E) (ii) Î“(E) = Th(Î“(E)), and (iii) for each Î±:Î²Î³ âˆˆ D with Î± âˆˆ Î“(E) and Â¬Î² /âˆˆ E, it holds
that Î³ âˆˆ Î“(E). E is a stable extension of ã€ˆW,Dã€‰, if E = Î“(E). An extension is inconsistent if it contains âˆ…,
otherwise it is called consistent. The definition of stable extensions allows inconsistent stable extensions.
However, inconsistent extensions only occur if the set W is already inconsistent where ã€ˆW,Dã€‰ is the theory
of interest [13, Corollary 3.60]. In consequence, (i) if W is consistent, then every stable extension of ã€ˆW,Dã€‰
is consistent, and (ii) if W is inconsistent, then ã€ˆW,Dã€‰ has a stable extension. For Case (ii) the stable
extension consists of all formulas. Thus, we consider only consistent stable extensions. For default theories
with consistent W , we can trivially transform every formula in W into a default rule. Hence, in this paper
we generally assume that W = âˆ… and write a default theory simply as set of default rules. Moreover, we
refer by SE(D) to the set of all consistent stable extensions of D.
A definition of stable extensions beyond fixed point semantics, which has been introduced by Reiter [16]
as well, uses the principle of a stage construction.
2
ljust,d2 ljust,d1 a
b
d2lcon,d2
lpre,d2
d1
lpre,d1
lcon,d1
{a, d1, ljust,d1}t1
{a, d1, lpre,d1}t2
{a, b, d1, lcon,d1}t3
{a, d2, lpre,d2} t4
{a, d2, ljust,d2} t5
{a, b, d2, lcon,d2} t6
{a, b} t7
Figure 1 Graph G (left) and an LTD T (right) of G.
Proposition 1 (Stage construction, [16]). Let D be a default theory and E be a set of formulas. Then
define E0 := âˆ… and Ei+1 := Th(Ei) âˆª { Î³(d) | Î±(d) âˆˆ Ei,Â¬Î²(d) /âˆˆ E, d âˆˆ D }. E is a stable extension of
ã€ˆW,Dã€‰ if and only if E = â‹ƒiâˆˆNEi. The set G = { d | Î±(d) âˆˆ E âˆ§ Â¬Î²(d) /âˆˆ E, d âˆˆ D } is called the set of
generating defaults. If E is a stable extension of D, then E = Th({ Î³(d) | d âˆˆ G }). In that case, we call G
a characteristic generating default.
Example 1. Let the default theories D1 and D2 be given as
D1 :=
{
d1 =
{} : {a}
{a âˆ¨ b} , d2 =
{} : {Â¬a}
{Â¬b}
}
,
D2 :=
{
d1 =
{c} : {a}
{a âˆ¨ b} , d2 =
{c} : {Â¬a}
{Â¬b} , d3 =
{} : {c}
{c} , d4 =
{} : {Â¬c}
{Â¬c}
}
.
D1 has no stable extension, while D2 has only one stable extension E1 = {Â¬c} .
Given a default theory D we are interested in the following problems: The extension existence problem
(called Ext) asks whether D has a consistent stable extension. Ext is Î£p2-complete [11]. The computation
problem (called CompSE) asks to output a characteristic generating default of D. The enumerating
problem asks to enumerate all characteristic generating defaults of D (called EnumSE).
Tree Decompositions. Let G = (V,E) be a graph, T = (N,F, n) a rooted tree, and Ï‡ : N â†’ 2V a
function that maps to each node t âˆˆ T a set of vertices. We call the sets Ï‡(Â·) bags and N the set of
nodes. Then, the pair T = (T, Ï‡) is a tree decomposition (TD) of G if the following conditions hold: (i) for
every vertex v âˆˆ V there is a node t âˆˆ N with v âˆˆ Ï‡(t); (ii) for every edge e âˆˆ E there is a node t âˆˆ N
with e âŠ† Ï‡(t); and (iii) for any three nodes t1, t2, t3 âˆˆ N , if t2 lies on the unique path from t1 to t3, then
Ï‡(t1) âˆ© Ï‡(t3) âŠ† Ï‡(t2). We call max{|Ï‡(t)| âˆ’ 1 | t âˆˆ N} the width of the TD. The treewidth tw(G) of the
graph G is the minimum width over all possible TDs of G.
Note that each graph has a trivial TD (T, Ï‡) consisting of the tree ({n}, âˆ…, n) and the mapping Ï‡(n) = V .
It is well known that the treewidth of a tree is 1, and a graph containing a clique of size k has at least
treewidth k âˆ’ 1. For arbitrary but fixed k we can compute a TD of a graph of width that equals its
treewidth in time 2O(k
3) Â· |V | [4]. Given a TD (T, Ï‡) with T = (N, Â·, Â·), for a node t âˆˆ N we say that
type(t) is leaf if t has no children; join if t has children tâ€² and tâ€²â€² with tâ€² 6= tâ€²â€² and Ï‡(t) = Ï‡(tâ€²) = Ï‡(tâ€²â€²);
int (â€œintroduceâ€) if t has a single child tâ€², Ï‡(tâ€²) âŠ† Ï‡(t) and |Ï‡(t)| = |Ï‡(tâ€²)| + 1; rem (â€œremovalâ€) if t has
a single child tâ€², Ï‡(t) âŠ† Ï‡(tâ€²) and |Ï‡(tâ€²)| = |Ï‡(t)| + 1. If every node t âˆˆ N has at most two children,
type(t) âˆˆ {leaf, join, int, rem}, and bags of leaf nodes and the root are empty, then the TD is called nice.
For every TD, we can compute a nice TD in linear time without increasing the width [4]. In our algorithms
we will traverse a TD bottom up, therefore, let post-order(T, t) be the sequence of nodes in post-order of
the induced subtree T â€² = (N â€², Â·, t) of T rooted at t.
For the ease of presentation, we also require the notion of labelled tree decompositions (LTDs). Again,
let G = (V,E) be a graph and T = (T, Ï‡) be a tree decomposition of G. Further, let L âŠ† V be a set of
labels. We call T a labelled tree decomposition, if (i) for each node t of T , we have |Ï‡(t) âˆ© L| = 1, and
(ii) whenever for some node t of T Ï‡(t)âˆ©L 6= âˆ…, then Ï‡(t) âŠ‡ {v | (v, l) âˆˆ E, {l} = Ï‡(t)âˆ©L} as well. Assume
in the following, that we use labelled graphs and nice labelled TDs, unless mentioned otherwise.
3
Algorithm 1: Algorithm DPA(T ) for Dynamic Programming on TD T for DL, cf. [9].
In: Table algorithm A, nice TD T = (T, Ï‡) with T = (N, Â·, n) of G(D) according to A.
Out: Table: maps each TD node t âˆˆ T to some computed table Ï„t.
1 for iterate t in post-order(T,n) do
2 Child-Tabs := {Tables[tâ€²] | tâ€² is a child of t in T}
3 Tables[t] â† A(t, Ï‡(t), Dt, atâ‰¤t,Child-Tabs)
Example 2. Figure 1 (left) depicts a graph G together with a LTD of width 3 of G. G has treewidth 3,
since there is a clique on the set {a, b, d1, lcon,d1} of vertices. Further, the LTD T in Figure 3 sketches main
parts of a nice LTD of G (obvious parts are left out).
Graph Representations of Default Theories. In order to use TDs for DL solving, we need dedicated
graph representations. These definitions adapt similar concepts from ASP [9]. For a default theory D, its
semi-incidence graph P (D) is the graph that has the atoms of D as vertices and an edge a b if there exists
a default d âˆˆ D and a, b âˆˆ at(d). The incidence graph I(G) is the bipartite graph, where the vertices are of
atoms of D and defaults d âˆˆ D, and there is an edge d a between a default d âˆˆ D and a corresponding
atom a âˆˆ at(d). In order to simplify the presentation of our algorithm, we mainly cover the semi-incidence
graph S(D) of D, where the vertices are atoms at(D), defaults of D and labels l(pre,d), l(just,d) and l(con,d)
for each default d âˆˆ D. For each default d âˆˆ D, we have edges l(pre,d) d, l(just,d) d and l(con,d) d, and a d
if atom a âˆˆ at(d) occurs in d. Moreover, there are edges a l(pre,d), a l(just,d), or a l(con,d) if atom a occurs
in the respective formula of d. Finally, we have an edge a b if either a, b âˆˆ at(Î±(d)), or a, b âˆˆ at(Î²(d)), or
a, b âˆˆ at(Î³(d)). For sake of simplicity of the presentation, which we will see later, we require in addition
that in each bag of the decomposition two fresh vertices are present Îµ and bf, where Îµ represents an empty
default and bf represents a fail state.
Example 3. Recall default theory D1 of Example 1. We observe that graph G in the left part of Figure 1
is the semi-incidence graph of D1.
Sub-Theories. Let T = (T, Ï‡) be a nice LTD of the semi-incidence graph S(D) of a default theory D.
Further, let T = (N, Â·, n) and t âˆˆ N . The bag-defaults are defined as Dt := D âˆ© Ï‡(t). Moreover, the bag-
default parts Î±t, Î²t and Î³t contain the corresponding preconditions Î±t := Î±(D) âˆ© Ï‡(t), justifications Î²t :=
Î²(D) âˆ© Ï‡(t) and conclusions Î³t := Î³(D) âˆ© Ï‡(t), respectively. Further, the set atâ‰¤t := {a | a âˆˆ at(D) âˆ©
Ï‡(tâ€²), tâ€² âˆˆ post-order(T, t)} is called atoms below t, the default theory below t is defined as Dâ‰¤t := {d |
d âˆˆ Dtâ€² , tâ€² âˆˆ post-order(T, t)}, and the default theory strictly below t is D<t := Dâ‰¤t \ Dt. It holds that
Dâ‰¤n = D<n = D and atâ‰¤n = at(D). The former definitions naturally extend to the respective bag-default
parts, i.e., we also use Î±â‰¤t, Î²â‰¤t, and Î³â‰¤t.
Example 4. Intuitively, the LTD of Figure 1 enables us to evaluate D by analyzing sub-theories ({d1} and
{d2}) and combining results agreeing on a, b. Indeed, for the given LTD of Figure 1 (right), Dâ‰¤t3 = {d1},
Dâ‰¤t4 = {d2} and D = Dâ‰¤t7 = D<t7 = Dâ‰¤t3 âˆª Dâ‰¤t6 . Moreover, atâ‰¤t7 = at(D), Î±â‰¤t3 = {Î±(d1)} and
Î³â‰¤t7 = {Î³(d1), Î³(d2)}.
3 Computing Characterizing Generating Defaults
In this section, we present our dynamic programming (DP) algorithms to solve the problems Ext and
EnumSE. Our algorithms are inspired by earlier work [9] in answer set programming, but require significant
extensions due to much more evolved semantics in DL. Algorithm 1 (DPA) outlines the basis of our
algorithms and sketches the general dynamic programming scheme on TD for computing characterizing
generating defaults. Roughly, the algorithm splits the search space for a stage construction (see Proposition 1)
based on a given LTD and evaluates the input default theory D in parts. The results are stored in so-called
4
Algorithm 2: Table algorithm SINC(t, Ï‡t, Dt, atâ‰¤t,Child-Tabs).
In: Bag Ï‡t, bag-theory Dt and child tables Child-Tabs of node t. Out: Table Ï„t.
1 cpyd(C, Î´) := {ã€ˆÏ,MC,RCã€‰ | ã€ˆÏ,MC,RCã€‰ âˆˆ C, Ï(d) 6= Î´}
2 if type(t) = leaf then Ï„t â† {ã€ˆâˆ…, {âˆ…}, {ã€ˆâˆ…, âˆ…, âˆ…ã€‰}, âˆ…ã€‰} /* Abbreviations see Footnote 1. */
3 else if type(t) = int, d âˆˆ Dt is the introduced default, and Ï„ â€² âˆˆ Child-Tabs then
4 subS,M(C) := {ã€ˆÏ+d7â†’Î´,MâˆªMC,RCã€‰ | ã€ˆÏ,MC,RCã€‰ âˆˆ C, Î´ âˆˆ S}
5 Ï„t â† {ã€ˆZ+d ,M, sub{c},âˆ…(P), sub{p,j,c},âˆ…(C) âˆª sub{p,j},M(P)ã€‰,
ã€ˆZ,M, sub{p,j},âˆ…(P), sub{p,j},âˆ…(C)ã€‰ | ã€ˆZ,M,P, Cã€‰ âˆˆ Ï„
â€²}
6 else if type(t) = int, l(con,d) âˆˆ Ï‡t for d âˆˆ Dt is the introduced label, and Ï„ â€² âˆˆ Child-Tabs then
7 Updc(C) := {ã€ˆÏ,Mod(Î³(d),MC), {R | R âˆˆ RC, R = Mod(Î³(d), R)}ã€‰ | ã€ˆÏ,MC,RCã€‰ âˆˆ C, Ï(d) = c}
8 CW(C) := {ã€ˆÏ,MCâˆ¼bf âˆªMod(Î³(d),MCBF),RCã€‰ | ã€ˆÏ,MC,RCã€‰ âˆˆ C, Ï(d) 6= Î³}
9 Ï„t â† {ã€ˆZ,Mod(Î³(d),M),Updc(P), Updc(C) âˆª CW(C)ã€‰ | ã€ˆZ,M,P, Cã€‰ âˆˆ Ï„ â€², d âˆˆ Z} âˆª
{ã€ˆZ,M,P, Cã€‰ | ã€ˆZ,M,P, Cã€‰ âˆˆ Ï„ â€², d 6âˆˆ Z}
10 else if type(t) = int, l(pre,d) âˆˆ Ï‡t for d âˆˆ Dt is the introduced label, and Ï„ â€² âˆˆ Child-Tabs then
11 RtÏƒM := {R âˆª {M} | R âˆˆ R âˆª {âˆ… | Îµ 6âˆˆ Ïƒâˆ’1(Î±)},M âˆˆM}
12 Updp(C, f) := cpyd(C, Î±) âˆª {ã€ˆÏ+Îµ7â†’Î±,MC,RC tÏ Mod(Î±(d), f(MCâˆ¼bf))ã€‰ | ã€ˆÏ,MC,RCã€‰ âˆˆ C, Ï(d) = p}
13 Ï„t â† {ã€ˆZ,M,Updp(P, fM), Updp(C, fid)ã€‰ | ã€ˆZ,M,P, Cã€‰ âˆˆ Ï„ â€²}
14 else if type(t) = int, l(just,d) âˆˆ Ï‡t for d âˆˆ Dt is the introduced label, and Ï„ â€² âˆˆ Child-Tabs then
15 Updj(M, C) := cpyd(C, Î²) âˆª {ã€ˆÏ,MC âˆª [Mod(Î²(d),M)]
]
bf,RC)ã€‰ | ã€ˆÏ,MC,RCã€‰ âˆˆ C, Ï(d) = j}
16 Ï„t â† {ã€ˆZ,M,Updj(M,P), Updj(M, C)ã€‰ | ã€ˆZ,M,P, Cã€‰ âˆˆ Ï„
â€²}
17 else if type(t) = int, a âˆˆ Ï‡t is the introduced atom, and Ï„ â€² âˆˆ Child-Tabs then
18 AGuess(C) := {ã€ˆÏ,MC âˆªMC]a , {Râ€² | Râ€² âˆˆ R?a, R âˆˆ RC}ã€‰ | ã€ˆÏ,MC,RCã€‰ âˆˆ C}
19 Ï„t â† {ã€ˆZ,MâˆªM]a ,AGuess(P), AGuess(C)ã€‰ | ã€ˆZ,M,P, Cã€‰ âˆˆ Ï„ â€²}
20 else if type(t) = rem, d 6âˆˆ Dt is the removed default, and Ï„ â€² âˆˆ Child-Tabs then
21 SProj(C) := {ã€ˆÏ \ {d 7â†’ Î±, d 7â†’ Î², d 7â†’ Î³},MC,RCã€‰ | ã€ˆÏ,MC,RCã€‰ âˆˆ C}
22 Ï„t â† {ã€ˆZâˆ’d ,M, SProj(P), SProj(C)ã€‰ | ã€ˆZ,M,P, Cã€‰ âˆˆ Ï„
â€²}
23 else if type(t) = rem, a 6âˆˆ Ï‡t is the removed atom or label, and Ï„ â€² âˆˆ Child-Tabs then
24 AProj(C) := {ã€ˆÏ,MCâˆ¼a , {Râˆ¼a | R âˆˆ RC}ã€‰ | ã€ˆÏ,MC,RCã€‰ âˆˆ C}
25 Ï„t â† {ã€ˆZ,Mâˆ¼a ,AProj(P), AProj(C)ã€‰ | ã€ˆZ,M,P, Cã€‰ âˆˆ Ï„ â€²}
26 else if type(t) = join and Ï„ â€², Ï„ â€²â€² âˆˆ Child-Tabs with Ï„ â€² 6= Ï„ â€²â€² then
27 Mâ€² ./Mâ€²â€² := {M â€² âˆªM â€²â€² |M â€² âˆˆMâ€²,M â€²â€² âˆˆMâ€²â€²,M â€² âˆ© Ï‡t =M â€²â€² âˆ© Ï‡t}
28 MCâ€² ./Mâ€²,Mâ€²â€² MCâ€²â€² := (MCâ€² âˆ©MCâ€²â€²) âˆª [MCâ€²BF ./ (MCâ€²â€²BF âˆªMâ€²â€²)] âˆª [(MCâ€²BF âˆªMâ€²) ./MCâ€²â€²BF]
29 Câ€².Ì‚/Mâ€²,Mâ€²â€²Câ€²â€² := {ã€ˆÏ,MCâ€² ./Mâ€²,Mâ€²â€² MCâ€²â€²,RCâ€² âˆ©RCâ€²â€²ã€‰ | ã€ˆÏ,MCâ€²,RCâ€²ã€‰ âˆˆ Câ€², ã€ˆÏ,MCâ€²â€²,RCâ€²â€²ã€‰ âˆˆ Câ€²â€²}
30 Ï„t â† {ã€ˆZ,Mâ€² âˆ©Mâ€²â€²,P â€².Ì‚/Mâ€²,Mâ€²â€²P â€²â€², (Câ€².Ì‚/Mâ€²,Mâ€²â€²Câ€²â€²) âˆª (P â€².Ì‚/Mâ€²,Mâ€²â€²Câ€²â€²) âˆª (Câ€².Ì‚/Mâ€²,Mâ€²â€²P â€²â€²)ã€‰
| ã€ˆZ,Mâ€²,P â€², Câ€²ã€‰ âˆˆ Ï„ â€², ã€ˆZ,Mâ€²â€²,P â€²â€², Câ€²â€²ã€‰ âˆˆ Ï„ â€²â€²}
Figure 2 Selected DP tables of SCONS for nice LTD T .
tables, that is, sets of all possible tuples of generating defaults, additional information to identify the
satisfiability of formulas, and counter-candidates that contradict to extend a generating default to a
characterizing default. A main part of the algorithm is a procedure that computes a table Ï„t for node t
from the tables of the children of t (if exist), which we call table algorithm. We will below present the table
algorithm for DL as given in Algorithm 2 (SINC) in more detail. Given a default theory D. Algorithm DPSINC
visits every node t âˆˆ T in post-order, and then applies algorithm SINC to the sub-theory Dt to compute
new tables.
Consider an LTD T = (T, Ï‡) and a node t of T . The Algorithm 2 (SINC) consists of two parts:
finding (i) consistent generating defaults of the default theory Dt and (ii) generating defaults Z, whose
extensions Î³(Z) are subset minimal among consistent defaults (characterizing generating defaults). For SINC,
we store in Ï„t tuples that are of the form ã€ˆZ,M,P, Cã€‰, where Z âŠ† Î³t and MâŠ† 2X for X = Ï‡(t) âˆ© at(D).
The first three tuple positions (red and green) cover Part (i), which we call the witness part. The last
positions consist of a set of tuples C = ã€ˆÏ,MC,RCã€‰ to handle Part (ii), which we call the counter-witness
5
part.
We call Z the witness generating default, since Î³(Z), is, roughly speaking, part of a potential generating
default. In particular, Z witnesses the existence of an extension Z â€² âŠ‡ Î³(Z) for a sub-theory S of D<t, i.e., the
default theory strictly below t. The set M of witness models contains models of F â€² := {C | C âˆˆ F, F âˆˆ âˆ†}
where âˆ† âŠ† Î³(D<t) âˆª Z â€² is a set of conclusions of the firing defaults of Dâ‰¤t. For our assumed witness
generating default Z, we require a witness proof P. The set P consists of tuples of the form ã€ˆÏƒ,B,Rã€‰,
where Ïƒ : Dt âˆª {Îµ} â†’ {p, j, c}, B âŠ† 2X and R âŠ† 22
X
for X = Ï‡(t) âˆ© at(D). The function Ïƒ, which we
call witness states function, maps each default d âˆˆ Dt to a certain decision state. In particular, Ïƒ(d) = c
marks that d should â€œfireâ€, in other words, we assume that d is part of a characterizing generating default.
Assignment Ïƒ(d) = p or Ïƒ(d) = j marks that d does not fire, because of Î± or Î², respectively. Note that
we require to remember whether any default in D<t has been set to p, resulting in Ïƒ(Îµ) = p in such a
case (using empty default Îµ). The set B, consists of backfire witness models, containing atom bf. Such a
model M âˆˆ B is not only a model of F â€², but also of Î²(d) for some default d âˆˆ Ïƒâˆ’1(Î²) âˆªD<t and proves
that d â€œbackfiresâ€, i.e., d should have fired. In the end, Z proves an extension of sub-theory S, where
such backfiring defaults are excluded. Hence, {d | d âˆˆ D<t, Ïƒ(d) = Î²,âˆƒM âˆˆ B : M  Z â€², Î²(d)} âˆ© S = âˆ….
In the end, we want to have S = D<n for the root n. If there is such a tuple ã€ˆÏƒ, {{bf}}, Â·ã€‰ âˆˆ P, this
indicates a wrong assignment to Ïƒâ€²(d) = j for some default d and node in the tree decomposition below.
For assignment Ïƒ(d) = p to be correct, it is required that d does not fire, because Î±(d) is not a consequence
of Z â€². To be more concrete, we additionally have to find at least one model M such that M  Z â€²,Â¬Î±(d).
Since such a model M is required for each d âˆˆ D<t \ {d | Î³(d) âˆˆ Z â€²}, which does not fire because of Î±, the
set R of required witness model sets keeps a set of such potential model sets R âˆˆ R containing at least one
such model M âˆˆ R for each such default d. Note that R contains and keeps every R of these potential sets,
as long as each M âˆˆ R also satisfies Z â€², and otherwise the whole set is excluded. This set R of sets allows
us to not distinguish at any TD node t between defaults d with Ïƒ(d) = Î±, and to therefore still maintain
the runtime guarantees. To be more concrete, we have that {d | d âˆˆ D<t, Ïƒ(d) = Î±,R = âˆ…} âˆ© S = âˆ…, i.e.,
if at least one default d âˆˆ D<t did not fire because of Î±, we require to have at least one R âˆˆ R in order
to guarantee that all of these defaults are satisfied (we can not differentiate). Finally, we end up with
S = D<t \ [{d | d âˆˆ D<t, Ïƒ(d) = Î²,âˆƒM âˆˆ B : M  Z â€², Î²(d)} âˆª {d | d âˆˆ D<t, Ïƒ(d) = Î±,R = âˆ…}]. To
conclude, there is a consistent default E of the default theory D if table tn for (empty) root n contains
ã€ˆâˆ…, {âˆ…},Pã€‰, where P either contains ã€ˆâˆ…, âˆ…, âˆ…ã€‰ or ã€ˆ{Îµ 7â†’ Î±}, âˆ…, {{âˆ…}}ã€‰. The main aim of C is to invalidate the
subset-minimality of Î³(Z), and will be covered later.
In the following, we intuitively discuss important cases of Algorithm 2 for Part (i), which consists only
of the first three tuple positions (colored red and green) and ignore the remaining parts of the tuple. We
call the resulting algorithm SCONS. Let t again be a node of a given LTD and ã€ˆZ,M,P, Â·ã€‰ a tuple of
table âˆˆ Ï„ â€² for an LTD child node of t. Further, we also assume any tuple ã€ˆÏƒ,B,Rã€‰ âˆˆ P . When a default d
is introduced (type(t) = int), Line 5 is responsible for making decisions concerning whether d fires, and the
reason why it does not fire, otherwise. Lines 6â€“16 cover nodes with type(t) = int using labels, â€œintermediateâ€
node types designed for the ease of presentation, and are explained as follows: In the case of l(con,d) is
the introduced label (Lines 6â€“9) and if Ïƒ(d) = c, we enforce that each M âˆˆ M is also a model of Î³(d)
and only keep sets R in R, where each M âˆˆ R is a model of Î³(d). Next, Lines 10â€“13 mark for defaults d,
which do not fire because of Î± (Ïƒ(d) = p), the empty default Îµ by setting Ïƒ(Îµ) = p. Additionally, it is
enforced for these defaults d that each set R âˆˆ R contains any non-backfire model of M, which is also a
model of Â¬(Î±(d)). Finally, if Ïƒ(d) = Î², Lines 14â€“16 increase B such that it grows by models of M that
are also models of Î²(d) and contain the atom bf. Next, we cover the case, where an atom a is introduced.
Lines 17â€“19 cover this node type, which increases existing witness set M, backfire witness sets B, and
required witness sets R by the case where a is set to true. In particular, we have to compute all potential
1SBF = {S : S âˆˆ S, bf âˆˆ S}, Sâˆ’e := S \ {e}, Sâˆ¼e := {S
âˆ’
e | S âˆˆ S}, S+e := S âˆª {e}, S]e := {S
+
e | S âˆˆ S}, âˆ…?e := {âˆ…}
and S?e :=
â‹ƒ
SâˆˆS,Sâ€²âˆˆ(S\S)?e
{Sâ€² âˆª {S+e }, Sâ€² âˆª {S}}. Further, identity function fid is defined by fid(x) 7â†’ x, and constant
function fS is given by f(x) 7â†’ S.
6
/0
t16T:
{a,b}
t15
{a,b,d2, lcon,d2}
t14
{a,d2, ljust,d2}t13
{a,d2, lpre,d2}t12
{a,d2}t11
/0t9
{a,b}
t8
{a,b,d1, lcon,d1}
t7
{a,b,d1} t6
{a,d1, lpre,d1} t5
{a,d1, ljust,d1} t4
{a,d1} t3
{a} t2
/0t1
ã€ˆZ14.i,M14.i,P14.i,C14.iã€‰ Ï„14
ã€ˆ /0,2{a,b},{ã€ˆ{d2 7â†’ p,Îµ 7â†’ p}, /0, /0ã€‰,
ã€ˆ{d2 7â†’ j},{{bf},{b,bf}}, /0ã€‰}, /0ã€‰
ã€ˆ{d2},{ /0,{a}},{ã€ˆ{d2 7â†’ c}, /0, /0ã€‰},{
ã€ˆ{d2 7â†’ p,Îµ 7â†’ p},2{a,b}, /0ã€‰,
ã€ˆ{d2 7â†’ j},2{a,b} âˆª{{bf}}, /0ã€‰}ã€‰
ã€ˆZ16.i,M16.i,P16.i,C16.iã€‰ Ï„16
ã€ˆ /0,{ /0},{ã€ˆ{Îµ 7â†’ p}, /0, /0ã€‰},
{ã€ˆ /0,{bf}, /0ã€‰}, /0ã€‰
ã€ˆ /0,{ /0},{ã€ˆ /0, /0, /0ã€‰},{
ã€ˆ{Îµ 7â†’ p}, /0, /0ã€‰,ã€ˆ /0,{{bf}}, /0ã€‰}ã€‰
ã€ˆZ5.i,M5.i,P5.i,C5.iã€‰ Ï„5
ã€ˆ /0,{ /0,{a}},{ã€ˆ{d1 7â†’ p,Îµ 7â†’ p}, /0, /0ã€‰,
ã€ˆ{d1 7â†’ j},{{a,bf}}, /0ã€‰}, /0ã€‰
ã€ˆ{d1},{ /0,{a}},{ã€ˆ{d1 7â†’ c}, /0, /0ã€‰},{
ã€ˆ{d1 7â†’ p,Îµ 7â†’ p},2{a}, /0ã€‰,
ã€ˆ{d1 7â†’ j},{ /0,{a},{a,bf}}, /0ã€‰}ã€‰
ã€ˆZ7.i,M7.i,P7.i,C7.iã€‰ Ï„7
ã€ˆ /0, 2{a,b},{ã€ˆ{d1 7â†’ p,Îµ 7â†’ p}, /0, /0ã€‰,
ã€ˆ{d1 7â†’ j},{{a,bf},{a,b,bf}}, /0ã€‰}, /0ã€‰
ã€ˆ{d1},2{a,b} \ /0,{ã€ˆ{d1 7â†’ c}, /0, /0ã€‰},{
ã€ˆ{d1 7â†’ p,Îµ 7â†’ p},2{a,b}, /0ã€‰,
ã€ˆ{d1 7â†’ j},2{a,b} âˆª{{a,bf},{a,b,bf}}, /0ã€‰}ã€‰
ã€ˆZ3.i,M3.i,P3.i,C3.iã€‰ Ï„3
ã€ˆ /0,{ /0,{a}},{ã€ˆ{d1 7â†’ Î±}, /0, /0ã€‰,
ã€ˆ{d1 7â†’ j}, /0, /0ã€‰}, /0ã€‰
ã€ˆ{d1},{ /0,{a}},{ã€ˆ{d1 7â†’ c}, /0, /0ã€‰},{
ã€ˆ{d1 7â†’ p},2{a}, /0ã€‰,
ã€ˆ{d1 7â†’ j},2{a}, /0ã€‰}ã€‰
ã€ˆZ4.i,M4.i,P4.i,C4.iã€‰ Ï„4
ã€ˆ /0,{ /0,{a}},{ã€ˆ{d1 7â†’ p}, /0, /0ã€‰,
ã€ˆ{d1 7â†’ j},{{a,bf}}, /0ã€‰}, /0ã€‰
ã€ˆ{d1},{ /0,{a}},{ã€ˆ{d1 7â†’ c}, /0, /0ã€‰},{
ã€ˆ{d1 7â†’ p},2{a}, /0ã€‰,
ã€ˆ{d1 7â†’ j},{ /0,{a},{a,bf}}, /0ã€‰}ã€‰
ã€ˆZ1.i,M1.i,P1.i,C1.iã€‰ Ï„1
ã€ˆ /0,{ /0},{ã€ˆ /0, /0, /0ã€‰}, /0ã€‰
Figure 3 Selected DP tables of SINC for nice LTD T .
sets R âˆˆ R of models, where a is either set to true or to false. When a default d gets removed in Lines 20â€“22,
we remove the mapping of d in Ïƒ to any of {p, j, c} since d is not considered anymore. The removal of an
atom a (Lines 23â€“25) is roughly speaking, a kind of projection to the current bag. We remove objects
anywhere within the tuples, which contain the atom a we do not consider anymore. We also use this case
for removing a label, since we only copy all the tuples there. Finally, the case where type(t) = join, also
talks about a second tuple uâ€²â€² of a different, second child table Ï„ â€²â€². Intuitively, both tuples, representing
intermediate results of two different branches, have to agree on the witness extension, witness states, and
the witness models. Note that for a backfire model B to endure in B within P of Ï„t, it suffices if B is a
backfire model in one branch B âˆª {bf} âˆˆ Bâ€² and an ordinary model in the other branch (M âˆˆMâ€²â€²).
Example 5. Consider default theory D from Example 1 and in Figure 3 (left) LTD T = (Â·, Ï‡) of S(D)
and the tables Ï„1, . . . , Ï„16 illustrating computation results obtained during post-order traversal of T by
DPSCONS. Table Ï„1 = {ã€ˆâˆ…, {âˆ…}, {ã€ˆâˆ…, âˆ…, âˆ…ã€‰}ã€‰} as type(t1) = leaf (see Line 2). Since type(t2) = int and a is
the introduced atom, we construct table Ï„2 from Ï„1 by {ã€ˆÏƒ1.1,M2.1,R1.1ã€‰}, where M2.1 contains M1.1.k
and M1.1.k âˆª{a} for each M1.1.k (k â‰¤ 1) in Ï„1 (corresponding to a guess on a). Precisely, M2.1 := {âˆ…, {a}}
(L 19). Then, t3 introduces default d1, resulting in two tuples. Either (see tuple u3.1), we do not let
default d1 fire. In this case, the reason for not firing can be Î±(d1) or Î²(d1) (see P3.1, L 5). Otherwise,
i.e., default d1 fires, we have Z3.2 = {d1} and P3.2 = {{d1 7â†’ c}, âˆ…, âˆ…ã€‰}, since d1 fires. Node t4 introduces
label ljust,d1 and modifies P4.1. In particular, it chooses among M candidates, which might prove that d1
backfires (see Line 16). Obviously, since Î²(d1) = b, B4.1.2 = {{a, bf}}. In table Ï„5, we cover cases, where
default d1 does not fire because of its preconditions Î±(d1) = {}. In this case (see P5.1.1), we do not find any
model of {âˆ…}, hence R5.1.1 = âˆ…. Whenever such a set ã€ˆÏƒ, Â·, âˆ…ã€‰ âˆˆ P occurs in some table, we could discard
the tuple in case of Îµ âˆˆ Ïƒâˆ’1(Î±), since at least one choice concerning Î± was wrong. Table Ï„7 concerns about
the conclusion Î³(d1) of a default, and, intuitively, updates every model occurring in the table, such that the
models satisfy Î³(d1) in case it fires. The right branch of the LTD works similarly to the left branch, and in
the end, join node t16, intuitively, just combines witnesses agreeing on its bag content.
Next, we briefly discuss the handling of counter-witnesses, which completes Algorithm SINC. Observe
that the handling of counter-witnesses C is quite similar to the witness proofs P . The tuples ã€ˆÏ,MC,RCã€‰ âˆˆ C
consist of a counter-witness state Ï : Dâ‰¤t âˆª {Îµ} 7â†’ {p, j, c}, counter-witness models MC âŠ† 2X , and a set of
required counter-witness models RC âŠ† 22X for X = atâ‰¤t âˆª {bf}. Compared to the witness models, MC
potentially contains backfire counter-witness models per design, since here we do not require to enumerate
7
all the justifications, why a certain witness does not lead to a (subset-minimal) generating default. Instead,
the existence of a certain counter-witness tuple for a witness in a table Ï„t proves that the corresponding
witness can not be extended to a generating default of Dâ‰¤t.
In the following, we provide insights on the correctness of the algorithm DPSINC.
Theorem 1. Given a default theory D, the algorithm DPSINC correctly solves Ext.
The correctness proof of these algorithms need to investigate each node type separately. We have to
show that a tuple at a node t guarantees existence of a model for the program Dâ‰¤t, proving soundness.
Conversely, one can show that each generating default set is indeed evaluated while traversing the TD,
which provides completeness. We employ this idea using the notions of (i) partial solutions consisting of
partial extensions and the notion of (ii) local partial solutions.
Definition 1. Let D be a default theory, T = (T, Ï‡) be an LTD of the semi-incidence graph S(D) of D, where
T = (N, Â·, Â·), and t âˆˆ N be a node. Further, let âˆ… (MâŠ† 2atâ‰¤tâˆª{bf}, R âŠ† 2Mâˆ¼bf , Ïƒ : (Dâ‰¤t âˆª {Îµ})â†’ {p, j, c},
E âŠ† Î³â‰¤t, and Z := Î³(Ïƒâˆ’1(c)) with Z âŠ† E. The tuple (Ïƒ,M,R) is a partial extension under E for t if the
following conditions hold:
1. Z  D<t \ [{d âˆˆ D<t | Ïƒ(d) = j, âˆƒM âˆˆMBF : M  E, Î²(d)} âˆª {d âˆˆ D<t | Ïƒ(d) = p,R = âˆ…}],
2. Ïƒ(Îµ) = pâ‡= Ïƒâˆ’1(p) 6= âˆ…; Ïƒâˆ’1(p) = âˆ… =â‡’ Ïƒ(Îµ) undefined,
3. M is the largest set such that:
(a) M  Z for every M âˆˆM,
(b) M  E, Î²(d) =â‡’M+bf âˆˆMBF for every d âˆˆ Dâ‰¤t s.t. Ïƒ(d) = j, Î²(d) âˆˆ Î²â‰¤t,M âˆˆM,
(c) âˆƒd âˆˆ Dâ‰¤t : Ïƒ(d) = j, Î²(d) âˆˆ Î²â‰¤t,M  E, Î²(d) for every M âˆˆMBF, and
4. R is the largest set such that:
(a) |R| â‰¤ |Ïƒâˆ’1(Î±)| âˆ’ 1 for every R âˆˆ R,
(b) âˆƒd âˆˆ Dâ‰¤t : Ïƒ(d) = p, Î±(d) âˆˆ Î±â‰¤t,M  Z,Â¬Î±(d) for every M âˆˆ (
â‹ƒ
RâˆˆRR), and
(c) âˆƒM âˆˆ R : M  Z,Â¬(Î±(d))â‡= Ïƒ(d) = p for every d âˆˆ Dâ‰¤t s.t. Î±(d) âˆˆ Î±â‰¤t, R âˆˆ R
Definition 2. Let D be a default theory, T = (T, Ï‡) where T = (N, Â·, n) be an LTD of S(D), and t âˆˆ N
be a node. A partial solution for t is a tuple (Z,M,P, C) where Z âŠ† Î³â‰¤t, and P is the largest set of tuples
such that each (Ïƒ,B,R) âˆˆ P is a partial extension under Z with BBF = B and Z = Ïƒâˆ’1(c). Moreover, C is
the largest set of tuples such that for each (Ï,MC,RC) âˆˆ C, we have that (Ï,MC,RC) is a partial extension
under Z with Ïâˆ’1(c) ( Ïƒâˆ’1(c). Finally, MâŠ† 2atâ‰¤t is the largest set with M  Î³(Z) for each M âˆˆM.
The following lemma establishes correspondence between stable extensions and partial solutions.
Lemma 1 (?). Let D be a default theory, T = (T, Ï‡) be an LTD of the semi-incidence graph S(D), where
T = (Â·, Â·, n), and Ï‡(n) = âˆ…. Then, there exists a stable extension Z â€² for D if and only if there exists a
partial solution u = (Z,M,P, C) for root n with at least one tuple ã€ˆÏƒ,B,Rã€‰ âˆˆ P where BBF = âˆ…, and either
Ïƒâˆ’1(p) = âˆ…, or R 6= âˆ…, where C is of the following form: For each (Ï,MC,RC) âˆˆ C, either MCBF 6= âˆ…, or
RC = âˆ… and Ïâˆ’1(p) 6= âˆ….
Next, we require the notion of local partial solutions corresponding to the tuples obtained in Algorithm 2.
Definition 3. Let D be a default theory, T = (T, Ï‡) an LTD of the semi-incidence graph S(D), where T =
(N, Â·, n), and t âˆˆ N be a node. A tuple (Ïƒ,B,R) is a local partial solution part of partial solution (ÏƒÌ‚, BÌ‚, RÌ‚)
for t if
1Proofs for statements marked with â€œ?â€ can be found in the appendix.
8
1. Ïƒ = ÏƒÌ‚ âˆ© ([Ï‡(t) âˆª {Îµ}]Ã— {p, j, c}),
2. B = BÌ‚t, where St := {S âˆ© (Ï‡(t) âˆª {bf}) | S âˆˆ S}, and
3. R = {Rt | R âˆˆ RÌ‚}.
Definition 4. Let D be a default theory, T = (T, Ï‡) an LTD of the semi-incidence graph S(D), where
T = (N, Â·, n), and t âˆˆ N be a node. A tuple u = ã€ˆZ,M,P, Cã€‰ is a local partial solution for t if there
exists a partial solution uÌ‚ = (ZÌ‚,MÌ‚, PÌ‚, CÌ‚) for t such that the following conditions hold: (1) Z = ZÌ‚ âˆ© 2Dt ,
(2) M = MÌ‚t, (3) P is the smallest set containing local partial solution part (Ïƒ,B,R) for each (ÏƒÌ‚, BÌ‚, RÌ‚) âˆˆ PÌ‚,
and (4) C is the smallest set with local partial solution part (Ï,MC,RC) âˆˆ C for each (ÏÌ‚,MÌ‚C, RÌ‚C) âˆˆ CÌ‚. We
denote by uÌ‚t the local partial solution u for t given partial solution uÌ‚.
The following proposition provides justification that it suffices to store local partial solutions instead of
partial solutions for a node t âˆˆ N .
Lemma 2. Let D be a default theory, T = (T, Ï‡) an LTD of S(D), where T = (N, Â·, n), and Ï‡(n) = âˆ…. Then,
there exists a stable extension for D if and only if there exists a local partial solution of the form ã€ˆâˆ…, {âˆ…},P, Cã€‰
for the root n âˆˆ N with at least one tuple of the form ã€ˆÏƒ, âˆ…,Rã€‰ âˆˆ P where either Ïƒâˆ’1(Î±) = âˆ…, or R 6= âˆ….
Moreover, for each ã€ˆÏ,MC,RCã€‰ in C, either MCBF 6= âˆ…, or Ïâˆ’1(Î±) 6= âˆ… and RC = âˆ….
Proof. Since Ï‡(n) = âˆ…, every partial solution for the root n is an extension of the local partial solution u
for the root n âˆˆ N according to Definition 4. By Lemma 1, we obtain that the lemma is true.
In the following, we abbreviate atoms occurring in bag Ï‡(t) by att, i.e., att := Ï‡(t) \Dt.
Proposition 2 (?,Soundness). Let D be a default theory, T = (T, Ï‡) an LTD of the semi-incidence
graph S(D), where T = (N, Â·, Â·), and t âˆˆ N a node. Given a local partial solution uâ€² of child table Ï„ â€²
(or local partial solution uâ€² of table Ï„ â€² and local partial solution uâ€²â€² of table Ï„ â€²â€²), each tuple u of table Ï„t
constructed using table algorithm SINC is also a local partial solution.
Proposition 3 (?,Completeness). Let D be a default theory, T = (T, Ï‡) where T = (N, Â·, Â·) be an LTD
of S(D) and t âˆˆ N be a node. Given a local partial solution u of table Ï„t, either t is a leaf node, or there
exists a local partial solution uâ€² of child table Ï„ â€² (or local partial solution uâ€² of table Ï„ â€² and local partial
solution uâ€²â€² of table Ï„ â€²â€²) such that u can be constructed by uâ€² (or uâ€² and uâ€²â€², respectively) and using table
algorithm SINC.
Corollary 1 (Completeness for Enumeration). Let D be a default theory, T = (T, Ï‡) where T = (N, Â·, Â·)
be an LTD of S(D) and t âˆˆ N be a node. Given a partial solution uÌ‚ and the corresponding local partial
solution u = uÌ‚t for table Ï„t, either t is a leaf node, or there exists a local partial solution u
â€² of child table
Ï„ â€² (or local partial solution uâ€² of table Ï„ â€² and local partial solution uâ€²â€² of table Ï„ â€²â€²) such that u can be
constructed by uâ€² (or uâ€² and uâ€²â€², respectively) and using table algorithm SINC.
Proof. The result directly follows from the proof for completeness (see Proposition 3).
Now, we are in the situation to prove Theorem 1.
Proof of Theorem 1. We first show soundness. Let T = (T, Ï‡) be the given LTD, where T = (N, Â·, n). By
Lemma 2 we know that there is a stable extension D if and only if there exists a local partial solution for
the root n. Note that the tuple is by construction of the form ã€ˆâˆ…, {âˆ…},P, Cã€‰, where P 6= âˆ… can contain a
combination of the following tuples ã€ˆâˆ…, âˆ…, âˆ…ã€‰, ã€ˆ{Îµ 7â†’ Î±}, âˆ…, {{âˆ…}}ã€‰. For each ã€ˆÏ,MC,RCã€‰ âˆˆ C eitherMCBF 6=
âˆ… or Ïâˆ’1(Î±) 6= âˆ… and RC = âˆ…. In total, this results in 48 possible tuples, since C âŠ† 2C can contain any
combination (16 many) of C, where C = {ã€ˆâˆ…, {âˆ…, {bf}}, âˆ…ã€‰, ã€ˆ{Îµ 7â†’ Î±}, {âˆ…}, âˆ…ã€‰, ã€ˆ{Îµ 7â†’ Î±}, {âˆ…, {bf}}, {{âˆ…}}ã€‰,
ã€ˆ{Îµ 7â†’ Î±}, {âˆ…, {bf}}, âˆ…ã€‰}.
9
Hence, we proceed by induction starting from the leaf nodes in order to end up with such a tuple at the
root node n. In fact, the tuple ã€ˆâˆ…, {âˆ…}, {ã€ˆâˆ…, âˆ…, âˆ…ã€‰}, âˆ…ã€‰ is trivially a partial solution for (empty) leaf nodes by
Definitions 1 and 2 and also a local partial solution of ã€ˆâˆ…, {âˆ…}, {ã€ˆâˆ…, âˆ…, âˆ…ã€‰}, âˆ…ã€‰ by Definition 4. We already
established the induction step in Proposition 2. Hence, when we reach the root n, when traversing the
TD in post-order by Algorithm DPSINC, we obtain only valid tuples inbetween and a tuple of the form
discussed above in the table of the root n witnesses an answer set.
Next, we establish completeness by induction starting from the root n. Let therefore, ZÌ‚ be an arbitrary
stable extension of D. By Lemma 2, we know that for the root n there exists a local partial solution
of the discussed form ã€ˆâˆ…, {âˆ…},P, Cã€‰ for some partial solution ã€ˆZÌ‚ â€²,MÌ‚, PÌ‚, CÌ‚ã€‰ with Î³(ZÌ‚ â€²) = ZÌ‚. We already
established the induction step in Proposition 3. Hence, we obtain some (corresponding) tuples for every
node t. Finally, stopping at the leaves n. In consequence, we have shown both soundness and completeness
resulting in the fact that Theorem 1 is true.
Theorem 1 states that we can decide the problem Cons by means of Algorithm DPSINC. The following
theorem states its that we obtain fourfold exponential runtime in the treewidth.
Theorem 2 (?). Given a default theory D, the algorithm DPSINC and runs in time O(42
22
k+2
Â· â€–S(D)â€–),
where k := tw(S(D)) is the treewidth of the semi-incidence graph S(D).
Next, we establish that we can slightly extend DPSINC to enumerate characterizing generating defaults.
The algorithm on top of DPSINC is relatively straight forward and presented in Algorithm 3.
Theorem 3 (?). Given a default theory D, the algorithm DPSINC can be used as a preprocessing step to
construct tables from which we can correctly solve the problem EnumSE.
The correctness proof requires to extend the previous results to establish a one-to-one correspondence
when traversing the tree the TD and we can reconstruct each solution as well as we do not get duplicates.
Therefore, we require the following three results.
Observation 1. Let D be a default theory, T = (T, Ï‡) where T = (N, Â·, Â·) be an LTD of S(D) and t âˆˆ N
be a node. Then, for each partial solution u = ã€ˆZ,M,P, Cã€‰ for t, M,P and C are functional dependent
from Z, i.e., for any partial solution uâ€² = ã€ˆZ,Mâ€²,P â€², Câ€²ã€‰ for t, we have u = uâ€².
Lemma 3 (?). Let D be a default theory, T = (T, Ï‡) with T = (N, Â·, Â·) be an LTD of S(D), and Z be a
characterizing generating default. Then, there is a unique set of tuples S, containing exactly one tuple per
node t âˆˆ N containing only local partial solutions of the unique partial solution for Z.
Proposition 4 (?). Let D be a default theory, T = (T, Ï‡) with T = (N, Â·, Â·) be an LTD of S(D), and Z be
a characterizing generating default. Moreover, let S be the unique set of tuples, containing exactly one tuple
per node t âˆˆ N and containing only local partial solutions of the unique partial solution for Z. Given S,
and tables of Algorithm SINC, one can compute in time O(â€–Dâ€–) a characterizing generating default Z â€²
with Z â€² 6= Z, assuming one can get for a specific tuple u for node t its corresponding â‰º-ordered predecessor
tuple set origt(u) of tuples in the child node(s) of t in constant time.
4 Conclusion
In this paper, we established dynamic programming algorithms that operate on tree decompositions of the
semi-incidence graph of a given default theory. Our algorithms can be used to decide whether the default
theory has a stable extension or to enumerate all characterizing generating defaults. Our algorithms run in
fpt-time and linear delay, respectively.
We believe that our algorithms can be extended to tree decompositions of the incidence graph. However,
then we need additional states to handle the situation that prerequisite, justification, and conclusion may
10
not occur together in one bag, consequently such an algorithm will likely be very complex. An interesting
research question is whether we can improve our runtime bounds. Still it might be worth implementing
our algorithms to enumerate characterizing generating defaults for DL, as previous work showed that a
relatively bad worst-case runtime may anyways lead to practical useful results [5].
References
[1] Olaf Beyersdorff, Arne Meier, Michael Thomas, and Heribert Vollmer. The complexity of reasoning
for fragments of default logic. J. of Logic and Computation, 22(3):587â€“604, 2012.
[2] Bernhard Bliem, GuÌˆnther Charwat, Markus Hecher, and Stefan Woltran. D-FLATË†2: Subset min-
imization in dynamic programming on tree decompositions made easy. Fund. Inform., 147:27â€“34,
2016.
[3] Bernhard Bliem, Markus Hecher, and Stefan Woltran. On efficiently enumerating semi-stable extensions
via dynamic programming on tree decompositions. COMMAâ€™16, 2016.
[4] H. Bodlaender and A. M. C. A. Koster. Combinatorial optimization on graphs of bounded treewidth.
The Computer Journal, 51(3):255â€“269, 2008.
[5] GuÌˆnther Charwat and Stefan Woltran. Dynamic programming-based qbf solving. In Florian Lonsing
and Martina Seidl, editors, QBFâ€™16, 2016.
[6] Bruno Courcelle. Graph rewriting: An algebraic and logic approach. In Jan van Leeuwen, editor,
Handbook of theoretical computer science, Vol. B, pages 193â€“242. Elsevier, 1990.
[7] Nadia Creignou, Arne Meier, Julian-Steffen MuÌˆller, Johannes Schmidt, and Heribert Vollmer. Paradigms
for parameterized enumeration. Th.Comp. Syst., 60(4):737â€“758, 2017.
[8] M. Cygan, F. V. Fomin, L. Kowalik, D. Lokshtanov, D. Marx, M. Pilipczuk, and S. Saurabh.
Parameterized Algorithms. Springer, 2015.
[9] Johannes K. Fichte, Markus Hecher, Michael Morak, and Stefan Woltran. Answer set solving with
bounded treewidth revisited. LPNMRâ€™17, Springer, 2017.
[10] Johannes K. Fichte, Arne Meier, and Irina Schindler. Strong backdoors for default logic. SATâ€™16, 2016.
[11] Georg Gottlob. Complexity results for nonmonotonic logics. JLC., 2(3):397â€“425, 1992.
[12] M. Jakl, R. Pichler, and S. Woltran. Answer-set programming with bounded treewidth. In IJCAIâ€™09,
2009.
[13] Victor W. Marek and Miros law TruszczynÌski. Nonmonotonic Logic: context-dependent reasoning.
Artificial Intelligence. 1993.
[14] Arne Meier, Irina Schindler, Johannes Schmidt, Michael Thomas, and Heribert Vollmer. On the
parameterized complexity of non-monotonic logics. Archive for Mathematical Logic, 54(5-6):685â€“710,
2015.
[15] Christos H. Papadimitriou. Computational Complexity. Addison-Wesley, 1994.
[16] Raymond Reiter. A logic for default reasoning. AIJ, 13:81â€“132, April 1980.
[17] Marko Samer and Stefan Szeider. Constraint satisfaction with bounded treewidth revisited. J. Comp.
and Sys. Sci,., 76(2):103â€“114, 2010.
11
A Omitted Proofs
Lemma 4. Let D be a default theory, T = (T, Ï‡) be an LTD of the semi-incidence graph S(D), where
T = (Â·, Â·, n), and Ï‡(n) = âˆ…. Then, there exists a stable extension Z â€² for D if and only if there exists a
partial solution u = (Z,M,P, C) for root n with at least one tuple ã€ˆÏƒ,B,Rã€‰ âˆˆ P where BBF = âˆ…, and either
Ïƒâˆ’1(p) = âˆ…, or R 6= âˆ…, where C is of the following form: For each (Ï,MC,RC) âˆˆ C, either MCBF 6= âˆ…, or
RC = âˆ… and Ïâˆ’1(p) 6= âˆ….
Proof (Sketch). Given a stable extension Z â€² of D we construct u = (Z,M,P, C) where we generate every
potential function Ïƒ : Dâ‰¤t âˆª {Îµ} â†’ {p, j, c} with Ïƒ(d) := p (only if Z â€²,Â¬(Î±(d)) 6 {âˆ…}), or Ïƒ(d) := j (only
if Z â€², Î²(d)  {âˆ…}) for any d âˆˆ Dâ‰¤t. Finally, if Ïƒ(d) has not been set yet (and neither one of the two
conditions holds), let Ïƒ(d) := c. In case of Ïƒâˆ’1(p) 6= âˆ…, we also set the empty default Ïƒ(Îµ) := p. Observe
that since Z â€² is a stable extension, Ïƒ(d) = c =â‡’ Î³(d) âˆˆ Z â€².
For each of this functions Ïƒ, we require ã€ˆÏƒ, âˆ…,Rã€‰ âˆˆ P, where R := {R | R âŠ† 2at(D), |R| â‰¤ |Ïƒâˆ’1(Î±)| âˆ’
1, for all d âˆˆ Ïƒâˆ’1(Î±) \ {Îµ} : âˆƒM âˆˆ R : M  Z â€²,Â¬Î±(d)}.
Moreover, we define set Z := Ïƒâˆ’1(Î³) and set M := Mod({C | C âˆˆ Z â€²i, Z â€²i âˆˆ Z â€²}, 2at(D)), in order for u
to be a partial solution for n (see Definition 2). We construct C, consisting of partial solutions (Ï,MC,RC)
where we use every potential state function Ï with Ïâˆ’1(c) ( Ïƒâˆ’1(c). For this, let E := Î³(Ïâˆ’1(c)). For
the defaults d with Ï(d) 6= c, i.e., defaults d that do not fire because of Î±(d) or Î²(d), we also set their
state Ï(d) to Î± or Î², respectively (analogous to above). Again, in case of Ïâˆ’1(p) 6= âˆ…, we also set the
empty default Ï(Îµ) := p, otherwise Ï(Îµ) is undefined. Finally, we define set MC := Mod({C | C âˆˆ Ei, Ei âˆˆ
E}, 2at(D)) âˆª [â‹ƒd:Ï(d)=j Mod({Z â€²i | C âˆˆ Z â€²i, Z â€²i âˆˆ Z â€²} âˆª Î²(d), 2at(D))+bf] and RC := {R | R âŠ† 2at(D), |R| â‰¤
|Ïâˆ’1(p)| âˆ’ 1, for all d âˆˆ Ïâˆ’1(p) \ {Îµ} : âˆƒM âˆˆ R : M  E,Â¬(Î±(d))} according to Definition 1.
For the other direction, Definitions 1 and 2 guarantee that Z â€² is a stable extension if there exists such a
partial solution u. In consequence, the lemma holds.
Proposition 5 (Soundness). Let D be a default theory, T = (T, Ï‡) an LTD of the semi-incidence
graph S(D), where T = (N, Â·, Â·), and t âˆˆ N a node. Given a local partial solution uâ€² of child table Ï„ â€²
(or local partial solution uâ€² of table Ï„ â€² and local partial solution uâ€²â€² of table Ï„ â€²â€²), each tuple u of table Ï„t
constructed using table algorithm SINC is also a local partial solution.
Proof. Let uâ€² be a local partial solution for tâ€² âˆˆ N and u a tuple for node t âˆˆ N such that u was derived
from uâ€² using table algorithm SINC. Hence, node tâ€² is the only child of t and t is either removal or introduce
node.
Assume that t is a removal node and d âˆˆ Dtâ€² \Dt for some default d. Observe that for u = ã€ˆZ,M,P, Cã€‰
and uâ€² = ã€ˆZ â€²,M,P â€², Câ€²ã€‰, models M and model sets R are equal, i.e., ã€ˆÂ·,M,Rã€‰ âˆˆ P â‡â‡’ ã€ˆÂ·,M,Rã€‰ âˆˆ P â€²
and ã€ˆÂ·,M,Rã€‰ âˆˆ C â‡â‡’ ã€ˆÂ·,M,Rã€‰ âˆˆ Câ€². Since uâ€² is a local partial solution, there exists a partial solution uÌ‚â€²
of tâ€², satisfying the conditions of Definition 4. Then, uÌ‚â€² is also a partial solution for node t, since it satisfies
all conditions of Definitions 1 and 2. Finally, note that u = (uÌ‚â€²)t since the projection of uÌ‚â€² to the bag Ï‡(t)
is u itself. In consequence, the tuple u is a local partial solution.
For a âˆˆ attâ€² \ att as well as for introduce nodes, we can analogously check the proposition.
Next, assume that t is a join node. Therefore, let uâ€² and uâ€²â€² be local partial solutions for tâ€², tâ€²â€² âˆˆ N ,
respectively, and u be a tuple for node t âˆˆ N such that u can be derived using both uâ€² and uâ€²â€² in
accordance with the SINC algorithm. Since uâ€² and uâ€²â€² are local partial solutions, there exists partial solution
uÌ‚â€² = (ZÌ‚ â€²,MÌ‚â€², PÌ‚ â€², CÌ‚â€²) for node tâ€² and partial solution uÌ‚â€²â€² = (ZÌ‚ â€²â€²,MÌ‚â€²â€², PÌ‚ â€²â€², CÌ‚â€²â€²) for node tâ€²â€². Using these two
partial solutions, we can construct uÌ‚ = (ZÌ‚ â€² âˆª ZÌ‚ â€²â€²,MÌ‚â€² ./ MÌ‚â€²â€², PÌ‚ â€² .Ì‡/ PÌ‚ â€²â€², (CÌ‚â€² .Ì‡/ CÌ‚â€²â€²) âˆª (PÌ‚ â€² .Ì‡/ CÌ‚â€²â€²) âˆª (CÌ‚â€² .Ì‡/ PÌ‚ â€²â€²))
12
where for ./ (Â·, Â·) we refer to Algorithm 2. We define .Ì‡/(Â·, Â·) in accordance with Algorithm 2 as follows:
compatf (RÌ‚) := trueâ‡â‡’ |{MÌ‚ | MÌ‚ âˆˆ RÌ‚, MÌ‚ âˆ© Ï‡(t) = f(MÌ‚) âˆ© Ï‡(t)}| = |RÌ‚|
RÌ‚â€² .Ì‡/ RÌ‚â€²â€² :=
â‹ƒ
f :RÌ‚â€²â†’RÌ‚â€²â€²,f surjective, compatf (RÌ‚â€²)
{
â‹ƒ
MÌ‚ â€²âˆˆRÌ‚â€²
{MÌ‚ â€² âˆª f(MÌ‚ â€²)}}
RÌ‚â€² .Ì‡/ RÌ‚â€²â€² :=
â‹ƒ
RÌ‚â€²âˆˆRÌ‚â€²,RÌ‚â€²â€²âˆˆRÌ‚â€²â€²
(RÌ‚â€² .Ì‡/ RÌ‚â€²â€²) âˆª (RÌ‚â€²â€² .Ì‡/ RÌ‚â€²)
MCâ€² .Ì‡/Mâ€²,Mâ€²â€²MCâ€²â€² :=(MCâ€² ./MCâ€²â€²) âˆª [MCâ€²BF ./ (MCâ€²â€²BF âˆªMâ€²â€²)]âˆª
[(MCâ€²BF âˆªMâ€²) ./MCâ€²â€²BF]
CÌ‚â€² .Ì‡/ CÌ‚â€²â€² :={(ÏÌ‚â€² âˆª ÏÌ‚â€²â€²,MÌ‚Câ€² ./MÌ‚â€²,MÌ‚â€²â€² MÌ‚Câ€²â€², RÌ‚Câ€² .Ì‡/ Ë†RCâ€²â€²) | (ÏÌ‚â€²,MÌ‚Câ€², RÌ‚Câ€²) âˆˆ CÌ‚â€²,
(ÏÌ‚â€²â€²,MÌ‚Câ€²â€², Ë†RCâ€²â€²) âˆˆ CÌ‚â€²â€², ÏÌ‚â€²âˆ’1(Ï€) âˆ© Ï‡(t) = ÏÌ‚â€²â€²âˆ’1(Ï€) âˆ© Ï‡(t)
forall Ï€ âˆˆ {p, j, c}}.
Then, we check all conditions of Definitions 1 and 2 in order to verify that uÌ‚ is a partial solution for t.
Moreover, the projection uÌ‚t of uÌ‚ to the bag Ï‡(t) is exactly u by construction and hence, u = uÌ‚t is a local
partial solution.
Since one can provide similar arguments for each node type, we established soundness in terms of the
statement of the proposition.
Proposition 6 (Completeness). Let D be a default theory, T = (T, Ï‡) where T = (N, Â·, Â·) be an LTD of
S(D) and t âˆˆ N be a node. Given a local partial solution u of table Ï„t, either t is a leaf node, or there
exists a local partial solution uâ€² of child table Ï„ â€² (or local partial solution uâ€² of table Ï„ â€² and local partial
solution uâ€²â€² of table Ï„ â€²â€²) such that u can be constructed by uâ€² (or uâ€² and uâ€²â€², respectively) and using table
algorithm SINC.
Proof. Let t âˆˆ N be a removal node and d âˆˆ Dtâ€² \Dt with child node tâ€² âˆˆ N . We show that there exists a
tuple uâ€² in table Ï„tâ€² for node t
â€² such that u can be constructed using uâ€² by SINC (Algorithm 2). Since u is
a local partial solution, there exists a partial solution uÌ‚ = (ZÌ‚,MÌ‚, PÌ‚, CÌ‚) for node t, satisfying the conditions
of Definition 4. It is easy to see that uÌ‚ is also a partial solution for tâ€² and we define uâ€² := uÌ‚t
â€²
, which is the
projection of uÌ‚ onto the bag of tâ€². Apparently, the tuple uâ€² is a local partial solution for node tâ€² according
to Definition 4. Then, u can be derived using SINC algorithm and uâ€². By similar arguments, we establish
the proposition for a âˆˆ attâ€² \ att and the remaining node types. Hence, the propositions sustains.
Theorem 2. Given a default theory D, the algorithm DPSINC and runs in time O(42
22
k+2
Â· â€–S(D)â€–), where
k := tw(S(D)) is the treewidth of the semi-incidence graph S(D).
First, we give a proposition on worst-case space requirements in tables for the nodes of our algorithm.
Proposition 7. Given a default theory D, an LTD T = (T, Ï‡) with T = (N, Â·, Â·) of the semi-incidence
graph S(D), and a node t âˆˆ N . Then, there are at most 2k+1 Â· 22k+1 Â· 4(3k+1Â·22
k+1
Â·22
2k+1
) tuples in Ï„t using
algorithm DPSINC for width k of T .
Proof. (Sketch) Let D be the given default theory, T = (T, Ï‡) an LTD of the semi-incidence graph S(D),
where T = (N, Â·, Â·), and t âˆˆ N a node of the TD. Then, by definition of a decomposition of the semi-
incidence graph for each node t âˆˆ N , we have |Ï‡(t)| âˆ’ 1 â‰¤ k. In consequence, we can have at most
2k+1 many witness defaults and 22
k+1
many witnesses models. Each set P may contain a set of witness
proof tuples of the form ã€ˆÏƒ,B,Rã€‰, with at most 3k+1 many witness state Ïƒ mappings, 2k+1 many backfire
13
Algorithm 3: Algorithm NGDS(T ) for computing next characteristic generating default.
In: TD T = (T, Â·) with T = (N, Â·, n), solution tuples S, total ordering â‰º of orig(Â· Â· Â· ).
Out: Next solution tuples using â‰º.
1 for iterate t in post-order(T,n) do
2 Child-Tabs := {Tables[tâ€²] | tâ€² is a child of t in T}
3 tÌ‚ := parent of t
4 S[t] â† direct successor sâ€²  S[t] in origtÌ‚(S[tÌ‚])
5 if S[t] defined then
6 for iterate tâ€² in Child-Tabs do
7 for iterate tâ€²â€² in pre-order(T,tâ€™) do
8 tÌ‚â€²â€² := parent of tâ€²â€²
9 S[tâ€²â€²] â† â‰º-smallest element in origtÌ‚â€²â€²(S[tÌ‚â€²â€²])
10 return S
11 return undefined
witness models B, and 222
k+1
many required witnesses model sets. In the end, we need to distinguish
2k+1 Â· 22k+1 Â· 2(3k+1Â·2k+1Â·22
2k+1
) different witnesses of a tuple in the table Ï„t for node t. For each witness,
we can have at most 2(3
k+1Â·22
k+1
Â·22
2k+1
) many counter-witnesses per witness default, witness models, and
required witness model sets. Thus, there are at most 2k+1 Â· 22k+1 Â· 4(3k+1Â·22
k+1
Â·22
2k+1
) tuples in table Ï„t for
node t. In consequence, we established the proposition.
Proof of Theorem 2. Let D be a default theory, S(D) = (V, Â·) its semi-incidence graph, and k be the
treewidth of S(D). Then, we can compute in time 2O(k
3) Â· |V | an LTD of width at most k [4]. We take such
a TD and compute in linear time a nice TD [4]Let T = (T, Ï‡) be such a nice TD with T = (N, Â·, Â·). Since the
number of nodes in N is linear in the graph size and since for every node t âˆˆ N the table Ï„t is bounded by
2k+1 Â· 22k+1 Â· 4(3k+1Â·22
k+1
Â·22
2k+1
) according to Proposition 7, we obtain a running time of O(422
2k+2
Â· â€–S(D)â€–).
Consequently, the theorem sustains.
Theorem 3. Given a default theory D, the algorithm DPSINC can be used as a preprocessing step to
construct tables from which we can correctly solve the problem EnumSE; more precisely, by first running
Algorithm DPSINC and then Algorithm NGDSINC(T ) on the resulting tables of Algorithm DPSINC until
NGDSINC(T ) returns â€œundefinedâ€.
Observation 2. Let D be a default theory, T = (T, Ï‡) where T = (N, Â·, Â·) be an LTD of S(D) and t âˆˆ N
be a node. Then, for each partial solution u = ã€ˆZ,M,P, Cã€‰ for t, M,P and C are functional dependent
from Z, i.e., for any partial solution uâ€² = ã€ˆZ,Mâ€²,P â€², Câ€²ã€‰ for t, we have u = uâ€².
Proof. The claim immediately follows from Definition 2.
Lemma 5. Let D be a default theory, T = (T, Ï‡) with T = (N, Â·, Â·) be an LTD of S(D), and Z be a
characterizing generating default. Then, there is a unique set of tuples S, containing exactly one tuple per
node t âˆˆ N containing only local partial solutions of the unique partial solution for Z.
Proof. By Observation 1, given Z, we can construct one unique partial solution uÌ‚ = ã€ˆZ,M,P, Cã€‰ for n.
We then define the set S by S :=
â‹ƒ
tâˆˆN{uÌ‚t}. Assume that there is a different set Sâ€² 6= S containing also
exactly one tuple per node t âˆˆ N . Then there is at least one node t âˆˆ N , for which the corresponding
tuples u âˆˆ S, uâ€² âˆˆ Sâ€² differ (u 6= uâ€²), since uÌ‚ is unique and the computation uÌ‚t is defined in a deterministic,
functional way (see Definition 4). Hence, either uÌ‚t 6= u or uÌ‚t 6= uâ€², leading to the claim.
14
Proposition 8. Let D be a default theory, T = (T, Ï‡) with T = (N, Â·, Â·) be an LTD of S(D), and Z be a
characterizing generating default. Moreover, let S be the unique set of tuples, containing exactly one tuple
per node t âˆˆ N and containing only local partial solutions of the unique partial solution for Z. Given S,
and tables of Algorithm SINC, one can compute in time O(â€–Dâ€–) a characterizing generating default Z â€²
with Z â€² 6= Z, assuming one can get for a specific tuple u for node t its corresponding â‰º-ordered predecessor
tuple set origt(u) of tuples in the child node(s) of t in constant time.
Proof. Note that with Z, it is easy to determine, which element of S belongs to which node t in T , hence,
we can construct a mapping S : N â†’ S. With S, we can easily apply algorithm NGD, which is given
in Algorithm 3, in order to construct a different solution S â€² in a systematic way with linear time delay,
since T is nice.
Proof of Theorem 3 (Sketch). First, we construct an LTD T = (T, Ï‡) with T = (N, Â·) for graph S(D). Then
we run our algorithm DPSINC and get tables for each TD node. In order to enumerate all the characterizing
generating defaults, we investigate each of these tuple, which lead to a valid characterizing generating default
(see proof of Theorem 1). For each of these tuples (if exist), we construct a first solution S (if exist) (as done
in Lines 6 to 9 of Algorithm 3) using origt(Â·, Â·), and total order â‰º. Thereby, we keep track of which tuple
in S belongs to which node, resulting in the mapping S (see proof of Proposition 4). Note that origt(Â·, Â·)
and â‰º can easily be provided by remembering for each tuple an ordered set of predecessor tuple sets during
construction (using table algorithm SINC). Now, we call algorithm NGDS(T ) multiple times, by outputting
and passing the result again as argument, until the return value is undefined, enumerating solutions in a
systematic way. Using correctness results (by Theorem 1), and completeness result for enumeration by
Corollary 1, we obtain only valid solution sets, which directly represent characterizing generating defaults
and, in particular, we do not miss a single one. Observe, that we do not get duplicates (see Lemma 3).
15

