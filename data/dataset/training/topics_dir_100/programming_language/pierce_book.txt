Type Systems
for Programming Languages
Benjamin C. Pierce
bcpierce@cis.upenn.edu
Working draft of January 15, 2000
This is preliminary draft of a book in progress. Comments, suggestions, and
corrections are welcome.
Contents
Preface 8
1 Introduction 13
1.1 What is a Type System? . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
1.2 A Brief History of Type . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
1.3 Applications of Type Systems . . . . . . . . . . . . . . . . . . . . . . . 16
1.4 Related Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
2 Mathematical Preliminaries 18
2.1 Sets and Relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
2.2 Induction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
2.3 Term Rewriting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
3 Untyped Arithmetic Expressions 20
3.1 Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
3.2 Formalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
3.3 Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
3.4 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
3.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
3.6 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
4 The Untyped Lambda-Calculus 31
4.1 Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
Operational Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . 34
4.2 Programming in the Lambda-Calculus . . . . . . . . . . . . . . . . . . 34
1
4.3 Is the Lambda-Calculus a Programming Language? . . . . . . . . . . 39
4.4 Formalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
Substitution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
Operational Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . 43
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
4.5 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
5 Implementing the Lambda-Calculus 45
5.1 Nameless Representation of Terms . . . . . . . . . . . . . . . . . . . . 45
Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
Shifting and Substitution . . . . . . . . . . . . . . . . . . . . . . . . . 48
Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
5.2 A Concrete Realization . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
Shifting and Substitution . . . . . . . . . . . . . . . . . . . . . . . . . 50
Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
5.3 Ordinary vs. Nameless Representations . . . . . . . . . . . . . . . . . 51
6 Typed Arithmetic Expressions 52
6.1 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
6.2 The Typing Relation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
6.3 Properties of Typing and Reduction . . . . . . . . . . . . . . . . . . . 53
Typing Derivations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
Typechecking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
Safety = Preservation + Progress . . . . . . . . . . . . . . . . . . . . 54
6.4 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
6.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
7 Simply Typed Lambda-Calculus 58
7.1 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
7.2 The Typing Relation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
7.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
7.4 Properties of Typing and Reduction . . . . . . . . . . . . . . . . . . . 62
Typechecking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
Typing and Substitution . . . . . . . . . . . . . . . . . . . . . . . . . 64
Type Soundness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
7.5 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
7.6 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
8 Extensions 67
8.1 Base Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
8.2 Unit type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
8.3 Let bindings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
8.4 Records and Tuples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
8.5 Variants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
8.6 General recursion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
8.7 Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
8.8 Lazy records and let-bindings . . . . . . . . . . . . . . . . . . . . . . . 75
9 References 76
9.1 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
10 Exceptions 80
10.1 Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
10.2 Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
11 Type Equivalence 81
12 Definitions 83
12.1 Type Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
12.2 Term Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
13 Subtyping 86
13.1 The Subtype Relation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
13.2 Metatheory of Subtyping . . . . . . . . . . . . . . . . . . . . . . . . . . 91
Algorithmic Subtyping . . . . . . . . . . . . . . . . . . . . . . . . . . 91
Minimal Typing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
13.3 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
13.4 Meets and Joins . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
13.5 Primitive Subtyping . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
13.6 The Bottom Type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
13.7 Other stuff . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
14 Imperative Objects 100
14.1 Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
14.2 Object Generators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
14.3 Subtyping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
14.4 Basic classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
14.5 Extending the Internal State . . . . . . . . . . . . . . . . . . . . . . . . 105
14.6 Classes with “Self” . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
15 Recursive Types 109
15.1 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
Hungry Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
Recursive Values from Recursive Types . . . . . . . . . . . . . . . . 110
Untyped Lambda-Calculus, Redux . . . . . . . . . . . . . . . . . . . 110
Recursive Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
15.2 Equi-recursive Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
ML Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
15.3 Iso-recursive Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
15.4 Subtyping and Recursive Types . . . . . . . . . . . . . . . . . . . . . . 116
16 Case Study: Featherweight Java 117
17 Type Reconstruction 118
17.1 Substitution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
17.2 Universal vs. Existential Type Variables . . . . . . . . . . . . . . . . . 119
17.3 Constraint-Based Typing . . . . . . . . . . . . . . . . . . . . . . . . . . 121
17.4 Unification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
17.5 Principal Typings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
17.6 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
18 Universal Types 130
18.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
18.2 Varieties of Polymorphism . . . . . . . . . . . . . . . . . . . . . . . . . 131
18.3 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
18.4 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
Warm-ups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
Polymorphic Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
Impredicative Encodings . . . . . . . . . . . . . . . . . . . . . . . . . 136
18.5 Metatheory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
Soundness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
Strong Normalization . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
Erasure and Typeability . . . . . . . . . . . . . . . . . . . . . . . . . 140
Type Reconstruction . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
18.6 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
Nameless Representation of Types . . . . . . . . . . . . . . . . . . . 141
ML Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
18.7 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
19 Existential Types 144
19.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
19.2 Data Abstraction with Existentials . . . . . . . . . . . . . . . . . . . . 149
Abstract Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
Existential Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
Objects vs. ADTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
19.3 Encoding Existentials . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
19.4 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156
19.5 Historical Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156
20 Bounded Quantification 157
20.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157
20.2 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
Kernel F<: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
Full F<: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
20.3 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
Encoding Products . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
Encoding Records . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
Church Encodings with Subtyping . . . . . . . . . . . . . . . . . . . 165
20.4 Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
20.5 Bounded Existential Types . . . . . . . . . . . . . . . . . . . . . . . . . 171
20.6 Historical Notes and Further Reading . . . . . . . . . . . . . . . . . . 171
21 Implementing Bounded Quantification 173
21.1 Promotion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
21.2 Minimal Typing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
21.3 Subtyping in Fk
<:
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176
21.4 Subtyping in Ff<: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
21.5 Undecidability of Subtyping in Full F<: . . . . . . . . . . . . . . . . . . 181
22 Denotational Semantics 185
22.1 Types as Subsets of the Natural Numbers . . . . . . . . . . . . . . . . 186
The Universe of Natural Numbers . . . . . . . . . . . . . . . . . . . 186
Subset Semantics for F<: . . . . . . . . . . . . . . . . . . . . . . . . . 187
Problems with the Subset Semantics . . . . . . . . . . . . . . . . . . 190
22.2 The PER interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
Interpretation of Types . . . . . . . . . . . . . . . . . . . . . . . . . . 191
Applications of the PER model . . . . . . . . . . . . . . . . . . . . . 192
Digression on full abstraction . . . . . . . . . . . . . . . . . . . . . . 196
22.3 General Recursion and Recursive Types . . . . . . . . . . . . . . . . . 196
Continuous Partial Orders . . . . . . . . . . . . . . . . . . . . . . . . 196
The CUPER Interpretation . . . . . . . . . . . . . . . . . . . . . . . . 200
Interpreting Recursive Types . . . . . . . . . . . . . . . . . . . . . . 201
22.4 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
23 Polymorphic Update 204
24 Type Operators and Kinding 206
24.1 Intuitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
24.2 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
25 Higher-Order Polymorphism 213
25.1 Higher-Order Universal Types . . . . . . . . . . . . . . . . . . . . . . 213
25.2 Higher-Order Existential Types . . . . . . . . . . . . . . . . . . . . . . 215
25.3 Type Equivalence and Reduction . . . . . . . . . . . . . . . . . . . . . 218
25.4 Soundness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
26 Implementing Higher-Order Systems 221
27 Higher-Order Subtyping 224
28 Pure Objects and Classes 228
28.1 Simple Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
28.2 Subtyping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
28.3 Interface Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230
28.4 Sending Messages to Objects . . . . . . . . . . . . . . . . . . . . . . . 230
28.5 Simple Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
28.6 Adding Instance Variables . . . . . . . . . . . . . . . . . . . . . . . . . 232
28.7 Classes with “Self” . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234
28.8 Class Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
28.9 Generic Inheritance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
29 Structures and Modules 238
29.1 Basic Structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238
29.2 Record Kinds and Subkinding . . . . . . . . . . . . . . . . . . . . . . . 242
29.3 Singleton Kinds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244
29.4 Dependent Function and Record Kinds . . . . . . . . . . . . . . . . . 245
29.5 Dependent Record Expressions and Records of Types . . . . . . . . . 246
29.6 Higher-Kind Singletons . . . . . . . . . . . . . . . . . . . . . . . . . . 247
29.7 First-class Substructures and Functors . . . . . . . . . . . . . . . . . . 248
29.8 Second-Class Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . 250
29.9 Other points to make . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250
30 Planned Chapters 251
Appendices 253
A Solutions to Selected Exercises 253
B Summary of Notation 266
B.1 Metavariable Conventions . . . . . . . . . . . . . . . . . . . . . . . . . 266
B.2 Rule Naming Conventions . . . . . . . . . . . . . . . . . . . . . . . . . 266
C Suggestions for Larger Projects 268
C.1 Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268
C.2 Encodings of Logics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
C.3 Type Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
C.4 Other Type Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
C.5 Sources for Additional Ideas . . . . . . . . . . . . . . . . . . . . . . . . 271
D Bluffers Guide to OCaml 272
E Running the Checkers 273
E.1 Preparing Your Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
E.2 Ascii Equivalents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
E.3 Running the Checker . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274
E.4 Compiling the Checkers . . . . . . . . . . . . . . . . . . . . . . . . . . 274
E.5 Objective Caml . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274
Bibliography 275
Index 288
Preface
The study of type systems for programming languages has emerged over the past
decade as one of the most active areas of computer science research, with impor-
tant applications in software engineering, programming language design, high-
performance compiler implementation, and security of information networks.
This text aims to introduce the area to beginning graduate students and ad-
vanced undergraduates. A broad range of core topics are covered in detail, includ-
ing simple type systems, type reconstruction, universal and existential polymor-
phism, subtyping, bounded quantification, recursive types, and type operators.
Early chapters on the untyped lambda-calculus help make the book self-contained,
allowing it to be used in courses for students with no background in the theory of
programming languages.
The book adopts a strongly pragmatic approach throughout: a typical chapter
begins with programming examples motivating a new typing feature, develops the
feature and its basic metatheory, adduces typechecking algorithms, and illustrates
these with executable ML typecheckers. The underlying semantic formalism is
almost entirely operational, for a close correspondence with familiar programming
languages.
A repeated theme is the theoretical properties required to build sound and com-
plete typechecking algorithms. Both the proofs and the algorithms themselves
are presented in detail. Moreover, each chapter is accompanied by a running im-
plementation that can be used as a basis for experimentation by students, class
projects, etc.
Audience
The book is aimed at graduate students, including both the general graduate pop-
ulation as well as students intending to specialize in programming language re-
search. For the former, it should serve to introduce a number of key ideas from
the design and analysis of programming languages, with type systems as an or-
ganizing structure. For the latter, it should provide sufficient background to pro-
ceed directly on to the research literature. The book is suitable for self-study by
8
January 15, 2000 PREFACE 9
researchers in other areas who want to learn something about type systems, and
should be a useful reference for experts. The first several chapters should be usable
in upper-division undergraduate courses.
Goals
The mail goals of the book are:
 Accessibility. A reader should be able to approach the book with little or no
background in theory of programming languages.
 Coverage of core topics. By the end of the book, the reader should fully
equipped to tackle the research literature in type systems.
 Pragmatism. The book stays as close as possible to programming languages
(sometimes at the expense of topics that might be included in a book written
from the perspective of typed lambda-calculi and logic). In particular, the
underlying computational substrate is a call-by-value lambda-calculus.
 Diversity. The book tries to show the leafiness of the topic rather than trying
to unify all the threads addressed in the book. (Of course, I’ve unified as
many of the threads as I could manage.)
 Honesty. Every type system discussed in the book must be implemented.
Every example must run.
To achieve all this, a few other desirable properties have been sacrificed.
 Completeness of coverage (probably impossible in one book, certainly in a
textbook).
 Efficiency (as opposed to termination) of the typechecking algorithms de-
scribed. This is not a book about industrial-strength typechecker implemen-
tation.
Required Background
No background in the theory of programming languages is assumed, but students
should should approach the book with a degree of prior mathematical maturity
(in particular, rigorous undergraduate coursework in discrete mathematics, algo-
rithms, and elementary logic).
Readers should also be familiar with some higher-order functional program-
ming language (Scheme, ML, Haskell, etc.), and basic concepts of programming
languages and compilers (abstract syntax, Backus-Naur grammars, evaluation, ab-
stract machines, etc.). This material is available in many excellent undergraduate
texts. I particularly like the one by Friedman, Wand, and Haynes [FWH92].
January 15, 2000 PREFACE 10
Course Outlines
In an advanced graduate course, it should be possible to cover essentially the
whole book in a semester. For an undergraduate or beginning graduate course,
there are two basic paths through the material:
 type systems in programming (omitting implementation chapters), and
 basic theory and implementation (omitting or skimming the end of the book).
Shorter courses can also be constructed by selecting particular chapters of interest.
In a course where term projects are a major part of the work, it may be desir-
able to postpone some of the theoretical material (e.g., denotational semantics, and
perhaps some of the deeper chapters on implementation) so that a broad range of
examples can be covered before the point where students have to choose project
topics.
Chapter Dependencies
The major dependencies between chapters are outlined in Figure 1. Solid lines
indicate that the later chapter is best read after the earlier. Dotted lines mean that
the chapters can be read out of order except for some sections.
Typographic Conventions
Most chapters develop the features of some type system in a discursive way, then
define the system formally as a collection of inference rules with brackets above
and below to set them off from the surrounding text. For the sake of completeness,
these definitions are usually presented in full, including not only the new rules for
the features under discussion at the moment, but also the rest of the rules needed
to constitute a complete calculus. The new parts are set on a gray background to
make the “delta” from previous systems visually obvious.
An unusual feature of the book’s production is that all the examples are me-
chanically checked during typesetting: an automatic script goes through each chap-
ter, extracts the examples, generates and compiles a custom typechecker contain-
ing just the features under discussion, applies it to the examples, and inserts the
checker’s responses in the text. The system that does the hard parts of this, called
TinkerType, was developed by Michael Levin and myself [LP99].
Electronic resources
A collection of implementations for the typecheckers and interpreters described in
the text is available at http://www.cis.upenn.edu/~bcpierce/typesbook. These
January 15, 2000 PREFACE 11
2
3
4
6
5
7
7.5
8 11
13
15
17 18
24
9
10
14
12
21
15.4
16 2822
22.3
19
20
20.6
23 27
26
25
Figure 1: Chapter dependencies
January 15, 2000 PREFACE 12
implementations have been carefully polished for readability and modifiability,
and have been used very successfully by my students as the basis of both small im-
plementation exercises and larger course projects. The implementation language is
the Objective Caml dialect of ML, freely available through http://caml.inria.fr.
Corrections for any errors discovered in the text will also be made available at
http://www.cis.upenn.edu/~bcpierce/typesbook.
Acknowledgements
Many!
Chapter 1
Introduction
Proofs of programs are too boring for the social process of mathematics to work.
— Richard DeMillo, Richard Lipton, and Alan Perlis [DLP79]
...So don’t rely on social processes for verification.
— David Dill
Despite decades of concern in both industry and academia, expensive failures of
large software projects are common. Proposed approaches to improving software
quality include—among other ideas—a broad spectrum of techniques for helping
ensure that a software system behaves correctly with respect to some specifica-
tion, implicit or explicit, of its desired behavior. On one end of this spectrum are
powerful frameworks such as algebraic specification languages, modal logics, and
denotational semantics; these can be used to express very general correctness prop-
erties but are cumbersome to use and demand significant involvement by the pro-
grammer not only in the application domain but also in the formal subtleties of the
framework itself. At the other end are techniques of much more limited power—so
limited that they can be built into compilers or linkers and thus “applied” even by
programmers unfamiliar with the underlying theories. Such methods often take
the form of type systems.
1.1 What is a Type System?
Type systems are generally formulated as collections of rules for checking the “con-
sistency” of programs.
This kind of checking exposes not only trivial mental slips, but also deeper
conceptual errors, which frequently manifest as type errors.
A useful—though rough—distinction divides the world of programming lan-
guages into two parts:
13
January 15, 2000 1. INTRODUCTION 14
 Untyped — programs simply execute flat out; there is no attempt to check
“consistency of shapes”
 Typed — some attempt is made, either at compile time or at run-time, to
check shape-consistency
Among typed languages, we can break things down further:
Statically checked Dynamically checked
Strongly typed ML, Haskell, Pascal (almost),
Java (almost)
Lisp, Scheme
Weakly typed C, C++ Perl
1.2 A Brief History of Type
The following table presents a (rough and incomplete) chronology of some impor-
tant high points in the history of type systems in computer science. Related devel-
opments in logic are also included (in italics), to give a sense of the importance of
this field’s contributions.
late 1800s Origins of formal logic [?]
early 1900s Formalization of mathematics [WR25]
1930s Untyped lambda-calculus [Chu41]
1940s Simply typed lambda-calculus [Chu40, CF58]
1950s Fortran [Bac81]
1950s Algol [N+63]
1960s Automath project [dB80]
1960s Simula [BDMN79]
1970s Martin-Löf type theory [Mar73, Mar82, SNP90]
1960s Curry-Howard isomorphism [How80]
1970s System F, F! [Gir72]
1970s polymorphic lambda-calculus [Rey74]
1970s CLU [LAB+81]
1970s polymorphic type inference [Mil78, DM82]
1970s ML [GMW79]
1970s intersection types [CDC78, CDCS79, Pot80]
1980s NuPRL project [Con86]
1980s subtyping [Rey80, Car84, Mit84a]
1980s ADTs as existential types [MP88]
1980s calculus of constructions [Coq85, CH88]
1980s linear logic [Gir87, GLT89]
1980s bounded quantification [CW85, CG92, CMMS94]
January 15, 2000 1. INTRODUCTION 15
1980s Edinburgh Logical Framework [HHP92]
1980s Forsythe [Rey88]
1980s pure type systems [Bar92a]
1980s dependent types and modularity [Mac86]
1980s Quest [Car91]
1980s Extended Calculus of Constructions [Luo90]
1980s Effect systems [?, TJ92, TT97]
1980s row variables and extensible records [Wan87, Rém89, CM91]
1990s higher-order subtyping [Car90, CL91, PT94]
1990s typed intermediate languages [TMC+96]
1990s Object Calculus [AC96]
1990s translucent types and modarity [HL94, Ler94]
1990s typed assembly language [MWCG98]
In computer science, the earliest type systems, beginning in the 1950s (e.g.,
FORTRAN), were used to improve efficiency of numerical calculations by distin-
guishing between natural-number-valued variables and arithmetic expressions and
real-valued ones, allowing the compiler to use different representations and gen-
erate appropriate machine instructions for arithmetic operations. In the late 1950s
and early 1960s (e.g., ALGOL), the classification was extended to structured data
(arrays of records, etc.) and higher-order functions. Beginning in the 1970s, these
early foundations have been extended in many directions...
 parametric polymorphism allows a single term to be used with many differ-
ent types (e.g., the same sorting routine might be used to sort lists of natural
numbers, lists of reals, lists of records, etc.), encouraging code reuse;
 module systems support programming in the large by providing a frame-
work for defining (and automatically checking) interfaces between the parts
of a large software system;
 subtyping and object types address the special needs of object-oriented pro-
gramming styles;
 connections are being developed between the type systems of programming
languages, the specification languages used in program verification, and the
formal logics used in theorem proving.
All of these (among many others) are still areas of active research.
I’d like to include here a longer discussion of the historical origins of various ideas in
type systems. This is usually how I use the whole first lecture of my graduate course, and
it goes down very well, but to put it all in writing will require a bit of research.
January 15, 2000 1. INTRODUCTION 16
1.3 Applications of Type Systems
Beyond their traditional benefits of robustness and efficiency, type systems play
an increasingly central role in computer and network security: static typing lies
at the core of the security models of Java and JINI, for example, and is the main
enabling technology for Proof-Carrying Code. Type systems are used to organize
compilers, verify protocols, structure information on the web, and even model
natural languages.
Short sketches of some of these diverse applications...
 In programming in the large (module systems, interface definition languages, etc.)
 In compiling and optimization (static analyses, typed intermediate languages, typed
assembly languages, etc.)
 In “self-certification” of untrusted code (so-called “proof-carrying code” [NL96, Nec97,
NL98])
 In security
 In theorem proving
 In databases
 In linguistics (categorial grammar [Ben95, vBM97, etc.] , and maybe something
seminal by Lambek)
 In Y2K conversion tools
 DTDs and other “web metadata” (note from Henry Thompson: DTDs were origi-
nally designed for SGML because of the expense of cancelling huge typesetting runs
due to errors in the markup!)
1.4 Related Reading
While this book attempts to be self contained, it is far from comprehensive: the
area is too large, and can be approached from too many angles, to do it justice in
one book. Here are a few other good entry points:
 Handbook articles by Cardelli [Car96] and Mitchell [Mit90] offer quick intro-
ductions to the area. Barendregt’s article [Bar92b] is for the more mathemat-
ically inclined.
 Mitchell’s massive textbook on programming languages [Mit96] covers basic
lambda calculus, a range of type systems, and many aspects of semantics.
January 15, 2000 1. INTRODUCTION 17
 Abadi and Cardelli’s A Theory of Objects [AC96] develops much of the same
material as this present book, de-emphasizing implementation aspects and
concentrating instead on the application of these ideas in a foundation treat-
ment of object-oriented programming. Kim Bruce’s forthcoming Foundations
of Object-Oriented Programming Languages will cover similar ground. Intro-
ductory material on object-oriented type systems can also be found in [PS94,
Cas97].
 Reynolds [Rey98] Theories of Programming Languages, a graduate-level survey
of the theory of programming languages, includes beautiful expositions of
polymorphic typing and intersection types.
 Girard’s Proofs and Types [GLT89] treats logical aspects of type systems (the
Curry-Howard isomorphism, etc.) thoroughly. It also includes a description
of System F from its creator, and an appendix introducing linear logic.
 The Structure of Typed Programming Languages, by Schmidt [?], develops core
concepts of type systems in the context of programming language design,
including several chapters on conventional imperative languages. Simon
Thompson’s Type Theory and Functional Programming [Tho91] focuses on con-
nections between functional programming (in the “pure functional program-
ming” sense of Haskell or Miranda) and constructive type theory, viewed
from a logical perspective.
 Semantic foundations for both untyped and typed languages are covered in
depth in textbooks by Gunter [Gun92] and Winskel [Win93].
 Hindley’s monograph Basic Simple Type Theory [Hin97] is a wonderful com-
pendium of results about the simply typed lambda-calculus and closely re-
lated systems. Its coverage is deep rather than broad.
If you want a single book besides the one you’re holding, I’d recommend either
Mitchell or Abadi and Cardelli.
Chapter 2
Mathematical Preliminaries
This chapter mostly still needs to be written. I do not intend to go into a great deal of detail
(a student that needs a real introduction to these topics is going to be lost in a couple of
chapters anyway) — just remind the reader of basic concepts and notations.
Before getting started, we need to establish some common notation and state
a few basic mathematical facts. Most readers should be able to skim this chapter
and refer back to it as necessary.
2.1 Sets and Relations
2.2 Induction
2.2.1 Definition: A partially ordered set S is said to be well founded if it contains
no infinite decreasing chains—that is, if there is no infinite sequence s1; s2; s3; : : :
of elements of S such that each si+1 is strictly less than si. 2
2.2.2 Theorem [Principle of well-founded induction]: Suppose that the set S is
well founded and that P is some predicate on the elements of S. If we can show,
for each s : S, that (8s 0 < s: P(s 0)) implies P(s), then we may conclude that P(s)
holds for every s : S. 2
2.2.3 Corollary [Principle of induction on the natural numbers]: Suppose that P
is some predicate on the natural numbers. If we can show, for each m, that (8i <
m: P(i)) implies P(m), then we may conclude that P(n) holds for every n. 2
Proof: The set of natural numbers is well founded. 2
18
January 15, 2000 2. MATHEMATICAL PRELIMINARIES 19
2.2.4 Corollary [Principle of lexicographic induction]: Define the following “dic-
tionary ordering” on pairs of natural numbers: (m;n) < (m 0; n 0) iff m < m 0 or
m = m 0 and n < n 0.
Now, suppose that P is some predicate on pairs of natural numbers. If we can
show, for each (m;n), that (8(m 0; n 0) < (m;n): P(m 0; n 0)) implies P(m;n), then
we may conclude that P(m;n) holds for every pair (m;n).
(A similar principle holds for lexicographically ordered triples, quadruples,
etc.) 2
Proof: The lexicographic ordering on pairs of numbers is well founded. 2
2.3 Term Rewriting
(or maybe this material should be folded into the next chapter...)
Chapter 3
Untyped Arithmetic
Expressions
Quite a bit of text and a few technical definitions are still missing here. The idea is to
introduce the basic ideas of defining a language and its operational semantics formally, and
proving some simple properties by structural induction, before getting to the complexities
(esp. name binding) of the full-blown lambda-calculus.
3.1 Basics
We begin with a very simple language for calculating with numbers and booleans.
true;
I true
if false then true else false;
I false
0;
I 0
succ (succ (succ 0));
I 3
succ (pred 0);
I 1
iszero (pred (succ 0));
20
January 15, 2000 3. UNTYPED ARITHMETIC EXPRESSIONS 21
I true
iszero (succ (succ 0));
I false
Throughout the book, the symbol I will be used to display the results of eval-
uating examples. You can think of the lines marked with I as the responses from
an interactive interpreter when presented with the preceding inputs.
For brevity, the examples use standard arabic numerals as shorthand for nested
applications of succ to 0, writing succ(succ(succ(0))) as 3.
Syntax
The syntax of arithmetic expressions comprises several kinds of terms. The con-
stants true, false, and 0 are terms. If t is a term, then so are succ t, pred t, and
iszero t. Finally, if t1, t2, and t3 are terms, then so is if t1 then t2 else t3.
These forms are summarized in the following abstract grammar:
t ::= (terms...)
true constant true
false constant false
if t then t else t conditional
0 constant zero
succ t successor
pred t predecessor
iszero t zero test
Evaluation
3.2 Formalities
Syntax
3.2.1 Definition [Terms]: The set of terms is the smallest set T such that
1. ftrue; false; 0g  T ;
2. if t1 2 T , then fsucc t1; pred t1; iszero t1g  T ;
3. if t1 2 T , t2 2 T , and t3 2 T , then if t1 then t2 else t3 2 T .
These three clauses capture exactly what is meant by the productions in the more
concise and readable “abstract grammar” notation that we used above. 2
January 15, 2000 3. UNTYPED ARITHMETIC EXPRESSIONS 22
Definition 3.2.1 is an example of an inductive definition. Since inductive defi-
nitions are ubiquitous in the study of programming languages, it is worth pausing
for a moment to examine this one in detail. Here is an alternative definition of the
same set, in a more concrete style.
3.2.2 Definition [Terms, more concretely]: For each natural number i, define a set
Si as follows:
S0 = ;
Si+1 = ftrue; false; 0g
[ fsucc t1; pred t1; iszero t1 jt1 2 Sig
[ fif t1 then t2 else t3 j t1; t2; t3 2 Sig:
Finally, let
S =
[
i
Si:
That is, S0 is empty; S1 contains just the constants; T2 contains the constants plus
the phrases that can be built with constants and just one succ, pred, iszero, or
if; S3 contains these plus all phrases that can be built using succ, pred, iszero,
and if on phrases in S2; and so on. S collects together all the phrases that can be
built in this way—i.e., all phrases built by some finite number of applications and
abstractions, beginning with just variables. 2
3.2.3 Exercise [Quick check]: List the elements of S3. 2
3.2.4 Exercise: Show that the sets Si are cumulative—that is, that for each i we
have Si  Si+1. 2
Now let us check that the two definitions of terms actually define the same set.
We’ll do the proof in quite a bit of detail, to show how all the pieces fit together.
3.2.5 Proposition: T = S. 2
Proof: T was defined as the smallest set satisfying certain conditions. So it suffices
to show (a) that S satisfies these conditions, and (b) that any set satisfying the
conditions has S as a subset (i.e., that S is the smallest set satisfying the conditions).
For part (a), we must check that each of the three conditions in Definition 3.2.1
holds of S. First, since S1 = ftrue; false; 0g and S1 
S
i Si, it is clear that the
constants are in S. Second, if t1 2 S, then (since S =
S
i Si) there must be some
i such that ti 2 Si. But then, by the definition of Si+1, we must have succ t1 2
Si+1, hence succ t1 2 S; similarly, we see that pred t1 2 S and iszero t1 2 S.
Third, if t1 2 S, t2 2 S, and t3 2 S, then if t1 then t2 else t3 2 S, by a
similar argument.
For part (b), suppose that some set S 0 satisfies the three conditions in Defini-
tion 3.2.1. We will argue, by induction on n, that every Sn  S 0, from which it
January 15, 2000 3. UNTYPED ARITHMETIC EXPRESSIONS 23
will clearly follow that S  S 0. Suppose that Sm  S 0 for all m < n; we must
then show that Sn  S 0. Since the definition of Sn has two clauses (for n = 0 and
n = i+ 1), there are two cases to consider.
 If n = 0, then Sn = ;. But ;  S 0 trivially.
 Otherwise, n = i + 1 for some i. Let t be some element of Si+1. Since Si+1
is defined as the union of three smaller sets, t must come from one of these
sets, and there are three possibilities to consider:
1. t is a constant, hence t 2 S 0 by condition (1).
2. t has the form succ t1, pred t1, or iszero t1, for some t1 2 Si. But
then, by the induction hypothesis, t1 2 S 0, and so, by condition (2),
t 2 S 0.
3. t has the form if t1 then t2 else t3, for some t1; t2; t3 2 Si. Again,
by the induction hypothesis, t1, t2, and t3 are all in S 0, and hence, by
condition (3), so is t.
Thus, we have shown that each Si  S 0. By the definition of S as the union of all
the Si, this gives S  S 0, completing the argument. 2
The explicit characterization of T justifies an important principle for reasoning
about its elements. If t 2 T, then one of three things must be true about t—either
1. t is a constant, or
2. t has the form succ t1, pred t1, or iszero t1 for some smaller term t1, or
3. t has the form if t1 then t2 else t3 for some smaller terms t1, t2, and t3.
We can put this observation to work in two ways: we can give inductive definitions
of functions over the set of terms, and we can give inductive proofs of properties of
terms. For example, here is a simple inductive definition of a function mapping
each term t to the set of constants used in t.
3.2.6 Definition: The set of constants appearing in a term t, written Consts(t), is
defined as follows:
Consts(true) = ftrueg
Consts(false) = ffalseg
Consts(iszero) = fiszerog
Consts(succ t1) = Consts(t1)
Consts(pred t1) = Consts(t1)
Consts(iszero t1) = Consts(t1)
Consts(if t1 then t2 else t3) = Consts(t1) [ Consts(t1) [ Consts(t1) 2
January 15, 2000 3. UNTYPED ARITHMETIC EXPRESSIONS 24
Another property of terms that can be calculated by an inductive defintion is
their size.
3.2.7 Definition: The size of a term t, written size(t), is defined as follows:
size(true) = 1
size(false) = 1
size(iszero) = 1
size(succ t1) = size(t1) + 1
size(pred t1) = size(t1) + 1
size(iszero t1) = size(t1) + 1
size(if t1 then t2 else t3) = size(t1) + size(t1) + size(t1) + 1
That is, the size of t is the number of nodes in its abstract syntax tree. Similarly,
the depth of a term t, written depth(t), is defined as follows:
depth(true) = 1
depth(false) = 1
depth(iszero) = 1
depth(succ t1) = depth(t1) + 1
depth(pred t1) = depth(t1) + 1
depth(iszero t1) = depth(t1) + 1
depth(if t1 then t2 else t3) = max(depth(t1); depth(t1); depth(t1)) + 1
Equivalently, depth(t), is the smallest i such that t 2 Si. 2
Here is an inductive proof of a simple fact relating the number of constants in
a term to its size.
3.2.8 Lemma: The number of distinct constants in a term t is always smaller than
the size of t (jConsts(t)j  size(t)). 2
Proof: The property in itself is entirely obvious, of course. What’s interesting is
the form of the inductive proof, which we’ll see repeated many times as we go
along.
The proof proceeds by induction on the size of t. That is, assuming the desired
property for all terms smaller than t, we must prove it for t itself; if we can do
this, we may conclude that the property holds for all t. There are three cases to
consider:
Case: t is a constant
Immediate: jConsts(t)j = jftgj = 1 = size(t).
Case: t = succ t1, pred t1, oriszero t1
By the induction hypothesis, jConsts(t1)j  size(t1). We now calculate as follows:
jConsts(t)j = jConsts(t1)j  size(t1) < size(t).
January 15, 2000 3. UNTYPED ARITHMETIC EXPRESSIONS 25
Case: t = if t1 then t2 else t3
By the induction hypothesis, jConsts(t1)j  size(t1) and jConsts(t2)j  size(t2) and
jConsts(t3)j  size(t3). We now calculate as follows: jConsts(t)j = jConsts(t1) [
Consts(t2) [ Consts(t3)j  jConsts(t1)j + jConsts(t2)j + jConsts(t3)j  size(t1) +
size(t2) + size(t3) < size(t). 2
The form of this proof can be clarified by restating it as a general reasoning
principle. (Compare this principle with the induction principle for natural num-
bers on p. 18.)
3.2.9 Theorem [Principle of induction on terms]: Suppose that P is some predi-
cate on terms. If we can show, for each s, that (8r: size(r) < size(s) implies P(r))
implies P(s), then we may conclude that P(t) holds for every term t. 2
Proof: Exercise. 2
Evaluation
3.2.10 Definition: The set of values is the subset of terms defined by the following
abstract grammar:
v ::= (values...)
true value true
false value false
0 zero value
succ v successor value
3.2.11 Definition: The one-step evaluation relation  ! is the smallest relation
containing all instances of the following rules:
if true then t2 else t3  ! t2 (E-BOOLBETAT)
if false then t2 else t3  ! t3 (E-BOOLBETAF)
t1  ! t 01
if t1 then t2 else t3  ! if t 01 then t2 else t3 (E-IF)
t1  ! t 01
succ t1  ! succ t 01 (E-SUCC)
pred 0  ! 0 (E-BETANATPZ)
pred (succ v)  ! v (E-BETANATPS)
t1  ! t 01
pred t1  ! pred t 01 (E-PRED)
January 15, 2000 3. UNTYPED ARITHMETIC EXPRESSIONS 26
iszero 0  ! true (E-BETANATIZ)
iszero (succ v)  ! false (E-BETANATIS)
t1  ! t 01
iszero t1  ! iszero t 01 (E-ISZERO)
2
3.2.12 Definition: The multi-step evaluation relation  !  is the reflexive, transi-
tive closure of one-step evaluation. That is, it is the smallest relation such that
 if t  ! t 0 then t  ! t 0,
 t  ! t for all t, and
 if t  ! t 0 and t 0  ! t 00, then t  ! t 00. 2
3.2.13 Exercise [Quick check]: Rewrite the previous definition using a set of infer-
ence rules to define the relation t  ! t 0. (Solution on page 253.) 2
3.2.14 Definition: A term t is in normal form if no evaluation rule applies to it—
i.e., if there is no t 0 such that t  ! t 0. 2
3.2.15 Definition: An evaluation sequence starting from a term t is a (finite or
infinite) sequence of terms t1, t2, . . . , such that
t  ! t1
t1  ! t2
etc. 2
3.2.16 Definition: A term is said to be stuck if it is a normal form but not a value.2
3.2.17 Exercise: Write an abstract grammar that generates all (and only) the stuck
arithmetic expressions. 2
“Stuckness” gives us a simple notion of “run-time type error” for this rather
abstract abstract machine. Intuitively, it characterizes the situations where the op-
erational semantics does not know what to do because the program has reached a
“meaningless state.” A more serious implementation might choose other behavior
in these cases, such as dumping core.
January 15, 2000 3. UNTYPED ARITHMETIC EXPRESSIONS 27
3.3 Properties
3.3.1 Proposition: Every value is in normal form. 2
Proof: By inspection of the definitions of values and one-step evaluation. 2
3.3.2 Proposition [Determinacy of evaluation]: If t  ! t 0 and t  ! t 00, then
t 0 = t 00. 2
Proof: Exercise. (Solution on page 253.) 2
3.3.3 Definition: A value v is the result of a term t if t  ! v. 2
3.3.4 Proposition [Uniqueness of results]: If v and w are both results of t, then
v = w. 2
Proof: Exercise. 2
3.4 Implementation
Explanatory text still needs to be written.
Note that this implementation is optimized for readability and for correspondence with
the mathematical definitions, not for efficient execution! We’ll ignore parsing and printing,
the top-level read-eval-print loop, etc. Interested readers are encouraged to have a look at
the ML code for the whole typechecker.
Syntax
type info
type term =
TmTrue of info
| TmFalse of info
| TmIf of info * term * term * term
| TmZero of info
| TmSucc of info * term
| TmPred of info * term
| TmIsZero of info * term
The info components of this datatype are extracted, as necessary, by the error
printing functions.
January 15, 2000 3. UNTYPED ARITHMETIC EXPRESSIONS 28
Evaluation
exception No
let rec eval1 t =
match t with
TmIf(fi,t1,t2,t3) when not (isval t1) !
let t1' = eval1 t1 in
TmIf(fi, t1', t2, t3)
| TmIf(fi,TmTrue(_),t2,t3) !
t2
| TmIf(fi,TmFalse(_),t2,t3) !
t3
| TmSucc(fi,t1) when not (isval t1) !
let t1' = eval1 t1 in
TmSucc(fi, t1')
| TmPred(fi,t1) when not (isval t1) !
let t1' = eval1 t1 in
TmPred(fi, t1')
| TmPred(_,TmZero(_)) !
TmZero(unknown)
| TmPred(_,TmSucc(_,v1)) !
v1
| TmIsZero(fi,t1) when not (isval t1) !
let t1' = eval1 t1 in
TmIsZero(fi, t1')
| TmIsZero(_,TmZero(_)) !
TmTrue(unknown)
| TmIsZero(_,TmSucc(_,_)) !
TmFalse(unknown)
| _ ! raise No
let rec eval t =
try let t' = eval1 t
in eval t'
with No ! t
3.5 Summary
January 15, 2000 3. UNTYPED ARITHMETIC EXPRESSIONS 29
Booleans B (untyped)
Syntax
t ::= (terms...)
true constant true
false constant false
if t then t else t conditional
v ::= (values...)
true value true
false value false
Evaluation (t  ! t 0)
if true then t2 else t3  ! t2 (E-BOOLBETAT)
if false then t2 else t3  ! t3 (E-BOOLBETAF)
t1  ! t 01
if t1 then t2 else t3  ! if t 01 then t2 else t3 (E-IF)
Arithmetic expressions B N (untyped)
New syntactic forms
t ::= ... (terms...)
0 constant zero
succ t successor
pred t predecessor
iszero t zero test
v ::= ... (values...)
0 zero value
succ v successor value
New evaluation rules (t  ! t 0)
t1  ! t 01
succ t1  ! succ t 01 (E-SUCC)
pred 0  ! 0 (E-BETANATPZ)
pred (succ v)  ! v (E-BETANATPS)
t1  ! t 01
pred t1  ! pred t 01 (E-PRED)
January 15, 2000 3. UNTYPED ARITHMETIC EXPRESSIONS 30
iszero 0  ! true (E-BETANATIZ)
iszero (succ v)  ! false (E-BETANATIS)
t1  ! t 01
iszero t1  ! iszero t 01 (E-ISZERO)
3.6 Further Reading
Chapter 4
The Untyped Lambda-Calculus
There may, indeed, be other applications of the system than its use as a logic.
— Alonzo Church, 1932
In the mid 1960s, Peter Landin observed that a complex programming lan-
guage can often be understood very cleanly by formulating it as a tiny “core cal-
culus” capturing its essential mechanisms, together with a collection of conve-
nient “derived forms” whose behavior is understood by translating them into the
core [Lan64, Lan65, Lan66] (also cf. [Ten81]). The core language used by Landin
was the lambda-calculus, a formal system in which all computation is reduced
to the basic operations of function definition and application. Since the 60s, the
lambda-calculus has seen widespread use in the specification of programming lan-
guage features, language design and implementation, and the study of type sys-
tems. Its importance arises from the fact that it can be viewed simultaneously as a
simple programming language in which computations can be described and as a
mathematical object about which rigorous statements can be proved.
The lambda-calculus is just one of a large number of core calculi that have been
used for these purposes. For example, the pi-calculus of Robin Milner, Joachim
Parrow, and David Walker [MPW92, Mil91] has become a popular core language
for defining the semantics of message-based concurrent languages, while Martı́n
Abadi and Luca Cardelli’s object calculus [AC96] distills the core features of many
object-oriented languages. The concepts and techniques we will develop for the
lambda-calculus can, in most cases, be transferred quite directly to other calculi.
The lambda-calculus can be enriched in a variety of ways. First, it is often con-
venient to add special concrete syntax for features like tuples and records whose
behavior can already be simulated in the core language. More interestingly, we
may want to provide more complex features such as mutable reference cells or
nonlocal exception handling, which can be modeled in the core language only via
rather heavy translations. Such extensions make the calculus look more like a full-
31
January 15, 2000 4. THE UNTYPED LAMBDA-CALCULUS 32
blown high-level programming language in its own right, and lead eventually to
languages such as ML [GMW79, MTH90, WAL+89, MTHM97] and Scheme [SJ75,
KCR98]. As we shall see, extensions to the core language often involve extensions
to the type system as well.
This chapter reviews the definition and some basic properties of the pure or
untyped lambda-calculus.
4.1 Basics
Procedural abstraction is a key feature of most programming languages. Instead of
writing the same calculation over and over, we write a procedure or function that
performs the calculation abstractly, in terms of one or more named parameters; we
then instantiate this function as needed, providing values for the parameters in
each case. For example, it is second nature for a programmer to take a long and
repetitive expression like
(5*4*3*2*1) + (7*6*5*4*3*2*1) - (3*2*1)
and rewrite it as
factorial(5)+factorial(7)-factorial(3),
where:
factorial(n) = if n=0 then 1 else n * factorial(n-1)
For each nonnegative number n, instantiating the function factorial with the ar-
gument n yields a number, the factorial of n, as result. Writing “n. ...” as a
shorthand for “the function that, for each n, yields...,” we can restate the definition
of factorial as:
factorial = n. if n=0 then 1 else n * factorial(n-1)
Then factorial(0) means “the function ‘n. if n=0 then 1 else ...’ applied
to the argument 0,” that is, “the value that results when the bound variable n
in the function body ‘n. if n=0 then 1 else ...’ is replaced by 0,” that is
“if 0=0 then 1 else ...,” that is, 1.
In the 1930s, Alonzo Church invented a mathematical system called the lambda-
calculus (or -calculus) that embodies this kind of function definition and appli-
cation in a pure form [Chu36, Chu41]. In the lambda-calculus everything is a func-
tion: the arguments accepted by functions are themselves functions and the result
returned by a function is another function.
January 15, 2000 4. THE UNTYPED LAMBDA-CALCULUS 33
Syntax
The syntax of the lambda-calculus comprises three kinds of terms. A variable x
by itself is a lambda-term; the application of a lambda-term t1 to another lambda-
term t2, written t1 t2, is a lambda-term; and the abstraction of a variable x from
a lambda-term t1, written x. t1, is a lambda-term. These forms are summarized
in the following abstract grammar:
t ::= (terms...)
x variable
x.t abstraction
t t application
The letters s, t, and u (with or without subscripts) are used throughout to stand
for arbitrary lambda-terms, while x, y, and z are used to stand for arbitrary vari-
able names. We call s, t, u, x, y, and z metavariables: they are “variables” in the
sense that they stand for terms of the lambda-calculus, and “meta” in the sense that
they are part of the metalanguage (i.e. English plus ordinary mathematical nota-
tions) in which an object language, the lambda-calculus, is being discussed. Since
the set of short names is limited, we will also sometimes use x, y, etc. as object-
language variables, but the context of the discussion will always make it clear
which is which. For example, in a statement like “The term (x. y. x (y x))
has the form (z. s), where z = x and s = y. x (y x),” the names z and s are
metavariables, whereas x and y are object-language variables. A complete sum-
mary of metavariable conventions appears in Appendix B.
The words “lambda-term” (or just “term”) and “lambda-expression” are often
used as synonyms.
Note that what we’ve defined is only the abstract syntax of lambda-terms. In a
full-scale programming language, we would also need to address concrete syntax
issues of lexing, parsing, operator precedence, etc. For present purposes, though, it
is better to avoid such issues by concentrating on the abstract syntax, using paren-
theses informally as necessary to clarify the tree structure of examples. Application
is taken to “associate to the left”—that is, t s u is considered the same as (t s) u.
Also, the bodies of abstractions are assumed to extend as far to the right as possi-
ble, so that writing m. n. m n m is the same as writing x. (y. (x y) x).
The variable x is said to be bound in the body t of the abstraction x.t. Con-
versely, we say that a variable x is free in a term s if x appears at some position in
s where it is not bound by an enclosing abstraction on x. For example, x is free in
x y and y. x y, but not in x.x or z. x. y. x (y z).
A term with no free variables is said to be closed; closed terms are also some-
times called combinators. The simplest combinator is called the identity function:
id = x.x;
January 15, 2000 4. THE UNTYPED LAMBDA-CALCULUS 34
Operational Semantics
In its pure form, the lambda-calculus has no built-in constants or operators—no
numbers, arithmetic operations, records, loops, sequencing, I/O, etc. The sole
means by which terms “compute” is the application of functions to arguments,
which is captured in the following evaluation rule, traditionally called beta-reduction.
(x.t12) v2  ! fx 7! v2gt12 (E-BETA)
This rule says that an application of the form (x.t1) v2 (where the argument
has already been evaluated to a value), is evaluated by substituting the argument
v2 for the bound variable x in the body t1. For example, (x.x) y evaluates to y
and (x. x y) (u r) evaluates to u r y, while (x.y.x) z w evaluates (by the
underlined redex) to (y.z) w, which further evaluates to z.
4.2 Programming in the Lambda-Calculus
The lambda-calculus is much more powerful than its tiny definition might suggest.
For example, there is no built-in provision for multi-argument functions, but it is
easy to achieve the same effect using higher-order functions that yield functions
as results.
Suppose that s is a term involving two free variables x and y and we want
to write a function f that, for each pair (p,q) of arguments, yields the result of
substituting p for x and q for y in s. Instead of writing f = (x,y).s, as we might
in a higher-level programming language, we write f = x.y.s. That is, f is a
function that, given a value p for x, yields a function that, given a value q for y,
yields the desired result. We then apply f to its arguments one at a time, writing
f p q, which reduces to (y.fp 7! xgs) q and then to fq 7! ygfp 7! xgs. This
transformation of multi-argument functions into higher-order functions is often
called Currying after its popularizer, Haskell Curry. (It was actually invented by
Schönfinkel, but the term “Schönfinkeling” has not caught on.)
Another common language feature that can easily be encoded in the lambda-
calculus is boolean values and conditionals. Define the terms tru and fls as fol-
lows:
tru = t. f. t;
fls = t. f. f;
The only way to “interact” with combinators is by applying them to other
terms. For example, we can use application to define a combinator test with
the property that test b m n reduces to m when b = tru and reduces to q when
b = fls.
test = l. m. n. l m n;
January 15, 2000 4. THE UNTYPED LAMBDA-CALCULUS 35
The test combinator does not actually do much: (test b m n) just reduces to
(b m n). In effect, the boolean value b itself is the conditional: it takes two argu-
ments and chooses the first (if it is tru) or the second (if it is fls). For example, the
term (test tru m n) reduces as follows:
test tru m n
= (l. m. n. l m n) tru m n by definition
 ! (m. n. tru m n) m n reducing the underlined redex
 ! (n. tru m n) n reducing the underlined redex
 ! tru m n reducing the underlined redex
= (t.f.t) m n by definition
 ! (f. m) n reducing the underlined redex
 ! m reducing the underlined redex
We can also write boolean operators like logical conjunction as functions:
and = b. c. b c fls;
That is, and is a function that, given two boolean arguments b and c, returns c if b
is tru or fls if b is fls; thus and b c yields tru if both b and c are tru and fls if
either b or c is fls.
and tru tru;
I (t. f. t)
and tru fls;
I (t. f. f)
and fls tru;
I (t. f. f)
and fls fls;
I (t. f. f)
4.2.1 Exercise: Define logical or and not functions. 2
Using booleans, we can encode pairs of values as lambda-terms. Define:
pair = f.s.b. b f s;
fst = p. p tru;
snd = p. p fls;
That is, pair m n is a function that, when applied to a boolean b, applies b to m
and n. By the definition of booleans, this application yields m if b is tru and n if b is
fls, so the first and second projection functions fst and snd can be implemented
January 15, 2000 4. THE UNTYPED LAMBDA-CALCULUS 36
simply by supplying the appropriate boolean. To check that fst (pair m n)  !
m, calculate as follows:
fst (pair m n)
= fst ((f. s. b. b f s) m n) by definition
 ! fst ((s. b. b m s) n) reducing the underlined redex
 ! fst (b. b m n) reducing the underlined redex
= (p. p tru) (b. b m n) by definition
 ! (b. b m n) tru reducing the underlined redex
 ! tru m n reducing the underlined redex
 ! m as before.
The encoding of numbers as lambda-terms is only slightly more intricate than
what we have just seen. Define the Church numerals c0, c1, c2, etc., as follows:
c0 = s. z. z;
c1 = s. z. s z;
c2 = s. z. s (s z);
c3 = s. z. s (s (s z));
c4 = s. z. s (s (s (s z)));
etc.
That is, each number n is represented by a combinator cn that takes two argu-
ments, z and s (for “zero” and “successor”), and applies s, n times, to z. As with
booleans and pairs, this encoding makes numbers into active entities: the number
n is represented by a function that does something n times—a kind of active unary
numeral.
We can define some common arithmetic operations on Church numerals as fol-
lows:
plus = m. n. s. z. m s (n s z);
times = m. n. m (plus n) c0;
Here, plus is a combinator that takes two Church numerals, m and n, as arguments,
and yields another Church numeral—i.e., a function that accepts arguments z and
s, applies s iterated n times to z (by passing s and z as arguments to n), and then
applies s iterated m more times to the result.
4.2.2 Exercise: Verify that (plus c2 c1) ! c3. 2
The definition of times uses another trick: since plus takes its arguments one at a
time, applying it to just one argument n yields the function that adds n to whatever
argument it is given. Passing this function as the second argument to m and c0 as
the first argument means “apply the function that adds n to its argument, iterated
m times, to zero,” i.e., “add together m copies of n.”
4.2.3 Exercise [Recommended]: Define a similar term for calculating the successor
of a number. (Solution on page 254.) 2
January 15, 2000 4. THE UNTYPED LAMBDA-CALCULUS 37
4.2.4 Exercise: Define a similar term for raising one number to the power of an-
other. 2
To test whether a Church numeral is zero, we must apply it to a pair of terms
zz and ss such that applying ss to zz one or more times yields fls, while not
applying it at all yields tru. Clearly, we should take zz to be just tru. For ss, we
use a function that throws away its argument and always returns fls.
iszro = m. m (x. fls) tru;
Surprisingly, it is quite a bit more difficult to subtract using Church numerals. It
can be done using the following rather tricky “predecessor function,” which, given
c0 as argument, returns c0 and, given ci+1, returns ci:
zz = pair c0 c0;
ss = p. pair (snd p) (plus c1 (snd p));
prd = m. fst (m ss zz);
This definition works by using m as a function to apply m copies of the function
ss to the starting value zz. Each copy of ss takes a pair of numerals pair ci cj
as its argument and yields (pair cj cj+1) as its result. So applying ssm times to
(pair c0 c0) yields (pair c0 c0) when m = 0 and (pair cm-1 cm) when m is
positive. In both cases, the predecessor of m is found in the first component.
4.2.5 Exercise:
1. Use prd to define a subtraction function.
2. How many steps of evaluation (as a function of n) are required to calculate
the result of (prd cn)? 2
4.2.6 Exercise: Write a function equal that tests two numbers for equality and re-
turns a boolean. For example,
equal c3 c3;
I (t. f. t)
equal c3 c2;
I (t. f. f)
(Solution on page 254.) 2
Other common datatypes like lists, trees, arrays, and variant records can be en-
coded using similar techniques. Of course, in most programming languages based
on the lambda-calculus, such basic data types are added as primitive constants,
rather than being encoded.
January 15, 2000 4. THE UNTYPED LAMBDA-CALCULUS 38
4.2.7 Exercise [Recommended]: Build an encoding of lists in the pure lambda-
calculus by defining a constant nil (the empty list) and operations cons (for con-
structing a list from a new head element and an old list), head and tail (for ex-
tracting the parts of a list), and isnull (for testing whether a list is empty).
One straightforward way to do this is to generalize the encoding of numbers as
follows. A list is represented by a function that takes two arguments, hh and tt. If
the list is empty, this function simply returns tt. On the other hand, if the list has
head h and tail t, the function calls hh, passing it h and (t hh tt) as parameters.
(In other words, a list is represented by its own fold function.)
Can you think of any different ways of encoding lists? (Solution on page 254.)2
Recall that a term that cannot take a step under the evaluation relation is said to
be in normal form. Interestingly, in the untyped lambda-calculus, not every term
can be evaluated to a normal form. For example, the divergent combinator
omega = (x. x x) (x. x x);
can never be reduced to a value. It contains just one redex, and reducing this redex
yields exactly omega again! Terms with no normal form are sometimes said to
diverge.
The omega combinator has a useful generalization called the fixed-point com-
binator (or Y-combinator), which can be used to define recursive functions such
as factorial.
fixpoint = f. (x. f (y. (x x) y))
(x. f (y. (x x) y));
The crucial property of fixpoint is that fixpoint ff has the same behavior as
ff (fixpoint ff) for any term ff.
(Note that this is a call-by-value fixed point combinator, since we using a call-
by-value reduction strategy. The simpler call-by-name fixed point combinator
fixpointn = f. (x. f (x x))
(x. f (x x));
is useless in a call-by-value setting, since an expression like fixpointn ff always
diverges, no matter what ff is.)
Now, suppose we want to write a recursive function definition of the form
ff = hbody containing ffi—i.e., we want to write a definition where the term on
the right-hand side of the = uses the very function that we are defining, as in the
definition of factorial on page 32. The intention is that the recursive definition
should be “unrolled” at the point where it occurs; for example, the definition of
factorial would intuitively be:
if n=0 then 1
else n * (if n-1=0 then 1
else (n-1) * (if (n-2)=0 then 1
else (n-2) * ...))
January 15, 2000 4. THE UNTYPED LAMBDA-CALCULUS 39
This effect can be achieved using fixpoint by defining gg = f.hbody containing fi
and ff = fixpoint gg. For example, we can define the factorial function by
ff = f. n.
test
(iszro n) (x. c1) (x. (times n (f (prd n)))) c0;
factorial = fixpoint ff;
We then have:
equal (factorial c3) c6;
I (t. f. t)
4.2.8 Exercise [Recommended]: Use the fixpoint combinator and the encoding
of lists from Exercise 4.2.7 to write a function that sums lists of church numerals.
(Solution on page 254.) 2
4.3 Is the Lambda-Calculus a Programming Language?
4.4 Formalities
As we did in Chapter 3, we must now consider the syntax and operational seman-
tics of the lambda-calculus in a little more detail. Most of the structure we need is
closely analogous to what we saw there. However, the operation of substituting a
term for a variable involves some surprising subtleties.
Syntax
As in Chapter 3, the abstract grammar defining terms should be read as shorthand
for the union of an inductively defined family of sets of abstract syntax trees. To
define it precisely, we begin with some set V of variable names.
4.4.1 Definition [Terms]: The set of terms is the smallest set T such that
1. x 2 T for every x 2 V ;
2. if t1 2 T and x is a variable name, then x.t1 2 T ;
3. if t1 2 T and t2 2 T , then (t1 t2) 2 T . 2
The size of a term t can be defined exactly as we did for arithmetic expressions
in Definition 3.2.7. More interestingly, we can give a simple inductive definition of
the set of variables appearing “free” in a lambda-term.
January 15, 2000 4. THE UNTYPED LAMBDA-CALCULUS 40
4.4.2 Definition: The set of free variables of a term t, written FV(t), is defined as
follows:
FV(x) = fxg
FV(x.t1) = FV(t1) n fxg
FV(t1 t2) = FV(t1) [ FV(t2) 2
Here is an inductive proof of a simple fact relating the definitions of size and
free variables, analogous to Lemma 3.2.8 in the previous chapter.
4.4.3 Lemma: The number of distinct free variables in a term t is always smaller
than the size of t (in symbols: jFV(t)j  size(t)). 2
Proof: By induction on the size of t. (That is, assuming the desired property for
all terms smaller than t, we must prove it for t itself; if we can do this, we may
conclude that the property holds for all t.) There are three cases to consider:
Case: t = x
Immediate: jFV(t)j = jfxgj = 1 = size(t).
Case: t = x.t1
By the induction hypothesis, jFV(t1)j  size(t1). We now calculate as follows:
jFV(t)j = jFV(t1) n fxgj  jFV(t1)j  size(t1) < size(t).
Case: t = t1 t2
By the induction hypothesis, jFV(t1)j  size(t1) and jFV(t2)j  size(t2). We now
calculate as follows: jFV(t)j = jFV(t1) [ FV(t2)j  jFV(t1)j+ jFV(t2)j  size(t1) +
size(t2) < size(t). 2
Substitution
Dealing carefully with the operation of substitution requires some work. We’ll
take it in two large steps. First (in this section), we’ll discuss the basic issues, iden-
tify some traps for the unwary, and come up with a definition of substitution that
is precise enough for most purposes. In Section 5.1 we’ll go the rest of the way,
defining a more refined “nameless” presentation of terms on which substitution
is completely formal (and, in particular, suitable for implementation). The reason
for presenting both is that the nameless formulation becomes too fiddly to use all
the time. Having worked it out in detail, we will return to the more comfortable,
slightly informal presentation developed in this section, regarding it as a conve-
nient shorthand for the other.
It is instructive to arrive at the correct definition of substitution via a couple of
wrong attempts. First off, let’s try the most naive possible recursive definition:
fx 7! sgx = s
fx 7! sgy = y if x 6= y
fx 7! sg(y.t1) = y. fx 7! sgt1
fx 7! sg(t1 t2) = fx 7! sgt1 fx 7! sgt2
January 15, 2000 4. THE UNTYPED LAMBDA-CALCULUS 41
This definition works fine for most examples. For instance, it gives
fx 7! (z. z w)g(y. x) = (y.z. z w);
which is fine. However, if we are unlucky with our choice of bound variable
names, the definition breaks down. For example:
fx 7! yg(x.x) = x.y
This conflicts with the basic intuition about functional abstractions that the alpha-
betic names of bound variables do not matter—the identity function is exactly the same
whether we write it x.x or y.y or franz.franz. If these do not behave exactly
the same under substitution, then they will not behave the same under reduction
either, which seems wrong.
Clearly, the first mistake that we’ve made in the naive definition of substitution
is that we have not distinguished between free occurrences of a variable x in a
term t (which should get replaced during substitution) and bound ones, which
should not. When we reach an abstraction binding the name x inside of t, the
substitution operation should stop. This leads to the next attempt at a definition of
substitution:
fx 7! sgx = s
fx 7! sgy = y if y 6= x
fx 7! sg(y.t1) =

y. t1 if y = x
y. fx 7! sgt1 if y 6= x
fx 7! sg(t1 t2) = fx 7! sgt1 fx 7! sgt2
This is better, but it is still not quite right. For example, consider what happens
when we substitute the term z for the variable x in the term z.x:
fx 7! zg(z.x) = z.z
This time, we have made essentially the opposite mistake as in the previous un-
fortunate example: we’ve turned the constant function z.x into the identity func-
tion! Again, this occurred only because we happened to choose z as the name of
the bound variable in the constant function, so something is clearly still wrong.
This phenomenon of free variables in a term s becoming bound when s is
naively substituted into a term t containing variable binders is called variable
capture. To avoid it, we need to make sure that the bound variable names of t
kept distinct from the free variable names of s. A substitution operation that does
this correctly is called capture-avoiding substitution. This is almost always what
is meant by the unqualified term “substitution.” We can achieve this by adding
another side condition to the second clause of the abstraction case:
fx 7! sgx = s
fx 7! sgy = y if y 6= x
fx 7! sg(y.t1) =

y. t1 if y = x
y. fx 7! sgt1 if y 6= x and y =2 FV(s)
fx 7! sg(t1 t2) = fx 7! sgt1 fx 7! sgt2
January 15, 2000 4. THE UNTYPED LAMBDA-CALCULUS 42
We are almost there: this definition of substitution does the right thing when it
does anything at all. The problem now is that our last fix has changed substitution
into a partial operation. For example, the new definition does not give any result
at all for fx 7! y zg(y. x y): the bound variable y of the term being substituted
into is not equal to x, but it does appear free in (y z), so none of the clauses of the
definition apply.
One common fix for this last problem in the type systems and lambda-calculus
literature is to work with terms “up to renaming of bound variables” (or “up to
alpha-conversion”):
4.4.4 Convention: Terms that differ only in the names of bound variables are in-
terchangeable in all contexts. 2
What this means in practice is that the name of any bound variable can be
changed to another name (consistently making the same change in the body), at
any point where this is convenient. For example, if we want to calculate fx 7!
y zg(y. x y), we first rewrite (y. x y) as, say, (w. x w). We then calculate
fx 7! y zg(w. x w), giving (w. y z w). This renders the substitution operation
“as good as total,” since whenever we find ourselves about to apply it to a collec-
tion of arguments for which it is undefined, we can perform one or more steps of
renaming as necessary, so that the side conditions are satisfied.
Indeed, having adopted this convention, we can formulate the definition of
substitution a little more tersely. The first clause for abstractions can be dropped,
since we can always assume (renaming if necessary) that the bound variable y is
different from both x and the free variables of s. This yields the final form of the
definition.
4.4.5 Definition [Substitution]:
fx 7! sgx = s
fx 7! sgy = y if y 6= x
fx 7! sg(y.t1) = y. fx 7! sgt1 if y 6= x and y =2 FV(s)
fx 7! sg(t1 t2) = fx 7! sgt1 fx 7! sgt2 2
The convention about implicit renaming of bound variables is is easy to work
with, and its slight informality does not usually lead to trouble in practice. We
shall adopt it in most of what follows. However, it is also important to know how
to formulate basic operations such as substitution with complete rigor, so that we
have a solid foundation to fall back on in case there is ever any question. We will
see one way to accomplish this in Section 5.1.
4.4.6 Exercise: Without looking forward to Section 5.1, can you think of any other
ways in which the incomplete definition of substitution might be repaired to give
a complete operation, without resorting to a convention about implicit renaming
of bound variables? 2
January 15, 2000 4. THE UNTYPED LAMBDA-CALCULUS 43
Operational Semantics
4.4.7 Definition: The set of values is the subset of terms defined by the following
abstract grammar:
v ::= (values...)
x.t abstraction value
2
4.4.8 Definition: The one-step evaluation relation  ! is the smallest relation con-
taining all instances of the following rules:
(x.t12) v2  ! fx 7! v2gt12 (E-BETA)
t1  ! t1 0
t1 t2  ! t 01 t2 (E-APP1)
t2  ! t2 0
v1 t2  ! v1 t 02 (E-APP2)
2
Summary
The foregoing definitions may be summarized compactly as follows.
 : Untyped lambda-calculus ! (untyped)
Syntax
t ::= (terms...)
x variable
x.t abstraction
t t application
v ::= (values...)
x.t abstraction value
Evaluation (t  ! t 0)
(x.t12) v2  ! fx 7! v2gt12 (E-BETA)
t1  ! t1 0
t1 t2  ! t 01 t2 (E-APP1)
t2  ! t2 0
v1 t2  ! v1 t 02 (E-APP2)
January 15, 2000 4. THE UNTYPED LAMBDA-CALCULUS 44
4.5 Further Reading
Information on the untyped lambda-calculus can be found in many places. The
first and best is Barendregt’s encyclopedic monograph, The Lambda Calculus [Bar84].
Hindley and Seldin’s book [HS86] gives a more accessible treatment of some of the
basic material. Barendregt’s article in the Handbook of Theoretical Computer Sci-
ence [Bar90] is a compact survey. Material on lambda-calculus can also be found
in many textbooks on functional programming languages (e.g. [AS85, FWH92,
PJL92]) and programming language semantics (e.g.[Sch86, Gun92, Win93, Mit96]).
Chapter 5
Implementing the
Lambda-Calculus
Just because you’ve implemented something doesn’t mean you understand it.
— Brian Cantwell Smith
5.1 Nameless Representation of Terms
In the previous chapter, we worked with terms “up to renaming of bound vari-
ables.” This is fine for discussing basic concepts and for presenting proofs cleanly,
but for building an implementation we need to choose a single concrete represen-
tation for each term.
There are various ways to do this:
1. We can represent a variable occurrence as a string. This makes our concrete
(“algorithmic”) representation close to the declarative one, but it means that
we have to alpha-convert during substitution. This becomes quite tricky and
it is easy to introduce subtle bugs.
2. We can replace the names chosen by the programmer with some canonical
naming scheme.
3. We can avoid substitution altogether by introducing mechanisms like clo-
sures.
We choose the second, using a well-known technique due to Nicolas de Bruijn [dB72].
Making this choice will require some work now, but will save us a lot of trouble-
some debugging when we come to implementing more complex systems.
45
January 15, 2000 5. IMPLEMENTING THE LAMBDA-CALCULUS 46
Syntax
De Bruijn’s idea was that we can represent terms more straightforwardly—though
less readibly—by making variable occurrences point directly to their binders, rather
than referring to them by name. This can be accomplished by replacing named
variables by natural numbers, where the number k stands for “the variable bound
by the k’th enclosing ” (starting from 0). For example, the ordinary term x.x
corresponds to the nameless term .0, while x.y. x (y x) is represented by
the nameless term .. 1 (0 1). Nameless terms are also sometimes called de
Bruijn terms, and the numeric variables in them are called de Bruijn indices. (In
passing, a note on pronunciation: the closest English approximation to the second
syllable in “de Bruijn” is “brown,” not “broyn.”)
5.1.1 Exercise [Quick check]: For each of the following combinators
c0 = z. s. z;
c2 = z. s. s (s z);
plus = m. n. z. s. m (n z s) s;
fixpoint = f. (x. f (x x)) (x. f (x x));
foo = (x. (x. x)) (x. x);
write down the corresponding nameless term. 2
Note that each (closed) ordinary term has just one de Bruijn representation,
and that two ordinary terms are equivalent modulo renaming of bound variables
exactly when they have the same de Bruijn representation.
To deal with terms containing free variables, we need the idea of a naming
context. For example, suppose we want to represent x. y x as a nameless term.
We know what to do with x, but we cannot see the binder for y, so it is not clear
how far out it might be and so we do not know what number to assign to it. The
solution is to choose, once and for all, an assignment (called a naming context) of
de Bruijn indices to free variables, and use this assignment consistently when we
need to choose numbers for free variables. For example, suppose that we choose
to work under the following naming context:
  = x 7! 4
y 7! 3
z 7! 2
a 7! 1
b 7! 0
Then (x (y z)) would be represented as (4 (3 2)), while x. y x would be
represented as . 4 0 and w.a.x would be represented as ..6.
Actually, all we need to know about   is the order in which the variables appear.
Instead of writing it in tabular form, as we did above, we will elide the numbers
and write it as a sequence.
January 15, 2000 5. IMPLEMENTING THE LAMBDA-CALCULUS 47
5.1.2 Definition: Suppose x0 through xn are variable names in V . The naming
context   = xn; xn-1; : : :x1; x0 assigns to each xi the de Bruijn index i. Note
that the rightmost variable in the sequence is given the index 0. (This matches the
way we count s—from right to left—when converting a named term to nameless
form.) We will write dom( ) for the set fx0; : : : ; xng of variable names mentioned
in  . 2
Formally, we define the syntax of nameless terms almost exactly like the syntax
of ordinary terms (Definition 4.4.1). The only difference is that we need to keep
careful track of how many free variables each term may contain. That is, we dis-
tinguish the sets of terms with no free variables (called the 0-terms), terms with at
most one free variable (1-terms), and so on.
5.1.3 Definition [Terms]: Let T be the smallest family of sets fT0; T1; T2; : : :g such
that
1. k 2 Tn whenever 0  k < n;
2. if t 2 Tn and n > 0, then .t 2 Tn-1;
3. if t1 2 Tn and t2 2 Tn, then t1 t2 2 Tn.
The elements of each Tn are called n-terms. 2
Note that the elements of Tn are terms with at most free variables numbered
between 0 and n - 1: a given element of Tn need not have free variables with all
these numbers, or indeed any free variables at all. If t is closed, for example, it will
be an element of Tn for every n.
Also, note that, strictly speaking, it does not make sense to speak of “some
t 2 T ”—we always need to specify how many free variables t might have. In
practice, though, we will often have some fixed naming context   in mind; we will
then abuse the notation slightly and write t 2 T to mean t 2 Tn, where n is the
length of  .
5.1.4 Exercise: Give an alternative construction of the sets of n-terms in the style
of 3.2.2, and show (as we did in Fact ??) that it is equivalent to the one above. 2
5.1.5 Exercise [Recommended]:
1. Define a function removenames that takes a naming context   and an ordinary
term t (with FV(t)  dom( )) and yields the corresponding nameless term.
2. Define a function restorenames that takes a nameless term t and a naming
context   and produces an ordinary term. (To do this, you will need to “make
up” names for the variables bound by abstractions in t. You may assume that
the set V of variable names is ordered, so that it makes sense to say “choose
the smallest variable name that is not already in dom( ).”)
January 15, 2000 5. IMPLEMENTING THE LAMBDA-CALCULUS 48
This pair of functions should have the property that removenames (restorenames (t)) =
t for any nameless term t, and similarly restorenames (removenames (t)) = t, up
to renaming of bound variables, for any ordinary term t. 2
Shifting and Substitution
Before defining substitution on nameless terms, we need one auxiliary operation
on terms, called “shifting,” which renumbers the indices of the free variables in a
term. When a substitution goes under a -abstraction (as in fx 7! sg(y.x)), the
context in which the substitution is taking place becomes one variable longer than
the original; we need to increment the indices of the free variables in s so that they
keep referring to the same names in the new context as they did before.
5.1.6 Definition [Shifting]: The d-place shift of a term t above cutoff c, written"dc (t), is defined as follows:
"dc (k) =

k if k < c
k+ d if k  c"dc (.t1) = . "dc+1 (t1)"dc (t1 t2) = "dc (t1) "dc (t2)
We will write "d (t) for "d0 (t). 2
5.1.7 Exercise [Quick check]:
1. What is "2 (.. 1 (0 2))?
2. What is "2 (. 0 1 (. 0 1 2))? 2
5.1.8 Exercise: Show that if t is an n-term, then "dc (t) is an (n+d)-term. 2
Now we are ready to define the substitution operator fj 7! sgt. At the end, we
will be most interested in substituting for the last variable in the context (i.e., j = 0),
since that is the case we need in order to define the reduction relation. However,
to substitute for variable 0 in a -abstraction, we need to be able to substitute for
variable number 1 in the body. Thus, the definition of substitution must work on
an arbitrary variable.
5.1.9 Definition [Substitution]: The substitution of a term s for variable number j
in a term t, written fj 7! sgt, is defined as follows:
fj 7! sgk = s if k = j
k otherwise
fj 7! sg(.t1) = . fj+ 1 7!"1 (s)gt1
fj 7! sg(t1 t2) = fj 7! sgt1 fj 7! sgt2 2
January 15, 2000 5. IMPLEMENTING THE LAMBDA-CALCULUS 49
5.1.10 Exercise [Quick check]: Convert the following substitution operations to
nameless form (assuming the global context is   = a; b) and calculate their re-
sults using the above definition. Do the answers make sense with respect to the
original definition of substitution on ordinary terms in Section 4.4?
 fb 7! ag (b (x.y.b))
 fb 7! ag (b (x.y.b))
 fb 7! (a (z.a))g (b (x.b)) 2
5.1.11 Exercise: Show that if s and t are n-terms and j  n, then fj 7! sgt is an
n-term. 2
5.1.12 Exercise [Quick check]: Take a sheet of paper and, without looking at the
definitions of substitution and shifting above, see if you can regenerate them. 2
5.1.13 Exercise [Recommended]: The definition of substitution on nameless terms
should agree with our informal definition of substitution on ordinary terms. What
theorem would need to be proved to justify this correspondence rigorously? For
extra credit, prove it. (Solution on page 255.) 2
Evaluation
We can now define the evaluation relation on nameless terms.
The beta-reduction rule is defined in terms of our new nameless substitution
operation. The only slightly subtle technical point is that reducing a redex “uses
up” the bound variable—when we reduce (x.t1) v2 to fx 7! v2gt1, the bound
variable x disappears in the process. Thus, we will need to renumber the variables
of the result of substitution to take into account the fact that x is no longer part
of the context. Similarly, we need to shift the variables in v2 up by one before
substituting into t1 to take account of the fact that t1 is defined in a larger context
than v2.
(.t1) v2  ! "-1 (f0 7!"1 (v2)gt1) (E-BETA)
The other rules are identical to what we had before.
5.2 A Concrete Realization
January 15, 2000 5. IMPLEMENTING THE LAMBDA-CALCULUS 50
Syntax
type term =
TmVar of info * int * int
| TmAbs of info * string * term
| TmApp of info * term * term
let tmInfo = function
TmVar(fi,_,_) ! fi
| TmAbs(fi,_,_) ! fi
| TmApp(fi, _, _) ! fi
Shifting and Substitution
let tmmap onvar =
let rec walk c = function
TmVar(fi,x,n) ! onvar fi c x n
| TmAbs(fi,x,t1) ! TmAbs(fi, x, walk (c+1) t1)
| TmApp(fi,t1,t2) ! TmApp(fi, walk c t1, walk c t2)
in walk
let tmshifti d c t =
tmmap
(fun fi c x n ! if x>=c then TmVar(fi,x+d,n+d) else TmVar(fi,x,n+d))
c
t
let tmshift t d = tmshifti d 0 t
let tmsubsti s j t =
tmmap
(fun fi j x n ! if x=j then (tmshift s j) else TmVar(fi,x,n))
j
t
let tmsubst s t = tmsubsti s 0 t
let tmsubstsnip s t = tmshift (tmsubst (tmshift s 1) t) (-1)
January 15, 2000 5. IMPLEMENTING THE LAMBDA-CALCULUS 51
Evaluation
let rec isval ctx = function
TmAbs(_,_,_) ! true
| _ ! false
let rec eval ctx t =
try let t' = eval1 ctx t
in eval ctx t'
with No ! t
5.3 Ordinary vs. Nameless Representations
Strictly speaking, having gone to the trouble of making all this so precise, we
should now continue through the rest of the material in the course using de Bruijn
representations consistently throughout. However, we will not do this, as it would
make the text essentially unreadable. Instead, we will adopt the following com-
promise:
 In this chapter and in all the implementation sections to follow, we use de
Bruijn representations faithfully.
 In textual (and TeXtual) presentations of calculi, discussions, examples, and
proofs, we will stick with the original presentation in terms of named vari-
ables. However, we will always regard this as a convenient shorthand for an
underlying de Bruijn representation. For example, when we write
(x.t11) t2  ! fx 7! t2gt11
we will actually mean:
(.t11) t2  ! "-1 (f0 7!"1 (t2)gt11)
In particular, this convention has the following consequences:
1. we always work “up to alpha-conversion,” ignoring the particular names
chosen for bound variables, and
2. whenever we mention a term, we will always (at least implicitly) have
some context in mind that imposes a numerical ordering on its free vari-
able names.
Chapter 6
Typed Arithmetic Expressions
This and the following chapter are technically mostly complete but the text needs to be
expanded. The idea is that, as we did in the untyped case, we go through all the basic facts
about typed calculi in the very simple setting of just numbers and booleans, then redo it all
for the lambda-calculus.
6.1 Syntax
6.1.1 Definition: The set of types for arithmetic expressions contains just the sym-
bols Bool and Nat:
T ::= (types...)
Bool type of booleans
Nat type of natural numbers
The metavariables S, T, U, etc. range over types. 2
6.2 The Typing Relation
The type system for arithmetic expressions is defined by a set of rules assigning
types to terms. We write “` t : T” to mean “term t has type T.”
For example, the fact that the term 0 has the type Nat is captured by the follow-
ing axiom:
0 : Nat (T-ZERO)
Similarly, the term succ t1 has type Nat as long as t1 has type Nat.
t1 : Nat
succ t1 : Nat
(T-SUCC)
52
January 15, 2000 6. TYPED ARITHMETIC EXPRESSIONS 53
Likewise, pred yields a Nat when its argument has type Nat
t1 : Nat
pred t1 : Nat
(T-PRED)
and iszero yields a Bool when its argument has type Nat:
t1 : Nat
iszero t1 : Bool
(T-ISZERO)
The boolean constants both have type Bool
true : Bool (T-TRUE)
false : Bool (T-FALSE)
The only interesting typing rule is the one for if expressions:
t1 : Bool t2 : T t3 : T
if t1 then t2 else t3 : T
(T-IF)
The metavariable T is used to indicate that the result of the if is the type of the
then- and else- branches, and that this may be any type (either Nat or Bool or,
when we get to calculi with more interesting sets of types, any other type whatso-
ever).
6.3 Properties of Typing and Reduction
Typing Derivations
Formally, the typing relation can be thought of as a simple logic for proving typing
assertions (sometimes called typing judgements) of the form ` t : T, pronounced
“the term t has the type T.” The provable statements of this logic are defined as
follows:
6.3.1 Definition: The typing relation is the least two-place relation containing all
instances of the axioms T-ZERO, T-TRUE, and T-FALSE and closed under all in-
stances of the remaining rules. (In the literature on type systems, the symbol 2 is
often used instead of : for the typing relation.) 2
6.3.2 Definition: A typing derivation is a tree of instances of the typing rules.
Each statement ` t : T in the typing relation is justified by a typing derivation
with conclusion ` t : T. We sometimes write D :: J to indicate that D is a deriva-
tion tree with conclusion J . When D :: J for some D, we say that J is derivable.
2
6.3.3 Theorem [Principle of induction on typing derivations]: Suppose that P is
some predicate on typing statements. If we can show, for each typing derivation
D :: J , that (P(J 0), for all D 0 :: J 0 with size(D 0) < size(D)) implies P(J ), then we
may conclude that P(J ) holds for every derivable typing statement. 2
January 15, 2000 6. TYPED ARITHMETIC EXPRESSIONS 54
Typechecking
6.3.4 Lemma [Inversion of the typing relation]:
1. If ` 0 : R, then R = Nat.
2. If ` succ t1 : R, then R = Nat and ` t1 : Nat.
3. If ` pred t1 : R, then R = Nat and ` t1 : Nat.
4. If ` iszero t1 : R, then R = Bool and ` t1 : Nat.
5. If ` true : R, then R = Bool.
6. If ` false : R, then R = Bool.
7. If   ` if t1 then t2 else t3 : R, then
  ` t1 : Bool
  ` t2 : R
  ` t3 : R:
The inversion lemma is sometimes called the generation lemma for the typing re-
lation, since, given a valid typing statement, it shows how proofs of this statement
might have been generated. 2
Proof: Immediate from the definition of the typing relation. 2
6.3.5 Theorem [Uniqueness of Types]: Each term t has at most one type. That is,
if t is typeable, then its type is unique. Moreover, there is just one derivation of
this typing built from the inference rules of Definition 6.3.1. 2
Proof: Exercise. 2
Safety = Preservation + Progress
The most important property of this type system (or any other) is soundness: well-
typed programs do not “go wrong.” A simple way of formalizing this fact is the
observation that well-typed programs can only reduce to well-typed programs—
that is, a well-typed program can never reach an ill-typed state at run-time.
6.3.6 Theorem [Preservation of types during evaluation]: If ` t : T and t  ! 
t 0, then ` t 0 : T. 2
Proof: Exercise. 2
January 15, 2000 6. TYPED ARITHMETIC EXPRESSIONS 55
The preservation theorem is often called “subject reduction” (or “subject evalu-
ation”) in the literature—the intuition being that a typing statement ` t : T can be
thought of as a sentence: “t has type T.” The term t is the subject of this sentence,
and the subject reduction property then says that the truth of the sentence is stable
under reduction of the subject.
Recall (from Definition3.2.16) that a “stuck” term is one that is in normal form
but not a value.
6.3.7 Theorem [Progress]: If ` t : T, then either t is a value or there is some t 0
such that t  ! t 0. 2
Proof: Exercise. 2
The combination of the latter property with the preservation theorem guar-
antees that “well-typed terms never get stuck.” This combination of properties
captures what is usually thought of as “type safety” or “type soundness.”
6.3.8 Exercise [Recommended]: Having seen the “subject reduction” property, we
may wonder whether the opposite (“subject expansion”) property also holds. Is it
always the case that, if t  ! t 0 and ` t 0 : T, then ` t : T? If so, prove it. If not,
give a counterexample. (Solution on page 255.) 2
6.4 Implementation
type ty =
TyBool
| TyNat
let rec tyeqv tyS tyT =
match (tyS,tyT) with
(TyBool,TyBool) ! true
| (TyNat,TyNat) ! true
| _ ! false
val error : info ! string ! 'a
let rec typeof t =
match t with
TmTrue(fi) !
TyBool
| TmFalse(fi) !
TyBool
| TmIf(fi,s1,s2,s3) !
if tyeqv (typeof s1) TyBool then
let tyS = typeof s2 in
January 15, 2000 6. TYPED ARITHMETIC EXPRESSIONS 56
if tyeqv tyS (typeof s3) then tyS
else error fi "arms of conditional have different types"
else error fi "guard of conditional not a boolean"
| TmZero(fi) !
TyNat
| TmSucc(fi,t1) !
if tyeqv (typeof t1) TyNat then TyNat
else error fi "argument of succ is not a number"
| TmPred(fi,t1) !
if tyeqv (typeof t1) TyNat then TyNat
else error fi "argument of pred is not a number"
| TmIsZero(fi,t1) !
if tyeqv (typeof t1) TyNat then TyBool
else error fi "argument of iszero is not a number"
6.5 Summary
Typing rules for booleans B (typed)
New syntactic forms
T ::= ... (types...)
Bool type of booleans
New typing rules (t : T)
true : Bool (T-TRUE)
false : Bool (T-FALSE)
t1 : Bool t2 : T t3 : T
if t1 then t2 else t3 : T
(T-IF)
Typing rules for numbers B N (typed)
New syntactic forms
T ::= ... (types...)
Nat type of natural numbers
New typing rules (t : T)
0 : Nat (T-ZERO)
January 15, 2000 6. TYPED ARITHMETIC EXPRESSIONS 57
t1 : Nat
succ t1 : Nat
(T-SUCC)
t1 : Nat
pred t1 : Nat
(T-PRED)
t1 : Nat
iszero t1 : Bool
(T-ISZERO)
Chapter 7
Simply Typed
Lambda-Calculus
This chapter introduces the most elementary member of the family of typed lan-
guages that we shall be studying for the rest of the course: the simply typed
lambda-calculus of Church [Chu40] and Curry [CF58].
7.1 Syntax
7.1.1 Definition: The set of simple types over the atomic type Bool (for brevity,
we omit natural numbers) is generated by the following grammar:
T ::= (types...)
T!T type of functions
Bool type of booleans
The type constructor! is right-associative: S!T!U stands for S!(T!U). 2
7.1.2 Definition: The abstract syntax of simply typed lambda-terms (with booleans
and conditional) is defined by the following grammar:
t ::= (terms...)
x variable
x:T.t abstraction
t t application
true constant true
false constant false
if t then t else t conditional
2
58
January 15, 2000 7. SIMPLY TYPED LAMBDA-CALCULUS 59
In the literature on type systems, two different presentation styles are com-
monly used:
 In implicitly typed (or, for historical reasons, Curry-style) systems, the pure
(untyped) lambda-calculus is used as the term language. The typing rules
define a relation between untyped terms and the types that classify them.
 In explicitly typed (or Church-style) systems, the term language itself is re-
fined so that terms carry some type information within them; for example,
the bound variables in function abstractions are always annotated with the
type of the expected parameter. The type system relates typed terms and
their types.
To a large degree, the choice is a matter of taste, though explicitly typed systems
generally pose fewer algorithmic problems for typecheckers. We will adopt an
explicitly typed presentation throughout.
7.2 The Typing Relation
In order to assign a type to an abstraction like x:T2.t1, we need to know what
will happen later when it is applied to some argument t2. The annotation on the
bound variable tells us that we may assume that the argument will be of type T2.
In other words, the type of the result will be just the type of t1, where occurrences
of x in t1 are assumed to denote terms of type T2. This intuition is captured by the
following rule:
x:T1 ` t2 : T2
` x:T1.t2 : T1!T2 (T-ABS)
Since, in general, function abstractions can be nested, typing assertions actually
have the form   ` t : T, pronounced “term t has type T under the assumptions  
about the types of its free variables.” Formally, the typing context   is just a list of
variables and their types, and the “comma” operator extends   by concatenating a
new binding on the right. To avoid confusion between the new binding and any
bindings that may already appear in  , we require that the name x be chosen so
that it does not already appear in dom( ). (As usual, this condition can always be
satisfied by renaming the bound variable if necessary.)   can thus be thought of
as a finite function from variables to their types. Following this intuition, we will
write dom( ) for the set of variables bound by   and  (x) for the type T associated
with x in  .
So the rule for typing abstractions actually has the general form
 ; x:T1 ` t2 : T2
  ` x:T1.t2 : T1!T2 (T-ABS)
where the premise adds one more assumption to those in the conclusion.
January 15, 2000 7. SIMPLY TYPED LAMBDA-CALCULUS 60
The typing rule for variables follows immediately from this discussion. A vari-
able has whatever type we are currently assuming it to have:
x:T 2  
  ` x : T
(T-VAR)
Next, we need a rule for application:
  ` t1 : T11!T12   ` t2 : T11
  ` t1 t2 : T12
(T-APP)
In English: If t1 evaluates to a function mapping arguments in T2 to results in T1
(under the assumption that the terms represented by its free variables yield results
of the types associated to them by  ), and if t2 evaluates to a result in T2, then the
result of applying t1 to t2 will be a value of type T1.
We have now given typing rules for each of the individual constructs in our
simple language. To assign types to whole programs, we combine these rules
into derivation trees. For example, here is a derivation tree showing that the term
(x:Bool.x) true has type Bool in the empty context:
T-VAR
x:Bool ` x : Bool
T-ABS
` x:Bool.x : Bool!Bool T-TRUE` true : Bool
T-APP
` (x:Bool.x) true : Bool
7.2.1 Exercise [Quick check]: Show (by exhibiting derivation trees) that the fol-
lowing terms have the indicated types in the given contexts:
1. f:Bool!Bool ` f (if false then true else false) : Bool
2. f:Bool!Bool ` x:Bool. f (if x then false else x) : Bool!Bool 2
7.2.2 Exercise [Quick check]: Find a context   under which the term f x y has
type Bool. Can you give a simple description of the set of all such contexts? 2
It is interesting to note that, in the above discussion, the “!” type constructor
comes with typing rules of two kinds:
1. an introduction rule describing how elements of the type can be
created, and
2. an elimination rule describing how elements of the type can be
used.
This terminology, which arises from connections between type theory and logic,
is frequently useful in discussing type systems. When we come to consider more
complex systems later in the course, we’ll see a similar pattern of linked introduc-
tion and elimination rules being repeated for each type constructor we consider.
7.2.3 Exercise [Quick check]: Which of the rules for the type Bool are introduction
rules and which are elimination rules? (Solution on page 255.) 2
January 15, 2000 7. SIMPLY TYPED LAMBDA-CALCULUS 61
7.3 Summary
We have been discussing the simply typed lambda-calculus with booleans and
conditionals, !B . In later chapters, we are going to want to extend the simply
typed lambda-calculus with many other base types, in addition to or instead of
booleans. We therefore split the formal summary of the system into two pieces: the
pure simply typed lambda calculus !, with no base types at all, and a separate
extension with booleans.
! : Simply typed lambda-calculus ! (typed)
Syntax
t ::= (terms...)
x variable
x :T .t abstraction
t t application
v ::= (values...)
x :T .t abstraction value
T ::= (types...)
T!T type of functions
  ::= (contexts...)
; empty context
 ; x:T term variable binding
Evaluation (t  ! t 0)
(x :T11 .t12) v2  ! fx 7! v2gt12 (E-BETA)
t1  ! t1 0
t1 t2  ! t 01 t2 (E-APP1)
t2  ! t2 0
v1 t2  ! v1 t 02 (E-APP2)
Typing (   ` t : T)
x:T 2  
  ` x : T
(T-VAR)
 ; x:T1 ` t2 : T2
  ` x:T1.t2 : T1!T2 (T-ABS)
January 15, 2000 7. SIMPLY TYPED LAMBDA-CALCULUS 62
  ` t1 : T11!T12   ` t2 : T11
  ` t1 t2 : T12
(T-APP)
The highlighted areas here are used to mark material that is new with respect to
the untyped lambda-calculus—whole new rules as well as new bits that need to be
added to rules that we have already seen.
7.3.1 Exercise [Quick check]: The system ! by itself is actually trivial, in the
sense that it has no well-typed programs at all. Why? (Solution on page 255.) 2
7.4 Properties of Typing and Reduction
Typechecking
As in Chapter 6, we need to develop a few basic lemmas before we can prove
type soundness. Most of these are similar to what we saw before (just adding
contexts to the typing relation and adding appropriate clauses for -terms. The
only significant new requirement is a substitution principle for the typing relation
(Lemma 7.4.9).
7.4.1 Lemma [Inversion of the typing relation]:
1. If   ` x : R, then x:R 2  .
2. If   ` x:T2. t1 : R2!R1, then R2 = T2 and  ; x:T2 ` t1 : R1.
3. If   ` t1 t2 : R, then there is some type T2 such that   ` t1 : T2!R and
  ` t2 : T2.
4. If   ` true : R, then R = Bool.
5. If   ` false : R, then R = Bool.
6. If   ` if t1 then t2 else t3 : R, then
  ` t1 : Bool
  ` t2 : R
  ` t3 : R: 2
Proof: Immediate from the definition of the typing relation. 2
7.4.2 Exercise [Easy]: Write out a typechecking algorithm for ! in pseudo-code
or a programming language of your choice. Compare your answer with the ML
implementation in Section 7.5. 2
January 15, 2000 7. SIMPLY TYPED LAMBDA-CALCULUS 63
In Section 7.1, we chose to use an explicitly typed presentation of the calculus,
partly in order to simplify the algorithmic issues involved in typechecking. This
involved adding type annotations to bound variables in function abstractions, but
nowhere else. In what sense is this “enough”?
One answer is provided by the “uniqueness of types” theorem, the substance
of which is that well-typed terms are in one-to-one correspondence with the typing
derivations that justify their well-typedness (in a given environment). The typing
derivation can be recovered immediately from the term, and vice versa. In fact, the
correspondence is so straightforward that, in a sense, there is little difference be-
tween the term and the derivation. (For many of the type systems that we will see,
this simple correspondence will not hold: there will be significant work involved
in showing that typing derivations can be recovered effectively from typed terms.)
7.4.3 Theorem [Uniqueness of Types]: In a given typing context  , a term t (with
free variables all in the domain of  ) has at most one type. That is, if a term is
typeable, then its type is unique. Moreover, there is just one derivation of this
typing built from the inference rules that generate the typing relation. 2
The proof of the uniqueness theorem is so direct that there is almost nothing
to say. We present a few cases carefully just to illustrate the structure of proofs by
induction on typing derivations.
Proof: Suppose that   ` t : S and   ` t : T. We show, by induction on a deriva-
tion of   ` t : T, that S = T.
Case T-VAR: t = x
with x:T 2  
By case (1) of the inversion lemma (7.4.1), the final rule in any derivation of   ` t :
S must also be T-VAR, and S = T.
Case T-ABS: t = y:T2.t1
T = T2!T1
 ; y:T2 ` t1 : T1
By case (2) of the inversion lemma, the final rule in any derivation of   ` t : S
must also be T-ABS, and this derivation must have a subderivation with conclu-
sion  ; y:T2 ` t1 : S1, with S = T2!S1. By the induction hypothesis (on the
subderivation with conclusion ( ; y:T2 ` t1 : T1), we obtain S1 = T1, from which
S = T is immediate.
Case T-APP, T-TRUE, T-FALSE, T-IF:
Similar. 2
7.4.4 Exercise [Quick check]: Write out the case for T-APP. 2
7.4.5 Exercise [Recommended]: Is there any context   and type T such that   `
x x : T? If so, give   and T and show a typing derivation for   ` x x : T; if not,
prove it. 2
January 15, 2000 7. SIMPLY TYPED LAMBDA-CALCULUS 64
We shall sometimes need to talk about the types of subterms of well-typed
terms. The following notation is useful for this purpose.
7.4.6 Definition: Suppose the term s is well typed with respect to the typing con-
text  , and that r is some subterm of s. We write typeOf
 
(r) for the type R such
that   0 ` r : R, where   0 is calculated by extending   with bindings corresponding
to all of the function abstractions inside s under which r occurs. For example, if
s = f:A!B. g:A. f g and r = f g, then typeOf
 
(r) = B. When (as in this chap-
ter)   is fixed for the whole discussion, we usually elide it, writing just typeOf(r).
Note that R is unique, by Theorem 7.4.3. 2
We close this section with a couple of “structural lemmas” for the typing re-
lation. These are not particularly interesting in themselves, but will permit us to
perform some useful manipulations of typing derivations in later proofs.
7.4.7 Lemma [Permutation]: If   ` t : T and  is a permutation of  , then  ` t :
T. Moreover, the latter derivation has the same depth as the former. 2
Proof: Straightforward induction on typing derivations. 2
7.4.8 Lemma [Weakening]: If   ` t : T and x =2 dom( ), then  ; x:S ` t : T.
Moreover, the latter derivation has the same depth as the former. 2
Proof: Straightforward induction on typing derivations. 2
Typing and Substitution
7.4.9 Lemma [Substitution]: If  ; x:S ` t : T and   ` s : S, then   ` fx 7! sgt :
T. 2
7.4.10 Exercise [Recommended]: Prove the substitution lemma, using an induc-
tion on the depth of typing derivations and Lemma 7.4.1. The full proof appears
in the solutions; try to write it out yourself before having a look at the answer.
(Solution on page 255.) 2
Type Soundness
7.4.11 Theorem [Preservation of types during evaluation]: If   ` t : T and t  ! 
t 0, then ` t 0 : T. 2
Proof: 2
7.4.12 Theorem [Progress]: Suppose t is closed and stuck. If ` t : T, then t is a
value. 2
Proof: Outline: first show that every closed value of type Bool is either true or
false and every closed value of type S!T is a  abstraction. 2
January 15, 2000 7. SIMPLY TYPED LAMBDA-CALCULUS 65
7.5 Implementation
type ty =
TyArr of ty * ty
| TyBool
type term =
TmVar of info * int * int
| TmAbs of info * string * ty * term
| TmApp of info * term * term
| TmTrue of info
| TmFalse of info
| TmIf of info * term * term * term
let rec tyeqv tyS tyT =
match (tyS,tyT) with
(TyArr(tyS1,tyS2),TyArr(tyT1,tyT2)) !
(tyeqv tyS1 tyT1) && (tyeqv tyS2 tyT2)
| (TyBool,TyBool) ! true
| _ ! false
let rec typeof ctx t =
match t with
TmVar(fi,i,_) !
gettype fi ctx i
| TmAbs(fi,x,tyS,t1) !
let ctx' = addbinding ctx x (VarBind(tyS)) in
let tyT = typeof ctx' t1 in
TyArr(tyS, tyshift tyT (-1))
| TmApp(fi,t1,t2) !
let tyT1 = typeof ctx t1 in
let tyT2 = typeof ctx t2 in
(match tyT1 with
TyArr(tyT11,tyT12) !
if tyeqv tyT2 tyT11 then tyT12
else error fi "parameter type mismatch"
| _ ! error fi "arrow type expected")
| TmTrue(fi) !
TyBool
| TmFalse(fi) !
TyBool
| TmIf(fi,s1,s2,s3) !
if tyeqv (typeof ctx s1) TyBool then
let tyS = typeof ctx s2 in
if tyeqv tyS (typeof ctx s3) then tyS
else error fi "arms of conditional have different types"
else error fi "guard of conditional not a boolean"
January 15, 2000 7. SIMPLY TYPED LAMBDA-CALCULUS 66
7.6 Further Reading
The untyped lambda-calculus was developed by Church and his co-workers in the
1930s [Chu41]. The standard text for all aspects of the untyped lambda-calculus is
Barendregt [Bar84]. Hindley and Seldin [HS86] is less comprehensive, but some-
what more accessible. Barendregt’s article in the Handbook of Theoretical Com-
puter Science [Bar90] is a compact survey.
The simply typed lambda-calculus is studied in Hindley and Seldin [HS86]
and in even greater detail in Hindley’s more recent book [Hin97]. Material on
both typed and untyped lambda-calculus can also be found in many textbooks
on functional programming languages (e.g. [PJL92]) and programming language
semantics (e.g.[Sch86, Gun92, Win93, Mit96]).
Chapter 8
Extensions
This chapter is just a sketch (but all the underlying implementations are finished, so it
won’t be too hard to fill in). It presents a bunch of familiar typing features and program-
ming language constructs and shows how they fit into the framework we’ve built. There
should be lots of exercises.
8.1 Base Types
Base types ! B
New syntactic forms
T ::= ... (types...)
B base type
8.2 Unit type
Unit type ! Unit
New syntactic forms
t ::= ... (terms...)
unit constant unit
T ::= ... (types...)
67
January 15, 2000 8. EXTENSIONS 68
Unit unit type
New typing rules (  ` t : T)
  ` unit : Unit (T-UNIT)
Note: C and Java’s void type is a misnomer – what they really mean is Unit
8.3 Let bindings
Let binding ! let
New syntactic forms
t ::= ... (terms...)
let x=t in t let binding
New evaluation rules (t  ! t 0)
let x=v1 in t2  ! fx 7! v1gt2 (E-LETBETA)
t1  ! t1 0
let x=t1 in t2  ! let x=t 01 in t2 (E-LET)
New typing rules (  ` t : T)
  ` t1 : T1  ; x:T1 ` t2 : T2
  ` let x=t1 in t2 : T2
(T-LET)
8.3.1 Exercise [Recommended]: Add let bindings to the “simple” typechecker
implementation. (Solution on page ??.) 2
8.4 Records and Tuples
January 15, 2000 8. EXTENSIONS 69
Records and tuples ! fg
New syntactic forms
t ::= ... (terms...)
{li=ti
i21::n} record
t.l projection
v ::= ... (values...)
{li=vi
i21::n} record value
T ::= ... (types...)
{li:Ti
i21::n} type of records
New evaluation rules (t  ! t 0)
{li=vi
i21::n}.li  ! vi (E-RCDBETA)
t1  ! t 01
t1.l  ! t 01.l (E-PROJ)
tj  ! t 0j
{li=vi
i21::n}  ! {li=vi i21::j-1,lj=t 0j,lk=tk k2j+1::n} (E-RECORD)
New typing rules (  ` t : T)
for each i   ` ti : Ti
  ` {li=ti i21::n} : {li:Ti i21::n}
(T-RCD)
  ` t : {li:Ti
i21::n}
  ` t.lj : Tj
(T-PROJ)
New abbreviations
{...ti...}
def
= {...i=ti...}
{...Ti...}
def
= {...i:Ti...}
8.4.1 Exercise: In this presentation of records, the projection operation is used to
extract the fields of a record one by one. Many high-level programming languages
provide an alternative pattern matching syntax that extracts all the fields at the
same time, allowing many programs to be expressed more concisely. Patterns can
typically be nested, allowing parts to be extracted easily from complex nested data
structures.
For example, we can add a simple form of pattern matching to the untyped
lambda calculus with records by adding a new syntactic category of patterns, plus
January 15, 2000 8. EXTENSIONS 70
one new case (for the pattern matching construct itself) to the syntax of terms. To
define the computation rule for pattern matching, we need an auxiliary “match-
ing” function. Given a pattern and a term, the pattern matching function either
fails (if the term does not match the pattern) or else yields a substitution that re-
places variables appearing in the pattern with the corresponding subterms of the
given term. Here is the formal definition of the calculus, highlighting differences
from the pure untyped lambda-calculus with records and ordinary let-binding:
January 15, 2000 8. EXTENSIONS 71
Record patterns ! fg let pat (untyped)
New syntactic forms
p ::= :::
x variable pattern
{li=pi
i21::n} record pattern
t ::= ... (terms...)
let p =t in t pattern binding
Matching rules:
match(x; t) = fx 7! tg (M-VAR)
for each i match(pi; ti) = i
match({li=pi i21::n}; {li=ti i21::n}) = 1 Æ    Æ n
(M-RCD)
New evaluation rules (t  ! t 0)
let p =v1 in t2  ! match(p; v1) t2 (E-LETBETA)
t1  ! t1 0
let p =t1 in t2  ! let p =t 01 in t2 (E-LET)
New abbreviations
{...pi...}
def
= {...i=pi...}
Your job is to add types to this calculus, in the style of the simply typed lambda-
calculus:
1. Give typing rules for the new constructs (making any changes to the syntax
you feel are necessary in the process).
2. Sketch a proof of type preservation and progress for the whole calculus by
stating the sequence of major lemmas needed to carry out the proof. (You
do not need to show proofs, just statements of the required lemmas in the
correct order.)
(Solution on page 256.) 2
January 15, 2000 8. EXTENSIONS 72
8.5 Variants
Variants ! <>
New syntactic forms
t ::= ... (terms...)
<l=t> as T tagging
case t of ... | li=x)ti | ... case
T ::= ... (types...)
<li:Ti
i21::n> type of variants
New evaluation rules (t  ! t 0)
case <li=vi> as T of ...|li=x)ti|...  ! fx 7! vigti (E-CASEBETA)
s1  ! s1 0
case s1 of ...|li=x)ti|...  ! case s 01 of ...|li=x)ti|... (E-CASE)
ti  ! ti 0
<li=ti> as T  ! <li=t 0i> as T (E-TAG)
New typing rules (  ` t : T)
for each i   ` ti : Ti
  ` <li=ti> as <li:Ti i21::n> : <li:Ti i21::n>
(T-VARIANT)
  ` t0 : <li:Ti i21::n>
for each i  ; xi:Ti ` ti : T
  ` case t0 of ...|li=xi)ti|... : T (T-CASE)
Note that we syntactically allow the type label to be a non-variant type, but the
typing rule then excludes this case. This is just for brevity (and implementation
flexibility, e.g. when we get to definitions).
8.6 General recursion
January 15, 2000 8. EXTENSIONS 73
General recursion ! fix
New syntactic forms
t ::= ... (terms...)
fix t fixed point of t
New typing rules (  ` t : T)
  ` t1 : T1!T1
  ` fix t1 : T1
(T-FIX)
New abbreviations
letrec x=t1 in t2
def
= let x = fix (x.t1) in t2
A corollary of the definability of fixed-point combinators at every type is that
every type in this system is inhabited. For example, for each type T, the application
(divergeT unit) has type T, where divergeT is defined like this:
divergeT = _:Unit. fix (x:T. x);
I T = Nat: *
divergeT : Unit ! T
8.7 Lists
Lists ! B List
New syntactic forms
t ::= ... (terms...)
nil [T] empty list
cons [T] t t list constructor
null [T] t test for empty list
head [T] t head of a list
tail [T] t tail of a list
v ::= ... (values...)
nil [T] empty list
cons [T] v v list constructor
T ::= ... (types...)
List T type of lists
New evaluation rules (t  ! t 0)
January 15, 2000 8. EXTENSIONS 74
t1  ! t 01
cons[T] t1 t2  ! cons[T] t 01 t2 (E-CONS1)
t2  ! t 02
cons[T] v1 t2  ! cons[T] v 01 t2 (E-CONS2)
null[S] (nil[T])  ! true (E-NULLBETAT)
null[S] (cons[T] v1 v2)  ! false (E-NULLBETAF)
t1  ! t 01
null[T] t1  ! null[T] t 01 (E-NULL)
head[S] (cons[T] v1 v2)  ! v1 (E-HEADBETA)
t1  ! t 01
head[T] t1  ! head[T] t 01 (E-HEAD)
tail[S] (cons[T] v1 v2)  ! v1 (E-TAILBETA)
t1  ! t 01
tail[T] t1  ! tail[T] t 01 (E-TAIL)
New typing rules (  ` t : T)
  ` nil [T] : List T (T-NIL)
  ` t1 : T1   ` t2 : List T1
  ` cons t1 t2 : List T1
(T-CONS)
  ` t1 : List T1
  ` null t1 : Bool
(T-NULL)
  ` t1 : List T1
  ` head t1 : T1
(T-HEAD)
  ` t1 : List T1
  ` tail t1 : List T1
(T-TAIL)
January 15, 2000 8. EXTENSIONS 75
8.8 Lazy records and let-bindings
Lazy let bindings ! let lazy
New syntactic forms
t ::= ... (terms...)
lazy let x=t in t lazy let binding
New evaluation rules (t  ! t 0)
lazy let x=t1 in t2  ! fx 7! t1gt2 (E-LLETBETA)
New typing rules (  ` t : T)
  ` t1 : T1  ; x:T1 ` t2 : T2
  ` lazy let x=t1 in t2 : T2
(T-LLET)
Lazy records ! fg lazy
New syntactic forms
t ::= ... (terms...)
lazy {li=ti
i21::n} lazy record
v ::= ... (values...)
lazy {li=ti
i21::n} lazy record value
New evaluation rules (t  ! t 0)
(lazy {li=ti
i21::n}).li  ! ti (E-LRCDBETA)
New typing rules (  ` t : T)
  ` i21::n ti : Ti
  ` lazy {li=ti i21::n} : {li:Ti i21::n}
(T-LRCD)
Exercise: write down rules for lazy functions
(These are used only in the advanced parts of the object examples.)
Chapter 9
References
This chapter is still very rough. The basic approach seems fine, but there’s a good deal of
work to do on details.
References ! Unit :=
Syntax
t ::= (terms...)
x variable
x:T.t abstraction
t t application
unit constant unit
l store location
ref t reference creation
!t dereference
t:=t assignment
v ::= (values...)
x:T.t abstraction value
l store location
T ::= (types...)
T!T type of functions
Unit unit type
Ref T1 type of reference cells
  ::= (contexts...)
; empty context
 ; x:T term variable binding
76
January 15, 2000 9. REFERENCES 77
 ::= ; empty store
; l = t location binding
 ::= ; empty store typing
; l:T location typing
Evaluation (t j   ! t 0 j  0 )
(x :T11 .t12) v2 j   ! fx 7! v2gt12 j  (E-BETA)
t1 j   ! t1 0 j  0
t1 t2 j   ! t 01 t2 j  0 (E-APP1)
t2 j   ! t2 0 j  0
v1 t2 j   ! v1 t 02 j  0 (E-APP2)
l =2 dom()
ref v1 j   ! l j (; l = v1) (E-REF)
t1 j   ! t1 0 j  0
ref t1 j   ! ref t 01 j  0 (E-REF1)
(l) = v
!l j   ! v j  (E-DEREF)
t1 j   ! t1 0 j  0
!t1 j   ! !t 01 j  0 (E-DEREF1)
l:=v2 j   ! unit j fl 7! v2g (E-ASSIGN)
t1 j   ! t1 0 j  0
t1:=t2 j   ! t 01:=t2 j  0 (E-ASSIGN1)
t2 j   ! t2 0 j  0
v1:=t2 j   ! v1:=t 02 j  0 (E-ASSIGN2)
Typing (  j  ` t : T)
x:T 2  
  j  ` x : T
(T-VAR)
 ; x:T1 j  ` t2 : T2
  j  ` x:T1.t2 : T1!T2 (T-ABS)
January 15, 2000 9. REFERENCES 78
  j  ` t1 : T11!T12   j  ` t2 : T11
  j  ` t1 t2 : T12
(T-APP)
  j  ` unit : Unit (T-UNIT)
(l) = T
  j  ` l : Ref T
(T-LOC)
  j  ` t1 : T1
  j  ` ref t1 : Ref T1
(T-REF)
  j  ` t1 : Ref T1
  j  ` !t1 : T1
(T-DEREF)
  j  ` t1 : Ref T1   j  ` t2 : T1
  j  ` t1:=t2 : Unit
(T-ASSIGN)
9.1 Definition: We say that a store  is well-typed with respect to a typing context
  and a store typing , written   j  ` , if dom() = dom() and   j  ` (l) : (l)
for every l 2 dom(). 2
9.2 Lemma [Substitution]: If  ; x:S;  ` t : T and   j  ` s : S, then   j  ` fx 7!
sgt : T. 2
Proof: Just like the proof of Lemma 7.4.9. 2
9.3 Lemma: If   j  ` t : T and  0  , then  ;  0 ` t : T. 2
Proof: Easy. 2
9.4 Theorem [Preservation]: If
  j  ` t : T
  j  ` 
t j   ! t 0 j  0
then, for some  0  ,
  j  0 ` t 0 : T
  j  0 `  0. 2
Proof: Clearly, the preservation property for multi-step evaluation will follow (by
a straightforward induction) from preservation for single-step evaluation. This,
in turn, is established by an induction on a derivation of t j   ! t 0 j  0. All
the cases of this induction are straightforward, using the lemmas above and the
evident inversion property of the typing rules. 2
9.5 Exercise: Is the evaluation relation defined in this chapter strongly normaliz-
ing on well-typed terms? (Solution on page 260.) 2
January 15, 2000 9. REFERENCES 79
9.1 Further Reading
The presentation of references in this chapter is adapted from Harper’s treatment [?].
An earlier account in a similar style is given by Wright and Felleisen [?].
The combination of references (or other computational effects) with ML-style
polymorphic type inference (cf. Section ??) raises some subtle problems and has
received a good deal of attention in the research literature. See [Tof90, HMV93,
JG91, TJ92, TJ92, LW91, Wri92] and the references cited there.
Chapter 10
Exceptions
I’m not sure whether the amount of material here warrants a separate chapter, or just a
section in Chapter 8.
10.1 Errors
10.2 Exceptions
80
Chapter 11
Type Equivalence
To be written.
The point of introducing equivalence as a separate notion is that it gives a uniform
framework for all kinds of definitional equivalences on types. It introduces a bit of overhead
too, but I think it’s worth it in this case.
This chapter has just been added, and some of the later chapters have not been brought
up to date (the equivalence rules used to be folded into the subtyping relation).
Records with permutation of fields ! fg 
Type equivalence (S  T)
T  T (Q-REFL)
T  S
S  T
(Q-SYMM)
S  U U  T
S  T
(Q-TRANS)
S1  T1 S2  T2
S1!S2  T1!T2 (Q-ARROW)
 is a permutation of f1::ng
{li:Ti
i21::n}  {li:T
i21::n
i }
(Q-RCD-PERM)
New typing rules (  ` t : T)
  ` t : S S  T
  ` t : T
(T-EQ)
81
January 15, 2000 11. TYPE EQUIVALENCE 82
Algorithmic rules for simply typed lambda-calculus ! B
Algorithmic typing (  `I t : T)
x:T 2  
  `I x : T
(TA-VAR)
 ; x:T1 `I t2 : T2
  `I x:T1.t2 : T1!T2 (TA-ABS)
  `I t1 : T1 T1 = T11!T12   `I t2 : T2 T2 = T11
  `I t1 t2 : T12
(TA-APP)
Algorithmic rules for records with permutation ! fg 
Algorithmic type equivalence (`I S  T)
`I S1  T1 `I S2  T2
`I S1!S2  T1!T2 (QA-ARROW)
 is a permutation of f1::ng
for each i `I Ti  Ti
`I {li:Ti i21::n}  {li:T
i21::n
i }
(QA-RCD)
Algorithmic typing (  `I t : T)
x:T 2  
  `I x : T
(TA-VAR)
 ; x:T1 `I t2 : T2
  `I x:T1.t2 : T1!T2 (TA-ABS)
  `I t1 : T1 T1 = T11!T12   `I t2 : T2 `I T2  T11
  `I t1 t2 : T12
(TA-APP)
for each i   `I ti : Ti
  `I {l1=t1...ln=tn} : {l1:T1...ln:Tn}
(TA-RCD)
  `I t : {l1:T1...ln:Tn}
  `I t.li : Ti
(TA-PROJ)
Chapter 12
Definitions
12.1 Type Definitions
(needed for equirec implementation stuff)
introduce type variables (this section is optional, so we need to re-introduce
them when we get to polymporphism)
extend type equivalence relation
talk about exposing types before matching against them
Exercise: inner defns (not trivial: must eliminate remaining occurrences when
leaving the scope of the definition)
Type definitions ! B $
New syntactic forms
T ::= ... (types...)
X type variable
  ::= ... (contexts...)
 ; X$T type definition binding
New type equivalence rules (   ` S  T)
  ` T  T (Q-REFL)
  ` T  S
  ` S  T
(Q-SYMM)
  ` S  U   ` U  T
  ` S  T
(Q-TRANS)
83
January 15, 2000 12. DEFINITIONS 84
  ` S1  T1   ` S2  T2
  ` S1!S2  T1!T2 (Q-ARROW)
X$T 2  
  ` X  T
(Q-DEF)
New typing rules (  ` t : T)
  ` t : S   ` S  T
  ` t : T
(T-EQ)
Algorithmic rules for type definitions ! B $
Algorithmic reduction (   `I T T 0)
X$T 2  
  ` X T
(RA-DEF)
Algorithmic type equivalence (   `I S  T)
  `I B  B (QA-BASE)
  `I S S 0   `I S 0  T
  `I S  T
(QA-REDUCEL)
  `I T T 0   `I S  T 0
  `I S  T
(QA-REDUCER)
  `I S1  T1   `I S2  T2
  `I S1!S2  T1!T2 (QA-ARROW)
Exposure (   `I T * T 0)
otherwise
  `I T * T (XA-OTHER)
  `I T T 0   `I T 0 * T 00
  `I T * T 00 (XA-REDUCE)
Algorithmic typing (  `I t : T)
x:T 2  
  `I x : T
(TA-VAR)
 ; x:T1 `I t2 : T2
  `I x:T1.t2 : T1!T2 (TA-ABS)
January 15, 2000 12. DEFINITIONS 85
  `I t1 : T1   `I T1 * (T11!T12)   `I t2 : T2   `I T2  T11
  `I t1 t2 : T12
(TA-APP)
12.2 Term Definitions
(This should be very optional, but it’s nice to be honest about what the checkers
are doing.)
Chapter 13
Subtyping
This material is not too far from finished, but the proofs and presentation need to be re-
worked a little in light of the addition of Chapter 11.
In programming in the simply typed lambda-calculus, we may sometimes find
ourselves irritated by the type system’s insistence that types match exactly, for
example in the rule T-APP for typing applications:
  ` t1 : T11!T12   ` t2 : T11
  ` t1 t2 : T12
(T-APP)
According to this rule, the term
(r:{x:Nat}. r.x) {x=0, y=1}
is not typeable, even though it will obviously evaluate without producing any
run-time errors, since the function only requires that its argument has a field x; it
doesn’t care what other fields the argument may or may not have. Moreover, this
fact is evident from the type of the function—we don’t need to look at its body to
see that it doesn’t use any fields besides x.
One way to formalize this observation is to extend the typing rules so that
the term {x=0, y=0} is given a set of types including both {x:Nat, y:Nat} and
{x:Nat}. Then the application above is well typed because one of the possible
types of the argument matches the left-hand side of the type of the function.
To accomplish this in a general way, we introduce a principle of safe substitu-
tion: We say that “S is a subtype of T,” written S <: T, to mean that any term of
type S can safely be used in a context where a term of type T is required. If this is
the case, then a term t of type S is also given the type T, using the so-called rule of
subsumption:
  ` t : S   `S <: T
  ` t : T
(T-SUB)
86
January 15, 2000 13. SUBTYPING 87
No other changes are needed to the typing relation (though, as we shall see in
Section 13.2, some changes are required to the algorithmic implementation of the
typing relation). It remains only to formalize the subtype relation.
In this chapter, we’ll mainly work with a calculus with just records and func-
tions (written <:fg, for short), which is rich enough to bring out most of the inter-
esting issues. Examples and exercises will touch on the combination of subtyping
with most of the other features we have seen.
13.1 The Subtype Relation
Clearly, it is not safe to substitute functions for records, records for functions, etc.
The subtyping relation will only be defined for types with similar structure.
First, just to make sure that our subtyping relation is sensible, we make two
general stipulations: first, that it should be reflexive,
and second, that it should be transitive:
  `S <: U   `U <: T
  `S <: T
(S-TRANS)
These rules follow directly from the intuition of safe substitutivity. The remainder
of the rules defining the subtype relation concern the behavior of specific type
constructors.
For record types, we have already seen that we want to consider the type S =
{k1:S1...km:Sm} to be a subtype of T = {l1:T1...ln:Tn} if T is obtained by
dropping fields from S.
  `{li:Ti i21::n+k} <: {li:Ti i21::n} (S-RCD-WIDTH)
In fact, we can be a little more general than this and also allow the types of the
common fields to differ, so long as their types in S are subtypes of their types in T.
for each i   `Si <: Ti
  `{li:Si i21::n} <: {li:Ti i21::n}
(S-RCD-DEPTH)
Also, it makes sense to ignore the order of fields in a record, since the only thing
that we can do with records—namely, field projection—is insensitive to the order
of fields.
For functions, the rule is a little trickier:
  `T1 <: S1   `S2 <: T2
  `S1!S2 <: T1!T2 (S-ARROW)
That is, we allow a function of one type to be used where another is expected as
long as none of the arguments that may be passed to the function by the context
will surprise it (T1 <: S1) and none of the results that it returns will surprise the
context (S2 <: T2). Notice that the sense of the subtype relation is reversed on
the left of the arrow; this rule is sometimes referred to as the “contravariant arrow
rule” for this reason.
January 15, 2000 13. SUBTYPING 88
13.1.1 Exercise [Quick check]: Demonstrate that the premises of S-ARROW are both
necessary by giving ill-behaved programs that would be well typed if either premise
were dropped. 2
Finally, for various reasons, it will be convenient to have a type that is a super-
type of every type. We introduce a new type constant Top for this purpose, plus a
rule that makes Top maximal in the subtype relation.
  `S <: Top (S-TOP)
Formally, the subtype relation is the least relation closed under the rules we
have given.
13.1.2 Exercise [Quick check]: In a system with reference cells, would it be a good
idea to add a rule
S <: T
Ref S <: Ref T
for subtyping between reference cell types? 2
Variance
We pause for a moment to introduce some useful terminology for discussing types
and subtyping.
Suppose T[ ] is a type term containing some number of holes, written “[ ]” some-
place inside it; we write T(S) for the term that results from filling the holes in
T with S. For example, if T[ ] = {x:Top,y:[ ]}!Top![ ]!Nat, then T(Nat) =
{x:Top,y:Nat}!Top!Nat!Nat.
We say that T[ ] is covariant in the position(s) marked by the holes if, whenever
S1<:S2, we have T(S1) <: T(S2). We say that T[ ] is contravariant if, whenever
S1<:S2, we have T(S2) <: T(S1). If T[ ] is neither covariant nor contravariant,
it is said to be invariant. For example, we say that the arrow type constructor
is contravariant in its first argument and covariant in its second, since [ ]!S is
contravariant while S![ ] is covariant.
13.1.3 Exercise: Which of the following types are covariant in the position marked
by the hole(s)? Which are contravariant? Which are invariant?
1. T[ ] = [ ]!Top
2. T[ ] = Top![ ]
3. T[ ] = {x:Top,y:[ ]}!Nat!Nat
4. T[ ] = [ ]!Top!Top
5. T[ ] = ([ ]!Top)!Top
January 15, 2000 13. SUBTYPING 89
6. T[ ] = [ ]!Nat![ ]
7. T[ ] = [ ]
8. T[ ] = Nat 2
Summary
As usual, we present the subtyping extension of the pure simply typed lambda
calculus first, then the additional rules for records.

<:
: Simply typed lambda-calculus with subtyping ! <:
Syntax
t ::= (terms...)
x variable
x:T.t abstraction
t t application
v ::= (values...)
x:T.t abstraction value
T ::= (types...)
T!T type of functions
Top maximum type
  ::= (contexts...)
; empty context
 ; x:T term variable binding
Evaluation (t  ! t 0)
(x:T11.t12) v2  ! fx 7! v2gt12 (E-BETA)
t1  ! t1 0
t1 t2  ! t 01 t2 (E-APP1)
t2  ! t2 0
v1 t2  ! v1 t 02 (E-APP2)
Subtyping (S <: T)
S <: S (S-REFL)
S <: U U <: T
S <: T
(S-TRANS)
January 15, 2000 13. SUBTYPING 90
S <: Top (S-TOP)
T1 <: S1 S2 <: T2
S1!S2 <: T1!T2 (S-ARROW)
Typing (  ` t : T)
x:T 2  
  ` x : T
(T-VAR)
 ; x:T1 ` t2 : T2
  ` x:T1.t2 : T1!T2 (T-ABS)
  ` t1 : T11!T12   ` t2 : T11
  ` t1 t2 : T12
(T-APP)
  ` t : S S <: T
  ` t : T
(T-SUB)
Subtyping rules for records !<: fg
New type equivalence rules (S  T)
T  T (Q-REFL)
T  S
S  T
(Q-SYMM)
S  U U  T
S  T
(Q-TRANS)
S1  T1 S2  T2
S1!S2  T1!T2 (Q-ARROW)
 is a permutation of f1::ng
{li:Ti
i21::n}  {li:T
i21::n
i }
(Q-RCD-PERM)
New subtyping rules (S <: T)
S  T
S <: T
(S-EQV)
{li:Ti
i21::n+k} <: {li:Ti
i21::n} (S-RCD-WIDTH)
for each i Si <: Ti
{li:Si
i21::n} <: {li:Ti
i21::n}
(S-RCD-DEPTH)
January 15, 2000 13. SUBTYPING 91
13.1.4 Exercise: What should the subtyping rules for variants be? 2
13.1.5 Exercise: In what ways are the Top type and the empty record type {} simi-
lar? In what ways are they different? 2
13.2 Metatheory of Subtyping
First, show that type equivalence can be deleted by merging with the record rule as below.
Then proceed as before.
In this section we consider some of the properties of the system !fg<:, the
simply typed lambda-calculus with records and subtyping.
Algorithmic Subtyping
The three rules for record subtyping are often combined into one more compact
but less readable rule:
fli
i21::ng  fkj j21::mg kj = li implies Sj <: Ti
{kj:Sj
j21::m} <: {li:Ti
i21::n}
(S-RCD)
13.2.1 Lemma: This rule can be derived from S-RCD-DEPTH, S-RECORD-WIDTH,
and S-RECORD-PERM (using reflexivity and transitivity) and vice versa. 2
Proof: Exercise. 2
We now observe that the rules of reflexivity and transitivity are inessential, in
the following sense:
13.2.2 Lemma:
1. S <: S can be derived for every type S without using S-REFL.
2. If S <: T can be derived at all, then it can be derived without using S-TRANS.2
Proof: Exercise. 2
13.2.3 Exercise [Quick check]: If we add Nat to the type system, how do these
properties change? 2
13.2.4 Definition: The algorithmic subtyping relation is the least relation closed
under the following rules:
January 15, 2000 13. SUBTYPING 92
Algorithmic subtyping ! fg <:
Algorithmic subtyping (`I S <: T)
`I S <: Top (SA-TOP)
`I T1 <: S1 `I S2 <: T2
`I S1!S2 <: T1!T2 (SA-ARROW)
fli
i21::ng  fkj j21::mg if kj = li, then `I Sj <: Ti
`I {kj:Sj j21::m} <: {li:Ti i21::n}
(SA-RCD)
2
13.2.5 Proposition [Soundness and completeness of algorithmic subtyping]:
S <: T iff S <:a T. 2
Proof: Using the two previous lemmas. 2
This, in turn, leads directly to an algorithm for checking the algorithmic sub-
type relation (and hence also the declarative subtype relation, by Proposition 13.2.5).
subtype(S; T) = if T = Top,
then true
else if S = S1!S2 and T = T1!T2
then subtype(T1; S1) ^ subtype(S2; T2)
else if S = {kj:Sj j21::m} and T = {li:Ti i21::n}
then, for all i 2 1::n,
find j such that kj = li and check
subtype(Sj; Ti)
else
false.
Minimal Typing
By introducing the rule of subsumption into the typing relation, we have lost the
useful syntax-directedness property, which in the simply typed lambda-calculus
allows a typechecker to be implemented simply by “reading the rules from bottom
to top.” Without this property, how can we now check whether   ` t : T is a
derivable statement?
We do it in two steps:
1. Find another set of syntax rules that are syntax directed, defining a relation
  `I t : T. This is called the algorithmic typing relation.
January 15, 2000 13. SUBTYPING 93
2. Show that, although they are defined differently, the ordinary typing relation
  ` t : T and the algorithmic typing relation   `I t : T give rise to the same
set of typable terms. Interestingly, though, they will not assign exactly the
same types to those terms.
In order to find an algorithmic presentation of the typing relation, we need to
think carefully about the structure of typing derivations to see where the rule of
subsumption is really needed, and where we could just as well do without it.
For example, consider the following derivation:
...
 ; x:S ` t : T
...
T <: T 0
(T-SUB)
 ; x:S ` t : T 0
(T-ABS)
  ` x:S.t : S!T 0
Any such derivation can be rearranged like this:
...
 ; x:S ` t : T
(T-ABS)
  ` x:S.t : S!T
(S-REFL)
S <: S
...
T <: T 0
(S-ABS)
S!T <: S!T 0
(T-SUB)
  ` x:S.t : S!T 0
So we can get away with not allowing instances of T-SUB as the final rule in the
right-hand premise of an instance of T-ABS.
Similarly, any derivation of the form
...
  ` t1 : S1!S2
...
T1 <: S1
...
S2 <: T2
(S-ARROW)
S1!S2 <: T1!T2
(T-SUB)
  ` t1 : T1!T2
...
  ` t2 : T1
  ` t1 t2 : T2
can be replaced by one of the form:
...
  ` t1 : S1!S2
...
  ` t2 : T1
...
T1 <: S1
(T-SUB)
  ` t2 : S1
(T-APP)
  ` t1 t2 : S2
...
S2 <: T2
(T-SUB)
  ` t1 t2 : T2
January 15, 2000 13. SUBTYPING 94
That is, we can take any derivation where subsumption is used as the final rule in
the left-hand premise of an instance of T-APP and replace it by a derivation with
one instance of subsumption appearing at the end of the right-hand premise and
another instance of subsumption appearing at the end of the whole derivation.
Finally, adjacent uses of subsumption can be coalesced, in the sense that any
derivation of the form
...
  ` t : S
...
S <: U
(T-SUB)
  ` t : U
...
U <: T
(T-SUB)
  ` t : T
can be rewritten:
...
  ` t : S
...
S <: U
...
U <: T
(S-TRANS)
S <: T
(T-SUB)
  ` t : T
13.2.6 Exercise [Recommended]: Show that a similar rearrangement can be per-
formed on derivations in which T-SUB is used immediately before T-PROJ. 2
A motivating intuition behind all of these transformations is that nothing is
harmed by moving most uses of subsumption as late as possible in a typing deriva-
tion, so that each subterm is given the smallest possible (or minimal) type at the
outset and this small type is maintained until a point is reached (in the application
rule) where a larger type is needed. This motivates the following definition:
13.2.7 Definition: The algorithmic typing relation is the least relation closed un-
der the following rules:
Algorithmic typing ! fg <:
Algorithmic typing (  `I t : T)
x:T 2  
  `I x : T
(TA-VAR)
 ; x:T1 `I t2 : T2
  `I x:T1.t2 : T1!T2 (TA-ABS)
  `I t1 : T1 T1 = T11!T12   `I t2 : T2 `I T2 <: T11
  `I t1 t2 : T12
(TA-APP)
January 15, 2000 13. SUBTYPING 95
for each i   `I ti : Ti
  `I {l1=t1...ln=tn} : {l1:T1...ln:Tn}
(TA-RCD)
  `I t : {l1:T1...ln:Tn}
  `I t.li : Ti
(TA-PROJ)
2
13.2.8 Exercise [Recommended]: Show, by example, that minimal types of terms
in this calculus can decrease during evaluation. Give a term t such that t  ! r
and R <: T but T 6<: R, where R is the minimal type of r and T is the minimal type
of t. 2
We now want to see formally that the algorithmic typing rules define the same
relation as the ordinary rules. We do this in two steps:
Soundness: Every typing statement that can be proved by an algorith-
mic derivation can also be proved by an ordinary derivation.
Completeness: Every typing statement that can be proved by an ordi-
nary derivation can almost be proved by an algorithmic derivation.
(In fact, the algorithmic derivation may yield a better type.)
13.2.9 Theorem [Soundness of the algorithmic typing relation]: If   `I t : T, then
  ` t : T. 2
Proof: By straightforward induction on algorithmic typing derivations. The de-
tails are left as an exercise. 2
The ordinary typing relation can be used to assign many types to a term, while
the algorithmic typing relation assigns at most one (this is easy to check). So a
straightforward converse of Theorem 13.2.9 is clearly not going to hold. Instead,
we can show that if a term t has a type T under the ordinary typing rules, then
it has a better type S under the algorithmic rules, in the sense that S <: T. In
other words, the algorithmic rules assign each typeable term its smallest possible
(“minimal”) type.
13.2.10 Theorem [Minimal Typing]: If   ` t : T, then   `I t : S for some S <: T. 2
Proof: Exercise (recommended). 2
13.2.11 Exercise: If we dropped the function subtyping rule S-ARROW but kept
the rest of the subtyping and typing rules the same, would we lose the minimal
typing property? If not, prove it. If so, give an example of a term that would have
two incomparable types. 2
January 15, 2000 13. SUBTYPING 96
13.2.12 Exercise [Recommended]: Add numbers and iteration to the algorithmic
typing relation. Prove that your algorithmic rules are sound and complete for the
declarative system. 2
The proof itself will be presented, of course — probably in the solutions chapter.
13.2.13 Exercise [Recommended]: Show how to extend the proof of preservation
for the simply typed lambda-calculus (7.4.11) to the system with subtyping. 2
13.3 Implementation
let rec subtype tyS tyT =
tyeqv tyS tyT ||
match (tyS,tyT) with
(TyArr(tyS1,tyS2),TyArr(tyT1,tyT2)) !
(subtype tyT1 tyS1) && (subtype tyS2 tyT2)
| (_,TyTop) !
true
| (TyRecord(fS), TyRecord(fT)) !
List.for_all
(fun (li,tyTi) !
try let tySi = List.assoc li fS in
subtype tySi tyTi
with Not_found ! false)
fT
| _ !
false
let rec typeof ctx t =
match t with
TmVar(fi,i,_) !
gettype fi ctx i
| TmAbs(fi,x,tyS,t1) !
let ctx' = addbinding ctx x (VarBind(tyS)) in
let tyT = typeof ctx' t1 in
TyArr(tyS, tyshift tyT (-1))
| TmApp(fi,t1,t2) !
let tyT1 = typeof ctx t1 in
let tyT2 = typeof ctx t2 in
(match tyT1 with
TyArr(tyT11,tyT12) !
if subtype tyT2 tyT11 then tyT12
else error fi "parameter type mismatch"
| _ ! error fi "arrow type expected")
January 15, 2000 13. SUBTYPING 97
| TmRecord(fi, fields) !
let fieldtys = List.map (fun (li,ti) ! (li, typeof ctx ti)) fields in
TyRecord(fieldtys)
| TmProj(fi, t1, l) !
(match (typeof ctx t1) with
TyRecord(fieldtys) !
(try List.assoc l fieldtys
with Not_found ! error fi ("label "^l^" not present"))
| _ ! error fi "Expected record type")
13.4 Meets and Joins
A type J is called a join of a pair of types S and T if
` S <: J
` T <: J
for all types U, if ` S <: U and ` T <: U then ` J <: U:
A given typed lambda-calculus is said to have joins if, for every S and T, there is
some J that is a join of S and T under  .
Similarly, a type M is called a meet of S and T if
` M <: S
` M <: T
for all types L, if ` L <: S and ` L <: T then ` L <: M:
A pair of types S and T is said to be bounded below if there is some type L such
that ` L <: S and ` L <: T. A typed lambda-calculus is said to have bounded
meets if, for every S and T such that S and T are bounded below, there is some M
that is a meet of S and T.
let rec join tyS tyT =
if subtype tyS tyT then tyT
else if subtype tyT tyS then tyS
else match (tyS,tyT) with
(TyRecord(f1), TyRecord(f2)) !
let rec loop = function
(_,[]) ! []
| ([],_) ! []
| ((l1,t1)::rest1,(l2,t2)::rest2) !
if l1 = l2 then
(l1,(join t1 t2))::(loop (rest1,rest2))
else []
in let f = loop (f1,f2)
January 15, 2000 13. SUBTYPING 98
in (match f with
(* when the first field names did not agree *)
[] ! TyTop
| _ ! TyRecord(f))
| (TyArr(tyS1,tyS2),TyArr(tyT1,tyT2)) !
(try TyArr(meet tyS1 tyT1, join tyS2 tyT2)
with Not_found ! TyTop)
| _ ! TyTop
and meet tyS tyT =
if subtype tyS tyT then tyS
else if subtype tyT tyS then tyT
else
match (tyS,tyT) with
(TyRecord(f1), TyRecord(f2)) !
let rec loop = function
(restf1,[]) ! restf1
| ([],restf2) ! restf2
| ((l1,t1)::rest1,(l2,t2)::rest2) !
if l1 = l2 then
(l1,(meet t1 t2))::(loop (rest1,rest2))
else raise Not_found
in let f = loop (f1,f2)
in TyRecord(f)
| (TyArr(tyS1,tyS2),TyArr(tyT1,tyT2)) !
TyArr(join tyS1 tyT1, meet tyS2 tyT2)
| _ ! raise Not_found
let rec typeof' ctx t =
match t with
...
| TmTrue(fi) !
TyBool
| TmFalse(fi) !
TyBool
| TmIf(fi,s1,s2,s3) !
if subtype (typeof ctx s1) TyBool then
join (typeof ctx s2) (typeof ctx s3)
else error fi "guard of conditional not a boolean"
and typeof ctx t =
if !debugtypeof then
Support.Debug.wrap "typeof"
(fun () ! typeof' ctx t)
(fun () ! prtm ctx t)
(fun tyT ! prty tyT)
else
January 15, 2000 13. SUBTYPING 99
typeof' ctx t
13.4.1 Exercise [Recommended]: Add booleans and conditionals to both the declar-
ative typing relation and the algorithmic typing relation. Prove that your algorith-
mic rules are sound and complete for the declarative system. 2
13.4.2 Exercise [Recommended]: The directory simpleplus in the course web site
contains an ML checker for the simply typed lambda-calculus with records, num-
bers, and booleans. Add subtyping (and a Top type) to this checker using the
algorithms described in this chapter. 2
13.5 Primitive Subtyping
13.6 The Bottom Type
13.7 Other stuff
Chapter 14
Imperative Objects
This chapter needs a little more writing, but my main annoyance with it is that the final
section (on “self”) requires lazy evaluation at the moment. There are some fairly deep
issues here (Didier and I have been discussing for years whether it is actually possible to
build a completely satisfactory object model by translation to lambda-calculus, and this is
one of the biggest reasons). I think the material is still valuable even so, but I’d love to find
a better way around this point.
Some of the examples in this chapter would look nicer if we added operations for record
extension and overriding (not polymorphic: just on ordinary records). The overriding
operation should, if possible, be consistent with the polymorphic record update operation.
In this chapter we come to our first substantial programming examples. We’ll
use the features we have defined – functions, records, effects, fixed points, refer-
ence cells, and subtyping – to give a straightforward model of objects and classes,
as they are found in object-oriented languages such as Smalltalk and Java. We be-
gin with very simple “stand-alone” objects and then proceed to define increasingly
powerful kinds of classes.
14.1 Objects
An object is a data structure encapsulating some internal state and offering access
to this state to clients via a collection of methods. The internal state is typically
broken up into a number of mutable instance variables (or fields) that are shared
among the definitions of the methods (and typically inaccessible to the rest of the
program). An object’s methods are invoked by the operation of message-sending.
Our running example for the chapter will be simple “storage cell” objects. Each
cell object will hold a single number and respond to three messages: get, which
causes it to return the number it currently has; set, which sets its internal state
100
January 15, 2000 14. IMPERATIVE OBJECTS 101
to some number given by the sender of the message; and inc, which causes it to
increment the number it is holding. (Except for the inc message, our cells are just
an object-oriented variation of the refs that we saw in Chapter 9.)
A very simple way of obtaining this behavior using the features we have stud-
ied so far is to use a reference cell for the object’s internal state and a record of
functions for the methods.
c =
let r = ref 0 in
{get = _:Unit. !r,
set = i:Nat. r:=i,
inc = _:Unit. r:=succ(!r)};
I c : {get:Unit!Nat, set:Nat!Unit, inc:Unit!Unit}
The fact that the state is shared by the methods and inaccessible to the rest of the
program arises directly from the lexical scope of the variable r. “Sending a mes-
sage” to the object c means just extracting some field of the record and applying it
to an appropriate argument. For example:
c.set 2;
c.inc unit;
c.get unit;
(c.set 2; c.inc unit; c.get unit);
I unit : Unit
unit : Unit
3 : Nat
3 : Nat
Note the use of the syntactic sugar for sequencing (cf. Section ??) in the last line.
We could equivalently (but less readably) have written
let x = c.set 2 in let y = c.inc unit in c.get unit;
or even (using the _ convention for “don’t care” variable names):
let _ = c.set 2 in let _ = c.inc unit in c.get unit;
We may want to create and manipulate a lot of counters, so it will be convenient
to use an abbreviation for their rather long record type:
Counter = {get:Unit!Nat, set:Nat!Unit, inc:Unit!Unit};
To force the typechecker to print the type of a new counter using the short form
Counter, we add an explicit coercion (recall from Section ?? that t as T means the
same as (x:T.x)t):
January 15, 2000 14. IMPERATIVE OBJECTS 102
c =
let r = ref 0 in
{get = _:Unit. !r,
set = i:Nat. r:=i,
inc = _:Unit. r:=succ(!r)}
as Counter;
I c : Counter
(This need to explicitly annotate terms to control the way their types are printed
is a little annoying. It is the price we pay for “unbundling” all the features of our
programming language into the simplest and most orthogonal possible units, so
that we can study them in isolation. A practical high-level programming language
design would probably combine many of these primitive features into more con-
venient macro-constructs.)
A typical piece of “client code” that manipulates counter objects might look
something like this:
inc3 = c:Counter. (c.inc unit; c.inc unit; c.inc unit);
I inc3 : Counter ! Unit
The function inc3 takes a counter object and increments it three times by sending
it three inc messages in succession.
(c.set 5; inc3 c; c.get unit);
I 8 : Nat
14.2 Object Generators
In the development that follows, it will be useful to be able to manipulate all the
instance variables of an object as a single unit. To support this, let us change the
internal representation of our counters to be a record of reference cells and use the
name of this record to refer to instance variables from the method body.
c =
let r = {x=ref 0} in
{get = _:Unit. !(r.x),
set = i:Nat. r.x:=i,
inc = _:Unit. r.x:=succ(!(r.x))}
as Counter;
I c : Counter
This representation makes it is easy, for example, to write a counter generator that
creates a new counter every time it is called.
January 15, 2000 14. IMPERATIVE OBJECTS 103
newCounter =
_:Unit.
(let r = {x=ref 0} in
{get = _:Unit. !(r.x),
set = i:Nat. r.x:=i,
inc = _:Unit. r.x:=succ(!(r.x))}
as Counter);
I newCounter : Unit ! Counter
14.3 Subtyping
One of the reasons for the popularity of object-oriented programming styles is that
they permit objects of many shapes to be manipulated by the same client code.
For example, suppose that, in addition to the Counter objects defined above,
we also create some cell objects with one more method that allows them to be reset
to their initial state (say, 0) at any time.
ResetCounter = {get:Unit!Nat,
set:Nat!Unit,
inc:Unit!Unit,
reset:Unit!Unit};
newResetCounter =
_:Unit.
let r = {x=ref 0} in
{get = _:Unit. !(r.x),
set = i:Nat. r.x:=i,
inc = _:Unit. r.x:=succ(!(r.x)),
reset = _:Unit. r.x:=0}
as ResetCounter;
I newResetCounter : Unit ! ResetCounter
Note that our old inc3 function on counters can safely use our refined counters
too:
rc = newResetCounter unit;
(inc3 rc; rc.reset unit; inc3 rc; rc.get unit);
I rc : ResetCounter
3 : Nat
January 15, 2000 14. IMPERATIVE OBJECTS 104
14.4 Basic classes
The definitions of newCounter and newResetCounter are identical except for the
body of the reset method. Of course, for such short definitions this makes little
difference, but if the method bodies were much longer we might quickly find our-
selves wanting to write the common ones in just one place. The mechanism by
which this is achieved in most object-oriented languages is called the class.
Here is one very simple way to define newResetCounter in terms of newCounter:
newResetCounter =
_:Unit.
(let c = newCounter unit in
{get = c.get,
set = c.set,
inc = c.inc,
reset = _:Unit. c.set 0}
as ResetCounter);
I newResetCounter : Unit ! ResetCounter
But this trick is not very robust. For example, if the type Counter had just get and
inc methods (no set), then we couldn’t write newResetCounter in this way.
A more general approach is to abstract the methods of a prototype counter
object over the instance variables. This is a simple example of a class.
CounterRep = {x: Ref Nat};
counterClass =
r:CounterRep.
({get = _:Unit. !(r.x),
set = i:Nat. r.x:=i,
inc = _:Unit. r.x:=succ(!(r.x))}
as Counter);
I counterClass : CounterRep ! Counter
Now we can build a class for ResetCounterby re-using the fields of counterClass:
resetCounterClass =
r:CounterRep.
let super = counterClass r in
({get = super.get,
set = super.set,
inc = super.inc,
reset = _:Unit. r.x:=0}
as ResetCounter);
I resetCounterClass : CounterRep ! ResetCounter
The definitions of newCounter and newResetCounterbecome trivial: we simply
allocate the instance variables and supply them to counterClassor resetCounterClass,
where the real work happens:
January 15, 2000 14. IMPERATIVE OBJECTS 105
newCounter =
_:Unit.
(let r = {x=ref 0} in
counterClass r)
as Counter;
newResetCounter =
_:Unit.
(let r = {x=ref 0} in
resetCounterClass r)
as ResetCounter;
I newCounter : Unit ! Counter
newResetCounter : Unit ! ResetCounter
14.5 Extending the Internal State
Suppose we want to define a class of BackupCounters whose reset method resets
their state to its value at the last call to a new method backup...
BackupCounter = {get:Unit!Nat,
set:Nat!Unit,
inc:Unit!Unit,
reset:Unit!Unit,
backup: Unit!Unit};
BackupCounterRep = {x: Ref Nat, b: Ref Nat};
Here is the class:
backupCounterClass =
r:BackupCounterRep.
({get = _:Unit. !(r.x),
set = i:Nat. r.x:=i,
inc = _:Unit. r.x:=succ(!(r.x)),
reset = _:Unit. r.x:=!(r.b),
backup = _:Unit. r.b:=!(r.x)}
as BackupCounter);
I backupCounterClass : BackupCounterRep ! BackupCounter
The interesting point is that we can actually define backupCounterClass in
terms of resetCounterClass. Note how subtyping is used in checking the defi-
nition of super. Also, note that we need to override the definition of the reset
method as well as adding backup.
backupCounterClass =
r:BackupCounterRep.
let super = resetCounterClass r in
({get = super.get,
January 15, 2000 14. IMPERATIVE OBJECTS 106
set = super.set,
inc = super.inc,
reset = _:Unit. r.x:=!(r.b),
backup = _:Unit. r.b:=!(r.x)}
as BackupCounter);
I backupCounterClass : BackupCounterRep ! BackupCounter
The variable super was used above to “copy functionality” from the superclass
into the new subclass.
The super variable can also be used inside method definitions to extend the
superclass’s behavior with something new. Suppose, for instance, that we want a
variant of our backupCounter class in which the inc method increments not only
the cell’s value but also the backed-up value in the instance variable b. (Goodness
knows why this behavior would be useful—it’s just an example!)
funnyBackupCounterClass =
r:BackupCounterRep.
let super = resetCounterClass r in
({get = super.get,
set = super.set,
inc = _:Unit.
(super.inc unit;
r.b := succ(!(r.b))),
reset = _:Unit. r.x:=!(r.b),
backup = _:Unit. r.b:=!(r.x)}
as BackupCounter);
I funnyBackupCounterClass : BackupCounterRep ! BackupCounter
Note how use of super.inc in the definition of inc avoids repeating the super-
class’s inc code here.
14.6 Classes with “Self”
Our final extension is allowing the methods of classes to refer to each other “re-
cursively.” For example, suppose that we want to implement the inc method of
simple counters in terms of the get and set methods. (Of course, all three methods
are so small in this example that all this code reuse is hardly worth the trouble!
For larger examples, though, it can make a substantial difference in code size and
maintainability.)
counterClass =
r:CounterRep.
fix
(self: Counter.
{get = _:Unit. !(r.x),
set = i:Nat. r.x:=i,
inc = _:Unit. self.set (succ(self.get unit))});
January 15, 2000 14. IMPERATIVE OBJECTS 107
I counterClass : CounterRep ! {get:Unit!Nat, set:Nat!Unit, inc:Unit!Unit}
Classes in mainstream object-oriented languages such as Smalltalk, C++, and
Java actually support a more general form of recursive call between methods,
sometimes known as open recursion. Instead of taking the fixed point within the
class, we wait until we use the class to actually create an object.
counterClass =
r:CounterRep.
self: Counter.
{get = _:Unit. !(r.x),
set = i:Nat. r.x:=i,
inc = _:Unit. self.set (succ(self.get unit))};
I counterClass : CounterRep !
Counter ! {get:Unit!Nat, set:Nat!Unit, inc:Unit!Unit}
newCounter =
_:Unit.
let r = {x=ref 0} in
fix (counterClass r);
I newCounter : Unit ! {get:Unit!Nat, set:Nat!Unit, inc:Unit!Unit}
What’s interesting about leaving the recursion open is that, when we build a
new class by subclassing counterClass, we can override the methods of counterClass
in such a way that recursive calls to these methods from within counterClass will
actually invoke the new method bodies that we provide. For example, here’s a
subclass that keeps track of how many times the get method has been called.
InstrumentedCounter = {get:Unit!Nat,
set:Nat!Unit,
inc:Unit!Unit,
accesses:Unit!Nat};
InstrumentedCounterRep = {x: Ref Nat, a: Ref Nat};
instrumentedCounterClass =
r:InstrumentedCounterRep.
self: InstrumentedCounter.
lazy let super = counterClass r self in
lazy
{get = _:Unit.
let result = super.get unit in
(r.a:=succ(!(r.a)); result),
set = super.set,
inc = super.inc,
accesses = _:Unit. !(r.a)}
as InstrumentedCounter;
I instrumentedCounterClass : InstrumentedCounterRep !
InstrumentedCounter ! InstrumentedCounter
January 15, 2000 14. IMPERATIVE OBJECTS 108
Notice that, because of the open recursion through self, the call to get from
within inc results in the a field being incremented, even though the increment-
ing behavior of get is defined in the subclass and the call to get appears in the
superclass.
14.6.1 Exercise: The two lazy annotations in newInstrumentedCounter are both
essential. Check what happens when either of them is omitted. 2
We create an instrumented counter in the same way as before—by taking a
fixed point of the class and providing it with some newly allocated instance vari-
ables.
newInstrumentedCounter =
_:Unit.
let r = {x = ref 0, a = ref 0} in
fix (instrumentedCounterClass r);
I newInstrumentedCounter : Unit ! InstrumentedCounter
Note how the accesses method counts calls to both get and inc:
ic = newInstrumentedCounter unit;
ic.get unit;
I 0 : Nat
ic.accesses unit;
I 1 : Nat
ic.inc unit;
I unit : Unit
ic.get unit;
I 1 : Nat
ic.accesses unit;
I 3 : Nat
14.6.2 Exercise [Recommended]: Use the fullsubeff checker from the course di-
rectory to implement the following extensions to the classes above:
1. Change the definition of instrumentedCounterClass so that it also counts
calls to set.
2. Extend your modified instrumentedCounterClasswith a subclass that adds
a reset method (as in Section 14.3).
3. Extend this subclass with yet another subclass that supports backups as well
(as in Section 14.5). 2
Chapter 15
Recursive Types
the type IntList is an infinite tree
so let’s just allow types to be infinite; use the  notation as a shorthand for
infinite trees
(Of course, the typechecker can’t actually manipulate infinite trees; later in the
chapter we will see two different ways of dealing with  types more realistically)
15.1 Examples
Lists
Hungry Functions
As another simple illustration of the use of recursive types, here is a type of func-
tions that can accept any number of numeric arguments:
Hungry = A. Nat ! A;
An element of this type can be defined using the least fixed point operator on
values:
f =
fix
(f: Nat!Hungry.
n:Nat.
f);
I f : Nat ! Nat ! Hungry
f 0 1 2 3 4 5;
I (n:Nat. fix f':Nat!Hungry. n':Nat.f') : A. Nat ! A
109
January 15, 2000 15. RECURSIVE TYPES 110
Recursive Values from Recursive Types
A more challenging example—and one that reveals some of the power of the ex-
tension we are making—uses recursive types to write down a well-typed version
of the least-fixed-point combinator:
fixpointT =
f:T!T.
(x:(A.A!T). f (x x))
(x:(A.A!T). f (x x));
I fixpointT : (T!T) ! T
Untyped Lambda-Calculus, Redux
Perhaps the best illustration of the power of recursive types is the observation
that it is possible to embed the whole untyped lambda-calculus (in a well-typed
way!) into a statically typed calculus with recursive types. Let D be the following
universal type:
D = X. X!X;
(Note that the form of D’s definition is reminiscent of the defining properties of
“universal domains” in denotational semantics.) Now define an “injection func-
tion” lam mapping functions from D to D into elements of D as follows:
lam = f:D!D. f;
I lam : (D!D) ! D ! D
ap = f:D. a:D. f a;
I ap : D ! D ! (X. X ! X)
Now, suppose M is a closed pure lambda-term involving just variables, abstrac-
tions, and applications. Then we can construct an element of D representing M,
written M?, in a uniform way as follows:
x? = x
(x.M)? = lam (x:D. M?)
(M N)? = ap M? N?
For example, here is how the untyped fixed point combinator is expressed as an
element of D:
fixD = lam (f:D.
ap (lam (x:D. ap f (ap x x)))
(lam (x:D. ap f (ap x x))));
I fixD : D ! D
January 15, 2000 15. RECURSIVE TYPES 111
15.1.1 Exercise: Note that the term defining fixpoint contains many redices. Use
the reduction rules (C-UNFOLDFOLD plus the usual -reduction rule) to find its
normal form. What is the type-erasure of this normal form? 2
We can go even further, if we work in a language with variants as in Section 8.5.
Then we can extend the datatype of pure lambda-terms to include numbers like
this:
D = X. <nat:Nat, fn:X!X>;
That is, an element of D is either a number or a function from D to D, tagged nat
or fn, repectively. It will also be convenient to have an abbreviation for the “once-
unrolled” body of D:
DBody = <nat:Nat, fn:D!D>;
The implementation of the lam constructor is essentially the same as before:
lam = f:D!D.
<fn=f> as DBody;
I lam : (D!D) ! DBody
The implementation of ap, though, is different in an interesting way:
ap =
f:D. a:D.
case f of
nat=n ) divergeD unit
| fn=f ) f a;
I ap : D ! D ! D
Notice how closely the tag-checking going on here resembles the run-time tag
checking inside an implementation of a strongly-but-latently typed language such
as Scheme [?]. In this sense, typed computation may be said to “include” untyped
or dynamically typed computation. Similar tag checking is needed in order to de-
fine the successor function on elements of D:
suc =
f:D.
case f of
nat=n ) (<nat=succ n> as DBody)
| fn=f ) divergeD unit;
The injection of 0 into D is trivial:
zro = <nat=0> as DBody;
I suc : D ! DBody
zro : DBody
January 15, 2000 15. RECURSIVE TYPES 112
15.1.2 Exercise: Use the untyped fixed point combinator that we saw above to de-
fine an untyped factorial function on D. 2
15.1.3 Exercise [Recommended]: Using the fullrec checker from the course web
directory, extend the datatype D to include untyped records
D = X. <nat:Nat, fn:X!X, rcd:Nat!X>;
and implement record construction and field projection. For simplicity, use natu-
ral numbers as field labels—i.e., records are represented as functions from natural
numbers to elements of D. (N.b.: this exercise has nothing to do with hungry func-
tions!) 2
Recursive Objects
Counter = P. {get:Nat, inc:Unit!P};
p =
let create =
fix
(cr: {x:Nat}!Counter.
s: {x:Nat}.
{get = s.x,
inc = _:Unit. cr {x=succ(s.x)}})
in
create {x=0};
I p : {get:Nat, inc:Unit!Counter}
p1 = p.inc unit;
p1.get;
I p1 : Counter
1 : Nat
15.2 Equi-recursive Types
note that we cannot obtain all infinite trees by writing finite expressions using ,
just the regular ones.
Prove this by writing a function that expands a  type into its regular tree form,
and showing that this function is not surjective (maybe the latter is an exercise).
introduce the idea of contractive types
 use the equivalence relation (should introduce it previously) to capture the
intuition that a recursive type is “the same as” its unfolding
January 15, 2000 15. RECURSIVE TYPES 113
 but this doesn’t give us enough equivalences. For example X.T!T!X and
T!(X.T!T!X) are equal as trees but inequivalent.
 So we switch to a coinductive view of equivalence.
 now equivalence coincides with equality of infinite tree expansions (prove
it!)
 Now we need to decide this coinductive equivalence
– show simulation algorithm (and its ML realization)
– prove that it is sound, complete, and terminating
notice that we need to deal with more than just type equivalence: we also need
to provide an expose function that unrolls recursive types as needed during typ-
ing. What needs to be proved about this?
Algorithmic rules for equi-recursive types ! B 
Algorithmic type equivalence (   `I S  T)
(S  T) 2 P
P `I S  T
(QA-LOOP)
P ; (X.S1  T) `I fX 7! X.S1gS1  T
P `I X.S1  T
(QA-RECL)
P ; (S  X.T1) `I S  fX 7! X.T1gT1
P `I S  X.T1
(QA-RECR)
P `I B  B (QA-BASE)
P `I S1  T1 P `I S2  T2
P `I S1!S2  T1!T2 (QA-ARROW)
Exposure (   `I T * T 0)
`I fX 7! X.T1gT1 * T 0
`I X.T1 * T 0 (XA-REC)
T is not a recursive type
`I T * T (XA-OTHER)
Algorithmic typing (  `I t : T)
x:T 2  
  `I x : T
(TA-VAR)
January 15, 2000 15. RECURSIVE TYPES 114
 ; x:T1 `I t2 : T2
  `I x:T1.t2 : T1!T2 (TA-ABS)
  `I t1 : T1 `I T1 * T11!T12   `I t2 : T2 `I T2  T11
  `I t1 t2 : T12
(TA-APP)
ML Implementation
Datatypes
type ty =
TyArr of ty * ty
| TyId of string
| TyVar of int * int
| TyRec of string * ty
type term =
TmVar of info * int * int
| TmAbs of info * string * ty * term
| TmApp of info * term * term
Type substitution
Type equivalence
let rec tyeqv pairs ctx tyS tyT =
List.mem (tyS,tyT) pairs
|| match (tyS,tyT) with
(TyArr(tyS1,tyS2),TyArr(tyT1,tyT2)) !
(tyeqv pairs ctx tyS1 tyT1) && (tyeqv pairs ctx tyS2 tyT2)
| (TyId(b1),TyId(b2)) ! b1=b2
| (TyVar(i,_),TyVar(j,_)) ! i=j
| (TyRec(x,tyS1),_) !
tyeqv ((tyS,tyT)::pairs) ctx (tysubstsnip tyS tyS1) tyT
| (_,TyRec(x,tyT1)) !
tyeqv ((tyS,tyT)::pairs) ctx tyS (tysubstsnip tyT tyT1)
| _ ! false
let tyeqv ctx tyS tyT =
tyeqv [] ctx tyS tyT
January 15, 2000 15. RECURSIVE TYPES 115
Typing
let rec typeof ctx t =
match t with
TmVar(fi,i,_) !
gettype fi ctx i
| TmAbs(fi,x,tyS,t1) !
let ctx' = addbinding ctx x (VarBind(tyS)) in
let tyT = typeof ctx' t1 in
TyArr(tyS, tyshift tyT (-1))
| TmApp(fi,t1,t2) !
let tyT1 = typeof ctx t1 in
let tyT2 = typeof ctx t2 in
(match tyT1 with
TyArr(tyT11,tyT12) !
if tyeqv ctx tyT2 tyT11 then tyT12
else error fi "parameter type mismatch"
| _ ! error fi "arrow type expected")
15.3 Iso-recursive Types
A different, and even simpler, way of dealing with recursive types is to “make the
isomorphism explicit”...
 : Iso-recursive types ! B 
New syntactic forms
t ::= ... (terms...)
fold [T] t folding
unfold [T] t unfolding
v ::= ... (values...)
fold [T] v folding
T ::= ... (types...)
X type variable
X.T recursive type
  ::= ... (contexts...)
 ; X type variable binding
New evaluation rules (t  ! t 0)
January 15, 2000 15. RECURSIVE TYPES 116
unfold [S] (fold [T] v1)  ! v1 (E-FOLDBETA)
t1  ! t 01
fold [T] t1  ! fold [T] t 01 (E-FOLD)
t1  ! t 01
unfold [T] t1  ! unfold [T] t 01 (E-UNFOLD)
New typing rules (  ` t : T)
U = X.T1   ` t1 : fX 7! UgT1
  ` fold [U] t1 : U
(T-FOLD)
U = X.T1   ` t1 : U
  ` unfold [U] t1 : fX 7! UgT1 (T-UNFOLD)
15.3.1 Exercise: Re-do the examples in Section 15.1 using the Using the fullisorec
checker from the course web directory. (Solution on page 260.) 2
Prove: preservation and progress
Nice exercise: observe that we can just erase folds and unfolds from a well-
typed program to obtain a well-typed program in the equi-recursive system. This
tells us that any well typed iso-recursive program is “meaningful.” Does this con-
stitute “soundness”? (Answer: no, it doesn’t tell us that the fold and unfold typing
rules were done properly.)
15.4 Subtyping and Recursive Types
Chapter 16
Case Study: Featherweight Java
This chapter will draw some connections between the material that’s been presented so far
and the mainstream world of object-oriented type systems, focusing on Java. The pedagog-
ical vehicle will be the Featherweight Java language studied by Atsushi Igarashi, Phil
Wadler, and myself [IPW99]. It is a very simple core calculus, not much larger than the
lambda-calculus, omitting nearly all of the features of the full Java language (including
assignment!), while retaining its basic flavor: classes, objects, methods, fields, (explicitly
declared) subtyping, casts, etc. The presentation here will be based closely on (the full
version of) the OOPSLA paper on FJ.
The main technical work to be done lies in tying FJ as explicitly as possible with the
concepts we have already seen. This is not all that simple, since we’ve been working in
an entirely “structural” setting, where the only salient thing about a type expression is its
structure (i.e., there are no “type names” except as simple abbreviations for structures),
while Java uses names throughout its type system. A section re-formulating the simply
typed lambda-calculus with subtyping in “by-name form” should provide a helpful bridge.
Sections:
 By-name vs. structural presentations of type systems (note a big advantage of struc-
tural presentations: portability! If you’re going to transmit code across the network,
then what do the names mean??)
 A by-name presentation of the simply typed lambda-calculus with subtyping
(Comments about Pascal vs. M3 treatments of “branding”.)
 Summary of Featherweight Java
117
Chapter 17
Type Reconstruction
For technical reasons, this chapter uses a slightly different definition of substitution from
what we had before. This should be changed to correspond exactly to the earlier notion.
Aside from that, it’s essentially finished.
The present chapter does not mention let-polymorphism. I think that’s a shame and I’ve
tried to figure out how to put in something about it, but it’s apparently quite hard to do it
in a rigorous way without going on for page after page of technicalities.
Given an explicitly typed term in the simply typed lambda-calculus, we have
seen an algorithm for determining its type, if it has one. In this chapter, we develop
a more powerful type reconstruction algorithm, capable of calculating a principal
type for a term in which some of the explicit type annotations are replaced by
variables. Similar algorithms lie at the heart of languages like ML and Haskell.
The term “type inference” is often used instead of “type reconstruction.”
17.1 Substitution
We will work in this chapter with the system !NX, the simply typed lambda
calculus with numbers and an infinite collection of atomic types. When we saw
them in Section 8.1, these atomic types were completely uninterpreted. Now we
are going to think of them as type variables—i.e., placeholders standing for other
types. In order to make this idea precise, we need to define what it means to
substitute arbitrary types for type variables.
17.1.1 Definition: A type substitution (or, for purposes of this chapter, just sub-
stitution) is a finite function from type variables to types. For example, we write
fX 7! T; Y 7! Ug for the substitution that maps X to T and Y to U and is undefined on
other arguments.
118
January 15, 2000 17. TYPE RECONSTRUCTION 119
We can regard a substitution  as a function from types to types in an obvious
way:
X =

T if  maps X to T
X if X is not in the domain of 
(Nat) = Nat
(T1!T2) = T1 ! T2
Note that we do not need to make any special provisions to avoid variable capture
during type substitution, because there are no binders for type variables. (This will
change when we discuss System F in Chapter 18; we will then have to treat type
substitutions more carefully.)
Substitution is extended to contexts by defining ( )(x) to be ( (x)). Similarly,
a type substitution is applied to a term t by applying it to all types appearing in t.
If  and  are type substitutions, we write Æ for the type substitution formed
by composing  and  as follows:
( Æ )(X) =
8<
:
((X)) if X 2 dom()
(X) if X =2 dom() and X 2 dom()
undefined if X =2 dom() [ dom():
Note that ( Æ )T = (T). 2
A crucial property of type substitutions is that they preserve the validity of
typing statements: if a term involving variables is well typed, then so are all of its
substitution instances.
17.1.2 Theorem [Preservation of typing under substitution]: If   ` t : T and  is
any type substitution, then   ` t : T. 2
Proof: Straightforward induction on typing derivations. 2
17.2 Universal vs. Existential Type Variables
Suppose that t is a term containing type variables and   is an associated envi-
ronment (possibly also containing type variables). There are two quite different
questions that we can ask about t:
1. “Are all substitution instances of t well typed?” That is, is it the case that, for
every , we have   ` t : T for some T?
2. “Is some substitution instance of t well typed?” That is, can we find a  such
that   ` t : T for some T?
According to the first view, type variables should be held abstract during typecheck-
ing, thus ensuring that a well-typed term will behave properly no matter what
concrete types are later substituted for its type variables. For example, the term
January 15, 2000 17. TYPE RECONSTRUCTION 120
f:X!X. a:X. f (f a);
has type (X!X)!X!X, and, whenever we replace X by T, the instance
f:T!T. a:T. f (f a);
is well typed. Holding type variables abstract in this way leads to the idea of
parametric polymorphism, in which type variables are used to encode the fact
that a term can be used in many concrete contexts with different concrete types.
We shall return to parametric polymorphism in more depth in Chapter 18.
In the second view, the original term t may not even be well typed; what we
want to know is whether it can be instantiated to a well typed term by choosing
appropriate values for some of its type variables. For example, the term
f:Y. a:X. f (f a);
is not typeable as it stands, but if we replace Y by Nat!Nat and X by Nat, we obtain
f:Nat!Nat. a:Nat. f (f a);
of type (Nat!Nat)!Nat!Nat. Or, if we simply replace Y by X!X, we obtain the
term
f:X!X. a:X. f (f a);
which is well typed even though it contains variables. Indeed, this term is a most
general instance of f:Y. a:X. f (f a), in the sense that it makes the least com-
mitment about the values of type variables that is required to obtain a well-typed
term.
We may even, in the limit, allow type annotations to be omitted completely, fill-
ing in a fresh type variable during parsing whenever an annotation is discovered
to be missing. This allows the term above to be written
f. a. f (f a);
as in languages like ML.
Looking for valid instantiations of type variables leads to the idea of type re-
construction, in which the compiler is asked to help fill in type information that
has been underspecified by the programmer. We develop this point of view in the
rest of the chapter.
17.2.1 Definition: Let   be a context and t a term. A typing for ( ; t) is a pair (; T)
such that   ` t : T. 2
17.2.2 Example: Let   = f:X; a:Y and t = f a. Then
(fX 7! Y!Natg; Nat)
(fX 7! Y!Z; Z 7! Natg; Z)
(fX 7! Y!Nat!Natg; Nat!Nat)
(fX 7! Y!Zg; Z)
are all typings for ( ; t). 2
January 15, 2000 17. TYPE RECONSTRUCTION 121
17.2.3 Exercise [Quick check]: Find three different typings for
x:X. y:Y. z:Z. (x z) (y z):
with respect to the empty context. 2
17.3 Constraint-Based Typing
We now give a different presentation of the typing relation in which, for example,
instead of checking directly whether types of arguments match domains of func-
tions, we generate a set of constraints C recording the fact that this check should
be performed later.
17.3.1 Definition: A constraint set C is a set of equations fSi = Ti i21::ng. A substi-
tution  is said to satisfy the constraint setC if, for each i, the substitution instances
Si and Ti are equal. 2
17.3.2 Definition: The constraint typing relation   ` t : T jX C is defined by the
rules below. Informally,   ` t : T jX C can be read as “Term t has type T under as-
sumptions   whenever constraints C are satisfied.” The subscript X , which tracks
the type variables introduced in the process, is used for internal bookkeeping—to
make sure that the fresh type variables used in different subderivations are actu-
ally distinct.
x:T 2  
  ` x : T j; fg
(CT-VAR)
 ; x:S ` t1 : T jX C x 62 dom( )
  ` x:S.t1 : S!T jX C (CT-ABS)
  ` t1 : T1 jX1 C1   ` t2 : T2 jX2 C2
X1 \ X2 = ; X not mentioned in X1, X2, T1, T2, C1, C2,  , t1, or t2
  ` t1 t2 : X jX1[X2[fXg C1 [ C2 [ fT1 = T2!Xg (CT-APP)
  ` 0 : Nat j; fg (CT-ZERO)
  ` t1 : T jX C
  ` succ t1 : Nat jX C [ fT = Natg
(CT-SUCC)
  ` t1 : T1 jX1 C1   ` t2 : T2 jX2 C2   ` t3 : T3 jX3 C3
X1; X2; X3 nonoverlapping
C 0 = C1 [ C2 [ C3 [ fT1 = Nat; T2 = T3!T3g
  ` iter T t1 t2 t3 : T3 jX1[X2[X3 C
0
(CT-ITER)
As usual, these rules (when read from bottom to top) determine a straightforward
procedure that, given   and t, calculates T and C (and X ) such that   ` t : T jX C.
January 15, 2000 17. TYPE RECONSTRUCTION 122
However, unlike the original typing algorithm, this one never fails, in the sense
that for every   and t there are always some T and C such that   ` t : T j C,
and moreover that T and C are uniquely determined by   and t, up to the choice of
names of fresh type variables in X . (The nondeterminism arising from the freedom
to choose different fresh type variable names will be addressed in Exercise 17.3.9.)
To lighten the notation in the following discussion, we usually elide the X and
write just   ` t : T j C. 2
17.3.3 Exercise [Quick check]: Construct a constraint typing derivation whose con-
clusion is
` x:X. y:Y. z:Z. (x z) (y z) : S j C
for some S and C. 2
17.3.4 Definition: Suppose that   ` t : S j C. A typing for ( ; t; S; C) is a pair
(; T) such that  satisfies C and S = T. 2
Given a context   and a term t, we now have two different ways of calculating
sets of typings for   and t:
1. directly, via Definition 17.2.1; or
2. via the constraint typing relation, by finding S and C such that   ` t : S j C
and then using Definition 17.3.4 to identify the set of typings for ( ; t; S; C).
Our next job is to show that these two methods yield essentially the same sets of
typings. We do this in two steps. First we show that every ( ; t; S; C)-typing is a
( ; t)-typing [soundness]. Then we show that every ( ; t)-typing can be extended
to a ( ; t; S; C)-typing [completeness].
17.3.5 Theorem [Soundness of constraint typing]: Suppose that   ` t : S j C. If
(; T) is a typing for ( ; t; S; C), then it is also a typing for ( ; t). 2
Proof: By induction on the given constraint typing derivation for   ` t : S j C,
reasoning by cases on the last rule used.
Case CT-VAR: t = x
x:S 2  
C = fg
The result is immediate, since by T-VAR   ` x : ( )(x) for any .
Case CT-ABS: t = x:T1.t1
S = T1!S2
 ; x:T1 ` t1 : S2 j C
By the induction hypothesis, (; S2) is a typing for (( ; x:T1); t1), i.e.,
 ; x:T1 ` t1 : S2:
By T-ABS,   ` x:T1.t1 : T1!S2 = (T1!S2) = T, as required.
January 15, 2000 17. TYPE RECONSTRUCTION 123
Case CT-APP: t = t1 t2
S = X
  ` t1 : S1 j C1
  ` t2 : S2 j C2
C = C1 [ C2 [ fS1 = S2!Xg
By the definition of satisfaction,  satisfies both C1 and C2 and S1 = (S2!X).
By Definition 17.3.4, we see that (; S1) and (; S2) are typings for ( ; t1; S1; C1)
and ( ; t2; S2; C2), from which the induction hypothesis gives us   ` t1 : S1
and   ` t2 : S2. But since S1 = S2!X, we then have   ` t1 : S2!X,
and, by T-APP,   ` (t1 t2) : X = T, as required.
Other cases:
Left as an exercise. 2
17.3.6 Definition: Write nX for the substitution that is undefined for all the vari-
ables in X and otherwise behaves like . 2
17.3.7 Theorem [Completeness of constraint typing]: Suppose   ` t : S jX C. If
(; T) is a typing for ( ; t) and dom() \X = ;, then there is some typing ( 0; T) for
( ; t; S; C) such that  0nX = . 2
Proof: By induction on the given constraint typing derivation.
Case CT-VAR: t = x
x:S 2  
From the assumption that (; T) is a typing for ( ; x), the inversion lemma for the
typing relation (7.4.1) tells us that T is ( )(x). But then (; T) is also a ( ; x; S; fg)-
typing.
Case CT-ABS: t = x:T1.t1
 ; x:T1 ` t1 : S2 jX C
S = T1!S2
From the assumption that (; T) is a typing for ( ; x:T1.t1), the inversion lemma
for the typing relation yields  ; x:T1 ` t1 : T2 and T = T1!T2.
By the induction hypothesis, there is a typing (0; T2) for (( ;x:T1); t1; S2; C)
such that  0nX agrees with . But then  0(S) =  0(T1!S2) = T1! 0S2 =
T1!T2 = T, so ( 0; T) is a typing for ( ; (x:T1.t1); T1!S2; C).
Case CT-APP: t = t1 t2
  ` t1 : S1 jX1 C1
  ` t2 : S2 jX2 C2
X1 \ X2 = ; and X not mentioned in X1, X2, S1, S2, C1, C2
S = X
X = X1 [ X2 [ fXg
C = C1 [ C2 [ fS1 = S2!Xg
January 15, 2000 17. TYPE RECONSTRUCTION 124
From the assumption that (; T) is a typing for ( ; t1 t2), the inversion lemma for
the typing relation yields   ` t1 : T1!T and   ` t2 : T1.
By the induction hypothesis, there are typings (1; T1!T) for ( ; t1; S1; C1) and
(2; T1) for ( ; t2; S2; C2), and 1nX and 2nX agree with . We must exhibit a
substitution  0 such that: (1)  0nX agrees with , (2)  0X = T, and (3)  0 satisfies
fS1 = S2!Xg, i.e.,  0S1 =  0S2! 0X. Define  0 as follows:
 0Y = Y if Y =2 X
 0Y = 1Y if Y 2 X1
 0Y = 2Y if Y 2 X2
 0Y = T if Y = X.
Conditions (1) and (2) are obviously satisfied. To check (3), calculate as follows:
 0S1 = 1S1 = T1!T = 2S2!T =  0S2! 0X =  0(S2!X).
Other cases:
Left as an exercise. 2
17.3.8 Corollary: Suppose   ` t : S j C. There is some typing for ( ; t) iff there is
some typing for ( ; t; S; C). 2
Proof: By Theorems 17.3.5 and 17.3.7. 2
17.3.9 Exercise [Recommended]: Because we have not described how the choice
of fresh variable names actually occurs (beyond stipulating that they must be “fresh
enough”), the constraint generation algorithm that we have been working with is
actually nondeterministic. Fortunately, this nondeterminism is inessential and eas-
ily eliminated.
In a production compiler, the nondeterministic choice of a fresh type variable
name in the rule CT-APP might be replaced by a call to a function that generates
a new type variable—different from all others that it ever generates, and from all
type variables mentioned explicitly in the context or term being checked—each
time it is called. Because this global “gensym” operation works by side effects on a
hidden global variable, it is difficult to reason about it formally. However, we can
easily simulate it by “threading” a sequence of unused variable names through the
constraint generation rules.
Let F denote a sequence of fresh type variable names (with each element of the
sequence different from every other). Then, instead of writing
  ` t : T jX C
for the constraint generation judgement, we write
  `F t : T jF 0 C;
where  , F, and t are inputs to the algorithm and T, F 0, and C are outputs. When-
ever it needs a fresh type variable, the algorithm takes off the front element of F
and returns the rest of F as F 0.
January 15, 2000 17. TYPE RECONSTRUCTION 125
Write out the rules for this algorithm in detail. Prove that they are equivalent,
in an appropriate sense, to the original constraint generation rules. (Solution on
page 256.) 2
17.3.10 Exercise [Recommended]: Implement the algorithm discussed in Exercise 17.3.9
in ML. Use the datatype
type ty =
TyArr of ty * ty
| TyId of string
| TyBool
| TyNat
for types, and
type constr = (ty * ty) list
for constraint sets. You will also need a representation for infinite sequences of
fresh variable names. There are lots of ways of doing this; here is a fairly direct one
using a recursive datatype:
type nextuvar = NextUVar of string * uvargenerator
and uvargenerator = unit ! nextuvar
let uvargen =
let rec f n () = NextUVar("?X_" ^ string_of_int n, f (n+1))
in f 0
That is, uvargen is a function that, when called with argument (), returns a value
of the form NextUVar(x,f), where x is a fresh type variable name and f is another
function of the same form. (Solution on page 257.) 2
17.4 Unification
We have given two different characterizations of the set of typings for a given term
in a given context. But we have not addressed the algorithmic problem of deciding
whether or not this set is empty—i.e., of deciding whether it is possible to replace
type variables by types so as to make the term typeable in the ordinary sense. The
key insight that we need, due to Hindley [?] and Milner [?], is that, if the set of
typings of a term is nonempty, it always contains a “best” element, in the sense
that the rest of the typings can be generated straightforwardly from this one.
To show that such principal typings exist (and, in fact, to give an algorithm for
generating them), we rely on the familiar operation of unification [?] on constraint
sets.
January 15, 2000 17. TYPE RECONSTRUCTION 126
17.4.1 Definition: A substitution  is said to unify two types S and T if S = T.
So saying that “ satisfies the constraint set C” is the same as saying “ unifies Si
and Ti for every equation Si = Ti in C.” We sometimes speak of  as a unifier for
C. 2
17.4.2 Definition: We say that a substitution  is more general than a substitution
 0, written  v  0, if  0 =  Æ  for some substitution . 2
17.4.3 Definition: A principal unifier for a constraint set C is a substitution  that
satisfies C and such that  v  0 for every substitution  0 that also satisfies C. 2
17.4.4 Exercise [Quick check]: Write down principal unifiers (when they exist) for
the following sets of constraints:
fX = Nat; Y = X!Xg
fNat!Nat = X!Yg
fX!Y = Y!Z; Z = U!Wg
fNat = Nat!Yg
fY = Nat!Yg
fg (the empty set of constraints)
(Solution on page 258.) 2
17.4.5 Definition: The unification algorithm is defined as follows:
unify(C) = if C = ;, then f g
else let fS = Tg [ C 0 = C in
if S = T
then unify(C 0)
else if S = X and X =2 FV(T)
then unify(fX 7! TgC 0) Æ fX 7! Tg
else if T = X and X =2 FV(S)
then unify(fX 7! SgC 0) Æ fX 7! Sg
else if S = S1!S2 and T = T1!T2
then unify(C 0 [ fS1 = T1; S2 = T2g)
else
fail
where C is the constraint set formed by applying  to both sides of all the con-
straints in C. 2
17.4.6 Theorem: The algorithm unify always terminates, fails only when given a
non-unifiable constraint set as input, and otherwise returns a principal unifier.
More formally:
1. unify(C) halts, either by failing or by returning a substitution, for all C;
January 15, 2000 17. TYPE RECONSTRUCTION 127
2. if unify(C) = , then  is a unifier for C;
3. if Æ is a unifier for C, then unify(C) =  with  v Æ. 2
Proof: For part (1), define the degree of a constraint set C to be the pair (m;n),
where m is the number of distinct type variables in C and n is the total size of
the types in C. It is easy to check that each clause of the unify algorithm either
terminates immediately (with success in the first case or failure in the last) or else
makes a recursive call to unify with a constraint set of smaller degree.
Part (2) is a straightforward induction on the number of recursive calls in the
computation of unify(C). All the cases are trivial except for the two involving vari-
ables, which depend on the observation that, if  unifies fX 7! TgC 0, then ÆfX 7! Tg
unifies fX = Tg [ C 0.
Part (3) again proceeds by induction on the number of recursive calls in the
computation of unify(C). If C is empty, then unify(C) immediately returns f g; since
Æ = Æ Æ f g, we have f g v Æ as required. If C is non-empty, then unify(C) chooses
some pair (S; T) from C and continues by cases on the shapes of S and T.
Case: S = T
Since Æ is a unifier for C, it also unifies C 0. By the induction hypothesis, unify(C) =
 with  v Æ, as required.
Case: S = X and X =2 T
Since Æ unifies S and T, we have Æ(X) = Æ(T). So, for any type U, we have Æ(U) =
Æ(fX 7! TgU); in particular, since Æ satisfies C 0 it must also satisfy fX 7! TgC 0. The
induction hypothesis then tells us that unify(fX 7! TgC0) =  0, with Æ =  Æ  0
for some . Since unify(C) =  0 Æ fX 7! Tg, showing that Æ =  Æ ( 0 Æ fX 7! Tg)
will complete the argument. Choose any type variable Y. If Y 6= X, then clearly
( Æ ( 0 Æ fX 7! Tg))Y = ( Æ  0)Y = ÆY. On the other hand, ( Æ ( 0 Æ fX 7! Tg))X =
( Æ  0)T = ÆX, as we saw above. Combining these observations, we see that ÆY =
( Æ ( 0 Æ fX 7! Tg))Y for all variables Y, i.e. Æ = ( Æ ( 0 Æ fX 7! Tg)).
Case: T = X and X =2 S
Similar.
Case: S = S1!S2 and T = T1!T2
Straightforward. Just note that Æ is a unifier of fS1!S2 = T1!T2g [ C 0 iff it is a
unifier of C 0 [ fS1 = T1; S2 = T2g.
If none of the above cases apply to S and T, then unify(C) fails. But this can
only happen in two ways: either S is Nat and T is an arrow type (or vice versa),
or else S = X and X 2 T (or vice versa). The first case obviously contradicts the
assumption that C is unifiable. To see that the second does too, recall that, by
assumption, ÆS = ÆT; if X occurred in T, then ÆT would always be strictly larger
than ÆS. Thus, unify(C) never fails when C is satisfiable. 2
17.4.7 Exercise [Recommended]: Implement the unification algorithm in ML.
January 15, 2000 17. TYPE RECONSTRUCTION 128
The main data structure needed for this exercise is a representation of substitu-
tions. There are many alternatives; one simple one is to reuse the constr datatype
from Exercise 17.3.10: a substitution is just a constraint set, all of whose left-hand
sides are unification variables. If substinty is a function that performs substitu-
tion of a type for a single type variable
let substinty tyX tyT tyS =
let rec o = function
TyArr(tyT1,tyT2) ! TyArr(o tyT1, o tyT2)
| TyNat ! TyNat
| TyBool ! TyBool
| TyId(s) ! if s=tyX then tyT else TyId(s)
in o tyS
then application of a whole substitution to a type can be defined as follows:
let applysubst constr tyT =
List.fold_left
(fun tyS (TyId(tyX),tyC2) ! substinty tyX tyC2 tyS)
tyT constr
(Solution on page 258.) 2
17.5 Principal Typings
17.5.1 Definition: A principal typing for ( ; t; S; C) is a typing (; T) such that,
whenever ( 0; T 0) is also a typing for ( ; t; S; C), we have  v  0. 2
17.5.2 Exercise [Quick check]: Find a principal typing for
x:X. y:Y. z:Z. (x z) (y z): 2
17.5.3 Theorem [Principal typing]: If ( ; t; S; C) has any typing, then it has a prin-
cipal one. Moreover, the unification algorithm can be used to determine whether
( ; t; S; C) has a typing and, if so, to return a principal one. 2
Proof: Immediate from the definition of typing and the properties of unification. 2
17.5.4 Corollary: It is decidable whether ( ;t) has a typing. 2
Proof: By Corollary 17.3.8 and Theorem 17.5.3. 2
17.5.5 Exercise [Recommended]: Use the implementations of constraint genera-
tion (Exercise 17.3.10) and unification (Exercise 17.4.7) to construct a running type-
checker that calculates principal typings, using the simple checker provided in the
course directory as a starting point. 2
January 15, 2000 17. TYPE RECONSTRUCTION 129
17.5.6 Exercise: What difficulties arise in extending the basic definitions (17.3.2,
etc.) to deal with records? How might they be addressed? (Solution on page 259.)
2
Principal typings can be used to build a type reconstruction algorithm that
works more incrementally than the one we have developed here. Instead of gen-
erating all the constraints first and then trying to solve them, we can interleave
generation and solving, so that the type reconstruction algorithm actually returns
a principal typing at each step. The fact that the typings are always principal is what
ensures that the algorithm never needs to go back and re-analyze a subterm that it
has already processed, since it makes only the minimum commitments needed to
achieve typeability at each step. One major advantage of such an algorithm is that
it can pinpoint errors in the user’s program much more precisely.
17.5.7 Exercise: Modify your solution to Exercise 17.5.5 to perform unification in-
crementally during typechecking and return principal typings. 2
17.6 Further Reading
Chapter 18
Universal Types
Type structure is a syntactic discipline for enforcing levels of abstraction.
— John Reynolds [Rey83]
Some writing needed.
18.1 Motivation
As we observed at the beginning of Chapter 13, the pure simply typed lambda-
calculus is a rather restrictive system in some respects, if we consider it as the basis
for a programming language. Although we can enrich it with numerous additional
type constructors (references, lists, etc.), primitive types (Nat, Bool, Unit, etc.), and
convenient control constructs (let, fix, etc.), the rigidity of the “core” typing rules
can make it difficult to exploit these features to full advantage. In Chapter 13, we
explored one way of refining the typing relation to make it much more flexible:
adding a subtyping relation and allowing types of terms to be “promoted” when
matching the types of functions and their arguments.
In this chapter, we introduce another, rather different, way of adding flexibility
to the core type system. To motivate this extension, note that in ! there are an
infinite number of “doubling” functions
doubleNat = f:Nat!Nat. x:Nat. f (f x);
doubleRcd = f:{l:Nat}!{l:Nat}. x:{l:Nat}. f (f x);
doubleRcd = f:(Nat!Nat)!(Nat!Nat). x:Nat!Nat. f (f x);
(etc.)
I doubleNat : (Nat!Nat) ! Nat ! Nat
doubleRcd : ({l:Nat}!{l:Nat}) ! {l:Nat} ! {l:Nat}
doubleRcd : ((Nat!Nat)!Nat!Nat) ! (Nat!Nat) ! Nat ! Nat
130
January 15, 2000 18. UNIVERSAL TYPES 131
each applicable to a different type of argument, but all sharing precisely the same
behavior (even the same program text, modulo typing annotations). This kind of
“cut and paste” programming violates a basic principle of software engineering:
Write each piece of functionality in one place. If something has to be
used many times in slightly different ways, abstract out the varying
parts.
Here, the varying parts are the types! What we want, it seems, are facilities for
“abstracting out” a type from a term and later instantiating this abstract (or “poly-
morphic”) term by applying it to a concrete type.
The system we’ll be studying in this chapter was developed (one is tempted
to say “discovered”) independently, in the early 1970s by a computer scientist,
John Reynolds, who called it the polymorphic lambda-calculus [Rey74], and by
a logician, Jean-Yves Girard, who called it System F [Gir72]. It has been used
extensively as a research vehicle for foundational work on polymorphism and as
the basis for numerous programming language designs. For reasons that we shall
see later (in Chapter 25), it is sometimes called the second-order lambda-calculus.
18.2 Varieties of Polymorphism
Type systems that allow a single piece of code to be used with multiple types are
collectively known as polymorphic systems. Several types of polymorphism have
been proposed (this way of classifying them is due to Strachey [?]):
Parametric polymorphism, the subject of this chapter, allows a piece
of code to be typechecked “generically,” using type variables in place
of actual types, and then instantiated with particular types as needed.
We have seen this phenomenon already in Chapter ??, and it will be the
main focus of the present chapter.
Ad-hoc polymorphism allows different behaviors at run-time when a
single piece of code is used with multiple types. The most powerful
form of ad-hoc polymorphism is a general typecase construct that al-
lows arbitrary computation based on type information, but this is sel-
dom seen in real languages. More common are constructs such as Java’s
hasType , which allow simple branching on run-time type tags.
Overloading is a very simple form of ad-hoc polymorphism where
only a limited collection of (usually built-in) operations are given multi-
ple types. For example, many languages overload arithmetic operators
like +with multiple types such as Int!Int!Int and Real!Real!Real.
The subtype polymorphism that we saw in Chapter 13 gives a single
term many types using the rule of subsumption, allowing us to selec-
tively “forget” information about the term’s behavior.
January 15, 2000 18. UNIVERSAL TYPES 132
These categories are not exclusive: different forms of polymorphism can be mixed
in the same language. For example, Standard ML offers a restricted form of para-
metric polymorphism and simple arithmetic overloading, but not subtyping, while
Java includes subtyping, overloading, and simple ad-hoc polymorphism, but not
parametric polymorphism. (There are numerous proposals for adding parametric
polymorphism to Java. At the time of this writing, the front-runner is probably
GJ [BOSW98].)
The bare term “polymorphism” is the source of a certain amount of confusion
in the programming languages literature. In the functional programming commu-
nity (i.e., those who use or design languages like ML, Haskell, etc.), it always refers
to parametric polymorphism. In the object-oriented programming community, it
almost always refers to subtype polymorphism.
18.3 Definitions
The definition of the polymorphic lambda-calculus (System F for short) is actu-
ally a very straightforward extension of the simply typed lambda-calculus. In !,
lambda-abstraction is used to abstract terms out of terms, and application is used
to supply values for the abstracted parts. Similarly, we want a mechanism for ab-
stracting types out of terms and filling them in later—we might as well use lambda-
abstraction and application as a model. To this end, we introduce a new form of
lambda-abstraction
X. t
whose parameter is a type—a kind of function that takes a type X as argument.
Similarly, we introduce a new form of application
t [T]
in which the argument is a type expression. We call our new functions with type
parameters polymorphic functions or type abstractions; the new application con-
struct is called type application.
When, during evaluation, a type abstraction meets a type application, the pair
forms a redex, just as in !. We add a reduction rule
analogous to the ordinary reduction rule for abstractions and applications. For
example, when the polymorphic identity function
id = X. x:X. x;
is applied to the argument Nat, the result is fX 7! Natg(x:X.x), i.e., x:Nat.x,
which is the identity function on natural numbers.
Finally, we need to define the type of a polymorphic function. Just as we had
types like Nat!Nat for classifying ordinary functions like x:Nat.x, we now need
January 15, 2000 18. UNIVERSAL TYPES 133
a different form of “arrow type” whose domain is a type, for classifying polymor-
phic functions like id. Notice that, for each argument T to which it is applied, id
yields a function of type T!T; that is, the type of the result of id depends on the
actual type that we pass it as argument. To capture this dependency, we write the
type of id like this:
id : 8X.X!X
The typing rules for polymorphic abstraction and application are analogous to
the corresponding rules for ordinary abstraction and application.
 ; X ` t2 : T2
  ` X.t2 : 8X.T2
(T-TABS)
  ` t1 : 8X.T12
  ` t1 [T2] : fX 7! T2gT12 (T-TAPP)
Note that we include the “binding” X in the typing context used in the subderiva-
tion for t. For the moment, this binding plays no role except to keep track of the
scopes of type variables and make sure that the same type variable is not added
twice to the context. In later chapters, we will annotate type variable bindings in
the context with information of various kinds.
In summary, here is the complete polymorphic lambda-calculus, with differ-
ences from ! highlighted.
System F : Polymorphic lambda-calculus ! 8
Syntax
t ::= (terms...)
x variable
x:T.t abstraction
t t application
X.t type abstraction
t [T] type application
v ::= (values...)
x:T.t abstraction value
X.t type abstraction value
T ::= (types...)
X type variable
T!T type of functions
8X.T universal type
  ::= (contexts...)
January 15, 2000 18. UNIVERSAL TYPES 134
; empty context
 ; x:T term variable binding
 ; X type variable binding
Evaluation (t  ! t 0)
(x:T11.t12) v2  ! fx 7! v2gt12 (E-BETA)
t1  ! t1 0
t1 t2  ! t 01 t2 (E-APP1)
t2  ! t2 0
v1 t2  ! v1 t 02 (E-APP2)
(X.t12) [T2]  ! fX 7! T2gt12 (E-BETA2)
t1  ! t 01
t1 [T2]  ! t 01 [T2] (E-TAPP)
Typing (  ` t : T)
x:T 2  
  ` x : T
(T-VAR)
 ; x:T1 ` t2 : T2
  ` x:T1.t2 : T1!T2 (T-ABS)
  ` t1 : T11!T12   ` t2 : T11
  ` t1 t2 : T12
(T-APP)
 ; X ` t2 : T2
  ` X.t2 : 8X.T2
(T-TABS)
  ` t1 : 8X.T12
  ` t1 [T2] : fX 7! T2gT12 (T-TAPP)
As usual, this summary defines just the “pure” polymorphic lambda-calculus,
omitting other type constructors such as records, base types such as Nat and Bool,
and term-language extensions such as let and fix. These extra constructs can be
added straightforwardly to the pure system, and we will use them freely in the
examples that follow.
18.3.1 Exercise [Quick check]: In Exercise 7.3.1, we saw that the pure simply typed
lambda calculus (with no base types or type variables) is actually a trivial system
containing no typeable terms. What about pure System F? 2
January 15, 2000 18. UNIVERSAL TYPES 135
18.4 Examples
We now turn to developing some more interesting examples of “programming
with polymorphism,” of several different sorts:
 To warm up, we’ll start with a few small but increasingly tricky examples,
showing some of the expressive power of System F.
 We’ll then review the basic ideas of “ordinary” polymorphic programming
with lists, trees, etc. This is the kind of programming that usually comes to
mind when polymorphism is mentioned.
 The final subsection will introduce typed versions of the Church Encodings
of simple algebraic datatypes like booleans, numbers, and lists that we saw in
Chapter 4 for the untyped lambda-calculus. Although these encodings are of
little practical importance, they make excellent exercises for understanding
the intricacies of System F.
Warm-ups
We have seen already how type abstraction and application can be used to define
a single polymorphic identity function
id = X. x:X. x;
and instantiate it to yield any particular concrete identity function that may be
required:
id [Nat];
I id : 8X. X ! X
(x:Nat. x) : Nat ! Nat
id [Nat] 0;
I 0 : Nat
A more useful example is the polymorphic “double” function, which takes a
function f and an argument a and applies f twice in succession to a:
double = X. f:X!X. a:X. f (f a);
I double : 8X. (X!X) ! X ! X
The abstraction on the type X allows us to obtain doubling functions for specific
types by instantiating double with different type arguments:
doubleNat = double [Nat];
doubleNatArrowNat = double [Nat!Nat];
January 15, 2000 18. UNIVERSAL TYPES 136
I doubleNat : (Nat!Nat) ! Nat ! Nat
doubleNatArrowNat : ((Nat!Nat)!Nat!Nat) ! (Nat!Nat) ! Nat ! Nat
Once instantiated with a type argument, double can be further applied to an actual
function and an argument of appropriate types:
double [Nat] (x:Nat. succ(succ(x))) 3;
I 7 : Nat
Here is a slightly trickier example: polymorphic self-application. Recall that, in
the simply typed lambda-calculus, there is no way to give a typing to an untyped
term of the form x x (cf. Exercise 7.4.5). In System F, on the other hand, this term
becomes typeable if we make x a polymorphic function and add a type application:
selfApp = x:8X.X!X. x [8X.X!X] x;
I selfApp : (8X. X!X) ! (8X. X ! X)
Here is a more useful example of self application. We can apply the polymor-
phic double function to itself, yielding a polymorphic quadrupling function:
quadruple = X. double [X!X] (double [X]);
I quadruple : 8X. (X!X) ! X ! X
18.4.1 Exercise [Quick check]: Using the typing rules above, convince yourself that
these terms have the types given. 2
Polymorphic Lists
Impredicative Encodings
Here are the “Church booleans”:
CBool = 8X.X!X!X;
tt = X. t:X. f:X. t;
ff = X. t:X. f:X. f;
cif = b:CBool. X. th:X. el:X. b [X] th el;
I tt : 8X. X ! X ! X
ff : 8X. X ! X ! X
cif : CBool ! (8X. X ! X ! X)
In fact, cif is the identity function! In other words, an element of type CBool is
itself a “conditional,” in the sense that it takes two alternatives and chooses either
the first or the second depending on whether it represents true or false.
We can write common boolean operations like not either in terms of cif
January 15, 2000 18. UNIVERSAL TYPES 137
not = b:CBool. cif b [CBool] ff tt;
I not : CBool ! CBool
or, more interestingly, by directly constructing a new boolean from the given one:
not = b:CBool.
X. t:X. f:X.
b [X] f t;
I not : CBool ! (8X. X ! X ! X)
18.4.2 Exercise [Recommended]: Write a term
and : CBool!CBool!CBool
without using cif. 2
We can play a similar game with numbers. The elements of the type
CNat = 8X. (X!X) ! X ! X;
of “Church numerals” can be used to represent natural numbers as follows:
czero = X. s:X!X. z:X. z;
cone = X. s:X!X. z:X. s z;
ctwo = X. s:X!X. z:X. s (s z);
cthree = X. s:X!X. z:X. s (s (s z));
I czero : 8X. (X!X) ! X ! X
cone : 8X. (X!X) ! X ! X
ctwo : 8X. (X!X) ! X ! X
cthree : 8X. (X!X) ! X ! X
and so on. That is, a church numeral n is a function that, given arguments s and z,
applies s to z, n times.
The successor function can be defined as follows:
csucc = n:CNat.
X. s:X!X. z:X.
s (n [X] s z);
I csucc : CNat ! (8X. (X!X) ! X ! X)
That is, csucc n returns an element of CNat that, given s and z, applies s to z, n
times (by applying n), and then once more.
Other arithmetic operations can be defined similarly:
cplus = m:CNat. n:CNat.
m [CNat] csucc n;
I cplus : CNat ! CNat ! CNat
January 15, 2000 18. UNIVERSAL TYPES 138
Or, more directly:
cplus = m:CNat. n:CNat.
X. s:X!X. z:X.
m [X] s (n [X] s z);
I cplus : CNat ! CNat ! (8X. (X!X) ! X ! X)
We can convert from church numerals to ordinary numbers like this:
cnat2nat = m:CNat. m [Nat] (x:Nat. succ(x)) 0;
I cnat2nat : CNat ! Nat
This allows us to verify that the terms we have defined actually compute the de-
sired arithmetic functions:
cnat2nat (cplus (csucc czero) (csucc (csucc czero)));
I 3 : Nat
18.4.3 Exercise [Recommended]: Write a function iszero that returns true when
applied to the church numeral czero and false otherwise. 2
18.4.4 Exercise: Show that the terms
ctimes = m:CNat. n:CNat.
X. s:X!X.
n [X] (m [X] s);
cexp = m:CNat. n:CNat.
X.
n [X!X] (m [X]);
I ctimes : CNat ! CNat ! (8X. (X!X) ! X ! X)
cexp : CNat ! CNat ! (8X. (X!X) ! X ! X)
have the indicated types. Sketch an informal argument that they implement the
arithmetic multiplication and exponentiation operators. 2
So, if we wanted to, we could actually drop Nat and iteration from the lan-
guage. This doesn’t affect real programming languages based on System F, since
we want to build in booleans for efficiency and syntactic convenience, but it helps
when we’re doing theoretical work because it keeps the system small.
18.4.5 Exercise [Recommended]: In what sense does the type
PairNat = 8X. (CNat!CNat!X) ! X;
represent pairs of numbers? Write functions
January 15, 2000 18. UNIVERSAL TYPES 139
pairNat : CNat!CNat!PairNat;
fstNat : PairNat!CNat;
sndNat : PairNat!CNat;
for constructing elements of this type from pairs of numbers and for accessing their
first and second components. 2
18.4.6 Exercise [Moderately difficult, recommended]: Use the functions defined
in Exercise 18.4.5 to write a function pred that computes the predecessor of a
church numeral (returning 0 if its input is 0). (Hint: the key idea is developed
in the example in Section ??. Define a function f : PairNat!PairNat that maps
the pair (i; j) into (i + 1; i)—that is, it throws away the second component of its
argument, copies the first component to the second, and increments the first. Then
n applications of f to the starting pair (0; 0) yields the pair (n;n - 1)...) 2
18.4.7 Exercise [Optional]: There is another way of computing the predecessor
function on church numerals. Let K stand for the untyped lambda-term x. y. x
and I for x. x. The untyped lambda-term
vpred = [n] s. z. n (p. q. q (p s)) (K z) I
(due to J. Velmans) computes the predecessor of an untyped Church numeral.
Show that this term can be typed in System F by adding type abstractions and ap-
plications as necessary and annotating the bound variables in the untyped term
with appropriate types. For extra credit, explain why it works! (Solution on
page ??.) [Thanks to Michael Levin for making me aware of this example.] 2
18.5 Metatheory
Soundness
The preservation and progress properties from the simply typed lambda-calculus holds ex-
actly the same here. To prove it, we need one additional substitution lemma, for types.
Strong Normalization
The strong normalization property for System F, proved using an extension of the
method presented in Chapter ??, was one of the major achievements of Girard’s
Ph.D. thesis. Since then, this proof technique has been studied and reworked by
many authors, including [?].
18.5.1 Theorem [Strong normalization]: All well-typed System F terms are strongly
normalizing. 2
January 15, 2000 18. UNIVERSAL TYPES 140
Erasure and Typeability
There are two reasonable definitions of erasure for System F: the “type-passing” and “type-
forgetting” interpretations...
18.5.2 Exercise: The strong normalization property of System System F implies
that the term

 = (x. x x) (y. y y)
in the untyped lambda-calculus cannot be typed in System F, since reduction of

 never reaches a normal form. However, it is possible to give a more direct,
“combinatorial” proof of this fact, using just the rules defining the typing relation.
1. Let us call a System F term exposed if it is a variable, an abstraction x:T.t,
or an application t s (i.e., if it is not a type abstraction X.t or type applica-
tion t S).
Show that if t is well typed (in some context) and erase(t) = M, then there is
some exposed term s such that erase(s) = M and s is well typed (possibly in a
different context).
2. Write X.t as shorthand for a nested sequence of type abstractions of the
form X1.. . .Xn.t. Similarly, write t [A] for a nested sequence of type
applications ((t [A1]) : : : [An-1]) [An] and 8X.T for a nested sequence of
polymorphic types 8X1.. . .8Xn.T. Note that these sequences are allowed to
be empty. For example, if X is the empty sequence of type variables, then
8X.T is just T.
Show that if erase(t) = M and   ` t : T, then there exists some s of the form
X. (u [A]), for some sequence of type variables X, some sequence of types
A, and some exposed term u, with erase(s) = M and   ` s : T.
3. Show that if t is an exposed term of type T (under  ) and erase(t) = M N,
then t has the form s u for some terms s and u such that erase(s) = M and
erase(u) = N, with   ` s : U!T and   ` u : U.
4. Suppose that x:T 2  . Show that if   ` u : U and erase(u) = x x, then either
(a) T = 8X.Xi, where Xi 2 X, or else
(b) T = 8X1X2.T1!T2, where fX1X2 7! AgT1 = fX1 7! Bg(8Z.T1!T2) for
some sequences of types A and B with jAj = jX1X2j and jBj = jX1j.
5. Show that if erase(s) = x.M and   ` s : S, then S has the form 8X.S1!S2,
for some X, S1, and S2.
January 15, 2000 18. UNIVERSAL TYPES 141
6. Define the leftmost leaf of a type T as follows:
leftmost-leaf(X) = X
leftmost-leaf(S!T) = leftmost-leaf(S)
leftmost-leaf(8X.S) = leftmost-leaf(S):
Show that if fX1X2 7! Ag(8Y.T1) = fX1 7! Bg(8Z.(8Y.T1)!T2), then leftmost-leaf(T1) =
Xi for some Xi 2 X1X2.
7. Show that 
 is not typeable in System F.
(Solution on page ??.) 2
The type erasure function for System F is the following mapping from System
F to terms in the untyped lambda-calculus:
erase(x) = x
erase(x:T. t) = x. erase(t)
erase(t s) = erase(t) erase(s)
erase(X. t) = erase(t)
erase(t [S]) = erase(t)
A term M in the untyped lambda-calculus is said to be typeable in System F if there
is some well-typed term t such that erase(t) = M.
Type Reconstruction
18.6 Implementation
Nameless Representation of Types
ML Code
type ty =
...
| TyVar of int * int
| TyAll of string * ty
type term =
...
| TmTAbs of info * string * term
| TmTApp of info * term * ty
let tyshifti d c tyT =
tymap
(fun c x n ! if x>=c then
January 15, 2000 18. UNIVERSAL TYPES 142
if x+d<0 then err "Scoping error!"
else TyVar(x+d,n+d)
else TyVar(x,n+d))
c
tyT
let tmshifti d c t =
tmmap
(fun fi c x n ! if x>=c then TmVar(fi,x+d,n+d) else TmVar(fi,x,n+d))
(tyshifti d)
c
t
let tmshift t d = tmshifti d 0 t
let tyshift tyT d = tyshifti d 0 tyT
(Note that we also need to shift the type annotation in the TmAbs case.)
let tmsubsti s j t =
tmmap
(fun fi j x n ! if x=j then (tmshift s j) else TmVar(fi,x,n))
(fun j tyT ! tyT)
j
t
let tmsubst s t = tmsubsti s 0 t
let tmsubstsnip s t = tmshift (tmsubst (tmshift s 1) t) (-1)
let tysubsti tyS j tyT =
tymap
(fun j x n ! if x=j then (tyshift tyS j) else (TyVar(x,n)))
j
tyT
let tysubst tyS tyT = tysubsti tyS 0 tyT
let tysubstsnip tyS tyT = tyshift (tysubst (tyshift tyS 1) tyT) (-1)
let rec tytmsubsti tyS j t =
tmmap
(fun fi c x n ! TmVar(fi,x,n))
(fun j tyT ! tysubsti tyS j tyT)
j
t
let tytmsubst tyS t = tytmsubsti tyS 0 t
January 15, 2000 18. UNIVERSAL TYPES 143
let tytmsubstsnip tyS t = tmshift (tytmsubst (tyshift tyS 1) t) (-1)
18.7 Further Reading
Chapter 19
Existential Types
Some writing needed.
Having seen the role of universal quantifiers in a type system, one might won-
der whether existential quantifiers would also be useful in programming. In fact,
they provide an elegant foundation for data abstraction and “information hiding,”
as we shall see in this chapter.
19.1 Motivation
The polymorphic types in Chapter 18 can be viewed in two different ways:
1. A logical intuition is that an element of the type 8X.T is a value that has type
fX 7! SgT for any choice of S.
This intuition corresponds to a “type-erasure view” of what a term means:
for example, the polymorphic identify function X.x:X.x erases to the un-
typed identity function x.x, which maps an argument of any type S to a
result of the same type S.
2. A more operational intuition is that an element of 8X.T is a function mapping
a type S to a concrete instance with type fX 7! SgT.
This intuition corresponds to our definition of System F in Chapter 18, where
the reduction of a type application is considered an actual step of the com-
putation.
Similarly, there are two different ways of looking at an existential type {9X,T}:
1. The logical intuition is that an element of {9X,T} has type fX 7! SgT for some
type S.
144
January 15, 2000 19. EXISTENTIAL TYPES 145
2. The operational intuition is that an element of {9X,T} is a pair of a type S and
a term t of type fX 7! SgT.
We will take an operational view of existentials in this chapter, since it provides a
closer analogy between existential packages and modules or abstract data types.
Our concrete syntax for existential types ({9X,T} rather than the more standard
9X.T) reflects this analogy.
As always, to understand existential types we need to know two things: how
to build (or “introduce,” in the jargon of Section ??) elements of existential types,
and how to use (or “eliminate”) these values in computations.
A value {9X=S,t} of type {9X,T} can be thought of as a simple module with
one (hidden) type component and one term component.1 The type S is often called
the hidden representation type, or sometimes (to emphasize the connection with
intuitionistic logic) the witness type of the package. As a simple example, the
package
p = {9X=Nat, {a=5, f=x:Nat. succ(x)}}
has the existential type
{9X, {a:X, f:X!X}}:
That is, the right-hand component of p is a record containing a field a of type X and
a field f of type X!X, for some X (namely Nat).
The same package p also has the type
{9X, {a:X, f:X!Nat}};
since its right-hand component is a record with fields a and f of type X and X!Nat,
for some X (namely Nat). This example shows that, in general, we can’t make an
automatic decision about which existential type a given package belongs to: the
programmer must specify which one is intended. The simplest way to do this is
just to add an annotation to every package that explicitly gives its intended type.
So we’ll write
p1 = {9X=Nat, {a=5, f=x:Nat. succ(x)}} as {9X, {a:X, f:X!X}};
I p1 : {9X, {a:X,f:X!X}}
or:
1Obviously, we could generalize to many type/term components, but we’ll stick with just one of
each to keep the notation tractable. The effect of multiple type components can be achieved by nesting
single-type existentials, while the effect of multiple term components can be achieved by using a tuple
or record as the right-hand component:
{9X1=S1, 9X2=S2, t1, t2}
def
= {9X1=S1, {9X2=S2, {t1, t2}}}
January 15, 2000 19. EXISTENTIAL TYPES 146
p2 = {9X=Nat, {a=5, f=x:Nat. succ(x)}} as {9X, {a:X, f:X!Nat}};
I p2 : {9X, {a:X,f:X!Nat}}
The type annotation introduced by as is similar to the coercion construct intro-
duced in Section ??, which allows any term to be annotated with its intended type.
We are essentially requiring a single coercion as part of the concrete syntax of the
package construct.
The complete typing rule for packages is as follows:
  ` t2 : fX 7! UgT2
  ` {9X=U,t2} as {9X,T2} : {9X,T2}
(T-PACK)
Of course, packages with different representation types can inhabit the same
existential type. For example:
p3 = {9X=Nat, 0} as {9X,X};
p4 = {9X=Bool, true} as {9X,X};
I p3 : {9X, X}
p4 : {9X, X}
Or, more usefully:
p5 = {9X=Nat, {a=0, f=x:Nat. succ(x)}} as {9X, {a:X, f:X!Nat}};
p6 = {9X=Bool, {a=true, f=x:Bool. 0}} as {9X, {a:X, f:X!Nat}};
I p5 : {9X, {a:X,f:X!Nat}}
p6 : {9X, {a:X,f:X!Nat}}
19.1.1 Exercise [Quick check]: Here are three more variations on the same theme:
p7 = {9X=Nat, {a=0, f=x:Nat. succ(x)}} as {9X, {a:X, f:X!X}};
p8 = {9X=Nat, {a=0, f=x:Nat. succ(x)}} as {9X, {a:X, f:Nat!X}};
p9 = {9X=Nat, {a=0, f=x:Nat. succ(x)}} as {9X, {a:Nat, f:Nat!Nat}};
I p7 : {9X, {a:X,f:X!X}}
p8 : {9X, {a:X,f:Nat!X}}
p9 : {9X, {a:Nat,f:Nat!Nat}}
In what ways are these less useful than p5 and p6? (Solution on page ??.) 2
A useful intuition for the existential elimination construct comes from the anal-
ogy with modules. If an existential package is a simple form of module, then pack-
age elimination is like an open or import construct: it allows the components of
the module to be used in some other part of the program, but holds the identity
of the module’s type component abstract. This can be achieved with a kind of
pattern-matching binding:
  ` t1 : 9X.T12  ; X; x:T12 ` t2 : T2
  ` let {X,x}=t1 in t2 : T2
(T-UNPACK)
That is, if t1 is an expression that yields an existential package, then we can bind
its type and term components to the pattern variables X and x and use them in
computing t2.
For example, suppose that p has the following existential type:
January 15, 2000 19. EXISTENTIAL TYPES 147
I p : {9X, {a:X,f:X!Nat}}
Then the elimination expression
let {X,x}=p in (x.f x.a);
I 1 : Nat
opens p and uses its components (x.f and x.a) to compute a numeric result. The
body of the elimination form is also permitted to use the type variable X, as in the
following example:
let {X,x}=p in (y:X. x.f y) x.a;
I 1 : Nat
The fact that the package’s representation type is held abstract during the type-
checking of the body (t2) means that the only operations allowed on x are those
warranted by its “abstract type” T1. In the present example, we are not allowed to
use x.a concretely as a number:
let {X,x}=p in succ(x.a);
I Error: argument of succ is not a number
This restriction makes good sense, since we saw above that a package p with the
given existential type might use either Nat or Bool as its representation type.
There is another, more subtle, way in which typechecking of the existential
elimination construct may fail. In the rule T-UNPACK, the type variable X appears
in the context in which t2’s type is calculated, but does not appear in the context
of the rule’s conclusion. This means that the result type T2 cannot contain X free,
since any free occurrences of X will be out of scope in the conclusion. More oper-
ationally, in terms of the nameless presentation of terms discussed in Section 5.1,
the T-UNPACK rule proceeds in three steps:
1. Check the subexpression t1 and ensure that it has an existential type {9X.T11}.
2. Extend the context   with X and x:T11 and check that t2 has some type T2.
3. Shift the indices of free variables in T2 down by two, so that it makes sense
with respect to  .
4. Return the resulting type as the type of the whole let...in... expression.
Clearly, if X occurs free in T2, then the shifting step will yield a nonsensical type
containing free variables with negative indices; typechecking must fail at this point.
let {X,x}=p in x.a;
I Error: Scoping error!
January 15, 2000 19. EXISTENTIAL TYPES 148
The computation rule for existentials is straightforward: if the package subex-
pression has already been reduced to a concrete package, then we may substitute
the components of the package for the variables X and x in the body t2:
In terms of the analogy with modules, this rule can be viewed as a kind of “link-
ing” operation, in which symbolic names (X and x) referring to the components of
a separately compiled module are replaced by direct references to the actual con-
tents of the module.
Since the type variable X is substituted away by this rule, the resulting pro-
gram actually has concrete access to the package’s internals. This is just another
example of a phenomenon we have seen several times: expressions can become
“more typed” as computation proceeds, and in particular an ill-typed expression
can reduce to a well-typed one.
Existential types !8 9
New syntactic forms
t ::= ... (terms...)
{9X=T,t} as T packing
let {X,x}=t in t unpacking
v ::= ... (values...)
{9X=T,v} as T package value
T ::= ... (types...)
{9X,T} existential type
New evaluation rules (t  ! t 0)
let {X,x}={9X=T11,v12} as T1 in t2
 ! fX 7! T11gfx 7! v12gt12 (E-PACKBETA)
t12  ! t 012
{9X=T11,t12} as T1
 ! {9X=T11,t 012} as T1
(E-PACK)
t1  ! t 01
let {X,x}=t1 in t2
 ! let {X,x}=t01 in t2
(E-UNPACK)
New typing rules (  ` t : T)
  ` t2 : fX 7! UgT2
  ` {9X=U,t2} as {9X,T2} : {9X,T2}
(T-PACK)
January 15, 2000 19. EXISTENTIAL TYPES 149
  ` t1 : 9X.T12  ; X; x:T12 ` t2 : T2
  ` let {X,x}=t1 in t2 : T2
(T-UNPACK)
19.2 Data Abstraction with Existentials
Abstract Data Types
For a more interesting example, here is a simple package defining an abstract data
type of (purely functional) counters.
counterADT =
{9Counter = Nat,
{new = 0,
get = i:Nat. i,
inc = i:Nat. succ(i)}}
as {9Counter,
{new: Counter,
get: Counter!Nat,
inc: Counter!Counter}};
I counterADT : {9Counter,
{new:Counter,get:Counter!Nat,inc:Counter!Counter}}
The concrete representation of a counter is just a number. The package provides
three operations on counters: a constant new, a function get for extracting a counter’s
current value, and a function inc for creating a new counter whose stored value is
one more than the given counter’s. Having created the counter package, we next
open it, exposing the operations as the fields of a record counter:
let {Counter,counter}=counterADT in
counter.get (counter.inc counter.new);
I 1 : Nat
If we organize our code so that the body of this let contains the whole remainder
of the program, then this idiom
let {Counter,counter} = <counter package> in
<rest of program>
has the effect of declaring a fresh type Counter and a variable counter of type
{new:Counter,get:Counter!Nat,inc: Counter!Counter}.
It is instructive to compare the above with a more standard abstract data type
declaration, such as might be found in a program in Ada [oD80] or Clu [LAB+81]:
January 15, 2000 19. EXISTENTIAL TYPES 150
ADT counter =
type Counter
representation Nat
operations
{new = 0
: Counter,
get = i:Nat. i
: Counter!Nat,
inc = i:Nat. succ(i)}
: Counter!Counter};
counter.get (counter.inc counter.new);
The version using existential types is somewhat harder to read, compared to the
syntactically sugared second version, but otherwise the two programs are essen-
tially identical.
Note that we can substitute an alternative implementation of the CounterADT—
for example, one where the internal representation is a record containing a Nat
rather than just a single Nat
counterADT =
{9Counter = {x:Nat},
{new = {x=0},
get = i:{x:Nat}. i.x,
inc = i:{x:Nat}. {x=succ(i.x)}}}
as {9Counter,
{new: Counter,
get: Counter!Nat,
inc: Counter!Counter}};
I counterADT : {9Counter,
{new:Counter,get:Counter!Nat,inc:Counter!Counter}}
in complete confidence that the whole program will remain typesafe, since we are
guaranteed that the rest of the program cannot access instances of Counter except
using get and inc. This is the essence of data abstraction by information hiding.
In the body of the program, the type name Counter can be used just like the
base types built into the language. We can define functions that operate on coun-
ters:
let {Counter,counter}=counterADT
in
let addthree = c:Counter.
counter.inc (counter.inc (counter.inc c))
in
counter.get (addthree counter.new);
January 15, 2000 19. EXISTENTIAL TYPES 151
I 3 : Nat
We can even define new abstract data types whose representation involves coun-
ters. For example, the following program defines an ADT of flip-flops, using a
counter as the (not very efficient) representation type:
let {Counter,counter} =
{9Counter = Nat,
{new = 0,
get = i:Nat. i,
inc = i:Nat. succ(i)}}
as {9Counter,
{new: Counter,
get: Counter!Nat,
inc: Counter!Counter}}
in
let {FlipFlop,flipflop} =
{9FlipFlop = Counter,
{new = counter.new,
read = c:Counter. iseven (counter.get c),
toggle = c:Counter. counter.inc c,
reset = c:Counter. counter.new}}
as {9FlipFlop,
{new: FlipFlop,
read: FlipFlop!Bool,
toggle: FlipFlop!FlipFlop,
reset: FlipFlop!FlipFlop}}
in
flipflop.read (flipflop.toggle (flipflop.toggle flipflop.new));
I false : Bool
19.2.1 Exercise [Recommended]: Follow the model of the above example to de-
fine an abstract data type of stacks of numbers, with operations new, push, pop, and
isempty. Use the List type introduced in Exercise ?? as the underlying representa-
tion. Write a simple main program that creates a stack, pushes a couple of numbers
onto it, pops off the top element, and returns it.
This exercise is best done on-line. Use the checker named “everything” and
copy the contents of the file test.f from the everythingdirectory (which contains
definitions of the List constructor and associated operations) to the top of your
own input file. 2
January 15, 2000 19. EXISTENTIAL TYPES 152
Existential Objects
The sequence of “pack then open” that we saw in the last section is the hallmark of
ADT-style programming using existential packages. A package defines an abstract
type and its associated operations, and each package is opened immediately after
it is built, binding a type variable for the abstract type and exposing the ADT’s op-
erations abstractly, with this variable in place of the concrete representation type.
Existential types can also be used to model other common types of data abstrac-
tion. In this section, we show how a simple form of objects can be understood in
terms of a different idiom based on existentials.
We will again use simple counters as our running example, as we did both
in the previous section on existential ADTs and in our previous encounter with
objects, in Chapter 14. Unlike the counters of Chapter 14, however, the counter ob-
jects in this section will be purely functional: sending the message inc to a counter
will not change its internal state in-place, but rather will return a fresh counter ob-
ject with incremented internal state.
A counter object, then, will comprise two basic components: a number (its in-
ternal state), and a pair of methods, get and inc, that can be used to query and
update the state. We also need to ensure that the only way that the state of a
counter object can be queried or updated is by using one of its two methods. This
can be accomplished by wrapping the state and methods in an existential package,
abstracting the type of the internal state. For example, a counter object holding the
value 5 might be written
c = {9X = Nat,
{state = 5,
methods = {get = x:Nat. x,
inc = x:Nat. succ(x)}}}
as Counter;
where:
Counter = {9X, {state:X, methods: {get:X!Nat, inc:X!X}}};
To use a method of a counter object, we will need to open it up and apply
the appropriate element of its methods to its state field. For example, to get the
current value of c we can write:
let {X,body} = c in
body.methods.get(body.state);
I 5 : Nat
More generally, we can define a little function that “sends the get message” to any
counter:
sendget = c:Counter.
let {X,body} = c in
body.methods.get(body.state);
January 15, 2000 19. EXISTENTIAL TYPES 153
I sendget : Counter ! Nat
Invoking the inc method of a counter object is a little more complicated. If we
simply do the same as for get, the typechecker complains
let {X,body} = c in
body.methods.inc(body.state);
I Error: Scoping error!
because the type variable X appears free in the type of the body of the let. Indeed,
what we’ve written doesn’t make intuitive sense either, since the result of the inc
method is a “bare” internal state, not an object. To satisfy both the typechecker and
our informal understanding of what invoking inc should do, we must take this
fresh internal state and “repackage” it as a counter object, using the same record
of methods and the same internal state type as in the original object:
c1 = let {X,body} = c in
{9X = X,
{state = body.methods.inc(body.state),
methods = body.methods}}
as Counter;
More generally, to “send the inc message” to an arbitrary counter object, we can
write:
sendinc = c:Counter.
let {X,body} = c in
{9X = X,
{state = body.methods.inc(body.state),
methods = body.methods}}
as Counter;
I sendinc : Counter ! Counter
More complex operations on counters can be implemented in terms of these two
basic operations:
addthree = c:Counter. sendinc (sendinc (sendinc c));
I addthree : Counter ! Counter
19.2.2 Exercise: Implement FlipFlop objects with Counter objects as their internal
representation type, following the model of the FlipFlop ADT in Section 19.2. 2
January 15, 2000 19. EXISTENTIAL TYPES 154
Objects vs. ADTs
What we have seen in Section 19.2 falls significantly short of a full-blown model
of object-oriented programming. Many of the features that we saw in Chapter 14,
including subtyping, classes, inheritance, and recursion through self and super,
are missing here. We will come back to modeling these features in later chapters,
when we have added a few necessary refinements to our modeling language. But
even for the simple objects we have developed so far, there are several interesting
comparisons to be made with ADTs.
At the coarsest level, the two programming idioms fall at opposite ends of a
spectrum: when programming with ADTs, packages are opened immediately after
they are built; on the other hand, when packages are used to model objects they
are kept closed as long as possible—until the moment when they must be opened
so that one of the methods can be applied to the internal state.
A consequence of this difference is that the “abstract type” of counters refers
to different things in the two styles. In an ADT-style program, the counter val-
ues manipulated by client code such as addthree are elements of the underlying
representation type (e.g., simple numbers). In an object-style program, a counter
value is a whole package—not only a number, but also the implementations of
the get and inc methods. This stylistic difference is reflected in the fact that, in
the ADT style, the type Counter is a bound type variable introduced by the let
construct, while in the object style Counter abbreviates the whole existential type
{9X, {state:X, methods: {get:X!Nat,inc:X!X}}}. Thus:
 All the counter values generated from the counter ADT are elements of the
same internal representation type; there is a single implementation of the
counter operations that works on this internal representation.
 Each counter object, on the other hand, carries its own representation type
and its own set of methods that work for this representation type.
19.2.3 Exercise: In what ways do the classes found in mainstream object-oriented
languages like C++ and Java resemble the simple object types discussed here? In
what ways do they resemble ADTs? 2
19.3 Encoding Existentials
The encoding of pairs as a polymorphic type in Exercise 18.4.5 suggests a similar
encoding for existential types in terms of universal types, using the intuition that
an element of an existential type is a pair of a type and a value:
{9X,T}
def
= 8Y. (8X. T!Y) ! Y:
That is, an existential package is thought of as a data value that, given a result type
and a “continuation,” calls the continuation to yield a final result. The continuation
January 15, 2000 19. EXISTENTIAL TYPES 155
takes two arguments—a type X and a value of type T—and uses them in computing
the final result.
Given this encoding of existential types, the encoding of the packaging and
unpackaging constructs is essentially forced. To encode a package
{9X=S,t} as {9X,T}
we must exhibit a value of type 8Y. (8X. T!Y) ! Y. This type begins with a
universal quantifier, the body of which is an arrow. An element of this type should
therefore begin with two abstractions:
{9X=S,lt} as {9X,T}
def
= Y. f:(8X.T!Y). ...
To complete the job, we need to return a result of type Y; clearly, the only way to
do this is to apply f to some appropriate arguments. First, we supply the type S
(this is a natural choice, being the only type we have lying around at the moment):
{9X=S,t} as {9X,T}
def
= Y. f:(8X.T!Y). f [S] ...
Now, the type application f [S] has type fX 7! Sg(T!Y), i.e., (fX 7! SgT)!Y. We
can thus supply t (which, by rule T-PACK, has type fX 7! SgT) as the next argument:
{9X=S,t} as {9X,T}
def
= Y. f:(8X.T!Y). f [S] t
The type of the whole application f [S] t is now Y, as required.
To encode the unpacking construct
let {X,x}=t1 in t2
def
= ...
we proceed as follows. First, the typing rule T-UNPACK tells us that t1 should
have some type {9X,T11}, that t2 should have type T2 (under an extended context
binding X and x:T11), and that T2 is the type we expect for the whole let...in...
expression.2 As in the Church encodings in Section 18.4, the intuition here is that
the introduction form ({9X=S,t}) is encoded as an active value that “performs its
own elimination.” So the encoding of the elimination form here should simply
take the existential package t1 and apply it to enough arguments to yield a result
of the desired type T2:
let {X,x}=t1 in t2
def
= t1 ...
The first argument to t1 should be the desired result of the whole expression, i.e.,
T2:
let {X,x}=t1 in t2
def
= t1 [T2] ...
2Strictly speaking, the fact that the translation requires these extra bits of type information not
present in the syntax of terms means that what we are translating is actually typing derivations, not
terms.
January 15, 2000 19. EXISTENTIAL TYPES 156
Now, the application t1 [T2] has type (8X. T!T2) ! T2. That is, if we can now
supply another argument of type (8X.T!T2), we will be finished. Such an argu-
ment can be obtained by abstracting the body t2 on the variables X and x:
let {X,x}=t1 in t2
def
= t1 [T2] (X. x:T11. t2):
This finishes the encoding.
19.3.1 Exercise: What must we prove to show that our encoding of existentials is
correct? 2
19.3.2 Exercise [Recommended]: Take a blank piece of paper and, without looking
at the above encoding, regenerate it from scratch. 2
19.3.3 Exercise: Can universal types be encoded in terms of existential types? 2
19.4 Implementation
type ty =
...
| TySome of string * ty
type term =
...
| TmPack of info * string * ty * term * ty
| TmUnpack of info * string * string * term * term
19.5 Historical Notes
The correspondence between ADTs and existential types was first developed by
Mitchell and Plotkin [MP88]. (They also noticed the correspondance with objects.)
Chapter 20
Bounded Quantification
Many of the interesting problems in type systems arise from the combination of
features that, in themselves, may be quite simple. In this chapter, we encounter
our first substantial example: a system that mixes subtyping with polymorphism.
The most basic combination of these features is actually quite straightforward.
We simply add to the subtyping relation a rule for comparing quantified types:
S <: T
8X.S <: 8X.T
We consider here a more interesting combination, in which the syntax, typing, and
subtyping rules for universal quantifiers are actually refined to take subtyping into
account. The resulting notion of bounded quantification substantially increases
both the expressive power of the system and its metatheoretic complexity.
20.1 Motivation
To see why we might want to combine subtyping and polymorphism in this more
intimate manner, consider the identity function on records with a numeric field a:
f = x:{a:Nat}. x;
I f : {a:Nat} ! {a:Nat}
If we define a record of this form
ra = {a=0};
then we can apply f to ra (in any of the systems that we have seen), yielding a
record of the same form.
(f ra);
I {a=0} : {a:Nat}
157
January 15, 2000 20. BOUNDED QUANTIFICATION 158
If we define a larger record rab with two fields, a and b,
rab = {a=0, b=true};
we can also apply f to rab, using the rule of subsumption introduced in Chap-
ter 13.
(f rab);
I {a=0, b=true} : {a:Nat}
However, the type of the result has only the field a, which means that a term like
(f rab).b will be judged ill typed. In other words, by passing rab through the
identity function, we have lost the ability to access its b field!
Using the polymorphism of System F, we can write f in a different way:
fpoly = X. x:X. x;
I fpoly : 8X. X ! X
The application of fpoly to rab (and an appropriate type argument) yields the
desired result:
(fpoly [{a:Nat, b:Bool}] rab);
I {a=0, b=true} : {a:Nat, b:Bool}
But in making the type of x into a variable, we have given up some information
that f might have wanted to use. For example, suppose we intend that f return a
pair of its original argument and the numeric successor of its a field.
f2 = x:{a:Nat}. {orig=x, asucc=succ(x.a)};
I f2 : {a:Nat} ! {orig:{a:Nat}, asucc:Nat}
Again, we can apply f2 to both ra and rab, losing the b field in the second case.
(f2 ra);
I {orig={a=0}, asucc=1} : {orig:{a:Nat}, asucc:Nat}
(f2 rab);
I {orig={a=0,b=true}, asucc=1} : {orig:{a:Nat}, asucc:Nat}
But this time polymorphism offers us no solution. If we replace the type of x by
a variable X as before, we lose the constraint that x must have an a field, which is
required to compute the asucc field of the result.
f2poly = X. x:X. {orig=x, asucc=succ(x.a)};
I Error: Expected record type
The fact about the operational behavior of f2 that we want to express in its type is:
January 15, 2000 20. BOUNDED QUANTIFICATION 159
f2 takes an argument of any record type R that includes a numeric a
field and returns as its result a record containing a field of type R and a
field of type Nat.
We can use the subtype relation to express this concisely as follows:
f2 takes an argument of any subtype R of the type {a:Nat} and returns
a record containing a field of type R and a field of type Nat.
This intuition can be formalized by introducing a subtyping constraint on the
bound variable X of f2poly.
f2poly = X<:{a:Nat}. x:X. {orig=x, asucc=succ(x.a)};
I f2poly : 8X<:{a:Nat}. X ! {orig:X, asucc:Nat}
This interaction of subtyping and polymorphism, called bounded quantification,
leads us to a type system commonly called System F<: (“F sub”), which is the topic
of this chapter.
20.2 Definitions
We form System F<: by combining the types and terms of System F with the sub-
type relation from Chapter 13 and refining universal quantifiers with subtyping
constraints on their bound variables. When we define the subtyping rule for these
bounded quantifiers, there will actually be two choices: a more tractable but less
flexible rule called the kernel rule and a more expressive full subtyping rule,
which will turn out to raise some unexpected difficulties when we come to de-
signing typechecking algorithms.
Kernel F<:
Since type variables now have associated bounds (just as ordinary variables have
associated types), we must keep track of them during both subtyping and type-
checking. We change the type bindings in contexts to include an upper bound
for each type variable, and add contexts to all the rules in the subtype relation.
These bounds will be used during subtyping to justify steps of the form “the type
variable X is a subtype of the type T because we assumed it was.”
X<:T 2  
  ` X <: T
(S-TVAR)
20.2.1 Exercise [Quick check]: Exhibit a subtyping derivation showing that
B<:Top; X<:B; Y<:X ` B!Y <: X!B: 2
January 15, 2000 20. BOUNDED QUANTIFICATION 160
Next, we introduce bounded universal types, extending the syntax and typ-
ing rules for ordinary universal types in the obvious way. The only rule where
the extension is not completely obvious is the subtyping rule for quantified types,
S-ALL. We give here the simpler variant, called the kernel subtyping rule for
universal quantifiers, in which the bounds of the two quantifiers being compared
must be identical. (The term “kernel” comes from Cardelli and Wegner’s original
paper [CW85], where this variant of F<: was called Kernel Fun.)
X<:T 2  
  ` X <: T
(S-TVAR)
For easy reference, here is the complete definition of kernel F<:, with differences
from previous systems highlighted:
Fk
<:
: Bounded quantification ! 8 <: bq
Syntax
t ::= (terms...)
x variable
x:T.t abstraction
t t application
X <:T .t type abstraction
t [T] type application
v ::= (values...)
x:T.t abstraction value
X <:T .t type abstraction value
T ::= (types...)
X type variable
Top maximum type
T!T type of functions
8X <:T .T universal type
  ::= (contexts...)
; empty context
 ; x:T term variable binding
 ; X <:T type variable binding
Evaluation (t  ! t 0)
(x:T11.t12) v2  ! fx 7! v2gt12 (E-BETA)
t1  ! t1 0
t1 t2  ! t 01 t2 (E-APP1)
January 15, 2000 20. BOUNDED QUANTIFICATION 161
t2  ! t2 0
v1 t2  ! v1 t 02 (E-APP2)
(X <:T11 .t12) [T2]  ! fX 7! T2gt12 (E-BETA2)
t1  ! t 01
t1 [T2]  ! t 01 [T2] (E-TAPP)
Subtyping (   ` S <: T)
  ` S <: S (S-REFL)
  ` S <: U   ` U <: T
  ` S <: T
(S-TRANS)
  ` S <: Top (S-TOP)
X<:T 2  
  ` X <: T
(S-TVAR)
  ` T1 <: S1   ` S2 <: T2
  ` S1!S2 <: T1!T2 (S-ARROW)
 ; X<:U1 ` S2 <: T2
  ` 8X<:U1.S2 <: 8X<:U1.T2
(S-ALL)
Typing (  ` t : T)
x:T 2  
  ` x : T
(T-VAR)
 ; x:T1 ` t2 : T2
  ` x:T1.t2 : T1!T2 (T-ABS)
  ` t1 : T11!T12   ` t2 : T11
  ` t1 t2 : T12
(T-APP)
 ; X <:T1 ` t2 : T2
  ` X <:T1 .t2 : 8X <:T1 .T2
(T-TABS)
  ` t1 : 8X <:T11 .T12   ` T2 <: T11
  ` t1 [T2] : fX 7! T2gT12 (T-TAPP)
  ` t : S   ` S <: T
  ` t : T
(T-SUB)
January 15, 2000 20. BOUNDED QUANTIFICATION 162
Full F<:
In kernel F<:, two quantified types can only be compared if their upper bounds are
identical. If we think of quantifiers as a kind of arrow types (since they classify
functions from types to terms), then the kernel rule corresponds to a “covariant”
version of the subtyping rule for arrows, in which the domain of an arrow type is
not allowed to vary in subtypes:
S2 <: T2
U!S2 <: U!T2
This restriction feels rather unnatural, both for arrows and for quantifiers. Car-
rying the analogy a little further, we can allow the “left-hand side” of bounded
quantifiers to vary (contravariantly) during subtyping:
F
f
<: : “Full” bounded quantification ! 8 <: bq full
New subtyping rules (  ` S <: T)
  ` T1 <: S1  ; X<: T1 ` S2 <: T2
  ` 8X<:S1 .S2 <: 8X<:T1 .T2
(S-ALL)
Intuitively, the “full F<:” quantifier subtyping rule can be understood as fol-
lows. A type T = 8X<:T1.T2 describes a collection of polymorphic values (func-
tions from types to values), each mapping subtypes of T1 to instances of T2. If T1
is a subtype of S1, then the domain of T is smaller than that of S = 8X<:S1.S2, so
S is a stronger constraint and describes a smaller collection of polymorphic values.
Moreover, if, for each type U that is an acceptable argument to the functions in both
collections (i.e., one that satisfies the more stringent requirement U <: T1), the U-
instance of S2 is a subtype of the U-instance of T2, then S is a “pointwise stronger”
constraint and again describes a smaller collection of polymorphic values.
The system with just the kernel subtyping rule for quantified types is called
Kernel F<: (or Fk<:). The same system with the full quantifier subtyping rule is called
Full F<: (or F
f
<:). The bare name F<: refers ambiguously to both systems.
20.2.2 Exercise [Quick check]: Give a couple of examples of pairs of types that are
related by the subtype relation of full F<: but are not subtypes in kernel F<:. 2
20.2.3 Exercise [Challenging]: Can you find any useful examples with this prop-
erty? 2
January 15, 2000 20. BOUNDED QUANTIFICATION 163
20.3 Examples
We now present some simple examples of programming in F<:. More sophisticated
uses of bounded quantification will appear in later chapters.
Encoding Products
In Exercise ??, we gave the following encoding of pairs in System F. The elements
of the type
Pair T1 T2 = 8X. (T1!T2!X) ! X;
correspond to pairs of T1 and T2. The constructor pair and the destructors fst and
snd were defined as follows:
pair = X. Y. x:X. y:Y.
( R. p:X!Y!R. p x y
as Pair X Y);
fst = X. Y. p: Pair X Y.
p [X] (x:X. y:Y. x);
snd = X. Y. p: Pair X Y.
p [Y] (x:X. y:Y. y);
Of course, the same encoding can be used in F<:, since F<: contains all the features
of System F. What is interesting, though, is that this encoding also has some natural
subtyping properties. In fact, the expected subtyping rule for pairs
  ` S1 <: T1   ` S2 <: T2
  ` Pair S1 S2 <: Pair T1 T2
follows directly from the encoding.
20.3.1 Exercise [Quick check]: Show this. 2
Encoding Records
It is interesting to notice that records and record types—including subtyping—
can actually be encoded in the pure calculus. The encoding presented here was
discovered by Cardelli [Car92]. We begin by defining flexible tuples as follows:
20.3.2 Definition: For each n  0 and types T1 through Tn, let
{Ti
i21::n}
def
= Pair T1 (Pair T2 ... (Pair Tn Top)...):
In particular, {} = Top. Similarly, for terms t1 through tn, let
{ti
i21::n}
def
= pair t1 (pair t2 ... (pair tn top)...);
January 15, 2000 20. BOUNDED QUANTIFICATION 164
where we elide the type arguments to pair, for the sake of brevity. (Recall that top
is just some element of Top.) The projection t.n (again eliding type arguments) is:
fst(snd(snd...(snd| {z }
n-1 times
t)...) 2
From this abbreviation, we immediately obtain the following rules for subtyping
and typing.
  ` i21::n Si <: Ti
  ` {Si
i21::n+k} <: {Ti
i21::n}
  ` i21::n ti : Ti
  ` {ti i21::n} : {Ti i21::n}
  ` t : {Ti
i21::n}
  ` t.i : Ti
Now, let L be a countable set of labels, with a fixed total ordering given by the
bijective function label-with-index : N ! L. We define records as follows:
20.3.3 Definition: Let L be a finite subset of L and let Sl be a type for each l 2 L.
Let m be the maximal index of any element of L, and
Ŝi =

Sl if label-with-index(i) = l 2 L
Top if label-with-index(i) =2 L:
The record type {l:Sll2L} is defined as the flexible tuple {Ŝ
i21::m
i }. Similarly, if tl
is a term for each l : L, then
t̂i =

ti if label-with-index(i) = l 2 L
top if label-with-index(i) =2 L:
The record value {l=tll2L} is {t̂
i21::m
i }. The projection t.li is just the tuple projec-
tion t.i. 2
This encoding validates the expected rules for typing and subtyping:
  ` {li:Ti i21::n+k} <: {li:Ti i21::n} (S-RCD-WIDTH)
for each i   ` Si <: Ti
  ` {li:Si
i21::n} <: {li:Ti
i21::n}
(S-RCD-DEPTH)
January 15, 2000 20. BOUNDED QUANTIFICATION 165
Church Encodings with Subtyping
As a last simple illustration of the expressiveness of F<:, let’s take a look at what
happens when we add bounded quantification to the encoding of Church Numer-
als in System F that we saw in Section 18.4. The original polymorphic type of
church numerals was:
CNat = 8X. (X!X) ! X ! X;
The intuitive reading of this type was: “Tell me a result type T and give me a
function on T and an element of T, and I’ll give you back another element of T
formed by iterating the function you gave me n times over the base value you
gave.”
We can generalize this by adding two bounded quantifiers and refining the
types of the parameters s and z.
SNat = 8X<:Top. 8S<:X. 8Z<:X. (X!S) ! Z ! X;
Intuitively, this type can be read as follows: “Give me a generic result type T and
two subtypes S and Z. Then give me a function that maps from the whole set T into
the subset S and an element of the special set Z, and I’ll return you an element of T
formed in the same way as before.”
To see why this is an interesting generalization, consider this slightly different
type:
SZero = 8X<:Top. 8S<:X. 8Z<:X. (X!S) ! Z ! Z;
Although SZerohas almost the same form as SNat, it says something much stronger
about the behavior of its elements, since it promises that its result will be an ele-
ment of Z, not just of T. In fact, there is just one way that an element of Z could be
returned—namely by yielding just z itself. In other words, the value
szero = (X. S<:X. Z<:X. s:X!S. z:Z. z) as SZero;
I szero : SZero
is the only inhabitant of the type SZero. On the other hand, the similar type
SPos = 8X<:Top. 8S<:X. 8Z<:X. (X!S) ! Z ! S;
has more inhabitants; for example,
sone = (X. S<:X. Z<:X. s:X!S. z:Z. s z) as SPos;
stwo = (X. S<:X. Z<:X. s:X!S. z:Z. s (s z)) as SPos;
sthree = (X. S<:X. Z<:X. s:X!S. z:Z. s (s (s z))) as SPos;
and so on.
Moreover, notice that SZero and SPos are both subtypes of SNat (Exercise:
check this), so we also have szero : SNat, sone : SNat, stwo : SNat, etc.
Finally, we can similarly refine the typings of operations defined on church
numerals. For example, the type system is capable of detecting that the successor
function always returns a positive number:
January 15, 2000 20. BOUNDED QUANTIFICATION 166
ssucc = n:SNat.
(X. S<:X. Z<:X. s:X!S. z:Z.
s (n [X] [S] [Z] s z))
as SPos;
I ssucc : SNat ! SPos
Similarly, by refining the types of its parameters, we can write the function plus in
such a way that the typechecker gives it the refined type SPos!SZero!SPos.
spluspz = n:SPos. m:SZero.
(X. S<:X. Z<:X. s:X!S. z:Z.
n [X] [S] [Z] s (m [X] [S] [Z] s z))
as SPos;
I spluspz : SPos ! SZero ! SPos
20.3.4 Exercise: Write a similar version of plus that has type SPos!SPos!SPos.
Write one that has type SNat!SNat!SNat. 2
The previous example and exercise raise an interesting point: obviously, we
don’t want to have several different versions of plus lying around and have to de-
cide which to apply based on the expected types of its arguments: we want to have
a single version of plus whose type contains all these possibilities—something like
plus : SZero!SZero!SZero
^ SNat!SPos!SPos
^ SPos!SNat!SPos
^ SNat!SNat!SNat
The desire to support this kind of overloading has led to the study of systems with
intersection types.
20.3.5 Exercise [Recommended]: Generalize the type CBool of Church Booleans
from Section 18.4 in a similar way by defining a type SBool and two subtypes
STrue and SFalse. Write a function notft with type SFalse!STrue and a similar
one nottf with type STrue!SFalse. 2
The examples that we have seen in this section are amusing to play with, but
they might not convince you that F<: is a system of tremendous practical impor-
tance! We will come to some more interesting uses of bounded quantification in
Chapter 28, but these will require just a little more machinery, which we will de-
velop in the intervening chapters.
January 15, 2000 20. BOUNDED QUANTIFICATION 167
20.4 Safety
We now consider the metatheory of both kernel and full systems of bounded quan-
tification (Fk
<:
and Ff<:). Much of the development is the same for both systems: we
carry it out first for the simpler case of Fk
<:
and then consider Ff<:.
The type preservation property can actually be proved quite directly for both
systems, with minimal technical preliminaries. This is good, since the soundness
of the type system is a critical property, while other properties such as decidability
may be less important in some contexts. (The soundness theorem belongs in the
language definition, while decision procedures are buried in the compiler.) We
develop the proof in detail for Fk
<:
. The argument for Ff<: is very similar.
We begin with a couple of technical facts about the typing and subtyping rela-
tions. The proofs go by straightforward induction on derivations.
20.4.1 Lemma [Permutation]:
1. If   ` t : T and  is a permutation of  , then  ` t : T.
2. If   ` S <: T and  is a permutation of  , then  ` S <: T. 2
20.4.2 Lemma [Weakening]:
1. If   ` t : T and x =2 dom( ), then  ; x:S ` t : T.
2. If   ` t : T and X =2 dom( ), then  ; X<:S ` t : T.
3. If   ` S <: T and x =2 dom( ), then  ; x:S ` S <: T.
4. If   ` S <: T and X =2 dom( ), then  ; X<:S ` S <: T. 2
As usual, the proof of type preservation relies on several lemmas relating sub-
stitution with the typing and subtyping relations.
20.4.3 Definition: We write fX 7! Sg  for the context obtained by substituting S for
X in the right-hand sides of all of the bindings in  . 2
20.4.4 Exercise [Quick check]: Show the following properties of subtyping and
typing derivations:
1. if  ; X<:Q;  ` S <: T and   ` P <: Q, then  ; X<:P;  ` S <: T;
2. if  ; X<:Q;  ` t : T and   ` P <: Q, then  ; X<:P;  ` t : T;
These properties are often called narrowing because they involve restricting the
range of the variable X. 2
Next, we have the usual lemma relating substitution and the typing relation.
January 15, 2000 20. BOUNDED QUANTIFICATION 168
20.4.5 Lemma [Substitution preserves typing]: If  ; x:Q;  ` t : T and   ` q : Q,
then  ;  ` fx 7! qgt : T. 2
Proof: Straightforward induction on a derivation of  ; x:Q;  ` t : T, using the
properties proved above. 2
Since we may substitute types for type variables during reduction, we also need
a lemma relating type substitution and typing, as we did in System F. Here, though,
we must deal with one new twist: the proof of this lemma (specifically, the T-SUB
case) depends on a new lemma relating substitution and subtyping:
20.4.6 Lemma [Type substitution preserves subtyping]: If  ; X<:Q;  ` S <: T
and   ` P <: Q, then  ; fX 7! Pg ` fX 7! PgS <: fX 7! PgT. 2
Proof: By induction on a derivation of  ; X<:Q;  ` S <: T. The only interesting
cases are the last two:
Case S-TVAR: S = Y Y<:T 2 ( ; X<:Q; )(Y)
There are two subcases to consider. If Y 6= X, then the result follows immediately
from S-TVAR. On the other hand, if Y = X, then we have T = Q and fX 7! PgS = Q,
and the result follows by S-REFL.
Case S-ALL: S = 8Z<:U1.S2 T = 8Z<:U1.T2
 ; X<:Q; ; Z<:U1 ` S2 <: T2
By the induction hypothesis,  ; fX 7! Pg; Z<:fX 7! PgU1 ` fX 7! PgS2 <: fX 7! PgT2.
By S-ALL,  ; fX 7! Pg ` 8Z<:fX 7! PgU1.fX 7! PgS2 <: 8Z<:fX 7! PgU1.fX 7! PgT2,
that is,  ; fX 7! Pg ` fX 7! Pg(8Z<:U1.S2) <: fX 7! Pg(8Z<:U1.T2), as required. 2
20.4.7 Lemma [Type substitution preserves typing]: If  ; X<:Q;  ` t : T and
  ` P <: Q, then  ; fX 7! Pg ` fX 7! Pgt : fX 7! PgT. 2
Proof: By induction on a derivation of  ; X<:Q;  ` t : T. We give just the
interesting cases.
Case T-TAPP: t = t1 [T2]  ; X<:Q;  ` t1 : 8Z<:T11.T12
T = fZ 7! T2gT12
By the induction hypothesis,  ; fX 7! Pg ` fX 7! Pgt1 : fX 7! Pg(8Z<:T11.T12),
i.e,  ; fX 7! Pg ` fX 7! Pgt1 : 8Z<:T11.fX 7! PgT12. By T-TAPP,  ; fX 7! Pg `
fX 7! Pgt1 [(fX 7! PgT2]) : fZ 7! fX 7! PgT2g(fX 7! PgT12), i.e.,  ; fX 7! Pg ` fX 7!
Pg(t1 [T2]) : fX 7! Pg(fZ 7! T2gT12).
Case T-SUB:  ; X<:Q;  ` t : S  ; X<:Q;  ` S <: T
By the induction hypothesis,  ; fX 7! Pg ` fX 7! Pgt : fX 7! PgT. By the preserva-
tion of subtyping under substitution (20.4.6),  ; fX 7! Pg ` fX 7! PgS <: fX 7! PgT,
and the result follows by T-SUB. 2
Next, we establish some simple structural facts about the subtype relation.
January 15, 2000 20. BOUNDED QUANTIFICATION 169
20.4.8 Lemma [Inversion of the subtyping relation, from right to left]:
1. If   ` S <: X, then S is a type variable.
2. If   ` S <: T1!T2, then either S is a type variable or else S = S1!S2 with
  ` T1 <: S1 and   ` S2 <: T2.
3. If   ` S <: 8X<:U1.T2, then either S is a type variable or else S = 8X<:U1.S2
with  ; X<:U1 ` S2 <: T2. 2
Proof: Part (1) follows by an easy induction on subtyping derivations. The only
interesting case is the rule S-TRANS, which proceeds by two uses of the induction
hypothesis, first on the right premise and then on the left. The arguments for the
other parts are similar (part (1) is used in the transitivity cases). 2
20.4.9 Exercise: Show the following “left to right inversion” properties:
1. If   ` S1!S2 <: T, then either T = Top or else T = T1!T2 with   ` T1 <: S1
and   ` S2 <: T2.
2. If   ` 8X<:U.S2 <: T, then either T = Top or else T = 8X<:U.T2 with  ; X<:U `
S2 <: T2.
3. If   ` X <: T, then either T = Top or T = X or   ` S <: T, where X<:S 2  .
4. If   ` Top <: T, then T = Top. 2
We use Lemma 20.4.8 for one straightforward structural property of the typing
relation that will be needed in the critical cases of the type preservation proof.
20.4.10 Lemma:
1. If   ` x:S1.s2 : T and   ` T <: U1!U2, then   ` U1 <: S1 and there is some
S2 such that  ; x:S1 ` s2 : S2 and   ` S2 <: U2.
2. If   ` X<:S1.s2 : T and   ` T <: 8X<:U1.U2, then U1 = S1 and there is some
S2 such that  ; X<:S1 ` s2 : S2 and  ; X<:S1 ` S2 <: U2. 2
Proof: Straightforward induction on typing derivations, using Lemma 20.4.8 for
the induction case (rule T-SUB). 2
With all these facts in-hand, the actual proof of type preservation is straightfor-
ward.
20.4.11 Theorem [Preservation]: If   ` t : T and   ` t  ! t 0, then   ` t 0 : T. 2
Proof: By induction on a derivation of   ` t : T. All of the cases are straightfor-
ward, using the facts established in the above lemmas.
January 15, 2000 20. BOUNDED QUANTIFICATION 170
Case T-VAR: t = x
This case cannot actually arise, since we assumed   ` t  ! t 0 and there are no
evaluation rules for variables.
Case T-ABS: t = x:T1.t2
Ditto.
Case T-APP: t = t1 t2   ` t1 : T11!T12
T = T12   ` t2 : T11
By the definition of the evaluation relation, there are three subcases to consider:
Subcase:   ` t1  ! t 01 t 0 = t 01 t2
Then the result follows from the induction hypothesis and T-APP.
Subcase: t1 is a value   ` t2  ! t 02 t 0 = t1 t 02
Similar.
Subcase: t1 = x:U11.u12 t 0 = fx 7! t2gu12
By Lemma 20.4.10,  ; x:U11 ` u12 : U12 with   ` T11 <: U11 and   ` U12 <: T12.
By the preservation of typing under substitution (Lemma 20.4.5),   ` fx 7!
t2gu12 : U12, from which   ` fx 7! t2gu12 : T12 follows by T-SUB.
Case T-TABS: t = X<:U.t
Can’t happen.
Case T-TAPP: t = t1 [T2]   ` t : 8X<:T11.T12
T = fX 7! T2gT12   ` T2 <: T11
By the definition of the evaluation relation, there are two subcases to consider:
Subcase: t1  ! t 01 t 0 = t 01 [T2]
The result follows from the induction hypothesis and T-TAPP.
Subcase: t1 = X<:U11.u12 t 0 = fX 7! T2gu12
By Lemma 20.4.10, U11 = T11 and  ; X<:U11 ` u12 : U12 with  ; X<:U11 `
U12 <: T12. By the preservation of typing under substitution (20.4.5),   ` fX 7!
T2gu12 : fX 7! T2gU12, from which   ` fX 7! T2gu12 : fX 7! T2gT12 follows by
Lemma 20.4.6 and T-SUB.
Case T-SUB:   ` t : S   ` S <: T
By the induction hypothesis,   ` t0 : S; the result follows by T-SUB. 2
20.4.12 Exercise: Show how to extend the argument in this section to Ff<:. 2
January 15, 2000 20. BOUNDED QUANTIFICATION 171
20.5 Bounded Existential Types
This final section remains to be written.
Bounded existential quantification F k
<:
+ 9
New syntactic forms
T ::= ... (types...)
{9X <:T ,T} existential type
New subtyping rules (  ` S <: T)
 ; X<:U ` S2 <: T2
  ` {9X<:U,S2} <: {9X<:U,T2}
(S-SOME)
New typing rules (  ` t : T)
  ` t2 : fX 7! UgT2   ` U <: T1
  ` {9X=U,t2} as {9X <:T1 ,T2} : {9X <:T1 ,T2}
(T-PACK)
  ` t1 : 9X <:T11 .T12  ; X <:T11 ; x:T12 ` t2 : T2
  ` let {X,x}=t1 in t2 : T2
(T-UNPACK)
20.5.1 Exercise: Show how the subtyping rule S-SOME can be obtained from the
subtyping rules for universals by extending the encoding of existential types in
terms of universal types described in Section 19.3. 2
20.6 Historical Notes and Further Reading
The idea of bounded quantification was introduced by Cardelli and Wegner [CW85]
in the language Fun. (Their “Kernel Fun” calculus corresponds to our Fk
<:
.) Based
on informal ideas by Cardelli and formalized using techniques developed by Mitchell
[Mit84b], Fun integrated Girard-Reynolds polymorphism [Gir72, Rey74] with Cardelli’s
first-order calculus of subtyping [?, Car84]. The original Fun was simplified and
slightly generalized by Bruce and Longo [BL90], and again by Curien and Ghelli [CG92],
yielding the calculus we call Ff<:.
The most comprehensive single paper on bounded quantification is the survey
by Cardelli, Martini, Mitchell, and Scedrov [CMMS94].
Fun and its relatives have been studied extensively by programming language
theorists and designers. Cardelli and Wegner’s survey paper gives the first pro-
gramming examples using bounded quantification; more are developed in Cardelli’s
study of power kinds [Car88]. Curien and Ghelli [CG92, Ghe90] address a number
of syntactic properties of F<:. Semantic aspects of closely related systems have been
studied by Bruce and Longo [BL90], Martini [Mar88], Breazu-Tannen, Coquand,
January 15, 2000 20. BOUNDED QUANTIFICATION 172
Gunter, and Scedrov [BCGS91], Cardone [Car89], Cardelli and Longo [CL91], Cardelli,
Martini, Mitchell, and Scedrov [?], Curien and Ghelli [CG92, CG91], and Bruce and
Mitchell [BM92]. F<: has been extended to include record types and richer notions
of inheritance by Cardelli and Mitchell [CM91], Bruce [Bru91], Cardelli [Car92],
and Canning, Cook, Hill, Olthoff, and Mitchell [CCH+89]. Bounded quantification
also plays a key role in Cardelli’s programming language Quest [Car91, CL91] and
in the Abel language developed at HP Labs [CCHO89, CCH+89, CHO88, CHC90].
The undecidability of full F<: was shown by Pierce [Pie94] and further analyzed
by Ghelli [Ghe95].
The effect of bounded quantification on Church encodings of algebraic datatypes
(cf. Section 20.3) was considered by Ghelli thesis [Ghe90] and Cardelli, Martini,
Mitchell, and Scedrov [CMMS94].
An extension of F<: with intersection types was studied by Pierce [Pie91a, Pie97]
and applied to the modeling of object-oriented languages with multiple inheri-
tance by Compagnoni and Pierce [CP96].
Chapter 21
Implementing Bounded
Quantification
Next we consider the problem of building a typechecking algorithm for a language
with bounded quantifiers. The algorithm that we construct will be parametric in
an algorithm for the subtype relation, which we consider in the following section.
21.1 Promotion
In the typechecking algorithm for <: in Section 13.2, the key idea was that we can
calculate a minimal type for each term from the minimal types of its subterms. We
will use the same basic idea to typecheck Fk
<:
, but we need to take into account one
slight complication arising from the presence of type variables in the system.
Consider the term
f = X<:Nat!Nat. y:X. y 5;
I f : 8X<:Nat!Nat. X ! Nat
This term is clearly well typed, since the type of the variable y in the application
(y 5) is X, which can be promoted to Nat!Nat by T-SUB. But the minimal type
of y is not an arrow type. In order to find the minimal type of the application, we
need to find the minimal arrow type that y possesses—i.e., the minimal arrow type
that is a supertype of X. Not too surprisingly, the correct way to find this type is to
promote the minimal type of y until it is something other than a type variable.
Formally, write   ` S * T to mean “T is the least nonvariable supertype of S,”
defined by repeated promotion of variables as follows:
173
January 15, 2000 21. IMPLEMENTING BOUNDED QUANTIFICATION 174
Exposure
Exposure (   `I T * T 0)
X<:T 2     `I T * T 0
  `I X * T 0 (XA-PROMOTE)
T is not a type variable
  `I T * T (XA-OTHER)
It is easy to check that these rules define a total function. Moreover, the re-
sult of promotion is always the least supertype that has some shape other than a
variable.
21.1.1 Lemma: Suppose   ` S * T.
1.   ` S <: T.
2. If   ` S <: U and U is not a variable, then   ` T <: U. 2
Proof: Part (1) is easy. Part (2) goes by straightforward induction on a derivation
of   ` S <: U. 2
21.2 Minimal Typing
The algorithm for calculating minimal types is built along the same basic lines as
the one for <:, with one additional twist: the minimal type of a term may always
be a type variable, and such a type will need to be promoted to its smallest non-
variable supertype (its smallest concrete supertype, we might say) in order to be
used on the left of an application or type application.
Algorithmic typing
Algorithmic typing (  `I t : T)
x:T 2  
  `I x : T
(TA-VAR)
 ; x:T1 `I t2 : T2
  `I x:T1.t2 : T1!T2 (TA-ABS)
  `I t1 : T1   `I T1 * (T11!T12)   `I t2 : T2   `I T2 <: T11
  `I t1 t2 : T12
(TA-APP)
January 15, 2000 21. IMPLEMENTING BOUNDED QUANTIFICATION 175
 ; X <:T1 `I t2 : T2
  `I X <:T1 .t2 : 8X <:T1 .T2
(TA-TABS)
  `I t1 : T1   `I T1 * 8X<:T11.T12   `I T2 <: T11
  `I t1 [T2] : fX 7! T2gT12 (TA-TAPP)
The proofs of soundness and completeness of this algorithm with respect to the
original typing rules are fairly routine.
21.2.1 Theorem [Minimal typing]:
1. If   `I t : T, then   ` t : T.
2. If   ` t : T, then   `I t : M where   ` M <: T. 2
Proof: Part (1) proceeds by a straightforward induction on algorithmic deriva-
tions. Part (2) is more interesting; it goes by induction on a derivation of   ` t : T.
(The most important cases are those for the rules T-APP and T-TAPP.)
Case T-VAR: t = x x:T 2  
By TA-VAR,   `I x : T. By S-REFL,   ` T <: T.
Case T-ABS: t = x:T1.t2  ; x:T1 ` t2 : T2 T = T1!T2
By the induction hypothesis,  ; x:T1 `I t2 : M2 for some M2 with  ; x:T1 ` M2 <: T2,
i.e. (since subtyping does not depend on term variable bindings),   ` M2 <: T2. By
TA-ABS,   ` t : T1!M2. Finally, by S-REFL and S-ARROW, we have   ` T1!M2 <:
T1!T2.
Case T-APP: t = t1 t2   ` t1 : T11!T12
T = T12   ` t2 : T11
By the induction hypothesis, we have   `I t1 : M1 and   `I t2 : M2, with   ` M1 <:
T11!T12 and   ` M2 <: T11. Let N1 be the least nonvariable supertype of M1—i.e.,
suppose   ` M1 * N1. By the promotion lemma (21.1.1),   ` N1 <: T11!T12. But
we know that N1 is not a variable, so the inversion lemma for the subtype relation
(20.4.8) tells us that N1 = N11!N12, with   ` T11 <: N11 and   ` N12 <: T12. By
transitivity,   ` M2 <: N11, so rule TA-APP applies and gives us   `I t1 t2 : N12,
which satisfies the requirements.
Case T-TABS: t = X<:T1.t2  ; X<:T1 ` t2 : T2 T = 8X<:T1.T2
By the induction hypothesis,  ; X<:T1 `I t2 : M2 for some M2 with  ; X<:T1 ` M2 <:
T2. By TA-TABS,   `I t : 8X<:T1.M2. Finally, by S-REFL and S-ALL, we have
  ` 8X<:T1.M2 <: 8X<:T1.T2.
January 15, 2000 21. IMPLEMENTING BOUNDED QUANTIFICATION 176
Case T-TAPP: t = t1 [T2]   ` t1 : 8X<:T11.T12
T = fX 7! T2gT12   ` T2 <: T11
By the induction hypothesis, we have   `I t1 : M1, with   ` M1 <: 8X<:T11.T12.
Let N1 be the least nonvariable supertype of M1—i.e., suppose   ` M1 * N1. By
the promotion lemma (21.1.1),   ` N1 <: 8X<:T11.T12. But we know that N1 is
not a variable, so the inversion lemma for the subtype relation (20.4.8) tells us that
N1 = 8X<:N11.N12, with N11 = T11 and  ; X<:T11 ` N12 <: T12. Rule TA-TAPP
gives us   `I t1 [T2] : fX 7! T2gN12, and the preservation of subtyping under
substitution (20.4.6) yields   ` fX 7! T2gN12 <: fX 7! T2gT12 = T.
Case T-SUB:   ` t : S   ` S <: T
By the induction hypothesis,   `I t : M with   ` M <: S. By S-TRANS,   ` M <: T,
from which T-SUB yields the desired result. 2
21.2.2 Corollary [Decidability of typing]: The Fk
<:
typing relation is decidable (if
we are given a decision procedure for the subtyping relation). 2
Proof: Given   and t, we can check whether there is some T such that   ` t : T by
using the algorithmic typing rules to generate a proof of   `I t : T. If we succeed,
then this T is also a type for T in the original typing relation (by part (1) of 21.2.1). If
not, then part (2) of 21.2.1 implies that t has no type in the original typing relation.
Finally, note that the algorithmic typing rules constitute a terminating algo-
rithm, since they are syntax-directed and always reduce the size of t when read
from bottom to top. 2
21.2.3 Exercise: Show how to add primitive booleans and conditionals to the min-
imal typing algorithm for Fk
<:
. (Solution on page 261.) 2
21.3 Subtyping in Fk
<:
As we saw in the simply typed lambda-calculus with subtyping, the subtyping
rules in their present form do not constitute an algorithm for deciding the subtyp-
ing relation. We cannot use them “from bottom to top,” for two reasons:
1. There are some overlaps between the conclusions of different rules (specifi-
cally, between S-REFL and nearly all the other rules). That is, looking at the
form of a derivable subtyping statement   ` S <: T, we cannot decide which
of the rules must have been used last in deriving it.
2. More seriously, one rule (S-TRANS) contains a metavariable in the premises
that does not appear in the conclusion. To apply this rule from botom to top,
we’d need to guess what type to replace this metavariable with.
January 15, 2000 21. IMPLEMENTING BOUNDED QUANTIFICATION 177
The overlap between S-REFL and the other rules is easily dealt with, using ex-
actly the same technique as we used in Chapter 13: we remove the full reflexivity
rule and replace it by a restricted reflexivity rule that applies only to type variables.
  ` X <: X
Next we must deal with S-TRANS. Unfortunately, unlike the simple subtyping
relation studied in Chapter 13, the transitivity rule here interacts in an important
way with another rule—namely S-TVAR, which allows assumptions about type
variables to be used in deriving subtyping statements. For example, if
  = W<:Top; X<:W; Y<:X; Z<:Y
then the statement
  ` Z <: W
is provable using all the subtyping rules, but cannot be proved if S-TRANS is re-
moved. That is, an instance of S-TRANS whose left-hand subderivation is an in-
stance of the axiom S-TVAR, as in
(S-TVAR)
  ` Z <: Y
...
  ` Y <: W
(S-TRANS)
  ` Z <: W
cannot, in general, be eliminated.
Fortunately, it turns out that derivations of this form are the only essential uses
of transitivity in subtyping. This observation can be made precise by introducing
a new subtyping rule
X<:U 2     ` U <: T
  ` X <: T
that captures exactly this pattern of variable lookup followed by transitivity, and
showing (as we will do below) that replacing the transitivity and variable rules by
this one does not change the set of derivable subtyping statements.
These intuitions are summarized in the following definition. The algorithmic
subtype relation of Fk
<:
is the least relation closed under the following rules:
Algorithmic subtyping
Algorithmic subtyping (   `I S <: T)
  `I S <: Top (SA-TOP)
  `I X <: X (SA-REFL-TVAR)
X<:U 2     `I U <: T
  `I X <: T
(SA-TRANS-TVAR)
January 15, 2000 21. IMPLEMENTING BOUNDED QUANTIFICATION 178
  `I T1 <: S1   `I S2 <: T2
  `I S1!S2 <: T1!T2 (SA-ARROW)
 ; X<:U1 `I S2 <: T2
  `I 8X<:U1.S2 <: 8X<:U1.T2
(SA-ALL)
21.3.1 Lemma [Reflexivity of the algorithmic subtype relation]: The statement   `I
T <: T is provable for all   and T. 2
Proof: Easy induction on T. 2
21.3.2 Lemma [Transitivity of the algorithmic subtype relation]: If   `I S <: Q
and   `I Q <: T, then   `I S <: T. 2
Proof: By induction on the sum of the sizes of the two derivations. Given two
derivations of some total size, we proceed by considering the final rules in each.
First, if the right-hand derivation is an instance of SA-TOP, then we are done,
since   ` S <: Top by SA-TOP. Moreover, if the left-hand derivation is an instance
of SA-TOP, then Q = Top and by looking at the algorithmic rules we see that the
right-hand derivation must also be an instance of SA-TOP.
If either derivation is an instance of SA-REFL-TVAR, then we are again done
since the other derivation is the desired result.
Next, if the left-hand derivation ends with an instance of SA-TRANS-TVAR,
then S = X with X<:U 2   and we have a subderivation with conclusion   ` U <: Q.
By the induction hypothesis,   `I U <: T, and, by SA-TRANS-TVAR again,   `I X <:
T, as required.
If the left-hand derivation ends with an instance of SA-ARROW, then we have
S = S1!S2 and Q = Q1!Q2, with subderivations   `I Q1 <: S1 and   `I S2 <: Q2.
But, since we have already considered the case where the right-hand derivation is
SA-TOP, the only remaining possibility is that the right-hand derivation also ends
with SA-ARROW; we therefore have T = T1!T2, and two more subderivations
  `I T1 <: Q1 and   `I Q2 <: T2. We now apply the induction hypothesis twice,
obtaining   `I T1 <: S1 and   `I S2 <: T2. Finally, SA-ARROW yields   `I S1!S2 <:
T1!T2, as required.
The case where the left-hand derivation ends with an instance of SA-ALL is
similar. 2
21.3.3 Theorem [Soundness and completeness of algorithmic subtyping]:
1. If   ` S <: T then   `I S <: T.
2. If   `I S <: T then   ` S <: T. 2
January 15, 2000 21. IMPLEMENTING BOUNDED QUANTIFICATION 179
Proof: Both directions proceed by induction on derivations. Soundness is routine.
Completeness is also straightforward, since we have already done the hard work
(for the reflexivity and transitivity rules of the original subtype relation) in Lem-
mas 21.3.1 and 21.3.2. 2
Finally, we should check that the subtyping rules define an algorithm that is
total—i.e., that always terminates no matter what input it is given. We do this by
assigning a weight to each subtyping statement, and checking that the algorithmic
rules all have conclusions with greater weight than their premises.
21.3.4 Definition: The weight of a type T in a context  , written weight
 
(T), is de-
fined as follows:
weight
 
(X) = weight
 1
(U) + 1 if   =  1; X<:U;  2
weight
 
(Top) = 1
weight
 
(T1!T2) = weight (T1) + weight (T2) + 1
weight
 
(8X<:T1.T) = weight ; X<:T1(T2) + 1
The weight of a subtyping statement “  ` S <: T” is the maximum weight of S and
T in  . 2
21.3.5 Theorem: The weight of the conclusion in an instance of any of the algorith-
mic subtyping rules is strictly greater than the weight of any of the premises. 2
Proof: Straightforward inspection of the rules. 2
21.4 Subtyping in Ff
<:
The only difference in the full system Ff<: is that the quantifier subtyping rule S-ALL
is replaced by the more expressive variant:
  ` T1 <: S1  ; X<:T1 ` S2 <: T2
  ` 8X<:S1.S2 <: 8X<:T1.T2
(S-ALL)
The algorithmic subtype relation of Ff<: consists of exactly the same set of rules
as the algorithm for Fk
<:
, except that SA-ALL is refined to reflect the new version of
S-ALL:
  ` T1 <: S1  ; X<:T1 `I S2 <: T2
  `I 8X<:S1.S2 <: 8X<:T1.T2
(SA-ALL)
As with Fk
<:
, the soundness and completeness of this algorithmic relation with
respect to the original subtype relation can be shown easily, once we have estab-
lished that the algorithmic relation is reflexive and transitive. For reflexivity, the
argument is exactly the same as before. For transitivity, on the other hand, the
issues are more subtle.
January 15, 2000 21. IMPLEMENTING BOUNDED QUANTIFICATION 180
21.4.1 Lemma [Transitivity and narrowing]:
1. If   `I S <: Q and   `I Q <: T, then   `I S <: T.
2. If  ; X<:Q;  `I M <: N and   `I P <: Q then  ; X<:P;  `I S <: T. 2
Proof: The two parts are proved simultaneously, by induction on the size of Q. At
each stage of the induction, the argument for part (2) assumes that part (1) has been
established already for the Q in question; part (1), on the other hand, uses part (2)
only for strictly smaller Qs.
1. Most of the argument is identical to the proof of 21.3.2. The only differ-
ence lies in the case where both of the given derivations end in instances
of SA-ALL. In this case, we have
S = 8X<:S1.S2
Q = 8X<:Q1.Q2
T = 8X<:T1.T2
  ` Q1 <: S1
 ; X<:Q1 `I S2 <: Q2  ` T1 <: Q1
 ; X<:T1 `I Q2 <: S2
as subderivations. By part (1) of the induction hypothesis, we can immedi-
ately combine the three subderivations for the bounds to obtain   `I T1 <: S1.
For the bodies, we need to work a little harder, since the two contexts do
not quite agree. We first use part (2) of the induction hypothesis to “nar-
row” the bound of X in the derivation of  ; X<:Q1 `I S2 <: Q2, obtaining
 ; X<:T1 `I S2 <: Q2. Now part (1) of the induction hypothesis applies, yield-
ing  ; X<:T1 `I S2 <: T2. Finally, by SA-ALL,   `I 8X<:S1.S2 <: 8X<:T1.T2,
as required.
2. Given Q of a certain size, we use an inner induction on the size of a derivation
of  ; X<:Q;  `I S <: T, with a case analysis on the last rule used in this
derivation.
The only interesting case is SA-TRANS-TVAR, where S = X and  ; X<:Q;  `I
Q <: T as a subderivation. By the inner induction hypothesis,  ; X<:P;  `I
Q <: T. Rule SA-TRANS-TVAR now yields  ; X<:P;  `I X <: T, as required. 2
21.4.2 Exercise: Show that Fk
<:
has joins and bounded meets. (Solution on page 261.)
2
21.4.3 Exercise: Consider the types (due to Ghelli [Ghe90, p. 92])
S = 8X<:Y!Z.Y!Z
January 15, 2000 21. IMPLEMENTING BOUNDED QUANTIFICATION 181
and
T = 8X<:Y0!Z 0.Y 0!Z 0
and the context   = Y<:Top; Z<:Top; Y 0<:Y; Z 0<:Z.
1. In Ff<:, how many types are subtypes of both S and T under  .
2. Show that, in Ff<:, the types S and T have no meet under  .
3. Exhibit a pair of types that has no join (under  ) in Ff<:.
(Solution on page 265.) 2
21.5 Undecidability of Subtyping in Full F<:
Unfortunately, the proof of termination of the Fk
<:
subtyping algorithm in Section ??
does not work for Ff<:.
21.5.1 Exercise [Quick check]: Why not? 2
In fact, not only does this particular proof technique not work—the subtyping
algorithm actually does not terminate on some inputs. Here is an example, due
to Ghelli [Ghe95], that makes the algorithm diverge. First define the following
abbreviation:
:S
def
= 8X<:S.X:
21.5.2 Fact:   ` :S <: :T iff   ` T <: S. 2
Proof: Exercise. 2
Now, define a type T as follows:
T = 8X<:Top. :(8Y<:X.:Y):
If we use the algorithmic subtyping rules bottom-to-top to attempt to construct a
subtyping derivation for the statement
X0<:T ` X0 <: (8X1<:X0.:X1)
we end up in an infinite regress of larger and larger “subgoals”:
X0<:T ` X0 <: (8X1<:X0.:X1)
X0<:T ` 8X1<:Top. :(8X2<:X1.:X2) <: (8X1<:X0.:X1)
X0<:T; X1<:X0 ` :(8X2<:X1.:X2) <: :X1
X0<:T; X1<:X0 ` X1 <: (8X2<:X1.:X2)
X0<:T; X1<:X0 ` X0 <: (8X2<:X1.:X2)
etc.
January 15, 2000 21. IMPLEMENTING BOUNDED QUANTIFICATION 182
The -conversion steps necessary to maintain the well-formedness of the context
when new variables are added are performed tacitly here, choosing new names
so as to clarify the pattern of regress. The crucial trick is the “re-bounding” that
occurs, for instance, between the second and third lines, where the bound of X1
on the left-hand side is changed from Top in line 2 to X0 in line 3. Since the whole
left-hand side in line 2 is itself the upper-bound of X0, the re-bounding creates a
cyclic pattern where longer and longer chains of variables in the context must be
traversed on each loop. (The reader is cautioned not to look for semantic intuitions
behind this example; in particular, :T is a negation only in the sense that it allows
the left- and right-hand sides of subtyping judgements to be swapped.)
Worse yet, not only does this particular algorithm fail to terminate on some in-
puts, it can be shown [Pie94] that there is no algorithm that is sound and complete
for the original Ff<: subtyping relation and that terminates on all inputs.
The full proof of this fact is beyond the scope of this book (the argument re-
quires no particularly deep mathematics, but takes several pages to develop). How-
ever, to give a little of its flavor, let’s look at one more example.
21.5.3 Definition: The positive and negative occurences in a type T are defined as
follows:
 T itself is a positive occurence in T.
 If T1!T2 is a positive (respectively, negative) occurrence, then T1 is a nega-
tive (resp. positive) occurrence and T2 is a positive (negative) occurrence.
 If 8X<:T1.T2 is a positive (respectively, negative) occurrence, then T1 is a neg-
ative (resp. positive) occurrence and T2 is a positive (negative) occurrence.
The positive and negative occurences in a subtyping statement   ` S <: T are
defined as follows: the type S and the bounds of type variables in   are negative
occurrences. The type T is a positive occurrence. 2
The words “positive” and “negative” come from logic. According to the well-
known “Curry-Howard isomorphism” [How80, CF58] between propositions and
types, the type S!T corresponds to the logical proposition S ) T, which, by the
definition of logical implication, is equivalent to :S _ T. The subproposition S
here is obviously in a “negative” position—that is, inside of an odd number of
negations—if and only if the whole implication appears inside an even number of
negations.
21.5.4 Fact: If X occurs only positively in S and negatively in T, then X<:U ` S <: T
iff ` fX 7! UgS <: fX 7! UgT. 2
Proof: Exercise. 2
January 15, 2000 21. IMPLEMENTING BOUNDED QUANTIFICATION 183
Now, let T be the following (pretty horrible) type
T = 8X0<:Top.8X1<:Top.8X2<:Top.
:(8Y0<:X0.8Y1<:X1.8Y2<:X2.:X0)
and consider the subtyping statement
` T
<: 8X0<:T.8X1<:P.8X2<:Q.
:(8Y0<:Top.8Y1<:Top.8Y2<:Top.
:(8Z0<:Y0.8Z1<:Y2.8Z2<:Y1. U)):
We can think of this statement as a description of the state of a simple computer:
 The variables X1 and X2 are the “registers” of this machine. Their current
contents are the types P and Q.
 The “instruction stream” of the machine is the last line of the statement: the
first instruction is encoded in the bounds (Y2 and Y1—note their order!) of
the variables Z1 and Z2, and the type U is the remaining instructions in the
program.
 The type T, the nested negations, and the bound variables X0 and Y0 here play
much the same role as their counterparts in the simpler example above: they
allow us to “turn the crank” and get back to a subgoal of the same shape as
the original goal. One turn of the crank will correspond to one cycle of our
machine.
In this example, the instruction at the front of the instruction stream encodes the
command “switch the contents of registers 1 and 2.” To see this, we use the two
facts stated above to calculate as follows. (The values P and Q in the two registers
are highlighted, to make them easier to track through the derivation.)
` T
<: 8X0<:T.8X1<: P .8X2<: Q .
:(8Y0<:Top.8Y1<:Top.8Y2<:Top.
:(8Z0<:Y0.8Z1<:Y2.8Z2<:Y1. U))
iff ` :(8Y0<:T.8Y1<: P .8Y2<: Q .:T)
<: :(8Y0<:Top.8Y1<:Top.8Y2<:Top.
:(8Z0<:Y0.8Z1<:Y2.8Z2<:Y1. U))
by Fact 21.5.4
iff ` (8Y0<:Top.8Y1<:Top.8Y2<:Top.
:(8Z0<:Y0.8Z1<:Y2.8Z2<:Y1. U))
<: (8Y0<:T.8Y1<: P .8Y2<: Q .:T) by Fact 21.5.2
iff ` :(8Z0<:T.8Z1<: Q .8Z2<: P . U))
<: :T by Fact 21.5.4
iff ` T
<: (8Z0<:T.8Z1<: Q .8Z2<: P . U)) by Fact 21.5.2
January 15, 2000 21. IMPLEMENTING BOUNDED QUANTIFICATION 184
Note that, at the end of the derivation, not only have the values P and Q switched
places, but the instruction that caused this to happen has been used up in the pro-
cess, leaving U at the front of the instruction stream to be “executed” next. By
choosing a value of U that begins in the same way as the instruction we just exe-
cuted
U = :(8Y0<:Top.8Y1<:Top.8Y2<:Top.
:(8Z0<:Y0.8Z1<:Y2.8Z2<:Y1. U 0))
we can perform another swap and return the registers to their original state before
continuing with U0. More interestingly, we can choose other values for U that cause
different sorts of behavior. For example, if
U = :(8Y0<:Top.8Y1<:Top.8Y2<:Top.
:(8Z0<:Y0.8Z1<:Y1.8Z2<:Y2. Y1))
then, on the next cycle of the machine, the current value of register 1 (Q) will appear
in the position of U—in effect, performing an “indirect branch” through register 1
to the stream of instructions Q. Conditional constructs and arithmetic (successor,
predecessor, and zero-test) can be encoded using a generalization of this trick.
Putting all of this together, we arrive at a proof of undecidability, via a reduc-
tion from two-counter machines—a simple variant on ordinary turing machines,
consisting of a finite control and two counters, each holding a natural number
(cf. [HU79], for example)—to subtyping statements.
21.5.5 Theorem [Undecidability]: For each two-counter machine M, there exists a
subtyping statement S(M) such that S(M) is derivable in Ff<: iff the execution of M
halts. 2
Thus, if we could decide whether any subtype statement is provable, then we
could also decide whether any given two-counter machine will eventually halt.
21.5.6 Exercise [Challenging]:
1. Define a variant of Ff<: with no Top type but with both X<:T and X bindings.
2. Show that the subtype relation for this system is decidable.
3. Does this restriction offer a satisfactory solution to the basic problem? In par-
ticular, does it work for languages with additional features such as numbers,
records, variants, etc.?
(Hint on page 265.) 2
Chapter 22
Denotational Semantics
By Martin Hofmann and Benjamin Pierce
Some notation is out of date in this chapter.
Denotational semantics is a compositional assigment of mathematical objects to
program phrases (terms, types, and typing and subtyping statements). Composi-
tionality means that the meaning of a phrase is defined in terms of its outermost
constructor and the meanings of its immediate subphrases.
The foremost and easiest application of semantics is demonstrating the sound-
ness and consistency of equational theories—in particular, the one generated by
the reduction rules. (To show that the equational theory is sound, we show that
terms equated by the theory have equal interpretations; to show that it is consistent—
i.e., that not all terms are equated by the equational theory—it suffices to exhibit
two terms with different interpretations.) Semantic models can also suggest exten-
sions to the syntax, in particular program logics.
If a semantics is “computationally adequate” (we’ll come back to this term later
on), it can also be used to reason about observational equivalence of programs.
For example, it is intuitively the case that the two records p = {x=0,y=0} and
q = {x=0,y=1} are equal when used at type {x:Nat}, because the only thing that
a program can do with a record of type {x:Nat} is to project out its x field, and
p.x = q.x = 0. The semantics we are going to develop will allow us to argue that,
indeed, p and q are observationally equivalent at type {x:Nat}, i.e., that for every
closed term c : {x:Nat}!Nat, the terms c p and c q of type Nat yield the same
result.
Finally, in some cases a (non-standard) semantics can be employed to establish
syntactic meta-properties such as normalization or confluence.
185
January 15, 2000 22. DENOTATIONAL SEMANTICS 186
22.1 Types as Subsets of the Natural Numbers
In building semantic models of programming languages, types are commonly mod-
eled as sets (or, if the language includes recursion, “domains”); closed terms are
modeled as elements of the appropriate sets, open terms as functions of the in-
terpretations of their free variables. For example, a straightforward model of the
simply typed lambda-calculus can be obtained by interpreting base types as arbi-
trary sets (e.g. [[Nat]] = N) and each function type S!T as the set of functions from
[[S]] to [[T]].
For F<:, a more refined framework is required, due principally to the impredica-
tivity of the universal quantifier in System F—the fact that the bound type variable
in a type 8[X]T ranges over all types, including 8[X]T itself. Accordingly, in a
simple set-theoretic model, the first candidate for an intepretation of a universal
type would be a function whose domain is the set of all sets; such a function can-
not exist, for cardinality reasons. A more refined strategy would be to restrict the
domain of polymorphic functions to only those sets which actually arise as inter-
pretations of types in our programming language. However, Reynolds [Rey84, RP]
has shown that, no matter how we interpret universal types, there cannot exist a
model of System F in which a function type S!T is interpreted as the full set of
functions from [[S]] to [[T]]. Intuitively, what Reynolds shows is that there is a type1
R in System F whose interpretation must be the same size as the function space
(R!Bool)!Bool; the fact that no such set exists is a direct consequence of Rus-
sell’s Paradox.
The key to a successful interpretation of F<: lies in the observation that the func-
tions we are interested in always arise as the interpretations of finite expressions
in our programming language—they are “algorithms,” not arbitrary set-theoretic
functions. This means that we may restrict the interpretations of types to subsets
of some a priori given universe of data values and algorithms; universal quantifiers
may now be taken to range over the subsets of this set.
The Universe of Natural Numbers
A convenient choice for the universe of data values and algorithms is the set N
of natural numbers. As is well known, all flat datatypes such as integers, strings,
lists, floating point numbers, etc. can be encoded as natural numbers.2
We will not need to be too formal, here, about the precise encoding of algo-
rithms as numbers. We just assume that
1. we are given some way of intepreting a number n as a partial function fng
from numbers to numbers, and that
1Namely R = 8[X] (((X!Bool)!Bool) ! X) ! X.
2For example, a pair (m;n) of numbers can be encoded as 2m  (2  n+ 1).
January 15, 2000 22. DENOTATIONAL SEMANTICS 187
2. every “intuitively computable partial function” f on the natural numbers is
represented by some number n, in the sense that fng(m) = f(m) (where by
the equality symbol here we mean the so-called “Kleene equality”: either
both fng(m) and f(m) are undefined, or both are defined and they are equal).
We write x: g(x) for the number representing the function mapping each x to
g(x), where g(x) is some concrete description of a computable function.
Subset Semantics for F<:
We can obtain a simple semantics for F<: in this setting by interpreting types as sub-
sets of N and terms as elements of the meaning of their types. More formally, the
interpretation of simple types (i.e., the types of the simply typed lambda-calculus)
is given by the following recursive definition:
[[Nat]] = N
[[Top]] = N
[[S!T]] = ft j 8x 2 [[S]]: ftg(x) 2 [[T]]g
[[{l1:T1...ln:Tn}]] = ft j 8li 2 fl1 : : : lng: ftg(li) 2 [[Ti]]g:
A few comments about this definition are in order:
 By convention, a statement like ftg(x) 2 [[T]] means, in particular, that ftg(x) is
defined. Thus, if t 2 [[S!T]], then ftg is defined whenever it is applied to an
element of [[S]].
In other words, although we are interpreting the elements of N as partial
functions, the interpretations of types turn out to be functions that are total
on the elements of their domains.
 For notational convenience, we assume that record labels are drawn from
N, so that records can be modeled as partial functions on numbers and field
projection as application.
In order to interpret types containing variables, we must parameterize the above
definition with an environment mapping type variables to subsets of N and (for
subsequent use) term variables to natural numbers. We parameterize the above
definition by an environment 
[[Nat]] = N
[[Top]] = N
[[S!T]] = ft j 8x 2 [[S]]: ftg(x) 2 [[T]]g
[[{l1:T1...ln:Tn}]] = ft j 8li 2 fl1 : : : lng: ftg(li) 2 [[Ti]]g
and add appropriate clauses for type variables and universal types:
[[X]] = (X)
[[8[X<:S]T]] = ft j 8U  [[S]]: t 2 [[T]]+fX7!Ugg
that is,
T
U[[S]]
[[T]]+fX7!Ug
January 15, 2000 22. DENOTATIONAL SEMANTICS 188
Similarly we define the meaning of terms:
[[x]] = (x)
[[0]] = 0
[[succ t]] = [[t]] + 1
[[iter T t1 t2 t3]] = [[t2]]
n
 ([[t3]]); where n = [[t1]]
[[t.l]] = f[[t]]g(l)
[[{li=ti}]] = l: if l = li then [[ti]] else undefined
[[t t 0]] = f[[t]]g([[t
0]])
[[fun[x:S]t]] = v: [[t]]+fx7!vg
[[fun[X<:S]t]] = [[t]]
[[t S]] = [[t]]
Notice that the meaning [[t]] only depends on the restriction of  to term vari-
ables; the interpretation of types, even of those which occur as annotations in t, is
irrelevant.
Notice also that the semantics of a term may be undefined either because one of
its variables is not declared in the environment or because one of the semantic ap-
plications is undefined. Our aim is to formulate a soundness theorem which states
that the meaning of every well-typed term is defined and is contained in the mean-
ing of its type. To this end, we need to define what it means for an environment to
match a typing context.
22.1.1 Definition: Let  be an environment and   be a context. Say that  satisfies  
(written  j=  ) if, whenever X<:S occurs in  , we have (X) and [[S]] both defined
and the former a subset of the latter and, similarly, whenever x:S occurs in  , we
have (x) and [[S]] both defined with the former an element of the latter. 2
22.1.2 Theorem [Soundness]: If   is a context and  an environment satisfying  ,
then:
1. If all the free type variables in S appear in dom( ) then [[S]] is defined.
2. If   ` S<:T then [[S]]  [[T]].
3. If   ` t 2 S then [[t]] is an element of [[S]]. 2
The proof is by induction on derivations. The most important ingredient is the
following substitution lemma.
22.1.3 Lemma [Semantic substitution]:
1. If [[S]]+fX7![[T]]g is defined, then so is [[fX 7! TgS]] and they are equal.
2. If [[t]]+fx7![[t 0]]g is defined, then so is [[fx 7! t 0gt]] and they are equal. 2
January 15, 2000 22. DENOTATIONAL SEMANTICS 189
Proof: By induction on types (part 1) or terms (part 2). 2
Notice that this substitution lemma is nothing but a formalisation of the re-
quirement of compositionality mentioned in the introduction to this chapter.
Proof of Theorem 22.1.2: Part (1) is by induction on types. Part (2) is by induction
on subtyping derivations (not necessarily algorithmic derivations: the transitivity
rule is not problematic). Part (3) is by induction on typing derivations. None of the
cases in these inductions are difficult; as examples, we show the cases for function
abstraction and type application in part (3).
For the function abstraction case, suppose that  ; x:S ` t : T and that  j=  .
Then [[fun[x:S]t]] = v: [[t]]+fx7!vg; call this number d. We must show d 2
[[S!T]]—that is, if a 2 [[S]], then fdg(a) is defined and belongs to [[T]]. Now, if
a 2 [[S]], then fdg(a) = [[t]]+fx7!ag. Since a 2 [[S]], the extended environment
 + fx 7! ag satisfies  ; x:S, so the induction hypothesis applies, yielding fdg(a) 2
[[T]], as required.
For the type application case, suppose that   ` t : 8[X<:S]T, that   ` U <: S,
and that  j=  . Part (2) gives us [[U]]  [[S]]. Using the induction hypothesis on t
and the interpretation of universal types, we obtain [[t]] 2 [[T]]+fX7![[U]]g. Thus, by
Lemma 22.1.3 and the interpretation of type application, we have [[t U]] = [[t]] 2
[[fX 7! UgT]]. 2
22.1.4 Exercise [Quick check]: How can it happen that [[fx 7! t 0gt]] is defined,
but [[t]]+fx7![[t 0]]g is not? 2
22.1.5 Exercise: Show the proofs of the cases for record and quantifier subtyping
for part (2) of the last proof. 2
An application of the subset model is that it can be used to decide whether
certain types are inhabited by any closed terms. For example, [[8[X<:Top]X]] =T
UNU is the empty set
3; so there can be no closed term of type 8[X<:Top]X,
because its interpretation would have to be an element of the empty set. Similarly,
the set [[8[X<:Top]8[Y<:Top]((X!Y)!(X!Y))!X!Y]]—the interpretation of the
type of the fixed-point combinator—is empty, which shows that the fixed-point
combinator cannot be interpreted in the subset model, and hence cannot be defined
in pure System F<:. This ties in with the observation made above that all functions
in the subset model are total.
3From here on, when the environment  in an expression [[T]] is empty, we will usually omit it.
January 15, 2000 22. DENOTATIONAL SEMANTICS 190
Problems with the Subset Semantics
Though it validates the typing, subtyping, and evaluation relations, the subset se-
mantics is unsatisfactory because it does not validate some of the rules of the re-
duction relation. More precisely, from
[[t]]+fx7!vg = [[t
0]]+fx7!vg for all v 2 [[S]]
we cannot conclude that
[[fun[x:S]t]] = [[fun[x:S]t
0]]:
For instance, we have [[0]]fx7!vg = 0 = [[(fun[y:Nat]0)x]]fx7!vg, but not necessarily
[[fun[x:Nat]0]] = [[fun[x:Nat] (fun[y:Nat]0)x]], because the semantical lambda
abstraction is defined on descriptions, not on actual functions. This possibility
represents a failure of extensionality of the semantics.
Another problem with the subset semantics is that, since subtypes are modeled
as subsets, the model fails to validate some expected typed equations between
records, such as the one we saw above:
{x=0,y=0} = {x=0,y=1} 2 {x:Nat}
22.2 The PER interpretation
We can obtain these missing equations by endowing each type interpretation with
its own “local” notion of equality. In the case of function types, this equality will be
defined in such a way that algorithms that map equal arguments to equal results
are regarded as equal. (This will solve both of the problems observed at the end of
the previous Section, since records are interpreted as partial functions on labels.)
22.2.1 Definition: A partial equivalence relation (PER) is a symmetric and transi-
tive relation (not, in general, reflexive) on the set N of natural numbers. 2
We write mRn when m and n are related by R; alternatively, we can view R as
a subset of N  N and write (m;n) 2 R. When R is a PER, we write dom(R) for
the set fn j nRng, the set of numbers related to themselves by R. Notice that R is
an equivalence relation on dom(R), so a PER can be thought of as consisting of a
subset of N together with a local equality relation. Also, note that if xRy then both
x and y are in dom(R).
If R and S are PERs, we write R  S to mean that R is a subrelation of S in the
set-theoretic sense—i.e., xRy implies xSy. This means that dom(S) is a superset of
dom(R) and that the equality in S on the common part is coarser than the one in R.
This will account for the “non-injective” nature of the subtyping relation between
record types (the fact that two different records in a type S can become equal when
viewed at a supertype T).
January 15, 2000 22. DENOTATIONAL SEMANTICS 191
Interpretation of Types
The types of F<: are interpreted as PERs as follows. (The environment  here as-
signs PERs, not just sets of numbers, to type variables—and, as before, natural
numbers to term variables.)
[[Nat]] = f(n;n) j n 2 Ng
[[Top]] = N  N (the everywhere-true relation)
[[S!T]] = f(t; t 0) j 8(x; x 0) 2 [[S]]: ftg(x)[[T]]ft 0g(x 0)g
[[{l1:T1...ln:Tn}]] = f(t; t
0) j 8li 2 fl1 : : : lng: (ftgli; ft 0gli) 2 [[Ti]]g
[[8[X<:S]T]] = f(t; t
0) j t[[T]]+fX7!Ugt
0 for all U  [[S]]g
that is,
T
U[[S]]

[[T]]+fX7!Ug
22.2.2 Exercise [Quick check]: Show that, if f; g 2 dom([[S!T]]), then f[[S!T]]g
iff f(a)[[T]]g(a) for all a 2 dom([[S]]). 2
The interpretation of terms is exactly as in the subset interpretation in Sec-
tion 22.1. To show that this interpretation is sound, we must slightly modify the
definition of satisfaction between environments and contexts: when x:S is a bind-
ing in  , we require that (x) 2 dom([[S]]).
22.2.3 Theorem [Semantic soundness of the PER intepretation]: The PER interpre-
tation is sound in the sense that all statements are validated semantically. If  j=  ,
then:
1.   ` S <: T implies [[S]]  [[T]];
2.   ` t : S implies [[t]] 2 dom([[S]]);
3. t  ! t 0, with   ` t : T and   ` t 0 : T, implies [[t]][[T]][[t 0]]. 2
Proof: Exercise. The argument is similar to the proof of 22.1.2. First, one estab-
lishes the validity of the semantic substitution lemma, replacing subsets by PERs.
The proofs then proceed by induction on derivations. In part (2), the statement
must be strengthened as follows:
2’. If  j=   and  0 j=  , and if (X) =  0(X) for all type variables X declared in
  and (x)[[S]]
0(x) for all term variable declarations x:S, then   ` t : S
implies [[t]][[S]][[t]] 0 .
Notice that [[S]] = [[S]] 0 2
One technical note is in order. Strictly speaking, the PER semantics does not
model reduction as equality, but rather as relatedness in a certain PER. If one de-
sires actual equality, one can decree that the meaning of a term is not a natural
number, but rather an equivalence class of natural numbers; then, however, the
meaning of a term depends on its type, which makes the interpretation of subtyp-
ing more complicated.
January 15, 2000 22. DENOTATIONAL SEMANTICS 192
Applications of the PER model
Now we come to the promised application of the PER model as a means to estab-
lish observational equivalence of programs. The main idea is that, at the atomic
type Nat, the semantic equality agrees with the syntactic equality given by the re-
duction relation.
22.2.4 Lemma: If t1 and t2 are closed terms of type Nat, then [[t1]][[Nat]][[t2]] im-
plies that t1 and t2 have the same number as normal form. 2
Proof: By the strong normalization of System F<: (Theorem ??) together with preser-
vation (??), t1 and t2 each have some number as normal form. By the soundness
theorem (22.2.3, part 3), the interpretation of a term is related to the interpretation
of its normal form, so the normal forms of t1 and t2 are related by [[Nat]], hence
equal. 2
The proof of this lemma relies heavily on the strong normalization of F<:. An
analogous property also holds in the absence of strong normalization (e.g., in the
presence of the fixed-point operator). Here, one must show that, if the interpreta-
tion of a term is a number, then the term admits a reduction to this number.
22.2.5 Exercise: Give this argument in detail. 2
22.2.6 Definition: Two closed terms t1, t2 of type S are observationally equiva-
lent at type S (written t1
obs
= S t2 or, when S is clear from context, just t1
obs
= t2) if,
for every closed term c : S!Nat, it holds that c t1 and c t2 reduce to the same
number. 2
The idea is that t1
obs
= t2 means that t1 and t2 can be replaced by one another
in an arbitrary program, since the visible output of a program must be a number.
22.2.7 Remark: This rather simple definition of observational equivalence relies
on the fact that there is a distinguished atomic type in which to make observations
and on the fact that open terms can be treated as closed terms using functional ab-
straction (so that we can regard every term containing t as a subphrase is equal to
an term of the form c t, where t does not occur in c). In more complex languages
where other binders are available, it may be necessary to extend the notion of ob-
servational equivalence to so-called contextual equivalence, where the observing
context is a term with a hole somewhere inside it. In particular, such a context may
bind free variables in the observed term. 2
22.2.8 Theorem [Computational adequacy]: Let t1 and t2 be closed terms of a
closed type S. If [[t1]][[S]][[t2]], then t1
obs
= S t2. 2
January 15, 2000 22. DENOTATIONAL SEMANTICS 193
Proof: Suppose t1; t2 : S and [[t1]][[S]][[t2]]. If c : S!Nat, then [[c]] 2 dom([[S!Nat]]).
Thus,
[[c t1]] = f[[c]]g([[t1]]) [[Nat]] f[[c]]g([[t2]]) = [[c t2]]:
Hence, by Lemma 22.2.4, c t1 and c t2 must have the same number as normal
form, and t1
obs
= t2. 2
The computational adequacy theorem shows how the PER model can be employed
to reason about observational equivalence. For example, the two records p =
{x=0,y=0} and q = {x=0,y=1} are observationally equivalent at type {x:Nat}.
To see this, note that [[p]][[{x:Nat}]][[q]], since f[[p]]g(x) = f[[q]]g(x).
22.2.9 Exercise [Recommended]:
1. Show that if e and f are closed, well typed terms, then e obs= Top f.
2. Show that whenever ` p : T where T = {l1:T1...ln:Tn}, we have p
obs
= T
{l1=p.l1...ln=p.ln}. 2
We now investigate observational equivalence at polymorphic types. As we
did with the subset semantics, we can use the PER semantics to argue that types
such as [[8[X] 8[Y] ((X!Y)!(X!Y))!X!Y]] are empty (showing that no fixed-
point operator can be defined). Unlike the subset model, though, the PER model
can also be used to constrain the elements of inhabited universal types, validating
some useful principles of uniformity.
22.2.10 Notation: To reduce clutter in the following, we will often abbreviate ftg(n)
by t n or t(n). 2
22.2.11 Proposition: Let S be an arbitrary type and U = [[8[X<:S]X!X]]. If f 2
dom(U), then f U x: x. 2
Proof: We must show that, for every PER X  [[S]] and every x 2 dom(X), we have
f(x) X x. From f 2 dom(U), we know that, for each PER Y  [[S]] and x 2 dom(Y),
we have f(x) 2 dom(Y). Suppose that X  [[S]] and x 2 dom(X). Choose Y  X  [[S]]
to be the singleton f(x; x)g. From x 2 dom(Y) we infer f(x) 2 dom(Y), so f(x) = x.
Thus, f(x) X x for every x 2 dom(X). 2
Notice that this excludes the possibility of “polymorphically updating” fields
of records in the PER model; for example, it follows by a similar argument that
every function of type 8[X<{x:Nat}]Nat!X must discard its Nat argument and
return its X argument unchanged. In particular, such a function cannot have the
effect of replacing the x field in its first argument by the number given as its sec-
ond argument. Also, notice that, by computational adequacy, every closed term
January 15, 2000 22. DENOTATIONAL SEMANTICS 194
of this type must be observationally equivalent to such a constant function. Poly-
morphic update can be supported by extending the syntax of F<:, as we shall see
in Chapter 23, but such extensions cannot be interpreted in the PER model as it
stands; it is, however, possible to construct a more refined PER model, using a
different interpretation of subtyping, in which polymorphic update functions do
exist [HP95, Pol96, ?].
Next we examine the interpretations of impredicative encodings of algebraic
datatypes, such as the Church booleans and Church numerals introduced in Sec-
tion 18.4.
22.2.12 Proposition: Let CBool be the PER [[8[X] X!X!X]]. Let tt = x: y: x and
ff = x: y: y. We have ff; tt 2 dom(CBool) and, whenever f 2 dom(CBool), either
f CBool tt or f CBool ff. 2
Proof: First, recall that f 2 dom(CBool) means that x X x 0 and y X y 0 imply
f x y X f x 0 y 0, for every PER X and numbers x; x 0; y; y 0. In particular, if x; y 2
dom(X), then f x y 2 dom(X).
Now consider the PER X = f(0; 0); (1; 1)g, with dom(X) = f0; 1g. Since f 0 1 2
dom(X), we have either f 0 1 = 0 or f 0 1 = 1. Suppose, without loss of generality,
that f 0 1 = 0. We claim that, in this case, f CBool tt. Letting x and y be natural
numbers, we must show that f x y = x. Using the same argument as before, with
0 and 1 replaced by x and y, we find that f x y 2 fx; yg. So if x = y, then f x y = x
and we are done. Suppose, on the other hand, that x and y are different. There are
several cases to consider.
 Suppose x and y are both different from 0 and 1. Let X be the PER with
equivalence classes fx; 0g and fy; 1g—i.e.,
X = f(0; 0); (0; x); (x; 0); (x; x); (1; 1); (1; y); (y; 1); (y; y)g:
From x X 0 and y X 1, we get (f x y) X (f 0 1) so (f x y) X 0 and f x y = x,
using the fact that f x y is either x or y, hence not 0.
 Suppose x is 0. Let X be the PER with equivalence classes f0g and fy; 1g.
Since x 6= y, these two classes are different. Reasoning as before, we have
(f x y) X 0, so f x y = 0 = x.
 Suppose x = 1 and y = 0. LetX be the PER with equivalence classes f0; 2g and
f1g and let Y be the PER with equivalence classes f0; 1g and f2g. From 2 X 0
and 1 X 1, we obtain f 2 1 = 2. From 2 Y 2 and 0 Y 1, we get f 2 0 = f 2 1 = 2.
Finally, using Z with classes f1; 2g and f0g, we get (f 1 0)Z(f 2 0), and hence
f 1 0 2 f1; 2g. Since f x y 2 fx; yg, we conclude that f 1 0 = 1.
The other cases are left as exercises. 2
January 15, 2000 22. DENOTATIONAL SEMANTICS 195
Similar in spirit but more complex is Freyd’s proof that every element of the
type [[8[X] (X!X)!X!X]] must be related to the interpretation of a Church nu-
meral [Fre89].
The above characterisation of Church booleans would be much easier if we
were allowed to use arbitrary relations, not just PERs—if it were the case, for exam-
ple, that f 2 dom(CBool) implied (f x y) R (f x 0 y 0) whenever x R x 0 and y R y 0 for
some relation R. We could then directly use the relation defined by 0 R x and 1 R y
and wouldn’t need any case distinctions. A model in which such relation based
reasoning principles are valid for arbitrary polymorphic types (not only booleans)
is called parametric [Rey83, ?]. In a parametric model, very powerful principles
for polymorphic encodings of inductive types and abstract datatypes are available
(cf. [PA93]). However, it is an open problem whether the PER model is parametric,
and the only known parametric models are rather syntactic in flavor.
However, some simple instances of parametric reasoning do go through in the
PER model.
22.2.13 Proposition: Let f 2 [[8[X]X!S]], where X is not free in S. Then f is constant—
that is, for each PER X and element x 2 dom(X), we have (f x) [[S]] (f 0). 2
Proof: Using the everywhere true relation [[Top]]. (Let x be given. Then x [[Top]] 0,
so (f x) [[S]] (f 0).) 2
The above example is a a simple case of representation independence. One
can view f 2 [[8[X]X!A]] as a piece of code depending on a module that supplies
a type X and a constant of that type. (Think of the encoding of existential types in
terms of universal types sketched in Exercise ??.) If there are no other constants or
functions defined on this type, then intuitively it should not be possible to make
any use of it. The PER model validates this intuition.
Here is another reasoning principle based on the observation that the PER se-
mantics uses neither type annotations nor type applications or abstractions.
22.2.14 Reasoning Principle [Mitchell]: Any two F<: terms of the same type and
with equal erasures are observationally equal.
For example, if
f : 8[X] (X!X) ! (Nat!X) ! X
V <: Top
U <: V
g : V!U
h : Nat!U;
then
f U (fun[u:U]g(u))(h)
obs
= V f V (fun[v:V]g(v))(h):
2
Proof: Exercise. 2
January 15, 2000 22. DENOTATIONAL SEMANTICS 196
Digression on full abstraction
One may ask whether the reasoning method arising from Theorem 22.2.8 is com-
plete, i.e., whether t1
obs
= t2 implies [[s]]=[[t]]. Semantic models for which this is the
case are called fully abstract. It is an open problem (as far as we know) whether
the PER model is fully abstract, but it seems unlikely for the following reason.
We might attempt to prove full abstraction by induction on the type S of s and
t. If S = Nat, then it clearly holds; but for the function space S!T we encounter the
following problem. Suppose ` f; g : S!T and f obs= g. To prove [[f]] = [[g]], we have
to show that [[f]](v) [[T]] [[g]](v) for all v 2 dom([[S]]). Using full abstraction induc-
tively on T, we get [[f]](v) [[T]] [[g]](v) for all definable v, i.e., those of the form [[t]] for
some ` t : S. But even dom([[Nat!Nat]]) contains non-definable elements (since
it contains all total computable functions, and some of these cannot be defined4
in F<:). It could, however, be that every non-definable element is observationally
equivalent to a definable one, in which case we could salvage this argument.
22.3 General Recursion and Recursive Types
Although the PER semantics is based on arbitrary computable functions, only the
total ones actually arise as denotations. In order to account for general recursion
and recursive types, we need a more generous notion of model.
Continuous Partial Orders
We have already seen that the PER model does not account for general recursion—
although the elements of the underlying universe (N) encode partial functions, the
interpretations of types include only elements encoding functions that are total on
the relevant domain. There does not seem to be an easy way of removing this
restriction: if we insist on interpreting types as PERs over N, our model will ac-
count only for total functions. To model recursive types (and accordingly, general
recursion and higher-order partial functions), we must adopt a richer view of the
underlying computations. The required machinery comes from the mathematical
area of domain theory.
22.3.1 Definition: A domain is a partial ordering (D;v) (that is, a set D with a
transitive, reflexive, and anti-symmetric orderingv) with the following properties:
1. If x0 v x1 v x2 v ::: is an increasing chain in D then there exists a least upper
bound
F
i xi 2 D. That is, xi v
F
i xi for all i and, if xi v y for all i, thenF
i xi v y.
4This can be seen from a simple diagonalization argument. Suppose that (fx)x2N is an effective
enumeration of all closed F<: terms of type Nat!Nat. Then x: fx(x)+ 1 is a computable function that
is not definable in F<:.
January 15, 2000 22. DENOTATIONAL SEMANTICS 197
2. D has a least element (written ? or ?D and pronounced “bottom”). 2
22.3.2 Exercise [Easy]: Show that the least upper bound of each chain in a domain
D is uniquely determined, in the sense that, if xi v z for all i and, whenever xi v y
for all i, we have z v y, then z =
F
i xi. 2
The structures we call domains are often called “omega-complete partial or-
ders (with bottom),” reserving the word “domain” for structures satisfying further
properties such as “algebraicity” or “continuity.”
Let D and E be domains. We define the space [D!E] of continuous functions
from D to E as the set of monotone functions f 2 D ! E that preserve suprema,
i.e.,
 x v y implies f(x) v f(y), and
 f(
F
i xi) =
F
i f(xi) for every increasing chain (xi)i2N.
D ! E can be viewed as a domain itself by ordering its elements pointwise, i.e.,
f v g iff f(x) v g(x) for all x 2 D. The bottom element and least upper bounds
in this domain are also calculated pointwise. Note that we do not require that the
elements of [D!E] should be strict (i.e., map ?D to ?E).
22.3.3 Proposition: Every continuous function f 2 [D!D] has a fixed point given
as the least upper bound of the chain ? v f(?) v f(f(?)) v : : : 2
Proof: Exercise. 2
22.3.4 Definition: Let L denote the set of natural numbers considered as record la-
bels. (For technical convenience, we continue using numbers as labels.) We define
Rcd(D) as the set of functions f 2 L ! D, ordered pointwise, plus a distinguished
least element ?Rcd(D) (usually written just ?). Again, this forms a domain.
We will use Rcd(D) to interpret record types. The addition of the ? element
allows us to distinguish a nonterminating computation of record type (such as
fix {} fun[r:{}] r) from a record containing an undefined (nonterminating)
field (such as {l=omega}). This reflects the fact that the call-by-name evaluation
relation does not evaluate within the fields of a record, but waits until a field is
projected to evaluate it further. 2
22.3.5 Definition: The flat domain of natural numbers N? has as elements the
natural numbers plus an extra bottom element ?. The ordering is: x v y iff x = ?
or x = y. 2
As before, types will be interpreted as partial equivalence relations. Instead of
the natural numbers, though, the underlying universe of these PERs will be the
domain that forms the least solution of the following equation:
D = N? + [D!D] + Rcd(D)
January 15, 2000 22. DENOTATIONAL SEMANTICS 198
That is, we will use a domainD that “contains” the flat domain of natural numbers,
the function space [D!D], and the record domain Rcd(D). Rather than developing
a general theory of such equations and their solutions, we simply assert (without
proof) the existence of a suitable domain and list its relevant properties:
22.3.6 Proposition: There exists a domain D with functions
N 2 [N? ! D] N? 2 [D! N? ]
fun 2 [[D!D]! D] fun? 2 [D! [D!D]]
rcd 2 [Rcd(D)! D] rcd? 2 [D! Rcd(D)]
satisfying the following equations (for  2 fN; fun; rcdg)
(?(x)) = x
(?) = ?D
?(d) =

e if d = (e) for some e
? otherwise
and such that every element d 2 D can be expressed as d = (e) for some e, where
 is one of fN; fun; rcdg. Furthermore, there is an increasing sequence of projection
functions
r 2 [D! D] for all r 2 N
with the following properties:
1. r(d) v d
2. r(s(d)) = min(r;s)(d)
3. 0(d) = ?
4.
F
r r(d) = d
5. Dr
def
= fd j r(d) = dg is a finite set
6. the projections r are compatible with the structure of D in the following
sense:
(a) r+1(N(n)) =

N(n) if n  r
? otherwise
(b) r+1(fun(f)) = fun(x: r(f(r(x)))).
(c) r+1(rcd(f)) = rcd(l: if l  r then r(f(l)) else ?) 2
Proof: See [Gun92] or any other standard text on domain theory. 2
January 15, 2000 22. DENOTATIONAL SEMANTICS 199
In other words, D has N? , Rcd(D), and—in particular—its own function space
[D!D] as “subdomains,” and D is obtained as the “limit” of an increasing se-
quence of finite subsets—the ranges Dr of the r. These approximating subdo-
mains can be explicitly constructed by taking the clauses under (6) as an inductive
definition. In particular,
D0 = f?g
D1 = f?; N(0); rcd(l:?)g
D2 = f?; N(0); N(1);
rcd(l:?); rcd(0 7! N(0); l>0 7! ?); rcd(0 7! N(0); 1 7! N(0); l>1 7! ?);
rcd(0 7! rcd(l:?); 1 7! rcd(l:?);
l>1 7! ?); and 5 more records : : : ;
fun(x 2 D1:N(0)); fun(x 2 D1: x); and 8 more functions : : : g
etc.
22.3.7 Exercise:
1. How many elements does D3 contain?
2. Convince yourself that Dr can be described as fr(d) j d 2 Dg.
3. Describe explicitly the action of the projection 1 viewed as a function from
D2 to D1. 2
22.3.8 Exercise [Recommended]:
1. Call a domain D finitary if every increasing chain in D contains a finite num-
ber of elements. Show that, if D is finitary, then the least upper bound of
every increasing chain in D is an element of the chain. Does this implication
hold in the other direction?
2. Note that N? and each Dr are (trivially) finitary. Give an example of an
increasing chain with infinitely many distinct elements in [N?!N? ].
3. Consider an increasing chain x0 v x1 v : : : in D. Show that r(
F
i xi) =
r(xj) for some j. 2
22.3.9 Exercise: Give an explicit definition of a continuous function succ 2 [D!D]
with the property that succ(N(n)) = N(n + 1). 2
January 15, 2000 22. DENOTATIONAL SEMANTICS 200
The CUPER Interpretation
As before, we will interpret types as “subsets of D equipped with local notions of
equality”—i.e., PERs over D. However, in order to interpret general recursion and
recursive types, some additional conditions will be needed.
1. In order to ensure that the fixed-point functional described in Exercise ??
(which sends f to fix(f) def=
F
i f
i(?)) will be an element of dom([[8[X](X!X)!X]]),
we require that every PER used to interpret types contains the pair (?;?) and
is closed under least upper bounds of increasing chains. (Informally, if R is
such a PER and f sends R-related elements to R-related elements, then from
? R ?we see by induction that fi? R fi? for every i. Hence fix(f) 2 dom(R).)
This condition is called completeness.
2. In order to interpret recursive types, we must further require that the PERs
used to interpret types be determined by their restrictions to the finite sets
Dr. This condition is called uniformity.
22.3.10 Definition: A complete uniform PER (CUPER) is a symmetric, transitive
relation R on D such that:
1. ? R ?.
2. If (xi)i2N and (yi)i2N are two increasing chains such that xi R yi for all i,
then
F
i xi R
F
i yi (completeness).
3. x R y iff r(x) R r(y) for all r (uniformity). 2
22.3.11 Exercise: There is some redundancy in this definition: we can either drop
(2) or replace the “iff” in (3) by “implies.” Show this. 2
22.3.12 Definition:
1. The CUPER Nat is defined by f(N(n);N (n)) j n 2 N? g.
2. The CUPER Top is the total relation DD.
3. When R and S are CUPERs, the CUPER R) S is defined by
f(fun(f); fun(g)) j for all x; y 2 D, if x R y then f(x) S g(y)g.
4. IfR1 through Rn are CUPERs and l1 : : : ln are labels, then the CUPER fl1:R1 : : : ln:Rng
is defined by f(?;?)g[f(rcd(f); rcd(g)) j f; g 2 L!D and f(li) Ri g(li) for i = 1 : : : ng.
5. Let I be any set and (Ri)i2I be an I-indexed family of CUPERs. The CUPERT
i Ri is defined as the intersection of all the Ri, i.e., x
T
i Ri y iff x Ri y for
all i 2 I.
(When we use this definition below, the index set I will always be the set of
sub-CUPERs of some CUPER.)
January 15, 2000 22. DENOTATIONAL SEMANTICS 201
6. ? is the CUPER f(?;?)g. 2
22.3.13 Exercise [Recommended]: Show that all of these constructions actually de-
fine CUPERs. 2
These constructions on CUPERs allow us to define a semantics that maps types
of F<: (without recursive types) to CUPERs and maps terms to elements of D ly-
ing in the domains of their types, using essentially the same definition as in Sec-
tion 22.2 (the interepretations of both types and terms are with respect to an en-
vironment, as before). In this semantics, the type dom([[8[X] (X!X)!X]]) is non-
empty; in particular, it contains the function that sends f 2 [D!D] to its least fixed
point. Other elements of this type are finite approximations of the fixed point, i.e.,
functionals mapping functions f to fn(?) for some n.
It remains to show how to interpret recursive types.
Interpreting Recursive Types
22.3.14 Definition: Let R be a CUPER and r 2 N. We write Rr for the restriction
of R to the finite set Dr, i.e., x Rr y iff x R y and r(x) = x and r(y) = y. 2
Notice that R0 =? and Rr is a sub-CUPER of R and Rr+1, for each CUPER
R. Also note that, by the uniformity condition, two CUPERs R and S are equal iff
Rr = Sr for all r 2 N.
22.3.15 Definition: A function F mapping CUPERs to CUPERs is called contrac-
tive if, for each CUPER R and r 2 N we have F(R)r+1 = F(Rr)r+1. F is called
nonexpansive if F(R)r+1 = F(Rr+1)r+1. 2
Note that “F contractive” implies “F non-expansive,” since F(Rr+1)r+1 =
F(Rr+1)r+2r+1 = F(R)r+2jr+1 = F(R)r+1.
22.3.16 Exercise [Recommended]: Show that F(R) = R ) N? is contractive. Give
an example of a nonexpansive function on CUPERs that is not contractive. 2
22.3.17 Definition: Let F be a contractive function mapping CUPERs to CUPERs.
The CUPER (F) is defined by x (F) y iff r(x) Fr(?) r(y) for all r. 2
22.3.18 Lemma: (F)r = Fr(?)r. 2
Proof: The direction (F)r  Fr(?)r is immediate from the definitions. For the
other direction, we first establish
Fk+1(?)k = F
k(?)k for all k 2 N (22.1)
January 15, 2000 22. DENOTATIONAL SEMANTICS 202
by calculating as follows: Fk+1(?)k = Fk(F(?)0)k = Fk(?)k. The penulti-
mate step follows by “commuting” k with k applications of F, reducing the index
by 1 at each step using contractiveness.
Now assume that xFr(?)ry, hence, x; y 2 Dr. From Fk+1(?)k+1  Fk+1(?)k =
Fk(?)k we obtain inductively that k(x)Fk(?)kk(y) for all k  r. (Note that
k(x) = k(r(x)) = r(x) = x.)
On the other hand, r-1(x)Fr(?)r-1r-1(y) by uniformity, hence
r-1(x)F
r-1(?)r-1r-1(y)
by Equation 22.1. Proceeding inductively in this way yields k(x)Fk(?)kk(y)
for all k < r. 2
22.3.19 Proposition: (F) is the unique fixed point of F, that is, F((F)) = (F) and,
if F(R) = R then R = (F). 2
Proof: To show that (F) is a fixed point of F, it suffices to show that (F)r+1 =
F((F))r+1 for all r 2 N. Now, since F is contractive, F((F))r+1 = F((F)r)r+1 =
F(Fr(?)r)r+1 = F
r+1(?)r+1 = (F)r+1 (using Lemma 22.3.18 in the second
step and the definition of contractiveness in the third step). On the other hand, if
F(R) = R, we can show Rr = mu(F)r by induction on r. If r = 0, both sides are?.
Otherwise, we have Rr+1 = F(R)r+1 = F(Rr)r+1 = F((F)rr+1 = (F)r+1,
where the induction hypothesis is used in the penultimate step. 2
22.3.20 Proposition: All functions on CUPERs definable from the operations in
Definition 22.3.12 plus  are nonexpansive; they are contractive if their outermost
operation is record formation or function space formation. 2
Proof: Straightforward induction (see [AC96]). 2
22.3.21 Exercise [Possibly difficult]: We believe that the only nonexpansive but
not contractive function that can be constructed using these operators is the iden-
tity. Prove or refute this claim. 2
It follows that, if a function F on CUPERs is definable from the operations in
Definition 22.3.12 plus , then the function G mapping each CUPER R to Top )
F(R) is contractive. This enables us to interpret recursive types by adding the fol-
lowing semantic clauses:
[[(X)T]] = (R:Top => [[T]]+fX7!Rg)
[[fold ((X)T)]] = fun(d: fun(x: d))
[[unfold ((X)T)]] = fun(d: fun
?
(d)(0))
For the last two clauses, we use the fact that [[(X)T]] = Top ) [[fX 7! (X)TgT]],
which follows from Proposition 22.3.20 and an appropriate substitution lemma.
January 15, 2000 22. DENOTATIONAL SEMANTICS 203
This semantics shows us (somewhat trivially) that the reduction rules for the
system including recursive types do not equate different natural numbers. It also
shows the soundness of an equational theory for F<: including additional equa-
tions like
fold ((X)T) (unfold ((X)T) t) = t 2 (X)T:
An appropriate definition of observational equivalence for F<: must deal with
the possibility of nontermination—for example, as follows:
Two closed terms t1 and t2 of type T are observationally equivalent
(at type T) if, for all closed terms C : T!Nat, the terms C t1 and C t2
either both diverge (i.e., admit no normal form) or can be reduced to
the same number.
Computational adequacy of the CUPER semantics with respect to this notion of
equivalence now becomes a nontrivial result. We must show that, if m is a closed
term of type Nat, then [[m]] = ? iff m has no normal form. One direction is trivial
(which?). The other requires a “logical relations” proof, i.e., an induction over
terms using a suitable generalization of the desired property for types other than
Nat. (We are not aware of such a proof in the literature, but there seem to be no
major obstacles.)
22.4 Further Reading
The subset and PER models of the simply typed lambda-calculus are due to Kreisel,
who called them HRO (“hereditarily recursive operations”) and HEO (“hereditar-
ily effective operations”), respectively. A good reference with pointers to related
topics of historical interest is Troelstra and van Dalen’s book [TvD88]. A standard
reference on PER models in a computer science context is Mitchell’s book [Mit96].
Our presentation of CUPERs is a simplified version of the one used by Abadi
and Cardelli [AC96]. Other treatments of CUPERs can be found in [?, ?]
The concept of full abstraction was introduced by Plotkin in [Plo77], which
is still well worth reading. Recent progress in the construction of fully abstract
models (albeit not yet for F<:) is reported in [AJM94, HO94, OR94].
Parametricity was first studied by Reynolds in the context of representation
independence [Rey83]. Parametric models of System F are described in [BFSS90,
RR94]. Parametricity in System F<: is considered in [CMMS94].
Good general textbooks on semantics include [Sch86, Gun92, Ten81, Win93,
Mit96].
Chapter 23
Polymorphic Update
This chapter is just a sketch.
The mechanism of polymorphic update is quite a bit less “mainstream” than almost all
of what’s covered in the rest of the chapters. It’s not completely clear that it belongs. On
the other hand, it makes the object encoding examples in Chapter 28 vastly clearer.
In fact, I’m tempted to go even further and introduce an ad-hoc “in place update”
operation for existential types (following a suggestion in [HP98]). This makes it possible
to do the whole of Chapter 28 in a second-order setting, before discussing type operators.
Polymorphic update F<:+ fg update
New syntactic forms
t ::= ... (terms...)
{ i li=ti
i21::n} record
t l=t field update
T ::= ... (types...)
{ i li:Ti
i21::n} type of records
 ::= # invariant (updatable) field
omitted covariant (fixed) field
New evaluation rules (t  ! t 0)
{ili=vi
i21::n} li=v
 ! {ili=vi j21::i-1,li=v,klk=vk k2i+1::n} (E-UPDATEBETA)
{ i li=vi
i21::n}.li  ! vi (E-RCDBETA)
204
January 15, 2000 23. POLYMORPHIC UPDATE 205
tj  ! t 0j
{li=vi
i21::n}  ! { i li=vi i21::j-1,lj=t 0j, k lk=tk k2j+1::n} (E-RECORD)
New type equivalence rules (  ` S  T)
 is a permutation of f1::ng
  ` { i li:Ti i21::n}  { i li:T
i21::n
i }
(Q-RCD-PERM)
New subtyping rules (  ` S <: T)
  ` { i li:Ti i21::n+k} <: { i li:Ti i21::n} (S-RCD-WIDTH)
for each i   ` Si <: Ti if i = #, then   ` Ti <: Si
  ` { i li:Si
i21::n} <: { i li:Ti
i21::n}
(S-RCD-DEPTH)
  ` {:::#li:Si:::} <: {:::li:Si:::} (S-RCD-VARIANCE)
New typing rules (  ` t : T)
for each i   ` ti : Ti
  ` { i li=ti i21::n} : { i li:Ti i21::n}
(T-RCD)
  ` t : { i li:Ti i21::n}
  ` t.lj : Tj
(T-PROJ)
  ` r : R   ` R <: {#lj:Tj}   ` t : Tj
  ` r lj=t : R (T-UPDATE)
Chapter 24
Type Operators and Kinding
The introduction to this chapter is in good shape. The technicalities are all missing at the
moment.
In previous chapters, we have often made use of informal abbreviations like
Pair S T = 8X. (S!T!X) ! X;
for brevity and readability, writing Pair Nat Bool, for example, instead of the
more cumbersome 8X. (Nat!Bool!X) ! X. What sort of thing is Pair in itself?
Given any pair of types S and T, it picks out the type of “pairs of S and T”—that is,
it is intuitively a function from types to types. The definition of Pair can thus be
written explicitly as follows:
Pair = A. B. 8X. (A!B!X) ! X;
Formally, then, the type expression Pair S T is actually a nested operator appli-
cation (Pair S) T. In other words, Pair itself is a function from types to type
operators mapping types to types. In this chapter, we take a more careful look at
the mechanisms involved in defining and using such functions.
24.1 Intuitions
Once we have introduced syntax for abstracting type expressions on type expres-
sions () and performing the corresponding instantiations (application), nothing
prevents us from considering functions mapping type operators to types, func-
tions mapping type operators to type operators, etc. To keep things organized and
prevent ourselves from writing nonsensical type applications like Pair Pair, we
206
January 15, 2000 24. TYPE OPERATORS AND KINDING 207
classify types and type operators by kinds. E.g.,
* the kind of “proper types” like Bool and Bool!Bool
*!* the kind of type operators (functions from types to types)
*!*!* the kind of functions from types to type operators
(*!*)!* the kind of functions from type operators to types
etc.
Kinds can be thought of as the “types of types.” In essence, the system of kinds
is a little copy of the simply typed lambda-calculus, placed one level higher in
the hierarchy of classification. Just as in the lambda-calculus, we shall henceforth
annotate the bound variables in operator abstractions with the kind of the bound
type variable, so that Pair is really defined as:
Pair = A::*. B::*. 8X. (A!B!X) ! X;
However, since * is by far the most common case, we allow X.T as an abbreviation
for X::*.T.
A few pictures should make all this easier to understand. The phrases of our
language are divided now into three separate classes: terms, types, and kinds. The
level of terms contains actual data values (integers, records, etc.) and computations
(functions) over them.
5
 x:Nat.x
( x:Nat.x)5
( x:Nat.x)true
 X. x:X.x
pair [Nat] [Bool] 5 false
etc.
Terms
λ λ
λ
λ
λ
The level of types contains proper types like Nat, Nat!Nat, Pair Nat Bool and
8X.X!X, which classify terms,
5
 x:Nat.x
( x:Nat.x)5
( x:Nat.x)true
 X. x:X.x
pair [Nat] [Bool] 5 false
Nat
Nat->Nat
Pair Nat Bool
( X.X->X)Nat
  X.X->X
etc.
etc.
Terms
Types
λ
λ λ
λ
λ
λ
∀
January 15, 2000 24. TYPE OPERATORS AND KINDING 208
as well as type operators like Pair and X.X!X that do not themselves classify
terms but that can be applied to type arguments to form type expressions like
(X.X!X)Nat that do classify terms. (We use the word “types” to include both
proper types and type operators.)
5
 x:Nat.x
( x:Nat.x)5
( x:Nat.x)true
 X. x:X.x
pair [Nat] [Bool] 5 false
Nat
Nat->Nat
Pair Nat Bool
Pair
Pair Nat
 X.X->X
( X.X->X)Nat
  X.X->X
etc.
etc.
Terms
Types
Pair Pair
λλ
λ λ
λ
λ
λ
∀
Proper types are classified by the kind *, pronounced “kind type” or just “type.”
Type operators are classified by more complex kinds, such as *)* and *)*)*.
5
 x:Nat.x
( x:Nat.x)5
( x:Nat.x)true
 X. x:X.x
pair [Nat] [Bool] 5 false
Nat
Nat->Nat
Pair Nat Bool
Pair
Pair Nat
 X.X->X
( X.X->X)Nat
  X.X->X
* *->* *->*->*
etc.
etc.
etc.
Terms
Types
Kinds
Pair Pair
λλ
λ λ
λ
λ
λ
∀
Note that proper types (type expressions of kind *) can include type operators of
higher kinds as subphrases, as in (X::*.X!X)Nat or Pair Nat Bool.
Also, note the different roles in this diagram of the proper type 8X.X!X and
the type operator X.X!X. The former classifies terms like X.x:X.x—it is a type
January 15, 2000 24. TYPE OPERATORS AND KINDING 209
whose elements are functions from types to terms—while the latter is itself a func-
tion from types to types, and does not have any terms as “elements.”
A natural question to ask at this point is “Why stop at three levels of expres-
sions?” That is, why couldn’t we go on to introduce functions from kinds to kinds,
application at the level of kinds, etc., and add a fourth level to classify kind ex-
pressions according to their functionality? In fact, why stop there? We could go on
adding levels indefinitely! The answer is that we could very well do this, and such
systems (without subtyping) have been studied under the heading of pure type
systems [Bar92a, Bar92b, JMP94, MP93, Pol94, etc.] and used in computer science
for applications such as theorem proving. For purposes of this book, though, there
is no need to go beyond three levels.
24.2 Definitions
We now define a core calculus with type operators. At the term level, it includes
just the variables, abstraction, and application of the simply typed lambda-calculus;
the type level includes the usual arrow types and type variables, plus operator ab-
straction and application. To formalize this system, we need to add three new
things to the systems we have seen before.
First, we need a collection of rules of kinding (or, more pedantically, type
well-formedness), which specify how type expressions can be combined to yield
new type expressions. In effect, these rules constitute a copy of the simply typed
lambda-calculus, “one level up.” We write   ` T :: K for “type T has kind K in
context  .”
Second, whenever a type T appears in a term (as in x:T.t), we must check that
T is well formed. This involves adding a new premise to the old T-ABS rule that
checks   ` T :: *. Note that T must have exactly kind *—i.e., it must be a proper
type—since it is being used to describe the values that x may range over.
Third, note that, by introducing abstraction and application in types, we have
given ourselves the ability to write different “names” for the same type. For exam-
ple, if Id = X.X, then
Nat ! Bool
Nat ! Id Bool
Id Nat ! Id Bool
Id Nat ! Bool
Id (Id (Id Nat)) ! Bool
all mean the same thing, in the sense that they have the same terms as members.
January 15, 2000 24. TYPE OPERATORS AND KINDING 210
Type operators and kinding !  )
Syntax
t ::= (terms...)
x variable
x:T.t abstraction
t t application
v ::= (values...)
x:T.t abstraction value
T ::= (types...)
X type variable
X::K.T operator abstraction
T T operator application
T!T type of functions
  ::= (contexts...)
; empty context
 ; x:T term variable binding
 ; X ::K type variable binding
K ::= (kinds...)
* kind of proper types
K)K kind of operators
Evaluation (t  ! t 0)
(x:T11.t12) v2  ! fx 7! v2gt12 (E-BETA)
t1  ! t1 0
t1 t2  ! t 01 t2 (E-APP1)
t2  ! t2 0
v1 t2  ! v1 t 02 (E-APP2)
Type equivalence (  ` S  T)
  ` T :: K
  ` T  T :: K
(Q-REFL)
  ` T  S :: K
  ` S  T :: K
(Q-SYMM)
  ` S  U :: K   ` U  T :: K
  ` S  T :: K
(Q-TRANS)
January 15, 2000 24. TYPE OPERATORS AND KINDING 211
 ; X::K11 ` T12 :: K12   ` T2 :: K11
  ` (X::K11.T12) T2  fX 7! T2gT12 :: K12 (Q-BETA)
  ` S :: K1)K2   ` T :: K1)K2
 ; X::K1 ` S X  T X :: K2
  ` S  T : K1)K2 (Q-EXT)
 ; X::K1 ` S2  T2 :: K2
  ` X::K1.S2  X::K1.T2 :: K1)K2 (Q-TABS)
  ` S1  T1 :: K11)K12   ` S2  T2 :: K11
  ` S1 S2  T1 S2 :: K12
(Q-APP)
  ` S1  T1 :: *   ` S2  T2 :: *
  ` S1!S2  T1!T2 :: * (Q-ARROW)
Kinding (  ` T :: K)
X::K 2  
  ` X :: K
(K-TVAR)
 ; X::K1 ` T2 :: K2
  ` X::K1.T2 :: K1)K2 (K-TABS)
  ` T1 :: K11)K12   ` T2 :: K11
  ` T1 T2 :: K12
(K-TAPP)
  ` T1 :: *   ` T2 :: *
  ` T1!T2 :: * (K-ARROW)
Typing (  ` t : T)
  ` t : S   ` S  T:: *
  ` t : T
(T-EQ)
x:T 2  
  ` x : T
(T-VAR)
  ` T1 :: *  ; x:T1 ` t2 : T2
  ` x:T1.t2 : T1!T2 (T-ABS)
  ` t1 : T11!T12   ` t2 : T11
  ` t1 t2 : T12
(T-APP)
Abbreviations
unannotated binder for X def= X::*
January 15, 2000 24. TYPE OPERATORS AND KINDING 212
Chapter 25
Higher-Order Polymorphism
Just a sketch.
I’m not certain whether it’s productive to develop metatheory in detail for this part of
the book, or whether to refer interested readers into the literature. For F-omega itself, the
proofs are not all that hard or tedious, so it may be illuminating to go through at least some
of them. For later systems like F-omega-sub, it becomes increasingly heavy. (One purpose
of putting some of that in would probably be to give students the impression that it’s not
that easy, in case they thought type systems was a trivial topic!)
When type operators are added to System F, we can abstract over types of ar-
bitrary kinds. This substantially increases the power of the system. In particular,
higher-order universal polymorphism (i.e., abstraction over types of kinds other
than *) will be used in Chapter 28 to complete our model of purely functional
object-oriented programming. Higher-order existential types have more practical
uses, for building abstract data types whose hidden representation type is actually
an operator like List or Pair.
25.1 Higher-Order Universal Types
The higher-order extension of the polymorphic lambda-calculus is formed by sim-
ply allowing X::K in place of just X in the original definition of System F.
For example, here is a ridiculously polymorphic identity function
wayPolyId = F::*)*. X. x:F X. x;
I wayPolyId : 8F::*)*. 8X. F X ! F X
and here is a typical use:
wayPolyId [Y.{a:Y}] [Bool] {a=true};
213
January 15, 2000 25. HIGHER-ORDER POLYMORPHISM 214
25.1.1 Exercise: Write and typecheck a ridiculously polymorphic applyTwice func-
tion, of type 8F::*)*. 8X. ((F X) ! (F X)) ! (F X). 2
We will see some more interesting applications of higher-order universal types
in later chapters.
F! : Higher-order polymorphic lambda-calculus System F + )
New syntactic forms
t ::= ... (terms...)
X ::K .t type abstraction
v ::= ... (values...)
X :: K .t type abstraction value
T ::= ... (types...)
8X ::K .T universal type
New evaluation rules (t  ! t 0)
(X ::K11 .t12) [T2]  ! fX 7! T2gt12 (E-BETA2)
New type equivalence rules (  ` S  T)
 ; X ::K1 ` S2  T2 :: *
  ` 8X ::K1 .S2  8X ::K1 .T2 :: *
(Q-ALL)
New kinding rules (  ` T :: K)
 ; X::K1 ` T2 :: *
  ` 8X::K1.T2 :: *
(K-ALL)
New typing rules (  ` t : T)
 ; X ::K1 ` t2 : T2
  ` X ::K1 .t2 : 8X ::K1 .T2
(T-TABS)
  ` t1 : 8X ::K11 .T12   ` T2 :: K11
  ` t1 [T2] : fX 7! T2gT12 (T-TAPP)
January 15, 2000 25. HIGHER-ORDER POLYMORPHISM 215
25.2 Higher-Order Existential Types
Similarly, the higher-order variant of existential types is obtained by generalizing
X to X::K in the original definition of 9.
Higher-order existential types F !<: + 9
New syntactic forms
T ::= ... (types...)
{9X ::K ,T} existential type
New typing rules (  ` t : T)
  ` t2 : fX 7! UgT2   ` {9X::K1,T2} : *
  ` {9X=U,t2} as {9X ::K1 ,T2} : {9X ::K1 ,T2}
(T-PACK)
  ` t1 : 9X ::K11 .T12  ; X ::K11 ; x:T12 ` t2 : T2
  ` let {X,x}=t1 in t2 : T2
(T-UNPACK)
For example, here is an ADT (cf. Section ??) that provides the type operator
Pair abstractly:
let pairADT =
{9Pair = X. Y. 8R. (X!Y!R) ! R,
{pair = X. Y. x:X. y:Y.
R. p:X!Y!R. p x y,
fst = X. Y. p: Pair X Y.
p [X] (x:X. y:Y. x),
snd = X. Y. p: Pair X Y.
p [Y] (x:X. y:Y. y)}}
as {9Pair::*)*)*,
{pair: 8X. 8Y. X!Y!(Pair X Y),
fst: 8X. 8Y. (Pair X Y)!X,
snd: 8X. 8Y. (Pair X Y)!Y
}}
in let {Pair,pair}=pairADT
in
pair.fst [Nat] [Bool] (pair.pair [Nat] [Bool] 5 true);
25.2.1 Exercise [Recommended]: Write a program that defines the pairADT, opens
it, and then defines a List ADT with the representation type
List = X. 8R. (X!R!R) ! R ! R;
and with operations nil, cons, car, and cdr of appropriate types. 2
January 15, 2000 25. HIGHER-ORDER POLYMORPHISM 216
F! : Summary System F+)
Syntax
t ::= (terms...)
x variable
x:T.t abstraction
t t application
X::K.t type abstraction
t [T] type application
v ::= (values...)
x:T.t abstraction value
X :: K.t type abstraction value
T ::= (types...)
X type variable
T!T type of functions
8X::K.T universal type
X::K.T operator abstraction
T T operator application
K ::= (kinds...)
* kind of proper types
K)K kind of operators
  ::= (contexts...)
; empty context
 ; x:T term variable binding
 ; X::K type variable binding
Evaluation (t  ! t 0)
(x:T11.t12) v2  ! fx 7! v2gt12 (E-BETA)
t1  ! t1 0
t1 t2  ! t 01 t2 (E-APP1)
t2  ! t2 0
v1 t2  ! v1 t 02 (E-APP2)
(X::K11.t12) [T2]  ! fX 7! T2gt12 (E-BETA2)
t1  ! t 01
t1 [T2]  ! t 01 [T2] (E-TAPP)
Type equivalence (  ` S  T)
January 15, 2000 25. HIGHER-ORDER POLYMORPHISM 217
  ` T :: K
  ` T  T :: K
(Q-REFL)
  ` T  S :: K
  ` S  T :: K
(Q-SYMM)
  ` S  U :: K   ` U  T :: K
  ` S  T :: K
(Q-TRANS)
 ; X::K1 ` S2  T2 :: *
  ` 8X::K1.S2  8X::K1.T2 :: *
(Q-ALL)
 ; X::K11 ` T12 :: K12   ` T2 :: K11
  ` (X::K11.T12) T2  fX 7! T2gT12 :: K12 (Q-BETA)
  ` S :: K1)K2   ` T :: K1)K2
 ; X::K1 ` S X  T X :: K2
  ` S  T : K1)K2 (Q-EXT)
 ; X::K1 ` S2  T2 :: K2
  ` X::K1.S2  X::K1.T2 :: K1)K2 (Q-TABS)
  ` S1  T1 :: K11)K12   ` S2  T2 :: K11
  ` S1 S2  T1 S2 :: K12
(Q-APP)
  ` S1  T1 :: *   ` S2  T2 :: *
  ` S1!S2  T1!T2 :: * (Q-ARROW)
Kinding (  ` T :: K)
X::K 2  
  ` X :: K
(K-TVAR)
 ; X::K1 ` T2 :: *
  ` 8X::K1.T2 :: *
(K-ALL)
 ; X::K1 ` T2 :: K2
  ` X::K1.T2 :: K1)K2 (K-TABS)
  ` T1 :: K11)K12   ` T2 :: K11
  ` T1 T2 :: K12
(K-TAPP)
  ` T1 :: *   ` T2 :: *
  ` T1!T2 :: * (K-ARROW)
Typing (  ` t : T)
x:T 2  
  ` x : T
(T-VAR)
January 15, 2000 25. HIGHER-ORDER POLYMORPHISM 218
  ` T1 :: *  ; x:T1 ` t2 : T2
  ` x:T1.t2 : T1!T2 (T-ABS)
  ` t1 : T11!T12   ` t2 : T11
  ` t1 t2 : T12
(T-APP)
 ; X::K1 ` t2 : T2
  ` X::K1.t2 : 8X::K1.T2
(T-TABS)
  ` t1 : 8X::K11.T12   ` T2 :: K11
  ` t1 [T2] : fX 7! T2gT12 (T-TAPP)
  ` t : S   ` S  T :: *
  ` t : T
(T-EQ)
25.3 Type Equivalence and Reduction
25.3.1 Definition: The type reduction relation   ` S V T :: K is defined just like
  ` S  T :: K, replacing  byV and dropping the rule Q-SYMM. 2
25.3.2 Proposition: If   ` S  T :: K, then there is some U such that   ` SV U :: K
and   ` TV U :: K. 2
Proof: Standard. 2
25.4 Soundness
25.4.1 Lemma:
1. If  ; x:S;  ` T :: K, then  ;  ` T :: K.
2. If  ; x:S;  ` S  T :: K, then  ;  ` S  T :: K. 2
Proof: The kinding and type equivalence relations do not depend on term variable
bindings. 2
25.4.2 Lemma [Substitution]: If  ; x:S;  ` t : T and   ` s : S, then  ;  ` fx 7!
sgt : T. 2
Proof: Straightforward. (Quick check: where is Lemma 25.4.1 used?) 2
25.4.3 Theorem [Preservation]: If   ` t : T and t  ! t 0, then ` t 0 : T. 2
Proof: Straightforward induction on evaluation derivations, using Lemma 25.4.2
for the T-VAR case. 2
January 15, 2000 25. HIGHER-ORDER POLYMORPHISM 219
25.4.4 Lemma:
1. If t is a value and ` t : T1!T2, then t is an abstraction.
2. If t is a value and ` t : 8X.T2, then t is a type abstraction. 2
Proof: The arguments for the two parts are similar; we show just (1). Since there
are only two forms of values, if t is a value and not an abstraction, then it must be
a type abstraction. Suppose (for a contradiction) that it is a type abstraction. Then
the given typing derivation for   ` t : T1!T2 must end with a use of T-TABS
followed by at least one use of T-EQ. That is, it must have the following form:
...
(T-TABS)
  ` t : 8X.S12   ` 8X.S12  U1 :: *
(T-EQ)
  ` t : U1
...
  ` t : Un-1   ` Un-1  Un :: *
(T-EQ)
  ` t : Un   ` Un  T1!T2 :: *
(T-EQ)
  ` t : T1!T2
Since type equivalence is transitive, we can collapse all of these uses of equivalence
into one and conclude that   ` 8X.S12  T1!T2.
By Proposition 25.3.2, there must be some type U such that   ` 8X.S12 V U and
  ` T1!T2 V U. A quick inspection of the rules defining theV relation shows that
there can be no such U. 2
25.4.5 Theorem [Progress]: Suppose t is closed and stuck, and that ` t : T. Then
t is a value. 2
Proof: By induction on typing derivations. The T-VAR case cannot occur, because
t is closed. The T-ABS and T-TABS cases are immediate, since abstractions are val-
ues. The T-EQ case follows directly from the induction hypothesis. The remaining
cases, for application and type application, are more interesting.
Case T-APP: t = t1 t2 ` t1 : T11!T12 ` t2 : T11
This case cannot occur. To see this, we reason by contradiction. Looking at the
evaluation rules, it is clear that a term of the form t1 t2 can be stuck only if
1. t1 is stuck (otherwise E-APP1 would apply to t), and
2. either t1 is not a value or else t2 is stuck (otherwise E-APP2 would apply).
From (1) and the induction hypothesis, we see that t1 must be a value; so by (2)
and the induction hypothesis, t2 must also be a value. But by Lemma 25.4.4(1), t1
must be an abstraction, which means that E-BETA applies to t, contradicting our
assumption that it is stuck.
January 15, 2000 25. HIGHER-ORDER POLYMORPHISM 220
Case T-TAPP:
Similar. 2
Chapter 26
Implementing Higher-Order
Systems
Algorithmic rules for F!
Algorithmic reduction (  `I T T 0)
  `I (X::K11. T12) T2  fX 7! T2gT12 (RA-BETA)
  `I T1 T
0
1   `
I T 01 T2 T
0
  `I T1 T2  T 0
(RA-APP)
Algorithmic type equivalence (  `I S  T)
  `I X  X (QA-TVAR)
  `I S S 0   `I S 0  T
  `I S  T
(QA-REDUCEL)
  `I T T 0   `I S  T 0
  `I S  T
(QA-REDUCER)
  `I S1  T1   `I S2  T2
  `I S1!S2  T1!T2 (QA-ARROW)
 ; X::K1 `I S2  T2
  `I 8X::K1.S2  8X::K1.T2
(QA-ALL)
 ; X::K1 `I S2  T2
  `I X::K1.S2  X::K1.T2
(QA-TABS)
  `I S1  T1   `I S2  T2
  `I S1 S2  T1 T2
(QA-TAPP)
221
January 15, 2000 26. IMPLEMENTING HIGHER-ORDER SYSTEMS 222
Exposure (  `I T * T 0)
otherwise
  `I T * T (XA-OTHER)
  `I T T 0   `I T 0 * T 00
  `I T * T 00 (XA-REDUCE)
Algorithmic typing (  `I t : T)
x:T 2  
  `I x : T
(TA-VAR)
 ; x:T1 `I t2 : T2   `I T1 :: *
  `I x:T1.t2 : T1!T2 (TA-ABS)
  `I t1 : T1   `I T1 * (T11!T12)   `I t2 : T2   `I T2  T11
  `I t1 t2 : T12
(TA-APP)
 ; X::K1 `I t2 : T2
  `I X::K1.t2 : 8X::K1.T2
(TA-TABS)
  `I t1 : T1   `I T1 * 8X::K1.T12   ` T2 :: K1
  `I t1 [T2] : fX 7! T2gT12 (TA-TAPP)
26.1 Definition: The set of well-formed contexts is defined as follows:
` ; ok
`   ok   ` T :: *
`  ; x:T ok
`   ok
`  ; X::K ok
2
26.2 Proposition: If   ` t : T and `   ok, then   ` T :: *. 2
Proof: 2
26.3 Proposition: If   ` t : T, then every type annotation on a -abstraction
within t” has kind * (in the evident context). 2
Proof: Straightforward induction on typing derivations. 2
26.4 Theorem [Equivalence of declaractive and algorithmic typing]: Suppose we
have `   ok. Then:
1. If   `I t : T, then   ` t : T.
January 15, 2000 26. IMPLEMENTING HIGHER-ORDER SYSTEMS 223
2. If   ` t : T, then   `I t : S with   ` S  T.
2
Proof: 2
26.5 Theorem [Decidability]:
1. The context well-formedness rules are syntax-directed and total.
2. The algorithmic typing relation is total as long as the input context is well
formed.
2
Proof: 2
Chapter 27
Higher-Order Subtyping
Just a sketch.
Some kinding premises are omitted in the subtyping rules presented here...
F!<: : Higher-order bounded quantification F<: + F
!
Syntax
t ::= (terms...)
x variable
x:T.t abstraction
t t application
X <:T .t type abstraction
t [T] type application
v ::= (values...)
x:T.t abstraction value
X <:T .t type abstraction value
T ::= (types...)
X type variable
T!T type of functions
8X <:T .T universal type
Top maximum type
X::K.T operator abstraction
T T operator application
  ::= (contexts...)
; empty context
 ; x:T term variable binding
224
January 15, 2000 27. HIGHER-ORDER SUBTYPING 225
 ; X <:T type variable binding
K ::= (kinds...)
* kind of proper types
K)K kind of operators
Evaluation (t  ! t 0)
(x:T11.t12) v2  ! fx 7! v2gt12 (E-BETA)
t1  ! t1 0
t1 t2  ! t 01 t2 (E-APP1)
t2  ! t2 0
v1 t2  ! v1 t 02 (E-APP2)
(X <:T11 .t12) [T2]  ! fX 7! T2gt12 (E-BETA2)
t1  ! t 01
t1 [T2]  ! t 01 [T2] (E-TAPP)
Type equivalence (  ` S  T)
  ` T :: K
  ` T  T :: K
(Q-REFL)
  ` T  S :: K
  ` S  T :: K
(Q-SYMM)
  ` S  U :: K   ` U  T :: K
  ` S  T :: K
(Q-TRANS)
  ` S1  T1 :: *   ` S2  T2 :: *
  ` S1!S2  T1!T2 :: * (Q-ARROW)
 ; X<:U ` S2  T2 :: *
  ` 8 X<:U .S2  8 X<:U .T2 :: *
(Q-ALL)
 ; X::K11 ` T12 :: K12   ` T2 :: K11
  ` (X::K11.T12) T2  fX 7! T2gT12 :: K12 (Q-BETA)
  ` S :: K1)K2   ` T :: K1)K2
 ; X::K1 ` S X  T X :: K2
  ` S  T : K1)K2 (Q-EXT)
 ; X::K1 ` S2  T2 :: K2
  ` X::K1.S2  X::K1.T2 :: K1)K2 (Q-TABS)
  ` S1  T1 :: K11)K12   ` S2  T2 :: K11
  ` S1 S2  T1 S2 :: K12
(Q-APP)
January 15, 2000 27. HIGHER-ORDER SUBTYPING 226
Kinding (  ` T :: K)
X<:T 2     ` T :: K
  ` X :: K
(K-TVAR)
 ; X<:T1 ` T2 :: *
  ` 8X <:T1 .T2 :: *
(K-ALL)
 ; X <:TopK1 ` T2 :: K2
  ` X::K1.T2 :: K1)K2 (K-TABS)
  ` T1 :: K11)K12   ` T2 :: K11
  ` T1 T2 :: K12
(K-TAPP)
  ` T1 :: *   ` T2 :: *
  ` T1!T2 :: * (K-ARROW)
Subtyping (  ` S <: T)
  ` S <: U   ` U <: T
  ` S <: T
(S-TRANS)
  ` S  T :: K
  ` S <: T
(S-EQV)
  ` S <: Top (S-TOP)
  ` T1 <: S1   ` S2 <: T2
  ` S1!S2 <: T1!T2 (S-ARROW)
X<:T 2  
  ` X <: T
(S-TVAR)
 ; X<:U1 ` S2 <: T2
  ` 8X<:U1.S2 <: 8X<:U1.T2
(S-ALL)
 ; X::K ` S2 <: T2
  ` X::K.S2 <: X::K.T2
(S-ABS)
  ` S1 <: T1
  ` S1 U <: T1 U
(S-APP)
Typing (  ` t : T)
x:T 2  
  ` x : T
(T-VAR)
  ` T1 :: *  ; x:T1 ` t2 : T2
  ` x:T1.t2 : T1!T2 (T-ABS)
January 15, 2000 27. HIGHER-ORDER SUBTYPING 227
  ` t1 : T11!T12   ` t2 : T11
  ` t1 t2 : T12
(T-APP)
  ` t : S   ` S <: T
  ` t : T
(T-SUB)
 ; X <:T ` t2 : T2
  ` X <:T .t2 : 8X <:T .T2
(T-TABS)
  ` t1 : 8X <:T11 .T12   ` T2 <: T11
  ` t1 [T2] : fX 7! T2gT12 (T-TAPP)
Abbreviations
unannotated binder for X def= X <:Top
Top*
def
= Top
TopK1)K2
def
= X::K1. TopK2
Chapter 28
Pure Objects and Classes
Technically complete, more or less. Work needed on writing.
28.1 Simple Objects
Recall (from Chapter 19) the type of pure (or “purely functional”) Counter objects:
Counter = {9X, {state:X, methods:{get: X!Nat, inc:X!X}}};
The representation type of counters:
CounterR = {x:Nat};
A counter object:
c = {9X = Nat,
{state = 5,
methods = {get = x:Nat. x,
inc = x:Nat. succ(x)}}}
as Counter;
I c : Counter
Message-sending operations:
sendget = c:Counter.
let {X,body} = c in
body.methods.get(body.state);
I sendget : Counter ! Nat
sendinc = c:Counter.
let {X,body} = c in
{9X = X,
{state = body.methods.inc(body.state),
methods = body.methods}}
as Counter;
228
January 15, 2000 28. PURE OBJECTS AND CLASSES 229
I sendinc : Counter ! Counter
addthree = c:Counter. sendinc (sendinc (sendinc c));
I addthree : Counter ! Counter
c3 = addthree c;
sendget c3;
I c3 : Counter
8 : Nat
28.2 Subtyping
Recall (from Section ??) the subtyping rule for existential types:
This means that if we define an object type with more methods than our Counter
type
ResetCounter =
{9X, {state:X, methods:{get: X!Nat, inc:X!X, reset:X!X}}};
we will have:
ResetCounter <: Counter
So if we define a reset counter object
rc = {9X = Nat,
{state = 0,
methods = {get = x:Nat. x,
inc = x:Nat. succ(x),
reset = x:Nat. 0}}}
as ResetCounter;
I rc : ResetCounter
we can pass it as a legal argument to sendgetand sendinc, and hence also addthree:
rc3 = addthree rc;
sendget rc3;
I rc3 : Counter
3 : Nat
Notice, though, that the type of rc3 here is just Counter – passing it through the
addthree operation has lost some information about its type.
January 15, 2000 28. PURE OBJECTS AND CLASSES 230
28.3 Interface Types
Using type operators, we rewrite the type Counter in two parts,
Counter = Object CounterM;
where
CounterM = R. {get: R!Nat, inc:R!R};
I CounterM = R. {get:R!Nat, inc:R!R}: * ) *
is a type operator representing the interface of counter objects (the part that is
specific to the fact that these are counters and not some other kind of objects) and
Object = I::*)*. {9X, {state:X, methods:(I X)}};
I Object = I::*)*. {9X, {state:X,methods:I X}}: (*)*) ) *
is a type operator (whose parameter is a type operator!) that captures the common
structure of all object types.
If we similarly define
ResetCounterM = R. {get: R!Nat, inc:R!R, reset:R!R};
ResetCounter = Object ResetCounterM;
I ResetCounterM = R. {get:R!Nat, inc:R!R, reset:R!R}: * ) *
ResetCounter = Object ResetCounterM: *
we have not only
ResetCounter <: Counter
as before but also
ResetCounterM <: CounterM
by the rules above for subtyping between type operators.
28.4 Sending Messages to Objects
We can now give sendinc a more refined typing by abstracting over sub-operators
of CounterM
sendinc =
M<:CounterM.
o:Object(M).
let {X, b} = o in
({9X = X,
{state = b.methods.inc(b.state),
methods = b.methods}}
as Object(M));
January 15, 2000 28. PURE OBJECTS AND CLASSES 231
I sendinc : 8M<:CounterM. Object M ! Object M
and send messages to counter and reset-counter objects like this (assuming sendget
and sendreset are defined analogously):
sendget [CounterM] (sendinc [CounterM] c);
I 6 : Nat
sendget [ResetCounterM]
(sendreset [ResetCounterM]
(sendinc [ResetCounterM] rc));
I 0 : Nat
Intuitively, the type of sendinc can be read “give me an object interface refining
the interface of counters, then give me an object with that interface, and I’ll return
you another object with the same interface.”
28.4.1 Exercise: Check carefully that sendinc has the claimed type and that the
expressions involving applications of sendinc are well typed. 2
28.4.2 Exercise: Define sendget and sendreset. 2
28.5 Simple Classes
In Chapter 14, we defined a class to be a function from states to objects, where
objects were records of methods. Here, an object is more than just a record of
methods: it includes a representation type and a state as well as methods. More-
over, each of the methods here takes the state as a parameter, so it doesn’t make
sense to pass the state to the class. In fact, a class here (as long as we are holding
the representation type fixed) is just a record of methods – no packaging, and no
abstraction of the whole thing on the state.
CounterR = Nat;
counterClass =
{get = x:CounterR. x,
inc = x:CounterR. succ(x)}
as {get: CounterR!Nat, inc:CounterR!CounterR};
I counterClass : {get:CounterR!Nat, inc:CounterR!CounterR}
Or, using the CounterM operator to write the annotation more tersely:
counterClass =
{get = x:CounterR. x,
inc = x:CounterR. succ(x)}
as CounterM CounterR;
January 15, 2000 28. PURE OBJECTS AND CLASSES 232
I counterClass : CounterM CounterR
We then build an instance by adding state and packaging:
c = {9X = CounterR,
{state = 0,
methods = counterClass}}
as Counter;
I c : Counter
Here is a simple subclass...
resetCounterClass =
let super = counterClass in
{get = super.get,
inc = super.inc,
reset = x:CounterR. 0}
as ResetCounterM CounterR;
I resetCounterClass : ResetCounterM CounterR
28.6 Adding Instance Variables
A record representation for counters:
CounterR = {x:Nat};
counterClass =
{get = s:CounterR. s.x,
inc = s:CounterR. {x=succ(s.x)}}
as CounterM CounterR;
A more interesting representation using updatable records (Chapter 23):
CounterR = {#x:Nat};
counterClass =
{get = s:CounterR. s.x,
inc = s:CounterR. s x=succ(s.x)}
as CounterM CounterR;
I counterClass : CounterM CounterR
counterClass : CounterM CounterR
(Note that objects built from these classes will have the same old type Counter,
and the same message-sending code as before will apply without change.)
Now, because we’ve used polymorphic update operations to define the meth-
ods of the counter class, it is actually not necessary to know that the state has
exactly type CounterR: we can also work with states that are subtypes of this type.
January 15, 2000 28. PURE OBJECTS AND CLASSES 233
counterClass =
R<:CounterR.
{get = s:R. s.x,
inc = s:R. s x=succ(s.x)}
as CounterM R;
I counterClass : 8R<:CounterR. CounterM R
To build an object from the new counterClass, we simply supply CounterR itself
as the representation:
c = {9X = CounterR,
{state = {#x=0},
methods = counterClass [CounterR]}}
as Counter;
I c : Counter
We can write resetCounterClass in the same style:
resetCounterClass =
R<:CounterR.
let super = counterClass [R] in
{get = super.get,
inc = super.inc,
reset = s:R. s x=0}
as ResetCounterM R;
I resetCounterClass : 8R<:CounterR. ResetCounterM R
Finally, we can write backupCounterClass in the same style, this time abstract-
ing over a subtype of BackupCounterR: We can define another subclass – backup
counters – this time using a different representation type:
BackupCounterM = R. {get: R!Nat, inc:R!R, reset:R!R, backup:R!R};
BackupCounterR = {#x:Nat,#old:Nat};
backupCounterClass =
R<:BackupCounterR.
let super = resetCounterClass [R] in
{get = super.get,
inc = super.inc,
reset = s:R. s x=s.old,
backup = s:R. s old=s.x}
as BackupCounterM R;
I backupCounterClass : 8R<:BackupCounterR. BackupCounterM R
28.6.1 Exercise [Moderate]: We have used polymorphic update in this section to
allow methods in classes to update “their” instance variables while leaving room
for subclasses to extend the state with additional instance variables. Show that it
is possible to achieve the same effect even in a type system lacking polymorphic
record update. 2
January 15, 2000 28. PURE OBJECTS AND CLASSES 234
28.7 Classes with “Self”
In Section 14.6, we saw how to extend imperative classes with a mechanism allow-
ing the methods of a class to refer to each other recursively. This extension also
makes sense in the pure setting.
We begin by abstracting counterClass on a collection of methods (appropriate
for the same representation type R):
counterClass =
R<:CounterR.
self: CounterM R.
{get = s:R. s.x,
inc = s:R. s x=succ(s.x)}
as CounterM R;
To build an object from this class, we have to build the fixed point of the function
counterClass:
c = {9X = CounterR,
{state = {#x=0},
methods = fix (counterClass [CounterR])}}
as Counter;
I c : Counter
To use this new mechanism, we define a new form of “counters with a set opera-
tion”:
SetCounterM = R. {get: R!Nat, set:R!Nat!R, inc:R!R};
The implementation of the setCounterClass defines a set method and uses the
set and get methods of self to implement the inc method:
setCounterClass =
R<:CounterR.
self: SetCounterM R.
let super = counterClass [R] self in
{get = super.get,
set = s:R. n:Nat. s x=n,
inc = s:R. self.set s (succ(self.get s))}
as SetCounterM R;
Finally, we can further extend setCounterClass to form a class of instrumented
counters, whose set operation counts the number of times that it has been called:
InstrumentedCounterM =
R. {get: R!Nat, set:R!Nat!R, inc:R!R, accesses:R!Nat};
InstrumentedCounterR = {#x:Nat,#count:Nat};
instrumentedCounterClass =
January 15, 2000 28. PURE OBJECTS AND CLASSES 235
R<:InstrumentedCounterR.
self: InstrumentedCounterM R.
let super = setCounterClass [R] self in
{get = super.get,
set = s:R. n:Nat.
let r = super.set s n in
r count=succ(r.count),
inc = super.inc,
accesses = s:R. s.count}
as InstrumentedCounterM R;
Note that calls to inc are included in the access count, since inc is implemented in
terms of self.set.
28.8 Class Types
We can write the type of counterClass as
CounterClass = Class CounterM CounterR;
where:
Class = M::*)*. R. 8R<:R. M R ! M R;
I Class = M::*)*. R. 8R'<:R. M R' ! M R': (*)*) ) * ) *
In other words, Class M R is the type of classes with representation type R and
methods M. Class itself is a higher-order operator, like Object.
28.9 Generic Inheritance
Going further along the same lines, we can actually use type operators to con-
struct well-typed terms that perform instantiation of classes (object creation) and
subclassing.
The code that performs the instantiation of counterClass to yield a counter
does not depend in any way on the fact that we are building a counter as opposed
to some other kind of object. We can avoid writing this boilerplate it over and
over by abstracting out counterClass, CounterM, CounterR, and the initial value
{#x=0} as follows:
new =
M<:TopM.
R<:Top.
c: Class M R.
r:R.
{9X = R,
{state = r,
methods = fix (c [R])}}
as Object M;
January 15, 2000 28. PURE OBJECTS AND CLASSES 236
I new : 8M<:TopM. 8R. Class M R ! R ! Object M
where we write TopM for the “maximal interface” X.Top:
TopM = X.Top;
We can now build counter objects by applying new to counterClass as follows:
c = new [CounterM] [CounterR] counterClass {#x=0};
I c : Object CounterM
Similarly, we can write a generic function that builds a subclass given a class
and a “delta” that shows how the methods of the subclass are derived from the
methods of the superclass. We begin with the concrete subclass setCounterClass
from Section 28.6:
setCounterClass =
R<:CounterR.
self: SetCounterM R.
let super = counterClass [R] self in
{get = super.get,
set = s:R. n:Nat. s x=n,
inc = s:R. self.set s (succ(self.get s))}
as SetCounterM R;
Abstracting out the parts that are specific to counters leaves the following param-
eterized skeleton:
extend =
SuperM <: TopM.
SuperR.
superClass: Class SuperM SuperR.
SelfM <: SuperM.
SelfR <: SuperR.
delta: (8R<:SelfR. SuperM R ! SelfM R ! SelfM R).
(R<:SelfR.
self: SelfM R.
let super = superClass [R] self in
delta [R] super self)
as Class SelfM SelfR;
I extend : 8SuperM<:TopM.
8SuperR.
Class SuperM SuperR !
(8SelfM<:SuperM.
8SelfR<:SuperR.
(8R<:SelfR. SuperM R!SelfM R!SelfM R) !
Class SelfM SelfR)
January 15, 2000 28. PURE OBJECTS AND CLASSES 237
In other words, extend takes several parameters (SuperM to delta) and returns a
class—i.e., a function that takes a representation type R (the “final type” that will
eventually be provided by the new function) and a vector of “self methods” special-
ized to the type R and returns a new vector of self methods. The most important
bit of this definition—the bit that does all the work—is the parameter delta. It
takes the final type R and two method vectors—the “super methods” calculated
by instantiating the superclass at R and self and the “self methods” provided by
new—and returns the self methods.
Now we can recover setCounterClass by extending counterClass like this:
setCounterClass =
extend [CounterM] [CounterR] counterClass
[SetCounterM] [CounterR]
(R<:CounterR.
super: CounterM R.
self: SetCounterM R.
{get = super.get,
set = s:R. n:Nat. s x=n,
inc = s:R. self.set s (succ(self.get s))});
I setCounterClass : Class SetCounterM CounterR
28.9.1 Exercise [Recommended]: Use the fullupdate checker from the course di-
rectory to implement the following extensions to the classes above:
1. Reimplement setCounterClass and instrumentedCounterClass using the
generic inheritance operations explored in this section.
2. Extend your modified instrumentedCounterClasswith a subclass that adds
a reset method. 2
Chapter 29
Structures and Modules
By Robert Harper and Benjamin Pierce
It’s not clear yet whether this sketch will eventually be just a chapter of the present book
or a whole book in its own right. The latter seems more likely at the moment.
29.1 Basic Structures
Structures ! X S
Syntax
t ::= (terms...)
t as T coercion
x variable
x:T.t abstraction
t t application
{S X=T::K,t} structure creation
bodyof(t) term component of a structure
v ::= (values...)
x:T.t abstraction value
{S X=T::K,v} structure value
T ::= (types...)
X type variable
T!T type of functions
{S X::K,T} structure type
typeof(t) type component of a structure
  ::= (contexts...)
238
January 15, 2000 29. STRUCTURES AND MODULES 239
; empty context
 ; x:T term variable binding
 ; X::K type variable binding
K ::= (kinds...)
* kind of proper types
Evaluation (t  ! t 0)
t1 as T2  ! t1 (E-COERCE1)
(x:T11.t12) v2  ! fx 7! v2gt12 (E-BETA)
t1  ! t1 0
t1 t2  ! t 01 t2 (E-APP1)
t2  ! t2 0
v1 t2  ! v1 t 02 (E-APP2)
t1  ! t 01
bodyof(t1)  ! bodyof(t01) (E-BODYOF)
X =2 FV(v2)
bodyof({S X=T1,v2})  ! v2 (E-STRUCTBETA)
X 2 FV(t2)
{S X=T1,t2}  ! {S X=T1,fX 7! T1gt2} (E-STRUCTSUBST)
X =2 FV(t2) t2  ! t 02
{S X=T1,t2}  ! {S X=T1,t 02} (E-STRUCT)
Type equivalence (  ` S  T)
  ` T :: K
  ` T  T :: K
(Q-REFL)
  ` T  S :: K
  ` S  T :: K
(Q-SYMM)
  ` S  U :: K   ` U  T :: K
  ` S  T :: K
(Q-TRANS)
  ` S1  T1 :: *   ` S2  T2 :: *
  ` S1!S2  T1!T2 :: * (Q-ARROW)
  ` T1 :: K1   ` fX 7! T1gt2 : T2
  ` typeof({S X=T1,t2})  T1 :: K1
(Q-STRUCTBETA)
January 15, 2000 29. STRUCTURES AND MODULES 240
Kinding (  ` T :: K)
  ` T1 :: *   ` T2 :: *
  ` T1!T2 :: * (K-ARROW)
X::K 2  
  ` X :: K
(K-TVAR)
 ; X::K ` T1 :: *
  ` {S X::K,T1} :: *
(K-STRUCT)
  ` v1 : {S X::K,T1}
  ` typeof(v1) :: K
(K-TYPEOF)
Typing (  ` t : T)
  ` T1 : *   ` t1 : T1
  ` t1 as T1 : T1
(T-COERCE)
x:T 2  
  ` x : T
(T-VAR)
  ` t : S   ` S  T :: *
  ` t : T
(T-EQ)
  ` T1 :: *  ; x:T1 ` t2 : T2
  ` x:T1.t2 : T1!T2 (T-ABS)
  ` t1 : T11!T12   ` t2 : T11
  ` t1 t2 : T12
(T-APP)
  ` T1 :: K1   ` fX 7! T1gt2 : fX 7! T1gT2  ; X::K1 ` T2 :: *
  ` {S X=T1,t2} : {S X::K1,T2}
(T-STRUCT)
  ` v0 : {S X::K1.T2}
  ` bodyof(v0) : fX 7! typeof(v0)gT2 (T-BODYOF)
Abbreviations
unannotated binder for X def= X::*
Important points:
 The calculus relies on an evaluation relation to determine under what cir-
cumstances typeof(t) makes sense. In the presence of effects, it need not
make sense.
 We omit a general “valuability” judgement at this point, in favor of a syntac-
January 15, 2000 29. STRUCTURES AND MODULES 241
tic definition of “open values”
 typeof always makes sense on values (or more generally, later, a valuable
expression)
 bodyof is restricted to values because of the substitution of typeof. (We
could go a little further and allow it for nonvalues in the non-dependent
case, where the substitution doesn’t do anything.)
 With these restrictions, all of this should be encodable using existentials with
the open elimination form.
 We don’t evaluate type expressions, since they play no role in computation.
This would need to be revisited if we had any kind of type analysis (Dynamic,
etc.).
 Structure values are binders. Dependencies are eliminated during projection
(this is easy in the binary case).
 On the face of it, there are two choices for type equivalence for typeof: (1)
we can include the computation rule above for reducing a typeof applied
to a structure, or (2) we can eliminate this rule and rely on reflexivity for
comparing typeof(structure) expressions. We have chosen the first because it
supports a “phase distinction,” in the sense that type equality never depends
on any notion of equality for ordinary expressions — i.e. type equality can
be computed by looking only at the types. Taking the second choice is a step
on the road to structure sharing.
 We have omitted the congruence rule for type reduction for typeof, since
the only possible arguments to typeof are already values (when we extend
to paths later, this needs to be revisited — note that this may be tricky, since
we do not have a “full beta-equivalence” notion of equality on terms: we
may need to define a simplification relation separate from evaluation)
 Structure values do not have principal types, for the same reason as exis-
tential values did not. The fix is the same: if every structure intro form is
immediately ascribed, then the term will have a principal type.
January 15, 2000 29. STRUCTURES AND MODULES 242
29.2 Record Kinds and Subkinding
Records of types ! ) trcd
New syntactic forms
T ::= ... (types...)
{li=Ti
i21::n} record of types
T.l projection
K ::= ... (kinds...)
{li::Ki
i21::n} kind of records of types
New type equivalence rules (  ` S  T)
  `
i21::n
Ti :: Ki
  ` {li=Ti i21::n}.li  Ti :: Ki
(Q-TRCDBETA)
  ` T1  T 01 :: {li::Ki
i21::n}
  ` T1.li  T 01.li :: Ki
(Q-TYPROJ)
  `
i21::n
Ti  T 0i :: Ki
  ` {li=Ti i21::n}  {li=T 0i
i21::n} :: {li::Ki
i21::n}
(Q-TRCD)
  ` T :: {li::Ki
i21::n}   ` T 0 :: {li::Ki
i21::n}
  `
i21::n
T.li  T
0.li :: Ki
  ` T  T 0 :: {li::Ki
i21::n}
(Q-TRCDEXT)
  ` {li=Ti i21::n} :: K
  ` {li=T
i21::n
i } :: K
 is a permutation of f1::ng
  ` {li=Ti i21::n}  {li=T
i21::n
i } :: K
(Q-TRCD-PERM)
  ` S  T :: K1   ` K1 <: K2
  ` S  T :: K2
(Q-SUB)
New kind formation rules
  `
i21::n
Ki ok
  ` {li::Ki i21::n} ok
(KF-TRCD)
New kind equivalence rules
January 15, 2000 29. STRUCTURES AND MODULES 243
 is a permutation of f1::ng
  ` {li::Ki i21::n} ok
  ` {li::K
i21::n
i } ok
  ` {li::Ki i21::n}  {li::K
i21::n
i }
(KEQV-TRCD-PERM)
New kinding rules (  ` T :: K)
  `
i21::n
Ti :: Ki
  ` {li=Ti
i21::n} :: {li::Ki
i21::n}
(K-TRCD)
  ` T0 :: {li::Ki i21::n}
  ` T0.lj :: Kj
(K-TYPROJ)
New abbreviations
{...Ki...}
def
= {...i::Ki...}
New subkinding rules
  ` K1  K2
  ` K1 <: K2
(SK-EQV)
  ` K1 <: K2   ` K2 <: K3
  ` K1 <: K3
(SK-TRANS)
  ` {li::Ki i21::n+k} ok
  ` {li::Ki i21::n+k} <: {li::Ki
i21::n}
(S-TRCD-WIDTH)
  ` {li::Ji i21::n} ok   ` {li::Ki i21::n} ok
  `
i21::n
Si <: Ti
  ` {li::Ji i21::n} <: {li::Ki i21::n}
(SK-TRCD-DEPTH)
Notes:
 We include an extensionality rule for several reasons:
– It’s natural. (Programmers would expect it.)
– It’s needed for selfification to work.
– The present algorithm relies on it (weak argument, but there it is)
January 15, 2000 29. STRUCTURES AND MODULES 244
29.3 Singleton Kinds
Singleton kinds ! Eq
New syntactic forms
K ::= ... (kinds...)
Eq(T) singleton kind
New type equivalence rules (  ` S  T)
  ` S  T :: K1   ` K1 <: K2
  ` S  T :: K2
(Q-SUB)
  ` S :: Eq(T)
  ` S  T :: *
(Q-SINGLETON1)
  ` S  T :: *
  ` S  T :: Eq(S)
(Q-SINGLETON2)
New kind formation rules
  ` S :: *
  ` Eq(S) ok
(KF-SINGLETON)
New kind equivalence rules
  ` S  T :: *
  ` Eq(S)  Eq(T)
(KEQV-SINGLETON)
New subkinding rules
  ` K1  K2
  ` K1 <: K2
(SK-EQV)
  ` K1 <: K2   ` K2 <: K3
  ` K1 <: K3
(SK-TRANS)
  ` S :: *
  ` Eq(S) <: *
(SK-SINGLETON)
New kinding rules (  ` T :: K)
  ` S :: *
  ` S :: Eq(S)
(K-SINGLETON)
January 15, 2000 29. STRUCTURES AND MODULES 245
29.4 Dependent Function and Record Kinds
Dependent records of types ! ) trcd depkind
New syntactic forms
K ::= ... (kinds...)
X::K.K dependent kind of operators
{li . Xi ::Ki
i21::n} dependent kind of records of types
New kind formation rules
  ` K1 ok   ; X::K1 ` K2 ok
  ` X::K1.K2 ok
(KF-TARR)
  ; X1::K1   Xi-1::Ki-1 ` i21::n Ki ok
  ` {li . Xi ::Ki i21::n} ok
(KF-TRCD)
New kind equivalence rules
  ` K1  K 01   ; X::K1 ` K2  K
0
2
  ` X::K1.K2  X::K 01.K
0
2
(KEQV-TARR)
 is a permutation of f1::ng
  ` {li . Xi ::Ki i21::n} ok
  ` {li . Xi ::K
i21::n
i } ok
  ` {li . Xi ::Ki i21::n}  {li . Xi ::K
i21::n
i }
(KEQV-TRCD-PERM)
New kinding rules (  ` T :: K)
 ; X::K1 ` T2 :: K2
  ` X::K1.T2 :: X::K1.K2
(K-TABS)
  ` T1 :: X::K11.K12   ` T2 :: K11
  ` T1 T2 :: fX 7! T2g K12 (K-TAPP)
 ; X1::K1    Xi-1::Ki-1 `
i21::n Ti :: Ki
  ` {li . Xi =Ti i21::n} :: {li . Xi ::Ki
i21::n}
(K-TRCD)
  ` T0 :: {li . Xi ::Ki
i21::n}
  ` T0.lj :: fX1 7! T0.l1g    fXj-1 7! T0.lj-1gKj (K-TYPROJ)
New subkinding rules
  ` {li . Xi ::Ki i21::n+k} ok
  ` {li . Xi ::Ki i21::n+k} <: {li . Xi ::Ki i21::n}
(S-TRCD-WIDTH)
January 15, 2000 29. STRUCTURES AND MODULES 246
  ` {li . Xi ::Ji i21::n} ok
  ` {li . Xi ::Ki i21::n} ok
 ; X1::K1   Xi-1::Ki-1 `
i21::n
Si <: Ti
  ` {li . Xi ::Ji i21::n} <: {li . Xi ::Ki i21::n}
(SK-TRCD-DEPTH)
Notes:
 We introduced primitive labeled record kinds because Cardelli’s encoding
doesn’t work in the presence of dependencies, because it presumes the ability
to reorder labels arbitrarily to match the fixed global order; but this may
break dependencies between fields.
29.5 Dependent Record Expressions and Records of Types
Dependent record terms (??) ???
New syntactic forms
t ::= ... (terms...)
{li . xi =ti
i21::n} dependent record
v ::= ... (values...)
{li . xi =vi
i21::n} dependent record value
New evaluation rules (t  ! t 0)
for each i fx1:::xi-1g \ FV(vi) = ;
{li . xi =vi
i21::n}.li  ! vi (E-RCDBETA)
for each j < i, fx1:::xj-1g \ FV(vj) = ;
for some j < i, xj 2 FV(ti)
t 0i = fx1 7! v1g    fxi-1 7! vi-1gti
{lj . xj =vj
j21::i-1,li. xi=ti,lk . xk =tk
k2i+1::n}  !
{lj . xj =vj
j21::i-1,li. xi=t
0
i,lk . xk =tk
k2i+1::n}
(E-RECORDSUBST)
for each i < j, fx1:::xi-1g \ FV(vi) = ;
fx1:::xj-1g \ FV(tj) = ;
tj  ! t 0j
{li . xi =vi
i21::j-1,lj. xj=tj,lk . xk =tk
k2j+1::n}  !
{li . xi =vi
i21::j-1,lj. xj=t
0
j,lk . xk =tk
k2j+1::n}
(E-RECORD)
New typing rules (  ` t : T)
for each i   ; x1:T1; : : : ; xi-1:Ti-1 ` ti : Ti
  ` {li . xi =ti
i21::n} : {li . xi :Ti
i21::n}
(T-RCD)
January 15, 2000 29. STRUCTURES AND MODULES 247
New abbreviations
{...ti...}
def
= {...i . xi =ti...} where xi is fresh
29.6 Higher-Kind Singletons
Higher-order singletons ????
New syntactic forms
K ::= ... (kinds...)
EQ(T::K) higher singleton kind
New kind formation rules
  ` T :: K
  ` EQ(T::K) ok
(KF-HOS)
New kind equivalence rules
  ` T  T 0 :: K   ` K  K 0
  ` EQ(T::K)  EQ(T0::K 0)
(KEQV-HOS)
  ` T :: *
  ` EQ(T::*)  Eq(T)
(KEQV-HOS-TYPE)
  ` T :: Eq(U)
  ` EQ(T::Eq(U)) Eq(T)
(KEQV-HOS-SINGLETON)
  ` T :: X::K1.K2
  ` EQ(T::X::K1.K2)  X::K1.EQ(T X :: K2)
(KEQV-HOS-TARR)
  ` T :: {li. Xi::Ki i21::n}
  ` EQ(T::{li. Xi::Ki i21::n})  {li. Xi::EQ(T.li::Ki) i21::n}
(KEQV-HOS-TRCD)
New kinding rules (  ` T :: K)
  ` T :: X::K1.K2
 ; X::K1 ` T X :: K 02
  ` T :: X::K1.K 02
(K-TARR-SELF)
January 15, 2000 29. STRUCTURES AND MODULES 248
  ` T :: {li. Xi::Ki
i21::n}
 ; X1::K1    Xi-1::Ki-1 ` i21::n T.li :: K 0i
  ` T :: {li. Xi::K
0
i
i21::n}
(K-TRCD-SELF)
29.7 First-class Substructures and Functors
Dependent functions ???
New syntactic forms
T ::= ... (types...)
x:T.T type of dependent functions
New type equivalence rules (   ` S  T)
  ` T :: K
  ` T  T:: K
(Q-REFL)
  ` T  S:: K
  ` S  T:: K
(Q-SYMM)
  ` S  U:: K   ` U  T :: K
  ` S  T:: K
(Q-TRANS)
  ` S1  T1 :: *  ; x:S1 ` S2  T2 :: *
  ` x:S1.S2  x:T1.T2 :: *
(Q-ARROW)
New kinding rules (  ` T :: K)
  ` T1 :: *  ; x:T1 ` T2 :: *
  ` x:T1.T2 :: *
(K-ARROW)
New typing rules (  ` t : T)
  ` t : S   ` S  T:: *
  ` t : T
(T-EQ)
  ` T1 :: *  ; x:T1 ` t2 : T2
  ` x:T1.t2 : x:T1.T2
(T-ABS)
  ` t1 : x:T11.T12 x =2 FV(T11)   ` t2 : T11
  ` t1 t2 : T12
(T-APP)
New abbreviations
T1!T2 def= x:T1.T2 where x =2 FV(T2)
January 15, 2000 29. STRUCTURES AND MODULES 249
Dependent records ????
New syntactic forms
T ::= ... (types...)
{li . xi :Ti
i21::n} type of dependent records
New type equivalence rules (   ` S  T)
  ` T :: K
  ` T  T:: K
(Q-REFL)
  ` T  S:: K
  ` S  T:: K
(Q-SYMM)
  ` S  U:: K   ` U  T :: K
  ` S  T:: K
(Q-TRANS)
  ` S1  T1 :: *   ` S2  T2 :: *
  ` S1!S2  T1!T2 :: * (Q-ARROW)
  ` {li . xi :Ti i21::n} :: *
  ` {li. xi:T
i21::n
i } :: *
 is a permutation of f1::ng
  ` {li . xi :Ti i21::n}  {li . xi :T
i21::n
i }:: *
(Q-RCD-PERM)
New typing rules (  ` t : T)
  ` t : S   ` S  T:: *
  ` t : T
(T-EQ)
for each i   ; x1:T1    xi-1:Ti-1 ` ti : Ti
  ` {li=ti i21::n} : {li . xi :Ti i21::n}
(T-RCD)
  ` t : {li . xi :Ti i21::n} fx1 : : :xj-1g \ FV(Tj) = ;
  ` t.lj : Tj
(T-PROJ)
New abbreviations
{...Ti...}
def
= {...i . x :Ti...} where x is fresh
Notes:
 These types are only apparently dependent: the elim forms apply only in
the non-dependent case, in the expectation that dependencies will first be
eliminated by propagation of sharing
 This approach depends crucially on the presence of singleton kinds, since
these provide the mechanism for propagating sharing
January 15, 2000 29. STRUCTURES AND MODULES 250
 We hold the type of earlier substructures abstract while checking the next
one — i.e., we propagate forward only type information, not “identity”
 The “selfification” rules allow us to specialize signatures (types of modules)
to propagate sharing. They are critical.
 Note that the T-RCD rule here does not do any substitution of earlier fields.
It could, but this would constitute a violation of abstraction (besides raising
the usual issues in combination with effects). This version of the rule, though,
relies on the presence of singleton kinds to be very useful. For example, we
want the expression
{l={S Int,...}, l'=3}
will not have the intended type
{l. x:{S *,...}, l'. x':typeof(x)}
by a direct application of this rule. Instead, we need to use singletons to give
the term the type
{l. x:{S Eq(Int),...}, l'. x':typeof(x)}
(a subtype of the previous type), from which T-RCD does derive the intended
type.
29.8 Second-Class Modules
phase-separation equations
29.9 Other points to make
 The old argument about whether modules are strong sums.
– The argument that strong sums are “not abstract” doesn’t hold water.
Our structures here are not either: the abstraction comes from the com-
bination of structures with ascription (or let-binding, etc.)
– A better reason is that strong sums propagate sharing information by
substitution, which doesn’t scale to systems with effects (the Harper/Lillibridge
calculus can be described as a variant of strong sums that does this right)
 Applicative vs. generative functors
Chapter 30
Planned Chapters
I’m not sure yet how much material will get added after this point—it depends mostly on
how much time it takes to get the rest into a polished state—but here are my top priorities:
 Basic material on modularity. (Bob Harper and I are working together on a de-
velopment that includes enough technicalities to understand module systems of the
complexity of SML97’s (or OCaml’s), including both first- and second-class vari-
ants. It’s a huge task, and it’s not clear yet whether we’re going to be able to finish
something, or whether, if we do, it will turn out to be just a long co-authored chapter
here or a short book in its own right.)
 Basics of dependent types. (General sums are the point where this gets hard.)
 Maybe some elementary material on intersection types, linear types, or the Curry-
Howard isomorphism.
 A chapter on Moggi’s computational lambda-calculus
 Something on curry-howard. (In any case, make sure these are in the bibliography:
gallier notes on constructive logic)
251
Appendices
252
Appendix A
Solutions to Selected Exercises
Solution to 3.2.13:
t  ! t 0
t  ! t 0
t  ! t
t  ! t 0 t 0  ! t 00
t  ! t 00
Solution to 3.3.2: By induction on the structure of t.
Case: t is a value
By Proposition 3.3.1, this case cannot occur.
Case: t = succ t1
Looking at the evaluation rules, we find that only the rule E-SUCC could possibly
be used to derive t  ! t 0 and t  ! t 00 (all the other rules have left-hand sides
whose outermost constructor is something other than succ). So there must be
two subderivations with conclusions of the form t1  ! t 01 and t1  ! t 001 . By
the induction hypothesis (which applies because t1 is a subterm of t), we obtain
t 01 = t
00
1 . But then succ t
0
1 = succ t
00
1 , as required.
Case: t = pred t1
Here there are three evaluation rules (E-PRED, E-BETANATIZ, and E-BETANATIS)
that might have been used to reduct t to t 0 and t 00. Notice, however, that these
rules do not overlap: if t matches the left-hand side of one rule, then it definitely
does not match the left-hand side of the others. (For example, if t matches E-PRED,
then t1 is definitely not a value, in particular not 0 or succ v.) This tells us that
the same rule must have been used to derive t  ! t 0 and t  ! t 00. If that rule was
E-PRED, then we use the induction hypothesis as in the previous case. If it was
E-BETANATIZ or E-BETANATIS, then the result is immediate.
253
January 15, 2000 A. SOLUTIONS TO SELECTED EXERCISES 254
Case: Other cases
Similar.
Solution to 4.2.3: There are several possibilities:
succ1 = n. s. z. s (n s z);
succ2 = n. s. z. n s (s z);
succ3 = n. plus c1 n;
Solution to 4.2.6: Here’s a simple one:
equal = m. n.
and (iszro (m prd n))
(iszro (n prd m));
Solution to 4.2.7: This is the solution I had in mind:
nil = hh. tt. tt;
cons = h. t. hh. tt. hh h (t hh tt);
head = l. l (h.t.h) fls;
tail = l.
fst (l (x. p. pair (snd p) (cons x (snd p)))
(pair nil nil));
isnull = l. l (h.t.fls) tru;
Here is a rather different approach:
nil = pair tru tru;
cons = h. t. pair fls (pair h t);
head = z. fst (snd z);
tail = z. snd (snd z);
isnull = fst;
Solution to 4.2.8:
ff = f. l.
test (isnull l)
(x. c0) (x. (plus (head l) (f (tail l)))) c0;
sumlist = fixpoint ff;
l = cons c2 (cons c3 (cons c4 nil));
equal (sumlist l) c9;
I (x. y. x)
January 15, 2000 A. SOLUTIONS TO SELECTED EXERCISES 255
Solution to 5.1.13: For convenience, let’s define a little notation first. If   is a
naming context, write  (x) for the index of x in  , counting from the right. Write
  n x for the context that results when x is removed from  . For example, if   =
a; b; c; d, then  (c) = 1 and   n c = a; b; d.
Now, the property that we want is that, if x =2 FV(s), then
removenames nx(fx 7! sgt) = f (x) 7! removenames nx(s)g(removenames (t)):
The proof proceeds by induction on t, using Definitions 4.4.5 and 5.1.9, some sim-
ple calculations, and some easy lemmas about removenames and the other basic
operations on terms. Convention 4.4.4 plays a crucial role in the abstraction case.
Solution to 6.3.8: Here’s a counterexample: the term (if false then true else 0)
is ill-typed, but evaluates to the well-typed term 0.
Solution to 7.2.3: T-TRUE and T-FALSE are introduction rules. T-IF is an elimina-
tion rule.
Solution to 7.3.1: Because the set of type expressions is empty (there is no base
case in the syntax of types).
Solution to 25.4.2: The proof proceeds by induction on a derivation of  ; x:S ` t :
T. There are cases for each of the typing rules (or, equivalently, each of the possible
forms of t).
Case T-VAR: t = z
with  (z) = T
There are two sub-cases to consider, depending on whether z is the same as x or
different. If z = x, then fx 7! sgz = s. The required result is then   ` s : S, which
is among the assumptions of the lemma. Otherwise, fx 7! sgz = z, and the desired
result is immediate.
Case T-ABS: t = y:T2.t1
T = T2!T1
 ; x:S; y:T2 ` t1 : T1
First note that, by convention 4.4.4, we may assume x 6= y and y =2 FV(s). Using
weakening and permutation on the given subderivation, we obtain  ; y:T2; x:S `
t1 : T1. By the induction hypothesis,  ; y:T2 ` fx 7! sgt1 : T1. By T-ABS,   `
y:T2. fx 7! sgt1 : T2!T1. But this is the needed result, since, by the definition
of substitution, fx 7! sgt = y:T1. fx 7! sgt1.
Case T-APP: t = t1 t2
 ; x:S ` t1 : T2!T1
 ; x:S ` t2 : T2
T = T2
By the induction hypothesis,   ` fx 7! sgt1 : T2!T1 and   ` fx 7! sgt2 : T2. By
T-APP,   ` fx 7! sgt1 fx 7! sgt2 : T, i.e.,   ` fx 7! sg(t1 t2) : T.
January 15, 2000 A. SOLUTIONS TO SELECTED EXERCISES 256
Case T-TRUE, T-FALSE: t = 0
T = Bool
Then fx 7! sgt = 0, and the desired result,   ` fx 7! sgt : T, is immediate.
Case T-IF: t = if t1 then t2 else t3
 ; x:S ` t1 : Bool
 ; x:S ` t2 : T
 ; x:S ` t3 : T
The induction hypothesis yields
  ` fx 7! sgt1 : Bool
  ` fx 7! sgt2 : T
  ` fx 7! sgt3 : T,
from which the result follows by T-IF. 2
Solution to 8.4.1:
Typed record patterns ! fg let pat (typed)
Pattern typing rules
` x : T) x:T (P-VAR)
for each i ` pi : Ti ) i
` {li=pi i21::n} : {kj:Tj j21::m}) 1; : : : ; n (P-RCD)
New typing rules (  ` t : T)
  ` t1 : T1 ` p : T1 )   ;  ` t2 : T2
  ` let p =t1 in t2 : T2
(T-LET)
Solution to 17.3.9: Here are the algorithmic constraint generation rules:
 (x) = T
  `F x : T jF fg
(CT-VAR)
 ; x:S `F t1 : T jF 0 C x 62 dom( )
  `F x:S.t1 : S!T jF 0 C (CT-ABS)
  `F t1 : T1 jF 0 C1   `F 0 t2 : T2 jF 00 C2 F
00 = X; F 000
  `F t1 t2 : X jF 000 C1 [ C2 [ fT1 = T2!Xg (CT-APP)
  `F 0 : Nat jF fg (CT-ZERO)
  `F t1 : T jF 0 C
  `F succ t1 : Nat jF 0 C [ fT = Natg
(CT-SUCC)
January 15, 2000 A. SOLUTIONS TO SELECTED EXERCISES 257
  `F t1 : T1 jF 0 C1   `F 0 t2 : T2 jF 00 C2   `F 00 t3 : T3 jF 000 C3
C 0 = C1 [ C2 [ C3 [ fT1 = Nat; T2 = T3!T3g
  `F iter T t1 t2 t3 : T3 jF 000 C 0
(CT-ITER)
The equivalence of the original rules and the algorithmic presentation can be stated
as follows:
1. (Soundness) If   `F t : T jF 0 C and the variables mentioned in   and t do
not appear in F, then   ` t : T jF 0nF C.
2. (Completeness) If   ` t : T jX C, then there is some permutation F of the
names in X such that   `F t : T j; C.
Both parts are proved by straightforward induction on derivations. For the appli-
cation case in part 1, the following lemma is useful:
If the type variables mentioned in   and t do not appear in F and if
  `F t : T jF 0 C, then the type variables mentioned in T and C do not
appear in F 0 n F.
For the same case in part 2, the following lemma is used:
If   `F t : T jF 0 C, then   `F;G t : T jF 0;G C, where G is any sequence
of fresh variable names.
Solution to 17.3.10: Representing constraint sets as lists of pairs of types, the con-
straint generation algorithm is a direct transcription of the inference rules given
above.
let rec recon ctx nextuvar t =
match t with
TmVar(fi,i,_) !
let tyS = gettype fi ctx i in
(tyS, nextuvar, [])
| TmAbs(fi, x, tyS, t1) !
let ctx' = addbinding ctx x (VarBind(tyS)) in
let (tyT1,nextuvar1,constr1) = recon ctx' nextuvar t1 in
(TyArr(tyS, tyshift tyT1 (-1)), nextuvar1, constr1)
| TmApp(fi,t1,t2) !
let (tyT1,nextuvar1,constr1) = recon ctx nextuvar t1 in
let (tyT2,nextuvar2,constr2) = recon ctx nextuvar1 t2 in
let NextUVar(tyX,nextuvar') = nextuvar2() in
let newconstr = [(tyT1,TyArr(tyT2,TyId(tyX)))] in
((TyId(tyX)), nextuvar', (newconstr constr1 constr2))
| TmZero(fi) ! (TyNat, nextuvar, [])
| TmSucc(fi,t1) !
let (tyT1,nextuvar1,constr1) = recon ctx nextuvar t1 in
(TyNat, nextuvar1, [(tyT1,TyNat)])
January 15, 2000 A. SOLUTIONS TO SELECTED EXERCISES 258
| TmPred(fi,t1) !
let (tyT1,nextuvar1,constr1) = recon ctx nextuvar t1 in
(TyNat, nextuvar1, [(tyT1,TyNat)])
| TmIsZero(fi,t1) !
let (tyT1,nextuvar1,constr1) = recon ctx nextuvar t1 in
(TyBool, nextuvar1, [(tyT1,TyNat)])
| TmTrue(fi) ! (TyBool, nextuvar, [])
| TmFalse(fi) ! (TyBool, nextuvar, [])
| TmIf(fi,t1,t2,t3) !
let (tyT1,nextuvar1,constr1) = recon ctx nextuvar t1 in
let (tyT2,nextuvar2,constr2) = recon ctx nextuvar1 t2 in
let (tyT3,nextuvar3,constr3) = recon ctx nextuvar2 t3 in
let newconstr = [(tyT1,TyBool); (tyT2,tyT3)] in
(tyT3, nextuvar3, List.concat [newconstr; constr1; constr2; constr3])
Solution to 17.4.4:
fX = Nat; Y = X!Xg fX 7! Nat; Y 7! Nat!Natg
fNat!Nat = X!Yg fX 7! Nat; Y 7! Natg
fX!Y = Y!Z; Z = U!Wg fX 7! U!W; Y 7! U!W; Z 7! U!Wg
fNat = Nat!Yg Not unifiable
fY = Nat!Yg Not unifiable
Solution to 17.4.7: One more variant of substitution is needed in the unification
function—the application of a substitution to all the types in some constraint set:
let substinconstr tyX tyT constr =
List.map
(fun (tyS1,tyS2) !
(substinty tyX tyT tyS1, substinty tyX tyT tyS2))
constr
Also crucial is the “occur-check” that detects circular dependencies:
let occursin tyX tyT =
let rec o = function
TyArr(tyT1,tyT2) ! o tyT1 || o tyT2
| TyNat ! false
| TyBool ! false
| TyId(s) ! (s=tyX)
in o tyT
The unification function is now a direct transcription of the rules given on page 126.
As usual, it takes a file position and string as extra arguments to be used in print-
ing error messages when unification fails. (This pedagogical version of the unifier
does not work very hard to print useful error messages. In practice, “explaining”
type errors can be one of the hardest parts of engineering a production compiler
for a language with type reconstruction.)
January 15, 2000 A. SOLUTIONS TO SELECTED EXERCISES 259
let unify fi ctx msg constr =
let rec u constr =
match constr with
[] !
[]
| (tyS,TyId(tyX)) :: rest !
if tyS = TyId(tyX) then
u rest
else if occursin tyX tyS then
error fi (msg ^ ": circular constraints")
else
List.append (u (substinconstr tyX tyS rest)) [(TyId(tyX),tyS)]
| (TyId(tyX),tyT) :: rest !
if tyT = TyId(tyX) then
u rest
else if occursin tyX tyT then
error fi (msg ^ ": circular constraints")
else
List.append (u (substinconstr tyX tyT rest)) [(TyId(tyX),tyT)]
| (TyNat,TyNat) :: rest !
u rest
| (TyBool,TyBool) :: rest !
u rest
| (TyArr(tyS1,tyS2),TyArr(tyT1,tyT2)) :: rest !
u ((tyS1,tyT1) :: (tyS2,tyT2) :: rest)
| (tyS,tyT)::rest !
error fi "Unsolvable constraints"
in
u constr
Solution to 17.5.6: Extending the type reconstruction algorithm to handle records
is not straightforward, though it can be done. The main difficulty is that it is not
clear what constraints should be generated for a record projection. A naive first
attempt would be
  ` t : T jX C
  ` t.li : X jX[fXg C [ fT = {li:X}g
but this is not satisfactory, since this rule says, in effect, that the field li can only
be projected from a record containing just the field li and no others.
An elegant solution was proposed by Wand [Wan87] and further developed by
Wand [Wan88, Wan89], Remy [Rém89, Rém90], and others. We introduce a new
kind of unification variable, called a row variable, ranging not over types but over
“rows” of field labels and associated types. Using row variables, the constraint
generation rule for field projection can be written
  ` t : T jX C
  ` t.li : X jX[fX;;g C [ fT = {};  = li:X g
(CT-PROJ)
January 15, 2000 A. SOLUTIONS TO SELECTED EXERCISES 260
where  and  are row variables and the operator combines two rows (assuming
that their fields are disjoint). That is, the term t.li has type X if t has a record type
with fields , where  contains the field li:X and some other fields .
The constraints generated by this refined algorithm are more complicated than
the simple sets of equations between types with unification variables of the original
reconstruction algorithm, since the new constraint sets also involve the associative
and commutative operator . A simple form of equational unification is needed
to find solutions to such constraint sets.
Solution to 9.5: There are well-typed terms in this system that are not strongly
normalizing. For example, consider the following:
t1 = r:Ref (Unit!Unit).
(r:=(x:Unit. (!r)x);
(!r) unit);
t2 = ref (x:Unit. x);
Applying t1 to t2 yields a (well-typed) divergent term.
Solution to 15.3.1: Lists:
Hungry functions:
f =
fix
(f: Nat!Hungry.
n:Nat.
fold [Hungry] f);
ff = fold [Hungry] f;
I Hungry = A. Nat ! A: *
f : Nat ! Hungry
ff : Hungry
ff1 = (unfold [Hungry] ff) 0;
I ff1 : Hungry
ff2 = (unfold [Hungry] ff1) 2;
I ff2 : Hungry
Fixed points:
fixpointT =
f:T!T.
(x:(A.A!T). f ((unfold [A.A!T] x) x))
(fold [A.A!T] (x:(A.A!T). f ((unfold [A.A!T] x) x)));
divergeT = X. fixpointT (x:T. x);
Untyped lambda-calculus:
January 15, 2000 A. SOLUTIONS TO SELECTED EXERCISES 261
D = X. X!X;
lam = f:D!D. fold [D] f;
ap = f:D. a:D. (unfold [D] f) a;
Untyped lambda-calculus with numbers and booleans:
Objects:
p =
let create =
fix
(cr: {x:Nat}!Counter.
s: {x:Nat}.
fold [Counter]
{get = s.x,
inc = _:Unit. cr {x=succ(s.x)}})
in
create {x=0};
p1 = (unfold [Counter] p).inc unit;
(unfold [Counter] p1).get;
I T = Nat: *
fixpointT : (T!T) ! T
divergeT : 8X. T
D = X. X ! X: *
lam : (D!D) ! D
ap : D ! D ! D
Counter = P. {get:Nat, inc:Unit!P}: *
p : Counter
p1 : Counter
((unfold [Counter] p1).get) : Nat
Solution to 21.2.3: Just one additional rule is needed:
  `I b : B   ` B * Bool
  `I t1 : T1   `I t2 : T2   ` T1 _ T2 = J
  `I if b then t1 else t2 : J
(TA-COND)
where the final premise says that J is a join of T1 and T2 in  .
Solution to 21.4.2: We begin by giving a pair of algorithms that, when presented
with  , S, and T, calculate a pair of types J and M, which we will claim are a join
and meet, respectively, of S and T. (The second algorithm may also fail, in which
case we claim that S and T have no meet in  .)
We write   ` S ^ T = M for “M is the meet of S and T in context  ” and
  ` S _ T = J for “J is the join of S and T in  .” The algorithms are defined
simultaneously as follows. (Note that some of the cases of the definition overlap.
January 15, 2000 A. SOLUTIONS TO SELECTED EXERCISES 262
Since it is technically convenient to treat meet and join as functions rather than
relations, we stipulate that the first clause that applies must be chosen.)
  ` S ^ T =
8>>>>>>>>>>>><
>>>>>>>>>>>>:
S if   ` S <: T
T if   ` T <: S
J!M if S = S1!S2
T = T1!T2
  ` S1 _ T1 = J
  ` S2 ^ T2 = M
8X<:U.M if S = 8X<:U.S2
T = 8X<:U.T2
 ; X<:U ` S2 ^ T2 = M
fail otherwise
  ` S _ T =
8>>>>>>>>>>>>>>>>><
>>>>>>>>>>>>>>>>>:
T if   ` S <: T
S if   ` T <: S
J if S = X with X<:U 2   and   ` U _ T = J
J if T = X with X<:U 2   and   ` S _ U = J
M!J if S = S1!S2
T = T1!T2
  ` S1 ^ T1 = M
  ` S2 _ T2 = J
8X<:U.J if S = 8X<:U.S2
T = 8X<:U.T2
 ; X<:U ` S2 _ T2 = J
Top otherwise
It is easy to check that ^ and _ are total functions: for every  , S, and T, there are
unique types M and J such that   ` S ^ T = M and   ` S _ T = J: just note that the
total weight of S and T with respect to   is always reduced in recursive calls.
Now let us verify that these definitions do indeed calculate meets and joins in
the subtype relation. The argument into two parts: Proposition A.1 shows that
the calculated meet is a lower bound of S and T and the join is an upper bound;
Proposition A.2 then shows that the calculated meet is greater than every common
lower bound of S and T and the join is less than every common upper bound.
A.1 Proposition:
1. If   ` S ^ T = M, then   ` M <: S and   ` M <: T.
2. If   ` S _ T = J, then   ` S <: J and   ` T <: J. 2
Proof: By a straightforward induction on the size of a “derivation” of   ` S ^ T =
M or   ` S _ T = J (i.e., the number of recursive calls to the definitions of ^ and _
needed to calculate M or J). 2
January 15, 2000 A. SOLUTIONS TO SELECTED EXERCISES 263
A.2 Proposition:
1. Suppose that   ` S ^ T = M and, for some L, that   ` L <: S and   ` L <: T.
Then   ` L <: M.
2. Suppose that   ` S _ T = J and, for some U, that   ` S <: U and   ` T <: U.
Then   ` J <: U. 2
Proof: Simultaneously, by induction on the total size of derivations of   ` L <: S
and   ` L <: T (for part 1) or   ` S <: U and   ` T <: U (for part 2).
In both parts, let us deal first with the case where   ` S <: T or   ` T <: S.
If   ` S <: T, then   ` S ^ T = S and   ` S _ T = T. But then   ` L <: M and
  ` J <: U by assumption. Similarly when   ` T <: S.
To complete the proofs, assume that   ` S 6<: T and   ` T 6<: S and consider the
two parts of the proposition in turn.
1. Consider the form of L.
Case: L = Top
Then S = Top and T = Top, so   ` S <: T and this case has already been dealt
with.
Case: L = X
If either S or T is the variable X, then we have either   ` S <: T or   ` T <: S;
these cases have already been dealt with.
Otherwise, by the inversion lemma, we have   ` U <: S and   ` U <: T,
where X<:U 2  . The induction hypothesis yields   ` U <: M, from which
  ` X <: M follows by S-TVAR and S-TRANS.
Case: L = A!B
First note that, since   ` S 6<: T and   ` T 6<: S, neither S nor T can be Top, so
the only remaining case is where
S = V!P
T = W!Q
with
  ` V <: A
  ` B <: P
  ` W <: A
  ` B <: Q:
Also, by the definition of meets, M = J!N with
  ` V _ W = J
  ` P ^ Q = N:
January 15, 2000 A. SOLUTIONS TO SELECTED EXERCISES 264
Applying the induction hypothesis, we obtain
  ` J <: A
  ` B <: N;
from which   ` L <: M follows by S-ARROW.
Case: L = 8X<:U.B
Similar.
2. First, observe that, by the inversion lemma, there are two possibilities for S—
either it is a variable whose upper bound is a subtype of U, or else its form
depends on the form of U—and similarly for T. Let us deal first with the first
possibility for both S and T, leaving the structural cases to be considered in
detail.
If S = Y with  (Y) = R and   ` R <: U, then, by the definition of _, we have
  ` R _ T = J. The induction hypothesis now yields   ` J <: U, and we are
finished. Similarly if T is a variable bounded by U.
Now suppose that the forms of S and T depend on the form of U.
Case: U = Top
Immediate.
Case: U = X
By the inversion lemma, we have S = X and T = X; we have dealt with this
case already.
Case: U = A!B
Then by the inversion lemma we have
S = V!P
T = W!Q
with
  ` A <: V
  ` P <: B
  ` A <: W
  ` Q <: B:
The rest of the argument proceeds as in the corresponding case in part 1.
Case: U = 8X<:A.B
Similar. 2
January 15, 2000 A. SOLUTIONS TO SELECTED EXERCISES 265
Solution to 21.4.3:
1. Using the inversion lemma, I count 9 common subtypes of S and T:
8X<:A0!B. A!B 0
8X<:A0!B. Top!B 0
8X<:A0!B. X
8X<:A0!Top. A!B 0
8X<:A0!Top. Top!B 0
8X<:A0!Top. X
8X<:Top. A!B 0
8X<:Top. Top!B 0
8X<:Top. X:
2. Both
8X<:A0!B. A!B 0
and
8X<:A0!B. X
are lower bounds for S and T, but these two types have no common supertype
that is also a subtype of S and T.
3. Consider S!Top and T!Top. (Or, if you like, 8X<:A 0!B. A!B 0 and 8X<:A0!B. X.)
Solution to ??: Note that the two kinds of quantifiers—bounded and unbounded—
should not be allowed to mix: there should be a subtyping rule for comparing two
bounded quantifiers and another for two unbounded quantifiers, but no rule for
comparing a bounded to an unbounded quantifier. Otherwise we’d be right back
where we started!
1. See [KS92] for details.
2. No. In any practical language with subtyping, we will want to allow width
subtyping on record types. But the empty record type is a kind of maximal
type (among record types), and it can be used to cause divergence in the
subtype checker using a modified version of Ghelli’s example. If
T = 8[X<:{}|] :{a: 8[Y<:X|]:Y}
then the input
X0<:{a:T} ` X0 <: {a: 8[X1<:X0|]:X1}
will cause the subtype checker to diverge. [Martin Hofmann helped work
out this example.]
Appendix B
Summary of Notation
B.1 Metavariable Conventions
IN TEXT IN ML CODE USAGE
p, q, r, s, t, u s, t terms
x, y, z x, y term variables
v, w v, w values
M, N, P, Q, S, T, U, V tyS, tyT types
A, B, C tyA, tyB base types
, , , Æ alpha, beta unification variables
X, Y, Z tyX, tyY type variables
K, L kK, kL kinds
 , ctx contexts
fi file position information
J arbitrary typing statements
B.2 Rule Naming Conventions
PREFIX USAGE
E- evaluation
XA- exposure
K- kinding
M- matching
P- pattern typing
Q- type equivalence
QA- algorithmic type equivalence
RA- algorithmic type reduction
266
January 15, 2000 B. SUMMARY OF NOTATION 267
PREFIX USAGE
S- subtyping
SA- algorithmic subtyping
T- typing
TA- algorithmic typing
Appendix C
Suggestions for Larger Projects
These need to be cleaned up, and I’d like to add several more.
This appendix collects some ideas for larger course projects based on the ma-
terial in these notes and on the research literature on type systems. Most of the
projects involve some additional reading and some implementation work.
The suggestions are roughly categorized into “T” [theoretical] projects, which
are more open-ended and may require more reading, thinking, and design before
getting started, and “I” [implementation] projects, which are somewhat more spe-
cific and involve getting down to implementation fairly early. This does not mean
that the “T” projects are better – or even harder, ultimately – than “I” projects, but
the “I” projects may be easier to get started on.
One note on the implementation-oriented projects. You should feel free to use
any programming language you’re comfortable with for building projects in... but
if your favorite language happens to be C or Pascal, I urge you to think seriously
about learning and using some higher-level language with built-in garbage collec-
tion and facilities for high-level symbol manipulation—for example, ML, Haskell,
Scheme, Modula 3, or even Java.1 All of these projects can be done in Pascal, C, or
C++, but you’ll spend more time than you can imagine chasing pointer bugs.
C.1 Objects
1. [I] In their book, A Theory of Objects [AC96] (and in a series of earlier arti-
cles [AC94b, AC94a, etc.]), Abadi and Cardelli have proposed a primitive cal-
culus analogous to the lambda-calculus, but with objects (rather than func-
tions) as the basic terms and message passing (rather than application) as the
1An object-oriented language like Java will probably be somewhat less convenient than a language
with support for datatypes and pattern matching; if you do choose an OO language, you may want to
structure your code according to the “visitor pattern” [GHJV94, FF98, etc.].
268
January 15, 2000 C. SUGGESTIONS FOR LARGER PROJECTS 269
basic mechanism for computation. They develop several type systems for
their object-calculus (OC). Implement one or more of these.
2. [T] Bruce, Cardelli, and Pierce wrote a paper [BCP99] comparing four dif-
ferent lambda-calculus encodings of objects—the “existential encoding” pre-
sented in Chapters 28 and ??, the “recursive record” encoding mentioned in
Chapter 15, and two other, hybrid, models with more refined properties. A
number of different points of comparison are addressed in the paper, but
different encodings of classes in the four object models are not considered.
(a) Using the typechecker that we’ve used for exercises and for the exam-
ples in the notes, implement the examples in [BCP99].
(b) Extend these examples to include encodings of classes and inheritance,
following Chapter 28 in the case of the existential encoding and other
papers (see the bibliography of [BCP99]) for the other encodings.
(c) Compare and contrast.
(d) If time remains, it is also interesting to compare and contrast the imper-
ative variants of these four encodings—i.e., versions of the encodings
where the instance variables of objects can be mutable Ref cells.
3. [I] Chapter ?? shows how to do some simple examples of object-oriented
programming in F<:. Using the everything typechecker from the course web
directory, develop a more significant object-oriented program following the
same lines.
(a) To get started, implement a group of collection classes (for example, using
the collection classes of Smalltalk [GR83] as a model). Some hints for
how to do this can be found in [PT94].
(b) Use these classes as a library to implement a larger object-oriented pro-
gram of your choice.
C.2 Encodings of Logics
1. [I] The Logical Framework of Harper, Honsell, and Plotkin [HHP92] is a typed
lambda-calculus intended as a meta-language for defining logics and prov-
ing theorems in them.
(a) Implement LF
(b) Use your implementation to encode a simple propositional logic and
prove some small theorems.
2. [T] A generalization of the LF logic has been used as the core of Frank Pfen-
ning’s logic programming language ELF [Pfe89, Pfe91, Pfe94, Pfe96].
January 15, 2000 C. SUGGESTIONS FOR LARGER PROJECTS 270
(a) Download and install the ELF system.
(b) Use it to encode the syntax and typing rules of the simply typed lambda-
calculus with subtyping and prove some simple theorems about the sys-
tem, along the lines of [MP91].
C.3 Type Inference
1. [T] Implement a type inference system for the simply typed lambda-calculus
(or ML) with subtyping. (The literature on approaches to this problem is
huge. See [Pot97, Pot98], for example.)
2. [I] Row variables, proposed by Mitch Wand [Wan87, Wan88, Wan89] and sub-
sequently refined by Didier Remy [Rém89, Rém90, RV97], provide an alter-
native to subtyping as a foundation for object-oriented programming lan-
guages, and can coexist smoothly with ML-style type inference. Implement
a type system with type inference and row variables.
C.4 Other Type Systems
1. [T] Implement a lambda-calculus with intersection types [Rey88, Pie97] (or,
for a bit more challenge, with both intersection and union types [Pie91b,
Pie90, BDCd95, Hay91]).
2. [T] Implement a linear type system for the lambda-calculus [Wad91, Wad90,
TWM95].
3. [I] Implement a typed assembly language in the style of Morrisett and co-workers [MWCG98,
MCGW98, MCG+99].
4. [T] A great variety of type systems for extensible records, developed by various
researchers, are summarized and unified in Cardelli and Mitchell’s encyclo-
pedic article, Operations on Records [CM91]. Implement a simple variant of
their system.
5. [I] Effect type systems [JG91, TJ92], which track the computational effects of
functions (memory reads and writes, allocation, etc.) in addition to their
input-output behavior, have been used for a variety of purposes. Perhaps
most surprisingly, Tofte and his co-workers have used “region inference”
techniques to build an ML compiler that runs without a garbage collector [TT97,
TB98]. Implement a simple effect inference algorithm.
6. [T] Harper and Lillibridge [HL94] and Leroy [Ler96] have independently
proposed similar accounts of modules (in the style of ML) using the type-
theoretic tools of existential types and (a limited form of) dependent types.
January 15, 2000 C. SUGGESTIONS FOR LARGER PROJECTS 271
These accounts place powerful module systems like those of Standard ML [MTH90]
and Objective Caml [Ler95] on a well-understood and tractable theoretical
foundation. Read and implement one of these papers.
7. [I] A series of papers [ACPP91, LM91, ACPR95] have proposed adding a type
Dynamic to statically typed languages, in order to provide a smooth interface
between statically typed and dynamically typed data.
(a) Add Dynamic to the implementation of the simply typed lambda-calculus,
following [ACPP91].
(b) Extend this implementation to System F (or even Fomega), using ideas
in [ACPR95] and your own creativity.
C.5 Sources for Additional Ideas
The research literature is full of descriptions of interesting type systems and ap-
plications of type systems. The premier conference in the area is Principles of
Programming Languages (POPL). Other conferences with a high density of papers
on type systems include International Conference on Functional Programming (ICFP),
Typed Lambda Calculi and Applications (TLCA), Theoretical Aspects of Computer Soft-
ware (TACS), Logic in Computer Science (LICS), (among many others). Leafing through
a recent proceedings of any of these conferences should yield several papers in-
volving type systems. Pick one, read it carefully, and build a simple implementa-
tion of the system it describes.
Appendix D
Bluffers Guide to OCaml
The systems discussed in the text have all been implemented in the Objective
CAML dialect of ML. An excellent compiler for this language is freely available
from INRIA.
Students who want to undertake the implementation exercises suggested in
many chapters will need to pick up the basics of OCaml programming, if they are
not already familiar with it. For programmers already familiar with another dialect
of ML (e.g. Standard ML), the brief, but excellent, tutorial in the OCaml reference
manual will do fine for this. Readers with no prior familiarity with any ML may
wish to read some of Cousineau and Mauny’s textbook [CM98].
For the convenience of readers who just want to understand enough of the pro-
gramming examples presented here to translate them into another programming
language, this appendix summarizes the key features used.
To be written. I have in mind something along the lines of the “Bluffers Guide to ML”
in Baader and Nipkow’s recent book, Term Rewriting and All That. In fact, it might
be possible to reprint that appendix entirely from this book, crediting the original authors
and just translating, mutatis mutandi, SML to OCaml. (I have not talked to Baader and
Nipkow about this.)
272
Appendix E
Running the Checkers
The systems discussed in the text have all been implemented in Objective CAML.
You’ll find the programming exercises and experiments throughout the notes much
more enjoyable if you use the implementations to check and execute your solu-
tions.
E.1 Preparing Your Input
An input file for a checker consists of a sequence of clauses terminated by semi-
colons. Input clauses can have the following forms:
t; typecheck (if appropriate) and evaluate term t
x = t; typecheck t (if appropriate) and bind it to x
import "filename"; include filename at this point
E.2 Ascii Equivalents
Programs in the text are typeset using some non-ascii symbols. When preparing
input to the typechecker, you should use the following equivalents:
TYPESET ASCII
 lambda! ->
0a 'a
0b 'b
0c 'c
0d 'd
273
January 15, 2000 E. RUNNING THE CHECKERS 274
E.3 Running the Checker
Precompiled binaries for solaris can be found in the course web directory. From
CIS machines, you should be able to run the checkers directly out of the web di-
rectory:
/mnt/saul/extra/bcpierce/pub/courses/700/checkers/<checkername>/f <test.f>
(where <checkername> is the name of the checker that you want—untyped, fulluntyped,
simple, etc.—and <test.f> is the name of your input file).
E.4 Compiling the Checkers
To modify the checker itself, you’ll need to make a local copy:
cp -r /mnt/saul/extra/bcpierce/pub/courses/700/checkers/<checkername> <mydir>
To recompile it from scratch, first install the Objective CAML compiler if necessary
(see the following section). Do
make clean
to throw away all the existing object-code files, and then
make
to rebuild the executable file (called f) for the checker.
E.5 Objective Caml
On CIS machines, you should be able to use the Objective CAML compiler simply
by adding
/mnt/saul/extra/bcpierce/bin/sun4
to your search path.
On other machines (including most varieties of Unix workstations, Macs, and
Windows 95/98/NT PCs) you’ll need to install Objective Caml yourself. It can be
obtained from ftp://ftp.inria.fr/lang. It’s quite easy to install.
Bibliography
[AC94a] Martı́n Abadi and Luca Cardelli. A theory of primitive objects: Second-order
systems. In European Symposium on Programming (ESOP), Edinburgh, Scotland,
1994.
[AC94b] Martı́n Abadi and Luca Cardelli. A theory of primitive objects: Untyped and
first-order systems. In Theoretical Aspects of Computer Software (TACS), Sendai,
Japan, 1994.
[AC96] Martı́n Abadi and Luca Cardelli. A Theory of Objects. Springer-Verlag, 1996.
[ACPP91] Martı́n Abadi, Luca Cardelli, Benjamin Pierce, and Gordon Plotkin. Dynamic
typing in a statically typed language. Transactions on Programming Languages
and Systems, 13(2):237–268, April 1991. Preliminary version in Proceedings of
the Sixteenth Annual ACM Symposium on Principles of Programming Lan-
guages (Austin, TX), January, 1989.
[ACPR95] Martı́n Abadi, Luca Cardelli, Benjamin Pierce, and Didier Rémy. Dynamic typ-
ing in polymorphic languages. Journal of Functional Programming, 5(1):111–130,
January 1995. Preliminary version in Proceedings of the ACM SIGPLAN Work-
shop on ML and its Applications, June 1992.
[AJM94] Samson Abramsky, Radha Jagadeesan, and Pasquale Malacaria. Full abstrac-
tion for PCF (extended abstract). In Masami Hagiya and John C. Mitchell, ed-
itors, Theoretical Aspects of Computer Software. International Symposium TACS’94,
number 789 in Lecture Notes in Computer Science, pages 1–15, Sendai, Japan,
April 1994. Springer-Verlag.
[AS85] Harold Abelson and Gerald Sussman. Structure and Interpretation of Computer
Programs. The MIT Press, New York, 1985.
[Bac81] John Backus. The history of Fortran I, II, and III. In Wexelblat, editor, History of
Programming Languages, pages 25–45. Academic Press, 1981.
[Bar84] H. P. Barendregt. The Lambda Calculus. North Holland, revised edition, 1984.
[Bar90] H. P. Barendregt. Functional programming and lambda calculus. In Jan van
Leeuwen, editor, Handbook of Theoretical Computer Science, Volume B, volume B,
chapter 7, pages 321–364. Elsevier / MIT Press, 1990.
[Bar92a] Henk Barendregt. Introduction to generalized type systems. Journal of Func-
tional Programming, 1992.
275
January 15, 2000 BIBLIOGRAPHY 276
[Bar92b] Henk Barendregt. Lambda calculi with types. In Gabbay Abramsky and
Maibaum, editors, Handbook of Logic in Computer Science, volume II. Oxford
University Press, 1992.
[BCGS91] Val Breazu-Tannen, Thierry Coquand, Carl Gunter, and Andre Scedrov. Inher-
itance as implicit coercion. Information and Computation, 93:172–221, 1991. Also
in Carl A. Gunter and John C. Mitchell, editors, Theoretical Aspects of Object-
Oriented Programming: Types, Semantics, and Language Design (MIT Press, 1994).
[BCP99] Kim B. Bruce, Luca Cardelli, and Benjamin C. Pierce. Comparing object en-
codings. Information and Computation, 1999. To appear in a special issue with
papers from Theoretical Aspects of Computer Software (TACS), September, 1997.
An earlier version appeared as an invited lecture in the Third International
Workshop on Foundations of Object Oriented Languages (FOOL 3), July 1996.
[BDCd95] Franco Barbanera, Mariangiola Dezani-Ciancaglini, and Ugo de’Liguoro. Inter-
section and union types: Syntax and semantics. Information and Computation,
119(2):202–230, June 1995.
[BDMN79] Graham M. Birtwistle, Ole-Johan Dahl, Bjorn Myhrhaug, and Kristen Nygaard.
Simula Begin. Studentlitteratur (Lund, Sweden), Bratt Institut fuer neues Ler-
nen (Goch, FRG), Chartwell-Bratt Ltd (Kent, England), 1979.
[Ben95] Johan Van Benthem. Language in Action : Categories, Lambdas, and Dynamic Logic.
MIT Press, 1995.
[BFSS90] S. Bainbridge, P. Freyd, A. Scedrov, and P. Scott. Functorial polymorphism.
Theoretical Computer Science, 70:35–64, 1990.
[BL90] Kim B. Bruce and Giuseppe Longo. A modest model of records, inheritance,
and bounded quantification. Information and Computation, 87:196–240, 1990.
Also in Carl A. Gunter and John C. Mitchell, editors, Theoretical Aspects of
Object-Oriented Programming: Types, Semantics, and Language Design (MIT Press,
1994). An earlier version appeared in the proceedings of the IEEE Symposium
on Logic in Computer Science, 1988.
[BM92] Kim Bruce and John Mitchell. PER models of subtyping, recursive types and
higher-order polymorphism. In Proceedings of the Nineteenth ACM Symposium
on Principles of Programming Languages, Albequerque, NM, January 1992.
[BOSW98] Gilad Bracha, Martin Odersky, David Stoutamire, and Philip Wadler. Mak-
ing the future safe for the past: Adding genericity to the Java programming
language. In Craig Chambers, editor, Object Oriented Programing: Systems, Lan-
guages, and Applications (OOPSLA), ACM SIGPLAN Notices volume 33 number
10, pages 183–200, Vancouver, BC, October 1998.
[Bru91] Kim B. Bruce. The equivalence of two semantic definitions for inheritance in
object-oriented languages. In Proceedings of Mathematical Foundations of Pro-
gramming Semantics, Pittsburgh, PA, March 1991.
[Car84] Luca Cardelli. A semantics of multiple inheritance. In G. Kahn, D. MacQueen,
and G. Plotkin, editors, Semantics of Data Types, volume 173 of Lecture Notes in
Computer Science, pages 51–67. Springer-Verlag, 1984. Full version in Informa-
tion and Computation 76(2/3):138–164, 1988.
January 15, 2000 BIBLIOGRAPHY 277
[Car88] Luca Cardelli. Structural subtyping and the notion of power type. In Proceed-
ings of the 15th ACM Symposium on Principles of Programming Languages, pages
70–79, San Diego, CA, January 1988.
[Car89] Felice Cardone. Relational semantics for recursive types and bounded quan-
tification. In Proceedings of the Sixteenth International Colloquium on Automata,
Languages, and Programming, volume 372 of Lecture Notes in Computer Science,
pages 164–178, Stresa, Italy, July 1989. Springer-Verlag.
[Car90] Luca Cardelli. Notes about F!<:. Unpublished manuscript, October 1990.
[Car91] Luca Cardelli. Typeful programming. In E. J. Neuhold and M. Paul, editors,
Formal Description of Programming Concepts. Springer-Verlag, 1991. An ear-
lier version appeared as DEC Systems Research Center Research Report #45,
February 1989.
[Car92] Luca Cardelli. Extensible records in a pure calculus of subtyping. Research
report 81, DEC Systems Research Center, January 1992. Also in Carl A. Gunter
and John C. Mitchell, editors, Theoretical Aspects of Object-Oriented Programming:
Types, Semantics, and Language Design (MIT Press, 1994).
[Car96] Luca Cardelli. Type systems. In Allen B. Tucker, editor, Handbook of Computer
Science and Engineering. CRC Press, 1996.
[Cas97] Giuseppe Castagna. Object-Oriented Programming: A Unified Foundation.
Springer-Verlag, 1997.
[CCH+89] Peter Canning, William Cook, Walter Hill, Walter Olthoff, and John Mitchell.
F-bounded quantification for object-oriented programming. In Fourth Interna-
tional Conference on Functional Programming Languages and Computer Architec-
ture, pages 273–280, September 1989.
[CCHO89] Peter Canning, William Cook, Walt Hill, and Walter Olthoff. Interfaces for
strongly-typed object-oriented programming. In Object Oriented Programing:
Systems, Languages, and Applications (OOPSLA), pages 457–467, 1989.
[CDC78] M. Coppo and M. Dezani-Ciancaglini. A new type-assignment for -terms.
Archiv Math. Logik, 19:139–156, 1978.
[CDCS79] M. Coppo, M. Dezani-Ciancaglini, and P. Salle. Functional characterization
of some semantic equalities inside -calculus. In Hermann A. Maurer, editor,
Proceedings of the 6th Colloquium on Automata, Languages and Programming, vol-
ume 71 of LNCS, pages 133–146, Graz, Austria, July 1979. Springer.
[CF58] H. B. Curry and R. Feys. Combinatory Logic, volume 1. North Holland, 1958.
(Second edition, 1968).
[CG91] Pierre-Louis Curien and Giorgio Ghelli. Subtyping + extensionality: Conflu-
ence of -reductions in F. In T. Ito and A. R. Meyer, editors, Theoretical
Aspects of Computer Software (Sendai, Japan), number 526 in Lecture Notes in
Computer Science, pages 731–749. Springer-Verlag, September 1991.
[CG92] Pierre-Louis Curien and Giorgio Ghelli. Coherence of subsumption: Minimum
typing and type-checking in F. Mathematical Structures in Computer Science,
2:55–91, 1992. Also in Carl A. Gunter and John C. Mitchell, editors, Theoretical
Aspects of Object-Oriented Programming: Types, Semantics, and Language Design
(MIT Press, 1994).
January 15, 2000 BIBLIOGRAPHY 278
[CH88] Thierry Coquand and Gérard Huet. The Calculus of Constructions. Information
and Computation, 76(2/3):95–120, February/March 1988.
[CHC90] William R. Cook, Walter L. Hill, and Peter S. Canning. Inheritance is not sub-
typing. In Seventeenth Annual ACM Symposium on Principles of Programming
Languages, pages 125–135, San Francisco, CA, January 1990. Also in Carl A.
Gunter and John C. Mitchell, editors, Theoretical Aspects of Object-Oriented Pro-
gramming: Types, Semantics, and Language Design (MIT Press, 1994).
[CHO88] Peter Canning, Walt Hill, and Walter Olthoff. A kernel language for object-
oriented programming. Technical Report STL-88-21, Hewlett-Packard Labs,
1988.
[Chu36] Alonzo Church. An unsolvable problem of elementary number theory. Ameri-
can Journal of Mathematics, 58:354–363, 1936.
[Chu40] Alonzo Church. A formulation of the simple theory of types. Journal of Symbolic
Logic, 5:56–68, 1940.
[Chu41] Alonzo Church. The Calculi of Lambda Conversion. Princeton University Press,
1941.
[CL91] Luca Cardelli and Giuseppe Longo. A semantic basis for Quest. Journal of Func-
tional Programming, 1(4):417–458, October 1991. Preliminary version in ACM
Conference on Lisp and Functional Programming, June 1990. Also available as
DEC SRC Research Report 55, Feb. 1990.
[CM91] Luca Cardelli and John Mitchell. Operations on records. Mathematical Struc-
tures in Computer Science, 1:3–48, 1991. Also in Carl A. Gunter and John C.
Mitchell, editors, Theoretical Aspects of Object-Oriented Programming: Types, Se-
mantics, and Language Design (MIT Press, 1994); available as DEC Systems Re-
search Center Research Report #48, August, 1989, and in the proceedings of
MFPS ’89, Springer LNCS volume 442.
[CM98] Guy Cousineau and Michel Mauny. The Functional Approach to Programming.
Cambridge University Press, 1998.
[CMMS94] Luca Cardelli, Simone Martini, John C. Mitchell, and Andre Scedrov. An ex-
tension of system F with subtyping. Information and Computation, 109(1–2):4–56,
1994. Preliminary version in TACS ’91 (Sendai, Japan, pp. 750–770).
[Con86] Robert L. Constable, et. al. Implementing Mathematics with the NuPRL Proof De-
velopment System. Prentice–Hall, Englewood Cliffs, NJ, 1986.
[Coq85] Thierry Coquand. Une Théorie des Constructions. PhD thesis, University Paris
VII, January 1985.
[CP96] Adriana B. Compagnoni and Benjamin C. Pierce. Intersection types and mul-
tiple inheritance. Mathematical Structures in Computer Science, 6(5):469–501, Oc-
tober 1996. Preliminary version available as University of Edinburgh technical
report ECS-LFCS-93-275 and Catholic University Nijmegen computer science
technical report 93-18, Aug. 1993, under the title Multiple Inheritance via Inter-
section Types.
[CW85] Luca Cardelli and Peter Wegner. On understanding types, data abstraction,
and polymorphism. Computing Surveys, 17(4):471–522, December 1985.
January 15, 2000 BIBLIOGRAPHY 279
[dB72] Nicolas G. de Bruijn. Lambda-calculus notation with nameless dummies: a
tool for automatic formula manipulation with application to the Church-Rosser
theorem. Indag. Math., 34(5):381–392, 1972.
[dB80] Nicolas G. de Bruijn. A survey of the project AUTOMATH. In J. P. Seldin
and J. R. Hindley, editors, To H. B. Curry: Essays in Combinatory Logic, Lambda
Calculus, and Formalism, pages 589–606. Academic Press, 1980.
[DLP79] Richard A. De Millo, Richard J. Lipton, and Alan J. Perlis. Social processes and
proofs of theorems and programs. Communications of the ACM, 22(5):271–280,
May 1979. An earlier version appeared in Conference Record of the Fourth
ACM Symposium on Principles of Programming Languages (POPL), 1977, pp.
206-214.
[DM82] Luis Damas and Robin Milner. Principal type schemes for functional programs.
In Proceedings of the 9th ACM Symposium on Principles of Programming Languages,
pages 207–212, 1982.
[FF98] Matthias Felleisen and Daniel P. Friedman. A little Java, A few Patterns. The MIT
Press, Cambridge, Massachusetts, 1998.
[Fre89] Peter J. Freyd. POLYNAT in PER. In John W. Gray and Andre Scedrov, editors,
Categories in Computer Science and Logic, volume 92 of Contemporary Mathematics,
pages 67–68, Providence, Rhode Island, 1989. American Mathematical Society.
[FWH92] Daniel P. Friedman, Mitchell Wand, and Christopher T. Haynes. Essentials of
Programming Languages. McGraw-Hill Book Co., New York, N.Y., 1992.
[Ghe90] Giorgio Ghelli. Proof Theoretic Studies about a Minimal Type System Integrating
Inclusion and Parametric Polymorphism. PhD thesis, Università di Pisa, March
1990. Technical report TD–6/90, Dipartimento di Informatica, Università di
Pisa.
[Ghe95] Giorgio Ghelli. Divergence of F type checking. Theoretical Computer Science,
139(1,2):131–162, 1995.
[GHJV94] Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides. Design
Patterns: Elements of Reusable Object-Oriented Software. Addison Wesley, Mas-
sachusetts, 1994.
[Gir72] Jean-Yves Girard. Interprétation fonctionelle et élimination des coupures de l’arith-
métique d’ordre supérieur. PhD thesis, Université Paris VII, 1972. A summary
appeared in the Proceedings of the Second Scandinavian Logic Symposium
(J.E. Fenstad, editor), North-Holland, 1971 (pp. 63–92).
[Gir87] Jean-Yves Girard. Linear logic. Theoretical Computer Science, 50:1–102, 1987.
[GLT89] Jean-Yves Girard, Yves Lafont, and Paul Taylor. Proofs and Types, volume 7 of
Cambridge Tracts in Theoretical Computer Science. Cambridge University Press,
Cambridge, 1989.
[GMW79] Michael J. Gordon, Robin Milner, and Christopher P. Wadsworth. Edinburgh
LCF. Springer-Verlag LNCS 78, 1979.
[GR83] Adele Goldberg and David Robson. Smalltalk-80: The Language and Its Imple-
mentation. Addison-Wesley, Reading, MA, 1983.
January 15, 2000 BIBLIOGRAPHY 280
[Gun92] C. A. Gunter. Semantics of Programming Languages: Structures and Techniques.
The MIT Press, Cambridge, MA, 1992.
[Hay91] S. Hayashi. Singleton, union and intersection types for program extraction.
In T.Ito and A.R.Meyer, editors, Theoretical Aspect of Computer Software (Lecture
Notes in Comuter Science No. 526), pages 701–730, Berlin, 1991. Springer-Verlag.
[HHP92] Robert Harper, Furio Honsell, and Gordon Plotkin. A framework for defining
logics. Journal of the ACM, 40(1):143–184, 1992. Preliminary version in LICS’87.
[Hin97] J. Roger Hindley. Basic Simple Type Theory, volume 42 of Cambridge Tracts in
Theoretical Computer Science. Cambridge University Press, Cambridge, 1997.
[HL94] Robert Harper and Mark Lillibridge. A type-theoretic approach to higher-order
modules with sharing. In Proceedings of the Twenty-First ACM Symposium on
Principles of Programming Languages (POPL), Portland, Oregon, pages 123–137,
Portland, OR, January 1994.
[HMV93] My Hoang, John Mitchell, and Ramesh Viswanathan. Standard ML-NJ weak
polymorphism and imperative constructs. In Proceedings, Eighth Annual IEEE
Symposium on Logic in Computer Science, pages 15–25. IEEE Computer Society
Press, 1993.
[HO94] J. M. E. Hyland and C.-H. L. Ong. On full abstraction for PCF: I,
II and III. Submitted for publication; electronic draft available through
ftp://ftp.comlab.ox.ac.uk/pub/Documents/techpapers/Luke.Ong/, 1994.
[How80] W. A. Howard. The formulas-as-types notion of construction. In J. P. Seldin and
J. R. Hindley, editors, To H. B. Curry: Essays on Combinatory Logic, Lambda Cal-
culus, and Formalism, pages 479–490. Academic Press, New York, 1980. Reprint
of 1969 article.
[HP95] Martin Hofmann and Benjamin Pierce. Positive subtyping. In Proceedings of
Twenty-Second Annual ACM Symposium on Principles of Programming Languages,
pages 186–197. ACM, January 1995. Full version in Information and Computation,
volume 126, number 1, April 1996. Also available as University of Edinburgh
technical report ECS-LFCS-94-303, September 1994.
[HP98] Martin Hofmann and Benjamin C. Pierce. Type destructors. In Didier Rémy,
editor, Informal proceedings of the Fourth International Workshop on Foundations
of Object-Oriented Languages (FOOL), January 1998. Full version to appear in
Theory and Practice of Object Systems.
[HS86] J. Roger Hindley and Jonathan P. Seldin. Introduction to Combinators and -
Calculus, volume 1 of London Mathematical Society Student Texts. Cambridge
University Press, 1986.
[HU79] John E. Hopcroft and Jeffrey D. Ullman. Introduction to Automata Theory, Lan-
guages, and Computation. Addison-Wesley, 1979.
[IPW99] Atsushi Igarashi, Benjamin Pierce, and Philip Wadler. Featherweight Java: A
minimal core calculus for Java and GJ. In Object Oriented Programing: Systems,
Languages, and Applications (OOPSLA), October 1999.
[JG91] Pierre Jouvelot and David Gifford. Algebraic reconstruction of types and ef-
fects. In Conference Record of the Eighteenth Annual ACM Symposium on Principles
January 15, 2000 BIBLIOGRAPHY 281
of Programming Languages, Orlando, Florida, pages 303–310. ACM Press, January
1991. This paper presents the first algorithm for reconstructing the types and
effects of expressions in the presence of first-class procedures in a polymorphi-
cally typed language. The algorithm involves a new technique called algebraic
reconstruction, whose soundness and completeness properties are proved.
[JMP94] L.S. van Benthem Jutting, James McKinna, and Robert Pollack. Checking algo-
rithms for Pure Type Systems. In Henk Barendregt and Tobias Nipkow, editors,
Proceedings of the International Workshop on Types for Proofs and Programs, pages
19–61, Nijmegen, The Netherlands, May 1994. Springer-Verlag LNCS 806.
[KCR98] Richard Kelsey, William Clinger, and Jonathan Rees. Revised5 report on the
algorithmic language Scheme. ACM SIGPLAN Notices, 33(9):26–76, September
1998. With H. Abelson, N. I. Adams, IV, D. H. Bartley, G. Brooks, R. K. Dybvig,
D. P. Friedman, R. Halstead, C. Hanson, C. T. Haynes, E. Kohlbecker, D. Oxley,
K. M. Pitman, G. J. Rozas, G. L. Steele, Jr., G. J. Sussman, and M. Wand.
[KS92] Dinesh Katiyar and Sriram Sankar. Completely bounded quantification is de-
cidable. In Proceedings of the ACM SIGPLAN Workshop on ML and its Applications,
June 1992.
[LAB+81] B. Liskov, R. Atkinson, T. Bloom, E. Moss, J.C. Schaffert, R. Scheifler, and
A. Snyder. CLU Reference Manual. Springer-Verlag, 1981.
[Lan64] P. J. Landin. The mechanical evaluation of expressions. Computer Journal, 6:308–
320, January 1964.
[Lan65] P. J. Landin. A correspondence between ALGOL 60 and Church’s lambda-
notation: Parts I and II. Communications of the ACM, 8(2,3):89–101, 158–165,
February and March 1965.
[Lan66] P. J. Landin. The next 700 programming languages. Communications of the ACM,
9(3):157–166, March 1966.
[Ler94] Xavier Leroy. Manifest types, modules and separate compilation. In Confer-
ence record of POPL ’94: 21st ACM SIGPLAN-SIGACT Symposium on Principles of
Programming Languages, pages 109–122, Portland, OR, January 1994.
[Ler95] Xavier Leroy. Applicative functors and fully transparent higher-order mod-
ules. In Proceedings of the Twenty-Second ACM Symposium on Principles of Pro-
gramming Languages (POPL), Portland, Oregon, pages 142–153, San Francisco,
California, January 1995.
[Ler96] Xavier Leroy. A syntactic theory of type generativity and sharing. Journal of
Functional Programming, 6(5):667–698, September 1996.
[LM91] Xavier Leroy and Michel Mauny. Dynamics in ML. In John Hughes, editor,
Functional Programming Languages and Computer Architecture 1991, volume 523
of Lecture Notes in Computer Science, pages 406–426. Springer-Verlag, 1991.
[LP99] Michael Y. Levin and Benjamin C. Pierce. Tinkertype: A language for playing
with formal systems. Technical Report MS-CIS-99-19, Dept of CIS, University
of Pennsylvania, July 1999.
[Luo90] Zhaohui Luo. An Extended Calculus of Constructions. PhD thesis, Department of
Computer Science, University of Edinburgh, June 1990.
January 15, 2000 BIBLIOGRAPHY 282
[LW91] X. Leroy and P. Weis. Polymorphic type inference and assignment. In Eighteenth
Annual ACM Symposium on Principles of Programming Languages, Orlando, FL,
pages 291–302. ACM, New York, NY, 1991.
[Mac86] David MacQueen. Using dependent types to express modular structure. In
13th Annual ACM Symposium on Principles of Programming languages, pages 277–
286, St. Petersburg Beach, FL, January 1986.
[Mar73] Per Martin-Löf. An intuitionistic theory of types: predicative part. In H. E.
Rose and J. C. Shepherdson, editors, Logic Colloquium, ’73, pages 73–118, Ams-
terdam, 1973. North Holland.
[Mar82] Per Martin-Löf. Constructive mathematics and computer programming. In
Logic, Methodology and Philosophy of Science, VI. North Holland, Amsterdam,
1982.
[Mar88] Simone Martini. Bounded quantifiers have interval models. In Proceedings of the
ACM Conference on Lisp and Functional Programming, pages 174–183, Snowbird,
Utah, July 1988. ACM.
[MCG+99] Greg Morrisett, Karl Crary, Neal Glew, Dan Grossman, Richard Samuels, Fred-
erick Smith, David Walker, Stephanie Weirich, and Steve Zdancewic. TALx86:
A realistic typed assembly language. Submitted to the 1999 ACM SIGPLAN
Workshop on Compiler Support for System Software, 1999.
[MCGW98] Greg Morrisett, Karl Crary, Neal Glew, and David Walker. Stack-based typed
assembly language. In Second International Workshop on Types in Compilation,
pages 95–117, Kyoto, March 1998. Published in Xavier Leroy and Atsushi
Ohori, editors, Lecture Notes in Computer Science, volume 1473, pages 28-52.
Springer-Verlag, 1998.
[Mil78] Robin Milner. A theory of type polymorphism in programming. Journal of
Computer and System Sciences, 17:348–375, August 1978.
[Mil91] Robin Milner. The polyadic-calculus: a tutorial. Technical Report ECS–LFCS–
91–180, Laboratory for Foundations of Computer Science, Department of Com-
puter Science, University of Edinburgh, UK, October 1991. Appeared in Pro-
ceedings of the International Summer School on Logic and Algebra of Specification,
Marktoberdorf, August 1991. Reprinted in Logic and Algebra of Specification, ed.
F. L. Bauer, W. Brauer, and H. Schwichtenberg, Springer-Verlag, 1993.
[Mit84a] John C. Mitchell. Coercion and type inference (summary). In Proc. 11th ACM
Symp. on Principles of Programming Languages, pages 175–185, January 1984.
[Mit84b] John C. Mitchell. Type inference and type containment. In Proc. Int. Symp. on
Semantics of Data Types, Sophia-Antipolis (France), pages 257–278, Berlin, June
1984. Springer LNCS 173. Full version in Information and Computation, vol. 76,
no. 2/3, 1988, pp. 211–249. Reprinted in Logical Foundations of Functional Pro-
gramming, ed. G. Huet, Addison-Wesley (1990) 153–194.
[Mit90] J. C. Mitchell. Type systems for programming languages. In J. van Leeuwen,
editor, Handbook of Theoretical Computer Science, Volume B, pages 365–458.
North-Holland, Amsterdam, 1990.
[Mit96] John C. Mitchell. Foundations for Programming Languages. The MIT Press, Cam-
bridge, MA, 1996.
January 15, 2000 BIBLIOGRAPHY 283
[MP88] John C. Mitchell and Gordon D. Plotkin. Abstract types have existential types.
ACM Trans. on Programming Languages and Systems, 10(3):470–502, 1988. Prelim-
inary version appeared in Proc. 12th ACM Symp. on Principles of Programming
Languages, 1985.
[MP91] Spiro Michaylov and Frank Pfenning. Natural semantics and some of its meta-
theory in Elf. In L.-H. Eriksson, L. Hallnäs, and P. Schroeder-Heister, editors,
Proceedings of the Second International Workshop on Extensions of Logic Program-
ming, pages 299–344, Stockholm, Sweden, January 1991. Springer-Verlag LNAI
596.
[MP93] James McKinna and Robert Pollack. Pure Type Sytems formalized. In
M. Bezem and J. F. Groote, editors, Proceedings of the International Conference
on Typed Lambda Calculi and Applications, pages 289–305. Springer-Verlag LNCS
664, March 1993.
[MPW92] R. Milner, J. Parrow, and D. Walker. A calculus of mobile processes (Parts I and
II). Information and Computation, 100:1–77, 1992.
[MTH90] Robin Milner, Mads Tofte, and Robert Harper. The Definition of Standard ML.
The MIT Press, 1990.
[MTHM97] Robin Milner, Mads Tofte, Robert Harper, and David MacQueen. The Definition
of Standard ML (Revised). The MIT Press, 1997.
[MWCG98] Greg Morrisett, David Walker, Karl Crary, and Neal Glew. From System F to
Typed Assembly Language. In Twenty-fifth ACM Symposium on Principles of
Programming Languages, pages 85–97, San Diego, January 1998.
[N+63] P. Naur et al. Revised report on the algorithmic language algol 60. Communica-
tions of the ACM, 6:1–17, January 1963.
[Nec97] George C. Necula. Proof-carrying code. In Conference Record of POPL ’97:
The 24th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Lan-
guages, pages 106–119, Paris, France, 15–17 January 1997.
[NL96] George C. Necula and Peter Lee. Safe kernel extensions without run-time
checking. In USENIX, editor, 2nd Symposium on Operating Systems Design and
Implementation (OSDI ’96), October 28–31, 1996. Seattle, WA, pages 229–243,
Berkeley, CA, USA, October 1996. USENIX.
[NL98] G. C. Necula and P. Lee. Safe, untrusted agents using proof-carrying code. In
G. Vigna, editor, Mobile Agents and Security, volume 1419 of LNCS, pages 61–91.
SV, 1998.
[oD80] US Dept. of Defense. Reference Manual for the Ada Programming Language. GPO
008-000-00354-8, 1980.
[OR94] Peter W. O’Hearn and Jon G. Riecke. Fully abstract translations and parametric
polymorphism. In ESOP ’94: 6th European Symposium on Programming, April
1994. Springer Lecture Notes in Computer Science, volume 788.
[PA93] Gordon Plotkin and Martı́n Abadi. A logic for parametric polymorphism. In
M. Bezem and J. F. Groote, editors, International Conference on Typed Lambda Cal-
culi and Applications, number 664 in Lecture Notes in Computer Science, pages
361–375, Utrecht, The Netherlands, March 1993. Springer-Verlag. TLCA’93.
January 15, 2000 BIBLIOGRAPHY 284
[Pfe89] Frank Pfenning. Elf: A language for logic definition and verified meta-
programming. In Fourth Annual Symposium on Logic in Computer Science, pages
313–322, Pacific Grove, California, June 1989. IEEE Computer Society Press.
[Pfe91] Frank Pfenning. Logic programming in the LF logical framework. In Gérard
Huet and Gordon Plotkin, editors, Logical Frameworks, pages 149–181. Cam-
bridge University Press, 1991.
[Pfe94] Frank Pfenning. Elf: A meta-language for deductive systems. In A. Bundy,
editor, Proceedings of the 12th International Conference on Automated Deduction,
pages 811–815, Nancy, France, June 1994. Springer-Verlag LNAI 814. System
abstract.
[Pfe96] Frank Pfenning. The practice of logical frameworks. In Hélène Kirchner, editor,
Proceedings of the Colloquium on Trees in Algebra and Programming, pages 119–134,
Linköping, Sweden, April 1996. Springer-Verlag LNCS 1059. Invited talk.
[Pie90] Benjamin C. Pierce. Preliminary investigation of a calculus with intersection
and union types. Unpublished manuscript, June 1990.
[Pie91a] Benjamin C. Pierce. Programming with Intersection Types and Bounded Polymor-
phism. PhD thesis, Carnegie Mellon University, December 1991. Available as
School of Computer Science technical report CMU-CS-91-205.
[Pie91b] Benjamin C. Pierce. Programming with intersection types, union types, and
polymorphism. Technical Report CMU-CS-91-106, Carnegie Mellon Univer-
sity, February 1991.
[Pie94] Benjamin C. Pierce. Bounded quantification is undecidable. Information and
Computation, 112(1):131–165, July 1994. Also in Carl A. Gunter and John C.
Mitchell, editors, Theoretical Aspects of Object-Oriented Programming: Types, Se-
mantics, and Language Design (MIT Press, 1994). Preliminary version in POPL
’92.
[Pie97] Benjamin C. Pierce. Intersection types and bounded polymorphism. Mathemat-
ical Structures in Computer Science, 7(2):129–193, April 1997. Summary version
appeared in Conference on Typed Lambda Calculi and Applications, March
1993, pp. 346–360. Preliminary version available as University of Edinburgh
technical report ECS-LFCS-92-200.
[PJL92] Simon L. Peyton Jones and David R. Lester. Implementing Functional Languages.
Prentice Hall, 1992.
[Plo77] G. D. Plotkin. LCF considered as a programming language. Theoretical Com-
puter Science, 5:223–255, 1977.
[Pol94] Robert Pollack. The Theory of LEGO: A Proof Checker for the Extended Calculus of
Constructions. PhD thesis, University of Edinburgh, 1994.
[Pol96] Erik Poll. Width-subtyping and polymorphic record update. Manuscript, June
1996.
[Pot80] Garrell Pottinger. A type assignment for the strongly normalizable -terms.
In To H. B. Curry: Essays on Combinatory Logic, Lambda Calculus, and Formalism,
pages 561–577. Academic Press, New York, 1980.
January 15, 2000 BIBLIOGRAPHY 285
[Pot97] François Pottier. Simplifying subtyping constraints. In Proceedings of the Inter-
national Conference on Functional Programming (ICFP), 1997.
[Pot98] François Pottier. A framework for type inference with subtyping. In Proceedings
of the third ACM SIGPLAN International Conference on Functional Programming
(ICFP ’98), pages 228–238, September 1998.
[PS94] Jens Palsberg and Michael I. Schwartzbach. Object-Oriented Type Systems. Wiley,
1994.
[PT94] Benjamin C. Pierce and David N. Turner. Simple type-theoretic foundations
for object-oriented programming. Journal of Functional Programming, 4(2):207–
247, April 1994. Preliminary version in Principles of Programming Languages
(POPL), 1993.
[Rém89] Didier Rémy. Typechecking records and variants in a natural extension of ML.
In Proceedings of the Sixteenth Annual ACM Symposium on Principles of Program-
ming Languages, Austin, pages 242–249. ACM, January 1989. Also in Carl A.
Gunter and John C. Mitchell, editors, Theoretical Aspects of Object-Oriented Pro-
gramming: Types, Semantics, and Language Design (MIT Press, 1994).
[Rém90] Didier Rémy. Algèbres Touffues. Application au Typage Polymorphe des Objets En-
registrements dans les Langages Fonctionnels. PhD thesis, Université Paris VII,
1990.
[Rey74] John Reynolds. Towards a theory of type structure. In Proc. Colloque sur la
Programmation, pages 408–425, New York, 1974. Springer-Verlag LNCS 19.
[Rey80] John Reynolds. Using category theory to design implicit conversions and
generic operators. In N. D. Jones, editor, Proceedings of the Aarhus Workshop
on Semantics-Directed Compiler Generation, number 94 in Lecture Notes in Com-
puter Science. Springer-Verlag, January 1980. Also in Carl A. Gunter and John
C. Mitchell, editors, Theoretical Aspects of Object-Oriented Programming: Types,
Semantics, and Language Design (MIT Press, 1994).
[Rey83] John C. Reynolds. Types, abstraction, and parametric polymorphism. In
R. E. A. Mason, editor, Information Processing 83, pages 513–523, Amsterdam,
1983. Elsevier Science Publishers B. V. (North-Holland).
[Rey84] J. C. Reynolds. Polymorphism is not set-theoretic. In G. Kahn, D. B. MacQueen,
and G. D. Plotkin, editors, Semantics of Data Types, volume 173 of Lecture Notes
in Computer Science, pages 145–156, Berlin, 1984. Springer-Verlag.
[Rey88] John C. Reynolds. Preliminary design of the programming language Forsythe.
Technical Report CMU-CS-88-159, Carnegie Mellon University, June 1988.
[Rey98] John Reynolds. Theories of Programming Languages. Cambridge University
Press, 1998.
[RP] John C. Reynolds and Gordon D. Plotkin. On functors expressible in the poly-
morphic lambda calculus. Submitted to Information and Computation. Also
available as CMU School of Computer Science technical report number CMU-
CS-90-147.
[RR94] E. P. Robinson and G. Rosolini. Reflexive graphs and parametric polymor-
phism. In Proceedings, Ninth Annual IEEE Symposium on Logic in Computer Sci-
ence, pages 364–371, Paris, France, 4–7 July 1994. IEEE Computer Society Press.
January 15, 2000 BIBLIOGRAPHY 286
[RV97] Didier Rémy and Jérôme Vouillon. Objective ML: A simple object-oriented
extension of ML. In Conference Record of POPL ’97: the 24th ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages, pages 40–53, Paris,
France, January 15–17, 1997. ACM Press. Full version to appear in Theory and
Practice of Object Systems, 1998.
[Sch86] David A. Schmidt. Denotational Semantics: A Methodology for Language Develop-
ment. Allyn and Bacon, 1986.
[SJ75] Gerald Jay Sussman and Guy Lewis Steele Jr. Scheme: an interpreter for ex-
tended lambda calculus. MIT AI Memo 349, Massachusetts Institute of Tech-
nology, Cambridge, Mass., December 1975.
[SNP90] Jan Smith, Bengt Nordström, and Kent Petersson. Programming in Martin-Löf’s
Type Theory. An Introduction. Oxford University Press, 1990.
[TB98] Tofte and Birkedal. A region inference algorithm. ACMTOPLAS: ACM Trans-
actions on Programming Languages and Systems, 20, 1998.
[Ten81] R. D. Tennent. Principles of Programming Languages. Prentice-Hall, 1981.
[Tho91] Simon Thompson. Type Theory and Functional Programming. Addison Wesley,
1991.
[TJ92] J.-P. Talpin and P. Jouvelot. The type and effects discipline. In Proc. IEEE Symp.
on Logic in Computer Science, pages 162–173, 1992.
[TMC+96] D. Tarditi, G. Morrisett, P. Cheng, C. Stone, R. Harper, and P. Lee. TIL : A
type-directed optimizing compiler for ML. In Proceedings of the ACM SIGPLAN
Conference on Programming Language Design and Implemantation, pages 181–192,
New York, May 21–24 1996. ACM Press.
[Tof90] Mads Tofte. Type inference for polymorphic references. Information and Com-
putation, 89(1), November 1990.
[TT97] Mads Tofte and Jean-Pierre Talpin. Region-based memory management. Infor-
mation and Computation, 132(2):109–176, 1 February 1997.
[TvD88] A. S. Troelstra and D. van Dalen. Constructivism in Mathematics, An Introduction
(vol I). North-Holland, 1988.
[TWM95] David N Turner, Philip Wadler, and Christian Mossin. Once upon a type. In
Functional Programming Languages and Computer Architecture, San Diego, Cali-
fornia, 1995.
[vBM97] J. F. A. K. van Benthem and Alice Ter Meulen, editors. Handbook of Logic and
Language. MIT Press, 1997.
[Wad90] Philip Wadler. Linear types can change the world. In TC 2 Working Conference
on Programming Concepts and Methods (Preprint), pages 546–566, 1990.
[Wad91] Philip Wadler. Is there a use for linear logic? In Proceedings of ACM Symposium
on Partial Evaluation and Semantics-Based Program Manipulation, pages 255–273,
1991.
[WAL+89] Pierre Weis, Marı́a-Virginia Aponte, Alain Laville, Michel Mauny, and
Ascánder Suárez. The CAML reference manual, Version 2.6. Technical report,
Projet Formel, INRIA-ENS, 1989.
January 15, 2000 BIBLIOGRAPHY 287
[Wan87] Mitchell Wand. Complete type inference for simple objects. In Proceedings of
the IEEE Symposium on Logic in Computer Science, Ithaca, NY, June 1987.
[Wan88] Mitchell Wand. Corrigendum: Complete type inference for simple objects. In
Proceedings of the IEEE Symposium on Logic in Computer Science, 1988.
[Wan89] Mitchell Wand. Type inference for record concatenation and multiple inher-
itance. In Fourth Annual IEEE Symposium on Logic in Computer Science, pages
92–97, Pacific Grove, CA, June 1989.
[Win93] Glynn Winskel. The Formal Semantics of Programming Languages: An Introduc-
tion. MIT Press, 1993.
[WR25] Alfred North Whitehead and Bertrand Russell. Principia Mathematica, Volume
1. Cambridge University Press, Cambridge, 1925.
[Wri92] Andrew K. Wright. Typing references by effect inference. In Bernd Krieg-
Bruckner, editor, ESOP ’92, 4th European Symposium on Programming, Rennes,
France, February 1992, Proceedings, volume 582 of Lecture Notes in Computer Sci-
ence, pages 473–491. Springer-Verlag, New York, N.Y., 1992.
Index
F
f
<:(“Full” bounded quantification), 162
Fk
<:
(Bounded quantification), 160
F!<: (Higher-order bounded quantification),
224
F!(Higher-order polymorphic lambda-calculus),
214
(Iso-recursive types), 115
 !
 (multi-step evaluation), 26
 ! (one-step evaluation), 25, 43
System F(Polymorphic lambda-calculus),
133
!(Simply typed lambda-calculus), 61
<:(Simply typed lambda-calculus with sub-
typing), 89
F!(Summary), 216
(Untyped lambda-calculus), 43
abstract grammar, 21
abstract syntax tree, 24
Ad-hoc polymorphism, 131
algorithmic subtyping, 91
beta-reduction, 34
bound variable, 33
capture-avoiding substitution, 41
Church numerals, 36
Church-style, 59
closed term, 33
combinator, 33
Curry-style, 59
Currying, 34
de Bruijn indices, 46
de Bruijn terms, 46
DeMillo, Richard, 13
depth of a term, 24
derivable, 53
Dill, David, 13
elimination rule, 60
explicitly typed, 59
expression, see term
fixed-point combinator, 38
free variable, 33
free variables, 40
generation lemma, see inversion lemmas
higher-order functions, 34
identity function, 33
implicitly typed, 59
inductive definition, 22
introduction rule, 60
inversion lemmas
typing, 54, 62
lambda-calculus, 31, 32
lambda-term, see term
lexicographic induction, 19
Lipton, Richard, 13
metalanguage, 33
metavariable, 33
nameless term, 46
naming context, 46
natural-number induction, 18
normal form, 26, 38
object, 100
object calculus, 31
object language, 33
Overloading, 131
288
January 15, 2000 INDEX 289
Parametric polymorphism, 131
Perlis, Alan, 13
pi-calculus, 31
preservation theorem, 54, 64, 218
principal typings, 125
progress theorem, 55, 64, 219
pure lambda-calculus, 32
rules
CT-ABS, 121, 256
CT-APP, 121, 256
CT-ITER, 121, 256
CT-PROJ, 259
CT-SUCC, 121, 256
CT-VAR, 121, 256
CT-ZERO, 121, 256
E-APP1, 43, 61, 77, 89, 134, 160, 210,
216, 225, 239
E-APP2, 43, 61, 77, 89, 134, 160, 210,
216, 225, 239
E-ASSIGN, 77
E-ASSIGN1, 77
E-ASSIGN2, 77
E-BETA, 34, 43, 49, 61, 77, 89, 134,
160, 210, 216, 225, 239
E-BETA2, 134, 161, 214, 216, 225
E-BETANATIS, 26, 30
E-BETANATIZ, 25, 30
E-BETANATPS, 25, 29
E-BETANATPZ, 25, 29
E-BODYOF, 239
E-BOOLBETAF, 25, 29
E-BOOLBETAT, 25, 29
E-CASE, 72
E-CASEBETA, 72
E-COERCE1, 239
E-CONS1, 73
E-CONS2, 74
E-DEREF, 77
E-DEREF1, 77
E-FOLD, 116
E-FOLDBETA, 115
E-HEAD, 74
E-HEADBETA, 74
E-IF, 25, 29
E-ISZERO, 26, 30
E-LET, 68, 71
E-LETBETA, 68, 71
E-LLETBETA, 75
E-LRCDBETA, 75
E-NULL, 74
E-NULLBETAF, 74
E-NULLBETAT, 74
E-PACK, 148
E-PACKBETA, 148
E-PRED, 25, 29
E-PROJ, 69
E-RCDBETA, 69, 204, 246
E-RECORD, 69, 204, 246
E-RECORDSUBST, 246
E-REF, 77
E-REF1, 77
E-STRUCT, 239
E-STRUCTBETA, 239
E-STRUCTSUBST, 239
E-SUCC, 25, 29
E-TAG, 72
E-TAIL, 74
E-TAILBETA, 74
E-TAPP, 134, 161, 216, 225
E-UNFOLD, 116
E-UNPACK, 148
E-UPDATEBETA, 204
K-ALL, 214, 217, 226
K-ARROW, 211, 217, 226, 240, 248
K-SINGLETON, 244
K-STRUCT, 240
K-TABS, 211, 217, 226, 245
K-TAPP, 211, 217, 226, 245
K-TARR-SELF, 247
K-TRCD, 243, 245
K-TRCD-SELF, 247
K-TVAR, 211, 217, 226, 240
K-TYPEOF, 240
K-TYPROJ, 243, 245
KEQV-HOS, 247
KEQV-HOS-SINGLETON, 247
KEQV-HOS-TARR, 247
KEQV-HOS-TRCD, 247
KEQV-HOS-TYPE, 247
KEQV-SINGLETON, 244
KEQV-TARR, 245
KEQV-TRCD-PERM, 242, 245
KF-HOS, 247
January 15, 2000 INDEX 290
KF-SINGLETON, 244
KF-TARR, 245
KF-TRCD, 242, 245
M-RCD, 71
M-VAR, 71
P-RCD, 256
P-VAR, 256
Q-ALL, 214, 217, 225
Q-APP, 211, 217, 225
Q-ARROW, 81, 83, 90, 211, 217, 225,
239, 248, 249
Q-BETA, 210, 217, 225
Q-DEF, 84
Q-EXT, 211, 217, 225
Q-RCD-PERM, 81, 90, 205, 249
Q-REFL, 81, 83, 90, 210, 216, 225, 239,
248, 249
Q-SINGLETON1, 244
Q-SINGLETON2, 244
Q-STRUCTBETA, 239
Q-SUB, 242, 244
Q-SYMM, 81, 83, 90, 210, 217, 225,
239, 248, 249
Q-TABS, 211, 217, 225
Q-TRANS, 81, 83, 90, 210, 217, 225,
239, 248, 249
Q-TRCD, 242
Q-TRCD-PERM, 242
Q-TRCDBETA, 242
Q-TRCDEXT, 242
Q-TYPROJ, 242
QA-ALL, 221
QA-ARROW, 82, 84, 113, 221
QA-BASE, 84, 113
QA-LOOP, 113
QA-RCD, 82
QA-RECL, 113
QA-RECR, 113
QA-REDUCEL, 84, 221
QA-REDUCER, 84, 221
QA-TABS, 221
QA-TAPP, 221
QA-TVAR, 221
RA-APP, 221
RA-BETA, 221
RA-DEF, 84
S-ABS, 226
S-ALL, 161, 162, 179, 226
S-APP, 226
S-ARROW, 87, 90, 161, 226
S-EQV, 90, 226
S-RCD, 91
S-RCD-DEPTH, 87, 90, 164, 205
S-RCD-VARIANCE, 205
S-RCD-WIDTH, 87, 90, 164, 205
S-REFL, 89, 161
S-SOME, 171
S-TOP, 88, 89, 161, 226
S-TRANS, 87, 89, 161, 226
S-TRCD-WIDTH, 243, 245
S-TVAR, 159–161, 226
SA-ALL, 178, 179
SA-ARROW, 92, 178
SA-RCD, 92
SA-REFL-TVAR, 177
SA-TOP, 92, 177
SA-TRANS-TVAR, 177
SK-EQV, 243, 244
SK-SINGLETON, 244
SK-TRANS, 243, 244
SK-TRCD-DEPTH, 243, 245
T-ABS, 59, 61, 77, 90, 134, 161, 211,
217, 226, 240, 248
T-APP, 60, 61, 77, 86, 90, 134, 161,
211, 218, 226, 240, 248
T-ASSIGN, 78
T-BODYOF, 240
T-CASE, 72
T-COERCE, 240
T-CONS, 74
T-DEREF, 78
T-EQ, 81, 84, 211, 218, 240, 248, 249
T-FALSE, 53, 56
T-FIX, 73
T-FOLD, 116
T-HEAD, 74
T-IF, 53, 56
T-ISZERO, 53, 57
T-LET, 68, 256
T-LLET, 75
T-LOC, 78
T-LRCD, 75
T-NIL, 74
T-NULL, 74
January 15, 2000 INDEX 291
T-PACK, 146, 148, 171, 215
T-PRED, 53, 57
T-PROJ, 69, 205, 249
T-RCD, 69, 205, 246, 249
T-REF, 78
T-STRUCT, 240
T-SUB, 86, 90, 161, 227
T-SUCC, 52, 57
T-TABS, 133, 134, 161, 214, 218, 227
T-TAIL, 74
T-TAPP, 133, 134, 161, 214, 218, 227
T-TRUE, 53, 56
T-UNFOLD, 116
T-UNIT, 68, 78
T-UNPACK, 146, 148, 171, 215
T-UPDATE, 205
T-VAR, 60, 61, 77, 90, 134, 161, 211,
217, 226, 240
T-VARIANT, 72
T-ZERO, 52, 56
TA-ABS, 82, 84, 94, 113, 174, 222
TA-APP, 82, 84, 94, 114, 174, 222
TA-COND, 261
TA-PROJ, 82, 95
TA-RCD, 82, 94
TA-TABS, 174, 222
TA-TAPP, 175, 222
TA-VAR, 82, 84, 94, 113, 174, 222
XA-OTHER, 84, 113, 174, 222
XA-PROMOTE, 174
XA-REC, 113
XA-REDUCE, 84, 222
simple types, 58
simply typed lambda-terms, 58
size of a term, 24
Smith, Brian Cantwell, 45
soundness, 54
stuck term, 26
subject expansion, 55
subject reduction, see preservation
substitution lemma, 218
subtype polymorphism, 131
term, 21
Type systems and components
Type systems and components
F
f
<:: “Full” bounded quantification
[! 8 <: bq full], 162
Algorithmic rules for equi-recursive
types [! B ], 113
Algorithmic rules for records with per-
mutation [! fg ], 82
Algorithmic rules for simply typed
lambda-calculus [! B], 82
Algorithmic rules for type definitions
[! B $], 84
Algorithmic rules for F! [], 221
Algorithmic subtyping [! fg <:], 92
Algorithmic subtyping [], 177
Algorithmic typing [! fg <:], 94
Algorithmic typing [], 174
Arithmetic expressions [B N (untyped)],
29
Base types [! B], 67
Booleans [B (untyped)], 29
Bounded existential quantification [Fk
<:
+
9], 171
Type systems and components
Fk
<:
: Bounded quantification [! 8
<: bq], 160
Dependent functions [???], 248
Dependent record terms (??) [???],
246
Dependent records [????], 249
Dependent records of types [! )
trcd depkind ], 245
Existential types [!89], 148
Exposure [], 174
General recursion [! fix], 73
Type systems and components
F!<: : Higher-order bounded quan-
tification [F<:+ F!], 224
Higher-order existential types [F !<: +
9], 215
Type systems and components
F!: Higher-order polymorphic lambda-
calculus [System F+)], 214
Higher-order singletons [????], 247
Type systems and components
: Iso-recursive types [! B ],
115
Lazy let bindings [! let lazy], 75
Lazy records [! fg lazy], 75
January 15, 2000 INDEX 292
Let binding [! let], 68
Lists [! B List], 73
Type systems and components
System F: Polymorphic lambda-calculus
[!8], 133
Polymorphic update [F<:+ fg update],
204
Record patterns [! fg let pat (un-
typed)], 71
Records and tuples [! fg], 69
Records of types [! ) trcd ], 242
Records with permutation of fields
[! fg ], 81
References [! Unit :=], 76
Type systems and components
!: Simply typed lambda-calculus
[! (typed)], 61
Type systems and components
<:: Simply typed lambda-calculus
with subtyping [!<:], 89
Singleton kinds [! Eq], 244
Structures [! X S ], 238
Subtyping rules for records [!<:fg],
90
Type systems and components
F!: Summary [System F+)], 216
Type definitions [! B $], 83
Type operators and kinding [! 
)], 210
Typed record patterns [! fg let pat(typed)],
256
Typing rules for booleans [B (typed)],
56
Typing rules for numbers [B N (typed)],
56
Unit type [! Unit], 67
Type systems and components
: Untyped lambda-calculus [!
(untyped)], 43
Variants [! <>], 72
type variables, 118
types, 52
typing assertions, 53
typing context, 59
typing derivation, 53
typing judgements, 53
typing relation, 53
unification, 125
unification algorithm, 126
unifier, 126
unify, 126
untyped lambda-calculus, 32
value, 25
variable capture, 41
well-founded induction, 18
well-founded set, 18
Y combinator, 38

