58 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 14, NO. 1, FEBRUARY 2010
On Set-Based Multiobjective Optimization
Eckart Zitzler, Lothar Thiele, and Johannes Bader
Abstract— Assuming that evolutionary multiobjective opti-
mization (EMO) mainly deals with set problems, one can identify
three core questions in this area of research: 1) how to formalize
what type of Pareto set approximation is sought; 2) how to
use this information within an algorithm to efficiently search
for a good Pareto set approximation; and 3) how to compare
the Pareto set approximations generated by different optimizers
with respect to the formalized optimization goal. There is a vast
amount of studies addressing these issues from different angles,
but so far only a few studies can be found that consider all
questions under one roof. This paper is an attempt to summarize
recent developments in the EMO field within a unifying theory
of set-based multiobjective search. It discusses how preference
relations on sets can be formally defined, gives examples for
selected user preferences, and proposes a general preference-
independent hill climber for multiobjective optimization with
theoretical convergence properties. Furthermore, it shows how to
use set preference relations for statistical performance assessment
and provides corresponding experimental results. The proposed
methodology brings together preference articulation, algorithm
design, and performance assessment under one framework and
thereby opens up a new perspective on EMO.
Index Terms— Convergence, evolutionary algorithms, multi-
objective optimization, Pareto set approximation, preference
articulation.
I. INTRODUCTION
BY FAR, MOST PUBLICATIONS within the field ofevolutionary multiobjective optimization (EMO) focus on
the issue of generating a suitable approximation of the Pareto-
optimal set, or Pareto set approximation for short. For instance,
the first book on EMO by Kalyanmoy Deb [7] is mainly
devoted to techniques of finding multiple tradeoff solutions
using evolutionary algorithms.
Taking this view, one can state that EMO in general deals
with set problems: the search space  consists of all potential
Pareto set approximations rather than single solutions, i.e.,
 is a set of sets. Furthermore, an appropriate order on 
is required to fully specifiy the set problem—this order will
here be denoted as set preference relation. A set preference
relation provides the information on the basis of which the
search is carried out; for any two Pareto set approximations,
it says whether one set is better or not. Set preference relations
can be defined, e.g., via set quality measures, which can
be regarded as objective functions for sets, or directly using
a binary relation, e.g., extended Pareto dominance on sets.
Transforming the original problem into such a set problem
Manuscript received February 22, 2008, revised August 22, 2008 and
December 11, 2008; accepted January 8, 2009. First version published
October 30, 2009; current version published January 29, 2010.
The authors are with the Computer Engineering and Networks Laboratory
(TIK), Eidgenössische Technische Hochschule Zürich, Switzerland (e-mail:
zitzler@tik.ee.ethz.ch; thiele@tik.ee.ethz.ch; jbader@tik.ee.ethz.ch).
Digital Object Identifier 10.1109/TEVC.2009.2016569
offers many advantages for decision making, but also poses
new challenges in terms of search space complexity.
In the light of this dicussion, three core research issues
can be identified in the EMO field: 1) how to formalize
the optimization goal in the sense of specifying what type
of set is sought; 2) how to effectively search for a suitable
set to achieve the formalized optimization goal; and 3) how
to evaluate the outcomes of multiobjective optimizers with
respect to the underlying set problem.
The question of what a good set of compromise solutions
is depends on the preferences of the decision maker. Suppose,
for instance, that a few representative solutions are to be
selected from a large Pareto-optimal set; the actual choice
can be quite different for different users. Many multiobjective
evolutionary algorithms (MOEAs) aim at generating a subset
that is uniformly distributed in the objective space [8], [16],
[37]; others consider the subset maximizing the hypervolume
of the dominated objective space as the best one [14], [22].
There are many more possibilites depending on the user and
the situation: one may be interested in the extreme regions of
the Pareto-optimal set [9], in convex portions of the tradeoff
surface (knee points) [3], or in regions close to a predefined
ideal point [11], to name only a few. These preferences are
usually hard-coded in the algorithm, although there have been
attemtps to design methods with more flexibility with respect
to user preferences [13], [36].
Overall, one can conclude that EMO in general relies on set
preferences, i.e., preference information that specifies whether
one Pareto set approximation is better than another, and that
MOEAs usually implement different types of set preferences.
There are various studies that focus on the issue of prefer-
ence articulation in EMO, in particular integrating additional
preferences such as priorities, goals, and reference points [2],
[4], [6], [11], [17], [23], [28]. However, these studies mainly
cover preferences on solutions and not preferences on sets.
Furthermore, there is a large amount of publications that deal
with the definition and the application of quantitative quality
measures for Pareto set approximations [20], [24], [31], [38],
[40]. These quality measures or quality indicators reflect set
preferences and have been widely employed to compare the
outcomes generated by different MOEAs. Moreover, in recent
years a trend can be observed to directly use specific measures
such as the hypervolume indicator and the epsilon indicator
in the search process [1], [10], [14], [15], [21], [22], [25],
[27], [36]. Nevertheless, a general methodology to formalize
set preferences and to use them for optimization is missing.
This paper represents one step toward such an overarching
methodology. It:
1) proposes a theory of set preference relations that clarifies
how user preferences on Pareto set approximations can
1089-778X/$26.00 © 2010 IEEE
ZITZLER et al.: ON SET-BASED MULTIOBJECTIVE OPTIMIZATION 59
TABLE I
OVERVIEW OF IMPORTANT SYMBOLS USED THROUGHOUT THE PAPER
Symbol Meaning
X set of feasible solutions resp. decision vectors
Z objective space with Z ⊆ Rn
f =
( f1, . . . , fn)
vector-valued function f : X −→ Rn
a par b weak Pareto dominance relation on solutions
a  b any preference relation on solutions
a ≺ b a  b ∧ b  a (strict preference)
a ‖ b a  b ∧ b  a (incomparability)
a ≡ b a  b ∧ b  a (indifference)
Min(X ,) optimal solutions with respect to 
 set of all admissible solutions sets A ⊆ X
m set of all solutions sets A ⊆ X with |A| ≤ m
A par B weak Pareto dominance relation on solution sets
A  B any preference relation on solution sets
A minpart B constructed set preference relation that combines
 with minimum elements partitioning
A ≺ B A  B ∧ B  A (strict preference)
A ‖ B A  B ∧ B  A (incomparability)
A ≡ B A  B ∧ B  A (indifference)
Min(,) optimal solution sets with respect to 
be formalized on the basis of quality indicators and what
criteria such formalizations must fulfill;
2) introduces a general set-preference based search algo-
rithm that can be flexibly adapted to arbitrary types of set
preference relations and that can be shown to converge
under certain mild assumptions; and
3) discusses an approach to statistically compare the out-
comes of multiple search algorithms with respect to a
specific set preference relation.
The novelty of this approach is that it brings all aspects
of preference articulation, multiobjective search, and perfor-
mance assessment under one roof, while achieving a clear
separation of concerns. This offers several benefits: 1) it
provides flexibility to the decision maker as he can change his
preferences without the need to modify the search algorithm;
2) the search can be better guided which is particularly
important in the context of high-dimensional objective spaces;
3) algorithms designed to meet specific preferences can be
compared on a fair basis since the optimization goal can be
explicitly formulated in terms of the underlying set preference
relation. The practicability of this approach has already been
demonstrated in a preliminary study which contains selected
proof-of-principle results [39]. This paper is the full version of
this paper; in particular, it introduces the underlying theoretical
framework and contains an extensive investigation of the
proposed search methodology.
In the following, we will first provide the formal basis of
set preference relations and introduce fundamental concepts.
Afterward, we will discuss how set preference relations can be
Decision space Objective space
x
f
j
i
l
m
g
k
f2
f1
Z
Fig. 1. Optimization scenario with X = { f, g, i, j, k, l, m} and n = 2. In
the case that the preference relation is the weak Pareto-dominance relation
par, the shaded areas represent locations of solutions that are dominated by
k (dark) and that dominate k (light).
designed using quality indicators and present some example
relations. A general, set preference based multiobjective search
algorithm will be proposed in Section IV, including a discus-
sion of convergence properties. Finally, Section V presents a
methodology to compare algorithms with respect to a given
set preference relation and provides experimental results for
selected preferences.
II. NEW PERSPECTIVE: SET PREFERENCE RELATIONS
As has been described in the introduction, multiobjective
optimization will be viewed as a preference-based optimization
on sets. The purpose of this section is to formally define
the notation of optimization and optimality in this context
and to provide the necessary foundations for the practical
algorithms described in the forthcoming sections. Table I
serves as a reference for the nomenclature introduced in the
following.
A. Basic Terms
We are considering the optimization of vector-valued
objective functions f = ( f1, . . . , fn) : X −→ Rn where
all components fi are—without loss of generality—to be
minimized. Here, X denotes the feasible set of solutions in
the decision space, i.e., the set of alternatives of the decision
problem. A single alternative x ∈ X will be denoted as a
decision vector or solution. The image of X under f is denoted
as the feasible set in the objective space Z = f (X ) = {y ∈
R
n | ∃x ∈ X : y = f (x)} where Z ⊆ Rn . The objective values
of a single alternative x will be denoted as objective vector
y = f (x).
For reasons of simplicity, we suppose that the decision
space is finite. Nevertheless, almost all results described in
the paper hold for infinite sets also or can be generalized.
Fig. 1 illustrates a possible scenario with seven solutions in
the feasible set and a 2-D objective space (n = 2).
In order to allow for optimization in such a situation,
we need a preference relation a  b on the feasible set
in the decision space which denotes that a solution a is at
least as good as a solution b. In the context of this paper,
we will suppose that all preference relations are preorders.1
1A preorder  on a given set S is reflexive and transitive: a  a and
(a  b ∧ b  c)⇒ (a  c) holds for all a, b, and c in S.
60 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 14, NO. 1, FEBRUARY 2010
f g
c
c    b
ba
ed
k
j m
lih
Fig. 2. Representation of a preordered set (X ,) where X consists of the
solutions {a, . . . , m}. The optimal solutions are Min(X ,) = {c, g, l, m}.
{i, j} and {l, m} form two equivalence classes, i.e. i ≡ j and l ≡ m. As
b  c and c  b, we find c ≺ b.
A well-known preference relation in the context of multiob-
jective optimization is the (weak) Pareto dominance.
Definition 2.1: A solution a ∈ X weakly Pareto-dominates
a solution b ∈ X , denoted as a par b, if it is at least as good
in all objectives, i.e. fi (a) ≤ fi (b) for all 1 ≤ i ≤ n.
Note that par is only one example of a useful preference
relation. The results described in this paper are not restricted
to the concept of Pareto dominance but hold for any preference
relation defined on the set of solutions.
The situation that a solution a is at least as good as a
solution b will also be denoted as a being weakly preferable to
b in this paper. Moreover, we will use the following terms: A
solution a is strictly better than or preferable to a solution
b (denoted as a ≺ b) if a  b ∧ b  a. A solution a
is incomparable to a solution b (a ‖ b) if a  b ∧ b 
a. A solution a is equivalent or indifferent to a solution b
(denoted as a ≡ b) if a  b ∧ b  a. We say that a set
of solutions form an equivalence class, if they are mutually
equivalent. We denote the set of minimal elements2 in the
ordered set (S,) as
Min(S,) = {x ∈ S |  ∃a ∈ S : a  x ∧ x  a}.
We will call the set
X ∗ = Min(X ,)
the optimal set of X with respect to  and an element x∗ ∈ X ∗
is an optimal solution. Optimization may now be termed as
finding a minimal element in the ordered feasible set (X ,).
Preference relations can also be depicted graphically. Fig. 2
shows a possible preordered set of solutions X = {a, . . . , m}.
In particular, the preferences among { f, g, i, k, l, m} corre-
spond directly to the scenario shown in Fig. 1.
2A minimal element u of an ordered set (S,) set with a preorder 
satisfies: If a  u for some a in the set, then u  a.
B. Approximation of the Pareto-Optimal Set
As a preference relation  defined above is usually not
a total order on the feasible set,3 we will often have many
optimal solutions, i.e., many minimal elements that reflect the
different tradeoffs among the objective functions.
In particular, this holds for the Pareto preference relation
par. As a result, we may not only be interested in one of these
minimal elements but also in a carefully selected subset that
reflects additional preference information of some decision
maker. Traditional evolutionary multiobjective optimization
methods attempt to solve this problem by maintaining and im-
proving sets of decision vectors, denoted as populations. The
corresponding optimization algorithms are tuned to anticipated
preferences of a decision maker.
Thus, the underlying goal of set-based multiobjective opti-
mization can be described as determining a (small-sized) set
of alternative solutions:
1) that contains as many different decision vectors as possi-
ble that are minimal with respect to a preference relation
on the feasible set in the decision space (for example
the weak Pareto-dominance according to Definition 2.1);
and
2) whose selection of minimal and non-minimal decision
vectors reflects the preferences of the decision maker.
As pointed out in Section I, the purpose of the paper is to
define set-based multiobjective optimization on the basis of
these two aspects. In contrast to previous results, the second
item as defined above is made formal and treated as a first
class citizen in optimization theory and algorithms. This not
only leads to a better understanding of classical population-
based multiobjective optimization but also allows for defining
set-based methods with corresponding convergence results as
well as statistical tests to compare different algorithms. Finally,
a new set of optimization algorithms can be obtained which
can directly take preference information into account.
Therefore, we need to formalize the preferences of a deci-
sion maker on the subset of decision vectors in an optimal set
of solutions. This will be done by defining a preorder  on
the set of all possible sets of solutions. A set of solutions P
is defined as a set of decision vectors, i.e., x ∈ P ⇒ x ∈ X .
A set of all admissible sets, e.g., sets of finite size, is denoted
as  , i.e., P ∈  .
We define set-based multiobjective optimization as find-
ing a minimal element of the ordered set (,) where
 is a set of admissible sets of solutions.
We can summarize the elements of a set-based multiobjective
optimization problem as follows:
1) a set of feasible solutions X ;
2) a vector-valued objective function f : X −→ Rn;
3) a set  of all admissible sets P of decision vectors with
x ∈ P ⇒ x ∈ X ;
4) a preference relation  on  .
In the light of the above discussion, the preference rela-
tion  needs to satisfy the aforementioned two conditions;
3A binary relation  on a set S is called total, if (a  b) ∨ (b  a) holds
for all a, b ∈ S.
ZITZLER et al.: ON SET-BASED MULTIOBJECTIVE OPTIMIZATION 61
f2
f1
Z
:    A
:    G
:    B
Fig. 3. Representation of a preordered set of sets of solutions {A, B, G} ∈ 
where par is assumed to be the underlying solution-based preference relation.
We find B  A, G  A and B ‖ G , i.e., B and G are incomparable.
the first one guarantees that we actually optimize the
objective functions and the second one allows the addition
of preferences of the decision maker. In the next section, we
will discuss the necessary properties of suitable preference
relations and the concept of refinement.
C. Preference Relations
We will construct  in two successive steps. At first,
a general set-based preference relation (a set preference re-
lation)  ⊆  ×  will be defined that is conforming to
a solution-based preference relation  ⊆ X × X . This set
preference relation will then be refined by adding preferences
of a decision maker in order to possibly obtain a total order.
For a conforming set preference relation we require that no
solution is excluded that could be interesting to a decision
maker. In addition, if for each solution b ∈ B there is some
solution a ∈ A which is at least as good, then we can safely
say that A is at least as good as or weakly preferable to B .
From the above considerations, the definition of a con-
forming set-based preference relation follows directly; it is
in accordance to the formulations used in [20], [40].
Definition 2.2: Let be given a set X and a set  whose
elements are subsets of X , i.e., sets of solutions. Then the
preference relation  on  conforms to  on X if for all
A, B ∈ 
A  B ⇔ (∀b ∈ B : (∃a ∈ A : a  b)).
As an example, Fig. 3 shows three sets of solutions A, B, and
G. According to the above definition, we find that B  A and
G  A. As sets B and G are incomparable, we have B ‖ G.
Now, it will be shown that the above preference relation is
indeed suitable for optimization.
Theorem 2.3: The set preference relation  as defined in
Definition 2.2 is a preorder.
Proof: A  A is true as ∀a′ ∈ A : (∃a ∈ A : a  a′)
holds with a′ = a. Now we need to show that A  B ∧ B 
C ⇒ A  C . Given an arbitrary c∗ ∈ C . From B  C we
know that ∃b∗ ∈ B such that b∗  c∗. From A  B we know
that ∃a∗ ∈ A such that a∗  b∗. From the transitivity of 
A
FE
B
C
H
G
D
Fig. 4. Representation of a preordered set of sets of solutions  =
{A, B, C, D, E, F, G, H }. The minimal sets are Min(,) = {C, D, H }.
we can conclude that a∗  c∗ holds. As a result, ∀c∗ ∈ C :
(∃a∗ ∈ A : a∗  c∗).
Therefore, we can also represent the relations between the
sets of solutions in form of an acyclic graph whose nodes
correspond to sets of solutions and edges correspond to the
set preference relation . As an example, Fig. 4 represents
such a diagram. Note that the relation between the sets A, B ,
and G corresponds exactly to the scenario shown in Fig. 3.
The minimal sets are Min(,) = {C, D, H }.
The above definition of a conforming set-based preference
relation ensures that each set in Min(,) contains at least
one representative of each equivalence class of X ∗. Therefore,
no preferences other than that contained in  is included so
far.
For practical reasons, one may deal with sets of solutions
that have an upper bound m on their size, i.e., if P ∈ m , then
|P| ≤ m. In this case, the properties of minimal elements of
(m,) are somewhat more complex.
Let s denotes the number of equivalence classes of X ∗ =
Min(X ,), i.e., the maximal number of solutions that are not
equivalent. In the important case m < s (a small set size),
a set P is an element of Min(m,) (i.e., it is a minimal set
of solutions) iff it contains m minimal solutions that are not
equivalent, i.e., a minimal set of solutions may contain one
representative of each equivalence class only.
If we are interested in the solutions themselves, then we
may want to have the possibility to determine all solutions
that lead to the same value in objective space. They may well
be different in the decision space and, therefore, be interesting
to a decision maker, see Fig. 2. This can be achieved by
replacing a given solution-based preference relation  that
considers objective values only. Equivalent solutions that lead
to the same objective values should become incomparable. As
a result, solutions will be equivalent only if they are identical
in the decision space. We denote such a preference relation as
. with
a
. b⇔ (a = b)∨ (a ≺ b).
This new preference relation is a preorder as it is reflexive
(a
. a clearly holds) and transitive. The latter property can be
shown as follows: a
. b∧b . c⇒ ((a = b)∨(a ≺ b))∧((b =
c) ∨ (b ≺ c))⇒ ((a = c) ∨ (a ≺ c))⇒ a . c. Fig. 5 shows
the order graph if par is replaced by .par in Fig. 2. As can
62 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 14, NO. 1, FEBRUARY 2010
a
d e
h i
j m
k l
f g
b c
Fig. 5. Representation of the preordered set of solutions from Fig. 2 if par
is replaced by
.par.
be seen, the equivalence classes are not present anymore and
i, j as well as l, m are now considered as incomparable.
The above definition of a preference relation
. derived
from  ensures that the minimal set of sets Min(, .) con-
tains sets with all possible combinations of minimal elements
Min(X ,). More precisely, we can state that each minimal set
P∗ ∈ Min(m,
.
) now contains m minimal solutions provided
that m < |X ∗|.
D. Refinements
What remains to be done is to define the notion of refine-
ment, as we need to have a possibility to include preference
information into a conforming preference relation. This way,
we can include preference information of a decision maker
and optimize toward a set which contains a preferred subset
of all minimal solutions, i.e., nondominated solutions in the
case of Pareto dominance. The goal of such a refinement is
twofold: At first, the given preorder should become “more
total.” This way, there are less incomparable sets of solutions
which are hard to deal with by any optimization method.
Second, the refinement will allow us to explicitly take into
account preference information of a decision maker.
An example is shown in Fig. 6, where three edges (prefer-
ence relations) have been added and the resulting ordering is a
total preorder with the optimal set of solutions H . Just adding
an ordering among incomparable solutions potentially leads to
cycles in the ordering, as the resulting structure is no longer a
preorder. Using such an approach in optimization will prevent
convergence in general, see also Fig. 7.
For the refinement, we require the following properties.
1) The refinement should again be a preorder.
2) If a set is minimal in the refined order for some subset of
 , it should also be minimal in the original order in the
same subset. This way, we guarantee that we actually
A B
D
C
H
H
C
GFE
E A F G B
D
Fig. 6. Including preference information may create a total preorder that
can be used for optimization. Here, three preferences F  A, B  G and
H  C have been added to the preorder shown in Fig. 4. The resulting total
preorder is shown at the bottom.
A
E F G
H
C
D
B
Fig. 7. Including preference information arbitrarily may create cycles in the
optimization. Here, two preferences A  F and F  B have been added to
the preorder shown in Fig. 4.
optimize the objective functions with respect to some
preference relation, e.g., Pareto dominance.
As a result of this discussion, we obtain the following defini-
tion:
Definition 2.4: Given a set  . Then the preference relation
ref refines  if for all A, B ∈  we have
(A  B) ∧ (B  A)⇒ (A ref B) ∧ (B ref A).
Examples of legal refinements are depicted in Fig. 8. Note,
that the refinement still needs to be a preorder.
If we use the notion of strictly better, we can also derive
the condition A ≺ B ⇒ A ≺ref B . In other words, if in the
given preference relation a set A is strictly better than a set B
(A ≺ B), then it must be strictly better in the refined relation,
too (A ≺ref B). As can be seen, refining a preference relation
maintains existing strict preference relationships. If two sets
are incomparable, i.e., A ‖ B ⇔ (A  B) ∧ (B  A), then
ZITZLER et al.: ON SET-BASED MULTIOBJECTIVE OPTIMIZATION 63
ref
Fig. 8. Left-hand side shows the four different possibilities between two
nodes of the given preference relation: no edge (incomparable), single edge
(one is better than the other) and double edge (equivalent). The right-hand
side shows the possibility in case of the refined relation. The dotted edges
represent all possible changes of edges if  is refined to ref.
ref
Fig. 9. Left-hand side shows the four different possibilities between two
nodes of the given preference relation: no edge (incomparable), single edge
(one is better than the other) and double edge (equivalent). The right-hand
side shows the possibility in case of the weakly refined relation. The dotted
edges represent all possible changes of edges if  is weakly refined to ref.
additional edges can be inserted by the refinement. In case of
equivalence, i.e., A ≡ B ⇔ (A  B) ∧ (B  A), edges can
be removed.
As will be seen in the next section, some of the widely
used preference relations are not refinements in the sense of
Definition 2.4, but satisfy a weaker condition.
Definition 2.5: Given a set  . Then the set preference
relation ref weakly refines  if for all A, B ∈  we have
(A  B)∧ (B  A)⇒ (A ref B).
In other words, if set A is strictly better than B (A ≺ B),
then A weakly dominates B in the refined preference relation,
i.e., A ref B . Therefore, A could be incomparable to B in
the refined preference relation, i.e., A ‖ref B . In addition, if a
preference relation refines another one, it also weakly refines
it. Fig. 9 depicts all possibilities of a weak refinement. The
weak refinement still needs to be a preorder.
The following hierarchical construction of refinement rela-
tions will be used in later sections for several purposes. At
first, it allows the conversion of a given weak refinement into
a refinement. This way, a larger class of available indicators
and preference relations can be used. In addition, it provides a
simple method to add decision maker preference information
to a given relation by adding an order to equivalent sets. This
way, a preorder can be made “more total.” Finally, it enables
refining a given preorder in a way that helps to speed up the
convergence of an optimization algorithm, e.g., by taking into
account also solutions that are worse than others in a set. This
way, the successful technique of nondominated sorting can be
used in the context of set-based optimization.
The following construction resembles the concept of hierar-
chy used in [17]; however, here (a) we are dealing with pref-
erence relations on sets and (b) the hierarchical construction
is different.
Definition 2.6: Given a set  and a sequence S of k
preference relations over  with S = (1,2, . . . ,k), the
preference relation S associated with S is defined as follows.
Let A, B ∈ ; then A S B if and only if ∃1 ≤ i ≤ k such
that the following two conditions are satisfied:
(i) (i < k ∧ (A ≺i B)) ∨ (i = k ∧ (A k B))
(ii) ∀1 ≤ j < i : (A  j B ∧ B  j A).
With this definition, we can derive the following procedure
to determine A S B for two sets A and B .
1) Start from the first preference relation, i.e., j = 1.
Repeat the following step: If A ≡ j B holds (A and
B are equivalent), then increase j to point to the next
relation in the sequence if it exists.
2) If the final j points to the last preference relation ( j =
k), then set A S B ⇔ A k B . Otherwise, set A S
B ⇔ A ≺k B .
As described above, one of the main reasons to define a
sequence of preference relations is to upgrade a given weak
refinement to a refinement. In addition, it would be desirable
to add arbitrary preorders to the sequence S. As they need not
to be refinements of the given order , a decision maker can
freely add his preferences this way. The following theorem
states the corresponding results. The proof is provided in the
Appendix.
Theorem 2.7: Given a sequence of preference relations ac-
cording to Definition 2.6. Suppose there is a k ′ ≤ k such
that k′ is a refinement of a given preference relation  and
all relations  j , 1 ≤ j < k ′ are weak refinements of .
Then S is a refinement of . Furthermore, if all relations
 j , 1 ≤ j < k are preorders, so is S; if all relations  j ,
1 ≤ j < k are total preorders, then S is a total preorder.
All set preference relations  j , k ′ < j ≤ k can be arbitrary
preorders that may reflect additional preferences, see also
Fig. 10. Nevertheless, the resulting preference relation S still
refines . The previously described hierarchical construction
of refinements will be applied in later sections of the paper
to construct preference relations that are useful for set-based
multiobjective optimization.
III. DESIGN OF PREFERENCE RELATIONS USING QUALITY
INDICATORS
A. Unary Indicators
Unary quality indicators are a possible means to construct
set preference relations that on the one hand are total or-
ders and on the other hand satisfy the refinement property,
cf. Definition 2.4. They represent set quality measures that
64 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 14, NO. 1, FEBRUARY 2010
Weak
refinement
Preorder
Refinement
S = (  1,...,   k' – 1,   k',   k' + 1,...,   k)
Fig. 10. Representation of the hierarchical construction of refinements
according to Theorem 2.
f2
f1
Z
A = {d, e, f}
R = {r}
d
e
f
r
IH,R(A)
Fig. 11. Graphical representation of the unary hypervolume indicator.
map each set A ∈  to a real number I (A) ∈ R. Given
an indicator I , one can define the corresponding preference
relation as
A I B := (I (A) ≤ I (B)) (1)
where we assume that smaller indicator values stand for higher
quality; in other words, A is as least as good as B if the
indicator value of A is not larger than the one of B . By
construction, the preference relation I defined above is a
preorder as it is reflexive as I (A) ≤ I (A) and transitive as
(I (A) ≤ I (B)) ∧ (I (B) ≤ I (C))⇒ I (A) ≤ I (C). Moreover,
it is a total preorder because (I (A) ≤ I (B))∨ (I (B) ≤ I (A))
holds. Note that depending on the choice of the indicator func-
tion, there may be still sets that have equal indicator values,
i.e., they are indifferent with respect to the corresponding set
preference relation I. In this case, we may have equivalence
classes of sets, each one containing sets with the same in-
dicator value. For multiobjective optimization algorithms that
use indicators as their means of defining progress, sets with
identical indicator values pose additional difficulties in terms
of cyclic behavior and premature convergence. We will later
see how these problems can be circumvented by considering
hierarchies of indicators.
Clearly, not all possible indicator functions realize a refine-
ment of the orginal preference relation, e.g., weak Pareto dom-
inance. The following theorem provides sufficient conditions
for weak refinements and refinements.
Theorem 3.1: If a unary indicator I satisfies
(A  B) ∧ (B  A)⇒ (I (A) ≤ I (B))
for all A, B ∈  , then the corresponding preference re-
lation I according to (1) weakly refines the preference
relation  according to Definition 2.5. If
(A  B) ∧ (B  A)⇒ (I (A) < I (B))
holds, then I refines  according to Definition 2.4.
Proof: Consider A, B ∈  with (A  B) ∧ (B  A). If
I (A) ≤ I (B), then also A I B according to (1). If I (A) <
I (B), then I (A) ≤ I (B), but I (B) ≤ I (A), which implies
that A I B and B I A.
In other words, if A is strictly better than B , i.e., A ≺ B ,
then the indicator value of A must be not worse or must be
smaller than the one of B in order to achieve a weak refinement
or a refinement, respectively. In practice, this global property
may be difficult to prove for a specific indicator since one
has to argue over all possible sets. Therefore, the following
theorem provides sufficient and necessary conditions that are
only based on the local behavior, i.e., when adding a single
element. The proof of the theorem is given in the Appendix.
Theorem 3.2: Let I be a unary indicator and  a preference
relation on populations that itself conforms to a preference
relation  on its elements (see Definition 2.2). The relation
I according to (1) refines  if the following two conditions
hold for all sets A ∈  and solutions b with {b} ∈ :
1) if A  {b} then I (A ∪ {b}) = I (A);
2) if A  {b} then I (A ∪ {b}) < I (A).
For weak refinement one needs to replace the relation < by
≤ in the second condition. The second condition is necessary
for I being a refinement (in case of <) or weak refinement
(in case of ≤) of .
Using these two conditions, it is straightforward to prove
that an indicator induces a refinement of the weak Pareto
dominance relation. The hypervolume indicator [35], [38],
for instance, gives the volume of the objective space weakly
dominated by a set of solutions with respect to a given set of
reference points R ⊂ Z . We define the corresponding indicator
function as the negative volume IH (A) = −λ(H (A, R))
where λ denotes the Lebesgue measure with λ(H (A, R)) =∫
Rn
1H(A,R)(z)dz and
H (A, R) = {h | ∃a ∈ A ∃r ∈ R : f (a) ≤ h ≤ r}.
Now, it is easy to see that the volume is not affected whenever
a weakly Pareto dominated solution is added to a set A.
Furthermore, any solution b not weakly Pareto dominated by
A covers a part of the objective space not covered by A and
therefore the indicator value for A ∪ {b} is better (smaller)
than the one for A. These properties can easily be verified
by looking at the example shown in Fig. 11; therefore, the
hypervolume indicator induces a refinement, see also [15].
Furthermore, there are various other unary indicators which
ZITZLER et al.: ON SET-BASED MULTIOBJECTIVE OPTIMIZATION 65
induce weak refinements, e.g., the unary R2 and R3 indicators
[20] and the epsilon indicator [40]—the above conditions can
be used to show this, see also [24], [40] for a more detailed
discussion.
Furthermore, the necessary condition can be used to prove
that a particular indicator—when used alone—does not lead
to a weak refinement or a refinement of the weak Pareto
dominance relation. That applies, for instance, to most of
the diversity indicators proposed in the literature as they do
not fulfill the second condition in Theorem 3.2. Nevertheless,
these indicators can be useful in combination with indicators
inducing (weak) refinements as we will show in Section III-D.
B. Binary Indicators
In contrast to unary indicators, binary quality indicators
assign a real value to ordered pairs of sets (A, B) with
A, B ∈  . Assuming that smaller indicator values stand for
higher quality, we can define for each binary indicator I a
corresponding set preference relation as follows:
A I B := (I (A, B) ≤ I (B, A)) (2)
Similarly to unary undicators, one can derive sufficient condi-
tions for I being a refinement respectively a weak refinement
as the following theorem shows.
Theorem 3.3: Let I be a binary indicator that induces a
binary relation I on  according to (2). If I satisfies
(A  B) ∧ (B  A)⇒ (I (A, B) < I (B, A))
for all A, B ∈  , then the corresponding preference relation
I refines  according to Definition 2.4. If < is replaced by
≤, then I weakly refines  according to Definition 2.5.
Proof: Consider A, B ∈  with (A  B) ∧ (B  A).
If I (A, B) ≤ I (B, A), then also A I B according to (2). If
I (A, B) < I (B, A), then I (A, B) ≤ I (B, A), but I (B, A) ≤
I (A, B), which implies that A I B and B I A.
Note that the relation I is not necessarily a preorder,
and this property needs to be shown for each specific in-
dicator separately. Obviously, if transitivity and reflexitivity
are fulfilled, then I is even a total preorder because either
(I (A, B) ≤ I (B, A)) or (I (B, A) ≤ I (A, B)) (or both).
However, some binary indicators violate transitivity, although
I (weakly) refines  according to Definition 2.5.
Consider, for instance, the coverage indicator [38] which
gives the portion of solutions in B to which a weakly prefer-
able solution in A exists. This indicator represents a refinement
of par, but does not induce a preorder as transitivity cannot
be ensured [24].
Another example is the binary epsilon indicator [40]. Its
corresponding set preference relation I according to (2) is
a refinement of par. It is defined as follows:
I(A, B) = max
b∈B mina∈A F(a, b)
where we use the distance function
F(a, b) = max
1≤i≤n
( fi (a)− fi (b))
between two solutions a and b. Informally speaking, I(A, B)
denotes the minimum amount one needs to improve every
objective value fi (a) of every solution a ∈ A such that
the resulting set is weakly preferable to B . We will not
discuss further properties here and instead refer to [20], [24],
[40] for detailed reviews of binary indicators. The following
counterexample shows that the binary epsilon indicator does
not lead to a preorder. We consider four solutions a, b, c, d
with the objective values f (a) = (0, 8), f (b) = (1.5, 5),
f (c) = (2.5, 3), and f (d) = (4, 0) in R2. Using the solution
sets A = {a, d}, B = {b, d}, and C = {c, d}, we find
(I(C, B) = 1 ≤ I(B, C) = 2) ⇒ (C I B) and
(I(B, A) = 1.5 ≤ I(A, B) = 3) ⇒ (B I A) as well as
(I(A, C) = 1.5 ≤ I(C, A) = 2.5) ⇒ (A I C). However,
since I(C, A) = 2.5 ≤ I(A, C) = 1.5, it holds C I A
which contradicts transitivity.
In contrast to the negative results concerning the binary
coverage and epsilon indicators, one can derive valid binary
indicators from unary indicators. For example, for every unary
indicator I1 a corresponding binary indicator I2 can be defined
as I2(A, B) := I1(B) − I1(A); it is easy to show that
the property of (weak) refinement transfers from the unary
indicator to the binary version. In a similar way, one could
also use I2(A, B) := I1(B)− I1(A ∪ B) as in the case of the
binary hypervolume indicator, see, e.g., [34].
On the other hand, every binary indicator I2 can be trans-
formed into a unary indicator I1 by using a reference set
R: I1(A) := I2(A, R).4 Here, the refinement property is not
necessarily preserved, e.g., the unary versions of the binary
epsilon indicators induce only weak refinements, while the
original binary indicators induce refinements of the weak
Pareto dominance relation.
C. Refinement Through Set Partitioning
The Pareto dominance relation par on sets is by definition
insensitive to dominated solutions in a set, i.e., whether A ∈ 
weakly dominates B ∈  only depends on the corresponding
minimal sets: A par B ⇔ Min(A,par) par Min(B,par).
The same holds for set preference relations induced by the
hypervolume indicator and other popular quality indicators.
Nevertheless, preferred solutions may be of importance.
1) When a Pareto set approximation is evaluated according
to additional knowledge and preferences—which may be
hard to formalize and therefore may not be included in
the search process—then preferred solutions can become
interesting alternatives for a decision maker.
2) When a set preference relation is used within a (evo-
lutionary) multiobjective optimizer to guide the search,
it is crucial that preferred solutions are taken into
account—for reasons of search efficiency.
Accordingly, the question is how to refine a given set prefer-
ence relation that only depends on its minimal elements such
that also non-minimal solutions are considered.
This issue is strongly related to fitness assignment in
MOEAs. Pareto-dominance-based MOEAs divide the popu-
lation into dominance classes which are usually hierarchically
4Usually, instead of a reference set of solutions a reference set of objective
vectors is given. This requires a slight modication of the indicator.
66 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 14, NO. 1, FEBRUARY 2010
f2
f1
Z f2
f1
Z
Fig. 12. Illustration of two set partitioning functions, here based on weak Pareto dominance: (left)minpart and (right) rankpart. The light-shaded areas stand for
the first subsets (A1) and the darkest areas represent the lth subsets (A3 left and A4 right). As to the resulting partitions, on the left holds P1 ≺par P2 ≺par P3,
while on the right P1 ≺par Pi for 2 ≤ i ≤ 4, P3 ≺par P4, and P2 ||par P3 as well as P2 ||par P4.
organized. For instance, with dominance ranking [16], indi-
viduals that are dominated by the same number of population
members are grouped into one dominance class; with nondom-
inated sorting [18], [30], the minimal elements are grouped
into the first dominance class, and the other classes are
determined by recursively applying this classification scheme
to the remaining population members. The underlying idea can
be generalized to arbitrary set preference relations. To this end,
we introduce the notion of a set partitioning function.
Definition 3.4: A set partitioning function part is a func-
tion part:  × N →  such for all A ∈  a sequence
(A1, A2, . . . , Al , . . .) of subsets is determined with Ai :=
part(A, i) and it holds:
1) ∀1 ≤ i ≤ l : Ai ⊆ A;
2) ∀i > l : Ai = ∅;
3) ∀1 ≤ i < j ≤ l + 1 : Ai ⊃ A j .
A set partitioning function indirectly creates l non-empty
partitions: the i th partition Pi is defined by the set difference
between the i th and the (i + 1)th subset: Pi = part(A, i) \
part(A, i + 1). By construction, the induced partitions are dis-
joint. For instance, the following two set partitioning functions
resemble the concepts of dominance rank and nondominated
sorting:
rankpart(A, i) := {a ∈ A : |{b ∈ A : b ≺ a}| ≥ i − 1}
minpart(A, i) :=
⎧⎪⎨
⎪⎩
A if i = 1
minpart(A, i − 1) \
Min(minpart(A, i − 1),) else
where  is the solution-based preference relation under
consideration. The second function, i.e., minpart, yields a
partitioning such that P1 ≺ P2 ≺ · · · ≺ Pl holds; this is
demonstrated in Fig. 12.
Now, given a set partitioning function, part one can con-
struct set preference relations that only refer to specific parti-
tions of two sets A, B ∈  . By concatenating these relations,
one then obtains a sequence of relations that induces a set
preference relation according to Definition 2.6.
Definition 3.5: Let  be a set preference relation and
part a set partitioning function. For a fixed l, the partition-
based extension of  is defined as the relation part[l] :=S
where S is the sequence (1part,2part, . . . ,lpart) of preference
relations with
A ipart B :⇔ (part(A, i) \ part(A, i + 1))
 (part(B, i) \ part(B, i + 1)).
A partition-based extension of a set preference relation  ba-
sically means that  is successively applied to the hierarchy of
partitions defined by the corresponding set partition function.
Given A, B ∈  , first the two first partitions of A and B are
compared based on ; if the comparison yields equivalence,
then the two second partitions are compared and so forth. This
principle reflects the general fitness assignment strategy used
in most MOEAs.
One important requirement for such a partition-based exten-
sion is that part[l] refines . Provided that  depends only on
the minimal elements in the sets, both rankpart and minpart
induce refinements. The argument is simply that 1part is the
same as  because the first partition corresponds for both
functions to the set of minimal elements; that means 1part
is a refinement of . Furthermore, all ipart are preorders.
Applying Theorem 2.7 leads to the above statement. For
minpart, it can even be shown that minpart[l+1] is a refinement
of minpart[l] for all l > 0.
In the following, we will mainly consider the set partitioning
function minpart and refer to it as minimum elements partition-
ing (or nondominated sorting in the case of Pareto dominance).
It induces a natural partitioning into sets of minimal elements
where the partitions are linearly ordered according to strict
preferability. For reasons of simplicity, we may omit the l
when refering to the partition-extended relation minpart[l]; it
is usually set equal to the population size of the evolutionary
algorithm used.
ZITZLER et al.: ON SET-BASED MULTIOBJECTIVE OPTIMIZATION 67
D. Combined Preference Relations
The issue of preferred (dominated) solutions in a set A ∈ 
can not only be addressed by means of set partitioning
functions, but also by using multiple indicators in sequence.
For instance, one could use the hypervolumen indicator IH
(to assess the minimal elements in A) in combination with
a diversity indicator ID (to assess the non-minimal elements
in A); according to Theorem 2.7, the set preference relation
H,D given by the sequence (H ,D) is a proper refinement
of weak Pareto dominance since H is a refinement (see
above) and D is a preorder. Thus, such combinations can be
useful to increase the sensitivity of a relation (meaning that the
number of unidirectional edges A ≺ B is increased); however,
there are several further reasons for combining indicators:
1) to embed indicators which induce only a weak refine-
ment or no refinement at all into set preference relations
representing refinements;
2) to reduce computation effort: for instance, the hypervol-
ume indicator is expensive to compute; by using it only
occasionally at the end of a sequence of indicators, a
considerable amount of computation time may be saved;
3) to include heuristic information to guide the search: a set
preference relation that reflects the user preferences not
necessarily provides information for an effective search;
therefore, it may be augmented by optimization-related
aspects like diversity through additional dedicated indi-
cators.
In the following, we present some examples for combined
set preference relations that illustrate different application sce-
narios. All these relations are refinements of the set preference
relation par.
1) The first combination is based on the unary epsilon
indicator I1 with a reference set R in objective space
which is defined as I1(A) = E(A, R) with
E(A, R) = max
r∈R mina∈A (a, r)
where
(a, r) = max{ fi (a)− ri | 1 ≤ i ≤ n}
and ri is the i th component of the objective vector r .
Since this indicator induces only a weak refinement of
the weak Pareto dominance relation par, we will use
the hypervolume indicator to distinguish between sets
indifferent with respect I1. The resulting set preference
relation is denoted as 1,H ; it is a refinement of par.
2) The second combination uses the R2 indicator proposed
in [20] for which the following definition is used here:
IR2(A) = R2(A, R) =
∑
λ∈ u∗(λ, R) − u∗(λ, f (A))
||
where the function u∗ is a utility function based on the
weighted Tchebycheff function
u∗(λ, T ) = −min
z∈T max1≤ j≤n
λ j |z∗j − z j |
and  is a set of weight vectors λ ∈ Rn , R ⊂ Z
is a reference set, and z∗ ∈ Z is a reference point.
In this paper, we will set R = {z∗}. Also the R2
indicator provides only a weak refinement; as before,
the hypervolume indicator is added in order to achieve
a refinement. This set preference relation will be denoted
as R2,H .
3) The next set preference relation can be regarded as
a variation of the above relation R2,H . It allows a
detailed modeling of preferences by means of a set of
reference points r (i) ∈ R with individual scaling factors
ρ(i) and individual sets of weight vectors (i). As a
starting point, we define the generalized epsilon-distance
between a solution a ∈ X and a reference point r ∈ Z
as
Fλ (a, r) = max
1≤i≤n λi · ( fi (a)− ri )
with the weight vector λ ∈ Rn where λi > 0 for 1 ≤
i ≤ n. In contrast to the usual epsilon-distance given, the
coordinates of the objective space are weighted which
allows choosing a preference direction.
The P indicator for a single reference point r can now
be described as
IP (A, r,) =
∑
λ∈
min
a∈A F
λ
 (a, r)
where  is a potentially large set of different weight vec-
tors. The minimum operator selects for each weight vec-
tor λ the solution a with minimal generalized epsilon-
distance. Finally, all these distances are summed up. In
order to achieve a broad distribution of solutions and
a sensitive indicator, the cardinality of || should be
large, i.e., larger than the expected number of minimum
elements in A. For example,  may contain a large
set of random vectors on a unit sphere, i.e., vectors
with length 1. One may also scale the weight vectors
to different lengths in order to express the preference
for an unequal density of solutions.
If we have a set of reference points r (i) ∈ R with
individual sets of weight vectors (i) and scaling factors
ρ(i) > 0, we can simply add the individual P indicator
values as follows:
IP (A) =
∑
r(i)∈R
ρ(i) · IP(A, r (i),(i)).
Of course, we may choose equal sets (i) for each
reference point. In this case, the scaling factors ρ(i) can
be used to give preference to specific reference points.
The P indicator as defined above provides only a
weak refinement; as before, the hypervolume indicator
is added in order to achieve a refinement. This set
preference relation will be denoted as P,H .
4) The previous three indicator combinations will be used
together with a set partitioning function. To demonstrate
that the partitioning can also be accomplished by indi-
cators, we propose the following sequence of indicators
S = (IH , IC , ID) where IC measures the largest distance
of a solution to the closest minimal element in a set
and ID reflects the diversity of the solutions in the
68 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 14, NO. 1, FEBRUARY 2010
objective space. The latter two indicators, which both
do not induce weak refinements of par, are defined as
follows:
IC (A) = max
a∈A minb∈Min(A,) dist( f (a), f (b))
and
ID(A) = max
a∈A
(
1
nn1(a, A \ {a}) +
1
nn2(a, A \ {a})
)
with
nn1(a, B) = min
b∈B dist( f (a), f (b))
nn2(a, B) = max
c∈B minb∈B\{c} dist( f (a), f (b))
where nn1(a, B) gives the smallest and nn2(a, B) the
second smallest distance of a to any solution in B . For
the distance function dist(z1, z2), Euclidean distance is
used here, i.e., dist(z1, z2) =
√∑
1≤i≤n(z1i − z2i )2. The
IC indicator resembles the generational distance measure
proposed in [32] and ID resembles the nearest neighbor
niching mechanism in SPEA2 [37]. We will refer to the
overall set preference relation as H,C,D. According to
Theorem 2.7, H,C,D is a refinement of par.
It is worth mentioning that it is also possible to combine a
non-total preorder such as par with total orders differently to
the principle suggested in Definition 2.6. As has been pointed
out, see e.g., Fig. 7, convergence may not be achievable if
an optimization is not based on a preorder or if the under-
lying preorder is not a refinement. The following example
illustrates why density-based MOEAs such as NSGA-II and
SPEA2 show cyclic behavior, see [27], in particular when the
population mainly contains incomparable solutions, e.g., when
being close to the tradeoff surface.
For instance, let I be a unary indicator, then one may define
a set preference relation par,I as follows with A, B ∈ :
A par,I B :⇔ (A par B) ∨ ((A ||par B) ∧ (A I B)).
Now, consider a unary diversity indicator, e.g., ID as defined
above; this type of indicator usually does not induce a weak
refinement. The resulting set preference relation par,I is
not a proper preorder as Fig. 13 demonstrates: transitivity is
violated, i.e., A par,I B and B par,I C , but A par,I C .
The relation graph of par,I contains cycles. However, if I
stands for the hypervolume indicator IH , then par,I is a set
preference relation refining par; this combination could be
useful to reduce computation effort.
IV. MULTIOBJECTIVE OPTIMIZATION USING SET
PREFERENCE RELATIONS
The previous two sections discussed how to design set
preference relations so that the concept of Pareto dominance
is preserved while different types of user preferences are
included. This section presents a corresponding generalized
multiobjective optimizer that makes use of such set prefer-
ence relations in order to search for promising solution sets.
Section IV-A describes the algorithm, while Section IV-B
discusses theoretical aspects of the algorithm, in particular
convergence properties.
f2
f1
Z
A
B
C
Fig. 13. Three sets are shown in the objective space where A par
B , A ||par C and B ||par C . Using a combination of Pareto dominance and
diversity results in a cyclic relation par,I with A ≺par,I B , B ≺par,I C , and
C ≺par,I A.
A. SPAM—Set Preference Algorithm for Multiobjective Opti-
mization
The main part of the SPAM is given by Algorithm 1. It
resembles a standard hill climber with the difference that two
new elements of the search space  are created using two
types of mutation operators. The termination criterion can be
any standard stopping condition like maximum number of
iterations or no improvement over a given number of iterations;
we will not discuss this critical issue here in detail and instead
refer to the corresponding literature, see e.g. [7]. However,
for the convergence proof provided later, we will assume that
the algorithm loops forever, i.e., the termination criterion is
False.
Algorithm 1 first creates a random initial set P ∈ m
of size m and then employs a random mutation operator to
generate another set P ′. This operator should be designed
such that every element in  could be possibly generated,
i.e., the neighborhood is in principle the entire search space.
In practice, the operator will usually have little effect on the
optimization process; however, its property of exhaustiveness
is important from a theoretical perspective, in particular to
show convergence, cf. Section IV-B.
Second, a heuristic mutation operator is employed. This
operator mimics the mating selection, variation, and environ-
mental selection steps as used in most MOEAs. The goal
of this operator is to create a third set P ′′ ∈  that is
better than P in the context of a predefined set preference
relation . However, since it is heuristic it cannot guarantee
to improve P; there may be situations where it is not able
to escape local optima of the landscape of the underlying set
problem. Finally, P is replaced by P ′′, if the latter is weakly
preferable to the former; otherwise, P is either replaced by P ′
(if P ′  P) or remains unchanged. Note that in the last step,
weak preferability () and not preferability (≺) needs to be
considered in order to allow the algorithm to cross landscape
plateaus, cf. [5].
ZITZLER et al.: ON SET-BASED MULTIOBJECTIVE OPTIMIZATION 69
Algorithm 1 SPAM Main Loop
Require: set preference relation 
1: generate initial set P of size m, i.e., randomly choose A ∈
m and set P ← A
2: while termination criterion not fulfilled do
3: P ′ ← randomSetMutation(P)
4: P ′′ ← heuristicSetMutation(P)
5: if P ′′  P then
6: P ← P ′′
7: else if P ′  P then
8: P ← P ′
9: return P
Algorithm 2 Random Set Mutation
1: procedure randomSetMutation(P)
2: randomly choose r1, . . . , rk ∈ X with ri = r j
3: randomly select p1, . . . , pk from P with pi = p j
4: P ′ ← P \ {p1, . . . , pk} ∪ {r1, . . . , rk}
5: return P ′
For the mutation operators, we propose Algorithms 2 and 3.
Algorithm 2 (random set mutation) randomly chooses k de-
cision vectors from X and uses them to replace k elements
in P .5 Algorithm 3 (heuristic set mutation) generalizes the
iterative truncation procedures used in NSGA-II [8], SPEA2
[37], and others. First, k new solutions are created based on
P; this corresponds to mating selection plus variation in a
standard MOEA. While the variation is problem-specific, for
mating selection either uniform random selection (used in the
following) or fitness-based selection can be used (using the
fitness values computed by Algorithm 4 resp. 5). Then, these
k solutions are added to P , and finally the resulting set of
size m + k is iteratively truncated to size m by removing the
solution with the worst fitness values in each step. Here, the
fitness value of a ∈ P reflects the loss in quality for the entire
set P if a is deleted: the lower the fitness, the larger the loss.
To estimate how useful a particular solution a ∈ P is,
Algorithm 4 compares all sets Ai ⊂ P with |Ai | = |P| − 1
to P \ {a} using the predefined set preference relation . The
fewer sets Ai are weakly preferable to P \ {a}, the better
the set P \ {a} and the less important is a. This procedure
has a runtime complexity of O((m + k)g), where g stands
for the runtime needed to compute the preference relation
comparisons which usually depends on m+ k and the number
of objective functions. If unary indicators are used, then fitness
assignment can be done faster. Algorithm 5 gives an example
where  is defined by a single unary indicator I ; the loss in
quality is simply the difference in the indicator value caused
by the removal of a. The last scheme is used, e.g., in [14], [22],
[25], [35] in combination with the hypervolume indicator;
Fig. 14 illustrates the working principles.
Finally, note that Algorithm 3 is heuristic in nature, in
particular the truncation method realized by the while loop at
Step 4. Before entering the loop at Step 4, P ′′ contains exactly
5Note that for both mutation operators the same k is used here, although
they can be chosen independently. The safe version (k = m) for the random
mutation operator means that a random walk is carried out on  .
Algorithm 3 Heuristic Set Mutation
1: procedure heuristicSetMutation(P)
2: generate r1, . . . , rk ∈ X based on P
3: P ′′ ← P ∪ {r1, . . . , rk}
4: while |P ′′| > m do
5: for all a ∈ P ′′ do
6: δa ← fitnessAssignment(a, P′′)
7: choose p ∈ P ′′ with δp = mina∈P ′′ δa
8: P ′′ ← P ′′ \ {p}
9: return P ′′
Algorithm 4 Fitness Assignment (General Version)
1: procedure fitnessAssignment(a, P ′′)
2: δa ← 0
3: for all b ∈ P ′′ do
4: if P ′′ \ {b}  P ′′ \ {a} then
5: δa ← δa + 1
6: return δa
m + k solutions. Ideally, that subset A ⊆ P ′′ with |A| = m
would be chosen that is weakly preferred by the lowest number
of m-element subsets Ai ⊆ P ′′. However, computing the
optimal subset A is usually computationally expensive and
therefore the iterative truncation procedure represents a greedy
strategy to obtain a good approximation of A in reasonable
time.
B. Convergence Results
The main advantage of SPAM, as presented above, with
respect to existing multiobjective randomized search algo-
rithms is its flexibility. In principle, it can be used with any
set relation; however, it will be effective only when the set
preference relation  is reasonably designed as discussed in
Sections II and III.
First, it is important that  represents a preorder and a
refinement according to Definition 2.4. These properties ensure
that 1) no cyclic behavior as reported for NSGA-II and SPEA2
in [27] can occur and that 2) under mild assumptions SPAM
actually converges to an optimal subset of the Pareto-optimal
set (see below). To our best knowledge, the latter property has
only been shown for theory-oriented algorithms, e.g., [19],
[29], but not for popular multiobjective evolutionary algo-
rithms used in practice. The construction principle presented
in Definition 2.6 provides a tool to design preorders and
refinements as shown by Theorem 2.7. Furthermore,  should
be a total preorder and it should be highly sensitive to changes
in the sets in order to enable SPAM to search efficiently. A
total set preference relation guarantees that SPAM has full
information whether to accept or to reject a newly generated
set. Section III explains in detail how total preorders can
be constructed using quality indicators and how it can be
ensured that the resulting preorders are still refinements, cf.
Theorem 3.2. The issue of sensitivity led to the idea of set
partitionings as presented in Section III-C—only this extension
makes the use of single quality indicators for search effective.
This discussion illustrates why the proper design of  is
70 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 14, NO. 1, FEBRUARY 2010
Algorithm 5 Fitness Assignment (Unary Indicator Version)
1: procedure fitnessAssigment(a, P ′′)
2: δa ← I (P ′′ \ {a})− I (P ′′)
3: return δa
crucial for SPAM and any other set-oriented multiobjective
optimizer and why the corresponding theoretical foundations
presented in Sections II and III are of high importance in
practice.
Next, we will focus on the theoretical convergence proper-
ties of SPAM, i.e., whether and under what conditions it con-
verges to the optimum given infinite running time resources.
Although convergence alone does not necessarily imply that
the algorithm is fast and efficient in practice, it is an important
and desirable property; in the EMO field, several convergence
results are available to date, most notably [19], [27], [29], [33].
Here, we are interested in the properties of the set mutation
operators that guarantee convergence of SPAM; in particular,
we will investigate the influence of the parameter k that
determines the number of newly created solutions per set
mutation. Convergence in this paper refers to the limit behavior
of an optimization algorithm. The line of arguments follows
most closely the investigations of Rudolph et al. in [29].
In order to simplify the discussion, let us suppose that the
set of solutions X is finite and that only random set mutation
is used, i.e., heuristicSetMutation(P) always returns P for the
time being. In addition, we have available a preference relation
 on the set m of sets containing not more than m solutions,
see Section II.
Then, SPAM is called convergent the probability that the
resulting set P is not minimal, i.e., P ∈ Min(m ,),
approaches 0 for N → ∞ where N denotes the number of
iterations of the while loop in Algorithm 1. If we can now
guarantee the convergence of SPAM, then this simple hill-
climbing strategy would be able to solve any multiobjective
optimization problem as stated in Section II-B in case of finite
but unbounded computation time.
Given m , let us consider the underlying set preference
relation  and, in particular, the corresponding relation graph
where there is an edge (A, B) for each pair A, B ∈ m with
A  B . As  is a preorder, there is a directed path from any
minimal element P∗ ∈ Min(m ,) to any node P . In order to
be able to reach such an optimal set using SPAM, the chosen
preference relation as well as the set mutation operator need to
satisfy certain constraints. They both must enable such paths
under the condition that each set mutation replaces at most k
elements from the current set P in order to generate P ′. Note
that the optimizer traverses a path in reverse direction as there
is an edge from A to B if A  B .
Let (P1, P2, . . . , Pi ) denote the sequence of sets generated
by SPAM where Pi denotes the contents of P at the beginning
of the i th iteration of the while loop in Algorithm 1. In
addition, r ij and p
i
j , 1 ≤ j ≤ k denote the elements randomly
created resp. selected for removal in Algorithm 2. In particular,
Pi is mutated by removing pi1, . . . , p
i
k and adding r
i
1, . . . , r
i
k .
Definition 4.1: Let us now suppose that for any initial set
P1 there exists a number N of iterations and pij and r
i
j , 1 ≤
f2
f1
Z
d
e
f
r
δd
δe
δf
Fig. 14. Figure depicting the fitness values computed according to Algo-
rithms 4 and 5 when using the hypervolume indicator. The light shaded area
stands for the volume of the entire three-elements set, the dark shaded areas
reflects the volume contributions (fitness values) of the distinct solutions.
j ≤ k, 1 ≤ i ≤ N such that 1) P N ∈ Min(m,) and 2)
Pi+1  Pi for all 1 ≤ i ≤ N − 1. Then we say that the given
set preference relation  is k-greedy.
The above property states that if the given set preference
relation  is k-greedy, then there exists a sequence of sets with
cardinality not larger than m that starts from any set in m and
ends at an optimal set in  where at most k elements differ
from one set to the next. Therefore, this path could be found
by SPAM, if the randomSetMutation operator does exactly
the requested replacements of elements. In order to make this
argument more formal, we need to define properties of the set
mutation operator. For example, if elements of some optimal
set P∗ cannot be generated, this set will never be reached.
Definition 4.2: Given any k different solutions s j ∈ X
and any k different solutions p̂ j in P where 1 ≤ j ≤ k.
If for an execution of the randomSetMutation operator the
probability is larger than zero that 1) the selected elements
satisfy p j = p̂ j and 2) the randomly generated elements
satisfy r j = s j for all 1 ≤ j ≤ k, then the randomSetMutation
operator is called exhaustive.
In other words, an exhaustive randomSetMutation operator
replaces any k elements of the current set P by any k elements
from X with a finite probability. Therefore, if the set mutation
operator is concatenated sufficiently often for an arbitrary
initial set (e.g., randomSetMutation(randomSetMutation(P))),
then any possible set in m can be generated. Based on the
above results and using a straightforward extension of the work
previously done in [29], we obtain the following theorem:
Theorem 4.3: If the given set preference relation  is
k-greedy and the given randomSetMutation operator is ex-
haustive, then the SPAM optimization algorithm converges
provided that the while-loop never terminates.
Proof: Consider a graph whose nodes correspond to all
sets Q ⊆ X with size |Q| = m and the edges of which cor-
respond to all possible executions of the randomSetMutation
operator. If we remove all edges (i, j) with Q j  Qi , then
each path in the graph corresponds to a feasible execution of
SPAM. If the set preference relation  is k-greedy and the
ZITZLER et al.: ON SET-BASED MULTIOBJECTIVE OPTIMIZATION 71
TABLE II
OVERVIEW OF THE SET PREFERENCE RELATIONS USED IN THE EXPERIMENTAL STUDIES; FOR DETAILS, SEE SECTION III
minpartH hypervolume indicator IH with reference point (12, 12) resp. (12, 12, 12, 12, 12) and minimum elements partitioning
minpartP1,H preference-based quality indicator IP with two reference points r
(1) = (0.2, 0.9) resp. (0.2, 0.9, 0.9, 0.9, 0.9),
r (2) = (0.8, 0.5) resp. (0.8, 0.5, 0.5, 0.5, 0.5) with scaling factors ρ(1) = 1/3 and ρ(2) = 2/3, followed by the
hypervolume indicator IH with reference point (12, 12) resp. (12, 12, 12, 12, 12); in addition, minimum elements
partitioning is used. For IP , the same 1, 000 weights λ are used for all reference points; the weights are (once)
uniformly randomly drawn from {(λ1, . . . , λn) ∈ Rn | λi > 0 for 1 ≤ i ≤ n, ||(λ1, . . . , λn)|| = 1}
H,C,D unary hypervolume indicator IH with reference point (12, 12) resp. (12, 12, 12, 12, 12) followed by the
distance-to-front indicator IC (maximum distance of any solution to the closest front member) and the diversity
indicator ID (kth-nearest neighbor approach)
minpartR2,H R2 indicator IR2 with reference set B = {(0, 0)} and  = {(0, 1),(0.01, 0.99), . . . , (0.3, 0.7), (0.7, 0.3),
(0.71, 0.29), . . . , (1, 0)} in the case of two objectivesa (|| = 62), followed by hypervolume indicator IH with
reference point (12, 12) resp. (12, 12, 12, 12, 12); in addition, minimum elements partitioning is used
minpart1,H unary (additive) epsilon indicator I1 with reference set B = {(k · 0.002, 0.8− k · 0.004) ; k ∈ {0, 1, . . . , 100}} resp.
B = {(k · 0.002, 0.8− k · 0.004, 0.8− k · 0.004, 0.8− k · 0.004, 0.8− k · 0.004) ; k ∈ {0, 1, . . . , 100}}, followed by the
hypervolume indicator IH with reference point (12, 12) resp. (12, 12, 12, 12, 12); in addition, minimum elements
partitioning is used
minpartP0,H preference-based quality indicator IP with reference point r
(1) = (0, 0) resp. (0, 0, 0, 0, 0), followed by the
hypervolume indicator IH with reference point (12, 12) resp. (12, 12, 12, 12, 12); in addition, minimum elements
partitioning is used. The same weights λ as in minpartP1,H are used by IP .
minpartD diversity indicator ID (kth-nearest neighbor approach) combined with minimum elements partitioning
aThe weight combinations used for the five-objective problem instances are provided in the Appendix; in this case, the considered reference set was
B = {(0, 0, 0, 0, 0)}.
randomSetMutation operator is exhaustive, then there exists
a path with finite probability from any node to a node with
Q ∈ Min(m,).
Because of the finiteness of X , SPAM will not converge
iff for some execution we have Pi ≡ Pi+1 and P∗ ≺ Pi+1
for all i ≥ K with some constant K and for some minimal
element P∗ ∈ Min(m ,). During such an execution, a
subset of nodes is visited infinitely often. Let us now suppose
that SPAM does not converge. Then none of the infinitely
visited nodes has an outgoing edge (i, j) with Q j ≺ Qi .
This contradicts the assumption that there exists a path with
finite probability from any node to an optimal node Q with
Q ∈ Min(m,).
Theorem 4.4: Every set preference relation  is m-greedy
where m denotes the maximum size of the sets of solutions,
i.e., m is the universe of the sets under consideration.
Proof: The set preference relation  is a preorder.
Therefore, there exists a path from any initial set P1 to
an optimal set P N in Definition 4.1. The intermediate
populations P2, . . . , P N can be generated by exchanging at
most all m solutions from one set to the next. As the set
preference relation is m-greedy, the elements pij and r
i
j can
be chosen correspondingly.
The last theorem leads to the fact that SPAM can be used
with any set preference relation resp. quality indicator inducing
a preorder if we use k = m. Whereas this statement may be
of theoretical value, SPAM will be of no practical use for
large m if only the randomSetMutation operator is applied;
the reason is that the probability to determine a better set by
exchanging randomly a large number of elements will be very
small. Therefore, the heursticSetMutation operator is used in
order to obtain improved sets with a high probability; however,
this operator in general is not exhaustive, i.e., it may not
possible to follow a path to an optimal set P∗ ∈ Min(m,).
Therefore, if the used randomSetMutation operator is exhaus-
tive, i.e., it generates any possible k-neighbor with a finite
probability, then SPAM converges to an optimal solution.
Finally, one may ask whether smaller values for k with k <
m are possible while still guaranteeing convergence. This may
be desirable from a practical perspective since the generation
of new solutions in X would thereby be tighter linked to the
update of P; several indicator-based MOEAs basically use set
mutation operators where k equals 1 [14], [22]. The answer
clearly depends on the set preference relation under consider-
ation. It can be shown that the set preference relations induced
by the epsilon indicator and the hypervolume indicator are in
general not 1-greedy; the proofs can be found in the appendix.
Corollary 4.5: The set preference relation 1 induced by
the unary epsilon indicator I1 is not 1-greedy.
Corollary 4.6: The set preference relation H induced by
the hypervolume indicator IH is not 1-greedy.
That means whenever these indicators are used within a set
preference relation incorporated in SPAM, then there are cases
where SPAM will not convergence if k = 1; this also holds
for any other MOEA that replaces only a single solution in the
current population and is based on these indicators. Whether
other values for k with 1 < k < m are sufficient to guarantee
convergence for these indicators is an open research issue.
72 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 14, NO. 1, FEBRUARY 2010
V. EXPERIMENTAL VALIDATION
This section investigates the practicability of the proposed
approach. The main questions are: 1) can different user pref-
erences be expressed in terms of set preference relations; 2)
is it feasible to use a general search algorithm for arbitrary
set preference relations, i.e., is SPAM effective in finding
appropriate sets; and 3) how well are set preference relations
suited to guide the optimization process? However, the purpose
is not to carry out a performance comparison of SPAM to
existing MOEAs; the separation of user preferences and search
algorithm is the focus of our study.
A. Comparison Methodology
In the following, we consider different set preference re-
lations for integration in SPAM; they have been discussed in
Section III and are listed in Table II. All of them except of the
last one are refinements of the set dominance relation par;
the relation minpartD is just used for the purpose of mimicking
the behavior of dominance and density-based MOEAs such
as NSGA-II and SPEA2. As reference algorithms, NSGA-II
[8] and IBEA6 [36] are used; in the visual comparisons also
SPEA2 [37] is included.
In order to make statements about the effectiveness of
the algorithms considered, one needs to assess the generated
Pareto-set approximations with regard to the set preference
relation under consideration. We suggest the use of the Mann–
Whitney U test to compare multiple outcomes of one algo-
rithm with multiple outcomes of another algorithm. This is
possible since all set preference relations considered in this
paper are total preorders; otherwise, the approach proposed in
[26] can be applied. Thereby, one can obtain statements about
whether either algorithm yields significantly better results for
a specified set preference relation.
In detail, the statistical testing is carried as follows. As-
suming two optimizers OA and OB, first all Pareto-set ap-
proximations generated by OA are pairwisely compared to
all Pareto-set approximations generated by OB. If, e.g., 30
runs have been performed for each algorithm, then overall
900 comparisons are made. Now, let A and B be two Pareto-
set approximations resulting from OA respectively OB; then,
we consider set A as better than set B with respect to the
set preference relation , if A ≺ B holds. By counting the
number of comparisons where the set of OA is better than
the corresponding set of OB, one obtains the test statistics U ;
doing the same for OB gives U ′ which reflects the number
of cases where OB yields a better outcome. The bigger U is
compared to U ′, the better algorithm OA is geared toward the
test relation  regarding OB.
As long as the entirety of the considered sets can be
regarded as a large sample (e.g., 30 runs per algorithm), one
can use the one-tailed normal approximation to calculate the
significance of the test statistics U , correcting the variance for
ties. Furthermore, multiple testing issues need to be taken into
account when comparing multiple algorithms with each other;
here, the significance levels are Bonferroni-corrected.
6With parameters κ = 0.05 and ρ = 1.1.
TABLE III
PARAMETER SETTINGS USED IN SECTION V-B
Parameter Value
Set size/population size m 20*, 50**
Newly created solutions/offspring individuals k 20*, 50**
Number of iterations/generations 1000
Mutation probability 1
Swap probability 0.5
Recombination probability 1
η-Mutation 20
η-Recombination 20
Symmetric recombination False
Scaling False
Tournament size 2
Mating selection Uniform
* Visual comparision, ** Statistical testing.
Finally, the SPAM implementation used for the following
experimental studies does not include the random set mutation
operator, i.e., lines 3, 7, and 8 in Algorithm 1 were omitted.
The reason is that every set comparison is computation-
ally expensive—especially when the hypervolume indicator is
involved—and that in practice it is extremely unlikely that
random set mutation according to Algorithm 2 yields a set
that is superior to the one generated by the heuristic set
mutation operator. Nevertheless, a set mutation operator that in
principle can generate any set in  is important to guarantee
theoretical convergence. One may think of more effective
operators than Algorithm 2 which preserves the convergence
property; however, this topic is subject to future work and not
investigated in this paper.
One may also ask whether the if statement at line 5
of Algorithm 1 is actually of practical relevance. Testing
SPAM with three set preference relations, namely minpartP0,H ,
minpartP1,H , and H,D , on a three-objective DTLZ5 problem
instance indicates that on average every 50th generation (using
minpartP0,H ) and 100th generation (using 
minpart
P1,H and H,D) the
set produced by heuristic mutation is worse than the current
set, i.e., the current set is not replaced. One can expect and
observe, though, that this situation arises especially when
being close to or on the Pareto front (all set members are
incomparable) and less frequently at the early phase of the
search process. Overall, no significant differences between
the quality of the outcomes could be measured when running
SPAM with and without the check at line 5; on average, the
computation time increased by 12% (minpartP0,H and 
minpart
P1,H )
and 8% (H,D). Nevertheless, we recommend to keep this
additional check because it represents a crucial aspect of a hill
climber and prevents cycling behavior which is theoretically
possible whenever worse sets are accepted.
B. Results
This section provides experimental results for two test
problems, namely DTLZ2 and DTLZ5 [12] with 20 decision
ZITZLER et al.: ON SET-BASED MULTIOBJECTIVE OPTIMIZATION 73
.0 .2 .4 .6 .8 1.0
.0
.2
.4
.6
.8
1.0
(a) SPAM with minpartH
1/3
2/3
.0 .2 .4 .6 .8 1.0
.0
.2
.4
.6
.8
1.0
(b) SPAM with minpartP1,H
.0 .2 .4 .6 .8 1.0
.0
.2
.4
.6
.8
1.0
(c) SPAM with minpartR2,H
.0 .2 .4 .6 .8 1.0
.0
.2
.4
.6
.8
1.0
(d) SPAM with minpart1,H
.0 .2 .4 .6 .8 1.0
.0
.2
.4
.6
.8
1.0
(e) SPAM with minpartP0,H
.0 .2 .4 .6 .8 1.0
.0
.2
.4
.6
.8
1.0
(f) SPAM with minpartD
.0 .2 .4 .6 .8 1.0
.0
.2
.4
.6
.8
1.0
(g) SPEA2
.0 .2 .4 .6 .8 1.0
.0
.2
.4
.6
.8
1.0
(h) IBEA
.0 .2 .4 .6 .8 1.0
.0
.2
.4
.6
.8
1.0
(i) NSGA-II
Fig. 15. Pareto-set approximations found after 1000 generations on a biobjective DTLZ2 problem for a set size/population size of m = 20. All algorithms
were started with the same initial set/population.
variables for two and five objectives. On one hand, we
will provide visual comparisons in order to verify to which
extent the formalized user preferences have been achieved.
On the other hand, statistical tests are applied to investigate
which search strategy is best suited to optimize which user
preferences; for each optimizer, 30 runs have been carried out.
The general parameters used in the optimization algorithms are
given in Table III.
1) Visual comparisons: Fig. 15 shows the Pareto-set ap-
proximations generated by SPAM with the aforementioned
set preference relations and by the reference algorithms for
the biobjective DTLZ2 problem. The plots well reflect the
chosen user preferences: (a) a set maximizing hypervolume,
(b) a divided set close to two reference points, (c) focus
on the extremes using corresponding weight combinations,
(d) closeness to a given reference set, (e) a set minimizing
the weighted epsilon-distance to the origin for a uniformly
distributed set of weight combinations, and (f) a uniformly
distributed set of solutions. This demonstrates that SPAM is
in principle capable of optimizing toward the user preferences
74 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 14, NO. 1, FEBRUARY 2010
TABLE IV
PAIRWISE STATISTICAL COMPARISON OF 30 RUNS PER ALGORITHM AFTER 1000 GENERATIONS. IN THE NOTATION U : U ′ , U (RESP. U ′) STANDS FOR
THE NUMBER OF TIMES A SET GENERATED BY ALGORITHM A (RESP. B ) BEATS A SET OF ALGORITHM B (RESP. A) WITH REGARD TO THE TEST
RELATION ASSOCIATED WITH THE CORRESPONDING ROW. A STAR NEXT TO THESE NUMBERS INDICATES A SIGNIFICANT DIFFERENCE, THE FEW
CASES WHERE THIS WAS NOT THE CASE ARE SHOWN IN BOLD
(a) 2-D DTLZ2
Alg. A
Alg B. SPAM with set preference relation … IBEA NSGA-II test
relationminpartP1,H 
minpart
H 
minpart
R2,H 
minpart
1,H 
minpart
P0 H,C,D 
minpart
D
SPAM
with set
preference
relation …
minpartP1,H — 900: 0* 900: 0* 900: 0* 899: 1* 900: 0* 900: 0* 900: 0* 900: 0* P1,H
minpartH 900: 0* — 900: 0* 900: 0* 900: 0* 456:444 900: 0* 900: 0* 900: 0* H
minpartR2,H 900: 0* 900: 0* — 900: 0* 900: 0* 900: 0* 900: 0* 900: 0* 900: 0* R2,H
minpart1,H 900: 0* 900: 0* 900: 0* — 900: 0* 889: 1* 900: 0* 900: 0* 900: 0* 1,H
minpartP0,H 900: 0* 60:840 830: 70* 846: 54* — 75:835 900: 0* 134:766 835: 75* P0,H
H,C,D 900: 0* 444:456 900: 0* 900: 0* 843: 57* — 900: 0* 820: 80* 900: 0* H,C,D
* Preference is significant at the 0.001 level (1-tailed, Bonferroni-adjusted).
(b) 2-D DTLZ5
Alg. A
Alg B. SPAM with set preference relation …
IBEA NSGA-II test
relationminpartP1,H 
minpart
H 
minpart
R2,H 
minpart
1,H 
minpart
P0 H,C,D 
minpart
D
SPAM
with set
preference
relation …
minpartP1,H — 900: 0* 900: 0* 900: 0* 900: 0* 900: 0* 900: 0* 887: 13* 900: 0* P1,H
minpartH 900: 0* — 900: 0* 900: 0* 900: 0* 445:455 900: 0* 900: 0* 900: 0* H
minpartR2,H 900: 0* 900: 0* — 900: 0* 900: 0* 900: 0* 900: 0* 900: 0* 900: 0* R2,H
minpart1,H 900: 0* 891: 9* 900: 0* — 900: 0* 897: 3* 900: 0* 900: 0* 900: 0* 1,H
minpartP0 898: 2* 22:878 891: 9* 899: 1* — 12:888 788:112* 95:805 885: 15* P0
H,C,D 900: 0* 455:445 900: 0* 900: 0* 795:105* — 900: 0* 900: 0* 900: 0* H,C,D
* Preference is significant at the 0.001 level (1-tailed, Bonferroni-adjusted).
(c) Five-dimensional DTLZ2
Alg. A
Alg B. SPAM with set preference relation … IBEA NSGA-II test
relationminpartP1,H 
minpart
H 
minpart
R2,H 
minpart
1,H 
minpart
P0 H,C,D 
minpart
D
SPAM
with set
preference
relation …
minpartP1,H — 820: 80* 820: 80* 805: 95* 838: 62* 820: 80* 900: 0* 820: 80* 900: 0* P1,H
minpartH 900: 0* — 900: 0* 900: 0* 900: 0* 404:496 900: 0* 895: 5* 900: 0* H
minpartR2,H 900: 0* 900: 0* — 900: 0* 900: 0* 900: 0* 900: 0* 900: 0* 900: 0* R2,H
minpart1,H 900: 0* 895: 5* 870: 30* — 894: 6* 895: 5* 900: 0* 895: 5* 900: 0* 1,H
minpartP0 880: 20* 810: 90* 871: 29* 899: 1* — 900: 0* 898: 2* 32:868 900: 0* P0
H,C,D 900: 0* 496:404 900: 0* 900: 0* 843: 57* — 900: 0* 900: 0* 900: 0* H,C,D
* Preference is significant at the 0.001 level (1-tailed, Bonferroni-adjusted).
(d) Five-dimensional DTLZ5
Alg. A
Alg B. SPAM with set preference relation … IBEA NSGA-II test
relationminpartP1,H 
minpart
H 
minpart
R2,H 
minpart
1,H 
minpart
P0 H,C,D 
minpart
D
SPAM
with set
preference
relation …
minpartP1,H — 877: 23* 900: 0* 900: 0* 900: 0* 723:177 900: 0* 874: 26* 900: 0* P1,H
minpartH 900: 0* — 900: 0* 900: 0* 900: 0* 455:445 900: 0* 900: 0* 900: 0* H
minpartR2,H 900: 0* 900: 0* — 900: 0* 900: 0* 900: 0* 900: 0* 900: 0* 900: 0* R2,H
minpart1,H 892: 8* 618:282 900: 0* — 900: 0* 626:274 900: 0* 893: 7* 900: 0* 1,H
minpartP0 900: 0* 841: 59* 819: 81* 873: 27* — 752:148* 867: 33* 121:779 547:453 P0
H,C,D 900: 0* 445:455 900: 0* 900: 0* 900: 0* — 900: 0* 900: 0* 900: 0* H,C,D
* Preference is significant at the 0.001 level (1-tailed, Bonferroni-adjusted).
that are encoded in the corresponding set preference relation.
It can also be seen that the density-based approaches by
NSGA-II and SPEA2 can be imitated by using a corresponding
diversity indicator—although this is not the goal of this paper.
2) Usefulness for Search: After having seen the proof-
of-principle results for single runs, we now investigate the
question of how effective SPAM is in optimizing a given
set preference relation , i.e., how specific the optimization
process is. The hypothesis is that SPAM used in combination
with a specific A (let us say SPAM-A) yields better Pareto-
set approximations than if used with any other set preference
relation B (let us say SPAM-B)—better here means with
respect to A. Ideally, for every set A generated by SPAM-
A and every set B generated by SPAM-B, it would hold
A A B or even A ≺A B . Clearly, this describes an ideal
situtation. A set preference relation that is well suited for
representing certain preferences may not be well suited for
search per se, cf. Section III-D; for instance, when using a
ZITZLER et al.: ON SET-BASED MULTIOBJECTIVE OPTIMIZATION 75
0 200 400 600 800 1000
0
100
200
300
400
500
600
700
800
900
Iteration
M
an
n−
W
hi
tn
ey
 U
minpart
H
minpart
P1, H
(a) SPAM using minpartP1,H and 
minpart
H
0 200 400 600 800 1000
0
100
200
300
400
500
600
700
800
900
Iteration
M
an
n−
W
hi
tn
ey
 U minpart
H
minpart
P0, H
(b) SPAM using minpartP0,H and 
minpart
H
Fig. 16. Each figure compares two SPAM variants for the biobjective DTLZ2 problem: SPAM with minpartH versus SPAM with 
minpart
P1,H (left) and SPAM
with minpartH versus SPAM with 
minpart
P0,H . Per figure, both algorithms are compared with respect to both set preference relations (without set partitioning).
The solid line on the left gives for each iteration, the number of cases (30 runs versus 30 runs) where SPAM with minpartH is better than SPAM with 
minpart
P1,H
with respect to H . The dotted line on the left shows how often SPAM with minpartP1,H is better than SPAM with 
minpart
H regarding P1,H over time. The
right figure provides the same where P1,H is replaced by P0,H .
TABLE V
AVERAGED RUNNING TIME IN SECONDS PER ITERATION FOR SPAM
USING THE GENERAL FITNESS ASSIGNMENT PROCEDURE
(ALGORITHM 4) AS WELL AS THE PROCEDURE DEDICATED TO UNARY
INDICATORS (ALGORITHM 5). THE COMPARISON ARE PROVIDED FOR
THE TWO SET PREFERENCE RELATIONS minpart1 AND 
minpart
H
Algorithm 2d 5d
SPAM using Algorithm 4 and minpart1 0.0601 s 24.8660 s
SPAM using Algorithm 5 and minpart1 0.0055 s 0.2128 s
SPAM using Algorithm 4 and minpartH 0.0170 s 253.8699 s
SPAM using Algorithm 5 and minpartH 0.0097 s 1.9722 s
single indicator such as the hypervolume indicator refinement
through set partitioning is important for effective search.
To this end, we statistically compare all algorithmic variants
with each other with respect to the six refinements listed in
Table II. Note that set partitioning is only used for search,
not for the comparisons. The outcomes of the pairwise com-
parisons after Bonferroni correction are given in Table IV.
With only a few exceptions, the above hypothesis is confirmed:
using A in SPAM yields the best Pareto-set approximations
with regard to A, independently of the problem and the
number of objectives under consideration. These results are
highly significant at a significance level of 0.001.
Concerning the exceptions, first it can be noticed that there
is no significant difference between minpartH and H,C,D when
used in SPAM—both times, the hypervolume indicator value
is optimized. This actually confirms the assumption that set
partitioning can be replaced by a corresponding sequence of
quality indicators. Second, the algorithm based on the set
preference relation minpartP0,H using the IP indicator with the
origin as reference point performs worse than SPAM with
minpartH on DTL2; this is not suprising, as it actually can
be regarded as an approximation of the hypervolume-based
relation. However, it is suprising that SPAM with minpartP0,H is
outperformed by IBEA on both DTLZ2 and DTLZ5; it seems
that IBEA is more effective in obtaining a well-distributed
front. This result indicates the sensitivity of minpartP0,H with
respect to the distribution and the number of the weight com-
binations chosen. The problem can be resolved by selecting a
larger number of weights as discussed in Section III-D.
To see how the differences develop over the course of time,
Fig. 16 compares selected SPAM variants with each other and
provides the test statistics for each iteration. As can be seen
on the left, already after 150 iterations the differences become
highly significant when comparing SPAM with minpartH and
SPAM with minpartP1,H . In Fig. 16 on the right, it can be observed
that SPAM with minpartP0,H is—after a competetive starting
phase—soon overtaken by SPAM with the hypervolume in-
dicator. As already mentioned, this reflects the dependency of
minpartP1,H from the number of weight combinations.
3) Running Time Issues: Last, we investigate the running
time of SPAM where the absolute computation time is consid-
ered instead of the number of fitness evaluations. The question
is how the choice of the set preference relation and the fitness
assignment procedure (Algorithm 4 versus 5) affects the num-
ber of iterations that can be performed in a fixed time budget.
Table V reveals that the average computation time per itera-
tion heavily depends on the specific set preference relation.
For instance, the hypervolume-based set preference relations
induce considerably more computation time—especially in
higher dimensions—than the relation based on the epsilon
indicator. However, the influence of the fitness assignment
algorithms is even stronger: the use of Algorithm 4 slows down
the search by a factor of 100 in comparison to Algorithm 5.
VI. CONCLUSION
In this paper, we have discussed EMO from a single-
objective perspective that is centered around set preference
76 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 14, NO. 1, FEBRUARY 2010
relations and based on the following three observations:
1) the result of an MOEA run is usually a set of trade-off
solutions representing a Pareto set approximation;
2) most existing MOEAs can be regarded as hill climbers—
usually (1, 1)-strategies—on set problems;
3) most existing MOEAs are (implicitly) based on set
preference information.
When applying an evolutionary algorithm to the problem
of approximating the Pareto-optimal set, the population itself
can be regarded as the current Pareto-set approximation. The
subsequent application of mating selection, variation, and
environmental selection heuristically produces a new Pareto-
set approximation that—in the ideal case—is better than the
previous one. In the light of the underlying set problem, the
population represents a single element of the search space
which is in each iteration replaced by another element of
the search space. Consequently, selection and variation can
be regarded as a mutation operator on populations resp. sets.
Somewhat simplified, one may say that a classical MOEA used
to approximate the Pareto-optimal set is a (1, 1)-strategy on a
set problem. Furthermore, MOEAs are usually not preference-
free. The main advantage of generating methods such as
MOEAs is that the objectives do not need to be aggregated
or ranked a priori; but nevertheless preference information is
required to guide the search, although it is usually weaker and
less stringent. In the environmental selection step, for instance,
an MOEA has to choose a subset of individuals from the
parents and the offspring which constitutes the next Pareto-
set approximation. To this end, the algorithm needs to know
the criteria according to which the subset should be selected,
in particular when all parents and children are incomparable,
i.e., mutually nondominating. That means the generation of a
new population usually relies on set preference information.
We here have tried to consequently take this line of thought
further and to study how set preference information can be
formalized such that a total order on the set of Pareto-set
approximations results. To this end, we have shown how
to construct set preference relations on the basis of quality
indicators and provided various examples. Moreover, we have
presented a general set preference algorithm for multiobjective
optimization (SPAM), which is basically a hill climber and
generalizes the concepts found in most modern MOEAs.
SPAM can be used in combination with any type of set
preference relation and thereby offers full flexibility for the
decision maker; furthermore, it can be shown to converge
under general conditions. As the experimental results indicate,
set preference relations can be used to effectively guide the
search as well as to evaluate the outcomes of multiobjective
optimizers.
The new perspective that this paper offers is, roughly speak-
ing, considering EMO as using evolutionary algorithms for
single-objective set problems in the context of multiobjective
optimization. Clearly, there are many open issues, e.g., the
design of both specific and arbitrary set preference relations
to integrate particular user preferences, especially local pref-
erences. Furthermore, the design of fast search algorithms
dedicated to particular set preference relations is of high
interest; SPAM provides flexibility, but is rather a baseline
algorithm that naturally cannot achieve maximum possible
efficiency. And finally, one may think of using a true evolution-
ary algorithm for set-based multiobjective optimization, one
that operates on populations of Pareto set approximations—
whether this approach can be beneficial is an open research
issue.
APPENDIX
In order to prove Theorem 2.7 we first need to state a set
of smaller results:
Lemma A.1: If all preference relations  j , 1 ≤ j ≤ k in
Definition 2.6 are preorders, then S is a preorder.
Proof: Reflexivity: As A i A holds for all 1 ≤ i ≤ k
(since all i are preorders), we have i = k in Definition 2.6 (i).
Therefore, (A S A) ⇔ (A i A) and the reflexivity holds.
Transitivity: We prove transitivity by induction. We first need
to show that transitivity holds for k = 1. In this case, we
have A S B ⇔ A 1 B as i = k in Definition 2.6 (i).
Transitivity holds as 1 is a preorder. Now we have to show
that transitivity holds for k if it holds for k − 1. Let us define
the sequence of length k − 1 as S′. Then we can reformulate
Definition 2.6 as follows:
(A S B)⇔ ((A ≡S’ B) ∧ (A k B)) ∨ (A ≺S’ B). (3)
Now, we can show that transitivity holds:
(A S B) ∧ (B S C)⇒
⇒[((A ≡S’ B) ∧ (A k B)) ∨ (A ≺S’ B)]∧
[((B ≡S’ C) ∧ (B k C)) ∨ (B ≺S’ C)]⇒
⇒((A ≡S’ B) ∧ (B ≡S’ C) ∧ (A k B) ∧ (k C))∨
((A ≺S’ B) ∧ (B ≺S’ C))⇒
⇒((A ≡S’ C) ∧ (A k C)) ∨ (A ≺S’ C)⇒ A S C.
Lemma A.2: If all preference relations  j , 1 ≤ j ≤ k in
Definition 2.6 are total preorders, then S is a total preorder.
Proof: A preorder  is called total if (A  B)∨ (B  A)
holds for all A, B ∈  . Using the same induction principle
as in the proof of A.1 we can notice that for k = 1 we have
(A S B) ⇔ (A 1 B) and therefore, S is total. For the
induction we know that (3) holds. Therefore, we can conclude
(A S B) ∨ (B S A)⇔
⇔((A ≡S’ B) ∧ (A k B)) ∨ ((B ≡S’ A) ∧ (B k A))∨
(A ≺S’ B)∨ (B ≺S’ A)⇔
⇔(A ≡S’ B) ∨ (A ≺S’ B)∨ (B ≺S’ A)⇔ true.
Lemma A.3: If k in Definition 2.6 is a refinement of a
given preference relation  and all relations  j , 1 ≤ j < k
are weak refinements of , then S is a refinement of .
Proof: Let us suppose that A ≺ B holds for some A, B ∈
 . We have to show that A ≺S’ B holds. At first note, the
A  j B holds for all 1 ≤ j < k as  j are weak refinements
and A ≺k B holds as k is a refinement. Let us now consider
the sequence S′ of length k − 1. Because all  j are weak
ZITZLER et al.: ON SET-BASED MULTIOBJECTIVE OPTIMIZATION 77
TABLE VI
COUNTEREXAMPLE FOR 1-GREEDYNESS OF THE UNARY EPSILON
INDICATOR
r1 r2 r3 r4 f (x1) f (x2) f (x3) f (x4)
1 4 0 6 3 6 2 0 3
2 0 4 3 6 2 6 0 3
3 6 6 2 2 4 4 6 2
refinements, either A ≡ j B or A ≺ j B holds. Taking into
account the construction of S′ according to Definition 2.6 we
can easily see that A S’ B holds. Based on the fact that S’
is a weak refinement, we will show that A ≺S B holds, i.e.
≺S is a refinement. To this end, we again use (3) to derive
(A S B) ∧ (B S A)⇔
⇔[((A ≡S’ B) ∧ (A k B)) ∨ (A ≺S’ B)]∧
((B ≡S’ A) ∨ (B k A)) ∧ (A ≺S’ B). (4)
As S’ is a weak refinement, we need to consider two cases.
If A ≡S’ B holds, then A ≺S’ B holds as well as B ≺S’ A.
In this case, the expression becomes (A k B) ∧ (B k A)
which yields true. If A ≺S’ B holds, then A ≡S’ B , B ≡S’
A and B ≺S’ A hold. The expression above becomes now
(A ≺S’ B)∧ (B ≺S’ A) which also yields true.
Now we can give the proof of Theorem 2.7.
Proof of Theorem 2.7: Because of Lemma A.3, we know that
the sequence S′ = (1,2, . . . ,k′) leads to a refinement of
. We just need to show that additional preference relations
 j , k ′ < j ≤ k in the sequence do not destroy this property.
We again use the same induction principle as in the previous
proofs. Let us suppose that S′ yields a refinement (as shown
above) and S has one additional relation k′+1, i.e. k = k ′+1.
Using again (3) we can derive the expression for A ≺S B as
in (4). If we suppose that A ≺ B holds in the given preorder,
and S’ is a refinement, the relations A ≡S’ B , B ≡S’ A,
A ≺S’ A, and B ≺S’ A hold. For the expression in (4) we get
(A k B) ∧ (B k A) which yields true.
Proof of Theorem 3.2: Suppose conditions 1 and 2 hold,
and let A, B ∈  be two arbitrary sets with A ≺ B ,
i.e. (A  B)∧ (B  A). For the proof, we will apply the two
local transformations in order to gradually change B to A and
show that at each step the indicator value does not increase
and there is at least one step where it decreases. First, we
successively add the elements of B to A; since for each b ∈ B
it holds A  {b}, according to condition 1 the indicator value
remains constant after each step, i.e., I (A) = I (A∪ B). Now,
we successively add the elements of A to B; since A ≺ B ,
there exists an element a ∈ A such that B  {a} according
to the conformance of  with . That means when adding
the elements of A to B the indicator value either remains
unchanged (condition 1) or decreases (and it will decrease
at least once, namely for a, according to condition 2), and
therefore I (A ∪ B) < I (B). Combining the two intermediate
results, one obtains I (A) = I (A ∪ B) < I (B) which implies
A I B and B I A. Hence, I refines . For weak
refinement, the proof is analogous.
TABLE VII
VALUES (z, r) FOR THE COUNTEREXAMPLE
f (x1) f (x2) f (x3) f (x4)
r1 2 6 0 3
r2 6 2 0 3
r3 2 3 4 0
r4 3 2 4 0
TABLE VIII
COUNTEREXAMPLE FOR 1-GREEDYNESS OF THE HYPERVOLUME
INDICATOR
r f (x1) f (x2) f (x3) f (x4)
1 10 1 6 5 7
2 7 6 2 3 1
To the prove that the second condition is a necessary
condition, suppose A  {b}. According to Definition 2.2,
(A ∪ {b}) ≺ A which implies that (A ∪ {b}) I A (weak
refinement) respectively (A ∪ {b}) ≺I A (refinement). Hence,
I (A ∪ {b}) ≤ I (A) respectively I (A ∪ {b}) < I (A) according
to (1).
Proof of Corollary 4.5: We will show that in the case of a
3-D objective space Z ⊂ R3, the epsilon indicator I1(A) =
I(A, R) is not 1-greedy.
The proof is done by providing a counterexample. We will
give a scenario consisting of an objective space Z ⊂ R3,
reference set R ⊂ Z , a maximum set size m and an initial set
P ∈ m . We will show that there is no path from the initial
set P to an optimal set P∗ such that every time only one
element of the set is exchanged. In particular, we have X =
{x1, x2, x3, x4}, R = {r1, r2, r3, r4}, m = 2, P = {x1, x2},
P∗ = {x3, x4}, and f : X → Z according to Table VI. With
the values (z, r) shown in Table VII we obtain the epsilon
indicator value for all possible sets as I({x1, x2}, R) = 2,
I({x1, x3}, R) = 3, I({x1, x4}, R) = 3, I({x2, x3}, R) =
3, I({x2, x4}, R) = 3 and I({x3, x4}, R) = 0.
Therefore, from the initial set {x1, x2}, every set mutation
operator that exchanges one element only leads to a worse
indicator value.
Finally, note that it can be shown that in R2 the epsilon
indicator is 1-greedy.
Proof of Corollary 4.6: We will show that in the case of a
2-D objective space Z ⊂ R2, the hypervolume indicator IH
is not 1-greedy.
The proof is done by providing a counterexample similar
to the proof of the previous Corollary. Here we use again a
decision space X = {x1, x2, x3, x4}, a reference set R = {r},
an initial set P = {x1, x2}, an optimal set P∗ = {x3, x4},
and f : X → Z according to Table VIII. Using this
scenario, we obtain the hypervolume indicators for all possible
populations as IH ({x1, x2}, R) = −25, IH ({x1, x3}, R) =
−24, IH ({x1, x4}, R) = −24, IH ({x2, x3}, R) = −24,
78 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 14, NO. 1, FEBRUARY 2010
IH ({x2, x4}, R) = −24 and IH ({x3, x4}, R) = −26. There-
fore, from the initial set {x1, x2}, every set mutation operator
that exchanges one element only leads to a worse indicator
value.
Proof Weight combinations for minpartR2,H : In the case of five
objectives, overall 32 · 5 weight combinations are used for the
set preference relation minpartR2,H , cf. Table II. In detail,  is
defined as follows:
 = {
(0, 0, 0, 0, 1),
(0.01/4, 0.01/4, 0.01/4, 0.01/4, 0.99),
. . . ,
(0.3/4, 0.3/4, 0.3/4, 0.3/4, 0.7)
}
∪
{
(0, 0, 0, 1, 0),
(0.01/4, 0.01/4, 0.01/4, 0.99, 0.01/4),
. . . ,
(0.3/4, 0.3/4, 0.3/4, 0.7, 0.3/4)
}
∪
. . .
∪
{
(1, 0, 0, 0, 0),
(0.99, 0.01/4, 0.01/4, 0.01/4, 0.01/4),
. . . ,
(0.7, 0.3/4, 0.3/4, 0.3/4, 0.3/4)
}
REFERENCES
[1] J. Bader and E. Zitzler, “HypE: An algorithm for fast hypervolume-
based many-objective optimization,” Institut für Technische Informatik
und Kommunikationsnetze, ETH Zürich, Switzerland, TIK Rep. 286,
Nov. 2008.
[2] J. Branke and K. Deb, “Integrating user preferences into evolutionary
multiobjective optimization,” Indian Inst. Technol., Kanpur, India, Tech.
Rep. 2004004, 2004. Knowledge Incorporation in Evolutionary Compu-
tation, New York: Springer-Verlag, 2004, pp. 461–477.
[3] J. Branke, K. Deb, H. Dierolf, and M. Osswald, “Finding knees in
multiobjective optimization,” in Proc. Conf. Parallel Problem Solving
from Nature (PPSN VIII), LNCS vol. 3242. New York: Springer-Verlag,
2004, pp. 722–731.
[4] J. Branke, T. Kaußler, and H. Schmeck, “Guidance in evolutionary
multiobjective optimization,” Adv. Eng. Soft., vol. 32, no. 6, pp. 499–507,
2001.
[5] D. Brockhoff, T. Friedrich, N. Hebbinghaus, C. Klein, F. Neumann,
and E. Zitzler, “Do additional objectives make a problem harder?” in
Proc. Genetic Evol. Comput. Conf. (GECCO 2007), New York: ACM,
pp. 765–772.
[6] D. Cvetković and I. C. Parmee, “Preferences and their application in
evolutionary multiobjective optimization,” IEEE Trans. Evol. Comput.,
vol. 6, no. 1, pp. 42–57, Feb. 2002.
[7] K. Deb, Multi-Objective Optimization Using Evolutionary Algorithms.
Chichester, U.K.: Wiley, 2001.
[8] K. Deb, S. Agrawal, A. Pratap, and T. Meyarivan, “A fast elitist non-
dominated sorting genetic algorithm for multiobjective optimization:
NSGA-II,” in Proc. Conf. Parallel Problem Solving from Nature (PPSN
VI), LNCS vol. 1917. New York: Springer-Verlag, 2000, pp. 849–858.
[9] K. Deb, S. Chaudhuri, and K. Miettinen, “Toward estimating nadir
objective vector using evolutionary approaches,” in Proc. Conf. Genetic
Evol. Comput. (GECCO ’06), New York: ACM, pp. 643–650.
[10] K. Deb, M. Mohan, and S. Mishra, “Evaluating the -domination
based multiobjective evolutionary algorithm for a quick computa-
tion of pareto-optimal solutions,” Evol. Comput., vol. 13, no. 4,
pp. 501–525, Winter 2005.
[11] K. Deb and J. Sundar, “Reference point based multiobjective opti-
mization using evolutionary algorithms,” in Proc. Conf. Genetic Evol.
Comput. (GECCO ’06), New York: ACM, pp. 635–642.
[12] K. Deb, L. Thiele, M. Laumanns, and E. Zitzler, “Scalable multiobjective
optimization test problems,” in Proc. Cong. Evol. Comput. (CEC ’02),
Piscataway, NJ: IEEE Press, pp. 825–830.
[13] K. Deb and S. Tiwari, “Omni-optimizer: A generic evolutionary algo-
rithm for single and multiobjective optimization,” Eur. J. Oper. Res.,
vol. 185, no. 3, pp. 1062–1087, 2008.
[14] M. Emmerich, N. Beume, and B. Naujoks, “An EMO algorithm using
the hypervolume measure as selection criterion,” in Proc. Conf. Evol.
Multi-Criterion Optimization (EMO ’05), LNCS vol. 3410. New York:
Springer-Verlag, pp. 62–76.
[15] M. Fleischer, “The measure of Pareto optima. Applications to multi-
objective metaheuristics,” in Proc. Conf. Evol. Multi-Criterion Opti-
mization (EMO ’03), LNCS vol. 2632. Faro, Portugal: Springer-Verlag,
pp. 519–533.
[16] C. M. Fonseca and Peter J. Fleming, “Genetic algorithms for multiobjec-
tive optimization: Formulation, discussion and generalization,” in Proc.
Conf. Genetic Algorithms, San Mateo, CA: Morgan Kaufmann, 1993,
pp. 416–423.
[17] C. M. Fonseca and P. J. Fleming, “Multiobjective optimization and
multiple constraint handling with evolutionary algorithms—part I: A
unified formulation,” IEEE Trans. Syst., Man, Cybern., vol. 28, no. 1,
pp. 26–37, Jan. 1998.
[18] D. E. Goldberg, “Multiobjective optimization,” in Genetic Algorithms in
Search, Optimization, and Machine Learning. Reading, MA: Addison-
Wesley, 1989, ch. 5, pp. 197–201.
[19] T. Hanne, “Covariance matrix adaptation for multiobjective optimiza-
tion,” Evol. Comput., vol. 15, no. 1, pp. 1–28, 2007.
[20] M. P. Hansen and A. Jaszkiewicz, “Evaluating the quality of approxima-
tions of the non-dominated set. Technical report,” Inst. Math. Modeling,
Tech. Univ. Denmark, Denmark, IMM Tech. Rep. IMM-REP-1998-7,
1998.
[21] S. Huband, P. Hingston, L. White, and L. Barone, “An evolution strategy
with probabilistic mutation for multiobjective optimization,” in Proc.
Congr. Evol. Comput. 2003 (CEC ’03), vol. 3. Canberra, Australia:
IEEE Press pp. 2284–2291.
[22] C. Igel, N. Hansen, and S. Roth, “Covariance matrix adaptation for
multiobjective optimization,” Evol. Comput., vol. 15, no. 1, pp. 1–28,
2007.
[23] Y. Jin and B. Sendhoff, “Incorporation of fuzzy preferences into evo-
lutionary multiobjective optimization,” in Proc. 4th Asia-Pacific Conf.
Simulated Evol. Learning, vol. 1. 2002, pp. 26–30.
[24] J. Knowles and D. Corne, “On metrics for comparing non-dominated
sets,” in Proc. Congr. Evol. Comput. (CEC ’02), Piscataway, NJ: IEEE
Press, pp. 711–716.
[25] J. Knowles and D. Corne, “Properties of an adaptive archiving algorithm
for storing nondominated vectors,” IEEE Trans. Evol. Comput., vol. 7,
no. 2, pp. 100–116, Apr. 2003.
[26] J. Knowles, L. Thiele, and E. Zitzler, “A tutorial on the performance
assessment of stochastic multiobjective optimizers,” Comput. Eng. Netw.
Lab. (TIK), ETH Zürich, Switzerland, TIK Rep. 214, Feb. 2006.
[27] M. Laumanns, L. Thiele, K. Deb, and E. Zitzler, “Combining conver-
gence and diversity in evolutionary multiobjective optimization,” Evol.
Comput., vol. 10, no. 3, pp. 263–282, 2002.
[28] L. Rachmawati and D. Srinivasan, “Preference incorporation in
multiobjective evolutionary algorithms: A Survey,” in Proc. Congr.
Evol. Comput. (CEC ’06), Piscataway, NJ: IEEE Press, Jul. 2006,
pp. 962–968.
[29] G. Rudolph and A. Agapie, “Convergence properties of some mul-
tiobjective evolutionary algorithms,” in Proc. Congr. Evol. Comput.
(CEC ’00), vol. 2. Piscataway, NJ: IEEE Press, pp. 1010–1016.
[30] N. Srinivas and K. Deb, “Multiobjective optimization using nondom-
inated sorting in genetic algorithms,” Evol. Comput., vol. 2, no. 3,
pp. 221–248, 1994.
ZITZLER et al.: ON SET-BASED MULTIOBJECTIVE OPTIMIZATION 79
[31] D. A. Van Veldhuizen and G. B. Lamont, “On measuring multiobjective
evolutionary algorithm performance,” in Proc. Congr. Evol. Comput.
(CEC ’00), vol. 1. Piscataway, NJ: IEEE Service Center, pp. 204–211.
[32] D. A. Van Veldhuizen and G. B. Lamont, “Multiobjective evolutionary
algorithms: Analyzing the state-of-the-art,” Evol. Comput., vol. 8, no. 2,
pp. 125–147, 2000.
[33] M. Villalobos-Arias, C. A. C. Coello, and O. Hernandez-Lerma, “As-
ymptotic convergence of some metaheuristics used for multiobjective
optimization,” in Proc. Found. Genetic Algorithms (LNCS), vol. 3469,
2005, pp. 95–111.
[34] E. Zitzler, “Evolutionary algorithms for multiobjective optimization:
Methods and applications,” Ph.D. thesis, Dept. Elect. Eng., ETH Zürich,
Switzerland, 1999.
[35] E. Zitzler, D. Brockhoff, and L. Thiele, “The hypervolume indicator
revisited: On the design of pareto-compliant indicators via weighted in-
tegration,” in Proc. Conf. Evol. Multi-Criterion Optimization (EMO ’07),
LNCS vol. 4403. Berlin, Germany: Springer-Verlag, pp. 862–876.
[36] E. Zitzler and S. Künzli, “Indicator-based selection in multiobjec-
tive search,” in Proc. Conf. Parallel Problem Solving from Nature
(PPSN VIII), LNCS vol. 3242. New York: Springer-Verlag, 2004,
pp. 832–842.
[37] E. Zitzler, M. Laumanns, and L. Thiele, “SPEA2: Improving the strength
pareto evolutionary algorithm for multiobjective optimization,” in Proc.
Evol. Methods Design, Optimization Control Applicat. Ind. Problems
(EUROGEN ’01), Barcelona, Spain: Inte. Center Numerical Methods
Eng. (CIMNE), 2002, pp. 95–100.
[38] E. Zitzler and L. Thiele, “Multiobjective evolutionary algorithms: A
comparative case study and the strength pareto approach,” IEEE Trans.
Evol. Comput., vol. 3, no. 4, pp. 257–271, Nov. 1999.
[39] E. Zitzler, L. Thiele, and J. Bader, “SPAM: Set preference algo-
rithm for multiobjective optimization,” in Proc. Conf. Parallel Problem
Solving From Nature (PPSN X), New York: Springer-Verlag, 2008,
pp. 847–858.
[40] E. Zitzler, L. Thiele, M. Laumanns, C. M. Fonseca, and V. Grunert
da Fonseca, “Performance assessment of multiobjective optimizers:
An analysis and review,” IEEE Trans. Evol. Comput., vol. 7, no. 2,
pp. 117–132, Apr. 2003.
Eckart Zitzler received the Diploma degree in
computer science from the University of Dortmund,
Germany, and Doctor of Technical Sciences degree
from Eidgenössische Technische Hochschule (ETH)
Zürich, Switzerland.
Since 2003, he has been Assistant Professor for
Systemsg Optimization in the Computer Engineer-
ing and Networks Laboratory, Department of In-
formation Technology and Electrical Engineering,
ETH Zürich, Switzerland. His research focuses on
bioinspired computation, multiobjective optimiza-
tion, computational biology, and computer engineering applications.
Prof. Zitzler was General Co-Chairman of the first three international
conferences on evolutionary multi-criterion optimization (EMO 2001, EMO
2003, and EMO 2005).
Johannes Bader studied Information Technology
and Electrical Engineering at the Eidgenössische
Technische Hochschule (ETH) Zürich, and received
the Master’s degree in 2006. Since then, he has
been a doctoral student in the Systems Optimization
Group at the Computer Engineering and Networks
Laboratory at the ETH Zürich, Switzerland.
His interest is focused on evolutionary multiobjec-
tive optimization.
Lothar Thiele was born in Aachen, Germany, on
April 7, 1957. He received the Diplom-Ingenieur
and Dr.-Ing. degrees in electrical engineering from
the Technical University of Munich in 1981 and
1985, respectively. After completing his Habilitation
thesis from the Institute of Network Theory and
Circuit Design of the Technical University Munich,
he joined the Information Systems Laboratory at
Stanford University in 1987.
In 1988, he took up the Chair of Microelec-
tronics at the Faculty of Engineering, University
of Saarland, Saarbrucken, Germany. He joined Eidgenössische Technische
Hochschule (ETH) Zürich, Switzerland, as a Full Professor of Computer
Engineering, in 1994. Currently, He is leading the Computer Engineering and
Networks Laboratory at the ETH Zürich, Switzerland. His research interests
include models, methods, and software tools for the design of embedded
systems, embedded software, and bioinspired optimization techniques.
Prof. Thiele received the “Dissertation Award” of the Technical University of
Munich in 1986; the “Outstanding Young Author Award” of the IEEE Circuits
and Systems Society in 1987; the Browder J. Thompson Memorial Award of
the IEEE in 1988; and in 2000–2001, the “IBM Faculty Partnership Award.”
In 2004, he joined the German Academy of Natural Scientists Leopoldina. In
2005, he was the recipient of the Honorary Blaise Pascal Chair of University
Leiden, The Netherlands.

