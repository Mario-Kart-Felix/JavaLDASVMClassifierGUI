Typical Approximation Performance for Maximum Coverage Problem
Satoshi Takabe,1, ∗ Takanori Maehara,2 and Koji Hukushima3
1Department of Computer Science, Nagoya Institute of Technology,
Gokiso-cho, Showa-ku, Nagoya, Aichi, 466-8555, Japan
2RIKEN Center for Advanced Intelligence Project 15F,
1-4-1, Nihonbashi, Chuo-ku, Tokyo, 103-0027, Japan
3Graduate School of Arts and Sciences, The University of Tokyo,
3-8-1 Komaba, Meguro-ku, Tokyo 153-8902, Japan
(Dated: June 28, 2017)
This study investigated typical performance of approximation algorithms known as belief prop-
agation, greedy algorithm, and linear-programming relaxation for maximum coverage problems on
sparse biregular random graphs. After using the cavity method for a corresponding hard-core
lattice–gas model, results show that two distinct thresholds of replica-symmetry and its breaking
exist in the typical performance threshold of belief propagation. In the low-density region, the
superiority of three algorithms in terms of a typical performance threshold is obtained by some
theoretical analyses. Although the greedy algorithm and linear-programming relaxation have the
same approximation ratio in worst-case performance, their typical performance thresholds are mu-
tually different, indicating the importance of typical performance. Results of numerical simulations
validate the theoretical analyses and imply further mutual relations of approximation algorithms
PACS numbers: 75.10.Nr, 89.70.Eg, 89.20.Ff, 02.60.Pn
I. INTRODUCTION
Approximation algorithms, which are important for
hard optimization problems, have attracted researchers’
interest because, for NP-hard optimization problems, one
encounters difficulty when solving optimal solutions ex-
actly in polynomial time of the problem size. Since the P
versus NP problem arose, development and performance
analyses of approximation algorithms have persisted as a
central issue of computer science and operations research.
Two performance evaluations of approximation algo-
rithms exist: worst-case performance and typical (or
average-case) performance. As described in this pa-
per, we specifically examine the latter mainly using
statistical–mechanical methods, although the former has
been investigated mainly in the literature of theoretical
computer science [1]. Worst-case performance is defined
by the pair of an optimization problem and its approx-
imation algorithm. An approximation ratio is then de-
fined by the maximal ratio of an optimal value to an
approximation value over all instances if the problem is
a maximization problem (and vice versa, otherwise). It
is important to provide strict performance guarantee of
the algorithm, although the worst-case instance is some-
times pathological. However, the typical performance is
defined as the average performance of approximation al-
gorithm for a given optimization problem over random-
ized instances. It is sometimes useful for practical use.
It sheds light on properties of optimization problems and
approximation algorithms in a perspective that is differ-
ent from worst-case analysis.
∗ E-mail: s takabe@nitech.ac.jp
An interesting point of the typical property of opti-
mization problems is found in a close relation to the
spin-glass theory in statistical physics. Extensive studies
of various computational problems have revealed that the
concept of replica symmetry (RS) and its breaking (RSB)
in spin-glass theory reflects average computational com-
plexity [2] and structure of the solution space [3] of the
problems.
Typical performance of approximation algorithms of-
ten exhibits a phase transition on typical goodness or
accuracy of approximation, which is called threshold phe-
nomena in the literature of theoretical computer sci-
ence [4]. Some approximation algorithms for minimum
vertex covers (min-VC) are good examples of thresh-
old phenomena. The problem is defined on a graph.
The randomized problem is characterized using a ran-
dom graph ensemble with c being the average degree.
From a statistical–mechanical perspective, the problem
on Erdös-Rényi random graphs has the RS-RSB thresh-
old at c = e = 2.71 . . . [5]. Moreover, three ap-
proximation algorithms have been investigated: belief
propagation (BP) (or message passing) [6], greedy leaf-
removal algorithm [7], and linear-programming (LP) re-
laxation [8, 9]. Approximation algorithms other than BP
naively have no direct connection to the spin-glass the-
ory. Nevertheless, for Erdös-Rényi random graphs, these
algorithms have the same performance threshold as the
RS-RSB threshold. However, subsequent studies of gen-
eral random graphs [10] indicate that their thresholds
are not equivalent for some random graphs because of
their graph structure. Using statistical–mechanical tech-
niques, typical performance has been studied for variants
of leaf removal [11–14] and relaxation technique such as
LP relaxation [15, 16] and semidefinite-programming re-
laxation [17]. These studies have revealed not only typi-
ar
X
iv
:1
70
6.
08
72
1v
1 
 [
co
nd
-m
at
.d
is
-n
n]
  2
7 
Ju
n 
20
17
2
cal approximate performance itself but also a suggestive
connection to typical properties of optimization prob-
lems, random graph structure, and the spin-glass theory.
As described in this paper, we examine the unweighted
maximum coverage (max-COV) problem defined in the
next section. Although the max-COV belongs to the class
of NP-hard, it has several practical applications such as
pan and scan problems [18], multi-topic blog watch [19],
and text summarization [20]. Our main purpose is to
examine the typical performance of approximation algo-
rithms for the problem and to compare their performance
thresholds. We specifically examine three approximation
algorithms: belief propagation, greedy algorithm, and LP
relaxation. Some statistical–mechanical methods applied
to both analytical and numerical analyses together with
mathematical rigorous discussions clarify typical perfor-
mance of those algorithms and a suggestive mutual rela-
tion among approximation algorithms.
This paper is organized as follows. In the next section,
we define details of the max-COV and its approximation
algorithms. As a random graph ensemble, biregular ran-
dom graphs are also defined. In Section III, a hard-core
lattice–gas model for the problem is introduced. Its BP
equations are obtained based on Bethe–Peierls approxi-
mation. In Section IV, we present a study of the typical
performance of BP using the RS cavity method. Calcula-
tion of the spin-glass susceptibility provides the threshold
below which BP typically approximate max-COV with
high accuracy. In Section V, the greedy algorithm is an-
alyzed based on a mean-field rate equation of its deletion
process. Using the obtained solution, the typical perfor-
mance threshold of the greedy algorithm is evaluated. In
Section VI, LP-relaxed approximate values are evaluated
rigorously. The theorem is proved using the weak dual-
ity theorem. In Section VII, we describe some numerical
results which support the validity of theoretical analy-
ses presented in the previous sections. We also execute
some additional simulations to consider the typical per-
formance of a modified greedy algorithm and randomized
rounding of LP relaxation. These results provide sug-
gestive relation between approximation algorithms. The
last section is devoted to a summary and discussion of
the results.
II. MAX-COVER PROBLEM AND
APPROXIMATION ALGORITHMS
A. Maximum coverage problem
The max-COV is defined as follows: Let S be a set
of M elements and S = {S1, · · · , SN} be a collection of
subsets of S. For a given positive integer K(≤ N), the
problem is to choose at most K subsets to maximize the
total number of elements in the union of chosen subsets.
An example of an instance with M = 4 and N = 3 is
shown at the left-hand side of Fig. 1. Given that K = 2,
one can select subsets S1 and S3 such that all elements
FIG. 1. Example of the maximum coverage problem. (Left)
An example with M = 4 and N = 3. S1, S2, and S3 rep-
resent subsets of S = {1, 2, 3, 4}. (Right) A bipartite graph
corresponding to the left example. Each vertex in V1 stands
for a subset in the left example.
are included in the union of the subsets.
Converting an instance to a bipartite graph, one ob-
tains an integer-programming (IP) representation of the
max-COV. Let G = (V1, V2, E) be a bipartite graph
where each edge in E connects to a vertex in V1 and
a vertex in V2. Vertices in V1 and V2 are labeled re-
spectively by i ∈ {1, . . . , N} and a ∈ {1, . . . ,M}. V1
corresponds to a collection of subsets S, whereas V2 rep-
resents S. Each edge (i, a) is set if subset Si includes
element a. For Fig. 1, the left example is converted to
a bipartite graph in the right-hand side. We then in-
troduce binary variables {xi} and {ya}, respectively, to
V1 and V2. Also, xi is set to one if vertex i (or subset
Si) is selected and zero otherwise. Similarly, ya is set to
one if vertex a is connected to a selected vertex (or ele-
ment a belongs to the union of chosen subsets) and zero
otherwise. The problem is therefore represented by the
following IP problem:
Max.
M∑
a=1
ya,
subject to ya ≤
∑
i; (i,a)∈E
xi ∀a ∈ V2,
N∑
i=1
xi ≤ K,
xi ∈ {0, 1} ∀i ∈ V1, ya ∈ {0, 1} ∀a ∈ V2.
(1)
The inequality in the second constraint can be replaced
with an equality sign because the problem is a maximiza-
tion problem.
As described in this paper, typical-case property of the
max-COV is analyzed by randomizing its instance. Then,
we introduce ρx = K/N and assume that ρx ∈ [0, 1] is
constant. For random bipartite graphs, we specifically
examine (L,R)-biregular random graphs where degrees of
each vertex in V1 and V2 respectively denote L andR. Us-
ing this simple random graph ensemble, our statistical–
mechanical analyses reveal interesting properties of the
problem.
To take the large graph limit, the number of vertices
in V2 is rescaled as M = αN . We assume that a random
graph is sparse, i.e., L and R are constant with respect to
3
N . For the randomized max-COV, we define an average
optimal cover ratio over random graphs with cardinality
N +M and a given ρx by
ρy(ρx;N) =
1
M
M∑
a=1
yopta (G, ρx), (2)
where {yopta (G, ρx)} represents optimal solutions in V2
and (· · · ) represents an average over random bipartite
graphs with size N + M . Its limiting value to N → ∞
is denoted by ρy. We simply call it the average optimal
cover ratio.
B. Approximation algorithms
We introduce three approximation methods for max-
COVs. The first algorithm is belief propagation (BP).
The recursive equations called BP equations are derived
from Bethe–Peierls approximation for a spin system cor-
responding to a given optimization problem. For sys-
tems on trees, graphs with no cycles, the Bethe–Peierls
approximation and BP are exact. In general, however,
there exist cycles in a graph yielding correlations between
variables or spins, which results in inexact estimation of
solutions (or configurations). BP on graphs with some
cycles is regarded as an approximation method. It is
called loopy BP [21].
The second one is a simple greedy algorithm. At
each step, this algorithm has the following procedure:
(i) choose one vertex named i with the maximum de-
gree in V1, (ii) delete vertices neighboring to vertex i
from V2, and (iii) update V1 to V1\i and return to (i) if
|V1| > N − K. This simple algorithm gives an approx-
imation ratio of 1 − 1/e [22]. The problem cannot be
approximated within this ratio unless P=NP [23].
The last is linear programming (LP) relaxation. An
integer programming problem including the max-COV is
relaxed to LP problems by replacing integral constraints
with real constraints. The LP-relaxed max-COV is given
as
Max.
M∑
a=1
ya,
subject to ya ≤
∑
i; (i,a)∈E
xi ∀a ∈ V2,
N∑
i=1
xi ≤ K,
xi ∈ [0, 1] ∀i ∈ V1, ya ∈ [0, 1] ∀a ∈ V2.
(3)
Actually, LP approximation value gives the upper bound
of the problem. Because LP problems are solvable ex-
actly in polynomial time, LP relaxation is a widely used
approximation technique. The approximate solution ob-
tained by LP relaxation usually involves non-integers.
One must round those numbers appropriately to obtain
an approximate integral solution for the IP problem.
Here, we consider randomized rounding [24]. Using the
obtained approximation solution {xLPi }, one selects ver-
tex i ∈ V1 to set I ⊂ V1 with probability xLPi /K up
to K vertices. Then, the rounded solution {xLPri } is set
to xLPri = 1 for i ∈ I and xLPri = 0 otherwise. The
rounded approximation value is readily calculated from
{xLPri }. In terms of the worst-case performance, LP re-
laxation and its randomized rounding in expectation has
the same approximation ratio as the greedy algorithm.
As described in this paper, we study the typical per-
formance of these approximation algorithms. It is eval-
uated by approximate values averaged over randomized
max-COVs defined in the last subsection. Similar to the
average optimal cover ratio, the average cover ratio is
defined as the average ratio of the approximate value to
the cardinality N of vertex set V1. It is regarded as ex-
hibiting good typical performance if the average cover
ratio obtained by an approximation algorithm is equal
to the average optimal cover ratio in the large-N limit.
The main aim of this paper is to evaluate the typical
performance threshold of ρx below which an approxi-
mate algorithm exhibits good typical performance with L
and R fixed. Evaluation of the approximation algorithms
is accomplished by comparing their typical performance
thresholds.
III. BP EQUATIONS FOR MAX-COV
As explained in this section, BP equations for max-
COV are derived based on the statistical–mechanical
model for the problem. We set particles on vertices in
V1 and V2, which respectively occupy vertex i and a if
xi = 1 and ya = 1.
The hard-core lattice-gas model for max-COVs on bipartite graph G is then naively given as the following partition
4
function.
Ξ0(µ;G) =
∑
x∈{0,1}N
∑
y∈{0,1}M
exp
(
µ
M∑
a=1
ya
)
H
(
K −
N∑
i=1
xi
)
M∏
a=1
H
(∑
i∈∂a
xi − ya
)
, (4)
Therein, H(x) = 1 (x ≥ 0), 0 (x < 0) is the Heaviside step function and ∂a = {i ∈ V1 | (i, a) ∈ E} stands for a set
of neighbors of vertex a ∈ V2. In the partition function, µ represents a chemical potential for particles on V2. One
can construct BP equations for this model. However, it is inconvenient for practical use because of the constraint∑N
i=1 xi ≤ K.
Therefore, we use the following alternative partition function of
Ξ(µ;G) =
∑
x∈{0,1}N
∑
y∈{0,1}M
exp
(
µ′
N∑
i=1
xi + µ
M∑
a=1
ya
)
M∏
a=1
H
(∑
i∈∂a
xi − ya
)
, (5)
where µ′ = µ′(µ, ρx;G) is a chemical potential for particles on V1. The ratio of µ′ with respect to µ is defined as
κ = −µ
′
µ
. (6)
This parameter is regarded as a Lagrange multiplier for the constraint on the number of selected vertices. We then
take the large-µ limit with parameter κ fixed. The appropriate value of κ must satisfy the condition of
lim
µ→∞
〈
1
N
N∑
i=1
xi
〉
µ
= ρx, , (7)
where 〈. . . 〉µ is a grand-canonical average with a given µ.
First, we construct BP equations for Eq. (5). Using the
Bethe–Peierls approximation, the single spin probability
Pi(x) which xi takes x is
Pi(x) ' Z−1i e
−µκx ∏
a∈∂i
Pa→i(x), , (8)
where ∂i = {a ∈ V2 | (i, a) ∈ E} is a set of neighbors of
vertex i ∈ V1. Z∗ is a normalization factor hereinafter.
Pa→i(x) represents the marginal probability of x∂a\i and
ya under the condition xi = x. Similarly, single spin
probability Pa(y) that ya takes y reads
Pa(y) ' Z−1a eµy
∑
x∂a
H
(∑
i∈∂a
xi − y
) ∏
i∈∂a
Pi→a(x), (9)
where Pi→a(x) is the probability of xi taking x on the
cavity graph G\a. These probabilities satisfy the follow-
ing recursive relations under the same approximation.
Pi→a(x) ' Z−1i→ae
−µκx ∏
b∈∂i\a
Pa→i(x), (10)
Pa→i(x) ' Z−1a→i
∑
y
eµy
∑
x∂a\i
H
x+ ∑
j∈∂a\i
xj − y
 ∏
j∈∂a\i
Pj→a(x). (11)
To take the large-µ limit later, it is convenient to in-
troduce cavity fields {hia} and {ĥai} defined respectively
by Pi→a(x) ∝ exp(µhiax) and Pa→i(y) ∝ exp(µĥaiy).
Then, BP equations for cavity fields are given as
hia = −κ+
∑
b∈∂i\a
ĥbi, (12)
ĥai = −
1
µ
ln
1− 1
1 + e−µ
∏
j∈∂a\i
1
1 + eµhja
 . (13)
5
By rescaling the single spin probability as Pi(x) ∝
exp(µξix) and Pa(y) ∝ exp(µξ̂ay) using local fields {ξi}
and {ξ̂a}, Eqs. (8) and (9) then read
ξi = −κ+
∑
a∈∂i
ĥai, (14)
ξ̂a = −
1
µ
ln
[
1− 1
1 + e−µ
∏
i∈∂a
1
1 + eµhia
]
. (15)
One can estimate the single spin probability by solving
BP equations (12) and (13) as the loopy belief propaga-
tion.
IV. REPLICA-SYMMETRIC SOLUTION
In this section, typical performance of BP is studied
using the RS cavity method based on the simplest RS
ansatz. The RS ansatz assumes that cavity fields {h}
and {ĥ} are independent random variables respectively
following probability distributions P (h) and P̂ (ĥ). For
biregular random graphs, it is apparent that these dis-
tributions have no variance because of the absence of
fluctuation of degree in V1 and V2. We therefore intro-
duce the cavity fields h and ĥ on (L,R)-biregular random
graphs. Using BP equations (12) and (13), they satisfy
the following RS cavity equations in the large-N limit as
h = −κ+ (L− 1)ĥ, (16)
ĥ = − 1
µ
ln
[
1− 1
(1 + e−µ)(1 + eµh)R−1
]
. (17)
Similarly, the local fields on (L,R)-biregular random
graphs are set to ξ and ξ̂, which satisfy
ξ = −κ+ Lĥ, (18)
ξ̂ = − 1
µ
ln
[
1− 1
(1 + e−µ)(1 + eµh)R
]
. (19)
According to Eq. (7), for a given ρx, the local field ξ is
determined as
eµξ
1 + eµξ
= ρx. (20)
Then, using Eqs. (18) and (20), the appropriate param-
eter κ is represented as
κ = Lĥ− 1
µ
ln r, (21)
where r = ρx/(1− ρx).
By substituting Eqs. (16) and (21) to Eq. (17) and
by introducing x = e−µĥ, one obtains the self-consistent
equation as
(1 + rx)
R−1
(1− x) = 1
1 + e−µ
. (22)
The order of this solution changes depending on the value
of ρx. The solution x vanishes as µ becomes large if
ρx < 1/R holds. Using Taylor expansion of the left-hand
side of Eq. (22), it is estimated as
x =
e−µ
1− (R− 1)r
+O(e−2µ). (23)
Using Eq. (19), an average density of particles on V2 reads
lim
M→∞
〈
1
M
M∑
i=1
ya
〉
µ
=
1− (1 + rx)−R
1− (1 + rx)−R + e−µ
(24)
= Rρx +O(e
−µ) (25)
Taking the large-µ limit, the average cover ratio for ρx <
1/R is obtained as
ρRSy = Rρx. (26)
This relation indicates that each vertex in V2 is connected
to at most one chosen vertex in V1. However, if ρx is
larger than 1/R (R ≥ 2), then the solution x remains
constant for sufficiently large µ. In this case, a simple
solution ρRSy = 1 is obtained by Eq. (24) because the
average cover ratio in Eq. (26) touches to one at ρx =
1/R.
Before closing this section, we discuss the stability of
the RS solutions using spin-glass susceptibility defined as
χSG(µ) =
1
N +M
∑
(i,a)∈E
(〈xiya〉µ − 〈xi〉µ〈ya〉µ)2. (27)
Another representation of χSG using cavity fields is
known based on the fluctuation–dissipation theorem [25].
As shown in [26], in the case of biregular random graphs,
it reads
χSG(µ) '
∞∑
d=0
λd, λ = E
 ∑
j∈∂a\i; b∈∂j\a
(
∂ĥai
∂ĥbj
)2 ,
(28)
where E[· · · ] represents an average over vertices in V1
and random graphs. The cavity fields are mutually cor-
related in general. Actually, BP cannot converge any
more [27] if the susceptibility diverges. In this sense, the
divergence of χSG not only means the instability of the
RS solution, but also poor typical performance of BP as
an approximation algorithm. In the low-density region
where ρx < 1/R holds, it is evaluated as
λ = (L− 1)(R− 1)
[
r(1− x)
1 + rx
]2
,
→ (L− 1)(R− 1)r2 (µ→∞). (29)
The RS-RSB threshold in the large-µ limit therefore
reads
ρRSx =
1
1 +
√
(L− 1)(R− 1)
. (30)
6
Otherwise, the other threshold ρRS
′
x (> 1/R) satisfies
(L− 1)(R− 1)
[
ρRS
′
x (1− x∗)
(1− ρRS′x )(1 + x∗)
]2
= 1, (31)
where x∗ is a solution of(
1 +
ρRS
′
x
1− ρRS′x
x∗
)R−1
(1− x∗) = 1. (32)
In Fig. 2, RS-RSB thresholds ρRSx and ρ
RS′
x on (3R,R)-
regular random graphs are shown as a function of R. Ex-
cept for the case R = 1, the RS-RSB thresholds separate
RS and RSB regions. The RSB region remains for a finite
ρx while they converge to zero in the large-R limit.
0
0.2
0.4
0.6
0.8
1
1 2 3 4 5 6 7 8 9 10
RS
RSB
RS
ρ
x
R
ρRSx
ρRS
′
x
FIG. 2. RS-RSB thresholds ρRSx (squares) and ρ
RS′
x (cycles)
on (3R,R)-regular random graphs.
V. TYPICAL ANALYSIS OF GREEDY
ALGORITHM
In this section, typical behavior of the greedy algo-
rithm on (L,R)-biregular random graphs is investigated
in the low-density region of ρx < 1/R. The correspond-
ing RS solution indicates that one can choose vertices in
V1 without overlapping their neighbors. It is therefore
sufficient to analyze the fraction of vertices in V1 with
maximum degree during the deletion process. Here we
analyze a rate equation that is used frequently for analy-
ses of similar greedy algorithms [4, 28]. Let V (T ) be the
expected number of vertices with maximum degree in V1
at T -th step of the algorithm. By the definition of the
algorithm in sec. II B, we find that
NV (T + 1) = NV (T )− 1−L(R− 1) NV (T )
N −RT
+O(N−1),
(33)
where the assumption L = O(1) is used. By introducing
v(t) = V (T )/N and t = T/N , we obtain the following
differential equation in the large graph limit.
dv(t)
dt
= −1− L(R− 1)
1−Rt
v(t). (34)
Under the initial condition v(0) = 1, the solution reads
v(t) =
(L− 1)(R− 1)(1−Rt)
L(R−1)
R − (1−Rt)
LR− L−R
. (35)
Let ρgx be a threshold below which vertices with the max-
imum degree are left at the end of the algorithm. Con-
sidering that t represents a fraction of chosen vertices in
V1, we find v(ρ
g
x) = 0, that is,
ρgx =
1
R
{
1− [(L− 1)(R− 1)]−
R
LR−L−R
}
. (36)
If ρx < ρ
g
x, then no chosen vertex in V1 has overlapped
neighbors in V2 resulting in good typical performance of
the algorithm, i.e., ρgy = Rρx. However, the algorithm
typically mistakes selection of vertices in V1 and under-
estimates the average cover ratio. Results show that
ρgx ≤ ρRSx where the equality holds for R = 1, indicat-
ing that BP is better than the greedy algorithm in terms
of the typical performance threshold.
VI. ANALYSIS OF LP RELAXATION
An LP-relaxed value of the max-COV on any biregular
graph is evaluated exactly using the LP duality [29] as
follows.
Theorem 1 An LP-relaxed value of the max-COV on
any (L,R)-biregular graph is LK if K ≤ 1/R holds.
Proof. xi = K/N (1 ≤ i ≤ N), ya = RK/N (1 ≤ a ≤M)
is a feasible solution of LP-relaxed max-COV (3). The
value of the cost function is then RKM/N = LK.
The Lagrangian function of Eq. (3) is written as
L(x,y, p, q) =
M∑
a=1
ya + p
(
K −
N∑
i=1
xi
)
+
M∑
a=1
qa
(∑
i∈∂a
xi − ya
)
, (37)
where p ∈ R and q ∈ RM . Using the weak duality theo-
rem, one finds the following inequalities.
max
x,y
min
p,q
L(x,y, p, q) ≤ min
p,q
max
x,y
L(x,y, p, q)
≤ max
x,y
L(x,y, p, q). (38)
Consequently, maxx,y L(x,y, p, q) is an upper bound of
the LP-relaxed value. Because Eq. (37) is represented by
L(x,y, p, q) =
N∑
i=1
(
−p+
∑
a∈∂i
qa
)
xi+
M∑
a=1
(1−qa)ya+pK,
(39)
7
where a solution xi = ya = 1 (1 ≤ i ≤ N, 1 ≤ a ≤ M)
realizes the maximum of the function with p, q satisfying
−p+
∑
a∈∂i qa ≥ 0 and 1−qa ≥ 0(1 ≤ a ≤M). Assuming
that qa = q holds for 1 ≤ a ≤M , one finds that
max
x,y
L (x,y, p, q) = −pN +LNq+M −Mq+ pK. (40)
On the right-hand side, setting (p, q) = (M/N,K/N)
results in LK, which indicates that the upper bound of
the LP-relaxed max-COV on (L,R)-biregular graph is
LK. Because the approximate solution denoted above
achieves this bound, the LP-relaxed value is equivalent
to the bound. 
This theorem claims that ρy = Rρx (ρx ≤ 1/R), sug-
gesting that LP relaxation typically finds good approx-
imate values in the RS regime. The LP-relaxed value
is equivalent to ρRSy in the high-density regime where
ρx > 1/R.
VII. NUMERICAL RESULTS
This section presents description of some numerical
results for validation of the theoretical analyses. Here,
we set (L,R) = (9, 3) as an example. Then, the RS-
RSB threshold and the typical performance threshold of
the greedy algorithm are evaluated as ρRSx = 0.2 and
ρgx = (1 − 2−4/5)/3 = 0.1418 . . . . Biregular random
graphs are generated based on implementation of the
configuration model [30]. At least 400 random graphs
are used to take a random graph average.
A. Average cover ratio
To examine the validity of theoretical analyses on the
typical performance of approximation algorithms, the av-
erage cover ratio ρy is evaluated using several methods.
The RS estimation of average cover ratio ρRSy in the
RS regime ρx < ρ
RS
x is used as approximate values ob-
tained by BP, which has a valid relation to the RS cavity
method. The theoretical result presented in Section VI is
used for LP relaxation, which is valid for arbitrary bireg-
ular graphs. Average approximate values of the greedy
algorithm are estimated numerically with N = 103.
We also evaluate the average optimal value using the
replica exchange Monte Carlo (EMC) method [31]. Re-
sults show that single-spin flip updates of the model (4)
takes a long relaxation time for equilibration even us-
ing the exchange MC, indicating the existence of deep
valleys of the free energy. Consequently, it is necessary
to accelerate equilibration for a system with sufficiently
small chemical potential µ. To avoid such slow relax-
ation, we consider an alternative lattice–gas model on
bipartite graph G represented as
Ξ1(µ;G) =
∑
x∈{0,1}N
exp
(
µ
M∑
a=1
θ
(∑
i∈∂a
xi
))
δ
(
K,
N∑
i=1
xi
)
,
(41)
where θ(x) takes one if x > 0 and zero otherwise, and
δ(x, y) is Kronecker’s delta. In this model, variables y
are eliminated because ya = θ(
∑
i∈∂a xi) holds in the
large-µ limit. The ground states of the alternative model
therefore correspond to the optimal solutions of the max-
COV on the same graph. Moreover, single-spin flip up-
dates in the model are substantially equivalent to multi-
spin updates in the original model (4), which make the
relaxation time to equilibrium states markedly short. Be-
cause optimal values are invariant by replacing inequal-
ity constraint
∑N
i=1 xi ≤ K to equality one, the equal-
ity constraint is adopted and Kawasaki dynamics for a
density-conserved system [32] is applied.
The results are presented in Fig. 3. As predicted the-
oretically, average optimal values obtained by EMC well
agree with the estimation of BP and LP-relaxed approxi-
mate values up to the RS-RSB threshold ρRSx = 0.2. They
split above the threshold, indicating that the Bethe–
Peierls approximation and LP relaxation are no longer
appropriate. The average cover ratio by the greedy al-
gorithm is lower than the average optimal ratio higher
than the typical performance threshold ρgx predicted an-
alytically. From these observations, we confirm that
statistical–mechanical analyses of typical performance
of approximation algorithms are correct for the average
cover ratio.
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0.1 0.12 0.14 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3
ρgx ρ
RS
x
L = 9, R = 3
ρ
y
ρx
EMC (N = 200)
EMC (N = 400)
Greedy (N = 1000)
RS/LP
FIG. 3. Maximum cover ratio ρy obtained by some approxi-
mation algorithms as a function of ρx. Average optimal cover
ratios are estimated for the cardinality N = 200 and 400
by the replica exchange Monte Carlo (EMC) method and for
N = 1000 by the greedy algorithm. The solid line is the RS so-
lution, equivalent to the LP relaxed value. Two vertical lines
respectively represent the analytical performance threshold
ρgx of the greedy algorithm and the RS-RSB threshold ρ
RS
x .
8
B. Greedy algorithm and its variant
Here we examine the greedy algorithm more closely.
To validate the correctness of our analysis, we specifi-
cally examine a fraction of selected vertices without the
maximum degree. The value rg is evaluated by
rg = 1−
ρgx
ρx
, (42)
where ρgx is given as Eq. (36). The algorithm finds an
optimal solution of the problem if rg = 0. As depicted
in Fig. 4, the analytical estimations of rg averaged over
biregular random graphs agree well with the numerical
results. The fraction arises at ρgx corresponding to the
typical performance threshold.
Additionally, we modify the greedy algorithm to re-
duce the gap of its typical performance to that of BP.
As suggested above, the reason lies in the point that the
greedy algorithm often chooses wrong vertices leading to
shortage of vertices with maximum degree. To avoid the
situation, one must select a vertex to preserve as many
vertices to a maximum degree as possible, meaning that
the optimal selection requires an exhaustive search. We
therefore propose a modified algorithm in consideration
of the influence of the selection on other vertices in V1,
the simplest improved algorithm toward the optimal se-
lection. Let ∂2i = {j ∈ V1\i | j ∈ ∂a (∀a ∈ ∂i)} be a set
of the second neighbors of vertex i ∈ V1. We also define
the subset of vertices with the maximum degree in V1 by
W1. The modified greedy algorithm is given as follows:
at each step, (i) choose vertex named i ∈ W1 so that
|∂2i ∩W1| is minimized, (ii) delete vertices neighboring
to vertex i from V2, and (iii) update W1 and V1 and re-
turn to (i) if |V1| > N − K. In Fig. 4, the fraction rg
of the modified algorithm is also shown with that of the
original greedy algorithm. As shown in Fig. 4, the typ-
ical performance threshold of the proposed algorithm is
improved, although it is still below the RS-RSB thresh-
old. This fact suggests that the typical performance of
greedy algorithms depends of approximate choices and
BP selects vertices better than those greedy selections.
C. Randomized rounding of LP relaxation
In Sec. VII A, we examine the typical performance of
LP relaxation in terms of its approximate value. In this
subsection, randomized rounding, a practical means of
constructing a feasible integer solution from LP relax-
ation, is applied to LP-relaxed solutions. It is notewor-
thy that the typical performance of randomized rounding
probably depends on the selection of an LP solver and its
setting. Here, we use IBM ILOG CPLEX with a default
setting. The approximate value of the rounded solution
is compared to that of the RS solution in the RS phase,
which is LK. One considers that the rounding finds an
optimal integer solution of the problem if two estimates
0
0.05
0.1
0.15
0.2
0.25
0.3
0.1 0.12 0.14 0.16 0.18 0.2
ρgx
L = 9, R = 3
r g
ρx
Greedy (N = 1000)
Greedy (N = 5000)
Theory
Modified (N = 1000)
Modified (N = 5000)
FIG. 4. Fraction rg of selected vertices without maximum
degree until the greedy algorithm stops as a function of ρx.
Symbols represent numerical results of the greedy algorithm
with cardinality N = 1000 (squares) and 5000 (circles) and
modified one with N = 1000 (cross marks) and 5000 (stars).
The solid line exhibits the analytical estimation of the fraction
rg.
mutually coincide. We define a success ratio pr by the
fraction of random graphs on which the rounding finds an
optimal solution. Fig. 5 presents the average approxima-
tion ratio ρry and the success ratio pr as a function of ρx,
which strongly suggests that the randomized rounding
exhibits a phase transition in terms of its typical perfor-
mance. The threshold ρrx is less than 0.1, which is much
lower than ρgx, whereas the LP-relaxed value is regarded
as nearly optimal in the RS region ρx < ρ
RS
x = 0.2. We
therefore conclude that the typical performance of the
randomized rounding of LP-relaxed solution is inferior
to that of the greedy algorithm.
VIII. SUMMARY AND DISCUSSION
As described in this paper, we investigate the typi-
cal performance of approximation algorithms called belief
propagation, greedy algorithm, and linear-programming
relaxation for maximum coverage problem on sparse
biregular random graphs. The typical performance of
BP is studied by application of the RS cavity method
to a correspondent hard-core lattice–gas model. Re-
sults show that, in the large-µ limit, there exist two dis-
tinct RS-RSB thresholds regarded as typical performance
thresholds of BP. In addition, the greedy algorithm per-
formance and LP relaxation were studied especially in
the low-density region. Results show that the typical
performance threshold of the greedy algorithm is lower
than that of BP and that LP-relaxed values are always
equivalent to the RS solutions leading to the threshold
equivalent to that of BP. Those analytical results were
validated by executing some numerical simulations. Re-
sults of additional numerical studies suggest that BP typ-
9
0
0.1
0.2
0.3
0.4
0.5
0.6
0 0.02 0.04 0.06 0.08 0.1 0.12
0
0.2
0.4
0.6
0.8
1
L = 9, R = 3
ρ
y p r
ρx
ρry (N = 1000)
ρry (N = 5000)
ρLPy
pr (N = 1000)
pr (N = 5000)
FIG. 5. Typical performance of randomized rounding of LP
relaxation as a function of ρx (left vertical axis). Symbols
represent approximation values ρry of rounded LP-relaxed so-
lutions with cardinality N = 1000 (squares) and 5000 (cross
marks). The solid line represents the average cover ratio
equivalent to that of LP relaxation in the region shown.
Squares and stars respectively represent the success ratio pr
(right vertical axis) of randomized rounding with N = 1000
and 5000.
ically works better than the modified greedy algorithm
and that randomized rounding of LP-relaxed solutions
has a lower threshold than the greedy algorithm.
To assess the typical performance of BP as an ap-
proximation algorithm, we concentrated on statistical–
mechanical analysis of max-COV up to the RS level.
Further analyses based on the one step RSB will be nec-
essary to reveal statistical–mechanical properties of the
problem and typical performance analysis of another al-
gorithm called survey propagation. Another possible av-
enue of future work is the extension of our analyses to
other random bipartite graphs. As with min-VCs, it is
an attractive question whether the magnitude relation of
typical performance thresholds changes depending on the
random graph ensembles.
Our results provide not only respective typical perfor-
mance of approximation algorithms but also their sug-
gestive mutual relations. Specifically examining LP re-
laxation, it is worth emphasizing that the LP relaxation
finds good approximate values compared to optimal val-
ues but the typical performance of its randomized round-
ing has the smallest threshold among approximation al-
gorithms studied here. To fill the gap of thresholds, it
is important to examine modifications of LP relaxation
such as the cutting-plane approach [33]. As for the greedy
algorithms and their modification, numerical results sug-
gest that evaluation of the influence of their deletion pro-
cess affects the marked improvement of the typical per-
formance threshold. The fact that BP is better than the
greedy algorithm and its modification indicates that BP
incorporates the influence more efficiently. These sug-
gestions are expected to be of great help to understand
properties and relations of approximation algorithms in
terms of typical performance. In addition, our analy-
ses of the greedy algorithm and randomized rounding of
LP relaxation illustrate that typical case and worst case
evaluations capture different notions of approximate per-
formance in optimization problems. This fact indicates
the importance of the typical-case analysis of approxi-
mation algorithms. We hope that the arguments and re-
sults presented herein stimulate further studies and that
the typical performance analyses of approximation algo-
rithms will attract the interest of researchers in many
diverse fields.
ST warmly thanks T. Takaguchi for stimulating this
study. The use of IBM ILOG CPLEX has been sup-
ported by the IBM Academic Initiative. This research
was supported by JSPS KAKENHI Grant Nos. 25120010
(KH), 16K16011 (TM), and 15J09001 (ST).
[1] V. V. Vazirani, Approximation Algorithms (Springer
Berlin Heidelberg, Berlin, Heidelberg, 2003).
[2] R. Monasson, R. Zecchina, S. Kirkpatrick, B. Selman,
and L. Troyanskyk, Nature 400, 133 (1999).
[3] M. Mézard, F. Ricci-Tersenghi, and R. Zecchina, Journal
of Statistical Physics 111 (2003).
[4] R. M. Karp and M. Sipser, in 22nd Annual Symposium
on Foundations of Computer Science (sfcs 1981) (IEEE,
1981) pp. 364–375.
[5] M. Weigt and A. K. Hartmann, Physical review letters
84, 6118 (2000).
[6] M. Weigt and H. Zhou, Physical Review E 74, 046110
(2006).
[7] M. Bauer and O. Golinelli, The European Physical Jour-
nal B - Condensed Matter 352, 339 (2001).
[8] T. Dewenter and A. K. Hartmann, Physical Review E
86, 041128 (2012).
[9] S. Takabe and K. Hukushima, Journal of the Physical
Society of Japan 83, 043801 (2014).
[10] S. Takabe and K. Hukushima, Journal of Statistical Me-
chanics: Theory and Experiment 2016, 113401 (2016).
[11] Y.-Y. Liu, E. Csóka, H. Zhou, and M. Pósfai, Physical
Review Letters 109, 205703 (2012).
[12] S. Takabe and K. Hukushima, Physical Review E 89,
062139 (2014).
[13] C. Lucibello and F. Ricci-Tersenghi, International Jour-
nal of Statistical Mechanics 2014, 1 (2014).
[14] Y. Habibulla, J.-H. Zhao, and H.-J. Zhou, in Interna-
tional Workshop on Frontiers in Algorithmics. (Springer
International Publishing., 2015) pp. 78–88.
[15] H. Schawe and A. K. Hartmann, EPL (Europhysics Let-
ters) 113, 30004 (2016).
[16] S. Takabe and K. Hukushima, Physical Review E 93,
053308 (2016).
[17] A. Javanmard, A. Montanari, and F. Ricci-Tersenghi,
Proceedings of the National Academy of Sciences (2015).
10
[18] M. P. Johnson and A. Bar-Noy, Proceedings - IEEE IN-
FOCOM , 1071 (2011).
[19] B. Saha and L. Getoor, in Ninth SIAM International
Conference on Data Mining (Society for Industrial and
Applied Mathematics, Philadelphia, PA, 2009) pp. 697–
708.
[20] H. Takamura and M. Okumura, in Proc. Conf. of the
European Chapter of the Association for Computational
Linguistics (EACL) (2009) pp. 781–789.
[21] M. Mézard and A. Montanari, Information, Physics, and
Computation (Oxford University Press, 2009) p. 560.
[22] G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher, Math-
ematical Programming 14, 265 (1978).
[23] U. Feige, Journal of the ACM 45, 634 (1998).
[24] P. Raghavan and C. D. Tompson, Combinatorica 7, 365
(1987).
[25] O. Rivoire, G. Biroli, O. C. Martin, and M. Mézard, The
European Physical Journal B - Condensed Matter 37, 55
(2003).
[26] M. Mézard and M. Tarzia, Physical Review E 76, 041124
(2007).
[27] L. Zdeborová, Acta Physica Slovaca. Reviews and Tuto-
rials 59, 169 (2009).
[28] M. Weigt, The European Physical Journal B - Condensed
Matter 28, 369 (2002).
[29] R. T. Rockafellar, Convex Analysis (Princeton University
Press, 1972).
[30] M. E. J. Newman, S. H. Strogatz, and D. J. Watts,
Physical Review E 64, 026118 (2001).
[31] K. Hukushima and K. Nemoto, Journal of the Physical
Society of Japan 65, 1604 (1996).
[32] K. Kawasaki, Physical Review 145, 224 (1966).
[33] A. Schrijver, Theory of linear and integer programming
(John Wiley & Sons Ltd,, West Sussex, 1998).

