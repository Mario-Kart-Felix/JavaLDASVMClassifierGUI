712 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 11, NO. 6, DECEMBER 2007
MOEA/D: A Multiobjective Evolutionary Algorithm
Based on Decomposition
Qingfu Zhang, Senior Member, IEEE, and Hui Li
Abstract—Decomposition is a basic strategy in traditional mul-
tiobjective optimization. However, it has not yet been widely used
in multiobjective evolutionary optimization. This paper proposes
a multiobjective evolutionary algorithm based on decomposition
(MOEA/D). It decomposes a multiobjective optimization problem
into a number of scalar optimization subproblems and optimizes
them simultaneously. Each subproblem is optimized by only
using information from its several neighboring subproblems,
which makes MOEA/D have lower computational complexity at
each generation than MOGLS and nondominated sorting genetic
algorithm II (NSGA-II). Experimental results have demonstrated
that MOEA/D with simple decomposition methods outperforms
or performs similarly to MOGLS and NSGA-II on multiobjective
0–1 knapsack problems and continuous multiobjective optimiza-
tion problems. It has been shown that MOEA/D using objective
normalization can deal with disparately-scaled objectives, and
MOEA/D with an advanced decomposition method can generate
a set of very evenly distributed solutions for 3-objective test
instances. The ability of MOEA/D with small population, the scal-
ability and sensitivity of MOEA/D have also been experimentally
investigated in this paper.
Index Terms—Computational complexity, decomposition, evolu-
tionary algorithm, multiobjective optimization, Pareto optimality.
I. INTRODUCTION
Amultiobjective optimization problem (MOP) can be statedas follows:
(1)
where is the decision (variable) space, consists
of real-valued objective functions and is called the ob-
jective space. The attainable objective set is defined as the set
.
If , all the objectives are continuous and is de-
scribed by
where are continuous functions, we call (1) a continuous
MOP.
Very often, since the objectives in (1) contradict each other,
no point in maximizes all the objectives simultaneously. One
has to balance them. The best tradeoffs among the objectives
can be defined in terms of Pareto optimality.
Manuscript received September 4, 2006; revised November 9, 2006.
The authors are with the Department of Computer Science, University
of Essex, Wivenhoe Park, Colchester, CO4 3SQ, U.K. (e-mail: qzhang@
essex.ac.uk; hlil@essex.ac.uk).
Digital Object Identifier 10.1109/TEVC.2007.892759
Let , is said to dominate if and only if
for every and for at least one index
.1 A point is Pareto optimal to (1) if
there is no point such that dominates .
is then called a Pareto optimal (objective) vector. In other words,
any improvement in a Pareto optimal point in one objective must
lead to deterioration in at least one other objective. The set of
all the Pareto optimal points is called the Pareto set (PS) and the
set of all the Pareto optimal objective vectors is the Pareto front
(PF) [1].
In many real-life applications of multiobjective optimization,
an approximation to the PF is required by a decision maker
for selecting a final preferred solution. Most MOPs may have
many or even infinite Pareto optimal vectors. It is very time-con-
suming, if not impossible, to obtain the complete PF. On the
other hand, the decision maker may not be interested in having
an unduly large number of Pareto optimal vectors to deal with
due to overflow of information. Therefore, many multiobjec-
tive optimization algorithms are to find a manageable number
of Pareto optimal vectors which are evenly distributed along the
PF, and thus good representatives of the entire PF [1]–[4]. Some
researchers have also made an effort to approximate the PF by
using a mathematical model [5]–[8].
It is well-known that a Pareto optimal solution to a MOP,
under mild conditions, could be an optimal solution of a scalar
optimization problem in which the objective is an aggregation of
all the ’s. Therefore, approximation of the PF can be decom-
posed into a number of scalar objective optimization subprob-
lems. This is a basic idea behind many traditional mathemat-
ical programming methods for approximating the PF. Several
methods for constructing aggregation functions can be found in
the literature (e.g., [1]). The most popular ones among them in-
clude the weighted sum approach and Tchebycheff approach.
Recently, the boundary intersection methods have also attracted
a lot of attention [9]–[11].
There is no decomposition involved in the majority of the
current state-of-the-art multiobjective evolutionary algorithms
(MOEAs) [2]–[4], [12]–[19]. These algorithms treat a MOP as
a whole. They do not associate each individual solution with
any particular scalar optimization problem. In a scalar objective
optimization problem, all the solutions can be compared based
on their objective function values and the task of a scalar ob-
jective evolutionary algorithm (EA) is often to find one single
optimal solution. In MOPs, however, domination does not
define a complete ordering among the solutions in the objective
space and MOEAs aim at producing a number of Pareto op-
timal solutions as diverse as possible for representing the whole
PF. Therefore, conventional selection operators, which were
1This definition of domination is for maximization. All the inequalities should
be reversed if the goal is to minimize the objectives in (1). “Dominate” means
“be better than.”
1089-778X/$25.00 © 2007 IEEE
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
ZHANG AND LI: MOEA/D: A MULTIOBJECTIVE EVOLUTIONARY ALGORITHM BASED ON DECOMPOSITION 713
originally designed for scalar optimization, cannot be directly
used in nondecomposition MOEAs. Arguably, if there is a
fitness assignment scheme for assigning an individual solution
a relative fitness value to reflect its utility for selection, then
scalar optimization EAs can be readily extended for dealing
with MOPs, although other techniques such as mating restric-
tion [20], diversity maintaining [21], some properties of MOPs
[22], and external populations [23] may also be needed for
enhancing the performances of these extended algorithms. For
this reason, fitness assignment has been a major issue in current
MOEA research. The popular fitness assignment strategies
include alternating objectives-based fitness assignment such
as the vector evaluation genetic algorithm (VEGA) [24], and
domination-based fitness assignment such as Pareto archived
evolutionary strategy (PAES) [14], strength Pareto evolutionary
algorithm II (SPEA-II) [15], and nondominated sorting genetic
algorithm II (NSGA-II) [16].
The idea of decomposition has been used to a certain extent
in several metaheuristics for MOPs [25]–[29]. For example, the
two-phase local search (TPLS) [25] considers a set of scalar op-
timization problems, in which the objectives are aggregations
of the objectives in the MOP under consideration, a scalar opti-
mization algorithm is applied to these scalar optimization prob-
lems in a sequence based on aggregation coefficients, a solution
obtained in the previous problem is set as a starting point for
solving the next problem since its aggregation objective is just
slightly different from that in the previous one. The multiob-
jective genetic local search (MOGLS) aims at simultaneous op-
timization of all aggregations constructed by the weighted sum
approach or Tchebycheff approach [29]. At each iteration, it op-
timizes a randomly generated aggregation objective.
In this paper, we propose a new multiobjective evolutionary al-
gorithm based on decomposition (MOEA/D). MOEA/D explic-
itlydecomposes theMOP(1) into scalaroptimizationsubprob-
lems. It solves these subproblems simultaneously by evolving
a population of solutions. At each generation, the population is
composed of the best solution found so far (i.e. since the start of
the run of the algorithm) for each subproblem. The neighborhood
relations among these subproblems are defined based on the dis-
tances between their aggregation coefficient vectors. The optimal
solutions to twoneighboringsubproblemsshouldbeverysimilar.
Each subproblem (i.e., scalar aggregation function) is optimized
in MOEA/D by using information only from its neighboring sub-
problems. MOEA/D has the following features.
• MOEA/D provides a simple yet efficient way of intro-
ducing decomposition approaches into multiobjective evo-
lutionary computation. A decomposition approach, often
developed in the community of mathematical program-
ming, can be readily incorporated into EAs in the frame-
work MOEA/D for solving MOPs.
• Since MOEA/D optimizes scalar optimization problems
rather than directly solving a MOP as a whole, issues such
as fitness assignment and diversity maintenance that cause
difficulties for nondecomposition MOEAS could become
easier to handle in the framework of MOEA/D.
• MOEA/D has lower computational complexity at each
generation than NSGA-II and MOGLS. Overall, MOEA/D
outperforms, in terms of solution quality, MOGLS on 0–1
multiobjective knapsack test instances when both algo-
rithms use the same decomposition approach. MOEA/D
with the Tchebycheff decomposition approach performs
similarly to NSGA-II on a set of continuous MOP test
instances. MOEA/D with an advanced decomposition
approach performs much better than NSGA-II on 3-ob-
jective continuous test instances. MOEA/D using a small
population is able to produce a small number of very
evenly distributed solutions.
• Objective normalization techniques can be incorporated
into MOEA/D for dealing with disparately scaled objec-
tives.
• It is very natural to use scalar optimization methods in
MOEA/D since each solution is associated with a scalar
optimization problem. In contrast, one of the major short-
comings of nondecomposition MOEAs is that there is no
easy way for them to take the advantage of scalar optimiza-
tion methods.
This paper is organized as follows. Section II introduces
three decomposition approaches for MOPs. Section III presents
MOEA/D. Sections IV and V compare MOEA/D with MOGLS
and NSGA-II and show that MOEA/D outperforms or performs
similarly to MOGLS and NSGA-II. Section VI presents more
experimental studies on MOEA/D. Section VII concludes this
paper.
II. DECOMPOSITION OF MULTIOBJECTIVE OPTIMIZATION
There are several approaches for converting the problem of
approximation of the PF into a number of scalar optimization
problems. In the following, we introduce three approaches,
which are used in our experimental studies.
A. Weighted Sum Approach [1]
This approach considers a convex combination of the dif-
ferent objectives. Let be a weight vector,
i.e., for all and . Then, the
optimal solution to the following scalar optimization problem:
(2)
is a Pareto optimal point to (1),2 where we use to em-
phasize that is a coefficient vector in this objective function,
while is the variables to be optimized. To generate a set of
different Pareto optimal vectors, one can use different weight
vectors in the above scalar optimization problem. If the PF
is concave (convex in the case of minimization), this approach
could work well. However, not every Pareto optimal vector can
be obtained by this approach in the case of nonconcave PFs.
To overcome these shortcomings, some effort has been made to
incorporate other techniques such as -constraint into this ap-
proach, more details can be found in [1].
B. Tchebycheff Approach [1]
In this approach, the scalar optimization problem is in the
form
(3)
where is the reference point, i.e.,
3 for each . For each Pareto
2If (1) is for minimization, “maximize” in (2) should be changed to “mini-
mize.”
3In the case when the goal of (1) is minimization, z = minff (x)jx 2 
g.
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
714 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 11, NO. 6, DECEMBER 2007
optimal point there exists a weight vector such that
is the optimal solution of (3) and each optimal solution of (3)
is a Pareto optimal solution of (1). Therefore, one is able to
obtain different Pareto optimal solutions by altering the weight
vector. One weakness with this approach is that its aggregation
function is not smooth for a continuous MOP. However, it can
still be used in the EA framework proposed in this paper since
our algorithm does not need to compute the derivative of the
aggregation function.
C. Boundary Intersection (BI) Approach
Several recent MOP decomposition methods such as
Normal-Boundary Intersection Method [9] and Normalized
Normal Constraint Method [10] can be classified as the BI
approaches. They were designed for a continuous MOP. Under
some regularity conditions, the PF of a continuous MOP is part
of the most top right4 boundary of its attainable objective set.
Geometrically, these BI approaches aim to find intersection
points of the most top boundary and a set of lines. If these
lines are evenly distributed in a sense, one can expect that the
resultant intersection points provide a good approximation to
the whole PF. These approaches are able to deal with noncon-
cave PFs. In this paper, we use a set of lines emanating from
the reference point. Mathematically, we consider the following
scalar optimization subproblem5:
(4)
where and , as in the above subsection, are a weight vector
and the reference point, respectively. As illustrated in Fig. 1, the
constraint ensures that is always in ,
the line with direction and passing through . The goal is to
push as high as possible so that it reaches the boundary of
the attainable objective set.
One of the drawbacks of the above approach is that it has to
handle the equality constraint. In our implementation, we use a
penalty method to deal with the constraint. More precisely, we
consider6:
(5)
where
is a preset penalty parameter. Let be the projection of
on the line . As shown in Fig. 2, is the distance be-
tween and . is the distance between and . If is set
appropriately, the solutions to (4) and (5) should be very close.
Hereafter, we call this method the penalty-based boundary in-
tersection (PBI) approach.
The advantages of the PBI approach (or general BI ap-
proaches ) over the the Tchebycheff approach are as follows.
4In the case of minimization, it will be part of the most left bottom.
5In the case when the goal of (1) is minimization, this equality constraint in
this subproblem should be changed to F (x)  z = d.
6In the case when the goal of (1) is minimization, d =
k(F (x)  z ) k=kk and to d = kF (x)  (z + d )k.
Fig. 1. Illustration of boundary intersection approach.
Fig. 2. Illustration of the penalty-based boundary intersection approach.
• In the case of more than two objectives, let both the PBI
approach and the Tchebycheff approach use the same set
of evenly distributed weight vectors, the resultant optimal
solutions in the PBI should be much more uniformly dis-
tributed than those obtained by the Tchebycheff approach
[9], particularly when the number of weight vectors is not
large.
• If dominates , it is still possible that
, while it is rare for and other BI aggrega-
tion functions.
However, these benefits come with a price. One has to set the
value of the penalty factor. It is well-known that a too large
or too small penalty factor will worsen the performance of a
penalty method.
The above approaches can be used to decompose the approxi-
mation of the PF into a number of scalar optimization problems.
A reasonably large number of evenly distributed weight vectors
usually leads to a set of Pareto optimal vectors, which may not
be evenly spread but could approximate the PF very well.
There are many other decomposition approaches in the liter-
ature that could also be used in our algorithm framework. Since
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
ZHANG AND LI: MOEA/D: A MULTIOBJECTIVE EVOLUTIONARY ALGORITHM BASED ON DECOMPOSITION 715
our major purpose is to study the feasibility and efficiency of the
algorithm framework. We only use the above three decomposi-
tion approaches in the experimental studies in this paper.
III. THE FRAMEWORK OF MULTIOBJECTIVE EVOLUTIONARY
ALGORITHM BASED ON DECOMPOSITION (MOEA/D)
A. General Framework
Multiobjective evolutionary algorithm based on decomposi-
tion (MOEA/D), the algorithm proposed in this paper, needs to
decompose the MOP under consideration. Any decomposition
approaches can serve this purpose. In the following description,
we suppose that the Tchebycheff approach is employed. It is
very trivial to modify the following MOEA/D when other de-
composition methods are used.
Let be a set of even spread weight vectors and
be the reference point. As shown in Section II, the problem of
approximation of the PF of (1) can be decomposed into scalar
optimization subproblems by using the Tchebycheff approach
and the objective function of the th subproblem is
(6)
where . MOEA/D minimizes all these
objective functions simultaneously in a single run.
Note that is continuous of , the optimal solution of
should be close to that of if and
are close to each other. Therefore, any information about
these ’s with weight vectors close to should be helpful
for optimizing . This is a major motivation behind
MOEA/D.
In MOEA/D, a neighborhood of weight vector is defined
as a set of its several closest weight vectors in .
The neighborhood of the th subproblem consists of all the sub-
problems with the weight vectors from the neighborhood of .
The population is composed of the best solution found so far
for each subproblem. Only the current solutions to its neigh-
boring subproblems are exploited for optimizing a subproblem
in MOEA/D.
At each generation , MOEA/D with the Tchebycheff ap-
proach maintains:
• a population of points , where is the
current solution to the th subproblem;
• , where is the -value of , i.e.,
for each ;
• , where is the best value found so far
for objective ;
• an external population (EP), which is used to store non-
dominated solutions found during the search.
The algorithm works as follows:
Input:
• MOP (1);
• a stopping criterion;
• : the number of the subproblems considered in
MOEA/D;
• a uniform spread of weight vectors: ;
• : the number of the weight vectors in the neighborhood
of each weight vector.
Output: .
Step 1) Initialization:
Step 1.1) Set .
Step 1.2) Compute the Euclidean distances between any
two weight vectors and then work out the closest weight
vectors to each weight vector. For each , set
, where are the closest
weight vectors to .
Step 1.3) Generate an initial population
randomly or by a problem-specific method. Set
.
Step 1.4) Initialize by a problem-specific
method.
Step 2) Update:
For , do
Step 2.1) Reproduction: Randomly select two indexes
from , and then generate a new solution from and
by using genetic operators.
Step 2.2) Improvement: Apply a problem-specific repair/
improvement heuristic on to produce .
Step 2.3) Update of : For each , if
, then set .
Step 2.4) Update of Neighboring Solutions: For each index
, if , then set
and .
Step 2.5) Update of :
Remove from all the vectors dominated by .
Add to if no vectors in dominate .
Step 3) Stopping Criteria: If stopping criteria is satisfied,
then stop and output . Otherwise, go to Step 2.
In initialization, contains the indexes of the closest
vectors of . We use the Euclidean distance to measure the
closeness between any two weight vectors. Therefore, ’s
closest vector is itself, and then . If , the
th subproblem can be regarded as a neighbor of the th sub-
problem.
In the th pass of the loop in Step 2, the neighboring sub-
problems of the th subproblem are considered. Since and
in Step 2.1 are the current best solutions to neighbors of the
th subproblem, their offspring should hopefully be a good
solution to the th subproblem. In Step 2.2, a problem-specific
heuristic7 is used to repair in the case when invalidates any
constraints, and/or optimize the th . Therefore, the resultant
solution is feasible and very likely to have a lower function
value for the neighbors of th subproblem. Step 2.4 considers all
the neighbors of the th subproblem, it replaces with if
performs better than with regard to the th subproblem.
is needed in computing the value of in Step 2.4.
Since it is often very time-consuming to find the exact ref-
erence point , we use , which is initialized in Step 1.4 by a
7An exemplary heuristic can be found in the implementation of MOEA/D for
the MOKP in Section IV.
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
716 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 11, NO. 6, DECEMBER 2007
problem-specific method8 and updated in Step 2.3, as a substi-
tute for in . The external population , initialized in Step
1.1, is updated by the new generated solution in Step 2.5.
In the case when the goal in (1) is to minimize , the
inequality in Step 2.3 should be reversed.
B. Discussions
1) Why a Finite Number of Subproblems are Considered in
MOEA/D: A weight vector used in MOEA/D is one of the
preselected weight vectors. MOEA/D spends about the same
amount of effort on each of the aggregation functions, while
MOGLS randomly generates a weight vector at each iteration,
aiming at optimizing all the possible aggregation functions. Re-
call that a decision maker only needs a finite number of evenly
distributed Pareto solutions, optimizing a finite of selected
scalar optimization subproblems is not only realistic but also
appropriate. Since the computational resource is always limited,
optimizing all the possible aggregation functions would not be
very practical, and thus may waste some computational effort.
2) How Diversity is Maintained in MOEA/D: As mentioned
in Section I, a MOEA needs to maintain diversity in its pop-
ulation for producing a set of representative solutions. Most,
if not all, of nondecomposition MOEAs such as NSGA-II and
SPEA-II use crowding distances among the solutions in their
selection to maintain diversity. However, it is not always easy
to generate a uniform distribution of Pareto optimal objective
vectors in these algorithms. In MOEA/D, a MOP is decom-
posed into a number of scalar optimization subproblems. Dif-
ferent solutions in the current population are associated with
different subproblems. The “diversity” among these subprob-
lems will naturally lead to diversity in the population. When
the decomposition method and the weight vectors are properly
chosen, and thus the optimal solutions to the resultant subprob-
lems are evenly distributed along the PF, MOEA/D will have a
good chance of producing a uniform distribution of Pareto so-
lutions if it optimizes all these subproblems very well.
3) Mating Restriction and the Role of in MOEA/D: is
the size of the neighborhood. Only current solutions to the
closest neighbors of a subproblem are used for optimizing it
in MOEA/D. In a sense, two solutions have a chance to mate
only when they are for two neighboring subproblems. This is a
mating restriction. Attention should be paid to the setting of . If
is too small, two solutions chosen ( and ) for undergoing
genetic operators in Step 2.1 may be very similar since they
are for very similar subproblems, consequently, , the solution
generated in Step 2.2, could be very close to their parents
and . Therefore, the algorithm lacks the ability to explore new
areas in the search space. On the other hand, if is too large,
and may be poor for the subproblem under consideration, and
so is their offspring . Therefore, the exploitation ability of the
algorithm is weakened. Moreover, a too large will increase
the computational overhead of Step 2.4.
C. Variants of MOEA/D
We can use any other decomposition methods in MOEA/D.
When the weighted sum approach is used, MOEA/D does not
need to maintain .
8Two exemplary methods can be found in Sections IV and V.
Step 2.2 allows MOEA/D to be able to make use of a
scalar optimization method very naturally. One can take the
or as the objective function in the
heuristic in Step 2.2. Although it is one of the major features
of MOEA/D, Step 2.2 is not a must in MOEA/D, particularly if
Step 2.1 can produce a feasible solution.
Using the external population is also an option, although
it is often very helpful for improving the performance of the
algorithm. An alternative is to return the final internal popula-
tion as an approximation to the PF when is not maintained.
Of course, other sophisticated strategies [21] for updating
can be easily adopted in the framework of MOEA/D. One can
also limit the size of to avoid any possible memory overflow
problem.
The cellular multiobjective genetic algorithm (cMOGA)
of Murata et al. [40] can also be regarded as an evolutionary
algorithm using decomposition. In essence it uses the same
neighborhood relationship for mating restriction. cMOGA
differs from MOEA/D in selecting solutions for genetic oper-
ators and updating the internal population, and it has to insert
solutions from its external population to its internal population
at each generation for dealing with nonconvex PFs, since it
uses weighted sums of the objectives as its guided functions
and there is no mechanism for keeping the best solution found
so far to each subproblem in its internal population.
IV. COMPARISON WITH MOGLS
In the following, we first introduce MOGLS and then analyze
the complexity of MOGLS and MOEA/D. We also compare the
performances of these two algorithms on a set of test instances
of the multiobjective 0/1 knapsack problem. The major reasons
for choosing MOGLS for comparison are that it is also based
on decomposition and performs better than a number of popular
algorithms on the multiobjective 0/1 knapsack problem [29].
A. MOGLS
MOGLS was first proposed by Ishibuchi and Murata in [28],
and further improved by Jaszkiewicz [29]. The basic idea is to
reformulate the MOP (1) as simultaneous optimization of all
weighted Tchebycheff functions or all weighted sum functions.
In the following, we give a brief description of Jaszkiewicz’s
version of MOGLS.
At each iteration, MOGLS maintains:
• a set of current solutions (CS), and the -values of these
solutions;
• an external population (EP), which is used to store non-
dominated solutions.
If MOGLS optimizes weighted Tchebycheff functions, it
should also maintain:
• , where is the largest value found so
far for objective .
MOGLS needs two control parameters and . is the size
of its temporary elite population and is the initial size of .
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
ZHANG AND LI: MOEA/D: A MULTIOBJECTIVE EVOLUTIONARY ALGORITHM BASED ON DECOMPOSITION 717
MOGLS works as follows:
Input:
• MOP (1);
• a stopping criterion;
• : the size of temporary elite population;
• : the size of initial population.
Output: .
Step 1) Initialization:
Step 1.1) Generate initial solutions randomly
or by a problem-specific method. Then, is initialized to
be .
Step 1.2) Initialize by a problem-specific
method.
Step 1.3) is initialized to be the set of the -values of
all the nondominated solutions in .
Step 2) Update:
Step 2.1) Reproduction:
Uniformly randomly generate a weight vector .
From select the best solutions, with regard to the
Tchebycheff aggregation function with the weight vector
, to form a temporary elite population (TEP).
Draw at random two solutions from , and then generate
a new solution from these two solutions by using genetic
operators.
Step 2.2) Improvement: Apply a problem-specific repair/
improvement heuristic on to generate .
Step 2.3) Update of : For each , if
, then set .
Step 2.4) Update of Solutions in TEP:
If is better than the worst solution in with regard to
with the weight vector and different from any solutions
in with regard to -values, then add it to the set .
If the size of is larger than , delete the oldest
solution in .
Step 2.5) Update of EP:
Remove from all the vectors dominated by .
Add to if no vectors in dominates .
Step 3) Stopping Criteria: If stopping criteria is satisfied,
then stop and output . Otherwise, go to Step 2.
As in MOEA/D with the Tchebycheff approach, is used
as a substitute for in . In the case of MOGLS with the
weighted sum approach, should be replaced by and there
is no need to store . Therefore, Step 2.3 should be removed.
MOGLS needs to keep the -values of all the current solutions
since these -values will be used in Step 2.4 for computing the
values of .
B. Comparison of Complexity of MOEA/D and MOGLS
1) Space Complexity: During the search, MOEA/D needs
to maintain its internal population of solutions, and external
population , while MOGLS stores the set of current solutions
and its external population . The size of increases
until it reaches its upper bound, which is suggested to be set as
in [29]. Therefore, if in MOGLS is much larger
than in MOEA/D and both algorithms produce about the
same number of nondominated solutions, then the space com-
plexity of MOEA/D is lower than that of MOGLS.
2) Computational Complexity: The major computational
costs in both MOEA/D and MOGLS are involved in their
Step 2. Both a single pass of Step 2 in MOEA/D and Step 2 in
MOGLS generates one new trial solution . Let us compare
the computational complexity in a single pass of Step 2 in
MOEA/D and Step 2 in MOGLS.
• Step 2.1 in MOEA/D versus Step 2.1 in MOGLS: MOGLS
has to generate . One has to compute the -values
of all the points in , which needs basic
operations. It also needs basic operations for
selecting if a naive selection method is employed,
while Step 2.1 in MOEA/D only needs to randomly pick
two solutions for genetic operators. Note that , the size
of , could be very large (e.g, it was set from 3000 to 7000
in [29]), the computational cost of Step 2.1 in MOGLS is
much higher than that of Step 2.1 in MOEA/D.
• Steps 2.2 and 2.3 in MOEA/D are the same as Steps 2.2
and 2.3 in MOGLS, respectively.
• Step 2.4 in MOEA/D versus Step 2.4 in MOGLS: Step 2.4
in MOEA/D needs basic operations, while Step 2.4
in MOGLS needs basic operations. In the case when
and are close as in our experiments, there is no sig-
nificant difference in computational costs between them.
Therefore, we can conclude that each pass of Step 2 in
MOEA/D involves less computational cost than Step 2 in
MOGLS does.
C. Multiobjective 0–1 Knapsack Problem
Given a set of items and a set of knapsacks, the multiob-
jective 0–1 knapsack problem (MOKP) can be stated as
(7)
where is the profit of item in knapsack ,
is the weight of item in knapsack , and is the capacity of
knapsack . means that item is selected and put in all
the knapsacks.
The MOKP is NP-hard and can model a variety of applica-
tions in resource allocation. A set of nine test instances of the
above problem have been proposed in [13] and widely used
in testing multiobjective heuristics. MOGLS outperforms a
number of MOEAs on these test instances [29]. In this paper,
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
718 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 11, NO. 6, DECEMBER 2007
we will also use these nine instances for comparing the perfor-
mances of MOEA/D and MOGLS.
D. Implementations of MOEA/D and MOGLS for MOKP
1) Repair Method: To apply an EA for the MOKP, one needs
a heuristic for repairing infeasible solutions. Several repair ap-
proaches have been proposed for this purpose [13], [29].
Let be an infeasible solution to
(7). Note that and in (7) are nonnegative, one can remove
some items from it (i.e., change the values of some from 1 to
0) for making it feasible. Recently, Jaszkiewicz proposed and
used the following greedy repair method9.
Input:
• MOP (7);
• a solution: ;
• an objective function to be maximized:
Output: a feasible solution .
Step 1) If is feasible, then set and return .
Step 2) Set and
.
Step 3) Select such that
where is different from only in position , i.e.,
for all and .
Set and go to Step 1.
In this approach, items are removed one by one from
until becomes feasible. An item with the heavy weights (i.e.,
) in the overfilled knapsacks and little contribution to
(i.e., ) is more likely to be removed.
2) Implementation of MOGLS: To have a fair comparison,
we directly use Jaszkiewicz’s latest implementation of MOGLS
for the MOKP, the details of MOGLS with the Tchebycheff ap-
proach are given as follows.
• Initialization of : Taking each as the
objective function, apply the repair method on a randomly
generated point and produce a feasible solution. Set to
be the value of the resultant point.
• Initialization of and :
Set and . Then, Repeat times:
1. Randomly generate a weight vector by using the
sampling method described in [29].
2. Randomly generate a solution
, where the probability of equals to 0.5.
3. Taking as the objective function, apply the
repair method to and obtain a feasible solution .
9This approach is used in the latest version of his implementation, which can
be downloaded from his web http://www-idss.cs.put.poznan.pl/~jaszkiewicz/
and is slightly better than that used in his earlier paper [29].
4. Add to . Remove from all the vectors dominated
by , then add to EP if no vectors in dominate
.
• Genetic operators in Step 2.1: The genetic operators
used are the one-point crossover operator and the standard
mutation operator. The one-point crossover is first applied
to the two solutions and generates one child solution, then
the standard mutation operator mutates it to produce a
new solution . The mutation mutates each position of the
child solution independently with probability 0.01.
• Heuristic in Step 2.2: The repair method described in this
section is used.
3) Implementation of MOEA/D: We use the same genetic
operators in Step 2.1 and the repair method in Step 2.2 as in the
implementation of MOGLS. The initialization of is also the
same as in MOGLS. Initialization of (the initial solution to
the th subproblem) is performed as follows.
• Initialization of in Step 1.3: Taking
as the objective function, apply the repair method to a
randomly generated solution. Set to be the resultant
solution.
Tchebycheff aggregation function is used in the above
implementations of MOEA/D and MOGLS.
The implementations of these two algorithms with the
weighted sum approach in our experimental studies are the
same as their counterparts with the Tchebycheff approach,
except that they use as the objective in the repair method
and do not maintain .
E. Parameter Setting
The setting of and in MOGLS, which determines the size
of , is the same as in [29]. is set to 20 for all the instances.
The values of for different instances are given in Table I.
in MOEA/D is set to 10 for all the test instances. The set-
ting of and in MOEA/D is controlled by a param-
eter . More precisely, are all the weight vectors in
which each individual weight takes a value from
Therefore, the number of such vectors is
Table I lists the value of and in MOEA/D for each test
instance. For the instances with two objectives, the value of
in MOEA/D is the same as that of in MOGLS. For all the
instances with three objectives, , and therefore
. For all the instances with four objectives, , and
then . It should be noted that the size of the internal
population in MOGLS can reach , much larger than
that of the internal population in MOEA-D.
The above method for generating weight vectors in MOEA-D
works well in our experiments. It could, however, result in a very
large when , the number of the objectives is large. To over-
come this shortcoming, one should resort to advanced experi-
mental design methods [30], [31] to generate weight vectors.
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
ZHANG AND LI: MOEA/D: A MULTIOBJECTIVE EVOLUTIONARY ALGORITHM BASED ON DECOMPOSITION 719
TABLE I
PARAMETER SETTING OF MOEA/D AND MOGLS FOR THE
TEST INSTANCES OF THE 0/1 KNAPSACK PROBLEM
Both of the algorithms stop after 500 calls of the repair
method.
In our experimental studies, both and have been
used in the repair method. In the following, W-MOEA/D
(W-MOGLS) stands for MOEA/D (MOGLS) in which
is used, while T-MOEA/D (T-MOGLS) represents MOEA/D
(MOGLS) in which is used.
F. Experimental Results
Both MOGLS and MOEA/D have been independently run
for 30 times for each test instance on identical computers
(Pentium(R) 3.2 GHZ, 1.00 GB). Due to the nature of MOPs,
multiple performance indexes should be used for comparing
the performances of different algorithms [2], [32]. In our
experiments, the following performance indexes are used.
• Set Coverage ( -metric): Let and be two approx-
imations to the PF of a MOP, is defined as the
percentage of the solutions in that are dominated by at
least one solution in , i.e.,
is not necessarily equal to .
means that all solutions in are dominated
by some solutions in , while implies that
no solution in is dominated by a solution in .
• Distance from Representatives in the PF ( -metric):
Let be a set of uniformly distributed points along the
PF. Let be an approximation to the PF, the average dis-
tance from to is defined as
where is the minimum Euclidean distance between
and the points in . If is large enough to represent
the PF very well, could measure both the diver-
sity and convergence of in a sense. To have a low value
of , set must be very close to the PF and cannot
miss any part of the whole PF.
In the case when we do not know the actual PF, we can set
to be an upper approximation of the PF. Jaszkiewicz
TABLE II
AVERAGE CPU TIME (IN SECONDS) USED BY MOEA/D AND MOGLS
TABLE III
AVERAGE SET COVERAGE BETWEEN MOEA/D (A) AND MOGLS (B)
has produced a very good upper approximation to each
0/1 knapsack test instance by solving the linear program-
ming relaxed version of (3) with a number of uniformly
distributed ’s [29]. The number of the points in the
upper approximation is 202 for each of the bi-objective
instances, 1326 for the 3-objective instances, and 3276 for
the 4-objectives. In our experiments, is set as such an
approximation.
Table II gives the average CPU time used by each algorithm
for each instance. Table III presents the means of the -metric
values of the final approximations obtained by the two algo-
rithms with two different repair methods.
Table IV shows the mean and standard deviation of the
-metric values in MOEA/D and MOGLS for each instance.
Fig. 3 shows the evolution of the average -metric value
of from in 30 runs with the number of the calls of
the repair method in each algorithm for each test instance.
Since the ranges of -metric values are large, we use the
logarithmic scale for the axes of the average -metric value
in Fig. 3. Figs. 4 and 5 plot the distributions of with the
lowest -metric value found in each algorithm for the three
bi-objective instances.
We can make the following remarks:
• With the same number of the calls of a repair method
(i.e., the same number of trial solutions), it is evident
from Table II that MOEA/D needs less computational
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
720 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 11, NO. 6, DECEMBER 2007
TABLE IV
D-METRIC VALUES OF THE SOLUTIONS FOUND BY MOEA/D AND MOGLS.
THE NUMBERS IN PARENTHESES REPRESENT THE STANDARD DEVIATION
time than MOGLS does. On average, MOEA/D requires
about 14% of the CPU time that MOGLS needs. In other
words, MOEA/D is seven times as fast as MOGLS. This
observation agrees with our analysis of the computational
complexity of MOEA/D and MOGLS in Section IV-B.
• Fig. 3 clearly indicates that for all the test instances,
W-MOEA/D (T-MOEA/D) needs fewer calls of a repair
method than MOGLS for minimizing the -metric value,
which suggests that MOEA/D is more efficient and effec-
tive than MOGLS for the MOKP.
• Tables III and IV show that the final obtained by
W-MOEA/D (T-MOEA/D) is better than that obtained
by W-MOGLS (T-MOGLS), in terms of both -metric
and -metric, for all the test instances except instance
250–4 in which W-MOEA/D is slightly worse than
W-MOGLS in -metric. Taking instance 500–3 as an
example, on average, 90.97% of the final solutions gen-
erated by T-MOGLS are dominated by those generated
by T-MOEA/D, and only 2.42% vice versa. The differ-
ence between the approximations by T-MOEA/D and
T-MOGLS on instances 250–2, 500–2 and 750–2 can be
visually detected from Fig. 5, while difference between
W-MOEA/D and W-MOGLS in middle part of the fronts
on instance 750–2 can be spotted from Fig. 4.
• Table IV also shows that the standard deviation of
-metric in W-MOEA/D (T-MOEA/D) is smaller than
that in W-MOGLS (T-MOGLS) for all the instances,
which implies that MOEA/D is more stable than MOGLS.
• Table IV and Fig. 3 reveal that the weighted sum approach
outperforms the Tchebycheff approach in both MOEA/D
and MOGLS, which suggests that different decomposition
approaches in MOEA/D and MOGLS can have different
performances.
Overall, we can claim that MOEA/D is computationally much
cheaper and can produce better approximations than MOGLS
on these MOKP test instances.
V. COMPARISON WITH NSGA-II ON CONTINUOUS MOPS
A. Multiobjective Continuous Test Suites
We use five widely used bi-objective ZDT test instances [33]
and two 3-objective instances [34] in comparing MOEA/D
with NSGA-II [16], one of the most successful nondecomposi-
tion MOEAs. All these test instances are minimization of the
objectives.
• ZDT1
and . Its PF is convex.
in our experiments.
• ZDT2
where and the range and dimensionality of are the
same as in ZDT1. The PF of ZDT2 is nonconvex.
• ZDT3
where and the range and dimensionality of are the
same as in ZDT1. Its PF is disconnected. The two objec-
tives are disparately scaled in the PF, is from 0 to 0.852,
while from to 1.
• ZDT4
where
and . It has many
local PFs. in our experiments.
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
ZHANG AND LI: MOEA/D: A MULTIOBJECTIVE EVOLUTIONARY ALGORITHM BASED ON DECOMPOSITION 721
• ZDT6
and . Its PF is nonconvex.
The distribution of the Pareto solutions in the Pareto front
is very nonuniform, i.e., for a set of uniformly distributed
points in the Pareto set in the decision space, their images
crowd in a corner of the Pareto front in the objective space.
in our experiments.
• DTLZ1
where
and . Its PF is nonconvex.
The function value of a Pareto optimal solution satisfies
with , , 2, 3. in our
experiments.
• DTLZ2
(8)
where
and . Its PF is
nonconvex. The function value of a Pareto optimal solution
satisfies with , , 2, 3. in
our experiments.
B. NSGA-II [16]
NSGA-II does not use an external population. NSGA-II
maintains a population of size at generation and gener-
ates from in the following way.
Step 1) Use selection, crossover and mutation to create an
offspring population from .
Step 2) Choose best solutions from to form
.
The characteristic feature of NSGA-II is that it uses a fast
nondominated sorting and crowded distance estimation proce-
dure for comparing qualities of different solutions in Step 2 and
selection in Step 1. The computational complexity of each gen-
eration in NSGA-II is , where is the number of the
objectives and is its population size.
C. Variant of MOEA/D Used in Comparison
To have a fair comparison, we use the following variant of
MOEA/D in our experiments.
• There is no external population . Instead, the final in-
ternal population is returned as an approximation to the PF.
Step 2.5 is not needed.
• No repair/improvement method is used, therefore, Step 2.2
is not needed.
• is used in Step 2.4.
We do not use mainly because the weighted sum ap-
proach is unable to deal with nonconvex PFs as is the case in
some test instances. Since NSGA-II has no external population,
we do not maintain an external population in this implementa-
tion of MOEA/D. In comparison with NSGA-II, the only extra
memory requirement in MOEA/D is for storing . The size of
is , which is very small compared with the population
size.
D. Comparison of Computational Complexity of the Variant of
MOEA/D and NSGA-II
In the above variant of MOEA/D, the major computational
costs are in Step 2. Step 2 in MOEA/D generates trial solu-
tions, so does NSGA-II at each generation. Note that Steps 2.2
and 2.5 have been removed from this variant, Step 2.1 just ran-
domly pick two solutions for genetic operators, Step 2.3 per-
forms comparisons and assignments, and Step 2.4 needs
basic operations since its major costs are to compute
the values of for solutions and computation of one such a
value requires basic operations. Therefore, the computa-
tional complexity of Step 2 in the above variant of MOEA/D is
since it has passes. If both MOEA/D and NSGA-II
use the same population size, the ratio between their computa-
tional complexities at each generation is
Since is smaller than , the variant of MOEA/D has lower
computational complexity than NSGA-II at each generation.
E. Experimental Setting
In our experimental studies, the implementation of NSGA-II
follows [16]. The population size in both NSGA-II and
MOEA/D is set to be 100 for all the 2-objective test instances,
and 300 for the other two 3-objective test instances. Both
algorithms stop after 250 generations.
Initial populations are generated by uniformly randomly sam-
pling from the feasible search space in both algorithms. in
MOEA/D is initialized as the lowest value of found in the
initial population. The simulated binary crossover (SBX) and
polynomial mutation are used in both NSGA-II and MOEA/D.
More precisely, in Step 2.1 of MOEA/D, the crossover operator
generates one offspring, which is then modified by the muta-
tion operator. The setting of the control parameters in these two
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
722 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 11, NO. 6, DECEMBER 2007
Fig. 3. The evolution of the average D-metric in MOEA/D and MOGLS for all the MOKP instances. The base 10 logarithmic scale is used for the y axis in all
these figures.
operators is the same in both algorithms. Following the prac-
tice in [16], the distribution indexes in both SBX and the poly-
nomial mutation are set to be 20. The crossover rate is 1.00,
while the mutation rate is , where is the number of deci-
sion variables.
In MOEA/D, the setting of weight vectors is the
same as in Section IV-E, is set to be 20.
Both MOEA/D and NSGA-II have been run 30 times inde-
pendently for each test instance.
F. Experimental Results
Table V presents the average CPU time used by each algo-
rithm for each test instance. It is clear from Table V that, on av-
erage, MOEA/D runs about twice as fast as NSGA-II with the
same number of function evaluations for the 2-objective test in-
stances, and more than 8 times for the 3-objective test instances.
This observation is consistent with our complexity analysis in
Section V-D.
As in the MOKP, we use both the -metric and -metric to
compare the performances of these two algorithms. To compute
-metric values, is chosen to be a set of 500 uniformly dis-
tributed points in the PF for all the 2-objective test instances,
and 990 points for 3-objective instances.
The number of function evaluations matters when the objec-
tive functions are very costly to evaluate. Fig. 6 presents the
evolution of the average -metric value of the current popula-
tion to with the number of function evaluations in each algo-
rithm for each test instance. These results indicate that MOEA/D
converges, in terms of the number of the function evaluations,
much faster than NSGA-II in minimizing the -metric value
for ZDT4, ZDT6, DTLZ1 and DTLZ2, and at the about same
speed as or a bit slower than NSGA-II for the other three test
instances.
Table VI shows that in terms of -metric, the final solutions
obtained by MOEA/D is better than those obtained by NSGA-II
for all the test instances but ZDT4.
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
ZHANG AND LI: MOEA/D: A MULTIOBJECTIVE EVOLUTIONARY ALGORITHM BASED ON DECOMPOSITION 723
Fig. 4. Plots of the nondominated solutions with the lowestD-metric in 30 runs
of MOEA/D and MOGLS with the weighted sum approach for all the 2-objec-
tive MOKP test instances.
Table VII presents the mean and standard deviation of
-metric value of the final solutions obtained by each algo-
rithm for each test instance. This table reveals that in terms of
Fig. 5. Plots of the nondominated solutions with the lowestD-metric in 30 runs
of MOEA/D and MOGLS with the Tchebycheff approach for all the 2-objective
MOKP test instances.
-metric, the final solutions obtained by MOEA/D is better
than NSGA-II for ZDT4, ZDT6 and the two 3-objective in-
stances, and slightly worse for other three instances.
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
724 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 11, NO. 6, DECEMBER 2007
TABLE V
AVERAGE CPU TIME (IN SECONDS) USED BY NSGA-II AND
MOEA/D WITH THE TCHEBYCHEFF APPROACH
TABLE VI
AVERAGE SET COVERAGE BETWEEN MOEA/D WITH THE
TCHEBYCHEFF APPROACH (A) AND NSGA-II (B)
TABLE VII
D-METRIC VALUES OF THE SOLUTIONS FOUND BY MOEA/D WITH
THE TCHEBYCHEFF APPROACH AND NSGA-II. THE NUMBERS
IN PARENTHESES REPRESENT THE STANDARD DEVIATION
Figs. 7 and 8 show in the objective space, the distribution of
the final solutions obtained in the run with the lowest -value
of each algorithm for each test instance. It is evident that as
to the uniformness of final solutions, MOEA/D is better than
NSGA-II for ZDT1, ZDT2, ZDT6, and the two 3-objective test
instances; it is about the same as NSGA-II for ZDT4, and worse
than NSGA-II for ZDT3, on which MOEA/D found fewer so-
lutions than NSGA-II in the two left segments of the PF. The
poor performance of MOEA/D on ZDT3 could be attributed to
the fact that the objectives in ZDT3 are disparately scaled.
We can conclude from the above results that MOEA/D with
the Tchebycheff approach needs less CPU time than NSGA-II
with the same number of function evaluations for these test in-
stances. In terms of the solution quality, these two algorithms
have about the same performance on the 2-objective test in-
stances, but MOEA/D is better than NSGA-II on the two 3-ob-
jective instances.
G. A Bit More Effort on MOEA/D
In the above experiments, we used a very naive implemen-
tation of MOEA/D. The decomposition method is the classic
Tchebycheff approach. We did not perform any objective nor-
malization.
As mentioned in Section II-C, the Tchebycheff approach may
perform worse, in terms of solution uniformness, than BI ap-
proaches, particularly when the number of objectives is more
than two. It is also well-known that objective normalization is
very useful for increasing the solution uniformness when the ob-
jectives are disparately scaled.
Revisiting Figs. 7 and 8, one may not be quite satisfied with
the uniformness in the solutions found by the above implemen-
tation of MOEA/D for ZDT3, DTLZ1, and DTLZ2. Note that
the two objectives in ZDT3 are disparately scaled, and DTLZ1
and DTLZ2 have three objectives, two questions naturally arise.
• Can MOEA/D with other advanced decomposition
methods such as the PBI approach find more evenly
distributed solutions for 3-objective test instances like
DTLZ1 and 2?
• Can MOEA/D with objective normalization perform better
in the case of disparately scaled objectives as in ZDT3?
We have performed some experiments to study these two issues.
In the following, we report our experimental results.
1) MOEA/D With the PBI Approach: We have tested
MOEA/D with the PBI approach on the two 3-objective test
instances. In our experiment, the penalty factor in is set
to be 5 and the other settings are exactly the same as in the
implementation of MOEA/D with the Tchebycheff approach in
the above subsection.
Table VIII compares the average -metric values of
NSGA-II and MOEA/D with two different decomposition
approaches. Fig. 9 shows the distributions of the nondominated
fronts with the lowest -metric values in 30 independent runs
of MOEA/D with the PBI approach for two 3-objective test
instances. It is very clear from these results and Fig. 8 that
MOEA/D with the PBI approach performs much better than
NSGA-II and MOEA/D with the Tchebycheff approach on
these two 3-objective instances. These results suggest that
incorporating other advanced decomposition approaches into
MOEA/D would be worthwhile studying in solving MOPs
with more than two objectives. We would like to point out
that MOEA/D with advanced decomposition approaches may
require a bit more human effort, for example, to set the value
of the penalty factor in the PBI approach.
2) Objective Normalization: We still use the Tchebycheff
approach and do not change the parameter settings in the
following experiments. However, we incorporate a simple
objective normalization technique into MOEA/D to study if
the performance can be improved in the case of disparately
scaled objectives.
A lot of effort has been made on the issue of objective nor-
malization in the communities of both mathematical program-
ming and evolutionary computation [1], [35], [36]–[38]. A very
simple normalization method is to replace objective (
) by10
(9)
where , as in Section II, is the reference
point, is the nadir point in the
10Here, we assume that the goal of (1) is minimization.
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
ZHANG AND LI: MOEA/D: A MULTIOBJECTIVE EVOLUTIONARY ALGORITHM BASED ON DECOMPOSITION 725
Fig. 6. The evolution of D-metric value in both NSGA-II and MOEA/D with the Tchebycheff approach for each test instance.
objective space, i.e., . In other
words, defines the upper bound of PF, the Pareto front.
In such a way, the range of each objective in the PF becomes
[0, 1].
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
726 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 11, NO. 6, DECEMBER 2007
Fig. 7. Plot of the nondominated front with the lowestD-metric value found by NSGA-II and MOEA/D with the Tchebycheff approach for each 2-objective test
instance. The left panel is for MOEA/D and the right panel for NSGA-II.
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
ZHANG AND LI: MOEA/D: A MULTIOBJECTIVE EVOLUTIONARY ALGORITHM BASED ON DECOMPOSITION 727
Fig. 8. Plot of the nondominated front with the lowestD-metric value found by NSGA-II and MOEA/D with the Tchebycheff approach for each 3-objective test
instance. The left panel is for MOEA/D and the right panel for NSGA-II.
It is not easy or necessary to compute and beforehand.
In our implementation, we replace by ,11 and each by
, the largest value of in the current population. Therefore,
in Step 2.4 of MOEA/D with the Tchebycheff approach for con-
tinuous MOPs, is replaced by
(10)
We have tested MOEA/D with the Tchebycheff approach and
the above normalization technique on ZDT3 and a modified ver-
sion of ZDT1 in which is replaced by such that the
two objectives are disparately scaled. Fig. 10 plots the nondom-
inated solutions obtained by a single run of MOEA/D with and
without normalization for the modified version of ZDT1. Fig. 11
shows the nondominated solutions obtained by a single run of
MOEA/D with normalization for ZDT3.
11Please refer to the description of MOEA/D for the details of initialization
and update of z.
Figs. 10 and 11, together with the plots of the solutions found
by NSGA-II and MOEA/D without normalization for ZDT3,
clearly indicate that normalization does improve MOEA/D sig-
nificantly, in terms of uniformness, in the case of disparately
scaled objectives.
In summary, we have very positive answers to the two ques-
tions raised at the outset of this subsection. Using other sophisti-
cated decomposition and normalization techniques in MOEA/D
will be our future research topics.
VI. SCALABILITY, SENSITIVITY, AND SMALL POPULATION
IN MOEA/D
A. Sensitivity of in MOEA/D
is a major control parameter in MOEA/D. To study the sen-
sitivity of the performance to in MOEA/D for both contin-
uous and discrete MOPs, we have tested different settings of
in the implementation of MOEA/D with the weighted sum
approach in Section IV for knapsack instance 250–2, and the
implementation of MOEA/D with the Tchebycheff approach in
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
728 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 11, NO. 6, DECEMBER 2007
Fig. 9. Plot of the nondominated fronts with the lowest D-metric values in
MOEA/D with the PBI approach for two 3-objective test instances.
TABLE VIII
COMPARISON OF AVERAGED-METRIC VALUES OF THE SOLUTIONS FOUND BY
NSGA-II, AND MOEA/D WITH THE TCHEBYCHEFF AND PBI APPROACHES.
THE NUMBERS IN PARENTHESES REPRESENT THE STANDARD DEVIATION
Section V for ZDT1. All the parameter settings are the same as
in Sections IV-E and V-E, except the settings of . As clearly
shown in Fig. 12, MOEA/D performs very well with from 10
to 50 on knapsack instance 250–2, and it works very well for all
the values of except very small ones on ZDT1. Thus, we can
claim that MOEA/D is not very sensitive to the setting of , at
least for MOPs that are somehow similar to these test instances.
Fig. 12 also reveals that MOEA/D does not work well on
both instances when is very small. This could be due to what
was mentioned in Section III-B3, MOEA/D with too small is
poor at exploration. The fact that MOEA/D with large works
poorly on knapsack instance 250–2 could be explained by our
Fig. 10. Plot of the nondominated fronts found by MOEA/D with and without
normalization for the modified version of ZDT1 in which f is replaced by 10f .
Fig. 11. Plot of the nondominated front found by MOEA/D with normalization
for ZDT3.
analysis in Section III-B3 since the solutions to two subprob-
lems with very different weight vectors are far different in this
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
ZHANG AND LI: MOEA/D: A MULTIOBJECTIVE EVOLUTIONARY ALGORITHM BASED ON DECOMPOSITION 729
Fig. 12. The average D-metric value versus the value of T in MOEA/D for
knapsack instance 2–250 and ZDT1.
instance. The reason that MOEA/D with large performs well
on ZDT1 could be because even if two weight vectors are dif-
ferent, the optimal solutions to their associated subproblems are
very similar, in fact, they are the same in all the components ex-
cept the first one.
B. MOEA/D Using Small Population
As mentioned in Section I, a decision maker may not want
to have a huge number of Pareto optimal solutions at high
computational cost. They are often interested in obtaining a
small number of evenly distributed solutions at low computa-
tional cost. In the following, we will show that MOEA/D using
small population could serve this purpose. We take ZDT1 as
an example and use MOEA/D with the Tchebycheff approach
in Section V. All the parameter settings are the same as in
Section V except the population size . For comparison,
we also run NSGA-II with on ZDT1. Both algorithms
stop after 250 generations as in Section V.
Fig. 13 plots the final solutions obtained in a single run
of NSGA-II and MOEA/D with . It is evident that
MOEA/D found 20 very evenly distributed Pareto solutions,
Fig. 13. Plot of the nondominated fronts found by MOEA/D and NSGA-II
using small population (N = 20).
Fig. 14. The average numbers of function evaluations used for reducing the
D-metric value under 0.005 for ZDT1 with different numbers of decision vari-
ables.
while NSGA-II failed in reaching the PF within the given
number of generations. Clearly, this advantage of MOEA/D
comes from its decomposition strategy.
C. Scalability
To study how the computational cost, in terms of the number
of function evaluations, increase as the number of decision vari-
able increases, we have tried, on ZDT1 with different numbers
of decision variables, the variant of MOEA/D in Section V-C,
with the same parameter settings except the maximal number of
generation is 1000 (i.e., the maximal number of function evalu-
ations is ). We have found that in every run
among 30 independent runs for each number of decision vari-
ables, MOEA/D has lowered the -metric value blow 0.005,
therefore the final solutions are a very good approximation to
the PF by our experience in Section V. Fig. 14 gives the average
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
730 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 11, NO. 6, DECEMBER 2007
numbers of function evaluations used for reducing the -metric
value under 0.005 for ZDT1 with different numbers of decision
variables. It is evident that the average number of function eval-
uations linearly scales up, as the number of decision variables
increases.
The linear salability of MOEA/D in this test instance should
be due to two facts: 1) The number of scalar optimization sub-
problems in MOEA/D is fixed to be 100, no matter how many
the decision variables are. One does not need to increase the
number of subproblems as the number of decision variables in-
creases since the intrinsic dimensionality of a MOP is deter-
mined by its number of objectives, but not its number of de-
cision variables [1], [39]. 2) The complexity of each scalar op-
timization could scale up linearly with the number of decision
variables.
VII. CONCLUSION
Decomposition was widely used in traditional mathematical
programming methods for solving MOPs. In contrast, most
MOEAs treat a MOP as a whole and mainly rely on domi-
nation for measuring the solution quality during their search.
These algorithms may not be very good at generating an even
distribution of solutions along the PF.
This paper has proposed a simple and generic evolutionary
multiobjective optimization algorithm based on decomposition,
called MOEA/D. It first uses a decomposition method to de-
compose the MOP into a number of scalar optimization prob-
lems. Then, an EA is employed for optimizing these subprob-
lems simultaneously. Each individual solution in the population
of MOEA/D is associated with a subproblem. A neighborhood
relationship among all the subproblems is defined based on the
distances of their weight vectors. In MOEA/D, optimization of a
subproblem uses the current information of its neighboring sub-
problems since two neighboring subproblems should have close
optimal solutions. We have compared MOEA/D with MOGLS
and NSGA-II on multiobjective knapsack problems and con-
tinuous multiobjective problems, respectively. Our analysis has
shown that MOEA/D has lower computational complexity than
MOGLS and NSGA-II, and the experimental results have also
confirmed it. In terms of solution quality, MOEA/D with simple
decomposition methods have outperformed or performed simi-
larly to MOGLS and NSGA-II on most test instances.
We have shown that MOEA/D with the PBI approach is
able to generate a very uniform distribution of representative
Pareto optimal solutions on the PF on two continuous 3-objec-
tive test instances. We have also demonstrated that MOEA/D
with a naive objective normalization technique can deal with
disparately scaled objectives very well. These results suggest
that more efficient and effective implementations of MOEA/D
could be obtained if more effort is made.
We have experimentally investigated the scalability and the
sensitivity to the neighborhood size of MOEA/D. We have
found that the computational cost linearly scales up with the
number of decision variables, and MOEA/D is not very sensitive
to the setting of . We have also shown that MOEA/D is good at
finding a small number of uniformly distributed Pareto solutions
at low computational cost.
Combination of mathematical programming methods and
EAs has been proven to be very successful in scalar optimiza-
tion problems. Our work in this paper provides a very natural
way for introducing decomposition strategies, which have been
studied in the community of mathematical programming for
a long time, into EAs for multiobjective optimization. New
developments in decomposition strategies and other techniques
in scalar optimization techniques can be readily integrated with
EAs in the framework of MOEA/D.
ACKNOWLEDGMENT
The authors are grateful to X. Yao, the anonymous associate
editor, and anonymous referees for their insightful comments.
They also thank A. Zhou and S. Lucas for his help on this work.
REFERENCES
[1] K. Miettinen, Nonlinear Multiobjective Optimization. Norwell, MA:
Kluwer, 1999.
[2] K. Deb, Multi-Objective Optimization using Evolutionary Algo-
rithms. New York: Wiley, 2001.
[3] C. A. C. Coello, D. A. V. Veldhuizen, and G. B. Lamont, Evolutionary
Algorithms for Solving Multi-Objective Problems. Norwell, MA:
Kluwer, 2002.
[4] K. Tan, E. Khor, and T. Lee, Multiobjective Evolutionary Algorithms
and Applications, ser. Advanced Information and Knowledge Pro-
cessing. Berlin, Germany: Springer-Verlag, 2005.
[5] E. Polak, “On the approximation of solutions to multiple criteria de-
cision making problems,” in Multiple Criteria Decision Making, M.
Zeleny, Ed. Berlin, Germany: Springer-Verlag, 1976, vol. 123, Lec-
ture Notes in Economics and Mathematical Systems, pp. 271–282.
[6] S. Helbig, “On a constructive approximation of the efficient outcomes
in bicriterion vector optimization,” J. Global Optim., vol. 5, pp. 35–48,
1994.
[7] M. Wiecek, W. Chen, and J. Zhang, “Piecewise quadratic approxima-
tion of the non-dominated set for bi-criteria programs,” J. Multi-Cri-
teria Decision Analysis, vol. 10, no. 1, pp. 35–47, 2001.
[8] S. Ruzika and M. Wiecek, “Approximation methods in multiobjective
programming,” J. Optim. Theory Appl., vol. 126, no. 3, pp. 473–501,
Sep. 2005.
[9] I. Das and J. E. Dennis, “Normal-bounday intersection: A new method
for generating Pareto optimal points in multicriteria optimization prob-
lems,” SIAM J. Optim., vol. 8, no. 3, pp. 631–657, Aug. 1998.
[10] A. Messac, A. Ismail-Yahaya, and C. Mattson, “The normalized normal
constraint method for generating the Pareto frontier,” Struct Multidisc.
Optim., vol. 25, pp. 86–98, 2003.
[11] C. A. Mattson, A. A. Mullur, and A. Messac, “Smart Pareto filter: Ob-
taining a minimal representation of multiobjective design space,” Eng.
Optim., vol. 36, no. 6, pp. 721–740, 2004.
[12] C. A. C. Coello, “An updated survey of GA-based multiobjective opti-
mization techniques,” ACM Comput. Surv., vol. 32, no. 2, pp. 109–143,
2000.
[13] E. Zitzler and L. Thiele, “Multiobjective evolutionary algorithms: A
comparative case study and the strength Pareto approach,” IEEE Trans.
Evol. Comput., vol. 3, no. 4, pp. 257–271, Nov. 1999.
[14] J. D. Knowles and D. W. Corne, “The Pareto archived evolution
strategy: A new baseline algorithm for multiobjective optimisation,” in
Proc. Congr. Evol. Comput., Washington, D.C., Jul. 1999, pp. 98–105.
[15] E. Zitzler, M. Laumanns, and L. Thiele, “SPEA2: Improving the
strength Pareto evolutionary algorithm for multiobjective optimiza-
tion,” in Proc. Evolutionary Methods for Design Optimization and
Control with Applications to Industrial Problems, K. C. Gian-
nakoglou, D. T. Tsahalis, J. Périaux, K. D. Papailiou, and T. Fogarty,
Eds., Athens, Greece, pp. 95–100.
[16] K. Deb, S. Agrawal, A. Pratap, and T. Meyarivan, “A fast and elitist
multiobjective genetic algorithm: NSGA-II,” IEEE Trans. Evol.
Comput., vol. 6, no. 2, pp. 182–197, Apr. 2002.
[17] H. Lu and G. G. Yen, “Rank-density-based multiobjective genetic algo-
rithm and benchmark test function study,” IEEE Trans. Evol. Comput.,
vol. 7, no. 4, pp. 325–343, Aug. 2003.
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.
ZHANG AND LI: MOEA/D: A MULTIOBJECTIVE EVOLUTIONARY ALGORITHM BASED ON DECOMPOSITION 731
[18] T. Okabe, Y. Jin, B. Sendhoff, and M. Olhofer, “Voronoi-based esti-
mation of distribution algorithm for multi-objective optimization,” in
Congress on Evolutionary Computation (CEC), Y. Shi, Ed. Piscat-
away, NJ: IEEE Press, 2004, pp. 1594–1602.
[19] C. A. C. Coello, G. T. Pulido, and M. S. Lechuga, “Handling mul-
tiple objectives with particle swarm optimization,” IEEE Trans. Evol.
Comput., vol. 8, no. 3, pp. 256–279, Jun. 2004.
[20] D. A. V. Veldhuizen and G. B. Lamont, “Multiobjective evolutionary
algorithms: Analyzing the state-of-the-art,” Evol. Comput., vol. 8, no.
2, pp. 125–147, 2000.
[21] J. D. Knowles and D. Corne, “Properties of an adaptive archiving algo-
rithm for storing nondominated vectors,” IEEE Trans. Evol. Comput.,
vol. 7, no. 2, pp. 100–116, Apr. 2003.
[22] Q. Zhang, A. Zhou, and Y. Jin, “Modelling the regularity in an estima-
tion of distribution algorithm for continuous multiobjective optimisa-
tion with variable linkages,” Dept. Comput. Sci., Univ. Essex, Colch-
ester, U.K., Tech. Rep. CSM-459, 2006, (a revised version of this paper
has been accepted for publication by the IEEE Trans. Evol. Comput.,
2007).
[23] P. A. N. Bosman and D. Thierens, “The balance between proximity
and diversity in multiobjective evolutionary algorithms,” IEEE Trans.
Evol. Comput., vol. 7, no. 2, pp. 174–188, Apr. 2003.
[24] J. D. Schaffer, “Multiple objective optimization with vector evaluated
genetic algorithms,” in Proc. 1st Int. Conf. Genetic Algorithms, 1985,
pp. 93–100.
[25] L. Paquete and T. Stützle, “A two-phase local search for the biobjective
traveling salesman problem,” in Proc. Evol. Multi-Criterion Optim.,
2003, pp. 479–493.
[26] E. J. Hughes, “Multiple single objective Pareto sampling,” in Proc.
Congr. Evol. Comput., Canberra, Australia, 2003, pp. 2678–2684.
[27] Y. Jin, T. Okabe, and B. Sendhoff, “Adapting weighted aggregation for
multiobjective evolutionary strategies,” in Evolutionary Multicriterion
Optimization. : Springer, 2001, vol. 1993, LNCS, pp. 96–110.
[28] H. Ishibuchi and T. Murata, “Multi-objective genetic local search al-
gorithm and its application to flowshop scheduling,” IEEE Trans. Syst.,
Man, Cybern., vol. 28, pp. 392–403, Aug. 1998.
[29] A. Jaszkiewicz, “On the performance of multiple-objective genetic
local search on the 0/1 knapsack problem – A comparative experi-
ment,” IEEE Trans. Evol. Comput., vol. 6, no. 4, pp. 402–412, Aug.
2002.
[30] Q. Zhang and Y. W. Leung, “Orthogonal genetic algorithm for multi-
media multicast routing,” IEEE Trans. Evol. Comput., vol. 3, no. 1, pp.
53–62, Apr.l 1999.
[31] N. J. W. T. J. Santers and W. I. Notz, The Design of Analysis of Com-
puter Experiments. Berlin, Germany: Springer-Verlag, 2003.
[32] E. Zitzler, L. Thiele, M. Laumanns, C. M. Fonseca, and V. G. da Fon-
seca, “Performance assessment of multiobjective optimizers: An anal-
ysis and review,” IEEE Trans. Evol. Comput., vol. 7, no. 2, pp. 117–132,
Apr. 2003.
[33] E. Zitzler, K. Deb, and L. Thiele, “Comparison of multiobjective evo-
lutionary algorithms: Empirical results,” Evol. Comput., vol. 8, no. 2,
pp. 173–195, 2000.
[34] K. Deb, L. Thiele, M. Laumanns, and E. Zitzler, “Scalable multiobjec-
tive optimization test problems,” in Proc. Congr. Evol. Comput., May
2002, vol. 1, pp. 825–830.
[35] R. E. Steuer, Multiple Criteria Optimization: Theory, Computation and
Application. New York: Wiley, 1986.
[36] M. Gen and R. Cheng, Genetic Algorithms and Engineering Design.
New York: Wiley, 1997.
[37] P. J. Bentley and J. P. Wakefield, “Finding acceptable solutions in the
Pareto-optimal range using multiobjective genetic algorithms,” in Proc.
2nd On-Line World Conf. Soft Comput. Eng. Design Manuf., Jun. 1997,
pp. 231–240.
[38] I. C. Parmee and D. Cvetkovic, “Preferences and their application in
evolutionary multiobjective optimization,” IEEE Trans. Evol. Comput.,
vol. 6, no. 1, pp. 42–57, Feb. 2002.
[39] M. Ehrgott, Multicriteria Optimization, 2nd ed. Berlin, Germany:
Springer-Verlag, 2005.
[40] T. Murata, H. Ishibuchi, and M. Gen, “Specification of Genetic
Search Direction in Cellular Multiobjective Genetic Algorithm,”
in Evolutionary Multicriterion Optimization. Berlin, Germany:
Springer-Verlag, 2001, LNCS1993, pp. 82–95.
Qingfu Zhang (M’01–SM’06) received the B.Sc.
degree in mathematics from Shanxi University,
Shanxi, China, in 1984, the M.Sc. degree in applied
mathematics and the Ph.D. degree in information
engineering from Xidian University, Xi’an, China,
in 1991 and 1994, respectively.
He is currently a Reader in the Department of
Computer Science, University of Essex, Colchester,
U.K. Before joining the University of Essex in
2000, he was with the National Laboratory of
Parallel Processing and Computing at the National
University of Defence Science and Technology (China), Hong Kong Poly-
technic University (Hong Kong), the German National Research Centre for
Information Technology (now Fraunhofer–Gesellschaft, Germany) and the
University of Manchester Institute of Science and Technology (U.K.). His main
research areas are evolutionary computation, optimization, neural networks,
data analysis and their applications.
Dr. Zhang is an Associate Editor of the IEEE TRANSACTIONS ON SYSTEMS,
MAN, AND CYBERNETICS—PART B and a Guest Editor of a forthcoming Special
Issue on Evolutionary Algorithms Based on Probabilistic Models in the IEEE
TRANSACTIONS ON EVOLUTIONARY COMPUTATION.
Hui Li received the B.Sc. and M.Sc degrees in ap-
plied mathematics from Xi’an Jiaotong University,
Xi’an, China, in 1999 and 2002, respectively. He is
currently working towards the Ph.D. degree in com-
puter science at the University of Essex, Colchester,
U.K.
His main research areas are evolutionary computa-
tion, multiobjective optimization, metaheuristics, and
portfolio optimization.
Authorized licensed use limited to: UNIVERSITY OF ESSEX. Downloaded on May 6, 2009 at 06:54 from IEEE Xplore.  Restrictions apply.

