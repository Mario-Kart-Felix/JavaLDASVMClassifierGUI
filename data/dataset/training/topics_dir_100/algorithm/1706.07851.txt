A practical fpt algorithm for Flow Decomposition
and transcript assembly
Kyle Kloster1, Philipp Kuinke2, Michael P. O’Brien1, Felix Reidl1,
Fernando Sánchez Villaamil2, Blair D. Sullivan1, and
Andrew van der Poel1
1 North Carolina State University, USA
(kakloste|mpobrie3|blair_sullivan|ajvande4)@ncsu.edu, felix.reidl@gmail.com
2 RWTH Aachen University, Germany
(kuinke|fernando.sanchez)@cs.rwth-aachen.de
Abstract
The Flow Decomposition problem, which asks for the smallest set of weighted paths that
“covers” a flow on a DAG, has recently been used as an important computational step in genetic
assembly problems. We prove the problem is in FPT when parameterized by the number of
paths, and we give a practical linear fpt algorithm. Combining this approach with algorithm
engineering, we implement a Flow Decomposition solver and demonstrate its competitiveness
with a state-of-the-art heuristic on RNA sequencing data. We contextualize our design choices
with two hardness results related to preprocessing and weight recovery. First, the problem
does not admit polynomial kernels under standard complexity assumptions. Second, the related
problem of assigning weights to a given set of paths is NP-hard even when the weights are known.
1 Introduction
We study the problem Flow Decomposition [4, 8, 13, 16] under the paradigm of parame-
terized complexity. Motivated by the principles of algorithm engineering, we not only design
and implement a competitive fpt algorithm but also characterize several key aspects of the
problem’s complexity. Decomposing flows naturally arises in analyzing high-throughput se-
quencing data in computational genomics, and we benchmark our implementation on data
from this use case [13].
Flow Decomposition asks for the minimum number of weighted paths necessary to
exactly cover a flow on a directed acyclic graph with a unique source s and sink t (called
an s-t–DAG in the following). More precisely, we say a set of s-t–paths P = p1, . . . , pk and
corresponding weights w = (w1, . . . , wk) are a flow decomposition of an s-t–DAG G with
flow f if for every arc a in G,
f(a) =
k∑
i=1
wi · 1pi(a),
where 1pi(a) is the indicator function whose output is 1 if a ∈ pi, and 0 otherwise. Specifi-
cally, in this paper, we are concerned with k-Flow Decomposition, which uses the natural
parameter of the number of paths.
Input: (G, f, k) with G an s-t–DAG, f a flow on G, and k a positive integer.
Problem: Is there an integral flow decomposition of (G, f) using at most k paths?
k-Flow Decomposition (k-FD)
Finding solutions to k-FD is a key step in a common technique for reassembling DNA
and RNA fragments. This method organizes short reads (called k-mers) into a De Bruijn
© Kyle Kloster, Philipp Kuinke, Michael O’Brien, Felix Reidl, Fernando Sánchez Villaamil,
Under Logo Blair D. Sullivan, Andrew van der Poel;
licensed under Creative Commons License CC-BY
Leibniz International Proceedings in Informatics
Schloss Dagstuhl – Leibniz-Zentrum für Informatik, Dagstuhl Publishing, Germany
ar
X
iv
:1
70
6.
07
85
1v
2 
 [
cs
.D
S]
  2
8 
Ju
n 
20
17
2 A practical fpt algorithm for Flow Decomposition and transcript assembly
graph where an arc between fragments s1, s2 indicates that s1 minus its first letter equals s2
minus its last letter. Each arc is labeled with an integer which corresponds to abundance
(frequency) in the sequencing data. Affixing dummy source and sink nodes s, t to the graph
forms an s-t–DAG and, in the absence of noise, the arc labels form an integral flow from s
to t. Recovering the original genetic sequences from the fragments (assembly) can then be
accomplished by finding an integral flow decomposition.
A precursory investigation of the setup and data used by Shao and Kingsford [13] to
evaluate the performance of Flow Decomposition heuristics in RNA transcript assembly
left us with three guiding observations:
1. 99% of instances admit decompositions into fewer than 8 paths. Our algorithm should
thus exploit the small natural parameter.
2. The data set contains ∼4 million mostly small instances. Our implementation should
therefore be able to handle a large throughput.
3. The flow decompositions computed by our implementation should reliably recover the
domain-specific solution.
The first point corroborates the parameterized approach. Using dynamic programming over
a suitable graph decomposition, a common algorithm design technique from parameterized
complexity, we show the problem can be solved in linear-fpt time (Section 3):
I Theorem 1. There is an 2O(k2)(n+λ) algorithm for solving k-FD, where λ is the logarithm
of the largest flow value.
To address the second point, we implement a Flow Decomposition solver, Toboggan [5],
based on this algorithm and compare it with the state-of-the-art heuristic Catfish (Section 5).
Our results show that Toboggan’s running time is comparable to Catfish and thus suitable for
high-throughput applications. With respect to the third point, using Flow Decomposi-
tion for assembly implicitly assumes that the true genetic sequences correspond to paths in
a minimum-size flow decomposition. Prior work focuses on heuristics which cannot be used
to evaluate the validity of this assumption. With Toboggan, we validate that minimum-size
flow decompositions accurately recover genetic sequences in most instances.
Toboggan incorporates several heuristic improvements (discussed in Section 4) to keep
the running time and memory consumption of the core dynamic programming routine as
small as possible. In particular the simple preprocessing we employ is highly successful in
solving (or discarding) many instances directly. A provable guarantee for this preprocessing
in the form of a small kernel, however, is unlikely: we show that unless NP is contained in
coNP/poly, k-FD does not admit a polynomial kernel (Section 6). Further, our experimental
evaluation hints at the following conjecture: for a given decomposition of an s-t–DAG into a
minimum number of paths, there is a unique assignment of weights to those paths to achieve
a flow-decomposition. We prove the more general ‘weight recovery’ problem is NP-hard given
a decomposition into an arbitrary number of paths (Section 7). If the conjecture holds, it
implies a tighter bound on the running time of the algorithm in Theorem 1.
2 Preliminaries
Related work. Flow Decomposition is known to be NP-complete, even when all flow
values are in {1, 2, 4}, and does not admit a PTAS [4, 16]. The best known approximation
algorithm for the problem is based on parity-balancing path flows [8], and guarantees an
approximation ratio of λLλ with a running-time of O(λ|V | · |E|2), where L is the length
K. Kloster, P. Kuinke, M.P. O’Brien, F. Reidl, F. Sánchez Villaamil,B. D. Sullivan, A. van der Poel 3
of the longest s-t–path, and λ is the logarithm of the maximum flow value. The variant
in which the decomposition approximates the original flow values to minimize a specified
penalty function was studied in [14], and the authors give an fpt algorithm and FPTAS
parameterized by k, the largest s-t-cut, and the maximum flow value.
Due to its practical use for sequencing data, much of the prior work on Flow Decompo-
sition has focused on fast heuristics, including two greedy algorithms which iteratively add
the remaining path which is shortest (greedy-length) or of maximum possible weight (greedy-
width) [16]. Both heuristics produce solutions with at most k = |E|− |V |+2 paths and have
variants [4] which decompose all but an ε-fraction of the flow using at most O(1/ε2) times the
minimum number of paths, for any ε > 0. Historically, greedy-width has provided the best
performance [4, 8, 16], but the recent heuristic Catfish [13] showed significant improvements
over greedy-width in accuracy and runtime.
Notation. Given a directed acylic graph (DAG), G = (V,A), we say G is an s-t–DAG
if G has a single source, s, and a single sink, t. We denote by A+(v) the set of out-arcs of a
node v, and by A−(v) the in-arcs. For a set of nodes, S, we define A+(S) = {vu | v ∈ S, u /∈
S, vu ∈ A+(v)}. If f is a flow on G, we write f(a) for the flow value on an arc a and F for
the total flow (the sum of flow values on the arcs in A+(s)).
Terminology. Given a DAG, a topological ordering on the nodes is a labeling such that
every arc is directed from a node with a smaller label to one with a larger label. We label the
nodes of an s-t–DAG G as v1, . . . , vn corresponding to an arbitrary, fixed topological ordering
of G; this implies that s = v1 and t = vn. We further define the sets Si = {vj | j ≤ i} based
on the ordering. We refer to the s-t–cuts A+(Si) as topological ordering cuts (top-cuts). Our
algorithm for computing a flow decomposition will ultimately depend on tracking how the
paths cross top-cuts, a notion we refer to as a routing.
I Definition 2 (Routings and extensions). A surjective function g : [k]→ A+(Si) is a routing
out of Si. A routing g′ : [k] → A+(Si) is an extension of g : [k] → A+(Si−1) if for each
j ∈ [k], g′(j) = xy implies g(j) = xy if x 6= vi, and g(j) = zx for some z ∈ Si−1 if x = vi.
In other words, an extension of a routing takes all the integers that map to in-arcs of vi and
maps them instead to the out-arcs of vi while leaving the rest of the mapping unchanged.
It will be important in our analysis to differentiate arcs that occur in multiple paths from
arcs that appear on only a single path: we say paths p and p′ coincide on arc a if a ∈ p and
a ∈ p′. An arc a is saturated by a path p if p is the only path for which a ∈ p.
Parameterized complexity. A parameterized decision problem Π ∈ Σ∗ × N is fixed
parameter tractable if there exists an algorithm that decides it in time g(k) · nc for some
computable function g and a constant c. When c = 1, we call such an algorithm linear fpt. A
polynomial kernel is an algorithm that transforms, in polynomial time, an instance (I, k) ∈
Σ∗×N of Π into an equivalent instance (I ′, k′) with |I ′|, k′ ≤ kO(1), meaning that (I, k) ∈ Π
if and only if (I ′, k′) ∈ Π. Some more advanced machinery pertaining to kernelization lower
bounds will be defined in Section 6.
3 A linear fpt algorithm for k-FD
We solve k-FD via dynamic programming over the topological ordering: we enumerate all
ways of routing k s-t–paths over each top-cut A+(Si). Each such routing determines a set of
constraints for the path weights, which we encode in linear systems. For example, if paths p1
and p2 are routed over an arc a, we add the constraint w1 + w2 = f(a) to our system.
4 A practical fpt algorithm for Flow Decomposition and transcript assembly
Figure 1 An entry of the table T3. The routing g out of S3 (dashed lines) is an extension of the
previous routings (solid paths). Each row in the constraint system L on the right corresponds to
an arc; those shaded in gray are from arcs inside S3, and those in white come from g.
Concretely, we keep a table Ti for 0 ≤ i ≤ n whose entries are sets of pairs (g, L), where
g : [k] → A+(Si) is a routing of the paths out of Si and L is a system of linear equations
that encodes the known path weight constraints. In particular, for every arc a ∈ A+(Si), we
write g−1(a) for the set of s-t–paths that are routed over a. Each system of linear equations,
L, is of the form Aw = b, where A is a binary matrix with k columns, w is the solution
weight vector, and b is a vector containing values of f . Each row r of A corresponds to an
arc ar and encodes the constraint that the weights of paths routed over ar sum up to f(ar).
The jth entry of row r is 1 if and only if path pj was routed over ar, and then f(ar) equals
the rth entry of b. Figure 1 illustrates an example of an entry (g, L).
We now describe how the dynamic programming tables are constructed. For ease of
description, we augment G to have two additional dummy arcs as and at, where as is an
in-arc of s and at is an out-arc of t and f(as) = f(at) = F . We begin with table T0 that
has a single entry. The routing of this entry routes all paths over as and the linear system
has a single row that constrains all path weights to sum to the total flow value.
For i > 0, we construct the table Ti from Ti−1. Conceptually, we “visit” node vi and
“push” all paths routed over its in-arcs to be routed over its out-arcs. Formally, we require
the routing out of Si to be an extension (Definition 2) of a routing out of Si−1. For each
entry (g, L) ∈ Ti−1 we compute an entry (g′, L′) of Ti for each extension g′ of g. For a given
g′, we create L′ by adding a row to L for each arc a ∈ A+(vi), encoding the constraint∑
i∈g′−1(a)
wi = f(a).
At the conclusion of the dynamic programming, all entries of the final table Tn will have
the same routing, since vn = t has one (dummy) out-arc at. This table allows us to decide
whether there is a solution; (G, f) is a yes-instance of k-FD if and only if some L ∈ Tn has
a solution w whose entries are positive integers. Pseudocode for our algorithm can be found
in Algorithm 1 in Appendix A.
I Lemma 3. An integer vector w is a solution to L ∈ Tn if and only if there is a set of
s-t–paths P such that (P,w) is a flow decomposition of (G, f).
Proof. We first prove the forward direction. If we keep backpointers in our DP tables i.e.
pointers from entry (gi, Li) to the entry in the previous table (gi−1, Li−1) for which gi was
the extension of gi−1, we can obtain a sequence of routings gn−1, . . . g1 that correspond
to backwards traversal of the backpointers. Let h(j) = g1(j), . . . gn−1(j). By Definition 2,
removing the duplicate elements that appear in consecutive order from h(j) yields a series of
K. Kloster, P. Kuinke, M.P. O’Brien, F. Reidl, F. Sánchez Villaamil,B. D. Sullivan, A. van der Poel 5
arcs that form an s-t–path pj . Because each routing requires every arc to have a path routed
over it, the system L contains constraints corresponding to each arc. Thus an integer solution
w to L corresponds to a weighting of P = p1, . . . pk such (P,w) is a flow decomposition.
In the reverse direction, we first observe that the incidence of paths in P on a top-cut
A+(Si) corresponds to a routing out of Si. Let gi be the corresponding routing out of Si.
For each node vi, the paths routed over A−(vi) must immediately be routed over an arc in
A+(vi), meaning gi is an extension of gi−1. Because (P,w) is a flow decomposition, the paths
routed over each arc will have weights summing to the flow value on that arc. Thus, any
constraint in a linear system associated with the routings gi will have w as a solution. J
To analyze the running time we now derive bounds on the dynamic programming table sizes.
First, we bound the number of possible routings in Lemma 4, then we give an upper bound
on the number of linear systems in Lemma 5.
I Lemma 4. There are at most
√
k (0.649k)k routings of k paths over any top-cut.
Proof. A routing of k paths over a top-cut C can be thought of as a partition of the paths
into ` = |C| many non-empty sets along with a mapping of these sets to the arcs of C.
We can assume that ` ≤ k, since a routing of k paths requires every top-cut to have at
most k arcs. The number of ways to partition k objects into ` non-empty sets is
{
k
`
}
, the
Stirling number of the second kind, and there are `! ways to assign each of these partitions
to a specific arc. Thus, the number of routings is
{
k
`
}
`!. To proceed, we use the upper
bound
{
k
`
}
≤ 12
(
k
`
)
`k−` due to Rennie and Dobson [9]. We also make use of the tighter
version of Stirling’s approximation due to Robbins [10], which states that
√
2πk
(
k
e
)k
e1/(12k+1) ≤ k! ≤
√
2πk
(
k
e
)k
e1/12k.
Hence, we have the upper bound{
k
`
}
`! ≤ 12
(
k
`
)
`k−``! = 12
k!
(k − `)!
`k
``
≤
√
k
2
√
k − `
(
k
e
)k (
e
k − `
)k−`
e
1
12k−
1
12(k−`)+1
`k
``
≤
√
k
kk`k−l
(k − `)k−`e` .
Letting ` = αk for α ∈ (0, 1), the above expression becomes
√
k
(αk)k−αk
(k − αk)k−αkeαk k
k ≤
√
k
((
α
1− α
)(1−α)
e−α
)k
kk ≤
√
k (0.649k)k,
where the constant 0.649 can be derived numerically by maximizing g(α) =
(
α
1−α
)(1−α)
e−α
on the interval [0, 1]. J
I Lemma 5. Each table has at most 4
k2
k! kk distinct linear systems.
Proof. Without loss of generality, we can ensure each linear system L has at most k rows
by removing linearly dependent rows. We note that because there are only 2k subsets of
weights, if f maps the arcs to more than 2k unique flow values, there cannot be a flow
decomposition of size k. Since the elements of b can thus take on at most 2k many values,
6 A practical fpt algorithm for Flow Decomposition and transcript assembly
and A contains binary rows of length k, it follows that there are at most 4k rows for L.
Accordingly, we can bound the number of possible linear systems by
(4k
k
)
. By imposing an
order on the rows we can remove a factor of 1/k!. Because k ≤
√
4k, we can apply the
bound
(
n
k
)
≤ (n/k)k which holds [6] for k ≤
√
n; thus, the number of linear systems is at
most 4k2/(k! kk). J
Now that we have bounded the size of the dynamic programming tables, we analyze the com-
plexity of solving the linear systems in the final table Tn. It has been shown that treating
linear systems as integer linear programs (ILPs) produces integer solutions in fpt-time.
I Proposition 6 ([7]). Finding an integer solution to a given system L takes time at most
O(k2.5k+o(k)|L|), where |L| is the encoding size of the linear system.
These results give the following upper bound on the runtime of our algorithm, proving
Theorem 1.
I Theorem 7. Algorithm 1 solves k-FD in time 4k2k1.5kko(k)1.765k · (n+λ) where λ is the
logarithm of the largest flow value of the input.
Proof. The correctness of the algorithm was already proven in Lemma 3, so all that remains
is to bound the running time. By Lemmas 4 and 5, the total number of elements in DP
table Ti is bounded by
4k2
k! kk ·
√
k (0.649k)k =
√
k
4k20.649k
k! .
Reducing the linear systems and checking for consistency is polynomial in the size of the
matrix (which is k × k). Finally, we need to find a feasible solution among all the linear
systems left after the last DP step. We apply Proposition 6 to these systems, whose encoding
size is bounded by kO(1)λ. We arrive at the desired running time of
4k2k2.5k0.649k
k! k
o(k) · (n+ λ) ≤ 4k
2
k1.5k1.765kko(k) · (n+ λ)
where we use the well-known bound k
k
k! ≤ e
k. J
4 Implementation
To establish that our exact algorithm for k-FD is a viable alternative to the heuristics cur-
rently in use by the computational biology community, we implemented Algorithm 1 as the
core of a Flow Decomposition solver Toboggan [5]. The solver iterates over values of k
in increasing order until reaching a yes-instance of k-FD. Toboggan also implements back-
tracking to recover the s-t–paths. Making Toboggan’s runtime competitive with existing im-
plementations of state-of-the-art heuristics required non-trivial algorithm engineering. Our
improvements broadly fall into three categories: preprocessing, pruning, and low-memory
strategies for exploring the search space. The remainder of this section describes the most
noteworthy techniques implemented in Toboggan that are not captured by Algorithm 1.
4.1 Preprocessing
Toboggan implements two key preprocessing routines. The first generates an equivalent
instance on a simplified graph using a series of arc contractions. The second calculates lower
bounds on feasible values of k to reduce the number of calls to the k-FD solver.
K. Kloster, P. Kuinke, M.P. O’Brien, F. Reidl, F. Sánchez Villaamil,B. D. Sullivan, A. van der Poel 7
Graph reduction. We first reduce the graph by contracting all arcs into/out of nodes
of in-/out-degree 1. We prove in Lemma 8 that given a flow decomposition of the contracted
graph, we can efficiently recover a decomposition of the same size for the original graph.
I Lemma 8. Let uv be an arc for which |A+(u)| = 1 or |A−(v)| = 1 and G′ the graph
created by contracting uv. Then (G′, f) has a flow decomposition (P ′,w) of size k iff (G, f)
has a flow decomposition (P,w) of size k. Moreover, we can construct (P,w) from (P ′,w)
in polynomial time.
Proof. We first note that if GR is the graph formed by reversing the directions of the arcs in
G, any solution to G can be transformed into a solution to GR by reversing the order of the
paths and maintaining the same weights. Since this reversal is involutive, the correspondence
between solutions to G and GR is bijective, so it suffices to consider the case |A+(u)| = 1.
GivenG with a node u that has |A+(u)| = 1, letG′ be the graphG with arc uv contracted.
Given a flow decomposition (P,w) of (G, f), we construct a corresponding decomposition
(P ′,w) for (G′, f) as follows. Every path p ∈ P containing u must have v as the vertex
succeeding u. Removing u from each such p will create a valid path in G′, since A−(u)
becomes part of A−(v) in G′. Moreover, the incidence of paths on each other arc remains
unchanged, so the solution covers the flows in G′.
In the reverse direction, consider a labeling of the arcs of G′ such that we can distinguish
among the in-arcs of v those which exist in G from those that result from contracting uv.
Let Anew be the set of latter arcs. We construct P from P ′ as follows. For each path p ∈ P ′,
if p is routed over xv ∈ Anew we modify p to include the arcs xu and uv, rather than the
arc xv, and add the modified path to P . If no such arc lies in p, we simply add p to P .
As in the forward direction, it is clear that any arcs in G without u as an endpoint
have their flow values covered by P , and that every path in P is an s-t–path in G. Since
xv ∈ Anew is derived from an arc xu ∈ G, if Q′ ⊂ P ′ are the paths routed over xv and Q is
the set of paths corresponding to Q′ in P , then Q exactly covers xu. Since every path in P
routed through A−(u) subsequently is routed over uv and the flow values on the in-arcs of
u sum to f(uv), uv is also covered by P . Thus (P,w) is a valid solution to (G, f). J
Lower bounds on k. To reduce the number of values of k that Toboggan considers
before reaching a yes-instance, we compute a lower bound on the optimal value of k. One
immediate lower bound is the size of the largest top-cut; we implement this in conjunction
with the additional bound established in Lemma 9.
I Lemma 9. Given a flow (G, f), let C1 and C2 be any two top-cuts with |C1| ≥ |C2|.
Letting F(S) be the multiset of flow values occurring in S, set F1 = F(C1) \ F(C2) and
F2 = F(C2) \ F(C1). If (G, f) has a flow decomposition of size k, then
k ≥ |F(C1) ∩ F(C2)|+ 23 (|F1|+ |F2|), (1)
and this lower bound is tighter than the cutset size |C1| iff |F1| < 2|F2|.
Proof. Suppose k paths cross cutsets C1 and C2. For every flow value in I = F(C1)∩F(C2),
it is possible a single path saturates the arc with that flow value in both cuts. Consider the
remaining h = k − |I| paths. To maximize the number of distinct flow values these h paths
produce, let each path saturate an arc in C1, yielding h values in F1, and then route those
h paths in pairs across distinct arcs in C2. This produces at most h/2 new flow values in
F2. This yields (3/2)h ≥ |F1|+ |F2|, and substituting for h proves Inequality (1).
To prove the relationship between this lower bound and |C1| there are two cases. If |F1| ≥
2|F2|, then by substituting we can upper bound (2/3)(|F1|+ |F2|) ≤ |F1| = |C1|− |I| ≤ |C1|.
If instead |F1| < 2|F2|, substituting yields |I|+ (2/3)(|F1|+ |F2|) > |I|+ |F1| = |C1|. J
8 A practical fpt algorithm for Flow Decomposition and transcript assembly
4.2 Search Space Strategies
To reduce the memory required by dynamic programming, our implementation diverges
from the pseudocode of Algorithm 1 in two ways. Specifically, we solve a restricted weight
variant of k-FD and use a separate phase to recover the s-t–paths.
Weight restriction. Rather than make one pass through the dynamic programming
that infers the weights of the solutions exclusively from the linear systems, we employ a
multi-pass strategy. Each pass restricts the potential weight vector by fixing a subset of its
entries. This reduces the number of candidate linear systems, saving both time and memory.
Further, this approach often reveals infeasibility earlier in the dynamic programming. If such
a pass identifies a feasible set of weights, we immediately proceed to the path recovery phase.
Motivated by our observation that in many instances derived from real data, some—if
not all—of the solution paths saturate at least one arc, we systematically choose restrictions
on the weights based on f . Initially all k weights are restricted to values of f . If this fails to
produce a yes-instance, we incrementally reduce the number of weights that we fix (leaving
the others unconstrained). If no yes-instance has a weight in f , this process eventually
results in running the dynamic programming with no weight restrictions.
Path recovery. Computing the path weights requires storing only the current and
previous dynamic programming tables in memory. In contrast, recovering the paths requires
storing all dynamic programming tables. For this reason, we first determine the weights
w and then recover the paths by running the dynamic programming again with weights
restricted to w. This is equivalent to solving the k-Flow Routing problem in Section 6.
4.3 Pruning
Within the dynamic programming we employ a number of heuristics that help recognize
algorithmic states that cannot lead to a solution.
Weight bounds. We augment the weight constraints imposed by the linear systems
with a set of routing-independent constraints. These take the form of upper and lower
bounds (Bi and bi, respectively) on the ith smallest weight wi.
First, we compute bk by noting that for any top-cut C and any arc a ∈ C, only k−|C|+1
paths can be routed over a, i.e. bk ≥ f(a)/(k − |C| + 1). Then, we compute Bk by finding
the largest weight of any s-t–path. This can be done via a simple dynamic programming
algorithm: for any node v, an s-v–path with weight w requires a path of equal weight to an
in-neighbor u such that w ≤ f(uv).
To compute the bounds on the other weights, i < k, we let B1 be the smallest flow value
and Bi be the smallest1 flow value greater than
∑i−1
j=1 Bj . In other words, if f(a) >
∑i−1
j=1 wj ,
then a must be part of a path of weight at least wi. Finally, we use these upper bounds to
derive the bis. If the weights greater than wi sum to W , then by the pigeonhole principle
wi ≥ (F −W )/i, where F is the total flow. Thus, wi ≥ (F −
∑k
j=i+1 Bj)/(i+ 1).
In each dynamic programming table, for each linear system L we run a linear program
to see if there are any (rational) weights within the bounds that satisfy L. If not, we remove
the entry of the dynamic programming table containing L.
Storing linear systems. Within the dynamic programming we store linear systems
in row-reduced echelon form (RREF). When a new row r is introduced to the system,
1 If no such flow value exists, set Bi = Bk.
K. Kloster, P. Kuinke, M.P. O’Brien, F. Reidl, F. Sánchez Villaamil,B. D. Sullivan, A. van der Poel 9
we perform Gaussian elimination to convert the new row to RREF, checking for linear
dependence and inconsistency in O(k2) time. The iterative row reduction also has the
advantage of revealing determined path weights even if the system is not fully determined,
and thus we can check whether any such values are not positive integers. Furthermore, once
the system is full rank, no additional computation needs to be done to recover the weights.
5 Experimental Results
In this section we empirically evaluate the efficiency and solution quality of Toboggan by
comparing with the current state-of-the-art, Catfish, on a corpus of simulated RNA sequenc-
ing data. Additionally, we use Toboggan to theoretically validate the k-FD problem as a
model for the transcript assembly task.
5.1 Experimental setup
Our experiments were run on a corpus of data used in previous experiments by Shao and
Kingsford [13], available at [12]. The data set consists of simulated RNA sequencing data
for three different species (human, mouse, zebrafish), totaling over 4 million instances; each
instance is an s-t–DAG generated with a corresponding flow decomposition. We will refer
to this particular decomposition as the “ground truth” since it is the biologically relevant
information we are trying to reconstruct.
For a small number of the 4M instances, the ground truth decomposition contained at
least one path that appeared multiple times. The data provides no means for mathemat-
ically or biologically distinguishing these; thus, we aggregated the duplicated paths into a
single path, summing their weights. Additionally, we removed “trivial” instances in which
the graph consisted of a single s-t–path; on such graphs Toboggan terminates during prepro-
cessing without executing the k-FD algorithm described in this paper. We remark that this
is a departure from the experimental setup of Catfish [13], which included such graphs, ex-
plaining some slight differences in our statistics. About 64% of the 4M graphs in the corpus
are trivial in this manner. The number of non-trivial graphs for each species is summarized
in Table 1.
All experiments were executed on a dedicated system with an Intel i7-3770 processor
(3.40GHz, 8 cores) with an 8192 KB cache and 32 GB of RAM. We terminated Toboggan
on any run whose weight computation took longer than 800 seconds on zebrafish, and 50
seconds on human and mouse2.
5.2 Benchmarking
We start by analyzing the efficiency of Toboggan and Catfish, noting that this compares
a Python implementation [5] with C++ code [12]. Their runtimes on all 2.6M non-trivial
instances in the corpus are shown side-by-side in Figure 2. We observe that the two im-
plementations are both quite fast on the vast majority of instances: their median runtimes
are 1.24 milliseconds (ms) (Toboggan) and 3.47ms (Catfish). However, the implementations
have different runtime distributions—whereas Catfish is consistent, terminating between 2.3–
4.6ms on 90% of instances and never running longer than 1.3 seconds, Toboggan trades off
faster termination, e.g. less than 2ms on 80% of instances, with a higher variance and a
small chance of a much longer runtime, e.g. over 50 seconds on 0.48% of instances.
2 In total, Toboggan timed out on 5,136 of the 4M instances under these constraints.
10 A practical fpt algorithm for Flow Decomposition and transcript assembly
Figure 2 Runtimes of Toboggan and Catfish on all non-trivial instances. The y-axes indicate
the number of instances on which the algorithms terminate in the given time window.
5.3 Model Validation
Previous papers that use flow decompositions to recover RNA sequences [13, 15] implicitly
assume that the true RNA sequences correspond to a minimum size flow decomposition, as
opposed to one with an arbitrary number of paths. Because Toboggan provably finds the
minimum size of a flow decomposition, our implementation enables us to investigate exactly
how often this assumption holds in practice.
Table 1 gives the percentage of instances whose ground truth decompositions are in
fact minimum decompositions, as well as the percentage of ground truth decompositions we
proved have non-optimal size3. We conclude from this table that the Flow Decomposition
problem is in fact a useful model for transcript assembly, which underscores the need for
efficient algorithms to compute minimum decompositions.
dataset instances non-trivial optimal non-optimal
zebrafish 1,549,373 445,880 99.907% 0.053%
mouse 1,316,058 473,185 99.401% 0.074%
human 1,169,083 529,523 99.490% 0.043%
all 4,034,514 1,448,588 99.589% 0.056%
Table 1 Summary of the RNA sequencing dataset available at [12]. Only non-trivial instances
are analyzed for optimality3. The high percentage of instances with ground truth of minimum size
supports the use of Flow Decomposition as a model for transcript assembly.
5.4 Ground Truth Recovery
Though the ground truth flow decompositions are almost always of minimum size, it is bio-
logically desirable to find a particular minimum size decomposition rather than an arbitrary
one. In this section we investigate how often the decompositions output by Toboggan and
3 Because Toboggan timed out on some instances, these percentages do not sum to 100.
K. Kloster, P. Kuinke, M.P. O’Brien, F. Reidl, F. Sánchez Villaamil,B. D. Sullivan, A. van der Poel 11
k instances Catfish Toboggan
2 63.2791% 0.992 0.995
3 22.0775% 0.967 0.969
4 8.5237% 0.931 0.930
5 3.4920% 0.886 0.886
6 1.5375% 0.830 0.828
7 0.6698% 0.788 0.780
8 0.2889% 0.767 0.766
9 0.1241% 0.740 0.743
10 0.0070% 0.752 0.802
11 0.0004% 0.500 0.500
all 100% 0.973 0.975
Figure 3 (Left) Proportion of ground truth path sets that Catfish and Toboggan recover exactly,
organized by path set size (k). Bold numbers indicate the algorithm with better performance.
(Right) Distributions of the Jaccard index between the algorithms’ solutions and the ground truth
on instances where the paths are not exactly recovered.
Catfish are identical to the ground truth decomposition, restricting our attention to non-
trivial instances in which the ground truth decomposition is of minimum size. Additionally,
for those instances where each algorithm does not exactly recover the ground truth, we
analyze the similarity of the (imperfect) path set to the ground truth using the Jaccard
index.
The table in Figure 3 summarizes the performance of both Toboggan and Catfish algo-
rithms in exactly computing the ground truth flow decompositions. The table shows that
the algorithms perform quite similarly, with slight differences at various decomposition sizes,
and a 0.2% advantage for Toboggan overall.
For instances where an algorithm’s output is not identical to the ground truth, an output
can still recover some useful information if it is highly similar to the ground truth decompo-
sition. With this in mind, we evaluate how similar each algorithm’s output is to the ground
truth when they do not exactly match4. The plot in Figure 3 shows the distribution of the
Jaccard index of each algorithm’s output compared to the ground truth paths. Interestingly,
the two distributions are shaped very similarly suggesting that, when the algorithms differ
from the ground truth they are missing the same amount of information.
6 Kernelization lower bounds
As described in Section 4.1, our implementation employs a graph reduction algorithm that
rapidly identifies any trivial graph and immediately solves Flow Decomposition. Out of
the 4M total instances, this preprocessing handles all of the roughly 2.6M trivial instances.
On non-trivial instances, Toboggan then tries to identify the correct number k of paths in
an optimal solution. The naïve lower bound from the largest edge cut is equal to the correct
value of k in 97.64% of non-trivial instances; incorporating the bound from Lemma 9 brings
this up to 99.066%.
In the framework of parameterized complexity, it is therefore natural to ask whether k-
FD admits a polynomial kernel. Below we answer the question in the negative, despite the
4 There are 43,817 such instances for Catfish and 41,783 for Toboggan.
12 A practical fpt algorithm for Flow Decomposition and transcript assembly
real-world success of our preprocessing. Our proof strategy requires hardness reductions
involving the following restricted variants of Flow Decomposition.
Input: An s-t–DAG, G with an integral flow f , an integer k, and a set U ⊂ Z.
Problem: Does (G, f) have a flow decomposition into k paths whose weights are all
members of U?
U-k-Flow Decomposition (U-kFD)
Input: An s-t–DAG, G, integral flow f , and k integers w = (w1, . . . , wk) taken from
U ⊂ Z.
Problem: Is there a flow decomposition of (G, f) into k paths with respective weights
w?
U-k-Flow Routing (U-kFR)
I Lemma 10. {1, 2, 4}-k-Flow Routing is NP-complete.
Proof. Consider an instance (G, f, k) of {1, 2, 4}-kFD, which is NP- complete [4]. Note that
every s-t–path in a potential solution to such an instance can only take weights in {1, 2, 4}.
This enables us to Turing-reduce (G, f, k) to at most k3 instances of {1, 2, 4}-kFR: we
simply guess how many of the k s-t–paths use each of the three possible values. It follows
that {1, 2, 4}-kFR is NP-complete. J
In order to show that k-FD does not admit polynomial kernels, we will provide a cross-
composition from {1, 2, 4}-kFR. We first need the following technical definition to set up
the necessary machinery:
I Definition 11 (Polynomial equivalence relation [2]). An equivalence relation R over Σ∗ is
called a polynomial equivalence relation if the following holds:
1. There exists an algorithm that decides for x, y ∈ Σ∗ whether x and y are equivalent
under R in time polynomial in |x|+ |y| and
2. for any finite set S ⊆ Σ∗ the index |S/R| is bounded by a polynomial in maxx∈S |x|.
The benefit of a polynomial equivalence relation is that we can focus on collection of instances
which share certain characteristics, as long as these characteristics do not distinguish too
many instances. A simple example is that we can ask for input instances (Gi, fi, ki) in which
all graphs Gi have the same number of vertices and the values ki are the same.
I Definition 12 (AND-cross-composition [2]). Let L ⊂ Σ∗ be a language, R a polynomial
equivalence relation over Σ∗, and let Π ⊆ Σ∗×N be a parameterized problem. An AND-cross
composition of L into Π (under R) is an algorithm that, given ` instances x1, . . . xt ∈ Σ∗
of L belonging to the same equivalence class of R, takes time polynomial in
∑`
i=1 |xi| and
outputs an instance (y, k) ∈ Σ∗ × N such that
a) the parameter k is polynomially bounded in max1≤i≤` |xi|+ log `, and
b) we have that (y, k) ∈ Π if and only if all instances xi ∈ L.
We will now use the following theorem (abridged to our needs here) and the subsequent
AND-cross-composition to prove that k-FD does not admit small kernels.
I Proposition 13 (Bodlaender, Jansen, Kratsch [2]). If an NP-hard language L AND-cross-
composes into a parameterized problem Π, then Π does not admit a polynomial kernelization
unless NP ⊆ coNP/poly and the polynomial hierarchy collapses.
K. Kloster, P. Kuinke, M.P. O’Brien, F. Reidl, F. Sánchez Villaamil,B. D. Sullivan, A. van der Poel 13
Let Rw be the equivalence relation on instances of {1, 2, 4}-kFR where (G1, f1,w1) ≡
(G2, f2,w2) if and only if w1 = w2. Since each entry of wi is in {1, 2, 4}, Rw has at most
k3 equivalence classes, and is a polynomial equivalence relation.
I Theorem 14. k-Flow Decomposition does not admit a polynomial kernel unless NP ⊆
coNP/poly and the polynomial hierarchy collapses.
Proof. Let x1, . . . , x` be instances of {1, 2, 4}-kFR all contained in the same equivalence
class of Rw, with xi = (Gi, fi,w) and w = (w1, . . . , wk) the common prescribed path
weights. We denote the source and sink of Gi by si and ti, respectively.
We construct an additional instance x`+1 as follows: G`+1 consists of two vertices s`+1, t`+1,
and k arcs a1, . . . , ak from s`+1 to t`+1. The flow f`+1 has value wi on arc ai. By construc-
tion x`+1 = (G`+1, f`+1,w) is a positive instance of {1, 2, 4}-kFR, moreover, it has a unique
decomposition into k s-t–paths (up to isomorphism).
Before we describe the composition, we treat a technicality. If the total flow Fi for
any fi is different from
∑k
j=1 wj , then xi is a negative instance. In this case, instead of a
composition we output a trivial negative instance y for k-FD. Otherwise, we compose the
instances x1, . . . , x`+1 into a single composite instance y = (G, f, k) of k-FD. To form G,
we chain the Gis together by identifying the vertex ti with the vertex si+1 for 1 ≤ i ≤ `.
The resulting G is an s-t–DAG with source s = s1 and sink t = t`+1. We define f to label
each arc in G with the flow value from its original instance. Since each xi has the same total
flow, f is a flow on G.
We point out that property a) of Definition 12 is trivially satisfied. To see that the second
property holds, first assume that all instances xi are positive. Since all these solutions consist
of k s-t–paths with the same prescribed values w1, . . . , wk, we can chain the individual flow
decompositions together into k s-t–paths in G. Accordingly, y is then a positive instance. In
the other direction, assume that y has a solution, i.e. f can be split into exactly k s-t–paths.
Due to our inclusion of the instance x`+1 in the construction of y, the respective values of
the s-t–paths must be exactly w1, . . . , wk. But then restricting this global solution to each
individual instance xi (since all s-t–paths meet at the identified source/sink cut vertices)
produces a solution. We conclude that therefore all xi must have been positive instances,
proving that property b) of Definition 12 holds for our construction.
Finally, our construction clearly takes time polynomial in
∑`
i=1 |xi| making it a AND-
cross-composition of {1, 2, 4}-kFR into k-FD. Invoking Theorem 13, this proves that k-FD
does not admit a polynomial kernel unless NP ⊆ coNP/poly. J
We note that our construction in the proof of Theorem 14 produces an instance of U-kFD,
which can easily be Turing reduced into an instance of U-kFR.
I Corollary 15. Unless NP ⊆ coNP/poly, the problems U-k-Flow Decomposition and
U-k-Flow Routing do not admit polynomial kernels.
7 Hardness of assigning weights
Every solution computed by Toboggan in our experiments corresponded to a fully determined
linear system in the final dynamic programming table. This means that we never had to
run the expensive ILP solver to determine the weights; instead, they were computed in
polynomial time with respect to k using row reduction. This raises the question: is the linear
system obtained from a decomposition into paths always fully determined? In the following
we show that the answer must be ‘no’ in case of non-optimal decompositions. Not only can
14 A practical fpt algorithm for Flow Decomposition and transcript assembly
there be multiple weight-assignments for the same set of paths, recovering these weights is
actually NP-hard. However, the question remains open for optimal decompositions:
I Conjecture 16. If k is the minimum value for which (G, f) has a flow decomposition of
size k, then every integer-weighted solution has a corresponding linear system L of rank k.
A direct consequence of this conjecture would be that the running time in Theorem 7
immediately improves to 1k! ·4
k20.649kkO(1) ·n since the ILP-solving step would never occur.
In this context, we note that Vatinlen et al. [16] proved that when k is minimum, every
solution with real-valued weights has a corresponding linear system of full rank. However,
this proof does not hold when the path weights are restricted to the integers.
We now show that the flow-decomposition problem remains NP-hard if the s-t–paths P
are known in advance, even with the additional information that half the entries in w are 1
and the other half are 2. Formally, we consider the problem k-Flow Weight Assignment.
Input: An s-t–DAG G with an integral flow f , and a prescribed set of s-t–paths,
P = p1, · · · , pk.
Problem: Identify integral weights w = (w1, . . . wk) such that (P, w) is a flow decompo-
sition of G.
k-Flow Weight Assignment (kFWA)
Our proof that kFWA is NP-complete relies on a reduction from Exact 3-Hitting Set,
which is equivalent to monotone 1-in-3-SAT and known to be NP-hard [11].
Input: A finite universe U = {u1, · · · , un}, and a collection S ⊆
(
U
3
)
of subsets of U
of size 3.
Problem: Find a subset X ⊆ U such that each element of S intersects (“hits”) X exactly
once, i.e. ∀S ∈ S, |S ∩X| = 1.
Exact 3-Hitting Set (X3HS)
I Theorem 17. k-Flow Weight Assignment is NP-complete.
Proof. Given an instance (U,S) of X3HS, we will construct an equivalent instance of
kFWA. Our approach is to encode each element of U using two “partner” s-t–paths in
an s-t–DAG, G, whose weights sum to 3, and each triad in S as a different top-cut in G. We
will route the partner paths and assign flow values so that the set of s-t–paths with weight
2 exactly correspond to elements in a solution to the hitting set problem.
We first construct the G. Let V (G) = {s, v1, . . . , v|S|, t = v|S|+1}, where vi is associated
with the ith triad in S for 1 ≤ i ≤ |S|, and s/t are source/sink vertices. Our construction
will be such that each vertex other than t has exactly one out-neighbor: s has out-neighbor
v1 and vi has out-neighbor vi+1. Create one sv1d arc with flow value 3 for each element of
U , and (|U | − 1) vivi+1 arcs—one each of flow values 4 and 5, and |U | − 3 with flow value
3. We now define a set of prescribed paths P = {pY , p̄Y }Y ∈U . For each element Y ∈ U ,
the corresponding partner s-t–paths pY and p̄Y are routed over the same arc out of s. This
guarantees that each pair of partner paths must receive weights summing to 3. At vi, we
route these paths to encode the corresponding triad Si = {u1, u2, u3} as follows. The paths
pu1 , pu2 , and pu3 are routed over the arc with flow 4 and p̄u1 , p̄u2 , and p̄u3 go over the arc
of flow 5. Now assign each element u′ ∈ U \Si to a unique vivi+1 arc au′ of flow value 3 and
route pu′ and p̄u′ together over au′ . This construction is illustrated in Figure 4.
K. Kloster, P. Kuinke, M.P. O’Brien, F. Reidl, F. Sánchez Villaamil,B. D. Sullivan, A. van der Poel 15
Figure 4 (Left) Instance of X3HS with unique solution {A, E}. (Right) The s-t–DAG from
our reduction, and a flow decomposition corresponding to the solution {A, E}. Light arcs have
weight 3, medium 4, and heavy 5; dashed paths have weight 1 and solid paths 2.
To complete the proof, we describe how a solution to this instance of kFWA yields a
solution to the original instance of X3HS. Consider the possible values of the weights of
the paths in P . By design, the out-arcs of s force each pair of partner paths to have one of
weight 1 and one of weight 2. Each triad Si is represented by two arcs out of vi: one with
flow value 4 (ai), and the other with 5 (āi). Because exactly three prescribed s-t–paths are
routed over a, and all our paths must have weight 1 or 2, this guarantees that exactly one
s-t–path routed over a has weight 2 (and the other two must have weight 1). Thus, finding
a set of weights that solve this instance of kFWA is equivalent to choosing a set of paths
to have weight 2 such that exactly one selected path is routed over each arc with flow value
4. But this is equivalent to choosing a set of elements (paths) such that each triad (arc) is
hit by (incident to) exactly one of the chosen elements (s-t–paths of weight 2). J
The graph constructed above admits a flow decomposition with |U | + 1 paths (|U | − 1 of
weight three, one of weight two, and one of weight one) and a corresponding linear system
of full rank5. As such, it is possible that Conjecture 16 is true and kFWA is not difficult
when the prescribed paths on a yes-instance are part of an optimal decomposition. Finally,
let us note that the instances resulting from the reduction are extremely restricted: not only
do the graphs have pathwidth 2, and all involved numbers are bounded by 5; we also can
assume that the multi-set of weights is given without affecting the hardness result.
8 Conclusion
We presented a holistic treatment of Flow Decomposition from the perspectives of param-
eterized complexity and algorithm engineering, resulting in a competitive solver, Toboggan.
Our approach verifies that parameterized algorithms can (with sufficient engineering) be
applied to real-world problems even in high-throughput situations. Our work also naturally
leads to several practical and theoretical questions for further investigation.
On the practical side, we would like to understand the cases in which a minimal flow
decomposition does not match the assembly problem’s ground truth, and how we might
5 This is true regardless of whether (U,S) is a a yes-instance.
16 A practical fpt algorithm for Flow Decomposition and transcript assembly
improve the recovery rate. The similarity in performance of Toboggan and Catfish in our
experiments suggests that we need to refine either the problem formulation or our notion of
minimality; in either case, more domain-specific knowledge is needed.
On the theory side, we ask whether there exists an fpt algorithm for Flow Decomposi-
tion with running time kO(k)n or better. In particular, it will be interesting to see whether
the established techniques used to improve dynamic programming algorithms [1, 3] are appli-
cable to our algorithm. Furthermore, if Conjecture 16 holds, it immediately implies a tighter
upper bound on the running time of our algorithm, and might lead to further optimizations.
Acknowledgements. This work supported in part by the Gordon & Betty Moore Foundation’s
Data-Driven Discovery Initiative through Grant GBMF4560 to Blair D. Sullivan.
References
1 H. L. Bodlaender, M. Cygan, S. Kratsch, and J. Nederlof. Deterministic single exponential
time algorithms for connectivity problems parameterized by treewidth. In International
Colloquium on Automata, Languages, and Programming, pages 196–207. Springer, 2013.
2 H. L. Bodlaender, B. M. Jansen, and S. Kratsch. Kernelization lower bounds by cross-
composition. SIAM Journal on Discrete Mathematics, 28(1):277–305, 2014.
3 M. Cygan, J. Nederlof, M. Pilipczuk, M. Pilipczuk, J. M. van Rooij, and J. O. Wojtaszczyk.
Solving connectivity problems parameterized by treewidth in single exponential time. In
FOCS 2011, pages 150–159. IEEE, 2011.
4 T. Hartman, A. Hassidim, H. Kaplan, D. Raz, and M. Segalov. How to split a flow? In
INFOCOM 2012, pages 828–836. IEEE, 2012.
5 K. Kloster, P. Kuinke, M. P. O’Brien, F. Reidl, F. Sánchez Villaamil, B. D. Sullivan, and
A. van der Poel. Toboggan. https://github.com/theoryinpractice/toboggan.
6 R. J. Lipton. Bounds on binomial coefficents.
https://rjlipton.wordpress.com/2014/01/15/bounds-on-binomial-coefficents/.
7 D. Lokshtanov. New Methods in Parameterized Algorithms and Complexity. PhD thesis,
University of Bergen, 2009.
8 B. Mumey, S. Shahmohammadi, K. McManus, and S. Yaw. Parity balancing path flow
decomposition and routing. In Globecom Workshops 2015, pages 1–6. IEEE, 2015.
9 B. C. Rennie and A. J. Dobson. On Stirling numbers of the second kind. Journal of
Combinatorial Theory, 7(2):116–121, 1969.
10 H. Robbins. A remark on Stirling’s formula. American Mathematical Monthly, 62(1):26–29,
1955.
11 T. J. Schaefer. The complexity of satisfiability problems. In 10th Annual STOC, pages
216–226. ACM, 1978.
12 M. Shao and C. Kingsford. Catfish. https://github.com/Kingsford-Group/catfish.
13 M. Shao and C. Kingsford. Efficient heuristic for decomposing a flow with minimum number
of paths. Presented at RECOMB-seq, 2017. doi: http://dx.doi.org//10.1101/087759.
14 A. I. Tomescu, T. Gagie, A. Popa, R. Rizzi, A. Kuosmanen, and V. Makinen. Explaining
a weighted dag with few paths for solving genome-guided multi-assembly. IEEE/ACM
Transactions on Computational Biology and Bioinformatics, 12(6):1345–1354, 2015.
15 A. I. Tomescu, A. Kuosmanen, R. Rizzi, and V. Mäkinen. A novel min-cost flow method
for estimating transcript expression with RNA-Seq. BMC bioinformatics, 14(5):S15, 2013.
16 B. Vatinlen, F. Chauvet, P. Chrétienne, and P. Mahey. Simple bounds and greedy algo-
rithms for decomposing a flow into a minimal set of paths. European Journal of Operational
Research, 185(3):1390–1401, 2008.
K. Kloster, P. Kuinke, M.P. O’Brien, F. Reidl, F. Sánchez Villaamil,B. D. Sullivan, A. van der Poel 17
A Pseudocode for k-Flow Decomposition
input : An s-t–DAG G, a flow f , and an integer k.
output: A vector w that contains the weights of the s-t–paths for a flow
decomposition into k integral-weighted s-t–paths. Or ∅ if none exist.
1 order(G) ; // Order vertices via topological ordering
// Build T0
2 for i ∈ [k] do
3 g0(i) := as;
4 L0 :=
[∑k
i=1 wi = F
]
;
5 T0 := (g0, L0);
// Do iterative steps
6 for i=1 to n do
7 Ti = ∅;
8 for (g, L) ∈ Ti−1 do
9 forall extensions g′ of g do
10 L′ := L;
11 for a ∈ A+(vi) do
12 add equation
[∑
i∈g′−1(a) wi = f(a)
]
to L′;
13 reduce(L′) ; // Remove linearly dependent rows
14 if L′ is consistent then
15 Ti = Ti ∪ {(g′, L′)};
16 if Ti = ∅ then
17 return ∅;
// Find L in final table that has an integer solution
18 for (g, L) ∈ Tn do
19 if L has an integer solution w then
20 return w;
// No solution was found
21 return ∅;
Algorithm 1: Linear-fpt algorithm for deciding k-Flow Decomposition.
18 A practical fpt algorithm for Flow Decomposition and transcript assembly
B Experimental results organized by species
Following the experimental setup of [13], in this section we report the our results on each of
the species data sets individually. Figure 5 gives this breakdown for the aggregated results
shown in Figure 3, and Figure 6 shows the similarity to ground truth path sets by species.
k instances Catfish Toboggan
2 76.6132% 0.992 0.995
3 17.3138% 0.962 0.963
4 4.3831% 0.913 0.911
5 1.1359% 0.855 0.858
6 0.3731% 0.765 0.761
7 0.1174% 0.700 0.696
8 0.0411% 0.710 0.727
9 0.0157% 0.700 0.643
10 0.0054% 0.833 0.792
11 0.0013% 0.500 0.500
All 100% 0.980 0.983
(a) zebrafish
k instances Catfish Toboggan
2 59.4943% 0.992 0.995
3 23.4974% 0.966 0.968
4 9.6369% 0.930 0.928
5 4.1312% 0.880 0.883
6 1.8605% 0.821 0.814
7 0.8402% 0.776 0.769
8 0.3755% 0.773 0.770
9 0.1573% 0.751 0.746
10 0.0066% 0.677 0.742
All 100% 0.969 0.971
(b) mouse
k instances Catfish Toboggan
2 55.3832% 0.992 0.996
3 24.8378% 0.970 0.973
4 11.0312% 0.937 0.939
5 4.9135% 0.897 0.894
6 2.2336% 0.846 0.847
7 0.9848% 0.805 0.798
8 0.4212% 0.766 0.767
9 0.1860% 0.734 0.748
10 0.0087% 0.761 0.848
All 100% 0.969 0.972
(c) human
Figure 5 Proportion of ground truth pathsets of a given size that Catfish and Toboggan recover
exactly, organized by species. Bolded numbers indicate the algorithm with better performance.
(a) zebrafish (b) mouse (c) human
Figure 6 Distribution of Jaccard indices between the algorithms’ solutions and the ground
truth. The bars in the middle indicate the median value; those at the top and bottom demarcate
the extreme values. Instances for which the Jaccard index is 1 are omitted because those statistics
are summarized in the tables in Figure 5.

