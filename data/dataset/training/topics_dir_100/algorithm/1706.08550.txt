Semidefinite Programming
and Nash Equilibria in Bimatrix Games
Amir Ali Ahmadi and Jeffrey Zhang âˆ—
Abstract
We explore the power of semidefinite programming (SDP) for finding additive -approximate
Nash equilibria in bimatrix games. We introduce an SDP relaxation for a quadratic programming
formulation of the Nash equilibrium (NE) problem and provide a number of valid inequalities to
improve the quality of the relaxation. If a rank-1 solution to this SDP is found, then an exact
NE can be recovered. We show that for a (generalized) zero-sum game, our SDP is guaranteed
to return a rank-1 solution. Furthermore, we prove that if a rank-2 solution to our SDP is found,
then a 511 -NE can be recovered for any game, or a
1
3 -NE for a symmetric game. We propose two
algorithms based on iterative linearization of smooth nonconvex objective functions which are
designed to produce rank-1 solutions. Empirically, we show that these algorithms often recover
solutions of rank at most two and  close to zero. We then show how our SDP approach can
address two (NP-hard) problems of economic interest: finding the maximum welfare achievable
under any NE, and testing whether there exists a NE where a particular set of strategies is not
played. Finally, we show that by using the Lasserre/sum of squares hierarchy, we can get an
arbitrarily close spectrahedral outer approximation to the convex hull of Nash equilibria, and
that the SDP proposed in this paper dominates the first level of the sum of squares hierarchy.
1 Introduction
A bimatrix game is a game between two players (referred to in this paper as players A and B)
defined by a pair of m Ã— n payoff matrices A and B. Let 4m and 4n denote the m-dimensional
and n-dimensional simplices
4m = {x âˆˆ Rm| xi â‰¥ 0,âˆ€i,
mâˆ‘
i=1
xi = 1},4n = {y âˆˆ Rn| yi â‰¥ 0, âˆ€i,
nâˆ‘
i=1
yi = 1}.
These form the strategy spaces of player A and player B respectively. For a strategy pair (x, y) âˆˆ
4m Ã—4n, the payoff received by player A (resp. player B) is xTAy (resp. xTBy). In particular,
if the players pick vertices i and j of their respective simplices (also called pure strategies), their
payoffs will be Ai,j and Bi,j . One of the prevailing solution concepts for bimatrix games is the
notion of Nash equilibrium. At such an equilibrium, the players are playing mutual best responses,
i.e., a payoff maximizing strategy against the opposing playerâ€™s strategy. In our notation, a Nash
equilibrium for the game (A,B) is a pair of strategies (xâˆ—, yâˆ—) âˆˆ 4m Ã—4n such that
xâˆ—TAyâˆ— â‰¥ xTAyâˆ—,âˆ€x âˆˆ 4m,
âˆ—The authors are partially supported by the Young Investigator Award of the AFOSR, the CAREER Award of
the NSF, the Google Faculty Award, and the Sloan Fellowship.
1
ar
X
iv
:1
70
6.
08
55
0v
1 
 [
m
at
h.
O
C
] 
 2
6 
Ju
n 
20
17
and
xâˆ—TByâˆ— â‰¥ xâˆ—TBy, âˆ€y âˆˆ 4n.1
Nash [25] proved that for any bimatrix game, such pairs of strategies exist (in fact his result more
generally applies to games with a finite number of players and a finite number of pure strategies).
While existence of these equilibria is guaranteed, finding them is believed to be a computationally
intractable problem. More precisely, a result of Daskalakis, Goldberg, and Papadimitriou [9] implies
that computing Nash equilibria is PPAD-complete (see [9] for a definition) even when the number
of players is 3. This result was later improved by Chen and Deng [6] who showed the same hardness
result for bimatrix games.
These results motivate the notion of an approximate Nash equilibrium, a solution concept in
which players receive payoffs â€œcloseâ€ to their best response payoffs. More precisely, a pair of
strategies (xâˆ—, yâˆ—) âˆˆ 4m Ã—4n is an (additive) -Nash equilibrium for the game (A,B) if
xâˆ—TAyâˆ— â‰¥ xTAyâˆ— âˆ’ , âˆ€x âˆˆ 4m,
and
xâˆ—TByâˆ— â‰¥ xâˆ—TBy âˆ’ ,âˆ€y âˆˆ 4n.
Approximation of Nash equilibria has also shown to be computationally difficult. Cheng, Deng, and
Teng proved in [7] that, unless PPAD âŠ† P, there cannot be a fully polynomial-time approximation
scheme for computing Nash equilibria in bimatrix games. There have, however, been a series of
constant factor approximation algorithms for this problem [11, 10, 17, 33], with the current best
producing a .3393 approximation via an algorithm by Tsaknakis and Spirakis [33].
We remark that there are exponential-time algorithms for computing Nash equilibria, such as
the Lemke-Howson algorithm [21, 30]. There are also certain subclasses of the problem which can
be solved in polynomial time, the most notable example being the case of zero-sum games (i.e.
when B = âˆ’A). This problem was shown to be solvable via linear programming by Dantzig [8],
and later shown to be polynomially equivalent to linear programming by Adler [1]. Aside from
computation of Nash equilibria, there are a number of related decision questions which are of
economic interest but unfortunately NP-hard. Examples include deciding whether a playerâ€™s payoff
exceeds a certain threshold in some Nash equilibrium, deciding whether a game has a unique Nash
equilibrium, or testing whether there exists a Nash equilibrium where a particular set of strategies
is not played [13].
Our focus in this paper is on understanding the power of semidefinite programming2 (SDP) for
finding approximate Nash equilibria in bimatrix games or providing certificates for related deci-
sion problems. Semidefinite programming relaxations have been analyzed in the past for an array
of intractable problems in computational mathematics (most notably in combinatorial optimiza-
tion [14], [22] and systems theory [5]), but to our knowledge not for computation of Nash equilibria
in general bimatrix games. SDPs have appeared however elsewhere in the literature on game theory
for finding equilibria, e.g. by Stein for exchangeable equilibria in symmetric games [32], by Parrilo,
Laraki, and Lasserre for Nash equilibria in zero-sum polynomial games [27, 18], or by Parrilo and
Shah for zero-sum stochastic games [31].
1In this paper we assume that all entries of A and B are between 0 and 1, and argue at the beginning of Section 2
why this is without loss of generality for the purpose of computing Nash equilibria.
2The unfamiliar reader is referred to [34] for the theory of SDPs and a description of polynomial-time algorithms
for them based on interior point methods.
2
1.1 Organization and Contributions of the Paper
In Section 2, we pose the problem of finding a Nash equilibrium in a bimatrix game as a nonconvex
quadratically constrained quadratic program and pose an SDP relaxation for it. In Section 2.3, we
exploit the structure of the Nash equilibrium problem to introduce a number of valid inequalities
which strengthen our SDP relaxation. In Section 3, we show that our SDP is exact when the
game is zero-sum (or generalized zero-sum; see Definition 3.3). In Section 4, we produce a number
of bounds on the quality of the approximate Nash equilibria that our SDP produces. We show
that if the SDP has a rank-k solution with nonzero eigenvalues Î»1, . . . , Î»k, then one can recover
from it an -Nash equilibrium with  â‰¤ m+n2
âˆ‘k
i=2 Î»i (Theorem 4.5). We then present an improved
analysis in the rank-2 case which shows how one can recover a 511 -Nash equilibrium from the SDP
solution (Theorem 4.12). We further prove that for symmetric games (i.e., when B = AT ), a
1
3 -Nash equilibrium can be recovered in the rank-2 case (Theorem 4.16). In Section 5, we design
two algorithms based on iterative linearization of smooth nonconvex objective functions, which if
minimized globally, would produce rank-1 solutions. We show empirically that these algorithms
produce  very close to zero (on average in the order of 10âˆ’3). In Section 6, we show how our
SDP formulation can be used to provide certificates for certain (NP-hard) questions of economic
interest about Nash equilibria. These are the problems of testing whether the maximum welfare
achievable under any Nash equilibrium exceeds some threshold, and whether a set of strategies is
played in every Nash equilibrium. In Section 7, we show that by using the Lasserre/sum of squares
hierarchy, we can get an arbitrarily close spectrahedral outer approximation to the convex hull of
Nash equilibria (Theorem 7.5), and that the SDP analyzed in this paper dominates the first level
of the Lasserre hierarchy (Proposition 7.1). Some directions for future research are discussed in
Section 8.
2 The Formulation of our SDP Relaxation
In this section we present an SDP relaxation for the problem of finding Nash equilibria in bi-
matrix games. This is done after a straightforward reformulation of the problem as a nonconvex
quadratically constrained quadratic program. Throughout the paper the following notation is used.
Â· Ai, refers to the i-th row of a matrix A.
Â· A,j refers to the j-th column of a matrix A.
Â· ei refers to the elementary vector (0, . . . , 0, 1, 0, . . . , 0)T with the 1 being in position i.
Â· 4k refers to the k-dimensional simplex.
Â· 1m refers to the m-dimensional vector of oneâ€™s.
Â· 0m refers to the m-dimensional vector of zeroâ€™s.
Â· Jm,n refers to the mÃ— n matrix of oneâ€™s.
Â· A  0 denotes that the matrix A is positive semidefinite (psd), i.e., has nonnegative eigen-
values.
Â· A â‰¥ 0 denotes that the matrix A is nonnegative, i.e., has nonnegative entries.
Â· A  B denotes that Aâˆ’B  0.
Â· SkÃ—k denotes the set of symmetric k Ã— k matrices.
Â· Tr(A) denotes the trace of a matrix A, i.e., the sum of its diagonal elements.
Â· AâŠ—B denotes the Kronecker product of matrices A and B.
Â· vec(M) denotes the vectorized version of a matrix M , and diag(M) denotes the vector con-
taining its diagonal entries.
3
We also assume that all entries of the payoff matrices A and B are between 0 and 1. This
can be done without loss of generality because Nash equilibria are invariant under certain affine
transformations in the payoffs. In particular, the games (A,B) and (cA+ dJmÃ—n, eB + fJmÃ—n)
have the same Nash equilibria for any scalars c, d, e, and f , with c and e positive. This is because
xâˆ—TAy â‰¥ xTAy
â‡” c(xâˆ—TAyâˆ—) + d â‰¥ c(xTAyâˆ—) + d
â‡” c(xâˆ—TAyâˆ—) + d(xâˆ—TJmÃ—nyâˆ—) â‰¥ c(xTAyâˆ—) + d(xTJmÃ—nyâˆ—)
â‡” xâˆ—T (cA+ dJmÃ—n)yâˆ— â‰¥ xT (cA+ dJmÃ—n)y
Identical reasoning applies for player B.
2.1 Nash Equilibria as Solutions to Quadratic Programs
Recall the definition of a Nash equilibrium from Section 1. The following offers a straightforward
reformulation, which states that existence of a profitable deviation implies existence of a profitable
pure strategy deviation.
Proposition 2.1. A strategy pair (xâˆ—, yâˆ—) âˆˆ 4m Ã—4n is a Nash equilibrium for the game (A,B)
if and only if
xâˆ—TAyâˆ— â‰¥ eTi Ayâˆ—,âˆ€i âˆˆ {1, . . . ,m},
xâˆ—TByâˆ— â‰¥ xâˆ—TBei, âˆ€i âˆˆ {1, . . . , n}.
Proof. The fact that we require xâˆ—TAyâˆ— â‰¥ eTi Ayâˆ—, xâˆ—TByâˆ— â‰¥ xâˆ—TBei follows from the definition
of a Nash equilibrium as each ei is a simplex vector. For the other direction, observe that if
xâˆ—TAyâˆ— â‰¥ eTi Ayâˆ—, âˆ€i, then we must have
xâˆ—TAyâˆ— â‰¥ max
i
eTi Ay
âˆ— â‰¥ xTAyâˆ—, âˆ€x âˆˆ 4m,
where the second inequality follows from that for any x âˆˆ 4m, the quantity xTAy is a convex
combination of the scalars eTi Ay. The same logic applies to y and B and this concludes the
proof.
We now treat the Nash problem as the following quadratic programming (QP) feasibility prob-
lem:
min
xâˆˆRm,yâˆˆRn
0
subject to xTAy â‰¥ eTi Ay,âˆ€i âˆˆ {1, . . . ,m},
xTBy â‰¥ xTBej ,âˆ€j âˆˆ {1, . . . , n},
xi â‰¥ 0, âˆ€i âˆˆ {1, . . . ,m},
yi â‰¥ 0,âˆ€j âˆˆ {1, . . . , n},
mâˆ‘
i=1
xi = 1,
nâˆ‘
i=1
yi = 1.
(1)
4
An identical argument as in Proposition 2.1 shows that xâˆ— âˆˆ 4m and yâˆ— âˆˆ 4n form an -Nash
equilibrium for the game (A,B) if and only if
xâˆ—TAyâˆ— â‰¥ eTi Ayâˆ— âˆ’ ,âˆ€i âˆˆ {1, . . . ,m},
xâˆ—TByâˆ— â‰¥ xâˆ—TBei âˆ’ ,âˆ€i âˆˆ {1, . . . , n}.
Observe that any pair of simplex vectors (x, y) is an -Nash equilibrium for the game (A,B) for
any  that satisfies
 â‰¥ max{max
i
eTi Ay âˆ’ xTAy,max
i
xTBei âˆ’ xTBy}.
We use the following notation throughout the paper:
Â· A(x, y) := max
i
eTi Ay âˆ’ xTAy,
Â· B(x, y) := max
i
xTBei âˆ’ xTBy,
Â· (x, y) := max{A(x, y), B(x, y)},
and the function parameters are later omitted if they are clear from the context.
2.2 SDP Relaxation
The QP formulation in (1) lends itself to a natural SDP relaxation. We define a matrix
M :=
[
X P
Z Y
]
,
and an augmented matrix
Mâ€² :=
ï£®ï£°X P xZ Y y
x y 1
ï£¹ï£» ,
with X âˆˆ SmÃ—m, Z âˆˆ RnÃ—m, Y âˆˆ SnÃ—n, x âˆˆ Rm, y âˆˆ Rn and P = ZT .
The SDP relaxation can then be expressed as
min
Mâ€²âˆˆSm+n+1,m+n+1
0 (SDP1)
subject to Tr(AZ) â‰¥ eTi Ay,âˆ€i âˆˆ {1, . . . ,m}, (2)
Tr(BZ) â‰¥ xTBej , âˆ€j âˆˆ {1, . . . , n}, (3)
mâˆ‘
i=1
xi = 1, (4)
nâˆ‘
i=1
yi = 1, (5)
Mâ€²ij â‰¥ 0 âˆ€i, j âˆˆ {1, . . . ,m+ n+ 1}, (6)
Mâ€²m+n+1,m+n+1 = 1, (7)
Mâ€²  0. (8)
We refer to the constraints (2) and (3) as the relaxed Nash constraints and the constraints (4)
and (5) as the unity constraints. This SDP is motivated by the following observation.
5
Proposition 2.2. Let Mâ€² be any rank-1 feasible solution to SDP1. Then the vectors x and y from
its last column constitute a Nash equilibrium for the game (A,B).
Proof. We know that x and y are in the simplex from the constraints (4), (5), and (6).
If the matrix Mâ€² is rank-1, then it takes the formï£®ï£°xxT xyT xyxT yyT y
xT yT 1
ï£¹ï£» =
ï£®ï£°xy
1
ï£¹ï£»ï£®ï£°xy
1
ï£¹ï£»T . (9)
Then, from the relaxed Nash constraints we have that
eTi Ay â‰¤ Tr(AZ) = Tr(AyxT ) = Tr(xTAy) = xTAy,
xTAei â‰¤ Tr(BZ) = Tr(ByxT ) = Tr(xTBy) = xTBy.
The claim now follows from Proposition 2.1.
Remark 2.1. Because a Nash equilibrium always exists, there will always be a matrix of the form (9)
which is feasible to SDP1. Thus we can disregard any concerns about SDP1 being feasible, even
when we add valid inequalities to it in Section 2.3.
Remark 2.2. It is intuitive to note that the submatrix P = ZT of the matrix Mâ€² corresponds to a
probability distribution over the strategies, and that seeking a rank-1 solution to our SDP can be
interpreted as making P a product distribution.
The following theorem shows that SDP1 is a weak relaxation and stresses the necessity of
additional valid constraints.
Theorem 2.3. Consider a bimatrix game with payoff matrices bounded in [0, 1]. Then for any
two vectors x âˆˆ 4m and y âˆˆ 4n, there exists a feasible solution Mâ€² to SDP1 with
ï£®ï£°xy
1
ï£¹ï£» as its last
column.
Proof. Consider any x, y, Î³ > 0, and the matrixï£®ï£°xy
1
ï£¹ï£»ï£®ï£°xy
1
ï£¹ï£»T + [Î³Jm+n,m+n 0m+n
0Tm+n 0
]
.
This matrix is the sum of two nonnegative psd matrices and is hence nonnegative and psd. By
assumption x and y are in the simplex, and so constraints (4)âˆ’ (8) of SDP1 are satisfied. To check
that constraints (2) and (3) hold, note that since A and B are nonnegative, as long as the matrices
A and B are not the zero matrices, the quantities Tr(AZ) and Tr(BZ) will become arbitrarily
large as Î³ increases. Since eTi Ay and x
TBei are bounded by 1 by assumption, we will have that
constraints (2) and (3) hold for Î³ large enough. In the case where A or B is the zero matrix, the
Nash constraints are trivially satisfied for the respective player.
2.3 Valid Inequalities
In this subsection, we introduce a number of valid inequalities to improve upon the SDP relaxation
in SDP1. These inequalities are justified by being valid if the matrix returned by the SDP is rank-1.
The terminology we introduce here to refer to these constraints is used throughout the paper.
6
2.3.1 Distribution Constraints
Proposition 2.4. Any rank-1 solution Mâ€² to SDP1 must satisfy the following:
mâˆ‘
i=1
mâˆ‘
j=1
Xi,j = 1, (10)
nâˆ‘
i=1
mâˆ‘
j=1
Zi,j = 1, (11)
nâˆ‘
i=1
nâˆ‘
j=1
Yi,j = 1. (12)
Proof. Recall from (9) that if Mâ€² is rank-1, it is of the formï£®ï£°xxT xyT xyxT yyT y
xT yT 1
ï£¹ï£» =
ï£®ï£°xy
1
ï£¹ï£»ï£®ï£°xy
1
ï£¹ï£»T .
Then we must have
mâˆ‘
i=1
mâˆ‘
j=1
Xi,j =
mâˆ‘
i=1
mâˆ‘
j=1
xixj =
mâˆ‘
i=1
xi
mâˆ‘
j=1
xj = 1,
nâˆ‘
i=1
mâˆ‘
j=1
Zi,j =
nâˆ‘
i=1
mâˆ‘
j=1
yixj =
nâˆ‘
i=1
yi
mâˆ‘
j=1
xj = 1,
nâˆ‘
i=1
nâˆ‘
j=1
Yi,j =
nâˆ‘
i=1
nâˆ‘
j=1
yiyj =
nâˆ‘
i=1
yi
nâˆ‘
j=1
yj = 1.
The next proposition shows that we can drop constraint (11) from above.
Proposition 2.5. In SDP1, the equality in (11) is implied by the equalities in (10) and (12) along
with the unity and positive semidefiniteness constraints on Mâ€².
Proof. Denote sX , sY , sZ as the sums of all elements inX, Y and Z respectively (note sX = sY = 1).
If sz > 1, then ï£®ï£° 1mâˆ’1n
0
ï£¹ï£»TMâ€²
ï£®ï£° 1mâˆ’1n
0
ï£¹ï£» = sX + sY âˆ’ 2sZ = 2âˆ’ 2sz < 0.
If sz < 1, thenï£®ï£°1m1n
âˆ’2
ï£¹ï£»TMâ€²
ï£®ï£°1m1n
âˆ’2
ï£¹ï£» = sX + sY + 2sZ + 4âˆ’ 4 mâˆ‘
i=1
xâˆ’ 4
nâˆ‘
i=1
y = âˆ’2 + 2sZ < 0.
Since we require Mâ€² be positive semidefinite, it must be that condition (11) holds.
7
2.3.2 Row Constraints
Proposition 2.6. Any rank-1 solution Mâ€² to SDP1 must satisfy the following:
mâˆ‘
j=1
Xi,j =
nâˆ‘
j=1
Pi,j = xi, âˆ€i âˆˆ {1, . . . ,m}, (13)
nâˆ‘
j=1
Yi,j =
mâˆ‘
j=1
Zi,j = yi, âˆ€i âˆˆ {1, . . . , n}. (14)
Proof. Recall the rank-1 form of Mâ€². Then we must have
mâˆ‘
j=1
Xi,j =
mâˆ‘
j=1
xixj = xi,âˆ€i âˆˆ {1, . . . ,m},
nâˆ‘
j=1
Pi,j =
nâˆ‘
j=1
yjxi = xi,âˆ€i âˆˆ {1, . . . ,m},
nâˆ‘
j=1
Yi,j =
nâˆ‘
j=1
yiyj = yi, âˆ€i âˆˆ {1, . . . , n},
mâˆ‘
j=1
Zi,j =
mâˆ‘
j=1
yixj = yi, âˆ€i âˆˆ {1, . . . , n}.
Remark 2.3. One can easily show that the distribution constraints are also implied by the row
constraints in conjunction with the unity constraints, but it will be useful for us later to refer to
them separately.
2.3.3 Correlated Equilibrium Constraints
Proposition 2.7. Any rank-1 solution Mâ€² to SDP1 must satisfy the following:
nâˆ‘
j=1
Ai,jPi,j â‰¥
nâˆ‘
j=1
Ak,jPi,j , âˆ€i, k âˆˆ {1, . . . ,m}, (15)
mâˆ‘
j=1
Bj,iPj,i â‰¥
mâˆ‘
j=1
Bj,kPj,i, âˆ€i, k âˆˆ {1, . . . , n}. (16)
Proof. Note that the pair (x, y) is a Nash equilibrium if and only if
âˆ€i, xi > 0â‡’ eTi Ay = xTAy = max
i
eTi Ay,
âˆ€i, yi > 0â‡’ xTBei = xTBy = max
i
xTBei.
This is because the Nash conditions require that xTAy, a convex combination of eTi Ay, be at least
eTi Ay for all i. Indeed, if xi > 0 but e
T
i Ay < x
TAy, the convex combination must be less than
max
i
xTAy.
8
For each i such that xi = 0 or yi = 0, inequalities (15) and (16) reduce to 0 â‰¥ 0, so we only
need to consider strategies played with positive probability. Observe that if Mâ€² is rank-1, then
nâˆ‘
j=1
Ai,jPi,j = xi
nâˆ‘
j=1
Ai,jyj = xie
T
i Ay â‰¥ xieTkAy =
nâˆ‘
j=1
Ak,jPi,j , âˆ€i, k
mâˆ‘
j=1
Bj,iPj,i = yi
mâˆ‘
j=1
Bj,ixj = yix
TBei â‰¥ yixTBek =
mâˆ‘
j=1
Bj,iPj,k, âˆ€i, k.
There are two ways to interpret the inequalities in (15) and (16): the first is as a relaxation of
the constraint xi(e
T
i Ayâˆ’ eTj Ay) â‰¥ 0,âˆ€i, j, which must hold since any strategy played with positive
probability must give the best response payoff. The other interpretation is to have the distribution
over outcomes defined by P be a correlated equilibrium [2]. This can be imposed by a set of linear
constraints on the entries of P as explained next.
Suppose the players have access to a public randomization device which prescribes a pure
strategy to each of them (unknown to the other player). The distribution over the assignments can
be given by a matrix P , where Pi,j is the probability that strategy i is assigned to player A and
strategy j is assigned to player B. This distribution is a correlated equilibrium if both players have
no incentive to deviate from the strategy prescribed, that is, if the prescribed pure strategies a and
b satisfy
nâˆ‘
j=1
Ai,jProb(b = j|a = i) â‰¥
nâˆ‘
j=1
Ak,jProb(b = j|a = i),
mâˆ‘
i=1
Bi,jProb(a = i|b = j) â‰¥
mâˆ‘
i=1
Bi,kProb(a = i|b = j).
If we interpret the P submatrix in our SDP as the distribution over the assignments by the
public device, then because of our row constraints, Prob(b = j|a = i) = Pi,jxi whenever xi 6= 0
(otherwise the above inequalities are trivial). Similarly, P (a = i|b = j) = Pi,jyj for nonzero yj .
Observe now that the above two inequalities imply (15) and (16). Finally, note that every Nash
equilibrium generates a correlated equilibrium, since if P is a product distribution given by xyT ,
then Prob(b = j|a = i) = yj and P (a = i|b = j) = xi.
2.4 McCormick Inequalities
McCormick inequalities [23] are a well-known set of valid inequalities for box-constrained quadratic
programs. However, they are not included explicitly in our SDP because they are redundant given
the constraints we have, as shown in the following lemma.
Lemma 2.8. Let z :=
[
x
y
]
. The McCormick inequalities
Mi,j â‰¤ zi, âˆ€i, j âˆˆ {1, . . . ,m+ n},
Mi,j + 1 â‰¥ zi + zj ,âˆ€i, j âˆˆ {1, . . . ,m+ n},
are implied by the row constraints and nonnegativity of Mâ€².
9
Proof. The first inequality is immediate as a consequence of (13) and (14), as all entries of M are
nonnegative. To see why the second inequality holds, consider whichever submatrix X,Y, P , or Z
that contains Mi,j . Suppose that this submatrix is, e.g., P . Then, since P is nonnegative,
0 â‰¤
mâˆ‘
k=1,k 6=i
nâˆ‘
l=1,l 6=j
Pk,l
(13)
=
mâˆ‘
k=1,k 6=i
(xk âˆ’ Pk,j)
(14)
= (1âˆ’ xi)âˆ’ (yj âˆ’ Pi,j) = Pi,j + 1âˆ’ xi âˆ’ yj .
The same argument holds for the other submatrices, and this concludes the proof.
2.5 The Effect of Valid Inequalities on an Example Game
Consider the following randomly-generated 5Ã— 5 bimatrix game:
A =
ï£®ï£¯ï£¯ï£¯ï£¯ï£°
0.42 0.46 0.03 0.77 0.33
0.54 0.03 0.71 0.06 0.56
0.53 0.43 0.17 0.85 0.30
0.19 0.56 0.59 0.38 0.37
0.08 0.64 0.61 0.40 0.35
ï£¹ï£ºï£ºï£ºï£ºï£» , B =
ï£®ï£¯ï£¯ï£¯ï£¯ï£°
0.63 0.19 0.09 0.22 0.33
0.66 0.92 0.26 0.97 0.43
0.99 0.29 0.43 0.43 0.72
0.94 0.55 0.58 0.78 0.92
0.35 0.92 0.90 0.53 0.89
ï£¹ï£ºï£ºï£ºï£ºï£» .
Figure 1 demonstrates the shrinkage in the feasible set of our SDP, projected onto the first two
pure strategies of player A, as valid inequalities are added. Subfigure (a) depicts the Nash equilibria
and the feasible set of SDP1 (recall from 2.3 that the feasible region without valid inequalities is the
projection of the entire simplex). The row and distribution constraints are added for subfigure (b),
and the correlated equilibrium constraints are further added for subfigure (c). Subfigure (d) depicts
the true projection of the convex hull of Nash equilibria.
Figure 1: Reduction in the size of our spectrahedral outer approximation to the convex hull of Nash
equilibria through the addition of valid inequalities.
10
2.6 Strengthened SDP Relaxation
We now write out our new SDP with all constraints in one place. Recall the representation of the
matrix
Mâ€² :=
ï£®ï£°X P xZ Y y
xT yT 1
ï£¹ï£» ,
with P = ZT . The improved SDP is now:
min
Mâ€²âˆˆS(m+n+1)Ã—(m+n+1)
0 (SDP2)
subject to Mâ€²  0, (17)
Mâ€²ij â‰¥ 0, i, j âˆˆ {1, . . . ,m+ n+ 1}, (18)
Mâ€²m+n+1,m+n+1 = 1, (19)
mâˆ‘
i=1
xi = 1, (20)
nâˆ‘
i=1
yi = 1, (21)
Tr(AZ)âˆ’ eTi Ay â‰¥ 0,âˆ€i âˆˆ {1, . . . ,m}, (22)
Tr(BZ)âˆ’ xTBei â‰¥ 0, âˆ€i âˆˆ {1, . . . , n}, (23)
mâˆ‘
j=1
Xi,j =
nâˆ‘
j=1
Zj,i = xi, âˆ€i âˆˆ {1, . . . ,m}, (24)
nâˆ‘
j=1
Yi,j =
mâˆ‘
j=1
Zi,j = yi, âˆ€i âˆˆ {1, . . . , n}, (25)
nâˆ‘
j=1
Ai,jPi,j â‰¥
nâˆ‘
j=1
Ak,jPi,j , âˆ€i, k âˆˆ {1, . . . ,m}, (26)
mâˆ‘
j=1
Bj,iPj,i â‰¥
mâˆ‘
j=1
Bj,kPj,i, âˆ€i, k âˆˆ {1, . . . , n}. (27)
Constraints (22) and (23) are the relaxed Nash constraints, constraints (24) and (25) are the
row constraints, and constraints (26) and (27) are the correlated equilibrium constraints.
3 Exactness for Zero-Sum Games
In this section, we show that the semidefinite programs we have proposed are guaranteed to recover
a Nash equilibrium for zero-sum games. This class of games is solvable in polynomial time with
linear programming. Nonetheless, it is reassuring to know that our SDPs recover this important
special case.
Definition 3.1. A zero-sum game is a game in which the payoff matrices satisfy A = âˆ’B.
11
Remark 3.1. This definition captures a game in which two players are in direct competition, how-
ever, it clearly cannot be applied in the context of games where all payoffs are assumed to be
nonnegative. We later define (see Definition 3.3) a generalized zero-sum game, which preserves this
property of direct competition but is more general and allows for nonnegative payoffs.
Theorem 3.2. For a zero-sum game, the vectors x and y from the last column of any feasible
solution Mâ€² to SDP1 constitute a Nash equilibrium.
Proof. Recall that the relaxed Nash constraints (2) and (3) read
Tr(AZ) â‰¥ eTi Ay,âˆ€i âˆˆ {1, . . . ,m},
Tr(BZ) â‰¥ xTBej ,âˆ€j âˆˆ {1, . . . , n}.
Since B = âˆ’A, the latter statement is equivalent to
Tr(AZ) â‰¤ xTAej ,âˆ€j âˆˆ {1, . . . , n}.
In conjunction these imply
eTi Ay â‰¤ Tr(AZ) â‰¤ xTAej , âˆ€i âˆˆ {1, . . . ,m}, j âˆˆ {1, . . . , n}. (28)
We claim that any pair x âˆˆ 4m and y âˆˆ 4n which satisfies the above condition is a Nash
equilibrium. To see that xTAy â‰¥ eTi Ay,âˆ€i âˆˆ {1, . . . ,m}, observe that xTAy is a convex combination
of xTAej , which are at least e
T
i Ay by (28). To see that x
TBy â‰¥ xTBej â‡” xTAy â‰¤ xTAej , âˆ€j âˆˆ
{1, . . . , n}, observe that xTAy is a convex combination of eTi Ay, which are at most xTAej by (28).
Definition 3.3. We say that a game (A,B) is generalized zero-sum if there exist scalars c, d, e,
and f, with c > 0, e > 0, such that cA+ dJmÃ—n = âˆ’eB + fJmÃ—n.
One can easily show that there exist generalized zero-sum games for which not all feasible
solutions to SDP1 have Nash equilibria as their last columns (see Theorem 2.3). However, we show
that this is the case for SDP2. To prove this, we need the following lemma, which shows that
feasibility of a matrix Mâ€² in SDP2 is invariant under certain transformations of A and B.
Lemma 3.4. Let c, d, e, and f be any set of scalars with c > 0 and e > 0. If a matrix Mâ€² is
feasible to SDP2 with input payoff matrices A and B, then it is also feasible to SDP2 with input
matrices cA+ dJmÃ—n and eB + fJmÃ—n.
Proof. It suffices to check that constraints (22),(23),(26), and (27) of SDP2 still hold, as only the
relaxed Nash and correlated equilibrium constraints use the matrices A and B. We only show
that constraints (22) and (26) still hold because the arguments for constraints (23) and (27) are
identical.
First recall that due to constraints (21) and (25) of SDP2, Tr(JmÃ—nZ) = 1. To check that the
relaxed Nash constraints hold, observe that for scalars c > 0 and d, and for all i âˆˆ {1, . . . ,m},
Tr(AZ)âˆ’ eTi Ay â‰¥ 0
â‡” cTr(AZ) + dâˆ’ c(eTi Ay)âˆ’ d â‰¥ 0
â‡” cTr(AZ) + d(Tr(JmÃ—nZ))âˆ’ c(eTi Ay)âˆ’ d(Tr(JmÃ—nZ)) â‰¥ 0
â‡” Tr((cA+ dJmÃ—n)Z)âˆ’ eTi (cA+ dJmÃ—n)y â‰¥ 0.
12
Now recall from constraint (24) of SDP2 (keeping in mind that P = ZT ) that
âˆ‘n
j=1(JmÃ—n)i,jPi,j =
xi. To check that the correlated equilibrium constraints hold, observe that for scalars c > 0, d, and
for all i, k âˆˆ {1, . . . ,m},
nâˆ‘
j=1
Ai,jPi,j â‰¥
nâˆ‘
j=1
Ak,jPi,j
â‡” c
nâˆ‘
j=1
Ai,jPi,j + dxi â‰¥ c
nâˆ‘
j=1
Ak,jPi,j + dxi
â‡” c
nâˆ‘
j=1
Ai,jPi,j + d
nâˆ‘
j=1
(JmÃ—n)i,jPi,j â‰¥ c
nâˆ‘
j=1
Ak,jPi,j + d
nâˆ‘
j=1
(JmÃ—n)k,jPi,j
â‡”
nâˆ‘
j=1
(cAi,j + dJmÃ—n)k,jPi,j â‰¥
nâˆ‘
j=1
(cAi,j + dJmÃ—n)k,jPi,j .
Theorem 3.5. For a generalized zero-sum game, the vectors x and y from the last column of any
feasible solution Mâ€² to SDP2 constitute a Nash equilibrium.
Proof. Let A and B be the payoff matrices of the given generalized zero-sum game and let Mâ€² be
a feasible solution to SDP2. Since the game is generalized zero-sum, we know that cA+ dJmÃ—n =
âˆ’eB + fJmÃ—n for some scalars c > 0, e > 0, d, f . Consider a new game with input matrices
AÌƒ = cA + dJmÃ—n and BÌƒ = eB âˆ’ fJmÃ—n. By Lemma 3.4, Mâ€² is still feasible to SDP2 with input
matrices AÌƒ and BÌƒ. Furthermore, since the constraints of SDP1 are a subset of the constraints
of SDP2, Mâ€² is also feasible to SDP1. Now notice that since AÌƒ = âˆ’BÌƒ, Theorem 3.2 implies that
the vectors x and y in the last column form a Nash equilibrium to the game (AÌƒ, BÌƒ). Finally recall
from Section 2 that Nash equilibria are invariant to scaling and shifting of the payoff matrices, and
hence (x, y) is a Nash equilibrium to the game (A,B).
Remark 3.2. We later show in Proposition 5.1 that using the trace of M as the objective function
to SDP2 will guarantee that SDP2 returns a rank-1 solution.
4 Bounds on  for General Games
In this section, we provide upper bounds on the  returned by SDP2 for an arbitrary bimatrix
game. Since the problem of computing a Nash equilibrium in such a game is PPAD-complete, it is
unlikely that one can find rank-1 solutions to this SDP in polynomial time. In Section 5, we design
objective functions (such as variations of the nuclear norm) that empirically do very well in finding
low-rank solutions to SDP2. Nevertheless, it is of interest to know if the solution returned by SDP2
is not rank-1, whether one can recover an -Nash equilibrium from it and have a guarantee on .
Recall our notation for the matrices
M :=
[
X P
Z Y
]
,
and
13
Mâ€² :=
ï£®ï£°X P xZ Y y
xT yT 1
ï£¹ï£» .
Throughout this section, any matrices X,Z, P = ZT and Y or vectors x and y are assumed to be
taken from a feasible solution to SDP2. The ultimate results of this section are Theorems 4.5, 4.12,
and 4.16. To work towards them, we need a number of preliminary lemmas which we present in
Section 4.1.
4.1 Lemmas Towards Bounds on 
We first observe the following connection between the approximate payoffs Tr(AZ) and Tr(BZ),
and (x, y), as defined in Section 2.1.
Lemma 4.1. Consider a feasible solution Mâ€² to SDP2 and the vectors x and y and the matrix Z
from that solution. Then
(x, y) â‰¤ max{Tr(AZ)âˆ’ xTAy,Tr(BZ)âˆ’ xTBy}.
Proof. Note that since Tr(AZ) â‰¥ eTi Ay and Tr(BZ) â‰¥ xTBei from constraints (22) and (23)
of SDP2, we have A â‰¤ Tr(AZ)âˆ’ xTAy and B â‰¤ Tr(BZ)âˆ’ xTBy.
We thus are interested in the difference of the two matrices P = ZT and xyT . These two
matrices can be interpreted as two different probability distributions over the strategy outcomes.
The matrix P is the probability distribution from the SDP which generates the approximate payoffs
Tr(AZ) and Tr(BZ), while xyT is the product distribution that would have resulted if the matrix
had been rank-1. We will see that the difference of these distributions is key in studying the 
which results from the SDP. Hence, we first take steps to represent this difference.
Lemma 4.2. Consider any feasible matrix Mâ€² to SDP2, and its submatrix M. Let the matrix M
be given by an eigendecomposition
M =
kâˆ‘
i=1
Î»iviv
T
i =:
kâˆ‘
i=1
Î»i
[
ai
bi
] [
ai
bi
]T
, (29)
so that the eigenvectors vi âˆˆ Rm+n are partitioned into ai âˆˆ Rm and bi âˆˆ Rn. Then for all
i,
âˆ‘m
j=1(ai)j =
âˆ‘n
j=1(bi)j.
Proof. We know from the distribution constraints from Section 2.3.1 that
kâˆ‘
i=1
Î»i1
T
maia
T
i 1m
(10)
= 1, (30)
kâˆ‘
i=1
Î»i1
T
maib
T
i 1n
(11)
= 1, (31)
kâˆ‘
i=1
Î»i1
T
n bia
T
i 1m
(11)
= 1, (32)
kâˆ‘
i=1
Î»i1
T
n bib
T
i 1n
(12)
= 1. (33)
14
Then by subtracting terms we have
(30)âˆ’ (31) =
kâˆ‘
i=1
Î»i1
T
mai(a
T
i 1m âˆ’ bTi 1n) = 0, (34)
(32)âˆ’ (33) =
kâˆ‘
i=1
Î»i1
T
n bi(a
T
i 1m âˆ’ bTi 1n) = 0. (35)
By subtracting again these imply
(34)âˆ’ (35) =
kâˆ‘
i=1
Î»i(1
T
mai âˆ’ 1Tn bi)2 = 0. (36)
As all Î»i are nonnegative due to positive semidefiniteness of M, the only way for this equality to
hold is to have 1Tmai = 1
T
n bi, âˆ€i. This is equivalent to the statement of the claim.
From Lemma 4.2, we can let si :=
âˆ‘m
j=1(ai)j =
âˆ‘n
j=1(bi)j , and furthermore we assume without
loss of generality that each si is nonnegative. Note that from the row constraint (13) we have
xi =
mâˆ‘
j=1
Xij =
kâˆ‘
l=1
mâˆ‘
j=1
Î»l(al)i(al)j =
kâˆ‘
j=1
Î»jsj(al)i. (37)
Hence,
x =
kâˆ‘
i=1
Î»isiai. (38)
Similarly,
y =
kâˆ‘
i=1
Î»isibi. (39)
Finally note from the distribution constraint (10) that this implies
kâˆ‘
i=1
Î»is
2
i = 1. (40)
Lemma 4.3. Let
M =
kâˆ‘
i=1
Î»i
[
ai
bi
] [
ai
bi
]T
,
be a feasible solution to SDP2, such that the eigenvectors of M are partitioned into ai and bi withâˆ‘m
i=1 ai =
âˆ‘n
i=1 bi = si,âˆ€i. Then
P âˆ’ xyT =
kâˆ‘
i=1
kâˆ‘
j>i
Î»iÎ»j(sjai âˆ’ siaj)(sjbi âˆ’ sibj)T .
15
Proof. Using equations (38) and (39) we can write
P âˆ’ xyT =
kâˆ‘
i=1
Î»iaib
T
i âˆ’ (
kâˆ‘
i=1
Î»isiai)(
kâˆ‘
j=1
Î»jsjbj)
T
=
kâˆ‘
i=1
Î»iai(bi âˆ’ si
kâˆ‘
j=1
Î»jsjbj)
T
(40)
=
kâˆ‘
i=1
Î»iai(
kâˆ‘
j=1
Î»js
2
jbi âˆ’ si
kâˆ‘
j=1
Î»jsjbj)
T
=
kâˆ‘
i=1
kâˆ‘
j=1
Î»iÎ»jaisj(sjbi âˆ’ sibj)T
=
kâˆ‘
i=1
kâˆ‘
j>i
Î»iÎ»j(sjai âˆ’ siaj)(sjbi âˆ’ sibj)T .
We can relate  and P âˆ’ xyT with the following lemma.
Lemma 4.4. Consider any feasible solution Mâ€² to SDP2 and the matrix P âˆ’ xyT . Then
 â‰¤ â€–P âˆ’ xy
T â€–1
2
,
where â€– Â· â€–1 here denotes the entrywise L-1 norm, i.e., the sum of the absolute values of the entries
of the matrix.
Proof. Let D := P âˆ’ xyT . From Lemma 4.1,
A â‰¤ Tr(AZ)âˆ’ xTAy = Tr(A(Z âˆ’ yxT )).
If we then hold D fixed and restrict that A has entries bounded in [0,1], the quantity Tr(ADT ) is
maximized when
Ai,j =
{
1 Di,j â‰¥ 0
0 Di,j < 0
.
The resulting quantity Tr(ADT ) will then be the sum of all nonnegative elements of D. Since the
sum of all elements in D is zero, this quantity will be equal to 12â€–Dâ€–1.
The proof for B is identical, and the result follows from that  is the maximum of A and B.
4.2 Bounds on 
We provide a number of bounds on (x, y), where x and y are taken from the last column of a
feasible solution to SDP2. The first is a theorem stating that solutions which are â€œcloseâ€ to rank-1
provide small .
Theorem 4.5. Let Mâ€² be a feasible solution to SDP2. Suppose M is rank-k and its eigenvalues
are Î»1 â‰¥ Î»2 â‰¥ ... â‰¥ Î»k â‰¥ 0. Then, the x and y from the last column of Mâ€² constitute an -NE to
the game (A,B) with  â‰¤ m+n2
âˆ‘k
i=2 Î»i.
16
Proof. By the Perron Frobenius theorem (see e.g. [24, Chapter 8.3]), the eigenvector corresponding
to Î»1 can be assumed to be nonnegative, and hence
s1 = â€–a1â€–1 = â€–b1â€–1. (41)
We further note that for all i, since
[
ai
bi
]
is a vector of length m + n with 2-norm equal to 1, we
must have âˆ¥âˆ¥âˆ¥âˆ¥[aibi
]âˆ¥âˆ¥âˆ¥âˆ¥
1
â‰¤
âˆš
m+ n. (42)
Since si is the sum of the elements of ai and bi, we know that
si â‰¤ min{â€–aiâ€–1, â€–biâ€–1} â‰¤
âˆš
m+ n
2
. (43)
This then gives us
s2i â‰¤ â€–aiâ€–1â€–biâ€–1 â‰¤
m+ n
4
. (44)
Finally note that a consequence of the nonnegativity of â€– Â· â€–1 and (42) is that for all i, j,
â€–aiâ€–1â€–bjâ€–1 + â€–biâ€–1â€–aiâ€–1 â‰¤
âˆ¥âˆ¥âˆ¥âˆ¥[aibi
]âˆ¥âˆ¥âˆ¥âˆ¥
1
âˆ¥âˆ¥âˆ¥âˆ¥[ajbj
]âˆ¥âˆ¥âˆ¥âˆ¥
1
(42)
â‰¤ m+ n. (45)
Now we let D := P âˆ’ xyT and upper bound 12â€–Dâ€–1 using Lemma 4.3.
1
2
â€–Dâ€–1 =
1
2
â€–
kâˆ‘
i=1
kâˆ‘
j>i
Î»iÎ»j(sjai âˆ’ siaj)(sjbi âˆ’ sibj)T â€–1
â‰¤ 1
2
kâˆ‘
i=1
kâˆ‘
j>i
â€–Î»iÎ»j(sjai âˆ’ siaj)(sjbi âˆ’ sibj)T â€–1
â‰¤ 1
2
kâˆ‘
i=1
kâˆ‘
j>i
Î»iÎ»jâ€–sjai âˆ’ siajâ€–1â€–sjbi âˆ’ sibjâ€–1
â‰¤ 1
2
kâˆ‘
i=1
kâˆ‘
j>i
Î»iÎ»j(sjâ€–aiâ€–1 + siâ€–ajâ€–1)(sjâ€–biâ€–1 + siâ€–bjâ€–1)
(41),(44)
â‰¤ 1
2
kâˆ‘
j=2
Î»1s
2
1Î»j(sj + â€–ajâ€–1)(sj + â€–bjâ€–1)
+
1
2
kâˆ‘
i=2
kâˆ‘
j>i
Î»iÎ»j(s
2
j
m+ n
4
+ s2i
m+ n
4
+ sisjâ€–aiâ€–1â€–bjâ€–1 + sisjâ€–ajâ€–1â€–biâ€–1)
(42),(45),(43)
â‰¤ m+ n
2
Î»1s
2
1
kâˆ‘
i=2
Î»i
+
1
2
kâˆ‘
i=2
kâˆ‘
j>i
Î»iÎ»j
m+ n
4
(s2i + s
2
j ) + Î»iÎ»jsisj(m+ n)
AMGM
â‰¤ m+ n
2
Î»1s
2
1
kâˆ‘
i=2
Î»i +
m+ n
2
kâˆ‘
i=2
kâˆ‘
j>i
Î»iÎ»j(
s2i + s
2
j
4
+
s2i + s
2
j
2
)
17
=
m+ n
2
Î»1s
2
1
kâˆ‘
i=2
Î»i +
3(m+ n)
8
kâˆ‘
i=2
kâˆ‘
j>i
Î»iÎ»j(s
2
i + s
2
j )
=
m+ n
2
Î»1s
2
1
kâˆ‘
i=2
Î»i +
3(m+ n)
8
(
kâˆ‘
i=2
Î»is
2
i
kâˆ‘
j>i
Î»j +
kâˆ‘
i=2
Î»i
kâˆ‘
j>i
Î»js
2
j )
=
m+ n
2
Î»1s
2
1
kâˆ‘
i=2
Î»i +
3(m+ n)
8
(
kâˆ‘
j=2
Î»j
kâˆ‘
1<i<j
Î»is
2
i +
kâˆ‘
i=2
Î»i
kâˆ‘
j>i
Î»js
2
j )
â‰¤ m+ n
2
Î»1s
2
1
kâˆ‘
i=2
Î»i +
3(m+ n)
8
(
kâˆ‘
j=2
Î»js
2
j )
kâˆ‘
i=2
Î»i
(40)
=
m+ n
2
Î»1s
2
1
kâˆ‘
i=2
Î»i +
3(m+ n)
8
(1âˆ’ Î»1s21)
kâˆ‘
i=2
Î»i
=
m+ n
8
(3 + Î»1s
2
1)
kâˆ‘
i=2
Î»i
(40)
â‰¤ m+ n
2
kâˆ‘
i=2
Î»i.
4.3 Bounds on  in the Rank-2 Case
We now give a series of bounds on  which hold for feasible solutions to SDP2 that are rank-2 (note
that due to the row inequalities, M will have the same rank as Mâ€²). This is motivated by our
ability to show stronger (constant) bounds in this case, and the fact that we often recover rank-2
(or rank-1) solutions with our algorithms in Section 5. As it will be important in our study of this
particular case, we first recall the definition of a completely positive factorization/rank of a matrix.
Definition 4.6. A matrix M is completely positive (CP) if it admits a decomposition M = UUT
for some nonnegative matrix U .
Definition 4.7. The CP-rank of an nÃ— n CP matrix M is the smallest k for which there exists a
nonnegative nÃ— k matrix U such that M = UUT .
Theorem 4.8 (see e.g. [16] or Theorem 2.1 in [4]). A rank-2, nonnegative, and positive semidefinite
matrix is CP and has CP-rank 2.
It is also known (see e.g., Section 4 in [16]) that the CP factorization of a rank-2 CP matrix can
be found to arbitrary accuracy in polynomial time. With these preliminaries in mind, we present
lemmas which are similar to Lemmas 4.2 and 4.3, but provide a decomposition which is specific to
the rank-2 case.
Lemma 4.9. Suppose that a feasible solution Mâ€² to SDP2 is rank-2. Then there exists a decompo-
sition M = Ïƒ1
[
a
b
] [
a
b
]T
+ Ïƒ2
[
c
d
] [
c
d
]T
, where Ïƒ1 and Ïƒ2 are nonnegative, Ïƒ1 + Ïƒ2 = 1, a, c âˆˆ 4m,
and b, d âˆˆ 4n.
18
Proof. Since the matrixM is rank-2, nonnegative, and positive semidefinite, from Theorem 4.8 we
can decompose the matrix M into v1vT1 + v2vT2 where v1 and v2 are nonnegative. We can then
partition v1 and v2 into vectors
[
aâ€²
bâ€²
]
and
[
câ€²
dâ€²
]
as we did in Lemma 4.2. Furthermore, we note that
because the distribution constraints (10)-(12) still hold, by repeating the proof of Lemma 4.2, we
find that
âˆ‘m
i=1 a
â€²
i =
âˆ‘n
i=1 b
â€²
i, and
âˆ‘m
i=1 c
â€²
i =
âˆ‘n
i=1 d
â€²
i. By letting
Ïƒ1 = (
mâˆ‘
i=1
aâ€²i)
2, Ïƒ2 = (
mâˆ‘
i=1
câ€²i)
2, a =
aâ€²
âˆš
Ïƒ1
, b =
bâ€²
âˆš
Ïƒ1
, c =
câ€²
âˆš
Ïƒ2
, d =
dâ€²
âˆš
Ïƒ2
,
we have found constants Ïƒ1 and Ïƒ2, and vectors a, b, c and d which satisfy
M = Ïƒ1
[
a
b
] [
a
b
]T
+ Ïƒ2
[
c
d
] [
c
d
]T
,
and a, b, c, and d are simplex vectors. Note that we can assume Ïƒ1 and Ïƒ2 are both positive, as
otherwise we are in the rank-1 case. Finally, to show that Ïƒ1 + Ïƒ2 = 1, recall that the sum of all
elements in M is 4, as are the sum of the elements of
[
a
b
] [
a
b
]T
and
[
c
d
] [
c
d
]T
.
Lemma 4.10. Suppose a feasible solution Mâ€² to SDP2 is rank-2, and that
M = Ïƒ1
[
a
b
] [
a
b
]T
+ Ïƒ2
[
c
d
] [
c
d
]T
,
where Ïƒ1 and Ïƒ2 are nonnegative, Ïƒ1 + Ïƒ2 = 1, a, c âˆˆ 4m, and b, d âˆˆ 4n. Then,
P âˆ’ xyT = Ïƒ1Ïƒ2(aâˆ’ c)(bâˆ’ d)T .
Proof. Recall that in our notation,
P = Ïƒ1ab
T + Ïƒ2cd
T ,
x = Ïƒ1a+ Ïƒ2c,
y = Ïƒ1b+ Ïƒ2d.
Then,
P âˆ’ xyT = Ïƒ1abT + Ïƒ2cdT âˆ’ (Ïƒ1a+ Ïƒ2c)(Ïƒ1b+ Ïƒ2d)T
= Ïƒ1ab
T + Ïƒ2cd
T âˆ’ Ïƒ21abT âˆ’ Ïƒ1Ïƒ2adT âˆ’ Ïƒ1Ïƒ2cbT âˆ’ Ïƒ22cdT
= Ïƒ1(1âˆ’ Ïƒ1)abT âˆ’ Ïƒ1Ïƒ2adT âˆ’ Ïƒ1Ïƒ2cbT + Ïƒ2(1âˆ’ Ïƒ2)cdT
= Ïƒ1Ïƒ2ab
T âˆ’ Ïƒ1Ïƒ2adT âˆ’ Ïƒ1Ïƒ2cbT + Ïƒ2Ïƒ1cdT
= Ïƒ1Ïƒ2(aâˆ’ c)(bâˆ’ d)T .
With this decomposition we can present a series of constant additive factor approximations for
the rank-2 case. To do so we apply Lemma 4.4 to the decomposition in Lemma 4.10. All the
following proofs will use the notation with Ïƒ, a, b, c, and d as in Lemma 4.10.
Theorem 4.11. If a feasible solutionMâ€² to SDP2 is rank-2, then the x and y from the last column
of Mâ€² constitute a 12âˆ’Nash equilibrium.
19
Proof. We can use Lemma 4.10 to represent
D := P âˆ’ xyT = Ïƒ1Ïƒ2(aâˆ’ c)(bâˆ’ d)T ,
where Ïƒ1, Ïƒ2 â‰¥ 0, Ïƒ1 + Ïƒ2 = 1, a, c âˆˆ 4m, and b, d âˆˆ 4n. Then we can use Lemma 4.4 to get that
 â‰¤ â€–Dâ€–1
2
=
1
2
â€–Ïƒ1Ïƒ2(aâˆ’ c)(bâˆ’ d)T â€–1 â‰¤
1
2
Ïƒ1Ïƒ2â€–aâˆ’ câ€–1â€–bâˆ’ dâ€–1.
Since we have â€–aâ€–1 = â€–bâ€–1 = â€–câ€–1 = â€–dâ€–1 = 1, we get the following bound for :
1
2
Ïƒ1Ïƒ2â€–aâˆ’ câ€–1â€–bâˆ’ dâ€–1 â‰¤
1
2
Ïƒ1Ïƒ2 Â· 2 Â· 2 = 2Ïƒ1Ïƒ2.
Since Ïƒ1 and Ïƒ2 sum to one and are nonnegative, we know that Ïƒ1Ïƒ2 â‰¤ 14 , and hence we have
 â‰¤ 12 .
Theorem 4.12. If a feasible solution Mâ€² to SDP2 is rank-2, then either the x and y from its last
column constitute a 511 -NE, or a
5
11 -NE can be recovered from M
â€² in polynomial time.
Proof. We consider 3 cases, depending on whether A(x, y) and B(x, y) are greater than or less
than .4. If A â‰¤ .4, B â‰¤ .4, then (x, y) is already a .4-Nash equilibrium. Now consider the case
when A â‰¥ .4, B â‰¥ .4. Since A â‰¤ Tr(A(P âˆ’ xyT )T ) and B â‰¤ Tr(B(P âˆ’ xyT )T ), we have
Ïƒ1Ïƒ2(aâˆ’ c)TA(bâˆ’ d) â‰¥ .4, Ïƒ1Ïƒ2(aâˆ’ c)TB(bâˆ’ d) â‰¥ .4.
Since A, a, b, c, and d are all nonnegative and Ïƒ1Ïƒ2 â‰¤ 14 ,
aTAb+ cTAd â‰¥ (aâˆ’ c)TA(bâˆ’ d) â‰¥ 1.6,
and the same inequalities hold for for player B. In particular, since A and B have entries bounded
in [0,1] and a, b, c, and d are simplex vectors, all the quantities aTAb, cTAd, aTBb, and cTBd are
at most 1, and consequently at least .6. Hence (a, b) and (c, d) are both .4-Nash equilibria.
Now suppose that (x, y) is a .4-NE for one player (without loss of generality player A) but not for
the other (without loss of generality player B). Then A â‰¤ .4, and B â‰¥ .4. Let yâˆ— be a best response
for player B to x, and let p = 11+Bâˆ’A . Consider the strategy profile (xÌƒ, yÌƒ) := (x, py + (1âˆ’ p)y
âˆ—).
This can be interpreted as the outcome (x, y) occurring with probability p, and the outcome (x, yâˆ—)
happening with probability 1 âˆ’ p. In the first case, player A will have A(x, y) = A and player
B will have B(x, y) = B. In the second outcome, player A will have A(x, y
âˆ—) at most 1, while
player B will have B(x, y
âˆ—) = 0. Then under this strategy profile, both players have the same
upper bound for , which equals Bp =
B
1+Bâˆ’A . To find the worst case for this value, let B = .5
(note from Theorem 4.11 that B â‰¤ 12) and A = .4, and this will return  =
5
11 .
We now show a stronger result in the case of symmetric games.
Definition 4.13. A symmetric game is a game in which the payoff matrices A and B satisfy
B = AT .
Definition 4.14. A Nash equilibrium strategy (x, y) is said to be symmetric if x = y.
Theorem 4.15 (see Theorem 2 in [25]). Every symmetric bimatrix game has a symmetric Nash
equilibrium.
20
For the proof of Theorem 4.16 below we modify SDP2 so that we are seeking a symmetric
solution.
Theorem 4.16. Suppose the constraints x = y and X = P = Y are added to SDP2. Then if a
feasible solution Mâ€² to this new SDP is rank-2, either the x and y from its last column constitute
a symmetric 13 -NE, or a symmetric
1
3 -NE can be recovered from M
â€² in polynomial time.
Proof. If (x, y) is already a symmetric 13 -NE, then the claim is established. Now suppose that (x, y)
does not constitute a 13 -Nash equilibrium. Observe that since x = y, we must have a = b and c = d.
Then following the same reasoning as in the proof of Theorem 4.12, we have
Ïƒ1Ïƒ2(aâˆ’ c)TA(aâˆ’ c) â‰¥
1
3
.
Since A, a, and c are all nonnegative, and Ïƒ1Ïƒ2 â‰¤ 14 , we get
aTAa+ cTAc â‰¥ (aâˆ’ c)TA(aâˆ’ c) â‰¥ 4
3
.
In particular, at least one of aTAa and cTAc is at least 23 . Since the maximum possible payoff is 1,
at least one of (a, a) and (c, c) is a (symmetric) 13 -Nash equilibrium.
5 Algorithms for Lowering the Rank
In this section, we present heuristics which aim to find low-rank solutions to SDP2 and present some
empirical results. Recall that our SDP2 in Section 2.6 did not have an objective function. Hence, we
can encourage low-rank solutions by choosing certain objective functions, for example the nuclear
norm (i.e. trace) of the matrix M, which is a general heuristic for rank minimization [29, 12].
This simple objective function is already guaranteed to produce a rank-1 solution in the case of
generalized zero-sum games (see Proposition 5.1 below). For general games, however, one can
design better objective functions in an iterative fashion (see Section 5.1).
Proposition 5.1. For a generalized zero-sum game, any optimal solution to SDP2 with Tr(M) as
the objective function must be rank-1.
Proof. Let
M :=
[
X P
Z Y
]
,Mâ€² :=
ï£®ï£°X P xZ Y y
xT yT 1
ï£¹ï£» ,
with P = ZT , be a feasible solution to SDP2. In the case of generalized zero-sum games, from
Theorem 3.5 we know that that (x, y) is a Nash equilibrium. Then because the matrix Mâ€² must
be psd, by applying the Schur complement, we have that M 
[
x
y
] [
x
y
]T
, and therefore M =[
xxT xyT
yxT yyT
]
+ P for some psd matrix P and some Nash equilibrium (x, y). Given this expression,
the objective value is then xTx+ yT y+ Tr(P). As (x, y) is a Nash equilibrium, the choice of P = 0
results in a feasible solution. Since the zero matrix has the minimum possible trace among all psd
matrices, the solution will be the rank-1 matrix
[
x
y
] [
x
y
]T
.
21
5.1 Linearization Algorithms
The algorithms we present in this section are based on iterative linearization of certain nonconvex
objective functions. Motivated by the next proposition, we design two continuous (nonconvex)
objective functions that, if minimized exactly, would guarantee rank-1 solutions. We will then
linearize these functions iteratively.
Proposition 5.2. Let the matrices X and Y and vectors x and y be taken from a feasible solution
Mâ€² to SDP2. Then the matrix Mâ€² is rank-1 if and only if Xi,i = x2i and Yi,i = y2i for all i.
Proof. Necessity of the condition is trivial; we argue sufficiency. Denote the vector z =
[
x
y
]
. First
recall from the row constraints of Section 2.3.2 that M will have the same rank as Mâ€², as the
last column is a linear combination of the columns of X and Y . Since M is psd, we have that
Mi,j â‰¤
âˆš
Mi,iMj,j , which implies Mi,j â‰¤ zizj by the assumption of the proposition. Further
recall that a consequence of the unity constraints (20) and (21) is that
âˆ‘m+n
i=1
âˆ‘m+n
j=1 zizj = 4, and
that we require from the distribution constraints from Section 2.3.1 that
âˆ‘m+n
i=1
âˆ‘m+n
j=1 Mi,j = 4.
Now we can see that in order to have the equality
4 =
m+nâˆ‘
i=1
m+nâˆ‘
j=1
Mi,j â‰¤
m+nâˆ‘
i=1
m+nâˆ‘
j=1
zizj = 4,
we must have Mi,j = zizj for each i and j. Consequently M is rank-1.
We focus now on two nonconvex objectives that as a consequence of the above proposition
would return rank-1 solutions:
Proposition 5.3. All optimal solutions to SDP2 with the objective function
âˆ‘m+n
i=1
âˆš
Mi,i or
Tr(M)âˆ’ xTxâˆ’ yT y are rank-1.
Proof. We show that each of these objectives has a specific lower bound which is achieved if and
only if the matrix is rank-1.
Observe that since M
[
x
y
] [
x
y
]T
, we have
âˆš
Xi,i â‰¥ xi and
âˆš
Yi,i â‰¥ yi, and hence
m+nâˆ‘
i=1
âˆš
Mi,i â‰¥
mâˆ‘
i=1
xi +
nâˆ‘
i=1
yi = 2.
Further note that
Tr(M)âˆ’
[
x
y
]T [
x
y
]
â‰¥
[
x
y
]T [
x
y
]
âˆ’
[
x
y
]T [
x
y
]
= 0.
We can see that the lower bounds are achieved if and only if Xi,i = x
2
i and Yi,i = y
2
i for all i,
which by Proposition 5.2 happens if and only if M is rank-1.
We refer to our two objective functions in Proposition 5.3 as the â€œsquare root objectiveâ€ and
the â€œdiagonal gap objectiveâ€ respectively. While these are both nonconvex, we will attempt to
iteratively minimize them by linearizing them through a first order Taylor expansion. For example,
at iteration k of the algorithm,
m+nâˆ‘
i=1
âˆš
M(k)i,i '
m+nâˆ‘
i=1
âˆš
M(kâˆ’1)i,i +
1
2
âˆš
M(kâˆ’1)i,i
(M(k)i,i âˆ’M
(kâˆ’1)
i,i ).
22
Note that for the purposes of minimization, this reduces to minimizing
âˆ‘m+n
i=1
1âˆš
M(kâˆ’1)i,i
M(k)i,i .
In similar fashion, for the second objective function, at iteration k we can make the approxi-
mation
Tr(M)âˆ’
[
x
y
](k)T [
x
y
](k)
' Tr(M)âˆ’
[
x
y
](kâˆ’1)T [
x
y
](kâˆ’1)T
âˆ’ 2
[
x
y
](kâˆ’1)T
(
[
x
y
](k)
âˆ’
[
x
y
](kâˆ’1)
).
Once again, for the purposes of minimization this reduces to minimizing Tr(M)âˆ’2
[
x
y
](kâˆ’1)T [
x
y
](k)
.
This approach then leads to the following two algorithms.3
Algorithm 1 Square Root Minimization Algorithm
1: Let x(0) = 1m, y
(0) = 1n, k = 1.
2: while !convergence do
3: Solve SDP2 with
âˆ‘m
i=1
1âˆš
x
(kâˆ’1)
i
Xi,i +
âˆ‘n
i=1
1âˆš
y
(kâˆ’1)
i
Yi,i as the objective, and denote the op-
timal solution by Mâ€²âˆ—.
4: Let x(k) = diag(Xâˆ—), y(k) = diag(Y âˆ—).
5: Let k = k + 1.
6: end while
Algorithm 2 Diagonal Gap Minimization Algorithm
1: Let x(0) = 0m, y
(0) = 0n, k = 1.
2: while !convergence do
3: Solve SDP2 with Tr(X)+Tr(Y )âˆ’2
[
x
y
](kâˆ’1)T [
x
y
](k)
as the objective, and denote the optimal
solution by Mâ€²âˆ—.
4: Let x(k) = xâˆ—, y(k) = yâˆ—.
5: Let k = k + 1.
6: end while
Remark 5.1. Note that the first iteration of both algorithms uses the nuclear norm (i.e. trace) of
M as the objective.
The square root algorithm has the following property.
Theorem 5.4. Let Mâ€²(1),Mâ€²(2), . . . be the sequence of optimal matrices obtained from the square
root algorithm. Then the sequence
{
m+nâˆ‘
i=1
âˆš
M(k)i,i } (46)
is nonincreasing and is lower bounded by two. If it reaches two at some iteration t, then the matrix
Mâ€²(t) is rank-1.
Proof. Observe that for any k > 1,
m+nâˆ‘
i=1
âˆš
M(k)i,i â‰¤
1
2
m+nâˆ‘
i=1
(
M(k)i,iâˆš
M(kâˆ’1)i,i
+
âˆš
M(kâˆ’1)i,i ) â‰¤
1
2
m+nâˆ‘
i=1
(
M(kâˆ’1)i,iâˆš
M(kâˆ’1)i,i
+
âˆš
M(kâˆ’1)i,i ) =
m+nâˆ‘
i=1
âˆš
M(kâˆ’1)i,i ,
3An algorithm similar to Algorithm 2 is used in [15].
23
where the first inequality follows from the arithmetic-mean-geometric-mean inequality, and the
second follows from that M(k)i,i is chosen to minimize
âˆ‘m+n
i=1
M(k)i,iâˆš
M(kâˆ’1)i,i
and hence achieves a no
larger value than the feasible solution M(kâˆ’1). This shows that the sequence is nonincreasing.
The proof of Proposition 5.3 already shows that the sequence is lower bounded by two, and
Proposition 5.3 itself shows that reaching two is sufficient to have the matrix be rank-1.
The diagonal gap algorithm has the following property.
Theorem 5.5. LetMâ€²(1),Mâ€²(2), . . . be the sequence of optimal matrices obtained from the diagonal
gap algorithm. Then the sequence
{Tr(M(k))âˆ’
[
x
y
](k)T [
x
y
](k)
} (47)
is nonincreasing and is lower bounded by zero. If it reaches zero at some iteration t, then the matrix
Mâ€²(t) is rank-1.
Proof. Observe that
Tr(M(k))âˆ’
[
x
y
](k)T [
x
y
](k)
â‰¤ Tr(M(k))âˆ’
[
x
y
](k)T [
x
y
](k)
+ (
[
x
y
](k)
âˆ’
[
x
y
](kâˆ’1)
)T (
[
x
y
](k)
âˆ’
[
x
y
](kâˆ’1)
)
= Tr(M(k))âˆ’ 2
[
x
y
](k)T [
x
y
](kâˆ’1)
+
[
x
y
](kâˆ’1)T [
x
y
](kâˆ’1)
â‰¤ Tr(M(kâˆ’1))âˆ’ 2
[
x
y
](kâˆ’1)T [
x
y
](kâˆ’1)
+
[
x
y
](kâˆ’1)T [
x
y
](kâˆ’1)
= Tr(M(kâˆ’1))âˆ’
[
x
y
](kâˆ’1)T [
x
y
](kâˆ’1)
,
where the second inequality follows from thatMâ€²(k) is chosen to minimize Tr(M(kâˆ’1))âˆ’2
[
x
y
](kâˆ’1)T [
x
y
](kâˆ’1)
and hence achieves a no larger value than the feasible solution Mâ€²(kâˆ’1). This shows that the se-
quence is nonincreasing.
The proof of Proposition 5.3 already shows that the sequence is lower bounded by zero, and
Proposition 5.3 itself shows that reaching zero is sufficient to have the matrix be rank-1.
5.2 Numerical Experiments
We tested Algorithms 1 and 2 on games coming from 100 randomly generated payoff matrices with
entries bounded in [0, 1] of varying sizes. Below is a table of statistics for 20 Ã— 20 matrices; the
data for the rest of the sizes can be found in Appendix A.4 We can see that our algorithms return
approximate Nash equilibria with fairly low  (recall the definition from Section 2.1). We ran 20
iterations of each algorithm on each game.
4The code that produced these results is publicly available at aaa.princeton.edu/software. The function nash.m
computes an approximate Nash equilibrium using one of our two algorithms as specified by the user.
24
Table 1: Statistics on  for 20Ã— 20 games after 20 iterations.
Algorithm Max Mean Median StDev
Square Root 0.0198 0.0046 0.0039 0.0034
Diagonal Gap 0.0159 0.0032 0.0024 0.0032
The histograms below show the effect of increasing the number of iterations on lowering  on
20 Ã— 20 games. For both algorithms, there was a clear improvement of the  by increasing the
number of iterations.
Figure 2: Distribution of  over numbers of iterations for the square root algorithm.
Figure 3: Distribution of  over numbers of iterations for the diagonal gap algorithm.
25
6 Bounding Payoffs and Strategy Exclusion
In addition to finding -additive Nash equilibria, our SDP approach can be used to answer certain
questions of economic interest about Nash equilibria without actually computing them. For in-
stance, economists often would like to know the maximum welfare (sum of the two playersâ€™ payoffs)
achievable under any Nash equilibrium, or whether there exists a Nash equilibrium in which a given
subset of strategies (corresponding, e.g., to undesirable behavior) is not played. Both these ques-
tions are NP-hard for bimatrix games [13]. In this section, we show how our SDP can be applied
to these problems and given some numerical experiments.
6.1 Bounding Payoffs
When designing policies that are subject to game theoretic behavior by agents, economists would
often like to find one with a good socially optimal outcome, which usually corresponds to an
equilibrium giving the maximum welfare. Hence, given a game, it is of interest to know the highest
achievable welfare under any Nash equilibrium.
To address this problem, we begin as we did in Section 2.1 by posing the question of maximizing
the welfare under any Nash equilibrium as a quadratic program. Since the feasible set of this
program is the set of Nash equilibria, the constraints are the same as those in the formulation
in (1), though the objective function is now the welfare:
max
x,y
xTAy + xTBy
subject to xTAy â‰¥ eTi Ay,âˆ€i âˆˆ {1, . . . ,m},
xTBy â‰¥ xTBej ,âˆ€j âˆˆ {1, . . . , n},
xi â‰¥ 0, âˆ€i âˆˆ {1, . . . ,m},
yj â‰¥ 0,âˆ€j âˆˆ {1, . . . , n},
mâˆ‘
i=1
xi = 1,
nâˆ‘
i=1
yi = 1.
(48)
The SDP relaxation of this quadratic program will then be given by
max
Mâ€²âˆˆSm+n+1,m+n+1
Tr(AZ) + Tr(BZ) (SDP3)
subject to (17)âˆ’ (27). (49)
One can easily see that the optimal value of this SDP is an upper bound on the welfare achievable
under any Nash equilibrium. To test the quality of this upper bound, we tested this SDP on a
random sample of one hundred 5Ã—5 and 10Ã—10 games5. The results are in Figures 4 and 5, which
show that the bound returned by SDP3 was exact in a large number of the experiments.
5The matrices were randomly generated with uniform and independent entries in [0,1]. The computation of the
upper bounds on the maximum payoffs was done with the function nashbound.m, which computes an SDP lower
bound on the problem of minimizing a quadratic function over the set of Nash equilibria of a bimatrix game. This
code is publicly available at aaa.princeton.edu/software. The exact computation of the maximum payoffs was done
with the lrsnash software [3], which computes extreme Nash equilibria. For a definition of extreme Nash equilibria
and for understanding why it is sufficient for us to compare against extreme Nash equilibria (both in Section 6.1 and
in Section 6.2), see Appendix B.
26
Figure 4: The quality of the upper bound on the maximum welfare obtained by SDP3 on 100 5Ã— 5
games.
Figure 5: The quality of the upper bound on the maximum welfare obtained by SDP3 on 100
10Ã— 10 games.
27
6.2 Strategy Exclusion
The strategy exclusion problem asks, given a subset of strategies S = (Sx,Sy), with Sx âŠ† {1, . . . ,m}
and Sy âŠ† {1, . . . , n}, is there a Nash equilibrium in which no strategy in S is played with positive
probability. We will call a set S â€œpersistentâ€ if the answer to this question is negative, i.e. at least
one strategy in S is played with positive probability in every Nash equilibrium. One application
of the strategy exclusion problem is to understand whether certain strategies can be discouraged
in the design of a game, such as reckless behavior in a game of chicken or defecting in a game of
prisonerâ€™s dilemma. In these particular examples these strategy sets are persistent and cannot be
discouraged.
A quadratic program which can address the strategy exclusion problem is as follows:
min
x,y
âˆ‘
iâˆˆSx
xi +
âˆ‘
iâˆˆSy
yi
subject to xTAy â‰¥ eTi Ay,âˆ€i âˆˆ {1, . . . ,m},
xTBy â‰¥ xTBej ,âˆ€j âˆˆ {1, . . . , n},
xi â‰¥ 0, âˆ€i âˆˆ {1, . . . ,m},
yj â‰¥ 0,âˆ€j âˆˆ {1, . . . , n},
mâˆ‘
i=1
xi = 1,
nâˆ‘
i=1
yi = 1.
(50)
Observe that by design, S is persistent if and only if this quadratic program has a positive
optimal value. The SDP relaxation of this problem is given by
min
Mâ€²âˆˆSm+n+1,m+n+1
âˆ‘
iâˆˆS
xi +
âˆ‘
iâˆˆS
yi (SDP4)
subject to (17)âˆ’ (27). (51)
Our approach for the strategy exclusion problem would be to declare that a strategy set is
persistent if and only if SDP4 has positive optimal value.
Note that since the optimal value of SDP4 is a lower bound for that of (50), SDP4 carries over
the property that if a set S is not persistent, then the SDP for sure returns zero. Thus, when
using SDP4 on a set which is not persistent, our algorithm will always be correct. However, this is
not necessarily the case for a persistent set. While we can be certain that a set is persistent if SDP4
returns a positive optimal value (again, because the optimal value of SDP4 is a lower bound for
that of (50)), there is still the possibility that for a persistent set SDP4 will have optimal value
zero.
To test the performance of SDP4, we generated 100 random games of size 5Ã—5 and 10Ã—10 and
computed all their extreme Nash equilibria6. We then, for every strategy set S of cardinality one
and two, checked whether that set of strategies was persistent, first by checking among the extreme
6The exact computation of the Nash equilibria was done again with the lrsnash software [3], which computes
extreme Nash equilibria. To understand why this suffices for our purposes see Appendix B.
28
Nash equilibria, then through SDP4. The results are presented in Tables 2 and 3. As motivated by
the discussion above, we separately show the performance on all instances and the performances
on persistent input instances. As can be seen, SDP4 was quite effective for the strategy exclusion
problem. In particular, for 10Ã— 10 games, we have a perfect identification rate.
Table 2: Performance of SDP4 on 5Ã— 5 games
|S| 1 2
Number of Total Sets 1000 4500
Number Correct 996 4465
Percent Correct 99.6 % 99.2 %
|S| 1 2
Number of Persistent Sets 22 1478
Number Correct 18 1443
Percent Correct 81.8% 97.6%
Table 3: Performance of SDP4 on 10Ã— 10 games
|S| 1 2
Number of Total Sets 2000 19000
Number Correct 2000 19000
Percent Correct 100 % 100 %
|S| 1 2
Number of Persistent Sets 11 841
Number Correct 11 841
Percent Correct 100% 100%
7 Higher Order Semidefinite Relaxations and the Sum of Squares
Hierarchy
The SDPs we have presented thus far have all had semidefinite constraints of size (m + n + 1) Ã—
(m+n+ 1). In this section, we demonstrate how increasing the size of the SDP can provide better
approximations to the convex hull of Nash equilibria.
7.1 Sum of Squares/Lasserre Hierarchy
The sum of squares/Lasserre hierarchy7 gives a recipe for constructing a sequence of SDPs whose
optimal values converge to the optimal value of a given polynomial optimization problem. In this
section, we will discuss the implications of this hierarchy for the Nash equilibrium problem. We
start with a very brief review of the Lasserre hierarchy.
Recall that a polynomial optimization problem (pop) is a problem of minimizing a polynomial
over a basic semialgebraic set, i.e., a problem of the form
min
xâˆˆRn
f(x)
subject to gi(x) â‰¥ 0, âˆ€i âˆˆ {1, . . . ,m},
(52)
where f, gi are polynomial functions. We say that a polynomial p is a sum of squares (sos) if there
exist polynomials q1, . . . , qr such that p =
âˆ‘r
i=1 q
2
i . A basic semialgebraic set {x âˆˆ Rn| gi(x) â‰¥ 0}
is said to be Archimedean if there exist a scalar R > 0 and sos polynomials Ïƒ0, . . . , Ïƒm such that
Râˆ’
nâˆ‘
i=1
x2i = Ïƒ0(x) +
mâˆ‘
i=1
Ïƒi(x)gi(x).
7The unfamiliar reader is referred to [19, 26, 20] for an introduction to the sum of squares/Lasserre hierarchy and
the related theory of moment relaxations.
29
Note that any Archimedean set is compact.
In this section, when we refer to the k-th level of the Lasserre hierarchy, we mean the optimiza-
tion problem
Î³ksos :=maxÎ³,Ïƒi
Î³
subject to f(x)âˆ’ Î³ = Ïƒ0(x) +
mâˆ‘
i=1
Ïƒi(x)gi(x),
Ïƒi is sos, âˆ€i âˆˆ {0, . . . ,m},
Ïƒ0, giÏƒi have degree at most 2k, âˆ€i âˆˆ {1, . . . ,m}.
(53)
There are two primary properties of the Lasserre hierarchy which are of interest. The first is
that when the degree of the polynomials f and gi are fixed, and when k is fixed, the k-th level of
this hierarchy is an SDP of size polynomial in n. The second is that, if the set {x âˆˆ Rn|gi(x) â‰¥ 0}
is Archimedean, then lim
kâ†’âˆ
Î³ksos = p
âˆ—, where pâˆ— is the optimal value of the pop in (52). This is a
consequence of Putinarâ€™s positivstellensatz [28], [19].
7.2 The Lasserre Hierarchy and SDP1
We show in this section that the first level of the Lasserre hierarchy is dominated by our SDP1.
Proposition 7.1. Consider the problem of minimizing any quadratic objective function over the
set of Nash equilibria of a bimatrix game. Then, SDP1 (and hence SDP2) gives a lower bound on
this problem which is no worse than that produced by the first level of the Lasserre hierarchy.
Proof. To prove this proposition we show that the first level of the Lasserre hierarchy is dual to a
weakened version of SDP1.
Explicit parametrization of first level of the Lasserre hierarchy. Consider the for-
mulation of the Lasserre hierarchy in (53) with k = 1. Suppose we are minimizing a quadratic
function
f(x, y) =
ï£®ï£°xy
1
ï£¹ï£»T C
ï£®ï£°xy
1
ï£¹ï£»
over the set of Nash equilibria as described by the linear and quadratic constraints in (1). If we
apply the first level of the Lasserre hierarchy to this particular pop, we get
30
max
Q,Î±,Ï‡,Î²,Ïˆ,Î·
Î³
subject to
ï£®ï£°xy
1
ï£¹ï£»T C
ï£®ï£°xy
1
ï£¹ï£»âˆ’ Î³ =
ï£®ï£°xy
1
ï£¹ï£»T Q
ï£®ï£°xy
1
ï£¹ï£»+ mâˆ‘
i=1
Î±i(x
TAy âˆ’ eTi Ay)
+
nâˆ‘
i=1
Î²i(x
TBy âˆ’ xTBei)
+
mâˆ‘
i=1
Ï‡ixi +
nâˆ‘
i=1
Ïˆiyi
+ Î·1(
mâˆ‘
i=1
xi âˆ’ 1) + Î·2(
nâˆ‘
i=1
yi âˆ’ 1),
Q  0,
Î±, Ï‡, Î², Ïˆ â‰¥ 0,
(54)
where Q âˆˆ Sm+n+1Ã—m+n+1, Î±, Ï‡ âˆˆ Rm, Î², Ïˆ âˆˆ Rn, Î· âˆˆ R2.
By matching coefficients of the two quadratic functions on the left and right hand sides of (54),
this SDP can be written as
max
Î³,Î±,Î²,Ï‡,Ïˆ,Î·
Î³
subject to H  0,
Î±, Î², Ï‡, Ïˆ â‰¥ 0,
(55)
where
H := 1
2
ï£®ï£° 0 (âˆ’âˆ‘mi=1 Î±i)A+ (âˆ’âˆ‘mi=1 Î²i)B âˆ‘ni=1 Î²iB,i âˆ’ Ï‡âˆ’ Î·11m(âˆ’âˆ‘mi=1 Î±i)A+ (âˆ’âˆ‘ni=1 Î²i)B 0 âˆ‘mi=1 Î±iATi, âˆ’ Ïˆ âˆ’ Î·21nâˆ‘n
i=1 Î²iB
T
,i âˆ’ Ï‡T âˆ’ Î·11Tm
âˆ‘m
i=1 Î±iAi, âˆ’ ÏˆT âˆ’ Î·21Tn 2Î·1 + 2Î·2 âˆ’ 2Î³
ï£¹ï£»+C.
(56)
Dual of a weakened version of SDP1. With this formulation in mind, let us consider a
weakened version of SDP1 with only the relaxed Nash constraints, unity constraints, and nonneg-
ativity constraints on x and y in the last column (i.e., the nonegativity constraint is not applied to
the entire matrix). Let the objective be Tr(CMâ€²). To write this new SDP in standard form, let
Ai :=
1
2
ï£®ï£° 0 A 0AT 0 âˆ’ATi,
0 âˆ’Ai, 0
ï£¹ï£» ,Bi := 1
2
ï£®ï£° 0 B âˆ’B,iBT 0 0
âˆ’BT,i 0 0
ï£¹ï£» ,
S1 :=
1
2
ï£®ï£° 0 0 1m0 0 0
1Tm 0 âˆ’2
ï£¹ï£» ,S2 := 1
2
ï£®ï£°0 0 00 0 1n
0 1Tn âˆ’2
ï£¹ï£» .
Let Ni be the matrix with all zeros except a 12 at entry (i,m+ n+ 1) and (m+ n+ 1, i) (or a 1 if
i = m+ n+ 1).
Then this SDP can be written as
31
min
Mâ€²
Tr(CMâ€²) (SDP0)
subject to Mâ€²  0, (57)
Tr(NiMâ€²) â‰¥ 0,âˆ€i âˆˆ {1, . . . ,m+ n}, (58)
Tr(AiMâ€²) â‰¥ 0,âˆ€i âˆˆ {1, . . . ,m}, (59)
Tr(BiMâ€²) â‰¥ 0, âˆ€i âˆˆ {1, . . . , n}, (60)
Tr(S1Mâ€²) = 0, (61)
Tr(S2Mâ€²) = 0, (62)
Tr(Nm+n+1) = 1. (63)
We now create dual variables for each constraint; we choose Î±i and Î²i for the relaxed Nash
constraints (59) and (60), Î·1 and Î·2 for the unity constraints (61) and (62), Ï‡ for the nonnegativity
of x (58), Ïˆ for the nonnegativity of y (58), and Î³ for the final constraint on the corner (63). These
variables are chosen to coincide with those used in the parametrization of the first level of the
Lasserre hierarchy, as can be seen more clearly below.
We then write the dual of the above SDP as
max
Î±,Î²,Î»,Î³
Î³
subject to
mâˆ‘
i=1
Î±iAi +
nâˆ‘
i=1
Î²iBi +
2âˆ‘
i=1
Î·iSi +
mâˆ‘
i=1
Ni+nÏ‡i +
nâˆ‘
i=1
NiÏˆi + Î³  C,
Î±, Î², Ï‡, Ïˆ â‰¥ 0.
which can be rewritten as
max
Î±,Î²,Ï‡,Ïˆ,Î³
Î³
subject to G  0,
Î±, Î², Ï‡, Ïˆ â‰¥ 0,
(64)
where
G := 1
2
ï£®ï£° 0 (âˆ’âˆ‘mi=1 Î±i)A+ (âˆ’âˆ‘mi=1 Î²i)B âˆ‘ni=1 Î²iB,i âˆ’ Ï‡âˆ’ Î·11m(âˆ’âˆ‘mi=1 Î±i)A+ (âˆ’âˆ‘ni=1 Î²i)B 0 âˆ‘mi=1 Î±iATi, âˆ’ Ïˆ âˆ’ Î·21nâˆ‘n
i=1 Î²iB
T
,i âˆ’ Ï‡T âˆ’ Î·11Tm
âˆ‘m
i=1 Î±iAi, âˆ’ ÏˆT âˆ’ Î·21Tn 2Î·1 + 2Î·2 âˆ’ 2Î³
ï£¹ï£»+C.
We can now see that the matrix G coincides with the matrix H in the SDP (55). Then we have
(54)opt = (55)opt = (64)opt â‰¤ SDP0opt â‰¤ SDP1opt,
where the first inequality follows from weak duality, and the second follows from that the constraints
of SDP0 are a subset of the constraints of SDP1.
Remark 7.1. One can see, either by inspection or as an implication of the proof of Theorem 2.3,
that in the case where the objective function corresponds to maximizing player Aâ€™s and/or Bâ€™s
32
payoffs8, SDPs (55) and (64) are infeasible. This means that for such problems the first level of
the Lasserre hierarchy gives a trivial upper bound of +âˆ on the maximum payoff. On the other
hand, the additional valid inequalities in SDP2 guarantee that the resulting bound is always finite.
Remark 7.2. The Lasserre hierarchy can be viewed in each step as a pair of primal-dual SDPs: the
sum of squares formulation which we have just presented, and a moment formulation which is dual to
the sos formulation [19]. All our SDPs in this paper can be viewed more directly as an improvement
upon the moment formulation. The valid inequalities in Section 2.3 were improvements upon the
first level of the Lasserre hierarchy. One can make similar improvements in higher order relaxations.
For example, since any strategy played with positive probability must give the same payoff, one
can add a relaxed version of the cubic constraints
xixj(e
T
i Ay âˆ’ eTj Ay) = 0, âˆ€i, j âˆˆ {1, . . . ,m},
to improve the second level of the Lasserre hierarchy.
7.3 The Lasserre Hierarchy and Convergence to Convex Hull of Nash Equilibria
Our goal for this section is to show that for any bimatrix game, there exists a sequence of SDPs
which provide an arbitrarily tight outer approximation to the convex hull of Nash equilibria. This
is obtained by a direct application of Lassereâ€™s hierarchy to (1), but we fill in the details. Before
we apply the Lasserre hierarchy, we need to first demonstrate the Archimedean property.
Lemma 7.2. The simplex constraints given by
{x âˆˆ Rm|
mâˆ‘
i=1
xi = 1, xi â‰¥ 0, i = 1, . . . ,m}
are Archimedean.
Proof. A basic semialgebraic set {x âˆˆ Rm| gi(x) â‰¥ 0, i = 1, . . . ,m, hj(x) = 0, j = 1, . . . , r} is
Archimedean if there exist a scalar R > 0 and sos polynomials Ïƒ0, . . . , Ïƒm such that
Râˆ’
nâˆ‘
i=1
x2i = Ïƒ0(x) +
mâˆ‘
i=1
Ïƒi(x)g(x) +
râˆ‘
i=1
pi(x)hi(x).
One can verify the following identity,
1âˆ’
mâˆ‘
i=1
x2i =
mâˆ‘
i=1
xi(
mâˆ‘
j=1,j 6=i
2x2j ) + (1âˆ’
mâˆ‘
i=1
xi)(1 +
mâˆ‘
i=1
xi + 2
mâˆ‘
i=1
mâˆ‘
j=1,j 6=i
xixj),
which proves that the simplex constraints are Archimedean since each polynomial
âˆ‘m
j=1,j 6=i 2x
2
j is
sos.
Corollary 7.3. The constraints of (1) are Archimedean.
8This would be the case, for example, in the maximum social welfare problem of Section 6.1, where the matrix of
the quadratic form in the objective function is given by
C =
ï£®ï£° 0 âˆ’Aâˆ’B 0âˆ’Aâˆ’B 0 0
0 0 0
ï£¹ï£» .
33
Proof. This is an immediate consequence of the following identity:
2âˆ’
mâˆ‘
i=1
x2i âˆ’
nâˆ‘
i=1
y2i =0 +
mâˆ‘
i=1
xi(
mâˆ‘
j=1,j 6=i
2x2j ) + (1âˆ’
mâˆ‘
i=1
xi)(1 +
mâˆ‘
i=1
xi + 2
mâˆ‘
i=1
mâˆ‘
j=1,j 6=i
xixj)
+
nâˆ‘
i=1
yi(
nâˆ‘
j=1,j 6=i
2y2j ) + (1âˆ’
nâˆ‘
i=1
yi)(1 +
nâˆ‘
i=1
yi + 2
nâˆ‘
i=1
nâˆ‘
j=1,j 6=i
yiyj)
+
mâˆ‘
i=1
(xTAy âˆ’ eTi Ay) Â· 0 +
nâˆ‘
i=1
(xTBy âˆ’ xTAei) Â· 0.
(65)
Definition 7.4. For a set S âŠ† Rn, we define its -neighborhood
N(S) := {x âˆˆ Rn| âˆƒs âˆˆ S such that â€–xâˆ’ sâ€–2 â‰¤ }
to be the set of points that are within distance  of S.
In the sequel, we denote the boundary of a set S by âˆ‚(S).
Proposition 7.5. For a bimatrix game, denote the convex hull of the set of its Nash equilibria by
convNE := convNE(A,B). Denote by Pk the projection to the x and y variables of the feasible set
of the SDP generated by the dual of the k-th level Lasserre hierarchy applied to (1). Then, for any
 > 0, there exists K such that Pk âŠ‚ N(convNE) for all k > K.
Proof. Consider  > 0. If, for some k, no point on the boundary of N(convNE) is in Pk, then
Pk âŠ‚ N(convNE). This is because Pk is convex and contains convNE.
Now suppose that for some  this is not the case, i.e., for any k, there exists some point
pk âˆˆ âˆ‚(N(convNE))âˆ©Pk. Consider the sequence of points {pk}. Since âˆ‚(N(convNE)) is a closed
and bounded set, the sequence {pk} has a convergent subsequence {pki} which converges to a point
pâˆ— âˆˆ âˆ‚(N(convNE)). We claim that pâˆ— âˆˆ Pk, âˆ€k.
Suppose for some K, we had pâˆ— /âˆˆ PK . Then because the complement of PK is open, for Î´ small
enough, NÎ´(p
âˆ—)âˆ©PK = âˆ…. Thus because Pk is a monotonically shrinking sequence, NÎ´(pâˆ—)âˆ©Pk = âˆ…
for all k > K. However, this contradicts the construction of pâˆ— as the limit of {pki}, since for any Î´
there is M large enough such that {pkm} âˆˆ NÎ´(pâˆ—) for any m > M . Thus, it must be that pâˆ— âˆˆ Pk
for all k > K.
Now note that such a point pâˆ— âˆˆ âˆ‚(N(convNE)) has nonzero distance to convNE, and therefore
there exists a hyperplane aT
[
x
y
]
= b which separates pâˆ— and the convex hull of Nash equilibria.
Without loss of generality suppose aT pâˆ— < b and aT c > b for any c in convNE. Now consider the
dual of Lasserre hierarchy applied to (1), but with the objective being the minimization of aT
[
x
y
]
.
By assumption, the maximum value achieved by any Nash equilibrium is strictly larger than b, but
the optimal value of the dual of the Lasserre hierarchy will converge to some number at most b
(since pâˆ— âˆˆ Pk, âˆ€k), and so will the Lasserre hierarchy by weak duality. Since the Lasserre hierarchy
must converge to the correct value under the Archimedean assumption, we have a contradiction.
Hence such an  cannot exist.
34
8 Future Work
Our work leaves many avenues of further research. Are there other interesting subclasses of games
(besides generalized zero-sum games) for which our SDP is guaranteed to recover an exact Nash
equilibrium? Can the guarantees on  in Section 4 be improved in the rank-2 case (or the general
case), for example by using the correlated equilibrium constraints (which we did not use)? Is
there a polynomial time algorithm that is guaranteed to find a rank-2 solution to SDP2? Such
an algorithm, together with our analysis, would improve the best known approximation bound
for symmetric games (see Theorem 4.16). Can SDPs in a higher level of the Lasserre hierarchy
be used to achieve better  guarantees? What are systematic ways of adding valid inequalities to
these higher-order SDPs by exploiting the structure of the Nash equilibrium problem? Finally, our
algorithms were specifically designed for two-player one-shot games. This leaves open the design
and analysis of semidefinite relaxations for repeated games or games with more than two players.
References
[1] I. Adler. The equivalence of linear programs and zero-sum games. International Journal of
Game Theory, 42(1):165â€“177, 2013.
[2] R. J. Aumann. Subjectivity and correlation in randomized strategies. Journal of Mathematical
Economics, 1(1):67â€“96, 1974.
[3] D. Avis, G. D. Rosenberg, R. Savani, and B. Von Stengel. Enumeration of Nash equilibria for
two-player games. Economic Theory, 42(1):9â€“37, 2010.
[4] A. Berman and N. Shaked-Monderer. Completely positive matrices. World Scientific, 2003.
[5] S. P. Boyd, L. El Ghaoui, E. Feron, and V. Balakrishnan. Linear matrix inequalities in system
and control theory, volume 15. SIAM, 1994.
[6] X. Chen and X. Deng. Settling the complexity of two-player Nash equilibrium. In FOCS,
volume 6, page 47th, 2006.
[7] X. Chen, X. Deng, and S.-H. Teng. Computing Nash equilibria: Approximation and smoothed
complexity. In 2006 47th Annual IEEE Symposium on Foundations of Computer Science
(FOCSâ€™06), pages 603â€“612. IEEE, 2006.
[8] G. B. Dantzig. A proof of the equivalence of the programming problem and the game problem.
Activity analysis of production and allocation, 13:330â€“338, 1951.
[9] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou. The complexity of computing a
Nash equilibrium. SIAM Journal on Computing, 39(1):195â€“259, 2009.
[10] C. Daskalakis, A. Mehta, and C. Papadimitriou. A note on approximate Nash equilibria. In
International Workshop on Internet and Network Economics, pages 297â€“306. Springer, 2006.
[11] C. Daskalakis, A. Mehta, and C. Papadimitriou. Progress in approximate Nash equilibria. In
Proceedings of the 8th ACM conference on Electronic commerce, pages 355â€“358. ACM, 2007.
[12] M. Fazel. Matrix rank minimization with applications. PhD thesis, PhD thesis, Stanford
University, 2002.
35
[13] I. Gilboa and E. Zemel. Nash and correlated equilibria: Some complexity considerations.
Games and Economic Behavior, 1(1):80â€“93, 1989.
[14] M. X. Goemans and D. P. Williamson. Improved approximation algorithms for maximum cut
and satisfiability problems using semidefinite programming. Journal of the ACM (JACM),
42(6):1115â€“1145, 1995.
[15] S. Ibaraki and M. Tomizuka. Rank minimization approach for solving BMI problems with
random search. In American Control Conference, 2001. Proceedings of the 2001, volume 3,
pages 1870â€“1875. IEEE, 2001.
[16] V. Kalofolias and E. Gallopoulos. Computing symmetric nonnegative rank factorizations.
Linear Algebra and its Applications, 436(2):421â€“435, 2012.
[17] S. C. Kontogiannis, P. N. Panagopoulou, and P. G. Spirakis. Polynomial algorithms for ap-
proximating Nash equilibria of bimatrix games. In International Workshop on Internet and
Network Economics, pages 286â€“296. Springer, 2006.
[18] R. Laraki and J. B. Lasserre. Semidefinite programming for minâ€“max problems and games.
Mathematical Programming, 131(1-2):305â€“332, 2012.
[19] J. B. Lasserre. Global optimization with polynomials and the problem of moments. SIAM
Journal on Optimization, 11(3):796â€“817, 2001.
[20] M. Laurent. Sums of squares, moment matrices and optimization over polynomials. In Emerg-
ing Applications of Algebraic Geometry, pages 157â€“270. Springer, 2009.
[21] C. E. Lemke and J. T. Howson, Jr. Equilibrium points of bimatrix games. Journal of the
Society for Industrial and Applied Mathematics, 12(2):413â€“423, 1964.
[22] L. LovaÌsz. On the shannon capacity of a graph. IEEE Transactions on Information theory,
25(1):1â€“7, 1979.
[23] G. P. McCormick. Computability of global solutions to factorable nonconvex programs: Part
I : Convex underestimating problems. Mathematical Programming, 10(1):147â€“175, 1976.
[24] C. D. Meyer. Matrix analysis and applied linear algebra, volume 2. SIAM, 2000.
[25] J. Nash. Non-cooperative games. Annals of mathematics, pages 286â€“295, 1951.
[26] P. A. Parrilo. Semidefinite programming relaxations for semialgebraic problems. Mathematical
Programming, 96(2):293â€“320, 2003.
[27] P. A. Parrilo. Polynomial games and sum of squares optimization. In Proceedings of the 45th
IEEE Conference on Decision and Control, pages 2855â€“2860. IEEE, 2006.
[28] M. Putinar. Positive polynomials on compact semi-algebraic sets. Indiana University Mathe-
matics Journal, 42(3):969â€“984, 1993.
[29] B. Recht, M. Fazel, and P. A. Parrilo. Guaranteed minimum-rank solutions of linear matrix
equations via nuclear norm minimization. SIAM Review, 52(3):471â€“501, 2010.
[30] R. Savani and B. Stengel. Hard-to-solve bimatrix games. Econometrica, 74(2):397â€“429, 2006.
36
[31] P. Shah and P. A. Parrilo. Polynomial stochastic games via sum of squares optimization. In
Decision and Control, 2007 46th IEEE Conference on, pages 745â€“750. IEEE, 2007.
[32] N. D. Stein. Exchangeable equilibria. PhD thesis, Massachusetts Institute of Technology, 2011.
[33] H. Tsaknakis and P. G. Spirakis. An optimization approach for approximate Nash equilibria.
In International Workshop on Web and Internet Economics, pages 42â€“56. Springer, 2007.
[34] L. Vandenberghe and S. Boyd. Semidefinite programming. SIAM Review, 38(1):49â€“95, 1996.
A Statistics on  from Algorithms in Section 5
Below are statistics for the  recovered in 100 random games of varying sizes using the algorithms
of Section 5.
Table 4: Statistics on  for 5Ã— 5 games after 20 iterations.
Algorithm Max Mean Median StDev
Square Root 0.0702 0.0040 0.0004 0.0099
Diagonal Gap 0.0448 0.0027 0 0.0061
Table 5: Statistics on  for 10Ã— 5 games after 20 iterations.
Algorithm Max Mean Median StDev
Square Root 0.0327 0.0044 0.0021 0.0064
Diagonal Gap 0.0267 0.0033 0.0006 0.0053
Table 6: Statistics on  for 10Ã— 10 games after 20 iterations.
Algorithm Max Mean Median StDev
Square Root 0.0373 0.0058 0.0039 0.0065
Diagonal Gap 0.0266 0.0043 0.0026 0.0051
Table 7: Statistics on  for 15Ã— 10 games after 20 iterations.
Algorithm Max Mean Median StDev
Square Root 0.0206 0.0050 0.0034 0.0045
Diagonal Gap 0.0212 0.0038 0.0025 0.0039
Table 8: Statistics on  for 15Ã— 15 games after 20 iterations.
Algorithm Max Mean Median StDev
Square Root 0.0169 0.0051 0.0042 0.0039
Diagonal Gap 0.0159 0.0038 0.0029 0.0034
37
Table 9: Statistics on  for 20Ã— 15 games after 20 iterations.
Algorithm Max Mean Median StDev
Square Root 0.0152 0.0046 0.0035 0.0036
Diagonal Gap 0.0119 0.0032 0.0022 0.0027
Table 10: Statistics on  for 20Ã— 20 games after 20 iterations.
Algorithm Max Mean Median StDev
Square Root 0.0198 0.0046 0.0039 0.0034
Diagonal Gap 0.0159 0.0032 0.0024 0.0032
B Lemmas for Extreme Nash Equilibria
The results reported in Section 6 were found using the lrsnash [3] software which computes extreme
Nash equilibria (see definition below). In particular the true maximum welfare and the persistent
strategy sets were found in relation to extreme Nash equilibria only. We show in this appendix why
this is sufficient for the claims we made about all Nash equilibria.
Definition B.1. An extreme Nash equilibrium is a Nash equilibrium which cannot be expressed
as a convex combination of other Nash equilibria.
Lemma B.2. All Nash equilibria are convex combinations of extreme Nash equilibria.
Proof. It suffices to show that any extreme point of the convex hull of the set of Nash equilibria
must be an extreme Nash equilibrium, as any point in a convex set can be written as a convex
combination of its extreme points. Suppose for the purpose of contradiction that this was not the
case, i.e. there is a point x which is an extreme point of the convex hull of Nash equilibria but is not
an extreme Nash equilibrium. Then either it is not a Nash equilibrium, or it is a Nash equilibrium
which is not extreme. In both cases, x can be written as a convex combination of other Nash
equilibria, and so cannot be an extreme point for the convex hull. For the former case it is because
its membership in the convex hull must be due to an expression of it as a convex combination of
Nash equilibria, and in the latter it is due to the definition of extreme Nash equilibria.
The next lemma shows that checking extreme Nash equilibria are sufficient for the maximum
welfare problem.
Lemma B.3. For any bimatrix game, there exists an extreme Nash equilibrium giving the maximum
welfare among all Nash equilibria.
Proof. Consider any Nash equilibrium (xÌƒ, yÌƒ), and let it be written as
[
xÌƒ
yÌƒ
]
=
âˆ‘r
i=1 Î»i
[
xi
yi
]
for some
set of extreme Nash equilibria
[
x1
y1
]
, . . . ,
[
xr
yr
]
and Î» âˆˆ 4r. Observe that for any i, j,
xiTAyj â‰¤ xjTAyj , xiTByj â‰¤ xiTByi, (66)
from the definition of a Nash equilibrium. Now note that
38
xÌƒT (A+B)yÌƒ = (
râˆ‘
i=1
Î»ix
i)T (A+B)(
râˆ‘
i=1
Î»iy
i)
=
râˆ‘
i=1
râˆ‘
j=1
Î»iÎ»jx
iT (A+B)yj
=
râˆ‘
i=1
râˆ‘
j=1
Î»iÎ»jx
iTAyj +
râˆ‘
i=1
râˆ‘
j=1
Î»iÎ»jx
iTByj
(66)
â‰¤
râˆ‘
i=1
râˆ‘
j=1
Î»iÎ»jx
jTAyj +
râˆ‘
i=1
râˆ‘
j=1
Î»iÎ»jx
iTByi
=
râˆ‘
i=1
Î»ix
iTAyi +
râˆ‘
i=1
Î»ix
iTByi
=
râˆ‘
i=1
Î»ix
iT (A+B)yi.
In particular, since each (xi, yi) is an extreme Nash equilibrium, this tells us for any Nash
equilibrium (xÌƒ, yÌƒ) there must be an extreme Nash equilibrium which has at least as much welfare.
Similarly for the results for persistent sets in Section 6.2, there is no loss in restricting attention
to extreme Nash equilibria.
Lemma B.4. For a given strategy set S, if every extreme Nash equilibrium plays at least one
strategy in S with positive probability, then every Nash equilibrium plays at least one strategy in S
with positive probability.
Proof. Let S be a persistent set of strategies. Since all Nash equilibria are composed of nonnegative
entries, and every extreme Nash equilibrium has positive probability on some entry in S, any convex
combination of extreme Nash equilibria must have positive probability on some entry in S.
39

