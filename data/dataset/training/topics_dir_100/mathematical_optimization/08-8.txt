 
Volume 6, Number 1, pp 56-60 
California Journal of Operations Management © 2008 CSU-POM 
 
Decision Making Under Uncertainty Using 
Mathematical Optimization: A Survey 
 
Michael R. Wagner 
California State University East Bay, Hayward, CA 
 
 
In this paper, we provide a survey of mathematical optimization techniques for decision making 
under uncertainty. We first consider situations where forecasts (i.e., probabilistic distributions) are 
available to characterize problem parameter uncertainty. We then consider techniques that are 
applicable for cases where a sufficient amount of data, and consequently forecasts, are not available. 
 
 
I. INTRODUCTION 
 
Quantitative optimization techniques have 
proven to be a powerful tool in tackling 
complicated decision-making problems in 
various application domains. Scheduling 
workforces, pricing airline tickets, managing 
production systems and designing engineering 
projects are just a small sample of the myriad 
industrial applications that have benefited from 
optimization techniques such as linear, non-
linear and integer programming, just to name a 
few. Deterministic optimization is a well-
developed field that, while perhaps not fully 
mature, has definitely passed out of adolescence. 
 However, despite the many successes, 
there are drawbacks to deterministic 
optimization techniques. A prominent 
underlying assumption is frequently violated in 
practice, namely, that problem data are known 
exactly. For example, in production systems, 
forecasts of future customer demand are 
routinely input into deterministic production 
optimization models. While this approximate 
approach can sometimes lead to an acceptable 
solution, in many cases practitioners resort to 
optimization techniques that account for 
uncertainty in the problem data. In this paper, we 
survey various techniques for optimization under 
uncertainty.  
Outline: In Section II, we consider optimization 
techniques when problem data uncertainty is 
characterized by probabilistic distributions. In 
particular, we consider chance-constrained 
programming, recourse-based stochastic 
programming and dynamic programming. In 
Section III, we consider approaches that are 
appropriate when there are not distributions 
available to characterize uncertain problem 
parameters; more specifically, we survey robust 
and online optimization in this section.  
 
II. TECHNIQUES WHEN FORECASTS 
ARE AVAILABLE 
  
In this section, we survey mathematical 
programming techniques when forecasts, or 
probabilistic distributions, are available to 
characterize a problem’s uncertainty. 
 
Chance-Constrained Programming 
In chance-constrained optimization, the problem 
data are not known, but are characterized by a 
given probabilistic distribution. To illustrate this 
method, we consider a linear programming 
model with a single constraint 
min{c'x : a'x $ b}. 
We assume that the constraint vector a is 
uncertain and that the remaining data (the vector 
Wagner 
Decision Making Under Uncertainty Using Mathematical Optimization: A Survey 
 
California Journal of Operations Management, Volume 6, Number 1, February 2008 
 
57 
c and scalar b) are known exactly. In chance-
constrained optimization, the vector a is 
characterized by a given multivariate distribution 
f. In other words, a is a vector of random 
variables.  
In chance-constrained programming, a 
vector x is considered feasible if it satisfies the 
constraint with at least a given probability. In 
particular, given a value p in the interval (0, 1), a 
chance-constrained variant of the above linear 
program is the following: 
min{c'x : P[a'x $ b] % p} 
 
Clearly, this approach is extendable to a generic 
linear program, where there is uncertainty in any 
of the problem data, which are characterized by 
probabilistic distributions. Chance-constrained 
programming originated in the work by Charnes 
and Cooper (1959). Examples of chance 
constrained programs, and corresponding 
solution approaches, can be found in Beraldi and 
Ruszczynski (2002), in the context of a 
probabilistic set-covering problem, Dentcheva, 
Prekopa and Ruszczynski (2002) and in the 
references therein. 
 
Recourse Programming 
In this section, we present recourse-based 
stochastic optimization, where two sets of 
decisions are made sequentially. In particular, an 
initial set of decisions must be made before all 
problem data are known exactly. After these 
initial decisions are made, the remaining 
problem data are realized (from a probabilistic 
distribution) and then a second set of decisions 
are made. This approach is also known as two-
stage stochastic programming. In a recourse 
model, an initial set of decisions x must be made 
and must satisfy some constraints Ax <= b, 
where A and b are known a priori. After the 
initial decisions are made, the remaining 
problem data are realized. It is usually assumed 
that there is a finite number of scenarios that are 
possible. Let S denote the set of all possible 
scenarios, s in S a specific scenario and p(s) the 
probability that scenario s is realized. Scenario s 
corresponds to the realizations of matrix B(s) 
and vectors d(s) and f(s). At this point, a second 
set of decisions y(s) must be made that satisfies 
the following constraint: B(s)x + Dy(s) $ d(s), 
where D is a matrix that is known. Since D is 
known a priori, the problem is said have fixed 
recourse. If the matrix D depends on the scenario 
realized, the problem is usually more difficult. 
This problem can be modeled by the following 
linear program:  
min c'x + +{s in S}p(s)f(s)'y(s)  
s.t.  
 Ax $ b  
B(s)x + Dy(s) $ d(s), for all s in S.  
 
Note that the summation in the objective can be 
considered an expected value. Our presentation 
of stochastic programming with recourse follows 
that of Bertsimas and Tsitsiklis (1997). See 
Birge and Louveaux (1997) for solution 
techniques, such as the L-method. An example 
of stochastic programming with recourse applied 
to a vehicle routing problem with random 
demands can be found in Frantzeskakis and 
Powell (1990).  
 
Dynamic Programming  
Dynamic programming is a frequently applied 
approach to optimization under uncertainty that 
has a sequential decision-making aspect. In the 
dynamic programming framework, we consider 
N stages (N possibly infinite), where in each 
stage a decision must be made. In particular, in 
stage k, the decision is denoted as u(k). There is 
also the notion of a state, which summarizes all 
relevant information up to a given stage; in stage 
k, the state is denoted as x(k). The state evolves 
as a function of the previous state, the decisions 
being made and a random disturbance. In 
particular, the state evolution is given by a 
function fk, for each stage k, as follows:  
x(k+1) = fk(x(k),u(k),w(k)), 
 
where w(k) is a random disturbance in stage k, 
whose distribution is known. In each stage k, a 
Wagner 
Decision Making Under Uncertainty Using Mathematical Optimization: A Survey 
 
California Journal of Operations Management, Volume 6, Number 1, February 2008 
 
58 
cost gk(x(k),u(k),w(k)) is incurred and a final 
cost gN+1(x(N+1)), depending on only the 
terminating state, is also incurred. The objective 
is to minimize the total expected cost  
E[+gk(x(k),u(k),w(k)) + gN+1(x(N+1))].  
 
A generic dynamic program is therefore  
minu(1),…,u(N)  E[+gk(x(k),u(k),w(k))+  
gN+1(x(N+1))]  
s.t.   
x(k+1) = fk(x(k),u(k),w(k))}.  
 
The generic approach to solve a dynamic 
program is to use a backwards recursion. We 
introduce the cost-to-go function Jk(x(k)), which 
is used in creating a recursion that is initialized 
at the final stage: 
JN+1(x(N+1)) = gN+1(x(N+1)) 
and  
Jk(x(k))= minu(1),…,u(N){E[gk(x(k),u(k),w(k))+ 
Jk+1(fk(x(k),u(k),w(k)))]},  
 
for all k. However, a straightforward solution of 
this recursion is usually prohibitive (known as 
the curse of dimensionality) and approximation 
techniques are utilized. Our presentation of 
dynamic programming follows that of Bertsekas 
(2007), which can also be referenced for more 
details, a myriad of applications and solution 
approaches, both exact and approximate. 
 
III. TECHNIQUES WHEN FORECASTS 
ARE NOT AVAILABLE 
  
In this section, we consider mathematical 
optimization techniques that are appropriate 
when there is less information to characterize 
problem data uncertainty. We first consider 
robust optimization, which uses set membership 
to characterize uncertainty. Then, we consider 
online optimization, an approach that simply 
assumes that the problem data is revealed 
incrementally. Throughout this section, it is 
assumed that probabilistic distributions (i.e., 
forecasts) are not available.  
 
Robust Optimization 
Robust optimization is perhaps best explained 
using linear programming, where certain 
problem data are unknown and no specific 
probabilistic distributions are available to 
characterize the uncertainty. Instead, the 
uncertainty is characterized by set membership; 
we are given sets that contain the true values of 
the problem parameters. To illustrate the robust 
optimization framework, we again consider a 
simple linear program  
min{c'x : a'x $ b}, 
 
which has a single uncertain constraint vector a 
= (a1,…,an). A common characterization of 
uncertainty in robust optimization is interval 
uncertainty; for each i = 1,…,n, there exists âi 
such that the true value of ai is contained in the 
interval [ai - âi, ai + âi]. The robust optimization 
framework, applied to this simple example, 
considers a solution feasible if it is feasible for 
any realization of the uncertain constraint vector. 
Therefore, the robust linear programming 
counterpart is the following  
 
min c'x   
s.t.  
+ãixi 3 b, for all ãi such that ai - âi $   
 ãi $ ai + âi, for all i.  
 
It can be shown that this counterpart is, in fact, 
equivalent to a standard linear program. This 
model of interval uncertainty is from Soyster 
(1973). 
More sophisticated approaches to robust 
optimization exist. For example, instead of 
interval uncertainty, one can consider ellipsoidal 
uncertainty; see, for example, Ben-Tal and 
Nemirovski (1998), Ben-Tal and Nemirovski 
(1999), Ben-Tal and Nemirovski (2000), El-
Ghaoui and Lebret (1997) and El-Ghaoui et al. 
(1998). Another approach is to consider a budget 
of uncertainty, where it is assumed that not all 
Wagner 
Decision Making Under Uncertainty Using Mathematical Optimization: A Survey 
 
California Journal of Operations Management, Volume 6, Number 1, February 2008 
 
59 
problem data will change simultaneous, as was 
implicitly assumed above; for further details, see 
Bertsimas and Sim (2003). In these cited works, 
the authors respectively show how a robust 
optimization problem can be recast as a 
deterministic mathematical program, usually 
with increases in complexity, which can then be 
solved using standard methods.  
 
Online Optimization 
The online optimization approach assumes that 
there is uncertainty in the problem data, but 
makes no assumption whatsoever about the 
structure of the uncertainty; it is only assumed 
that the problem data are revealed incrementally. 
In particular, no distributions nor sets are ever 
defined that characterize the uncertainty. 
Since we have just stated that the online 
optimization methodology does not characterize 
the problem data uncertainty, the reader might 
wonder what can be done. A natural task is to 
create optimization strategies that perform 
“relatively well" regardless of what data is 
actually realized. The relativity is measured with 
respect to another optimization strategy, for the 
same problem, that knew all the problem data 
with certainty a priori. Before we discuss the 
specifics of comparing strategies, we first must 
give some mathematical structure to the form of 
an online optimization problem. 
To make the above ideas more precise, we 
need to introduce some concepts and notation 
pertinent to the online optimization 
methodology. As previously mentioned, an 
online problem is one where the problem data 
are revealed incrementally. Decisions can and 
usually must be made before the entire problem 
instance is revealed. Any algorithm that gives a 
solution to an online problem is denoted an 
online algorithm. An offline algorithm solves the 
same problem but is given all of the problem 
data a priori; clearly, the offline algorithm will 
perform better than its online counterpart. 
Let I denote a complete instance of an 
online optimization problem. We partition I into 
a sequence of partial problem instances, 
hereafter denoted requests: I = (I1,…,In). These 
requests are revealed incrementally and 
collectively define the problem instance. In 
general, the number of requests n is not known a 
priori. There are two main frameworks for 
revealing these requests, namely a sequential 
model and a dynamic model. 
In the sequential model, when Ii is 
revealed, a decision by the online algorithm 
must be made before Ii+1 is revealed. In the 
dynamic model, the requests are revealed 
dynamically over time, irrespective of the 
actions of the online algorithm. The time at 
which a request is revealed is denoted as the 
request's release date. Note that time is usually 
an important dimension in the dynamic model, 
while it is not a necessary component in the 
sequential model. 
We now add precision to our earlier goal 
of designing an optimization strategy that 
performs relatively well for any realization of 
the problem data. More specifically, we describe 
a framework for evaluating the quality of online 
algorithms. For simplicity, we focus on 
minimization problems. Central concepts in the 
analysis of online algorithms are the notions of 
competitiveness and the competitive ratio. An 
online minimization algorithm is said to be r-
competitive (r % 1) if, given any instance of the 
problem, the cost of the solution given by the 
online algorithm is no more than r multiplied by 
that of an optimal offline algorithm. The 
minimum over all r such that an online 
algorithm is r-competitive is called the 
competitive ratio of the online minimization 
algorithm. An online algorithm is said to be 
best-possible if there does not exist another 
online algorithm with a strictly smaller 
competitive ratio. 
We conclude this section with a simple 
online optimization problem. We consider the 
online traveling salesman problem when all 
cities li are on the nonnegative real line. Cities 
are revealed at their release dates ri % 0; the 
salesman does not know a city exists until its 
release date. The total number of cities to be 
Wagner 
Decision Making Under Uncertainty Using Mathematical Optimization: A Survey 
 
California Journal of Operations Management, Volume 6, Number 1, February 2008 
 
60 
visited is not known either. A simple strategy for 
this problem is the Move-Right-If-Necessary 
(MRIN) algorithm: An online salesman starts at 
the origin and always moves right if he knows of 
an un-visited city to his right; otherwise, the 
salesman moves left, and back to the origin. It 
can be shown that the competitive ratio of this 
strategy is 1.5 (see Blom et al., 2001); 
furthermore, this result is best possible. When 
cities are instead located in a metric space, there 
exists a best-possible online algorithm that has a 
competitive ratio of 2 (see Ausiello et al., 2001).  
 
IV. CONCLUSIONS 
 
In this paper we surveyed the major techniques 
for optimization under uncertainty. We began 
with more classic approaches, where the 
problem uncertainty is assumed to be well 
characterized by probabilistic distributions. We 
then discussed more modern approaches, which 
address the realistic situation where accurate 
forecasts are not available to characterize the 
problem uncertainty.  
 
V. REFERENCES 
 
Ausiello, G., E. Feuerstein, S. Leonardi, L. 
Stougie, and M. Talamo, “Algorithms for 
The On-Line Traveling Salesman,” 
Algorithmica, 29(4), 2001, 560-581. 
Ben-Tal, A., and A. Nemirovski, “Robust 
Convex Optimization,” Mathematics of 
Operations Research, 23, 1998, 769-805. 
Ben-Tal, A., and A. Nemirovski, “Robust 
Solutions to Uncertain Programs,” 
Operations Research Letters, 25, 1999, 1-13. 
Ben-Tal, A., and A. Nemirovski, “Robust 
Solutions of Linear Programming Problems 
Contaminated with Uncertain Data,” 
Mathematical Programming, 88, 2000, 411-
424. 
Beraldi, P., and A. Ruszczynski, “The 
Probabilistic Set Covering Problem,” 
Operations Research, 50, 2002, 956-967. 
Bertsekas, D., Dynamic Programming and 
Optimal Control: Volume 1, Athena 
Scientific, 2007. 
Bertsimas, D., and M. Sim, “Price of 
Robustness,” Operations Research, 52, 2003, 
35-53. 
Bertsimas, D., and J. Tsitsiklis, Introduction to 
Linear Programming, Athena Scientific, 
1997. 
Birge, J., and F. Louveaux, Introduction to 
Stochastic Programming, Springer-Verlag, 
1997. 
Blom, M., S. Krumke, W. de Paepe, and L. 
Stougie, “The Online TSP Against Fair 
Adversaries,” INFORMS Journal on 
Computing, 13(2), 2001, 138-148. 
Charnes, A., and W. Cooper, “Chance-
constrained Programming,” Management 
Science, 6, 1959, 73-79.  
Dentcheva, D., A. Prekopa, and A. Ruszczynski, 
“Bounds for Probabilistic Integer 
Programming Problems,” Discrete Applied 
Mathematics, 124, 2002, 55-65. 
El-Ghaoui, L., and H. Lebret, “Robust Solutions 
to Least-Square Problems to Uncertain Data 
Matrices,” SIAM J. Matrix Anal. Appl., 18, 
1997, 1035-1064. 
El-Ghaoui, L., F. Oustry, and H. Lebret, “Robust 
Solutions to Uncertain Semidefinite 
Programs,” SIAM J. Optim., 9, 1998, 33-52. 
Frantzeskakis, L., and W. Powell, “A Successive 
Linear Approximation Procedure for 
Stochastic, Dynamic Vehicle Allocation 
Problems,” Transportation Science, 24, 
1990, 40-57. 
Soyster, A., “Convex Programming with Set-
Inclusive Constraints And Applications to 
Inexact Linear Programming,” Operations 
Research, 21, 1973, 1154-1157.

