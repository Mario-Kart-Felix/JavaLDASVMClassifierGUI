IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 3, NO. 4, NOVEMBER 1999 257
Multiobjective Evolutionary Algorithms:
A Comparative Case Study and
the Strength Pareto Approach
Eckart Zitzler and Lothar Thiele
Abstract—Evolutionary algorithms (EA’s) are often well-suited
for optimization problems involving several, often conflicting
objectives. Since 1985, various evolutionary approaches to mul-
tiobjective optimization have been developed that are capable
of searching for multiple solutions concurrently in a single run.
However, the few comparative studies of different methods pre-
sented up to now remain mostly qualitative and are often re-
stricted to a few approaches. In this paper, four multiobjective
EA’s are compared quantitatively where an extended 0/1 knap-
sack problem is taken as a basis. Furthermore, we introduce
a new evolutionary approach to multicriteria optimization, the
Strength Pareto EA (SPEA), that combines several features of
previous multiobjective EA’s in a unique manner. It is character-
ized by a) storing nondominated solutions externally in a second,
continuously updated population, b) evaluating an individual’s
fitness dependent on the number of external nondominated points
that dominate it, c) preserving population diversity using the
Pareto dominance relationship, and d) incorporating a clustering
procedure in order to reduce the nondominated set without
destroying its characteristics. The proof-of-principle results ob-
tained on two artificial problems as well as a larger problem, the
synthesis of a digital hardware–software multiprocessor system,
suggest that SPEA can be very effective in sampling from along
the entire Pareto-optimal front and distributing the generated
solutions over the tradeoff surface. Moreover, SPEA clearly out-
performs the other four multiobjective EA’s on the 0/1 knapsack
problem.
Index Terms— Clustering, evolutionary algorithm, knapsack
problem, multiobjective optimization, niching, Pareto optimality.
I. INTRODUCTION
MANY real-world problems involve simultaneous opti-mization of several incommensurable and often com-
peting objectives. Often, there is no single optimal solution,
but rather a set of alternative solutions. These solutions are
optimal in the wider sense that no other solutions in the search
space are superior to them when all objectives are considered.
They are known as Pareto-optimal solutions.
Consider, for example, the design of a complex hard-
ware/software system. An optimal design might be an ar-
chitecture that minimizes cost and power consumption while
maximizing the overall performance. However, these goals
are generally conflicting: one architecture may achieve high
Manuscript received July 24, 1998; revised March 18, 1999. This work was
supported by the Swiss National Science Foundation.
The authors are with the Computer Engineering and Networks Laboratory
(TIK), Swiss Federal Institute of Technology (ETH), Zürich, Switzerland (e-
mail: zitzler@tik.ee.ethz.ch; thiele@tik.ee.ethz.ch).
Publisher Item Identifier S 1089-778X(99)08067-4.
performance at high cost, an alternative low-cost architecture
might considerably increase power consumption—none of
these solutions can be said to be superior if we do not include
preference information (e.g., a ranking of the objectives).
Thus if no such information is available, it may be useful
to have knowledge about those alternative architectures. A
tool exploring the design space for Pareto-optimal solutions
in reasonable time can essentially aid the decision maker in
arriving at a final design.
Evolutionary algorithms (EA’s) seem to be particularly
suited for this task because they process a set of solutions
in parallel, possibly exploiting similarities of solutions by
recombination. Some researchers suggest that multiobjective
search and optimization might be a problem area where EA’s
do better than other blind search strategies [1], [2]. Although
this statement must be qualified with regard to the “no free
lunch” theorems [3], up to now there are few if any alternatives
to EA-based multiobjective optimization [4].
Since the mid-1980’s, there has been a growing interest
in solving multicriteria optimization problems using evolu-
tionary approaches. In the meantime, several multiobjective
EA’s are available that are capable of searching for multiple
Pareto-optimal solutions concurrently in a single run. They
differ mainly in the fitness assignment, but the question of
which of these methods is better on what type of problem
is mostly unsettled. The few comparative studies that have
been published up to now remain mostly qualitative and
are often restricted to a few algorithms. Therefore, extensive
quantitative comparisons are needed in order to assess the
performance of the EA’s in a greater context. Previous effort
in this direction has been reported in [5].
In the present study, we provide a comparison of five
multicriteria EA’s, four previously known and one new, by
solving a multiobjective 0/1 knapsack problem. Thereby, two
complementary quantitative measures are considered in order
to assess the performance of the algorithms concerning the
tradeoff surfaces produced. A random-search strategy as well
as a single-objective EA serve as additional points of reference.
The Strength Pareto Evolutionary Algorithm (SPEA), the new
multiobjective approach proposed in this paper, has been
developed on the basis of a comparative study previously
carried out [5]; it integrates established techniques used in
existing EA’s in a single unique algorithm. We show that
SPEA can have advantages over the other algorithms under
consideration in convergence to the Pareto-optimal front.
1089–778X/99$10.00  1999 IEEE
258 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 3, NO. 4, NOVEMBER 1999
The paper is organized as follows. Section II introduces
key concepts used in the field of evolutionary multicriteria
optimization and gives an overview of the multiobjective
EA’s considered in this investigation. The comparison of
the four multiobjective EA’s on the 0/1 knapsack problem
is the subject of Section III, which itself is divided into
three parts: description of the test problem, methodology
of the comparison, and experimental results. Section IV is
devoted to SPEA and describes both underlying principles
and the application to three problems (Schaffer’s , knapsack
problem, and system-level synthesis). The last section offers
concluding remarks and future perspectives.
II. MULTIOBJECTIVE OPTIMIZATION
USING EVOLUTIONARY ALGORITHMS
A. Definitions
A general multiobjective optimization problem can be de-
scribed as a vector function that maps a tuple of
parameters (decision variables) to a tuple of objectives.
Formally:
subject to
(1)
where is called the decision vector, is the parameter
space, is the objective vector, and is the objective space.1
The set of solutions of a multiobjective optimization prob-
lem consists of all decision vectors for which the correspond-
ing objective vectors cannot be improved in any dimension
without degradation in another—these vectors are known
as Pareto optimal. Mathematically, the concept of Pareto
optimality is as follows: Assume, without loss of generality,
a maximization problem and consider two decision vectors
. Then, is said to dominate (also written as )
iff
(2)
Additionally, in this study is said to cover iff
or . All decision vectors which are not
dominated by any other decision vector of a given set are
called nondominated regarding this set. If it is clear from
the context which set is meant, we simply leave it out. The
decision vectors that are nondominated within the entire search
space are denoted as Pareto optimal and constitute the so-
called Pareto-optimal set or Pareto-optimal front.
B. Fitness Assignment Strategies
In their excellent review of evolutionary approaches to mul-
tiobjective optimization, Fonseca and Fleming [1] categorize
1 The definitions and terms presented in this section correspond to the
mathematical formulations most widespread in multiobjective EA literature
(e.g., [6], [1]). For more detailed information, we refer to [7] and [8].
several multicriteria EA’s and compare different fitness assign-
ment strategies. In particular, they distinguish plain aggregat-
ing approaches, population-based non-Pareto approaches, and
Pareto-based approaches.
Aggregation methods combine the objectives into a higher
scalar function that is used for fitness calculation. Scalar-
ization is mandatory when applying an EA, but aggregation
approaches have the advantage of producing one single so-
lution. On the other hand, defining the goal function in this
way requires profound domain knowledge that is often not
available. Popular aggregation methods are the weighted-sum
approach, target vector optimization, and the method of goal
attainment [1], [6]. Nevertheless, pure aggregation methods are
not considered here because they are not designed for finding
a family of solutions.
Population-based non-Pareto approaches, however, are able
to evolve multiple nondominated solutions concurrently in
a single simulation run. By changing the selection criterion
during the reproduction phase, the search is guided in several
directions at the same time. Often, fractions of the mating pool
are selected according to one of the objectives [9], [10].
Other non-Pareto algorithms use multiple linear combinations
of the objectives in parallel [11], [12].
Pareto-based fitness assignment was first proposed in [13].
All approaches of this type explicitly use Pareto dominance
in order to determine the reproduction probability of each
individual. While non-Pareto EA’s are often sensitive to the
nonconvexity of Pareto-optimal sets, this is not the case for
Pareto-based EA’s [1].
Finally, some multiobjective EA’s also make use of com-
binations of the presented fitness assignment strategies (e.g.,
[14], [15]).
C. Multimodal Optimization and Preservation of Diversity
When we consider the case of finding a set of nondominated
solutions rather than a single-point solution, multiobjective
EA’s have to perform a multimodal search that samples the
Pareto-optimal set uniformly. Unfortunately, a simple (elitist)
EA tends to converge toward a single solution and often
loses solutions due to three effects [16]: selection pressure,
selection noise, and operator disruption. To overcome this
problem, several methods have been developed that can be
divided into niching techniques and nonniching techniques
[16]. Both types aim at preserving diversity in the population
(and therefore try to prevent from premature convergence),
but in addition niching techniques are characterized by their
capability of promoting the formulation and maintenance of
stable subpopulations (niches).
Fitness sharing [17] is used most frequently, which is a
niching technique based on the idea that individuals in a
particular niche have to share the available resources. The
more individuals are located in the neighborhood of a cer-
tain individual, the more its fitness value is degraded. The
neighborhood is defined in terms of a distance measure
and specified by the so-called niche radius . Depending
on whether the distance function operates on the geno-
types or the phenotypes, one distinguishes between genotypic
ZITZLER AND THIELE: MULTIOBJECTIVE EVOLUTIONARY ALGORITHMS 259
sharing and phenotypic sharing; phenotypic sharing can be
performed on the decision vectors or the objective vectors.
Currently, most multiobjective EA’s implement fitness sharing
(e.g., [11], [14], [18], [6], [15], [19], [20]).
Among the nonniching techniques, restricted mating is the
most common in multicriteria function optimization. Basically,
two individuals are allowed to mate only if they are within a
certain distance (given by the parameter ) to each other.
This mechanism may avoid the formation of lethal individuals
and therefore improve the online performance. Nevertheless,
as mentioned in [1], it does not appear to be widespread in the
field of multiobjective EA’s (e.g., [11], [14], [21]).
To our knowledge, other niching methods like crowding
[22] and its derivatives as well as nonniching techniques as
isolation by distance [23] have never been applied to EA’s
with multiple objectives (an exception is offered in [24], cf.
Section IV-D).
D. Four Population-Based Approaches
In the following we present the multiobjective EA’s applied
to the knapsack problem in our comparison. For a thorough
discussion of other evolutionary approaches, we refer to [1],
[25], and [4].
1) Vector Evaluated Genetic Algorithm: Schaffer [9] pre-
sented a multimodal EA called vector evaluated genetic al-
gorithm (VEGA) that carries out selection for each objective
separately. In detail, the mating pool is divided into parts
of equal size; part is filled with individuals that are chosen
at random from the current population according to objective
. Afterwards, the mating pool is shuffled and crossover and
mutation are performed as usual. Schaffer implemented this
method in combination with fitness proportionate selection.
Although some serious drawbacks are known, this algorithm
has been a strong point of reference up to now. Therefore, it
was included in this investigation.
2) Aggregation by Variable Objective Weighting: Another
non-Pareto approach was introduced in [11] (in the following
referred to as HLGA—Hajela’s and Lin’s genetic algorithm),
that used the weighted-sum method for fitness assignment.
Thereby, each objective is assigned a weight , such
that , and the scalar fitness value is calculated by
summing up the weighted objective values To
search for multiple solutions in parallel, the weights are not
fixed but instead encoded in the genotype. The diversity of
the weight combinations is promoted by phenotypic fitness
sharing. As a consequence, the EA evolves solutions and
weight combinations simultaneously. Finally, [11, p. 102]
emphasized mating restrictions to be necessary in order to
“both speed convergence and impart stability to the genetic
search.”
Several other multiobjective EA’s make use of weighted-
sum aggregation (e.g., [12]). We have chosen HLGA to
represent this class of multiobjective EA’s.
3) Niched Pareto Genetic Algorithm: The niched Pareto
genetic algorithm (NPGA) proposed in [18] and [26] combines
tournament selection and the concept of Pareto dominance.
Two competing individuals and a comparison set of other
individuals are picked at random from the population; the size
of the comparison set is given by the parameter . If one
of the competing individuals is dominated by any member
of the set and the other is not, then the latter is chosen as
winner of the tournament. If both individuals are dominated
(or not dominated), the result of the tournament is decided
by sharing: The individual that has the least individuals in
its niche (defined by ) is selected for reproduction.
Horn and Nafpliotis [18], [26] used phenotypic sharing on
the objective vectors.
This algorithm seems to be widespread and has been often
taken as reference in recent publications [2], [21], [20], hence,
it is also examined here.
4) Nondominated Sorting Genetic Algorithm: Srinivas and
Deb [6] also developed an approach based on [13], called
nondominated sorting genetic algorithm (NSGA). Analogously
to [13], the fitness assignment is carried out in several steps. In
each, the nondominated solutions constituting a nondominated
front are assigned the same dummy fitness value. These solu-
tions are shared with their dummy fitness values (phenotypic
sharing on the decision vectors) and ignored in the further
classification process. Finally, the dummy fitness is set to a
value less than the smallest shared fitness value in the current
nondominated front. Then the next front is extracted. This
procedure is repeated until all individuals in the population
are classified. In the original study [6], this fitness assignment
method was combined with a stochastic remainder selection.
We have selected NSGA as the second Pareto-based EA,
although there are also other Pareto-based approaches that
may be under consideration for the comparison, e.g., the
multiobjective EA presented in [14].
III. PERFORMANCE COMPARISON
In the following, the case study is described that has been
carried out using the above four multiobjective EA’s for
solving an extended 0/1 knapsack problem. The comparison
focuses on the effectiveness in finding multiple Pareto-optimal
solutions, disregarding their number. Nevertheless, in the case
that the tradeoff surface is continuous or contains many points,
the distribution of the nondominated solutions achieved is
also important. Although we do not consider the distribution
explicitly, it influences the performance of the EA indirectly.
A. The Multiobjective 0/1 Knapsack Problem
A test problem for a comparative investigation like this has
to be chosen carefully. The problem should be understandable
and easy to formulate so that the experiments are repeatable
and verifiable. It should also be a rather general problem
and ideally represent a certain class of real-world problems.
Both conditions apply to the knapsack problem: the problem
description is simple, yet the problem itself is difficult to solve
(NP-hard). Moreover, due to its practical relevance it has been
subject to several investigations in various fields. In particular,
there are some publications in the domain of evolutionary
computation related to the knapsack problem [27]–[29], even
in conjunction with multiobjective optimization [30].
260 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 3, NO. 4, NOVEMBER 1999
1) Formulation as Multiobjective Optimization Problem:
Generally, a 0/1 knapsack problem consists of a set of items,
weight and profit associated with each item, and an upper
bound for the capacity of the knapsack. The task is to find
a subset of items which maximizes the total of the profits in
the subset, yet all selected items fit into the knapsack, i.e., the
total weight does not exceed the given capacity [31].
This single-objective problem can be extended directly to
the multiobjective case by allowing an arbitrary number of
knapsacks. Formally, the multiobjective 0/1 knapsack problem
considered here is defined in the following way: Given a set
of items and a set of knapsacks, with
profit of item according to knapsack
weight of item according to knapsack
capacity of knapsack
find a vector , such that
(3)
and for which is maximum,
where
(4)
and iff item is selected.
2) Test Data: In order to obtain reliable and sound results,
we used nine different test problems where both the number
of knapsacks and the number of items were varied.2 Two,
three, and four objectives were taken under consideration, in
combination with 250, 500, and 750 items.
Following suggestions in [31], uncorrelated profits and
weights were chosen, where and are random integers
in the interval . The knapsack capacities were set to
half the total weight regarding the corresponding knapsack
(5)
As reported in [31], about half of the items are expected to
be in the optimal solution (of the single-objective problem)
when this type of knapsack capacity is used. We also examined
more restrictive capacities where the solutions
contain only a few items. As this had no significant influence
on the relative performance of the EA’s, we only present the
results concerning the former type of knapsack capacity in the
following.
3) Implementation: Concerning the chromosome coding as
well as the constraint handling, we drew upon results published
in [28], which examined EA’s with different representation
mappings and constraint handling techniques on the (single-
objective) 0/1 knapsack problem. Concluding from the exper-
iments in [28], penalty functions achieve best results on data
sets with capacities of half the total weight; however, they
fail on problems with more restrictive capacities. Since the
2 The test data sets are available from the authors.
experiments should be performed on both kinds of knapsack
capacities, we decided to implement a greedy repair method
that produced the best outcomes among all algorithms under
consideration when both capacity types are regarded. This
method is based on a vector representation and repairs infea-
sible solutions according to a predefined scheme. We adopted
this approach with a slightly modified repair mechanism.
In particular, a binary string of length is used to
encode the solution . Since many codings lead
to infeasible solutions, a simple repair method is applied
to the genotype : . The repair algorithm removes
items from the solution coded by step by step until all
capacity constraints are fulfilled. The order in which the items
are deleted is determined by the maximum profit/weight ratio
per item; for item the maximum profit/weight ratio is
given by the equation3
(6)
The items are considered in increasing order of the , i.e.,
those achieving the lowest profit per weight unit are removed
first. This mechanism intends to fulfill the capacity constraints
while diminishing the overall profit as little as possible.
B. Methodology
In the context of this comparison, several questions arise:
What quantitative measures should be used to express the
quality of the results so that the EA’s can be compared in a
meaningful way? What is the outcome of a multiobjective EA
regarding a set of runs? How can side effects caused by differ-
ent selection schemes or mating restrictions be precluded, such
that the comparison is not falsified? How can the parameters
of the EA, particularly the niche radius, be set appropriately?
In the following, we treat these problems.
1) Performance Measures: Two complementary measures
were used to evaluate the tradeoff fronts produced by the
various EA’s.
Size of the space covered: Let
be a set of decision vectors. The function
gives the volume enclosed by the union of the polytopes
where each is formed by the intersections
of the following hyperplanes arising out of , along with
the axes: for each axis in the objective space, there exists a
hyperplane perpendicular to the axis and passing through the
point . In the two-dimensional
(2-D) case, each represents a rectangle defined by the
points and .
Coverage of two sets: Let be two sets of
decision vectors. The function maps the ordered pair
to the interval
(7)
The value means that all points in
are dominated by or equal to points in . The opposite,
3 This is a straightforward extension to the single-objective approach
presented in [28] where qj = p1;j=w1;j :
ZITZLER AND THIELE: MULTIOBJECTIVE EVOLUTIONARY ALGORITHMS 261
, represents the situation when none of the
points in are covered by the set . Note that both
and have to be considered, since
is not necessarily equal to (e.g., if
dominates then and ).
The first measure has the advantage that each EA can
be evaluated independently of the other EA’s; however, con-
vex regions may be preferred to concave regions, possibly
overrating certain solutions. The second measure overcomes
this drawback and can be used to show that the outcomes of
one algorithm dominate the outcomes of another algorithm,
although it does not tell how much better it is.
Since in this comparison the focus is on finding the Pareto-
optimal set rather than obtaining a uniform distribution along
the tradeoff surface, we did not consider the online perfor-
mance of the EA’s but rather the offline performance. Thus
the nondominated set regarding all individuals generated over
all generations was taken as the output of an optimization
run. Altogether 30 independent runs were performed per EA
and test problem in order to restrict the influence of random
effects. Another randomly created initial population was taken
each time, and for each test problem all EA’s operated on the
same 30 initial populations.
2) Selection and Mating Restrictions: Actually, each mul-
tiobjective EA should be combined with the selection scheme
originally applied. But the influence of the selection scheme
on the outcome of an EA cannot be neglected, e.g., fitness
proportionate selection, which is used in VEGA, is well known
to have serious disadvantages [32]. In order to guarantee
a fair comparison, all EA’s considered were implemented
with the same selection scheme: binary tournament selection
with replacement. This selection method turned out to be
superior to both stochastic remainder selection (used in [6])
and linear ranking selection on our test problems—that has
been confirmed experimentally.
Unfortunately, a conventional combination of fitness sharing
and tournament selection may lead to chaotic behavior of the
EA [33]. Therefore, both NSGA and HLGA were implemented
using a slightly modified version of sharing, called contin-
uously updated sharing, which was proposed by the same
researchers. Thereby, the partly filled next generation is used
to calculate the niche count rather than the current generation.
Horn and Nafpliotis [18], [26] introduced this concept in
NPGA as well.
Another problem is the influence of mating restrictions.
While Hajela and Lin [11] found it necessary to restrict
mating, the other EA’s under consideration do not explicitly
incorporate this concept. We decided not to use mating re-
strictions in this study, since the effectiveness of the different
fitness assignment and niching methods should be compared.
In addition, it was experimentally verified that no significant
improvement could be observed when running HLGA with
mating restrictions.
3) Parameter Settings: On all test problems, 500 genera-
tions were simulated per optimization run, the probabilities
of crossover (one-point) and mutation were fixed (0.8 and
0.01, respectively). The population size was chosen to
TABLE I
PARAMETERS THAT WERE ADJUSTED TO THE PROBLEM COMPLEXITY:
POPULATION SIZE (N), NICHE RADIUS (OBJECTIVE SPACE: share,
PARAMETER SPACE: 
share
), AND DOMINATION PRESSURE (tdom)
be dependent on the complexity of the test problem, as can
be seen in Table I: the more knapsacks and items involved,
the greater the value for . Following the guidelines in
[34], the niche radius was calculated based on normalized
distance, assuming the formation of ten (15 and 20, respec-
tively) independent niches in the case of two (three and four,
respectively) knapsacks. In Table I, relates to sharing on
the parameter space, which is implemented in NSGA, while
stands for the niche radii used by HLGA and NPGA.
Finally, the domination pressure , a parameter of NPGA,
was determined experimentally. All NPGA simulations were
carried out five times, each time using another value for
(5, 10, 15, 20, and 25% of the population size). At the end,
the parameter value which achieved the best results for the
measure was chosen per test problem (cf. Table I).
C. Experimental Results
As additional points of reference, two further methods were
considered in this comparison: random sampling and multiple
independent sampling. The first algorithm (RAND) randomly
generates a certain number of individuals per generation,
according to the rate of crossover and mutation (though neither
crossover, mutation, nor selection are performed). Hence the
number of fitness evaluations was the same as for the EA’s.
The second algorithm is an elitist single-objective EA using
weighted-sum aggregation. In contrast to the other algorithms
under consideration, 100 independent runs were performed per
test problem, each run optimizing toward another randomly
chosen linear combination of the objectives. The nondomi-
nated solutions among all solutions generated in the 100 runs
form the tradeoff front achieved on a particular test problem.
Furthermore, two versions of the single-objective EA were
investigated: one with 100 generations per linear combination
(SO-1) and another one that terminated after 500 generations
in every single optimization run (SO-5).
The results concerning the measure (size of the space
covered) are shown in Fig. 3, the direct comparison of the
different algorithms based on the measure (coverage) is
depicted in Fig. 2. For each algorithm and ordered pair of
algorithms, respectively, there is a sample of 30 , respectively
262 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 3, NO. 4, NOVEMBER 1999
Fig. 1. Tradeoff fronts for two knapsacks: here, the nondominated solutions regarding the first five runs are plotted. For better visualization, the points
achieved by a particular method are connected by dashed lines and RAND is not included in the figure. Note that SPEA and SP-S are described later.
, values per test problem according to the 30 runs performed.
Here, box plots [35] are used to visualize the distribution of
these samples. A box plot consists of a box summarizing 50%
of the data. The upper and lower ends of the box are the upper
and lower quartiles, while a thick line within the box encodes
the median. Dashed appendages summarize the spread and
shape of the distribution, and dots represent outside values.
Generally, the simulation results prove that all multiobjec-
tive EA’s do better than the random search strategy. Fig. 2
shows that the tradeoff fronts achieved by RAND are entirely
dominated by the fronts evolved by HLGA, NPGA, and
NSGA (with regard to the same population). Concerning the
distributions, the RAND median is less by more than
20 quartile deviations than the medians associated with the
EA’s when the maximum quartile deviation of all samples is
considered.
Among the multiobjective EA’s, NSGA seems to provide
the best performance. The median of the values is for each
test problem greater than the corresponding medians of the
other three EA’s by more than five quartile deviations. In
addition, on eight of the nine test problems NSGA covers
more than 70% of the fronts computed by HLGA, NPGA, and
VEGA in more than 75% of the runs; in 99% of the runs it
covers more than 50%. In contrast, those three EA’s cover less
than 10% of the NSGA outcomes in 75% of all runs and less
than 25% in 99% of the runs (on eight of the nine problems).
ZITZLER AND THIELE: MULTIOBJECTIVE EVOLUTIONARY ALGORITHMS 263
Fig. 2. Box plots based on the C measure. Each rectangle contains nine box plots representing the distribution of the C values for a certain ordered pair
of algorithms; the three box plots to the left relate to two knapsacks and (from left to right) 250, 500, and 750 items; correspondingly the three middle box
plots relate to three knapsacks and the three to the right to four knapsacks. The scale is 0 at the bottom and 1 at the top per rectangle. Furthermore, each
rectangle refers to algorithm A associated with the corresponding row and algorithm B associated with the corresponding column and gives the fraction
of B covered by A (C(A;B)). Note that SPEA and SP-S are introduced later.
For four knapsacks and 250 items, the coverage rates scatter
more, however, NSGA achieves higher values in comparison
with the other multiobjective EA’s.
Comparing NPGA and VEGA, there is no clear evidence
that one algorithm outperforms the other, although VEGA
seems to be slightly superior to NPGA. Only on two of the
test problems (two knapsacks, 500 and 750 items) do the
medians of the distributions of the two EA’s deviate by
more than three quartile deviations (in favor of VEGA). In the
direct comparison based on the measure, VEGA covers more
than 50% of the NPGA outcomes on average, while NPGA
achieves less than 25% coverage regarding VEGA on average.
Furthermore, both algorithms generate better assessments in
comparison with HLGA. With three and four knapsacks, the
fronts produced by HLGA are dominated by the NPGA and
VEGA fronts by 99% (cf. Fig. 2), and the medians of the
values associated with HLGA are more than ten quartile
deviations less than the medians related to NPGA and
VEGA. For two knapsacks, the distributions are closer
together; however, the measure indicates clear advantages
of NPGA and VEGA over HLGA.
Finally, the fact that SO-5 covers on average more than
90% of the nondominated solutions computed by HLGA,
NPGA, VEGA, and NSGA and achieves significantly greater
264 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 3, NO. 4, NOVEMBER 1999
Fig. 3. Distribution of the S values for the nine test problems. Note that RAND, SO-1, and SO-5 are not considered in this figure, since the focus is on
the four multiobjective EA’s and otherwise the differences between those algorithms would be blurred.
values (the median is greater by more than 21 quartile
deviations than the other medians per test problem) suggests
that none of the multiobjective EA’s converge to the Pareto-
optimal front using the chosen parameter settings. This can
also be observed in Fig. 1, where the tradeoff fronts obtained
in five runs are plotted for the 2-D problems. Note that the
computational effort needed by SO-5 to produce the depicted
fronts is 20 times higher than the one for the multiobjective
EA’s.
IV. THE STRENGTH PARETO APPROACH
We propose a new approach to multiobjective optimization,
the Strength Pareto Evolutionary Algorithm (SPEA). SPEA
uses a mixture of established and new techniques in order
to find multiple Pareto-optimal solutions in parallel. On one
hand, similarly to other multiobjective EA’s, it:
• stores the nondominated solutions found so far externally
(e.g., [10], [12], [19]);
• uses the concept of Pareto dominance in order to assign
scalar fitness values to individuals;
• performs clustering to reduce the number of nondomi-
nated solutions stored without destroying the characteris-
tics of the tradeoff front [20].
On the other hand, SPEA is unique in four respects.
• It combines the above three techniques in a single algo-
rithm.
• The fitness of an individual is determined only from
the solutions stored in the external nondominated set;
whether members of the population dominate each other
is irrelevant.
• All solutions in the external nondominated set participate
in the selection.
• A new niching method is provided in order to preserve
diversity in the population; this method is Pareto-based
and does not require any distance parameter (like the
niche radius for sharing).
A. Algorithm
The flow of the algorithm is as follows.
Step 1) Generate an initial population and create the
empty external nondominated set .
Step 2) Copy nondominated members of to .
Step 3) Remove solutions within which are covered by
any other member of .
Step 4) If the number of externally stored nondominated
solutions exceeds a given maximum , prune
by means of clustering.
ZITZLER AND THIELE: MULTIOBJECTIVE EVOLUTIONARY ALGORITHMS 265
(a) (b)
Fig. 4. Two scenarios for a maximization problem with two objectives. The number associated with each solution gives the fitness (and strength in
case of nondominated points).
Step 5) Calculate the fitness of each individual in as well
as in .
Step 6) Select individuals from (multiset union),
until the mating pool is filled. In this study, binary
tournament selection with replacement is used.
Step 7) Apply problem-specific crossover and mutation op-
erators as usual.
Step 8) If the maximum number of generations is reached,
then stop, else go to Step 2.
In the next two subsections, the fitness assignment as well
as the clustering procedure are described in detail.
1) Fitness Assignment: The fitness assignment procedure
is a two-stage process. First, the individuals in the external
nondominated set are ranked. Afterwards, the individuals
in the population are evaluated.
Step 1) Each solution is assigned a real value
, called strength;4 is proportional to
the number of population members for which
. Let denote the number of individuals in
that are covered by and assume is the size of
. Then is defined as . The fitness
of is equal to its strength: .
Step 2) The fitness of an individual is calculated by
summing the strengths of all external nondominated
solutions that cover . We add one to the
total in order to guarantee that members of
have better fitness than members of (note that
fitness is to be minimized, i.e., small fitness values
correspond to high reproduction probabilities)
where
To make the effect of this ranking method clear, take a look
at Fig. 4. The objective space which is covered by the three
nondominated solutions is divided into distinct rectangles.
Each subset of defines one such area that all members
4 This term is adopted from [36] where it was introduced in the context of
classifier systems; it stands for a quantity summarizing the usefulness of a
rule. Here, it reflects the usefulness of a nondominated point.
of the subset cover in common. For instance, the dark-
shaded rectangle in the lower-left corner is covered by all
three nondominated points, while the upper left bright-shaded
rectangle is only covered by one nondominated point. We
consider these areas as niches, and the goal is to distribute
the individuals over this “grid” such that:
a) (brighter shaded) areas covered by only a few non-
dominated points contain more individuals than (darker
shaded) rectangles that are covered by many nondomi-
nated points, and
b) an area comprises as many individuals as the other
(equally shaded) rectangles that are covered by the same
number of nondominated points.
This mechanism intuitively reflects the idea of preferring
individuals near the Pareto-optimal front and distributing them
at the same time along the tradeoff surface. In Fig. 4(a), the
first aspect is illustrated: Individuals located in the bright areas
achieve better fitness values than the remaining population
members. Fig. 4(b) provides an example for the second as-
pect and directly visualizes the strength principle: Individuals
having many neighbors in their niche are penalized due to the
high strength value of the associated nondominated point; the
“stronger” a nondominated solution, the less “fitter” are the
covered individuals.
The main difference to fitness sharing is that niches are
not defined in terms of distance but Pareto dominance. This
renders the setting of a distance parameter superfluous, al-
though the parameter influences the niching capability
as we will discuss in the next section. Furthermore, it has
to be mentioned that this kind of fitness assignment using
two interacting populations has been inspired by [37]–[41].
Paredis [41] studied the use of cooperating populations in
EA’s and showed that symbiotic evolution can speed up the
search process. In [37]–[40], a similar concept was applied to
immune system models where two cooperative populations
were used to maintain population diversity; [39] reported
that this method has emergent properties that are similar to
fitness sharing.
266 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 3, NO. 4, NOVEMBER 1999
2) Reducing the Pareto Set by Clustering: In certain prob-
lems, the Pareto-optimal set can be extremely large or even
contain an infinite number of solutions. However, from the
decision maker’s point of view, presenting all nondominated
solutions found is useless when their number exceeds reason-
able bounds. Moreover, the size of the external nondominated
set influences the behavior of SPEA. On the one hand, since
participates in selection, too many nondominated solutions
might reduce selection pressure and slow down the search [20].
On the other hand, the strength niching mechanism relies on a
uniform granularity of the “grid” defined by the nondominated
solutions (cf. Fig. 4); if the points in are not distributed
uniformly, the fitness assignment method is possibly biased
toward certain regions of the search space, leading to an
unbalanced distribution in the population. Thus pruning the
external nondominated set while maintaining its characteristics
might be necessary or even mandatory.
A method that has been applied to this problem successfully
and studied extensively in the same context is cluster analysis
[42], [43]. In general, cluster analysis partitions a collection of
elements into groups of relatively homogeneous elements,
where . The average linkage method [42], a clustering
approach that has proven to perform well on this problem (cf.
[42]), has been chosen in this paper.
Step 1) Initialize cluster set ; each external nondominated
point constitutes a distinct cluster:
.
Step 2) If , go to Step 5, else go to Step 3.
Step 3) Calculate the distance of all possible pairs of clus-
ters. The distance of two clusters and
is given as the average distance between pairs of
individuals across the two clusters
where the metric reflects the distance between
two individuals and (in this study an Euclidean
metric on the objective space is used).
Step 4) Determine two clusters and with minimal
distance ; the chosen clusters amalgamate into a
larger cluster: Go to
Step 2.
Step 5) Compute the reduced nondominated set by se-
lecting a representative individual per cluster. We
consider the centroid (the point with minimal av-
erage distance to all other points in the cluster) as
representative solution.
Cunha et al. [20] also combined a multiobjective EA with a
clustering approach in order to achieve reasonably sized Pareto
sets. This algorithm, however, uses a different clustering
method which has been proposed in [43]; thereby, for each
objective, a tolerance value has to be specified. Moreover, it
differs from SPEA with regard to the following two aspects:
a) The nondominated solutions are not stored externally, and
b) fitness sharing is incorporated to preserve diversity in the
population.
B. A Simple Test Function: Schaffer’s
A very simple test function for multiobjective optimizers
is the well-known function used by Schaffer [44]. It is
defined as follows:
minimize
where
(8)
Obviously, the Pareto-optimal points are located in the range
. Outside this interval, as well as are increasing,
while within the interval, there is a tradeoff between the two
functions (one is increasing, the other one is decreasing).
To test SPEA on , we used a 14-bit chromosome which
is decoded to a real number between and . The bit string
encodes and
stands for . Furthermore, the following parameters were
used for SPEA:
Population size 95/70/30
Size of external nondominated set 5/30/70
Crossover probability: 1.0
Mutation probability: 0.0
Number of generations: 100
Altogether, we tried three different combinations of and
, where equaled 100 in each case. In order
to examine the effectiveness of SPEA alone, no mutation
operator was applied to the individuals. Instead, we used a
crossover probability of 1.0. In addition, VEGA ran on this
problem with identical parameters . In order to
guarantee a fair comparison, the offline performance of VEGA
is considered here, i.e., the final tradeoff front is formed by
the nondominated solutions found during a run, not only by
the Pareto-optimal points in generation 100.
The results produced by the algorithms using the same initial
population are shown in Fig. 5.5 It can be observed that SPEA
is able to well approximate the Pareto-optimal front, depending
on the size of the external nondominated set. In comparison to
VEGA, it evolved more Pareto-optimal solutions (VEGA:20,
SPEA:5/30/70) and distributed them more uniformly along the
tradeoff front.
C. Performance on the 0/1 Knapsack Problem
The same parameters as for the other multiobjective EA’s
were used for SPEA on the 0/1 knapsack problem. For reasons
of fairness, was set to and to of the population
size given in Table I. In addition, a slightly modified version of
SPEA was examined (SP-S) where does not participate in
the selection phase; there, the population size was the same as
for the other EA’s, and the size of the external nondominated
set was restricted to .
The results concerning the measure (size of the space
covered) are depicted in Fig. 6, the direct comparison of SPEA
5 Certainly, only limited weight can be given to a single run per algorithm.
Nevertheless, the results were similar when the experiments were repeated
with different initial populations.
ZITZLER AND THIELE: MULTIOBJECTIVE EVOLUTIONARY ALGORITHMS 267
Fig. 5. Performance of SPEA and VEGA on Schaffer’s f2.
with the other algorithms based on the measure (coverage)
is shown in Fig. 2. Furthermore, Fig. 1 gives the plots of the
2-D tradeoff fronts achieved by SPEA and the other EA’s. The
main observations can be summarized as follows.
• SPEA achieves the best assessments among the mul-
tiobjective EA’s. It covers 100% of the nondominated
solutions found by HLGA, NPGA, VEGA, and NSGA
with eight of the nine test problems; for four knapsacks
and 250 items at least 87% are covered. On the other
hand, those algorithms cover less than 5% of the SPEA
outcomes in all 270 runs. Concerning the size of the
covered space, the medians of the distributions related
to SPEA are greater than the corresponding medians of
the other multiobjective EA’s by more than ten quartile
deviations. Although the Pareto-optimal fronts of the
test problems considered here are all convex, we have
shown recently [45] that SPEA also has advantages over
the other EA’s for different types of problems (e.g.,
nonconvex functions).
• As Fig. 1 indicates, SPEA can find solutions that are
closer to the Pareto-optimal front than those produced by
SO-5 in spite of less computational effort. This observa-
tion is supported by the fact that SO-5 covers only 48% of
the SPEA front with eight of the nine test problems (SO-
1 less than 12%). However, the fronts found by multiple
single-objective searches contain many more solutions
and are wider in the sense that the size of the covered
space is significantly greater (cf. Fig. 6). Whether SPEA
can outperform a single-objective EA with substantially
less computation time is the subject of future work;
however, it was shown recently [45] that this is the case
for 2-D problems of different characteristics.
• Elitism seems to be important for the effectiveness of
the search, as SP-S performs substantially worse than
SPEA. Nevertheless, SP-S appears to do slightly better
than NSGA on the three- and four-dimensional problems.
Both the values (the median distance to NSGA is
greater than three quartile deviations) and the values
suggest a slight advantage for SP-S over NSGA. For two
knapsacks, the results are ambiguous and do not allow a
final conclusion to be made.
268 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 3, NO. 4, NOVEMBER 1999
Fig. 6. SPEA in comparison with the other algorithms with regard to the size of the covered space. The box plots represent the distributions of the
S values achieved in the 30 optimization runs.
D. Application to System-Level Synthesis
The third application is a larger problem in the domain of
computer engineering that is concerned with computer-based
system-level synthesis. Blickle et al. [24], [46], [47] have
presented an evolutionary approach to this problem which we
use as the basis for the SPEA implementation.
1) Problem Description: In [47], system-level synthesis is
considered as the problem of optimally mapping a task-
level specification onto a heterogeneous hardware/software
architecture. The input consists of three parts.
1) A behavioral description of a hardware/software system
to synthesize. The behavior is defined in terms of func-
tional objectives such as algorithms, tasks, procedures,
or processes together with their data interdependencies.
2) A structural specification of the system ( a class of pos-
sible architectures) where structural objects are general-
or special-purpose processors, application-specific inte-
grated circuits (ASIC’s), buses, and memories. With
each structural object, a fixed cost is associated that
arises when the particular resource is realized.
3) A Boolean function of the set of functional objects
to the set of structural objects that defines the space
of possible mappings; when , the task
can be mapped to the resource , otherwise it cannot.
Additionally, a latency function gives the estimated
time that is necessary to execute task on
resource .
The optimization goal is to find an implementation which
simultaneously minimizes cost and execution time; thereby,
an implementation is described by:
1) the set of the selected resources and structural objects
(allocation);
2) the mapping of the algorithm onto the selected architec-
ture (binding);
3) the schedule that defines the start times of the tasks on
the selected resources.
An example that visualizes the relations between input
and output is provided in Fig. 7. The behavioral specification
described by means of a directed graph contains seven func-
tional objects, where shaded nodes stand for communication
operations. The architecture, which includes a RISC processor,
a digital signal processor (DSP), and an application-specific
integrated circuit (ASIC), interconnected by two buses, is
also modeled by a directed graph. Finally, the function
is represented by edges between nodes of the two graphs.
For instance, Algorithm 4 can be mapped to any chip while
Algorithm 1 has to be executed on the RISC processor. On
the right-hand side of Fig. 7, a sample implementation is
depicted. All resources except Bus 2 are selected, thus all
communications are handled by Bus 1 (this is also reflected
ZITZLER AND THIELE: MULTIOBJECTIVE EVOLUTIONARY ALGORITHMS 269
Fig. 7. System-level synthesis: problem statement (slightly modified ex-
ample from [24]). Given is a set of algorithms together with their data
interdependencies, a superset of possible architectures, and a set of possible
mappings of algorithms to computing resources. The goal is to find an
implementation that is described by the selected architecture (allocation), the
selected mapping (binding), and a schedule for the algorithms to be executed
on the architecture.
by the binding that maps the communication nodes 5, 7, and
6 to Bus 1). For each functional object, a start time is given
(schedule).
2) EA Implementation: The overall picture of the EA is
depicted in Fig. 8. Each individual encodes both allocation and
binding, whereas the schedule is computed deterministically
by a heuristic list-scheduling algorithm incorporating loop
pipelining. An allocation is intuitively represented as a binary
string, the length of which corresponds to the number of
specified resources in the set of possible architectures. In order
to reduce the number of unfeasible solutions, allocations are
partially repaired by a heuristic whenever an individual is de-
coded. For the same reason, bindings are not encoded directly
using one chromosome but rather indirectly based on several
chromosomes: one chromosome including a permutation of
all tasks in the behavioral description determines the order in
which the tasks are mapped to the resources with respect to
the repaired allocation. Further lists, permutations of the set
of resources, define separately for each task which resource is
to be checked next for mapping.
To obtain the entire Pareto-optimal front (design space ex-
ploration), [24] used the same Pareto ranking method proposed
in [14]: An individual’s fitness is equal to the number of
population members that dominate it. For the purpose of a
diverse population, he incorporated a niching technique which
has been rather seldom used: restricted tournament selection
(RTS) [48]. RTS is a special binary tournament selection
for steady-state EA’s where two individuals hold tournament
with the most similar individual of a randomly chosen group;
winners replace inferior individuals in the population.
3) Experimental Results: The presented EA has been im-
plemented with the Strength Pareto approach for multiobjec-
tive optimization and compared both to a single-objective EA
Fig. 8. An evolutionary algorithm for system-level synthesis (diagram taken
from [24, p. 174]). Depicted is the process of fitness evaluation. In the
first step, an allocation is derived from the information encoded in the
individual. The binding, which is computed in the second step, depends on
both the encoded information and the allocation. Afterwards, the schedule
is determined heuristically and the resulting implementation is assessed
concerning the design criteria, possibly taking user-defined constraints into
account.
TABLE II
VIDEO CODEC: NONDOMINATED SOLUTIONS FOUND BY THE THREE DIFFERENT
METHODS. IN EACH COLUMN, THE PAIRS SET IN ITALIC MARK POINTS
THAT ARE INFERIOR TO ANY POINT IN THE OTHER TWO COLUMNS. THE
OUTCOMES OF THE SINGLE-OBJECTIVE EA ARE TAKEN FROM [24, p. 203]
and to the algorithm proposed in [24]. The synthesis of a
video codec, based on the H.261 standard (cf. [24, ch. 9]),
was chosen as test problem; the search space of this problem
contains about possible bindings.
All algorithms ran with a population size of 30 (SPEA: 20
with ten externally stored nondominated solutions), a crossover
probability of 0.5, and a mutation probability of 0.2. In
case of the two multiobjective EA’s, the offline performance
over ten independent runs with 100 generations each was
considered. The single-objective EA was used to optimize each
objective separately; for the other objective, a maximum value,
a constraint, was defined. We examined 11 different latency
constraints when minimizing cost and 11 cost constraints in
the case of latency optimization. For each constraint, the best
result out of ten independent runs (100 generations each)
was taken, and the nondominated solutions of all 22 single-
objective results constituted the final Pareto set.
SPEA covers 100% and dominates 50% of the solutions
found by the combination of RTS and Pareto ranking as shown
in Table II. Although Blickle [24] ran the algorithm with a
population size of 100 and a maximum number of 200 gener-
ations, the results he reported are the same as generated by the
single-objective EA (Table II, second column). Moreover, in
spite of significantly lower computational effort, SPEA covers
100% and dominates 33% of the nondominated front achieved
by the single-objective EA.
270 IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 3, NO. 4, NOVEMBER 1999
V. CONCLUSION
This study compared four multiobjective EA’s on a multi-
objective 0/1 knapsack problem with nine different problem
settings. The quality of the Pareto-optimal sets achieved was
measured quantitatively by the size of the covered space. Addi-
tionally, the approaches were compared directly by evaluating
the outcomes regarding the concept of Pareto dominance.
All multiobjective EA’s clearly outperformed a pure random
search strategy which randomly generates new points in the
search space without exploiting similarities between solutions.
Among these multicriteria EA’s, the nondominated sorting
genetic algorithm [6] achieved the best results on all test
problems. It was followed by VEGA [9] which seems to have
slight advantages over the niched Pareto genetic algorithm
[18], [26] on this type of problem. Compared with Hajela’s
and Lin’s weighted-sum approach [11], both VEGA and
NPGA were assessed as better regarding the two performance
measures considered here.
Furthermore, a new evolutionary approach to multiobjective
optimization has been provided (SPEA) that differs from
existing multicriteria EA’s in the kind of fitness assignment
based on principles of coevolution and the niching technique
founded on the concept of Pareto dominance. As shown on
three applications, SPEA is capable of efficiently guiding the
search toward the Pareto-optimal front. On the 0/1 knapsack
problem, it outperformed the other four multiobjective EA’s
by a wide margin. Moreover, the experimental results indicate
that SPEA can even find solutions that are closer to the
globally optimal trade-off surface than solutions evolved by
a single-objective EA optimizing a linear combination of the
objectives.
With regard to future perspectives, it may be worthwhile to
investigate the following issues.
• If possible, other probabilistic search algorithms like
simulated annealing, hill climbing, tabu search, etc., as
well as “exact” methods (e.g., integer linear program-
ming, branch-and-bound) and deterministic heuristics (cf.
[31]) should be tested on the multiobjective 0/1 knapsack
problem. This would permit a more precise assessment of
the performance of the EA’s.
• The distribution of the obtained nondominated sets should
be included in the comparison. Although the size of
the covered space is a performance measure that takes
this property into account, it does not allow separate
evaluation of the distribution.
• Comparative studies should also be performed on the
basis of other test problems with different characteristics
(e.g., nonconvexity). First steps in this direction have
already been made [45].
Finally, as stated in [1], a theory of evolutionary multiobjec-
tive optimization is still required, examining different fitness
assignment methods in combination with different selections
schemes.
ACKNOWLEDGMENT
The authors wish to thank D. B. Fogel and the anonymous
reviewers for their helpful comments and suggestions.
REFERENCES
[1] C. M. Fonseca and P. J. Fleming, “An overview of evolutionary
algorithms in multiobjective optimization,” Evol. Comput., vol. 3, no.
1, pp. 1–16, 1995.
[2] M. Valenzuela-Rendón and E. Uresti-Charre, “A nongenerational genetic
algorithm for multiobjective optimization,” in Proc. 7th Int. Conf. Ge-
netic Algorithms, T. Bäck, Ed. San Francisco, CA: Morgan Kaufmann,
1997, pp. 658–665.
[3] D. H. Wolpert and W. G. Macready, “No free lunch theorems for
optimization,” IEEE Trans. Evol. Comput., vol. 1, pp. 67–82, Apr. 1997.
[4] J. Horn, “F1.9 Multicriteria decision making,” in Handbook of Evolu-
tionary Computation, T. Bäck, D. B. Fogel, and Z. Michalewicz, Eds.
Bristol, U.K.: Inst. Phys. Pub., 1997.
[5] E. Zitzler and L. Thiele, “Multiobjective optimization using evolutionary
algorithms—A comparative case study,” in 5th Int. Conf. Parallel
Problem Solving from Nature (PPSN-V), A. E. Eiben, T. Bäck, M.
Schoenauer, and H.-P. Schwefel, Eds. Berlin, Germany: Springer-
Verlag, 1998, pp. 292–301.
[6] N. Srinivas and K. Deb, “Multiobjective optimization using nondomi-
nated sorting in genetic algorithms,” Evol. Comput., vol. 2, no. 3, pp.
221–248, 1994.
[7] R. E. Steuer, Multiple Criteria Optimization: Theory, Computation, and
Application. New York: Wiley, 1986.
[8] J. L. Ringuest, Multiobjective Optimization: Behavioral and Computa-
tional Considerations. Boston, MA: Kluwer, 1992.
[9] M. P. Fourman, “Compaction of symbolic layout using genetic algo-
rithms,” in Proc. Int. Conf. Genetic Algorithms and Their Applications,
J. J. Grefenstette, Ed., Pittsburgh, PA, July 24–26, 1985, pp. 141–153,
sponsored by Texas Instruments and U.S. Navy Center for Applied
Research in Artificial Intelligence (NCARAI).
[10] F. Kursawe, “Evolution strategies for vector optimization,” in Proc.
10th Int. Conf. Multiple Criteria Decision Making, G.-H. Tzeng and P.
L. Yu, Eds., National Chiao Tung University, Hsinchu, Taiwan, 1992,
pp. 187–193.
[11] P. Hajela and C.-Y. Lin, “Genetic search strategies in multicriterion op-
timal design,” in Structural Optimization, vol. 4. New York: Springer,
June 1992, pp. 99–107.
[12] H. Ishibuchi and T. Murata, “Multi-objective genetic local search
algorithm,” in Proc. 1996 IEEE Int. Conf. Evolutionary Computation
(ICEC’96), Piscataway, NJ, May 20–22, 1996, pp. 119–124.
[13] D. E. Goldberg, Genetic Algorithms in Search, Optimization, and Ma-
chine Learning. Reading, MA: Addison-Wesley, 1989.
[14] C. M. Fonseca and P. J. Fleming, “Genetic algorithms for multiobjective
optimization: Formulation, discussion and generalization,” in Proc. 5th
Int. Conf. Genetic Algorithms, S. Forrest, Ed. San Mateo, CA: Morgan
Kaufmann, 1993, pp. 416–423.
[15] G. W. Greenwood, X. S. Hu, and J. G. D’Ambrosio, “Fitness functions
for multiple objective optimization problems: Combining preferences
with pareto rankings,” in Foundations of Genetic Algorithms 4 (FOGA-
96), R. K. Belew and M. D. Vose, Eds. San Francisco, CA: Morgan
Kaufmann, 1996, pp. 437–455.
[16] S. W. Mahfoud, “Niching methods for genetic algorithms,” Ph.D.
dissertation, Univ. Illinois, Urbana-Champaign, 1995.
[17] D. E. Goldberg and J. Richardson, “Genetic algorithms with sharing
for multimodal function optimization,” in Genetic Algorithms and Their
Applications: Proceedings of the Second International Conference on
Genetic Algorithms, J. J. Grefenstette, Ed. Hillsdale, NJ: Lawrence
Erlbaum, 1987, pp. 41–49.
[18] J. Horn and N. Nafpliotis, “Multiobjective optimization using the
niched pareto genetic algorithm,” IlliGAL Report 93005, Illinois Genetic
Algorithms Lab., Univ. Illinois, Urbana-Champaign, July 1993.
[19] D. S. Todd and P. Sen, “A multiple criteria genetic algorithm for
containership loading,” in Proc. 7th Int. Conf. Genetic Algorithms, T.
Bäck, Ed. San Francisco, CA: Morgan Kaufmann, 1997, pp. 674–681.
[20] A. G. Cunha, P. Oliviera, and J. Covas, “Use of genetic algorithms in
multicriteria optimization to solve industrial problems,” in Proc. 7th Int.
Conf. Genetic Algorithms, T. Bäck, Ed. San Francisco, CA: Morgan
Kaufmann, 1997, pp. 682–688.
[21] D. H. Loughlin and S. Ranjithan, “The neighborhood constraint-method:
A genetic algorithm-based multiobjective optimization technique,” in
Proc. 7th Int. Conf. Genetic Algorithms, T. Bäck, Ed. San Francisco,
CA: Morgan Kaufmann, 1997, pp. 666–673.
[22] K. A. De Jong, “An analysis of the bevavior of a class of genetic
adaptive systems,” Ph.D. dissertation, Univ. Michigan, Ann Arbor, 1975.
[23] C. Ryan, “Niche and species formation in genetic algorithms,” in
Practical Handbook of Genetic Algorithms, vol. 1, L. Chambers, Ed.
Boca Raton, FL: CRC, 1995, ch. 2, pp. 57–74.
ZITZLER AND THIELE: MULTIOBJECTIVE EVOLUTIONARY ALGORITHMS 271
[24] T. Blickle, “Theory of evolutionary algorithms and application to
system-synthesis,” Ph.D. dissertation, Swiss Federal Inst. Technol.
(ETH), Zürich, Switzerland, 1996, ETH diss no. 11894.
[25] H. Tamaki, H. Kita, and S. Kobayashi, “Multi-objective optimization
by genetic algorithms: A review,” in Proc. 1996 IEEE Int. Conf.
Evolutionary Computation (ICEC’96), Piscataway, NJ, May 20–22,
1996, pp. 517–522.
[26] J. Horn, N. Nafpliotis, and D. E. Goldberg, “A niched pareto genetic
algorithm for multiobjective optimization,” in Proc. 1st IEEE Conf.
Evolutionary Computation, IEEE World Congr. Computational Compu-
tation, Piscataway, NJ, June 27–29, 1994, vol. 1, pp. 82–87.
[27] S. Khuri, T. Bäck, and J. Heitkötter, “The zero/one multiple knapsack
problem and genetic algorithms,” in Proc. 1994 ACM Symp. Applied
Computing, E. Deaton, D. Oppenheim, J. Urban, and H. Berghel, Eds.
New York: ACM-Press, 1994, pp. 188–193.
[28] Z. Michalewicz and J. Arabas, “Genetic algorithms for the 0/1 knapsack
problem,” in Methodologies for Intelligent Systems (ISMIS’94), Z. W.
Raś and M. Zemankova, Eds. Berlin, Germany-Verlag: Springer, 1994,
pp. 134–143.
[29] R. Spillman, “Solving large knapsack problems with a genetic algo-
rithm,” in IEEE Int. Conf. Systems, Man and Cybernetics, Piscataway,
NJ, Oct. 22–25, 1995, vol. 1, pp. 632–637.
[30] M. Sakawa, K. Kato, and T. Shibano, “An interactive fuzzy satisficing
method for multiobjective multidimensional 0-1 knapsack problems
through genetic algorithms,” in Proc. 1996 IEEE Int. Conf. Evolution-
ary Computation (ICEC’96), Piscataway, NJ, May 20–22, 1996, pp.
243–246.
[31] S. Martello and P. Toth, Knapsack Problems: Algorithms and Computer
Implementations. Chichester, U.K.: Wiley, 1990.
[32] T. Blickle and L. Thiele, “A comparison of selection schemes used in
evolutionary algorithms,” Evol. Comput., vol. 4, no. 4, pp. 361–394,
1996.
[33] C. K. Oei, D. E. Goldberg, and S.-J. Chang, “Tournament selection,
niching, and the preservation of diversity,” IlliGAL Rep. 91011, Univ.
Illinois, Urbana-Champaign, Urbana, IL 61801, Dec. 1991.
[34] K. Deb, and D. E. Goldberg, “An investigation of niche and species
formation in genetic function optimization,” in Proc. 3rd Int. Conf.
Genetic Algorithms, J. D. Schaffer, Ed. San Mateo, CA: Morgan
Kaufmann, 1989, pp. 42–50.
[35] J. M. Chambers, W. S. Cleveland, B. Kleiner, and P. A. Tukey,
Graphical Methods for Data Analysis. Pacific Grove, CA: Wadsworth
& Brooks/Cole, 1983.
[36] J. H. Holland, Adaption in Natural and Artificial Systems. Ann Arbor,
MI: Univ. Michigan Press, 1975.
[37] S. Forrest and A. S. Perelson, “Genetic algorithms and the immune
system,” in Parallel Problem Solving from Nature (PPSN I), H.-P.
Schwefel and R. Männer, Eds. Berlin, Germany: Springer-Verlag,
1991, pp. 320–325.
[38] R. E. Smith and S. Forrest, “Population diversity in an immune
system model: Implications for genetic search,” Foundations of Genetic
Algorithms 2 (FOGA-92), L. D. Whitley, Ed. San Mateo, CA: Morgan
Kaufmann, 1992.
[39] R. E. Smith, S. Forrest, and A. S. Perelson, “Searching for diverse,
cooperative populations with genetic algorithms,” Evol. Comput., vol.
1, no. 2, pp. 127–149, 1993.
[40] S. Forrest, B. Javornik, R. E. Smith, and A. S. Perelson, “Using genetic
algorithms to explore pattern recognition in the immune system,” Evol.
Comput., vol. 1, no. 3, pp. 191–211, 1993.
[41] J. Paredis, “The symbiotic evolution of solutions and their representa-
tions,” in Proc. 6th Int. Conf. Genetic Algorithms, L. J. Eshelman, Ed.
San Francisco, CA: Morgan Kaufmann, 1995, pp. 359–365.
[42] J. N. Morse, “Reducing the size of the nondominated set: Pruning by
clustering,” Comput. Oper. Res., vol. 7, nos. 1–2, 1980.
[43] M. A. Rosenman and J. S. Gero, “Reducing the pareto optimal set in
multicriteria optimization,” Eng. Optim., vol. 8, pp. 189–206, 1985.
[44] J. D. Schaffer, “Multiple objective optimization with vector evaluated
genetic algorithms,” Ph.D. dissertation, Vanderbilt Univ., Nashville, TN,
1984.
[45] E. Zitzler, K. Deb, and L. Thiele, “Comparison of multiobjective
evolutionary algorithms: Empirical results,” Tech. Rep. 70, Comput.
Eng. Networks Lab. (TIK), Swiss Federal Inst. Technol. (ETH) Zurich,
Switzerland, Feb. 1999.
[46] J Teich, T. Blickle, and L. Thiele, “System-level synthesis using
evolutionary algorithms,” in Proc. Codes/CASHE’97, 5th Int. Worksh.
Hardware/Software Codesign. Los Alamitos, CA: IEEE Comput. Soc.
Press, 1997, pp. 167–171.
[47] T. Blickle, J. Teich, and L. Thiele, “System-level synthesis using
evolutionary algorithms,” Des. Automat. Embedded Syst., vol. 3, no.
1, pp. 23–58, 1998.
[48] G. R. Harik, “Finding multimodal solutions using restricted tournament
selection,” in Proc. 6h Int. Conf. Genetic Algorithms, L. J. Eshelman,
Ed. San Francisco, CA: Morgan Kaufmann, 1995, pp. 24–31.
Eckart Zitzler received the Diploma degree in com-
puter science in 1996 from University of Dortmund,
Dortmund, Germany.
Since 1996, he has been a Research and Teaching
Assistant at the Computer Engineering Group at the
Electrical Engineering Department of ETH Zurich,
Switzerland. His main research interests are in the
areas of evolutionary computation, multiobjective
optimization, and computer engineering.
Lothar Thiele recieved the Dipl.-Ing. and Dr.-Ing.
degrees in electrical engineering from Technical
University of Munich, Munich, Germany, in 1981
and 1985, respectively.
Since 1981, he has been a Research Associate
with Prof. R. Saal at the Institute of Network Theory
and Circuit Design of the Technical University
Munich. After finishing his Habilitation thesis, he
joined the group of Prof. T. Kailath at the Infor-
mation Systems Laboratory, Stanford University,
Stanford, CA, in 1987. In 1988, he became Chair
of Microelectronics at the faculty of engineering, University of Saarland,
Saarbrücken, Germany. He joined ETH Zürich, Switzerland, as a Full Profes-
sor in Computer Engineering in the Fall of 1994. His research interests include
models, methods and software tools for the design of hardware/software
systems, and array processors as well as the development of parallel algorithms
for signal and image processing, combinatorial optimization, and cryptogra-
phy. He authored and co-authored more than 100 papers.
In 1986, Dr. Thiele received the award of the Technical University of
Munich for his Ph.D. dissertation. He received the 1987 Outstanding Young
Author Award of the IEEE Circuits and Systems Society. In 1988, he was
the recipient of the 1988 Browder J. Thompson Memorial Prize Award of
the IEEE.

