Numerical Methods for the Solution of the Generalized
Nash Equilibrium Problem
Anna von Heusinger
PhD Thesis
Würzburg, August 2009
1. Gutachter:
Prof. Dr. C. Kanzow
Universität Würzburg
Institut für Mathematik
Lehrstuhl für Angewandte Mathematik II
2. Gutachter:
Prof. M. Fukushima
Kyoto University
Graduate School of Informatics
Department of Applied Mathematics and Physics
Acknowledgements
First of all I thank my PhD advisor Christian Kanzow for constant support
throughout the past four years. His ideas, guidance, corrections and additions have
contributed essentially. Further, I am grateful that I had the opportunity to study
three months at the System Optimization Laboratory of Kyoto University, and I
thank Masao Fukushima and the members of the Laboratory for the hospitality
and scientific advice.
This work was supported in part by a grant from the International Doctorate
Program ’Identification, Optimization and Control with Applications in Modern
Technologies’ within the Elite Network of Bavaria. The doctorate program also
financed the three month stay at the university of Kyoto and the participation at
national and international conferences, which, together with the regular seminars
and summer schools with the members of the doctorate program, were of great
benefit to me.
Also I would like to thank my former teachers Dr. Schreiber, Mack, Angelkort,
Dr. Friedrich and Heuser from the Anne-Frank Gymnasium Werne, who promoted
my interest in mathematics and physics in the first instance.
At times, working on a PhD thesis can be demanding, and I am very happy
about the support and affection from my family and friends.
Contents
1 Introduction 3
1.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.2 The Generalized Nash Equilibrium Problem . . . . . . . . . . . . 5
1.3 Normalized Nash Equilibria . . . . . . . . . . . . . . . . . . . . 7
1.4 Electricity Market Model . . . . . . . . . . . . . . . . . . . . . . 10
1.5 Previous Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
2 Optimization Reformulations 14
2.1 A Constrained Optimization Reformulation . . . . . . . . . . . . 14
2.2 A Smooth Constrained Optimization Reformulation . . . . . . . . 20
2.3 An Unconstrained Smooth Optimization Reformulation . . . . . . 24
3 Descent Methods 28
3.1 Properties of the Optimization Reformulation . . . . . . . . . . . 28
3.2 A Relaxation Method with Inexact Line Search . . . . . . . . . . 38
3.3 A Nonsmooth Descent Method . . . . . . . . . . . . . . . . . . . 43
4 Newton’s Method Type I 47
4.1 Semismooth Functions . . . . . . . . . . . . . . . . . . . . . . . 48
4.2 S C1-Optimization Reformulations . . . . . . . . . . . . . . . . . 53
4.3 Newton’s method . . . . . . . . . . . . . . . . . . . . . . . . . . 59
5 Newton’s Method Type II 65
5.1 The Computable Generalized Jacobian . . . . . . . . . . . . . . . 66
5.2 Newton’s Method . . . . . . . . . . . . . . . . . . . . . . . . . . 75
6 Applications and Numerical Results 81
6.1 Implementations . . . . . . . . . . . . . . . . . . . . . . . . . . 81
6.1.1 Barzilai Borwein Method . . . . . . . . . . . . . . . . . . 82
6.1.2 Relaxation Method . . . . . . . . . . . . . . . . . . . . . 82
6.1.3 Newton’s Method based on Optimization Reformulation . 83
1
2
6.1.4 Newton’s Method through Fixed Point Formulation . . . . 83
6.2 Examples of Generalized Nash Equilibrium Problems . . . . . . . 84
6.3 Numerical Results . . . . . . . . . . . . . . . . . . . . . . . . . . 93
Bibliography 103
Chapter 1
Introduction
The Nash equilibrium, and game theory in general, is nowadays present in var-
ious fields of science, most prominently in economics and social science. More
recently, also engineering sciences have discovered the Nash equilibrium concept
as a means to design technical systems, for instance telecommunication networks.
Often not only the formulation of a model is desired but also the actual com-
putation of a Nash equilibrium. This thesis is about the numerical computation
of Nash equilibria, more precisely, generalized Nash equilibria. For very simple
games, such as two-player games with two strategies a player each, it is possible
to calculate a Nash equilibrium analytically, that is, with the help of pencil and
paper. Here we aim at the development of numerical methods for the computa-
tion of Nash equilibria in a general setting. More precisely, we consider games
with finitely many players with continuous cost functions and finite-dimensional
strategy sets.
Four different numerical methods are being presented, which are all based on
either an optimization reformulation or a fixed point reformulation of the general-
ized Nash equilibrium problem. These reformulations are introduced in the next
chapter. Chapters 3-5 deal with the numerical methods. In chapter 3, descent
methods for the solution of constrained and unconstrained optimization reformu-
lations are considered. These methods are designed to be globally convergent,
however, local convergence is rarely faster than linear. Therefore, in chapter 4 a
Newton-type method is derived through an unconstrained optimization reformu-
lation of the generalized Nash equilibrium problem. Another locally superlinearly
convergent method is presented in chapter 5, where a Newton-type method based
on a fixed point formulation of the generalized Nash equilibrium problem is con-
sidered. Finally some examples of generalized Nash equilibrium problems are de-
scribed in chapter 6, and numerical results of four numerical methods presented.
In the remainder of this introduction we give a formal definition of the gener-
alized Nash equilibrium problem, and of a particular subclass of these generalized
3
4 CHAPTER 1. INTRODUCTION
Nash equilibria called normalized Nash equilibria, on which we focus in this the-
sis. A popular area where generalized Nash equilibria are applied is in the mod-
elling of the liberalized electricity markets, which is why we present an electricity
market model next. The introduction closes with an overview on existing work on
the numerical computation of generalized Nash equilibria.
We begin with some terms and results from optimization theory that will be
used in this introduction and later on.
1.1 Preliminaries
Here we state some basic facts from optimization theory and clarify our notation.
A nonempty set X ⊆ Rn is said to be convex, if for all x, y ∈ X and t ∈ [0, 1] we
have tx + (1 − t)y ∈ X. A function f : X → R is convex, if for all x, y ∈ X and
t ∈ [0, 1] the inequality f (tx + (1 − t)y) ≤ t f (x) + (1 − t) f (y) holds.
Given a convex, continuously differentiable function f : Rn → R and convex,
continuously differentiable functions gi : Rn → R, i = 1, . . . ,m, we consider the
constrained optimization problem
min f (x)
subject to gi(x) ≤ 0 for all i = 1, . . . ,m.
(1.1)
Due to the convexity of the function f , every local minimum of (1.1) is already
a global minimum. We say that Slater’s constraint qualification holds for the
convex optimization problem (1.1), if there is a vector x̄ such that gi(x̄) < 0 for
all i = 1, . . . ,m. Slater’s constraint qualification implies that for any solution x∗ of
problem (1.1) there exists a vector of Lagrange multipliers λ = (λ1, . . . , λm)T such
that the Karush Kuhn Tucker conditions
∇ f (x∗) +
∑m
i=1 λi∇gi(x
∗) = 0
0 ≥ g(x∗) ⊥ λ ≥ 0.
hold, where g(x∗) ⊥ λ means that the vector g(x∗) is perpendicular to the vector λ,
that is, λT g(x∗) = 0.
Notation: Given a differentiable function g : Rn → Rm, g′(x) ∈ Rm×n or
Dg(x) denotes the Jacobian of g at x, whereas ∇g(x) ∈ Rn×m is the transposed
Jacobian. In particular, for m = 1, the gradient ∇g(x) is viewed as a column
vector. Several times, we also consider partial derivatives of a real-valued function
f : Rn → R with respect to certain block components of x only, and this will be
denoted by using suitable subscripts, e.g., ∇xν f (x) denotes the partial gradient
of f at x, where the derivatives are taken with respect to the components of the
block vector xν only. Second-order partial derivatives with respect to certain block
1.2. THE GENERALIZED NASH EQUILIBRIUM PROBLEM 5
components are written in a similar way as ∇2xνxµ f (x), for example, meaning that
we first differentiate with respect to xν and then with respect to xµ.
For a matrix A ∈ Rm×n and a subset I ⊆ {1, . . . , n} we denote by AI the subma-
trix of A consisting of the columns ai, i ∈ I. For a vector d ∈ Rn we write d ≥ 0 if
di ≥ 0 for all i = 1, . . . ,m.
1.2 The Generalized Nash Equilibrium Problem
The generalized Nash equilibrium is a solution concept for a particular class of
games. Basically a game is described through a number of players, their strategy
sets and their cost functions. Let the number of players be N. To refer to a par-
ticular player, we use the index ν ∈ {1, . . . ,N}. Each player controls a decision
vector xν, where xν has to be chosen from a set Xν ⊆ Rnν . The set Xν is usually
called the strategy set of player ν, or the feasible set of player ν. Let n :=
∑N
ν=1 nν,
and x := (x1, x2, . . . , xν, . . . , xN) ∈ Rn denote the vector that comprises the deci-
sion vectors of all players. We write (xν, x−ν) := x if we want to emphasize the νth
player’s decision vector within x. Here the vector x−ν = (x1, . . . , xν−1, xν+1, . . . , xN)
is short notation for the vector that consists of all the decision vectors except player
νth decision variables.
Each player ν has a cost function θν : Rn → R. Given a decision vector x =
(x1, x2, . . . , xN), player ν incurs costs θν(x1, . . . , xN). Thus, the cost function of
player ν does not only depend on player νth decision vector xν, but also on all
other players decision vectors x−ν. Altogether, a game is fully described by Γ :=
{
Xν, θν
}
ν=1,...,N .
We assume that a player acts rational in that, given the decision vector x−ν of
the rival players, he chooses a decision vector xν that minimizes his cost function.
In other words, given a vector x−ν, player ν solves the optimization problem
min
xν
θν(x
ν, x−ν) subject to xν ∈ Xν.
A Nash equilibrium (or solution to the Nash equilibrium problem) is a vector
x∗ with x∗ = (x∗,1, x∗,2, . . . , x∗,N) ∈ X1 × X2 × · · · × XN , such that for each ν ∈
{1, . . . ,N} the vector x∗,ν solves the optimization problem
min
xν
θν(x
ν, x∗,−ν) subject to xν ∈ Xν. (1.2)
Literally speaking, at a Nash equilibrium point x∗, no player has an intend to
change his own decision vector as long as the other players do not change their
decision vector. In the sequel we will use the term standard Nash equilibrium
problem, Nash equilibrium problem or standard Nash game, in short NEP, to refer
6 CHAPTER 1. INTRODUCTION
to the above problem, in contrast to the generalized Nash equilibrium problem,
GNEP, which we describe next.
In the generalized Nash game not only the cost functions depend on the rival
players’ decision variables, but also the strategy sets Xν, ν = 1, . . . ,N. Let X ⊆ Rn
be a nonempty, closed and convex set. The set X doesn’t necessarily feature a
cartesian product structure.
For each ν ∈ {1, . . . ,N} we define the strategy set of player ν,
Xν(x
−ν) := {xν ∈ Rnν | (xν, x−ν) ∈ X}, (1.3)
which means that the strategy set of player ν is given by a set-valued map Xν :
R
n−nν → Rnν . In analogy to the definition of the standard Nash equilibrium, we
arrive at the following definition of a generalized Nash equilibrium.
Definition 1.2.1 A vector x∗ = (x∗,1, x∗,2, . . . , x∗,N) is a generalized Nash equilib-
rium (GNE) or a solution to the generalized Nash equilibrium problem (GNEP),
if for all ν = 1, 2, . . . ,N, the block component x∗,ν of x∗ solves the optimization
problem
min
xν
θν(x
ν, x∗,−ν) subject to xν ∈ Xν(x
∗,−ν). (1.4)
Other terms than generalized Nash equilibrium are coupled constraint Nash equi-
librium [59], [60] Nash equilibrium problem with shared constraints [71],[32]
and social equilibrium problem. Some of these terms refer to the fact that the
individual strategy sets of the players are defined through a single convex set X
by equation (1.3). In a wider sense, the term ’generalized Nash equilibrium prob-
lem’ refers to Nash equilibrium problems where the feasible sets Xν(x−ν) of the
players can not be expressed through a single set X, see [25] for a more detailed
description.
From now on, unless otherwise mentioned, we will always assume that the follow-
ing assumptions concerning the cost functions θν, ν = 1, . . . ,N, and the strategy
set X hold.
Assumption 1.2.2
(A.1) For all ν ∈ {1, . . . ,N} the cost function θν is continuous as a function of x.
Furthermore, θν is convex as a function of the variable xν, i.e., the function
θν(·, x−ν) is convex for all x−ν.
(A.2) The strategy set X is nonempty, convex and closed.
1.3. NORMALIZED NASH EQUILIBRIA 7
1.3 Normalized Nash Equilibria
An important subclass of the set of generalized Nash equilibria is the class of
normalized Nash equilibria. It was introduced by J.B. Rosen [92] in a slightly
different fashion than described below.
Throughout this section, we assume that in addition to Assumption 1.2.2 the
cost functions θν, ν = 1, . . . ,N, are continuously differentiable. We consider the
function
F(x1, x2, . . . , xN) :=


∇x1θ1(x1, x−1)
∇x2θ2(x2, x−2)
...
∇xNθN(xN , x−N)


,
where ∇xνθν(xν, x−ν) denotes the partial gradient of θν with respect to the block
component xν. Then x∗ is a called a normalized Nash equilibrium (or variational
equilibrium in [25]), if and only if x∗ ∈ X satisfies
F(x∗)T (y − x∗) ≥ 0 for all y ∈ X, (1.5)
in other words, x∗ is the solution of a variational inequality. In order to clarify
the meaning of normalized Nash equilibria, let us consider equation (1.5) with
y := (zν, x∗,−ν). Since x∗ ∈ X there is zν such that y ∈ X, implying that zν ∈
Xν(x∗,−ν). Thus (1.5) reduces to the first order necessary conditions for player ν′s
optimization problem (1.4), that is,
∇xνθν(x
∗)T (zν − x∗,ν) ≥ 0 ∀ zν ∈ Xν(x
∗,−ν).
Since θν(·, x−ν) is convex by Assumption 1.2.2, the first order condition already
implies that xν,∗ solves optimization problem (1.4) of player ν. Therefore, any
normalized Nash equilibrium is a generalized Nash equilibrium. The converse
is not true in general. This follows from the above considerations, in particular,
from the fact that the first order necessary conditions for x∗ to be a solution of the
GNEP, which are
F(x∗)T (y − x∗) ≥ 0 for all y ∈ X1(x
∗,−1) × · · · × XN(x
∗,−N), (1.6)
may admit more solutions than the variational inequality (1.5). The above formu-
lation (1.6) of the GNEP is a quasi-variational inequality (QVI) [43],[78]. How-
ever, in the standard Nash game, the set of Nash equilibria is the same as the set
of normalized Nash equilibria, whereas the role of variational inequality prob-
lems within generalized Nash games is precisely identified through the notion of
normalized Nash equilibria ([6], [43] and [31]).
8 CHAPTER 1. INTRODUCTION
Since a normalized Nash equilibrium is the solution of the particular varia-
tional inequality problem (1.5), one can apply the extensive theory on variational
inequalities ([27],[28]) to deduce existence and uniqueness results for normalized
Nash equilibria. For instance, it follows that a game satisfying Assumptions 1.2.2
with continuously differentiable cost functions, having the additional property that
the strategy set X is compact, has at least one normalized Nash equilibrium. If fur-
thermore, the function F is strictly monotone, that is, for all x, y ∈ X with x , y
the inequality
(F(x) − F(y))T (x − y) > 0
holds, then the normalized Nash equilibrium is unique. If, in addition, F is
strongly monotone, that is, there exists a parameter µ > 0 such that the inequality
(F(x) − F(y))T (x − y) ≥ µ‖x − y‖2
holds for all x, y ∈ X, then there is a unique normalized Nash equilibrium regard-
less of whether X is compact or not.
The normalized Nash equilibrium has an interesting application in that it pro-
vides a solution concept for a particular class of leader-follower games. This
connection has been noted by Harker in a remark at the very end of [43], and a
somewhat related idea is explored by Krawczyk [60, Section 2.3] in the context
of an environmental pollution model.
We consider N players, where each player ν chooses a strategy xν ∈ Rnν subject
to an individual constraint gν(xν) ≤ 0, gν : Rnν → Rmν . Playing xν results in costs
θν(xν, x−ν) for agent ν, while it requires the use of l differnet scarce resources at
level dν(xν) ∈ Rl, where dν is a convex function. We assume that the price for these
resources is fixed and that it is equal for all players, that is, prices for resources
are given by a single vector p ∈ Rl. Thus, given the decision vector x−ν of the rival
players, player ν solves the optimization problem
minxν θν(xν, x−ν) + pT dν(xν)
subject to gν(xν) ≤ 0.
(1.7)
For x−ν fixed let x∗,ν be a solution of this optimization problem and suppose
that Slater’s constraint qualification holds. Moreover, we assume that all functions
involved are continuously differentiable. Then the Karush-Kuhn-Tucker condi-
tions are both necessary and sufficient for x∗,ν to be a solution of (1.7), implying
that there exists a vector of multipliers λ∗,ν ∈ Rmν such that (x∗,ν, λ∗,ν) solves the
equations
∇xνθν(x∗,ν, x−ν) + ∇dν(x∗,ν) · p + ∇gν(x∗,ν) · λ∗,ν = 0
0 ≥ gν(x∗,ν) ⊥ λ∗,ν ≥ 0.
(1.8)
Solving optimization problem (1.7) for all players ν = 1, . . . ,N simultane-
ously is a standard Nash equilibrium problem. Each player ν has a separate strat-
egy set defined through the function gν. Suppose now that there is an additional
1.3. NORMALIZED NASH EQUILIBRIA 9
player who has the power to set prices for the resources. We assume that this
player, the leader, is non-discriminating in that he demands the same price from
all players, his only intend being that the total resource consumption of all play-
ers does not exceed certain upper bounds. This leader might be a governmental
authority caring for natural resources like water, minerals, pollutant emissions or
land usage.
In order to find a price vector such that aggregated resource consumption of
players does not surmount prescribed limits, we formulate a generalized Nash
equilibrium problem. In this game, the functions θν are still the cost functions of
the players, whose individual strategy set is given by Xν = {xν ∈ Rnν | gν(xν) ≤ 0}.
Different to the standard Nash game above, joint constraints are imposed on the
players of the form
X̄ := {x ∈ Rn |
N∑
ν=1
dν(x
ν) ≤ c},
with dν : Rnν → Rl and a given constant c ∈ Rl.
Consider the optimization problem
minxν θν(xν, x−ν)
subject to gν(xν) ≤ 0, dν(xν) +
∑
ξ,ν dξ(x
ξ) ≤ c
(1.9)
for player ν and let x∗,ν be a solution for given x−ν. Assuming that Slater’s con-
straint qualification holds for (1.9), it follows that there are vectors λ∗,ν ∈ Rmν
and µ∗,ν ∈ Rl such that the triple (x∗,ν, λ∗,ν, µ∗,ν) solves the Karush-Kuhn-Tucker
equations
∇xνθν(x∗,ν, x−ν) + ∇gν(x∗,ν) · λ∗,ν + ∇xνdν(x∗,ν) · µ∗,ν = 0
0 ≥ gν(x∗,ν) ⊥ λ∗,ν ≥ 0
0 ≥
∑N
ξ=1 dξ(x
ξ) − c ⊥ µ∗,ν ≥ 0.
A comparision with the KKT-condition of optimization problem (1.7) shows
that (x∗,ν, λ∗,ν) solves (1.8) with p := µ∗,ν.
Concatenating these KKT-conditions for all players ν = 1, . . . ,N, we see that
every solution (x∗, λ∗, µ∗) of the generalized Nash equilibrium problem with the
property that µ∗,1 = µ∗,2 = · · · = µ∗,N solves the KKT-conditions of problems
(1.7) for all players ν with the Lagrange multiplier p := µ∗,1. Since µ∗,1 = µ∗,2 =
· · · = µ∗,N , we have a normalized Nash equilibrium. This particular solution of
the optimization problems (1.7) has the additional property that
∑N
ξ=1 dξ(x
ξ) ≤ c,
where equality holds whenever the corresponding component of p is nonzero. The
latter fact allows two economic interpretations, which we will outline in brief. In
the scenario of a government facing the decision of whether to impose taxes or
not, taxes are not installed whenever the aggregated consumption of the resource
(natural resources) does not exceed the targeted amount.
10 CHAPTER 1. INTRODUCTION
On the other hand, the model allows a quite different interpretation. Suppose
that resources, like oil or minerals, are being auctioned on a market with infinitely
many sellers. As long as the total demand for a resource is below the available
amount, prices for this resource will be equal to the costs it takes to obtain them,
for instance costs for oil extraction. (This case is not considered in the model, but
the extension is straightforward). Whenever there is a shortfall, prices will rise
due to scarcity, which corresponds to a non-zero price in the model above.
1.4 Electricity Market Model
Here we consider an electricity market model with two competitors sharing a
power line network that is owned by a third party. The network consists of four
nodes with different consumers at each node, see figure 1.1.
  
  
  



  
  
  



  
  
  
  




  
  
  
  




  
  
  



B
AA
B
Consumer 1 Consumer 2
Consumer 3
Consumer 4
e1 e2
e3
e4
Figure 1.1: Electricity Market Example
Consumer 1 for instance can be interpreted as a remote rural area with low
electricity demand, consumers 2 and 4 as big industrial cities and consumer 3 as
a smaller city with medium-level electricity demand. Each company owns one
power plant, that of company A being at node 2 and that of company B at node
4. Nodes are linked by four power transmission lines with different capacity and
different costs (due to different voltage and length). Routing electricity through a
power line incurs costs on a company proportional to the current in that particular
line. Each company decides about the amount of electricity it sells at each node.
Since costs for shipping electricity depend on the paths chosen in the network, the
company also has to decide how to route the electricity. This is fully described
by one additional decision variable, since the network contains only one loop.
In general, power lines can be used in both directions. In this model, however,
the direction of flow is prescribed in order to avoid nonsmoothness in the cost
functions of the companies.
1.4. ELECTRICITY MARKET MODEL 11
The model contains the following variables and parameters:
xAi , x
B
i : electricity company A (B) sells to consumer i
yA : current on edge 4 from company A
yB : current on edge 4 from company B
cA, cB : costs for producing one MWh with power plant A (B)
ki : capacity limit of link i
ei : costs on link i
Ci : specific constant of consumer i
γ : parameter of inverse demand function
We suppose that the price for electricity is given by an inverse demand func-
tion, that differs in each node due to number and preferences of consumers, that
is, electricity price at node i is
pi(x
A, xB) = Cγi ·
1
(xAi + x
B
i )
γ
, i = 1, 2, 3, 4.
The cost function of company A is
f A(xA, yA) = cA
4∑
i=1
xAi + e1x
A
1 + e2(x
A
4 + y
A) + e3(x
A
3 − y
A) + e4y
A
while company B’s costs are
f B(xB, yB) = cB
4∑
i=1
xBi + e1x
B
1 + e2(x
B
1 + x
B
2 + x
B
3 − y
B) + e3(x
B
3 − y
B) + e4y
B.
The profit functions are
πA(xA, yA, xB) = p(xA, xB)T · xA − f A(xA, yA)
and
πB(xA, xB, yB) = p(xA, xB)T · xB − f B(xB, yB),
respectively. The joint constraints imposed through the capacity limits of the
power line are
xA1 + x
B
1 ≤ k1,
xA4 + y
A − xB1 − x
B
2 − x
B
3 + y
B ≤ k2,
−xA4 − y
A + xB1 + x
B
2 + x
B
3 − y
B ≤ k2,
xA3 + x
B
3 − y
A − yB ≤ k3,
yA + yB ≤ k4.
12 CHAPTER 1. INTRODUCTION
Further, for technical reasons we assume that electricity sales are strictly positive
at all markets
xA ≥ 0.1,
xB ≥ 0.1,
and two additional constraints that prevent negative flow on edge 3,
yA ≤ xA3 ,
yB ≤ xB3 .
Numerical results for this model are presented in chapter 6.
1.5 Previous Work
The first appearance of generalized Nash games, though not termed this way, is
probably in the seminal work of Arrow and Debreu [5] on the existence of an
equilibrium in abstract economies in 1954. In 1965, Rosen formally introduced
the definition of a normalized Nash equilibrium and considered questions of ex-
istence and uniqueness. Rosen also proposed a gradient method for computing a
normalized Nash equilibrium. However, the generalized Nash equilibrium prob-
lem did not attract particular attention for a long time after the work of Rosen.
Bensoussan [11] formulated the GNEP as a quasi-variational inequality in 1974,
though with infinite-dimensional strategy sets, which Harker [43] further explored
for the finite-dimensional case 15 years later. Harker pointed out that the general-
ized Nash equilibrium problem encompasses a class of Stackelberg-like (Leader-
follower) problems.
In the late nineties, generalized Nash games became popular for modelling
environmental and energy economic issues, as well as for the design and analysis
of telecommunication networks [15], [45], [59] and [61]. Some of the models
presented in these papers are described in chapter 6.
Still the numerical solution of the generalized Nash equilibrium problem re-
mained a difficult task. While the standard Nash equilibrium problem 1.2 (NEP)
is equivalent to the variational inequality problem 1.5, see [44], as mentioned
earlier, the generalized Nash equilibrium problem is not. Nonetheless, numeri-
cal methods designed for the solution of the variational inequality problems have
constantly inspired approaches towards the solution of the GNEP.
In the eighties, when numerical methods for solving variational inequality
problems were yet widely unknown, Dafermos [17] proposed an iterative method
for the solution of variational inequalties, which is based on a fixed point formu-
lation. This method resembles somewhat the Jacobi iteration for the solution of
a linear system, and is therefore also called Jacobi or Gauss-Seidel method [25].
Başar and Li [64],[9], applied this method in the particular context of NEPs.
1.5. PREVIOUS WORK 13
Some years later, in 1994, Uryasev and Rubinstein [98] investigated a fixed
point iteration for the computation of normalized Nash equilibria, called relax-
ation method. They improved on existing convergence theory for relaxation meth-
ods, in that they did not require differentiability of the cost functions. This relax-
ation method has been applied by several different authors since then.
Other approaches towards the numerical solution of the GNEP include Penalty
methods [78], [39],[29], [26], and solution methods for quasi-variational inequal-
ities [77]. Also the gradient method introduced by Rosen received some further
attention. Primal-dual gradient methods are investigated by Flåm [36] and for the
NEP by Antipin in [3]. Further relaxation-type methods were analysed in [37]
for a very restricted class of generalized Nash equilibrium problems called convex
games. Quite different from all prior approaches, Nabetani, Fukushima and Tseng
[71] compute generalized Nash equilibria through repeated solution of parameter-
ized variational inequalities.
An overview on numerical methods for some Nash games other than the GNEP
provides the monograph [70]. These are in particular games defined on graphs
and bimatrix games. The book contains one article (chapter 6) about computing
an equilibrium in the pure exchange economy, which can be cast as a GNEP.
Chapter 2
Optimization Reformulations
In this chapter we derive constrained and unconstrained optimization reformula-
tions of the generalized Nash equilibrium problem. The first section starts with a
constrained optimization reformulation that yields a full characterization of the set
of generalized Nash equilibria. The drawback of this optimization reformulation
is, however, that the objective function of the optimization problem is in general
not differentiable, and therefore the problem itself not easy to solve with existing
optimization routines. Thus, in the next section, we present a constrained smooth
optimization reformulation. This reformulation characterizes a subset of the set of
generalized Nash equilibrium, precisely, it gives the set of normalized Nash equi-
libria. Alongside with the two constrained optimization reformulations we derive
fixed point formulations of the solutions of the the generalized Nash equilibrium
problem. The last section deals with an unconstrained smooth optimization refor-
mulation, which again characterizes the set of normalized Nash equilibria. The
approach is somewhat related to the work on equilibrium problems in [13] and the
recent paper [66].
2.1 A Constrained Optimization Reformulation
An important tool in the theoretical analysis of the generalized Nash equilibrium
problem is the so-called Nikaido-Isoda function. This function, sometimes also
called Ky-Fan function, was introduced originally in order to prove the existence
of a Nash equilbrium by means of a fixed point theorem [73]. In the following,
however, the Nikaido-Isoda function will be the main tool for the development of
numerical methods for the solution of the generalized Nash equilibrium problem.
Let θν, ν = 1, . . . ,N be the cost functions as described in the introduction. The
14
2.1. A CONSTRAINED OPTIMIZATION REFORMULATION 15
Nikaido-Isoda function is defined through
Ψ(x, y) :=
N∑
ν=1
[
θν(x
ν, x−ν) − θν(y
ν, x−ν)
]
. (2.1)
Let Xν(x−ν) be player ν’s strategy set as defined in (1.3). For given x ∈ Rn we write
Ω(x) := X1(x
−1) × X2(x
−2) × · · · × XN(x
N). (2.2)
The following Lemma connects the set X with the set-valued map Ω(x).
Lemma 2.1.1 We have x ∈ Ω(x) if and only if x ∈ X. In particular, Ω(x) , ∅ for
all x ∈ X.
Proof. Using the definitions of the sets Ω(x) and Xν(x−ν), we immediately obtain
x ∈ Ω(x) ⇐⇒ xν ∈ Xν(x
−ν) ∀ν = 1, . . . ,N
⇐⇒ (xν, x−ν) ∈ X ∀ν = 1, . . . ,N
⇐⇒ x = (xν, x−ν) ∈ X.
The second part is now obvious. 
Note that, for x < X, we have either Ω(x) = ∅ or Ω(x) , ∅, but then necessarily
x < Ω(x). Furthermore, given any x ∈ X, simple examples show that, in general,
neither Ω(x) is a subset of X nor X is included in Ω(x).
Using the Nikaido-Isoda-function, we define
V̂(x) := sup
y∈Ω(x)
Ψ(x, y), x ∈ X, (2.3)
where, for the moment, we assume implicitly that the supremum is always attained
for some y ∈ Ω(x). Later, this assumption will not be needed, so we do not state
it here explicitly. Then it is not difficult to see that V̂(x) is nonnegative for all x ∈
Ω(x), and that x∗ is a solution of the GNEP if and only if x∗ ∈ Ω(x∗) and V̂(x∗) = 0,
see also the proof of Theorem 2.1.2 below. Therefore, finding a solution of the
GNEP is equivalent to computing a global minimum of the optimization problem
min V̂(x) s.t. x ∈ Ω(x). (2.4)
Note that this optimization problem has a complicated feasible set since Ω(x)
explicitly depends on x. However, in view of Lemma 2.1.1, the program (2.4) is
equivalent to the optimization problem
min V̂(x) s.t. x ∈ X.
16 CHAPTER 2. OPTIMIZATION REFORMULATIONS
Although the Nikaido-Isoda-function is quite popular (especially for standard
Nash games) in the economic and engineering literature, see, for example, [15,
59, 61], it has some disadvantages from a mathematical and practical point of
view (also for the standard Nash game): On the one hand, given a vector x, the
supremum in (2.3) may not exist unless additional assumptions (like the compact-
ness of X) hold, and on the other hand, this supremum, if it exists, is usually not
attained at a single point which, in turn, implies that the mapping V̂ and, there-
fore, also the corresponding optimization reformulation (2.4) is nondifferentiable
in general.
In order to overcome these deficiencies, we use a simple regularization of the
Nikaido-Isoda-function. This idea was used earlier in several contexts, see, for
example, Fukushima [38] (for variational inequalities), Gürkan and Pang [42] (for
standard Nash games), and Mastroeni [66] (for equilibrium programming prob-
lems). Here we apply the regularization idea to GNEPs. To this end, let α > 0 be
a fixed parameter and define the regularized Nikaido-Isoda-function by
Ψα(x, y) :=
N∑
ν=1
[
θν(x
ν, x−ν) − θν(y
ν, x−ν) −
α
2
‖xν − yν‖2
]
. (2.5)
Furthermore, for x ∈ X, let
V̂α(x) := max
y∈Ω(x)
Ψα(x, y)
= max
y∈Ω(x)
N∑
ν=1
[
θν(x
ν, x−ν) − θν(y
ν, x−ν) −
α
2
‖xν − yν‖2
]
(2.6)
=
N∑
ν=1
{
θν(x
ν, x−ν) − min
yν∈Xν(x−ν)
[
θν(y
ν, x−ν) +
α
2
‖xν − yν‖2
]
}
.
be the corresponding value function.
A number of elementary properties of the mapping V̂α are summarized in the
following result.
Theorem 2.1.2 The regularized function V̂α has the following properties:
(a) V̂α(x) ≥ 0 for all x ∈ Ω(x).
(b) x∗ is a generalized Nash equilibrium if and only if x∗ ∈ Ω(x∗) and V̂α(x∗) =
0.
(c) For every x ∈ X, there exists a unique vector ŷα(x) =
(
ŷ1α(x), . . . , ŷ
N
α (x)
)
such
that for every ν = 1, . . . ,N,
argminyν∈Xν(x−ν)
[
θν(y
ν, x−ν) +
α
2
‖xν − yν‖2
]
= ŷνα(x).
2.1. A CONSTRAINED OPTIMIZATION REFORMULATION 17
Proof. (a) For all x ∈ Ω(x), we have V̂α(x) = maxy∈Ω(x) Ψα(x, y) ≥ Ψα(x, x) = 0.
(b) Suppose that x∗ is a solution of the GNEP. Then x∗ ∈ Ω(x∗) and
θν(x
∗,ν, x∗,−ν) ≤ θν(x
ν, x∗,−ν) ∀xν ∈ Xν(x
∗,−ν)
for all ν = 1, . . . ,N. Hence
Ψα(x
∗, y) =
N∑
ν=1
[
θν(x
∗,ν, x∗,−ν) − θν(y
ν, x∗,−ν)
︸                            ︷︷                            ︸
≤0 ∀yν∈Xν(x∗,−ν)
−
α
2
‖x∗,ν − yν‖2
]
≤ 0
for all y ∈ Ω(x∗). This implies
V̂α(x
∗) = max
y∈Ω(x∗)
Ψα(x
∗, y) ≤ 0.
Together with part (a), we therefore have V̂α(x∗) = 0.
Conversely, assume that x∗ ∈ Ω(x∗) and V̂α(x∗) = 0. Then Ψα(x∗, y) ≤ 0 holds
for all y ∈ Ω(x∗). Let us fix a particular player ν ∈ {1, . . . ,N}, and let xν ∈ Xν(x∗,ν)
and λ ∈ (0, 1) be arbitrary. Then define a vector y = (y1, . . . , yN) ∈ Rn blockwise
as follows:
yµ :=
{
x∗,µ, if µ , ν,
λx∗,ν + (1 − λ)xν, if µ = ν.
The convexity of the sets Xν(x∗,−ν) imply that yµ ∈ Xµ(x∗,−µ) for all µ = 1, . . . ,N,
i.e., y ∈ Ω(x∗). For this particular y, we therefore obtain
0 ≥ Ψα(x
∗, y)
= θν(x
∗,ν, x∗,−ν) − θν(λx
∗,ν + (1 − λ)xν, x∗,−ν) −
α
2
(1 − λ)2‖x∗,ν − xν‖2
≥ (1 − λ)θν(x
∗,ν, x∗,−ν) − (1 − λ)θν(x
ν, x∗,−ν) −
α
2
(1 − λ)2‖x∗,ν − xν‖2
from the convexity of θν with respect to xν. Dividing both sides by 1 − λ and then
letting λ → 1− shows that θν(x∗,ν, x∗,−ν) ≤ θν(xν, x∗,−ν). Since this holds for all
xν ∈ Xν(x∗,−ν) and all ν = 1, . . . ,N, it follows that x∗ is a solution of the GNEP.
(c) This statement follows immediately from the fact that the mapping yν 7→
θν(yν, x−ν) + α2 ‖x
ν − yν‖2 is strongly convex (for any given x), also taking into
account that Xν(x−ν) is a nonempty, closed and convex set. 
Note that the previous result reduces to Proposition 3 in [42] for the standard Nash
equilibrium problem. Using the first two statements of Theorem 2.1.2, we see that
18 CHAPTER 2. OPTIMIZATION REFORMULATIONS
finding a solution of the GNEP is equivalent to computing a global minimum of
the constrained optimization problem
min V̂α(x) s.t. x ∈ Ω(x), (2.7)
which, in turn, can be reformulated as
min V̂α(x) s.t. x ∈ X
in view of Lemma 2.1.1. The last statement of Theorem 2.1.2 shows that the new
objective function overcomes one of the deficiencies of the mapping V̂(x).
The following result shows that the definition of the mapping V̂α can also be
used in order to get a fixed point characterization of the GNEP.
Proposition 2.1.3 Let ŷα(x) be the vector defined in Theorem 2.1.2 (c) as the
unique maximizer in the definition of the regularized function V̂α(x), cf. (2.6).
Then x∗ is a solution of GNEP if and only if x∗ is a fixed point of the mapping
x 7→ ŷα(x), i.e., if and only if x∗ = ŷα(x∗).
Proof. First assume that x∗ is a solution of the GNEP. Then we obtain x∗ ∈ Ω(x∗)
(and, therefore, x∗ ∈ X in view of Lemma 2.1.1) and V̂α(x∗) = 0 from Theorem
2.1.2. In view of the definition of ŷα(x∗), this implies
0 = V̂α(x
∗) = max
y∈Ω(x∗)
Ψα(x
∗, y) = Ψα
(
x∗, ŷα(x
∗)
)
.
On the other hand, we also have Ψα(x∗, x∗) = 0. Since x∗ ∈ Ω(x∗) and the maxi-
mum ŷα(x∗) is uniquely defined by Theorem 2.1.2, it follows that x∗ = ŷα(x∗).
Conversely, let x∗ be a fixed point of the mapping ŷα. Then x∗ = ŷα(x∗) ∈ Ω(x∗)
and
0 = Ψα(x
∗, x∗) = Ψα
(
x∗, ŷα(x
∗)
)
= V̂α(x
∗).
Consequently, the statement follows from Theorem 2.1.2. 
We next consider a simple example which shows that, in general, the objective
function from (2.7) is nondifferentiable.
Example 2.1.4 Consider the GNEP with N = 2 players and the following opti-
mization problems:
minx1 θ1(x1, x2) := −x1 minx2 θ2(x1, x2) := 0
s.t. x1 + x2 ≤ 1, s.t. x1 + x2 ≤ 1,
2x1 + 4x2 ≤ 3, 2x1 + 4x2 ≤ 3,
x1, x2 ≥ 0, x1, x2 ≥ 0.
2.1. A CONSTRAINED OPTIMIZATION REFORMULATION 19
Hence we have X = {(x1, x2)T | x1 + x2 ≤ 1, 2x1 + 4x2 ≤ 3, x1 ≥ 0, x2 ≥ 0}. An
elementary calculation shows that the solution set is given by
S =
{
x∗ = (x∗1, x
∗
2)
∣
∣
∣
∣ x
∗
2 ∈
[
0,
3
4
]
, x∗1 =
{
1 − x∗2, if x
∗
2 ∈ [0,
1
2 ],
3
2 − 2x
∗
2, if x
∗
2 ∈ [
1
2 ,
3
4]
}
.
We want to compute V̂α(x). To this end, we first note that the regularized Nikaido-
Isoda-function for this game is
Ψα(x, y) = −x1 + y1 −
α
2
(x1 − y1)
2 −
α
2
(x2 − y2)
2.
Moreover, for this example, we have
X1(x
−1) =
{
x1
∣
∣
∣ x1 ≤ 1 − x2, x1 ≤
3
2
− 2x2, x1 ≥ 0
}
=
[
0,min{1 − x2,
3
2
− 2x2}
]
and
X2(x
−2) =
{
x2
∣
∣
∣ x2 ≤ 1 − x1, x2 ≤
3
4
−
1
2
x1, x2 ≥ 0
}
=
[
0,min{1 − x1,
3
4
−
1
2
x1}
]
and, therefore
V̂α(x) = −x1 − min
y1∈X1(x−1)
[
− y1 +
α
2
(x1 − y1)
2] − min
y2∈X2(x−2)
[α
2
(x2 − y2)
2].
Given x = (x1, x2) ∈ R2, the solution of the first minimization problem is given by
ŷ1α(x) =



0, if 1
α
+ x1 ≤ 0,
1
α
+ x1, if 1α + x1 ∈
[
0,min{1 − x2, 32 − 2x2}
]
,
min{1 − x2, 32 − 2x2}, if
1
α
+ x1 ≥ min{1 − x2, 32 − 2x2},
and the solution of the second problem is
ŷ2α(x) =



0, if x2 ≤ 0,
x2, if x2 ∈
[
0,min{1 − x1, 34 −
1
2 x1}
]
,
min{1 − x1, 34 −
1
2 x1}, if x2 ≥ min{1 − x1,
3
4 −
1
2 x1}.
However, since we are only interested in x ∈ X, the above formula simplify to
ŷ1α(x) =
{
1
α
+ x1, if 1α + x1 ∈
[
0,min{1 − x2, 32 − 2x2}
]
,
min{1 − x2, 32 − 2x2}, if
1
α
+ x1 ≥ min{1 − x2, 32 − 2x2},
= min
{1
α
+ x1, 1 − x2,
3
2
− 2x2
}
and
ŷ2α(x) = x2,
20 CHAPTER 2. OPTIMIZATION REFORMULATIONS
respectively. Now it is easy to see that the corresponding mapping
V̂α(x) = −x1 −
[
− ŷ1α(x) +
α
2
(x1 − ŷ
1
α(x))
2]
is not everywhere differentiable on the feasible set X.
The nondifferentiability of the mapping V̂α is a major disadvantage if one wants
to apply suitable optimization methods to the corresponding reformulation (2.7).
The very recent paper [23] considers some further properties of the function V̂α
and a related reformulation approach. In the following section, however, we de-
scribe a modification of the current approach which results into a smooth opti-
mization reformulation of the GNEP.
The situation is much more favourable if we specialize our results to the stan-
dard NEP. Then it can be shown that the mapping V̂α is continuously differentiable
provided all cost functions θν are smooth. This follows from the observation given
in Remark 2.2.7 below.
2.2 A Smooth Constrained Optimization Reformu-
lation
In this section, we modify the idea of the previous one and obtain another con-
strained optimization reformulation of the GNEP which has significantly different
properties than the reformulation discussed in Section 2.1. In particular, the re-
formulation to be given here is smooth. However, it does not give a complete
reformulation of all solutions of the GNEP, but it provides a characterization of
the normalized Nash equilibria, which were defined in the introduction. The nor-
malized Nash equilibrium can also be defined through the Nikaido-Isoda function
instead of the variational inequality (1.5), thereby avoiding the assumption of dif-
ferentiability of the cost functions.
Definition 2.2.1 A vector x∗ ∈ X is a called normalized Nash equilibrium (NoE)
of the GNEP, if supy∈X Ψ(x
∗, y) = 0 holds, where Ψ denotes the Nikaido-Isoda-
function from (2.1).
The above definition of a normalized Nash equilibrium corresponds to one given
in, e.g., [37, 98]. It is slightly different from the original definition of a normal-
ized equilibrium given in [92]. This and other features of the normalized Nash
equilibrium were discussed in the introduction in Section 1.3.
We next state a simple property of the Nikaido-Isoda-function which follows
immediately from the fact that the cost functions θν(x) = θν(xν, x−ν) are convex
with respect to xν.
2.2. A SMOOTH CONSTRAINED OPTIMIZATION REFORMULATION 21
Lemma 2.2.2 For any given x ∈ X, the Nikaido-Isoda-functionΨ(x, y) is concave
in y ∈ X.
In order to derive a smooth reformulation of the GNEP, our basic tool is, once
again, the regularized Nikaido-Isoda-function Ψα(x, y) from (2.5). Based on this
mapping, we define
Vα(x) := max
y∈X
Ψα(x, y)
= max
y∈X
N∑
ν=1
[
θν(x
ν, x−ν) − θν(y
ν, x−ν) −
α
2
‖xν − yν‖2
]
(2.8)
= max
y∈X
[
Ψ(x, y) −
α
2
‖x − y‖2
]
.
Note that, due to Lemma 2.2.2, given an arbitrary x ∈ X, we take the maximum
of a uniformly concave function in y, hence Vα(x) is well-defined. Comparing the
definition of Vα with the one of V̂α in (2.6), we see that the only difference is that
the maximum is taken over all y ∈ X instead of all y ∈ Ω(x).
This minor change has a number of important consequences. We first state the
counterpart of Theorem 2.1.2 for the mapping Vα.
Theorem 2.2.3 The regularized function Vα has the following properties:
(a) Vα(x) ≥ 0 for all x ∈ X.
(b) x∗ is a normalized Nash equilibrium if and only if x∗ ∈ X and Vα(x∗) = 0.
(c) For every x ∈ X, there exists a unique maximizer yα(x) such that
argmax
[
Ψ(x, y) −
α
2
‖x − y‖2
]
= yα(x), (2.9)
and yα(x) is continuous in x.
Proof. (a) For any x ∈ X, we have Vα(x) = maxy∈X Ψα(x, y) ≥ Ψα(x, x) = 0.
(b) First let x∗ be a normalized Nash equilibrium. Then x∗ ∈ X and supy∈X Ψ(x
∗, y) ≤
0. Hence Ψ(x∗, y) ≤ 0 for all y ∈ X. Since
Ψα(x
∗, y) = Ψ(x∗, y) −
α
2
‖x∗ − y‖2 ≤ Ψ(x∗, y) ≤ 0 ∀y ∈ X,
it follows that Vα(x∗) = maxy∈X Ψα(x∗, y) ≤ 0. Together with statement (a), this
implies Vα(x∗) = 0.
22 CHAPTER 2. OPTIMIZATION REFORMULATIONS
Conversely, let x∗ ∈ X be such that Vα(x∗) = 0. Then
Ψα(x
∗, y) ≤ 0 ∀y ∈ X. (2.10)
Assume there is a vector ŷ ∈ X such that Ψ(x∗, ŷ) > 0. Then λx∗ + (1−λ)ŷ ∈ X for
all λ ∈ (0, 1), and Lemma 2.2.2 implies
Ψ(x∗, λx∗+(1−λ)ŷ) ≥ λΨ(x∗, x∗)+(1−λ)Ψ(x∗, ŷ) = (1−λ)Ψ(x∗, ŷ) > 0 ∀λ ∈ (0, 1).
Therefore, we obtain
Ψα(x
∗, λx∗ + (1 − λ)ŷ) = Ψ(x∗, λx∗ + (1 − λ)ŷ) −
α
2
‖x∗ − λx∗ − (1 − λ)ŷ‖2
= Ψ(x∗, λx∗ + (1 − λ)ŷ) −
α
2
(1 − λ)2‖x∗ − ŷ‖2
≥ (1 − λ)Ψ(x∗, ŷ) −
α
2
(1 − λ)2‖x∗ − ŷ‖2
> 0
for all λ ∈ (0, 1) sufficiently close to 1. This, however, is a contradiction to (2.10).
(c) In view of Lemma 2.2.2, the mapping y 7→ Ψ(x, y) − α2 ‖x − y‖
2 is strongly
concave (uniformly in x). Hence statement (c) is a consequence of standard sen-
sitivity results, see, for example, [53, Corollaries 8.1 and 9.1]. 
Theorem 2.2.3 shows that we can characterize the normalized Nash equilibria of
a GNEP as the global minima of the constrained optimization problem
min Vα(x) s.t. x ∈ X. (2.11)
In contrast to the corresponding reformulation in (2.7), we do not get a reformu-
lation of all generalized Nash equilibria.
We next state the counterpart of Proposition 2.1.3. Its proof is omitted here
since it is essentially the same as the one for Proposition 2.1.3 (using Theorem
2.2.3 instead of Theorem 2.1.2).
Proposition 2.2.4 Let yα(x) be the vector defined in Theorem 2.2.3 (c) as the
unique maximizer in the definition of the regularized function Vα(x), cf. (2.6).
Then x∗ is a normalized Nash equilibrium of GNEP if and only if x∗ is a fixed
point of the mapping x 7→ yα(x).
Now we come back to the function Vα and the optimization problem 2.11. Our
aim is to show that the regularized function Vα is continuously differentiable, pro-
vided that the cost functions θν are continuously differentiable for each player
ν = 1, . . . ,N. Based on this result, further properties of the optimization problem
2.11, such as a stationary point result, will be derived in the next chapter.
2.2. A SMOOTH CONSTRAINED OPTIMIZATION REFORMULATION 23
Theorem 2.2.5 Suppose that the cost functions θν are continuously differentiable
for each player ν = 1, . . . ,N. Then the regularized function Vα is continuously
differentiable for every x ∈ X, and its gradient is given by
∇Vα(x) = ∇xΨα(x, y)
∣
∣
∣
y=yα(x)
=
N∑
ν=1
[
∇θν(x
ν, x−ν) − ∇θν(y
ν
α(x), x
−ν)
]
+


∇x1θ1(y1α(x), x
−1)
...
∇xNθN(yNα (x), x
−N)


− α
(
x − yα(x)
)
,
where yα(x) denotes the unique maximizer from Theorem 2.2.3 (c) associated to
the given vector x.
Proof. We first recall that the regularized function Vα can be represented as in
the last line of (2.6), and that the mapping
y 7→ Ψα(x, y) = Ψ(x, y) −
α
2
‖x − y‖2
is strongly concave for any fixed x in view of Lemma 2.2.2. Hence it follows
from Danskin’s Theorem (see, for example, [28]) that Vα is differentiable with
gradient ∇Vα(x) = ∇xΨα(x, y)
∣
∣
∣
y=yα(x)
. Using the definition of the mapping Ψα, an
elementary calculation shows that
∇xΨα(x, y) =
N∑
ν=1
[
∇θν(x
ν, x−ν) − ∇θν(y
ν, x−ν)
]
+


∇x1θ1(y1, x−1)
...
∇xNθN(yN , x−N)


− α(x − y),
Inserting y = yα(x) then gives the desired formula for the gradient of Vα. Since
all cost functions θν are continuously differentiable, and since yα(x) is also a con-
tinuous mapping of x in view of Theorem 2.2.3, we finally get that the gradient
∇Vα(x) = ∇xΨα(x, y)
∣
∣
∣
y=yα(x)
is continuous, i.e., the regularized function Vα is con-
tinuously differentiable. 
The following note shows that no regularization of the Nikaido-Isoda-function is
necessary if the cost functions θν have some stronger properties than those men-
tioned so far.
24 CHAPTER 2. OPTIMIZATION REFORMULATIONS
Remark 2.2.6 Suppose that the functions θν(x) = θν(xν, x−ν) are strongly convex
in xν (for any given x−ν). Then the mapping
V(x) := max
y∈X
Ψ(x, y)
is well-defined and gives a reformulation of the GNEP as a smooth optimization
problem
min V(x) s.t. x ∈ X.
This means that there is no need to regularize the function Ψ for strongly convex
cost functions. The proof of the above statement follows by simple inspection of
the proofs given in this section. Note, however, that the unconstrained optimiza-
tion reformulation to be presented in Section 2.3 needs a regularized Nikaido-
Isoda-function even in the case of strongly convex functions θν.
We close this section with a simple note on the application of our results to the
standard Nash equilibrium problem.
Remark 2.2.7 Suppose that the nonempty, closed, and convex set X ⊆ Rn has a
Cartesian product structure, that is,
X = X1 × X2 × · · · × XN
with Xν ⊆ Rnν fixed. Then Ω(x) = X for all x, and the GNEP reduces to the
standard NEP. Moreover, it follows that
V̂α(x) = max
y∈Ω(x)
Ψα(x, y) = max
y∈X
Ψα(x, y) = Vα(x)
for all x ∈ X, i.e., the two functions V̂α from the previous section and Vα from the
current section coincide. In particular, the mapping V̂α is therefore also continu-
ously differentiable when applied to a standard NEP.
2.3 An Unconstrained Smooth Optimization Refor-
mulation
Here we use the regularized Nikaido-Isoda-function in order to obtain an uncon-
strained optimization reformulation of the GNEP. To this end, let 0 < α < β be
two given parameters, let
Ψα(x, y) :=
N∑
ν=1
[
θν(x
ν, x−ν) − θν(y
ν, x−ν) −
α
2
‖xν − yν‖2
]
,
2.3. AN UNCONSTRAINED SMOOTH OPTIMIZATION REFORMULATION25
Ψβ(x, y) :=
N∑
ν=1
[
θν(x
ν, x−ν) − θν(y
ν, x−ν) −
β
2
‖xν − yν‖2
]
be the associated regularized Nikaido-Isoda functions, and let
Vα(x) := max
y∈X
Ψα(x, y) = Ψα
(
x, yα(x)
)
,
Vβ(x) := max
y∈X
Ψβ(x, y) = Ψβ
(
x, yβ(x)
)
be the corresponding regularized value functions. Formally, these functions are
defined only for x ∈ X in the previous section. However, it is easy to see that they
can be defined for any x ∈ Rn.
Similar to the way the D-gap function was derived from the regularized gap
function in the context of variational inequalities, see [82, 99], we then define
Vαβ(x) := Vα(x) − Vβ(x), x ∈ R
n. (2.12)
In order to show that this difference of two regularized Nikaido-Isoda-functions
gives an unconstrained optimization reformulation of the GNEP, we first state the
following result.
Lemma 2.3.1 The inequality
β − α
2
‖x − yβ(x)‖
2 ≤ Vαβ(x) ≤
β − α
2
‖x − yα(x)‖
2 (2.13)
holds for all x ∈ Rn.
Proof. By definition, we have for any x ∈ Rn
Vβ(x) = Ψβ
(
x, yβ(x)
)
= max
y∈X
Ψβ(x, y)
and, therefore
Vβ(x) ≥ Ψβ
(
x, yα(x)
)
.
This implies
Vαβ(x) = Vα(x) − Vβ(x)
≤ Ψα
(
x, yα(x)
)
−Ψβ
(
x, yα(x)
)
=
β − α
2
N∑
ν=1
‖xν − yνα(x)‖
2
=
β − α
2
‖x − yα(x)‖
2
26 CHAPTER 2. OPTIMIZATION REFORMULATIONS
for all x ∈ Rn. This proves the right-hand inequality in (2.13). The other inequal-
ity can be verified in a similar way. 
Note that, similar to an observation in [55], Lemma 2.3.1 immediately implies that
the level sets of the function Vαβ are compact for compact sets X. This observation
guarantees that any sequence {xk} generated by a descent method for Vαβ will
remain bounded and, therefore, has at least one accumulation point.
As another consequence of Lemma 2.3.1, we obtain the following result.
Theorem 2.3.2 The following statements about the function Vαβ hold:
(a) Vαβ(x) ≥ 0 for all x ∈ Rn.
(b) x∗ is a normalized Nash equilibrium of the GNEP if and only if x∗ is a global
minimum of Vαβ with Vαβ(x∗) = 0.
Proof. (a) Using Proposition 2.2.4, we have
Vαβ(x) ≥
β − α
2
‖x − yβ(x)‖
2 ≥ 0
for all x ∈ Rn.
(b) First assume that x∗ is a normalized Nash equilibrium. Then Proposition 2.2.4
implies x∗ = yα(x∗) and x∗ = yβ(x∗). Hence (2.13) immediately gives Vαβ(x∗) = 0.
Conversely, let x∗ be such that Vαβ(x∗) = 0. Then (2.13) implies x∗ = yβ(x∗).
Hence x∗ solves the GNEP in view of Proposition 2.2.4. 
Theorem 2.3.2 shows that the normalized Nash equilibria of GNEP are precisely
the global minima of the unconstrained optimization problem
min Vαβ(x), x ∈ R
n. (2.14)
We next note that this is a smooth problem. To this end, however, we need to as-
sume, for the remainder of this section, that all cost functions θν are continuously
differentiable. Then we have the following result.
Theorem 2.3.3 The function Vαβ is continuously differentiable for every x ∈ Rn,
and its gradient is given by
∇Vαβ(x) =
N∑
ν=1
[
∇θν(y
ν
β(x), x
−ν) − ∇θν(y
ν
α(x), x
−ν)
]
2.3. AN UNCONSTRAINED SMOOTH OPTIMIZATION REFORMULATION27
+


∇x1θ1(y1α(x), x
−1) − ∇x1θ1(y1β(x), x
−1)
...
∇xNθN(yNα (x), x
−N) − ∇xNθN(yNβ (x), x
−N)


−α
(
x − yα(x)
)
+ β
(
x − yβ(x)
)
.
Proof. First recall that Vα(x) and Vβ(x) are defined for all x ∈ Rn. Then observe
that the formula for the gradients of these two functions, as given in Theorem 2.2.5
for x ∈ X, remain true for all x ∈ Rn. Since we have ∇Vαβ(x) = ∇Vα(x) − ∇Vβ(x),
the statement follows from Theorem 2.2.5. 
Chapter 3
Descent Methods
In this chapter we consider the smooth constrained optimization reformulation and
the smooth unconstrained optimization reformulation from the preceding chapter
again. The focus is on properties of the functions Vα and Vαβ, respectively. In the
first section we derive conditions that imply convexity of the function Vα, as well
as stationary point results for both the constrained and unconstrained optimization
problems (2.11) and (2.14).
The next section deals with the relaxation method proposed in [98], which is
one of the most popular methods for computing normalized Nash equilibria. We
show that it is possible to interprete the relaxation method, which is essentially a
fixed point iteration, as a feasible descent method for the constrained optimization
problem (2.11). This viewpoint, in particular the application of a line search, leads
to improved theoretical and numerical results.
Finally we extend the relaxation method to the non-differentiable case, that
is, we do not require the assumption that the cost functions are smooth. Proving
convergence for this nonsmooth method however requires stronger assumptions
regarding convexity than for the differentiable case. Throughout this chapter, we
assume that Assumption 1.2.2 holds.
3.1 Properties of the Optimization Reformulation
Let Ψα,Vα, and yα be defined by (2.5), (2.8), and (2.9), respectively. Theorem
2.2.3 shows that x∗ is a normalized Nash equilibrium if and only if it is a global
minimum of the constrained minimization problem
min Vα(x) s.t. x ∈ X (3.1)
with optimal function value Vα(x∗) = 0. Moreover, from Theorem 2.2.5 it follows
that Vα is differentiable, if the cost functions θν are all differentiable.
28
3.1. PROPERTIES OF THE OPTIMIZATION REFORMULATION 29
Under certain assumptions, it can be shown that the objective function Vα is
(strongly) convex. In view of the definition of Vα, this (strong) convexity depends
on similar properties of the regularized mapping Ψα(x, y). In order to state a cor-
responding result, we recall that the function Ψα(·, y) (as a function of x alone) is
convex on a set S ⊆ Rn for any given y if the inequality
Ψα
(
λx + (1 − λ)z, y
)
≤ λΨα(x, y) + (1 − λ)Ψα(z, y)
holds for all x, z ∈ S and all λ ∈ (0, 1). Moreover, Ψα(·, y) (again as a function of
x alone) is strongly convex on a set S ⊆ Rn for any given y if there is a modulus
µ > 0 (possibly depending on the particular vector y) such that the inequality
Ψα
(
λx + (1 − λ)z, y
)
≤ λΨα(x, y) + (1 − λ)Ψα(z, y) − µλ(1 − λ)‖x − z‖
2
holds for all x, z ∈ S and all λ ∈ (0, 1). If the constant µ > 0 can be chosen
independently of y ∈ S , then we call Ψα(·, y) uniformly strongly convex on S .
Using this terminology, we have the following result.
Proposition 3.1.1 The following statements hold:
(a) If Ψα(·, y) is convex for every y ∈ X, then Vα is also convex on X.
(b) If Ψα(·, y) is uniformly strongly convex on X, then Vα is strongly convex on
X.
Proof. (a) Exploiting the convexity of Ψα(·, y) for any given y, we obtain for
every x, z ∈ X and all λ ∈ (0, 1)
Vα
(
λx + (1 − λ)z
)
= Ψα
(
λx + (1 − λ)z, yα(λx + (1 − λ)z)
)
≤ λΨα
(
x, yα(λx + (1 − λ)z)
)
+ (1 − λ)Ψα
(
z, yα(λx + (1 − λ)z)
)
≤ λΨα
(
x, yα(x)
)
+ (1 − λ)Ψα
(
z, yα(z)
)
= λVα(x) + (1 − λ)Vα(z),
where the first inequality takes into account that the vector yα(λx+(1−λ)z) belongs
to X, whereas the second inequality exploits the definitions of yα(x) and yα(z).
(b) Let µ > 0 be the uniform modulus of strong convexity of the mapping Ψα(·, y)
on the set X. Then, similar to the proof of part (a), we obtain for all x, z ∈ X and
all λ ∈ (0, 1) that
Vα
(
λx + (1 − λ)z
)
= Ψα
(
λx + (1 − λ)z, yα(λx + (1 − λ)z)
)
≤ λΨα
(
x, yα(λx + (1 − λ)z)
)
30 CHAPTER 3. DESCENT METHODS
+(1 − λ)Ψα
(
z, yα(λx + (1 − λ)z))
)
− µλ(1 − λ)‖x − z‖2
≤ λΨα
(
x, yα(x)
)
+ (1 − λ)Ψα
(
z, yα(z)
)
− µλ(1 − λ)‖x − z‖2
= λVα(x) + (1 − λ)Vα(z) − µλ(1 − λ)‖x − z‖
2.
Hence Vα is strongly convex on X with modulus µ > 0. 
In order to guarantee the (strong) convexity of Vα, we have to verify the assump-
tions from Proposition 3.1.1, namely the (uniform strong) convexity of the map-
ping Ψα(·, y) for all y ∈ X. In general, this requirement is not satisfied under
standard convexity assumptions for our cost functions θν. However, for the case
of quadratic cost functions, we have the following sufficient condition.
Proposition 3.1.2 Consider the case where the cost functions are quadratic, say
θν(x) :=
1
2
(xν)T Aννx
ν +
N∑
µ=1
µ,ν
(xν)T Aνµx
µ ∀ν = 1, . . . ,N
for certain matrices Aνµ ∈ Rnν×nµ such that the diagonal blocks Aνν are (without
loss of generality) symmetric. Assume that
B :=


1
2 A11 A12 · · · A1N
A21 12 A22 · · · A2N
...
...
. . .
...
AN1 AN2 · · ·
1
2 ANN


, (3.2)
is positive definite and let λmin > 0 be the smallest eigenvalue of the symmetric
matrix B + BT . Then the following statements hold:
(a) The function Vα is convex on Rn for all α ∈ (0, λmin].
(b) The function Vα is strongly convex on Rn for all α ∈ (0, λmin).
Proof. We show that Ψα(·, y) is (uniformly strongly) convex and then apply
Proposition 3.1.1. To this end, first note that the second partial derivatives of Ψα
with respect to x are given by
∇2xν xµΨα(x, y) =



Aνµ + ATµν, if µ , ν
Aνν − αInν , if µ = ν.
∀ν, µ = 1, . . . ,N.
Hence we have ∇2xxΨα(x, y) = B + B
T − αI. Consequently, assumption (a) (or (b))
implies that the Hessian ∇2xxΨα(x, y) is positive semidefinite (or positive definite).
3.1. PROPERTIES OF THE OPTIMIZATION REFORMULATION 31
This, in turn, implies that the quadratic function Ψα(·, y) itself is convex (or uni-
formly strongly convex). The statement therefore follows from Proposition 3.1.1.

Note that the previous result also holds if the cost functions θν contain additional
linear and/or constant terms since they do not change the second-order derivative
of Ψα used in the proof of that result.
The following example shows that the bounds given in Proposition 3.1.2 are
tight.
Example 3.1.3 We consider the following Nash equilibrium problem, where play-
er 1 controls the single variable x1, player 2 controls the single variable x2, and
the corresponding optimization problems are given by
minx1
1
2 x
2
1 minx2
1
2 x
2
2
s.t. x1 ≥ 1 s.t. x2 ≥ 1.
Actually, this is a special case with two separable optimization problems. The
unique solution is x∗ = (1, 1)T , and the matrix B + BT from Proposition 3.1.2 has
the two eigenvalues λ1 = λ2 = 1, hence we have λmin = 1.
Given an arbitrary α > 0, an elementary calculation shows that the component
functions of yα are given by
[yα(x)]i =



α
1+α xi, if xi ≥
1+α
α
,
1, else.
Therefore, for all x satisfying xi < 1+αα , we locally have yα(x) ≡
(
1
1
)
. Consequently,
the Hessian of Vα is this area is given by
∇2Vα(x) =
(
(1 − α) 0
0 (1 − α)
)
,
which implies that Vα is convex in the respective area for all 0 < α ≤ 1 and
nonconvex for all α > 1. ^
The previous results guarantee that (3.1) is a convex optimization problem, in par-
ticular, every stationary point is therefore a global minimum and hence a normal-
ized Nash equilibrium of the GNEP (provided there is at least one such solution of
the GNEP). Next we introduce an assumption which does not necessarily guaran-
tee convexity of the value function Vα, but still implies (among other things) that
a stationary point is a global minimum of (3.1).
32 CHAPTER 3. DESCENT METHODS
Assumption 3.1.4
(a) The cost functions θν are continuously differentiable.
(b) For given x ∈ X with x , yα(x), the inequality
N∑
ν=1
[
∇θν(x
ν, x−ν) − ∇θν(y
ν
α(x), x
−ν)
]T (x − yα(x)
)
> 0
holds.
Note that the smoothness assumption from Assumption 3.1.4 (a) is necessary,
in particular, to formulate part (b). This Assumption 3.1.4 (b) is crucial for the
development and analysis of the following descent method. On the one hand,
it can be shown that any stationary point of the optimization problem (3.1) is a
solution of the GNEP provided that Assumption 3.1.4 holds, see below. On the
other hand, it implies that the search direction used in the relaxation method from
the next section is a (feasible) descent direction for the value function Vα, see
Lemma 3.2.2 below.
We postpone a discussion of Assumption 3.1.4 to the end of this section. The
following result first shows that Assumption 3.1.4 provides a sufficient condition
for a stationary point to be a global minimum and, therefore, to be a normalized
Nash equilibrium.
Theorem 3.1.5 Let x∗ ∈ X be a stationary point of (2.11) in the sense that
∇Vα(x
∗)T (x − x∗) ≥ 0 ∀x ∈ X. (3.3)
If Assumption 3.1.4 holds at x = x∗, then x∗ is a normalized Nash equilibrium of
the GNEP.
Proof. Using (3.3) and the representation of the gradient ∇Vα(x∗) from Theorem
2.2.5, we obtain
0 ≤ ∇Vα(x
∗)T (x − x∗)
=
N∑
ν=1
[
∇θν(x
∗,ν, x∗,−ν) − ∇θν(y
ν
α(x
∗), x∗,−ν)
]T (x − x∗)
+
N∑
ν=1
∇xνθν(y
ν
α(x
∗), x∗,−ν)T (xν − x∗,ν) − α
(
x∗ − yα(x
∗)
)T (x − x∗)
=
N∑
ν=1
[
∇θν(x
∗,ν, x∗,−ν) − ∇θν(y
ν
α(x
∗), x∗,−ν)
]T (x − x∗)
3.1. PROPERTIES OF THE OPTIMIZATION REFORMULATION 33
+
N∑
ν=1
[
∇xνθν(y
ν
α(x
∗), x∗,−ν) − α
(
x∗,ν − yνα(x
∗)
)]T (xν − x∗,ν
)
for all x ∈ X. Choosing x = yα(x∗), we therefore get
0 ≤
∑N
ν=1
[
∇θν(x∗,ν, x∗,−ν) − ∇θν(yνα(x
∗), x∗,−ν)
]T (yα(x∗) − x∗
)
+
∑N
ν=1
[
∇xνθν(yνα(x
∗), x∗,−ν) − α(x∗,ν − yνα(x
∗))
]T (yνα(x
∗) − x∗,ν
)
.
(3.4)
Now recall that yα(x∗) is the unique solution of the optimization problem
max
N∑
ν=1
[
θν(x
∗,ν, x∗,−ν) − θν(y
ν, x∗,−ν) −
α
2
‖x∗,ν − yν‖2
]
s.t. y ∈ X.
Consequently, yα(x∗) satisfies the corresponding optimality conditions


∇x1θ1(y1α(x
∗), x∗,−1) − α(x∗,1 − y1α(x
∗))
...
∇xNθN(yNα (x
∗), x∗,−N) − α(x∗,N − yNα (x
∗))


T
(
z − yα(x
∗)
)
≥ 0 ∀z ∈ X.
Using z = x∗, we therefore obtain
N∑
ν=1
[
∇xνθν(y
ν
α(x
∗), x∗,−ν) − α(x∗,ν − yνα(x
∗))
]T (x∗,ν − yνα(x
∗)
)
≥ 0.
Taking this into account, we get
0 ≤
N∑
ν=1
[
∇θν(x
∗,ν, x∗,−ν) − ∇θν(y
ν
α(x
∗), x∗,−ν)
]T (yα(x
∗) − x∗
)
(3.5)
from (3.4). Now assume that x∗ , yα(x∗). Then (3.5) and Assumption 3.1.4 to-
gether imply 0 < 0. This contradiction shows that x∗ = yα(x∗). Hence x∗ is a
normalized Nash equilibrium of the GNEP because of Theorem 2.2.3 c). 
The rest of this section is devoted to a discussion of Assumption 3.1.4 (b).
While it looks somewhat strange in the beginning, we will show that it is satisfied
under some conditions which are much easier to verify. Further note that these
conditions guarantee that Assumption 3.1.4 holds for an arbitrary α > 0. The
main criterion is given in the following result.
Theorem 3.1.6 Let x∗ be a normalized Nash equilibrium and assume that the cost
functions θν are twice continuously differentiable. Suppose that the matrix A =
(Aνµ)Nν,µ=1 with Aνµ = ∇
2
xνxµθν(x
∗) is positive definite. Then there is a neighbourhood
N(x∗) such that Assumption 3.1.4 holds for all x ∈ N(x∗).
34 CHAPTER 3. DESCENT METHODS
Proof. Given any x, we simplify the notation and write y and yν instead of yα(x)
and yνα(x), respectively. From the intregral mean value theorem it follows that
∇θν(y
ν, x−ν) − ∇θν(x
ν, x−ν) =
(
∫ 1
0
∇2xxνθν
(
xν + τ(yν − xν), x−ν
)
dτ
)
(yν − xν).
Hence we get
N∑
ν=1
[
∇θν(x
ν, x−ν) − ∇θν(y
ν, x−ν)
]
=
N∑
ν=1
[(
∫ 1
0
∇2xxνθν
(
xν + τ(yν − xν), x−ν
)
dτ
)
(xν − yν)
]
(3.6)
=
(
∫ 1
0
∇2xx1θ1
(
x1 + τ(y1 − x1), x−1
)
dτ, . . . ,
∫ 1
0
∇2xxN θN
(
xN + τ(yN − xN), x−N
)
dτ
)
(x − y)
=
(
∫ 1
0
[
∇2xx1θ1
(
x1 + τ(y1 − x1), x−1
)
, . . . ,∇2xxN θN
(
xN + τ(yN − xN), x−N
)]
dτ
)
(x − y)
=
∫ 1
0
[
∇2xx1θ1
(
x1 + τ(y1 − x1), x−1
)
, . . . ,∇2xxN θN
(
xN + τ(yN − xN), x−N
)](
x − y
)
dτ.
Since the functions θν are twice continuously differentiable, and since x∗ is a fix
point of yα(·) in view of Theorem 2.2.3 c), the assumption that A is positive definite
implies that there exists a neighbourhood N(x∗) such that the slightly perturbed
matrix
(
∇2xx1θ1
(
x1 + τ(y1α(x) − x
1), x−1
)
, . . . ,∇2xxNθN
(
xN + τ(yNα (x) − x
N), x−N
))
is positive definite for all x ∈ N(x∗) and τ ∈ [0, 1]. Together with (3.6) this implies
that Assumption 3.1.4 holds for all x ∈ N(x∗) with x , yα(x). 
The following two corollaries are consequences of Theorem 3.1.6 and provide
some simplified sufficient conditions for Assumption 3.1.4 to be satisfied.
Corollary 3.1.7 Consider the case where the cost functions θν are quadratic, say
θν(x) =
1
2
(xν)T Aννx
ν +
N∑
µ=1
µ,ν
(xν)T Aνµx
µ
for ν = 1, . . . ,N. Suppose that the matrix A = (Aνµ)Nν,µ=1 is positive definite. Then
Assumption 3.1.4 is satisfied at an arbitrary point x ∈ X with x , yα(x).
3.1. PROPERTIES OF THE OPTIMIZATION REFORMULATION 35
Proof. The statement follows immediately from Theorem 3.1.6 by noting that
the second-order partial derivatives of our quadratic functions θν are given by
∇2xνxµθν(x) = Aνµ for all x ∈ R
n. 
Note that the assumption of the matrix A = (Aνµ) being positive definite is weaker
than the corresponding condition on the matrix B defined in (3.2). In fact, B being
positive definite implies that the diagonal block matrix D := 12diag
(
A11, . . . , ANN
)
is also positive definite, which, in turn, gives the positive definiteness of A since
this matrix is simply the sum of B and D.
Corollary 3.1.8 Suppose that the cost functions θν are twice continuously differ-
entiable and that the matrix B(x, y) =
(
Bµν(x, y)
)N
µ,ν=1 with
Bµν(x, y) = ∇
2
xµxνθν(y
ν, x−ν) (3.7)
is positive definite for all x, y ∈ X or equivalently, that the matrices
B(x, y) = −∇2xyΨα(x, y) − ∇
2
yyΨα(x, y) (3.8)
are positive definite for all x, y ∈ X. Then Assumption 3.1.4 holds for all x ∈ X
with x , yα(x).
Proof. By taking a look at the proof of Theorem 3.1.6, we immediately see that
the assumed positive definiteness of the matrices B(x, y) with the block compo-
nents given by (3.7) implies that Assumption 3.1.4 holds.
Hence we only have to show that the mapping B has the alternative represen-
tation given in (3.8). This, however, follows directly from the expression of the
second-order derivatives ∇2xyΨα(x, y) and ∇
2
yyΨα(x, y), see, e.g., [47]. 
The following example shows that the condition given in (3.7) is not sufficient for
the convexity of the function Vα. In particular, it follows that Assumption 3.1.4
guarantees that stationary points are global minima for a class of nonconvex prob-
lems.
Example 3.1.9 Consider a two-person game where each player controls a single
variable, and where the corresponding optimization problems are given by
minx1
1
2 x
2
1 +
3
4 x1x2 minx2
1
2 x
2
2 +
3
4 x1x2
s.t. x1 ≥ 1 s.t. x2 ≥ 1.
The unique Nash equilibrium is x∗ = (1, 1)T . Elementary calculations show that,
for all x ∈ X := [1,∞) × [1,∞) sufficiently close to x∗, we have yα(x) ≡
(
1
1
)
and,
36 CHAPTER 3. DESCENT METHODS
therefore,
∇2Vα(x) =
(
1 − α 32
3
2 1 − α
)
.
Obviously, there is no α > 0 such that this matrix is positive semidefinite. In
particular, the function Vα is not convex on X. Nevertheless, the matrix B(x, y)
from (3.7) is equal to
B(x, y) =
(
1 34
3
4 1
)
and therefore positive definite for all α ∈ (0,∞) and all x, y ∈ X, which implies
that Assumption 3.1.4 holds for all x ∈ X. ^
In the remainder of this section we consider the unconstrained optimization refor-
mulation from chapter 2.3 again. We know that (2.14) is a smooth unconstrained
optimization reformulation of the GNEP. Thus, if we want to develop a numerical
method based on this reformulation, we need to compute the global minimum of
Vαβ. However, standard optimization software is usually only able to find a sta-
tionary point, therefore we next want to give a result saying that such a stationary
point is already a normalized Nash equilibrium under certain conditions. To this
end, we first state the following preliminary result.
Lemma 3.1.10 The inequality
N∑
ν=1
[
∇xνθν(y
ν
α(x), x
−ν)−∇xνθν(y
ν
β(x), x
−ν)−α(xν−yνα(x))+β(x
ν−yνβ(x))
]T (yνβ(x)−y
ν
α(x)
)
≥ 0
holds for any x ∈ Rn.
Proof. As noted in the proof of Theorem 3.1.5, yνα(x) satisfies the optimality
condition
N∑
ν=1
[
∇xνθν(y
ν
α(x), x
−ν) − α(xν − yνα(x))
]T (zν − yνα(x)
)
≥ 0 ∀z ∈ X.
In a similar way, it follows that yν
β
(x) satisfies
N∑
ν=1
[
∇xνθν(y
ν
β(x), x
−ν) − β(xν − yνβ(x))
]T (zν − yνβ(x)
)
≥ 0 ∀z ∈ X.
Using z = yβ(x) in the first inequality and z = yα(x) in the second inequality, we
get
N∑
ν=1
[
∇xνθν(y
ν
α(x), x
−ν) − α(xν − yνα(x))
]T (yνβ(x) − y
ν
α(x)
)
≥ 0
3.1. PROPERTIES OF THE OPTIMIZATION REFORMULATION 37
and
N∑
ν=1
[
∇xνθν(y
ν
β(x), x
−ν) − β(xν − yνβ(x))
]T (yνα(x) − y
ν
β(x)
)
≥ 0,
respectively. Adding these two inequalities gives the desired result. 
In order to state a result that a stationary point is, automatically, a global minimum
of Vαβ, we need a certain condition which is quite similar to the one stated in
Assumption 3.1.4.
Assumption 3.1.11 For given x ∈ Rn with yα(x) , yβ(x), the inequality
N∑
ν=1
[
∇θν(y
ν
β(x), x
−ν) − ∇θν(y
ν
α(x), x
−ν)
]T (yβ(x) − yα(x)
)
> 0
holds.
Using Assumption 3.1.11, we are now able to state the following result.
Theorem 3.1.12 Let x∗ be a stationary point of Vαβ. If Assumption 3.1.11 holds
at x = x∗, then x∗ is a normalized Nash equilibrium of the GNEP.
Proof. Since x∗ is a stationary point of Vαβ, we obtain from Theorem 2.3.3
0 = ∇Vαβ(x
∗)
=
N∑
ν=1
[
∇θν(y
ν
β(x
∗), x∗,−ν) − ∇θν(y
ν
α(x
∗), x∗,−ν)
]
+


∇x1θ1(y1α(x
∗), x∗,−1) − ∇x1θ1(y1β(x
∗), x∗,−1)
...
∇xNθN(yNα (x
∗), x∗,−N) − ∇xNθN(yNβ (x
∗), x∗,−N)


(3.9)
−α
(
x∗ − yα(x
∗)
)
+ β
(
x∗ − yβ(x
∗)
)
.
Multiplication with
(
yβ(x∗) − yα(x∗)
)T and using Lemma 3.1.10, we therefore get
0 =
N∑
ν=1
[
∇θν(y
ν
β(x
∗), x∗,−ν) − ∇θν(y
ν
α(x
∗), x∗,−ν)
]T (yβ(x
∗) − yα(x
∗)
)
+
N∑
ν=1
[
∇xνθν(y
ν
α(x
∗), x∗,−ν) − ∇xνθν(y
ν
β(x
∗), x∗,−ν)
−α(x∗,ν − yνα(x
∗)) + β(x∗,ν − yνβ(x
∗))
]T (yνβ(x
∗) − yνα(x
∗)
)
38 CHAPTER 3. DESCENT METHODS
≥
N∑
ν=1
[
∇θν(y
ν
β(x
∗), x∗,−ν) − ∇θν(y
ν
α(x
∗), x∗,−ν)
]
(yβ(x
∗) − yα(x
∗)).
Assume that yβ(x∗) − yα(x∗) , 0. Then the previous chain of inequalities together
with Assumption 3.1.11 gives the contradiction 0 > 0. Hence yα(x∗) = yβ(x∗).
But then (3.9) simplifies to (β − α)(x∗ − yα(x∗)) = 0. Since α < β, this implies
x∗ = yα(x∗). Consequently, x∗ is a normalized Nash equilibrium in view of Propo-
sition 2.2.4. 
3.2 A Relaxation Method with Inexact Line Search
The so-called relaxation method is a fixed point iteration based on the result 2.2.4
and computes normalized Nash equilibria. While basically none of the existing
solvers for GNEPs has been tested extensively on a large variety of problems, the
relaxation method seems to be the only one that has been applied at least by a small
group of different people to a few problems coming from different applications,
see [12, 15, 46, 59, 61]. However, the conditions that guarantee convergence of
the relaxation method in [98, 61] are very restrictive. Moreover, the rather general
inexact stepsize rule given in [98] leads to more or less heuristic implementations
of the relaxation method, whereas the exact stepsize rule from [61] is not really
implementable, see the comments below for more details.
Here we present a new convergence theory for the relaxation method that al-
lows weaker assumptions and that uses a clear, Armijo-type rule for the choice of
an inexact stepsize that turns out to provide rather good numerical results.
The relaxation methods presented in [98, 61] as well as the one to be discussed
in the following find a normalized Nash equilibrium and, therefore, a particular
solution of a given GNEP. The relaxation method itself uses the iteration
xk+1 := xk + tkd
k, dk := yα(x
k) − xk, k = 0, 1, 2, . . . (3.10)
for the particular value α = 0 of the parameter α. Since this does not guarantee
existence and uniqueness of the maximizer yα(x) in (2.9), the authors of [98] have
to add some assumptions which are not necessary in our case, and convergence of
the method is guaranteed, if the stepsize tk ∈ (0, 1] satisfies the conditions
tk ↓ 0 and
∞∑
k=0
tk = ∞.
These conditions suggest a choice of the form tk = γ/k for some constant γ >
0, however, in practice this choice leads to very slow convergence, so different
3.2. A RELAXATION METHOD WITH INEXACT LINE SEARCH 39
heuristics are typically implemented in order to improve the numerical behaviour
of the relaxation method, see, e.g., [61, 46]. The version of the relaxation method
presented in [61] chooses the stepsize tk by an exact minimization of the one-
dimensional mapping
ϕk(t) := Vα(x
k + tdk)
over the interval [0, 1]. This method was shown to have the same global conver-
gence property as the original relaxation method under the same set of assump-
tions as in [98], however, since Vα is typically a highly nonlinear function, the
computation of tk by minimizing ϕk is usually not possible. Moreover, its com-
putation is very expensive since each function evaluation of ϕk corresponds to the
solution of a constrained optimization problem in order to evaluate the mapping
Vα at the intermediate point xk + tdk.
Note that the iteration (3.10) of the standard relaxation method (with α =
0) can also be applied to the case α > 0 considered in this paper, and that the
convergence results presented in [98, 61] for each of the above two stepsize rules
also hold in this situation under the assumptions stated there. Here, however, we
present a completely different convergence analysis motivated by standard descent
methods from optimization that uses an inexact Armijo-type line search in order
to calculate a suitable stepsize tk at each iteration k.
Throughout this section we suppose that Assumption 3.1.4 holds at every point
x ∈ X or at least at every iterate xk ∈ X that is generated by the following algo-
rithm.
Algorithm 3.2.1 (Relaxation method with inexact line search)
(S.0) Choose x0 ∈ X, β, σ ∈ (0, 1), and set k := 0.
(S.1) Check a suitable termination criterion (for instance Vα(xk) ≤ ε for some ε >
0, or ‖yα(xk) − xk‖ < ε).
(S.2) Compute yα(xk) and set dk := yα(xk) − xk.
(S.3) Compute tk = max {βl | l = 0, 1, 2, . . .} such that
Vα(x
k + tkd
k) ≤ Vα(x
k) − σt2k‖d
k‖. (3.11)
(S.4) Set xk+1 := xk + tkdk, k←− k + 1, and go to (S.1).
Recall that we assume continuous differentiability of all cost functions θν, cf. As-
sumption 3.1.4. This assumption is crucial for the subsequent convergence analy-
sis presented in this section. Nevertheless, we would like to point out that, at least
in principle, Algorithm 3.2.1 is a derivative-free method. In practice, the situation
40 CHAPTER 3. DESCENT METHODS
is somewhat different since we have to be able to compute the function values of
Vα which corresponds to the solution of a constrained optimization problem, and
this is typically done by suitable methods that exploit the differentiability of the
cost functions θν. While this section is therefore devoted to a convergence analysis
using derivatives, we present a completely derivative-free analysis in the next sec-
tion which, however, is based on a convexity-type assumption which is stronger
than the central Assumption 3.1.4 used within this section.
Our first aim is to show that Algorithm 3.2.1 is well-defined. To this end, we
note that dk is always a direction of descent for the merit function Vα.
Lemma 3.2.2 Let xk ∈ X be the current iterate and dk be the vector computed
in Step (S.2) of Algorithm 3.2.1. Then ∇Vα(xk)T dk < 0, i.e. dk is a direction of
descent at xk (as long as xk is not a normalized Nash equilibrium of the GNEP).
Proof. For simplicity of notation, we write yα instead of yα(x) and omit the
iteration index k. Recall from Theorem 2.2.5 that ∇Vα(x) = ∇xΨα(x, y)
∣
∣
∣
y=yα(x)
.
Calculating the partial derivative of Ψα with respect to x (cf. [46]), we then obtain
∇Vα(x)
T d =
(
N∑
ν=1
[
∇θν(x
ν, x−ν) − ∇θν(y
ν
α, x
−ν)
]
+ . . .


∇x1θ1(y1α, x
−1)
...
∇xNθN(yNα , x
−N)


− α(x − yα)
)T
(yα − x)
=
(
N∑
ν=1
[
∇θν(x
ν, x−ν) − ∇θν(y
ν
α, x
−ν)
])T
(yα − x)
+
(


∇x1θ1(y1α, x
−1)
...
∇xNθN(yNα , x
−N)


− α(x − yα)
)T
(yα − x).
The first term of this equality is negative by Assumption 3.1.4, while the sec-
ond term is nonpositive due to the first order optimality condition for yα(x) :=
arg maxy∈X Ψα(x, y). Altogether, we conclude that ∇Vα(x)T d < 0, hence d is a de-
scent direction. 
Note that Assumption 3.1.4 was crucial in proving the descent property. Based
on the previous result, we are now in the position to show that Algorithm 3.2.1 is
well–defined.
Lemma 3.2.3 Algorithm 3.2.1 is well–defined and generates a sequence {xk} be-
longing to the feasible set X.
3.2. A RELAXATION METHOD WITH INEXACT LINE SEARCH 41
Proof. The fact that {xk} belongs to X follows by induction: We have x0 ∈ X by
our choice of the starting point. Moreover, if xk ∈ X, we also have
xk+1 = xk + tkd
k = (1 − tk)x
k + tkyα(x
k) ∈ X
since xk, yα(xk) ∈ X, tk ∈ (0, 1] and X is convex by assumption. In order to show
that Algorithm 3.2.1 is well–defined, we only need to verify that the inner loop in
(S.3) is finite at each iteration k. To this end, let the iteration number k be fixed,
and assume that the calculation of tk is an infinite loop. Then we have
Vα(x
k + βldk) > Vα(x
k) − σβ2l‖dk‖ ∀ l ∈ N
or, equivalently,
Vα(xk + βldk) − Vα(xk)
βl
> −σβl‖dk‖ ∀ l ∈ N.
Taking the limit l −→ +∞ and using the fact that Vα is continuously differen-
tiable, we obtain ∇Vα(xk)T dk ≥ 0. On the other hand, we know from Lemma
3.2.2 that ∇Vα(xk)T dk < 0 since xk is not a solution of our GNEP
(
otherwise the
algorithm would have stopped in (S.1)
)
. This contradiction completes the proof. 
We next give a global convergence result for Algorithm 3.2.1.
Theorem 3.2.4 Every accumulation point of a sequence generated by Algorithm
3.2.1 is a normalized Nash equilibrium of our GNEP.
Proof. Let x∗ be such an accumulation point, and let {xk}K be a corresponding
subsequence converging to x∗. The continuity of the solution operator x 7−→ yα(x)
then implies {yα(xk)}K −→ yα(x∗). Hence we have {dk}K −→ yα(x∗) − x∗ =: d∗. In
view of Proposition 2.2.4, we only need to show that d∗ = 0.
Assume we have d∗ , 0. Since the entire sequence {Vα(xk)} is monotonically
decreasing (by construction) and bounded from below
(
e.g., by Vα(x∗)
)
, it fol-
lows that the entire sequence {Vα(xk)} converges. From our line search rule, we
therefore get
0←− Vα(x
k+1) − Vα(x
k) ≤ −σt2k‖d
k‖ ≤ 0 ∀ k ∈ N.
This implies
lim
k−→∞
t2k‖d
k‖ = 0.
Since d∗ , 0 by assumption, we therefore have
lim
k∈K
tk = 0. (3.12)
42 CHAPTER 3. DESCENT METHODS
Let lk ∈ N be the unique exponent such that tk = βlk in (S.3) of Algorithm 3.2.1.
In view of (3.12), we can assume without loss of generality that tk < 1 for all
k ∈ K, hence the stepsize tk
β
= βlk−1 does not satisfy the inequality from (S.3) of
Algorithm 3.2.1. Hence we have
Vα(x
k + βlk−1dk) > Vα(x
k) − σ(βlk−1)2‖dk‖ ∀ k ∈ K.
This can be written as
Vα(xk + βlk−1dk) − Vα(xk)
βlk−1
> −σβlk−1‖dk‖ ∀ k ∈ K.
Taking the limit k −→ ∞ on K, using the fact that βlk−1 −→ 0 and exploiting
the continuous differentiability of Vα, we therefore obtain from the mean value
theorem that
∇Vα(x
∗)T d∗ ≥ 0.
On the other hand, since d∗ = yα(x∗) − x∗ , 0, it follows from Lemma 3.2.2 that
∇Vα(x∗)T d∗ < 0. This contradiction shows that d∗ = 0 and, therefore, x∗ is indeed
a normalized Nash equilibrium of our GNEP. 
The previous convergence result also holds for a minor modification of Algo-
rithm 3.2.1. This observation is formally stated in the following remark.
Remark 3.2.5 It is not difficult to see that all our previous results remain true if
we replace the line search rule (3.11) in Algorithm 3.2.1 by the slightly modified
condition
Vα(x
k + tkd
k) ≤ Vα(x
k) − σt2k‖d
k‖2
where the only difference to the original condition (3.11) is that we now take the
square of ‖dk‖ rather than ‖dk‖ itself.
We close this section with a simple example discussing the rate of convergence
of Algorithm 3.2.1. It turns out that one should not expect local quadratic con-
vergence of the iteration xk+1 = yα(xk), even under very favourable assumptions.
This is illustrated by the following simple example.
Example 3.2.6 Consider the GNEP (which is actually an unconstrained NEP)
with two players, where each player controls only a single variable and where the
corresponding optimization problems are given by
minx1
1
2 x
2
1 minx2
1
2 x
2
2
s.t. (x1, x2) ∈ R2 s.t. (x1, x2) ∈ R2.
3.3. A NONSMOOTH DESCENT METHOD 43
The solution of this GNEP is obviously the origin x∗ = (0, 0)T . Given any x ∈ R2,
an easy calculation shows that the maximizer yα(x) of the corresponding optimiza-
tion problem (2.8) is given by
yα(x) =
α
1 + α
x.
Consequently, for the stepsize tk = 1 in our relaxation method, we obtain
xk+1 = xk + tkd
k = yα(x
k) =
α
1 + α
xk.
Clearly, this shows that the rate of convergence is neither superlinear nor quadratic
although the example is very simple and has very nice properties. On the other
hand, it shows that we have a fast linear rate of convergence for small α > 0. ^
3.3 A Nonsmooth Descent Method
In this section, we consider Algorithm 3.2.1 once again. To this end, recall that
the method does not use any derivative information. The previous analysis, how-
ever, assumes differentiability of all functions θν. Here we present a completely
derivative-free analysis using the following slightly stronger assumption that we
assume to hold throughout this section.
Assumption 3.3.1 The function Ψα(·, y) is convex for every y taken from an open
convex neighbourhood of the set X.
In view of Proposition 3.1.1 and its proof, a direct consequence of Assumption
3.3.1 is the convexity of the mapping Vα on the open convex neighbourhood of
X. In particular, the function Vα is therefore both directionally differentiable and
locally Lipschitzian on this set. These observations will be exploited in our sub-
sequent analysis.
We begin our analysis with the following counterpart of Lemma 3.2.2.
Lemma 3.3.2 Let x ∈ X be any given point, and let d := yα(x) − x. Then there is
a constant t̄ > 0 (depending on x) such that Vα(x + td) < Vα(x) for all t ∈ (0, t̄]
(provided that x is not a normalized Nash equilibrium of the GNEP).
Proof. For arbitrary t ∈ (0, 1), the convexity of Ψα(·, y) implies
Vα(x + td) = Ψα
(
x + td, yα(x + td)
)
= Ψα
(
x + t(yα(x) − x), yα(x + td)
)
= Ψα
(
tyα(x) + (1 − t)x, yα(x + td)
)
44 CHAPTER 3. DESCENT METHODS
≤ tΨα
(
yα(x), yα(x + td)
)
+ (1 − t)Ψα
(
x, yα(x + td)
)
(3.13)
≤ tΨα
(
yα(x), yα(x + td)
)
+ (1 − t)Ψα
(
x, yα(x)
)
= tΨα
(
yα(x), yα(x + td)
)
+ (1 − t)Vα(x)
= t
[
Ψα
(
yα(x), yα(x + td)
)
− Vα(x)
]
+ Vα(x)
or, equivalently,
Vα(x + td) − Vα(x)
t
≤ Ψα
(
yα(x), yα(x + td)
)
− Vα(x). (3.14)
Since the function yα is continuous by Theorem 2.2.3 c), we have yα(x + td) →
yα(x) for t → 0 and, therefore, Ψα
(
yα(x), yα(x + td)
)
→ Ψα
(
yα(x), yα(x)
)
= 0.
Hence it follows from (3.14) that there is an ε = ε(x) > 0 (e.g., ε := 12Vα(x)) and
a t̄ = t̄(x) > 0 such that
Vα(x + td) − Vα(x)
t
≤ −ε ∀t ∈ (0, t̄]. (3.15)
This completes the proof. 
We next show that Algorithm 3.3.1 is well-defined under Assumption 3.3.1.
Lemma 3.3.3 Algorithm 3.2.1 is well–defined and generates a sequence {xk} be-
longing to the feasible set X.
Proof. Similar to the proof of Lemma 3.2.3, we only have to show that the
stepsize selection in (S.3) is a finite procedure at each iteration k. To this end, we
fix the iteration counter k and assume that the calculation of tk is an infinite loop.
Then
Vα(xk + βldk) − Vα(xk)
βl
> −σβl‖dk‖ ∀ l ∈ N.
Taking the limit l −→ +∞ and using the fact that Vα is convex and, therefore,
directionally differentiable at the current iterate xk ∈ X, we get
V ′α(x
k; dk) ≥ 0. (3.16)
On the other hand, we immediately obtain from (3.15) that V ′α(x
k; dk) ≤ −ε for
some sufficiently small ε = ε(xk) > 0, a contradiction to (3.16). 
We now come to the main global convergence result of Algorithm 3.2.1 under
Assumption 3.3.1.
3.3. A NONSMOOTH DESCENT METHOD 45
Theorem 3.3.4 Every accumulation point of a sequence generated by Algorithm
3.2.1 is a normalized Nash equilibrium of our GNEP.
Proof. We try to copy the proof of Theorem 3.2.4. Basically, this is possible
since Vα is a convex function, hence we can exploit suitable properties of the
convex subdifferential, see, e.g., [50, 90] for more details.
Let x∗ be an accumulation point, and let {xk}K be a corresponding subsequence
converging to x∗. The continuity of the solution operator x 7−→ yα(x) (cf. Theorem
2.2.3 c)) then implies {yα(xk)}K −→ yα(x∗). Hence we have {dk}K −→ yα(x∗)−x∗ =:
d∗. In view of Theorem 2.2.4, we only need to show that d∗ = 0.
Assume that d∗ , 0. Similar to the proof of Theorem 3.2.4, we know that the
entire sequence {Vα(xk)} converges and, since d∗ , 0, that limk∈K tk = 0. Let us
write tk = βlk for some exponent lk ∈ N. Then the line search rule is not satisfied
for βlk−1 for all k ∈ K (sufficiently large), giving
Vα(xk + βlk−1dk) − Vα(xk)
βlk−1
> −σβlk−1‖dk‖ ∀ k ∈ K. (3.17)
Taking the limit k −→ ∞ on K, the right-hand side converges to zero. In order
to get the limit of the left-hand side, we first note that the mean value theorem
for convex functions shows that, for each k ∈ K, there is a vector ξk on the line
segment between xk and xk + βlk−1dk and an element gk ∈ ∂Vα(ξk) such that
Vα(x
k + βlk−1dk) − Vα(x
k) = βlk−1(gk)T dk.
Hence the left-hand side of (3.17) simply becomes
Vα(xk + βlk−1dk) − Vα(xk)
βlk−1
= (gk)T dk
Now, on the subset K ⊆ N, we have xk → x∗, βlk−1 → 0, and dk → d∗ = yα(x∗)−x∗.
This implies xk + βlk−1dk → x∗ and, therefore, also ξk → x∗. Since the mapping
x 7→ ∂Vα(x) is locally bounded, the sequence {gk}K is bounded. Without loss of
generality, we can therefore assume that the entire subsequence {gk}K converges to
some vector g∗. Taking into account that the mapping x 7→ ∂Vα(x) is also closed,
it follows that g∗ ∈ ∂Vα(x∗). Exploiting the fact that the directional derivative is
the support function of the convex subdifferential, we obtain from (3.17) that
Vα(xk + βlk−1dk) − Vα(xk)
βlk−1
= (gk)T dk → (g∗)T d∗ ≤ max
g∈∂Vα(x∗)
gT d∗ = V ′α(x
∗; d∗).
In view of (3.17), we have (g∗)T d∗ ≥ 0, in particular, it therefore follows that
V ′α(x
∗; d∗) ≥ 0. On the other hand, since d∗ , 0, it follows from (3.15) that
46 CHAPTER 3. DESCENT METHODS
V ′α(x
∗; d∗) < 0. This contradiction shows that d∗ = 0 and therefore completes the
proof. 
Chapter 4
Newton’s Method based on an
Optimization Reformulation
In chapter 2 we introduced optimization reformulations of the generalized Nash
equilibrium problem. Two of these reformulations have a differentiable objective
function, namely the constrained optimization reformulation (2.11) and the un-
constrained optimization reformulation (2.14). However, the objective functions
of the latter optimization reformulations are, in general, not twice differentiable.
Here we investigate some further properties of these reformulations and, in partic-
ular, show that they are sufficiently smooth so that locally superlinearly convergent
Newton-type methods can be applied in order to solve the underlying GNEP.
As in the preceding chapters, let θν, ν = 1, . . . ,N be the cost function and X
the joint strategy set. In particular, throughout this chapter, we assume that the set
X is represented by inequalities, that is,
X = {x ∈ Rn | g(x) ≤ 0} (4.1)
with some function g : Rn → Rm. Additional equality constraints are also allowed,
but for notational simplicity, we prefer not to include them explicitly. In many
cases, a player ν might have some additional constraints of the form hν(xν) ≤ 0
depending on his decision variables only. However, these additional constraints
may simply be viewed as part of the joint constraints g(x) ≤ 0, with some of the
component functions gi of g depending on the block component xν of x only.
Stronger than Assumptions 1.2.2, we impose the following conditions through-
out this chapter.
Assumption 4.0.5
(a) The cost functions θν, ν = 1, . . . ,N are twice continuously differentiable,
and convex with respect to the variable xν, i.e., the function θν(·, x−ν) is
convex, uniformly for all x−ν;
47
48 CHAPTER 4. NEWTON’S METHOD TYPE I
(b) The function g is twice continuously differentiable, its components gi are
convex (in x), and the corresponding strategy space X defined by (4.1) is
nonempty.
The smoothness assumptions are natural since our aim is to develop locally fast
convergent methods for the solution of GNEPs. Note that Assumption 4.0.5 (b)
implies that the strategy space X is nonempty, closed, and convex.
In the first section, we recall some basic facts and recent results from nons-
mooth analysis. Then, in the next section, we show that the optimization refor-
mulations from chapter 2 are S C1 reformulations of the GNEP, i.e., the objective
function is continuously differentiable with semismooth gradient. In the last sec-
tion we consider a Newton-type method based on the unconstrained optimization
reformulation of the GNEP.
4.1 Semismooth Functions
In this section, we first recall some basic definitions and results from nonsmooth
analysis in this section, and then state some preliminary results that will be used
in our subsequent analysis. To this end, let F : Rn → Rm be a locally Lipschitzian
mapping. According to Rademacher’s theorem (see [86]), it follows that F is
almost everywhere differentiable. Let DF denote the set of all differentiable points
of F. Then we call
∂BF(x) :=
{
H ∈ Rm×n
∣
∣
∣∃{xk} ⊆ DF : x
k → x, F′(xk)→ H
}
the B-subdifferential of F at x. Its convex hull
∂F(x) := conv∂BF(x)
is Clarke’s generalized Jacobian of F at x, see [14]. In case of m = 1, we call this
set also the generalized gradient of F at x which, therefore, is a set of row vectors.
Furthermore, we call the set
∂CF(x) :=
(
∂F1(x)
T × . . . × ∂Fm(x)
T )T
the C-subdifferential of F at x, i.e., the C-subdifferential is the set of matrices
whose ith rows consist of the elements of the generalized gradient of the ith com-
ponent functions Fi. According to [14, Proposition 2.6.2], the following inclu-
sions hold:
∂BF(x) ⊆ ∂F(x) ⊆ ∂CF(x). (4.2)
Based on the generalized Jacobian, we next recall the definition of a semismooth
function.
4.1. SEMISMOOTH FUNCTIONS 49
Definition 4.1.1 Let F : Rn → Rm be locally Lipschitz continuous. Then F is
called semismooth at x if F is directionally differentiable at x and
‖Hd − F′(x; d)‖ = o(‖d‖)
holds for all d → 0 and all H ∈ ∂F(x + d).
In the following, we often call a mapping F : Rn → Rm semismooth if it is
semismooth at every point x ∈ Rn. The notion of a semismooth function was
originally introduced by Mifflin [68] for functionals, and later extended by Qi and
Sun [85] to vector-valued mappings.
Note that there are many different notions of semismooth functions available
in the literature, and we would like to give some comments here. First of all, our
definition of a semismooth function is not the original one from [85], however,
it follows from [85, Theorem 2.3] that it is equivalent to the original definition
(note that the assumption of directional differentiability is missing in that result).
Another very popular reformulation of the semismoothness of a locally Lipschitz
and directionally differentiable function is that it satisfies
‖F(x + d) − F(x) − Hd‖ = o(‖d‖) (4.3)
for all d → 0 and all H ∈ ∂F(x + d). Sun [95] calls this the superlinear ap-
proximation property of F at x since it is central in order to prove local super-
linear convergence of certain Newton-type methods, see also the general scheme
in Kummer [62, 63]. The equivalence of this superlinear approximation property
to our definition of semismoothness can be found, e.g., in [28, Theorem 7.4.3]
and is based on the fact that a locally Lipschitz and directionally differentiable
function is automatically B-differentiable, see [94] for details. On the other hand,
property (4.3) can be defined also for mappings that are not necessarily direction-
ally differentiable. In fact, Gowda [40] takes this property of a locally Lipschitz
function as the definition of semismoothness. In order to avoid confusion with
the existing definition of semismoothness, Pang et al. [83] suggested the name
G-semismoothness (with the ’G’ referring to Gowda).
We stress that the previous discussion on semismoothness is somewhat crucial
for our later analysis since we want to apply a suitable implicit function theorem
for semismooth functions. However, there are different implicit function theorems
available in the literature, and they are based on different notions of a semismooth
(or related) function, see, [95, 40] and, in particular, the corresponding discussion
in [83].
We next state a simple result that will play an important role in later sections,
in particular, the equivalence between statements (a) and (d).
50 CHAPTER 4. NEWTON’S METHOD TYPE I
Lemma 4.1.2 Let F : Rn → Rm be locally Lipschitz continuous and directionally
differentiable, and let x ∈ Rn be an arbitrary point. Then the following statements
are equivalent:
(a) F is semismooth at x, i.e., ‖Hd − F′(x; d)‖ = o(‖d‖) for all d → 0 and all
H ∈ ∂F(x + d).
(b) ‖Hd − F′(x; d)‖ = o(‖d‖) for all d → 0 and all H ∈ ∂BF(x + d).
(c) ‖Hd − F′(x; d)‖ = o(‖d‖) for all d → 0 and all H ∈ ∂CF(x + d).
(d) Fi is semismooth for all components i = 1, . . . ,m, i.e., ‖hid − F′i (x; d)‖ =
o(‖d‖) for all d → 0, all hi ∈ ∂Fi(x + d), and all i = 1, . . . ,m.
Proof. The implications (c) =⇒ (a) =⇒ (b) follow directly from the fact that
∂BF(x + d) ⊆ ∂F(x + d) ⊆ ∂CF(x + d), cf. (4.2).
The implication (b) =⇒ (a) is a consequence of Carathéodory’s theorem. To
see this, let dk → 0 and Hk ∈ ∂F(x + dk) be given arbitrarily. Then, for all k ∈ N,
we can find at most r := nm + 1 matrices Hkj ∈ ∂BF(x + d
k) and numbers λkj ≥ 0
satisfying
r∑
j=1
λkj = 1 and H
k =
r∑
j=1
λkjH
k
j .
Using (b), we therefore obtain
‖Hkdk − F′(x; dk)‖ =
∥
∥
∥
r∑
j=1
λkjH
k
j d
k − F′(x; dk)
∥
∥
∥
≤
r∑
j=1
λkj‖H
k
j d
k − F′(x; dk)‖ = o(‖dk‖)
in view of the boundedness of λkj.
The implication (a) =⇒ (d) can be verified in the following way: Using the
chain rule from [14, Theorem 2.6.6], the composite mapping f := g ◦ F with the
continuously differentiable function g(z) := zi has the generalized gradient
∂Fi(x) = ∂ f (x) = ∂g
(
F(x)
)
∂F(x) = eTi ∂F(x)
= {hi | hi is the ith row of some H ∈ ∂F(x)}.
Therefore, if we assume that (a) holds, and if we take an arbitrary d ∈ Rn as well
as any component i ∈ {1, . . . ,m}, it follows that for any hi ∈ ∂Fi(x + d), we can
choose an element H ∈ ∂F(x + d) such that its ith row is equal to hi. Then we get
∣
∣
∣F′i (x; d) − hid
∣
∣
∣ =
∣
∣
∣eTi (F
′(x; d) − Hd)
∣
∣
∣ ≤ ‖F′(x; d) − Hd‖ = o(‖d‖),
4.1. SEMISMOOTH FUNCTIONS 51
hence Fi is semismooth at x.
Finally, (d) =⇒ (c) is an immediate consequence of the definition of the C-
subdifferential.
Altogether, we have shown that (c) =⇒ (a) =⇒ (d) =⇒ (c) and (a) ⇐⇒ (b),
implying that all four statements are indeed equivalent. 
Some parts of the previous result are known, for example, [85, Corollay 2.4]
shows that the semismoothness of all component functions implies the semis-
moothness of F itself. The fact that the converse also holds seems to be around
in the community, but we were not able to find an explicit reference. Further-
more, [40, page 447] already observed the equivalence of statements (a) and (b)
in Lemma 4.1.2, albeit in the slightly different context of G-semismoothness.
We next want to state an implicit function theorem for semismooth mappings
that will be used in order to show local fast convergence of our Newton-type
method for generalized Nash equilibrium problems. To this end, consider a map-
ping H : Rm × Rn → Rn, (x, y) 7→ H(x, y). Then πy∂H(x, y) denotes the set of all
n×n matrices M such that, for some n×m matrix N, the n× (m+n) matrix [N, M]
belongs to ∂H(x, y). The set πx∂H(x, y) is defined in a similar way.
Theorem 4.1.3 Suppose that H : Rm × Rn → Rn is locally Lipschitz and semis-
mooth in a neighbourhood of a point (x̄, ȳ) satisfying H(x̄, ȳ) = 0, and assume that
all matrices in πy∂H(x̄, ȳ) are nonsingular. Then there exists an open neighbor-
hood X of x̄ and a function g : X → Rn which is Lipschitz and semismooth on X
such that g(x̄) = ȳ and H(x, g(x)) = 0 for all x ∈ X.
Proof. Since this particular implicit function theorem does not seem to be avail-
able in the literature, we derive it from a suitable inverse function theorem. To this
end, consider the mapping F : Rm × Rn → Rm × Rn defined by
F(x, y) :=
(
x − x̄
H(x, y)
)
.
Then
∂F(x̄, ȳ) ⊆
(
Im 0
πx∂H(x̄, ȳ) πy∂H(x̄, ȳ)
)
,
and our assumptions imply that all elements from the generalized Jacobian ∂F(x̄, ȳ)
are nonsingular. Noting that a continuously differentiable function is always semis-
mooth and recalling that the mapping H is semismooth by assumption, it follows
from Lemma 4.1.2 that F is also semismooth. Hence we can apply the inverse
function theorem from [83, Theorem 6] and obtain open neighbourhoods U of
(x̄, ȳ) and W of (0, 0) = F(x̄, ȳ) such that F : U → W is a homeomorphism and
52 CHAPTER 4. NEWTON’S METHOD TYPE I
has a locally Lipschitz and semismooth inverse G : W → U. Since W is open, the
set
X := {x ∈ Rm | (x − x̄, 0) ∈ W}
is also open as a subset of Rm. We now show that there is a locally Lipschitz and
semismooth function g : X → Rn such that g(x̄) = ȳ and H(x, g(x)) = 0 for all
x ∈ X.
To this end, let x ∈ X be arbitrarily given. Then (x− x̄, 0) ∈ W, and because F :
U → W is a homeomorphism, the definition of the mapping F implies that there
is a unique vector y such that (x, y) ∈ U and F(x, y) = (x− x̄, 0). Consequently, we
have H(x, y) = 0. Note that this unique vector y depends on x. Setting g(x) := y
then gives us a mapping g : X → Rn such that H(x, g(x)) = 0 for each x ∈ X. This
implies
F(x, g(x)) =
(
x − x̄
H(x, g(x))
)
=
(
x − x̄
0
)
∀x ∈ X.
Applying the inverse mapping G on both sides gives
(
x
g(x)
)
= G(x − x̄, 0) ∀x ∈ X.
This shows that g coincides with certain component functions of G. Since the
inverse function G is semismooth, it therefore follows from Lemma 4.1.2 that g is
also semismooth. This completes the proof of our implicit function theorem. 
A related implicit function theorem was stated in Sun [95]. However, he only
assumes that H has the local superlinear approximation property, and states that
the implicit function has the superlinear approximation property, too. A similar
result was also stated by Gowda [40] in the framework of H-differentiable func-
tions. Note also that the assumption on the nonsingularity of all elements from
πy∂H(x̄, ȳ) (corresponding to the strongest possible condition in the inverse func-
tion theorem from [83]) can be weakened, but that this (relatively strong) condi-
tion will be satisfied in our context.
We close this section with the definition of an S C1-function that will become
important in the next section.
Definition 4.1.4 A mapping f : Rn → R is called an S C1-function if it is contin-
uously differentiable and its gradient ∇ f is semismooth.
4.2. S C1-OPTIMIZATION REFORMULATIONS 53
4.2 S C1-Optimization Reformulations
Consider the GNEP with cost functions θν, ν = 1, . . . ,N, and a joint strategy set X
satisfying the requirements from Assumptions 4.0.5. Our aim is to show that the
GNEP can then be reformulated as both constrained and unconstrained S C1 op-
timization problems. This S C1-reformulation is based on the smooth constrained
and unconstrained optimization reformulations of chapter 2.
We briefly restate the essential statements from chapter 2. In equation 2.8, for
γ > 0 (γ instead of α) we defined the function
Vγ(x) = Ψγ(x, yγ(x)), (4.4)
with
yγ(x) = arg max
y∈X
Ψγ(x, y), (4.5)
where Ψγ is the regularized Nikaido-Isoda function,
Ψγ(x, y) =
N∑
ν=1
[
θν(x
ν, x−ν) − θν(y
ν, x−ν) −
γ
2
‖xν − yν‖2
]
. (4.6)
Theorem 2.2.3 shows that x∗ is a normalized Nash equilibrium if and only if x∗
solves the optimization problem
min
x
Vγ(x) subject to x ∈ X.
Furthermore, Theorem 2.2.5 implies that the function Vγ is continuously differen-
tiable with gradient
∇Vγ(x) = ∇xΨγ(x, y)
∣
∣
∣
y=yγ(x)
. (4.7)
Unfortunately, Vγ is, in general, not twice continuously differentiable. However,
in view of Assumption 4.0.5, we see that the regularized Nikaido-Isoda-function
Ψγ(x, y) is twice continuously differentiable. Using the fact that the composition
of semismooth functions is again semismooth, see [33], it therefore follows imme-
diately from the representation (4.7) of the gradient∇Vγ that Vγ is an S C1-function
if the mapping x 7→ yγ(x) is semismooth. Our aim in this section is therefore to
prove the semismoothness of this mapping.
To this end, we first consider a more general parameterized optimization prob-
lem of the form
min
y
f (x, y) s.t. y ∈ X (4.8)
where f : Rn ×Rn → R is twice continuously differentiable and uniformly convex
with respect to the variable y (for every fixed x). The feasible set X is given by a
54 CHAPTER 4. NEWTON’S METHOD TYPE I
number of inequalities as in (4.1) such that Assumption 4.0.5 (b) holds. Then the
Lagrangian of the optimization problem (4.8) is given by
L(x, y, λ) = f (x, y) +
m∑
i=1
λigi(y),
where, again, x ∈ Rn is supposed to be fixed. Let y = y(x) be the unique solution
of the optimization problem (4.8). Then, under a suitable constraint qualification,
like the Slater condition, it follows that there exists a Lagrange multiplier λ =
λ(x) ∈ Rm such that (y, λ) together with the fixed x solves the KKT system
∇yL(x, y, λ) = ∇y f (x, y) + ∇g(y)λ = 0, 0 ≤ λ ⊥ − g(y) ≥ 0. (4.9)
Using the minimum function ϕ : R × R → R, ϕ(a, b) := min{a, b}, we can refor-
mulate the KKT system (4.9) as a system of nonlinear equationsΦ(x, y, λ) = 0 via
the function
Φ(x, y, λ) :=
(
∇yL(x, y, λ)
φ
(
− g(y), λ
)
)
(4.10)
with
φ
(
− g(y), λ
)
:=
(
ϕ(−g1(y), λ1), . . . , ϕ(−gm(y), λm)
)T
∈ Rm.
Our first result gives a representation of the B-subdifferential and the generalized
Jacobian of the mapping Φ.
Lemma 4.2.1 Suppose that f and g are C2-functions. Let w = (x, y, λ) ∈ Rn+n+m.
Then, each element H ∈ ∂Φ(w)T can be represented as follows:
H =


∇2yxL(x, y, λ)
T 0
∇2yyL(x, y, λ) −∇g(y)Da(y, λ)
∇g(y)T Db(y, λ)


where Da(y, λ) := diag(a1(y, λ), . . . , am(y, λ)), Db(y, λ) = diag(b1(y, λ), . . . , bm(y, λ)) ∈
R
m×m are diagonal matrices whose ith diagonal elements are given by
ai(y, λ) =



1, if − gi(y) < λi,
0, if − gi(y) > λi,
µi, if − gi(y) = λi,
and bi(y, λ) =



0, if − gi(y) < λi,
1, if − gi(y) > λi,
1 − µi, if − gi(y) = λi,
for any µi ∈ [0, 1]. The elements H ∈ ∂BΦ(w)T are obtained by choosing µi ∈
{0, 1}.
Proof. The first n components of the vector function Φ are continuously differ-
entiable and Φ is continuously differentiable with respect to x, so the expression
4.2. S C1-OPTIMIZATION REFORMULATIONS 55
for the first n rows and columns of H readily follows. To compute the remaining
entries of H, we use the fact that each element of the generalized Jacobian of φ
can be represented by an element of the C-subdifferential of φ, that is
∂φ(−g(y), λ)T ⊆ ∂ϕ(−g1(y), λ1)
T × · · · × ∂ϕ(−gm(y), λm)
T .
If i is such that −gi(y) , λi, then ϕ is continuously differentiable at (−gi(y), λi) and
the expression for the (n + i)th column of H follows. If instead −gi(y) = λi, then,
using the definition of the B-subdifferential, it follows that
∂Bϕ(−gi(y), λi)
T =
{
(−∇gi(y)
T , 0), (0, eTi )
}
.
Taking the convex hull, we therefore get
∂ϕ(−gi(y), λi)
T = {(−µi∇gi(y)
T , (1 − µi)e
T
i ) | µi ∈ [0, 1]}.
(Note that this representation cannot be obtained by directly applying [14, Theo-
rem 2.3.9 (iii)] since the min-function is not regular in the sense of [14, Definition
2.3.4].) This gives the representation of H ∈ ∂Φ(w)T . 
Our next aim is to establish conditions for the nonsingularity of all elements in
π(y,λ)∂Φ(w)T at a point w = (x, y, λ) satisfying Φ(w) = 0. By definition, taking
the continuous differentiability of Φ with respect to x into account, the elements
V ∈ π(y,λ)∂Φ(w)T can be obtained by deleting the first n rows of the matrices H
from Lemma 4.2.1. In order to get a more detailed description of the matrices
V ∈ π(y,λ)∂Φ(w)T , let us partition the index set {1, . . . ,m} into
I0 := {i | gi(y) = 0} and I< := {i | gi(y) < 0},
where both the set of active constraints I0 and the set of inactive constraints I<
depend on the current vector y. The set of active constraints can be further divided
into
I00 := {i ∈ I0 | λi = 0} and I+ := {i ∈ I0 | λi > 0},
with both sets depending on y and λ. The set I00 will further be partitioned into
I01 := {i ∈ I00 | µi = 1}, I02 := {i ∈ I00 | µi ∈ (0, 1)}, I03 := {i ∈ I00 | µi = 0}.
Note that these index sets also depend (via µi) on the particular element taken
from the generalized Jacobian of Φ(w).
With these index sets, and using a suitable reordering of the constraints, every
element V ∈ π(y,λ)∂Φ(x, y, λ)T has the following structure (the dependence on w =
56 CHAPTER 4. NEWTON’S METHOD TYPE I
(x, y, λ) is suppressed for simplicity):
V =


∇2yyL −∇g+ −∇g01 −∇g02(Da)02 0 0
∇gT+ 0 0 0 0 0
∇gT01 0 0 0 0 0
∇gT02 0 0 (Db)02 0 0
∇gT03 0 0 0 I 0
∇gT< 0 0 0 0 I


, (4.11)
where (Da)02 and (Db)02 are positive definite diagonal matrices, and where we
used the abbreviations ∇g+,∇g01 etc. for the matrices ∇gI+,∇gI01 etc.
In order to obtain a suitable nonsingularity result, let us introduce the matrices
M(J) :=


∇2yyL −∇g+ −∇gJ
∇gT+ 0 0
∇gTJ 0 0


,
where J is any subset of I00. Using these matrices, we next define the concept
of strong regularity for the parameterized optimization problem (4.8). This name
comes from the fact that our condition corresponds to Robinson’s strong regularity
assumption (see [89]) in the context of ordinary nonlinear programs, cf. [65, 30].
Definition 4.2.2 A triple w∗ = (x∗, y∗, λ∗) satisfying Φ(w∗) = 0 is called strongly
regular for the optimization problem (4.8) if the matrices M(J) have the same
nonzero orientation for all J ⊆ I00.
According to Robinson [89], strong regularity holds if the strong second order
sufficiency condition and the linear independence constraint qualification (LICQ
for short) hold, where LICQ means that the gradients ∇gi(x∗) (i : gi(x∗) = 0) of
the active inequality constraints are linearly independent (note that LICQ is also
a necessary condition for strong regularity). In particular, it therefore follows that
all matrices M(J) have the same nonzero orientation if ∇2yyL is positive definite and
LICQ holds. This is the situation we are particularly interested in. In fact, in this
case, there is an easy way to see that strong regularity holds at w∗ = (x∗, y∗, λ∗).
To this end, write
M(J) =
(
H −AJ
ATJ 0
)
with H := ∇2yyL and AJ :=
(
∇g+,∇gJ
)
.
Using block Gaussian elimination, it follows that
M(J) =
(
I 0
ATJ H
−1 I
) (
H −AJ
0 ATJ H
−1AJ
)
.
4.2. S C1-OPTIMIZATION REFORMULATIONS 57
Consequently, we get
det
(
M(J)
)
= det
(
H −AJ
0 ATJ H
−1AJ
)
= det(H) det
(
ATJ H
−1AJ
)
> 0 ∀J ⊆ I00
since H is positive definite and AJ has full column rank for all J ⊆ I00.
We next state our main result on the nonsingularity of the elements of the
projected generalized Jacobian π(y,λ)∂Φ(x∗, y∗, λ∗). Its proof is similar to one given
in [30] which, however, uses a different reformulation of the KKT system arising
from variational inequalities.
Theorem 4.2.3 Consider the optimization problem (4.8) with f : Rn × Rn → R
and g : Rn → Rm being twice continuously differentiable. Let w∗ = (x∗, y∗, λ∗) ∈
R
n+n+m be a solution of the systemΦ(w) = 0, and suppose that the strong regularity
condition holds at w∗. Then all elements V ∈ π(y,λ)∂Φ(w∗) are nonsingular.
Proof. Consider an arbitrary but fixed element in π(y,λ)∂Φ(w∗)T . This element
has the structure indicated in (4.11) and is obviously nonsingular if and only if the
following matrix is nonsingular:
V =


∇2yyL −∇g+ −∇g01 −∇g02
∇gT+ 0 0 0
∇gT01 0 0 0
∇gT02 0 0 (Db)02(Da)
−1
02


. (4.12)
The matrix (4.12) can be written as the sum of the matrix M(J), with J = I01∪ I02,
and the diagonal matrix
D :=


0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 (Db)02(Da)−102


.
Given a square matrix Ā of dimension r and a diagonal matrix D̄ of the same
dimension, it follows from [16, p. 60] that
det(D̄ + Ā) =
∑
α
detD̄ααdetĀᾱᾱ, (4.13)
where the summation ranges over all subsets α of {1, . . . , r} (with complements
ᾱ = {1, . . . , r}\α), and where it is assumed that the determinant of an “empty”
matrix is equal to 1. Exploiting this formula, the determinant of (4.12) can be
written as
detM(J) +
∑
∅,α⊆I02
detDααdetM(J)ᾱᾱ, (4.14)
58 CHAPTER 4. NEWTON’S METHOD TYPE I
where the first term corresponds to α = ∅. Moreover, we have taken into account
that if α contains an element which does not belong to I02, then the determinant of
Dαα is 0. Since the nonzero diagonal elements of the matrix D are all positive, it
follows that the determinants of Dαα in (4.14) are all positive. Then to show that
the determinant of (4.12) is nonzero and hence to conclude the proof, it will now
be sufficient to show that the determinants of M(J) and of all M(J)ᾱᾱ in (4.14)
never have opposite signs, and that at least one of them is nonzero. But this is a
direct consequence of Definition 4.2.2. 
Now we are able to apply Theorem 4.1.3 to the optimization problem (4.8).
Corollary 4.2.4 Let the assumptions of Theorem 4.2.3 be satisfied. Then there
exists a neighbourhood U of x∗ and a semismooth function G : U → Rn+m, x 7→
(
y(x), λ(x)
)
such that Φ(x,G(x)) = 0 holds for all x ∈ U. In particular, the map-
ping x 7→ y(x) is semismooth.
Proof. The existence and semismoothness of the implicit function x 7→ G(x) =
(
y(x), λ(x)
)
is an immediate consequence of Theorems 4.1.3 and 4.2.3. Using
Lemma 4.1.2, this, in particular, implies the local semismoothness of the mapping
x 7→ y(x). 
We now get back to our GNEP and the mapping Vγ defined in (4.4). The following
is the main result of this section.
Theorem 4.2.5 Let x∗ ∈ X and assume that LICQ holds at yγ(x∗). Then Vγ is an
S C1-function in a neighbourhood of yγ(x∗).
Proof. In view of the introductory remarks of this section, we have to show that
the mapping x 7→ yγ(x) is semismooth in a neighbourhood of x∗. By definition,
yγ(x) is the solution of the optimization problem
max
y
Ψγ(x, y) s.t. y ∈ X := {y ∈ R
n | g(y) ≤ 0}, (4.15)
cf. (4.5). This is an optimization problem of the form (4.8) with f (x, y) :=
−Ψγ(x, y). Here, the mapping f is uniformly convex with respect to y due to the
regularization term in the definition of the regularized Nikaido-Isoda-function and
the assumed convexity of the mappings θν with respect to the variables xν. Corol-
lary 4.2.4 therefore gives the semismoothness of the mapping x 7→ yγ(x) provided
that the strong regularity assumption holds at
(
x∗, yγ(x∗), λγ(x∗)
)
, where yγ(x∗) de-
notes the solution of problem (4.15) with x = x∗ and λγ(x∗) is the corresponding
unique (due to LICQ) multiplier.
4.3. NEWTON’S METHOD 59
Since LICQ holds at yγ(x∗), it suffices to show that the Hessian (with respect
to y) of the corresponding Lagrangian
Lγ(x, y, λ) = −Ψγ(x, y) +
m∑
i=1
λigi(y)
is positive definite at (x, y, λ) =
(
x∗, yγ(x∗), λγ(x∗)
)
, see the comments after Def-
inition 4.2.2. However, we already observed that −Ψγ(x, y) is uniformly convex
with respect to y, hence its Hessian is (uniformly) positive definite. Furthermore,
∇2gi(yγ(x∗)) is positive semidefinite due to the assumed convexity of the functions
gi. Hence the assertion follows from the fact that λ = λγ(x∗) is nonnegative (as a
multiplier corresponding to an inequality constraint). 
Note that, if, in addition to the assumptions of Theorem 4.2.5, strict complemen-
tarity holds at yγ(x∗), then yγ is continuously differentiable and Vγ is a C2-function
in a neighbourhood of x∗. This follows directly from the previous derivation by
using the standard implicit function theorem in place of Theorem 4.1.3.
Furthermore, we would like to point out that the assertion of Theorem 4.2.5
holds at all x ∈ Rn such that LICQ is satisfied at yγ(x).
4.3 Newton’s method
In view of Theorem 4.2.5, both the constrained optimization reformulation (2.11)
and the unconstrained reformulation (2.14) of the GNEP are S C1 optimization
problems. Hence it is reasonable to believe that locally superlinearly convergent
Newton-type methods can be derived for the solution of GNEPs via the solution of
these optimization problems. Here we focus on the unconstrained reformulation
(2.14) and show that one can indeed expect local fast convergence of a nonsmooth
Newton-type method under suitable assumptions.
The nonsmooth Newton-type method from [85, 84] for the minimization of
the unconstrained function Vαβ from (2.12) is an iterative procedure of the form
xk+1 := xk + dk, k = 0, 1, 2, . . . , (4.16)
where x0 ∈ Rn is a starting point and dk is a solution of the linear system
Hkd = −∇Vαβ(x
k) for some Hk ∈ ∂
2Vαβ(x
k), (4.17)
where ∂2Vαβ(xk) denotes the generalized Hessian of Vαβ at xk in the sense of [51],
i.e., ∂2Vαβ(xk) is the generalized Jacobian in the sense of Clarke [14] of the locally
Lipschitz mapping F := ∇Vαβ.
60 CHAPTER 4. NEWTON’S METHOD TYPE I
In order to compute the gradient and (generalized) Hessian matrix of the map-
ping Vαβ, we need several (partial) derivatives of the mapping Ψγ from (4.6).
These derivatives are summarized in the following result whose proof is omitted
since it follows from standard calculus rules.
Lemma 4.3.1 The mapping Ψγ from (4.6) is twice continuously differentiable
with (partial) derivatives
∇xΨγ(x, y) =
N∑
ν=1
[
∇θν(x
ν, x−ν) − ∇θν(y
ν, x−ν)
]
+


∇x1θ1(y1, x−1)
...
∇xNθN(yN , x−N)


− γ(x − y),
∇yΨγ(x, y) = −


∇x1θ1(y1, x−1)
...
∇xNθN(yN , x−N)


+ γ(x − y),
∇2xxΨγ(x, y) =
N∑
ν=1
[
∇2θν(x
ν, x−ν) − ∇2θν(y
ν, x−ν)
]
+


∇2
x1 x1
θ1(y1, x−1) · · · ∇2x1 xNθN(y
N , x−N)
...
. . .
...
∇2
xN x1
θ1(y1, x−1) · · · ∇2xN xNθN(y
N , x−N)


+


∇2
x1 x1
θ1(y1, x−1) · · · ∇2x1 xNθ1(y
1, x−1)
...
. . .
...
∇2
xN x1
θN(yN , x−N) · · · ∇2xN xNθN(y
N , x−N)


−diag


∇2
x1 x1
θ1(y1, x−1)
. . .
∇2
xN xN
θN(yN , x−N)


− γI,
∇2xyΨγ(x, y) = −


∇2
x1 x1
θ1(y1, x−1) · · · ∇2x1 xNθN(y
N , x−N)
...
. . .
...
∇2
xN x1
θ1(y1, x−1) · · · ∇2xN xNθN(y
N , x−N)


+diag


∇2
x1 x1
θ1(y1, x−1)
. . .
∇2
xN xN
θN(yN , x−N)


+ γI,
∇2yxΨγ(x, y) = ∇
2
xyΨγ(x, y)
T
= −


∇2
x1 x1
θ1(y1, x−1) · · · ∇2x1 xNθ1(y
1, x−1)
...
. . .
...
∇2
xN x1
θN(yN , x−N) · · · ∇2xN xNθN(y
N , x−N)


4.3. NEWTON’S METHOD 61
+diag


∇2
x1 x1
θ1(y1, x−1)
. . .
∇2
xN xN
θN(yN , x−N)


+ γI,
∇2yyΨγ(x, y) = −diag


∇2
x1 x1
θ1(y1, x−1)
. . .
∇2
xN xN
θN(yN , x−N)


− γI.
We next consider the problem of how to implement the nonsmooth Newton-
type method. To this end, we have to compute, at each iterate xk, an element
Hk ∈ ∂2Vαβ(xk). Since this is not an easy task, we first assume that Vα and Vβ
are both twice continuously differentiable at xk, hence Vαβ is twice continuously
differentiable at x := xk with Hessian
∇2Vαβ(x) = ∇
2Vα(x) − ∇
2Vβ(x). (4.18)
Hence we need to calculate the Hessians ∇2Vγ(x) for γ ∈ {α, β}. Therefore, let
γ ∈ {α, β} be fixed and recall that Vγ is given by (4.4) with gradient ∇Vγ(x) =
∇xΨγ
(
x, yγ(x)
)
, cf. (4.7), where yγ(x) denotes the solution of the optimization
problem (4.5). Using the chain rule, we therefore get
∇2Vγ(x) = ∇
2
xxΨγ
(
x, yγ(x)
)
+ ∇2xyΨγ
(
x, yγ(x)
)
Dyγ(x), (4.19)
where Dyγ(x) ∈ Rn×n denotes the usual Jacobian (with respect to x) of the mapping
yγ. Expressions for the matrices ∇2xxΨγ
(
x, yγ(x)
)
and ∇2xyΨγ
(
x, yγ(x)
)
are given in
Lemma 4.3.1. At a nondifferentiable point, we have the following result.
Lemma 4.3.2 The following inclusion holds at an arbitrary point x ∈ Rn:
∇2xxΨγ(x, yγ(x)) + ∇
2
xyΨγ(x, yγ(x))∂Byγ(x) ⊆ ∂
2
BVγ(x),
where ∂2BVγ denotes the Bouligand subdifferential of the function ∇Vγ.
Proof. Let x ∈ Rn be arbitrarily given, and let Y ∈ ∂Byγ(x). Then there is a
sequence {ξk} → x such that yγ is differentiable at each ξk and Dyγ(ξk) → Y for
k →∞. Then the representation (4.7) of ∇Vγ shows that Vγ is twice differentiable
at each ξk, and we therefore obtain, taking the continuity of yγ and the twice
continuous differentiability of Ψγ into account:
∇2Vγ(ξ
k) = ∇2xxΨγ(ξ
k, yγ(ξ
k)) + ∇2xyΨγ(ξ
k, yγ(ξ
k))Dyγ(ξ
k)
→ ∇2xxΨγ(x, yγ(x)) + ∇
2
xyΨγ(x, y(x))Y.
This shows that the right-hand side belongs to ∂2BVγ(x). 
62 CHAPTER 4. NEWTON’S METHOD TYPE I
Hence we need to consider the computation of ∂Byγ(x). By definition, yγ(x) is the
unique solution of the optimization problem
min
y
−Ψγ(x, y) s.t. y ∈ X :=
{
y ∈ Rn | g(y) ≤ 0
}
.
Assume that LICQ holds at yγ(x), and let
Lγ(x, y, λ) := −Ψγ(x, y) +
m∑
i=1
λigi(y)
be the Lagrangian of this optimization problem. Since LICQ holds at yγ(x), it
follows that there exist unique multipliers λγ(x) such that the following KKT con-
ditions hold at (x, y, λ) =
(
x, yγ(x), λγ(x)
)
:
∇yLγ(x, y, λ) = 0, λ ≥ 0, g(y) ≤ 0, λ
T g(y) = 0.
Here we have
∇yLγ(x, y, λ) = −∇yΨγ(x, y) +
m∑
i=1
λi∇gi(y).
Therefore, assuming, for the moment, that strict complementarity holds, we then
obtain from the standard implicit function theorem that the implicit function G(x) :=
(
yγ(x), λγ(x)
)
satisfies (locally) the system of equations
Φγ
(
x,G(x)
)
= 0, where Φγ(x, y, λ) :=
(
∇yLγ(x, y, λ)
min{−g(y), λ}
)
. (4.20)
Differentiating this system therefore gives
0 = DxΦγ(x,G(x)) = DxΦγ(x,G(x)) + D(y,λ)Φγ(x,G(x))DxG(x),
from which we obtain DxG(x) =
(
Dxyγ(x),Dxλγ(x)
)
by solving the linear system
D(y,λ)Φγ(x,G(x))DxG(x) = −DxΦγ(x,G(x)). (4.21)
Some computational effort leads to the following formula for the Jacobian of the
function yγ at x :
∇yγ(x)
T = C−1A − C−1D(DT C−1D)−1DT C−1A, (4.22)
with
A = A(x) := ∇2yxΨγ(x, yγ(x)),
4.3. NEWTON’S METHOD 63
C = C(x) := −∇2yyΨγ(x, yγ(x)) +
m∑
i=1
λi∇
2gi(yγ(x)),
D = D(x) := ∇gI0(yγ(x)),
where I0 denotes the index set of active constraints at yγ(x). Still this formula does
not provide an element of the Bouligand subdifferential ∂Byγ(x). Yet it can be
shown, that under the linear independence constraint qualification, all elements of
∂Byγ(x) can be expressed by a formula of the type of (4.23), see Proposition 5.1.6
in the next chapter.
Even if we had an element of ∂Byγ(x), it would not be easy to calculate an
element of ∂2BVαβ(x). Knowledge of ∂Byγ(x) allows us to compute elements from
∂2BVα(x) and ∂
2
BVβ(x), respectively, as Lemma 4.3.2 shows, however, this does not
suffice, since it is very unlikely that the difference of any two elements in ∂2BVβ(x)
and ∂2BVα(x) is an element of ∂
2
BVαβ(x).
On the other hand, all examples from the literature presented in chapter 6
except Rosen’s example satisfy strict complementarity at the solution. Therefore,
applying Newton’s method to the unconstrained optimization reformulation is not
difficult to implement in these cases.
The following is the central local convergence result for our nonsmooth Newton-
type method for the solution of the GNEP.
Theorem 4.3.3 Let x∗ be a normalized Nash equilibrium of the GNEP such that
all elements V ∈ ∂2Vαβ(x∗) are nonsingular. Then the nonsmooth Newton-type
method from (4.16), (4.17) is locally superlinearly convergent to x∗.
Proof. Since Vαβ is an S C1-function in view of Theorem 4.2.5, the result follows
immediately from [85]. 
There are a number of comments that we would like to add in the following re-
mark.
Remark 4.3.4 (a) Theorem 4.3.3 remains true if we replace the assumption
that all elements of ∂2Vαβ(x∗) are nonsingular by the weaker condition that
all elements from the smaller set ∂2BVαβ(x
∗) are nonsingular. This follows
immediately from a result in [84].
(b) Theorem 4.3.3 is a local convergence result only. However, since Vαβ is
continuously differentiable, it is easy to globalize this method by either a
line search or a trust-region strategy. These globalized methods typically
find a stationary point of Vαβ only, and a sufficient condition for such a
stationary point to be a normalized Nash equilibrium of the GNEP is given
in Assumption 3.1.11.
64 CHAPTER 4. NEWTON’S METHOD TYPE I
(c) Theorem 4.3.3 gives a local superlinear rate of convergence. It is also pos-
sible to get a locally quadratically convergent method by our approach. To
this end, we have to strengthen Assumption 1.2.2 to some extend and as-
sume that, in addition, the Hessian matrices ∇2θν and ∇2gi are locally Lip-
schitz around a solution x∗ of the GNEP. Moreover, one has to use another
implicit function theorem like the one from Sun [95] in order to guarantee
a local quadratic approximation property (as defined in [95]) or to modify
Theorem 4.1.3 in a suitable way.
(d) A simple sufficient condition for the nonsingularity of all elements from
∂2Vαβ(x∗) (or ∂2BVαβ(x
∗)) exists for linear-quadratic games as defined in Pro-
position 3.1.2. Suppose that the solution x∗ from Theorem 4.3.3 is lo-
cally unique (for which there exist simple conditions in the case of linear-
quadratic games) and satisfies strict complementarity, i.e., the correspond-
ing vectors yγ(x∗) and λγ(x∗) satisfy the strict complementarity condition.
Then the standard implicit function theorem guarantees that Vαβ is twice
continuously differentiable around x∗. Therefore, the local uniqueness of
the normalized solution x∗, together with the quadratic nature of the costs
functions, implies that the Hessian ∇2Vαβ(x∗) is positive definite.
(e) The Newton method presented in this chapter is, under favourable condi-
tions, locally superlinearly or even quadratically convergent. Yet, there are
two major drawbacks of this method: First, there are some difficulties in the
calculation of elements of the generalized Jacobian of ∇Vαβ, and second, we
have to assume that the linear independence constraint qualification holds
at the solution x∗. In the next chapter we therefore present an approach that
disposes with both problems: It allows for a simple formula for the elements
of the generalized Jacobian, and it does not require LICQ, but instead the
slightly weaker constant rank constraint qualification.
Chapter 5
Newton’s Method through Fixed
Point Formulation
In the preceding chapter we presented a Newton method in order to solve the
unconstrained optimization problem
min Vαβ(x) x ∈ R
n,
where the function Vαβ (defined in (2.12)) has the property that every global min-
imum of Vαβ is a normalized Nash equilibrium. In this chapter, we also develop a
Newton method for the computation of a normalized Nash equilibrium, however,
the approach is completely different. Basically, the Newton method presented in
this chapter solves a fixed point equation, opposed to the Newton method in the
preceding chapter which solves the necessary first-order condition for an uncon-
strained optimization problem.
Throughout this chapter, we assume that the feasible set X is given by inequal-
ities,
X := {x ∈ Rn | g(x) ≤ 0}, (5.1)
with a function g : Rn → Rm. Both g and the cost functions θν, ν = 1, . . . ,N, shall
satisfy the following assumptions.
Assumption 5.0.5
(a) The cost functions θν, ν = 1, . . . ,N are twice continuously differentiable,
and convex with respect to the variable xν, i.e., the function θν(·, x−ν) is
convex, uniformly for all x−ν;
(b) The function g is twice continuously differentiable, its components gi are
convex functions (in x), and the corresponding strategy space X defined by
(5.1) is nonempty.
65
66 CHAPTER 5. NEWTON’S METHOD TYPE II
This is exactly the same assumption as Assumption (4.0.5) in the preceding chap-
ter.
For a fixed parameter α > 0 we define the function
ψα(x, y) :=
N∑
ν=1
[
θν(y
ν, x−ν) +
α
2
‖yν − xν‖2
]
(5.2)
and consider the optimization problem
min
y
ψα(x, y) s.t. y ∈ X. (5.3)
Due to the convexity assumptions on X and θν(·, x−ν), this minimization problem
has a unique solution for every x which we denote by
yα(x) := arg min
y∈X
ψα(x, y).
It is not difficult to see that the function yα is essentially the same function as
the one defined in equation (2.9). Therefore, Theorem 2.2.3 c) implies that yα is
continuous. Moreover, from Proposition 2.2.4 we have that x∗ is a normalized
Nash equilibrium if and only if x∗ is a fixed point of the mapping yα, i.e., x∗ =
yα(x∗). This puts into consideration Newton methods applied to the equation
yα(x) − x = 0 (5.4)
in order to develop an algorithm for the computation of normalized Nash equilib-
ria.
In general, the function yα is not differentiable which causes difficulties. In the
preceding chapter it was shown that yα is semismooth, if, in addition to the above
assumptions, the linear independence constraint qualification holds, see the proof
of Theorem 4.2.5. Using this result, one can define a nonsmooth Newton method
for the solution of the nonlinear equation (5.4) replacing the first derivative of yα
by generalized Jacobians. Yet, using the approach in the preceding chapter, it
is difficult to calculate an element of the generalized Jacobian and, as a conse-
quence, to show convergence of the Newton method. Therefore, we concern here
an alternative approach which yields explicit formulas for a suitable substitute of
the derivative of the function yα. Additionally, we dispose with the linear inde-
pendence constraint qualification and replace it by the somewhat weaker constant
rank constraint qualification.
5.1 The Computable Generalized Jacobian
In this section we define a kind of replacement for the Jacobian of the function
yα(·), which is related to the B-subdifferential, but easier to compute in practice.
5.1. THE COMPUTABLE GENERALIZED JACOBIAN 67
The concept is similar to the computable generalized Jacobian introduced in [96]
for the projection operator onto a closed convex set. The extension here for the
function yα(·) is actually motivated to a large extent by the ideas from [96].
By definition, yα(x) is the unique solution of the parameterized optimization
problem
minimizey ψα(x, y)
subject to gi(y) ≤ 0, i = 1, . . . ,m,
(5.5)
where ψα : Rn × Rn → R is defined by
ψα(x, y) =
N∑
ν=1
[
θν(y
ν, x−ν) +
α
2
‖yν − xν‖2
]
.
Then the KKT conditions for problem (5.5) can be written as
∇yψα(x, y) +
m∑
i=1
λi∇gi(y) = 0,
λi ≥ 0, gi(y) ≤ 0, λi · gi(y) = 0, i = 1, . . . ,m.
(5.6)
Note that ∇yψα(x, y) is given by
∇yψα(x, y) =


∇x1θ1(y1, x−1) + α(y1 − x1)
...
∇xNθN(yN , x−N) + α(yN − xN)


∈ Rn. (5.7)
Let
I0(x) := {i | gi(yα(x)) = 0} (5.8)
be the index set of active constraints at y = yα(x).
We adopt one of the main assumptions used in [96] which also appear in the
context of piecewise differentiable functions.
Assumption 5.1.1 The constant rank constraint qualification (CRCQ) holds at
yα(x), i.e., there exists a neighbourhood N(yα(x)) of yα(x) such that for every set
J ⊆ I0(x), the set of gradient vectors
{∇gi(y) | i ∈ J}
has the same rank (which depends on J) for all y ∈ N(yα(x)).
The CRCQ is weaker than the linear independence constraint qualification. More-
over, it is always fulfilled in the case of linear constraints. Furthermore, due to a
result by Janin [54], it is known that the CRCQ is a suitable constraint qualification
in the sense that the satisfaction of CRCQ at the minimizer yα(x) of problem (5.5)
68 CHAPTER 5. NEWTON’S METHOD TYPE II
guarantees the existence (not necessarily uniqueness) of corresponding Lagrange
multipliers λ such that the KKT conditions (5.6) hold. Hence the set
M(x) := { λ ∈ Rm | (yα(x), λ) satisfies (5.6) } (5.9)
is always nonempty under Assumption 5.1.1.
There is a family of index sets that will play a crucial role in our analysis. For
each x ∈ Rn, define
B(x) :=
{
J ⊆ I0(x) | ∇gi(yα(x)) (i ∈ J) are linearly independent and
supp(λ) ⊆ J for some λ ∈ M(x)
}
, (5.10)
where supp(λ) denotes the support of the nonnegative vector λ ∈ Rm, i.e.,
supp(λ) := {i ∈ {1, . . . ,m} | λi > 0}.
We first claim that the family B(x) is always nonempty.
Lemma 5.1.2 SupposeM(x) , ∅. Then B(x) , ∅.
Proof. Let us choose a multiplier λ ∈ M(x) with minimal support. If supp(λ) = ∅,
we take J := ∅ and immediately see that J ∈ B(x). Now suppose supp(λ) , ∅. We
claim that J := supp(λ) belongs to B(x). Obviously, we have supp(λ) ⊆ J ⊆ I0(x).
Hence it remains to show that ∇gi(yα(x)) (i ∈ J) are linearly independent. Suppose
this is not true. Then there is a nonzero vector βJ = (βi)i∈J such that
∑
i∈J
βi∇gi(yα(x)) = 0.
Replacing βJ by −βJ if necessary, we may assume without loss of generality that
at least one component βi (i ∈ J) is positive. Let t̃ := min{λi/βi | βi > 0}. Then we
have λi − t̃βi ≥ 0 for all i ∈ J and λi0 − t̃βi0 = 0 for at least one index i0 ∈ J. Now
define
λ̃i :=
{
λi − t̃βi, i ∈ J,
λi, i < J.
Then it follows immediately that the vector λ̃ = (λ̃1, . . . , λ̃m)T belongs to M(x).
However, by construction, the support of λ̃ is strictly contained in the support of
λ, a contradiction to our choice of λ. 
Recall thatM(x) , ∅ under Assumption 5.1.1, and hence the statement of Lemma
5.1.2 holds, in particular, in this situation.
5.1. THE COMPUTABLE GENERALIZED JACOBIAN 69
For an index set J ⊆ {1, . . . ,m} with complement Ĵ := {1, . . . ,m}\J, we now
consider the function φα(·, ·, · ; J) : Rn+n+m → Rn+m defined by
φα(x, y, λ; J) :=


∇yψα(x, y) +
∑
i∈J λi∇gi(y)
gJ(y)
λĴ


, (5.11)
where the partition (J, Ĵ) of {1, . . . ,m} is used to split the vectors λ and g(y) into
λ = (λJ , λĴ) and g(y) = (gJ(y), gĴ(y)), respectively.
Lemma 5.1.3 Let x ∈ X and suppose that Assumption 5.1.1 holds. Furthermore,
letM(x) be defined by (5.9). Then, for any J ∈ B(x), there exists a unique vector
λ ∈ M(x) such that φα(x, yα(x), λ; J) = 0.
Proof. Let J ∈ B(x) and let λ ∈ M(x) be such that supp(λ) ⊆ J. Then we
have λ = (λJ , λĴ) with λJ ≥ 0 and λĴ = 0. Since (x, yα(x), λ) satisfies the KKT
conditions (5.6), we have ∇yψα(x, yα(x))+
∑
i∈J λi∇gi(yα(x)) = 0 and gJ(yα(x)) = 0
(since J ⊆ I0(x)). Hence φα(x, yα(x), λ; J) = 0 holds. Furthermore, the gradients
∇gi(yα(x)) (i ∈ J) are linearly independent, which implies that λ is uniquely de-
termined. 
We next show that, under certain assumptions, for any fixed x and J ∈ B(x), the
system of equations φα(x, y, λ; J) = 0 has a locally unique solution (y(x; J), λ(x; J)).
Lemma 5.1.4 Let x̄ ∈ X be given, and suppose that Assumption 5.1.1 holds at
ȳ := yα(x̄). Let J ∈ B(x̄) be a fixed index set and λ̄ ∈ M(x̄) be the correspond-
ing unique multiplier from Lemma 5.1.3 such that φα(x̄, ȳ, λ̄; J) = 0. Then the
following statements hold:
(a) There exist open neighbourhoods NJ(x̄) of x̄ and NJ(ȳ, λ̄) of (ȳ, λ̄), and a C1-
diffeomorphism (y(· ; J), λ(· ; J)) : NJ(x̄) → NJ(ȳ, λ̄) such that y(x̄; J) = ȳ,
λ(x̄; J) = λ̄ and
φα(x, y(x; J), λ(x; J); J) = 0 (5.12)
holds for all x ∈ NJ(x̄).
(b) The transposed Jacobian of the function y(· ; J) is given by the formula
∇y(x; J) = ATC−1 − ATC−1D(DT C−1D)−1DTC−1, (5.13)
where
A = A(x; J) := −∇2yxψα(x, y(x; J)),
C = C(x; J) := ∇2yyψα(x, y(x; J)) +
∑
i∈J
λi(x; J)∇
2gi(y(x; J)),
D = D(x; J) := ∇gJ(y(x; J)).
70 CHAPTER 5. NEWTON’S METHOD TYPE II
Proof. (a) First note that, by Lemma 5.1.3, the pair (ȳ, λ̄) is determined uniquely
for any given x̄ and J ∈ B(x̄). The Jacobian of φα(· ; J) with respect to the variables
(y, λ) is given by (after some reordering)
∇(y,λ)φα(x, y, λ; J) =


∇2yyψα(x, y) +
∑
i∈J λi∇
2gi(y) ∇gJ(y) 0
∇gJ(y)T 0 0
0 0 I|Ĵ|


. (5.14)
We claim that this matrix is nonsingular at (x, y, λ) = (x̄, ȳ, λ̄). Statement (a) is then
an immediate consequence of the standard implicit function theorem. In fact, the
nonsingularity follows from the observation that the Jacobian ∇gJ(ȳ) has full rank
by the choice of J ∈ B(x̄) together with the observation that Assumption 5.0.5 (a)
implies the positive definiteness of the matrix ∇2yyψα(x̄, ȳ), whereas Assumption
5.0.5 (b) guarantees that the terms λ̄i∇2gi(ȳ) are at least positive semidefinite for
all i ∈ J.
(b) Differentiating equation (5.12) with respect to x and using some algebraic ma-
nipulations, it is not difficult to obtain the desired formula for the derivatives of
the function y(· ; J). The details are left to the reader. 
Our aim is to give a relation between the functions y(· ; J) as defined in Lemma
5.1.4 and the function yα(·) that is the solution map of the parameterized optimiza-
tion problem (5.5). More precisely, we will show that, under the same assumptions
as in Lemma 5.1.4, there is a neighbourhood of the point x̄ such that, for every x
in this neighbourhood, there is an index set J (depending on the point x) such that
yα(x) = y(x; J) holds. This is made precise in the next lemma.
Lemma 5.1.5 Let x̄ ∈ X be given, and suppose that Assumption 5.1.1 holds at
ȳ := yα(x̄). Then there exists a neighbourhood N(x̄) of x̄ such that for all x ∈ N(x̄),
the following statements hold:
(a) The CRCQ holds at yα(x);
(b) B(x) ⊆ B(x̄);
(c) at any given point x ∈ N(x̄), the equality yα(x) = y(x; J) holds for any index
set J ∈ B(x), where y(· ; J) is the function defined in Lemma 5.1.4.
Proof. (a) This follows from the definition of the CRCQ and the continuity of
the function yα(·), cf. Proposition 2.2.3 (c).
(b) The proof is essentially the same as the one in [79] for the projection operator.
Assume there exists no neighbourhood N(x̄) of x̄ such that B(x) ⊆ B(x̄) for all
5.1. THE COMPUTABLE GENERALIZED JACOBIAN 71
x ∈ N(x̄). Then there is a sequence {xk} converging to x̄ such that for each k, there
is an index set Jk ∈ B(xk) \ B(x̄). Since there are only finitely many such index
sets, by working with a subsequence if necessary, we may assume that these index
sets Jk are the same for all k. Let this common index set be J.
According to the definition ofB(xk), the vectors ∇gi(yα(xk)) (i ∈ J) are linearly
independent and there exists λk ∈ M(xk) such that supp(λk) ⊆ J ⊆ I0(xk), but J <
B(x̄). Due to the continuity of the functions gi and yα, it holds that I0(xk) ⊆ I0(x̄),
hence we have J ⊆ I0(x̄) for all k sufficiently large. Furthermore, the assumed
CRCQ condition guarantees that the vectors ∇gi(yα(x̄)) (i ∈ J) are also linearly
independent. Hence we have J < B(x̄) only if there is no λ ∈ M(x̄) such that
supp(λ) ⊆ J. However, the KKT conditions imply that
∇yψα(x
k, yα(x
k)) +
∑
i∈J
λki∇gi(yα(x
k)) = 0 for all k. (5.15)
Since the functions yα and ∇gi are continuous, we have ∇gi(yα(xk))→ ∇gi(yα(x̄)).
Taking into account the linear independence of {∇gi(yα(x̄))}i∈J , we see that the se-
quence {λk} is convergent, say λki → λ̌i for all i ∈ J. Taking the limit in (5.15) and
setting λ̌i = 0 for i ∈ Ĵ, we can easily verify that the vector λ̌ := (λ̌J , λ̌Ĵ) belongs
to M(x̄). Moreover, the definition of λ̌ guarantees that supp(λ̌) ⊆ J, and hence
J ∈ B(x̄). This contradicts our assumption.
(c) From (a) and (b) it follows that there is a neighbourhood N(x̄) such that for
any x ∈ N(x̄), the CRCQ holds at yα(x) and B(x) ⊆ B(x̄). Furthermore, for each
J ∈ B(x̄), let NJ(x̄) and NJ(ȳ, λ̄) be the neighbourhoods defined in Lemma 5.1.4,
where λ̄ is the vector also defined there. We then define the neighbourhood
V(x̄) :=
⋂
J∈B(x̄)
NJ(x̄) ∩ N(x̄),
which is open since there are only finitely many J’s.
For any given vector x ∈ V(x̄), the optimization problem (5.5) has a unique
solution yα(x). Moreover, Lemma 5.1.3 implies that for every fixed J ∈ B(x), there
exists a unique Lagrange multiplier λ = λJ(x) ∈ M(x) such that (x, yα(x), λJ(x))
satisfies
φα(x, yα(x), λ
J(x); J) = 0.
In particular, for the Lagrange multiplier associated with
(
x̄, ȳ
)
, we write λJ(x̄) as
λ̄J .
On the other hand, Lemma 5.1.4 implies that there is a continuously differen-
tiable function
(
y(· ; J), λ(· ; J)
)
: NJ(x̄)→ NJ(ȳ, λ̄J) such that, for every x ∈ NJ(x̄),
the pair
(
y(x; J), λ(x; J)
)
is the unique solution of
φα(x, y, λ; J) = 0 (5.16)
72 CHAPTER 5. NEWTON’S METHOD TYPE II
in the set NJ(ȳ, λ̄J). Hence, if we can show that there exists an open neighbour-
hood U(x̄) ⊆ V(x̄) such that for every x ∈ U(x̄) and every J ∈ B(x) we have
(
yα(x), λ
J(x)
)
∈ NJ(ȳ, λ̄J),
then the uniqueness implies that
(
yα(x), λ
J(x)
)
=
(
y(x; J), λ(x; J)
)
for all x ∈ U(x̄) and J ∈ B(x), and this would conclude the proof.
Suppose there exists no such open neighbourhood U(x̄) ⊆ V(x̄). Then there
exists a sequence {xk} with xk → x̄ and Jk ∈ B(xk) such that
(yα(x
k), λJk(xk)) < NJk (ȳ, λ̄Jk ) for all k. (5.17)
By working with a subsequence, we may assume that Jk is the same index set for
all k.Denote this index set by J. Furthermore, choose open neighbourhoods NJ(ȳ)
of ȳ and NJ(λ̄J) of λ̄J such that NJ(ȳ) × NJ(λ̄J) ⊆ NJ(ȳ, λ̄J).
Since the function yα is continuous, we have yα(xk) → yα(x̄) = ȳ. Hence
yα(xk) ∈ NJ(ȳ) for all k sufficiently large. On the other hand, for every xk with
associated yα(xk) and λJ(xk), we have from (5.11)
∇yψα(x
k, yα(x
k)) +
∑
i∈J
λJi (x
k)∇gi(yα(x
k)) = 0, (5.18)
λJi (x
k) = 0, i ∈ Ĵ
for all k. The continuity of the functions ∇yψα, yα and ∇gi, together with the
linear independence of the vectors ∇gi(ȳ) (i ∈ J), which is again a consequence
of the CRCQ, implies that the sequence {λJ(xk)} is convergent. Let λ̃J be the
corresponding limit point. Taking the limit in (5.18) therefore gives
∇yψα(x̄, ȳ) +
∑
i∈J
λ̃Ji ∇gi(ȳ) = 0
as well as λ̃Ji = 0 for all i ∈ Ĵ. Then the CRCQ implies that λ̃
J is the only
vector satisfying these equations. However, by definition, λ̄J also satisfies these
equations, so it follows that λ̃J = λ̄J .
Hence λJ(xk) converges to λ̄J , meaning that λJ(xk) ∈ NJ(λ̄J) for all k suffi-
ciently large. Therefore we have
(
yα(x
k), λJ(xk)
)
∈ NJ(ȳ) × NJ(λ̄J) ⊆ NJ(ȳ, λ̄J)
for all k sufficiently large, a contradiction to (5.17). 
5.1. THE COMPUTABLE GENERALIZED JACOBIAN 73
Since there are only finitely many possible index sets J ⊆ {1, . . . ,m}, it follows
from Lemma 5.1.5 that, given any point x in a sufficiently small neighbourhood
of x̄, the function yα(·) is equal to one of the finitely many functions y(· ; J) and,
therefore, piecewise smooth. However it is not necessarily easy to compute an
element of the B-subdifferential of yα at x, which is defined by
∂Byα(x) := {G ∈ R
n×n | G = lim
xk→x
∇yα(x
k)T , {xk} ⊆ Ω},
where Ω := {x ∈ Rn | yα(·) is differentiable at x}. Lemma 5.1.5 then suggests to
use, in place of the B-subdifferential, the following modification of a generalized
Jacobian, which we call the computable generalized Jacobian of yα(·) at x:
∂Cyα(x) :=
{
∇y(x; J)T | J ∈ B(x)
}
, (5.19)
where B(x) is defined by (5.10). Note that computing an element of ∂Cyα(x)
amounts to finding an index set J ∈ B(x), which is implementable in practice.
While the inclusion ∂Byα(x) ⊆ ∂Cyα(x) holds at any x, the converse is not true in
general, see [22, Example 11]. Under additional assumptions, however, it can be
shown that these two sets coincide; see, in particular, [?, Corollary 3.2.2] or [21,
Theorem 3.3].
Nevertheless, we have the following result, which indicates that there is a good
chance that the two sets actually coincide.
Proposition 5.1.6 Let x̄ ∈ Rn be fixed and let the linear independence constraint
qualification (LICQ) hold at ȳ = yα(x̄), that is, the vectors ∇gi(ȳ) (i ∈ I0(x̄))
are linearly independent. Then for all but at most n values of α, the equality
∂Byα(x̄) = ∂Cyα(x̄) holds.
Proof. The inclusion ∂Cyα(x̄) ⊆ ∂Byα(x̄) holds provided that the matrix∇2yxψα(x̄, ȳ)
is nonsingular, see [76, Corollary 3.2.2] or [21, Theorem 3.3].
Now, an elementary calculation shows that∇2yxψα(x̄, ȳ) is written as∇
2
yxψα(x̄, ȳ) =
W − αI, where the matrix W ∈ Rn×n is given by
W =


0 ∇2
x1 x2
θ1(y1, x−1) · · · ∇2x1 xNθ1(y
1, x−1)
∇2
x2 x1
θ2(y2, x−2) 0 · · · ∇2x2 xNθ2(y
2, x−2)
...
...
. . .
...
∇2
xN x1
θN(yN , x−N) ∇2xN x2θN(y
N , x−N) · · · 0


.
Since the matrix W has at most n different eigenvalues, the equality
det(∇2yxψα(x̄, ȳ)) = det(W − αI) = 0
holds for at most n different values of α. This implies that ∇2yxψα(x̄, ȳ) is nonsin-
gular for all but at most n values of α. 
74 CHAPTER 5. NEWTON’S METHOD TYPE II
Note that the previous result is the only one where we need the LICQ condition.
Neither LICQ nor this result will be used in our subsequent analysis. It is stated
here to give partial evidence that the gap between the computable generalized
Jacobian and the B-differential is not so significant.
To conclude this section, we consider the special case of a GNEP with quadratic
cost functions and linear constraints. Here the function yα(·) turns out to be piece-
wise linear (or piecewise affine, to be more precise).
Proposition 5.1.7 Consider the case where the cost functions θν are quadratic,
i.e.,
θν(x) =
1
2
(xν)T Aννx
ν +
N∑
µ=1
µ,ν
(xν)T Aνµx
µ
for ν = 1, . . . ,N. Suppose that the feasible set X is given by linear inequalities,
i.e., X := {x ∈ Rn | Bx ≤ b} for some matrix B ∈ Rm×n and vector b ∈ Rm. Let
x̄ ∈ X be arbitrarily given. Then there exists a neighbourhood U(x̄) of x̄ such that
for every x ∈ U(x̄) and every J ∈ B(x), there exist a matrix V J ∈ Rn×n and a vector
wJ ∈ Rn such that yα(x) = y(x; J) = V J x + wJ .
Proof. Since X is polyhedral, the CRCQ holds at every point x ∈ X. By Lemma
5.1.5, there exists a neighbourhood N(x̄) of x̄ such that for all x ∈ N(x̄), we have
B(x) ⊆ B(x̄) and yα(x) = y(x; J) for all J ∈ B(x), where y(· ; J) is the function
defined in Lemma 5.1.4.
Now consider an arbitrary index set J ∈ B(x̄), and let y(· ; J) be the corre-
sponding function. Furthermore, let Ā denote the n × n matrix Ā = (Aνµ)Nν,µ=1 and
diag(Aνν) denote the block-diagonal matrix with block component matrices Aνν,
ν = 1, . . . ,N. From Lemma 5.1.4, y(· ; J) is a continuously differentiable function
on N(x̄) with Jacobian
V J := ∇y(x; J)T = C−1A − C−1D(DT C−1D)−1DT C−1A,
where A := −Ā + diag(Aνν) + αI, C := diag(Aνν) + αI and D := BTJ . The as-
sumptions on the cost functions θν and the set X imply that the matrix V J is con-
stant. Consequently, y(· ; J) is an affine function, i.e., there is a vector wJ such that
y(x; J) = V J x + wJ . 
Note that it follows from the above proof that we have
yα(x) ∈ {V
J x + wJ | J ∈ B(x̄)}
for all x in a sufficiently small neighbourhood of x̄, i.e., yα(·) is a piecewise affine
function.
5.2. NEWTON’S METHOD 75
5.2 Newton’s Method
For the computation of a normalized Nash equilibrium, we use the nonsmooth
Newton method from [57] and apply it to the system of equations
F(x) := yα(x) − x = 0.
From the current iterate xk, the next iterate xk+1 is computed by
xk+1 = xk − H−1k F(x
k), (5.20)
where Hk is an element of the nonempty computable generalized Jacobian
∂CF(x
k) = ∂Cyα(x
k) − I = {∇y(xk; J)T − I | J ∈ B(xk)}. (5.21)
In this section, we give sufficient conditions for the matrices Hk to be nonsingu-
lar and show local superlinear/quadratic convergence of this nonsmooth Newton
method.
For convenience, we write
M(x, y) :=


∇2
x1 x1
θ1(y1, x−1) · · · ∇2x1 xNθ1(y
1, x−1)
...
. . .
...
∇2
xN x1
θN(yN , x−N) · · · ∇2xN xNθN(y
N , x−N)


.
This notation also facilitates the comparison with Newton methods from [32]
which are based on a variational inequality formulation of the GNEP.
The following assumption will be needed to establish fast local convergence
of the nonsmooth Newton method (5.20).
Assumption 5.2.1 For each J ∈ B(x) and λ ∈ M(x), we have
dT
(
M(x, yα(x)) +
∑
i∈J
λi∇
2gi(yα(x))
)
d > 0 ∀d ∈ T J(x), d , 0, (5.22)
where T J(x) is defined by
T J(x) := {d ∈ Rn | ∇gi(yα(x))
T d = 0 ∀i ∈ J}. (5.23)
The condition (5.22) is a kind of second order sufficiency condition. We will
revisit this condition after showing the following nonsingularity result.
Lemma 5.2.2 Let x̄ ∈ X and ȳ := yα(x̄). Suppose that Assumptions 5.1.1 and
5.2.1 hold at x̄. Then the matrix ∇y(x̄; J)T − I is nonsingular for any index set
J ∈ B(x̄).
76 CHAPTER 5. NEWTON’S METHOD TYPE II
Proof. Assume that there exists an index set J ∈ B(x̄) such that the ma-
trix ∇y(x̄; J)T − I is singular. Let λ̄ ∈ M(x̄) be the corresponding Lagrange
multiplier, which is unique by Lemma 5.1.3 under Assumption 5.1.1, such that
φα(x̄, ȳ, λ̄; J) = 0 holds. Furthermore, let y(· ; J) and λ(· ; J) be the functions de-
fined in Lemma 5.1.4; in particular, recall that we have y(x̄; J) = ȳ and λ(x̄; J) = λ̄.
Since ∇y(x̄; J)T − I is singular, there exists a nonzero vector v ∈ Rn such
that
(
∇y(x̄; J)T − I
)
v = 0, which is equivalent to saying that ∇y(x̄; J)T has an
eigenvalue equal to one with eigenvector v. From Lemma 5.1.4, along with the
fact that y(x̄; J) = ȳ and λ(x̄; J) = λ̄, we have the formula
∇y(x̄; J)T = C−1A −C−1D(DT C−1D)−1DTC−1A, (5.24)
with
A = A(x̄; J) := −∇2yxψα(x̄, ȳ),
C = C(x̄; J) := ∇2yyψα(x̄, ȳ) +
∑
i∈J
λ̄i∇
2gi(ȳ),
D = D(x̄; J) := ∇gJ(ȳ).
This expression of ∇y(x̄; J)T reveals immediately that DT∇y(x̄; J)T = 0m×n, which
implies that
0 = DT∇y(x̄; J)T v = DT v = ∇gJ(ȳ)
T v
holds, and thus,
v ∈ T J(x̄), (5.25)
where T J(x̄) is given by (5.23) with x = x̄. Therefore, multiplication of equation
(5.24) from the left side with vTC and from the right side with v gives, using the
fact that v is an eigenvector of the matrix ∇y(x̄; J)T with eigenvalue 1 once again,
vT Cv = vT Av. (5.26)
Note that the matrices C and A are expressed as
C = ∇2yyψα(x̄, ȳ) +
∑
i∈J
λ̄i∇
2gi(ȳ)
=


∇2
x1 x1
θ1(ȳ1, x̄−1)
. . .
∇2
xN xN
θN(ȳN , x̄−N)


+ αI +
∑
i∈J
λ̄i∇
2gi(ȳ)
and
A = −∇2yxψα(x̄, ȳ)
5.2. NEWTON’S METHOD 77
= −


∇2
x1 x1
θ1(ȳ1, x̄−1) · · · ∇2x1 xNθ1(ȳ
1, x̄−1)
...
. . .
...
∇2
xN x1
θN(ȳN , x̄−N) · · · ∇2xN xNθN(ȳ
N , x̄−N)


+


∇2
x1 x1
θ1(ȳ1, x̄−1)
. . .
∇2
xN xN
θN(ȳN , x̄−N)


+ αI.
Hence we have
C − A = M(x̄, ȳ) +
∑
i∈J
λ̄i∇
2gi(ȳ). (5.27)
On the other hand, by (5.22) in Assumption 5.2.1 and (5.25), we have
vT
(
M(x̄, ȳ) +
∑
i∈J
λ̄i∇
2gi(ȳ)
)
v > 0.
This together with (5.27) contradicts (5.26). 
The following example shows that Assumption 5.2.1 may hold even if the matrix
M(x, yα(x)) is not positive semidefinite. Furthermore, it shows that Assumption
5.2.1 does not imply uniqueness of the normalized Nash equilibrium.
Example 5.2.3 We consider the following Nash equilibrium problem, where player 1
controls the single variable x1, player 2 controls the single variable x2, and the cor-
responding optimization problems are given by
minx1
1
2 x
2
1 − 2x1x2 + x1 minx2
1
2 x
2
2 − 2x1x2 + x2
s.t. x1 + x2 ≥ 0 s.t. x1 + x2 ≥ 0.
The cost functions are convex with respect to xν each, and the game satisfies As-
sumptions 5.0.5. The normalized Nash equilibria are x∗ = (x∗1, x
∗
2) = (1, 1) with
Lagrange multiplier λ∗ = 0, and x∗ = (0, 0) with λ∗ = 1. We have
M(x, yα(x)) =
(
1 −2
−2 1
)
,
and, for x∗ = (0, 0),
T (x∗) = {d ∈ R2 | d = t
(
1
−1
)
, t ∈ R}.
This yields
dT Md = 6t2 > 0
for all d ∈ T (x∗).
78 CHAPTER 5. NEWTON’S METHOD TYPE II
In the case of quadratic cost functions, there is a simple sufficient condition for
Assumption 5.2.1 to hold.
Corollary 5.2.4 Suppose that the cost functions θν are given by
θν(x) =
1
2
(xν)T Aννx
ν +
N∑
µ=1
µ,ν
(xν)T Aνµx
µ
for ν = 1, . . . ,N. Then Assumption 5.2.1 holds provided that the matrix A :=
(Aνµ)Nν,µ=1 is positive definite.
Next we prove that the matrices Hk provide a superlinear approximation for the
function F.
Lemma 5.2.5 Let x∗ be a NoE. Suppose that Assumption 5.1.1 holds at x∗. Then
we have for any H ∈ ∂CF(x)
F(x) − F(x∗) − H(x − x∗) = o(‖x − x∗‖). (5.28)
Furthermore if the second derivatives of all θν and all gi are Lipschitz continuous
around x∗, then
F(x) − F(x∗) − H(x − x∗) = O(‖x − x∗‖2). (5.29)
Proof. By Lemma 5.1.4, for each J ∈ B(x∗), there is a neighbourhood NJ(x∗)
of x∗ and a continuously differentiable function y(· ; J) defined on NJ(x∗) such
that y(x∗; J) = yα(x∗) = x∗. Let ε > 0 be arbitrarily given. Then the continuous
differentiability of y(· ; J) on NJ(x∗) ensures the existence of a δ(ε, J) > 0 such
that
‖y(x; J) − y(x∗; J) − ∇y(x; J)T (x − x∗)‖
‖x − x∗‖
< ε (5.30)
holds whenever ‖x − x∗‖ < δ(ε, J). Let δ̄(ε) := minJ∈B(x∗) δ(ε, J) > 0. Then (5.30)
holds for any x such that ‖x − x∗‖ < δ̄(ε) and any J ∈ B(x∗).
Now consider an arbitrary sequence {xk} converging to x∗ and pick any Hk ∈
∂CF(xk). By the definition (5.21) of ∂CF(x), Hk can be written as Hk = ∇y(xk, Jk)T−
I for some Jk ∈ B(xk) ⊆ B(x∗). Hence, from the preceding argument, we have
‖F(xk) − F(x∗) − Hk(xk − x∗)‖
‖xk − x∗‖
=
‖yα(xk) − yα(x∗) − ∇y(xk; Jk)T (xk − x∗)‖
‖xk − x∗‖
=
‖y(xk; Jk) − y(x∗; Jk) − ∇y(xk; Jk)T (xk − x∗)‖
‖xk − x∗‖
< ε
5.2. NEWTON’S METHOD 79
for all k such that ‖xk− x∗‖ < δ̄(ε). Since {xk} and ε are arbitrary, we may conclude
that (5.28) holds.
If all functions θν and gi have Lipschitz continuous second derivatives, then for
all J ∈ B(x∗) the function ∇y(· ; J) is locally Lipschitz continuous. This follows
from formula (5.13) and the fact that the sum and the product of locally Lipschitz
continuous functions again lead to a locally Lipschitz continuous function. Then
it is not difficult to derive (5.29) in a similar manner to the above. 
Summarizing the above arguments, we are now in a position to state the main local
convergence result which shows that our method is locally superlinearly/quadrati-
cally convergent. Note that this result holds under the CRCQ condition which is
weaker than the linear independence constraint qualification.
Theorem 5.2.6 Let x∗ be a NoE and suppose that Assumptions 5.1.1 and 5.2.1
hold at x∗. Then there is a neighbourhood N(x∗) of x∗ such that for an arbi-
trary initial point x0 ∈ N(x∗), the sequence generated by the nonsmooth Newton
method (5.20) converges to x∗ superlinearly. Furthermore, if all the functions θν
and gi have Lipschitz continuous second derivatives, then the convergence rate is
quadratic.
Proof. By Lemma 5.2.2, each H ∈ ∂CF(x∗) = {∇y(x∗; J)T − I | J ∈ B(x∗)} is
nonsingular. Since the functions ∇y(· ; J) (J ∈ B(x∗)) are continuous, there ex-
ists a neighbourhood N(x∗) of x∗ such that B(xk) ⊆ B(x∗) and hence the matrices
Hk ∈ ∂CF(xk) = {∇y(xk; J)T − I | J ∈ B(xk)} are nonsingular for all xk ∈ N(x∗).
The rest of the proof consists of standard arguments based on Lemma 5.2.5 and
the definition of the nonsmooth Newton method (5.20). 
Our final result shows that the nonsmooth Newton method enjoys a local one-step
convergence property if the GNEP is described by quadratic cost functions and
linear constraints.
Proposition 5.2.7 Suppose that the cost functions and the constraints are given
as in Proposition 5.1.7 and that the matrix A := (Aµν)Nµ,ν=1 is positive definite. Let
x∗ be a NoE. Then there is a neighbourhood N(x∗) of x∗ such that, once xk enters
N(x∗), the next iterate xk+1 coincides with x∗.
Proof. By Lemma 5.1.5, there exists a neighbourhood N(x∗) of x∗ such that for
every x ∈ N(x∗) and every J ∈ B(x), we have yα(x) = y(x; J) and B(x) ⊆ B(x∗).
Moreover, from Proposition 5.1.7, we have y(x; J) = V J x + wJ for all x ∈ N(x∗)
with V J and wJ being some constant matrix and vector, respectively. Define the
function F(· ; J) on N(x∗) by F(x; J) := y(x; J) − x.
80 CHAPTER 5. NEWTON’S METHOD TYPE II
Let xk ∈ N(x∗) and Jk ∈ B(xk). Since y(· ; Jk) is an affine function on N(x∗),
Taylor’s formula yields
F(x∗; Jk) = F(x
k; Jk) + F
′(xk; Jk)(x
∗ − xk), (5.31)
where F′(· ; Jk) = V Jk − I is the Jacobian of F(· ; Jk), which is nonsingular from
Lemma 5.2.2 and Corollary 5.2.4. Since B(xk) ⊆ B(x∗), we have F(x∗; Jk) =
y(x∗; Jk)− x∗ = yα(x∗)− x∗ = F(x∗) = 0 by Lemma 5.1.5 (c) and Proposition 2.2.4.
Exploiting the nonsingularity of F′(xk; J), we then obtain from (5.31) that
x∗ = xk − F′(xk; Jk)
−1F(xk; Jk).
The right-hand side is precisely the Newton iteration at xk, and hence xk+1 coin-
cides with the NoE x∗. 
Chapter 6
Applications and Numerical Results
This chapter is concerned with four implementations of the numerical methods
developed in the preceding chapters and their application to some generalized
Nash games. In particular, we consider a Barzilai-Borwein method for the solu-
tion of the unconstrained optimization reformulation (2.14), the relaxation method
defined in Algorithm 3.2.1, a Newton method for solving the unconstrained op-
timization problem (2.14), and a Newton method (5.20) that solves a fixed point
formulation of the GNEP. We illustrate the numerical performance of these meth-
ods with five examples of generalized Nash games taken from the literature and
the electricity market example from the introduction.
6.1 Implementations
All implementations are done in MATLAB using the solver SNOPT from the TOM-
LAB package in order to calculate the values of yα(x) and yβ(x), respectively. In
order to compare the performance of the different methods, we use a similar stop-
ping criterion for all algorithms. Namely, we require that ‖yα(x) − x‖ < ε with
ε := 10−8 for the first order methods, that is, the Barzilai-Borwein method and
the relaxation method, and ε := 10−12 for the Newton-type methods, where the
parameter α is set to 10−4 for all methods except the Newton method solving the
unconstrained optimization reformulation, where it is set to 10−2. Since the ex-
amples have a rather simple structure, all algorithms are terminated by force if a
maximum of 15 iterations is reached.
81
82 CHAPTER 6. APPLICATIONS AND NUMERICAL RESULTS
6.1.1 Barzilai Borwein Method
Here we illustrate the performance of a first-order numerical method for the solu-
tion of the unconstrained optimization problem
min Vαβ(x) s.t. x ∈ R
n,
in order to compute a normalized Nash equilibrium, see the definition of Vαβ in
(2.12) and some further theoretical properties of Vαβ at the end of chapter 3.1.
We choose the Barzilai-Borwein (BB) gradient method [8], see also [87, 88,
35, 18, 41] for some subsequent modifications and investigations of this method,
for the unconstrained minimization of the objective function Vαβ. This method
uses the iterative procedure
xk+1 := xk − αk∇Vαβ(x
k), k = 0, 1, 2, . . .
with the stepsize
αk :=
yT s
yT y
,
where
s := xk − xk−1, y := ∇Vαβ(x
k) − ∇Vαβ(x
k−1).
Hence the BB method has the advantage of using an explicit formula for the step-
size. So no extra line search is required which would be very expensive in our case
since this would require further evaluations of the mapping Vαβ. Each function
evaluation of Vαβ, however, needs the solution of two constrained optimization
problems in order to compute yα(x) and yβ(x).
We use the parameters α = 10−4 and β = 5 · 10−4 for all test examples, and ter-
minate the iteration if either ‖yα(xk) − xk‖ < 10−8 or the iteration number exceeds
15. We state the value of Vαβ(xk), which shows that the objective function value
decreases in nearly every iteration despite the lack of a line search. At first view,
it seems odd not to use the value of Vαβ for termination criterion. However, the
value of Vαβ depends strongly on the choice of α and β, so choosing α and β close
to equality might cause the algorithm to stop earlier than for other values of α and
β, even if the distance to solution is greater. In any case, it is easier to compare
the Barzilai-Borwein method with the other methods using the stopping criterion
based on ‖yα(xk) − xk‖.
6.1.2 Relaxation Method
Here we implemented Algorithm 3.2.1 with the modified stepsize rule from Re-
mark 3.2.5. The method is terminated whenever ‖yα(xk) − xk‖ < ε with ε := 10−8
6.1. IMPLEMENTATIONS 83
and uses the parameters α = 10−4, β = 0.5 and σ = 10−4. For the electricity
market example we also tested the method setting σ = 1.
6.1.3 Newton’s Method based on Optimization Reformulation
This is the Newton-type method described through equations (4.16) and (4.17) for
the solution of the unconstrained optimization reformulation of the GNEP (2.14).
To this end, we need to calculate elements from ∂2BVαβ(x
k). This is not an easy
task, however, all examples except Rosen’s example satisfy, in addition to the lin-
ear independence constraint qualification, strict complementarity at the solution,
which results in differentiability of the function ∇Vαβ, so we simply compute the
Hessian of Vαβ(xk) in each iteration. We use an Armijo-type line search in order
to globalize this method. Moreover, we switch to the steepest descent direction
whenever the generalized Newton direction is not computable or does not satisfy
a sufficient decrease condition. In our experiments, however, we were always able
to take the generalized Newton direction. The method is terminated whenever
‖yα(xk) − xk‖ < ε with ε := 10−12 and uses the two parameters α = 0.01 and
β = 0.05 for the definition of Vαβ.
6.1.4 Newton’s Method through Fixed Point Formulation
Here we implemented the Newton method according to the iterative scheme (5.20).
The parameter α is set to 10−4 for all test runs and the iteration is stopped when-
ever ‖yα(xk) − xk‖ < 10−12.
To calculate an element of the computable generalized Jacobian of yα at xk,
we need to find an index set J ∈ B(xk) together with a corresponding multiplier
λk. This is an easy task if the linear independence constraint qualification (LICQ)
holds at the minimum yα(xk). In this case, we can take, for example, J := I0(xk),
where I0(x) is defined by (5.8). However, since LICQ is not needed in the conver-
gence theory of this method, we have to find a way to compute J and λk under the
weaker CRCQ assumption. To this end, consider the linear program
min
λ
∑
i∈I0
λi
s.t. ∇g(yα(x
k)) λ = −∇yψα(x
k, yα(x
k)), (6.1)
λi ≥ 0 ∀ i ∈ I0,
λi = 0 ∀ i ∈ {1, . . . ,m} \ I0,
where I0 := I0(xk). Since CRCQ holds at yα(xk), it follows thatM(xk) is nonempty,
and hence (6.1) has at least one feasible point. Moreover, the objective function is
obviously bounded from below on the feasible set. Standard linear programming
84 CHAPTER 6. APPLICATIONS AND NUMERICAL RESULTS
theory then shows that (6.1) is solvable; moreover, at least one of the vertices of
the polyhedron defined by the feasible set of (6.1) is also a solution. Now, let
λk be such a vertex solution of (6.1). Then, again by standard results for linear
programs, it follows that the gradients ∇gi(yα(xk)) corresponding to the positive
components λki > 0 are linearly independent. This proves the following result.
Lemma 6.1.1 Suppose that the CRCQ (or any other constraint qualification)
holds at yα(xk). Let λk be a vertex solution of the linear program (6.1) and de-
fine J := {i ∈ I0 | λki > 0}. Then J belongs to B(x
k).
Note that, in principle, a vertex solution of the linear program (6.1) can be calcu-
lated by the simplex method. It should be noted, however, that the linear program
(6.1) is not given in standard form since the rows of the constraint matrix may be
linearly dependent. Typically, implementations of the simplex method deal with
this problem automatically. Alternatively, one could modify (6.1) like in the Big-
M method to get an equivalent linear program which satisfies the full row rank
condition.
6.2 Examples of Generalized Nash Equilibrium Prob-
lems
In order to highlight some distinguishing properties of the numerical methods de-
scribed before, we selected five Nash games from the literature as test examples
in addition to the electricity market model from the introduction. These examples
can be classified according to the structure of cost functions and constraints. Ex-
amples 6.2.2, 6.2.4 and 6.2.6 are linear-quadratic games, that is, the cost functions
are quadratic with linear terms. Such games have been discussed in Proposition
3.1.2, Corollary 3.1.7 and Proposition 5.1.7, though without linear terms. It is not
difficult to see that the conclusions of these propositions still hold with additional
linear terms in the cost function. Examples 6.2.3 and 6.2.5, as well as the electric-
ity market example from the introduction, have in common that the cost functions
include a particular function that is subject of the following Lemma.
Lemma 6.2.1 Let xµ ∈ R for µ ∈ {1, . . . ,N} and consider for fixed ν ∈ {1, . . . ,N}
the function
fν(x
ν, x−ν) := δνx
ν −
xν
(
∑N
µ=1 xµ)γ
,
where δν and γ are some real parameters. Assume that xµ ≥ 0 for all µ ∈
{1, . . . ,N} and
∑N
µ=1 x
µ > 0. Then fν is well-defined and for 0 < γ < 1, the function
fν is strictly convex with respect to the variable xν and convex if γ = 1.
6.2. EXAMPLES OF GENERALIZED NASH EQUILIBRIUM PROBLEMS 85
Proof. We calculate the partial derivatives of fν. This yields
∇xν fν(x) = δ − (
N∑
µ=1
xµ)−γ + γxν(
N∑
µ=1
xµ)−γ−1,
∇2xνxν fν(x) = 2γ(
N∑
µ=1
xµ)−γ−1 − (γ2 + γ)xν(
N∑
µ=1
xµ)−γ−2,
∇2xν xξ fν(x) = γ(
N∑
µ=1
xµ)−γ−1 − (γ2 + γ)xν(
N∑
µ=1
xµ)−γ−2 for ξ , ν.
In order to prove strict convexity of the function fν with respect to xν it is sufficient
to show that ∇2xνxν fν(x) > 0. We arrive at
0 < γ < 1
⇒ 2γ > γ2 + γ
⇒ 2γ(
∑N
µ=1 x
µ)(
∑N
µ=1 x
µ)−1−γ > (γ2 + γ)xν(
∑N
µ=1 x
µ)−1−γ
⇒ ∇2xνxν fν(x) > 0
where we used
∑N
µ=1 x
µ > 0 and xµ ≥ 0∀µ = 1, . . . ,N, in the last but one inequal-
ity. The case γ = 1 follows analogue with ’≥’ instead of ’>’.

The numerical results indicate that the local convergence performance of all meth-
ods is connected to the properties of the matrix
M(x∗) :=


∇2
x1 x1
θ1(x∗) . . . ∇2x1 xNθ1(x
∗)
∇2
x2 x1
θ2(x∗) . . . ∇2x2 xNθ2(x
∗)
...
. . .
...
∇2
xN x1
θN(x∗) . . . ∇2xN xNθN(x
∗)


. (6.2)
From a theoretical point of view, if M(x∗) is positive definite, then Assumption
3.1.4 holds in a neighbourhood of a normalized Nash equilibrium by Theorem
3.1.6, which is essential for the relaxation method. Furthermore, this assumption
implies that the Newton method based on the fixed point formulation has local
superlinear convergence, see Lemma 5.2.2. In practice, the condition number of
the matrix M(x∗) seems to influence the efficiency of the first-order methods in a
similar way the Hessian of the objective function does in optimization problems.
The details are discussed with in the description of the respective examples.
86 CHAPTER 6. APPLICATIONS AND NUMERICAL RESULTS
Example 6.2.2 This test problem is the river basin pollution game taken from [45]
and [61]. The game consists of three players with cost functions
θν(x) =
(
d2
3∑
µ=1
xµ + c1ν + c2νx
ν − d1
)
xν,
where xν ∈ R+ for ν = 1, 2, 3. Furthermore, the players face two joint constraints,
l = 1, 2, of the form
ql(x) =
3∑
µ=1
uµleµx
µ ≤ Kl.
All constants are given in Table 6.1.
Player ν c1ν c2ν eν uν1 uν2 d1 d2 K1 K2
1 0.10 0.01 0.50 6.5 4.583 3.0 0.01 100 100
2 0.12 0.05 0.25 5.0 6.250
3 0.15 0.01 0.75 5.5 3.750
Table 6.1: Constants for the river basin pollution game
This game is a Cournot-type model. In [61], the authors describe the following
economic interpretation: Each player ν represents a company engaged in some
economic activity, for instance paper pulp production, at a level xν. The companies
sell their product on the same market and the price on that market depends on the
total output on the market. Thus, the revenue function, and therefore the profit
function of each agent, which equates to the negative cost function defined above,
depends on the production level of the rival companies.
The joint constraints ql arise from a limitation on environmental damage in-
duced by the players’ activities. In this particular example, the companies are
located along a river and expel pollutions from production into the river. The pol-
lution level of the river is monitored by two measurement stations along the river.
At each station, the local authority sets a limit on pollutant concentration, which
results in the joint constraints ql, l = 1, 2.
Since this game has quadratic cost functions with linear terms, the matrix
M(x∗) defined in equation (6.2) is
M(x∗) =


0.04 0.01 0.01
0.01 0.12 0.01
0.01 0.01 0.04


,
which is positive definite with condition number cond(M) = 4.1. Thus, in view of
Corollary 3.1.7 the sufficient conditions for convergence of the relaxation method
6.2. EXAMPLES OF GENERALIZED NASH EQUILIBRIUM PROBLEMS 87
hold. Moreover, the matrix B defined in Proposition 3.1.2 is positive definite,
implying that for small α the function Vα is convex. Thus, we may assume that
the relaxation method works quite well.
The local convergence of the Newton method based on the fixed point for-
mulation is ensured by Lemma 5.2.2. Moreover, Proposition 5.2.7 implies that
the Newton method based on the fixed point formulation terminates after a finite
number of iterations for suitable starting points. We actually observe convergence
in just one step for both Newton methods. The numerical results can be found in
Table 6.5.
Example 6.2.3 This test problem is the internet switching model introduced by
Kesselman et al. [56] and further analyzed by Facchinei et al. [32]. The cost
function of each user is given by
θν(x) =
xν
B
−
xν
∑N
µ=1 xµ
,
with constraints xν ≥ 0.01, ν = 1, . . . ,N, and a joint constraint of the form
N∑
µ=1
xµ ≤ B.
The constraints have been slightly modified from those in [56] to ensure that the
cost functions θν are defined on the whole feasible set. The exact solution of this
problem is x∗ = (0.9, . . . , 0.9)T .
This is the only example where the full step size tk = 1 was never accepted in
the relaxation method. Using our line search globalization, however, we observe
very fast linear convergence (see Table 6.6). The situation changes if the starting
point for the players is chosen unequally. Taking x0 = (0.1, 0.11, 0.12, 0.13 . . . )T ∈
R
10, for example, we obtain the results from Tables 6.7 and 6.8. Both relaxation
method and Barzilai-Borwein method have difficulties here, opposed to the New-
ton methods.
^
Example 6.2.4 Here we consider a simple two-player game originally suggested
by Rosen [92]. The example has the two cost functions
θ1(x1, x2) =
1
2
x21 − x1x2 and θ2(x1, x2) = x
2
2 + x1x2
and the joint constraints given by
X := {x ∈ R2 | x1 ≥ 0, x2 ≥ 0, x1 + x2 ≥ 1}.
88 CHAPTER 6. APPLICATIONS AND NUMERICAL RESULTS
The unique normalized Nash equilibrium of this GNEP is x∗ = (1, 0)T and does
not satisfy strict complementarity since an easy calculation shows that yα(x∗) =
(1, 0)T and λα(x∗) = (0, 0, 1)T for arbitrary parameter α > 0, hence strict com-
plementarity does not hold in the second component. Table 6.9 shows our corre-
sponding numerical results. ^
Example 6.2.5 This test problem is a Cournot oligopoly problem with shared
constraints and nonlinear cost functions, which was first described in [69] as a
standard Nash game and later in [75, p. 233] with additional joint constraints.
The model considers a number of N firms competing on the same market.
Each company chooses a production output xν ∈ R+ so as to maximize her profit
function
θν(x
ν, x−ν) = p(xν, x−ν) · xν − fν(x
ν),
where the market price p is given by the inverse demand function
p(xν, x−ν) = 5000γ ·
(
N∑
µ=1
xµ
)−γ
and the cost function of firm ν is
fν(x
ν) = cν · x
ν +
βν
βν + 1
K
− 1
βν
ν · (x
ν)
βν+1
βν .
The shared constraint imposed on joint production is
N∑
µ=1
xµ ≤ P.
In fact, in order to guarantee that all functions are well-defined, one should add an
additional constraint
∑N
µ=1 x
µ ≥ ε with some small constant ε. However, since this
does not change the solution and no difficulties arise in the numerical solution of
the problem, we omit this.
In accordance with [69] and [75] we consider five players and choose γ = 11.1 .
The remaining constants are given in Table 6.2, except for the parameter P, which
we vary.
It is not difficult to see that the negative of the profit function θν can be written
as the sum of a strictly convex function and a function of the type defined in
Lemma 6.2.1. Lemma 6.2.1 i) then implies that the negated profit function θν is
strictly convex with respect to player ν′s variable. The numerical results can be
found in Tables 6.10, 6.11, 6.12 and Table 6.13.
^
6.2. EXAMPLES OF GENERALIZED NASH EQUILIBRIUM PROBLEMS 89
Firm cν Kν βν
1 10 5 1.2
2 8 5 1.1
3 6 5 1.0
4 4 5 0.9
5 2 5 0.8
Table 6.2: Parameter specifications for the Cournot Oligopoly
Example 6.2.6 We solve the electricity market problem suggested by Contreras
et al. [15], case study 1. This model involves three power generating companies
owning one, two, and three power plants, respectively. It is different to the elec-
tricity market model from the introduction in that it does not involve a power line
network, in particular, there is only one type of consumers with linear demand
function. To avoid confusion, we refer to the present example as ’electricity mar-
ket example I’, while ’electricity market example II’ refers to the next example.
The decision variable xνi of company ν determines the electricity generated
with power plant i. Let nν be the number of power plants owned by company ν.
Each power plant has a capacity limit Pmax
νi incurring a production limit 0 ≤ x
ν
i ≤
Pmax
νi
The profit function of company ν is given by
θν(x
ν, x−ν) = p(xν, x−ν) ·
nν∑
i=1
xνi −
nν∑
i=1
fνi(x
ν
i ),
where the inverse demand function p is given by
p(xν, x−ν) = 378.4 − 2
3∑
ν=1
nν∑
i=1
xνi ,
and the cost function fνi of power plant i owned by player ν is
fνi(x
ν, x−ν) =
1
2
cνi · (x
ν
i )
2 + diνx
ν
i + eiν.
The constants are specified in Table 6.3.
In this game the restriction is only imposed on electricity generation of a par-
ticular company, thus, this is a standard Nash equilibrium problem. For the nu-
merical solution of the problem we take once again the negated profit function of
a player as cost function. While the matrix M(x∗) is positive definite, its condition
number is quite bad (around 610), which results in slow convergence of the first
order methods. In fact, the relaxation method was extremly slow with the choice
90 CHAPTER 6. APPLICATIONS AND NUMERICAL RESULTS
company ν generator i cνi dνi eiν Pminνi P
max
νi
1 1 0.04 2 0 0 80
2 1 0.035 1.75 0 0 80
2 0.125 1 0 0 50
1 0.0166 3.25 0 0 55
3 2 0.05 3 0 0 30
3 0.05 3 0 0 40
Table 6.3: Parameter specifications for the electricity market problem
of σ = 10−4, see Table 6.14. Choosing σ = 1 gives better results, cf. Table
6.15. The numerical results also show that the Barzilai-Borwein method works
suprisingly well. The Newton methods have no problem with this example, as the
results in Table 6.15 show.
Example 6.2.7 Here we solve the electricity market example from the introduc-
tion, which we call ’electricity market example II’ in the numerical results section.
The game has two players, A and B, each controlling 5 variables. Player A con-
trols xA ∈ R4 and yA ∈ R, while player B controls xB and yB. In order to implement
the method we change the names of the variables, in that we define
x := (xA, yA, xB, yB),
in particular, x5 = yA and x10 = yB. Parameters are chosen as follows:
i ei ki Ci cA cB γ
1 5 300 30000 26 28 11.1
2 2 300 50000
3 2 300 40000
4 2 300 30000
Table 6.4: Parameter specification for the electricity market model II
Since the profit functions and constraints have been defined in the introduction
already, we do not state them here. Instead of the profit function we consider of
course the negative of the profit function so as to have minimization problems. We
proceed with some considerations about convergence conditions for this particular
example.
6.2. EXAMPLES OF GENERALIZED NASH EQUILIBRIUM PROBLEMS 91
For this example, the matrix M from equation (6.2) has the structure
M(x) =


0 0
A(x)
... B(x)
...
0 . . . 0 . . . 0
C(x)
... D(x)
...
0 . . . 0 . . . 0


,
where A(x), B(x),C(x) and D(x) ∈ R4×4 are diagonal matrices with entries
Aii(x) = 2γpi(x)(xi + xi+5)−1 − (γ2 + γ)pi(x)(xi + xi+5)−2xi,
Bii(x) = γpi(x)(xi + xi+5)−1 − (γ2 + γ)pi(x)(xi + xi+5)−2xi,
Cii(x) = γpi(x)(xi + xi+5)−1 − (γ2 + γ)pi(x)(xi + xi+5)−2xi+5,
Dii(x) = 2γpi(x)(xi + xi+5)−1 − (γ2 + γ)pi(x)(xi + xi+5)−2xi+5.
This immediately shows that the matrix M(x) is not positive definite for any x, not
even nonsingular. However, there is a possibility to derive a condition which im-
plies that Assumption 5.22 holds, the latter being important to show convergence
of the Newton method based on the fixed point reformulation. To this end, we
formulate the following Lemma.
Lemma 6.2.8 Suppose that 0 < γ < 1, x ∈ R10, and x > 0 such that xi ≤ 3xi+5
and xi+5 ≤ 3xi for all i = 1, 2, 3, 4. Then the matrix
(
A(x) B(x)
C(x) D(x)
)
is positive definite.
Proof. With the Theorem of Gerschgorin, it follows easily that all eigenvalues of
the matrix in question are positive. However, this does not imply that the matrix
itself is positive definite, since the matrix is not symmetric.
We write ai := Aii(x), bi = Bii(x), ci = Cii(x) and di = Dii(x). With this
notation we have, for z , 0 arbitrary,
zT
(
A(x) B(x)
C(x) D(x)
)
z =
4∑
i=1
[
zi(aizi + bizi+4) + zi+4(cizi + dizi+4)
]
=
4∑
i=1
[
aiz
2
i + (bi + ci)zizi+4 + diz
2
i+4
]
≥
4∑
i=1
min{ai, di}(z
2
i + z
2
i+4) − |bi + ci||zizi+4|
≥
4∑
i=1
(
min{ai, di} −max{|bi|, |ci|}
)
(z2i + z
2
i+4).
92 CHAPTER 6. APPLICATIONS AND NUMERICAL RESULTS
In the remainder we show that min{ai, di} − max{|bi|, |ci|} > 0 for all γ and x
satisfying the assumptions. For simplicity, we write
δ := pi(x)(xi + xi+5)
−1.
Note that δ > 0 for all x > 0. It follows that
ai − bi = γδ > 0
and
ai + bi = 3γδ − (γ2 + γ)δ · 2 ·
xi
xi+xi+5
≥ 3γδ − (γ2 + γ)δ · 2 · 34
> 0,
where we used the assumption that xi ≤ 3xi+5 and γ < 1. Thus it follows that
ai − |bi| > 0 holds for all i = 1, 2, 3, 4. Further we get
ai − ci = γδ − (γ2 + γ)δ ·
xi−xi+5
xi+xi+5
≥ γδ − (γ2 + γ)δ · 23 ·
xi
xi+xi+5
≥ γδ − (γ2 + γ)δ · 23 ·
3
4
> 0,
and
ai + ci = 3γδ − (γ2 + γ)δ ·
xi+xi+5
xi+xi+5
> 0,
from which we conclude that ai − |ci| > 0 for all i = 1, 2, 3, 4. The inequalities
di − |bi| > 0 and di − |ci| > 0 follow analogously. All in all, this proves the
assertion. 
To show that Assumption (5.22) holds at the solution x∗, we have to analyse the
strongly active constraints at x∗. In particular, it is not difficult to verify that
whenever the constraints x5 ≤ x3 and x5 + x10 ≤ k5 are strongly active for all
λ ∈ M(x∗), which is the case at the numerical solution presented in the next
section, then any vector d ∈ T (x∗, λ) has at least one component i , 5, i , 10
with di , 0. According to the previous Lemma this implies immediately that
dT M(x∗)d > 0, meaning that Assumption (5.22) holds.
We solved this example with starting point (100, 100, . . . , 100), however, both
the Barzilai-Borwein method as well as the Newton method that is based on the
unconstrained optimization reformulation failed for this starting point. So for the
latter two methods a starting point very close to a solution was chosen. More-
over, for the Newton method we changed the parameters α and β, since it failed
otherwise. Interestingly, the relaxation method was able to find the solution even
from remote starting points such as (1000, 1000, 1000, 1000, 10, 10, 10, 10, 10, 10)
and (10, 10, . . . , 10) in only few iterations, while the Newton method based on the
fixed point formulation failed for these starting points.
6.3. NUMERICAL RESULTS 93
6.3 Numerical Results
We present the numerical results arranged according to the examples. The column
InnerIt refers to the number of iterations necessary for the computation of yα(xk),
or yα(xk) and yβ(xk), with the solver SNOPT in each iteration.
Barzilai-Borwein method
k xk1 x
k
2 x
k
3 Vαβ(x
k) InnerIt
0 0.000000 0.000000 0.000000 0.1361518082979245 0
1 0.007261 0.006910 0.002941 0.1360427094475938 14
2 17.628067 16.776627 7.138440 0.0036885797244235 14
3 19.273268 16.174578 4.492779 0.0007416785230008 14
4 21.026541 16.074125 2.836986 0.0000032596075654 12
5 21.138745 16.004907 2.722435 0.0000001156482999 8
6 21.151220 16.042181 2.731168 0.0000000570958838 8
7 21.144064 16.028078 2.725161 0.0000000002262616 8
8 21.144692 16.027979 2.725905 0.0000000000047775 4
9 21.144762 16.027865 2.725976 0.0000000000000127 4
10 21.144768 16.027865 2.725982 0.0000000000383554 2
11 21.144767 16.027865 2.725982 0.0000000000000000 2
Relaxation method
k xk1 x
k
2 x
k
3 Vα(x
k ) stepsize InnerIt
0 0.000000 0.000000 0.000000 90.8783016935181820 0.0000 0
1 19.325861 17.174694 3.811536 0.1184021869776447 1.0000 7
2 20.704322 16.105367 3.049513 0.0036631052660658 1.0000 6
3 21.036702 16.036753 2.808431 0.0002134195425450 1.0000 4
4 21.118192 16.029539 2.746413 0.0000129244012658 1.0000 3
5 21.138243 16.028243 2.731008 0.0000007843314006 1.0000 3
6 21.143180 16.027947 2.727207 0.0000000476926749 1.0000 3
7 21.144396 16.027876 2.726271 0.0000000029210997 1.0000 3
8 21.144696 16.027859 2.726040 0.0000000000000000 1.0000 3
Newton’s method based on optimization reformulation
k xk1 x
k
2 x
k
3 Vαβ(x
k) InnerIt
0 0.000000 0.000000 0.000000 10.2971171700988862 0
1 21.144786 16.027881 2.725962 0.0000000000000000 14
Newton’s method based on fixed point formulation
k xk1 x
k
2 x
k
3 ‖yα(x
k) − xk‖ InnerIt
0 0.000000 0.000000 0.000000 26.1340202062020914 0
1 21.144800 16.027868 2.725956 0.0000000000000000 7
Table 6.5: Numerical results for the river basin pollution game
94 CHAPTER 6. APPLICATIONS AND NUMERICAL RESULTS
Barzilai-Borwein method
k xk1 x
k
2 Vαβ(x
k) InnerIt
0 0.100000 0.100000 0.0000052653091851 0
1 0.099892 0.099892 0.0000051496217887 8
2 0.090643 0.090643 0.0000000207265598 8
3 0.090046 0.090046 0.0000000001068226 6
4 0.090000 0.090000 0.0000000000000000 6
Relaxation method
k xk1 x
k
2 Vα(x
k ) stepsize InnerIt
0 0.100000 0.100000 0.0263327223481960 0.0000 0
1 0.087171 0.087171 0.0022418335124145 0.2500 4
2 0.090378 0.090378 0.0000397082293171 0.2500 1
3 0.089905 0.089905 0.0000025173339792 0.2500 3
4 0.090024 0.090024 0.0000001572108120 0.2500 2
5 0.089994 0.089994 0.0000000093048805 0.2500 2
6 0.090001 0.090001 0.0000000005214422 0.2500 3
7 0.090000 0.090000 0.0000000000000000 0.2500 1
Newton’s method based on unconstrained optimization reformulation
k xk1 x
k
2 Vαβ(x
k) InnerIt
0 0.100000 0.100000 0.0005120314348019 0
1 0.090631 0.090631 0.0000019453839386 8
2 0.090003 0.090003 0.0000000000474542 6
3 0.090000 0.090000 0.0000000000000000 2
Newton’s method based on fixed point formulation
k xk1 x
k
2 x
k
3 ‖yα(x
k ) − xk‖ InnerIt
0 0.100000 0.100000 0.100000 0.1622704430677725 0
1 0.090238 0.090238 0.090238 0.0037588135778690 4
2 0.090000 0.090000 0.090000 0.0000000000000000 3
Table 6.6: Numerical results for the Internet switching example using starting
point x0 = (0.1, . . . , 0.1)
Barzilai-Borwein method, terminated by force
k xk1 x
k
2 x
k
3 Vαβ(x
k) InnerIt
0 0.100000 0.110000 0.120000 0.0000381000000002 0
1 0.099964 0.109960 0.119956 0.0000380695260959 2
2 0.010000 0.010000 0.010000 0.0000161999993167 2
3 0.064943 0.064943 0.064943 0.0000024579357576 2
4 0.100000 0.100000 0.100000 0.0000052653091811 2
5 0.068976 0.068976 0.068976 0.0000019249391410 8
6 0.072177 0.072177 0.072177 0.0000015482299654 2
7 0.100000 0.100000 0.100000 0.0000052653091654 2
8 0.074779 0.074779 0.074779 0.0000012721816533 8
9 0.076936 0.076936 0.076936 0.0000010638817308 2
10 0.100000 0.100000 0.100000 0.0000052653091788 2
11 0.078753 0.078753 0.078753 0.0000009028469890 8
12 0.080305 0.080305 0.080305 0.0000007757884890 2
13 0.100000 0.100000 0.100000 0.0000052653090356 2
14 0.081646 0.081646 0.081646 0.0000006737793841 8
15 0.082815 0.082815 0.082815 0.0000005906430434 4
Table 6.7: Numerical results for the Internet switching example using starting
point x0 = (0.1, 0.12, . . . , 0.19)
6.3. NUMERICAL RESULTS 95
Relaxation method, terminated by force
k xk1 x
k
2 x
k
3 Vα(x
k ) stepsize InnerIt
0 0.100000 0.110000 0.120000 0.4260724139309636 0.0000 0
1 0.055000 0.060000 0.065000 0.0298453579367650 0.5000 1
2 0.090304 0.092485 0.094657 0.0264434723093843 1.0000 5
3 0.078749 0.080644 0.082531 0.0023467024352681 0.2500 5
4 0.083142 0.084771 0.086392 0.0001111978318160 0.2500 5
5 0.083670 0.085074 0.086472 0.0000561849531093 0.2500 4
6 0.087607 0.088233 0.088856 0.0000505374595352 1.0000 4
7 0.087515 0.088055 0.088592 0.0000103974935023 0.2500 4
8 0.088418 0.088807 0.089196 0.0000097726000347 0.5000 3
9 0.088479 0.088813 0.089148 0.0000033929490075 0.2500 3
10 0.088981 0.089223 0.089465 0.0000023853246782 0.5000 3
11 0.089063 0.089271 0.089480 0.0000012232352152 0.2500 3
12 0.089644 0.089736 0.089829 0.0000010429882894 1.0000 3
13 0.089633 0.089712 0.089793 0.0000002229457964 0.2500 3
14 0.089765 0.089822 0.089880 0.0000002032869300 0.5000 3
15 0.089775 0.089824 0.089874 0.0000000736802234 0.2500 3
Newton’s method based on unconstrained optimization reformulation
k xk1 x
k
2 x
k
3 Vαβ(x
k) InnerIt
0 0.100000 0.110000 0.120000 0.0038100000000220 0
1 0.010000 0.010000 0.010000 0.0016200000002407 2
2 0.100000 0.100000 0.100000 0.0005120314355159 2
3 0.090631 0.090631 0.090631 0.0000019453837216 8
4 0.090003 0.090003 0.090003 0.0000000000474544 6
5 0.090000 0.090000 0.090000 0.0000000000000000 2
Newton’s method based on fixed point formulation
k xk1 x
k
2 x
k
3 ‖yα(x
k) − xk‖ InnerIt
0 0.100000 0.110000 0.120000 0.4364630568571630 0
1 0.010000 0.010000 0.010000 0.2846049894364130 1
2 0.100000 0.100000 0.100000 0.1622713515888371 1
3 0.090238 0.090238 0.090238 0.0037589338084981 4
4 0.090000 0.090000 0.090000 0.0000000000000000 3
Table 6.8: Numerical results for the Internet switching example using starting
point x0 = (0.1, 0.12, . . . , 0.19)
96 CHAPTER 6. APPLICATIONS AND NUMERICAL RESULTS
Barzilai-Borwein method
k xk1 x
k
2 Vαβ(x
k) InnerIt
0 1.000000 1.000000 0.0001999999999742 0
1 1.000000 0.999600 0.0001998400319845 2
2 1.000000 -0.000000 0.0000000000000000 2
Relaxation method
k xk1 x
k
2 Vα(x
k ) stepsize InnerIt
0 1.000000 1.000000 1.9999499999354007 0.0000 0
1 1.000000 0.000000 0.0000000000000000 1.0000 1
Newton’s method based on optimization reformulation
k xk1 x
k
2 Vαβ(x
k) InnerIt
0 0.000000 0.000000 0.0110681478315567 0
1 1.000000 -0.000000 0.0000000000000000 10
Newton’s method based on fixed point formulation
k xk1 x
k
2 ‖yα(x
k) − xk‖ InnerIt
0 1.000000 1.000000 0.9999999999353941 0
1 1.000000 0.000000 0.0000000000000000 1
Table 6.9: Numerical results for Rosen’s example
6.3. NUMERICAL RESULTS 97
Barzilai-Borwein method
k xk1 x
k
2 x
k
3 x
k
4 x
k
5 Vαβ(x
k) InnerIt
P = 75
0 10.000000 10.000000 10.000000 10.000000 10.000000 0.0268480539534721 0
1 10.001070 10.001579 10.002074 10.002531 10.002904 0.0268272037401402 14
2 12.817462 14.156111 15.461249 16.663323 17.645778 0.0009845862149476 14
3 10.689551 13.066910 15.324900 17.297873 18.745320 0.0000092732708712 10
4 10.430158 13.023471 15.393945 17.378413 18.772063 0.0000000864525910 8
5 10.406391 13.035304 15.407584 17.381497 18.770792 0.0000000007169719 6
6 10.403678 13.035667 15.407236 17.381502 18.771533 0.0000000000200473 4
7 10.403886 13.035907 15.407414 17.381566 18.771292 0.0000000000001722 4
8 10.403870 13.035891 15.407399 17.381551 18.771278 0.0000000000000139 2
9 10.403874 13.035891 15.407399 17.381551 18.771285 0.0000000000000000 2
P = 100
0 10.000000 10.000000 10.000000 10.000000 10.000000 0.1020219378488036 0
1 10.002988 10.003580 10.004129 10.004584 10.004872 0.1019411654908708 14
2 17.637915 19.151786 20.554940 21.720377 22.455028 0.0021474746283765 14
3 14.600540 17.886589 20.784894 22.959137 24.032952 0.0000382036002087 12
4 14.075578 17.773689 20.889808 23.111326 24.137870 0.0000001514347596 10
5 14.053873 17.798219 20.907911 23.111158 24.131859 0.0000000019138247 8
6 14.049869 17.798091 20.906969 23.111440 24.133067 0.0000000000324460 6
7 14.050123 17.798397 20.907212 23.111459 24.132877 0.0000000000001882 4
8 14.050107 17.798382 20.907196 23.111444 24.132863 0.0000000000000107 2
9 14.050115 17.798382 20.907196 23.111444 24.132863 0.0000000000000000 2
10 14.050115 17.798382 20.907196 23.111444 24.132863 0.0000000000000000 2
P = 150
0 10.000000 10.000000 10.000000 10.000000 10.000000 0.4015502352185649 0
1 10.007001 10.007725 10.008291 10.008588 10.008490 0.4012296537875955 18
2 27.581167 29.400812 30.821726 31.568544 31.321645 0.0026245998283327 18
3 24.142654 28.700749 31.861325 33.139026 32.342113 0.0000426540202867 12
4 23.600032 28.667245 32.016883 33.289873 32.418046 0.0000000516033283 12
5 23.589835 28.684688 32.021791 33.286980 32.418230 0.0000000002427575 10
6 23.588618 28.684232 32.021454 33.287291 32.418180 0.0000000000031846 6
7 23.588697 28.684322 32.021511 33.287265 32.418218 0.0000000000000178 4
8 23.588690 28.684322 32.021504 33.287265 32.418218 0.0000000000000000 2
P = 200
0 10.000000 10.000000 10.000000 10.000000 10.000000 0.9008965096018073 0
1 10.011344 10.012106 10.012512 10.012407 10.011675 0.9001761099880241 20
2 38.371089 40.278778 41.294023 41.030151 39.198877 0.0013693429954593 20
3 36.065684 40.686198 42.687317 41.907698 38.713861 0.0000130260916454 16
4 35.788937 40.745185 42.803534 41.966728 38.693647 0.0000000053306220 12
5 35.785448 40.749010 42.802408 41.966346 38.697054 0.0000000000110361 8
6 35.785340 40.748952 42.802469 41.966375 38.696840 0.0000000000000718 4
7 35.785347 40.748952 42.802488 41.966375 38.696840 0.0000000000000013 2
8 35.785344 40.748952 42.802488 41.966375 38.696840 0.0000000000000000 2
9 35.785345 40.748952 42.802488 41.966375 38.696840 0.0000000000000000 2
Table 6.10: Barzilai-Borwein method, Cournot oligopoly
98 CHAPTER 6. APPLICATIONS AND NUMERICAL RESULTS
Relaxation method
k xk1 x
k
2 x
k
3 x
k
4 x
k
5 Vα(x
k ) stepsize InnerIt
P = 75
0 10.000000 10.000000 10.000000 10.000000 10.000000 1028.8786429070255508 0 0
1 13.012779 14.054536 15.077163 16.029954 16.825568 3.5863763599505036 1 7
2 11.285846 13.311206 15.235897 16.937369 18.229682 0.3540710625785035 1 5
3 10.704955 13.106954 15.332147 17.236881 18.619062 0.0366161338762231 1 4
4 10.507367 13.052936 15.377109 17.334696 18.727893 0.0039489433586007 1 4
5 10.439626 13.039433 15.395804 17.366456 18.758681 0.0004407116225397 1 3
6 10.416270 13.036369 15.403095 17.376688 18.767579 0.0000505346883797 1 3
7 10.408178 13.035815 15.405831 17.379981 18.770196 0.0000059183085803 1 3
8 10.405378 13.035815 15.406784 17.381016 18.771007 0.0000007309734651 1 2
9 10.404398 13.035815 15.407169 17.381377 18.771241 0.0000000918735889 1 2
10 10.404046 13.035851 15.407310 17.381493 18.771301 0.0000000000000000 1 2
P = 100
0 10.000000 10.000000 10.000000 10.000000 10.000000 1836.0501506003590748 0 0
1 17.833057 19.050570 20.189450 21.150398 21.776524 4.8985691329028089 1 7
2 15.207009 18.069357 20.605740 22.548004 23.569889 0.3897086827633425 1 6
3 14.408248 17.849890 20.795596 22.950904 23.995363 0.0331524073207579 1 5
4 14.161944 17.805297 20.868563 23.065798 24.098398 0.0029760163785664 1 4
5 14.085258 17.797975 20.894328 23.098440 24.123998 0.0002781506763527 1 4
6 14.061206 17.797529 20.903009 23.107717 24.130539 0.0000267855976024 1 4
7 14.053618 17.797915 20.905866 23.110376 24.132225 0.0000026365305624 1 3
8 14.051213 17.798180 20.906774 23.111128 24.132705 0.0000002639463250 1 3
9 14.050453 17.798289 20.907047 23.111345 24.132866 0.0000000281294894 1 2
10 14.050207 17.798347 20.907143 23.111409 24.132894 0.0000000000000000 1 2
P = 150
0 10.000000 10.000000 10.000000 10.000000 10.000000 2960.3391382693284868 0 0
1 27.861564 29.366477 30.558893 31.203707 31.009359 3.3981613265572332 1 9
2 24.632641 28.734751 31.626029 32.850552 32.156026 0.1804220099046543 1 6
3 23.846734 28.671683 31.919700 33.194867 32.367016 0.0102235564269385 1 6
4 23.653031 28.675783 31.996005 33.267441 32.407740 0.0006072128116255 1 6
5 23.604847 28.681014 32.015203 33.282960 32.415976 0.0000373064440210 1 5
6 23.592767 28.683251 32.019964 33.286283 32.417735 0.0000023469891688 1 4
7 23.589726 28.684002 32.021128 33.287038 32.418106 0.0000001503470039 1 4
8 23.588960 28.684201 32.021408 33.287226 32.418205 0.0000000105297725 1 2
9 23.588765 28.684288 32.021485 33.287257 32.418205 0.0000000000000000 1 2
P = 200
0 10.000000 10.000000 10.000000 10.000000 10.000000 3592.9209675026095283 0 0
1 38.595613 40.204251 41.080180 40.865307 39.254648 1.2868808680857118 1 10
2 36.344525 40.610616 42.510038 41.804641 38.730180 0.0417678220639321 1 8
3 35.896154 40.715637 42.751504 41.940932 38.695772 0.0015123953742686 1 7
4 35.807288 40.741280 42.793422 41.962130 38.695880 0.0000574531909636 1 6
5 35.789690 40.747242 42.800846 41.965643 38.696579 0.0000022363864192 1 5
6 35.786204 40.748594 42.802181 41.966242 38.696779 0.0000000888394029 1 3
7 35.785510 40.748872 42.802431 41.966359 38.696829 0.0000000036951777 1 2
8 35.785374 40.748937 42.802468 41.966379 38.696842 0.0000000001307215 1 2
9 35.785360 40.748951 42.802468 41.966379 38.696842 0.0000000000000000 1 1
Table 6.11: Relaxation method, Cournot oligopoly
6.3. NUMERICAL RESULTS 99
Newton’s method based on optimization reformulation
k xk1 x
k
2 x
k
3 x
k
4 x
k
5 ‖yα(x
k) − xk‖ InnerIt
P = 75
0 10.000000 10.000000 10.000000 10.000000 10.000000 2.6786204605270996 0
1 11.014554 13.105738 15.130358 16.959172 18.384208 0.0064462863037402 14
2 10.405898 13.034733 15.406324 17.381103 18.770855 0.0000000558757351 8
3 10.403849 13.035879 15.407384 17.381549 18.771333 0.0000000000004384 4
4 10.403859 13.035877 15.407382 17.381548 18.771332 0.0000000000000535 2
5 10.403863 13.035877 15.407382 17.381547 18.771332 0.0000000000000000 2
P = 100
0 10.000000 10.000000 10.000000 10.000000 10.000000 10.1939346917138209 0
1 15.431454 17.979156 20.324112 22.223645 23.334286 0.0330866131224870 14
2 14.055011 17.795377 20.905247 23.111411 24.132776 0.0000003126881686 10
3 14.050101 17.798372 20.907203 23.111424 24.132903 0.0000000000000851 4
4 14.050097 17.798373 20.907204 23.111424 24.132903 0.0000000000000000 2
P = 150
0 10.000000 10.000000 10.000000 10.000000 10.000000 40.1459577329819695 0
1 26.213388 28.810884 30.821384 31.844606 31.465176 0.1144536600658421 18
2 23.594821 28.681442 32.022050 33.289099 32.419084 0.0000005886128564 12
3 23.588697 28.684325 32.021503 33.287262 32.418211 0.0000000000000000 8
P = 200
0 10.000000 10.000000 10.000000 10.000000 10.000000 90.0826592112757680 0
1 38.411841 40.116481 41.037314 40.813982 39.081464 0.1305591329655253 20
2 35.788495 40.748594 42.804137 41.967241 38.697104 0.0000002088390430 15
3 35.785339 40.748957 42.802481 41.966382 38.696840 0.0000000000000000 8
Table 6.12: Newton’s method based on optimization reformulation, Cournot
oligopoly
Newton’s method based on fixed point formulation
k xk1 x
k
2 x
k
3 x
k
4 x
k
5 ‖yα(x
k) − xk‖ InnerIt
P = 75
0 10.000000 10.000000 10.000000 10.000000 10.000000 11.5863027186178531 0
1 10.727996 13.099087 15.304209 17.218265 18.650443 0.2667545777621945 7
2 10.403967 13.035818 15.407354 17.381555 18.771306 0.0000000000000000 4
P = 100
0 10.000000 10.000000 10.000000 10.000000 10.000000 22.5856681233344716 0
1 14.742243 17.889842 20.649363 22.776440 23.942112 0.5830566903965523 7
2 14.050339 17.798223 20.907147 23.111451 24.132840 0.0002091129151843 5
3 14.050091 17.798381 20.907187 23.111428 24.132914 0.0000000000000000 2
P = 150
0 10.000000 10.000000 10.000000 10.000000 10.000000 44.8079718213763485 0
1 24.666020 28.638950 31.530397 32.884666 32.279967 0.9504256360932131 9
2 23.588783 28.684250 32.021532 33.287256 32.418178 0.0000000000000000 7
P = 200
0 10.000000 10.000000 10.000000 10.000000 10.000000 67.1154610852267837 0
1 36.770882 40.503658 42.325655 41.769703 38.630101 0.9181893886394852 10
2 35.785304 40.748979 42.802485 41.966390 38.696842 0.0000305348293455 7
3 35.785335 40.748961 42.802484 41.966378 38.696841 0.0000000000000000 2
Table 6.13: Newton’s method based on fixed point formulation, Cournot oligopoly
100 CHAPTER 6. APPLICATIONS AND NUMERICAL RESULTS
Barzilai-Borwein method, termination forced
k xk1 x
k
2 x
k
3 Vαβ(x
k ) InnerIt
0 0.000000 0.000000 0.000000 3.0311662234453252 0
1 0.051406 0.035012 0.017841 3.0251475139957620 64
2 47.368574 32.250330 16.433010 0.0715357894412136 64
3 41.663602 26.906336 12.447389 0.0157110871790564 62
4 43.637895 28.816875 13.786874 0.0022529927912274 48
5 43.777938 28.987535 13.850859 0.0019860267947251 50
6 45.134373 30.619596 14.451977 0.0006981427206973 52
7 45.828495 31.384372 14.509053 0.0004955949266563 48
8 46.246198 31.699690 15.088737 0.0001743351052406 62
9 45.975878 31.537081 14.632948 0.0003304410778542 42
10 46.470766 31.998881 14.980723 0.0001725436483664 46
11 46.296809 31.831463 14.859763 0.0000254077725542 46
12 46.314363 31.846087 14.870673 0.0000230479308367 34
13 46.616490 32.102620 15.042368 0.0000009312260811 34
14 46.661529 32.243389 14.829838 0.0000090882841041 38
15 46.652374 32.142600 15.006356 0.0000003026499943 42
Relaxation method, termination forced
k xk1 x
k
2 x
k
3 x
k
4 x
k
5 Vα(x
k) InnerIt Stepsize
0 0.000000 0.000000 0.000000 0.000000 0.000000 52371.6094234325355501 0 0.000
1 80.000000 68.380846 25.181592 50.158649 21.708525 42744.2808159713604255 32 1.000
2 0.526463 1.097102 6.268441 0.000000 3.512643 42072.0794469271204434 27 1.000
3 80.000000 65.449158 24.363140 47.788213 20.926774 37689.0644626562789199 33 1.000
4 4.331442 2.622106 6.698038 0.000000 4.444352 37147.0035835723028868 27 1.000
5 80.000000 63.251739 23.745700 46.062377 20.353441 34157.4454841218612273 32 1.000
6 7.146937 3.735045 7.011569 0.246908 5.020995 33693.7588451127958251 25 1.000
7 80.000000 61.617456 23.286507 44.792163 19.930745 31658.2507151712889026 32 1.000
8 9.230623 4.554719 7.242499 0.871427 5.230787 31241.6921930087737564 25 1.000
9 80.000000 60.404915 22.945817 43.855209 19.617534 29870.5953501933618099 31 1.000
10 10.773381 5.160365 7.413115 1.334715 5.386468 29483.8909876110883488 26 1.000
11 80.000000 59.506641 22.693269 43.162108 19.385895 28581.4010472223126271 23 1.000
12 11.915649 5.608469 7.539364 1.677942 5.501838 28214.0366338659441681 26 1.000
13 80.000000 58.841307 22.506357 42.648948 19.214398 27645.7632874234222982 25 1.000
14 12.761360 5.940151 7.632825 1.932217 5.587226 27291.2047398758331838 25 1.000
15 79.958887 58.348674 22.367940 42.269055 19.087431 26941.2895882350239845 25 1.000
Table 6.14: Numerical results for the electricity market example I
6.3. NUMERICAL RESULTS 101
Relaxation method, σ = 1, termination forced
k xk1 x
k
2 x
k
3 x
k
4 x
k
5 Vα(x
k ) InnerIt Stepsize
0 0.000000 0.000000 0.000000 0.000000 0.000000 52371.6094234325355501 0 0.000
1 80.000000 68.380846 25.181592 50.158649 21.708525 42744.2808159713604255 32 1.000
2 40.263232 34.738974 15.725016 25.079324 12.610584 33.3390410686054182 27 0.500
3 43.284224 33.273137 15.315784 23.038547 12.644888 8.5324916592153031 26 1.000
4 45.189424 32.866192 15.202456 22.690663 12.533050 2.4301259557224184 21 1.000
5 45.729968 32.348829 15.057528 22.275656 12.395186 0.9249245813960247 24 1.000
6 46.399782 32.406838 15.074095 22.311452 12.407640 0.5504151289254504 24 1.000
7 46.332824 32.123566 14.994591 22.088695 12.333389 0.4542232682575659 22 1.000
8 46.696199 32.293364 15.042407 22.217135 12.376326 0.4263998492369000 18 1.000
9 46.589291 32.181398 15.010933 22.130224 12.347342 0.0040787136268533 18 0.500
10 46.625111 32.167024 15.006902 22.118069 12.343418 0.0010068732068689 15 1.000
11 46.644134 32.160958 15.005130 22.112926 12.341637 0.0002509667549085 21 1.000
12 46.652319 32.156890 15.004052 22.109556 12.340536 0.0000650451317720 20 1.000
13 46.657626 32.155917 15.003742 22.108712 12.340203 0.0000190872658195 18 1.000
14 46.659011 32.154411 15.003360 22.107535 12.339785 0.0000079338418535 18 1.000
15 46.660938 32.154646 15.003435 22.107580 12.339886 0.0000049292382130 12 1.000
Newton’s method based on optimization reformulation
k xk1 x
k
2 x
k
3 x
k
4 x
k
5 Vαβ(x
k) InnerIt
0 0.000000 0.000000 0.000000 0.000000 0.000000 285.8006379540747730 0
1 80.000067 23.536227 12.590189 15.420989 10.120063 9.8613630619447576 61
2 46.661637 32.153992 15.003106 22.107226 12.339598 0.0000000000159522 24
3 46.661622 32.154032 15.003126 22.107200 12.339582 0.0000000000000000 8
Newton’s method based on fixed point formulation
k xk1 x
k
2 x
k
3 x
k
4 x
k
5 ‖yα(x
k ) − xk‖ InnerIt
0 0.000000 0.000000 0.000000 0.000000 0.000000 123.1610182063412395 0
1 80.000000 23.536242 12.590164 15.421419 10.118248 22.3691037849047198 32
2 46.661622 32.154050 15.003109 22.107198 12.339584 0.0000000000000000 14
Table 6.15: Numerical results for the electricity market example I
102
C
H
A
PT
E
R
6.
A
PPL
IC
A
T
IO
N
S
A
N
D
N
U
M
E
R
IC
A
L
R
E
SU
LT
S
Barzilai-Borwein method
k x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 Vαβ(xk) InnerIt
0 117.00 356.00 176.00 328.00 123.00 101.00 300.00 176.00 328.00 176.00 0.0005441749813340 0
1 117.00 356.00 176.00 328.00 123.00 101.00 300.00 176.00 328.00 176.00 0.0005437172349780 28
2 117.66 356.62 176.19 328.49 123.74 101.70 300.35 176.22 328.49 176.21 0.0000008561955186 28
3 117.64 356.63 176.21 328.47 123.79 101.69 300.32 176.21 328.47 176.21 0.0000000069543561 18
4 117.64 356.63 176.21 328.47 123.79 101.69 300.32 176.21 328.47 176.21 0.0000000000565859 10
5 117.64 356.63 176.21 328.47 123.79 101.69 300.32 176.21 328.47 176.21 0.0000000000000020 8
6 117.64 356.63 176.21 328.47 123.79 101.69 300.32 176.21 328.47 176.21 0.0000000000000000 2
Newton’s method based on unconstrained optimization reformulation, α = 10−4, β = 5 · 10−4
k x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 Vαβ(xk) InnerIt
0 117.00 356.00 176.00 328.00 123.00 101.00 300.00 176.00 328.00 176.00 0.0005441749923731 0
1 117.70 356.66 176.18 328.52 123.77 101.74 300.36 176.23 328.51 176.23 0.0000030893444696 31
2 117.64 356.62 176.20 328.47 123.79 101.68 300.32 176.21 328.47 176.21 0.0000000293252044 18
3 117.64 356.63 176.21 328.47 123.79 101.69 300.32 176.21 328.47 176.21 0.0000000004279991 14
4 117.64 356.63 176.21 328.47 123.79 101.69 300.32 176.21 328.47 176.21 0.0000000000662262 12
5 117.64 356.63 176.21 328.47 123.79 101.69 300.32 176.21 328.47 176.21 -0.0000000000053261 6
6 117.64 356.63 176.21 328.47 123.79 101.69 300.32 176.21 328.47 176.21 0.0000000000000000 4
Relaxation method
k x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 Vα(xk) stepsize InnerIt
0 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 15298.0520053010204720 0 0
1 117.59 296.42 169.77 278.82 130.25 102.89 263.22 169.75 278.82 169.75 434.2703592396658792 1 29
2 117.67 353.94 176.43 328.72 123.58 101.70 304.72 176.42 328.72 176.42 0.9584084392662747 1 12
3 117.64 356.77 176.20 328.46 123.80 101.69 300.62 176.20 328.46 176.20 0.0047460645900628 1 10
4 117.64 356.64 176.21 328.47 123.79 101.69 300.30 176.21 328.47 176.21 0.0000138890875876 1 9
5 117.64 356.63 176.21 328.47 123.79 101.69 300.32 176.21 328.47 176.21 0.0000000912400164 1 6
6 117.64 356.63 176.21 328.47 123.79 101.69 300.32 176.21 328.47 176.21 0.0000000000000000 1 3
Newton’s method based on fixed point formulation
k x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 ‖yα(xk) − xk‖ InnerIt
0 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 380.8002984381889746 0
1 117.72 1076.69 197.54 1012.10 90.04 104.01 1144.65 209.96 1176.45 209.96 2031.1264201718749973 29
2 117.65 486.47 177.58 438.35 124.87 101.68 323.17 175.13 366.18 175.13 184.0779777475790979 19
3 117.64 357.02 176.22 329.46 123.92 101.69 300.27 176.08 327.29 176.08 1.5412694384380414 14
4 117.64 356.63 176.21 328.48 123.79 101.69 300.29 176.21 328.38 176.21 0.0966162993432361 8
5 117.64 356.63 176.21 328.47 123.79 101.69 300.32 176.21 328.47 176.21 0.0006802778139822 3
6 117.64 356.63 176.21 328.47 123.79 101.69 300.32 176.21 328.47 176.21 0.0000000000000000 2
Table 6.16: Numerical results for the electricity market example II
Bibliography
[1] E. A  K. G: Simplicial and continuation methods for ap-
proximating fixed points and solutions to systems of equations. SIAM Re-
view 22, 1980, pp. 28–85.
[2] A. A: Extra-proximal methods for solving two-person nonzero-sum
games. Mathematical Programming, Series B, published online 2007
[3] A. A: Equilibrium programming: Gradient methods Automation and
Remote Control 58, 1997, p. 1337–1347.
[4] A. A  S.J. F: Equilibrium programming using proximal-like
algorithms. Mathematical Programming 78, 1997, 29–41.
[5] K.J. A  G. D: Existence of an equilibrium for a competitive
economy. Econometrica 22, 1954, pp. 265–290.
[6] J.-P. A: Mathematical Methods of Game and Economic Theory. North-
Holland, Amsterdam, 1979.
[7] J.-P. A: Optima and Equilibria. An Introduction to Nonlinear Analysis.
Springer, Berlin, second edition 1998.
[8] J. B  J.M. B: Two point step size gradient method. IMA
Journal on Numerical Analysis 8, 1988, pp. 141–148.
[9] T. B̧: Relaxation techniques and asynchronous algorithms for on-line
computation of non-cooperative equilibria. Journal of Economic Dynamics
and Control 11, 1987, pp. 531–549.
[10] T. B̧  G.J. O: Dynamic Noncooperative Game Theory. Aca-
demic Press, New York, second edition 1995 (reprinted by SIAM, Philadel-
phia, 1999).
103
104 BIBLIOGRAPHY
[11] A. B: Points de Nash dans le cas de fonctionelles quadratiques
et jeux differentiels lineaires a N personnes. SIAM Journal on Control 12,
1974, pp. 460–499.
[12] S. B  J.B. K: Relaxation algorithms in find-
ing Nash equilibria. Economic working papers archives, 1997,
http://econwpa.wustl.edu/eprints/comp/papers/9707/9707002.abs
[13] E. B  W. O: From optimization and variational inequalities to
equilibrium problems. The Mathematics Student 63, 1994, pp.123–145.
[14] F.H. C: Optimization and Nonsmooth Analysis. John Wiley, New York,
1983 (reprinted by SIAM, Philadelphia, 1990).
[15] J. C, M. K,  J.B. K: Numerical solutions to Nash-
Cournot equilibria in coupled constraint electricity markets. IEEE Transac-
tions on Power Systems 19, 2004, pp. 195–206.
[16] R.W. C, J.-S. P,  R.E. S: The Linear Complementarity
Problem. Academic Press, Boston, 1992.
[17] S. D: An iterative scheme for variational inequalities. Mathematical
Programming 26, 1983, pp. 40–47.
[18] Y.H. D  L.Z. L: R-linear convergence of the Barzilai and Borwein
gradient method. IMA Journal on Numerical Analysis 22, 2002, pp. 1–10.
[19] E.  D: Stability and Perfection of Nash Equilibria. Springer, Berlin,
Germany, second edition 1996.
[20] G. D: A social equilibrium existence theorem. Proceedings of the Na-
tional Academy of Sciences 38 (10), 1952, pp. 886–893.
[21] S. D  D. P: Quasidifferentiability of optimal solutions in
parametric nonlinear optimization. Optimization 40, 1997, pp. 1-24.
[22] S. D  S. V: The generalized Jacobian of the optimal solution in
parametric optimization. Optimization 50, 2001, pp. 387–405.
[23] A. D  C. K: Nonsmooth optimization reformulations charac-
terizing all solutions of jointly convex generalized Nash equilibrium prob-
lems. Preprint 287, Institute of Mathematics, University of Würzburg,
Würzburg, April 2009.
BIBLIOGRAPHY 105
[24] L. D . . An oracle based method to compute a coupled equilib-
rium in a model of international climate policy. Computational Management
Science 5, 2008, p. 119–140.
[25] F. F  C. K: Generalized Nash equilibrium problems. 4OR
– A Quarterly Journal of Operations Research 5, 2007, pp. 173–210.
[26] F. F  C. K: Penalty methods for the solution of generalized
Nash equilibrium problems. Preprint 285, Institute of Mathematics, Univer-
sity of Würzburg, Würzburg, January 2009.
[27] F. F  J.-S. P: Finite-Dimensional Variational Inequalities and
Complementarity Problems, Volume I. Springer, New York, NY, 2003.
[28] F. F  J.-S. P: Finite-Dimensional Variational Inequalities and
Complementarity Problems, Volume II. Springer, New York, NY, 2003.
[29] F. F  J.-S. P: Exact penalty functions for generalized Nash
problems. appeared in: Large-Scale Nonlinear Optimization, Springer, 2006.
[30] F. F, A. F,  C. K: Regularity properties of a semis-
mooth reformulation of variational inequalities. SIAM Journal on Optimiza-
tion 8, 1998, pp. 850–869.
[31] F. F, A. F,  V. P: On generalized Nash games and
VIs. Technical Report, Department of Computer and System Sciences “A.
Ruberti”, Università di Roma “La Sapienza”, Rome, Italy, January 2006.
[32] F. F, A. F,  V. P: Generalized Nash equilibrium
problems and Newton methods. Mathematical Programming 117, 2009, pp.
163–194.
[33] A. F: Solution of monotone complementarity problems with locally
Lipschitzian mappings. Mathematical Programming 76, 1997, pp. 513–532.
[34] S.D. F  A.S. A: Equilibrium programming using proximal-like
algorithms. Mathematical Programming 78, 1997, pp. 29–41.
[35] R. F: On the Barzilai-Borwein method. Numerical Analysis Re-
port NA/207, Department of Mathematics, University of Dundee, Dundee,
United Kingdom, 2001.
[36] S.D. F Paths to constrained Nash equilibria. Applied Mathematics and
Optimization 27, 1993, pp. 275–289.
106 BIBLIOGRAPHY
[37] S.D. F  A. R́: Noncooperative convex games: Computing
equilibria by partial regularization. IIASA Working Paper 94-42, Laxen-
burg, Austria, May 1994.
[38] M. F: Equivalent differentiable optimization problems and descent
methods for asymmetric variational inequality problems. Mathematical Pro-
gramming 53, 1992, pp. 99–110.
[39] M. F: Restricted generalized Nash equilibria and controlled
penalty algorithm. Technical Report 2008-007, Department of Applied
Mathematics and Physics, Graduate School of Informatics, Kyoto Univer-
sity, July, 2008.
[40] M.S. G: Inverse and implicit function theorems for H-differentiable
and semismooth functions. Optimization Methods and Software 19, 2004,
pp. 443–461.
[41] L. G  M. S: Nonmonotone globalization techniques for
the Barzilai-Borwein gradient method. Computational Optimization and Ap-
plications 23, 2002, pp. 143–169.
[42] G. G̈  J.-S. P: Approximations of Nash equilibria. Mathematical
Programming 117, 2009, pp. 223–253.
[43] P.T. H: Generalized Nash games and quasivariational inequalities.
European Journal of Operations Research 54, 1991, pp. 81–94.
[44] P.T. Harker and J.-S. Pang: Finite-Dimensional Variational Inequality and
Nonlinear Complementarity Problems: A Survey of Theory, Algorithms and
Applications. Mathematical Programming 48, 1990, pp. 161–220.
[45] A. H  J.B. K: Optimal charges on river effluent from
lumped and distributed sources. Environmental Modeling and Assessment
2, 1997, pp. 93–106.
[46] A.  H  C. K: Optimization reformulations of the
generalized Nash equilibrium problem using Nikaido-Isoda-type functions.
Computational Optimization and Applications, available online under DOI
10.1007/s10589-007-9145-6.
[47] A.  H  C. K: SC1 optimization reformulations of the
generalized Nash equilibrium problem. Optimization Methods and Software,
Volume 23 Issue 6, 2008.
BIBLIOGRAPHY 107
[48] A.  H  C. K: Relaxation methods for generalized
Nash equilibrium problems with inexact line search. Journal of Optimization
Theory and Applications, available online under DOI 10.1007/s10957-009-
9553-0.
[49] A.  H, C. K,  M. F: Newton’s method for
computing a normalized equilibrium in the generalized Nash game through
fixed point formulation. Preprint 286, Institute of Mathematics, University
of Würzburg, Würzburg, January 2009.
[50] J.-B. H-U  C. L́: Convex Analysis and Minimiza-
tion Algorithms I. Springer, Berlin, Germany, 1993.
[51] J.-B. H-U, J.-J. S, V.H. N: Generalized Hessian
matrix and second-order optimality conditions for problems with C1,1 data.
Applied Mathematics and Optimization 11, 1984, pp. 43–56.
[52] B.F. H: Linear complementarity models of Nash-Cournot competition
in bilateral and POOLCO power markets. IEEE Transactions on Power Sys-
tems 16, 2001, pp. 194–202.
[53] W.W. H: Point-to-set maps in mathematical programming. SIAM Re-
view 15, 1973, pp. 591–603.
[54] R. J: Directional derivative of the marginal function in nonlinear pro-
gramming. Mathematical Programming Study 21, 1984, pp. 110–126.
[55] C. K  M. F: Theoretical and numerical investigation of
the D-gap function for box constrained variational inequalities. Mathemati-
cal Programming 83, 1998, pp. 55–87.
[56] A. K, S. L,  V. B: Game-theoretic analysis of
internet switching with selfish users. Lecture Notes in Computer Science
3828, 2005, pp. 236–245.
[57] M. K  S. S: Extension of Newton and Quasi-Newton methods
to systems of PC1 equations. Journal of the Operations Research Society of
Japan 29, 1986, pp. 352–372.
[58] J.B. K: An Open-Loop Nash Equilibrium in an Environmental
Game with Coupled Constraints. Proceedings of the Ninth International
Symposium on Dynamic Games and Applications, December 18-21, 2000,
Adelaide, pp. 325-339.
108 BIBLIOGRAPHY
[59] J.B. K: Coupled constraint Nash equilibria in environmental
games. Resource and Energy Economics 27, 2005, pp. 157–181.
[60] J.B. K: Numerical solutions to coupled-constraint (or generalised
Nash) equilibrium problems. Computational Management Science 4, 2007,
p. 183–204.
[61] J.B. K  S. U: Relaxation algorithms to find Nash equilib-
ria with economic applications. Environmental Modeling and Assessment 5,
2000, pp. 63–73.
[62] B. K: Newton’s method for non-differentiable functions. In J. G
 . (eds.): Advances in Mathematical Optimization. Akademie-Verlag,
Berlin, 1988, pp. 114–125.
[63] B. K: Newton’s method based on generalized derivatives for nons-
mooth functions: Convergence analysis. In W. O  D. P
(eds.): Advances in Optimization. Lecture Notes in Economics and Mathe-
matical Systems 382, Springer-Verlag, Berlin, 1992, pp. 171–194.
[64] S. L  T. B̧: Distributed algorithms for the computation of noncoop-
erative equilibria. Automatica 23, 1987, pp. 523–533.
[65] J. L: Strong stability in variational inequalities. SIAM Journal on Control
and Optimization 33, 1995, pp. 725–749.
[66] G. M: Gap functions for equilibrium problems. Journal of Global
Optimization 27, 2003, pp. 411–426.
[67] L.W. MK: On the existence of general equilibrium for a competetive
market. Econometrica 27, 1959, pp. 54–71.
[68] R. M: Semismooth and semiconvex functions in constrained optimiza-
tion. SIAM Journal on Control and Optimization 15, 1977, pp. 957–972.
[69] F. M, H.D. S  A.B. S: A mathematical programming
approach for determining oligopolistic market equilibrium Mathematical
Programming 24, 1982, pp. 92–100.
[70] N. N .. (.) Algorithmic Game Theory. Cambridge University
Press, Cambridge, 2007.
[71] K. N, P. T M. F: Parametrized variational inequal-
ity approaches to generalized Nash equilibrium problems with shared con-
straints. Technical Report 2008-011, Department of Applied Mathematics
and Physics, Kyoto University, October 2008.
BIBLIOGRAPHY 109
[72] J. N: Non-cooperative games. Annals of Mathematics 54, 1951, pp. 286–
295.
[73] H. N  K. I: Note on noncooperative convex games. Pacific
Journal of Mathematics 5, 1955, pp. 807–815.
[74] J.M. O W.C. R: Iterative Slution of Nonlinear Equations
in Several Variables. Academic Press, New York, 1970.
[75] J. O, M. K,  J. Z: Nonsmooth Approach to Optimization
Problems with Equilibrium Constraints. Kluwer Academic Press, Dordrecht,
1998.
[76] J. O  J. Z: A numerical approach to optimization prob-
lems with variational inequality constraints. Mathematical Programming 68,
1995, pp. 105–130.
[77] J. O  J. Z: A Newton method for a class of quasi-variational
inequalities. Computational Optimization and Applications 4, 1995, pp. 5–
21.
[78] J.-S. P  M. F: Quasi-variational inequalities, generalized
Nash equilibria, and multi-leader-follower games. Computational Manage-
ment Science 2, 2005, pp. 21–56.
[79] J.-S. P D. R: Piecewise smoothness, local invertibility, and para-
metric analysis of normal maps. Mathematics of Operations Research 21,
1996, pp. 401–426.
[80] J.-S. P  J. S: Nash equilibria with piecewise quadratic costs. Pacific
Journal of Optimization 2, 2006, pp. 679–692.
[81] J.-S. P  L. Q: Nonsmooth equations: motivation and algorithms.
SIAM Journal on Optimization 3, 1993, pp. 443–465.
[82] J.-M. P: Equivalence of variational inequality problems to unconstrained
optimization. Mathematical Programming 78, 1997, pp. 347–356.
[83] J.-S. P, D. S,  J. S: Semismooth homeomorphisms and strong
stability of semidefinite and Lorentz complementarity problems. Mathemat-
ics of Operations Research 28, 2003, pp. 39–63.
[84] L. Q: Convergence analysis of some algorithms for solving nonsmooth
equations. Mathematics of Operations Research 18, 1993, pp. 227–244.
110 BIBLIOGRAPHY
[85] L. Q  J. S: A nonsmooth version of Newton’s method. Mathematical
Programming 58, 1993, pp. 353–367.
[86] H. R: Über partielle und totale Differenzierbarkeit I. Mathemati-
cal Annals 89, 1919, pp. 340–359.
[87] M. R: On the Barzilai and Borwein choice of the steplength for the
gradient method. IMA Journal on Numerical Analysis 13, 1993, pp. 321–
326.
[88] M. R: The Barzilai and Borwein gradient method for the large scale
unconstrained minimization problem. SIAM Journal on Optimization 7,
1997, pp. 26–33.
[89] S.M. R: Strongly regular generalized equations. Mathematics of Op-
erations Research 5, 1980, pp. 43–62.
[90] R.T. R: Convex Analysis. Princeton University Press, Princeton,
NJ, 1970.
[91] R.T. R  R.J.-B. W: Variational Analysis. Springer, Berlin,
2004.
[92] J.B. R: Existence and uniqueness of equilibrium points for concave N-
person games. Econometrica 33, 1965, pp. 520–534.
[93] T. S, A. G  V. C Mixed-Integer programming meth-
ods for finding Nash equilibria. Proceedings of the national conference on
artificial intelligence 20, part 2, 2005, pages 495-501.
[94] A. S: On concepts of directional differentiability. Journal of Optimiza-
tion Theory and Applications 66, 1990, pp. 477–487.
[95] D. S: A further result on an implicit function theorem for locally Lipschitz
functions. Operations Research Letters 28, 2001, pp. 193–198.
[96] D. S, M. F,  L. Q: A computable generalized Hessian of the
D-gap function and Newton-type methods for variational inequality prob-
lems. Complementarity and Variational Problems: State of the Art, M.C.
Ferris and J.-S. Pang (eds.), SIAM , Philadelphia , 1997, pp. 452-472.
[97] K. T, M. F,  T. I: A globally convergent Newton
method for solving strongly monotone variational inequalities. Mathemat-
ical Programming 58, 1993, pp. 369–383.
BIBLIOGRAPHY 111
[98] S. U  R.Y. R: On relaxation algorithms in computation
of noncooperative equilibria. IEEE Transactions on Automatic Control 39,
1994, pp. 1263–1267.
[99] N. Y, K. T,  M. F: Unconstrained optimization re-
formulations of variational inequality problems. Journal of Optimization
Theory and Applications 92, 1997, pp. 439–456.
[100] L. Z  J. H: Unconstrained optimization reformulation of equilib-
rium problems. Technical Report, Institute of Applied Mathematics, Chinese
Academy of Sciences, Beijing, China, 2006.

