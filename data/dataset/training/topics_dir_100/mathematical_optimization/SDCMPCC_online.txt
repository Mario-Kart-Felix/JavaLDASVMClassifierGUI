Math. Program., Ser. A
DOI 10.1007/s10107-013-0735-z
FULL LENGTH PAPER
First order optimality conditions for mathematical
programs with semidefinite cone complementarity
constraints
Chao Ding ¬∑ Defeng Sun ¬∑ Jane J. Ye
Received: 15 November 2010 / Accepted: 30 November 2013
¬© Springer-Verlag Berlin Heidelberg and Mathematical Optimization Society 2013
Abstract In this paper we consider a mathematical program with semidefinite cone
complementarity constraints (SDCMPCC). Such a problem is a matrix analogue of
the mathematical program with (vector) complementarity constraints (MPCC) and
includes MPCC as a special case. We first derive explicit formulas for the proximal
and limiting normal cone of the graph of the normal cone to the positive semidefinite
cone. Using these formulas and classical nonsmooth first order necessary optimality
conditions we derive explicit expressions for the strong-, Mordukhovich- and Clarke-
(S-, M- and C-)stationary conditions. Moreover we give constraint qualifications under
D. Sun‚Äôs research is supported in part by Academic Research Fund under grant R-146-000-149-112.
The research of J. J. Ye was partially supported by NSERC.
Part of this work was done while C. Ding was with Department of Mathematics, National University of
Singapore. The research of this author is supported by the National Science Foundation for Distinguished
Young Scholars of China (Grant No. 11301515).
C. Ding
National Center for Mathematics and Interdisciplinary Sciences,
Chinese Academy of Sciences, Beijing, People‚Äôs Republic of China
e-mail: dingchao@amss.ac.cn
D. Sun
Department of Mathematics and Risk Management Institute,
National University of Singapore, 10 Lower Kent Ridge Road, Singapore 119076,
Republic of Singapore
e-mail: matsundf@nus.edu.sg
J. J. Ye (B)
Department of Mathematics and Statistics, University of Victoria,
Victoria, BC V8W 3R4, Canada
e-mail: janeye@uvic.ca
123
C. Ding et al.
which a local solution of SDCMPCC is a S-, M- and C-stationary point. Moreover
we show that applying these results to MPCC produces new and weaker necessary
optimality conditions.
Keywords Mathematical program with semidefinite cone complementarity
constraints ¬∑ Necessary optimality conditions ¬∑ Constraint qualifications ¬∑ S-stationary
conditions ¬∑ M-stationary conditions ¬∑ C-stationary conditions
Mathematics Subject Classification 49K10 ¬∑ 49J52 ¬∑ 90C30 ¬∑ 90C22 ¬∑ 90C33
1 Introduction
Let Sn be the linear space of all n√ón real symmetric matrices equipped with the usual
Frobenius inner product „Äà¬∑, ¬∑„Äâ and its induced norm ‚Äñ ¬∑ ‚Äñ. For the given positive integer
n, let Sn+ (Sn‚àí) be the closed convex cone of all n √ó n positive (negative) semidefinite
matrices in Sn . Let ni , i = 1, . . . , m be given positive integers. The mathematical pro-
gram with (semidefinite) cone complementarity constraints (MPSCCC or SDCMPCC)
is defined as follows
(SDCMPCC) min f (z)
s.t. h(z) = 0,
g(z) Q 0,
Sni+  Gi (z) ‚ä• Hi (z) ‚àà Sni‚àí , i = 1, . . . , m, (1)
where Z and H are two finite dimensional real Euclidean spaces; f : Z ‚Üí 
, h :
Z ‚Üí 
p, g : Z ‚Üí H and Gi : Z ‚Üí Sni , Hi : Z ‚Üí Sni , i = 1, . . . , m are
continuously differentiable mappings; Q ‚äÜ H is a closed convex symmetric cone
with a nonempty interior (such as the nonnegative orthant, the second order cone, or
the cone of symmetric and positive semidefinite real matrices); for each i ‚àà {1, . . . , m},
‚ÄúGi (z) ‚ä• Hi (z)‚Äù means that the matrices Gi (z) and Hi (z) are perpendicular to each
other, i.e., „ÄàGi (z), Hi (z)„Äâ = 0; ‚Äúg(z) Q 0‚Äù means that ‚àíg(z) ‚àà Q. In particular, for
a given symmetric matrix Z ‚àà Sn , we use Z  0 and Z  0 to denote Z ‚àà Sn‚àí and
Z ‚àà Sn+, respectively.
Our research on SDCMPCC is motivated by a number of important applications in
diverse areas. Below we describe some of them.
A rank constrained nearest correlation matrix problem. A matrix is said to be a
correlation matrix if it is real symmetric positive semidefinite and its diagonal entries
are all ones. Let C be a given matrix in Sn . Let 1 ‚â§ r ‚â§ n be a given integer. The
rank constrained nearest correlation matrix problem takes the following form
min fC (X)
s.t. Xii = 1, i = 1, . . . , n,
X ‚àà Sn+,
rank(X) ‚â§ r,
(2)
123
First order optimality conditions
where fC : Sn ‚Üí 
 is a given cost function that measures the closeness of X to
a targeted matrix C . For instance, fC can be simply chosen as 12‚ÄñX ‚àí C‚Äñ2 in some
applications. Problem (2) has many important applications in quantitative finance and
engineering, e.g., [7,8,24,28,48,56,64] and the references therein. We may easily cast
(2) in a SDCMPCC form
min
X,U
fC (X)
s.t. Xii = 1, i = 1, . . . , n,
„ÄàI, U „Äâ = r, U ‚àà Sn+,
Sn+  X ‚ä• (U ‚àí I ) ‚àà Sn‚àí.
(3)
We refer to [23] for details on the equivalence of these two formulations. More
SDCMPCC examples concerning the matrix rank minimization problems can be found
in [5,65].
A bilinear matrix inequality (BMI) problem. Bilinear matrix inequalities arise fre-
quently from pooling and blending problems [54], system analysis and robust design
[18,46,53]. In particular, many problems including robustness analysis [11,37] and
robust process design problems [45,54,55] can be stated as the following optimization
problem with the BMI constraint
min bT u + dT v
s.t. D +
m‚àë
i=1
ui A
(i) +
n‚àë
j=1
v j B
( j) +
m‚àë
i=1
n‚àë
j=1
uiv j C
(i j)  0, (4)
where u ‚àà 
m and v ‚àà 
n are decision variables, b ‚àà 
m and d ‚àà 
n are given,
and D, A(i), B( j), and C (i j), i = 1, . . . , m, j = 1, . . . , n are given p by p symmetric
matrices. Denote x := (u, v) ‚àà 
m+n, c := (b, d) ‚àà 
m+n . Then, the optimization
problem (4) can be rewritten as the following optimization problem [15]
min cT x
s.t. D +
m+n‚àë
i=1
xi A
(i) +
m+n‚àë
i, j=1
Wi j C
(i j)  0,
W = xxT ,
(5)
where A
(i) = (A(1), . . . , A(m), B(1), . . . , B(n)) and for each i, j ‚àà {1, . . . , m} √ó
{1, . . . , n}, C (i j) = C (i j) if i ‚àà {1, . . . , m} and j ‚àà {1, . . . , n} and C (i j) = 0 other-
wise. It is easy to see that the second constraint in the problem (5) can be replaced by
the following constraints [15]
Z =
[
W x
xT 1
]
 0 and rank(Z) ‚â§ 1.
Therefore, similarly as the previous example, we know that the problem (5) can be
cast in the following SDCMPCC form
123
C. Ding et al.
min cT x
s.t. D +
m+n‚àë
i=1
xi A
(i) +
m+n‚àë
i, j=1
Wi j C
(i j)  0,
„ÄàI, U „Äâ = 1, U ‚àà Sn+,
Sn+ 
[
W x
xT 1
]
‚ä• (U ‚àí I ) ‚àà Sn‚àí.
A single-firm model in electric power market with uncertain data. The electric
power market is an oligopolistic market, which means that there are several dominant
firms in this market. Each dominant firm has some number of generators, which submit
the hourly bids to an independent system operator (ISO). The firm can be thought of as
a leader of a Stackelberg game, which calculates its bids based on what it anticipates
the followers would do, which is the ISO in this case.
Without the uncertain data, it is well-known that this single-firm problem in the
electric power market can be modeled as a bilevel programming problem [21]. In
this bilevel programming model, the upper-level problem is the single firm‚Äôs profit
maximization problem and the lower-level problem is the ISO‚Äôs single spatial price
equilibrium problem. In practice it is more realistic to assume that the lower-level
problem involves uncertainty. For instance, the coefficients of the marginal demand
functions, which are decided by the information of consumers, usually contain uncer-
tainty. Therefore, it makes sense to consider a robust bilevel programming problem
where for a fixed upper-level decision variable x , the lower-level problem is replaced
by its robust counterpart:
Px : min
y
{ f (x, y, Œ∂ ) : g(x, y, Œ∂ ) ‚â§ 0 ‚àÄ Œ∂ ‚àà U},
where U is some ‚Äúuncertainty set‚Äù in the space of the data. It is well-known (see
[2,3]) that if the uncertainty set U is given by a system of linear matrix inequalities,
then the deterministic counterpart of the problem Px is a semidefinite program. If
this semidefinite programming problem can be equivalently replaced by its Karush‚Äì
Kuhn‚ÄìTucker (KKT) condition, then it yields a SDCMPCC problem.
SDCMPCC is a broad framework, which includes the mathematical program with
(vector) complementarity constraints (MPCC) as a special case. In fact, if Q ‚â° 
q+, the
nonnegative orthant in H ‚â° 
q and ni ‚â° 1, i = 1, . . . , m, the SDCMPCC becomes
the following MPCC problem
(MPCC) min f (z)
s.t. h(z) = 0,
g(z) ‚â§ 0,

+  Gi (z) ‚ä• Hi (z) ‚àà 
‚àí, i = 1, . . . , m. (6)
Denote G(z) = (G1(z), . . . , Gm(z))T : Z ‚Üí 
m and H(z) = (H1(z), . . . , Hm(z))T :
Z ‚Üí 
m . Then the constraints (6) can be replaced by the following standard vector
complementarity constraint
123
First order optimality conditions

m+  G(z) ‚ä• H(z) ‚àà 
m‚àí.
MPCC is a class of very important problems since they arise frequently in applica-
tions where the constraints come from equilibrium systems and hence is also known
as the mathematical program with equilibrium constraints (MPEC); see [26,34] for
references. One of the main sources of MPCCs comes from bilevel programming
problems which have numerous applications; see [12].
In this paper, we study first order necessary optimality conditions for SDCMPCC.
For simplicity, we consider the SDCMPCC problem which has only one semidefinite
cone complementarity constraint. However all results can be generalized to the case
of more than one semidefinite cone complementarity constraints in a straightforward
manner.
MPCC is notoriously known as a difficult class of optimization problems since if
one treats a MPCC as a standard nonlinear programming problem, then Mangasarian
Fromovitz constraint qualification (MFCQ) fails to hold at each feasible point of the
feasible region; see [63, Proposition 1.1]. One of the implications of the failure of
MFCQ is that the classical KKT condition may not hold at a local optimizer. The
classical KKT condition for MPCC is known to be equivalent to the strong stationary
condition (S-stationary condition). Consequently weaker stationary conditions such
as the Mordukhovich stationary condition (M-stationary condition) and the Clarke
stationary condition (C-stationary condition) have been proposed and the constraint
qualifications under which a local minimizer is a M-(C-)stationary point have been
studied; see e.g., [47,61] for a detailed discussion.
The same difficulties exist for SDCMPCC. The cone complementarity constraint
(1) amounts to the following convex cone constraints:
„ÄàG(z), H(z)„Äâ = 0, G(z) ‚àà Sn+, H(z) ‚àà Sn‚àí.
For an optimization problem with convex cone constraints, the usual constraint qual-
ification is Robinson‚Äôs CQ. In this paper we show that if we consider SDCMPCC as
an optimization problem with cone constraints, Robinson‚Äôs CQ fails to hold at each
feasible point of the SDCMPCC. Hence SDCMPCC is also a difficult class of opti-
mization problems. One of the implications of the failure of Robinson‚Äôs CQ is that
the classical KKT condition may not hold at a local optimizer. It is obvious that the
complementarity constraint (1) can be reformulated as a nonconvex cone constraint:
(G(z), H(z)) ‚àà gph NSn+ ,
where gph NSn+ is the graph of the normal cone to the positive semidefinite cone.
We first derive the exact expressions for the proximal and limiting normal cone of
gph NSn+ . As in the vector case, the first order necessary optimality condition based
on the proximal and limiting normal cones are called S- and M-stationary condition
respectively. To derive the C-stationary condition, we reformulate the complementarity
constraint (1) as a nonsmooth equation constraint:
G(z) ‚àí Sn+(G(z) + H(z)) = 0,
123
C. Ding et al.
where Sn+ denotes the metric projection to the positive semidefinite cone. As in
the vector case, based on this reformulation and the classical nonsmooth necessary
optimality condition we derive the necessary optimality condition in terms of the
C-stationary condition. We also show that the classical KKT condition implies the
S-stationary condition but not vice versa.
To the best of our knowledge, this is the first time explicit expressions for S-, M-
and C-stationary conditions for SDCMPCC are given. In [58], a smoothing algorithm
is given for mathematical program with symmetric cone complementarity constraints
and the convergence to C-stationary points is shown. Although the problem studied in
[58] may include our problem as a special case, there is no explicit expression for C-
stationary condition given. It is also the first time precise formulas for the proximal and
limiting normal cone of gph NSn+ are developed. In particular the precise expression for
the limiting normal cone of gph NSn+ is not only important for deriving the M-stationary
condition but also useful in the so-called Mordukhovich criterion for characterizing
the Aubin continuity [44, Theorem 9.40] of a perturbed generalized equation such as:
S(x) := {z : x ‚àà H(z) + NSn+(z)}.
We organize our paper as following. In Sect. 2 we introduce the preliminaries and
preliminary results on the background in variational analysis, first order conditions
for a general problem and background in variational analysis in matrix spaces. In
Sect. 3, we give the precise expressions for the proximal and limiting normal cones of
the graph of the normal cone NSn+ . In Sect. 4, we show that if SDCMPCC is considered
as an optimization problem with convex cone constraints then Robinson‚Äôs CQ fails at
every feasible solution of SDCMPCC and derive the classical KKT condition under
the Clarke calmness condition. Explicit expressions for S-stationary conditions are
given in Sect. 5 where it is also shown that the classical KKT condition implies the
S-stationary condition. Explicit expressions for M- and C-stationary conditions are
given in Sects. 6 and 7 respectively. In Sect. 8 we reformulate MPCC as a particular
case of SDCMPCC by taking the vector complementarity functions as matrices with
diagonal values. Comparisons between the S-, M- and C-stationary points are made.
We show that the S-stationary condition for the two formulations are equivalent while
the M- and C-stationary conditions for SDCMPCC may be weaker.
2 Preliminaries and preliminary results
We first give the following notation that will be used throughout the paper. Let X and
Y be finite dimensional spaces. We denote by ‚Äñ¬∑‚Äñ the Euclidean norm in X . We denote
by B(x, Œ¥) := {y ‚àà X | ‚Äñy ‚àí x‚Äñ < Œ¥} the open ball centered at x with radius Œ¥ > 0
and B the open unit ball centered at 0. Given a set S ‚äÜ X and a point x ‚àà X , the
distance from x to S is denoted by
dist(x, S) := inf{‚Äñy ‚àí x‚Äñ | y ‚àà S}.
Given a linear operator A : X ‚Üí Y,A‚àó denotes the adjoint of the linear operator A.
Given a matrix A, we denote by AT the transpose of the matrix A. For a mapping
123
First order optimality conditions
F : X ‚Üí Y and x ‚àà X, F ‚Ä≤(x) stands for the classical derivative or the Jacobian of
F at x and ‚àáF(x) the adjoint of the Jacobian. We denote by F ‚Ä≤(x; d) the directional
derivative of F at x in direction d. For a set-valued mapping  : X ‚áí Y , we denote
by gph the graph of , i.e., gph  := {(z, v) ‚àà X √ó Y | v ‚àà (z)}. For a set C,
we denote by int C, clC, coC its interior, closure and convex hull respectively. For a
function g : X ‚Üí 
, we denote g+(x) := max{0, g(x)} and if it is vector-valued
then the maximum is taken componentwise.
‚Ä¢ Let On be the set of all n √ó n orthogonal matrices.
‚Ä¢ For any Z ‚àà 
m√ón , we denote by Zi j the (i, j)th entry of Z .
‚Ä¢ For any Z ‚àà 
m√ón and a given index set J ‚äÜ {1, . . . , n}, we use ZJ to denote the
sub-matrix of Z obtained by removing all the columns of Z not in J . In particular,
we use Z j to represent the j-th column of Z , j = 1, . . . , n.
‚Ä¢ Let I ‚äÜ {1, . . . , m} and J ‚äÜ {1, . . . , n} be two index sets. For any Z ‚àà 
m√ón , we
use ZIJ to denote the |I|√ó |J | sub-matrix of Z obtained by removing all the rows
of Z not in I and all the columns of Z not in J .
‚Ä¢ We use ‚Äú‚ó¶‚Äù to denote the Hardamard product between matrices, i.e., for any two
matrices A and B in
m√ón the (i, j)th entry of Z := A‚ó¶B ‚àà 
m√ón is Zi j = Ai j Bi j .
‚Ä¢ Let diag(¬∑) : 
m ‚Üí Sm be a linear mapping defined by for any x ‚àà 
n , diag(x)
denotes the diagonal matrix whose i th diagonal entry is xi , i = 1, . . . , n.
2.1 Background in variational analysis
In this subsection we summarize some background materials on variational analysis
which will be used throughout the paper. Detailed discussions on these subjects can
be found in [9,10,31,32,44]. In this subsection X is a finite dimensional space.
Definition 2.1 (see e.g., [10, Proposition 1.5(a)] or [44, page 213]) Let  be a non-
empty subset of X . Given xÃÑ ‚àà cl , the following convex cone
NœÄ(xÃÑ) := {Œ∂ ‚àà X : ‚àÉ M > 0, such that „ÄàŒ∂, x ‚àí xÃÑ„Äâ ‚â§ M‚Äñx ‚àí xÃÑ‚Äñ2 ‚àÄ x ‚àà } (7)
is called the proximal normal cone to set  at point xÃÑ .
Definition 2.2 (see e.g., [10, page 62 and Theorem 6.1(b)]) Let  be a nonempty
subset of X . Given xÃÑ ‚àà cl , the following closed cone
N(xÃÑ) :=
{
lim
i‚Üí‚àû Œ∂i : Œ∂i ‚àà N
œÄ
(xi ), xi ‚Üí xÃÑ, xi ‚àà 
}
(8)
is called the limiting normal cone (also known as Mordukhovich normal cone or basic
normal cone) to set  at point xÃÑ and the closed convex hull of the limiting normal
cone
N c(xÃÑ) := clco N(xÃÑ).
is the Clarke normal cone [9] to set  at point xÃÑ .
123
C. Ding et al.
Alternatively in a finite dimensional space, the limiting normal cone can be also
defined by the Fr√©chet (also called regular) normal cone instead of the proximal
normal cone, see [31, Definition 1.1 (ii)]. In the case when  is convex, the prox-
imal normal cone, the limiting normal cone and the Clarke normal cone coincide
with the normal cone in the sense of the convex analysis [43], i.e., N(xÃÑ) :=
{Œ∂ ‚àà X : „ÄàŒ∂, x ‚àí xÃÑ„Äâ ‚â§ 0 ‚àÄ x ‚àà } .
Definition 2.3 Let f : X ‚Üí 
‚à™{+‚àû} be a lower semicontinuous function and finite
at xÃÑ ‚àà X . The proximal subdifferential ([44, Definition 8.45]) of f at xÃÑ is defined as
‚àÇœÄ f (xÃÑ) := {Œ∂ ‚àà X : ‚àÉ œÉ >0, Œ¥>0 such that f (x) ‚â• f (xÃÑ) + „ÄàŒ∂, x ‚àí xÃÑ„Äâ‚àíœÉ‚Äñx‚àí xÃÑ‚Äñ2
‚àÄ x ‚àà B(xÃÑ, Œ¥)}
and the limiting (Mordukhovich or basic [31]) subdifferential of f at xÃÑ is defined as
‚àÇ f (xÃÑ) :=
{
lim
k‚Üí‚àû Œ∂k : Œ∂k ‚àà ‚àÇ
œÄ f (xk), xk ‚Üí xÃÑ, f (xk) ‚Üí f (xÃÑ)
}
.
When f is Lipschitz continuous near xÃÑ ,
‚àÇc f (xÃÑ) := co ‚àÇ f (xÃÑ)
is the Clarke subdifferential [9] of f at xÃÑ .
Note that in a finite dimensional space, alternatively the limiting subgradient can
be also constructed via Fr√©chet subgradients (also known as regular subgradients), see
[31, Theorem 1.89]. The equivalence of the two definitions is well-known, see the
commentary by Rockafellar and Wets [44, page 345]. In the case when f is convex
and locally Lipschitz, the proximal subdifferential, the limiting subdifferential and
the Clarke subdifferential coincide with the subdifferential in the sense of convex
analysis [43]. In the case when f is strictly differentiable, the limiting subdifferenial
and the Clarke subdifferential reduce to the classical gradient of f at xÃÑ , i.e., ‚àÇc f (xÃÑ) =
‚àÇ f (xÃÑ) = {‚àá f (xÃÑ)}.
2.2 First order optimality conditions for a general problem
In this subsection we discuss constraint qualifications and first order necessary opti-
mality conditions for the following general optimization problem:
(G P) min f (z)
s.t. h(z) = 0,
g(z) ‚â§ 0,
G(z) ‚àà K ,
where Y, Z are finite dimensional spaces, K is a closed subset of Y, f : Z ‚Üí 
, h :
Z ‚Üí 
p, g : Z ‚Üí 
q and G : Z ‚Üí Y are locally Lipschitz mappings.
123
First order optimality conditions
We denote the set of feasible solutions for (GP) by F and the perturbed feasible
region by
F(r, s, P) := {z ‚àà Z : h(z) + r = 0, g(z) + s ‚â§ 0, G(z) + P ‚àà K }. (9)
Then F(0, 0, 0) = F . The following definition is the Clarke calmness [9] adapted to
our setting.
Definition 2.4 (Clarke calmness) We say that problem (GP) is (Clarke) calm at a local
optimal solution zÃÑ if there exist positive Œµ and Œº such that, for all (r, s, P) in ŒµB, for
all z ‚àà (zÃÑ + ŒµB) ‚à© F(r, s, P), one has
f (z) ‚àí f (zÃÑ) + Œº‚Äñ(r, s, P)‚Äñ ‚â• 0.
The following equivalence is obvious.
Proposition 2.1 Problem (GP) is Clarke calm at a local optimal solution zÃÑ if and only
if (zÃÑ, G(zÃÑ)) is a local optimal solution to the penalized problem for some Œº > 0:
(GP)Œº min
z,X
f (z) + Œº(‚Äñh(z)‚Äñ + ‚Äñmax{g(z), 0}‚Äñ + ‚ÄñG(z) ‚àí X‚Äñ)
s.t. X ‚àà K .
Theorem 2.1 Let zÃÑ be a local optimal solution of (GP). Suppose that (GP) is Clarke
calm at zÃÑ. Then there exist Œªh ‚àà 
p, Œªg ‚àà 
q and G ‚àà Sn such that
0 ‚àà ‚àÇ f (zÃÑ) + ‚àÇ„Äàh, Œªh„Äâ(zÃÑ) + ‚àÇ„Äàg, Œªg„Äâ(zÃÑ) + ‚àÇ„ÄàG,G„Äâ(zÃÑ),
Œªg ‚â• 0, „Äàg(zÃÑ), Œªg„Äâ = 0 G ‚àà NK (G(zÃÑ)).
Proof The results follow from applying the limiting subdifferential version of the
generalized Lagarange multiplier rule (see e.g., Mordukhovich [32, Proposition 5.3]),
calculus rules for limiting subdifferentials in particular the chain rule in Mordukhovich
and Shao [33, Proposition 2.5 and Corollary 6.3]). 
The calmness condition involves both the constraint functions and the objective
function. It is therefore not a constraint qualification in classical sense. Indeed it is a
sufficient condition under which KKT type necessary optimality conditions hold. The
calmness condition may hold even when the weakest constraint qualification does not
hold. In practice one often uses some verifiable constraint qualifications sufficient to
the calmness condition.
Definition 2.5 (Calmness of a set-valued map) A set-valued map  : Z ‚áí Y is said
to be calm at a point (zÃÑ, vÃÑ) ‚àà gph  if there exist a constant M > 0 and a neighborhood
U of zÃÑ, a neighborhood V of vÃÑ such that
(z) ‚à© V ‚äÜ (zÃÑ) + M‚Äñz ‚àí zÃÑ‚Äñcl B ‚àÄ z ‚àà U.
123
C. Ding et al.
Although the term ‚Äúcalmness‚Äù was coined in Rockafellar and Wets [44], the concept
of calmness of a set-valued map was first introduced by Ye and Ye in [62] under the term
‚Äúpseudo upper-Lipschitz continuity‚Äù which comes from the fact that it is a combination
of Aubin‚Äôs pseudo Lipschitz continuity [1] and Robinson‚Äôs upper-Lipschitz continuity
[39,40].
For recent discussion on the properties and the criterion of calmness of a set-valued
mapping, see Henrion and Outrata [19,20]. In what follows, we consider the calmness
of the perturbed feasible region F(r, s, P) at (r, s, P) = (0, 0, 0) to establish the
Clarke calmness of the problem.
The proposition below is an easy consequence of Clarke‚Äôs exact penalty principle
[9, Proposition 2.4.3] and the calmness of the perturbed feasible region of the problem.
See [60, Proposition 4.2] for a proof.
Proposition 2.2 If the objective function of (GP) is Lipschitz near zÃÑ ‚àà F and the
perturbed feasible region of the constraint system F(r, s, P) defined as in (9) is calm
at (0, 0, 0, zÃÑ), then the problem (GP) is Clarke calm at zÃÑ.
From the definition it is easy to verify that the set-valued mapping F(r, s, P) is
calm at (0, 0, 0, zÃÑ) if and only if there exist a constant M > 0 and U , a neighborhood
of zÃÑ, such that
dist (z,F) ‚â§ M‚Äñ(r, s, P)‚Äñ ‚àÄ z ‚àà U ‚à© F(r, s, P).
The above property is also referred to the existence of a local error bound for the
feasible region F . Hence any results on the existence of a local error bound of the
constraint system may be used as a sufficient condition for calmness of the perturbed
feasible region (see e.g., Wu and Ye [57] for such sufficient conditions).
By virtue of Proposition 2.2, the following four constraint qualifications are stronger
than the Clarke calmness of (GP) at a local minimizer when the objective function of
the problem (GP) is Lipschitz continuous.
Proposition 2.3 Let F(r, s, P) be defined as in (9) and zÃÑ ‚àà F . Then the set-
valued map F(r, s, P) is calm at (0, 0, 0, zÃÑ) under one of the following constraint
qualifications:
(i) There is no singular Lagrange multiplier for problem (GP) at zÃÑ:
{
0 ‚àà ‚àÇ„Äàh, Œªh„Äâ(zÃÑ) + ‚àÇ„Äàg, Œªg„Äâ(zÃÑ) + ‚àÇ„ÄàG,G„Äâ(zÃÑ),
G ‚àà NK (G(zÃÑ)), Œªg ‚â• 0, „Äàg(zÃÑ), Œªg„Äâ = 0 ‚áí (Œª
h, Œªg,G) = 0.
(ii) Robinson‚Äôs CQ [41] holds at zÃÑ: h, g and G are continuously differentiable at zÃÑ.
K is a closed convex cone with a nonempty interior. The gradients h‚Ä≤i (zÃÑ)‚àó(i =
1, . . . , p) are linearly independent and there exists a vector d ‚àà Z such that
hi (zÃÑ)
‚Ä≤d = 0, i = 1, . . . , p,
gi (zÃÑ)
‚Ä≤d < 0, i ‚àà Ig(zÃÑ),
G(zÃÑ) + G ‚Ä≤(zÃÑ)d ‚àà int K ,
where Ig(zÃÑ) := {i : gi (zÃÑ) = 0} is the index of active inequality constraints.
123
First order optimality conditions
(iii) Linear Independence Constraint Qualification (LICQ) holds at zÃÑ:
0 ‚àà ‚àÇ„Äàh, Œªh„Äâ(zÃÑ) + ‚àÇ„Äàg, Œªg„Äâ(zÃÑ) + ‚àÇ„ÄàG,G„Äâ(zÃÑ),G ‚àà NK (G(zÃÑ))
‚áí (Œªh, Œªg,G) = 0.
(iv) h, g and G are affine mappings and the set K is a union of finitely many polyhedral
convex sets.
Proof It is obvious that (iii) implies (i). By [6, Propositions 3.16 (ii) and 3.19 (iii)],
Robinson‚Äôs CQ (ii) is equivalent to (i) when all functions h, g, G are continuously
differentiable and K is a closed convex cone with a nonempty interior. By Mor-
dukhovich‚Äôs criteria for pseudo-Lipschitz continuity, (i) implies that the set-valued
map F(r, s, P) is pseudo-Lipschitz continuous around (r, s, P) = (0, 0, 0) (see e.g.,
[33, Theorem 6.1]) and hence calm. By Robinson [42], (iv) implies the upper-Lipschitz
continuity and hence the calmness of the set-valued map F(r, s, P) at (0, 0, 0, zÃÑ). 
Combining Theorem 2.1 and Propositions 2.2 and 2.3, we have the following.
Theorem 2.2 Let zÃÑ be a local optimal solution of (GP). Suppose the problem is Clarke
calm at zÃÑ; in particular one of the constraint qualifications in Proposition 2.3 holds.
Then the KKT condition in Theorem 2.1 holds at zÃÑ.
2.3 Background in variational analysis in matrix spaces
Let A ‚àà Sn be given. We use Œª1(A) ‚â• Œª2(A) ‚â• ¬∑ ¬∑ ¬∑ ‚â• Œªn(A) to denote the eigenvalues
of A (all real and counting multiplicity) arranging in nonincreasing order and use Œª(A)
to denote the vector of the ordered eigenvalues of A. Denote (A) := diag(Œª(A)).
Consider the eigenvalue decomposition of A, i.e., A = P(A)PT , where P ‚àà On is
a corresponding orthogonal matrix of the orthonormal eigenvectors. By considering
the index sets of positive, zero, and negative eigenvalues of A, we are able to write A
in the following form
A = [ PŒ± PŒ≤ PŒ≥
]
‚é°
‚é£
(A)Œ±Œ± 0 0
0 0 0
0 0 (A)Œ≥ Œ≥
‚é§
‚é¶
‚é°
‚é¢‚é£
P
T
Œ±
P
T
Œ≤
P
T
Œ≥
‚é§
‚é•‚é¶ . (10)
where Œ± := {i : Œªi (A) > 0}, Œ≤ := {i : Œªi (A) = 0} and Œ≥ := {i : Œªi (A) < 0}.
Proposition 2.4 (see e.g., [16, Theorem 2.1]) For any X ‚àà Sn+ and Y ‚àà Sn‚àí,
NSn+(X) = {X‚àó ‚àà Sn‚àí : „ÄàX, X‚àó„Äâ = 0} = {X‚àó ‚àà Sn‚àí : X X‚àó = 0},
NSn‚àí(Y ) = {Y ‚àó ‚àà Sn+ : „ÄàY, Y ‚àó„Äâ = 0} = {Y ‚àó ‚àà Sn+ : Y Y ‚àó = 0} .
We say that X, Y ‚àà Sn have a simultaneous ordered eigenvalue decomposition
provided that there exists P ‚àà On such that X = P(X)PT and Y = P(Y )PT .
The following theorem is well-known and can be found in e.g., [22].
123
C. Ding et al.
Theorem 2.3 (von Neumann-Theobald) Any matrices X and Y in Sn satisfy the
inequality
„ÄàX, Y „Äâ ‚â§ Œª(X)Œª(Y ) ;
the equality holds if and only if X and Y admit a simultaneous ordered eigenvalue
decomposition.
Proposition 2.5 The graph of the set-valued map NSn+ can be written as
gph NSn+ = {(X, Y ) ‚àà Sn+ √ó Sn‚àí : Sn+(X + Y ) = X} (11)
= {(X, Y ) ‚àà Sn+ √ó Sn‚àí : Sn‚àí(X + Y ) = Y } (12)
= {(X, Y ) ‚àà Sn+ √ó Sn‚àí : XY = Y X = 0, „ÄàX, Y „Äâ = 0}. (13)
Proof Equations (11) and (12) are well-known (see [13]). Let X ‚àà Sn+. Since
NSn+(X) = ‚àÇŒ¥Sn+(X), where Œ¥C is the indicate function of a set C , by [22, Theo-
rem 3], since the function Œ¥Sn+(X) is an eigenvalue function, for any Y ‚àà NSn+(X), X
and Y commute. Equation (13) then follows from the expression for the normal cone
in Proposition 2.4. 
From [50, Theorem 4.7] we know that the metric projection operator Sn+(¬∑) is
directionally differentiable at any A ‚àà Sn and the directional derivative of Sn+(¬∑) at
A along direction H ‚àà Sn is given by
‚Ä≤Sn+(A; H) = P
‚é°
‚é¢‚é£
HÃÉŒ±Œ± HÃÉŒ±Œ≤ Œ±Œ≥ ‚ó¶ HÃÉŒ±Œ≥
HÃÉ TŒ±Œ≤ S |Œ≤|+ (HÃÉŒ≤Œ≤) 0
TŒ±Œ≥ ‚ó¶ HÃÉ TŒ±Œ≥ 0 0
‚é§
‚é•‚é¶ P
T
, (14)
where HÃÉ := PT H P , ‚ó¶ is the Hadamard product and
i j := max{Œªi (A), 0} ‚àí max{Œª j (A), 0}
Œªi (A) ‚àí Œª j (A) , i, j = 1, . . . , n, (15)
where 0/0 is defined to be 1. Since Sn+(¬∑) is global Lipschitz continuous on Sn , it is
well-known that Sn+(¬∑) is B(ouligand)-differentiable (c.f. [14, Definition 3.1.2]) onSn . In the following proposition, we will show that Sn+(¬∑) is also calmly B(ouligand)-
differentiable on Sn . This result is not only of its own interest, but also is crucial for
the study of the proximal and limiting normal cone of the normal cone mapping NSn+
in the next section.
Proposition 2.6 The metric projection operator Sn+(¬∑) is calmly B-differentiable for
any given A ‚àà Sn, i.e., for Sn  H ‚Üí 0,
Sn+(A + H) ‚àí Sn+(A) ‚àí ‚Ä≤Sn+(A; H) = O(‚ÄñH‚Äñ
2). (16)
Proof See the ‚ÄúAppendix‚Äù. 
123
First order optimality conditions
3 Expression of the proximal and limiting normal cones
In order to characterize the S-stationary and M-stationary conditions, we need to give
the precise expressions for the proximal and limiting normal cones of the graph of the
normal cone mapping NSn+ at any given point (X, Y ) ‚àà gph NSn+ . The purpose of this
section is to provide such formulas. The result is also of independent interest.
3.1 Expression of the proximal normal cone
By using the directional derivative formula (14), Qi and Fusek [38] characterized the
Fr√©chet normal cone of gph NSn+ . In this subsection, we will establish the representation
of the desired proximal normal cone by using the same formula and the just proved
calmly B-differentiability of the metric projection operator. The proximal normal cone
is in general smaller than the Fr√©chet normal cone. For the set gph N
n+ , however, it is
well-known that the Fr√©chet normal cone coincides with the proximal normal cone. The
natural question to ask is that whether this statement remains true for the set gph NSn+ .
Our computations in this section give an affirmative answer, that is, the expression for
the proximal normal cone coincides with the one for the Fr√©chet normal cone derived
by Qi and Fusek in [38].
From Proposition 2.6, we know that for any given X‚àó ‚àà Sn and any fixed X ‚àà Sn
there exist M1, M2 > 0 (depending on X and X‚àó only) such that for any X ‚Ä≤ ‚àà Sn
sufficiently close to X ,
„ÄàX‚àó,Sn+(X ‚Ä≤) ‚àí Sn+(X)„Äâ ‚â§ „ÄàX‚àó,‚Ä≤Sn+(X; X
‚Ä≤ ‚àí X)„Äâ + M1‚ÄñX ‚Ä≤ ‚àí X‚Äñ2, (17)
„ÄàX‚àó,Sn‚àí(X ‚Ä≤) ‚àí Sn‚àí(X)„Äâ ‚â§ „ÄàX‚àó,‚Ä≤Sn‚àí(X; X
‚Ä≤ ‚àí X)„Äâ + M2‚ÄñX ‚Ä≤ ‚àí X‚Äñ2. (18)
Proposition 3.1 For any given (X, Y ) ‚àà gph NSn+ , (X‚àó, Y ‚àó) ‚àà NœÄgph NSn+ (X, Y ) if
and only if (X‚àó, Y ‚àó) ‚àà Sn √ó Sn satisfies
„ÄàX‚àó,‚Ä≤Sn+(X + Y ; H)„Äâ + „ÄàY
‚àó,‚Ä≤Sn‚àí(X + Y ; H)„Äâ ‚â§ 0 ‚àÄ H ‚àà S
n . (19)
Proof ‚Äú‚áê‚Äù Suppose that (X‚àó, Y ‚àó) ‚àà Sn √ó Sn is given and satisfies the condition
(19).
By Proposition 2.5, (17) and (18), we know that there exist a constant Œ¥ > 0 and a
constant MÃÉ > 0 such that for any (X ‚Ä≤, Y ‚Ä≤) ‚àà gph NSn+ and ‚Äñ(X ‚Ä≤, Y ‚Ä≤) ‚àí (X, Y )‚Äñ ‚â§ Œ¥,
123
C. Ding et al.
„Äà(X‚àó, Y ‚àó), (X ‚Ä≤, Y ‚Ä≤) ‚àí (X, Y )„Äâ
= „Äà(X‚àó, Y ‚àó), (Sn+(X ‚Ä≤ + Y ‚Ä≤),Sn‚àí(X ‚Ä≤ + Y ‚Ä≤)) ‚àí (Sn+(X + Y ),Sn‚àí(X + Y ))„Äâ
‚â§ MÃÉ‚Äñ(X ‚Ä≤, Y ‚Ä≤) ‚àí (X, Y )‚Äñ2.
By taking M = max {MÃÉ, ‚Äñ(X‚àó, Y ‚àó)‚Äñ/Œ¥}, we know that for any (X ‚Ä≤, Y ‚Ä≤) ‚àà gph NSn+ ,
„Äà(X‚àó, Y ‚àó), (X ‚Ä≤, Y ‚Ä≤) ‚àí (X, Y )„Äâ ‚â§ M‚Äñ(X ‚Ä≤, Y ‚Ä≤) ‚àí (X, Y )‚Äñ2,
which implies, by the definition of the proximal normal cone, that (X‚àó, Y ‚àó) ‚àà
NœÄgph NSn+
(X, Y ).
‚Äú‚áí‚Äù Let (X‚àó, Y ‚àó) ‚àà NœÄgph NSn+ (X, Y ) be given. Then there exists M > 0 such
that for any (X ‚Ä≤, Y ‚Ä≤) ‚àà gph NSn+ ,
„Äà(X‚àó, Y ‚àó), (X ‚Ä≤, Y ‚Ä≤) ‚àí (X, Y )„Äâ ‚â§ M‚Äñ(X ‚Ä≤, Y ‚Ä≤) ‚àí (X, Y )‚Äñ2. (20)
Let H ‚àà Sn be arbitrary but fixed. For any t ‚Üì 0, let
X ‚Ä≤t = Sn+(X + Y + t H) and Y ‚Ä≤t = Sn‚àí(X + Y + t H).
By noting that (X ‚Ä≤t , Y ‚Ä≤t ) ‚àà gph NSn+ (c.f., (11)‚Äì(12) in Proposition 2.5) and Sn+(¬∑) and
Sn‚àí(¬∑) are globally Lipschitz continuous with modulus 1, we obtain from (20) that
„ÄàX‚àó,‚Ä≤Sn+(X + Y ; H)„Äâ + „ÄàY
‚àó,‚Ä≤Sn‚àí(X + Y ; H)„Äâ
‚â§ M lim
t‚Üì0
1
t
(‚ÄñX ‚Ä≤t ‚àí X‚Äñ2 + ‚ÄñY ‚Ä≤t ‚àí Y‚Äñ2) ‚â§ M limt‚Üì0
1
t
(2t2‚ÄñH‚Äñ2) = 0.
Therefore, we know that (X‚àó, Y ‚àó) ‚àà Sn √ó Sn satisfies the condition (19). The proof
is completed. 
For any given (X, Y ) ‚àà gph NSn+ , let A = X+Y have the eigenvalue decomposition
(10). From (11)‚Äì(12), we know that X = Sn+(A) and Y = Sn‚àí(A). It follows from
the directional derivative formula (14) that for any H ‚àà Sn ,
‚Ä≤Sn‚àí(A; H) = P
‚é°
‚é¢‚é£
0 0 (EŒ±Œ≥ ‚àí Œ±Œ≥ ) ‚ó¶ HÃÉŒ±Œ≥
0 S |Œ≤|‚àí (HÃÉŒ≤Œ≤) HÃÉŒ≤Œ≥
(EŒ±Œ≥ ‚àíŒ±Œ≥ )T ‚ó¶ HÃÉ TŒ±Œ≥ HÃÉŒ≤Œ≥ HÃÉŒ≥ Œ≥
‚é§
‚é•‚é¶ P
T
,
(21)
where E is a n √ó n matrix whose entries are all ones. Denote
1 :=
‚é°
‚é£
EŒ±Œ± EŒ±Œ≤ Œ±Œ≥
ETŒ±Œ≤ 0 0
TŒ±Œ≥ 0 0
‚é§
‚é¶ and 2 :=
‚é°
‚é£
0 0 EŒ±Œ≥ ‚àí Œ±Œ≥
0 0 EŒ≤Œ≥
(EŒ±Œ≥ ‚àí Œ±Œ≥ )T ETŒ≤Œ≥ EŒ≥ Œ≥
‚é§
‚é¶ .
(22)
123
First order optimality conditions
We are now in a position to derive the precise expression of the proximal normal cone
to gph NSn+ .
Proposition 3.2 For any (X, Y ) ‚àà gph NSn+ , let A = X + Y have the eigenvalue
decomposition (10). Then
NœÄgph NSn+
(X, Y )
=
{
(X‚àó, Y ‚àó) ‚àà Sn √ó Sn : 1 ‚ó¶ XÃÉ‚àó + 2 ‚ó¶ YÃÉ ‚àó = 0, XÃÉ‚àóŒ≤Œ≤  0 and YÃÉ‚àóŒ≤Œ≤  0
}
,
where XÃÉ‚àó := PT X‚àóP and YÃÉ ‚àó := PT Y ‚àóP.
Proof By Proposition 3.1, (X‚àó, Y ‚àó) ‚àà NœÄgph NSn+ (X, Y ) if and only if
„ÄàX‚àó,‚Ä≤Sn+(A; H)„Äâ + „ÄàY
‚àó,‚Ä≤Sn‚àí(A; H)„Äâ ‚â§ 0 ‚àÄ H ‚àà S
n,
which, together with the directional derivative formulas (14) and (21) implies that
(X‚àó, Y ‚àó) ‚àà NœÄgph NSn+ (X, Y ) if and only if
„Äà1 ‚ó¶ XÃÉ‚àó, HÃÉ„Äâ + „Äà2 ‚ó¶ YÃÉ ‚àó, HÃÉ„Äâ + „ÄàXÃÉ‚àóŒ≤Œ≤,S |Œ≤|+ (HÃÉŒ≤Œ≤)„Äâ
+„ÄàYÃÉ ‚àóŒ≤Œ≤,S |Œ≤|‚àí (HÃÉŒ≤Œ≤)„Äâ ‚â§ 0 ‚àÄ H ‚àà S
n .
The conclusion of the proposition holds. 
3.2 Expression of the limiting normal cone
In this subsection, we will use the formula of the proximal normal cone NœÄgph NSn+
(X, Y )
obtained in Proposition 3.2 to characterize the limiting normal cone Ngph NSn+
(X, Y ).
For any given (X, Y ) ‚àà gphNSn+ , let A = X+Y have the eigenvalue decomposition
(10) and Œ≤ be the index set of zero eigenvalues of A. Denote the set of all partitions of
the index set Œ≤ by P(Œ≤). Let 
|Œ≤| be the set of all vectors in 
|Œ≤| whose components
being arranged in non-increasing order, i.e.,

|Œ≤| :=
{
z ‚àà 
|Œ≤| : z1 ‚â• ¬∑ ¬∑ ¬∑ ‚â• z|Œ≤|
}
.
For any z ‚àà 
|Œ≤| , let D(z) represent the generalized first divided difference matrix for
f (t) = max{t, 0} at z, i.e.,
(D(z))i j =
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
max{zi , 0} ‚àí max{z j , 0}
zi ‚àí z j ‚àà [0, 1] if zi  = z j ,
1 if zi = z j > 0,
0 if zi = z j ‚â§ 0,
i, j = 1, . . . , |Œ≤|.
(23)
123
C. Ding et al.
Denote
U|Œ≤| := { ‚àà S |Œ≤| :  = lim
k‚Üí‚àû D(z
k), zk ‚Üí 0, zk ‚àà 
|Œ≤| }. (24)
Let 1 ‚àà U|Œ≤|. Then, from (23), it is easy to see that there exists a partition œÄ(Œ≤) :=
(Œ≤+, Œ≤0, Œ≤‚àí) ‚àà P(Œ≤) such that
1 =
‚é°
‚é£
EŒ≤+Œ≤+ EŒ≤+Œ≤0 (1)Œ≤+Œ≤‚àí
ETŒ≤+Œ≤0 0 0
(1)
T
Œ≤+Œ≤‚àí 0 0
‚é§
‚é¶ , (25)
where each element of (1)Œ≤+Œ≤‚àí belongs to [0, 1]. Let
2 :=
‚é°
‚é£
0 0 EŒ≤+Œ≤‚àí ‚àí (1)Œ≤+Œ≤‚àí
0 0 EŒ≤0Œ≤‚àí
(EŒ≤+Œ≤‚àí ‚àí (1)Œ≤+Œ≤‚àí)T ETŒ≤0Œ≤‚àí EŒ≤‚àíŒ≤‚àí
‚é§
‚é¶ . (26)
We first characterize the limiting normal cone Ngph NSn+
(X, Y ) for the special case
when (X, Y ) = (0, 0) and Œ≤ = {1, 2, . . . , n}.
Proposition 3.3 The limiting normal cone to the graph of the limiting normal cone
mapping NSn+ at (0, 0) is given by
Ngph NSn+
(0, 0) =
‚ãÉ
Q ‚àà On
1 ‚àà Un
{
(U‚àó, V ‚àó) : 1 ‚ó¶ QT U‚àóQ + 2 ‚ó¶ QT V ‚àóQ = 0,
QTŒ≤0U
‚àóQŒ≤0  0, QTŒ≤0 V ‚àóQŒ≤0  0
}
.
(27)
Proof See the ‚ÄúAppendix‚Äù. 
We now characterize the limiting normal cone Ngph NSn+
(X, Y ) for any (X, Y ) ‚àà
gph NSn+ for the general case in the following theorem.
Theorem 3.1 For any (X, Y ) ‚àà gph NSn+ , let A = X +Y have the eigenvalue decom-
position (10).
Then, (X‚àó, Y ‚àó) ‚àà Ngph NSn+ (X, Y ) if and only if
X‚àó = P
‚é°
‚é£
0 0 XÃÉ‚àóŒ±Œ≥
0 XÃÉ‚àóŒ≤Œ≤ XÃÉ‚àóŒ≤Œ≥
XÃÉ‚àóŒ≥Œ± XÃÉ‚àóŒ≥Œ≤ XÃÉ‚àóŒ≥ Œ≥
‚é§
‚é¶ PT and Y ‚àó = P
‚é°
‚é£
YÃÉ ‚àóŒ±Œ± YÃÉ ‚àóŒ±Œ≤ YÃÉ ‚àóŒ±Œ≥
YÃÉ ‚àóŒ≤Œ± YÃÉ ‚àóŒ≤Œ≤ 0
YÃÉ ‚àóŒ≥Œ± 0 0
‚é§
‚é¶ PT (28)
with
(XÃÉ‚àóŒ≤Œ≤, YÃÉ ‚àóŒ≤Œ≤) ‚àà Ngph NS|Œ≤|+ (0, 0) and Œ±Œ≥ ‚ó¶ XÃÉ
‚àó
Œ±Œ≥ +(EŒ±Œ≥ ‚àíŒ±Œ≥ ) ‚ó¶ YÃÉ ‚àóŒ±Œ≥ =0, (29)
123
First order optimality conditions
where  is given by (15), XÃÉ‚àó = PT X‚àóP, YÃÉ ‚àó = PT Y ‚àóP and
Ngph NS|Œ≤|+
(0, 0) =
‚ãÉ
Q ‚àà O|Œ≤|
1 ‚àà U|Œ≤|
{
(U‚àó, V ‚àó) : 1 ‚ó¶ QT U‚àóQ + 2 ‚ó¶ QT V ‚àóQ = 0,
QTŒ≤0U
‚àóQŒ≤0  0, QTŒ≤0 V ‚àóQŒ≤0  0
}
.
Proof See the ‚ÄúAppendix‚Äù. 
Remark 3.1 For any given (X, Y ) ‚àà gph NSn+ , the (Mordukhovich) coderivative
D‚àóNSn+(X, Y ) of the normal cone to the set Sn+ can be calculated by using Theo-
rem 3.1 and the definition of coderivative, i.e., for given Y ‚àó ‚àà Sn ,
X‚àó ‚àà D‚àóNSn+(X, Y )(Y ‚àó) ‚áê‚áí (X‚àó,‚àíY ‚àó) ‚àà Ngph NSn+ (X, Y ).
Furthermore, by (11) in Proposition 2.5, we know that
gph NSn+ = {(X, Y ) ‚àà Sn √ó Sn : L(X, Y ) ‚àà gph Sn+},
where L : Sn √ó Sn ‚Üí Sn √ó Sn is a linear function defined by
L(X, Y ) := (X + Y, X), (X, Y ) ‚àà Sn √ó Sn .
By noting that the derivative of L is nonsingular and self-adjoint, we know from [30,
Theorem 6.10] that for any given (X, Y ) ‚àà gph NSn+ and Y ‚àó ‚àà Sn ,
D‚àóNSn+(X, Y )(‚àíY ‚àó) = {X‚àó ‚àà Sn : (X‚àó, Y ‚àó) ‚àà L ‚Ä≤(X, Y )Ngph Sn+ (X + Y, X)}.
Thus, for any given U‚àó ‚àà Sn, V ‚àó ‚àà D‚àóSn+(X + Y )(U‚àó) if and only if there exists
(X‚àó, Y ‚àó) ‚àà Ngph NSn+ (X, Y ) such that (X
‚àó, Y ‚àó) = L(V ‚àó,‚àíU‚àó), that is,
X‚àó = V ‚àó ‚àí U‚àó and Y ‚àó = V ‚àó.
Note that for any given Z ‚àà Sn , there exists a unique element (X, Y ) ‚àà gph NSn+ such
that Z = X + Y . Hence, the coderivative of the metric projector operator Sn+(¬∑) at
any Z ‚àà Sn can also be computed by Theorem 3.1.
4 Failure of Robinson‚Äôs CQ
Since for any (G(z), H(z)) ‚àà Sn+ √ó Sn‚àí, by the von Neumann-Theobald theorem
(Theorem 2.3), one always has
„ÄàG(z), H(z)„Äâ ‚â§ Œª(G(z))T Œª(H(z)) ‚â§ 0.
123
C. Ding et al.
Consequently one can rewrite the SDCMPCC problem in the following form:
(C P ‚àí SDC M PCC) min f (z)
s.t. h(z) = 0,
g(z) Q 0,
„ÄàG(z), H(z)„Äâ ‚â• 0,
(G(z), H(z)) ‚àà Sn+ √ó Sn‚àí.
Rewriting the constraints g(z) Q 0 and (G(z), H(z)) ‚àà Sn+ √ó Sn‚àí as the cone
constraint
(g(z), G(z), H(z)) ‚àà ‚àíQ √ó Sn+ √ó Sn‚àí,
we know that the above problem belongs to the class of general optimization problems
with a cone constraint (GP) as discussed in Sect. 2.2. Hence, the necessary optimality
condition stated in Sect. 2.2 can be applied to obtain the following classical KKT
condition.
Definition 4.1 Let zÃÑ be a feasible solution of SDCMPCC. We call zÃÑ a classical KKT
point if there exists (Œªh, Œªg, Œªe,G ,H ) ‚àà 
p √ó H √ó 
 √ó Sn √ó Sn with Œªg ‚àà
Q, Œªe ‚â§ 0,G  0 and H  0 such that
0 = ‚àá f (zÃÑ) + h‚Ä≤(zÃÑ)‚àóŒªh + g‚Ä≤(zÃÑ)‚àóŒªg + Œªe[H ‚Ä≤(zÃÑ)‚àóG(zÃÑ) + G ‚Ä≤(zÃÑ)‚àóH(zÃÑ)]
+G ‚Ä≤(zÃÑ)‚àóG + H ‚Ä≤(zÃÑ)‚àóH , „Äàg(zÃÑ), Œªg„Äâ = 0, G(zÃÑ)G = 0, H(zÃÑ)H = 0.
Theorem 4.1 Let zÃÑ be a local optimal solution of SDCMPCC. Suppose that the prob-
lem CP-SDCMPCC is Clarke calm at zÃÑ; in particular the set-valued map
F(r, s, t, P) := {z : h(z) + r = 0, g(z) + s Q 0,‚àí„ÄàG(z), H(z)„Äâ
+t ‚â§ 0, (G(z), H(z)) + P ‚àà Sn+ √ó Sn‚àí} (30)
is calm at (0, 0, 0, 0, zÃÑ). Then zÃÑ is a classical KKT point.
Proof By Theorem 2.2, there exists a Lagrange multiplier (Œªh, Œªe, Œªg, G , H ) ‚àà

p √ó
q √ó
√ó H √ó Sn √ó Sn with Œªe ‚â§ 0 such that
0 = ‚àá f (zÃÑ) + h‚Ä≤(zÃÑ)‚àóŒªh + g‚Ä≤(zÃÑ)‚àóŒªg + Œªe[H ‚Ä≤(zÃÑ)‚àóG(zÃÑ) + G ‚Ä≤(zÃÑ)‚àóH(zÃÑ)] + G ‚Ä≤(zÃÑ)‚àóG
+H ‚Ä≤(zÃÑ)‚àóH , (Œªg, G , H ) ‚àà N‚àíQ√óSn+√óSn‚àí(g(zÃÑ), G(zÃÑ), H(zÃÑ)).
Since Q is a symmetric cone it follows that Œªg ‚àà Q and „Äàg(zÃÑ), Œªg„Äâ = 0. The desired
result follows from the normal cone expressions in Proposition 2.4. 
Definition 4.2 We say that (Œªh, Œªg, Œªe,G ,H ) ‚àà 
p√óH√ó
√óSn √óSn with Œªg ‚àà
Q, Œªe ‚â§ 0,G  0,H  0 is a singular Lagrange multiplier for CP-SDCMPCC if
it is not equal to zero and
123
First order optimality conditions
0 = h‚Ä≤(zÃÑ)‚àóŒªh + g‚Ä≤(zÃÑ)‚àóŒªg + Œªe[H ‚Ä≤(zÃÑ)‚àóG(zÃÑ) + G ‚Ä≤(zÃÑ)‚àóH(zÃÑ)] + G ‚Ä≤(zÃÑ)‚àóG
+H ‚Ä≤(zÃÑ)‚àóH , „Äàg(zÃÑ), Œªg„Äâ = 0, G(zÃÑ)G = 0, H(zÃÑ)H = 0.
For a general optimization problem with a cone constraint such as CP-SDCMPCC,
the following Robinson‚Äôs CQ is considered to be a usual constraint qualification:
h‚Ä≤(zÃÑ) is onto ( equivalently h‚Ä≤i (zÃÑ)(i = 1, . . . , p) are linearly independent),
‚àÉ d such that
‚éß
‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é©
h‚Ä≤i (zÃÑ)d = 0, i = 1, . . . , p,‚àíg(zÃÑ) ‚àí g‚Ä≤(zÃÑ)d ‚àà int Q
(H ‚Ä≤(zÃÑ)‚àóG(zÃÑ) + G ‚Ä≤(zÃÑ)‚àóH(zÃÑ))d > 0,
G(zÃÑ) + G ‚Ä≤(zÃÑ)d ‚àà int Sn+,
H(zÃÑ) + H ‚Ä≤(zÃÑ)d ‚àà int Sn‚àí.
It is well-known that the MFCQ never holds for MPCCs. We now show that Robin-
son‚Äôs CQ will never hold for CP-SDCMPCC.
Proposition 4.1 For CP-SDCMPCC, Robinson‚Äôs constraint qualification fails to hold
at every feasible solution of SDCMPCC.
Proof By the von Neumann-Theobald theorem, G(z)  0 and H(z)  0 implies that
„ÄàG(z), H(z)„Äâ ‚â§ 0. Hence any feasible solution zÃÑ of SDCMPCC must be a solution to
the following nonlinear semidefinite program:
min ‚àí„ÄàG(z), H(z)„Äâ
s.t. G(z)  0, H(z)  0.
Since for this problem, f (z) = ‚àí„ÄàG(z), H(z)„Äâ, we have‚àá f (z) = ‚àíH ‚Ä≤(z)‚àóG(z)‚àí
G ‚Ä≤(z)‚àóH(z). By the first order necessary optimality condition, there exist Œªe =
1,G  0,H  0 such that
0 = ‚àíŒªe[H ‚Ä≤(zÃÑ)‚àóG(zÃÑ) + G ‚Ä≤(zÃÑ)‚àóH(zÃÑ)] + G ‚Ä≤(zÃÑ)‚àóG + H ‚Ä≤(zÃÑ)‚àóH ,
G(zÃÑ)G = 0, H(zÃÑ)H = 0.
Since (‚àíŒªe,G ,H )  = 0, it is clear that (0, 0, 0,‚àíŒªe,G ,H ) is a singular
Lagrange multiplier of CP-SDCMPCC. By [6, Propositions 3.16 (ii) and 3.19(iii)]),
a singular Lagrange multiplier exists if and only if Robinson‚Äôs CQ does not hold.
Therefore we conclude that the Robinson‚Äôs CQ does not hold at zÃÑ for CP-SDCMPCC.

5 S-stationary conditions
In the MPCC literature [26,59], using the so-called ‚Äúpiecewise programming
approach‚Äù to rewrite the feasible region as a union of branches which consist of only
ordinary equality and inequality constraints, one derives the S-stationary condition as
a necessary optimality condition for a local optimal solution under the condition that
123
C. Ding et al.
each branch has a common multiplier. Moreover it is well-known that the S-stationary
condition is equivalent to the classical KKT condition; see e.g., [17]. In this section we
introduce the concept of S-stationary condition and show that the classical KKT con-
dition implies the S-stationary condition. Unfortunately for SDCMPCC, ‚Äúpiecewise
programming approach‚Äù is not applicable any more. Hence the converse implication
may not be true in general.
For MPCC, the S-stationary condition is shown to be equivalent to the necessary
optimality condition of a reformulated problem involving the proximal normal cone to
the graph of the normal cone operator (see [59, Theorem 3.2]). Motivated by this fact
and the precise expression for the proximal normal cone formula in Proposition 3.2,
we introduce the concept of a S-stationary point for SDCMPCC.
Definition 5.1 Let zÃÑ be a feasible solution of SDCMPCC. Let A := G(zÃÑ)+H(zÃÑ) have
the eigenvalue decomposition (10). We say that zÃÑ is a S-stationary point of SDCMPCC
if there exists (Œªh, Œªg, G , H ) ‚àà 
p √ó H √ó Sn √ó Sn such that
0 = ‚àá f (zÃÑ) + h‚Ä≤(zÃÑ)‚àóŒªh + g‚Ä≤(zÃÑ)‚àóŒªg + G ‚Ä≤(zÃÑ)‚àóG + H ‚Ä≤(zÃÑ)‚àóH , (31)
Œªg ‚àà Q, „ÄàŒªg, g(zÃÑ)„Äâ = 0, (32)
ÃÉGŒ±Œ± = 0, ÃÉGŒ±Œ≤ = 0, ÃÉGŒ≤Œ± = 0, (33)
ÃÉHŒ≥ Œ≥ = 0, ÃÉHŒ≤Œ≥ = 0, ÃÉHŒ≥Œ≤ = 0, (34)
Œ±Œ≥ ‚ó¶ ÃÉGŒ±Œ≥ + (EŒ±Œ≥ ‚àí Œ±Œ≥ ) ‚ó¶ ÃÉHŒ±Œ≥ = 0, (35)
ÃÉGŒ≤Œ≤  0, ÃÉHŒ≤Œ≤  0, (36)
where E is a n √ó n matrix whose entries are all ones and  ‚àà Sn is defined by (15),
and ÃÉG = PT G P and ÃÉH = PT H P .
We now show that for SDCMPCC, the classical KKT condition implies the
S-stationary condition.
Proposition 5.1 Let zÃÑ be a feasible solution of SDCMPCC. If zÃÑ is a classical KKT
point, i.e., there exists a classical Lagrange multiplier (Œªh, Œªg, Œªe,G ,H ) ‚àà 
p √ó
H √ó
√ó Sn √ó Sn with Œªg ‚àà Q, Œªe ‚â§ 0,G  0 and H  0 such that
0 = ‚àá f (zÃÑ) + h‚Ä≤(zÃÑ)‚àóŒªh + g‚Ä≤(zÃÑ)‚àóŒªg + Œªe[H ‚Ä≤(zÃÑ)‚àóG(zÃÑ) + G ‚Ä≤(zÃÑ)‚àóH(zÃÑ)] + G ‚Ä≤(zÃÑ)‚àóG
+H ‚Ä≤(zÃÑ)‚àóH , „ÄàŒªg, g(zÃÑ)„Äâ = 0, G(zÃÑ)G = 0, H(zÃÑ)H = 0,
then it is also a S-stationary point.
Proof Denote  := (A). Define G := G + Œªe H(zÃÑ) and H := H + ŒªeG(zÃÑ).
Then (31) and (32) hold. It remains to show (33)‚Äì(36). By the assumption we have
Sn+  G(zÃÑ) ‚ä• G ‚àà Sn‚àí and Sn‚àí  H(zÃÑ) ‚ä• H ‚àà Sn+.
By Theorem 2.3, we know that G(zÃÑ) and G (H(zÃÑ) and H ) admit a simultaneous
ordered eigenvalue decomposition, i.e., there exist two orthogonal matrices PÃÉ, PÃÇ ‚àà On
such that
123
First order optimality conditions
G = PÃÉ
[
0 0
0 (G)Œ≥ ‚Ä≤Œ≥ ‚Ä≤
]
PÃÉT , G(zÃÑ) = PÃÉ
‚é°
‚é£
Œ±Œ± 0 0
0 0 0
0 0 0
‚é§
‚é¶ PÃÉT
and
H = PÃÇ
[
(H )Œ±‚Ä≤Œ±‚Ä≤ 0
0 0
]
PÃÇT , H(zÃÑ) = PÃÇ
‚é°
‚é£
0 0 0
0 0 0
0 0 Œ≥Œ≥
‚é§
‚é¶ PÃÇT ,
where Œ±‚Ä≤ := {i | Œªi (H ) > 0} and Œ≥ ‚Ä≤ := {i | Œªi (G) < 0}. Moreover, we have
Œ≥ ‚Ä≤ ‚äÜ Œ±ÃÑ and Œ±‚Ä≤ ‚äÜ Œ≥ÃÑ , (37)
where Œ±ÃÑ := Œ≤ ‚à™ Œ≥ , Œ≥ÃÑ := Œ± ‚à™ Œ≤.
On the other hand, we know that
G(zÃÑ)=Sn+(A)= P
‚é°
‚é£
Œ±Œ± 0 0
0 0 0
0 0 0
‚é§
‚é¶ PT and H(zÃÑ) = Sn‚àí(A)= P
‚é°
‚é£
0 0 0
0 0 0
0 0 Œ≥Œ≥
‚é§
‚é¶ PT .
Therefore, it is easy to check that there exist two orthogonal matrices S, T ‚àà On such
that
P = PÃÉ S and P = PÃÇT,
with
S =
[
SŒ±Œ± 0
0 SŒ±ÃÑŒ±ÃÑ
]
and T =
[
TŒ≥ÃÑ Œ≥ÃÑ 0
0 TŒ≥ Œ≥
]
,
where SŒ±Œ± ‚àà O|Œ±|, SŒ±ÃÑŒ±ÃÑ ‚àà O|Œ±ÃÑ| and TŒ≥ÃÑ Œ≥ÃÑ ‚àà O|Œ≥ÃÑ |, TŒ≥ Œ≥ ‚àà O|Œ≥ |. Denote
SŒ±ÃÑŒ±ÃÑ = [S1 S2] and TŒ≥ÃÑ Œ≥ÃÑ = [T1 T2]
with S1 ‚àà 
|Œ±ÃÑ|√ó|Œ≤|, S2 ‚àà 
|Œ±ÃÑ|√ó|Œ≥ | and T1 ‚àà 
|Œ≥ÃÑ |√ó|Œ±| and T2 ‚àà 
|Œ≥ÃÑ |√ó|Œ≤|. Then, we have
ÃÉG = PT (G + Œªe H(zÃÑ))P = ST PÃÉT G PÃÉ S + Œªe
‚é°
‚é£
0 0 0
0 0 0
0 0 Œ≥Œ≥
‚é§
‚é¶
=
[
STŒ±Œ± 0
0 STŒ±ÃÑŒ±ÃÑ
] [
0 0
0 (G)Œ±ÃÑŒ±ÃÑ
] [
SŒ±Œ± 0
0 SŒ±ÃÑŒ±ÃÑ
]
+ Œªe
‚é°
‚é£
0 0 0
0 0 0
0 0 Œ≥Œ≥
‚é§
‚é¶
=
‚é°
‚é¢‚é£
0 0 0
0 ST1 (
G)Œ±ÃÑŒ±ÃÑ S1 ST1 (
G)Œ±ÃÑŒ±ÃÑ S2
0 ST2 (
G)Œ±ÃÑŒ±ÃÑ S1 ST2 (
G)Œ±ÃÑŒ±ÃÑ S2 + ŒªeŒ≥Œ≥
‚é§
‚é•‚é¶
123
C. Ding et al.
and
ÃÉH = PT (H + ŒªeG(zÃÑ))P = T T PÃÉT H PÃÉT + Œªe
‚é°
‚é£
Œ±Œ± 0 0
0 0 0
0 0 0
‚é§
‚é¶
=
[
T TŒ≥ÃÑ Œ≥ÃÑ 0
0 T TŒ≥ Œ≥
] [
(H )Œ≥ÃÑ Œ≥ÃÑ 0
0 0
] [
TŒ≥ÃÑ Œ≥ÃÑ 0
0 TŒ≥ Œ≥
]
+ Œªe
‚é°
‚é£
Œ±Œ± 0 0
0 0 0
0 0 0
‚é§
‚é¶
=
‚é°
‚é£
T T1 (
H )Œ≥ÃÑ Œ≥ÃÑ T1 + ŒªeŒ±Œ± T T1 (H )Œ≥ÃÑ Œ≥ÃÑ T2 0
T T2 (
H )Œ≥ÃÑ Œ≥ÃÑ T1 T T2 (
H )Œ≥ÃÑ Œ≥ÃÑ T2 0
0 0 0
‚é§
‚é¶ .
Therefore it is easy to see that (33)‚Äì(35) hold.
Since (G)Œ±ÃÑŒ±ÃÑ  0, (H )Œ≥ÃÑ Œ≥ÃÑ  0 and SŒ±ÃÑŒ±ÃÑ, TŒ≥ÃÑ Œ≥ÃÑ are orthogonal, we know that
STŒ±ÃÑŒ±ÃÑ(
G)Œ±ÃÑŒ±ÃÑ SŒ±ÃÑŒ±ÃÑ  0 and T TŒ≥ÃÑ Œ≥ÃÑ (H )Œ≥ÃÑ Œ≥ÃÑ TŒ≥ÃÑ Œ≥ÃÑ  0.
Hence, we have
ÃÉGŒ≤Œ≤ = ST1 (G)Œ±ÃÑŒ±ÃÑ S1  0 and ÃÉHŒ≤Œ≤ = T T2 (H )Œ≥ÃÑ Œ≥ÃÑ T2  0,
which implies (36). Therefore zÃÑ is also a S-stationary point. 
Combining Theorem 4.1 and Proposition 5.1 we have the following necessary
optimality condition in terms of S-stationary conditions.
Corollary 5.1 Let zÃÑ be an optimal solution of SDCMPCC. Suppose the problem CP-
SDCMPCC is Clarke calm at zÃÑ; in particular the set-valued map defined by (30) is
calm at (0, 0, 0, 0, zÃÑ). Then zÃÑ is a S-stationary point.
6 M-stationary conditions
In this section we study the M-stationary conditon for SDCMPCC. For this purpose
rewrite the SDCMPCC as an optimization problem with a cone constraint:
(GP-SDCMPCC) min f (z)
s.t. h(z) = 0,
g(z) Q 0,
(G(z), H(z)) ‚àà gph NSn+ .
Definition 6.1 Let zÃÑ be a feasible solution of SDCMPCC. Let A = G(zÃÑ)+H(zÃÑ) have
the eigenvalue decomposition (10). We say that zÃÑ is a M-stationary point of SDCMPCC
if there exists (Œªh, Œªg, G , H ) ‚àà 
p √ó H √ó Sn √ó Sn such that (31)‚Äì(35) hold and
there exist Q ‚àà O|Œ≤| and 1 ‚àà U|Œ≤| (with a partition œÄ(Œ≤) = (Œ≤+, Œ≤0, Œ≤‚àí) of Œ≤ and
the form (25)) such that
123
First order optimality conditions
1 ‚ó¶ QT ÃÉGŒ≤Œ≤ Q + 2 ‚ó¶ QT ÃÉHŒ≤Œ≤ Q = 0, (38)
QTŒ≤0 ÃÉ
G
Œ≤Œ≤ QŒ≤0  0, QTŒ≤0 ÃÉHŒ≤Œ≤ QŒ≤0  0, (39)
where ÃÉG = PT G P , ÃÉH = PT H P and 2 is defined by (26).
We say that (Œªh, Œªg, G , H ) ‚àà 
p √ó H √ó Sn √ó Sn is a singular M-multiplier
for SDCMPCC if it is not equal to zero and all conditions above hold except the term
‚àá f (zÃÑ) vanishes in (31).
The following result is on the first order necessary optimality condition of SDCM-
PCC in terms of M-stationary conditions.
Theorem 6.1 Let zÃÑ be a local optimal solution of SDCMPCC. Suppose that the prob-
lem GP-SDCMPCC is Clarke calm at zÃÑ; in particular one of the following constraint
qualifications holds.
(i) There is no singular M-multiplier for problem SDCMPCC at zÃÑ.
(ii) SDCMPCC LICQ holds at zÃÑ: there is no nonzero (Œªh, Œªg, G , H ) ‚àà 
p √óH√ó
Sn √ó Sn such that
h‚Ä≤(zÃÑ)‚àóŒªh + g‚Ä≤(zÃÑ)‚àóŒªg + G ‚Ä≤(zÃÑ)‚àóG + H ‚Ä≤(zÃÑ)‚àóH = 0,
ÃÉGŒ±Œ± = 0, ÃÉGŒ±Œ≤ = 0, ÃÉGŒ≤Œ± = 0,
ÃÉHŒ≥ Œ≥ = 0, ÃÉHŒ≤Œ≥ = 0, ÃÉHŒ≥Œ≤ = 0, (40)
Œ±Œ≥ ‚ó¶ ÃÉGŒ±Œ≥ + (EŒ±Œ≥ ‚àí Œ±Œ≥ ) ‚ó¶ ÃÉHŒ±Œ≥ = 0.
(iii) Assume that there is no inequality constraint g(z) Q 0. Assume also that Z =
X √ó Sn where X is a finite dimensional space and G(x, u) = u. The following
generalized equation is strongly regular in the sense of Robinson:
0 ‚àà ‚àíF(x, u) + N
q√óSn+(x, u),
where F(x, u) = (h(x, u), H(x, u)).
(iv) Assume that there is no inequality constraint g(z) Q 0. Assume also that Z =
X √ó Sn, G(z) = u and F(x, u) = (h(x, u), H(x, u)). ‚àíF is locally strongly
monotone in u uniformly in x with modulus Œ¥ > 0, i.e., there exist neighborhood
U1 of xÃÑ and U2 of uÃÑ such that
„Äà‚àíF(x, u) + F(x, v), u ‚àí v„Äâ ‚â• Œ¥‚Äñu ‚àí v‚Äñ2 ‚àÄ u ‚àà U2 ‚à© Sn+, v ‚àà Sn+, x ‚àà U1.
Then zÃÑ is a M-stationary point of SDCMPCC.
Proof Condition (ii) is obviously stronger than (i). Condition (i) is a necessary and
sufficient condition for the perturbed feasible region of the constraint system to be
pseudo Lipschitz continuous; see e.g., [33, Theorem 6.1]. See [60, Theorem 4.7] for
the proof of the implication of (iii) to (i). (iv) is a sufficient condition for (iii) and the
direct proof can be found in [62, Theorem 3.2(b)]. The desired result follows from
Theorem 2.2 and the expression of the limiting normal cone in Theorem 3.1. 
123
C. Ding et al.
Next, we give two SDCMPCC examples to illustrate the M-stationary conditions.
Note that in the first example the local solution is a M-stationary point, but not a
S-stationary point.
Example 6.1 Consider the following SDCMPCC problem
min ‚àí„ÄàI, X„Äâ + „ÄàI, Y „Äâ
s.t. X + Y = 0,
Sn+  X ‚ä• Y ‚àà Sn‚àí.
(41)
Since the unique feasible point of (41) is (0, 0), we know that (X‚àó, Y ‚àó) = (0, 0) is
the optimal solution of (41). Note that A = X‚àó + Y ‚àó = 0, which implies that
Œ± = ‚àÖ, Œ≤ = {1, . . . , n} and Œ≥ = ‚àÖ.
Without loss of generality, we may choose P = I . Therefore, by considering the
equation (31), we know that
[‚àíI
I
]
+
[
e
e
]
+
[
G
0
]
+
[
0
H
]
=
[
0
0
]
,
which implies that
G = I ‚àí e and H = ‚àíI ‚àí e, (42)
where e ‚àà Sn . Let e = I . Then, it is clear that the equation (38) holds for G = 0
and H = ‚àí2I with Œ≤+ = Œ≤ = {1, . . . , n}, Œ≤0 = Œ≤‚àí = ‚àÖ, and Q = I ‚àà On .
By noting that Œ≤0 = ‚àÖ, we know that the optimal solution (X‚àó, Y ‚àó) = (0, 0) is a
M-stationary point with the multiplier (I, 0,‚àí2I ) ‚àà Sn √ó Sn √ó Sn . However, the
optimal solution (X‚àó, Y ‚àó) = (0, 0) is not a S-stationary point. In fact, we know from
(42) that if there exists some e ‚àà Sn such that (36) holds, then
e  I and e  ‚àíI,
which is a contradiction.
Example 6.2 As a direct application, we characterize the M-stationary condition of the
rank constrained nearest correlation matrix problem (2). For any given feasible point
X ‚àà Sn of (2), suppose that X has the eigenvalue decomposition X = P(X)PT .
It is easy to check that (X , U ) ‚àà Sn √ó Sn is a feasible solution of (3) if and only if
U = ‚àëri=1 Pi PTi (see e.g., [23,27,35,36] for details). Assume rank(X) = rÃÑ ‚â§ r .
Then, the index sets of positive, zero and negative eigenvalues of A = X + (U ‚àí I )
are given by Œ± = {1, . . . , rÃÑ}, Œ≤ = {rÃÑ +1, . . . , r} and Œ≥ = {r +1, . . . , n}, respectively.
Therefore, we say that the feasible X ‚àà Sn is a M-stationary point of (2), if there exist
(Œªh1, Œª
h
2, Œª
g, G , H ) ‚àà 
n √ó
√óSn √óSn √óSn , Q ‚àà O|Œ≤| and 1 ‚àà U|Œ≤| such that
[
0
0
]
=
[‚àá fC (X)
0
]
+
[
diag(Œªh1)
Œªh2 I + Œªg
]
+
[
G
0
]
+
[
0
H
]
, (43)
123
First order optimality conditions
0  U ‚ä• Œªg  0, (44)
ÃÉGŒ±Œ± = 0, ÃÉGŒ±Œ≤ = 0, ÃÉGŒ≤Œ± = 0, ÃÉHŒ≥ Œ≥ = 0, ÃÉHŒ≤Œ≥ = 0, ÃÉHŒ≥Œ≤ = 0, (45)
Œªi (X)
Œªi (X) + 1
ÃÉGi j + (1 ‚àí
Œªi (X)
Œªi (X) + 1
)ÃÉHi j = 0, i ‚àà Œ±, j ‚àà Œ≥, (46)
1 ‚ó¶ QT ÃÉGŒ≤Œ≤ Q + 2 ‚ó¶ QT ÃÉHŒ≤Œ≤ Q = 0, (47)
QTŒ≤0 ÃÉ
G
Œ≤Œ≤ QŒ≤0  0, QTŒ≤0 ÃÉHŒ≤Œ≤ QŒ≤0  0, (48)
where ÃÉG = PT G P , ÃÉH = PT H P and 2 is defined by (26).
Remark 6.1 SDCMPCC LICQ is the analogue of the well-known MPCC LICQ (also
called MPEC LICQ). However, we would like to remark that unlike in MPCC case, we
can only show that SDCMPCC LICQ is a constraint qualification for a M-stationary
condition instead of a S-stationary condition.
7 C-stationary conditions
In this section, we consider the C-stationary condition by reformulating SDCMPCC
as a nonsmooth problem:
(NS ‚àí SDCMPCC) min f (z)
s.t. h(z) = 0,
g(z) Q 0,
G(z) ‚àí Sn+(G(z) + H(z)) = 0.
From (11), we know that the reformulation NS-SDCMPCC is equivalent to SDCM-
PCC. As in the MPCC case, the C-stationary condition introduced below is the non-
smooth KKT condition of NS-SDCMPCC by using the Clarke subdifferential.
Definition 7.1 Let zÃÑ be a feasible solution of SDCMPCC. Let A = G(zÃÑ)+H(zÃÑ) have
the eigenvalue decomposition (10). We say that zÃÑ is a C-stationary point of SDCMPCC
if there exists (Œªh, Œªg, G , H ) ‚àà 
p √ó
q √ó Sn √ó Sn such that (31)‚Äì(35) hold and
„ÄàÃÉGŒ≤Œ≤ , ÃÉHŒ≤Œ≤„Äâ ‚â§ 0, (49)
where ÃÉG = PT G P and ÃÉH = PT H P . We say that (Œªh, Œªg, G , H ) ‚àà 
p √ó
H √ó Sn √ó Sn is a singular C-multiplier for SDCMPCC if it is not equal to zero and
all conditions above hold except the term ‚àá f (zÃÑ) vanishes in (31).
Remark 7.1 It is easy to see that as in MPCC case,
S-stationary condition ‚áí M-stationary condition ‚áí C-stationary condition.
Indeed, since the proximal normal cone is included in the limiting normal cone,
it is obvious that the S-stationary condition implies the M-stationary condition.
123
C. Ding et al.
We now show that the M-stationary condition implies the C-stationary condition.
In fact, suppose that zÃÑ is a M-stationary point of SDCMPCC. Then, there exists
(Œªh, Œªg, G , H ) ‚àà 
p √ó 
q √ó Sn √ó Sn such that (31)‚Äì(35) hold and there exist
Q ‚àà O|Œ≤| and 1 ‚àà U|Œ≤| (with a partition œÄ(Œ≤) = (Œ≤+, Œ≤0, Œ≤‚àí) of Œ≤ and the form (25))
such that (38) and (39) hold. Let A = G(zÃÑ)+H(zÃÑ) have the eigenvalue decomposition
(10). Therefore, we know that
QTŒ≤+ ÃÉ
G
Œ≤Œ≤ QŒ≤+ = 0, QTŒ≤+ ÃÉGŒ≤Œ≤ QŒ≤‚àí = 0, QTŒ≤‚àí ÃÉGŒ≤Œ≤ QŒ≤+ = 0,
QTŒ≤‚àí ÃÉ
H
Œ≤Œ≤ QŒ≤‚àí = 0, QTŒ≤0 ÃÉHŒ≤Œ≤ QŒ≤‚àí = 0, QTŒ≤‚àí ÃÉHŒ≤Œ≤ QŒ≤0 = 0,
which implies that
„ÄàÃÉGŒ≤Œ≤, ÃÉHŒ≤Œ≤„Äâ = „ÄàQT ÃÉGŒ≤Œ≤ Q, QT ÃÉHŒ≤Œ≤ Q„Äâ
= 2„ÄàQTŒ≤+ ÃÉGŒ≤Œ≤ QŒ≤‚àí , QTŒ≤+ ÃÉHŒ≤Œ≤ QŒ≤‚àí„Äâ + 2„ÄàQTŒ≤0 ÃÉGŒ≤Œ≤ QŒ≤0 , QTŒ≤0 ÃÉHŒ≤Œ≤ QŒ≤0„Äâ.
Note that for each (i, j) ‚àà Œ≤+ √ó Œ≤‚àí, (1)i j ‚àà [0, 1] and (2)i j = 1 ‚àí (1)i j .
Therefore, we know from (38) that
„ÄàQTŒ≤+ ÃÉGŒ≤Œ≤ QŒ≤‚àí , QTŒ≤+ ÃÉHŒ≤Œ≤ QŒ≤‚àí„Äâ ‚â§ 0.
Finally, together with (39), we know that
„ÄàÃÉGŒ≤Œ≤, ÃÉHŒ≤Œ≤„Äâ ‚â§ 0,
which implies that zÃÑ is also a C-stationary point of SDCMPCC.
We present the first order optimality condition of SDCMPCC in terms of
C-stationary conditions in the following result.
Theorem 7.1 Let zÃÑ be a local optimal solution of SDCMPCC. Suppose that the prob-
lem NS-SDCMPCC is Clarke calm at zÃÑ; in particular suppose that there is no singular
C-multiplier for problem SDCMPCC at zÃÑ. Then zÃÑ is a C-stationary point of SDCM-
PCC.
Proof By Theorem 2.2 with K = {0}, we know that there exist Œªh ‚àà 
p, Œªg ‚àà 
q
and  ‚àà Sn such that
0 ‚àà ‚àÇ cz L(zÃÑ, Œªh, Œªg, ), Œªg ‚â• 0 and „ÄàŒªg, g(zÃÑ)„Äâ = 0, (50)
where L(z, Œªh, Œªg, ) := f (z)+ „ÄàŒªh, h(z)„Äâ + „ÄàŒªg, g(z)„Äâ + „Äà, G(z)‚àíSn+(G(z)+
H(z))„Äâ.
Consider the Clarke subdifferential of the nonsmooth part S(z) := „Äà,Sn+(G(z)+
H(z))„Äâ of L .
By the chain rule [9, Corollary pp.75], for any v ‚àà Z , we have
‚àÇ c S(zÃÑ)v ‚äÜ „Äà, ‚àÇ cSn+(A)(G ‚Ä≤(zÃÑ)v + H ‚Ä≤(zÃÑ)v)„Äâ.
123
First order optimality conditions
Therefore, since any element of the Clarke subdifferential of the metric projection
operator to a close convex set is self-adjoint (see e.g., [29, Proposition 1(a)]), we
know from (50) that there exists V ‚àà ‚àÇ cSn+(A) such that
‚àá f (zÃÑ) + h‚Ä≤(zÃÑ)‚àóŒªh + g‚Ä≤(zÃÑ)‚àóŒªg + G ‚Ä≤(zÃÑ)‚àó ‚àí (G ‚Ä≤(zÃÑ)‚àó + H ‚Ä≤(zÃÑ)‚àó)V () = 0. (51)
Define G :=  ‚àí V () and H := ‚àíV (). Then (31)‚Äì(32) follow from (50) and
(51) immediately. By [49, Proposition 2.2], we know that there exists W ‚àà ‚àÇ cS |Œ≤|+ (0)
such that
V () = P
‚é°
‚é¢‚é£
ÃÉŒ±Œ± ÃÉŒ±Œ≤ Œ±Œ≥ ‚ó¶ ÃÉŒ±Œ≥
ÃÉTŒ±Œ≤ W (ÃÉŒ≤Œ≤) 0
ÃÉTŒ±Œ≥ ‚ó¶ TŒ±Œ≥ 0 0
‚é§
‚é•‚é¶ P
T
,
where  ‚àà Sn is defined by (15). Therefore, it is easy to see that (33)‚Äì(35) hold.
Moreover, from [29, Proposition 1(c)], we know that
„ÄàW (ÃÉŒ≤Œ≤), ÃÉŒ≤Œ≤ ‚àí W (ÃÉŒ≤Œ≤)„Äâ ‚â• 0,
which implies „ÄàÃÉGŒ≤Œ≤ , ÃÉHŒ≤Œ≤„Äâ ‚â§ 0. Hence, we know zÃÑ is a C-stationary point of SDCM-
PCC. 
Next, we give an example whose optimal solution is a C-stationary point but not a
M-stationary point.
Example 7.1 Consider the following SDCMPCC problem
min 12 z1 ‚àí 12 z2 ‚àí z3 ‚àí 12 z4
s.t. ‚àí2z1 + z3 + z4 ‚â§ 0,
2z2 + z3 ‚â§ 0,
z24 ‚â§ 0,
S3+  G(z) ‚ä• H(z) ‚àà S3‚àí,
(52)
where G : 
4 ‚Üí S3 and H : 
4 ‚Üí S3 are the linear operators defined as follows
for any z = (z1, z2, z3, z4)T ‚àà 
4,
G(z) :=
‚é°
‚é¢‚é£
1 + z16 ‚àí1 + z16 ‚àí z13
‚àí1 + z16 1 + z16 ‚àí z13
‚àí z13 ‚àí z13 2z13
‚é§
‚é•‚é¶ and
H(z) :=
‚é°
‚é¢‚é£
z2
6 ‚àí 1 z26 ‚àí 1 ‚àí z23 ‚àí 1
z2
6 ‚àí 1 z26 ‚àí 1 ‚àí z23 ‚àí 1
‚àí z23 ‚àí 1 ‚àí z23 ‚àí 1 2z23 ‚àí 1
‚é§
‚é•‚é¶ .
Since „ÄàG(z), H(z)„Äâ = z1z2, one can verify that zÃÑ = (0, 0, 0, 0) is the unique optimal
solution of the problem (52). Thus, we have
123
C. Ding et al.
A = G(zÃÑ) + H(zÃÑ) = P
‚é°
‚é£
2 0 0
0 0 0
0 0 ‚àí3
‚é§
‚é¶ PT ,
where P is the 3 by 3 orthogonal matrix given by
P =
‚é°
‚é¢‚é£
1‚àö
2
1‚àö
6
1‚àö
3
‚àí 1‚àö
2
1‚àö
6
1‚àö
3
0 ‚àí2‚àö
6
1‚àö
3
‚é§
‚é•‚é¶ ,
and the index sets of positive, zero and negative eigenvalues are Œ± = {1}, Œ≤ = {2}
and Œ≥ = {3}. In the following we denote by ‚àÇG
‚àÇz1
the derivative of the mapping G with
respect to variable z1. Since G(z) only depends on z1 and H(z) only depends on z2,
(31) can be written as
‚é°
‚é¢‚é¢‚é£
0
0
0
0
‚é§
‚é•‚é•‚é¶ =
‚é°
‚é¢‚é¢‚é£
1
2‚àí 12‚àí1
‚àí 12
‚é§
‚é•‚é•‚é¶+
‚é°
‚é¢‚é¢‚é£
‚àí2
0
1
1
‚é§
‚é•‚é•‚é¶ Œª
g
1 +
‚é°
‚é¢‚é¢‚é£
0
2
1
0
‚é§
‚é•‚é•‚é¶ Œª
g
2 +
‚é°
‚é¢‚é¢‚é£
0
0
0
0
‚é§
‚é•‚é•‚é¶ Œª
g
3 +
‚é°
‚é¢‚é¢‚é£
„Äà ‚àÇG
‚àÇz1
, G„Äâ
0
0
0
‚é§
‚é•‚é•‚é¶
+
‚é°
‚é¢‚é¢‚é£
0
„Äà ‚àÇ H
‚àÇz2
, H „Äâ
0
0
‚é§
‚é•‚é•‚é¶ ,
for some (Œªg, G , H ) ‚àà 
3 √ó S3 √ó S3. From the above equation and (32), we
obtain that Œªg1 = Œªg2 = 12 > 0, Œªg3 ‚â• 0. Let ÃÉG = P
T
G P and ÃÉH = PT H P .
Let (G, H ) be such that all entries are zero except the entries (ÃÉG22, ÃÉ
H
22) left to be
determined. Then (33)‚Äì(35) hold and
‚å©
‚àÇG
‚àÇz1
, G
‚å™
=
‚å©
‚àÇG
‚àÇz1
, PÃÉG P
T
‚å™
=
‚å©
P
T ‚àÇG
‚àÇz1
P, ÃÉG
‚å™
= ÃÉG22.
Similarly we have „Äà ‚àÇ H
‚àÇz2
, H „Äâ = ÃÉH22. Therefore we obtain ÃÉG22 = 12 > 0, ÃÉH22 = ‚àí 12 <
0. Since ÃÉG22ÃÉ
H
22 < 0, we know that there exists a multiplier (Œª
g, G , H ) ‚àà 
3 √ó
S3 √óS3 such that (31)‚Äì(35) and (49) hold. Thus, the optimal solution zÃÑ = (0, 0, 0, 0)
is a C-stationary point. We now verify that the conditions (38) and (39) do not hold.
Since |Œ≤| = 1,O|Œ≤| = {1,‚àí1}. Let 1 ‚àà U1 and Q ‚àà {1,‚àí1}. If Œ≤0  = ‚àÖ, then
it is obvious that (39) does not hold. On the other hand if Œ≤0 = ‚àÖ then Œ≤ = Œ≤+ or
Œ≤ = Œ≤‚àí. If Œ≤ = Œ≤+, then 1 = [1] and 2 = [0] and hence it is clear that the
condition (38) does not hold. Alternatively if Œ≤ = Œ≤‚àí, then 1 = [0] and 2 = [1]
and hence the condition (38) does not hold. Therefore, we know that the optimal
solution zÃÑ = (0, 0, 0, 0) is not a M-stationary point.
123
First order optimality conditions
8 New optimality conditions for MPCC via SDCMPCC
As we mentioned in the introduction, the vector MPCC problem (6) can be considered
as a SDCMPCC problem with m one dimensional SDP complementarity constraints.
Consequently, in this way, all the stationary conditions developed for SDCMPCC
coincide with those for MPCC.
On the other hand, the vector MPCC problem (6) can also be considered as the
following SDCMPCC with one m dimensional SDP complementarity constraint:
min f (z)
s.t. h(z) = 0,
g(z) ‚â§ 0,
Sm+  D(G(z)) ‚ä• D(H(z)) ‚àà Sm‚àí ,
(53)
where G(z) = (G1(z), . . . , Gm(z))T : Z ‚Üí 
m and H(z) = (H1(z), . . . , Hm(z))T :
Z ‚Üí 
m and D : 
m ‚Üí Sm is the linear operator defined by D(y) = diag(y) for
any y ‚àà 
m . We now compare the resulting S-, M- and C-stationary conditions for
the two formulations. Since in this SDCMPCC reformulation the multipliers for the
matrix complementarity constraints are matrices, it may provide more flexibilities and
hence the resulting necessary optimality conditions may be weaker and more likely
to hold at an optimal solution. We now demonstrate this point.
First, consider the S-stationary condition. It is easy to see that if a feasible point
zÃÑ is a S-stationary point (see e.g., [47,61] for the definitions) of the original vector
MPCC problem, then zÃÑ is a S-stationary point of the special SDCMPCC problem
(53). We now show that the converse is also true. In fact, by the Definition 5.1, we
know that if the feasible point zÃÑ of (53) is a S-stationary point, then there exists
(Œªh, Œªg, G , H ) ‚àà 
p √ó
q √ó Sm √ó Sm such that (31)‚Äì(36) hold. In particular, we
have
0 = ‚àá f (zÃÑ) + h‚Ä≤(zÃÑ)‚àóŒªh + g‚Ä≤(zÃÑ)‚àóŒªg + G ‚Ä≤(zÃÑ)‚àóD‚àó(G) + H ‚Ä≤(zÃÑ)‚àóD‚àó(H ),
where D‚àó : Sm ‚Üí 
m is the adjoint of the linear operator D given by
D‚àó(A) = (a11, . . . , amm)T , A ‚àà Sm .
Denote by Œ∑G := D‚àó(G) ‚àà 
m and Œ∑H := D‚àó(H ) ‚àà 
m . Also, since A =
D(G(zÃÑ))+D(H(zÃÑ)) is a diagonal matrix, we can just choose P ‚â° I in the eigenvalue
decomposition (10) of A. Therefore, by (33) and (34), we have that
Œ∑Gi = 0 if Gi (zÃÑ) > 0 and Hi (zÃÑ) = 0,
Œ∑Hi = 0 if Gi (zÃÑ) = 0 and Hi (zÃÑ) < 0.
Moreover, since GŒ≤Œ≤ = ÃÉGŒ≤Œ≤  0 and HŒ≤Œ≤ = ÃÉHŒ≤Œ≤  0, we know that the diagonal
elements Œ∑G and Œ∑H satisfy
Œ∑Gi ‚â§ 0 and Œ∑Hi ‚â• 0 if Gi (zÃÑ) = 0 and Hi (zÃÑ) = 0. (54)
123
C. Ding et al.
Therefore, we conclude that the feasible point zÃÑ is also a S-stationary point of the
original vector MPCC problem with the Lagrange multiplier (Œªh, Œªg, Œ∑G , Œ∑H ) ‚àà 
p√ó

q √ó
m √ó
m .
For the M- and C-stationary conditions, it is easy to check that if a feasible point
zÃÑ is a M- (or C-)stationary point (see e.g., [47,61] for the definitions) of the original
MPCC problem, then zÃÑ is also a M- (or C-)stationary point of the SDCMPCC problem
(53). However, the converse may not hold. For example, consider the following vector
MPCC problem
min z1 ‚àí 258 z2 ‚àí z3 ‚àí 12 z4
s.t. z24 ‚â§ 0,
0 ‚â§ G(z) ‚ä• H(z) ‚â§ 0,
(55)
where G : 
4 ‚Üí 
2 and H : 
4 ‚Üí 
2 are defined as
G(z) :=
[
6z1 ‚àí z3 ‚àí z4
z1
]
and H(z) :=
[
6z2 + z3
z2
]
, z ‚àà 
4.
It is easy to see that z‚àó = (0, 0, 0, 0) is the unqiue optimal solution of (55). By
considering the weakly stationary condition (see e.g., [61] for the definition) of (55),
we know that the corresponding Lagrange multiplier (Œªg, Œ∑G , Œ∑H ) ‚àà 
 √ó 
2 √ó 
2
satisfies
Œªg ‚â• 0, Œ∑G =
[‚àí1/2
2
]
and Œ∑H =
[
1/2
1/8
]
.
Therefore, the optimal solution z‚àó = (0, 0, 0, 0) is a weakly stationary point. However,
by noting that z‚àó1 = z‚àó2 = 0, but Œ∑G2 > 0 and Œ∑H2 > 0, we know that z‚àó is neither the
M-stationary point nor the C-stationary point.
Next, consider the corresponding SDCMPCC problem (53), i.e.,
min z1 ‚àí 258 z2 ‚àí z3 ‚àí 12 z4
s.t. z24 ‚â§ 0,
S2+  D(G(z)) ‚ä• D(H(z)) ‚àà S2‚àí.
(56)
We know that the Lagrange multiplier (Œªg, G , H ) ‚àà 
 √ó S2 √ó S2 with respect to
the optimal solution z‚àó satisfies
Œªg ‚â• 0, G11 = ‚àí1/2, G22 = 2, H11 = 1/2 and H22 = 1/8.
Choose
G =
[‚àí1/2 0
0 2
]
and H =
[
1/2 1/4
1/4 1/8
]
.
Let
Q =
[‚àí2/‚àö5 1/‚àö5
‚àí1/‚àö5 ‚àí2/‚àö5
]
‚àà O2.
123
First order optimality conditions
Then, we have
QT G Q =
[
0 1
1 3/2
]
and QT H Q =
[
5/8 0
0 0
]
.
Conisder the partition Œ≤+ = ‚àÖ, Œ≤0 = {1}, Œ≤‚àí = {2}. Since QTŒ≤0G QŒ≤0 = 0 and
QTŒ≤0
H QŒ≤0 = 5/8, we know that there exist Q ‚àà O|Œ≤| and a partition œÄ(Œ≤) =
(Œ≤+, Œ≤0, Œ≤‚àí) of Œ≤ such that the Lagrange multiplier (Œªg, G , H ) ‚àà 
 √ó S2 √ó
S2 satisfies (31)‚Äì(35) and (38)‚Äì(39). Therefore, although the optimal solution z‚àó =
(0, 0, 0, 0) is not even a C-stationary point of the original MPCC (55), it is a M-
stationary point (also a C-stationary point) of the corresponding SDCMPCC (56).
Acknowledgments The authors are grateful to the anonymous referees for their constructive suggestions
and comments which helped to improve the presentation of the materials in this paper.
9 Appendix
Proof of Proposition 2.6 Firstly, we will show that (16) holds for the case that A =
(A). For any H ‚àà Sn , denote Y := A + H . Let P ‚àà On (depending on H ) be such
that
(A) + H = P(Y )PT . (57)
Let Œ¥ > 0 be any fixed number such that 0 < Œ¥ < Œª|Œ±|2 if Œ±  = ‚àÖ and be any fixed
positive number otherwise. Then, define the following continuous scalar function
f (t) :=
‚éß
‚é®
‚é©
t if t > Œ¥,
2t ‚àí Œ¥ if Œ¥2 < t < Œ¥,
0 if t < Œ¥2 .
Therefore, we have
{Œª1(A), . . . , Œª|Œ±|(A)} ‚àà (Œ¥,+‚àû) and {Œª|Œ±|+1(A), . . . , Œªn(A)} ‚àà
(
‚àí‚àû, Œ¥
2
)
.
For the scalar function f , let F : Sn ‚Üí Sn be the corresponding L√∂wner‚Äôs operator
[25], i.e., for any Z ‚àà Sn ,
F(Z) :=
n‚àë
i=1
f (Œªi (Z))ui u
T
i , (58)
where U ‚àà On satisfies that Z = U(Z)U T . Since f is real analytic on the open
set (‚àí‚àû, Œ¥2 ) ‚à™ (Œ¥,+‚àû), we know from [52, Theorem 3.1] that F is analytic at A.
Therefore, since A = (A), it is well-known (see e.g., [4, Theorem V.3.3]) that for
H sufficiently close to zero,
F(A + H) ‚àí F(A) ‚àí F ‚Ä≤(A)H = O(‚ÄñH‚Äñ2) (59)
123
C. Ding et al.
and
F ‚Ä≤(A)H =
‚é°
‚é¢‚é£
HŒ±Œ± HŒ±Œ≤ Œ±Œ≥ ‚ó¶ HŒ±Œ≥
H TŒ±Œ≤ 0 0
TŒ±Œ≥ ‚ó¶ H TŒ±Œ≥ 0 0
‚é§
‚é•‚é¶ ,
where  ‚àà Sn is given by (15) . Let R(¬∑) := Sn+(¬∑) ‚àí F(¬∑). By the definition of f ,
we know that F(A) = A+ := Sn+(A), which implies that R(A) = 0. Meanwhile, it
is clear that the matrix valued function R is directionally differentiable at A, and from
(14), the directional derivative of R for any given direction H ‚àà Sn , is given by
R‚Ä≤(A; H) = ‚Ä≤Sn+(A; H) ‚àí F
‚Ä≤(A)H =
‚é°
‚é£
0 0 0
0 S |Œ≤|+ (HŒ≤Œ≤) 0
0 0 0
‚é§
‚é¶ . (60)
By the Lipschitz continuity of Œª(¬∑), we know that for H sufficiently close to zero,
{Œª1(Y ), . . . , Œª|Œ±|(Y )} ‚àà (Œ¥,+‚àû), {Œª|Œ±|+1(Y ), . . . , Œª|Œ≤|(Y )} ‚àà
(
‚àí‚àû, Œ¥
2
)
and
{Œª|Œ≤|+1(Y ), . . . , Œªn(Y )} ‚àà (‚àí‚àû, 0).
Therefore, by the definition of F , we know that for H sufficiently close to zero,
R(A + H) = Sn+(A + H) ‚àí F(A + H) = P
‚é°
‚é£
0 0 0
0 ((Y )Œ≤Œ≤)+ 0
0 0 0
‚é§
‚é¶ PT . (61)
Since P satisfies (57), we know that for any Sn  H ‚Üí 0, there exists an orthogonal
matrix Q ‚àà O|Œ≤| such that
PŒ≤ =
‚é°
‚é£
O(‚ÄñH‚Äñ)
PŒ≤Œ≤
O(‚ÄñH‚Äñ)
‚é§
‚é¶ and PŒ≤Œ≤ = Q + O(‚ÄñH‚Äñ2), (62)
which was stated in [51] and was essentially proved in the derivation of Lemma 4.12
in [50]. Therefore, by noting that ((Y )Œ≤Œ≤)+ = O(‚ÄñH‚Äñ), we obtain from (60), (61)
and (62) that
R(A + H) ‚àí R(A) ‚àí R‚Ä≤(A; H)
=
‚é°
‚é¢‚é£
O(‚ÄñH‚Äñ3) O(‚ÄñH‚Äñ2) O(‚ÄñH‚Äñ3)
O(‚ÄñH‚Äñ2) PŒ≤Œ≤((Y )Œ≤Œ≤)+PTŒ≤Œ≤ ‚àí S |Œ≤|+ (HŒ≤Œ≤) O(‚ÄñH‚Äñ
2)
O(‚ÄñH‚Äñ3) O(‚ÄñH‚Äñ2) O(‚ÄñH‚Äñ3)
‚é§
‚é•‚é¶
123
First order optimality conditions
=
‚é°
‚é£
0 0 0
0 Q((Y )Œ≤Œ≤)+QT ‚àí S |Œ≤|+ (HŒ≤Œ≤) 0
0 0 0
‚é§
‚é¶+ O(‚ÄñH‚Äñ2).
By (57) and (62), we know that
(Y )Œ≤Œ≤ = PTŒ≤ (A)PŒ≤+PTŒ≤ H PŒ≤ = PTŒ≤Œ≤ HŒ≤Œ≤ PŒ≤Œ≤+O(‚ÄñH‚Äñ2)=QT HŒ≤Œ≤ Q+O(‚ÄñH‚Äñ2).
Since Q ‚àà O|Œ≤|, we have
HŒ≤Œ≤ = Q(Y )Œ≤Œ≤ QT + O(‚ÄñH‚Äñ2).
By noting that S |Œ≤|+ (¬∑) is globally Lipschitz continuous and S |Œ≤|+ (Q(Y )Œ≤Œ≤ Q
T ) =
Q((Y )Œ≤Œ≤)+QT , we obtain that
Q((Y )Œ≤Œ≤)+QT ‚àí S |Œ≤|+ (HŒ≤Œ≤)
= Q((Y )Œ≤Œ≤)+QT ‚àí S |Œ≤|+ (Q(Y )Œ≤Œ≤ Q
T ) + O(‚ÄñH‚Äñ2)
= O(‚ÄñH‚Äñ2).
Therefore,
R(A + H) ‚àí R(A) ‚àí R‚Ä≤(A; H) = O(‚ÄñH‚Äñ2). (63)
By combining (59) and (63), we know that for any Sn  H ‚Üí 0,
Sn+((A) + H) ‚àí Sn+((A)) ‚àí ‚Ä≤Sn+((A); H) = O(‚ÄñH‚Äñ
2). (64)
Next, consider the case that A = PT (A)P . Re-write (57) as
(A) + PT H P = PT P(Y )PT P.
Let HÃÉ := PT H P . Then, we have
Sn+(A + H) = P Sn+((A) + HÃÉ)P
T
.
Therefore, since P ‚àà On , we know from (64) and (14) that for any Sn  H ‚Üí 0,
(16) holds. 
Proof of Proposition 3.3 Denote the set in the righthand side of (27) by N . We
first show that Ngph NSn+
(0, 0) ‚äÜ N . By the definition of the limiting normal cone
in (8), we know that (U‚àó, V ‚àó) ‚àà Ngph NS|Œ≤|+ (0, 0) if and only if there exist two
sequences {(U k‚àó, V k‚àó)} converging to (U‚àó, V ‚àó) and {(U k, V k)} converging to (0, 0)
with (U k
‚àó
, V k
‚àó
) ‚àà NœÄgph NSn+ (U
k, V k) and (U k, V k) ‚àà gph NSn+ for each k.
123
C. Ding et al.
For each k, denote Ak :=U k+V k ‚àà Sn and let Ak = Pk(Ak)(Pk)T with Pk ‚ààOn
be the eigenvalue decomposition of Ak . Then for any i ‚àà{1, . . . , n}, we have
lim
k‚Üí‚àû Œªi (A
k) = 0.
Since {Pk}‚àûk=1 is uniformly bounded, by taking a subsequence if necessary, we may
assume that {Pk}‚àûk=1 converges to an orthogonal matrix Q := limk‚Üí‚àûPk ‚àà On . For
each k, we know that the vector Œª(Ak) is an element of 
n. By taking a subsequence
if necessary, we may assume that for each k, (Ak) has the same form, i.e.,
(Ak) =
‚é°
‚é£
(Ak)Œ≤+Œ≤+ 0 0
0 (Ak)Œ≤0Œ≤0 0
0 0 (Ak)Œ≤‚àíŒ≤‚àí
‚é§
‚é¶ ,
where Œ≤+, Œ≤0 and Œ≤‚àí are the three index sets defined by
Œ≤+ := {i : Œªi (Ak) > 0}, Œ≤0 := {i : Œªi (Ak) = 0} and Œ≤‚àí := {i : Œªi (Ak) < 0}.
Since (U k
‚àó
, V k
‚àó
) ‚àà NœÄgph NSn+ (U
k, V k), we know from Proposition 3.2 that for each
k, there exist
k1 =
‚é°
‚é¢‚é£
EŒ≤+Œ≤+ EŒ≤+Œ≤0 
k
Œ≤+Œ≤‚àí
ETŒ≤+Œ≤0 0 0
(kŒ≤+Œ≤‚àí)
T 0 0
‚é§
‚é•‚é¶
and
k2 =
‚é°
‚é£
0 0 EŒ≤+Œ≤‚àí ‚àí kŒ≤+Œ≤‚àí
0 0 EŒ≤0Œ≤‚àí
(EŒ≤+Œ≤‚àí ‚àí kŒ≤+Œ≤‚àí)T (EŒ≤0Œ≤‚àí)T EŒ≤‚àíŒ≤‚àí
‚é§
‚é¶
such that
k1 ‚ó¶ UÃÉ‚àók + k2 ‚ó¶ VÃÉ k
‚àó = 0, UÃÉ k‚àóŒ≤0Œ≤0  0 and VÃÉ k
‚àó
Œ≤0Œ≤0
 0, (65)
where UÃÉ k
‚àó = (Pk)T U k‚àóPk , VÃÉ k‚àó = (Pk)T V k‚àóPk and
(k)i, j = max{Œªi (A
k), 0} ‚àí max{Œª j (Ak), 0}
Œªi (Ak) ‚àí Œª j (Ak) ‚àÄ (i, j) ‚àà Œ≤+ √ó Œ≤‚àí. (66)
Since for each k, each element of kŒ≤+Œ≤‚àí belongs to the interval [0, 1], by further
taking a subsequence if necessary, we may assume that the limit of {kŒ≤+Œ≤‚àí}‚àûk=1 exists.
123
First order optimality conditions
Therefore, by the definition of Un in (24), we know that
lim
k‚Üí‚àû
k
1 = 1 ‚àà Un and limk‚Üí‚àû
k
2 = 2,
where 1 and 2 are given by (26). Therefore, we obtain from (65) that (U‚àó, V ‚àó) ‚àà N .
The other direction, i.e., Ngph NSn+
(0, 0) ‚äá N can be proved in a similar but simpler
way to that of the second part of Theorem 3.1. We omit it here. 
Proof of Theorem 3.1 ‚Äú‚áí‚Äù Suppose that (X‚àó, Y ‚àó) ‚àà Ngph NSn+ (X, Y ). By the defin-
ition of the limiting normal cone in (8), we know that (X‚àó, Y ‚àó) = limk‚Üí‚àû(Xk‚àó, Y k‚àó)
with
(Xk
‚àó
, Y k
‚àó
) ‚àà NœÄgph NSn+ (X
k, Y k) k = 1, 2, . . . ,
where (Xk, Y k) ‚Üí (X, Y ) and (Xk, Y k) ‚àà gph NSn+ . For each k, denote Ak :=
Xk +Y k and let Ak = Pk(Ak)(Pk)T be the eigenvalue decomposition of Ak . Since
(A) = limk‚Üí‚àû(Ak), we know that (Ak)Œ±Œ± $ 0, (Ak)Œ≥ Œ≥ ‚â∫ 0 for k sufficiently
large and limk‚Üí‚àû(Ak)Œ≤Œ≤ = 0.
Since {Pk}‚àûk=1 is uniformly bounded, by taking a subsequence if necessary, we
may assume that {Pk}‚àûk=1 converges to an orthogonal matrix PÃÇ ‚àà On(A). We can
write PÃÇ = [PŒ± PŒ≤ Q PŒ≥
]
, where Q ‚àà O|Œ≤| can be any |Œ≤| √ó |Œ≤| orthogonal matrix.
By further taking a subsequence if necessary, we may also assume that there exists a
partition œÄ(Œ≤) = (Œ≤+, Œ≤0, Œ≤‚àí) of Œ≤ such that for each k,
Œªi (A
k) > 0 ‚àÄ i ‚àà Œ≤+, Œªi (Ak) = 0 ‚àÄ i ‚àà Œ≤0 and Œªi (Ak) < 0 ‚àÄ i ‚àà Œ≤‚àí.
This implies that for each k,
{i : Œªi (Ak) > 0}=Œ± ‚à™ Œ≤+, {i : Œªi (Ak) = 0}=Œ≤0 and {i : Œªi (Ak) < 0}=Œ≤‚àí ‚à™ Œ≥.
Then, for each k, since (Xk
‚àó
, Y k
‚àó
) ‚àà NœÄgph NSn+ (X
k, Y k), we know from Proposition
3.2 that there exist
k1 =
‚é°
‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é£
EŒ±Œ± EŒ±Œ≤+ EŒ±Œ≤0 
k
Œ±Œ≤‚àí 
k
Œ±Œ≥
ETŒ±Œ≤+ EŒ≤+Œ≤+ EŒ≤+Œ≤0 
k
Œ≤+Œ≤‚àí 
k
Œ≤+Œ≥
ETŒ±Œ≤0 E
T
Œ≤+Œ≤0 0 0 0
kŒ±Œ≤‚àí
T
kŒ≤+Œ≤‚àí
T
0 0 0
kŒ±Œ≥
T
kŒ≤+Œ≥
T
0 0 0
‚é§
‚é•‚é•‚é•‚é•‚é•‚é•‚é•‚é¶
123
C. Ding et al.
and
k2 =
‚é°
‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é£
0 0 0 EŒ±Œ≤‚àí ‚àí kŒ±Œ≤‚àí EŒ±Œ≥ ‚àí kŒ±Œ≥
0 0 0 EŒ≤+Œ≤‚àí ‚àí kŒ≤+Œ≤‚àí EŒ≤+Œ≥ ‚àí kŒ≤+Œ≥
0 0 0 EŒ≤0Œ≤‚àí EŒ≤0Œ≥
(EŒ±Œ≤‚àí ‚àí kŒ±Œ≤‚àí)T (EŒ≤+Œ≤‚àí ‚àí kŒ≤+Œ≤‚àí )T ETŒ≤0Œ≤‚àí EŒ≤‚àíŒ≤‚àí EŒ≤‚àíŒ≥
(EŒ±Œ≥ ‚àí kŒ±Œ≥ )T (EŒ≤+Œ≥ ‚àí kŒ≤+Œ≥ )T ETŒ≤0Œ≥ ETŒ≤‚àíŒ≥ EŒ≥ Œ≥
‚é§
‚é•‚é•‚é•‚é•‚é•‚é•‚é•‚é¶
such that
k1 ‚ó¶ XÃÉ k
‚àó + k2 ‚ó¶ YÃÉ k
‚àó = 0, XÃÉ k‚àóŒ≤0Œ≤0  0 and YÃÉ k
‚àó
Œ≤0Œ≤0
 0, (67)
where XÃÉ k
‚àó = (Pk)T Xk‚àóPk, YÃÉ k‚àó = (Pk)T Y k‚àóPk and
(k)i, j = max{Œªi (A
k), 0} ‚àí max{Œª j (Ak), 0}
Œªi (Ak) ‚àí Œª j (Ak) ‚àÄ (i, j) ‚àà (Œ±‚à™Œ≤+)√ó(Œ≤‚àí‚à™Œ≥ ). (68)
By taking limits as k ‚Üí ‚àû, we obtain that
XÃÉ k
‚àó ‚Üí PÃÇT X‚àó PÃÇ =
‚é°
‚é¢‚é¢‚é£
XÃÉ‚àóŒ±Œ± XÃÉ‚àóŒ±Œ≤ Q XÃÉ‚àóŒ±Œ≥
(XÃÉ‚àóŒ±Œ≤ Q)T QT XÃÉ‚àóŒ≤Œ≤ Q QT XÃÉ‚àóŒ≤Œ≥
(XÃÉ‚àóŒ±Œ≥ )T (QT XÃÉ‚àóŒ≤Œ≥ )T XÃÉŒ≥ Œ≥
‚é§
‚é•‚é•‚é¶
and
YÃÉ k
‚àó ‚Üí PÃÇT Y ‚àó PÃÇ =
‚é°
‚é¢‚é¢‚é£
YÃÉ ‚àóŒ±Œ± YÃÉ ‚àóŒ±Œ≤ Q YÃÉ ‚àóŒ±Œ≥
(YÃÉ ‚àóŒ±Œ≤ Q)T QT YÃÉ ‚àóŒ≤Œ≤ Q QT YÃÉ ‚àóŒ≤Œ≥
(YÃÉ ‚àóŒ±Œ≥ )T (QT YÃÉ ‚àóŒ≤Œ≥ )T YÃÉŒ≥ Œ≥
‚é§
‚é•‚é•‚é¶ .
By simple calculations, we obtain from (68) that
lim
k‚Üí‚àû
k
Œ±Œ≤‚àí = EŒ±Œ≤‚àí , limk‚Üí‚àû
k
Œ≤+Œ≥ = 0 and limk‚Üí‚àû
k
Œ±Œ≥ = Œ±Œ≥ .
This, together with the definition of U|Œ≤|, shows that there exist 1 ‚àà U|Œ≤| and the
corresponding 2 such that
lim
k‚Üí‚àû
k
1 =
‚é°
‚é£
EŒ±Œ± EŒ±Œ≤ Œ±Œ≥
EŒ≤Œ± 1 0
TŒ±Œ≥ 0 0
‚é§
‚é¶ = 1 +
‚é°
‚é£
0 0 0
0 1 0
0 0 0
‚é§
‚é¶
and
lim
k‚Üí‚àû
k
2 =
‚é°
‚é£
0 0 EŒ±Œ≥ ‚àí Œ±Œ≥
0 2 EŒ≤Œ≥
(EŒ±Œ≥ ‚àí Œ±Œ≥ )T EŒ≥Œ≤ EŒ≥ Œ≥
‚é§
‚é¶ = 2 +
‚é°
‚é£
0 0 0
0 2 0
0 0 0
‚é§
‚é¶ ,
123
First order optimality conditions
where 1 and 2 are given by (22). Meanwhile, since Q ‚àà O|Œ≤|, by taking limits in
(67) as k ‚Üí ‚àû, we obtain that
1 ‚ó¶ XÃÉ‚àó + 2 ‚ó¶ YÃÉ ‚àó = 0, 1 ‚ó¶ QT XÃÉ‚àóŒ≤Œ≤ Q + 2 ‚ó¶ QT YÃÉ ‚àóŒ≤Œ≤ Q = 0 (69)
and
QTŒ≤0 XÃÉ
‚àó
Œ≤Œ≤ QŒ≤0  0 and QTŒ≤0 YÃÉ ‚àóŒ≤Œ≤ QŒ≤0  0.
Hence, by Proposition 3.3, we conclude that (XÃÉ‚àóŒ≤Œ≤, YÃÉ ‚àóŒ≤Œ≤) ‚àà Ngph NS|Œ≤|+ (0, 0). From
(69), it is easy to check that (X‚àó, Y ‚àó) satisfies the conditions (28) and (29).
‚Äú‚áê‚Äù Let (X‚àó, Y ‚àó) satisfies (28) and (29). We shall show that there exist two
sequences {(Xk, Y k)} converging to (X, Y ) and {(Xk‚àó, Y k‚àó)} converging to (X‚àó, Y ‚àó)
with (Xk, Y k) ‚àà gph NSn+ and (Xk
‚àó
, Y k
‚àó
) ‚àà NœÄgph NSn+ (X
k, Y k) for each k.
Since (XÃÉ‚àóŒ≤Œ≤, YÃÉ ‚àóŒ≤Œ≤) ‚àà Ngph NS|Œ≤|+ (0, 0), by Proposition 3.3, we know that there exist
an orthogonal matrix Q ‚àà O|Œ≤| and 1 ‚àà U|Œ≤| such that
1 ‚ó¶ QT XÃÉ‚àóŒ≤Œ≤ Q + 2 ‚ó¶ QT YÃÉ ‚àóŒ≤Œ≤ Q = 0, QTŒ≤0 XÃÉ‚àóŒ≤Œ≤ QŒ≤0  0 and QTŒ≤0 YÃÉ ‚àóŒ≤Œ≤ QŒ≤0  0.
(70)
Since 1 ‚àà U|Œ≤|, we know that there exists a sequence {zk} ‚àà 
|Œ≤| converging to 0
such that 1 = limk‚Üí‚àûD(zk). Without loss of generality, we can assume that there
exists a partition œÄ(Œ≤) = (Œ≤+, Œ≤0, Œ≤‚àí) ‚àà P(Œ≤) such that for all k,
zki > 0 ‚àÄ i ‚àà Œ≤+, zki = 0 ‚àÄ i ‚àà Œ≤0 and zki < 0 ‚àÄ i ‚àà Œ≤‚àí.
For each k, let
Xk = PÃÇ
‚é°
‚é¢‚é¢‚é¢‚é¢‚é£
(A)Œ±Œ± 0 0 0 0
0 (zk)+ 0 0 0
0 0 0 0 0
0 0 0 0 0
0 0 0 0 0
‚é§
‚é•‚é•‚é•‚é•‚é¶
PÃÇT and Y k = PÃÇ
‚é°
‚é¢‚é¢‚é¢‚é¢‚é£
0 0 0 0 0
0 0 0 0 0
0 0 0 0 0
0 0 0 (zk)‚àí 0
0 0 0 0 (A)Œ≥ Œ≥
‚é§
‚é•‚é•‚é•‚é•‚é¶
PÃÇT,
where PÃÇ = [PŒ± PŒ≤ Q PŒ≥
] ‚àà On(A). Then, it is clear that {(Xk , Y k)} ‚àà gph NSn+ converging
to (X, Y ). For each k, denote
Ak = Xk + Y k , k1 =
‚é°
‚é¢‚é¢‚é¢‚é¢‚é¢‚é¢‚é£
EŒ±Œ± EŒ±Œ≤+ EŒ±Œ≤0 
k
Œ±Œ≤‚àí Œ±Œ≥
ETŒ±Œ≤+ EŒ≤+Œ≤+ EŒ≤+Œ≤0 
k
Œ≤+Œ≤‚àí 
k
Œ≤+Œ≥
ETŒ±Œ≤0 E
T
Œ≤+Œ≤0 0 0 0
(kŒ±Œ≤‚àí)
T (kŒ≤+Œ≤‚àí)
T 0 0 0
(Œ±Œ≥ )
T (kŒ≤+Œ≥ )
T 0 0 0
‚é§
‚é•‚é•‚é•‚é•‚é•‚é•‚é¶
123
C. Ding et al.
and
k2 =
‚é°
‚é¢‚é¢‚é¢‚é¢‚é¢‚é£
0 0 0 EŒ±Œ≤‚àí ‚àí kŒ±Œ≤‚àí EŒ±Œ≥ ‚àí Œ±Œ≥
0 0 0 EŒ≤+Œ≤‚àí ‚àí kŒ≤+Œ≤‚àí EŒ≤+Œ≥ ‚àí kŒ≤+Œ≥
0 0 0 EŒ≤0Œ≤‚àí EŒ≤0Œ≥
(EŒ±Œ≤‚àí ‚àí kŒ±Œ≤‚àí)T (EŒ≤+Œ≤‚àí ‚àí kŒ≤+Œ≤‚àí )T ETŒ≤0Œ≤‚àí EŒ≤‚àíŒ≤‚àí EŒ≤‚àíŒ≥
(EŒ±Œ≥ ‚àí Œ±Œ≥ )T (EŒ≤+Œ≥ ‚àí kŒ≤+Œ≥ )T ETŒ≤0Œ≥ ETŒ≤‚àíŒ≥ EŒ≥ Œ≥
‚é§
‚é•‚é•‚é•‚é•‚é•‚é¶
,
where
(k)i, j = max{Œªi (A
k)), 0} ‚àí max{Œª j (Ak)), 0}
Œªi (Ak) ‚àí Œª j (Ak) ‚àÄ (i, j) ‚àà (Œ± ‚à™ Œ≤+) √ó (Œ≤‚àí ‚à™ Œ≥ ).
Next, for each k, we define two matrices XÃÇ k
‚àó
, YÃÇ k
‚àó ‚àà Sn . Let i, j ‚àà {1, . . . , n}. If
(i, j) and ( j, i) /‚àà (Œ± √ó Œ≤‚àí) ‚à™ (Œ≤+ √ó Œ≥ ) ‚à™ (Œ≤ √ó Œ≤). We define
XÃÇ k
‚àó
i, j ‚â° XÃÉ‚àói, j , YÃÇ k
‚àó
i, j ‚â° YÃÉ ‚àói, j , k = 1, 2, . . . . (71)
Otherwise, denote ck := (k)i, j , k = 1, 2, . . .. We consider the following four cases.
Case 1 (i, j) or ( j, i) ‚àà Œ± √ó Œ≤‚àí. In this case, we know from (28) that XÃÉ‚àói, j = 0. Since
ck  = 0 for all k and ck ‚Üí 1 as k ‚Üí ‚àû, we define
YÃÇ k
‚àó
i, j ‚â° YÃÉ ‚àói, j and XÃÇ k
‚àó
i, j =
ck ‚àí 1
ck
YÃÇ k
‚àó
i, j , k = 1, 2, . . . . (72)
Then, we have
ck XÃÇk
‚àó
i, j + (1 ‚àí ck)YÃÇ k
‚àó
i, j = 0 ‚àÄ k and (XÃÇ k
‚àó
i, j , YÃÇ
k‚àó
i, j ) ‚Üí (XÃÉ‚àói, j , YÃÉ ‚àói, j ) as k ‚Üí ‚àû.
Case 2 (i, j) or ( j, i) ‚àà Œ≤+ √ó Œ≥ . In this case, we know from (28) that YÃÉ ‚àói, j = 0. Since
ck  = 1 for all k and ck ‚Üí 0 as k ‚Üí ‚àû, we define
XÃÇ k
‚àó
i, j ‚â° XÃÉ‚àói, j and YÃÇ k
‚àó
i, j =
ck
ck ‚àí 1 XÃÇ
k‚àó
i, j , k = 1, 2, . . . . (73)
Then, we know that
ck XÃÇk
‚àó
i, j + (1 ‚àí ck)YÃÇ k
‚àó
i, j = 0 ‚àÄ k and (XÃÇ k
‚àó
i, j , YÃÇ
k‚àó
i, j ) ‚Üí (XÃÉ‚àói, j , YÃÉ ‚àói, j ) as k ‚Üí ‚àû.
Case 3 (i, j) or ( j, i) ‚àà (Œ≤ √ó Œ≤)\(Œ≤+ √ó Œ≤‚àí). In this case, we define
XÃÇ k
‚àó
i, j ‚â° QTi XÃÉ‚àóŒ≤Œ≤ Q j , YÃÇ k
‚àó
i, j ‚â° QTi YÃÉ ‚àóŒ≤Œ≤ Q j , k = 1, 2, . . . . (74)
Case 4 (i, j) or ( j, i) ‚àà Œ≤+ √ó Œ≤‚àí. Since c ‚àà [0, 1], we consider the following two
sub-cases:
123
First order optimality conditions
Case 4.1 c  = 1. Since ck  = 1 for all k large enough, we define
XÃÇ k
‚àó
i, j ‚â° QTi XÃÉ‚àóŒ≤Œ≤ Q j and YÃÇ k
‚àó
i, j =
ck
ck ‚àí 1 XÃÇ
k‚àó
i, j , k = 1, 2, . . . . (75)
Then, from (70), we know that
YÃÇ k
‚àó
i, j ‚Üí
c
c ‚àí 1 Q
T
i XÃÉ
‚àó
Œ≤Œ≤ Q j = QTi YÃÉ ‚àóŒ≤Œ≤ Q j as k ‚Üí ‚àû.
Case 4.2 c = 1. Since ck  = 0 for all k large enough, we define
YÃÇ k
‚àó
i, j ‚â° QTi YÃÉ ‚àóŒ≤Œ≤ Q j and XÃÇ k
‚àó
i, j =
ck ‚àí 1
ck
YÃÇ k
‚àó
i, j , k = 1, 2, . . . . (76)
Then, again from (70), we know that
XÃÇ k
‚àó
i, j ‚Üí
c ‚àí 1
c
QTi YÃÉ
‚àó
Œ≤Œ≤ Q j = QTi XÃÉ‚àóŒ≤Œ≤ Q j as k ‚Üí ‚àû.
For each k, define Xk
‚àó = PÃÇ XÃÇ k‚àó PÃÇT and Y k‚àó = PÃÇYÃÇ k‚àó PÃÇT . Then, from (71)‚Äì(76)
we obtain that
k1 ‚ó¶ PÃÇT Xk‚àó PÃÇ + k2 ‚ó¶ PÃÇT Y k‚àó PÃÇ = 0, k = 1, 2, . . . .
and
(PÃÇT Xk
‚àó
PÃÇ, PÃÇT Y k
‚àó
PÃÇ) ‚Üí (PÃÇT X‚àó PÃÇ, PÃÇT Y ‚àó PÃÇ) as k ‚Üí ‚àû. (77)
Moreover, from (74) and (70), we have
QTŒ≤0 XÃÉ
k‚àó
Œ≤Œ≤ QŒ≤0 ‚â° QTŒ≤0 XÃÉ‚àóŒ≤Œ≤ QŒ≤0  0 and QTŒ≤0 YÃÉ k
‚àó
Œ≤Œ≤ QŒ≤0 ‚â° QTŒ≤0 YÃÉ ‚àóŒ≤Œ≤ QŒ≤0  0,
k = 1, 2, . . . .
From Proposition 3.2 and (77), we know that
(Xk
‚àó
, Y k
‚àó
) ‚àà NœÄgph NSn+ (X
k, Y k) and (X‚àó, Y ‚àó) = lim
k‚Üí‚àû(X
k‚àó, Y k‚àó).
Hence, the assertion of the theorem follows.
References
1. Aubin, J.-P.: Lipschitz behavior of solutions to convex minimization problems. Math. Oper. Res. 9,
87‚Äì111 (1984)
2. Ben-Tal, A., Nemirovski, A.: Robust convex optimization. Math. Oper. Res. 23, 769‚Äì805 (1998)
3. Ben-Tal, A., Nemirovski, A.: Robust convex optimization-methodology and applications. Math. Pro-
gram. 92, 453‚Äì480 (2002)
4. Bhatia, R.: Matrix Analysis. Springer, New York (1997)
5. Bi, S., Han, L., Pan, S.: Approximation of rank function and its application to the nearest low-rank
correlation matrix. J. Glob. Optim. 57, 1113‚Äì1137 (2013)
123
C. Ding et al.
6. Bonnans, J.F., Shapiro, A.: Perturbation Analysis of Optimization Problems. Springer, New York
(2000)
7. Brigo, D., Mercurio, F.: Calibrating LIBOR. Risk Mag. 15, 117‚Äì122 (2002)
8. Burge, J.P., Luenberger, D.G., Wenger, D.L.: Estimation of structured covariance matrices. Proc. IEEE
70, 963‚Äì974 (1982)
9. Clarke, F.H.: Optimization and Nonsmooth Analysis. Wiley-Interscience, New York (1983)
10. Clarke, F.H., Ledyaev, Yu.S, Stern, R.J., Wolenski, P.R.: Nonsmooth Analysis and Control Theory.
Springer, New York (1998)
11. de Gaston, R.R.E., Safonov, M.G.: Exact calculation of the multiloop stability margin. IEEE Trans.
Autom. Control 33, 156‚Äì171 (1988)
12. Dempe, S.: Foundations of Bilevel Programming. Kluwer, Berlin (2002)
13. Eaves, B.C.: On the basic theorem for complementarity. Math. Program. 1, 68‚Äì75 (1971)
14. Faccchinei, F., Pang, J.S.: Finite-Dimensional Variational Inequalities and Complementarity Problem.
Springer, New York (2003)
15. Fazel, M.: Matrix Rank Minimization with Applications. PhD thesis, Stanford University (2002)
16. Fletcher, R.: Semi-definite matrix constraints in optimization. SIAM J. Control Optim. 23, 493‚Äì513
(1985)
17. Flegel, M.L., Kanzow, C.: On the Guignard constraint qualification for mathematical programs with
equilibrium constraints. Optimization 54, 517‚Äì534 (2005)
18. Goh, K.C., Ly, J.C., Safonov, M.G., Papavassilopoulos, G., Turan, L.: Biaffine matrix inequality prop-
erties and computational methods. In: Proceeding of the American Control Conference, Baltimore,
Maryland, pp. 850‚Äì855 (1994)
19. Henrion, R., Outrata, J.: On the calmness of a class of multifunctions. SIAM J. Optim. 13, 603‚Äì618
(2002)
20. Henrion, R., Outrata, J.: Calmness of constraint systems with applications. Math. Program. Ser. B 104,
437‚Äì464 (2005)
21. Hobbs, B.F., Metzler, C.B., Pang, J.S.: Strategic gaming analysis for electric power systems: an MPEC
approach. IEEE Trans. Power Syst. 15, 638‚Äì645 (2000)
22. Lewis, A.S.: Nonsmooth analysis of eigenvalues. Math. Program. 84, 1‚Äì24 (1999)
23. Li, Q.N., Qi, H.D.: A sequential semismooth Newton method for the nearest low-rank correlation
matrix problem. SIAM J. Optim. 21, 1641‚Äì1666 (2011)
24. Lillo, F., Mantegna, R.N.: Spectral density of the correlation matrix of factor models: a random matrix
theory approach. Phys. Rev. E 72, 016219-1‚Äì016219-10 (2005)
25. L√∂wner, K.: √úber monotone matrixfunktionen. Mathematische Zeitschrift 38, 177‚Äì216 (1934)
26. Luo, Z.Q., Pang, J.S., Ralph, D.: Mathematical Programs with Equilibrium Constraints. Cambridge
University Press, Cambridge (1996)
27. Hiriart-Urruty, J.-B., Ye, D.: Sensitivity analysis of all eigenvalues of a symmetric matrix. Numerische
Mathematik 70, 45‚Äì72 (1995)
28. Hoge, W.: A subspace identification extension to the phase correlation method. IEEE Trans. Med.
Imaging 22, 277‚Äì280 (2003)
29. Meng, F., Sun, D.F., Zhao, G.Y.: Semismoothness of solutions to generalized equations and Moreau-
Yosida regularization. Mathe. Program. 104, 561‚Äì581 (2005)
30. Mordukhovich, B.S.: Generalized differential calculus for nonsmooth and set-valued mappings. J.
Math. Anal. Appl. 183, 250‚Äì288 (1994)
31. Mordukhovich, B.S.: Variational Analysis and Generalized Differentiation, I: Basic Theory,
Grundlehren Series (Fundamental Principles of Mathematical Sciences), vol. 330. Springer, Berlin
(2006)
32. Mordukhovich, B.S.: Variational Analysis and Generalized Differentiation, II: Applications,
Grundlehren Series (Fundamental Principles of Mathematical Sciences), vol. 331. Springer, Berlin
(2006)
33. Mordukhovich, B.S., Shao, Y.: Nonsmooth sequential analysis in Asplund space. Trans. Am. Math.
Soc. 348, 215‚Äì220 (1996)
34. Outrata, J.V., KocÃÜvara, M., Zowe, J.: Nonsmooth Approach to Optimization Problem with Equilibrium
Constraints: Theory, Application and Numerical Results. Kluwer, Dordrecht (1998)
35. Overton, M., Womersley, R.S.: On the sum of the largest eigenvalues of a symmetric matrix. SIAM J.
Matrix Anal. Appl. 13, 41‚Äì45 (1992)
123
First order optimality conditions
36. Overton, M., Womersley, R.S.: Optimality conditions and duality theory for minimizing sums of the
largest eigenvalues of symmetric matrices. Math. Program. 62, 321‚Äì357 (1993)
37. Psarris, P., Floudas, C.A.: Robust stability analysis of linear and nonlinear systems with real parameter
uncertainty. AIChE Annual Meeting, p. 127e. Florida, Miami Beach (1992)
38. Qi, H.D., Fusek, P.: Metric regularity and strong regularity in linear and nonlinear semidefinite pro-
gramming. Technical Report, School of Mathematics, University of Southampton (2007)
39. Robinson, S.M.: Stability theory for systems of inequalities, part I: linear systems. SIAM J. Numer.
Anal. 12, 754‚Äì769 (1975)
40. Robinson, S.M.: Stability theory for systems of inequalities, part II: nonlinear systems. SIAM J. Numer.
Anal. 13, 473‚Äì513 (1976)
41. Robinson, S.M.: First order conditions for general nonlinear optimization. SIAM J. Appl. Math. 30,
597‚Äì607 (1976)
42. Robinson, S.M.: Some continuity properties of polyhedral multifunctions. Math. Program. Stud. 14,
206‚Äì214 (1981)
43. Rockafellar, R.T.: Convex Analysis. Princeton University Press, Princeton (1970)
44. Rockafellar, R.T., Wets, R.J.-B.: Variational Analysis. Springer, Berlin (1998)
45. Ryoo, H.S., Sahinidis, N.V.: Global optimization of nonconvex NLPs and MINLPs with applications
in process design. Comput. Chem. Eng. 19, 551‚Äì566 (1995)
46. Safonov, M.G., Goh, K.C., Ly, J.H.: Control system synthesis via bilinear matrix inequalities. In:
Proceeding of the American Control Conference, pp. 45‚Äì49. Baltimore, Maryland (1994)
47. Scheel, H., Scholtes, S.: Mathematical programs with complementarity constraints: stationarity, opti-
mality and sensitivity. Math. Oper. Res. 25, 1‚Äì22 (2000)
48. Simon, D.: Reduced order Kalman filtering without model reduction. Control Intell. Syst. 35, 169‚Äì174
(2007)
49. Sun, D.F.: The strong second-order sufficient condition and constraint nondegeneracy in nonlinear
semidefinite programming and their implications. Math. Oper. Res. 31, 761‚Äì776 (2006)
50. Sun, D.F., Sun, J.: Semismooth matrix valued functions. Math. Oper. Res. 27, 150‚Äì169 (2002)
51. Sun, D.F., Sun, J.: Strong semismoothness of eigenvalues of symmetric matrices and its applications
in inverse eigenvalue problems. SIAM J. Numer. Anal. 40, 2352‚Äì2367 (2003)
52. Tsing, N.K., Fan, M.K.H., Verriest, E.I.: On analyticity of functions involving eigenvalues. Linear
Algebra Appl. 207, 159‚Äì180 (1994)
53. VanAntwerp, J.G., Braatz, R.D., Sahinidis, N.V.: Globally optimal robust control for systems with
nonlinear time-varying perturbations. Comput. Chem. Eng. 21, S125‚ÄìS130 (1997)
54. Visweswaran, V., Floudas, C.A.: A global optimization algorithm (GOP) for certain classes of non-
convex NLPs‚ÄîI. Theory. Comput. Chem. Eng. 14, 1397‚Äì1417 (1990)
55. Visweswaran, V., Floudas, C.A.: A global optimization algorithm (GOP) for certain classes of noncon-
vex NLPs‚ÄîII. Application of theory and test problems. Comput. Chem. Eng. 14, 1419‚Äì1434 (1990)
56. Wu, L.X.: Fast at-the-money calibration of the LIBOR market model using Lagrange multipliers. J
Comput. Financ. 6, 39‚Äì77 (2003)
57. Wu, Z., Ye, J.J.: First and second order condition for error bounds. SIAM J. Optim. 14, 621‚Äì645 (2003)
58. Yan, T., Fukushima, M.: Smoothing method for mathematical programs with symmetric cone comple-
mentarity constraints. Optimization 60, 113‚Äì128 (2011)
59. Ye, J.J.: Optimality conditions for optimization problems with complementarity constraints. SIAM J.
Optim. 9, 374‚Äì387 (1999)
60. Ye, J.J.: Constraint qualifications and necessary optimality conditions for optimization problems with
variational inequality constraints. SIAM J. Optim. 10, 943‚Äì962 (2000)
61. Ye, J.J.: Necessary and sufficient optimality conditions for mathematical programs with equilibrium
constraints. J. Math. Anal. Appl. 307, 305‚Äì369 (2005)
62. Ye, J.J., Ye, X.Y.: Necessary optimality conditions for optimization problems with variational inequality
constraints. Math. Oper. Res. 22, 977‚Äì977 (1997)
63. Ye, J.J., Zhu, D.L., Zhu, Q.J.: Exact penalization and necessary optimality conditions for generalized
bilevel programming problems. SIAM J. Optim. 7, 481‚Äì507 (1997)
64. Zhang, Z.Y., Wu, L.X.: Optimal low-rank approximation to a correlation matrix. Linear Algebra Appl.
364, 161‚Äì187 (2003)
65. Zhao, Y.B.: An approximation theory of matrix rank minimization and its application to quadratic
equations. Linear Algebra Appl. 437, 77‚Äì93 (2012)
123

