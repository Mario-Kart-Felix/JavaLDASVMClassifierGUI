Mathematics
Science  
& Mathematics
Topic
Subtopic
Professor Scott P. Stevens
James Madison University
Mathematical Decision 
Making: Predictive Models 
and Optimization
Course Guidebook
PUBLISHED BY:
THE GREAT COURSES
Corporate Headquarters
4840 Westfields Boulevard, Suite 500
Chantilly, Virginia 20151-2299
Phone: 1-800-832-2412
Fax: 703-378-3819
www.thegreatcourses.com
Copyright © The Teaching Company, 2015
Printed in the United States of America
This book is in copyright. All rights reserved. 
Without limiting the rights under copyright reserved above,
no part of this publication may be reproduced, stored in 
or introduced into a retrieval system, or transmitted, 
in any form, or by any means 
(electronic, mechanical, photocopying, recording, or otherwise), 
without the prior written permission of
The Teaching Company.
i
Scott P. Stevens, Ph.D.
Professor of Computer Information Systems 
and Business Analytics 
James Madison University
Professor Scott P. Stevens is a Professor of Computer Information Systems and Business Analytics at James Madison 
University (JMU) in Harrisonburg, Virginia. 
In 1979, he received B.S. degrees in both 
Mathematics and Physics from The Pennsylvania State University, where 
completing his undergraduate work and entering a doctoral program, 
Professor Stevens worked for Burroughs Corporation (now Unisys) in the 
Advanced Development Organization. Among other projects, he contributed 
to a proposal to NASA for the Numerical Aerodynamic Simulation Facility, 
a computerized wind tunnel that could be used to test aeronautical designs 
without building physical models and to create atmospheric weather models 
better than those available at the time.
In 1987, Professor Stevens received his Ph.D. in Mathematics from The 
Pennsylvania State University, working under the direction of Torrence 
Parsons and, later, George E. Andrews, the world’s leading expert in the 
study of integer partitions. 
Professor Stevens’s research interests include analytics, combinatorics, 
graph theory, game theory, statistics, and the teaching of quantitative 
material. In collaboration with his JMU colleagues, he has published articles 
on a wide range of topics, including neural network prediction of survival 
in blunt-injured trauma patients; the effect of private school competition on 
public schools; standards of ethical computer usage in different countries; 
automatic data collection in business; the teaching of statistics and linear 
programming; and optimization of the purchase, transportation, and 
deliverability of natural gas from the Gulf of Mexico. His publications have 
appeared in a number of conference proceedings, as well as in the European 
ii
Journal of Operational Research; the International Journal of Operations 
& Production Management; Political Research Quarterly; Omega: The 
International Journal of Management Science; Neural Computing & 
Applications; INFORMS Transactions on Education; and the Decision 
Sciences Journal of Innovative Education. 
Corning Incorporated, C&P Telephone, and Globaltec. He is a member of 
the Institute for Operations Research and the Management Sciences and the 
Alpha Kappa Psi business fraternity. 
Professor Stevens’s primary professional focus since joining JMU in 1985 
has been his deep commitment to excellence in teaching. He was the 1999 
recipient of the Carl Harter Distinguished Teacher Award, JMU’s highest 
teaching award. He also has been recognized as an outstanding teacher 
its M.B.A. program. His teaching interests are wide and include analytics, 
statistics, game theory, physics, calculus, and the history of science. Much 
of his recent research focuses on the more effective delivery of mathematical 
concepts to students. 
Professor Stevens’s previous Great Course is Games People Play: Game 
Theory in Life, Business, and Beyond
iii
Table of Contents
LECTURE GUIDES
INTRODUCTION
Professor Biography ............................................................................ i
Course Scope .....................................................................................1
LECTURE 1
The Operations Research Superhighway...........................................4
LECTURE 2
Forecasting with Simple Linear Regression .....................................13
LECTURE 3
Nonlinear Trends and Multiple Regression.......................................24
LECTURE 4
Time Series Forecasting ...................................................................31
LECTURE 5
Data Mining—Exploration and Prediction .........................................40
LECTURE 6
 .............................................49
LECTURE 7
Optimization—Goals, Decisions, and Constraints ............................57
LECTURE 8
Linear Programming and Optimal Network Flow ..............................64
LECTURE 9
Scheduling and Multiperiod Planning ...............................................72
LECTURE 10
Visualizing Solutions to Linear Programs .........................................79
Table of Contents
iv
LECTURE 11
Solving Linear Programs in a Spreadsheet ......................................88
LECTURE 12
Sensitivity Analysis—Trust the Answer? ...........................................98
LECTURE 13
Integer Programming—All or Nothing.............................................106
LECTURE 14
 ...................................................116
LECTURE 15
Programs with Multiple Goals .........................................................128
LECTURE 16
Optimization in a Nonlinear Landscape ..........................................137
LECTURE 17
Nonlinear Models—Best Location, Best Pricing .............................144
LECTURE 18
Randomness, Probability, and Expectation ....................................152
LECTURE 19
Decision Trees—Which Scenario Is Best? .....................................161
LECTURE 20
Bayesian Analysis of New Information ...........................................171
LECTURE 21
Markov Models—How a Random Walk Evolves ............................178
LECTURE 22
Queuing—Why Waiting Lines Work or Fail ....................................188
LECTURE 23
Monte Carlo Simulation for a Better Job Bid ..................................197
Table of Contents
v
LECTURE 24
Stochastic Optimization and Risk ...................................................210
Entering Linear Programs into a Spreadsheet ...............................221
Glossary .........................................................................................230
Bibliography ....................................................................................250
SUPPLEMENTAL MATERIAL
vi
1
Mathematical Decision Making:  
Predictive Models and Optimization
Scope:
People have an excellent track record for solving problems that are small and familiar, but today’s world includes an ever-increasing number of situations that are complicated and unfamiliar. How can 
decision makers—individuals, organizations in the public or private sectors, 
or nations—grapple with these often-crucial concerns? In many cases, 
the tools they’re choosing are mathematical ones. Mathematical decision 
making is a collection of quantitative techniques that is intended to cut 
through irrelevant information to the heart of a problem, and then it uses 
powerful tools to investigate that problem in detail, leading to a good or even 
optimal solution. 
Such a problem-solving approach used to be the province only of the 
mathematician, the statistician, or the operations research professional. All 
computing: automatic data collection and cheap, readily available computing 
power. Automatic data collection (and the subsequent storage of that data) 
often provides the analyst with the raw information that he or she needs. 
The universality of cheap computing power means that analytical techniques 
can be practically applied to much larger problems than was the case in 
the past. Even more importantly, many powerful mathematical techniques 
can now be executed much more easily in a computer environment—even 
a personal computer environment—and are usable by those who lack a 
professional’s knowledge of their intricacies. The intelligent amateur, with a 
bit of guidance, can now use mathematical techniques to address many more 
of the complicated or unfamiliar problems faced by organizations large and 
small. It is with this goal that this course was created. 
The purpose of this course is to introduce you to the most important prediction 
and optimization techniques—which include some aspects of statistics and 
data mining—especially those arising in operations research (or operational 
research). We begin each topic by developing a clear intuition of the purpose 
Sc
op
e
2
of the technique and the way it works. Then, we apply it to a problem in a 
step-by-step approach. When this involves using a computer, as often it does, 
we keep it accessible. Our work can be done in a spreadsheet environment, 
Excel. This has two advantages. First, it allows you to see our progress each 
step of the way. Second, it gives you easy access to an environment where 
you can try out what we’re examining on your own. Along the way, we 
explore many real-world situations where various prediction and optimization 
techniques have been applied—by individuals, by companies, by agencies in 
the public sector, and by nations all over the world.
Just as there are many kinds of problems to be solved, there are many 
techniques for addressing them. These tools can broadly be divided into 
predictive models and mathematical optimization. 
Predictive models allow us to take what we already know about the behavior 
of a system and use it to predict how that system will behave in new 
circumstances. Regression, for example, allows us to explore the nature of 
the interdependence of related quantities, identifying those ones that are most 
Sometimes, what we know about a system comes from its historical behavior, 
and we want to extrapolate from that. Time series forecasting allows us to 
take historical data as a guide, using it to predict what will happen next and 
informing us how much we can trust that prediction. 
kind of challenge: how to sift through those gigabytes of raw information 
and identify the meaningful patterns hidden within them. This is the province 
of data mining, a hot topic with broad applications—from online searches to 
advertising strategies and from recognizing spam to identifying deadly genes 
in DNA.
But making informed predictions is only half of mathematical decision 
making. We also look closely at optimization problems, where the goal is 
crucially on creating a model of the situation in a mathematical form, and 
3
we’ll spend considerable time on this important step. As we’ll discover, 
some optimization problems are amazingly easy to solve while others are 
much more challenging, even for a computer. We’ll determine what makes 
the difference and how we can address the obstacles. Because our input data 
isn’t always perfect, we’ll also analyze how sensitive our answers are to 
changes in those inputs.
But uncertainty can extend beyond unreliable inputs. Much of life involves 
unpredictable events, so we develop a variety of techniques intended to help 
us make good decisions in the face of that uncertainty. Decision trees allow 
us to analyze events that unfold sequentially through time and evaluate 
future scenarios, which often involve uncertainty. Bayesian analysis allows 
us to update our probabilities of upcoming events in light of more recent 
information. Markov analysis allows us to model the evolution of a chance 
process over time. Queuing theory analyzes the behavior of waiting lines—
not only for customers, but also for products, services, and Internet data 
packets. Monte Carlo simulation allows us to create a realistic model of an 
environment and then use a computer to create thousands of possible futures 
for it, giving us insights on how we can expect things to unfold. Finally, 
stochastic optimization brings optimization techniques to bear even in the 
face of uncertainty, in effect uniting the entire toolkit of deterministic and 
probabilistic approaches to mathematical decision making presented in 
this course. 
Mathematical decision making goes under many different names, depending 
on the application: operations research, mathematical optimization, analytics, 
business intelligence, management science, and others. But no matter what 
you call it, the result is a set of tools to understand any organization’s 
good answers to them more consistently. This course will teach you how 
some fairly simple math and a little bit of typing in a spreadsheet can be 
4
Le
ct
ur
e 
1:
 T
he
 O
pe
ra
tio
ns
 R
es
ea
rc
h 
Su
pe
rh
ig
hw
ay
The Operations Research Superhighway
Lecture 1
Tand computational power. Taken as a whole, the discipline of mathematical decision making has a variety of names, including 
operational research, operations research, management science, quantitative 
management, and analytics. But its purpose is singular: to apply quantitative 
methods to help people, businesses, governments, public services, military 
what they do better. In this lecture, you will be introduced to the topic of 
operations research.
What Is Operations Research?
 Operations research is an umbrella term that encompasses many 
powerful techniques. Operations research applies a variety of 
mathematical techniques to real-world problems. It leverages those 
techniques by taking advantage of today’s computational power. 
And, if successful, it comes up with an implementation strategy to 
make the situation better. This course is about some of the most 
important and most widely applicable ways that that gets done: 
through predictive models and mathematical optimization.
 In broad terms, predictive models allow us to take what we already 
know about the behavior of a system and use it to predict how that 
system will behave in new circumstances. Often, what we know 
about a system comes from its historical behavior, and we want to 
extrapolate from that.
 Sometimes, it’s not history that allows us to make predictions 
but, instead, what we know about how the pieces of the system 
even simple parts. From there, we can investigate the possibilities—
and probabilities. 
5
 But making informed predictions is only half of what this course 
is about. We’ll also be looking closely at optimization and the 
possible to a problem. And the situation can change before the best 
answer that you found has to be scrapped. There are a variety of 
optimization techniques, and some optimization questions are much 
harder to solve than others.
 Mathematical decision making offers a different way of thinking 
about problems. This way of looking at problems goes all the 
investigating the world not only qualitatively but quantitatively. 
That change turned alchemy into chemistry, natural philosophy into 
physics and biology, astrology into astronomy, and folk remedies 
into medicine.
 It took a lot longer for this mindset to make its way from science 
In the 1830s, Charles Babbage, the pioneer in early computing 
machines, expounded what today is called the Babbage principle—
namely, the idea that highly skilled, high-cost laborers should not 
be “wasting” their time on work that lower-skilled, lower-cost 
laborers could be doing. 
 
management, which attempted to apply the principles of science 
Tools of statistical analysis began to be applied to business.
 Then, Henry Ford took the idea of mass production, coupled it with 
interchangeable parts, and developed the assembly line system at 
his Ford Motor Company. The result was a company that, in the 
early 20th century, paid high wages to its workers and still sold an 
affordable automobile. 
6
Le
ct
ur
e 
1:
 T
he
 O
pe
ra
tio
ns
 R
es
ea
rc
h 
Su
pe
rh
ig
hw
ay
 But most historians set the real start of operations research in Britain 
in 1937 during the perilous days leading up to World War II—
center of radar research and development in Britain at the time. It 
essential early-warning system against the German Luftwaffe. 
 A. P. Rowe was the station superintendent in 1937, and he wanted 
to investigate how the system might be improved. Rowe not only 
assessed the equipment, but he also studied the behavior of the 
operators of the equipment, who were, after all, soldiers acting as 
technicians. The results allowed Britain to improve the performance 
previously unnoticed weaknesses in the system.
 This analytical approach was dubbed “operational research” by the 
British, and it quickly spread to other branches of their military and 
to the armed forces of other allied countries. 
Computing Power
 Operational research—or, as it came to be known in the United 
States, operations research—was useful throughout the war. It 
doubled the on-target bomb rate for B-29s attacking Japan. It 
increased U-boat hunting kill rates by about a factor of 10. Most 
it wasn’t until after the war that people started turning a serious 
eye toward what operational research could do in other areas. 
And the real move in that direction started in the 1950s, with the 
introduction of the electronic computer.
 Until the advent of the modern computer, even if we knew how 
to solve a problem from a practical standpoint, it was often just 
too much work. Weather forecasting, for example, had some 
mathematical techniques available from the 1920s, but it was 
impossible to reasonably compute the predictions of the models 
before the actual weather occurred. 
7
 Computers changed that in a big way. And the opportunities 
have only accelerated in more recent decades. Gordon E. Moore, 
to be known as Moore’s law: that transistor chip count on an 
integrated circuit doubles about every two years. Many things that 
we care about, such as processor speed and memory capacity, grow 
along with it. Over more than 50 years, the law has continued to be 
remarkably accurate. 
 It’s hard to get a grip on how much growth that kind of doubling 
implies. Moore’s law accurately predicted that the number of chips 
on an integrated circuit in 2011 was about 8 million times as high as 
it was in 1965. That’s roughly the difference between taking a single 
step and walking from Albany, Maine, to Seattle, Washington, 
by way of Houston and Los Angeles. All of that power was now 
available to individuals and companies at an affordable price. 
Mathematical Decision-Making Techniques
 Once we have the complicated and important problems, like it or 
not, along with the computing power, the last piece of the puzzle 
is the mathematical decision-making techniques that allow us to 
better understand the problem and put all that computational power 
to work. 
 
accomplish. Then, you have to get the data that’s relevant to the 
problem at hand. Data collection and cleansing can always be a 
challenge, but the computer age makes it easier than ever before. So 
much information is automatically collected, and much of it can be 
retrieved with a few keystrokes.
 But then comes what is perhaps the key step. The problem lives 
in the real world, but in order to use the powerful synergy of 
mathematics and computers, it has to be transported into a new, 
more abstract world. The problem is translated from the English 
that we use to describe it to each other into the language of 
8
Le
ct
ur
e 
1:
 T
he
 O
pe
ra
tio
ns
 R
es
ea
rc
h 
Su
pe
rh
ig
hw
ay
mathematics. Mathematical language isn’t suited to describe 
everything, but what it can capture it does with unparalleled 
precision and stunning economy. 
 Once you’ve succeeded in creating your translation—once you 
have modeled the problem—you look for patterns. You try to see 
how this new problem is like ones you’ve seen before and then 
apply your experience with them to it. 
 But when an operations researcher thinks about what other problems 
are similar to the current one, he or she is thinking about, most of all, 
the mathematical formulation, not the real-world context. In daily 
life, you might have useful categories like business, medicine, or 
engineering, but relying on these categories in operations research 
is as sensible as thinking that if you know how to buy a car, then 
you know how to make one, because both tasks deal with cars. 
 In operations research, the categorization of a problem depends 
on the mathematical character of the problem. The industry from 
which it comes only matters in helping to specify the mathematical 
character of the problem correctly. 
Modeling and Formulation
 The translation of a problem from English to math involves 
modeling and formulation. An important way that we can classify 
problems is as either stochastic or deterministic. Stochastic 
problems involve random elements; deterministic problems don’t. 
 Many problems ultimately have both deterministic and stochastic 
elements, so it’s helpful to begin this course with some statistics 
and data mining to get a sense of that combination. Both topics 
operations research. 
 Many deterministic operations research problems focus on 
optimization. For problems that are simple or on a small scale, the 
optimal solution may be obvious. But as the scale or complexity 
9
of the problem increases, the number of possible courses of action 
tends to explode. And experience shows that seat-of-the-pants 
decision making can often result in terrible strategies. 
 But once the problem is translated into mathematics, we can apply 
or lowest point in some mathematical landscape. And how we do 
this is going to depend on the topography of that landscape. It’s 
easier to navigate a pasture than a glacial moraine. It’s also easier to 
crisscrossed by fences. 
 
when the landscape is rolling hills and the fences are well behaved, 
or non-existent. But in calculus, we tend to have complicated 
functions and simple boundary conditions. For many of the 
practical problems we’ll explore in this course through linear 
programming, we have exactly the opposite: simple functions but 
complicated boundary conditions. 
 In fact, calculus tends to be useless and irrelevant for linear functions, 
both because the derivatives involved are all constants and because 
the optimum of a linear function is always on the boundary of its 
domain, never where the derivative is zero. So, we’re going to focus 
on other ways of approaching optimization problems—ways that 
don’t require a considerable background in calculus and that are 
better at handling problems with cliffs and fences.
 These deterministic techniques often allow companies to use 
computer power to solve in minutes problems that would take 
hours or days to sort out on our own. But what about more sizeable 
uncertainty? As soon as the situation that you’re facing involves a 
random process, you’re probably not going to be able to guarantee 
answer” in the sense that we mean it for deterministic problems. 
10
Le
ct
ur
e 
1:
 T
he
 O
pe
ra
tio
ns
 R
es
ea
rc
h 
Su
pe
rh
ig
hw
ay
 For example, given the opportunity to buy a lottery ticket, the best 
strategy is to buy it if it’s a winning ticket and don’t buy it if it’s not. 
But, of course, you don’t know whether it’s a winner or a loser at 
the time you’re deciding on the purchase. So, we have to come up 
with a different way to measure the quality of our decisions when 
we’re dealing with random processes. And we’ll need different 
techniques, including probability, Bayesian statistics, Markov 
analysis, and simulation. 
derivative: The derivative of a function is itself a function, one that 
derivative is captured by the vector quantity of the gradient. 
deterministic: Involving no random elements. For a deterministic problem, 
the same inputs always generate the same outputs. Contrast to stochastic. 
model
elements of the situation and the relationships among those elements. 
Moore’s law: Formulated by Intel founder Gordon Moore in 1965, it is the 
prediction that the number of transistors on an integrated circuit doubles 
roughly every two years. To date, it’s been remarkably accurate. 
operations research: The general term for the application of quantitative 
called operational research in the United Kingdom. When applied to business 
problems, it may be referred to as management science, business analytics, 
or quantitative management. 
optimization: Finding the best answer to a given problem. The best answer 
is termed “optimal.” 
Important Terms
11
optimum: The best answer. The best answer among all possible solutions is 
a global optimum. An answer that is the best of all points in its immediate 
vicinity is a local optimum. Thus, in considering the heights of points in a 
mountain range, each mountain peak is a local maximum, but the top of the 
tallest mountain is the global maximum. 
stochastic: Involving random elements. Identical inputs may generate 
differing outputs. Contrast to deterministic. 
Budiansky, Blackett’s War.
Gass and Arjang, An Annotated Timeline of Operations Research. 
Horner and List, “Armed with O.R.”
Yu, Argüello, Song, McCowan, and White, “A New Era for Crew Recovery 
at Continental Airlines.”
1. Suppose that you decide to do your holiday shopping online. You have a 
complete list of the presents desired by your friends and family as well 
as access to the inventory, prices, and shipping costs for each online site. 
How could you characterize your task as a deterministic optimization 
problem? What real-world complications may turn your problem from a 
deterministic problem into a stochastic one?
Answer: 
The most obvious goal is to minimize total money spent, but it is by no 
means the only possibility. If you are feeling generous, you might wish 
to maximize number of presents bought, maximize number of people 
for whom you give presents, and so on. You’ll face some constraints. 
Perhaps you are on a limited budget. Maybe you have to buy at least one 
present for each person on your list. You might have a lower limit on the 
money spent on a site (to get free shipping). You also can’t buy more of 
Suggested Reading
Questions and Comments
12
Le
ct
ur
e 
1:
 T
he
 O
pe
ra
tio
ns
 R
es
ea
rc
h 
Su
pe
rh
ig
hw
ay
an item than the merchant has. In this environment, you’re going to try 
to determine the number of items of each type that you buy from each 
merchant.
The problem could become stochastic if there were a chance that a 
merchant might sell out of an item, or that deliveries are delayed, or that 
you may or may not need presents for certain people.
2. Politicians will often make statements like the following: “We are going 
to provide the best-possible health care at the lowest-possible cost.” 
While on its face this sounds like a laudable optimization problem, as 
stated this goal is actually nonsensical. Why? What would be a more 
accurate way to state the intended goal?
Answer: 
It’s two goals. Assuming that we can’t have negative health-care costs, 
the lowest-possible cost is zero. But the best-possible health care is not 
going to cost zero. A more accurate way to state the goal would be to 
provide the best balance of health-care quality and cost. The trouble, of 
course, is that this immediately raises the question of who decides what 
that balance is, and how. This is exactly the kind of question that the 
politician might want not to address.
13
Forecasting with Simple Linear Regression
Lecture 2
In this lecture, you will learn about linear regression, a forecasting technique with considerable power in describing connections between related quantities in many disciplines. Its underlying idea is easy to grasp 
and easy to communicate to others. The technique is important because it 
can—and does—yield useful results in an astounding number of applications. 
But it’s also worth understanding how it works, because if applied carelessly, 
linear regression can give you a crisp mathematical prediction that has 
nothing to do with reality. 
Making Predictions from Data
 Beneath Yellowstone National Park in Wyoming is the largest 
active volcano on the continent. It is the reason that the park 
contains half of the world’s geothermal features and more than half 
of its geysers. The most famous of these is Old Faithful, which is 
not the biggest geyser, nor the most regular, but it is the biggest 
regular geyser in the park—or is it? There’s a popular belief that the 
geyser erupts once an hour, like clockwork. 
Figure 2.1
14
Le
ct
ur
e 
2:
 F
or
ec
as
tin
g 
w
ith
 S
im
pl
e 
Li
ne
ar
 R
eg
re
ss
io
n
 In Figure 2.1, a dot plot tracks the rest time between one eruption 
and the next for a series of 112 eruptions. Each rest period is shown 
as one dot. Rests of the same length are stacked on top of one 
another. The plot tells us that the shortest rest time is just over 45 
minutes, while the longest is almost 110 minutes. There seems to be 
a cluster of short rest times of about 55 minutes and another cluster 
of long rest times in the 92-minute region. 
 Based on the information we have so far, when tourists ask about 
the next eruption, the best that the park service can say is that it 
will probably be somewhere from 45 minutes to 2 hours after the 
last eruption—which isn’t very satisfactory. Can we use predictive 
modeling to do a better job of predicting Old Faithful’s next eruption 
we already know that could be used to predict the rest periods.
 
heats up. When it gets hot enough, it boils out to the surface, and then 
the geyser needs to rest while more water enters the chamber and is 
heated to boiling. If this model of a geyser is roughly right, we could 
imagine that a long eruption uses up more of the water in the chamber, 
make a scatterplot with eruption duration on the horizontal axis and 
the length of the following rest period on the vertical.
Figure 2.2
15
 When you’re dealing with bivariate data (two variables) and they’re 
thing you’re going to want to look at. It’s a wonderful tool for 
exploratory data analysis.
 Each eruption gets one dot, but that one dot tells you two things: the 
x-coordinate (the left and right position of the dot) tells you how long 
that eruption lasted, and the y-coordinate (the up and down position 
of the same dot) tells you the duration of the subsequent rest period. 
 We have short eruptions followed by short rests clustered in the 
lower left of the plot and a group of long eruptions followed by 
long rests in the upper right. There seems to be a relationship 
between eruption duration and the length of the subsequent rest. We 
can get a reasonable approximation to what we’re seeing in the plot 
by drawing a straight line that passes through the middle of the 
data, as in Figure 2.3.
 
the distance of the dots from the line. We measure this distance 
vertically, and this distance tells us how much our prediction of rest 
time was off for each particular point. This is called the residual for 
that point. A residual is basically an error.
Figure 2.3
16
Le
ct
ur
e 
2:
 F
or
ec
as
tin
g 
w
ith
 S
im
pl
e 
Li
ne
ar
 R
eg
re
ss
io
n
 
how well the line predicts each point. We want to combine these 
residuals into a single number that gives us a sense of how tightly 
the dots cluster around the line, to give us a sense of how well the 
line predicts all of the points. 
 You might think about averaging all of the distances between the 
dots and the line, but for the predictive work that we’re doing, 
it’s more useful to combine these error terms by squaring each 
residual before we average them together. The result is called the 
mean squared error (MSE). The idea is that each residual tells you 
how much of an error the line makes in predicting the height of 
a particular point—and then we’re going to square each of these 
errors, and then average those squares. 
 A small mean squared error means that the points are clustering 
tightly around the line, which in turn means that the line is a 
decent approximation to what the data is really doing. The straight 
line drawn in the Old Faithful scatterplot is the one that has the 
lowest MSE of any straight line you can possibly draw. The proper 
name for this prediction line is the regression line, or the least 
squares line. 
Figure 2.4
17
 Finding and using this line is called linear regression. More 
precisely, it’s simple linear regression. The “simple” means that we 
only have one input variable in our model. In this case, that’s the 
duration of the last eruption.
 
regression line—the line that minimizes MSE—to work out the 
equation of the regression line, but the work is time consuming and 
tedious. Fortunately, any statistical software package or any decent 
spreadsheet, such as Excel Calc
you. In those spreadsheets, the easiest way to get it is to right-click 
on a point in your scatterplot and click on “add trendline.” For the 
cost of a few more clicks, it’ll tell you the equation of the line.
 For the eruption data, the equation of the line is about y = 0.21x + 
34.5, where x is the eruption duration and y is the subsequent rest. So, 
the equation says that if you want to know how long a rest to expect, 
on average, after an eruption, start with 34.5 minutes, and then add 
an extra 0.21 minutes for every additional second of eruption. 
 Any software package will also give you another useful number, 
the r2 value, which is also called the , 
because it tells you how much the line determines, or explains, the 
data. For the Old Faithful data, the spreadsheet reports the r2 value 
as about 0.87. Roughly, that means that 87% of the variation in the 
height of the dots can be explained in terms of the line. In other 
words, the model explains 87% of the variation in rest times in 
terms of the length of the previous eruption. 
Linear Regression
 Linear regression assumes that your data is following a straight line, 
apart from “errors” that randomly bump a data point up or down 
from that line. If that model’s not close to true, then linear regression 
is going to give you nonsense. We’ll expect data to follow a straight 
line when a unit change in the input variable can be expected to 
cause a uniform change in the output variable. For Old Faithful, 
each additional second of eruption adds about 12 seconds of rest.
18
Le
ct
ur
e 
2:
 F
or
ec
as
tin
g 
w
ith
 S
im
pl
e 
Li
ne
ar
 R
eg
re
ss
io
n
 If r2 is low, we’re on shaky ground—and that’s one thing everyone 
learns quite early about linear regression. But linear regression is 
so easy to do (at least with a statistical calculator or computer) that 
themselves into trouble.
 The problem is that linear regressions aren’t always as trustworthy 
as they seem. For example, using a small data set is a very bad way 
to make predictions. Even though you could draw a straight line 
between two data points and get an r2 of 1—a perfect straight-line 
that you want, the one that gives the true underlying relationship 
between your two variables. 
 
true line, but the farther you get to the left or right of the middle of 
your data, the larger the gap between the true line and your line can 
be. This echoes the intuitive idea that the farther you are from your 
observed data, the less you can trust your prediction.
 It’s a general principle of statistics that you get better answers 
from more data, and that principle applies to regression, too. 
But if so, how much data is enough? How much can we trust our 
you can probably also give you some insights into the answer to 
these questions. In Excel, it can be done by using the program’s 
regression report generator, part of its data analysis add-in. You put 
in your x and y values, and it generates an extensive report. 
 The software isn’t guaranteeing that the real intercept lies in the 
range it provides, but it’s making what is known as 
interval predictions based on some often-reasonable assumptions 
about how the residuals are distributed. It’s giving a range that is 
95% likely to contain the real intercept. 
19
 The uncertainties in the slope and intercept translate into 
uncertainties in what the correct line would predict. And any 
center of our data. The calculations for this are a bit messy, but if 
your data set is large and you don’t go too far from the majority of 
your sample, the divergence isn’t going to be too much. 
 
variable, given only the value of the second variable. There’s a 
complicated formula for this prediction interval, but if your data 
set is large, there’s a rule of thumb that will give you quite a good 
working approximation. Find one number in your regression report: 
It’s usually called either the standard error or standard error of the 
regression. Take that number and double it. About 95% of the time, 
the value of a randomly selected point is going to be within this 
number’s range of what the regression line said. 
 So, if you’re talking about what happens on average, the regression 
line is what you want. If you’re talking about an individual case, 
you want this prediction interval. 
Calc
but lacks some of the features of Excel. 
cluster: A collection of points considered together because of their proximity 
to one another. 
: See r2.
: An interval of values generated from a sample that 
hopefully contains the actual value of the population parameter of interest. 
See . 
Important Terms
20
Le
ct
ur
e 
2:
 F
or
ec
as
tin
g 
w
ith
 S
im
pl
e 
Li
ne
ar
 R
eg
re
ss
io
n
error: In a forecasting model, the component of the model that captures 
the variation in output value not captured by the rest of the model. For 
regression, this means the difference between the actual output value and the 
value forecast by the true regression line. 
Excel
linear regression
set of input variables and a single continuous output variable. If there is only 
one input variable, the technique is called simple; with more than one, it is 
called multiple. 
prediction interval
probability of containing the value of the output variable that will be 
. 
r2
model explains the variation in the output variable in terms of the model’s 
inputs. Intuitively, it reports what fraction of the total variation in the output 
variable is explained by the model. 
regression: A mathematical technique that posits the form of a function 
function from data. The regression is linear if the hypothesized relation is 
linear, polynomial if the hypothesized relation is polynomial, etc. 
regression line: The true regression line is the linear relationship posited 
to exist between the values of the input variables and the mean value of 
the output variable for that set of inputs. The estimated regression line is 
the approximation to this line found by considering only the points in the 
available sample. 
residual: Given a data point in a forecasting problem, the amount by which 
the actual output for that data point exceeds its predicted value. Compare 
to error. 
21
sample: A subset of a population.
standard error: Not an “error” in the traditional sense. The standard error 
is the estimated value of the standard deviation of a statistic. For example, 
the standard error of the mean for samples of size 50 would be found by 
of each sample, and then computing the standard deviation of all of those 
sample means. 
Hyndman and Athanasopoulos, Forecasting. 
Miller and Hayden, Statistical Analysis with the General Linear Model. 
Ragsdale, Spreadsheet Modeling & Decision Analysis.
1. Imagine that we set a group of students on a task, such as throwing 20 
darts and trying to hit a target. We let them try, record their number of 
successes, and then let them try again. When we record their results in a 
scatterplot, we are quite likely to get something similar to the following 
graph. The slope of the line is less than 1, the students who did the best 
we might take these results as evidence that punishment works and 
praise is counterproductive. In fact, it is just an example of regression 
toward the mean. (See Figure 2.5.)
Assume that a student’s performance is a combination of a skill factor 
and a luck factor and that the skill factor for a student is unchanged from 
trial to trial. Explain why you would expect behavior like that suggested 
by the graph without any effects of punishment or praise.
Suggested Reading
Questions and Comments
22
Le
ct
ur
e 
2:
 F
or
ec
as
tin
g 
w
ith
 S
im
pl
e 
Li
ne
ar
 R
eg
re
ss
io
n
Answer: 
Consider the highest scorers in the original round. Their excellence 
is probably due to the happy coincidence of considerable skill and 
considerable luck. When this student repeats the exercise, we can expect 
the skill factor to be essentially unchanged, but the luck factor is quite 
The result is that the performance of those best in round 1 is likely to 
decrease in round 2. On the low end, we have a mirror of this situation. 
The worst performers probably couple low skill with bad luck in round 
1. That rotten luck is likely to improve in round 2—it can hardly get 
worse!
This effect is seen in a lot of real-life data. For example, the children 
of the tallest parents are usually shorter than their parents, while the 
children of the shortest parents are usually taller than their parents.
Figure 2.5
23
2. Suppose that you are given a sack that you know contains 19 black 
marbles and 1 white marble of identical size. You reach into the bag, 
close your hand around a marble, and withdraw it from the bag. It is 
a)  This particular marble is 95% black and 5% white. (Maybe it has 
white spots!)
b)  This particular marble is black 95% of the time and white 5% of the 
c)  This particular marble doesn’t have a single color, only a probability. 
Its probability of being black is 95%.
d)  The process by which I got this particular marble can be repeated. If 
it were repeated many, many times, the resulting marble would be 
black in about 95% of those trials. 
Answer: 
The answer is d), but the point of the question is that answers a) through 
c) correspond roughly to statements that are often made by people when 
for mean income as $40,000 to $50,000, people will often think that 
95% of the population makes money between these bounds. Others will 
say that the mean is in this range 95% of the time. (The mean of the 
in a process giving an interval that manages to capture the population 
parameter of interest.
24
Le
ct
ur
e 
3:
 N
on
lin
ea
r T
re
nd
s 
an
d 
M
ul
tip
le
 R
eg
re
ss
io
n
Nonlinear Trends and Multiple Regression
Lecture 3
There are two important limitations to simple linear regression, both of which will be addressed in this lecture. First, linear regression is fussy about the kind of relation that connects the two variables. It has to be 
linear, with the output values bumped up and down from that straight-line 
relation by random amounts. For many practical problems, the scatterplot of 
input versus output looks nothing like a straight line. The second problem is 
that simple linear regression ties together one input with the output. In many 
situations, the values of multiple input variables are relevant to the value of 
the output. As you will learn, multiple linear regression allows for multiple 
inputs. Once these tools are in place, you can apply them to nonlinear 
dependencies on multiple inputs.
Exponential Growth and Decay
 Exponential growth is going to 
show up any time that the rate 
at which something is growing 
is proportional to the amount 
of that something present. For 
twice as much money in the 
bank at the beginning of the year, 
you earn twice as much interest 
during that year. Exponential 
decay shows up when the rate at 
which something is shrinking is 
proportional to the amount of that 
something present. For example, 
in advertising, if there are only 
half as many customers left to 
reach, your ads are only reaching 
half as many new customers.
Figure 3.1
Figure 3.2
25
 For exponential growth, the time taken for the quantity to double is 
a constant. For example, Moore’s law, which states that the number 
of transistors on a microchip doubles every two years, describes 
exponential growth. For exponential decay, the amount of time 
required for something to be cut in half is constant. For example, 
half-life for radioactivity is exponential decay. 
 Anything undergoing exponential growth or decay can be expressed 
mathematically as y = cax + b, where y is the output (the quantity 
that’s growing or shrinking); x is the input (in many models, that’s 
time); and a, b, and c are constants. You can pick a value for c; 
anything bigger than 1 is a good workable choice. 
 So many things follow the kind of hockey-stick curve that we see 
in exponential growth or decay that we really want to be able to 
predict them. Unfortunately, at the moment, our only prediction 
technique is restricted to things that graph as straight lines: linear 
expressions. In algebra, y = ax + b. 
 Anytime you do algebra and want to solve for a variable, you 
always have to use inverse functions—functions that undo what 
you’re trying to get rid of. You can undo an exponentiation by using 
its inverse: logarithm (log). If you take the log base c of both sides, 
logc y = logc (c
ax + b
c y = ax + b. This results 
in a linear expression on the right side of the equation, but y is no 
longer on the left—instead it’s the log of y. 
 If y is a number that we know and c is a number that we know, then 
the logc y
or calculator using a bunch of values for x and y. Whereas x versus 
y will graph as an exponential, x versus log y will graph as a straight 
line. And that means that if you start with x and y values that are 
close to an exponential relationship, then x and log y will have close 
to a linear relationship—and that means that we can use simple 
linear regression to explore that relationship.
26
Le
ct
ur
e 
3:
 N
on
lin
ea
r T
re
nd
s 
an
d 
M
ul
tip
le
 R
eg
re
ss
io
n
 This works for any reasonable c that you pick—anything bigger 
than 1 will work, for example. Most people use a base that is a 
number called e: 2.71828…. Using this base makes a lot of more 
advanced work a lot easier. 
 No matter what base we use, we’re going to need a calculator or 
spreadsheets have keys for e. Most calculators have an ex key, 
along with a key for the log base e, which is also called the natural 
logarithm (ln). The loge x, the natural log of x, or the ln x all mean 
the same thing. And ln and e to a power are inverses—they undo 
one another.
Power Laws
 Exponential growth and decay are a family of nonlinear 
relationships that can be analyzed with linear regression by a simple 
transformation of the output variable—by taking its logarithm. But 
there’s another family of relationships that are perhaps even more 
common that will yield to an extended application of this same idea. 
 Suppose that we took the log of both the input and output variables. 
We’d be able to apply linear regression to the result if ln x and ln 
y actually do have a linear relationship. That is, if ln y = a ln x + b, 
where a and b are constants. Then, using laws of exponents and the 
fact that e to the x undoes ln, we can recover the original relation 
between x and y, as follows.
ln y = a ln x + b 
eln y = ea ln x + b = ea ln xeb 
y = eb(eln x)a = ebxa
 Therefore, the relationship between y and x is y = ebxa, and eb is 
just a positive constant, so we’re saying that y is proportional to 
x. A relationship where one variable is directly 
proportional to a power of another is called a power law, and such 
27
neuroscience, linguistics, physics, computer science, geophysics, 
economics, and biology. You can discover whether a power law is 
a decent description of your data by taking the logarithm of both 
variables and plotting the results. 
 So many relationships seem to follow a rough power relation that 
research is being done as to why these kinds of connections should 
appear so often. But whenever they do, a log-log plot can tip you 
Multiple Regression
 What about allowing more than one input? With a linear relationship, 
each additional input variable adds one dimension of space to the 
picture, so the “best straight line through the data” picture needs to 
change, but the idea of linear regression will remain the same. The 
mathematics of this plays the same game that we used for simple 
linear regression. 
 Actually doing the math for this becomes quite tedious. The good 
news is that, again, statistical software or spreadsheets can do 
the work for you easily. If you’re using a spreadsheet, Excel’s 
report has historically been more complete and easier to read than 
like R—which is free online—can do an even more thorough job.
 It’s important to note that the  of a variable in a model 
is intended to capture the effect of that variable if all other inputs 
same thing, it’s often a good idea not to include both in your model. 
Which one gets credit for the effect can be an issue. This is a special 
case of the problem of multicollinearity.
 Another variant of linear regression is called polynomial 
regression. Suppose that you have bivariate data that suggests a 
nonlinear relationship from the scatterplot and that your “take 
the log” transformations can’t tame into a straight line. Multiple 
28
Le
ct
ur
e 
3:
 N
on
lin
ea
r T
re
nd
s 
an
d 
M
ul
tip
le
 R
eg
re
ss
io
n
is a lot going on in multiple regression, and there is some pretty 
sophisticated math that supports it. 
e: A natural constant, approximately 2.71828. Like the more familiar , e 
appears frequently in many branches of mathematics. 
exponential growth/decay: Mathematically, a relationship of the form y = 
abx for appropriate constants a and b. Such relations hold when the rate of 
change of a quantity is proportional to its current value. 
linear expression: An algebraic expression consisting of the sum or 
difference of a collection of terms, each of which is either simply a number 
straight lines, planes, or higher-dimensional analogs called hyperplanes. 
logarithm: The inverse function to an exponential. If y = ax for some positive 
constant a, then x = loga y. The most common choice for a is the natural 
constant e. loge x is also written ln x. 
multicollinearity: The problem in multiple regression arising when two or 
more input variables are highly correlated, leading to unreliable estimation 
polynomial: A mathematical expression that consists of the sum of one or 
more terms, each of which consists of a constant times a series of variables 
raised to powers. The power of each variable in each term must be a 
nonnegative integer. Thus, 3x2 + 2xy + z
power law: A relationship between variables x and y of the form y = axb for 
appropriate constants a and b. 
Important Terms
29
Hyndman and Athanasopoulos, Forecasting. 
Miller and Hayden, Statistical Analysis with the General Linear Model. 
1. 
polynomial to a set of data. Here, we look at it in a bit more detail. Given 
a table of values for the input x and the output y, add new input variables 
whose values are x2, x3, and so on. Stop when you reach the degree of 
polynomial that you wish to use. Now conduct multiple regression in 
the normal way with these variables. The table used in the regression 
might begin as follows.
The same technique can be used to look for interaction effects between 
two different input variables. In addition to input variables x1 and x2, 
for example, we could include the interaction term x1x2. For example, 
individually but might create quite an unpleasant reaction together!
2. 
the “random errors” in a model are supposed to look like. You could 
imagine how they’re supposed to work in this way. Suppose that you 
have a bucket containing a huge number of poker chips, each with a 
number on it. The numbers are centered on zero, balanced out between 
positive and negative, and there are a lot more chips with values close to 
Suggested Reading
Questions and Comments
x x2 x3 x4 y
3 9 27 81 17
4 16 40
… … … … …
Figure 3.3
30
Le
ct
ur
e 
3:
 N
on
lin
ea
r T
re
nd
s 
an
d 
M
ul
tip
le
 R
eg
re
ss
io
n
zero than there are with values of large magnitude. When you need the 
error for a particular input point, reach into the bucket for a chip, read its 
number, and then add that number to the calculated linear output. Then, 
throw the poker chip back in the bucket.
More technically, the errors are supposed to be normally distributed 
with a mean of zero, a constant standard deviation, and are supposed to 
be uncorrelated to one another as well as being uncorrelated to the input 
values—but the error bucket gets the key idea across. 
31
Time Series Forecasting
Lecture 4
The topic of this lecture is forecasting—predicting what’s going to happen, based on what we know. In many circumstances, we’re looking at historical data gathered over time, with one observation 
to happen next, as well as we can. Data of this type is called time series data, 
and to have any hope of making progress with predicting time series data, 
we have to assume that what has gone on in the past is a decent model for 
what will happen in the future.
Time Series Analysis
 Let’s look at some historical data on U.S. housing starts—a month-
by-month record of how many new homes had their construction 
start in each month. Housing starts are generally considered to be a 
leading indicator of the economy as a whole. 
 For a time series, we can visualize the data by making a line graph. 
The horizontal axis is time, and we connect the dots, where each 
dot represents the U.S. housing starts for that month. The basic 
strategy is to decompose the time series into a collection of different 
components. Each component will capture one aspect of the 
historical behavior of the series—one part of the pattern. 
Figure 4.1
32
Le
ct
ur
e 
4:
 T
im
e 
Se
rie
s 
Fo
re
ca
st
in
g
 The variation in the data series—the up-and-down bouncing—is far 
from random. Each January, new housing starts tank, then climb 
rapidly in the spring months, reaching a peak in summer. Given 
the weather patterns in North America, this makes sense, and we’d 
have every reason to expect this kind of variation to continue into 
the future. 
 
decomposition: the seasonal component. Seasonal components are 
like the four seasons. But the period of repetition doesn’t have to be 
 Getting a handle on seasonality is important in two ways. First, if 
you’re hoping to make accurate forecasts of what’s going to happen at 
some point in the future, then you’d better include seasonal variation 
in that forecast. Second, when trying to make sense of the past, we 
trends. This is certainly the case with housing starts and why the 
government reports “seasonally adjusted” measures of growth. 
 The other obvious pattern in the data, once seasonality is accounted 
for, is that there appears to be a steady increase in housing starts. In 
fact, we can apply simple linear regression to this line to see how 
x is measured in 
months, with x = 1 being January 1990, x = 13 being January 1991, 
and so on.
 With r2 being only 0.36, about 36% in the variation in housing starts 
can be laid at the doorstep of the steady passage of time. That leaves 
64% unaccounted for. But this is what we expect. The data has a 
very strong annual seasonal component, and the trend line is going 
to completely ignore seasonal effects. In the sense of tracking the 
center of the data, the regression line actually seems to be doing 
rather well.
33
Figure 4.2
 For this example, the regression line would be the second 
component of the time series, the trend component. Not all data 
demonstrates a linear trend, and in general, trend components can 
actually be quite complicated. 
 There’s a third component that arises with some time series called 
the cyclic component, and it tracks cyclic variation. While cyclic 
variation can be thought of as including regular seasonality as 
one of its subtypes, it’s clearer to say that cyclic variation refers 
variation. Business cycles are a good example: growth, recession, 
recovery—but of variable onset, intensity, and duration. 
 Our data for housing starts doesn’t show any cyclic variation. In 
fact, many short- and medium-range techniques for forecasting 
two years or fewer don’t include a cyclic component. So, we’re 
currently modeling our housing starts as a seasonal component 
overlaid on a linear trend. 
 Just like in regression, a time series almost never perfectly matches 
the real-world data. Whatever variation is left unexplained is 
residuals. The component captures all of the variation between 
what the model predicts and what actually happens. 
34
Le
ct
ur
e 
4:
 T
im
e 
Se
rie
s 
Fo
re
ca
st
in
g
 When we do a good job with our forecasting, there shouldn’t be 
error component mean that the errors contain more information—
information that we could have squeezed out of them and included 
in the other components of the forecast.
 Everything described so far applies to almost every time series 
forecasting technique, but there are a large number of such 
techniques, and the variety exists for a reason. Different time series 
display different characteristics, and the processes that generate 
them may dictate restrictions on the kind of model that we use. 
 Not every model includes all of the possible kinds of components. 
Some data shows virtually no seasonality, and some shows virtually 
no trend. But suppose that you have data that includes both. How 
do you combine them? 
 Two common approaches are additive and multiplicative models. 
In an additive model, you say that the observed value is the sum 
of the trend component, the seasonal component, and the error 
component. This is good when the seasonal component stays pretty 
constant over time. In a multiplicative model, you multiply these 
pieces together instead of adding them—a better choice when the 
seasonal component’s magnitude varies with the trend. 
Measures of Forecast Quality
 People who do forecasting like to be a bit more quantitative when 
assessing the performance of a forecast. One common measure is 
called 
each forecast value differed from the actual historical value—the 
error for each point in time. If it’s negative, take its absolute value 
to make it positive. Finally, average all of these absolute errors. 
35
 In addition to the MAD, people also often report the mean absolute 
forecast was wrong, take the absolute value of each of these in case 
they’re negative, and then average all of these percentages. MAD 
and MAPE are both particularly popular in the manufacturing sector.
 
. That is, take the error for each 
observation, square each of these errors, and then average all of the 
squared errors together. 
 MSE has much nicer statistical and calculus properties than MAD 
or MAPE does. It falls short, though, when you try to interpret it 
simply. You can’t compare these different measures of forecast 
quality to one another, but you can compare two different forecasts 
using the same measure of quality. The one with the lower MAD—
or MAPE, or MSE—should be the better forecast.
 Often, all of the different measures agree on the winner, but not 
always. MSE tends to care about consistency in a forecast. If you’re 
exactly right a lot of the time but occasionally make howling 
errors, MSE gives you a big penalty for the mistakes. That is, its 
squaring step turns a very bad error into a very, very bad error. 
MAD and MAPE are more forgiving of the occasional howler. 
In many applications, people would prefer many small errors to 
an occasional large one, which is one of the non-computational 
reasons that MSE is often the preferred measure. 
Characterizing Trends in Data
 One of the dangers you face when you’re working with historical data 
the evolution of the data outputs. Time series forecasting is based on 
the idea that the past is a good model for the future. When something 
fundamental about the situation changes, if you can’t anticipate it, 
you can be left with forecasts that are really quite dreadful. 
36
Le
ct
ur
e 
4:
 T
im
e 
Se
rie
s 
Fo
re
ca
st
in
g
 Extending a graph over a much longer number of years also shows 
how the business cycle (or other cyclic variation) can turn out to be 
important, even for short-term forecasts. One reason the business 
precisely. The better we understand the past, the better chance we 
have of predicting the future. And, sometimes, such as in economic 
analysis, we’re also trying to make sense of the past for its own sake. 
 A common way of characterizing a trend in a group of data is by 
using a simple moving average. Simply put, we peg the trend 
at some point in time by averaging together some number of 
observations near that point in time. If you’re trying to forecast the 
future with monthly data, you might average together the 12 most 
recent months to get the forecast of what happens next. If you’re 
trying to make sense of historical data, you might choose a set of 
observations centered on your current month to average. 
 But because each simple moving average forecast is just the average 
of the preceding 12 months, we don’t get a forecast until 12 months 
have gone by. More importantly, we can only use the technique to 
forecast one month in advance. If we want to go farther than that—
and we probably do—we need more advanced techniques. 
 And a plethora of them exist, each suited to different kinds of 
time series. Some are simple. Weighted moving average takes 
the simple moving average but gives each observation a different 
weight. These weights tell us the relative importance of the values 
used in computing the forecast. If what happened one time period 
 
values of the weights that minimize some measurement of error, 
such as the MSE of the forecast. 
37
 A close relative of the weighted moving average is called simple 
exponential smoothing. You can think of it as a weighted moving 
average in which weights grow smaller and smaller in a geometric 
fashion as we move back in time. Exponential smoothing is an 
extremely simple forecasting technique, but it’s the basis for a lot of 
more sophisticated and complicated approaches. 
cyclic component: The component of a time series forecast that attempts 
to capture cyclic variation. This differs from seasonal variation by showing 
nonconstant duration or intensity or unpredictable onset. 
exponential smoothing: A time series forecasting technique that forms the 
basis of many more-complicated models. Exponential smoothing can be 
thought of as a variant of the weighted moving average. 
: A measure of forecast accuracy, MAD is 
the average amount by which the forecast differs from the actual value. 
: A measure of forecast accuracy, 
MAPE is the average percentage by which the forecast differs from the 
actual value. 
: A measure of forecast accuracy that is similar 
to variance in its calculation, MSE is the average of the squares of all of the 
residuals for a forecast. 
penalty
genetic algorithms and soft constraints. 
seasonal component: The component of a time series forecast that captures 
the seasonality of the data—that is, its regular, periodic variation. Some 
sources use the term for such variation only if the period length is at least 
one year. 
Important Terms
38
Le
ct
ur
e 
4:
 T
im
e 
Se
rie
s 
Fo
re
ca
st
in
g
simple moving average: A forecast for a period in a time series made by 
For predictive models, this will mean the n observations immediately 
preceding the current time period. 
time series: A data set consisting of one value of the output variable for each 
point in time. The points in time are usually evenly spaced. Alternatively, a 
forecasting technique used on such data. 
weighted moving average: A forecast for a period in a time series made by 
this will mean a weighted average of the n observations immediately 
preceding the current time period. 
Hyndman and Athanasopoulos, Forecasting. 
1. If you’re going to apply more complicated time series approaches, you’re 
probably going to want to use software to do it. A few resources that you 
the open-source statistical software package R, which will run on a wide 
variety of computer platforms and is fairly straightforward to learn, 
powerful, and free; and 2) Forecasting: Principles and Practice, a free 
online text that does an excellent job of explaining more sophisticated 
time series analysis in more detail, including the R commands necessary 
to conduct the analysis on a time series. 
2. It is possible to look at two different time series over the same interval 
of time and to explore their relationship in a scatterplot. The point (xi, yi) 
is plotted if at time period i xI and the second 
series has the value yi. 
Suggested Reading
Questions and Comments
39
Think about what would happen if x and y really had no relationship to 
one another but both showed a positive trend over a period of time. The 
resulting scatterplot could have a high correlation for the two variables, 
which could mislead the investigator into believing the two variables 
were in fact linked. For this reason, it’s dangerous to create such a 
scatterplot for time series with trends.
40
Le
ct
ur
e 
5:
 D
at
a 
M
in
in
g—
Ex
pl
or
at
io
n 
an
d 
Pr
ed
ic
tio
n
Data Mining—Exploration and Prediction
Lecture 5
Statistical techniques like regression and time series forecasting were strongholds of mathematical prediction for much of the 20th century. But they have been supplemented in recent decades by additional 
techniques from the exciting and fast-growing area known as data mining, 
which focuses on large data sets. As you will learn in this lecture, the job 
sets contain—connections and patterns that might otherwise be missed. 
Data mining is especially important in the 21st century because of two 
advances: computational power and a veritable explosion in the quantity of 
collected data.
Data Mining
 One of the key differences between many classical statistical 
techniques and data mining is the quantity of data available. 
Throughout much of history, data was scarce and hard to come by. 
And that meant that all of the data that was available had to be used 
in the analysis—both to create the model and to test its accuracy. 
 In order for that analysis to get very far, some assumptions had 
to be made, including that the errors are normally distributed (in 
technical terms, the data is supposed to be homoscedastic) and that 
the errors are independent from one another. The violation of these 
assumptions leads to questions of how much to trust the predictions. 
 In data mining, we often have an embarrassment of riches when 
that means is that we can use part of the data to come up with our 
model and a completely different set of data to test the reliability 
of that model. This also means that we aren’t bound by a lot of 
assumptions, such as the distribution of errors. 
41
 In other techniques, such as regression, we can spend a lot of time 
transforming the data so that we don’t have heteroscedasticity, 
autocorrelation, or error terms that are distributed, for example, 
like lottery payoffs—many small negative values sprinkled with 
occasional big positive values. Fixing these problems can be quite a 
headache. With data mining, the headache largely goes away.
 Practitioners sometime debate where exactly the margins of data 
mining lie, but there are three objectives that are central to it: 
data visualization and exploration,  and prediction, 
and association among cases. Time series analysis is sometimes 
considered a part of data mining, too. 
Data Visualization
 When we’re exploring data in data mining, we’re probably going to 
start by looking at one variable at a time. If a variable is categorical, 
bar charts are a good choice. In the following chart, we can see at a 
glance that heart disease and cancer—“malignant neoplasms”—are 
overwhelmingly the most common causes of death in the United 
States, and seeing this in a chart conveys this fact much more 
quickly and memorably than a table of numbers does. 
Figure 5.1
42
Le
ct
ur
e 
5:
 D
at
a 
M
in
in
g—
Ex
pl
or
at
io
n 
an
d 
Pr
ed
ic
tio
n
 Increasingly, software supports the ability to look at interesting 
aspects of the data in greater detail. For example, from the previous 
graph, we can break things down by age, as follows. Excel’s pivot 
table and pivot chart can give you some of this functionality.
 For a single numeric variable, the most common choice is the 
histogram, which is like a bar chart in which each bar represents a 
range of values. For example, the following is a histogram of the 
distribution for how many Facebook friends a group of 
students have. 
Figure 5.2
Figure 5.3
43
 For relationships between two numeric variables, we generally 
use scatterplots. This initial exploration often uncovers 
connections between the variables—connections we can exploit in 
further analysis.
 For relationships among three variables, we can use a three-
dimensional plot. This is less useful when the software renders such 
data as a static plot on a two-dimensional screen, or piece of paper. 
But there are still options. We can code additional information with 
color or size. Many weather maps do this. Such representations 
are often called heat maps, even when the color is coding for 
something quite different than temperature or when the thing being 
colored is not a map. 
 We can also use the time dimension, combining multiple images 
into a movie. Swedish academician Hans Rosling created an 
which he tracks the wealth and longevity of people in 200 countries 
over 200 years of history. He uses a scatterplot with an axis for 
lifespan, a logarithmic axis for wealth, color to indicate continent, 
size to indicate population, and time to indicate the passage of 
communicating all of that data. 
 Processing visual information in two or three dimensions—
recognizing structures and patterns—is something that human beings 
are uncannily good at, which is why charts and graphs exist to begin 
with. But as the number of variables increases, obvious ways of 
representing data graphically fail. Each variable—each category of 
information—needs its own dimension in space, and for visualization, 
three dimensions of physical space is our limit. So, what can we do?
 To begin, we can conduct a kind of dimensional reduction by using 
mathematical procedures. It’s like using a student’s GPA or SAT 
score in place of every detail of his or her academic history. The 
that loses as little information as possible. 
44
Le
ct
ur
e 
5:
 D
at
a 
M
in
in
g—
Ex
pl
or
at
io
n 
an
d 
Pr
ed
ic
tio
n
 The computations required may not be simple, but because data 
perform the calculations by hand anyway. Statistical software such 
as SAS or SPSS, or the free package known as R, are perfectly 
capable of this kind of dimensional reduction; in fact, it can even be 
done in Excel with an add-in package such as XLMiner. 
Measuring Variation and Normalizing Data
 We measure variation by using the most common statistical measure 
of dispersion: the variance. The calculation for the variance bears 
a great similarity to the calculation of MSE—that “average the 
squared errors” calculation for regression. For variance, the only 
difference is that the “error” is taken to be the distance of each data 
point from the mean of the data. If you take the square root of the 
variance, you get the standard deviation, something that comes up 
in most statistical discussions.
 A technique called creates 
new variables that partition the variation between two variables 
that variation—that variance—is maximized. The math can be 
done by a computer, which gives us a line that would normally be 
called the z1 axis when doing PCA. Impressively, this line captures 
over 97% of the total variance in the two variables. To capture the 
remaining 2.6%, PCA would construct a second axis, perpendicular 
z2 axis.
 In complicated examples, with more than a handful of variables, 
the largest possible fraction of the variation in the data and calls 
that the z1 axis. It then looks for a direction perpendicular to that 
one that captures the maximal amount of the remaining variation. 
That’s the z2 axis, and with more than two dimensions in the 
original problem, there are more perpendicular directions to choose 
45
z3 axis 
that is perpendicular to both z1 and z2 and captures as much of the 
remaining variation as possible—and so on. 
 
found, the vast majority of the variation is accounted for. If that’s 
the case, the original variables, however many there were, can be 
discarded and replaced with this handful, losing almost nothing 
about the original variation in the data and greatly simplifying the 
future work.
 But there are some disadvantages to doing this, too. For example, 
PCA won’t work well for data whose underlying pattern is 
not linear. But that can be overcome by modeling a nonlinear 
pattern using local patterns that are linear, which is analogous to 
multiple regression. 
 Normalizing
subtracting the mean of a variable from all values of that variable, 
and then dividing each of those differences by the standard 
deviation of that variable. No matter what data you start with, after 
you’ve normalized it, the mean of the data is zero, and its standard 
deviation is one. In that sense, then, each variable is now on equal 
footing. Generally, if the two variables are measured in units that 
aren’t comparable or on dramatically different scales, normalization 
is a good idea. 
 Another factor that can be useful in reducing the dimension of 
investigation can often narrow our focus before we even start with 
the math. Experts can tell us what quantities are almost certainly 
relevant—or irrelevant—to the task at hand. They can also let us 
know when one of our variables is useless as a predictor because 
we won’t be able to gather it in time to make use of it. Domain 
it makes sense.
46
Le
ct
ur
e 
5:
 D
at
a 
M
in
in
g—
Ex
pl
or
at
io
n 
an
d 
Pr
ed
ic
tio
n
 Perhaps the most common kind of task for data mining is using the 
data about an individual to predict some unknown characteristic 
about them. An “individual” here could be a person, or a river, or 
a bottle of wine, or anything else. The thing we’re trying to predict 
might be a categorical variable, such as what brand of car the 
person owns, or whether he or she would accept a particular offer to 
federal income tax. When that’s the case, the prediction is often 
we think they belong. 
 On the other hand, we may be trying to predict a continuous 
variable, such as a person’s life expectancy, or the probability that 
“prediction” only for such continuous variable cases, while some 
use prediction for sorting individuals into classes as well.
  are a great data mining technique that we 
can picture as repeatedly subdividing rectangles into smaller and 
smaller rectangles until all of the points in any given rectangle 
fall into the same category of the output. If you’re working with 
continuous variables rather than classes, they’re usually called 
regression trees, but the idea is the same. This technique can be 
used on many different kinds of problems, it’s easy to explain to 
nontechnical people, the results are directly usable by the nonexpert, 
and it doesn’t care whether the data is normalized. 
: Using the information available about an individual to predict 
to which of a number of categories that individual belongs. 
repeatedly splits a subset of the individuals into two groups in a way that 
reduces total “impurity.” 
Important Terms
47
heat map: A data visualization technique in which colors or shades are used 
to convey information about a variable in a chart, graph, or map. 
heteroscedastic: A collection of random variables is heteroscedastic if their 
standard deviations are not all equal. 
homoscedastic: A collection of random variables is homoscedastic if they 
all have the same standard deviation. Linear regression generally assumes 
that the error terms in the forecast are homoscedastic. 
normalizing: Also called standardizing. Linearly rescaling a variable to 
make its mean 0 and its standard deviation 1. This is done by taking each of 
the variable’s values, subtracting the mean of the variable, and then dividing 
the result by the variable’s standard deviation. 
prediction: In data mining, using the information available about an 
individual to estimate the value that it takes on some continuous output 
: A technique for reducing the 
number of variables in a data set by identifying a collection of linear 
combinations of those variables that capture most of the variation of a larger 
set of the original variables. These new variables can then be used in place 
of the larger set. 
regression tree
standard deviation: A measure of dispersion, it is the square root of 
the variance. 
variance: A commonly used statistical measure of the dispersion, or spread, 
of data. For a population, the variance is computed by deviation of each 
observation from the population mean, squaring those differences, and 
averaging the squares. For a sample, the same calculation is performed, but 
the result is multiplied by n n n is the sample size. 
48
Le
ct
ur
e 
5:
 D
at
a 
M
in
in
g—
Ex
pl
or
at
io
n 
an
d 
Pr
ed
ic
tio
n
Berry and Linoff, Data Mining Techniques.
Dunham, Data Mining.
Shmeuli, Patel, and Bruce, Data Mining for Business Intelligence.
1. 
the output variable. Most of these record either the proportion of certain 
words in the email (“money” = 0.01 would mean that “money” made 
up 1% of the words) or the proportion of certain characters in the email 
(such as ! = 0.01 meaning that exclamation points made up 1% of the 
characters in the email). Notably different is the variable TOTCAPS, 
the total number of capital letters in the email. When PCA is done with 
dominated by TOTCAPS and captures 92.7% of the variance. When the 
variation and is not dominated by anything. Can you explain why this 
kind of result is to be expected?
Answer: 
The value of the TOTCAPS variable, when unnormalized, shows much 
more spread than the percentage variables, which run only between 0 
and 1. As a result, the vast majority of the variation is in the TOTCAPS 
variable. When variables are normalized, each variable is on equal 
footing, with a variance of 1. Now the variation in each variable 
contributes equally to total variation.
2. 
help with the reduction-of-variables problem. The variables appearing 
analysis of the problem, while those that appear quite late might be 
safely ignored. 
Suggested Reading
Questions and Comments
49
Lecture 6
With the mathematics of algorithms and the power of computers, data mining confers upon us an ability that could seem almost 
the business of anticipating customer preferences to a high art. For example, 
how does Amazon decide what offers to make to you? In this lecture, you 
will learn about some important tasks of data mining, including association 
and clustering.
Training Data
 Data mining involves using mathematical algorithms to extend our 
native ideas of pattern recognition. We can then use computers to 
implement those algorithms on large, multidimensional sets of data, 
 
a large set of training data. This data contains both the input and 
output values for a large collection of individuals. It’s like showing 
the algorithm a bunch of questions, along with their answers. The 
algorithm then generates a way of predicting the output value of 
new individuals, based on their input values. 
 Any such activity can be called prediction, although if the output 
All such procedures are called supervised learning, which merely 
means that you have to supply both the input and output values for 
each individual in the training data.
 When we get our data—and in data mining, we often have a lot 
of it—we don’t use all of it for training. Instead, we partition it 
50
the largest) is used for training. But the second set is called the 
validation set, and it’s not used until after the data mining algorithm 
has been applied to the training data to generate its rules. 
 The performance of the model on the validation data is a fair test 
of the model’s quality, because that data had nothing to do with the 
model’s creation. This gives us a way to benchmark the results of 
different data mining algorithms and to evaluate which one looks 
best—the one that does best on the validation data.
 However, selecting the model this way still doesn’t tell you how 
good you can expect it to be. The model you pick is the one that 
did best on the validation set, but would it do as well on other, new 
data? You picked the winning model because it was the best on the 
validation set, but maybe it just got lucky with that particular set.
 That’s where the third set comes in: the testing set. If we have 
used the validation data to pick a best model, we’ve more or less 
poisoned its usefulness for assessing how the model does with new 
does on brand new data—the testing data. Given a decently sized 
testing set, we should be able to use our model’s performance on it 
as a fairly reliable measure of its overall performance.
 
procedure that continues by adding one node after another to the 
reach the point where the original algorithm is no longer training 
to the real relationships between inputs and outputs; instead, it’s 
training set. 
 One way to handle this issue is called oversampling, and it’s 
used in particular when one of the classes of interest is especially 
uncommon in the data. The training set might include so few 
examples of the rare class of interest that a straightforward 
51
application of data mining techniques would fail. The “best” rule 
for the technique might be to classify everyone as belonging to the 
largest class and no one to the class of interest. 
 Oversampling includes a number of observations in the rare class 
disproportionate to its frequency in the population. You can do this 
by either taking a random sample (with replacement, if necessary) 
of individuals in the rare category and adding them to the training 
number of times. 
 In prediction problems, the quantity to be predicted is a continuous 
use the same kind of techniques, but we use different measures of 
error. Most software that can handle the one kind of problem can 
handle the other as well.
Association Rules
 There are other interesting pattern recognition problems besides 
of , or “what goes with what.” The recommender 
systems at online stores are an example. They use association 
rules. The system recognizes that you were looking at A and B, 
and then points out to you that people who liked them tend to be 
interested in C and D, too. 
 In retail, association rules are sometimes called market basket 
analysis. If you know that people who buy these two products also 
tend to buy that one, you can use that information—for product 
placement, for promotional sales, and so on.
 The strategy behind a basic association rule generator is actually 
pretty simple. In terms of retail sales, you have, for each customer 
in your database, a list of all of the items that the customer bought 
from you. You’re going to be looking for rules of the following 
form: “If a customer buys all of these, then I guess that he or she 
52
wants these, too.” The game is probabilistic in nature, of course. 
You won’t be right every time, but you want your rules to give you 
useful guesses as to what might interest your customer.
 What do we need for a useful rule? First, there’s no point in 
considering an item—or group of items—that appear very rarely, 
at least not unless the combination is very important. So, you want 
to consider the support of a collection of items, which is merely the 
number of your customers—or fraction of your customers—who 
bought everything in the collection. If you try doing this in every 
possible way for a store with more than a small number of items, 
you’re going to run into trouble. A common work-around is to use 
the Apriori method. 
 Association rules software will scan the data to create frequent 
sets of items and then generate association rules from them and 
compute the  and lift index for each. Those with high 
values are good candidates for rules that the company may want to 
process; there are some rules that can be either discarded or merged 
with others. 
Clustering
 
that one set of attributes gives you reason to anticipate another set 
of attributes as well. But other techniques for looking for “things 
that go together” are based on the idea of clustering the data—of 
creating categories and then sensibly sorting the individual data 
that will be based on these clusters. 
 The following two questions, of course, arise: what the categories 
should be and how we decide into which category an individual 
should be sorted. And the key idea to answering both of these 
questions is the same: distance.
53
 
two individuals is Euclidean distance, the straight-line distance 
separating the points in an n
to compute with a souped-up version of the Pythagorean theorem 
from geometry. 
 
much they differ on each of the six traits, square those differences, 
add them up, and take the square root. 
 
between two observations, there are some problems with it. There 
statistical distance, 
which both standardizes and accounts for correlation.
 Before we cluster data points together, we have to answer a 
question: What do we mean by the distance between two clusters? 
 Suppose that we’re trying to track pollution levels. If a river is 
You don’t have to be close to all points on the river—just to some 
point on the river. Your distance from the river, then, would be 
measured by the distance to the closest point on the river. That’s 
minimum distance, or the single linkage distance. If you use it, 
you can get clusters that tend to be ropey. 
 
the distance between two clusters to be the largest distance between 
any two points in the clusters. So, the distance from California to 
Washington is the distance from the southern tip of California to the 
Canadian border in Washington. This method usually gives small 
clusters to begin with, and clusters tend to be spherical. 
54
 
two clusters as the average distance, computed for each pair of 
points with one in each cluster. With large clusters, that’s a lot of 
centroid
centroids. Other, more complicated methods seek to minimize the 
amount of information lost by creating new clusters from old ones.
 How many clusters do you want? There is no universal answer 
to this. Sometimes your domain knowledge will inform you of 
how many clusters should be in the data, but more often it comes 
down to examining the groupings resulting from different levels 
of clustering. Ideally, the clusters pass three checks. First, they are 
interpretable in some sensible way. Second, the clusters should be 
stable to minor changes in the data used to create them. Finally, 
than the variation within a cluster. 
: Umbrella term for the data mining techniques that seek to 
determine “what goes with what.” 
Apriori method: A method for generating frequently occurring subsets of 
items for an association rules application. 
association rules: A data mining task of creating rules of the following form: 
“If an individual has this collection of traits, predict that individual also has 
that set of traits.” 
centroid: In data mining, the centroid of a cluster is the point for which each 
variable is the average of that variable among points in that cluster. 
Important Terms
55
: For an association rule, the probability that the 
consequent is true given that the antecedent is true. 
distance, average
two clusters as being the average of the distances between each point in one 
cluster and each point in the other. 
distance, single linkage
between two clusters as being the minimum of the distance between a point 
in one cluster and a point in the other. 
distance, statistical: Also called Mahalanobis distance. A distance measure 
that takes into account the variance and covariance of the various variables 
oversampling: In data mining, the choice of representing a class in a data 
set at a relative frequency higher than its occurrence in the population. 
Oversampling is appropriate if the class of interest forms only a small 
proportion of the entire population. 
population: The set of all individuals of interest for purposes of the current 
study, or the set of all relevant variable values associated with that group. 
training, validation, and testing sets: In data mining, where data is 
plentiful, model quality is usually assessed by using part of the data as a 
training set, to create one or more models, and then assessing their quality 
with the validation set. If more than one model is being assessed, the best is 
third set of data, the testing set. 
Berry and Linoff, Data Mining Techniques.
Dunham, Data Mining.
Shmeuli, Patel, and Bruce, Data Mining for Business Intelligence.
Suggested Reading
56
1. Why is an average distance measure more appropriate than a single 
linkage measure for the grade example in the video lecture?
Answer: 
 
(a cluster) should mean that the student is similar to what is typical for 
that group, not merely similar to one other student in that group.
2. The grade example was done without normalizing the data. Do you 
think that normalizing the data would have been a good idea? Do you 
think that it would have made a big difference in the resulting clusters?
Answer: 
Both variables are on a scale of 0 to 100, and we have no idea of their 
relative importance in this problem. Quiz averages appear to be slightly 
more dispersed than test averages, so normalizing would be equivalent 
to squeezing the picture slightly from top to bottom. It does not appear 
Questions and Comments
57
Optimization—Goals, Decisions, and Constraints
Lecture 7
When given a troublesome situation, the goal is to identify its key factors. What is it we’re trying to accomplish? What controls do we exert over the situation? What rules are we compelled to obey? 
a good model is going to strip away all of the extraneous distractions and 
focus on the heart of the problem. And once we have the model, we’ll be in 
a position to apply some accessible and powerful mathematical machinery—
machinery that will provide us with the best-possible answer to the problem. 
Optimization Problems
 
possible answer to the problem at hand. This idea of obtaining the 
best-possible answer leads to three questions that we ask for every 
optimization problem: What are you trying to accomplish? What 
do you have the power to decide? What rules do you have to obey 
along the way? 
 This set of questions can be surprisingly useful in getting a handle 
on problems—both professional and personal—without any 
mathematics. So, it’s amazing how rarely people take the time to 
explicitly identify their options, their restrictions, and what they’re 
actually trying to accomplish. 
 
problem with a mathematical model. We begin by framing the 
problem—by identifying its decisions, constraints, and objective. 
In order to apply mathematics to the result, we’re going to need to 
express all of the components of the model in terms of measurable 
quantities. A measurable quantity is basically anything that you 
58
Le
ct
ur
e 
7:
 O
pt
im
iz
at
io
n—
G
oa
ls
, D
ec
is
io
ns
, a
nd
 C
on
st
ra
in
ts
 Although there are exceptions to every rule, you can think of a 
measurable quantity as basically anything that you could specify 
with a phrase starting with “number of ….” Examples include the 
number of employees we hire or the number of dollars we spend 
on equipment. 
Objective
 
by a measurable quantity. For any particular proposed solution, 
the objective will be a number. We’ll judge the quality of the 
solution by the size of this number. While some problems might 
have the goal of keeping a value within a certain range, most can 
be expressed with the goal of either maximizing something or 
minimizing something.
 What if you have more than one goal? Perhaps you’re primarily 
concerned with minimizing costs of operations, but you also want 
goal, you’re in a bit of a jam, and there are only a few of ways out. 
One way out is to combine the goals in some way—for example, by 
taking a weighted average of them with appropriate weights. In this 
case, your multiple goals become one goal: minimize or maximize 
this weighted average. 
 A second option is to prioritize your goals—for example, that your 
second goal is to maintain a customer satisfaction level that’s as 
high as it can be. 
 A last option is to look at trade-offs, focusing on the question of 
how much of one thing you’re willing to give up for how much of 
another. But if you have more than one goal, the goals are usually 
about how to resolve those competing objectives.
59
Decisions
 The next step is to identify the decisions we make. Again, these are 
going to be represented by measurable quantities. There is generally 
one decision variable for each quantity over which you have direct 
control. Focusing on the word “direct” here will help you avoid 
some common formulation errors in optimization problems. 
 When you go to the store, for example, you do control how much 
money you spend—but not directly. Your total bill depends on the 
money you spend on each type of item, and that in turn depends 
on how many of each type of item you buy. And what does that 
depend on? Nothing. You get to pick. That’s the hallmark of a 
decision variable: If you repeatedly ask yourself, “what does that 
to decide that.” That’s the point at which you’re on the level of a 
decision variable. 
Constraints
 Next, we have to consider the constraints, which are the rules that we 
are required to obey. Again, if we’re going to be solving problems 
quantitatively, our restrictions have to be expressed in terms of 
measurable quantities. In almost every case, our constraints are 
basically going to specify how the size of one measurable quantity 
compares to the size of another one. Are they equal in size? Or is 
greater than or equal to the second one? 
 For example, a line worker may have a constraint that the number 
of units that he or she assembles in a shift must be greater than 
or equal to the prescribed shift quota. A soccer league may have 
a constraint that the number of games played by team A during 
a season is the same as the number of games played by team B. 
Constraints tell you what you may not do or what you must do. 
They’re the rules you have to obey.
60
Le
ct
ur
e 
7:
 O
pt
im
iz
at
io
n—
G
oa
ls
, D
ec
is
io
ns
, a
nd
 C
on
st
ra
in
ts
Modeling Optimization Problems
 Not every problem can be naturally described with a quantitative 
objective, a set of quantitative constraints, and a set of decision 
variables representing measurable quantities. For example, if your 
goal in life is to be happy—or to maximize your overall happiness—
how do you measure it? You might have no idea how to effectively 
measure your happiness numerically, or how you could accurately 
connect it to the decisions that you make. 
 Part of the problem is that you can’t effectively model your 
set of decisions in the face of the problem at hand.
 Even when we can sensibly model a problem mathematically, we’re 
going to want to look carefully at our answer before implementing 
it, or we may be in for a surprise. What we modeled might not quite 
be what we want.
 
as posed. To the extent that the question is not well posed, the 
answer is in doubt and may be nearly useless. But even when a 
mathematical solution doesn’t take into account some human detail, 
a small adjustment by a human decision maker can often result in 
an excellent solution.
Types of Programming
 There are many types of programming that we will encounter 
throughout this course, including linear programming, nonlinear 
programming, integer programming, mixed integer programming, 
and goal programming. Keep in mind that the term “programming” 
in all of these topics doesn’t refer to computer programming. Many 
of the early optimization problems that were worked out involved 
61
be making during World War II. The term “programming” is meant 
in the sense it has in the phrase “television programming.” It 
means scheduling.
 That being said, it’s undeniable that today almost any real-
world scheduling or optimization problem is going to be solved 
by harnessing the power of computers, whether it’s a PC or a 
mainframe. And for many smaller problems, you don’t need to be a 
computer programmer to take advantage of the computer’s power. 
Problems that took months to solve before computers can be done 
on any desktop computer in a fraction of a second today, once it is 
set up. And setting it up is a matter of minutes, not hours. 
 Spreadsheets were useful for our regression and data mining 
work, and they’ll continue to be useful for optimization. Excel, 
optimization work, and most people already have it on their 
computers. An alternative is Calc, the free alternative to Excel that 
 Spreadsheets are useful not just because they’re accessible and 
familiar to many people—they’re also transparent. That means that 
you’ll be able to analyze the details of the problem at hand, and 
you’ll be able to see the model as it evolves over time. 
constraint: A rule that must be obeyed by any acceptable solution. 
decision variable: In a mathematical model, any measurable quantity over 
values of all of its decision variables. 
measurable quantity: The quantities represented by numbers in a 
“the number of (unit of measure)” of something, such as the number of hours 
spent on a project. 
Important Terms
62
Le
ct
ur
e 
7:
 O
pt
im
iz
at
io
n—
G
oa
ls
, D
ec
is
io
ns
, a
nd
 C
on
st
ra
in
ts
: The mathematical expression that represents the goal 
of an optimization problem. The better the objective function value, the 
better the solution. Objective function values are usually either maximized 
or minimized in an optimal solution. 
Anderson, Sweeney, Williams, Cam, and Cochran, Quantitative Methods for 
Business. 
Butchers, Day, Goldie, Miller, Meyer, Ryan, Scott, and Wallace, “Optimized 
Crew Scheduling at Air New Zealand.”
Cox and Goldratt, The Goal.
Samuelson, “Election 2012.”
1. 
to the same optimal solution. Give an example where minimizing cost 
the state and at the end of the year must return any part of that budget 
might it buy a $3 screwdriver even if it has to spend $50 to get it?
Answer: 
it has an asset worth $3 as part of its net worth. If it does not buy the 
screwdriver, the money it would have spent on it is lost. In other words, 
$3 is better than $0. This is the kind of situation that can result in 
runaway prices.
Suggested Reading
Questions and Comments
63
2. 
and part of their solution is the location of the frozen foods section. Its 
location is consistent in most stores. Can you identify a goal that would 
suggest this placement? Do you think this is the only objective of the 
grocery store’s management? 
Answer: 
The frozen foods section is usually near the end of the standard path that 
customers take through the store. The goal is to minimize the amount 
of thawing that occurs before the frozen items bought can be put in the 
to be a concern, but market share, expansion, and customer satisfaction 
might also be objectives.
64
Le
ct
ur
e 
8:
 L
in
ea
r P
ro
gr
am
m
in
g 
an
d 
O
pt
im
al
 N
et
w
or
k 
Fl
ow
Linear Programming and Optimal Network Flow
Lecture 8
A linear program is an optimization model, but not all optimization problems are created equal—no more than all hikes are created 
much easier than scaling a rough and craggy mountain. A major issue in how 
geography. And linear programs are the simplest optimization problems to 
solve because they have the simplest geometry. That’s going to make the 
math easier to write and the model easier to solve, meaning that problems 
big and small can be solved reasonably quickly. In this lecture, you will learn 
the basics of linear programming. 
Linear Programs: Geometric
 The word “linear” suggests a line—and it’s worth keeping that 
association. Two variables are linearly related if and only if their 
relation between input and output; it’s the straight line that best 
matches the data on a scatterplot. 
 In multiple regression, we can talk about a linear function of more 
than one variable. If we have two inputs, we can visualize this as 
a tabletop in which every position on the table is represented by 
a pair of x and y coordinates. A function of these two variables is 
represented by a surface hovering over that tabletop. 
 Suppose that we have a function like 3x + 2y. Pick a point on the 
tabletop—for example, x = 5, y
tabletop that hovering landscape is over that point, plug x = 5, 
y = 10 into the function. So, 3x + 2y becomes 3(5) + 2(10), or 
35. That means that the landscape is hovering 35 units above the 
tabletop at that point. And the entire landscape is created by doing 
this for each x-y pair. In general, the graph—that surface—might 
resemble almost any landscape that you can imagine.
65
 But if the function is a linear function, the landscape has a very 
Pick any point on the glass, pick a direction, and then draw on 
the glass, continuing in that direction. What you draw will be a 
straight line. 
 
sight you choose along the surface, you’re always looking along 
a straight line that stays in the surface. That same idea can be used 
sense. That’s what linear is geometrically. But it’s even easier to 
characterize algebraically. 
Linear Programs: Algebraic
 Suppose that you have a collection of input variables and you want 
sense that was just described. You want a linear relation. You can 
build such a function in an extremely simple way. Multiply each 
variable by a number, and then add the results. If you like, add one 
more number, by itself, at the end, for good measure. The numbers 
could be positive, negative, zero—whatever you like. The result is 
always a linear function of the inputs. 
 So, 3x + 2y z w + 8. Or x y
x x x is not linear; you can’t divide 
by a variable. In addition, xy isn’t linear; you can’t multiply two 
variables together. It’s just a number times a variable, plus a number 
times a variable, and so on, maybe with a number by itself added to 
the end.
Linear Programs: Conceptual
 What is a linear function conceptually? Let’s begin with a concrete 
example with only two variables: an input and an output. Suppose 
66
Le
ct
ur
e 
8:
 L
in
ea
r P
ro
gr
am
m
in
g 
an
d 
O
pt
im
al
 N
et
w
or
k 
Fl
ow
you can buy as many cans of tomato soup as you want. The input 
variable is how many cans you buy, and the output is the total 
grocery bill.
 Each time you add one more can of soup to the cart, you increase 
the total bill by the same amount: the cost of a can of soup. And if 
you change your mind, each time you take a can out of the cart, you 
always decrease your bill by that same amount. These statements 
are true, regardless of what else is already in the cart—whether 
characterizes a linear relationship. On the other hand, if you got 
a discount for buying four or more cans, for example, that would 
make the relationship nonlinear.
 What about if there’s more than one input? Suppose that for 
your grocery run, you have more latitude. You can buy soup and 
hamburger meat in whatever quantities you like, along with the 
purchases, you’re going to see the linear behavior just discussed. 
 On the other hand, if you change only your hamburger purchases, 
you see the same kind of behavior. Each additional pound increases 
your bill by the cost of a pound of ground beef, and so on. Again, 
these numbers don’t depend on what else is in the cart; they only 
depend on the fact that you’re changing the quantity of only one 
thing at a time.
 Whenever you have these kinds of relations, then the output—here, 
your grocery bill—is a linear function of those inputs.
 
other totals $50. In addition to these items, you can buy as much 
soup and hamburger meat as you want. Soup costs $1.05 per can 
and hamburger costs $3.29 per pound. What will the total bill be? 
Obviously, that depends on how much soup and hamburger meat 
you buy. 
67
 Let S be the number of cans of soup that you buy and H be the 
number of pounds of hamburger meat that you buy. Then, the total 
bill is going to be the following. 
 As easy as this is, it’s worth looking at in a new way, because it’s 
a little road map for linear programming formulation. First, look at 
the algebra. It is linear: a number times a variable, plus a number 
times a variable, plus a number. But here’s the important thing: 
1.05: If I buy one more can of soup, how many dollars does my bill 
go up?
3.49: If I buy one more pound of hamburger meat, how many dollars 
does my bill go up?
50: If I buy no soup and no hamburger meat, how much is 
my bill?
 We can generalize this. In any linear expression, the numbers 
answer one of two questions. The constant term—the number 
with no variable—answers this question: “Suppose I set all of the 
variables to zero. What should the thing underneath be?” The “thing 
underneath” is the measurable quantity you’re interested in—here, 
that’s the total bill. 
 This problem has two variables, S and H, representing cans of soup 
and pounds of hamburger meat, respectively. If they’re both zero, 
you don’t buy soup or hamburger meat, so your total bill is just the 
cost of everything else in your cart, which is $50—the cost of the 
original shopping list.
S H1.05 3.49 50
number of dollars spent
  
68
Le
ct
ur
e 
8:
 L
in
ea
r P
ro
gr
am
m
in
g 
an
d 
O
pt
im
al
 N
et
w
or
k 
Fl
ow
 
just a number multiplying a variable.) They answer this question: 
“If I get one more of this and make no other changes, how much 
does the thing underneath go up?” So, that 1.05 in front of S means, 
“One more S, and cost goes up 1.05.” 
 
a variable tells you how much the “thing underneath” goes up if 
the variable increases by one. For most variables, this will either 
mean that you get one more, or use one more, or need one more of 
something, etc.
An Application
 Suppose that during a 40-hour workweek, a building inspector can 
inspect either 80 houses or 10 farms. What math represents the 
number of hours the inspector spends inspecting this week if he or 
she inspects H houses and F farms? 
 The problem implies that each farm takes the same amount of time 
and each house takes the same amount of time. That makes the 
expression linear. Then, algebraically, the answer will look like 
the following.
 
If we set both H and F equal to zero, the inspector doesn’t inspect 
anything, so he or she spends no time inspecting. That’s how we 
H F
number of hours used
  
H F 0
number of hours used
  
69
 H. The question is as follows: If H goes up 
by one—which means that the inspector inspects one more house—
then how much does “the thing underneath”—the hours used—go 
up? The inspector can do 80 houses in 40 hours, which means that it 
H goes up by one, 
 And, of course, we use the same reasoning for F. One more farm 
increases time used by how much? Ten farms in 40 hours means 4 
F. And we’re done. 
0.5H + 4F gives the time used. If the inspector only works 40 hours 
in a week, our constraint would be as follows.
 
numbers that we started with. Those were 80 and 10. We found the 
 This time constraint we just created is an example of the most 
common kind of constraint in a linear program, called a limited 
resource constraint. It says that you can’t use more of something 
of units available.
limited resource constraint: The most common kind of linear 
programming constraint. It says that you can’t use more of something than 
what is available. 
H F0.5 0
number of hours used
  
H F0.5 4 40+ ≤
Important Terms
70
Le
ct
ur
e 
8:
 L
in
ea
r P
ro
gr
am
m
in
g 
an
d 
O
pt
im
al
 N
et
w
or
k 
Fl
ow
linear program: A model in which the objective function and the two sides 
of each constraint are all linear expressions. Linear programs are especially 
easy to solve. 
Narisetty, Richard, Ramcharan, Murphy, Minks, and Fuller, “An Optimization 
Stevens and Palocsay, “A Translation Approach to Teaching Linear Program 
Formulation.”
1. In the railroad example in the video lecture, instead of shipping 
empty cars, imagine that we were shipping fruit and that the variables 
represented the number of tons of fruit shipped from city to city. Now 
reloaded, resulting in 5% of the fruit being ruined. How would you 
Answer:
The “measurable quantity formulation” would now read
and “95% of” becomes “0.95 ×.” So, we get
All “percentage constraints” follow this same pattern.
Suggested Reading
Questions and Comments
# of tons of fruit
leaving Chicago
95% of
# of tons of fruit
entering Chicago
     
CE CF CG AC BC
# of tons of fruit
leaving Chicago
0.95
# of tons of fruit
entering Chicago
     
( )+ + = +
71
2. A common mistake in formulation is what is sometimes called a 
“recipe error,” because it results when one attempts to write a recipe 
as a constraint. For example, suppose that you build chairs, and a 
chair consists of four legs, one back, and one seat. It is tempting (but 
altogether wrong) to write CHAIR = 4LEGS + BACK + SEAT.
a)  Assuming that CHAIR is the number of chairs made, LEGS is the 
number of legs used, and so on, show that this constraint is incorrect.
b)  Write the correct constraints to connect CHAIR, LEGS, BACK, and 
SEAT. (Hint: you’ll need three of them.)
Answers:
a)  The easiest way is “validation”: plugging in numbers that should 
work and checking to see if they do work. For example, 1 chair 
needs 4 legs, 1 back, and 1 seat, so the values CHAIR = 1, LEGS = 
4, BACK = 1, and SEAT = 1 should work in a correct equation. But 
plugging these values into the equation above gives the following.
 1 = 4(4) + 1 + 1 = 18 
  This is obviously untrue. So, the formula is wrong.
b)  BACK = CHAIR, SEAT = CHAIR, LEGS = 4CHAIR. The key idea 
here is that once you know CHAIR, you know all four variable 
values, which means that each of the other three variables can be 
CHAIR alone.
72
Le
ct
ur
e 
9:
 S
ch
ed
ul
in
g 
an
d 
M
ul
tip
er
io
d 
Pl
an
ni
ng
Scheduling and Multiperiod Planning
Lecture 9
Multiperiod planning problems are a class of problems in which planning extends over time. In a multiperiod planning problem, we generally need to make essentially the same kind of decisions 
repeatedly over time. Typically, with multiperiod planning problems, the 
situation we face at any given point in time depends on earlier decisions, 
planning. In this lecture, you will learn how to approach problems like these 
with linear programming. 
Multiperiod Planning
 What many multiperiod planning problems have in common is a 
reliance on conservation constraints, which are constraints that 
say that if you count the same thing in two different ways, you 
have to get the same answer in both counts. In network models, 
we often take this to mean that total in equals total out. Another 
auxiliary variable.
 To get a handle on what this means, let’s think about a production 
and inventory problem. We have a business where we make a 
product each month. There’s a demand for our product each month, 
too, and we’ll sell whatever we have on hand to satisfy as much of 
that demand as we can. If we have more product than customers 
want, what we don’t sell goes in inventory. 
 There might be more involved, of course—sometimes we’re 
contractually required to meet demand, sometimes we pay a penalty 
if we can’t, or we may be making multiple products with the same 
equipment, and so on. But let’s think about the simple transaction 
that occurs in any given month, in terms of total in equals total out.
73
 We start with our leftover inventory from last month. Then, this 
month, we make products and add them to the pile. That’s our 
total in. Where do the products go? Some of them get sold to meet 
demand, and whatever’s left, we stick into inventory for next 
month. So,
old inventory + current production = current sales + new inventory.
 But, if we subtract current sales from both sides, we get
 This new equation says the same thing as the original but can 
be looked at as an equation that tells you how to compute new 
inventory from the other three quantities. Of the four quantities 
in this equation, only three of them are independent. If we know 
fourth. So, we don’t really need all four variables. 
 We say that the fourth variable is a dependent variable, or an auxiliary 
variable. It’s one you might choose to use, but you don’t really 
need it, in the sense that its value is completely determined by the 
values of the other variables. You can make up these “unnecessary 
variables” anytime you want to, but the caveat is that every one of 
Scheduling Problems
 With scheduling problems, the situation might involve making 
sure that you have enough staff to cover your needs at different 
times. This kind of problem isn’t usually considered a multiperiod 
problem, in spite of the fact that it evolves through time. Most 
people would class it as a covering problem—making sure that 
you have enough coverage over each region in the domain of your 
problem. The easiest way to see how to formulate a problem like 
this is often with a timeline. 
74
Le
ct
ur
e 
9:
 S
ch
ed
ul
in
g 
an
d 
M
ul
tip
er
io
d 
Pl
an
ni
ng
 Suppose that we run a 24-hour emergency room, and we’ve decided 
that we need a certain number of nurses on duty during each 4-hour 
period through the day. And suppose that each nurse works an 
8-hour shift that starts either at midnight, 4 am, 8 am, noon, 4 pm, 
or 8 pm. 
 
of the day but to not pay more than we have to. We could add all 
kinds of complications to this problem—such as people being paid 
more for working the less-desirable shifts, or nurses getting a break 
for a meal, and so on—but for this example, let’s keep it simple. 
 
minimizing the number of nurses used. So, our goal is to minimize 
the number of nurses used. What are our constraints? There are six 
quota constraints. Every 4-hour interval has to have at least as 
many nurses on duty as the timeline requires. 
 What are our decision variables? We have to decide how many 
nurses to work in each of the possible shifts—how many start at 
midnight, at 4 am, at 8 am, and so on. So, let’s make variables for 
that. We’ll call the shift that starts at midnight shift 1, the one that 
starts at 4 am shift 2, and so on. Each shift is 8 hours long, so a 
nurse working shift 6 comes on duty at 8 pm and works until 4 am 
on the next day. Let xi be the number of nurses working shift i, 
as follows.
Figure 9.1
Figure 9.2
75
 There are x1 nurses working on shift 1, which runs from midnight 
to 8 am, and so on. And shift 6 wraps around from one end of the 
timeline to the other, because it starts at 8 pm today and ends in the 
wee hours of tomorrow, at 4 am.
 Our objective is the total number of nurses hired. This means that 
the objective is just the sum of these six variables.
Minimize x1 + x2 + x3 + x4 + x5 + x6
 
1 more nurse for any shift and the total number of nurses hired goes 
up by 1. And the constant term is zero, because if you set all of the 
variables to zero, you haven’t hired any nurses.
 
4-hour interval, and it says the following.
number of nurses needed for that interval
 This is a straightforward quota constraint. The right-hand side is the 
number of nurses that we need from midnight to 4 am, and we’re 
told that this is just 5, from our timeline. What about the left-hand 
side, the number of nurses on duty from midnight to 4 am?
 If we increase a single variable by 1, such as x1, that means that we’re 
hiring 1 more nurse for that shift. And 1 more nurse working shift 1 
will affect the number of nurses working during the 12 am to 4 am 
interval, because shift 1 runs from midnight all the way to 8 am. 
 So, in particular, the nurses working shift 1 are on duty during the 
midnight to 4 am interval. On the other hand, the nurses working 
shift 2 don’t start until 4 am, so increasing x2 by 1 doesn’t help us 
that x2, the number of nurses working shift 2, doesn’t appear on the 
left-hand side of this constraint.
76
Le
ct
ur
e 
9:
 S
ch
ed
ul
in
g 
an
d 
M
ul
tip
er
io
d 
Pl
an
ni
ng
 The timeline shows that only two groups of nurses are on duty 
during the midnight to 4 am window: shift 1 and shift 6. Midnight 
shift 6. So, the midnight to 4 am constraint is as follows.
x1 + x6
 Similarly, each constraint says the following: Add the number of 
nurses on the two shifts that include this 4-hour interval. That total 
has to be enough to cover the demand for that 4-hour interval. 
So, the following is the whole formulation.
Minimize x1 + x2 + x3 + x4 + x5 + x6
subject to
x6 + x1
x1 + x2
x2 + x3
x3 + x4
x4 + x5
x5 + x6
 In summary, minimize the total number of nurses hired, but require 
that the number of nurses working during any 4-hour window is at 
least what we need for that window. 
 Why are we using “greater than or equal to” in these constraints? 
Why not just use “equal to”? Why use more nurses than you need? 
We’re not going to use more nurses than we need—that’s what 
the objective is all about—but that doesn’t mean that some 4-hour 
window might not be overstaffed. 
 
77
4 nurses in the second window, and only 1 nurse again in the third 
and third windows, but those nurses are the only people that could 
possibly be on duty during the second window, because each nurse 
works 8 hours—2 successive windows. So, if we have 4 nurses in 
interval 2, we have to have more nurses than we need in interval 1, 
or interval 3, or both. Our program allows for this possibility.
auxiliary variable: Also called a dependent variable. A variable whose 
value is completely determined by the values of the other variables in the 
how its value is computed. 
conservation constraint: An equality constraint in a linear program that 
generally requires that counting the same thing in two different ways must 
give the same answer. It can often be interpreted as “total in = total out.” 
multiperiod planning: Problems in which the same pattern of decisions 
must be made repeatedly over time. 
program: Mathematically, an optimization model. The term corresponds to 
the idea of a program as a schedule, as in television programming, because 
many early optimization models were scheduling problems. 
quota constraint: The second-most-common kind of linear programming 
constraint. It says that the amount obtained of something is at least as much 
as is required. Also called a minimum performance constraint. 
Caixeta-Filho, van Swaay-Neto, and Wagemaker. “Optimization of the 
Production Planning and Trade of Lily Flowers at Jan de Wit Company.” 
Ragsdale, Spreadsheet Modeling & Decision Analysis.
Important Terms
Suggested Reading
78
Le
ct
ur
e 
9:
 S
ch
ed
ul
in
g 
an
d 
M
ul
tip
er
io
d 
Pl
an
ni
ng
1. People often expect that in an optimal solution to a linear program, 
all limited resources will be completely consumed. This is untrue. To 
generate a counterexample, imagine that you produce and sell baked 
goods (and only baked goods) and have found along with the rest of 
your inventory a jar of dill pickles. (There is nothing actually preventing 
you from making dill pickle cookies.)
Answer: 
Using all of the resources available would require using the pickles, too, 
and because you are in the baking business, that means making some 
baked good with dill pickles. This product is unlikely to be popular, 
pickle cookie (or whatever) would no longer be available for the more-
solution that let the pickles go unused.
2. 
its buildings, can’t be varied in the short term. Suppose that two analysts 
create a linear program for the short-term decisions of a company, using 
the same constraints. One has the goal of minimizing total cost while the 
other has the goal of minimizing variable cost. Why would their optimal 
solutions give the same values of the decision variables? (It’s because 
linear programs.) 
Answer: 
will be at a minimum precisely when the variable cost is at a minimum. 
Questions and Comments
79
Visualizing Solutions to Linear Programs
Lecture 10
In this lecture, you will learn how to solve a linear program by using limitations to this graphical approach, but there are also some important 
advantages. Most people process images better than numbers or equations, 
and this pictorial approach provides many insights into some of the key 
characteristics of all linear programs and their solutions. More complicated 
solutions rely on the same observations and properties that the simple 
problems do. 
A Graphical Approach to Personal Financial Investment
 Let’s say that you have $80,000 to invest in three different 
investment options. Each investment pays you back after four years. 
risk
that instead it will lose you 20% of your investment in that time. 
 Even in this linear program, there is a stochastic element, because 
the objective is to maximize your average return in this situation, 
also called your expected return. To calculate the expected return, 
multiply each possible outcome by its probability of occurring and 
add the results, as follows, resulting in an expected return of 20%.
 The second option is high risk and high return. It’s 50% likely to 
give you a 150% return on investment, but it’s also 50% likely to 
give you only half of your money back. This means that its expected 
return works out to be 50%.
80
Le
ct
ur
e 
10
: V
is
ua
liz
in
g 
So
lu
tio
ns
 to
 L
in
ea
r P
ro
gr
am
s
 
15% return, total, over the four years. 
 Your goal is to maximize the expected return, or average return, 
on the money you invest. To limit your downside risk, though, you 
want to be sure that you lose at most $10,000, even if the risky 
want no more than $40,000 in any single investment.
 Initially, this may seem like a three-variable problem—how much 
money do you put in each investment? But because we know that 
the total investment is $80,000, as soon as we know how much we 
third. That is, the third variable is really an auxiliary variable. So, 
the program is as follows.
Maximize 0.20M + 0.50H M H)
subject to
M
H
M H
0.2M + 0.50H M H
and M, H
 The objective just records the expected, or average, return on each 
of the three investments: 20% for the medium-risk one, 50% for 
the high-risk one, and 15% for the risk-free one. We’re trying to 
maximize this expected return, and we get it by multiplying the 
expected rate of return for an investment by the amount of money 
that we put into it.
81
 
investments can have more than $40,000 put into it. The fourth 
constraint is our Murphy’s law constraint, which says that the 
money we lose on our investments, even if everything goes 
wrong, is at most $10,000. In this worst case, we lose 20% of the 
medium-risk money and 50% of the high-risk money, and this loss 
is counterbalanced somewhat by what we make on the risk-free 
investment. We also have nonnegativity constraints, because we 
can’t invest negative dollars in any option.
 We can clean up the algebra by multiplying out parentheses and 
gathering like terms. We can also rewrite the problem in terms of 
thousands of dollars, rather than just dollars, to get rid of all the triple 
zeroes at the ends of everything. The following program might look 
Maximize 0.05M + 0.35H + 12
subject to
M
H
M + H
0.35 M + 0.65 H
and M, H
Finding Possible Answers
 How do we solve the problem? We have two decision variables, M 
and H, and we’ll give each one its own axis in a Cartesian plane. 
Then, we’ll add the constraints one at a time to see what points 
constraint is going to be a feasible solution, a possible answer. We’ll 
be able to see easily exactly which points—which combinations of 
M and H—these are.
82
Le
ct
ur
e 
10
: V
is
ua
liz
in
g 
So
lu
tio
ns
 to
 L
in
ea
r P
ro
gr
am
s
 Then, we’re going to have to decide which of these possible 
answers is the best one—for this problem, which one gives the 
largest expected return. And this is going to work because of the 
geometric character of linear functions. 
 Linear relations between two variables graph as straight lines. More 
generally, linear relations among a collection of variables graph as 
lines, or planes, or higher-dimensional equivalents called 
hyperplanes. The crucial point about these objects is that they are 
we draw in this problem is going to be a straight line, thanks to the 
linearity of our program.
 We graph all of the constraints to see what’s possible. The points 
in the shaded region in Figure 10.1 satisfy every one of our six 
constraints: the four nontrivial constraints and the nonnegativity 
constraints. That’s true of 
the points on the border 
of the shaded region, too. 
Conversely, any point outside 
of the shaded region violates 
at least one of the constraints; 
it’s on the wrong side of a 
line, so it doesn’t represent 
a possible answer to our 
question. The shaded region 
is called the feasible region 
because it contains precisely 
the points that satisfy every 
single one of the constraints.
Finding the Best-Possible Answer
 Among the points in the feasible region, which is best? To get at 
the answer, we’re going to pick a point in the feasible region and 
that we pick the point with coordinates M = 40, H = 0, which 
Figure 10.1
83
means putting $40,000 in the medium-risk investment and $0 in 
the high-risk investment. The other $40,000, then, will go in the 
risk-free investment.
 What expected return do we get? The $40,000 in the risk-free return 
is guaranteed to give us 15%, which is $6000. The $40,000 in the 
medium-risk investment on average pays 20%, so it gives us $8000 
on average. That’s a total of $14,000 in expected return. We’re going 
to do the same thing with every other point in the feasible region. 
 This is a linear program, so it graphs as straight lines, planes, or 
the three-dimensional graph of our expected returns is going to be 
or kinks. 
 
tilted, one of the corners is going to be a highest point—it’s going 
to be as high or higher than everything else. And that’s the point 
we want. This is the extreme point theorem of linear programming: 
If there’s an optimum point, there’s one at a corner of the feasible 
optimum. But we can also take a different approach.
 
depth. When the water gets high enough, some of the points 
will be submerged, but others will still peek above the surface. 
Let’s use an aerial view, looking straight down. We see the 
peeking above the water.
 . 
edge, so they all have the same height. In terms of our original 
problem, this means that each of the points along the OFL gives 
84
Le
ct
ur
e 
10
: V
is
ua
liz
in
g 
So
lu
tio
ns
 to
 L
in
ea
r P
ro
gr
am
s
the same expected revenue. 
That is, it gives a higher 
expected return than the level 
represented by the water. 
 If you want a shot at a higher 
expected return, send some 
more water into the picture. 
The water level will rise, and 
the points that are still not 
submerged make you more 
money on average. 
 How do we know how to 
take the objective function 
and set it equal to whatever 
number pleases us. The 
return we’re looking for—it’s 
the depth of the water. When 
we set the objective equal 
to a number, we get a linear 
equation, so it graphs as a 
straight line. That’s why the 
water’s edge is a straight line 
in the aerial view.
 If you think of this as a map, you’ll avoid a common mistake. In the 
water in the southwest from land to the northeast. As the water 
rises, the coastline covers more land and moves northeast. But, of 
Figure 10.3
Figure 10.2
85
 
water and which is dry land. 
The highest land is not always 
in the northeast.
 
just keep the water coming. 
The coastline keeps creeping 
in—in this case, from the 
southeast—and eventually 
only one point in our shaded 
triangle is still above water, 
which is the upper-left corner 
of the triangle.
 Where is it? From the graph, we can tell that it’s somewhere 
around $15,000 in the moderate-risk investment and $25,000 in 
the high-risk investment, which would leave about $40,000 for the 
risk-free investment. 
 We can get precise values for the coordinates by taking the two 
constraint equations that meet at the optimal point and solving them 
simultaneously. This involves more basic algebra. 
 Solving constraint equations 3 and 4 simultaneously gives us that 
M H
$13,333 in the moderate-risk option, $26,667 in the high-risk 
option, and the remaining $40,000 in the risk-free option. Doing so 
will give an expected return of $22,000 on your $80,000 investment, 
or a 27.5% expected return.
0.2(13,333) + 0.5(26,667) + 0.15(40,000) = 22,000
 That’s the unique, best answer to this problem. Any other solution 
either gives a lower return or breaks a constraint.
Figure 10.4
86
Le
ct
ur
e 
10
: V
is
ua
liz
in
g 
So
lu
tio
ns
 to
 L
in
ea
r P
ro
gr
am
s
feasible: Possible. In a mathematical program, feasible solutions are those 
that satisfy all of the constraints. 
feasible region: The set of decision variable combinations that correspond 
to feasible solutions to the problem. In a two-variable linear program, the 
feasible region, if it exists, will be one contiguous convex region bordered 
by straight lines. 
hyperplane
wall. Don’t worry—most people can’t visualize them. 
nonnegativity constraint: A constraint requiring a particular decision 
variable to be at least zero. Also called a trivial constraint. 
nontrivial constraint: Any constraint other than a nonnegativity constraint. 
: In a graphically solved linear program, a 
line of constant objective function value. OFLs act like contour lines on a 
topographic map. In problems with more than two variables, OFLs are 
replaced with planes or hyperplanes of constant objective function value. 
risk: Variability in the desirability of the possible outcomes of a situation 
involving uncertainty. Decision makers may be risk neutral, meaning that 
they choose whatever course of action gives the highest expected payoff. 
Alternatively, they may be risk averse or risk loving. Risk-loving individuals 
Risk-averse individuals are inclined to refuse a gamble even if, on average, 
Ragsdale, Spreadsheet Modeling & Decision Analysis.
Important Terms
Suggested Reading
87
1. In this lecture, we addressed only maximization problems, but an 
entirely equivalent procedure exists for solving minimization problems. 
If the word “maximize” in a linear program is changed to “minimize,” 
what effect, if any, would this have on the feasible region? The original 
would you characterize the optimal point for the “minimize” problem in 
Answer: 
The feasible region would not change at all, nor would the original 
direction, though. We could imagine withdrawing water from a partially 
2. The original objective function line that is drawn is generated by setting 
the objective equal to an arbitrary constant, setting the “depth of the 
if two different objective function lines are drawn for the same problem, 
they must be parallel. (Hint: Remember that they’re straight lines, 
because the objective is linear.)
Answer: 
The algebra is straightforward, the simplest method probably being to 
put both equations in slope-intercept form and verifying that they have 
the same slope. Logically, it’s even easier. Each objective function line 
objective function lines obtained from setting the objective equal to 
two different numbers, such as 10 and 20. If they are not parallel, then 
they intersect, and at the point of intersection, the objective function 
would then have two different values—both 10 and 20. Clearly, this 
is impossible.
Questions and Comments
88
Le
ct
ur
e 
11
: S
ol
vi
ng
 L
in
ea
r P
ro
gr
am
s 
in
 a
 S
pr
ea
ds
he
et
Solving Linear Programs in a Spreadsheet
Lecture 11
Iany linear program that has one by using a spreadsheet program on your computer. The example in this lecture will give you a good idea of 
what goes on behind the scenes once a problem is formulated and what its 
answer may look like. The technique that the spreadsheet uses is essentially 
George Dantzig’s simplex method. The example will be done in Calc, which 
suite. The interfaces of both programs are quite similar, but there are some 
variations between the two.
The Simplex Method
 Suppose that you have seven different investment options available 
for your $500,000 nest egg: investments A, B, and C and four 
money-market funds. Let’s say that you want to accrue as much 
wealth as possible at the end of the fourth year, but you also want 
to withdraw $10,000 at the end of the third year for a vacation. The 
program is as follows.
Maximize 1.10A + 0.53C + 1.02M4 Maximize cash at end of year 4
subject to subject to
500,000 = A + B + M1 (beginning of year 1)
0.02A + 1.02M1 = M2 (out of year 1 = into year 2)
0.02A + 1.05B + 1.02M2 = C + M3 (out of year 2 = into year 3)
0.02A + 0.53C + 1.02M3 = M4 + 10,000 (out of year 3 = into year 4)
89
 Each constraint says that the money that becomes available at the end 
of one year is equal to the money that’s disbursed at the beginning of 
the next year, and the objective tells us how much money becomes 
available at the end of year 4. In some ways, it’s amazing that so 
much information boils down to such a small formulation, isn’t it? 
That’s part of the charm and power of the language of mathematics.
 
is referred to as standard form, in which the left-hand side of the 
constraint is just a linear expression with no constant term and the 
right-hand side is just a constant term—no variables. 
 
500,000 = A + B + M1  
A + B + M1 = 500,000
 And the variables on the right-hand sides of the other constraints 
need to be subtracted, to get them over on the left-hand sides.
0.02A + 1.02M1 = M2  
0.02A + 1.02M1 M2 = 0
0.02A + 1.05B + 1.02M2 = C + M3  
0.02A + 1.05B + 1.02M2 C M3 = 0
0.02A + 0.53C + 1.02M3 = M4  
0.02A + 0.53C + 1.02M3 M4 = 10,000
 A method called the matrix representation is a straightforward 
approach that allows you to accurately and correctly enter any 
linear program into a spreadsheet. “Solving” a linear program 
to start off with a row that just lists the names of all of the variables 
in the program. Directly under those, we’re going to have cells that 
will—eventually—hold their best values. To keep things clear, 
90
Le
ct
ur
e 
11
: S
ol
vi
ng
 L
in
ea
r P
ro
gr
am
s 
in
 a
 S
pr
ea
ds
he
et
these so-called decision variable value cells are bordered with 
hand. Add a new row for the objective, aligned with the variables 
 The objective is just 1.10A + 0.53C + 1.02M4, so we just recorded 
corresponding variables. The other variables get zero entries in this 
row, because they aren’t in the objective.
 The spreadsheet is going to need to calculate how much money 
this expression works out to be. And that, of course, depends on 
how much money we put in each investment. Those numeric 
values are going to go in the cells with the dotted lines, and 
although we obviously don’t know how much money to put in each 
fund, we’re for the moment just going to put any numbers in those 
cells, as placeholders.
 Not only are these values not optimal—they’re not even feasible. 
Remember that we have to invest $500,000 right now, and clearly 
we aren’t. But it doesn’t matter. When we get to it, the spreadsheet’s 
solver
A B C D E F G H
1 A B C M1 M2 M3 M4
2
3
4 Maximize 1.10 0.00 0.53 0.00 0.00 0.00 1.02
Figure 11.1
A B C D E F G H
1 A B C M1 M2 M3 M4
2 300 200 100 1000 1000 1000 2000
3
4 Maximize 1.10 0.00 0.53 0.00 0.00 0.00 1.02
Figure 11.2
91
 
supposed to be generated by them. The objective is 1.10A + 0.53C + 
1.02M4, so the answer is as follows.
1.10(300) + 0.53(100) + 1.02(2000) = 2423
 In the spreadsheet, the decision variables’ values in the boxes with 
in the gray box. Then, corresponding terms are multiplied: 300 times 
1.10, 200 times 0, 100 times 0.53, and so on. Finally, all of these 
products are added. Both Excel and Calc have a built-in function for 
doing this with two rows of numbers. It’s called SUMPRODUCT. 
First, you do a bunch of products, and then you do a sum. 
 
range you want—in this case, the cells with the dotted lines in B2 
to H2—and then the second range that you want—in this case, 
the gray cells from B4 to H4. Between these two ranges goes a 
separator. In Calc, it’s a semicolon, and in Excel, it’s a comma. At 
the end, you close the parentheses.
=SUMPRODUCT(B2:H2;B4:H4)  (Calc)
=SUMPRODUCT(B2:H2,B4:H4)  (Excel)
 When you enter this, the spreadsheet calculates the correct value.
 This is dynamic, of course—change the numbers in the cells with 
the dotted lines and the spreadsheet automatically computes the 
A B C D E F G H I J
1 A B C M1 M2 M3 M4
2 300 200 100 1000 1000 1000 2000
3
4 Maximize 1.10 0.00 0.53 0.00 0.00 0.00 1.02 2423
Figure 11.3
92
Le
ct
ur
e 
11
: S
ol
vi
ng
 L
in
ea
r P
ro
gr
am
s 
in
 a
 S
pr
ea
ds
he
et
 Next, we’re going to play the same game with the left side of the 
constraints. 
 Column I is labeled LHS, which stands for “left-hand side.” When 
you multiply each entry in the row with dotted lines by the 
corresponding element in a gray row and then add all of those 
products together, the LHS entry tells you the result. 
A B C D E F G H I J
1 A B C M1 M2 M3 M4
2 300 200 100 1000 1000 1000 2000
3
4 Maximize 1.10 0.00 0.53 0.00 0.00 0.00 1.02 $2423.00
5
6 subject to
7 LHS
8 Now 1 1 0 1 0 0 0 1500
9 Year 1 end 0.02 0 0 1.02 0 0 26
10 Year 2 end 0.02 1.05 0 1.02 0 136
11 Year 3 end 0.02 0 0.53 0 0 1.02
Figure 11.4
A B C D E F G H I J K
1 A B C M1 M2 M3 M4
2 300 200 100 1000 1000 1000 2000
3
4 Maximize 1.10 0.00 0.53 0.00 0.00 0.00 1.02 $2423.00
5
6 subject to
7 LHS RHS
8 Now 1 1 0 1 0 0 0 1500 = 500,000
9 Year 1 end 0.02 0 0 1.02 0 0 26 = 0
10 Year 2 end 0.02 1.05 0 1.02 0 136 = 0
11 Year 3 end 0.02 0 0.53 0 0 1.02 = 10,000
Figure 11.5
93
 But a constraint has two sides, and we still need the right-hand sides. 
In this particular program, all of our constraints are conservation 
constraints—equality constraints—so let’s indicate that and include 
the right-hand sides in the spreadsheet as well.
 
Because all of our constraints are equality constraints, the LHS and 
RHS in each row have to be identical, or we don’t have a feasible 
solution. So, our current proposed solution is way off base. None of 
 We could play around with trying different numbers in the cells with 
constraints true, but that would not be the best-possible investment 
strategy. We don’t need to play around with these numbers, because 
that’s the job of the spreadsheet and the simplex method.
 Everything on the spreadsheet that isn’t a number is actually going 
to be irrelevant to the spreadsheet’s solver. We have to tell the 
solver where the objective is, where the decision variable values 
are, and where the constraints are. 
 
Excel to install the add-in, you’ll see it appear on the menus or 
ribbons on the top of your 
Excel screen. For Calc, 
which is what we’re using, 
the add-in is preinstalled. It’s 
accessible from the “Tools” 
menu. While the popup 
windows in the two 
applications look slightly 
different, they want the same 
information and work in the 
same way. The following is 
the process for Calc. Figure 11.6
94
Le
ct
ur
e 
11
: S
ol
vi
ng
 L
in
ea
r P
ro
gr
am
s 
in
 a
 S
pr
ea
ds
he
et
 The “target cell” is the cell that holds the objective function. In this 
case, that’s year 4 cash on hand, in cell I4. We want to maximize it, 
so we leave the radio button 
selecting “maximum” alone. 
And the “changing cells” are 
the cells that contain the 
values of our decision 
variables—the cells with the 
dotted lines, B2 through H2.
 That leaves the constraints. 
You can enter each constraint 
as its own row in Solver, but 
if a number of consecutive 
constraints have the same 
Because all of our constraints are equalities, we can do all of them 
at once, by saying that the four left-hand sides, from I8 to I11, have 
to equal the four right-hand sides, from K8 to K11. 
 We have only one more concern, if we’re using Calc. We forgot 
the nonnegativity constraints on all of the variables. This is easily 
remedied by clicking “options” and then checking the box by 
“Assume variables as nonnegative.” Then, get out of “options” 
by clicking “OK,” and 
you’re back in the Solver. 
 In Excel, assuming that all 
variables are nonnegative 
is the default. Also, if 
you’re using a version 
of Excel that includes 
“Premium Solver,” you’ll 
also want to tell it to use 
as the “Solving Method.”
Figure 11.7
Figure 11.8
95
 As soon as we press the “solve” button in the bottom-right corner, 
of all of the myriad possibilities. For problems of even considerable 
size, the simplex method for linear programs is blindingly fast. The 
best investment strategy is as follows.
 According to the boxes with the dotted lines, the best way to invest 
the money is to put all of it in investment A originally. After 1 year, 
you’ll have $10,000 come back from A, and this gets funneled into 
money-market 2 for a year. At the end of that time, it comes out 
as $10,200. Also, A gives another $10,000, so the total of $20,200 
gets plowed into investment C. Investment C, after a year, gives 
53% of this back, or $10,706. We also get another $10,000 from 
investment A, which is just enough to pay for the vacation, so the 
$10,706 gets one more year in the money-market fund. It matures, 
as does the money from investment A, along with another 53% of 
the money from investment C, and we end up with $571,626.12 
on hand at the end of year 4. With these lousy interest rates, it’s 
best-possible one. 
A B C D E F G H I J K
1 A B C M1 M2 M3 M4
2 5000 0 20200 0 10000 0 10706
3
4 Maximize 1.10 0.00 0.53 0.00 0.00 0.00 1.02 $571,626.12
5
6 subject to
7 LHS RHS
8 Now 1 1 0 1 0 0 0 500000 = 500,000
9 Year 1 end 0.02 0 0 1.02 0 0 0 = 0
10 Year 2 end 0.02 1.05 0 1.02 0 0 = 0
11 Year 3 end 0.02 0 0.53 0 0 1.02 10000 = 10,000
Figure 11.9
96
Le
ct
ur
e 
11
: S
ol
vi
ng
 L
in
ea
r P
ro
gr
am
s 
in
 a
 S
pr
ea
ds
he
et
simplex method
optimal solution to any linear program that has one. For most linear programs, 
solver: Generally, a piece of software for solving a class of problems. 
to linear and nonlinear programs. 
standard form: A linear constraint in standard form has all of its variable 
terms on the left side of the constraint and its constant term on the right side. 
2x + 4y
SUMPRODUCT: A function in Calc and Excel that takes two row or 
column arrays of equal length, multiplies corresponding elements, and then 
adds the results. In vector calculus, this is the dot product or scalar product 
of two vectors. 
Anderson, Sweeney, Williams, Cam, and Cochran, Quantitative Methods 
for Business. 
Ragsdale, Spreadsheet Modeling & Decision Analysis.
Strayer, Linear Programming and Its Applications.
1. Why should a manager focus his or her attention on those constraints 
that are binding on the optimal solution?
Suggested Reading
Questions and Comments
Important Terms
97
Answer: 
Because any change in a binding constraint will probably change the 
quality of the optimal solution. On the other hand, a small change in a 
nonbinding constraint will never affect the optimal solution, nor can a 
chance in a nonbinding constraint ever improve the optimal solution.
2. Imagine beginning with a linear program that has an optimal solution. 
We change this program by removing a constraint. Argue that the 
optimal objective function value may stay the same or may improve, but 
cannot grow worse. Argue that the program may become unbounded, 
but cannot become infeasible. (Hint: Think about what, if anything, 
happens to the feasible region.)
Answer:
Any solution that worked in the original program (that is, was feasible) 
removed. Thus, either the old optimal solution is still the best-possible 
solution (which is what would happen if the removed constraint were 
nonbinding on the optimal solution), or a new, better solution is now 
possible. Because the old optimal solution is still feasible, the new 
program is feasible. But the new program may now be unbounded. As 
an example, consider the program “maximize x,” subject to x
the constraint, the optimal solution is x = 5. Without the constraint, x 
may become arbitrarily large.
98
Le
ct
ur
e 
12
: S
en
si
tiv
ity
 A
na
ly
si
s—
Tr
us
t t
he
 A
ns
w
er
?
Sensitivity Analysis—Trust the Answer?
Lecture 12
With sensitivity analysis in operations research, we take a problem for which we have found the best answer and then ask how sensitive this best answer is to perturbations in the problem. How much can 
we change a program parameter before we affect the best solution? If changing 
a parameter does affect the optimal solution, can we anticipate and characterize 
the nature of this change? And if we can, when, if ever, does this rule break 
down? These questions for linear programs will be addressed in this lecture. 
Sensitivity Analysis: The Railroad Problem
 Suppose that we want to ship freight cars by railroad from the 
source cities of Atlanta and Baltimore, through the transshipment 
cities of Chicago and Dallas, and on to the destination cities of 
Eugene, Fresno, and Great Falls. Each source has a limited number 
has a demand for cars that has to be met (that’s the last three cities). 
And the constraints for Chicago and Dallas say that for those two 
cities in the middle, what goes in goes out.
 If you look at the matrix representation of this linear program, you’ll 
see that all of the problem parameters—the numbers given in the 
problem—appear in the gray boxes. The boxes with the dotted lines 
are the best values of the variables as found by the spreadsheet. The 
black cell with the white writing is the objective. The LHS (“left-
hand side”) column holds the left sides of the constraints, computed 
by using the decision cells (dotted lines) and the gray cells beneath 
them. So, the entry in cell L8 tells us that 250 cars leave Atlanta, 
and the entry in cell L14 tells us that 100 cars come into Great Falls.
 Sensitivity analysis asks the following question: What happens 
when we change one or more of the numbers in gray? These might 
be changes resulting from deliberate choices, or they might be 
changes imposed on us by some random variation. 
99
A B C D E F G H I J K L M N
1 AC AD BC BD BF CE CF CG DE DF
2 100 150 0 0 200 0 0 100 150 0
3
4 Maximize 72 78 70 277 136 213 214 138 206 156 $90,800
5
6 subject to
7 LHS RHS
8 Atlanta 1 1 0 0 0 0 0 0 0 0 250 300
9 Baltimore 0 0 1 1 1 0 0 0 0 0 200 200
10 Chicago 1 0 1 0 0 0 0 0 = 0
11 Dallas 0 1 0 1 0 0 0 0 0 = 0
12 Eugene 0 0 0 0 0 1 0 0 1 0 150 150
13 Fresno 0 0 0 0 1 0 1 0 0 1 200 200
14 Great Falls 0 0 0 0 0 0 0 1 0 0 100 100
Figure 12.1
 In the top gray row, changing a number would mean changing 
how much it costs to ship one car along a link from city to city. In 
the right-hand column, it would be changing how many cars are 
available in a city, or how many are needed, or allowing cars to be 
added or removed in Chicago or Dallas. Changing the numbers in 
the big gray rectangle to the lower left doesn’t make good physical 
sense in this problem.
 We’re doing math, and the power of math is generality. In this 
problem, the objective is cost, and the constraints are talking about 
freight cars. In a different problem, the numbers in the shaded 
regions might represent quantities that aren’t even close to these. 
But if it’s a linear program, the kinds of effects when we change a 
gray cell are always going to be the same. 
 Changing the right-hand side—the constant term—of a nonbinding 
constraint, such as the number of cars available in Atlanta, doesn’t 
impact the optimal solution. At least, it doesn’t impact the optimal 
solution unless you change the RHS (“right-hand side”) so much 
that you chew through the slack—the cars that we are currently 
leaving unused in Atlanta.
100
Le
ct
ur
e 
12
: S
en
si
tiv
ity
 A
na
ly
si
s—
Tr
us
t t
he
 A
ns
w
er
?
 In the optimal solution, after we ship 250 cars from Atlanta, 50 of 
Atlanta’s 300 cars are left in the train yard—that’s the slack. If you 
lost some or all of those 50, or if you got more cars in Atlanta, you 
really wouldn’t care. You’d just have more or less surplus. If you lost 
more than 50, of course, you’d have eaten through your slack, and 
the supply constraint would be broken. You’d need to change your 
shipping schedule, and it would probably cost you more money.
 Let’s try this same game with a constraint that is originally binding 
in our optimal solution. Let’s look at the bottom one, the demand 
for Great Falls. 
 It wants at least 100 cars, and it’s getting exactly that. No slack. 
Binding. Now, what do you think will happen to optimal cost if 
we change the amount of cars required by Great Falls, either up 
or down? If they need more cars, cost will go up, and if they need 
fewer cars, cost will go down. 
 The following shows a one-car increase in demand for Great 
Falls—101 cars, as shown in the bottom cell of the RHS column—
and the cost did increase by $210. The old cost was $90,800.
A B C D E F G H I J K L M N
1 AC AD BC BD BF CE CF CG DE DF
2 101 150 0 0 200 0 0 101 150 0
3
4 Maximize 72 78 70 277 136 213 214 138 206 156 $91,010
5
6 subject to
7 LHS RHS
8 Atlanta 1 1 0 0 0 0 0 0 0 0 251 300
9 Baltimore 0 0 1 1 1 0 0 0 0 0 200 200
10 Chicago 1 0 1 0 0 0 0 0 = 0
11 Dallas 0 1 0 1 0 0 0 0 0 = 0
12 Eugene 0 0 0 0 0 1 0 0 1 0 150 150
13 Fresno 0 0 0 0 1 0 1 0 0 1 200 200
14 Great Falls 0 0 0 0 0 0 0 1 0 0 101 101
Figure 12.2
101
 The following shows a decrease in the Great Falls demand by 1—
to 99, as shown in the bottom cell of the RHS column. Again, the 
original cost changes by $210, but dropping this time.
 
problem, but it found out that it was best to continue to use all of 
Baltimore’s cars for Fresno, so another car to Great Falls has to go 
from Atlanta to Chicago to Great Falls. Atlanta to Chicago costs 
$72, and Chicago to Great Falls costs $138. That total is $210. 
And it isn’t just one car, of course. Every time we need another car 
in Great Falls, the answer is to ship it from Atlanta to Chicago to 
Great Falls, and pay $210. 
 The key point here is that each time we change the right-hand side 
by 1, we alter our optimal solution according to the same recipe. 
If demand in Great Falls increases by 1 car, we’ll send 1 more car 
from Atlanta to Chicago to Great Falls, and pay $210. If they want 
another, we do it again. This is a linear pattern, but it doesn’t hold 
forever. Eventually, we run out of cars to send from Atlanta. This 
happens when Great Falls demand passes 150.
A B C D E F G H I J K L M N
1 AC AD BC BD BF CE CF CG DE DF
2 99 150 0 0 200 0 0 99 150 0
3
4 Maximize 72 78 70 277 136 213 214 138 206 156 $90,590
5
6 subject to
7 LHS RHS
8 Atlanta 1 1 0 0 0 0 0 0 0 0 249 300
9 Baltimore 0 0 1 1 1 0 0 0 0 0 200 200
10 Chicago 1 0 1 0 0 0 0 0 = 0
11 Dallas 0 1 0 1 0 0 0 0 0 = 0
12 Eugene 0 0 0 0 0 1 0 0 1 0 150 150
13 Fresno 0 0 0 0 1 0 1 0 0 1 200 200
14 Great Falls 0 0 0 0 0 0 0 1 0 0 99 99
Figure 12.3
102
Le
ct
ur
e 
12
: S
en
si
tiv
ity
 A
na
ly
si
s—
Tr
us
t t
he
 A
ns
w
er
?
 What we’ve done with this example isn’t intended to be impressive; 
it’s intended to be instructive. What’s important is that what we’ve 
done here always works. 
 When you change the RHS of a nonbinding constraint, it doesn’t 
affect your objective or your schedule, until you change the RHS 
so far as to make it become binding—you “use it all up.” If you 
change the RHS of a binding constraint, it generally changes both 
the optimal schedule—what you’re supposed to do—and your 
objective value—how well you do—but it does so in a predictable, 
linear way, such as how one more demand in Great Falls means 
one more car from Atlanta to Chicago to Great Falls and a $210 
increase in cost. This linear pattern holds for a while, but it may 
break down at some point.
 So, change the demand at Great Falls from 100 cars to a new value, 
and it’ll change your total cost by $210 for every 1 car you add or 
subtract from that demand. This $210 is called the shadow price 
of the constraint, although it’s also known as the dual price. In 
general, the shadow price of a constraint tells you how much the 
optimal objective value increases (or decreases) each time that you 
increase (or decrease) the right-hand side of the constraint by 1 
unit—at least for a while.
 We can’t play this game forever. If the demand at Great Falls 
gets too high or too low, that $210-per-car cost no longer applies, 
because our “ship a car from Atlanta to Chicago to Great Falls” 
recipe breaks down. 
 However, for a certain range of right-hand-side values, the recipe 
works great, and in that range, you can trust the shadow price. This 
range where everything is behaving is called the right-hand-side 
range of the constraint (RHS range).
 
this example by stating the following: The shadow price of the 
Great Falls constraint is $210 per car, and the RHS range is from 
103
0 to 150 cars. That is, as long as the number of cars Great Falls 
needs stays between 0 and 150 cars, each increase or decrease in 
its demand increases or decreases the total cost by $210. Also, the 
shadow price of the Atlanta constraint is $0 per car, and the RHS 
of cars in Atlanta stays at 250 or above, increasing or decreasing 
Atlanta supply does not change total cost.
binding: A constraint is binding on a solution if it has zero slack in 
that solution. 
dual price: See shadow price. 
nonbinding: A constraint is nonbinding on a solution if it has positive slack 
in that solution. (Negative slack means that the constraint is violated.) 
parameters: The values of the constants relevant to a problem, such as 
the quantity available of a resource. Models are often created so that the 
: The range of values over which the 
constant term in a constraint may vary without changing the shadow price of 
any constraint. 
sensitivity analysis: An investigation of how an optimal solution changes 
as parameters of the problem are varied from some set of original values. 
Sensitivity analysis can be done with most optimization techniques, such as 
linear programming or decision theory. 
shadow price: Also called dual price. The amount that the optimal objective 
function value increases when the right-hand side of a constraint is increased 
by 1. Shadow prices may change when one leaves the right-hand-side range 
of a constraint. 
Important Terms
104
Le
ct
ur
e 
12
: S
en
si
tiv
ity
 A
na
ly
si
s—
Tr
us
t t
he
 A
ns
w
er
?
slack: For any inequality constraint, the slack is the side of the constraint 
claiming to be bigger minus the side claiming to be smaller. Hence, the slack 
in 4x + y z is 4x + y z. The slack in 8x x. A constraint that is 
Ragsdale, Spreadsheet Modeling & Decision Analysis.
Winston and Albright, Practical Management Science.
1. The video lecture referred to the 100% rule for right-hand-side (RHS) 
ranging. It is applied to determine if multiple simultaneous changes in 
the right-hand sides of constraints will leave shadow prices unchanged. 
To apply it, divide each increase made in an RHS by the allowable 
increase to that RHS. Divide each decrease made to an RHS by the 
allowable decrease to that RHS. Add the results. If the total is 1 or less, 
then shadow prices are unchanged. If the total is more than 1, then the 
100% rule fails, and shadow prices may change or may stay the same.
Example: 
In the video lecture, we looked at increasing month 1 pants demand 
by 100 and decreasing month 3 pants demand by 100. The allowable 
increase for month 1 pants demand was 572, and the allowable decrease 
in month 3 pants demand was 300. The 100% rule would then have us 
prices remain unchanged by the combined RHS changes.
Suggested Reading
Questions and Comments
105
2. The shadow price of a nonbinding constraint is always zero. Provide 
an argument why this should be so in the case of a nonbinding limited 
resource constraint.
Answer: 
If a limited resource constraint is nonbinding, then the quantity of the 
resource used in the optimal solution is less than what is available—that 
is, there is some leftover. Then, adding more of that resource cannot 
improve the optimal solution. If more of the resource made the objective 
value better, the current optimal solution would not be leaving leftovers 
of the resource to begin with. On the other hand, the current solution 
leaves some leftover in the constraint. If the quantity available of the 
resource is reduced by only a fraction of this leftover, then the old 
optimal solution is still a feasible solution, so the change in RHS did not 
make the optimal solution any worse. So, a small enough change leaves 
the optimal value of the objective unchanged. Therefore, the constraint 
has a zero shadow price.
106
Le
ct
ur
e 
13
: I
nt
eg
er
 P
ro
gr
am
m
in
g—
A
ll 
or
 N
ot
hi
ng
Integer Programming—All or Nothing
Lecture 13
Up until this point in the course, we’ve mostly been assuming that variables could take on any value, subject to the constraints. But in linear programming, add the harmless-sounding additional 
requirement that your answer needs to involve only integers, and you can 
life problems, we often have no use for fractional answers. No one will buy 
three-fourths of a car for three-fourths of the sticker price, for example. 
Programs where variables have to be integers are called integer programs 
and are the subject of this lecture. 
Linear Programs with Integer Variables
 The following is a linear program with the objective of maximizing 
8x y, solved graphically. 
 The arrow on the dotted objective function line (OFL) tells us that 
the further one moves in the direction of the arrow, the larger the 
objective function value 
is growing. If you’re 
maximizing 8x y, large 
x’s are good and large y’s 
are bad.
 In the image, the optimal 
point is marked with a star. 
What makes it optimal? 
With graphical solutions, 
we imagine the feasible 
Figure 13.1
107
 As we let in more and more water, the OFL creeps to the lower 
right, keeping the same slope as it covers more and more of the 
feasible region. The last point above water is the optimal point, and 
that’s right at the star. The simplex method would get there by a 
different technique, walking along the edges of the feasible region 
and always going uphill, but the result is the same. We’ve solved 
this linear program.
 But what if it’s an integer program? For example, maybe x is 
the number of bulldozers we sell and y is the number of fueling 
stations. Such things have to be integer quantities. And you can 
probably see from the graph that the optimal solution is a little 
to the right of x = 3 and a little below y = 2. In other words, its 
coordinates aren’t integers.
 To be an acceptable answer 
to this integer linear 
program, both coordinates 
have to be whole numbers. 
We can show this on the 
graph as follows.
 The crosses in the graph 
form a lattice—a regular 
array of points. And these 
lattice points are the only 
points that are permissible 
answers to this integer programming problem. They’re the only 
points where both coordinates are integers. And you can see clearly 
that the optimal solution to our linear program isn’t on a lattice 
point. So, what do we do?
 A natural guess is to pick the lattice point nearest the linear 
program’s optimal solution. This essentially corresponds to 
rounding each decision variable in the program to the nearest whole 
Figure 13.2
108
Le
ct
ur
e 
13
: I
nt
eg
er
 P
ro
gr
am
m
in
g—
A
ll 
or
 N
ot
hi
ng
number. In this case, that’s x = 3 and y = 2. But the problem with 
this approach is that the point is outside of the feasible region, so 
we don’t get a feasible solution. 
 
optimal point that’s inside the feasible region? Mathematically, 
when the number of variables gets high—but we can deal with that. 
 The real problem is that this doesn’t necessarily give the best 
answer. The nearest integer solution that’s feasible in our problem 
is at x = 2, y = 2, almost directly to the left of the linear program’s 
optimal point. The objective in this problem is to maximize 
8x y. That means that the point (2, 2) gives an objective value 
x = 2, y = 0, which is 
much farther away from the linear program’s optimal point, does 
optimal point. The optimum integer point is marked with a star on 
the graph. (See Figure 13.2.)
 In this particular problem, there really aren’t that many feasible 
lattice points to check—there are only seven crosses in the shaded 
region. But in a more complicated problem, this number can 
quickly explode. 
 So, integers can cause us problems, even when the underlying 
program is linear. What do we do about it? We have a few options. 
Suppose that we try to solve an integer programming problem by 
ignoring the fact that the variables have to be integer. This linear 
program is called the linear programming (LP) relaxation of the 
linear integer program. 
 Linear programs can generally be solved very quickly, so maybe 
we’ll get lucky. Maybe the solution to the LP relaxation will 
have all integer values. In some cases, it’s not as unlikely as you 
109
might think. There are families of problems, such as one-product 
transportation problems, where you can be sure that you’ll always 
get integer optimal solutions. 
 However, most linear programs have nonintegral optimal solutions. 
So, when you aren’t lucky, what’s next? One possibility is to fake 
it—meaning adjusting the answer given by the LP relaxation by 
a little bit. We could poke around the feasible lattice points in the 
vicinity of the LP optimum and choose the one that’s best. The 
problem with this idea is that the integer optimum might not be in 
that neighborhood. In fact, it might be quite far away. 
 In some practical cases, though, you might not care. For example, 
suppose that you solve the LP relaxation and it says that the 
minimum cost is $900,000, and then by rounding some of the 
numbers in this solution, you get a feasible integer solution that 
costs $903,000. You’re within $3000, or about 0.3%, of the LP 
optimum. Maybe that’s good enough for you.
 
answer. How are integer problems solved? A common technique is 
called branch and bound, 
and we can get an idea of 
how it works by using our 
graphical example. 
Branch and Bound
 Start with the LP relaxation 
of the problem. Solving our 
the optimal point is at about 
x = 3.14, y = 1.71, and the 
optimal objective value is 20. 
 If we’re going to have an 
integer solution, x can’t be 3.14. It’s either going to be 3 or less, 
or it’s going to be 4 or more. So, we take our one original integer 
Figure 13.3
110
Le
ct
ur
e 
13
: I
nt
eg
er
 P
ro
gr
am
m
in
g—
A
ll 
or
 N
ot
hi
ng
program and replace it 
with two: one with a new 
requirement that x has 
to be 3 or less, and one 
with a new requirement 
that x has to be 4 or more. 
Graphically, it looks like 
the graph in Figure 13.4.
 We’re breaking the picture 
up into two regions: 
the striped one where 
x
one where x
Whichever of these two different programs gives the better integer 
answer will provide the best integer answer to the original problem. 
 But how do we solve these two branches? The dark gray region 
doesn’t have any feasible points in it, so we can get rid of it and 
focus on the striped 
region. We got lucky—
if not, we’d have to 
continue our work with 
both regions.
 In the striped region, 
x
constraint to the picture 
and solve the new LP 
relaxation. You can see 
in Figure 13.5 that this 
constraint cuts off the 
right tip of the feasible 
region, which makes the old LP optimal solution slide down and to 
the left. This new solution is x = 3, y = 1.5. Obviously, this is not an 
integer solution.
Figure 13.4
Figure 13.5
111
 So, now what? Well, y can’t be 1.5 in an integer solution. It either 
has to be 1 or less, or it has to be 2 or more. So, again, we create 
two regions, as shown in 
Figure 13.6. 
 Imposing the linear 
program’s constraints on 
these two big regions gives 
us two regions to search for 
the best answer. We get a 
striped triangle where y  
and a dark gray trapezoid 
where y
 These are two new 
problems. And when we 
solve these LP relaxations, 
at x = 2.75, y = 2, giving 
an objective of 16. The 
lower star is at x = 2.666, 
y = 1, giving 18.333 for the 
objective. 
 Neither of these is an integer 
solution. But they both have 
x between 2 and 3. So, for 
each one, either x is less 
than or equal to 2, or x is 
greater than or equal to 3. We divide each of these problems in two, 
playing the same kind of game we’ve already played twice.
 And we lucked out again. We can see from Figure 13.8 that x can 
no longer be 3 or more, so we know that x is 2 or less. That adds this 
one more constraint, x
regions of each of the two ongoing problems.
Figure 13.6
Figure 13.7
112
Le
ct
ur
e 
13
: I
nt
eg
er
 P
ro
gr
am
m
in
g—
A
ll 
or
 N
ot
hi
ng
 For the striped problem, the new best answer is at x = 2, y = 2—an 
integer solution. The objective is 8(2) – 3(2) = 10. For the dark gray 
program, the new optimal solution is at x = 2, y = 0—again, an 
integer solution. Its objective is 8(2) – 3(0) = 16, which is better 
than 10. So, the bottom star 
at (2, 0) marks the optimal 
integer solution to the 
original problem. 
 The “bound” part of 
“branch and bound” is a 
winnowing technique. It 
just says that if we found 
one integer solution, we 
don’t need to consider 
derived problems whose 
best answers have no 
chance of doing better than 
that one. It’s kind of like saying that if you’re looking for the oldest 
person in town and you’ve found a 90-year-old, you can skip the 
local school where you know that everyone is 65 or younger.
Integer Programs versus Linear Programs
 The previous example was an easy and short example of branch 
and bound. This procedure typically involves an absurd amount of 
work. And that’s what makes integer programs in general so much 
some real-life integer problems require so much ingenuity to solve. 
 In spite of this, for problems of a reasonable scope, you’re going 
to be perfectly capable of handling integer and mixed-integer 
programs in either Calc or Excel. Given the amazing amount of 
work required to solve an integer program as compared to a linear 
one, it’s almost embarrassing how little is required from you to turn 
a linear program into an integer program in Excel. 
Figure 13.8
113
branch and bound
linear programs by repeatedly replacing a linear integer program with two 
variants, each of which differs from the original by the inclusion of one 
additional constraint. 
integer program: A program in which all of the decision variables are 
required to be integers—that is, positive or negative whole numbers or zero. 
If only some of the variables have this requirement, the program is termed 
“mixed integer.” 
LP relaxation : The linear program that results 
from suspending the integer requirements of an integer linear program. 
Cornuejols, Trick, and Saltzman, “A Tutorial on Integer Programming.” 
Winston and Albright, Practical Management Science.
1. In the video lecture, we said that if ANNEX
build the annex” and CONTRACTOR
a contractor,” then the requirement “If we build the annex, we hire a 
contractor” is represented by the constraint ANNEX CONTRACTOR. 
Verify this. 
[Hint: Recall that a variable is 1 if and only if the corresponding 
statement is true and 0 otherwise. Under what circumstances is ANNEX
CONTRACTOR false, when ANNEX and CONTRACTOR are either 0 
or 1? Under what conditions is the statement, “If we build the annex, we 
hire a contractor” false?]
Important Terms
Suggested Reading
Questions and Comments
114
Le
ct
ur
e 
13
: I
nt
eg
er
 P
ro
gr
am
m
in
g—
A
ll 
or
 N
ot
hi
ng
Answer: 
Consider the following statement. I promise, “If I like you, I will shake 
your hand.” How could I be found a liar? If I don’t like you, I’m not a 
liar no matter what I do. The statement is only a promise of what I’ll do 
if I do like you. If I like you and shake your hand, I am clearly not a liar. 
But if I like you and yet fail to shake your hand, then I am lying. 
This is true of if-then statements in general. Such a statement is false 
if and only if the premise (“if” part) is true and the conclusion (“then” 
part) is false. 
Now look at the relation A B, where both A and B are either 0 or 1. 
When can it be false? Clearly, only if A = 1 and B
false. So, “If A, then B” is false only if A is true and B is false, and A B 
is false only if A is 1 and B is 0. The correspondence between the logic 
of if-then and the arithmetic of A B is perfect.
2. Suppose that PROJ1 is a binary variable that is 1 if project 1 is being 
PROJ2 and 
PROJ3 similarly, for project 2 and project 3. Let OPEN
that is 1 if the plant is open this weekend and 0 otherwise.
Verify that the constraint PROJ1 + PROJ2 + PROJ3 OPEN exactly 
enforces the requirement that if any of the projects are being worked on 
this weekend, then the plant must be open this weekend.
Answer: 
Just look at the possible cases. If OPEN = 0, then the right-hand side 
is 0, so the constraint says PROJ1 + PROJ2 + PROJ3
each of the PROJ variables is 0 or 1, this works only if they are all 
0. Hence, if OPEN = 0, then all of the PROJ variables are 0, too. 
On the other hand, if OPEN = 1, then the constraint says PROJ1 + 
PROJ2 + PROJ3
variables obviously can’t add to more than 3.
115
Conclusion: If the plant is closed, then no project can be worked on. Or, 
equivalently, if a project is worked on, the plant must be open.
You can also reason more directly. If any of the PROJ variables equals 
1, then the left-hand side adds to more than 0. This means that 3OPEN 
must be more than 0, which means that OPEN must be 1. On the other 
hand, if OPEN = 1, it puts no restriction on any of the PROJ variables. 
We reach the same conclusion.
116
Lecture 14
Mhow can we demonstrate into outputs. A technique called data envelopment analysis (DEA) 
mathematically boils down to a linear program, and that means that we have 
all of the tools available that we have for such programs. This includes being 
able to solve them, of course, but it also means that we have sensitivity 
analysis. As you will learn in this lecture, DEA allows us to consider and 
Data Envelopment Analysis
 Data envelopment analysis
and linear programming. To learn about DEA, we’ll start by 
comparing just two producers. In standard DEA terminology, 
these would be referred to as , but 
“producers” is a more familiar term and captures the essence. 
 
one focusing on inputs and one focusing on outputs. The output 
perspective would say that you are more  than another 
person if you can make more of every output than the other person 
does without using more of any input than the other person does. 
another person if you can use less of every input than the other 
person does and still make at least as much of every output as the 
other person does. 
 
using less of everything to make at least as much of everything. If 
you can squeak by and make what another person makes using only 
when compared to you is only 60%. 
117
 That’s a decent start, but it leaves a lot of ground to be covered. You 
might use less of everything than the other person, but you might 
make less of some things, too. In addition, there are more producers 
in the world than just you and that other person. How does that 
change things? Let’s start by dealing with a special case—the one 
in which all of the producers have the same supply of inputs. 
 Let’s say that we have 9 teams of workers in a factory and that each 
team is doing essentially the same job: making units of the product 
and shipping them out. Each team has the same inputs. Those inputs 
might include many things—such as raw materials, and so on—but 
to keep it simple, we’re going to focus only on personnel. Each 
team has 54 people: 30 trained workers, 20 untrained workers, and 
4 supervisors. We’ll also assume that they all face the same demand.
 What about outputs? Suppose that we decide that there are two 
outputs that matter for a team: productivity and rush responsiveness. 
Productivity is the average number of units that the team produces 
per week. Rush responsiveness is the average number of rush 
orders that are delivered on time per week. For each team, we 
collect data on these two outputs. Because there are only two 
outputs, we can show them on a scatterplot, where the horizontal 
position shows the productivity of the team and the vertical axis 
shows its responsiveness. 
Figure 14.1
118
 
production—1000 units per week—but terrible responsiveness, 
with only about 30 rush-order deliveries being on time. On the 
other hand, both teams 2 and 5, toward the top, do great on 
responsiveness—they lead the pack at 125 rush-order deliveries on 
time—but they’re not so great on quantity produced. 
 If we are prepared to assign relative importance to responsiveness 
and production, then we might be happy ranking one of these teams 
above the others. But without that kind of a priori decision, both 
beat them in one output without being beaten by them in the other. 
 
it’s also called Pareto optimality. Roughly, a solution is Pareto 
optimal if there’s no way to make one thing better than it already is 
without making something else that you care about worse.
 Let’s take this idea a bit further. Look at team 9. Should we consider 
or more units than team 9—namely, teams 1, 4, and 8—and none of 
them has as high a responsiveness score.
 However, we can look at this another way. Suppose that we 
blended teams 1 and 2 to make a hybrid team. Imagine that we cut 
each of them in half to make mini-teams, using only half as much 
of each input and generating only half as much of each output. 
Put these two demi-teams together, and we’re still consuming one 
team’s worth of inputs—30 trained workers, 20 untrained workers, 
and 4 supervisors.
 But what about outputs? This half-and-half hybrid will make 
810 units. 
 
0.5(900) + 0.5(720) = 450 + 360 = 810.
119
 Similarly, the hybrid has a responsiveness of 100.
 
0.5(75) + 0.5(125) = 100.
 This imaginary hybrid team uses the same resources as team 9, but 
it makes 810 units per week, not 800, and delivers 100 rush orders 
on time, not 80. So, the hybrid uses the same resources as team 
9 but outperforms it in both productivity and responsiveness. The 
of teams 1 and 2. 
 There’s nothing that says that our hybrid team has to consist 
of a 50%-50% blend of teams 1 and 2. The hybrid that is really 
spectacular is made of about 66% of team 1 and 28% of team 
2, because this hybrid outputs exactly what team 9 does, but it 
only uses about 95% of each of the input resources. So, team 9’s 
 For a problem like this one—identical inputs and only two 
outputs—there’s an even easier, geometric way to think about what 
we’re doing. Taking a weighted average of two teams and having 
the weights add to 1 corresponds graphically to identifying all of 
the points on the line segment that joins those two teams on the 
graph. Combining more than two teams allows you to reach any 
point inside the region of which those teams are the corners. 
 What we’re really looking for in a DEA problem is the frontier. 
What is the best that you can do by creating virtual producers 
that are weighted averages of the real producers? In our factory 
teams example, the frontier would look like Figure 14.2 on the 
following page. 
 Both axes are outputs, and more is better. So, higher is better, and 
farther to the right is better. The points on a straight line connecting 
two points are all hybrid, virtual producers made by blending the 
real-life producers that are the line’s two endpoints. 
120
 
If you are not on the frontier, we draw a line from the origin, 
through your point, and onto the frontier curve. Compare the length 
of the line from the origin to the producer with the length of the line 
from the origin to the frontier. For team 9, for example, this would 
look like the following.
Figure 14.3
Figure 14.2
121
 Team 9 is 95% of the way from the origin to the production 
computed. But when you look at it, there’s something a little wrong 
5 to team 2. Both use the same resources—all of the teams do. Both 
have 125 rush-order deliveries on time. But team 2 makes 200 more 
units per shift.
 It’s because of this that team 5 has what is called . 
It’s not Pareto optimal, because team 2 shows that you can do better 
on one output without doing worse on the other. On the other hand, 
you can’t do what team 5 does with less of each input, and that’s 
Comparing Teams with Different Inputs
 
depending on their distance from the frontier. However, so far 
we’ve been assuming that everyone has the same inputs—and, of 
course, that’s often not the case. How can we compare them, then? 
We can use essentially the same idea on a slightly larger scale. 
 
producer—the target producer. We do this by comparing it to 
a virtual producer, a hybrid blend of the real producers. In the 
previous example, we created a hybrid of just two teams, but you 
can use as many as you want. In order for this hybrid to have 
meet two conditions.
 Condition 1: The hybrid has to equal or exceed the performance 
of the target producer on every output.
 Condition 2: The hybrid has to use up no more of each input 
than the target producer does.
122
 Suppose that a hybrid meets these conditions. In fact, suppose that 
for any input, the consumption of the hybrid is never greater than 
x% of the consumption of that input by the target producer. Then, 
we can conclude that the target producer is at most x
 The best hybrid for the comparison is the one that meets our two 
conditions and uses as little of the inputs as possible. That is, we 
want the hybrid that meets the conditions and makes x%, the input 
fraction, as small as possible. 
 In other words, to make a hybrid, we decide how much of each real-
world producer goes into it. These are called the weights for each of 
the real-world producers. The weights can’t be negative, but other 
than that, we can pick them as we like.
 Of course, this hybrid isn’t relevant to our assessment of the target 
minimizes the input fraction for this hybrid. 
 This is an optimization problem. And because a hybrid is a linear 
combination of the real-world producers, it’s a linear program. Let’s 
see what it looks like for the example of our worker teams, when 
of the other teams. 
Team # 1 2 3 4 5 6 7 8 9
Untrained 20 20 20 20 20 20 20 20 20
Trained 30 30 30 30 30 30 30 30 30
Supervisor 4 4 4 4 4 4 4 4 4
Quantity 900 720 300 830 500 600 720 1000 800
Rush on time 75 125 110 60 125 100 100 30 85
Figure 14.4
123
 We start with a table listing the amount of each input that a real-
world team uses (shown in dark gray), as well as the amount of 
each output that it produces from those inputs (shown in light gray). 
To specify a hybrid, we have to give the weights for each of these 
real-world producers. 
 The numbers shown within borders of dotted lines are decision 
variables. We get to pick them. We’re looking at a mix that is 90% 
of a team 2 combined with 5% of a team 5. But it’s going to be the 
 
of each resource does it use, and how much of each output does it 
make? We saw how to do this when we were creating the 50%-50% 
blend of teams 1 and 2. The gray-boxed numbers in a given row are 
multiplied by the corresponding weights in the boxes with dotted 
lines, and then results are added to give the total for that row. That’s 
just the SUMPRODUCT operation that we used for our linear 
programming formulations. 
 We record this in a new column in the sheet, to the right of our 
earlier table. We can see, for example, that this hybrid uses only 19 
untrained workers, and it produces 673 units per shift. 
Team # 1 2 3 4 5 6 7 8 9
Weights 0 0.9 0 0 0.05 0 0 0 0
Figure 14.5
Team # 1 2 3 4 5 6 7 8 9
Weights 0 0.9 0 0 0.05 0 0 0 0
Hybrid input used/
output madeTeam # 1 2 3 4 5 6 7 8 9
Untrained 20 20 20 20 20 20 20 20 20 19.000
Trained 30 30 30 30 30 30 30 30 30 28.500
Supervisor 4 4 4 4 4 4 4 4 4 3.800
Quantity 900 720 300 830 500 600 720 1000 800 673
Rush on time 75 125 110 60 125 100 100 30 85 118.75
Figure 14.6
124
 How does this hybrid do? Look at the last column. The top three 
entries show that it uses less of each input than team 6, our target 
team. The last two entries show that it does better than team 6 on 
both productivity and responsiveness. We’ve just shown that team 
 Now let’s push our hybrid a little more, by cutting down its inputs 
to, for example, only 97% of the inputs of team 6. Could our hybrid 
still function? What would it have available for inputs? The three 
inputs for team 6 are 20, 30, and 4, and we multiply each of these 
by 97% to get 19.4, 29.1, and 3.88. 
 We see that our hybrid function can certainly function with these 
smaller fraction of the inputs—95% is good enough for this hybrid.
 
fraction of team 6’s inputs and still meets our performance 
conditions on inputs and outputs. And because we now have all of 
the pieces in place to do this, we just stick all of our pieces together, 
as shown in Figure 14.8.
Hybrid input used Inputs allowed Target (team 6) values Input fraction
19.000 19.400 (= 20 × 0.97
28.500 29.100 (= 30 × 0.97
3.800 3.880 (= 4 × 0.97
Figure 14.7
Team # 1 2 3 4 5 6 7 8 9
Weights 0 0.9 0 0 0.05 0 0 0 0 Minimize 0.970
Hybrid input 
used/ 
output made
Inputs allowed/ 
outputs 
required
Target  
(team 6) 
values
Input 
fraction
Team # 1 2 3 4 5 6 7 8 9
Untrained 20 20 20 20 20 20 20 20 20 19.000 19.400 (= 20 × 0.97
Trained 30 30 30 30 30 30 30 30 30 28.500 29.100 (= 30 × 0.97
Supervisor 4 4 4 4 4 4 4 4 4 3.800 3.880 (= 4 × 0.97
Quantity 900 720 300 830 500 600 720 1000 800 673 600 = 600
Rush on time 75 125 110 60 125 100 100 30 85 118.75 100 = 100
Figure 14.8
125
 The “hybrid” column shows what our hybrid uses and produces. 
conditions that our hybrid must satisfy—use at most x% of the 
inputs of the target team and still equal or exceed that team’s 
performance. Our goal is to minimize that input fraction, and we’re 
that is the linear 
program. When we let Solver solve it, it gives the following.
 This shows that a hybrid that is about 5% team 1 and 77% team 
2 can make everything that team 6 makes and can do it with only 
 To evaluate a different team, just replace the team 6 gray cells on 
the right side of the sheet by the values for the team being evaluated. 
d : A technique for evaluating the relative 
See . 
: The usual term given to a producer in data 
envelopment analysis. 
producer could create the same outputs as the producer under scrutiny while 
. 
Team # 1 2 3 4 5 6 7 8 9
Weights 0.051 0.769 0 0 0 0 0 0 0 Minimize 0.821
Hybrid input 
used/ 
output made
Inputs allowed/ 
outputs 
required
Target  
(team 6) 
values
Input 
fraction
Team # 1 2 3 4 5 6 7 8 9
Untrained 20 20 20 20 20 20 20 20 20 16.410 16.410 (= 20 × 0.821
Trained 30 30 30 30 30 30 30 30 30 24.615 24.615 (= 30 × 0.821
Supervisor 4 4 4 4 4 4 4 4 4 3.282 3.282 (= 4 × 0.821
Quantity 900 720 300 830 500 600 720 1000 800 600 600 = 600
Rush on time 75 125 110 60 125 100 100 30 85 100 100 = 100
Figure 14.9
Important Terms
126
Pareto optimal: A solution is Pareto optimal if one cannot do better at 
accomplishing one goal without doing worse on at least one other goal. 
virtual producer: In data envelopment analysis, a hypothetical producer 
created by taking a linear combination of actual producers. 
: In data envelopment analysis, a producer is weakly 
while using no more of any input and using less of at least one input. 
Cook and Zhu, Data Envelopment Analysis.
Winston and Albright, Practical Management Science.
1. Suppose that you could assign a monetary value to each unit of input 
consumed and each unit of output created. Then, DEA would not be the 
proceed instead?
Answer: 
Simply divide the total value of the outputs by the total value of the 
inputs. The highest ratio corresponds to the investment with the 
best return.
2. There are alternative ways to formulate DEA. One is based on shadow 
prices. In this approach, the producer currently under review gets to 
set a table of prices per unit for the inputs and outputs. There are only 
two rules for the table. First, nothing may be given a negative price. 
Second, with this price table, no producer can have its total outputs 
worth more than its total inputs. If a producer can create such a table 
for which its own outputs are worth as much as its own inputs, then it 
Suggested Reading
Questions and Comments
127
of inputs (according to this price table) into $80 of outputs, it would 
equivalent to the one in the lecture.
128
Le
ct
ur
e 
15
: P
ro
gr
am
s 
w
ith
 M
ul
tip
le
 G
oa
ls
Programs with Multiple Goals
Lecture 15
Because linear programs have only one objective, our approach when faced with more than one so far has been to choose the one we really care about and focus on that. However, very frequently, 
ignoring the other objectives just isn’t a satisfactory solution. In this lecture, 
you will learn one of many approaches to solving multi-objective problems 
that involves combining multiple objectives into one with the use of soft 
constraints and penalties. 
A Multi-Objective Problem
 Each year, the National Broadcasting Company (NBC) sees about 
$4 billion in revenues. From a revenue-generating point of view, 
the company is in the business of delivering viewers to advertisers. 
You could say that NBC has only one goal: maximizing revenue 
commercials are the most important programming, in both senses, 
for a commercial broadcaster’s bottom line. 
 
NBC wants repeat business. So, it also has the goal of giving an 
advertiser as much as it can of what the advertiser would prefer. 
And the advertisers have many preferences for many different 
factors, including season, day of the week, and program placement. 
In addition, they don’t want ads for their competitors appearing 
next to their own. And what the network offers to the advertisers 
has to work for them as a package.
 For NBC planning, there was more. Not all contracts close at the 
same time. Last-minute changes—new clients or clients dropping 
out—are part of the business. Of course, NBC wanted to make as 
129
much money as possible and to satisfy the current advertisers as 
much as possible, but it also wanted to minimize the number of 
prime commercial slots that it had to use on any given advertiser. It 
was trying to do this with each of its clients, and it was trying to do 
so in a timely fashion. 
 And if this wasn’t enough, NBC also wanted to encourage and 
reward big spenders, loyal customers, and clients who would take 
some slots in the less-popular programs with deals. 
 In May, NBC would tell potential advertisers what slots it would 
have available in the fall. Advertisers would respond on an 
NBC form saying what they wanted in terms of number of ads, 
days, seasons, shows, budget, and so on. Then, an NBC planner, 
working by hand and trying to keep all of the goals in mind, would 
work up a proposed schedule. The process usually took three to 
four hours. 
 Unfortunately, the proposed schedule was often unacceptable to the 
advertiser. So, that required reworking the schedule, often multiple 
times. And this had to be done with every advertiser. During the 
crunch period during which most of the ads for the year were 
booked, planners were usually working 12- to 16-hour days. There 
and a massive headache for everyone.
 How do you handle a situation like this, with multiple goals? The 
could create a single objective function to capture their desires if 
they were capable of stating their indifference point in the trade-off 
between the two. 
130
Le
ct
ur
e 
15
: P
ro
gr
am
s 
w
ith
 M
ul
tip
le
 G
oa
ls
 For example, suppose that they decided they’d be indifferent 
between gaining 1% of market share and gaining $100,000 in 
could create an objective like the following.
Maximize PROFIT + 100,000SHARE
 It’s left unchanged if market share moves 1% in one direction and 
over a wide range of changes, this objective captures their feelings 
about the relative importance of these two goals, and we can use it 
to evaluate the combination of both. And there’s nothing to limit us 
to two variables when using this approach. 
 But before this approach could even be considered for the NBC 
“maximizing advertiser satisfaction,” but doing that really means 
forms. If you can’t nail their request exactly, you want to at least get 
close. The further you are from what they asked for, the less happy 
they’re likely to be. 
 You’re not going to be able to exactly satisfy everyone’s requests. 
For starters, many of the variables in this problem are integers, such 
as how many ads a company runs. NBC found that if you got it 
 While this isn’t a new idea for us, it is something quite new for us 
in terms of our programming work. We’ve been assuming so far 
in this course that a constraint is a rule you have to obey. These 
have-to-obey constraints can be referred to as hard constraints. For 
example, for NBC, the number of commercial slots it has available 
is a hard constraint. 
131
 The money the advertiser is willing to spend is another constraint, 
although usually advertisers give a range with a hard upper limit. 
This is the idea of a soft constraint. The advertisers tell NBC what 
they want, but if they don’t get it, they at least want NBC to get 
close. The further NBC is from the target, the bigger the problem it 
is. The size of the deviation is usually measured by a penalty, and 
this idea is extremely useful in handling either multiple goals or 
soft constraints. 
 Suppose that we have a constraint that says NBC has to give the 
advertiser 30 commercial slots during a particular week. We have 
an integer variable specifying how many slots this advertiser 
is given on each show during the week. If we add all of those 
variables together, we want the total to be 30. Let’s call the number 
of commercials we assign to this client TOT1, for total in week 1. 
Then, we want the constraint to say the following.
TOT1 = 30
 As written, that’s a hard constraint. NBC has to give them 30 ads. 
But suppose that NBC gives them too few—it was under the target. 
How much under would it be? Take how many they wanted—30—
and subtract how many NBC gave them—TOT1. That would be 
the amount NBC was under the desired number of commercials in 
week 1.
TOT1 = UNDER1, or TOT1 + UNDER1 = 30
 On the other hand, NBC might give them too many commercials 
this week, perhaps to make up for the fact that NBC squeezed them 
out of some other week. Then, NBC would be over the desired 
number NBC gave the advertisers, TOT1, and subtract how many 
commercials the advertisers wanted, 30.
TOT1 OVER1, or TOT1 OVER1 = 30
132
Le
ct
ur
e 
15
: P
ro
gr
am
s 
w
ith
 M
ul
tip
le
 G
oa
ls
 
over, under, or just right. But we can combine these two formulas in 
a rather clever way that covers all of the bases, as follows.
TOT1 + UNDER1 1 = 30
 
blush, it looks like it won’t work. After all, the math allows, for 
example, that TOT1 = 30 and UNDER1 and OVER1 both equal 5. 
but it doesn’t make sense to say that we’re both under and over 5, 
when in fact we’re just right.
 But remember that being under or over is going to be a bad thing. 
We’re going to penalize it. So, the program is not going to make 
either of these numbers, UNDER1 or OVER1, any bigger than it 
has to. It can always make one of them zero, and the other one 
will then be the correct value of how much under or over the 
target we actually are. And this is a linear relationship, so it works 
wonderfully in a linear program. 
 When we want a soft constraint in a linear or integer programming 
problem, we’re going to see these “under” and “over” terms in 
them. It always goes value + under  over = target. Sometimes, 
there’s a penalty associated with deviations in either direction—
values that are too high or too low—and that’s the case with 
the advertisers. Sometimes, only one direction of deviation is 
penalized. For example, you may be unhappy if my car’s trunk 
capacity is less than two suitcases, but I certainly don’t mind it can 
hold more.
 And this is the approach that NBC took on their scheduling 
problem. Each commercial slot had a rating of how popular that 
slot would be to prospective advertisers. NBC’s goal was to satisfy 
the current advertiser’s needs using the least-highly-rated mix that 
would do the job. To this ratings total, NBC added penalties for 
133
missing targets on shows in a given week, shows in a given quarter, 
the budget for a given quarter, demographic targets, and so on. 
More serious violations had larger penalties.
Solving a Multi-Objective Problem
 NBC is running this optimization program for one advertiser at 
a time, coming up with a proposed schedule for them, getting it 
approved, and moving on. But think about how many integer 
variables are in this program—roughly one for each commercial 
length and each show aired during the year. Even if the advertiser 
each day, that’s still over 7000 integer variables. This problem 
would take a long time to solve, then, especially if it’s being solved 
on small computers.
 But from what we know about integer variables, we have some 
ideas of how to get around this. Start with the LP relaxation of the 
program—that is, ignore the integer constraints. You can solve that 
quickly. And that’s how the NBC operations research team began. 
 Unless you’re very lucky, your LP solution isn’t going to be your 
proceeded by rounding all of these values down. But before doing 
so, they sorted all of the variable values on the basis of how big 
their fractional part was, in order of decreasing fractional parts. 
Then, they improved this solution by working down the list in 
order and rounding up the value of each variable—unless doing that 
broke a program constraint. If it did, they skipped it and moved on. 
 Finally, they tweaked this schedule by adding a single commercial 
to it or deleting a single commercial from it to see if the result 
was improved. If it was, they took this as the new schedule and 
then tweaked this new solution in the same way; if not, they tried 
tries, they stopped. 
134
Le
ct
ur
e 
15
: P
ro
gr
am
s 
w
ith
 M
ul
tip
le
 G
oa
ls
 This search procedure is a simple example of what’s called a tabu 
search. You look at points in a particular area of the solution space, 
make small changes to them, and keep a list of the solutions you’ve 
recently tried. Those solutions are “taboo,” so the procedure does 
not return to them. 
 
unless you did a very long tabu search, but that’s okay. NBC was 
happy with a near-optimal solution. Their program generally ran in 
about 2 minutes, and some test runs suggested that the solutions 
were within a few percent of the optimal solution. It took about 10 
minutes to put the data into the computer and then a little bit of 
time to look at the computer output and make any changes that the 
human scheduler felt were appropriate. The whole procedure took 
about 20 minutes per advertiser. 
 
would spend per advertiser in creating the schedule by hand. And 
many of those handmade schedules had to be reworked because 
they didn’t meet the advertiser’s requirements or management’s 
single try by hand.
 The operations research team went further. They created a 
system to estimate the demand for each show for the upcoming 
season, based on buying patterns from previous years. This 
allowed NBC to better set its original price list in May. The team 
also implemented a system so that one advertiser with different 
commercials would have two airings of the same commercial 
separated by as much air time as possible. All of these projects 
together are estimated to have increased NBC’s revenues by at 
least $50 million per year. 
135
soft constraint
if it is not, a penalty is assessed, with a larger penalty applied to a larger 
violation of the constraint. 
tabu search: Also called taboo search. A search procedure of a part of the 
feasible region in which a list is kept of recently examined solutions. The 
procedure avoids returning to solutions already found unsatisfactory. 
Bollapragada, Cheng, Phillips, Garbiras, Scholes, Gibbs, and Humphreville, 
“NBC’s Optimization Systems Increase Revenues and Productivity.” 
Ragsdale, Spreadsheet Modeling & Decision Analysis.
1. In the medical center problem in the video lecture, we computed driving 
distances from home to center along a rectangular grid. Given the 
geometry of the roads in the city, this makes logical sense. But if we 
Answer: 
Distances would no longer be linear functions of the location of 
the center.
2. Suppose that you have the two goals of spending a lot of time with 
your family and making a lot of money at your job. Of the approaches 
discussed in this lecture, which would you favor in determining an 
optimal allocation of your time? 
Important Terms
Suggested Reading
Questions and Comments
136
Le
ct
ur
e 
15
: P
ro
gr
am
s 
w
ith
 M
ul
tip
le
 G
oa
ls
Answer: 
Almost certainly the last approach, which allows you to explore 
trade-offs.
137
Optimization in a Nonlinear Landscape
Lecture 16
In this lecture, you are going to leave linear programming behind and start exploring a landscape that is much more wild and wooly—nonlinear programming. As you will learn, when you get rid of the requirement 
that everything is linear, a lot of things change. This lecture will give you an 
idea of how nonlinear techniques work, why we use multiple techniques, and 
what to watch out for as you move from a linear to a nonlinear world. 
Linear versus Nonlinear Programming
 The landscape of a linear program is like a tilted pane of glass. The 
constraints run in straight lines on the surface of that glass, and you 
don’t need to be able to see to the horizon to be able to reach the 
lowest point—you only need to see the ground beneath your feet. 
When you do, walk straight downhill. When you hit a fence, follow 
it, again going downhill. When you reach a corner, if the new fence 
keeps going downhill, follow it. When you can’t go downhill any 
more, stop. You’ve reached a lowest point. 
 How do these instructions change for a nonlinear program? 
We’ll use two decision variables so that we can visualize our 
mathematical landscape as a landscape in the traditional sense. But 
now that landscape is much more interesting, including rolling hills 
and valleys. The topography is much more complex, and it is made 
even more so by the fact that the constraints can be nonlinear, too. 
That means that the fences that bound our zone of exploration—our 
feasible region—can be curvy, or zigzag in and out. But our goal is 
 How much of a difference do these new possibilities make? For a 
linear program, if the feasible region has a lowest point, it’s going 
to be on a fence line. In fact, for such a region, you can always 
reach minimum altitude just by checking all of the corners and 
picking the lowest one. 
138
Le
ct
ur
e 
16
: O
pt
im
iz
at
io
n 
in
 a
 N
on
lin
ea
r L
an
ds
ca
pe
 But for nonlinear programs, that’s not true anymore. The fence 
could run along a ring of mountains surrounding a valley, and the 
lowest point would be out in the middle somewhere. As a real-
world example, your store might have 10 checkout lanes so that 
you can handle your busiest times. Open them all on a typical day 
and you’re paying a lot of employees to stand by the registers. 
Open only one and you’re incurring costs from lost sales and 
customer dissatisfaction. Those are the two fences. The sweet spot 
is somewhere in the middle. 
 Another difference in a nonlinear world is that something might 
look like the lowest point but not really be the lowest point. It might 
only be the lowest point in your area—a local minimum, not the 
global minimum.
 Calculus isn’t as useful for some practical problems as you might 
guess. In contrast, nonlinear programming approaches can allow 
multiple variables, complicated boundary conditions, and the 
characterization of multivariate critical points.
Solving Nonlinear Programs
 How do we solve problems where the landscape is not smooth 
and continuous? There are a number of approaches, and which 
you should use depends, not surprisingly, on the topography of 
the landscape. Let’s start with rolling hills and valleys, meaning 
gradient of the objective. The 
following is a strategy that can take advantage of computer power. 
 Start at a random point in the landscape. Find out which direction is 
downhill at that point, just like you would for a linear program. Walk 
a little ways in that direction. Then, stop and repeat the process. 
you can’t make any more progress. This is the basic idea behind 
a collection of techniques called steepest descent, or gradient, 
139
methods. Excel’s GRG nonlinear method is an implementation of 
one of these. The variants differ in exactly what downhill direction 
you take and how far you go in that direction. 
 
rolling landscape? Sure. If it hits the bottom of a little dip valley, 
or follows a slope downhill to a point along a fence, then it’s just 
going to stay there, even though there might be much lower points 
somewhere else—a local minimum. And that is a problem with any 
gradient descent method. 
 One way to try to avoid this is to begin at many points, rather than 
just one. It’s kind of like having a Boy Scout troop out with you, 
each Boy Scout starting at a different spot. When you’re done, you 
compare notes to see who did the best. The more starting points you 
have, the better your chances are. 
 You can imagine a landscape like a hole in a miniature golf course, 
where the hole is surrounded by a volcano-like mound. The bottom 
of the hole might be the deepest point on the course, but how likely 
Every time you check your bearings when standing on the volcano, 
you’re going to end up going in exactly the wrong direction.
 It’s good that this kind of thing doesn’t happen too often in the 
mathematical landscapes of real-life problems, because in general, 
in any reasonable amount of time. But things often work well. 
And there are large classes of problems where gradient descent is 
guaranteed to work. 
 
region are opaque walls. Two people are standing at two points 
inside the region. Then, the region is convex if, no matter where the 
140
Le
ct
ur
e 
16
: O
pt
im
iz
at
io
n 
in
 a
 N
on
lin
ea
r L
an
ds
ca
pe
people stand, they can always look one another in the eye. There 
are no walls in the way. So, a square region is convex, but a star-
shaped region is not. 
 There’s no hiding from one 
another in a room with a 
one person was standing at 
one of the small dots in the 
star-shaped room and the 
other person was standing at 
the other, they couldn’t see 
one another. 
 
convexity of a function—
in our intuitive terms, of 
a landscape. It’s a closely 
related idea. Informally, the landscape is convex if no matter 
where two people stand on it, they can still make eye contact. So, 
if they are standing inside a bowl-like depression, they can see one 
another. If they are standing around a mountain, or in the vicinity of 
a mountain pass, then there are places where they could hide from 
one another’s view. The function giving the landscape is not convex 
in those cases. 
 
revisit the two people in the star-shaped room. Imagine that the goal 
is to move as far to the south (down) in this room as possible. If the 
two people, represented by the two dots, were following gradient 
descent, neither of them could move any farther south in the picture. 
They would both be at local minima—but only the person on the 
right would be at the actual global minimum.
Figure 16.1
141
 So, even if the objective is linear, a non-convex feasible region can 
cause problems. But what if we have a convex feasible region—and 
In fact, we can usually do so quite quickly. And that’s good news, 
because many important problems fall into this category. 
 There are some simple rules for identifying some functions as 
convex without doing any work. One rule is that sums of squares 
of linear expressions in the decision variables are always convex. 
And that means that variance is convex. So, because risk is often 
assessed in terms of variance, the objective of minimizing risk is 
often relatively straightforward. 
 But not everything behaves. We’ve been dealing with smooth 
landscapes, where derivatives always exist. But the absolute value 
function, for example, has a graph shaped like a V. At the point of 
the V, there’s no derivative. And, even worse, what about a cliff 
or mesa? Mathematically, now we’re dealing with a function that 
is discontinuous. It has a jump. Again, at the edge of the cliff, the 
 There are ways to handle even these kinds of problems, and the 
good news is that many of them have been implemented in computer 
software that can run on a PC. One neat family of techniques is 
referred to as genetic algorithms, or evolutionary algorithms. 
They take their paradigm from evolution in biology, and they work 
quite well. 
convex: A region is convex if a line segment drawn between two points of 
the region always stays within the region. A square is convex; a star is not. 
One can intuitively think of a function being convex if someone walking 
on the surface of the function has “line of sight” to every other point on 
the function’s surface. Hence, a single valley is convex, but two valleys 
separated by a ridge are not. 
Important Terms
142
Le
ct
ur
e 
16
: O
pt
im
iz
at
io
n 
in
 a
 N
on
lin
ea
r L
an
ds
ca
pe
evolutionary algorithm: See genetic algorithm.
genetic algorithm: An optimization technique involving a stochastic search 
of possible solutions in a way that somewhat mimics DNA recombination. 
gradient: A vector quantity that indicates the direction of “straight uphill” 
for a function of one or more variables. It is the higher-dimensional 
generalization of the derivative of a one-variable function. 
steepest descent: Also called gradient descent. A collection of techniques for 
the direction in which the objective function is changing most rapidly in the 
desirable direction and then jumps from the current solution to one (nearly) 
in that direction. 
Boyles, “Notes on Nonlinear Programming.” 
Winston and Albright, Practical Management Science.
1. The illustration depicts a hiker near a triangular lake. He spots a 
his distance between himself and the 
swim. Describe the path he will follow 
gradient descent approach. Now repeat 
the exercise, assuming that the lake has 
frozen over. What is the key 
mathematical distinction between the 
two feasible regions?
Suggested Reading
Questions and Comments
Figure 16.2
143
Answer: 
the edge of the lake, move right until reaching the closest point to the 
the lake is frozen but non-convex if it is not.
2. If you know calculus, consider the function z = x4 + y4 x2y2.
a)  Set x = 0. Verify that y = 0 is a minimum of the resulting function. 
This means that (0, 0) looks like a minimum in the x = 0 plane. 
Verify that if you set y = 0, the function looks like a minimum in the 
y = 0 plane.
b)  Now set x = y, so that z is a function of x only. Verify that x = 0 is 
a maximum for this function. That means that (0, 0) looks like a 
maximum in the plane x = y. This is the example given in the video 
lecture, reproduced here.
Answers: 
a)  If x = 0, z = y4. z’ = 4y3, and at y = 0, this is 0, so z has a critical point 
at y = 0. The second derivative test fails to identify it as a minimum, 
but in this case, it is obvious because y4 is nonnegative for all y. The 
same argument holds for the plane y = 0, by symmetry.
b)  In this plane, x = y, so z = 2x4 x4 x4. This equals 0 at 
x = 0 and is negative everywhere else, so x = 0 is a maximum in 
this plane. Again, the second derivative test would fail to reveal the 
nature of the critical point.
144
Le
ct
ur
e 
17
: N
on
lin
ea
r M
od
el
s—
B
es
t L
oc
at
io
n,
 B
es
t P
ric
in
g
Nonlinear Models—Best Location, Best Pricing
Lecture 17
In this lecture, you will explore the outer limits of programming, beyond linear programming to nonlinearity. You will learn about a practical problem and why a particular nonlinear technique may or may not be 
to conduct business. The idea that is addressed is one that allowed Delta 
Airlines to move from a small regional company to a major competitor in the 
U.S. airline industry. 
Facilities Placement
 
between every pair of airports that it serves is unworkable. It’s 
rapidly as the number of airports increases. 
 The solution that seems so familiar now was new in 1955, when 
the hub city. If you wanted to go from A to B, you went from A to 
from everywhere routed through Atlanta, and many still do today. 
Adopting this model made Delta a real competitor with Eastern 
Airlines. Since that time, all of the major airlines have adopted a 
similar system. 
 Since those early days, Delta has also expanded to have additional 
hubs in Cincinnati, New York, and Salt Lake City, leading to a 
multi-hub map that is much more complicated, while extending the 
hub-and-spoke approach. 
145
 The decision of where to place hubs takes into account a number 
of factors, of course, but very important among them is the goal of 
minimizing the total number of miles in the hub-and-spoke system. 
A slightly different goal is the following: Given the airports that 
those airports, what location for the hub airport would minimize the 
 There might not be an airport in this perfect location, but if we can 
existing airports might be close to that location. 
 For this problem, distance we care about is straight-line distances 
from the regional airports to the hub. And the math that gives the 
straight-line distance between two points is basically just the 
Pythagorean theorem. For example, if the hub is at coordinates (x, 
y) and the regional airport is at x = 10, y = 20, then the distance 
from the hub to the regional airport is the following.
 Those squares and that square root make the expression decidedly 
nonlinear. And minimizing average distance is going to mean taking 
a weighted average of the distances from the hub to each regional 
airport—weighted by how many people are traveling from and to 
each regional airport. So, that’s a nonlinear objective. The good 
news is that we have essentially no constraints—no limitations on 
where to build the hub.
 If possible, we’d like to anticipate whether this problem is going to 
be tractable or not. This hinges more on convexity than it does on 
whether a function is convex or not, but the following are a few 
helpful rules that you can keep in mind.
 Linear expressions are convex.
x y10 20
2 2( ) ( )− + −
146
Le
ct
ur
e 
17
: N
on
lin
ea
r M
od
el
s—
B
es
t L
oc
at
io
n,
 B
es
t P
ric
in
g
 Any even power of a variable is convex, such as x2, x4, and so 
on. So is ex.
 If you replace a variable by a linear expression in a convex 
function, it’s still convex. So, (3x + 4y + 2)2 is convex, because 
x2 is.
 If you take a weighted sum of convex functions, it’s still convex 
as long as none of the weights is negative. So, 0.3x2 + 0.4(y 2 
is convex.
 Euclidean distance—that is, straight-line distance—is convex.
 Our objective in this problem is to minimize a weighted average 
of the distances from the hub to each regional airport. Euclidean 
distance is convex, so the objective is a weighted sum of convex 
functions with each weight being nonnegative—namely, the 
fraction of travelers who hail from that city. By our rules for 
convexity, that means that our objective, while nonlinear, turns out 
the global minimum for this. In Excel, for example, the standard 
nonlinear Solver will do the trick. 
 We start out with the data on the cities served by our airline. Their 
from the arbitrary reference point of Houston, Texas. The cells with 
dotted lines for borders are our decision variables, specifying the 
location of the hub, again with Houston as the origin. From this, we 
just the Pythagorean theorem. We record these in the “distance to 
hub” column. (See Figure 17.1.)
 Finally, the weighted average of these distances is computed on the 
bottom of the sheet, using the populations of the cities in millions 
 
each city. 
147
 This objective minimizes the total number of miles that customers 
multiple planes per day. Alternatively, we could simply minimize 
the sum of the numbers in the “distance to hub” column; in this 
case, the resulting location is still in the same vicinity.
 We told Solver where the variables are and where the objective is, 
just as we did for linear programs. We didn’t have to impose any 
constraints, because we didn’t have any. The hub is allowed to be 
built anywhere. The only thing new was that we told Solver to use 
the GRG (generalized reduced gradient) nonlinear solving method 
rather than the Simplex LP method. 
 The answer comes very quickly, as we expect with this convex 
problem. It says that the hub should be built 628 miles east and 221 
miles north of Houston. That is, we’d like our hub to be about 63 
miles southwest of Atlanta. Just like Delta Airlines, we like the idea 
of Atlanta as a hub. 
Distance from Regional Airport to Hub
Regional airport x y Distance to Hub
St. Louis 321 607 493.3509
Houston 0 0 665.8336
Philadelphia 1210 711 760.7749
Atlanta 658 276 62.6776
Miami 908 570.3015
Jacksonville 822 41 264.4876
Hub Location
x = 628.1215 y = 220.9
Populations
City STL HOU PHL ATL MIA JAC
Population 0.32 2.1 1.54 0.42 0.41 0.82
Goal
MIN Average distance 571.3 miles
Figure 17.1
148
Le
ct
ur
e 
17
: N
on
lin
ea
r M
od
el
s—
B
es
t L
oc
at
io
n,
 B
es
t P
ric
in
g
Genetic Algorithms
 What happens when Delta grows and establishes new hubs? 
Imagine that the Atlanta hub was already established and that now 
we’re looking for locations of new hubs. The distance calculations 
of them. But a new factor would appear—namely, now a regional 
of whether that airport goes with that hub. Because of the large 
number of resulting integer variables and constraints, we should 
size up the problem before we get too committed to one approach.
 Linear programming is out, because the objective is nonlinear. 
But because we have no constraints to begin with, we might want 
to consider a genetic algorithm. They hate all but the simplest 
constraints—upper and lower bounds on decision variables—but 
 Let’s expand the problem to include multiple hubs and approach 
it with a genetic algorithm. They can be slow, but that probably 
won’t be a problem in this case. Let’s say that we’ll have up to four 
hubs and that each hub has to be at one of the cities that we serve. 
This restriction is desirable from a practical standpoint, and its 
addition will make the problem easier to solve. We don’t need the 
coordinates of the hub now, just the city where it will be located. 
 For this example, we have chosen 29 large U.S. cities for our airline 
to serve. Our system will have multiple hubs, with each regional 
airport being a spoke attached to one of the hubs. Our goal will be 
to minimize the total number of miles in this system. Additionally, 
we will make the reasonable assumption that each hub has to have 
also going to take a different approach to distance, getting it from a 
table of distances (given in miles) from city to city. 
149
 This information is much easier to obtain than the mileage 
coordinates from Houston that we used before. This means that we 
the table, but Excel actually has many functions for that sort of 
thing, such as INDEX or VLOOKUP, and because we’re using a 
genetic algorithm, we can use any such functions we want, with a 
 
temporarily put the hubs at cities 1 through 4: Atlanta, Austin, 
Baltimore, and Boston. To make it easier for a user to understand, 
we had the spreadsheet report the names of the hub cities as well. 
We used the INDEX function for this. We also have to have a 
variable for each regional airport, specifying to which hub it will be 
assigned. (See Figure 17.4.)
 The values in the cells that have dotted lines don’t matter. We’ll 
tell Solver that they are decision variables and have to be integers 
between 1 and 4—because there are four hubs, 1 through 4.
 Because we’re using a genetic algorithm, though, we have another 
option. Once the hubs are determined, this problem is going to have 
its optimal solution if each city is assigned to its nearest hub. That 
Hub Location
Hub 1 2 3 4
City # 1 2 3 4
Name of Hub Atlanta Austin Baltimore Boston
Figure 17.3
City # Atlanta Austin Baltimore Boston Chicago Dallas Denver
1 Atlanta 0 1315.28 927.35 1505.11 944.4 1157.42 1945.42
2 Austin 1315.25 0 2166 2724.01 1571.76 293.52 1240.77
3 Baltimore 927.35 2166 0 577.85 973.23 1947.28 2422.32
4 Boston 1505.11 2724.01 577.85 0 1366.63 2490.97 2838.62
5 Chicago 944.4 1571.76 973.23 1366.63 0 1290.15 1474.26
6 Dallas 1157.42 293.52 1947.28 2490.97 1290.15 0 1064.41
7 Denver 1945.42 1240.77 2422.32 2838.62 1474.26 1064.41 0
Figure 17.2
150
Le
ct
ur
e 
17
: N
on
lin
ea
r M
od
el
s—
B
es
t L
oc
at
io
n,
 B
es
t P
ric
in
g
is, we could tell the spreadsheet to compare the distances from this 
regional airport to each of the four hubs and then choose the hub 
Memphis, and Baltimore.
Anderson, “Setting Prices as Priceline.”
Suggested Reading
Questions and Comments
Figure 17.5
City # 1 2 3 4 5 6
Assigned to Hub 1 2 3 4 1 2
Distance to Hub 0 0 0 0 944.4 293.52
City # Atlanta Austin Baltimore Boston Chicago Dallas
1 Atlanta 0 1315.28 927.35 1505.11 944.4 1157.42
2 Austin 1315.25 0 2166 2724.01 1571.76 293.52
3 Baltimore 927.35 2166 0 577.85 973.23 1947.28
4 Boston 1505.11 2724.01 577.85 0 1366.63 2490.97
5 Chicago 944.4 1571.76 973.23 1366.63 0 1290.15
6 Dallas 1157.42 293.52 1947.28 2490.97 1290.15 0
Figure 17.4
151
1. Like the Delta problem, a number of transportation problems involve 
minimizing some distance measure. One interesting one is to connect a 
set of n cities with roads so that the road system allows travel from any 
one city to any other, and the total length of all of the roads is minimal. 
Such a road system is called a Steiner tree. 
It’s an interesting fact that every intersection of roads in such a system 
always consists of three roads meeting at angles of 120 degrees. The 
solutions for the cases when the cities are on the corners of a right 
triangle and on the corners of a square are shown in the diagram. If 
each side of the square is 1 mile in length, joining all four corners to the 
center requires a total of about 2.828 miles of roadway, but the Steiner 
tree requires only 2.732 miles. 
2. You are given the distances among four hubs: A, B, C, and D. Let AB be 
the distance from hub A to hub B AC, AD, BC, BD, and CD 
in parallel fashion. It is easy to see if two hubs are identical, because 
the distance between them is zero. In our second problem, we needed to 
know the total inter-hub distance. For example, if A and B are the same 
and C and D are the same, then the total distance should be just AB. 
Let NAB = 0 if AB = 0 and NAB = 1 if AB > 0. That is, NAB is 1 if and only 
if A and B Nij similarly for any pair of hubs 
i and j.
What expression would give the total distance in the system?
There are multiple answers, but here’s one: AB + NBCAC + NBDAD + 
NABNACBC + NABNADNCDBD + NACNADNBCNBDCD.
152
Le
ct
ur
e 
18
: R
an
do
m
ne
ss
, P
ro
ba
bi
lit
y,
 a
nd
 E
xp
ec
ta
tio
n
Randomness, Probability, and Expectation
Lecture 18
This lecture focuses on randomness, or uncertainty. We often have a pretty good intuition about random events that we deal with all the time, but when it comes to things that are unfamiliar or that 
occur only rarely, people are often terrible at estimating the probabilities 
of events or what average results they might expect if facing the situation 
many times. In this lecture, you will learn some essential tools used in 
probability, including calculations of the probabilities of compound events 
and expected value. 
Probability
 Probability is a measure of the chance that an event occurs. Events 
that never occur get a probability of zero; events that always occur 
that range, with more likely events getting higher probabilities. 
 
chance that the coin comes up heads; the probability of getting a 
head is 0.5. But that doesn’t really mean that it comes up heads half 
come up the same: two heads or two tails. In fact, half of the time, 
 So, where does this probability of 0.5 for a head come from? It’s 
the classical probability of the event. With the coin, there are two 
equally likely outcomes: heads and tails. There is a probability of 
likely, then divide the number of successful outcomes by the 
total number of possible outcomes and you get the probability 
of success.
153
 
useless. We often can’t break down all possible outcomes into 
a collection of equally likely possibilities. And when we can’t, 
probability based on historical data and relative frequencies. 
 Empirical probabilities might not always consider all of the factors 
involved, but they are often the best we have, and they’re often 
accurate enough to help us make good decisions. Unfortunately, 
sometimes we can’t even get empirical probabilities. 
 For example, what is the probability that AIDS will be cured 
in the next 10 years? Obviously, we can’t use either classical or 
empirical probability for a question like this. We can’t look at 
how often AIDS was cured in previous decades. And it may not 
really be sensible to use data for the cure rates of other diseases in 
predicting the eradication of AIDS. In this case, the best we have 
is a subjective probability—a (hopefully educated) guess. How 
reliable such a probability is depends on how much you can trust 
the person making the estimate.
 Regardless of where our probabilities come from, there are three 
things we can do with them once we have them. First, we can 
characterize the variation of the important quantities in a problem. 
How much on average will this risky investment pay? What’s the 
worst that can happen? What’s the chance of it losing money?
 Second, we can use probabilities to simulate situations. This lets us 
when we open a new lane on a particular highway?
 Underlying both of these uses is the third use: Probabilities of 
more complicated compound events. For example, how likely is it 
that Bank A or Bank B or both approve our loan? If we get the loan 
154
Le
ct
ur
e 
18
: R
an
do
m
ne
ss
, P
ro
ba
bi
lit
y,
 a
nd
 E
xp
ec
ta
tio
n
approval, how likely is it that our bid is accepted and that we can 
 The most important one is joint probability, which is the 
probability that one thing happens and another thing happens. More 
whole collection of events occur. 
 The answer is actually pretty simple. The word “and” in probability 
always goes with the operation of multiplication. The formula 
involves multiplying a string of probabilities together. The 
probability of event A is written as P(A), and the probability of 
event B is written as P(B). 
 The idea of “the probability of A being true given that B is true” 
is important in many computations, so it’s given a special name: 
conditional probability—in this case, the probability of A given 
B. The word “given” is represented in symbols as a vertical bar, 
as follows.
P(A | B) = probability of A, given B = the probability that A is true, 
given that B is true.
 The following is the representation of this idea in symbols.
P(A and B and C) = P(A)  P(B | A)  P(C | A and B).
 This kind of formula always works. In fact, it gets even easier 
when the events happen to be independent. A collection of events 
is independent if knowing whether some of them are true doesn’t 
change the probabilities that the others are true. 
 For example, this is always the case when the events have no 
connection with one another. If two people each pick a person 
randomly, whether one chosen person is married is independent of 
whether the other chosen person is of legal age. That is, knowing 
155
one chosen person’s marital status neither increases nor decreases 
the chance that another arbitrarily chosen person is a minor. On 
the other hand, if two people agreed to choose the same person, 
the marital status and whether the person is a minor would be 
dependent events. Minors are less likely to be married than people 
of legal age.
 Anytime you’re looking at joint probability, you always want to 
ask yourself if the events are independent. If they are, it’s easy to 
probability of each event individually, and then multiply all of those 
probabilities together. 
For independent events, P(A and B and C) = P(A) P(B)  P(C).
Errors in Reasoning
 
higher than their objective accuracy. 
 In a spelling test, for example, respondents correctly spelled only 
80% of the words of which they were “100% certain.” And the 
to be 80% certain, they were right far less than 80% of the time. 
 A 1981 study showed that 93% of American drivers rated 
median is the halfway point in the population, so only 50% are 
better than half of all other drivers. 
 Given any “concrete” information, people often seem to disregard 
the relevant probabilities. It’s called ignoring the base rate, and it 
leads people to believe that a short, slender English man is more 
likely to be a jockey than a welder, even though there are over 
100 times as many welders in the population as jockeys. It’s a 
tempting error. 
156
Le
ct
ur
e 
18
: R
an
do
m
ne
ss
, P
ro
ba
bi
lit
y,
 a
nd
 E
xp
ec
ta
tio
n
 
that if you are a jockey, the chances of your being slender are very 
high. But that does not mean that, if you are slender, your chances 
of being a jockey are very high. Every great pianist has two hands. 
But that doesn’t mean that a person with two hands is likely to be a 
great pianist.
 Interestingly, a number of studies have shown that it’s common 
for people to completely ignore the provided information of how 
frequently the target group appears in the population and instead 
to base their guesses on details of the people that have almost no 
predictive power for the question at hand. 
Expected Values
 
how to judge whether one strategy really is better than another—
because a strategy that would work out brilliantly under one set of 
chance circumstances may be the worst choice possible in another. 
 The following might be an important question: How well does the 
strategy do on average? A bank making loans is going to sometimes 
reject a person who would have paid up and will sometimes accept 
a person who defaults. But they’re interested in their long-term 
average return. 
 The average payoff is also called the mean payoff, but when dealing 
with matters involving chance, mathematicians often call it the 
expected value. This term is misleading, because it isn’t the value 
that any one person would actually expect. 
 
expects to win nothing—but the average winning is $5. The facts 
are that 10 people played, and the total winnings were $50, so the 
the expected value, even though it’s impossible to win $5.
157
 But once you get past possible confusions about the name, 
computing expected values—averages—in many cases is pretty 
straightforward. Suppose that you have a quantity that can only 
the fraction of the time that each occurs. That’s the probability. 
multiply it by the probability that it occurs, and then add all of 
these products together. 
 But keep in mind that unless a situation is being faced many, many 
times, knowing the average is never enough. If we’re doing a risk 
analysis for an event that happens only once or a few times, we 
need to watch out for variability in the data. Still, the average is an 
important place to start, and expected values show a lot of useful 
and important mathematical properties that will often allow us to 
 One such property is that they behave very well under addition. Take 
any two activities A and B, and the average result from doing both 
A and B is the same as the average from doing A plus the average 
from doing B—regardless of whether A and B are independent or 
intimately connected. 
event: A statement about the outcome of an experiment that is either true or 
false for any given trial of the experiment. 
expected value: The average (or mean) value of a numeric random variable. 
independent: Two events are independent if knowing the outcome 
of one does not alter the probability of the other. In symbols, A and B 
are independent if and only if P(A) = P(A | B). Two events that are not 
independent are dependent. 
Important Terms
158
Le
ct
ur
e 
18
: R
an
do
m
ne
ss
, P
ro
ba
bi
lit
y,
 a
nd
 E
xp
ec
ta
tio
n
probability: A measure of the likeliness of the occurrence of uncertain 
events. Probabilities lie between 0 and 1, with more-likely events having 
higher probability. If all possible outcomes of an experiment are equally 
likely, the classical probability or a priori probability of an event can be 
cases, probability may be empirically 
cases in which the event occurred. 
probability, conditional: The probability that some event occurs, given that 
some other collection of events occurred. The probability that A occurs given 
that B occurs is written P(A | B). 
probability, joint: The probability that all events in some collection occur. 
Grinstead and Snell, Introduction to Probability.
Piattelli-Palmarini, Inevitable Illusions.
1. Many people believe that “bad news comes in threes.” If this is nothing 
but a fantasy, how can we explain this? To simplify the math, imagine 
that a day has a 10% chance of having “bad news” but that each day is 
independent of the rest.
a)  Show that if one receives bad news on a given day, there is an 81% 
chance of no bad news on either of the following two days. Because 
10% of days have bad news, this is common and not seen as part of 
a pattern.
b)  Two bad days in a row are relatively rare: a 1% probability for any 
two particular consecutive days. This catches people’s attention. 
People are now looking for the third bad day. Given that two bad 
days in a row have just occurred, show that there is a 19% chance 
that at least one of the following two days will have bad news.
Suggested Reading
Questions and Comments
159
Answers:
a)  Each day is independent, so looking at two consecutive days, we’re 
just asking P(no bad on day 1 and no bad on day 2). Because a day 
has a 10% chance of being bad, it has a 90% chance of being good. 
Because bad news on one day is independent of what happens on 
other days, we can just multiply the probability of no bad on day 1 
with the probability of no bad on day 2. That’s 0.9 × 0.9, or 0.81.
b)  Again, days are independent, so we’re really asking, for two 
consecutive days, “How likely is it that at least one is a bad 
day?” Note that, as stated, this is not an “and” problem—it’s an 
“or” problem: day 1 bad or day 2 bad or both. But with a bit of 
cleverness, we can still get the solution.
  Turn the question around. The opposite of either of the next two 
days being bad is both of the next two days being good. But in part 
a), we found the probability of two good days in a row as 0.81. 
one of the two days is bad. Note that neither the answer to a) nor 
b) depended on knowing what kind of day today was. Each day is 
independent, by assumption.
2. In the “Cat or No Cat?” game from the video lecture, suppose that you 
knew that you were being shown the pictures of three people who owned 
cats and six who didn’t. You want to maximize the average amount of 
money you make on your guesses. How should you guess now?
Answer: 
Surprisingly, you should still guess that there are no cat owners, and 
your average payoff is still $600. This is a demonstration of the power 
implied by the statement that “expected values of payoffs always add.” 
For any one picture, alone, guessing “cat” gets you on average $33.33, 
and guessing “no cat” gets you on average $66.67. So, the sum over all 
nine pictures still works the same as before, with you getting 9 × $66.67 
= $600 on average. Indeed, in guessing that there are no cat owners, 
160
Le
ct
ur
e 
18
: R
an
do
m
ne
ss
, P
ro
ba
bi
lit
y,
 a
nd
 E
xp
ec
ta
tio
n
even though you know that there are three hidden in there somewhere, 
you are guaranteed $600, and any other guessing scheme will, on 
average, get you less.
So, should you never guess three cat owners and six non-owners? Well, 
there is one variant where you’d want to do that: if you were told that 
there were three cat owners and six non-owners but that you’ll only get 
paid if you guess every one correctly. In this situation, clearly, you’ll 
want to match the demographics. Your chance of success turns out to be 
1 in 84. You can work this out yourself, with an approach like that used 
for the English footballers. Imagine having nine poker chips, three of 
161
Decision Trees—Which Scenario Is Best?
Lecture 19
Every decision that you make, whether for yourself or as part of an organization, has the potential to affect your overall reputation and prospects into the future. And, often, your control of that future 
is limited. Decision trees are an analytics tool for addressing just such 
scenarios—ones that unfold over time, interleaving the choices you make 
and the unpredictability of the rest of the world. In this lecture, you will learn 
how to solve a complex problem by using the relatively simple approach of 
decision trees.
Decision Trees
 With decision trees, sometimes you get to choose your path, and 
sometimes chance dictates it for you. A decision tree has many 
actually, that’s the power of the technique—in generating all of the 
possible paths, and then navigating your way to the best decisions 
you can make in light of that collection of possibilities.
 For example, suppose that we run a mining company. We’ve had 
our eyes on two adjacent parcels of land that may have valuable 
deposits of minerals. Each deposit, if it’s there, is worth $3.5 
million, in fact. 
 The owner is asking for $1.6 million for the pair, which is too 
expensive; after all, there’s only a 30% chance that a parcel 
contains minerals. The owner agrees to sell us one of the parcels for 
$1 million. If we want, the owner will also sell us an option on the 
second parcel for $200,000. The option allows us to buy the other 
parcel for an additional $400,000. 
162
Le
ct
ur
e 
19
: D
ec
is
io
n 
Tr
ee
s—
W
hi
ch
 S
ce
na
rio
 Is
 B
es
t?
 If we eventually want both parcels, this allows us to get them for 
losing the $1 million and the $200,000 option. But if the one parcel 
has minerals, the other one is 60% likely to have them, too. The 
owner is no fool, so without the option, we would have to pay more: 
$1.3 million to buy the second parcel. 
 
forget the whole deal. Let’s think about the top choice, where we 
contains minerals. That’s a chance node with a 30% success rate. 
 A chance node is represented by a circle on the decision tree; which 
way the situation evolves from that node is a matter of chance. 
Alternatively, squares represent decision nodes, where we’re able 
to choose which option we prefer. 
Figure 19.1
163
 
minerals. There’s nothing more to do in that case but lose the 
another decision: whether to buy the second parcel. 
 Because we bought the option, we can get the second parcel for 
parcel contains minerals as well. That’s another chance node, with a 
minerals, there’s a 60% chance that the second one does, too.
Initial parcel: $1 million
If initial parcel successful: 
With option: $200,000 to buy 
2nd for $400,000 more or buy it 
without option for $1.3 million
Successful parcel generates 
$3.5 million
Figure 19.2
164
Le
ct
ur
e 
19
: D
ec
is
io
n 
Tr
ee
s—
W
hi
ch
 S
ce
na
rio
 Is
 B
es
t?
 The payoff at the ends of the branches just adds up all of the losses 
and gains experienced as we move through the tree. Take, for 
example, the $1.9 million on the third branch down. What events 
occurred to get to that end? We bought the initial parcel and the 
option, but found nothing in the second parcel. So, we spent $1 
million on the initial land, $200,000 on the option, and $400,000 
for the second parcel for a total outlay of $1.6 million. But we made 
million. All of the other payoffs work the same way.
 We can build the branch for buying the land without the option in 
exactly the same way. The whole tree is as shown in Figure 19.2. 
 Let’s see what we get when we roll back
optimal strategy. We work from the twigs on the right to the root at 
Figure 19.3. 
 This tree says to buy the original parcel and the option on the second 
parcel, and if the initial parcel contains minerals, then exercise the 
This is not bad, given that our maximum outlay is $1.6 million—
that’s about a 22% return on investment. On the other hand, this 
enterprise is fairly risky. The most common outcome, which 
happens 70% of the time, is that you lose $1.2 million.
Utility Functions
 Decision trees, as we’ve been using them, have been assuming risk 
neutrality. That is, given two options, the one that gives the better 
average payoff is the more desirable. When the same situation is 
faced many times, this attitude makes sense. 
165
Figure 19.3
Initial parcel: $1 million
If initial parcel successful: 
With option: $200,000 to buy 
2nd for $400,000 more or buy it 
without option for $1.3 million
Successful parcel generates 
$3.5 million
 The law of large numbers in statistics says that we’re very likely 
to see overall results that are quite close to the expected value 
calculation when we repeat a situation many times. This is the 
principle that allows insurance companies to make money, even 
though they have less of an idea about your individual health or 
property than you do.
166
Le
ct
ur
e 
19
: D
ec
is
io
n 
Tr
ee
s—
W
hi
ch
 S
ce
na
rio
 Is
 B
es
t?
 Nevertheless, most people are not risk neutral, most of the time. 
Most people are risk averse. For example, suppose that someone 
Honestly, would you take the wager? 
 Clearly, it favors you—on average, you’ll win $100,000 on the 
people, that downside risk is just too great. If you refuse the wager, 
you’re risk averse in this situation. And the reason is actually fairly 
simple: The $400,000 you might gain isn’t worth as much to you as 
the $200,000 that you might lose.
 
replace each payoff in the tree with its corresponding utility. The 
that the expected value calculations we’ve been doing make sense, 
when applied to utilities. 
 John Von Neumann and Oskar Morgenstern showed that, under 
four pretty weak assumptions, one could construct such a utility 
function for a decision maker. One assumption is transitivity—that 
if you like A better than B and B better than C, then you like A 
better than C. 
 Another assumption is continuity. Suppose that you like A better 
than B, and B better than C. Someone offers you a choice. If you 
want, you can get B for sure, or you can enter a lottery. Win the 
lottery and you get A, but lose the lottery and you only get C. 
Continuity says that the person offering you the choice can make 
you indifferent between B for sure and the lottery if that person 
chooses the right probability, p, of winning the lottery.
167
 If the person offering the choice gave you a 100% chance of 
winning, you’d take the lottery, because you’d be sure to get your 
A. If the person gave you a 0% chance of winning 
the lottery, you’d take B, because the lottery is sure to give you 
your least-favorite outcome, C. And somewhere in between is a 
probability where you’d think B and the lottery were equally good.
 In the 1700s, Daniel Bernoulli suggested the following utility 
function. If you end up with a wealth of w, Bernoulli suggested 
using ln(w), the natural logarithm of w, as the measure of your 
utility. Don’t worry about how to take natural logarithms by 
hand; the “ln” key on a calculator is happy to do this for you. The 
important thing about log functions is that they keep increasing as 
w increases, but they do so more and more slowly. 
 In the wager example, half of the time you’d gain $400,000 from 
someone, and the other half of the time you’d lose $200,000. If 
you’re risk neutral, you’d be a fool not to take this wager, because 
on average you win $100,000. 
 But let’s say that your current wealth is $400,000. Then, that person 
is offering you a chance to either double your current wealth or cut 
it in half. Using Bernoulli’s log utility, your utility if you keep your 
$400,000 would be ln(400,000), which comes out to be 12.9. If 
you win the wager, you’d end up with $800,000, and ln(800,000) 
is 13.59. On the other hand, if you lose, you end up with $200,000, 
and ln(200,000) = 12.21.
 Looking at utilities, if half the time you get a utility of 13.59 and 
half the time you get a utility of 12.21, your expected utility from 
the wager is the average of these two, which is 12.9. And that 
was the utility that you started with. So, with Bernoulli’s utility, 
you’d be indifferent between taking the wager and keeping your 
current money. 
168
Le
ct
ur
e 
19
: D
ec
is
io
n 
Tr
ee
s—
W
hi
ch
 S
ce
na
rio
 Is
 B
es
t?
 If you had more money already on hand, the bet would look better 
to you. If you had a million dollars to start, the wager would leave 
you with either $800,000—utility ln(800,000) = 13.59—or with 
$1.4 million—utility ln(1.4 million) = 14.15. The average of these 
is 13.87, while keeping your original million gives you a utility 
of ln(1,000,000)= 13.81. Of course, 13.87 is better. In logical 
terms, with more money in the bank, the pain of a $200,000 loss is 
less severe.
 People have proposed other utility functions for risk aversion, but 
it’s also possible to build a personal utility function to mirror any 
rational decision maker. Essentially, you take the lowest payoff on 
the tree, the highest payoff on the tree, and you offer the decision 
maker a lottery ticket that will pay either this lowest payoff or this 
highest payoff. What’s that ticket worth? It depends on what the 
probability of getting the high payoff is (p). A high-p ticket is worth 
a lot more than a low-p one.
decision tree: A structure consisting of branching decision nodes and chance 
nodes used to analyze sequential decision making in the face of uncertainty. 
rollback: The procedure of evaluating a decision tree by computing expected 
values at each chance node and choosing the most-attractive options at each 
decision node. 
utility: In essence, “happiness points.” Utilitarian models in economics posit 
that decision makers act so as to maximize their personal utility. A utility 
Dudley and Buckley, “How Gerber Used a Decision Tree in Strategic 
Decision-Making.”
Ragsdale, Spreadsheet Modeling & Decision Analysis.
Important Terms
Suggested Reading
169
1. Some decision trees allow the possibility of doing research. This will 
always involve the addition of at least one additional decision node to 
the tree and at least one additional chance node. 
c)  If the research is conducted, the probabilities for events beyond that 
point in the tree may change. Why?
Answers:
b)  What was the outcome of the research? This will always be in 
the form of “research says” or “research suggests” or “research 
predicts,” never in the form of “research right” or “research 
wrong.” That’s because at the time that you get the research results, 
you don’t yet know if they are correct!
c)  Because they are conditional probabilities. The purpose of research 
is to give you a better idea of how some future chance event will 
turn out. So, the research turning out a particular way will modify 
the chance that that future event occurs.
2. In decision theory, one sometimes computes the expected value of 
perfect information (EVPI), which tells you how much, on average, 
perfect information would be worth in the particular decision tree. 
Perfect information is knowing the outcome of every chance event in 
the problem before making any decisions.
Consider the following problem: A shoebox is equally likely to contain 
a $1 or a $10 bill. Someone gives you the choice of either taking the 
contents of the box or taking $5 from him or her. 
Questions and Comments
170
Le
ct
ur
e 
19
: D
ec
is
io
n 
Tr
ee
s—
W
hi
ch
 S
ce
na
rio
 Is
 B
es
t?
a) How much do you make, on average, if you take the box?
b)  Suppose that you knew what was in the box before choosing. This 
would be perfect information. Show that you would make $7.50 
on average.
c)  EVPI is how much better you would do with the perfect information 
than you could do on you own. Show that in this problem, the EVPI 
is $2.
Answers: 
a) $5.50.
b)  
the $5 instead. Your average winnings are 0.5(10) + (0.5)5 = $7.50.
171
Bayesian Analysis of New Information
Lecture 20
The chance that something is true changes as new and better information becomes available. This simple idea is the key to Bayesian analysis, named after mathematician and Presbyterian minister Thomas Bayes. 
In this lecture, you will learn that this type of analysis deserves to be used 
far more widely than it is. You will also learn that once you understand 
conditional probabilities, Bayesian probability is available to improve many 
kinds of decisions. In fact, when you have a conditional probability and need 
its reverse, then Bayesian probability is the answer.
Bayesian Analysis
 Bayesian analysis is named after the Englishman Thomas Bayes, 
an 18th century mathematician and Presbyterian minister who 
proposed a special case of what is now called Bayes’ theorem. It’s 
a powerful tool, but the idea behind Bayesian analysis is really 
pretty simple. The chance that something is true changes as new 
information becomes available. Bayes’ theorem tells you how to 
compute the new probabilities. 
 
cards and the ace of spades—and deals them facedown in a row. 
Your card is the one on the left, and in a moment, your friend will 
reveal the card on the right. Do you have the ace of spades?
 
chance of each. This is called the prior probability distribution—
it’s the distribution before any new information comes in. So, your 
 But, now, your friend reveals the rightmost card. Whatever happens, 
you’re going to learn something. Your friend turns over the ace, so 
that means that your card is not the ace. The new information just 
172
Le
ct
ur
e 
20
: B
ay
es
ia
n 
A
na
ly
si
s 
of
 N
ew
 In
fo
rm
at
io
n
 And even if your friend turned over a red card, you’d still have new 
probabilities. The ace is now equally likely to be either of the two 
 Alternatively, let’s say that the card your friend turns over is not the 
ace, meaning that the ace is still out there, and it’s equally likely to 
be either of the two remaining cards. So, your chance of having the 
of course, the change would be even more dramatic. Your chance of 
 That’s basically what Bayesian probability does. We begin with 
of each of the possible outcomes. Then, we get some additional 
information. Bayes’s theorem then allows us to compute the 
updated probability for each possible outcome, the so-called 
posterior probabilities. Our original information is combined with 
should change.
Applying Bayesian Analysis
 Understanding Bayesian probability is important because failing 
to do so can lead to a lot of bad decision making, including racial 
prejudice, medical misdiagnosis, and bad public policy. The 
reason is that most people who are untrained in the mathematics 
of probability fail to distinguish between a conditional and 
its reverse. 
 There’s a medical condition called phenylketonuria (PKU) that 
results from an error in phenylalanine metabolism in infants. It 
results in mental retardation if not detected, but there is a screening 
that is 100% successful in spotting children with the defect, and 
there’s a treatment for the condition. Screening is mandatory in all 
50 states, so if your child has PKU, you’re going to know.
173
 This test spots 100% of children with PKU, but what does it do 
with children who don’t have PKU? After all, if we simply say that 
all babies have PKU, we have a test that spots 100% of the children 
that have the condition. We’ll just be wrong about everyone else. 
Our test has no  at all. The missing information is that 
there are two common tests for PKU, and the better one is 98% 
likely to identify a PKU-free child as being PKU-free. 
 How afraid should you be when your baby tests positive, with a test 
that is somewhere between 98% and 100% accurate? The question 
we want is not how likely a sick child is to test positive—that’s 
100%. The question is how likely a child who tests positive is to be 
sick. Let’s use Bayesian analysis. 
 Somewhere around 1 child in 15,000 is born with PKU. Imagine 
15,000 children. On average, one of these children is going to be 
unlucky enough to have PKU—and our test is guaranteed to catch 
it. But there are 14,999 kids who don’t have PKU, and the 98% 
reliable test, on average, will report that about 2% of them appear 
to have PKU. That’s about 300 children. So, when this test that is 
over 98% reliable says that your child has PKU, the odds are 300 to 
1 against your child having the condition. The rarer the disease, the 
more likely that a positive test result is a false positive.
 More people are killed by bee stings each year than by shark 
attacks. And an appropriate reaction is, so what? Because we don’t 
want “probability of shark given death”; we want “probability of 
death given shark.” If you are hip-deep in the ocean and a bee is 
approaching you from the shore as a shark closes in on you from 
the sea, run toward the bee. 
 Most accidents occur within 15 miles of home. Of course they 
do—most driving occurs within 15 miles of home. The value that 
we need is P(accident | near home), not P(near home | accident). 
Numbers and probabilities have a cachet—they sound irrefutable. 
But even if the numbers are correct, you have to make sure that 
you’re looking at the right probabilities.
174
Le
ct
ur
e 
20
: B
ay
es
ia
n 
A
na
ly
si
s 
of
 N
ew
 In
fo
rm
at
io
n
 There has been congressional testimony that has examined whether 
marijuana is a gateway drug to cocaine and heroin. One argument 
presented was that the overwhelming majority of cocaine users 
put the fraction of cocaine users who previously used marijuana at 
around 95%. For many people, this is a strong argument for keeping 
marijuana use illegal. 
 But none of this makes the argument it purports to make. It’s 
not just the logical problem of post hoc, ergo prompter hoc, nor 
even that an addictive personality would probably be exposed to 
marijuana before cocaine. It’s that, if the argument were sound, an 
even stronger one could be made against milk, which more than 
95% of cocaine addicts used, and usually from a very early age. 
 What went wrong? Again, the problem is the reversed conditional. 
The question isn’t what fraction of coke users started with 
marijuana. The question is what fraction of marijuana users go on 
to cocaine—which statistics have shown is about 25%. This is not 
a small number, but it’s a far cry from 95%. What is amazing about 
the 95% statistic is how small it is; if correct, it means that 5% of 
coke users just vault over marijuana. 
 A similar problem comes up with statistics about the fraction 
of highway fatalities that involve drunk drivers. The president 
of Mothers Against Drunk Driving quoted this statistic in her 
congressional testimony: According to the Department of 
 But, again, knowing nothing else, this statistic tells us very little. 
After all, it means that over two-thirds of fatal accidents involve 
only sober people. If anything, that seems to imply that we should 
get liquored up before getting behind the wheel. 
175
 This reasoning is, of course, nonsense. Again, we’re looking at 
the reversed conditional. We don’t need to know the probability 
the probability that a drunk is involved in a fatal accident—as 
compared to a sober driver. 
 Doing the Bayesian work leads to a conclusion that those above the 
legal limit for blood alcohol are at least 13 times more likely to be 
that is 
the statistic that’s relevant to the drunk driving discussion.
 Many kinds of bigotry and prejudice are fueled, in effect, by 
confusing a conditional and its reverse. For example, when people 
to mind. And, overwhelmingly, the people involved in that attack 
were young, male, Arab, and Muslim. The hijackers themselves all 
hijacker, you have a pretty good idea of what he looks like.
 But the problem, of course, is that most of the time, people aren’t 
who is young, male, Arab, and Muslim, though. And it’s when 
you think about situations like these that you can realize how 
dangerous it is to confuse “A given B” and “B given A,” because the 
vast majority of young male Arab Muslims are not terrorists, and 
thinking that they are is a cause for terror of a whole different kind. 
Bayesian analysis: A technique for revising the probabilities of outcomes in 
light of new information. 
Important Terms
176
Le
ct
ur
e 
20
: B
ay
es
ia
n 
A
na
ly
si
s 
of
 N
ew
 In
fo
rm
at
io
n
prior probability distribution
of events in light of new information. The probability distribution in 
effect before new information is provided is called the prior probability 
distribution. The new distribution, accounting for the new information, is 
called the posterior probability distribution. 
: The probability that an observation is classed as not having the 
trait of interest, given that it does not, in fact, possess that trait. Contrast 
to sensitivity. 
Grinstead and Snell, Introduction to Probability.
Stone, “In Search of Air France Flight 447.”
1. How does Bayesian probability relate to drug testing? What procedures 
do you think should be followed when someone tests positive for an 
illegal substance?
Answer: 
It’s similar to the PKU example in the lecture. Assuming that illegal drug 
use occurs in a relatively small fraction of the population, the chances 
of a false positive, even with a test of high accuracy, are considerable. 
If a person tests positive, following up with a second test is appropriate 
before other action is taken.
2. Think of several examples where people commonly make the error of 
reversing conditional probabilities—that is, they confound the chance of 
A when B is true and the chance of B when A is true.
Suggested Reading
Questions and Comments
177
Answer: 
Examples are legion. Most follow the model of “because most A’s are 
B, most B’s are A” and can be made even worse if the A category is 
limited to one’s own individual experience. For example, if a person is 
engaged in criminal activity, he or she will probably not want to submit 
to a polygraph. From this, we conclude (fallaciously) that someone 
who doesn’t want to submit to a polygraph is probably engaged in 
criminal activity. If a proposed remedy to a problem works (medicine, 
treatment, prayer, etc.), then after the treatment, the problem will 
usually turn out okay. We conclude (again, fallaciously) that if such 
problems usually turn out okay after the remedy is employed, then the 
remedy probably works.
178
Le
ct
ur
e 
21
: M
ar
ko
v 
M
od
el
s—
H
ow
 a
 R
an
do
m
 W
al
k 
Ev
ol
ve
s
Markov Models—How a Random Walk Evolves
Lecture 21
In business and organizational decision making, Markov analysis, named after Russian mathematician Andrey Andreyevich Markov, is useful for 
a telecommunications network, predicting demands on hospital resources, 
characterizing web browsing behavior, designing maintenance schedules 
and predicting failure times, assessing the behavior of waiting lines, and 
evaluating whether admissions to a university program now will result in 
overloading the program in the future. It’s no less useful in the sciences—
for example, modeling diffusion across a membrane or drugs in a body. In 
this lecture, you will learn about the Markov process, including how to use 
Markov diagrams and transition matrices.
Markov Process
 The following is the mathematical skeleton of a Markov process. 
You have a system in which you are interested. At any given point 
in time, this system can exist in one of a variety of states. In many 
As far as the management of a restaurant is concerned, for example, 
a table might have eight possible states, as follows.
1. table reserved
2. table available
3. guests selecting orders
4. guests ordering
5. guests waiting for food
6. guests eating
7. guests waiting for check
8. table unoccupied but needing cleaning
 A system generally stays in one state for some amount of time, 
probability, and in a Markov process, it’s one that depends only on 
the current state. 
179
 So, for example, a table that is currently unoccupied but in need 
of cleaning may stay that way for the next minute, or may become 
a table that is available, or may become a table that is reserved. If 
we analyzed the system from the point of view of a diner, we’d 
the state of pay bill and leave, although other possibilities, such as 
leave without eating, might exist, too.
 A Markov process addresses the following questions: What will be 
the long-term behavior of such systems? How will they evolve over 
such as pay bill and leave—how long will it take to get there? 
 The Markov diagram, in some ways, is an odd cousin of a decision 
in. All of these nodes are like the chance nodes in a decision tree: 
There aren’t any “decisions” for you to make, so each of those 
nodes has a certain probability of transitioning to another state. But, 
unlike decision trees, there may be more than one way of getting to 
the same state. In spite of these differences, though, a path through 
a Markov diagram, like a path through a decision tree, tells a story. 
 Where things get really interesting with Markov analysis is 
when the Markov diagram bends back on itself, making a cycle. 
Conceptually, this means that it’s possible to revisit a state that you 
may have been in before. For example, the restaurant table can 
return to being ready. 
Applying the Markov Process
 Suppose that you run a direct marketing company. You send out 
catalogs once per year. You consider a new and promising customer 
or she slips to segment 2. If the customer doesn’t buy in the second 
year either, he or she slips to segment 3, and you send him or her 
a reactivation package. If the customer still doesn’t buy, you write 
him or her off as not worth it and stop sending him or her catalogs. 
But anytime that customer buys, he or she is back in segment 1. 
180
Le
ct
ur
e 
21
: M
ar
ko
v 
M
od
el
s—
H
ow
 a
 R
an
do
m
 W
al
k 
Ev
ol
ve
s
 Of course, you don’t know whether the customer is going to buy or 
not, but you can get probabilities for his or her actions from historical 
relative frequency data. For example, suppose that 30% of your 
segment 1 customers make an order when they receive a new annual 
catalog. Then, you could say that there’s a 30% probability that a 
segment 1 customer reorders and remains in segment 1. Similarly, 
perhaps 1% of customers are lost per year to death or disconnection, 
so you’d take that as the probability of involuntarily losing a 
customer. We can put all of this into a Markov diagram that describes 
a customer’s possible future relations with your company, as follows.
 We have two terminal nodes where things can end up: lost and 
dropped. In Markov analysis, we’d call these states absorbing states, 
because once you get into one of them, you never get out. But what 
goes on in the rest of the diagram is quite a bit more complicated. 
 The segment 1, 2, and 3 nodes each have a chance of transitioning 
to segment 1—it happens when the customer makes a purchase. 
When the annual catalog is received, there is a 30% chance of a 
purchase from a segment 1 customer, a 12% chance for a segment 2 
customer, and a 6% chance for a segment 3 customer. Each of these 
segments also has a 1% chance of transitioning to lost, because 
Figure 21.1
181
customers in any of these segments are equally likely to die or 
become disconnected. The remaining arrows capture the rest of the 
probability, because the total probability out of any node will equal 
1 in a Markov diagram. 
 It’s pretty clear that, sooner or later, a customer is going to reach an 
absorbing state—that the customer will go three annual catalogs in 
a row without ordering, or become lost. But what’s not clear is how 
long this is going to take. 
 As a marketer, you’re going to want to get a sense of how long you 
get to keep a person as a customer, as well as how many purchases 
you can expect the customer to make in that time. And with Markov 
analysis, we can do just this. First, we turn the Markov diagram into 
a Markov matrix (M), as follows.
 The row indicates the state you are transitioning from, and the 
column indicates the state you are transitioning to. Each row has its 
to a customer in segment 1: a 30% chance of buying from the 
annual catalog and therefore staying in segment 1, a 69% chance of 
not buying and therefore sliding into segment 2, and a 1% chance 
of being lost. 
 The last two rows show that once you’re dropped, you’re dropped, 
and that once you’re lost, you’re lost. That is, if before the transition, 
you’re in the dropped state, then after the transition, you’ll still be 
there, with 100% probability—and so on, forever. That’s why it’s 
called an absorbing state.
Seg1 Seg2 Seg3 Dropped Lost
Seg1 0.30 0.69 0 0 0.01
Seg2 0.12 0 0.87 0 0.01
Seg3 0.06 0 0 0.93 0.01
Dropped 0 0 0 1 0
Lost 0 0 0 0 1
182
Le
ct
ur
e 
21
: M
ar
ko
v 
M
od
el
s—
H
ow
 a
 R
an
do
m
 W
al
k 
Ev
ol
ve
s
 
transition matrix by itself: A year goes by and, then another year 
goes by. M times M, by the rules of matrix multiplication, results in 
the following.
 The top row says that a customer that is currently in segment 1 is 
about three years from now, we multiply this new M2 matrix by M 
to get M3, as follows.
 That is, about 59% of the customers are gone by the third year, 
with about 56% being dropped for not buying catalogs and 3% lost. 
We could continue this way, year by year, to watch how the top 
row of this matrix evolves. To get the next year’s matrix, we just 
multiply the previous year’s matrix by M. Figure 21.2 is a graphical 
representation of the evolution.
 As the graph shows, almost no customer lasts 10 years in this 
model. There is more than a 95% chance of being dropped from 
the mailing list for failing to make a purchase for three consecutive 
years. There’s a 4% chance of being lost. And there’s less than a 1% 
chance of still being active. 
Seg1 Seg2 Seg3 Dropped Lost
Seg1 0.1728 0.207 0.6003 0 0.0199
Seg2 0.0882 0.0828 0 0.8091 0.0199
Seg3 0.018 0.0414 0 0.93 0.0106
Dropped 0 0 0 1 0
Seg1 Seg2 Seg3 Dropped Lost
Seg1 0.112698 0.119232 0.18009 0.558279 0.029701
Seg2 0.036396 0.060858 0.072036 0.8091 0.02161
Seg3 0.010368 0.01242 0.036018 0.93 0.011194
Dropped 0 0 0 1 0
Lost 0 0 0 0 1
183
 There’s another way of interpreting Markov transitions that is 
conceptually different but mathematically identical. We could 
imagine that we are speaking not of one individual but of a large 
population and that the transition probabilities indicate the fraction 
of the population currently in a given state that transitions to 
another state. 
 For example, rather than saying that a segment 1 customer has a 
30% chance of making a purchase, we could say that 30% of 
segment 1 customers make a purchase. From this perspective, our 
graph shows that in 10 years, we lose about 99% our customers, 
and 95% of our customers are dropped for not making an order in 
three consecutive years. 
 One way to address this is to acquire new customers—for example, 
from mailing lists—to replace the customers who are dropped or 
lost. We can modify our Markov diagram to replace all lost and 
dropped customers by changing our lost and dropped states from 
absorbing states into ones that transition back to segment 1. That 
is, each person who is lost or dropped this year is replaced in the 
diagram is as shown in Figure 21.3.
Figure 21.2
184
Le
ct
ur
e 
21
: M
ar
ko
v 
M
od
el
s—
H
ow
 a
 R
an
do
m
 W
al
k 
Ev
ol
ve
s
 The long-term behavior for this diagram is going to be very 
different from the previous one. In a system with one or more 
absorbing states, any non-absorbing state that can ever reach an 
absorbing state is eventually going to be empty. Such eventually 
empty states are called transient states. 
Figure 21.4
Figure 21.3
185
 Our basic approach to solving this problem is to use the transition 
fraction of customers fall in each segment, and use this information 
and other cost and purchase information to determine how often 
mailings should be sent and to whom.
absorbing state: In a Markov system, a state that cannot be left once it 
is entered. 
Markov analysis: A set of techniques for analyzing the behavior of 
systems that can be viewed as occupying one of a number of states, with a 
particular probability of transitioning from one state to another at various 
points in time. 
Markov diagram: A graphical representation of Markov process. Each pure 
state of the system is represented by a node, and each possible transition 
from state to state is indicated with an arrow connecting those nodes. 
transient state: In a Markov system, a state whose long-run probability 
approaches zero regardless of initial conditions. 
transition matrix: In Markov analysis, a matrix whose entries p ij give the 
j given that the system is currently 
in state i. 
Elsner, Krafft, and Huchzermeier, “Optimizing Rhenania’s Mail-Order 
Business through Dynamic Multilevel Modeling (DMLM).”
Important Terms
Suggested Reading
186
Le
ct
ur
e 
21
: M
ar
ko
v 
M
od
el
s—
H
ow
 a
 R
an
do
m
 W
al
k 
Ev
ol
ve
s
1. The same kind of work we did in this lecture can be applied more 
broadly. For example, imagine a species of creature that each year either 
dies or gives birth to a single offspring. That offspring itself will either 
give birth or die in the following year, and so on. We could represent 
this with the following transition matrix.
This is not properly a Markov matrix, because the middle row does not 
add to 1. Instead, the matrix says the following: 20% of infants survive to 
adulthood. Adults have a 45% annual mortality rate. Adults who survive 
have a litter of 6 infants (3.3 = 0.55 × 6). The techniques of the lecture 
can still be applied to a matrix such as this. Because the questions are 
most easily done by looking at high powers of the transition matrix, you 
may want to do them on a spreadsheet. In Excel or Calc, the command 
to multiply two matrices is MMULT.
a)  Show that in 50 years, an initial population of 2 adults grows to a 
population of about 700 adults and their offspring.
b)  Show that if adult survival drops to 45% (for example, from 
overharvesting), the population dies out.
c)  Show that if litter size drops to 4 (for example, from ecological 
damage), the population dies out.
Answers: 
a)  We can take an initial vector of [0 2 0] for 2 adults and then multiply 
it by the M matrix above 50 times. The result is [1952.8 670.3 
14017.8], meaning that we have almost 2000 infants, 670 adults, 
and about 14,000 that have died.
Questions and Comments
infant adult dead
infant 0 0.2 0.8
adult 3.3 0.55 0.45
dead 0 0 1
187
b)  Replacing the second row of the matrix with [2.7 0.45 0.55] and 
repeating the calculations in a) shows this. Note that 2.7 = 6 × 0.45. 
c) Replace the second row with [2.2 0.55 0.45] and repeat part a). 
Moral: Relatively small changes in transition probabilities can have 
huge long-term impacts.
2. One requirement for a Markov process is memorylessness. That is, 
where you go next in the Markov diagram depends only on chance and 
where you are now, not on how you got there. Think of processes for 
which this requirement is met, and ones in which it is not.
Answer: 
Winnings on a slot machine is a memoryless process, as is radioactive 
decay. Many real-life events, such as arrivals at a grocery store, are 
close to memoryless. Human interaction with strangers is generally 
memoryless, but with the same individual, it is not. The history of 
previous interaction with an individual usually changes the probabilities 
of what happens next.
188
Le
ct
ur
e 
22
: Q
ue
ui
ng
—
W
hy
 W
ai
tin
g 
Li
ne
s 
W
or
k 
or
 F
ai
l
Queuing—Why Waiting Lines Work or Fail
Lecture 22
For something that, for the most part, consists of doing nothing, waiting is surprisingly unpleasant. When people have to wait in line, it’s annoying and a waste of time; when products wait in line, 
it’s costly. Either way, it’s undesirable. But it turns out that the behavior 
of waiting lines—of queues—is subject to mathematical analysis. Queuing 
theory allows us to characterize the behavior of such queuing systems and 
provides us with some ideas about how to make them work better. This 
lecture will approach queuing theory from the perspective of Markov 
analysis, meaning that we will ignore everything about the past, except the 
current state of things.
Queuing Theory
 Suppose that you offer online computer services to customers, and 
doing so requires that you have two mainframe computers online 
at all times. When both machines are online, you’re in business, 
and you generate a revenue of $6000 per day. Computers will go 
down from time to time, of course, but for the moment, let’s say 
that you’re taking that risk. Your data shows that, on average, a 
computer breaks about once every 6.5 months—once every 
200 days. 
 When one breaks, your income stream stops with it. In fact, it’s 
worse than that. Your clients are making critical transactions, and 
if they can’t rely on your service, they leave. You estimate a loss of 
$28,000 for every day that the system is down. 
 For a big mainframe, it takes an average of 4 days to get a computer 
that fails back online. Online or not, a mainframe computer costs 
you $1000 per day, and if it’s broken, the repairs cost $1000 per 
day on top of that. And the repair team can only work on one down 
computer at a time. 
189
 So, your business is okay if it’s not down too often. The following 
is a Markov diagram for your situation. It has only three states, 
depending on how many computers are up and running.
 In this diagram, each transition represents one day. The number 
in the middle of a circle indicates how many computers are up 
and running on a given day, and the arrows show the possible 
repaired, then it will on average take 4 days to repair it. Having 
the same chance of repair each day leads to what statisticians call 
a geometric distribution, and it’s what you get out of this kind of 
discrete Markov process.
 
200 days. When two computers are working, the chance of a 
computer breaking doubles, to two in 200. 
 Technically, there are some small errors in this model, because both 
computers could possibly break on the same day, or one computer 
could break on the same day that the other returns to service. The 
chance of these events occurring is very small, though.
Figure 22.1
190
Le
ct
ur
e 
22
: Q
ue
ui
ng
—
W
hy
 W
ai
tin
g 
Li
ne
s 
W
or
k 
or
 F
ai
l
 If nothing breaks or is repaired on a given day, the system loops 
back to the same state that it had at the beginning of the day. 
Sensibly enough, the total probability leaving each state is 1, which 
is how we found the probability for looping.
 This is indeed a queuing model, although it’s probably not what you 
normally think of when you think about waiting lines. In this case, 
the “customers in line” are machines waiting to be repaired, and 
the entire population of potential customers consists of only two 
individuals.
 We can analyze this queuing system using Markov analysis. The 
system is ergodic—you can verify that you can move from any 
state in the picture to any other state in exactly 4 transitions—and 
that means that, in the long run, the system is characterized by its 
steady state vector. Using the techniques from Markov analysis, 
.
 This means that your system is up with both computers online 
about 96% of the time, and at least one is down about 4% of the 
value calculation: probability times payoff for each possibility, 
added together. In this case, 96% of the time, you make $4000 per 
day—that’s $6000 revenue minus $2000 in operating expenses. The 
remaining 4% of the time you lose $30,000 per day, because you’re 
losing customers, paying for machines, and making repairs. On 
 This is not bad, but it’s quite a bit less than the $4000 per day 
you’d be making if your machines never went down. The sizeable 
is strongly affected by waiting; not having two computers online 
really costs you. 
0 1 2
Start 0.00077 0.03843 0.96080[ [
191
 
Figure 22.2
So, is it worthwhile to have a backup computer? The bad part of the 
idea is that it’s going to cost you an extra $1000 per day for another 
computer. The good part is that you could have one computer fail 
and still not hurt your business. Is the increased reliability worth the 
cost of providing it?
 Let’s modify the previous Markov diagram and add the new 
machine. We add one more state for having three machines in 
operation, with one of them on standby. 
 Either of the two active machines might fail when we’re in this 
assuming that the machine that is only on standby can’t fail. On the 
other hand, if a machine is broken, there is a 25% chance it’ll be 
192
Le
ct
ur
e 
22
: Q
ue
ui
ng
—
W
hy
 W
ai
tin
g 
Li
ne
s 
W
or
k 
or
 F
ai
l
two functioning machines to three. The steady state vector for this 
Markov system is as follows.
 Now, like before, the system incurs customer dissatisfaction if fewer 
than two machines are in operation. But, now, that only happens 
0.16% of the time. Even taking into account the cost of the backup 
to $2667 without the backup. That translates to an extra $100,000 
per year for you and happier customers—a win-win situation. So, 
queuing theory recommends getting the backup. 
 We have to address one weakness in our analysis. We’ve been 
assuming that each transition represents one day. That is, we 
assumed that each day, at most one thing could happen. But, of 
course, we could have two machines breaking on the same day or 
a repair and breakdown on the same day. Then again, every repair 
took a whole number of days—we never got the system back online 
in, for example, 16 hours. But in real life, we could. 
 It’s easy to address these issues by moving from a discrete Markov 
process, such as the one we’ve been using so far, to a continuous 
Markov process. In fact, most of queuing theory is done in this 
continuous process way. We just make a transition represent what 
happens during a very brief interval of time, of length dt. Our 
original problem without a backup, for example, would look like 
the diagram in Figure 22.3.
 There’s not much difference between this picture and the earlier 
one, other than the addition of the dt terms. The diagram really just 
carries forward with the argument we made for daily transitions. 
0 1 2 3
Start 0.00003 0.00154 0.03840 0.96003[ [
193
 
Figure 22.3
We said that if the average time for a computer repair is 4 days, then 
on any given day, there is 1 chance in 4 that a broken computer will 
a quarter of a day, and so on. In general, during a tiny fraction dt of 
dt.
 In the limit as dt approaches 0, this picture then describes a 
continuous process, where transitions can occur at any time. The 
continuous model gives the same steady state as the discrete one 
does. And, again, the Markov model is assuming that the chance of 
transition out of a state during an interval doesn’t depend on how long 
it’s already been in that state. That is, the process is memoryless.
 Whether we use the discrete or continuous model, this system is 
going to approach the same steady state in the long run, but with 
the continuous model we no longer have the concern of two events 
occurring at the same time. With dt small enough, each transition 
is a very brief span of time. The chance of a repair or a breakdown 
occurring during a single transition is quite small, but the chance of 
more than one occurring during the same interval is so small as to 
be negligible. 
194
Le
ct
ur
e 
22
: Q
ue
ui
ng
—
W
hy
 W
ai
tin
g 
Li
ne
s 
W
or
k 
or
 F
ai
l
 When you think about a waiting line, you probably imagine people 
standing in a line, perhaps a very large number of them. And the size 
of the calling population—the people that could enter the queue—
is much larger than the queue length that we generally observe. 
 When the calling units are people, the solution isn’t always found 
in mathematics. Psychological factors play an important role. 
Waiting feels longer when you’re unoccupied. That’s why there 
are often mirrors near elevators. That’s also why the Disney parks 
always give you something new to look at as you wait for a ride.
 Understanding human psychology can make queues less painful to 
the people in them. And, even better, understanding the mathematics 
production and service. 
 Queuing theory isn’t an optimization technique. It doesn’t tell 
you the best thing to do. But it does allow you to consider the 
consequences of various possible choices, and then you can see what 
options look most attractive. Playing around with queuing models 
can reveal many nonintuitive solutions to practical problems. 
calling units: General term applied to those individuals or objects that make 
use of a queuing system. 
ergodic: A Markov system is ergodic if there exists some n such that, for any 
two pure states i and j, it is possible to move from state i to state j in exactly 
n transitions. 
memoryless: A process where the probability of reaching a particular state 
after the passage of so much time depends only on the current state and not 
on the events that led to that state. Rolling a die is memoryless. 
Important Terms
195
queue: Waiting line. The study of waiting lines is called queuing theory. 
Technically, the queue does not include any calling units that are currently in 
service, only those waiting for service to begin. 
steady state vector: In Markov analysis, a state vector that is unchanged 
by the application of the transition matrix. A Markov system that reaches a 
steady state vector will never move from it. 
system, queuing: All of the calling units either currently under service or in 
the queue are considered to be in the system. 
Ragsdale, Spreadsheet Modeling & Decision Analysis.
Stevenson, “What You Hate Most about Waiting in Line.”
Winston and Albright, Practical Management Science.
1. This lecture focused on the steady state of a queuing system, and the 
equations most often presented for queuing systems are for their steady 
be the most appropriate? When would we be more concerned about the 
transient behavior of the system?
Answer: 
It’s an appropriate model when we are interested in the long-term 
behavior of the system when the conditions are not changing rapidly, 
it’s the transient behavior you care about when you want to know how 
the parking lot.
Suggested Reading
Questions and Comments
196
Le
ct
ur
e 
22
: Q
ue
ui
ng
—
W
hy
 W
ai
tin
g 
Li
ne
s 
W
or
k 
or
 F
ai
l
2. Imagine two different single-server queuing systems that have identical 
input streams of calling units but with different mean service rates. 
You’d expect that, on average, customers with the faster server would 
spend less time in the system. But this may not be so. The inversion 
occurs when the slower server is steady, with a constant or near-constant 
service times. Provide a persuasive argument as to why this could be so.
Answer: 
It’s an extension of why we still see waits, even when average service 
worker sometimes will be much faster than average—sometimes much 
slower. When he or she is fast, the queue may empty, leaving the worker 
with nothing to do and wasting his or her faster rate. When he or she is 
slow, he or she creates a huge backlog, and the resulting waiting times 
for the people waiting to be served grow accordingly.
197
Monte Carlo Simulation for a Better Job Bid
Lecture 23
In this lecture, you will learn about simulation. With simulation, we numerically model the relationships between the important parts of the problem: the decisions that we control and the random events that we 
don’t. It’s often called a Monte Carlo simulation, a name that comes from 
the famous casino in Monte Carlo, Monaco. We generate random values for 
the random variables in our problem and then see how a proposed strategy 
works when faced with these random events. The technique is remarkably 
powerful and versatile, making it, like linear programming, one of the most 
widely used techniques in operations research. 
Simulation
 Suppose that you’re a construction contractor who is bidding on a 
construction job. It’s a competitive bid, so your success is going 
to be dependent on your ability to determine, with reasonable 
accuracy, what completing the job is going to cost. You have 
enough experience with jobs like this that you can model its 
different activities pretty well.
 Preparing a bid will cost you $5000, win or lose. If you actually 
land the job, you’ll have other costs: materials, labor, and possible 
late fees if your work gets behind schedule. But, of course, with the 
winning bid, you’ll get paid for your efforts.
 So, what should you bid? Bid too high and you have little chance 
of getting the job, not to mention losing the $5000 prep fee. Bid too 
low and you’ll get the job, but you may be sorry that you did. Your 
going to use simulation to get a handle on what those expenses 
might be.
198
Le
ct
ur
e 
23
: M
on
te
 C
ar
lo
 S
im
ul
at
io
n 
fo
r a
 B
et
te
r J
ob
 B
id
 To begin, we’re not going to worry about how to handle the 
randomness—we’ll just put in average values, and then make them 
stochastic in a second pass through the model. So, let’s work out the 
cost of completing the job by using a Calc spreadsheet. 
 
from job to job, but for now we’ll use the average of similar jobs in 
the past, $60,000. 
 Next comes labor cost and late penalty—but the labor cost depends 
on how many weeks of labor we need, and the penalty depends on 
these random quantities for now: 9 weeks of labor and 2 weeks of 
delay. There are a few extra columns, too, for things that we’ll need 
 Your laborers get paid by the week: $700 per person for each week 
of work. You currently have 4 workers. So, your labor cost will be 
given by the following formula: 2800 times the number of labor 
weeks needed.
A B C D E F G H
1 Simulation 1: Actual Job Cost
2
3 Prep cost Materials cost
Labor 
weeks 
needed
Labor 
cost
Weeks 
delay
Job 
complete 
in week #
Completion 
penalty Total cost
4 $5000 $60,000 9 2
Figure 23.1
A B C D E F G H
1 Simulation 1: Actual Job Cost
2
3 Prep cost Materials cost
Labor 
weeks 
needed
Labor 
cost
Weeks 
delay
Job 
complete 
in week #
Completion 
penalty Total cost
4 $5000 $60,000 9 =2800*C4 2
Figure 23.2
199
 Labor weeks needed was in cell C4, so the formula for labor cost is 
2800 times C4. Every formula in a spreadsheet starts with an equal 
sign, and the asterisk means multiplication. (If you’re using Excel 
rather than Calc, all semicolons become commas in Excel.) When 
we enter this in the spreadsheet, it computes the value: $25,200. 
 When is the job done? To get completion time, take the labor time 
and add the delay time.
 With our current numbers, that’s 11. Next, we have to deal with 
the completion penalty. Part of the contract for this job is that it 
penalty of $12,000 
for every week that 
you’re over the 
limit. Again, we 
need a formula. One 
way to get it is an IF 
statement, as shown 
in Figure 23.4.
 
write the second thing; otherwise, write the third thing. So, in this 
case, it says: If cell F4—the job completion time—is less than or 
equal to 12, then write 0 (no penalty); otherwise, write the penalty 
A B C D E F G H
1 Simulation 1: Actual Job Cost
2
3 Prep cost Materials cost
Labor 
weeks 
needed
Labor 
cost
Weeks 
delay
Job 
complete 
in week #
Completion 
penalty Total cost
4 $5000 $60,000 9 $25,200 2 =C4+E4
Figure 23.3
F G H
1
2
3
Job 
complete 
in week #
Completion penalty Total cost
4 11 =IF(F4<=12; 0; 12000*(F4 12))
Figure 23.4
200
Le
ct
ur
e 
23
: M
on
te
 C
ar
lo
 S
im
ul
at
io
n 
fo
r a
 B
et
te
r J
ob
 B
id
 When we enter this formula, we get a late penalty of 0 this time, 
because our job was done in week 11. All that’s left is to add up 
the costs.
 This comes out to $90,200. And that’s our model for how much the 
job will actually cost.
 But this model is deterministic. We still have to put in the 
randomness—for materials cost, labor time needed, and delay time.
 The materials for the construction on a job like this average $60,000, 
but there’s a fair amount of variation in this. Looking at similar jobs 
in the past, you decide that the cost of materials is approximately as 
shown in Figure 23.7.
 This picture is called the probability density function of this 
random variable. It shows that costs that are close to $60,000 
are common and that the farther you get from $60,000, the less 
common that cost is. In statistics, a bell-shaped curve like this is 
called a normal distribution. This one has a mean of $60,000. Its 
spread, as measured by standard deviation, is $4000.
A B C D E F G H
1 Simulation 1: Actual Job Cost
2
3 Prep cost Materials cost
Labor 
weeks 
needed
Labor 
cost
Weeks 
delay
Job 
complete 
in week #
Completion 
penalty Total cost
4 $5000 $60,000 9 $25,200 2 11 $ - =A4+B4+D4+G4
Figure 23.5
A B C D E F G H
1 Simulation 1: Actual Job Cost
2
3 Prep cost Materials cost
Labor 
weeks 
needed
Labor 
cost
Weeks 
delay
Job 
complete 
in week #
Completion 
penalty Total cost
4 $5000 $60,000 9 $25,200 2 11 $ - $90,200
Figure 23.6
201
 We need to generate random materials costs for our model. If you’re 
using a simulation add-in to your spreadsheet (such as Analytic 
Solver, Crystal Ball, or @Risk), there are straightforward ways to 
get this, but for Excel and Calc, we are going to introduce a formula 
that gets the job done. For our normally distributed materials cost 
with a mean of $60,000 and a standard deviation of $4000, we can 
generate values by using the following.
=NORMINV(RAND(); 60000; 4000)
 Every time you enter something new anywhere in 
the spreadsheet, the sheet calculates a new value 
of RAND in this cell, and that means you’re 
going to get a new value for your materials cost. 
 
the number of weeks required to complete the 
project is uncertain. The following is a table of 
possible times and their probabilities. The table 
deals with a discrete random variable. It can take 
Figure 23.7
Labor completion 
time with  
4 workers
Weeks Prob.
7 0.1
8 0.3
9 0.3
10 0.1
11 0.05
12 0.07
13 0.08
Figure 23.8
202
Le
ct
ur
e 
23
: M
on
te
 C
ar
lo
 S
im
ul
at
io
n 
fo
r a
 B
et
te
r J
ob
 B
id
 How do we get this to work in our spreadsheet? If we’re not using 
the spreadsheet and, to its 
left, add a range of values 
for each row, as shown in 
Figure 23.9.
 The =RAND() function 
always returns a value 
between 0 and 1, and all 
values in that range are 
equally likely. 
 To get Excel or Calc to 
follow this rule, we use a 
command called VLOOKUP (”vertical lookup”). It uses the table 
we just made. The command will look like the following.
 
is going to be random. The second argument tells us where in the 
spreadsheet this 4-column table is, by specifying its upper-left and 
lower-right corners. 
A B C D
13 Labor completion 
time with  
4 workers14
15
RAND() 
from…
RAND() 
up to… Weeks Prob.
16 0 0.1 7 0.1
17 0.1 0.4 8 0.3
18 0.4 0.7 9 0.3
19 0.7 0.8 10 0.1
20 0.8 0.85 11 0.05
21 0.85 0.92 12 0.07
22 0.92 1 13 0.08
Figure 23.9
A B C D
13 Labor completion 
time with  
4 workers14
15
RAND() 
from…
RAND() 
up to… Weeks Prob.
16 0 0.1 7 0.1
17 0.1 0.4 8 0.3
18 0.4 0.7 9 0.3
19 0.7 0.8 10 0.1
20 0.8 0.85 11 0.05
21 0.85 0.92 12 0.07
22 0.92 1 13 0.08
23 Labor time =VLOOKUP(RAND(); A16:D22; 3)
Figure 23.10
203
 
the information that we want. In this case, it’s the third column of 
the table, which contains the number of weeks of labor.
 This is the formula that goes in the weeks of labor cell in our 
spreadsheet. In a parallel fashion, we’ll set up a table that tells us 
how many weeks of delay we have. The following is 
our simulation.
 Every time the spreadsheet recalculates, the cost will change, 
because we’ll have different random numbers. You can force the 
spreadsheet to do this by pressing the F9 key. By doing this, it 
becomes apparent that it’s not rare to have a late penalty and that 
they can be expensive. We also get some idea of what variation we 
can expect in job cost.
 What we want the spreadsheet to do is to repeat the simulation 
many times—just as we can do by pressing the F9 key—but to 
record the result of each trial. Once again, simulation add-ins will 
do this automatically. 
A B C D E F G H I
8 Simulation 1: Actual Job Cost
9
10
Prep 
cost
Materials 
cost
Labor 
weeks 
needed
Labor 
cost
Weeks 
delay
Job 
complete 
in week #
Completion 
penalty
Total 
cost
11 $5000 $60,000 9 $25,200 2 11 $ - $90,200
12
13 Labor completion 
time with  
4 workers
Weeks of delay
14
15
RAND() 
from…
RAND() 
up to… Weeks Prob.
RAND() 
from…
RAND() 
up to… Weeks Prob.
16 0 0.1 7 0.1 0 0.51 1 0.51
17 0.1 0.4 8 0.3 0.51 0.77 2 0.26
18 0.4 0.7 9 0.3 0.77 0.9 3 0.13
19 0.7 0.8 10 0.1 0.9 0.96 4 0.06
20 0.8 0.85 11 0.05 0.96 0.99 5 0.03
21 0.85 0.92 12 0.07 0.99 1 6 0.01
22 0.92 1 13 0.08
Figure 23.11
204
Le
ct
ur
e 
23
: M
on
te
 C
ar
lo
 S
im
ul
at
io
n 
fo
r a
 B
et
te
r J
ob
 B
id
 The results give the values 
15 simulation runs. We 
commanded the spreadsheet to 
repeat our situation 1000 times 
and to record the values of these 
three quantities in each trial.
 We can use the functions MAX, 
biggest, average, and smallest 
values of each variable. The 
following is what we get for the 
three variables we are tracking.
 
spreadsheet; every recalculation generates new random numbers. 
But the results over 1000 runs are pretty stable. Total costs average 
about $98,000, but the range is quite wide—from around $75,000 to 
over $190,000. 
 Even though the average cost of a job is just over $98,000, over 5% of 
the time the cost is $130,000 or more, and costs of $120,000 or more 
this is something to keep in mind, because a bid of $120,000 on a job 
like this, even if accepted, will actually lose you money 1 time in 8. 
 Why is this happening? Anything over 12 weeks starts the late fee 
clock, and at $12,000 per week, those fees can quickly eat up your 
but it can go as high as $72,000.
Summary of 1000 trials
Job duration Penalty Total cost
Maximum 19 $ 84,000 $ 121,064
Mean 11.249 $ 6,960 $ 86,783
Minimum 8 $ - $ 105,525
Figure 23.13
Trial Job duration Penalty Total cost
1 13 $ 12,000 $ 121,064
2 10 $ - $ 86,783
3 13 $ 12,000 $ 105,525
4 13 $ 12,000 $ 100,551
5 14 $ 24,000 $ 130,529
6 10 $ - $ 79,923
7 15 $ 36,000 $ 134,784
8 10 $ - $ 81,127
9 13 $ 12,000 $ 110,290
10 9 $ - $ 90,962
11 15 $ 36,000 $ 129,195
12 10 $ - $ 91,488
13 11 $ - $ 93,666
14 15 $ 36,000 $ 143,968
15 10 $ - $ 89,033
Figure 23.12
205
What-If Analysis
 One of the wonderful things of the analytic approach in general 
and of simulation in particular is what-if analysis. A simulation can 
allow you to explore the impacts of changes in your situation. In 
this case, it’s going to help us get a grip on our bottom line.
 In order to prepare for this, we have to modify our simulation 
model. One of the precepts of good modeling, particularly in a 
spreadsheet environment, is that if there is a constant in your 
problem—a number—it deserves its own cell in your spreadsheet. 
Then, whenever you want to use that number in a formula, the 
formula should refer to that cell rather than containing the number 
A B C D E F G H I
1 Parameters
2
3 Materials cost Late penalty Labor
4 Mean $60,000 Weeks allowed 12 # of workers 4
5
Standard 
deviation $4000
Penalty 
per week $12,000
Cost/
worker/
week
$700
6
7
8 Simulation 1: Actual Job Cost
9
10
Prep 
cost
Materials 
cost
Labor 
weeks 
needed
Labor 
cost
Weeks 
delay
Job 
complete 
in week #
Completion 
penalty Total cost
11 $5000 $60,000 13 $36,400 2 15 $36,000 $137,400
12
13 Labor completion 
time with  
4 workers
Weeks of delay
14
15
RAND() 
from…
RAND() 
up to… Weeks Prob.
RAND() 
from…
RAND() 
up to… Weeks Prob.
16 0 0.1 7 0.1 0 0.51 1 0.51
17 0.1 0.4 8 0.3 0.51 0.77 2 0.26
18 0.4 0.7 9 0.3 0.77 0.9 3 0.13
19 0.7 0.8 10 0.1 0.9 0.96 4 0.06
20 0.8 0.85 11 0.05 0.96 0.99 5 0.03
21 0.85 0.92 12 0.07 0.99 1 6 0.01
22 0.92 1 13 0.08
Figure 23.14
206
Le
ct
ur
e 
23
: M
on
te
 C
ar
lo
 S
im
ul
at
io
n 
fo
r a
 B
et
te
r J
ob
 B
id
itself. This allows you to change one number in your spreadsheet 
and have the effects of that change percolate throughout everything 
on the sheet. (See Figure 23.14.)
 This is essentially the same simulation we had before, but now 
everywhere we had a number, such as 12, we replace it with the 
name of the cell that contains that “12” in our parameters section. 
We ended up with six parameters.
 There is one change to be made in our simulation. We’ve now made 
the number of workers an explicit parameter in the problem, but the 
table for the labor time is written with the assumption of 4 laborers. 
How long does the job take when we change the number of laborers?
 We can answer this by looking at the labor requirement not in 
weeks, but in man-weeks. A man-week is the amount of work that 
one man—or woman—can do in a week. So, if 4 people working 
on a job can do it in 5 weeks, it takes 4 × 5, or 20, man-weeks. It 
could have been done by 5 people working for 4 weeks instead or 
10 people working for 2 weeks. 
 
of man-hours implied by our 4-worker table. That just means 
multiplying the time given in the table by 4. Then, we’ll divide that 
need for the job. Finally, we’ll round that up to the next whole 
number, because workers get paid by the week, or fractions thereof.
 The old formula for labor time was the following.
=VLOOKUP(RAND(); A16:D22; 3)
 The new one is as follows.
207
 Start with the old formula for how many weeks it takes 4 workers 
job. Then, divide that by how many workers we have. That’s in cell 
I4. Finally, round the result up to the next whole number. The zero 
at the end tells Calc to round to zero decimal places—that is, to a 
whole number.
 We’ll also modify the labor cost to say that even if the job is done 
in less than 5 weeks, the workers still have to be paid for 5 weeks 
of labor. In the following, I4 is the number of labors, I5 is what we 
pay each per week, and C11 is the number of weeks of labor that we 
need. If it’s less than 5, we still pay for 5.
=MAX(C11,5)*I4*I5
 More workers should be able to get the job done faster, cutting 
down on late penalties. On the other hand, you have to pay them. 
But because the job is completed faster, you don’t have to pay them 
for as long. The following shows what happens to total cost as we 
change the number of workers.
Figure 23.15
208
Le
ct
ur
e 
23
: M
on
te
 C
ar
lo
 S
im
ul
at
io
n 
fo
r a
 B
et
te
r J
ob
 B
id
 
number of workers, and we see that we can save some money, on 
average, by hiring more. Six seems to be the best number, saving us 
about $4000 on average, even though we need to pay more workers. 
 The vertical bars show the maximum and minimum costs in 
the 1000 simulated trials. With 8 workers—twice the original 
complement—the average price is about $2000 dollars cheaper 
than its original value, but the job price never rose above $115,000. 
The job is 99.9% likely to be completed on time—a fact you can 
use in negotiating with the customer. In fact, it’s usually done by 
the sixth week.
random variable: A measurable quantity, often numeric, associated with the 
outcome of a stochastic experiment.
Ragsdale, Spreadsheet Modeling & Decision Analysis.
1. It’s possible to model a queuing system by either using the queuing 
equations discussed in the previous lecture or simulation techniques, as 
discussed in this one. What are the relative advantages and disadvantages 
of the two approaches?
Important Term
Suggested Reading
Online Instructions for Creating Simulation Data Tables
Questions and Comments
209
Answer: 
The queuing models have fairly strong assumptions. If these assumptions 
are violated by a substantial amount, the model is inappropriate. Our 
queuing work also focused on long-term behavior only, and our 
equations, for the large part, reported only expected values. Simulation 
allows us to handle different model assumptions, to investigate transient 
behavior as well as steady state behavior, and to see the range of possible 
outcomes—not just the mean.
On the other hand, if the queuing equations apply to a question at hand, 
then they are faster to apply than a simulation model. Because they do 
not involve taking random samples, they are also not subject to sampling 
error in their answers. Finally, their explicit functional form allows one 
to use calculus or similar tools to investigate how the system’s behavior 
changes as its parameters change.
2. Our simulation in this lecture is a nice demonstration of what is 
the average value of an output by computing its value for the average 
values of its inputs. In our model, the average number of weeks of labor 
required for the job is 9.23, and the average delay time is 1.87 weeks. 
That means that the average time to job completion is 11.1 weeks, 
which is under our 12-week deadline. Such people conclude that they 
don’t have to worry about late penalties—when the reality, as seen in 
the lecture, is that the average late fee is almost $7000.
210
Le
ct
ur
e 
24
: S
to
ch
as
tic
 O
pt
im
iz
at
io
n 
an
d 
R
is
k
Stochastic Optimization and Risk
Lecture 24
Tcoupling the stochastic work that we’ve done in recent lectures with the optimization work from the middle of the course. The result is 
constitutes “best.” In this lecture, you will use your entire mathematical 
Stochastic Optimization 
 Getting a handle on our costs with the work we did in the previous 
lecture is only part of the problem. You still have to make your 
bid, and you have two competitors who are hoping to get the job 
for themselves. Let’s call them Fred and Wilma. Up to this point, 
the three of you have each used teams of 4 laborers and the same 
suppliers, so you’ve faced the same cost curves. Given your new 
understanding of the economics of the kind of jobs you generally 
do, though, you now have an ace up your sleeve. Assuming that you 
get the job, you’re going to use 8 workers. They’ll stick with 4.
 To make a bid, each of you is going to estimate what you think the 
job will cost you and then add to that a certain percent markup, 
each of you routinely decides on a 40% markup. 
 The real question that we’re trying to answer is how much you 
should bid. Your goal in bidding will be to maximize your average 
losing too much money. 
211
 In rough terms, we need to run a simulation with a set of input values, 
look at the results, use that information to make changes to the input 
variables, examine the new results to see whether the changes were 
in the direction that we desired, and continue this way until we 
narrow in on an optimal solution. This is stochastic optimization.
 It’s now possible to do problems like this in a spreadsheet 
environment with a surprisingly small amount of work—on the 
part of the human, at least. The kind of work that we’ll be doing 
can be accomplished by augmenting Excel with add-ins, such as 
Analytic Solver, Crystal Ball, or @Risk. It’s surprising how quickly 
formulated the problem. You still have to get to the superhighway.
 Let’s modify the simulation that we wrote for costing the 
A B C D E F G H I
1 Parameters
2
3 Materials cost (normal) Weeks of delay Labor  completion time
4 Mean $60,000 Weeks Prob. Weeks Prob.
5
Standard 
deviation $4000 1 0.51 7 0.1
6 2 0.26 8 0.3
7 Late penalty 3 0.13 9 0.3
8
Weeks 
allowed 12 4 0.06 10 0.1
9
Penalty 
per week $12,000 5 0.03 11 0.05
10 6 0.01 12 0.07
11 13 0.08
12 Labor Bidding Behavior
13 You Fred Wilma You Fred Wilma
14
# of 
workers 6 4 4 % markup 40% 40% 40%
15
Cost/
worker/
week
$700 $700 $700 Never bid below $0 $0 $120,000
Figure 24.1
212
Le
ct
ur
e 
24
: S
to
ch
as
tic
 O
pt
im
iz
at
io
n 
an
d 
R
is
k
 We’ve rearranged things a bit, but the same information is there: 
the distribution of materials costs, the late penalty information, the 
probability distributions for delay time and labor requirements, 
and information about the workers and their cost. We’ve added 
similar labor parameters for Fred and Wilma, who are only using 
4 workers each. 
 In the lower-right corner, we’ve added a section about how each of 
you price the job, based on your estimate of what you think it would 
cost you to complete it. This section allows you to specify not only 
what markup you want on the job but also to set a minimum bid for 
any job in order to limit downside risk. Currently, only Wilma is 
using this option.
 
the tables that you see in the upper-right corner with two more 
columns, specifying what ranges of random numbers corresponded 
to each output. Those RAND() columns are no longer necessary, 
nor is using RAND() or VLOOKUP. Any simulation add-in will 
include pull-down menus for all of the common distributions. 
 The cost simulation itself looks very much like what we had before, 
only this time there are three copies of the original simulation, one 
for each contractor.
Actual Job Cost (You)
Prep cost Materials cost
Labor weeks 
needed
Labor 
cost
Weeks 
delay
Job complete 
in week #
Completion 
penalty Total cost
$5000 $60,059 4 $28,000 1 5 $ - $93,059 
Actual Job Cost (Fred)
Prep cost Materials cost
Labor weeks 
needed
Labor 
cost
Weeks 
delay
Job complete 
in week #
Completion 
penalty Total cost
$5000 $60,059 8 $22,400 1 9 $ - $87,459 
Actual Job Cost (Wilma)
Prep cost Materials cost
Labor weeks 
needed
Labor 
cost
Weeks 
delay
Job complete 
in week #
Completion 
penalty Total cost
$5000 $60,059 8 $22,400 1 9 $ - $87,459
Figure 24.2
213
 We want to simulate the bidding. But a person’s bid is based on his 
or her estimate of the actual job cost. We have to model the accuracy 
of those estimates. With an add-in, we can take our historic data and 
 Suppose that we look at the percent error in the last 100 jobs that 
graph. You’ve been close to right on average—the balance point of 
the bars is very close to 0% error—but there’s some spread, high 
and low. The spreadsheet, with the add-in, can automatically 
compare this data to a host of different theoretical probability 
distributions to choose from, ranked from best to worst, according 
the best is shown as a curve over the bars.
 The software picked a shifted Weibull distribution, which provides 
the graph and a variety of statistical charts and measures to assess 
case, everything checks out. 
Figure 24.3
214
Le
ct
ur
e 
24
: S
to
ch
as
tic
 O
pt
im
iz
at
io
n 
an
d 
R
is
k
 Once we approve this choice for the distribution, we click the 
cell in our simulation that’s going to contain your estimate error. 
Thereafter, each time the sheet updates, it will automatically 
compute a new error for your estimate, drawn from this Weibull 
distribution. 
 Because we don’t have data on the accuracy of the bids of your 
competitors, we’ll run with the assumption that their errors are 
distributed the same way that yours are. But your estimates are 
independent, so each contractor get his or her own random variable.
 The new part of the model will look like the following.
 
that capture the errors in pricing. In the trial shown, you 
overestimated the cost of the project while Fred and Wilma priced it 
below the actual cost.
 Now we can compute what each person actually bids. Let’s walk 
through the logic for Wilma. The same reasoning will apply for you 
and Fred. For the current trial, Wilma’s actual cost ends up at about 
$87,500—but, of course, she doesn’t know that. What happens?
 Her error shows that she underpriced the job by about 13%, which 
means that her estimate is only 87% of the actual job cost, which 
is about $76,300. Now she applies her markup. She wants a 40% 
markup, according to our parameters section, so she multiplies her 
estimate by 140%, or 1.4. This gives her bid, about $107,000. 
Simulation 2
Job cost estimates errors Bids Winner
You Fred Wilma You Fred Wilma Fred -$500010.80% $144,357 $114,842 $120,000
Figure 24.4
215
 However, Wilma had a minimum bid of $120,000 as a hedge 
against downside risk. She’ll use either the bid she just computed or 
$120,000, whichever is larger. In this case, because $107,000 is less 
than $120,000, she bids $120,000, as shown in the table.
 In general, Wilma’s bid is calculated by the following formula.
 Her intended bid is the job cost adjusted for her error and then 
increased by her markup percentage. And she’ll bid that or her 
minimum bid value, whichever one’s higher. An equivalent formula 
is entered for you and for Fred. (See Figure 24.4.)
 What happened in the trial? Fred was the low bidder at about 
$115,000, so he gets the job—and actually makes about $27,000 in 
the process. Because you didn’t get the job, you are out the $5000 
prep fee. But this is only one trial. Every time we hit the F4 key, we 
get another simulation. 
 Next, we would simulate the situation thousands of times, and 
then collect and summarize the results. But with an add-in, we 
can just tell the spreadsheet what cells we want to keep track 
of, and then clicking on them automatically provides us with 
interactive graphics. It also computes many summary statistics on 
this distribution, such as the mean cost of the job, which is about 
 
You’re going for a 40% markup, and 40% on a job that costs nearly 
only about 9%. 
MAX min. bid, actual cost * 1 percent error on estimate * 1 markup percentage
Wilma’s intended bid
  
( )( ) ( ) ( )= + +
216
Le
ct
ur
e 
24
: S
to
ch
as
tic
 O
pt
im
iz
at
io
n 
an
d 
R
is
k
 
your payoff when you don’t get the job, which is happening about 
when you lose $5000. 
 Interestingly, that’s not all that’s going on. To see the rest of it, let’s 
temporarily reduce everyone’s prep fee to 0 and make it so that 
people are going to use a 0% markup and bid exactly what they 
think the job is worth. 
 If people never made a mistake in estimating the job’s cost, the 
whole thing would be a breakeven proposition. So, get the job or 
not, we should break even on average. However, when we change 
the sheet’s parameters to give a prep fee of 0 and a 0% markup 
for each contractor, the sheet reports that you don’t break even. On 
average, you lose over $2000. If you check Fred and Wilma, you’ll 
see similar results.
Figure 24.5
217
 This is called the winner’s curse, and it arises anytime people are 
bidding on something whose true value they don’t quite know. It’s 
true that your bid, while sometimes high and sometimes low, is right 
on average. In the trial on the screen, you got the job, because you 
had the low bid. But you had the low bid because you estimated the 
job at almost 14% under its actual cost. As a result, you won. And 
in winning, you lost—over $15,000. So, you have to shade your 
bid, accounting for the winner’s curse. 
 Let’s put back the prep fees and restore our 40% markups for 
each bidder. 
 Your current problem is that you aren’t making enough money 
because you aren’t getting the job often enough. What if you slash 
your markup and play with your minimum bid value? Given that 
the other two contractors are behaving as we’ve described, what’s 
the best thing for you to do?
 One approach would be to plug in a bunch of different values in 
place of our 40% markup and see what happens to our average 
make it possible to do this very easily. You specify the values that 
you want and the spreadsheet reports the results. 
Bidding Behavior
You Fred Wilma
% markup 40% 40% 40%
Never bid below $0 $0 $120,000
Figure 24.7
Simulation 2
Job cost estimates errors Bids Winner
You Fred Wilma You Fred Wilma You -$15,062.4217.97% 2.14% $94,154 $169,667 $146,895
$(2,127.19)
Figure 24.6
218
Le
ct
ur
e 
24
: S
to
ch
as
tic
 O
pt
im
iz
at
io
n 
an
d 
R
is
k
 
risk but that once you reach a 20% markup, there’s a limited effect. 
At most, 5% of the cases lose you more than $5000, your prep fee. 
So, any markup of 20% or more is pretty good insurance against 
losing everything. 
 
And once in a while, both of your competitors are going to grossly 
overestimate the cost of the job, and you can swoop in with your 
a markup.
The Solution
 If we have more than one variable to look at, it’s quite a bit more 
optimization, we can discover what the best combination of variable 
values for our contracting business is. 
 Using the add-in, we specify that our objective is to maximize our 
percentage and our minimum bid. We add a constraint, specifying 
that we want to lose more than $5000 at most 1% of the time. We 
also let the optimization decide on how many workers we should 
use. That will be an integer variable. 
 We really should go further, such as specifying generous upper and 
lower bounds on each of our decision variables and specifying that 
we want to use an evolutionary solver. The software has gotten 
smart enough, though, that if we don’t specify these things, it will 
probably make those decisions on its own. We set our original 
values for our variables to exactly match Fred’s, in which case our 
219
 Then, we tell the solver to run—and to get a really good feel for 
the range of possibilities, we have it conduct each simulation 5000 
times. In less than three minutes, it’s done, with the suggestion 
that you use a markup of 28%, never bid under $28,500, and, 
surprisingly, use 6 workers, not 8. 
stochastic optimization: Finding a (near) optimal solution to a problem 
involving chance. 
winner’s curse: In an auction in which the true value of the item up for bid 
is unknown, the phenomenon that the winner often pays more for the item 
than it is worth. 
1. Consider a private value auction, where each bidder has his or her own 
valuation on what the item is worth to him or her. Suppose that each 
bidder knows his or her own valuation but not the valuation of others. 
Would shading one’s bid below the true valuation still make sense?
Answer: 
Yes. If you bid exactly what you believe the item to be worth, you 
would always gain zero, regardless of whether you won the bid. Only by 
bidding something less than you think the item is worth can you capture 
a surplus. Of course, the more you shade, the more chance you have of 
losing the bid.
An interesting variant is the second price auction, where the high bid 
wins the item but only has to pay as much as the second-highest bid. 
One can show without too much work that in such an auction, each 
bidder should bid what the item is worth to him or her.
Important Terms
Questions and Comments
220
Le
ct
ur
e 
24
: S
to
ch
as
tic
 O
pt
im
iz
at
io
n 
an
d 
R
is
k
2. A tempting approach to determining good strategies is to look at those 
competitors who have had the most success in the past and to emulate 
what they’re doing. Why might a direct application of this strategy be a 
bad idea?
Answer: 
It’s necessary to see how those who succeed differ from those who fail. 
For a concrete example, consider people being given $100 and being 
allowed, if they wish, to use some or all of it for a single bet in roulette. 
most successful people bet all of the money, and they bet it on a single 
number. But people following this same strategy are also more likely to 
lose $100 than anyone else. In fact, the best strategy on average is not 
to bet.
collapse of the early 21st century. Until the meltdown, the most 
successful people were the ones taking extreme risks with high leverage. 
That didn’t make the policy a good one.
221
Entering Linear Programs into a Spreadsheet
is to do it yourself. Linear programming can be done in either application 
with almost identical effort and virtually identical steps. For this guide, it is 
recommended that you boot up one of these programs and work through the 
sample problem step by step. 
The assumption of this guide is that you know the basics of your 
spreadsheet program—how to refer to cells by row and column label, how 
to highlight cells by holding the left mouse button and dragging the mouse, 
how to copy one cell into another cell or a range of other cells, how to 
represent a range of cells (such as A2:A5 for all cells between A2 and A5), 
and a few other basics. If you don’t know how to do something in Excel or 
Calc, you can get help by pressing the F1 key while in the spreadsheet or 
(sometimes the best option) by using an Internet search engine to look for 
exactly what you need.
A Sample Problem
The following LEGO problem is a product mix problem with vertical 
integration, including a make-or-buy decision. But it can also be modeled it 
as a transshipment problem (raw materials and third-party packets “shipped” 
to packets available “shipped” to products), making it similar to problems 
from Lecture 8. 
The linear program is about taking plastic and metal to make two kinds of 
intermediate products called “construction packets” and “accessory packets,” 
and then combining these to make two products for sale: kit 1 and kit 2. You 
can buy construction packets from a third party, too, if you want to. 
222
En
te
rin
g 
Li
ne
ar
 P
ro
gr
am
s 
in
to
 a
 S
pr
ea
ds
he
et
The LEGO Problem
The LEGO company sells building toys and is currently selling two 
different kinds of building kits, kit 1 and kit 2. LEGO has found that it can 
save money by “modularizing” the kits that it sells. LEGO manufactures 
“packet.” A kit is made simply by collecting together the packets needed 
for that particular kit. LEGO makes two kinds of packets: the construction 
packet and the accessory packet. Kit 1 consists of 4 construction packets 
and 1 accessory packet, and it sells for $13. Kit 2 consists of 3 construction 
packets and 2 accessory packets, and it sells for $16. Because of limited 
demand for LEGO products in the marketplace, the total number of kits sold 
will not exceed 3000. (You may assume that LEGO will construct only those 
kits that it sells.)
To make a construction packet, LEGO uses 50 grams of plastic and incurs 
a cost of 20 cents. To make an accessory packet, LEGO uses 25 grams 
of plastic and 20 grams of steel. An accessory packet costs 35 cents to 
produce. (Neither of these packets may be sold directly.) LEGO may also 
buy construction packets from a third-party supplier for 30 cents each. 
LEGO has available 100,000 grams of plastic and 50,000 grams of steel. 
How should LEGO conduct its purchasing and production if it wishes to 
The “measurable quantity” formulation of the program is as follows.
subject to
 
 
 
 
223
The details of this problem don’t matter, but the problem allows us to work 
through most of the issues that will come up when you put a linear program 
into your spreadsheet. The following is the program.
Maximize  
13KIT1 + 16KIT2 CMAKE AMAKE CBUY
subject to
50CMAKE + 25AMAKE  
20AMAKE  
4KIT1 + 3KIT2 CMAKE + CBUY 
KIT1 + 2KIT2 AMAKE 
KIT1 + KIT2
The Setup
First, we put the problem in standard form. That means that all constant 
terms go on the right side of the constraints, all variable terms go on the left 
side of the constraints, and any parentheses in the problem are “multiplied 
out.” Here, the third and fourth constraints have variables on their right-hand 
sides. We’ll subtract them off to the left. This leaves us with the following.
Maximize 
CMAKE AMAKE CBUY + 13KIT1 + 16KIT2
subject to
50CMAKE + 25AMAKE  
20AMAKE  
4KIT1 + 3KIT2 CMAKE CBUY  
KIT1 + 2KIT2 AMAKE  
KIT1 + KIT2
224
En
te
rin
g 
Li
ne
ar
 P
ro
gr
am
s 
in
to
 a
 S
pr
ea
ds
he
et
The program is now in standard form. Next, we’re going to represent this 
program in a kind of shorthand form by creating the following tableau. The 
tableau contains everything that the program tells us, except for the fact that 
the program is a MAX and that all decision variables must be nonnegative. 
These are easy to remember, so don’t worry about them.
Do you see how the tableau works? We’ve essentially recorded only the 
the program at the top of the page, you just proceed across a row of the 
tableau and multiply each number in that row by the variable that heads its 
column. (RHS, which stands for “right-hand side,” isn’t a variable, so no 
multiplication is done for the RHS of the constraints.) So, for example, the 
second row of the tableau says 0KIT1 + 0KIT2 + 50CMAKE + 25AMAKE 
+ 0CBUY
The top row is the objective. Note that we did record the direction of each 
In the spreadsheet program, we’re going to record the information in the 
tableau almost exactly as we did there—with a few additions. We’ll have a 
these cells will hold the optimal solution. We’ll also include a column 
labeled LHS (which stands for “left-hand side”). The cells in this column 
will hold the computed numerical values of the left-hand side of each of our 
constraints, as well as the computed value of the objective function. Finally, 
we’ll also include a column to the left of our program, to remind us what 
each constraint says. 
KIT1 KIT2 CMAKE AMAKE CBUY RHS
13 16 = PROFIT
0 0 50 25 0 100,000
0 0 0 20 0 50,000
4 3 0 0
1 2 0 0 0
1 1 0 0 0 3000
Figure A.1
225
The following spreadsheet includes borders and shading. Why did we do 
this? We shaded all of the cells containing the numbers that we typed in. 
That way, it will be easy later to know what numbers we can change to new 
values (to make up a new problem) and what numbers we can’t (because 
they’re really formulas). We’ve put double-lined boxes around the cells that 
will hold our decision variable values. For now, we’ve put the values 1, 2, 5, 
4, and 10 in those cells, just as placeholders. You can type any numbers you 
Now, we’re going to write the mathematical relationships to tie all of these 
numbers together. You know how the numbers in the table are supposed to 
combine to produce meaningful calculations. For example, look at constraint 
1 in row 8 of the spreadsheet, which says that we can’t use more than the 
100,000 grams of plastic that we have on hand. How much are we using, with 
our made-up decision variable values we put in row 3 of the spreadsheet? 
0KIT1 + 0KIT2 + 50CMAKE + 25AMAKE + 0CBUY becomes 0(1) + 0(2) + 
50(5) + 25(4) +0(10) = 350 grams.
Excel and Calc both have a built-in function that does exactly this, without all 
of the typing: SUMPRODUCT. Let’s do it. Click in cell G8. For Excel, type 
= SUMPRODUCT(B3:F3,B8:F8), and then press return. SUMPRODUCT 
just multiplies each number in the one range by the corresponding one in the 
other range and then adds the results, exactly as we desire. If you are using 
A B C D E F G H I
1 Variables
2 KIT1 KIT2 CMAKE AMAKE CBUY
3 1 2 5 4 10
4
5 Maximize 13 16 = PROFIT
6
7 Constraints LHS RHS
8 Plastic 0 0 50 25 0 100,000
9 Steel 0 0 0 20 0 50,000
10 Construction 4 3 0 0
11 Accessory 1 2 0 0 0
12 Demand 1 1 0 0 0 3000
Make up any 
values you like 
in these cells!
Figure A.2
226
En
te
rin
g 
Li
ne
ar
 P
ro
gr
am
s 
in
to
 a
 S
pr
ea
ds
he
et
Calc, you’ll use a semicolon where Excel uses a comma—for example, 
SUMPRODUCT(B3:F3;B8:F8). When you press enter, you should see our 
350 grams of plastic used appear in cell G8.
We’re going to do this for each of the constraints, combining the variable 
out the equation for each row, but we’re going to enter it a little differently 
than this. Enter the formula as it is entered in the following spreadsheet 
(again, if you are using Calc, replace the comma with a semicolon). We’ve 
just edited the formula that was typed into G8 by inserting 4 dollar signs.
Those dollar signs did not affect the calculation of 350 grams in G8, but 
they will be important. Once you’ve typed the formula and pressed return, 
move your cursor to the lower-right corner of cell G8, where a small black 
square is visible. Your cursor will turn to a skinny cross. When it does, 
press and hold the left mouse button, and then drag downward until you 
have highlighted cells G9 to G12. Let go of the mouse button. You’ve just 
entered the formulas for the left-hand sides of all of the other constraints. 
The dollar signs told the spreadsheet that you didn’t want the row 3 values 
used in the formula to move when you dragged the formula downward. Do 
a fast double-click on cell G12 and you’ll understand. It uses data from row 
the objective in cell G5. It’s = SUMPRODUCT(B3:F3,B5:F5). As always, in 
Calc, that comma is going to be replaced by a semicolon.
A B C D E F G H I
1 Variables
2 KIT1 KIT2 CMAKE AMAKE CBUY
3 1 2 5 4 10
4
5 Maximize 13 16 = PROFIT
6
7 Constraints LHS RHS
8 Plastic 0 0 50 25 0 =SUMPRODUCT($B$3:$F$3,B8:G8) 100,000
9 Steel 0 0 0 20 0 50,000
10 Construction 4 3 0 0
11 Accessory 1 2 0 0 0
12 Demand 1 1 0 0 0 3000
Figure A.3
227
The Solution
Before you can use Solver to solve the problem, you need to tell Excel or 
Calc that you want to use it. The steps to do this vary a bit, depending on your 
spreadsheet program, but you only have to do this once. In some versions 
of Excel, you do this by clicking on the “File” tab on the top of the sheet, 
choosing “Options” from the left-hand menu, and then choosing “Add-ins.” 
At the bottom of the window that opens, choose the button labeled “Go” next 
to “Excel add-ins.” When the window pops up, check the option for “Solver 
add-in.” Click “OK.” If all went well, you should now see “Solver” listed on 
your “Data” tab. Calc comes with the linear solver already installed, and a 
beta version of a nonlinear and evolutionary solver is available online. If you 
have a different version of Excel, you can search the Internet for instructions 
appropriate for your version.
To use Solver, you need to tell it where the decision variables for your 
program appear in the spreadsheet, what the program constraints are, and 
where the objective function value is. You’re also going to have to tell it some 
other bits of information, such as the fact that all of your decision variables in 
this problem are nonnegative. Let’s do this in the spreadsheet where you’ve 
created our linear program. Figure A.4 shows you what it looks like in Calc. 
Excel’s requestor is almost identical. The biggest difference is that you’ll 
 tab in most versions of Excel and under the 
“Tools” menu in Calc. 
Most of this is pretty self-explanatory, once you know the names that the 
spreadsheet program uses for the parts of a linear program. Our objective 
would be labeled as “Set objective.” Below this, we specify the cells holding 
our decision variables, B3 through F3. Excel calls these “variable cells,” 
while in Calc they are the “changing cells.” We can either type this in the 
box, or we can click in the “variable cells” box to activate it, and then click 
and drag in the spreadsheet to highlight cells B3 through F3. 
This is a MAX program, so we need to click on the radio button for 
“Maximum”—but it’s already selected for us. We do, however, need to enter 
the constraints. The way that we’ve entered our program into the spreadsheet 
makes entering the constraints especially easy. We’ve computed the LHS of 
228
En
te
rin
g 
Li
ne
ar
 P
ro
gr
am
s 
in
to
 a
 S
pr
ea
ds
he
et
every constraint. We just have to make sure that it bears the right relation to 
the RHS of each constraint. For our program, by coincidence, every LHS is 
 in Calc, or by clicking on the “Add” 
button next to the “Subject to the constraints” box in Excel. You’ll then need 
to provide three bits of information: what cell represents the LHS of the 
constraint in question, what cell represents the RHS of the constraint, and 
one at a time, each time moving to a new row in Calc or pressing “Add” in 
Excel, but here we used a shortcut to do all constraints at once. We could do 
same relational operator can be done in one row.
Figure A.4
229
If you’re using Excel, make sure that at the bottom of the requestor, “Solver,” 
is set to “Simplex LP” for its solving method and the box for “assume 
variables nonnegative” is checked. In Calc, you’ll automatically be using the 
simplex method, but you’ll need to click on the “Options” button and tell 
Calc that your variables are nonnegative, and then click “OK.”
Click on the “Solve” button, and Solver should now solve your problem. 
When it’s done, it will present a window letting you know that a solution 
has been found. In Excel only (not yet in Calc), it’s also possible to include a 
sensitivity report (a topic considered in Lecture 12). 
Common problems arise from either 1) forgetting to impose the nonnegativity 
constraints (put a check mark in the appropriate box in Solver to do this) 
or 2) wanting to highlight an entire row of the spreadsheet (and not just the 
LHS cell) as the left-hand side of a constraint. In this example, we entered 
all of our constraints at once, but if you are unsure of what you are doing, 
enter them one at a time. Each constraint will have a single cell on its LHS 
and a single cell on its RHS.
Like most things with computers, the spreadsheet solution of linear programs 
help you get past many of the more common obstacles.
G
lo
ss
ar
y
230
Glossary
100% rule: A rule that often allows the determination of whether changes in 
the constant terms of multiple constraints in a linear program can be made 
without altering shadow prices. Alternatively, a rule that often allows the 
in a linear program can be made without altering the optimal values of the 
decision variables.
absorbing state: In a Markov system, a state that cannot be left once it 
is entered. 
adjusted r2
model. The value of r2 is adjusted downward for each additional 
independent variable, to help address the problem of choosing a model that 
: Umbrella term for the data mining techniques that seek to 
determine “what goes with what.” 
alternative optima: Two or more best solutions to the same problem. 
: A procedure for identifying the relative 
importance of factors in a project by decomposing the project into activities. 
These activities may themselves be broken down in a similar way through as 
many levels as desired. Pairwise comparisons are made between items at the 
same level of this decomposition, and AHP combines these comparisons into 
a ranking of the activities. 
Apriori method: A method for generating frequently occurring subsets of 
items for an association rules application. 
association rules: A data mining task of creating rules of the following form: 
“If an individual has this collection of traits, predict that individual also has 
that set of traits.” 
231
auxiliary variable: Also called a dependent variable. A variable whose 
value is completely determined by the values of the other variables in the 
how its value is computed. 
binary variable
that can only assume the values of 0 or 1. 
binding: A constraint is binding on a solution if it has zero slack in 
that solution. 
Bayesian analysis: A technique for revising the probabilities of outcomes in 
light of new information. 
branch and bound
linear programs by repeatedly replacing a linear integer program with two 
variants, each of which differs from the original by the inclusion of one 
additional constraint. 
Calc
but lacks some of the features of Excel. 
calling units: General term applied to those individuals or objects that make 
use of a queuing system. 
centroid: In data mining, the centroid of a cluster is the point for which each 
variable is the average of that variable among points in that cluster. 
: Using the information available about an individual to predict 
to which of a number of categories that individual belongs. 
repeatedly splits a subset of the individuals into two groups in a way that 
reduces total “impurity.” 
232
G
lo
ss
ar
y
cluster: A collection of points considered together because of their proximity 
to one another. 
: See r2.
: For an association rule, the probability that the 
consequent is true given that the antecedent is true. 
probability that the series of calculations that generate the interval, when 
contains the population parameter. 
: An interval of values generated from a sample that 
hopefully contains the actual value of the population parameter of interest. 
See . 
conservation constraint: An equality constraint in a linear program that 
generally requires that counting the same thing in two different ways must 
give the same answer. It can often be interpreted as “total in = total out.” 
constraint: A rule that must be obeyed by any acceptable solution. 
convex: A region is convex if a line segment drawn between two points of 
the region always stays within the region. A square is convex; a star is not. 
One can intuitively think of a function being convex if someone walking 
on the surface of the function has “line of sight” to every other point on 
the function’s surface. Hence, a single valley is convex, but two valleys 
separated by a ridge are not. 
correlation: Intuitively, a measure of the extent to which the variation in 
the correlation is to 1, the closer the variables, when plotted in a scatter plot, 
233
would be to a straight line. For plots where the slope of the trend line would 
be positive, the correlation is positive. It is negative for plots where the slope 
of the trend line would be negative. 
covariance: Similar to the correlation, the covariance of two quantities is 
their correlation multiplied by the standard deviations of two variables. 
cyclic component: The component of a time series forecast that attempts 
to capture cyclic variation. This differs from seasonal variation by showing 
nonconstant duration or intensity or unpredictable onset. 
: A technique for evaluating the relative 
See . 
: The usual term given to a producer in data 
envelopment analysis. 
decision theory: A collection of techniques for determining what decisions 
are optimal in a situation that involves stochastic elements, especially those 
situations that evolve over time. 
decision tree: A structure consisting of branching decision nodes and chance 
nodes used to analyze sequential decision making in the face of uncertainty. 
decision variable: In a mathematical model, any measurable quantity over 
values of all of its decision variables. 
dendrogram: A graph detailing the sequence of cluster mergers that 
eventually ends in a single cluster. 
derivative: The derivative of a function is itself a function, one that 
derivative is captured by the vector quantity of the gradient. 
234
G
lo
ss
ar
y
deterministic: Involving no random elements. For a deterministic problem, 
the same inputs always generate the same outputs. Contrast to stochastic. 
discriminant analysis: A data mining technique for separating a set of data 
into two categories with a hyperplane so as to separate a two-category output 
variable. 
distance, average
two clusters as being the average of the distances between each point in one 
cluster and each point in the other. 
distance, complete linkage
between two clusters as being the maximum of the distance between a point 
in one cluster and a point in the other. 
distance, Euclidean: Our normal concept of distance, applied in an arbitrary 
number of dimensions. 
distance, single linkage
between two clusters as being the minimum of the distance between a point 
in one cluster and a point in the other. 
distance, statistical: Also called Mahalanobis distance. A distance measure 
that takes into account the variance and covariance of the various variables 
dual price: See shadow price. 
dummy variable: A variable that can take on values of only 0 or 1. 
Dummy variables are useful in forecasting and data mining for representing 
two-category variables. A categorical variable with k categories can be 
represented by a collection of k
e: A natural constant, approximately 2.71828. Like the more familiar , e 
appears frequently in many branches of mathematics. 
235
producer could create the same outputs as the producer under scrutiny while 
. 
ergodic: A Markov system is ergodic if there exists some n such that, for any 
two pure states i and j, it is possible to move from state i to state j in exactly 
n transitions. 
error: In a forecasting model, the component of the model that captures 
the variation in output value not captured by the rest of the model. For 
regression, this means the difference between the actual output value and the 
value forecast by the true regression line. 
event: A statement about the outcome of an experiment that is either true or 
false for any given trial of the experiment. 
evolutionary algorithm: See genetic algorithm.
Excel
expected value: The average (or mean) value of a numeric random variable. 
exponential growth/decay: Mathematically, a relationship of the form 
y = abx for appropriate constants a and b. Such relations hold when the rate 
of change of a quantity is proportional to its current value. 
exponential smoothing: A time series forecasting technique that forms the 
basis of many more-complicated models. Exponential smoothing can be 
thought of as a variant of the weighted moving average. 
feasible: Possible. In a mathematical program, feasible solutions are those 
that satisfy all of the constraints. 
236
G
lo
ss
ar
y
feasible region: The set of decision variable combinations that correspond 
to feasible solutions to the problem. In a two-variable linear program, the 
feasible region, if it exists, will be one contiguous convex region bordered 
by straight lines. 
hyperplane
wall. Don’t worry—most people can’t visualize them. 
genetic algorithm: An optimization technique involving a stochastic search 
of possible solutions in a way that somewhat mimics DNA recombination. 
Gini index
rectangle is obtained by computing the fraction of observations in that 
rectangle that belong to each output category, squaring these fractions, and 
then subtracting their sum from 1. 
gradient: A vector quantity that indicates the direction of “straight uphill” 
for a function of one or more variables. It is the higher-dimensional 
generalization of the derivative of a one-variable function. 
heat map: A data visualization technique in which colors or shades are used 
to convey information about a variable in a chart, graph, or map. 
heteroscedastic: A collection of random variables is heteroscedastic if their 
standard deviations are not all equal. 
homoscedastic: A collection of random variables is homoscedastic if they 
all have the same standard deviation. Linear regression generally assumes 
that the error terms in the forecast are homoscedastic. 
independent: Two events are independent if knowing the outcome 
of one does not alter the probability of the other. In symbols, A and B 
are independent if and only if P(A) = P(A | B). Two events that are not 
independent are dependent. 
infeasible program: A program that has no feasible solutions. Its constraints 
237
INFORMS: The Institute for Operations Research and the Management 
Sciences. 
integer program: A program in which all of the decision variables are 
required to be integers—that is, positive or negative whole numbers or zero. 
If only some of the variables have this requirement, the program is termed 
“mixed integer.” 
irreducible: A Markov system is irreducible if it is possible to follow a set 
of transitions that passes through every state in the system and eventually 
returns to where it began. 
k-nearest neighbors
which the value assigned to a new observation is computed by the output 
values of the k training set observations closest to it. 
limited resource constraint: The most common kind of linear programming 
constraint. It says that you can’t use more of something than what is available. 
linear expression: An algebraic expression consisting of the sum or 
difference of a collection of terms, each of which is either simply a number 
straight lines, planes, or higher-dimensional analogs called hyperplanes. 
linear program: A model in which the objective function and the two sides 
of each constraint are all linear expressions. Linear programs are especially 
easy to solve. 
linear regression
set of input variables and a single continuous output variable. If there is only 
one input variable, the technique is called simple; with more than one, it is 
called multiple. 
logarithm: The inverse function to an exponential. If y = ax for some positive 
constant a, then x = loga y. The most common choice for a is the natural 
constant e. loge x is also written ln x. 
238
G
lo
ss
ar
y
LP relaxation : The linear program that results 
from suspending the integer requirements of an integer linear program. 
manifold, two-dimensional: A surface that on a very small scale looks like a 
plane. If you imagine a surface that doesn’t have rips, sharp ridges, or cliffs, 
you’re probably imagining a 2-manifold. 
Markov analysis: A set of techniques for analyzing the behavior of systems 
that can be viewed as occupying one of a number of states, with a particular 
probability of transitioning from one state to another at various points in time. 
Markov diagram: A graphical representation of Markov process. Each pure 
state of the system is represented by a node, and each possible transition 
from state to state is indicated with an arrow connecting those nodes. 
: A measure of forecast accuracy, MAD is 
the average amount by which the forecast differs from the actual value. 
: A measure of forecast accuracy, 
MAPE is the average percentage by which the forecast differs from the 
actual value. 
: A measure of forecast accuracy that is similar 
to variance in its calculation, MSE is the average of the squares of all of the 
residuals for a forecast. 
measurable quantity: The quantities represented by numbers in a 
“the number of (unit of measure)” of something, such as the number of hours 
spent on a project. 
memoryless: A process where the probability of reaching a particular state 
after the passage of so much time depends only on the current state and not 
on the events that led to that state. Rolling a die is memoryless. 
239
minimum performance constraint: The second-most-common kind of 
linear programming constraint. It says that the amount obtained of something 
is at least as much as is required. Also called a quota constraint. 
model
elements of the situation and the relationships among those elements. 
Monte Carlo: A kind of simulation, named after the famous Moroccan 
casino. The simulation is run a large number of times with different values 
for the random quantities in each run. 
Moore’s law: Formulated by Intel founder Gordon Moore in 1965, it is the 
prediction that the number of transistors on an integrated circuit doubles 
roughly every two years. To date, it’s been remarkably accurate. 
multicollinearity: The problem in multiple regression arising when two or 
more input variables are highly correlated, leading to unreliable estimation 
multiobjective programming: Any optimization problem with more than 
one objective. 
multiperiod planning: Problems in which the same pattern of decisions 
must be made repeatedly over time. 
naïve forecast: The forecast for future times of whatever just happened. 
nonbinding: A constraint is nonbinding on a solution if it has positive slack 
in that solution. (Negative slack means that the constraint is violated.) 
nonnegativity constraint: A constraint requiring a particular decision 
variable to be at least zero. Also called a trivial constraint. 
nontrivial constraint: Any constraint other than a nonnegativity constraint. 
240
G
lo
ss
ar
y
normalizing: Also called standardizing. Linearly rescaling a variable to 
make its mean 0 and its standard deviation 1. This is done by taking each of 
the variable’s values, subtracting the mean of the variable, and then dividing 
the result by the variable’s standard deviation. 
: The mathematical expression that represents the goal 
of an optimization problem. The better the objective function value, the 
better the solution. Objective function values are usually either maximized 
or minimized in an optimal solution. 
: The range of values over 
without changing the optimal values of the decision variables. 
: In a graphically solved linear program, a 
line of constant objective function value. OFLs act like contour lines on a 
topographic map. In problems with more than two variables, OFLs are 
replaced with planes or hyperplanes of constant objective function value. 
operations research: The general term for the application of quantitative 
called operational research in the United Kingdom. When applied to business 
problems, it may be referred to as management science, business analytics, 
or quantitative management. 
optimization: Finding the best answer to a given problem. The best answer 
is termed “optimal.” 
optimum: The best answer. The best answer among all possible solutions is 
a global optimum. An answer that is the best of all points in its immediate 
vicinity is a local optimum. Thus, in considering the heights of points in a 
mountain range, each mountain peak is a local maximum, but the top of the 
tallest mountain is the global maximum. 
241
: In forecasting or prediction, choosing a more complex model 
that performs better on the training data but does more poorly on new data 
because the model is responding to spurious patterns (noise) in the training 
data, rather than capturing a true relationship between inputs and the output. 
(3, 6)
oversampling: In data mining, the choice of representing a class in a data 
set at a relative frequency higher than its occurrence in the population. 
Oversampling is appropriate if the class of interest forms only a small 
proportion of the entire population. 
parameters: The values of the constants relevant to a problem, such as 
the quantity available of a resource. Models are often created so that the 
Pareto optimal: A solution is Pareto optimal if one cannot do better at 
accomplishing one goal without doing worse on at least one other goal. 
penalty
genetic algorithms and soft constraints. 
Poisson process: A process that generates successes at various points along 
tiny interval have the same minuscule chance of containing a success and 
that a success in any one such interval is independent of a success in any 
other. Arrival processes are often modeled as Poisson. 
polynomial: A mathematical expression that consists of the sum of one or 
more terms, each of which consists of a constant times a series of variables 
raised to powers. The power of each variable in each term must be a 
nonnegative integer. Thus, 3x2 + 2xy + z
population: The set of all individuals of interest for purposes of the current 
study, or the set of all relevant variable values associated with that group. 
242
G
lo
ss
ar
y
posterior probability distribution: See prior probability distribution.
power law: A relationship between variables x and y of the form y = axb for 
appropriate constants a and b. 
prediction: In data mining, using the information available about an 
individual to estimate the value that it takes on some continuous output 
prediction interval
probability of containing the value of the output variable that will be 
. 
: A technique for reducing the 
number of variables in a data set by identifying a collection of linear 
combinations of those variables that capture most of the variation of a larger 
set of the original variables. These new variables can then be used in place 
of the larger set. 
prior probability distribution
of events in light of new information. The probability distribution in 
effect before new information is provided is called the prior probability 
distribution. The new distribution, accounting for the new information, is 
called the posterior probability distribution. 
probability: A measure of the likeliness of the occurrence of uncertain 
events. Probabilities lie between 0 and 1, with more-likely events having 
higher probability. If all possible outcomes of an experiment are equally 
likely, the classical probability or a priori probability of an event can be 
cases, probability may be empirically 
cases in which the event occurred. 
probability, conditional: The probability that some event occurs, given that 
some other collection of events occurred. The probability that A occurs given 
that B occurs is written P(A | B). 
243
probability, joint: The probability that all events in some collection occur. 
program: Mathematically, an optimization model. The term corresponds to 
the idea of a program as a schedule, as in television programming, because 
many early optimization models were scheduling problems. 
queue: Waiting line. The study of waiting lines is called queuing theory. 
Technically, the queue does not include any calling units that are currently in 
service, only those waiting for service to begin. 
quota constraint: The second-most-common kind of linear programming 
constraint. It says that the amount obtained of something is at least as much 
as is required. Also called a minimum performance constraint. 
r2
model explains the variation in the output variable in terms of the model’s 
inputs. Intuitively, it reports what fraction of the total variation in the output 
variable is explained by the model. 
random variable: A measurable quantity, often numeric, associated with the 
outcome of a stochastic experiment.
random walk: A sequence in which each term is obtained from the previous 
one by the addition of a random term. The simplest example would be that xn 
equals the number of heads obtained in x
redundant: A constraint is redundant if satisfying the other constraints in the 
x y
then x + y
regression: A mathematical technique that posits the form of a function 
function from data. The regression is linear if the hypothesized relation is 
linear, polynomial if the hypothesized relation is polynomial, etc. 
244
G
lo
ss
ar
y
regression line: The true regression line is the linear relationship posited 
to exist between the values of the input variables and the mean value of 
the output variable for that set of inputs. The estimated regression line is 
the approximation to this line found by considering only the points in the 
available sample. 
regression tree
residual: Given a data point in a forecasting problem, the amount by which 
the actual output for that data point exceeds its predicted value. Compare 
to error. 
: The range of values over which the 
constant term in a constraint may vary without changing the shadow price of 
any constraint. 
risk: Variability in the desirability of the possible outcomes of a situation 
involving uncertainty. Decision makers may be risk neutral, meaning that 
they choose whatever course of action gives the highest expected payoff. 
Alternatively, they may be risk averse or risk loving. Risk-loving individuals 
Risk-averse individuals are inclined to refuse a gamble even if, on average, 
rollback: The procedure of evaluating a decision tree by computing expected 
values at each chance node and choosing the most-attractive options at each 
decision node. 
saddle point: A point on a manifold where the derivative is zero in any 
direction but is neither a maximum nor a minimum. The middle of a saddle has 
this characteristic, although technically a terrace point is also a saddle point. 
sample: A subset of a population.
245
seasonal component: The component of a time series forecast that captures 
the seasonality of the data—that is, its regular, periodic variation. Some 
sources use the term for such variation only if the period length is at least 
one year. 
sensitivity
of interest, given that it does indeed possess that trait. Contrast to . 
sensitivity analysis: An investigation of how an optimal solution changes 
as parameters of the problem are varied from some set of original values. 
Sensitivity analysis can be done with most optimization techniques, such as 
linear programming or decision theory. 
shadow price: Also called dual price. The amount that the optimal objective 
function value increases when the right-hand side of a constraint is increased 
by 1. Shadow prices may change when one leaves the right-hand-side range 
of a constraint. 
simple moving average: A forecast for a period in a time series made by 
For predictive models, this will mean the n observations immediately 
preceding the current time period. 
simplex method
the optimal solution to any linear program that has one. For most 
 
surprising speed. 
simulation, digital: A powerful technique for what-if analysis, allowing the 
development of a complex model and an analysis of its possible outcomes. 
Most often this model involves randomness and is therefore done as a Monte 
Carlo simulation. 
soft constraint
if it is not, a penalty is assessed, with a larger penalty applied to a larger 
violation of the constraint. 
246
G
lo
ss
ar
y
solver: Generally, a piece of software for solving a class of problems. 
to linear and nonlinear programs. 
slack: For any inequality constraint, the slack is the side of the constraint 
claiming to be bigger minus the side claiming to be smaller. Hence, the slack 
in 4x + y z is 4x + y z. The slack in 8x x. A constraint that is 
: The probability that an observation is classed as not having the 
trait of interest, given that it does not, in fact, possess that trait. Contrast 
to sensitivity. 
standard deviation: A measure of dispersion, it is the square root of 
the variance. 
standard error: Not an “error” in the traditional sense. The standard error 
is the estimated value of the standard deviation of a statistic. For example, 
the standard error of the mean for samples of size 50 would be found by 
of each sample, and then computing the standard deviation of all of those 
sample means. 
standard form: A linear constraint in standard form has all of its variable 
terms on the left side of the constraint and its constant term on the right side. 
2x + 4y
state vector: A string of values specifying the probability that a Markov 
system is in each of the possible pure states. 
stationary time series: A time series that does not show a long-term trend or 
change in variance. 
steady state vector: In Markov analysis, a state vector that is unchanged 
by the application of the transition matrix. A Markov system that reaches a 
steady state vector will never move from it. 
247
steepest descent: Also called gradient descent. A collection of techniques for 
the direction in which the objective function is changing most rapidly in the 
desirable direction and then jumps from the current solution to one (nearly) 
in that direction. 
stochastic: Involving random elements. Identical inputs may generate 
differing outputs. Contrast to deterministic. 
stochastic optimization: Finding a (near) optimal solution to a problem 
involving chance. 
SUMPRODUCT: A function in Calc and Excel that takes two row or 
column arrays of equal length, multiplies corresponding elements, and then 
adds the results. In vector calculus, this is the dot product or scalar product 
of two vectors. 
SWOT: Stands for “strengths, weaknesses, opportunities, threats.” A strategic 
management technique for identifying the direction that an organization 
should take by examining its inherent strengths and weaknesses and its 
comparative advantages and disadvantages in relation to its competitors. 
system, queuing: All of the calling units either currently under service or in 
the queue are considered to be in the system. 
tabu search: Also called taboo search. A search procedure of a part of the 
feasible region in which a list is kept of recently examined solutions. The 
procedure avoids returning to solutions already found unsatisfactory. 
testing set: See training, validation, and testing sets.
time series: A data set consisting of one value of the output variable for each 
point in time. The points in time are usually evenly spaced. Alternatively, a 
forecasting technique used on such data. 
248
G
lo
ss
ar
y
tornado diagram: A chart summarizing how the value of a quantity 
of interest, such as the objective, depends on the random variables in a 
stochastic optimization problem. 
training, validation, and testing sets: In data mining, where data is 
plentiful, model quality is usually assessed by using part of the data as a 
training set, to create one or more models, and then assessing their quality 
with the validation set. If more than one model is being assessed, the best is 
third set of data, the testing set. 
transformation of variable: The technique of replacing a variable in a 
transforming a variable by replacing it with its logarithm, square root, or the 
like can make a nonlinear relationship into a linear one as well as address 
problems of heteroscedasticity. 
transient state: In a Markov system, a state whose long-run probability 
approaches zero regardless of initial conditions. 
transition matrix: In Markov analysis, a matrix whose entries p ij give the 
j given that the system is currently 
in state i. 
transshipment problem: A classic kind of linear programming problem. 
Units are shipped from supply points through transshipment points and on to 
demand points. The goal is often to minimize the total cost of the operation. 
A variety of constraints can be added to this problem. 
unbounded program
that makes the objective function value arbitrarily good. Intuitively, you can 
utility: In essence, “happiness points.” Utilitarian models in economics posit 
that decision makers act so as to maximize their personal utility. A utility 
249
validation set: See training, validation, and testing sets.
variance: A commonly used statistical measure of the dispersion, or spread, 
of data. For a population, the variance is computed by deviation of each 
observation from the population mean, squaring those differences, and 
averaging the squares. For a sample, the same calculation is performed, but 
the result is multiplied by n n n is the sample size. 
virtual producer: In data envelopment analysis, a hypothetical producer 
created by taking a linear combination of actual producers. 
: In data envelopment analysis, a producer is weakly 
while using no more of any input and using less of at least one input. 
weighted moving average: A forecast for a period in a time series made by 
this will mean a weighted average of the n observations immediately 
preceding the current time period. 
winner’s curse: In an auction in which the true value of the item up for bid 
is unknown, the phenomenon that the winner often pays more for the item 
than it is worth. 
Zipf’s law: A relationship between the relative frequency of a word in 
a language and its position in a list of words in that language, sorted by 
frequency. The nth word in the list has a relative frequency proportional 
n. 
B
ib
lio
gr
ap
hy
250
Bibliography
Anderson, Chris K. “Setting Prices as Priceline.” Interfaces 4 (2009): 307–
315. A discussion of how Priceline uses operations research to determine 
optimal prices and inventory allocations for Kimpton Hotels. A nice example 
of dynamic programming.
Anderson, David, Dennis Sweeney, Thomas Williams, Jeffrey Cam, and 
James Cochran. Quantitative Methods for Business. Mason, OH: South-
Western Cengage Learning, 2013. Anderson, Sweeney, and Williams give a 
nice introduction into the skills and tools needed for business analytics. The 
book, now in its 10th edition, has stood the test of time.
Berry, Michael J., and Gordon Linoff. Data Mining Techniques: For 
Marketing, Sales, and Customer Support. Charlottesville: John Wiley and 
Sons, 1997. This is a quick read for a manager interested in an overview of 
the data mining techniques that exist and what they can and cannot do. A 
good introduction.
Bollapragada, Srinvas, Hong Cheng, Mary Phillips, Marc Garbiras, Michael 
Scholes, Tim Gibbs, and Mark Humphreville. “NBC’s Optimization Systems 
Increase Revenues and Productivity.” Interfaces 1 (2002): 42–60. An in-
depth but clear discussion of the NBC problem discussed in the lecture.
Boyles, Stephen. “Notes on Nonlinear Programming.” University of Texas. 
programming that is a little more advanced than the treatment in the lecture 
but still accessible to the mathematically competent layperson. Many more 
advanced resources are readily available online for the interested student.
Budiansky, Stephen. Blackett’s War: The Men Who Defeated the Nazi 
U-Boats and Brought Science to the Art of Warfare. New York City: Knopf, 
2013. An informative historical perspective on the early days of operational 
research and its importance in World War II. The discussion is primarily 
from a human rather than mathematical perspective.
251
Butchers, E. Rod, Paul R. Day, Andrew P. Goldie, Stephen Miller, Jeff 
Meyer, David M. Ryan, Amanda C. Scott, and Chris A. Wallace. “Optimized 
Crew Scheduling at Air New Zealand.” Interfaces 1 (2001): 30–56. A more 
in-depth treatment of the Air New Zealand application discussed in the 
lecture. The article discusses the extent and complexity of the challenge at a 
level quite accessible to the intelligent layperson.
Caixeta-Filho, José Vicente, Jan Maarten van Swaay-Neto, and Antonio de 
Pádua Wagemaker. “Optimization of the Production Planning and Trade of 
Lily Flowers at Jan de Wit Company.” Interfaces 1 (2002): 35–46. Like most 
Interfaces articles, this one provides considerable detail into the problem and 
solution while remaining comprehensible to the layperson. The model included 
at the end of the article shows the complexity of the real-world model.
Cook, Wade, and Joe Zhu. Data Envelopment Analysis: Balanced 
Benchmarking. 2013. Like the lecture, this book presents its examples in 
spreadsheets, but its treatment is far more extensive. A thorough treatment of 
data envelopment analysis as it is usually applied.
Cornuejols, Gerard, Michael Trick, and Matthew Saltzman. “A Tutorial on 
integer. A convenient and understandable discussion of a number of the 
classic problems in integer and mixed-integer programming.
Cox, Jeff, and Eliyahu Goldratt. The Goal: A Process of Ongoing 
Improvement. Great Barrington: North River Press Publishing Corporation, 
2012. In his struggles to save his job and his factory, Eliyahu Goldratt’s 
protagonist discovers many key ideas of operations management. A fast, 
informative, and engaging read, especially for those interested in the 
production sector.
Dudley, Jay, and Thomas Buckley. “How Gerber Used a Decision Tree in 
Strategic Decision-Making.” Graziadio Business Review
Gerber phthalates story.
252
B
ib
lio
gr
ap
hy
Dunham, Margaret. Data Mining: Introductory and Advanced Topics. Upper 
Saddle River: Prentice Hall, 2003. A more advanced data mining text. The 
latter sections deal with web mining, special mining, and temporal mining. 
Elsner, Ralf, Manfred Krafft, and Arnd Huchzermeier. “Optimizing 
Rhenania’s Mail-Order Business through Dynamic Multilevel Modeling 
(DMLM).” Interfaces 1 (2003): 50–66. The full story of Rhenania’s recovery.
Gass, Saul, and Assad Arjang. An Annotated Timeline of Operations 
Research: An Informal History. Boston: Springer Science Business 
29, 2014. This comprehensive chronology starts with operations research’s 
precursors in the 16th century and traces operations research developments 
and the people responsible for them through the year 2004. Given the scope 
of the material, discussion of any particular topic or individual is necessarily 
brief, but the book lends itself to browsing and gives a sense of the extent of 
the subject.
Grinstead, Charles M., and J. Laurie Snell. Introduction to Probability. 
2nd
Accessed March 30, 2014. A wonderful, free book on probability theory. 
Engaging examples, clear explanations, and an interesting interplay between 
probability calculations and empirical investigation.
Horner, Peter, and Barry List. “Armed with O.R.” ORMS Today (August 
2010): 24–29. An interesting interview with Admiral Mike Mullen, 
Chairman of the Joint Chiefs of Staff, and the usefulness of his master’s 
degree in operations research to his career. 
Hyndman, Rob, and George Athanasopoulos. Forecasting: Principles 
and Practice
30, 2014. An excellent text that is available online for free. Hyndman and 
Athanasopoulos use the statistical language R to create their examples. R 
and the interface RStudio are also available online at no cost, giving the 
253
interested student access to a powerful statistical and forecasting tool. 
Furthermore, the text includes the R text needed to execute the models 
created in the book.
Miller, Jeff, and Patricia Hayden. Statistical Analysis with the General 
Linear Model
March 30, 2014. An excellent and free book on regression and much more. 
Those who are interested in general linear models but have little background 
sensible intuition and presents examples that are worked out in detail.
Narisetty, Amar Kumar, Jean-Phillipe Richard, David Ramcharan, Debby 
Murphy, Gayle Minks, and Jim Fuller. “An Optimization Model for Empty 
Interfaces 2 (2008): 89–
actual model used.
Piattelli-Palmarini, Massimo. Inevitable Illusions: How Mistakes of Reason 
Rule Our Minds. Charlottesville: John Wiley and Sons, 1994. A fascinating 
look at how bad most people are at applying basic reasoning to everyday 
situations. Many of the mental tunnels discussed have their roots in incorrect 
intuitions about probability.
Ragsdale, Cliff. Spreadsheet Modeling & Decision Analysis: A Practical 
Introduction to Management Science. Mason, OH: South-Western Cengage 
to actually do analytics. Ragsdale works in the spreadsheet environment, 
making it possible for the interested student to formulate and solve nontrivial 
problems without investing in expensive software.
Samuelson, Douglas. “Election 2012: The ‘13 Keys’ to the White House.” 
ORMS Today (June 2011) 26–28. A discussion of a result by quantitative 
historian Allan Lichtman, who used a technique akin to discriminant analysis 
to identify a set of 13 criteria that he uses to predict the winner of presidential 
elections. It has correctly predicted the winner of the popular vote in every 
election since 1984.
254
B
ib
lio
gr
ap
hy
Shmeuli, Galit, Nitin R. Patel, and Peter C. Bruce. Data Mining for Business 
Excel® with XLMiner®. 2nd ed. Charlottesville: John Wiley and Sons, 
2010. A very nice introduction to data mining in a spreadsheet environment, 
presented at a level accessible to the interested amateur.
Stevens, Scott, and Susan Palocsay. “A Translation Approach to Teaching 
Linear Program Formulation.” Trans. ed. INFORMS
of the translation approach to linear programming formulation that is 
given in the lecture. This resource should be a valuable one to anyone just 
linear programs.
Stevenson, Seth. “What You Hate Most about Waiting in Line (It’s Not the 
Length of the Wait).” Slate
psychology of waiting in lines.
Stone, Lawrence D. “In Search of Air France Flight 447.” ORMS Today 4 (2011). 
 
Additional information and background on the search for Air France 447.
Strayer, James K. Linear Programming and Its Applications. New York: 
Springer-Verlag, 1989. A more advanced book for those who wish to know 
about the mathematics and theory of linear programming, such as the duality 
theorem and the mechanics of the simplex method. Strayer uses the Tucker 
tableau (invented by A. W. Tucker), which is the easiest way to work with 
the mathematics of linear programs.
Winston, Wayne, and S. Christian Albright. Practical Management Science. 
Mason, OH: Cengage, 2012. In this introductory text on analytics, Winston 
and Albright work in a spreadsheet environment and provide a plethora of 
interesting examples. Their treatment of sensitivity analysis using Solver 
tables makes a nice contrast to the approach discussed in the lecture.
255
Yu, Gang, Michael Argüello, Gao Song, Sandra McCowan, and Anna White. 
“A New Era for Crew Recovery at Continental Airlines.” Interfaces 1 (2003): 
5–22. A more in-depth discussion of the Continental Airline application in 
the lecture. The model structure is suggested, but most of the article is quite 
accessible to the interested layperson. 
Online Instructions for Creating Simulation Data Tables
In Calc, creating a simulation data table is decidedly kludgy and tedious. 
In Excel, it's much easier. A good video giving clear instructions can be 

