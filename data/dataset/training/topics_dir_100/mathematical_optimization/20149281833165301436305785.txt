
Engineering Optimization
Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
Engineering Optimization
Theory and Practice
Fourth Edition
Singiresu S. Rao
JOHN WILEY & SONS, INC.
This book is printed on acid-free paper.
Copyright c© 2009 by John Wiley & Sons, Inc. All rights reserved
Published by John Wiley & Sons, Inc., Hoboken, New Jersey
Published simultaneously in Canada
No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or
by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as permitted
under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior written permission
of the Publisher, or authorization through payment of the appropriate per-copy fee to the Copyright Clearance
Center, 222 Rosewood Drive, Danvers, MA 01923, (978) 750–8400, fax (978) 646–8600, or on the web
at www.copyright.com. Requests to the Publisher for permission should be addressed to the Permissions
Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748–6011, fax (201)
748–6008, or online at www.wiley.com/go/permissions.
Limit of Liability/Disclaimer of Warranty: While the publisher and the author have used their best efforts in
preparing this book, they make no representations or warranties with respect to the accuracy or completeness
of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness
for a particular purpose. No warranty may be created or extended by sales representatives or written sales
materials. The advice and strategies contained herein may not be suitable for your situation. You should
consult with a professional where appropriate. Neither the publisher nor the author shall be liable for any loss
of profit or any other commercial damages, including but not limited to special, incidental, consequential,
or other damages.
For general information about our other products and services, please contact our Customer Care Department
within the United States at (800) 762–2974, outside the United States at (317) 572–3993 or fax (317)
572–4002.
Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may
not be available in electronic books. For more information about Wiley products, visit our web site at
www.wiley.com.
Library of Congress Cataloging-in-Publication Data:
Rao, S. S.
Engineering optimization : theory and practice / Singiresu S. Rao.–4th ed.
p. cm.
Includes index.
ISBN 978-0-470-18352-6 (cloth)
1. Engineering—Mathematical models. 2. Mathematical optimization. I. Title.
TA342.R36 2009
620.001′5196—dc22
2009018559
Printed in the United States of America
10 9 8 7 6 5 4 3 2 1

Contents
Preface xvii
1 Introduction to Optimization 1
1.1 Introduction 1
1.2 Historical Development 3
1.3 Engineering Applications of Optimization 5
1.4 Statement of an Optimization Problem 6
1.4.1 Design Vector 6
1.4.2 Design Constraints 7
1.4.3 Constraint Surface 8
1.4.4 Objective Function 9
1.4.5 Objective Function Surfaces 9
1.5 Classification of Optimization Problems 14
1.5.1 Classification Based on the Existence of Constraints 14
1.5.2 Classification Based on the Nature of the Design Variables 15
1.5.3 Classification Based on the Physical Structure of the Problem 16
1.5.4 Classification Based on the Nature of the Equations Involved 19
1.5.5 Classification Based on the Permissible Values of the Design Variables 28
1.5.6 Classification Based on the Deterministic Nature of the Variables 29
1.5.7 Classification Based on the Separability of the Functions 30
1.5.8 Classification Based on the Number of Objective Functions 32
1.6 Optimization Techniques 35
1.7 Engineering Optimization Literature 35
1.8 Solution of Optimization Problems Using MATLAB 36
References and Bibliography 39
Review Questions 45
Problems 46
2 Classical Optimization Techniques 63
2.1 Introduction 63
2.2 Single-Variable Optimization 63
2.3 Multivariable Optimization with No Constraints 68
2.3.1 Semidefinite Case 73
2.3.2 Saddle Point 73
2.4 Multivariable Optimization with Equality Constraints 75
2.4.1 Solution by Direct Substitution 76
2.4.2 Solution by the Method of Constrained Variation 77
2.4.3 Solution by the Method of Lagrange Multipliers 85
vii
viii Contents
2.5 Multivariable Optimization with Inequality Constraints 93
2.5.1 Kuhn–Tucker Conditions 98
2.5.2 Constraint Qualification 98
2.6 Convex Programming Problem 104
References and Bibliography 105
Review Questions 105
Problems 106
3 Linear Programming I: Simplex Method 119
3.1 Introduction 119
3.2 Applications of Linear Programming 120
3.3 Standard Form of a Linear Programming Problem 122
3.4 Geometry of Linear Programming Problems 124
3.5 Definitions and Theorems 127
3.6 Solution of a System of Linear Simultaneous Equations 133
3.7 Pivotal Reduction of a General System of Equations 135
3.8 Motivation of the Simplex Method 138
3.9 Simplex Algorithm 139
3.9.1 Identifying an Optimal Point 140
3.9.2 Improving a Nonoptimal Basic Feasible Solution 141
3.10 Two Phases of the Simplex Method 150
3.11 MATLAB Solution of LP Problems 156
References and Bibliography 158
Review Questions 158
Problems 160
4 Linear Programming II: Additional Topics and Extensions 177
4.1 Introduction 177
4.2 Revised Simplex Method 177
4.3 Duality in Linear Programming 192
4.3.1 Symmetric Primal–Dual Relations 192
4.3.2 General Primal–Dual Relations 193
4.3.3 Primal–Dual Relations When the Primal Is in Standard Form 193
4.3.4 Duality Theorems 195
4.3.5 Dual Simplex Method 195
4.4 Decomposition Principle 200
4.5 Sensitivity or Postoptimality Analysis 207
4.5.1 Changes in the Right-Hand-Side Constants bi 208
4.5.2 Changes in the Cost Coefficients cj 212
4.5.3 Addition of New Variables 214
4.5.4 Changes in the Constraint Coefficients aij 215
4.5.5 Addition of Constraints 218
4.6 Transportation Problem 220
Contents ix
4.7 Karmarkar’s Interior Method 222
4.7.1 Statement of the Problem 223
4.7.2 Conversion of an LP Problem into the Required Form 224
4.7.3 Algorithm 226
4.8 Quadratic Programming 229
4.9 MATLAB Solutions 235
References and Bibliography 237
Review Questions 239
Problems 239
5 Nonlinear Programming I: One-Dimensional Minimization Methods 248
5.1 Introduction 248
5.2 Unimodal Function 253
ELIMINATION METHODS 254
5.3 Unrestricted Search 254
5.3.1 Search with Fixed Step Size 254
5.3.2 Search with Accelerated Step Size 255
5.4 Exhaustive Search 256
5.5 Dichotomous Search 257
5.6 Interval Halving Method 260
5.7 Fibonacci Method 263
5.8 Golden Section Method 267
5.9 Comparison of Elimination Methods 271
INTERPOLATION METHODS 271
5.10 Quadratic Interpolation Method 273
5.11 Cubic Interpolation Method 280
5.12 Direct Root Methods 286
5.12.1 Newton Method 286
5.12.2 Quasi-Newton Method 288
5.12.3 Secant Method 290
5.13 Practical Considerations 293
5.13.1 How to Make the Methods Efficient and More Reliable 293
5.13.2 Implementation in Multivariable Optimization Problems 293
5.13.3 Comparison of Methods 294
5.14 MATLAB Solution of One-Dimensional Minimization Problems 294
References and Bibliography 295
Review Questions 295
Problems 296
x Contents
6 Nonlinear Programming II: Unconstrained Optimization Techniques 301
6.1 Introduction 301
6.1.1 Classification of Unconstrained Minimization Methods 304
6.1.2 General Approach 305
6.1.3 Rate of Convergence 305
6.1.4 Scaling of Design Variables 305
DIRECT SEARCH METHODS 309
6.2 Random Search Methods 309
6.2.1 Random Jumping Method 311
6.2.2 Random Walk Method 312
6.2.3 Random Walk Method with Direction Exploitation 313
6.2.4 Advantages of Random Search Methods 314
6.3 Grid Search Method 314
6.4 Univariate Method 315
6.5 Pattern Directions 318
6.6 Powell’s Method 319
6.6.1 Conjugate Directions 319
6.6.2 Algorithm 323
6.7 Simplex Method 328
6.7.1 Reflection 328
6.7.2 Expansion 331
6.7.3 Contraction 332
INDIRECT SEARCH (DESCENT) METHODS 335
6.8 Gradient of a Function 335
6.8.1 Evaluation of the Gradient 337
6.8.2 Rate of Change of a Function along a Direction 338
6.9 Steepest Descent (Cauchy) Method 339
6.10 Conjugate Gradient (Fletcher–Reeves) Method 341
6.10.1 Development of the Fletcher–Reeves Method 342
6.10.2 Fletcher–Reeves Method 343
6.11 Newton’s Method 345
6.12 Marquardt Method 348
6.13 Quasi-Newton Methods 350
6.13.1 Rank 1 Updates 351
6.13.2 Rank 2 Updates 352
6.14 Davidon–Fletcher–Powell Method 354
6.15 Broyden–Fletcher–Goldfarb–Shanno Method 360
6.16 Test Functions 363
6.17 MATLAB Solution of Unconstrained Optimization Problems 365
References and Bibliography 366
Review Questions 368
Problems 370
Contents xi
7 Nonlinear Programming III: Constrained Optimization Techniques 380
7.1 Introduction 380
7.2 Characteristics of a Constrained Problem 380
DIRECT METHODS 383
7.3 Random Search Methods 383
7.4 Complex Method 384
7.5 Sequential Linear Programming 387
7.6 Basic Approach in the Methods of Feasible Directions 393
7.7 Zoutendijk’s Method of Feasible Directions 394
7.7.1 Direction-Finding Problem 395
7.7.2 Determination of Step Length 398
7.7.3 Termination Criteria 401
7.8 Rosen’s Gradient Projection Method 404
7.8.1 Determination of Step Length 407
7.9 Generalized Reduced Gradient Method 412
7.10 Sequential Quadratic Programming 422
7.10.1 Derivation 422
7.10.2 Solution Procedure 425
INDIRECT METHODS 428
7.11 Transformation Techniques 428
7.12 Basic Approach of the Penalty Function Method 430
7.13 Interior Penalty Function Method 432
7.14 Convex Programming Problem 442
7.15 Exterior Penalty Function Method 443
7.16 Extrapolation Techniques in the Interior Penalty Function Method 447
7.16.1 Extrapolation of the Design Vector X 448
7.16.2 Extrapolation of the Function f 450
7.17 Extended Interior Penalty Function Methods 451
7.17.1 Linear Extended Penalty Function Method 451
7.17.2 Quadratic Extended Penalty Function Method 452
7.18 Penalty Function Method for Problems with Mixed Equality and Inequality
Constraints 453
7.18.1 Interior Penalty Function Method 454
7.18.2 Exterior Penalty Function Method 455
7.19 Penalty Function Method for Parametric Constraints 456
7.19.1 Parametric Constraint 456
7.19.2 Handling Parametric Constraints 457
7.20 Augmented Lagrange Multiplier Method 459
7.20.1 Equality-Constrained Problems 459
7.20.2 Inequality-Constrained Problems 462
7.20.3 Mixed Equality–Inequality-Constrained Problems 463
xii Contents
7.21 Checking the Convergence of Constrained Optimization Problems 464
7.21.1 Perturbing the Design Vector 465
7.21.2 Testing the Kuhn–Tucker Conditions 465
7.22 Test Problems 467
7.22.1 Design of a Three-Bar Truss 467
7.22.2 Design of a Twenty-Five-Bar Space Truss 468
7.22.3 Welded Beam Design 470
7.22.4 Speed Reducer (Gear Train) Design 472
7.22.5 Heat Exchanger Design 473
7.23 MATLAB Solution of Constrained Optimization Problems 474
References and Bibliography 476
Review Questions 478
Problems 480
8 Geometric Programming 492
8.1 Introduction 492
8.2 Posynomial 492
8.3 Unconstrained Minimization Problem 493
8.4 Solution of an Unconstrained Geometric Programming Program Using Differential
Calculus 493
8.5 Solution of an Unconstrained Geometric Programming Problem Using
Arithmetic–Geometric Inequality 500
8.6 Primal–Dual Relationship and Sufficiency Conditions in the Unconstrained
Case 501
8.7 Constrained Minimization 508
8.8 Solution of a Constrained Geometric Programming Problem 509
8.9 Primal and Dual Programs in the Case of Less-Than Inequalities 510
8.10 Geometric Programming with Mixed Inequality Constraints 518
8.11 Complementary Geometric Programming 520
8.12 Applications of Geometric Programming 525
References and Bibliography 537
Review Questions 539
Problems 540
9 Dynamic Programming 544
9.1 Introduction 544
9.2 Multistage Decision Processes 545
9.2.1 Definition and Examples 545
9.2.2 Representation of a Multistage Decision Process 546
9.2.3 Conversion of a Nonserial System to a Serial System 548
9.2.4 Types of Multistage Decision Problems 548
9.3 Concept of Suboptimization and Principle of Optimality 549
9.4 Computational Procedure in Dynamic Programming 553
Contents xiii
9.5 Example Illustrating the Calculus Method of Solution 555
9.6 Example Illustrating the Tabular Method of Solution 560
9.7 Conversion of a Final Value Problem into an Initial Value Problem 566
9.8 Linear Programming as a Case of Dynamic Programming 569
9.9 Continuous Dynamic Programming 573
9.10 Additional Applications 576
9.10.1 Design of Continuous Beams 576
9.10.2 Optimal Layout (Geometry) of a Truss 577
9.10.3 Optimal Design of a Gear Train 579
9.10.4 Design of a Minimum-Cost Drainage System 579
References and Bibliography 581
Review Questions 582
Problems 583
10 Integer Programming 588
10.1 Introduction 588
INTEGER LINEAR PROGRAMMING 589
10.2 Graphical Representation 589
10.3 Gomory’s Cutting Plane Method 591
10.3.1 Concept of a Cutting Plane 591
10.3.2 Gomory’s Method for All-Integer Programming Problems 592
10.3.3 Gomory’s Method for Mixed-Integer Programming Problems 599
10.4 Balas’ Algorithm for Zero–One Programming Problems 604
INTEGER NONLINEAR PROGRAMMING 606
10.5 Integer Polynomial Programming 606
10.5.1 Representation of an Integer Variable by an Equivalent System of Binary
Variables 607
10.5.2 Conversion of a Zero–One Polynomial Programming Problem into a
Zero–One LP Problem 608
10.6 Branch-and-Bound Method 609
10.7 Sequential Linear Discrete Programming 614
10.8 Generalized Penalty Function Method 619
10.9 Solution of Binary Programming Problems Using MATLAB 624
References and Bibliography 625
Review Questions 626
Problems 627
11 Stochastic Programming 632
11.1 Introduction 632
11.2 Basic Concepts of Probability Theory 632
11.2.1 Definition of Probability 632
xiv Contents
11.2.2 Random Variables and Probability Density Functions 633
11.2.3 Mean and Standard Deviation 635
11.2.4 Function of a Random Variable 638
11.2.5 Jointly Distributed Random Variables 639
11.2.6 Covariance and Correlation 640
11.2.7 Functions of Several Random Variables 640
11.2.8 Probability Distributions 643
11.2.9 Central Limit Theorem 647
11.3 Stochastic Linear Programming 647
11.4 Stochastic Nonlinear Programming 652
11.4.1 Objective Function 652
11.4.2 Constraints 653
11.5 Stochastic Geometric Programming 659
References and Bibliography 661
Review Questions 662
Problems 663
12 Optimal Control and Optimality Criteria Methods 668
12.1 Introduction 668
12.2 Calculus of Variations 668
12.2.1 Introduction 668
12.2.2 Problem of Calculus of Variations 669
12.2.3 Lagrange Multipliers and Constraints 675
12.2.4 Generalization 678
12.3 Optimal Control Theory 678
12.3.1 Necessary Conditions for Optimal Control 679
12.3.2 Necessary Conditions for a General Problem 681
12.4 Optimality Criteria Methods 683
12.4.1 Optimality Criteria with a Single Displacement Constraint 683
12.4.2 Optimality Criteria with Multiple Displacement Constraints 684
12.4.3 Reciprocal Approximations 685
References and Bibliography 689
Review Questions 689
Problems 690
13 Modern Methods of Optimization 693
13.1 Introduction 693
13.2 Genetic Algorithms 694
13.2.1 Introduction 694
13.2.2 Representation of Design Variables 694
13.2.3 Representation of Objective Function and Constraints 696
13.2.4 Genetic Operators 697
13.2.5 Algorithm 701
Contents xv
13.2.6 Numerical Results 702
13.3 Simulated Annealing 702
13.3.1 Introduction 702
13.3.2 Procedure 703
13.3.3 Algorithm 704
13.3.4 Features of the Method 705
13.3.5 Numerical Results 705
13.4 Particle Swarm Optimization 708
13.4.1 Introduction 708
13.4.2 Computational Implementation of PSO 709
13.4.3 Improvement to the Particle Swarm Optimization Method 710
13.4.4 Solution of the Constrained Optimization Problem 711
13.5 Ant Colony Optimization 714
13.5.1 Basic Concept 714
13.5.2 Ant Searching Behavior 715
13.5.3 Path Retracing and Pheromone Updating 715
13.5.4 Pheromone Trail Evaporation 716
13.5.5 Algorithm 717
13.6 Optimization of Fuzzy Systems 722
13.6.1 Fuzzy Set Theory 722
13.6.2 Optimization of Fuzzy Systems 725
13.6.3 Computational Procedure 726
13.6.4 Numerical Results 727
13.7 Neural-Network-Based Optimization 727
References and Bibliography 730
Review Questions 732
Problems 734
14 Practical Aspects of Optimization 737
14.1 Introduction 737
14.2 Reduction of Size of an Optimization Problem 737
14.2.1 Reduced Basis Technique 737
14.2.2 Design Variable Linking Technique 738
14.3 Fast Reanalysis Techniques 740
14.3.1 Incremental Response Approach 740
14.3.2 Basis Vector Approach 743
14.4 Derivatives of Static Displacements and Stresses 745
14.5 Derivatives of Eigenvalues and Eigenvectors 747
14.5.1 Derivatives of λi 747
14.5.2 Derivatives of Yi 748
14.6 Derivatives of Transient Response 749
14.7 Sensitivity of Optimum Solution to Problem Parameters 751
14.7.1 Sensitivity Equations Using Kuhn–Tucker Conditions 752
xvi Contents
14.7.2 Sensitivity Equations Using the Concept of Feasible Direction 754
14.8 Multilevel Optimization 755
14.8.1 Basic Idea 755
14.8.2 Method 756
14.9 Parallel Processing 760
14.10 Multiobjective Optimization 761
14.10.1 Utility Function Method 763
14.10.2 Inverted Utility Function Method 764
14.10.3 Global Criterion Method 764
14.10.4 Bounded Objective Function Method 764
14.10.5 Lexicographic Method 765
14.10.6 Goal Programming Method 765
14.10.7 Goal Attainment Method 766
14.11 Solution of Multiobjective Problems Using MATLAB 767
References and Bibliography 768
Review Questions 771
Problems 772
A Convex and Concave Functions 779
B Some Computational Aspects of Optimization 784
B.1 Choice of Method 784
B.2 Comparison of Unconstrained Methods 784
B.3 Comparison of Constrained Methods 785
B.4 Availability of Computer Programs 786
B.5 Scaling of Design Variables and Constraints 787
B.6 Computer Programs for Modern Methods of Optimization 788
References and Bibliography 789
C Introduction to MATLAB 791
C.1 Features and Special Characters 791
C.2 Defining Matrices in MATLAB 792
C.3 CREATING m-FILES 793
C.4 Optimization Toolbox 793
Answers to Selected Problems 795
Index 803
Preface
The ever-increasing demand on engineers to lower production costs to withstand global
competition has prompted engineers to look for rigorous methods of decision mak-
ing, such as optimization methods, to design and produce products and systems both
economically and efficiently. Optimization techniques, having reached a degree of
maturity in recent years, are being used in a wide spectrum of industries, including
aerospace, automotive, chemical, electrical, construction, and manufacturing industries.
With rapidly advancing computer technology, computers are becoming more powerful,
and correspondingly, the size and the complexity of the problems that can be solved
using optimization techniques are also increasing. Optimization methods, coupled with
modern tools of computer-aided design, are also being used to enhance the creative
process of conceptual and detailed design of engineering systems.
The purpose of this textbook is to present the techniques and applications of engi-
neering optimization in a comprehensive manner. The style of the prior editions has
been retained, with the theory, computational aspects, and applications of engineering
optimization presented with detailed explanations. As in previous editions, essential
proofs and developments of the various techniques are given in a simple manner
without sacrificing accuracy. New concepts are illustrated with the help of numerical
examples. Although most engineering design problems can be solved using nonlin-
ear programming techniques, there are a variety of engineering applications for which
other optimization methods, such as linear, geometric, dynamic, integer, and stochastic
programming techniques, are most suitable. The theory and applications of all these
techniques are also presented in the book. Some of the recently developed methods of
optimization, such as genetic algorithms, simulated annealing, particle swarm optimiza-
tion, ant colony optimization, neural-network-based methods, and fuzzy optimization,
are also discussed. Favorable reactions and encouragement from professors, students,
and other users of the book have provided me with the impetus to prepare this fourth
edition of the book. The following changes have been made from the previous edition:
• Some less-important sections were condensed or deleted.
• Some sections were rewritten for better clarity.
• Some sections were expanded.
• A new chapter on modern methods of optimization is added.
• Several examples to illustrate the use of Matlab for the solution of different types
of optimization problems are given.
Features
Each topic in Engineering Optimization: Theory and Practice is self-contained, with all
concepts explained fully and the derivations presented with complete details. The com-
putational aspects are emphasized throughout with design examples and problems taken
xvii
xviii Preface
from several fields of engineering to make the subject appealing to all branches of
engineering. A large number of solved examples, review questions, problems,
project-type problems, figures, and references are included to enhance the presentation
of the material.
Specific features of the book include:
• More than 130 illustrative examples accompanying most topics.
• More than 480 references to the literature of engineering optimization theory and
applications.
• More than 460 review questions to help students in reviewing and testing their
understanding of the text material.
• More than 510 problems, with solutions to most problems in the instructor’s
manual.
• More than 10 examples to illustrate the use of Matlab for the numerical solution
of optimization problems.
• Answers to review questions at the web site of the book, www.wiley.com/rao.
I used different parts of the book to teach optimum design and engineering opti-
mization courses at the junior/senior level as well as first-year-graduate-level at Indian
Institute of Technology, Kanpur, India; Purdue University, West Lafayette, Indiana; and
University of Miami, Coral Gables, Florida. At University of Miami, I cover Chapters 1,
2, 3, 5, 6, and 7 and parts of Chapters 8, 10, 12, and 13 in a dual-level course entitled
Mechanical System Optimization . In this course, a design project is also assigned to
each student in which the student identifies, formulates, and solves a practical engineer-
ing problem of his/her interest by applying or modifying an optimization technique.
This design project gives the student a feeling for ways that optimization methods work
in practice. The book can also be used, with some supplementary material, for a sec-
ond course on engineering optimization or optimum design or structural optimization.
The relative simplicity with which the various topics are presented makes the book
useful both to students and to practicing engineers for purposes of self-study. The book
also serves as a reference source for different engineering optimization applications.
Although the emphasis of the book is on engineering applications, it would also be use-
ful to other areas, such as operations research and economics. A knowledge of matrix
theory and differential calculus is assumed on the part of the reader.
Contents
The book consists of fourteen chapters and three appendixes. Chapter 1 provides an
introduction to engineering optimization and optimum design and an overview of opti-
mization methods. The concepts of design space, constraint surfaces, and contours of
objective function are introduced here. In addition, the formulation of various types of
optimization problems is illustrated through a variety of examples taken from various
fields of engineering. Chapter 2 reviews the essentials of differential calculus useful
in finding the maxima and minima of functions of several variables. The methods of
constrained variation and Lagrange multipliers are presented for solving problems with
equality constraints. The Kuhn–Tucker conditions for inequality-constrained problems
are given along with a discussion of convex programming problems.
Preface xix
Chapters 3 and 4 deal with the solution of linear programming problems. The
characteristics of a general linear programming problem and the development of the
simplex method of solution are given in Chapter 3. Some advanced topics in linear
programming, such as the revised simplex method, duality theory, the decomposition
principle, and post-optimality analysis, are discussed in Chapter 4. The extension of
linear programming to solve quadratic programming problems is also considered in
Chapter 4.
Chapters 5–7 deal with the solution of nonlinear programming problems. In
Chapter 5, numerical methods of finding the optimum solution of a function of a single
variable are given. Chapter 6 deals with the methods of unconstrained optimization.
The algorithms for various zeroth-, first-, and second-order techniques are discussed
along with their computational aspects. Chapter 7 is concerned with the solution of
nonlinear optimization problems in the presence of inequality and equality constraints.
Both the direct and indirect methods of optimization are discussed. The methods
presented in this chapter can be treated as the most general techniques for the solution
of any optimization problem.
Chapter 8 presents the techniques of geometric programming. The solution tech-
niques for problems of mixed inequality constraints and complementary geometric
programming are also considered. In Chapter 9, computational procedures for solving
discrete and continuous dynamic programming problems are presented. The problem
of dimensionality is also discussed. Chapter 10 introduces integer programming and
gives several algorithms for solving integer and discrete linear and nonlinear optimiza-
tion problems. Chapter 11 reviews the basic probability theory and presents techniques
of stochastic linear, nonlinear, and geometric programming. The theory and applica-
tions of calculus of variations, optimal control theory, and optimality criteria methods
are discussed briefly in Chapter 12. Chapter 13 presents several modern methods of
optimization including genetic algorithms, simulated annealing, particle swarm opti-
mization, ant colony optimization, neural-network-based methods, and fuzzy system
optimization. Several of the approximation techniques used to speed up the conver-
gence of practical mechanical and structural optimization problems, as well as parallel
computation and multiobjective optimization techniques are outlined in Chapter 14.
Appendix A presents the definitions and properties of convex and concave functions.
A brief discussion of the computational aspects and some of the commercial optimiza-
tion programs is given in Appendix B. Finally, Appendix C presents a brief introduction
to Matlab, optimization toolbox, and use of Matlab programs for the solution of opti-
mization problems.
Acknowledgment
I wish to thank my wife, Kamala, for her patience, understanding, encouragement, and
support in preparing the manuscript.
S. S. Rao
srao@miami.edu
January 2009
1
Introduction to Optimization
1.1 INTRODUCTION
Optimization is the act of obtaining the best result under given circumstances. In design,
construction, and maintenance of any engineering system, engineers have to take many
technological and managerial decisions at several stages. The ultimate goal of all such
decisions is either to minimize the effort required or to maximize the desired benefit.
Since the effort required or the benefit desired in any practical situation can be expressed
as a function of certain decision variables, optimization can be defined as the process
of finding the conditions that give the maximum or minimum value of a function. It can
be seen from Fig. 1.1 that if a point x∗ corresponds to the minimum value of function
f (x), the same point also corresponds to the maximum value of the negative of the
function, −f (x). Thus without loss of generality, optimization can be taken to mean
minimization since the maximum of a function can be found by seeking the minimum
of the negative of the same function.
In addition, the following operations on the objective function will not change the
optimum solution x∗ (see Fig. 1.2):
1. Multiplication (or division) of f (x) by a positive constant c.
2. Addition (or subtraction) of a positive constant c to (or from) f (x).
There is no single method available for solving all optimization problems effi-
ciently. Hence a number of optimization methods have been developed for solving
different types of optimization problems. The optimum seeking methods are also known
as mathematical programming techniques and are generally studied as a part of oper-
ations research. Operations research is a branch of mathematics concerned with the
application of scientific methods and techniques to decision making problems and with
establishing the best or optimal solutions. The beginnings of the subject of operations
research can be traced to the early period of World War II. During the war, the British
military faced the problem of allocating very scarce and limited resources (such as
fighter airplanes, radars, and submarines) to several activities (deployment to numer-
ous targets and destinations). Because there were no systematic methods available to
solve resource allocation problems, the military called upon a team of mathematicians
to develop methods for solving the problem in a scientific manner. The methods devel-
oped by the team were instrumental in the winning of the Air Battle by Britain. These
methods, such as linear programming, which were developed as a result of research
on (military) operations, subsequently became known as the methods of operations
research.
1Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
2 Introduction to Optimization
Figure 1.1 Minimum of f (x) is same as maximum of −f (x).
cf(x)
cf(x)
f(x)
f(x)
f(x)
f(x) f(x)
cf*
f* f*
x*
x
x*
x
c + f(x)
c + f*
Figure 1.2 Optimum solution of cf (x) or c + f (x) same as that of f (x).
Table 1.1 lists various mathematical programming techniques together with other
well-defined areas of operations research. The classification given in Table 1.1 is not
unique; it is given mainly for convenience.
Mathematical programming techniques are useful in finding the minimum of a
function of several variables under a prescribed set of constraints. Stochastic process
techniques can be used to analyze problems described by a set of random variables
having known probability distributions. Statistical methods enable one to analyze the
experimental data and build empirical models to obtain the most accurate represen-
tation of the physical situation. This book deals with the theory and application of
mathematical programming techniques suitable for the solution of engineering design
problems.
1.2 Historical Development 3
Table 1.1 Methods of Operations Research
Mathematical programming or Stochastic process
optimization techniques techniques Statistical methods
Calculus methods Statistical decision theory Regression analysis
Calculus of variations Markov processes Cluster analysis, pattern
recognitionNonlinear programming Queueing theory
Geometric programming Renewal theory Design of experiments
Quadratic programming Simulation methods Discriminate analysis
(factor analysis)Linear programming Reliability theory
Dynamic programming
Integer programming
Stochastic programming
Separable programming
Multiobjective programming
Network methods: CPM and PERT
Game theory
Modern or nontraditional optimization techniques
Genetic algorithms
Simulated annealing
Ant colony optimization
Particle swarm optimization
Neural networks
Fuzzy optimization
1.2 HISTORICAL DEVELOPMENT
The existence of optimization methods can be traced to the days of Newton, Lagrange,
and Cauchy. The development of differential calculus methods of optimization was
possible because of the contributions of Newton and Leibnitz to calculus. The founda-
tions of calculus of variations, which deals with the minimization of functionals, were
laid by Bernoulli, Euler, Lagrange, and Weirstrass. The method of optimization for con-
strained problems, which involves the addition of unknown multipliers, became known
by the name of its inventor, Lagrange. Cauchy made the first application of the steep-
est descent method to solve unconstrained minimization problems. Despite these early
contributions, very little progress was made until the middle of the twentieth century,
when high-speed digital computers made implementation of the optimization proce-
dures possible and stimulated further research on new methods. Spectacular advances
followed, producing a massive literature on optimization techniques. This advance-
ment also resulted in the emergence of several well-defined new areas in optimization
theory.
It is interesting to note that the major developments in the area of numerical meth-
ods of unconstrained optimization have been made in the United Kingdom only in the
1960s. The development of the simplex method by Dantzig in 1947 for linear program-
ming problems and the annunciation of the principle of optimality in 1957 by Bellman
for dynamic programming problems paved the way for development of the methods
of constrained optimization. Work by Kuhn and Tucker in 1951 on the necessary and
4 Introduction to Optimization
sufficiency conditions for the optimal solution of programming problems laid the foun-
dations for a great deal of later research in nonlinear programming. The contributions
of Zoutendijk and Rosen to nonlinear programming during the early 1960s have been
significant. Although no single technique has been found to be universally applica-
ble for nonlinear programming problems, work of Carroll and Fiacco and McCormick
allowed many difficult problems to be solved by using the well-known techniques of
unconstrained optimization. Geometric programming was developed in the 1960s by
Duffin, Zener, and Peterson. Gomory did pioneering work in integer programming,
one of the most exciting and rapidly developing areas of optimization. The reason for
this is that most real-world applications fall under this category of problems. Dantzig
and Charnes and Cooper developed stochastic programming techniques and solved
problems by assuming design parameters to be independent and normally distributed.
The desire to optimize more than one objective or goal while satisfying the phys-
ical limitations led to the development of multiobjective programming methods. Goal
programming is a well-known technique for solving specific types of multiobjective
optimization problems. The goal programming was originally proposed for linear prob-
lems by Charnes and Cooper in 1961. The foundations of game theory were laid by
von Neumann in 1928 and since then the technique has been applied to solve several
mathematical economics and military problems. Only during the last few years has
game theory been applied to solve engineering design problems.
Modern Methods of Optimization. The modern optimization methods, also some-
times called nontraditional optimization methods, have emerged as powerful and pop-
ular methods for solving complex engineering optimization problems in recent years.
These methods include genetic algorithms, simulated annealing, particle swarm opti-
mization, ant colony optimization, neural network-based optimization, and fuzzy opti-
mization. The genetic algorithms are computerized search and optimization algorithms
based on the mechanics of natural genetics and natural selection. The genetic algorithms
were originally proposed by John Holland in 1975. The simulated annealing method
is based on the mechanics of the cooling process of molten metals through annealing.
The method was originally developed by Kirkpatrick, Gelatt, and Vecchi.
The particle swarm optimization algorithm mimics the behavior of social organisms
such as a colony or swarm of insects (for example, ants, termites, bees, and wasps), a
flock of birds, and a school of fish. The algorithm was originally proposed by Kennedy
and Eberhart in 1995. The ant colony optimization is based on the cooperative behavior
of ant colonies, which are able to find the shortest path from their nest to a food
source. The method was first developed by Marco Dorigo in 1992. The neural network
methods are based on the immense computational power of the nervous system to solve
perceptional problems in the presence of massive amount of sensory data through its
parallel processing capability. The method was originally used for optimization by
Hopfield and Tank in 1985. The fuzzy optimization methods were developed to solve
optimization problems involving design data, objective function, and constraints stated
in imprecise form involving vague and linguistic descriptions. The fuzzy approaches
for single and multiobjective optimization in engineering design were first presented
by Rao in 1986.
1.3 Engineering Applications of Optimization 5
1.3 ENGINEERING APPLICATIONS OF OPTIMIZATION
Optimization, in its broadest sense, can be applied to solve any engineering problem.
Some typical applications from different engineering disciplines indicate the wide scope
of the subject:
1. Design of aircraft and aerospace structures for minimum weight
2. Finding the optimal trajectories of space vehicles
3. Design of civil engineering structures such as frames, foundations, bridges,
towers, chimneys, and dams for minimum cost
4. Minimum-weight design of structures for earthquake, wind, and other types of
random loading
5. Design of water resources systems for maximum benefit
6. Optimal plastic design of structures
7. Optimum design of linkages, cams, gears, machine tools, and other mechanical
components
8. Selection of machining conditions in metal-cutting processes for minimum pro-
duction cost
9. Design of material handling equipment, such as conveyors, trucks, and cranes,
for minimum cost
10. Design of pumps, turbines, and heat transfer equipment for maximum efficiency
11. Optimum design of electrical machinery such as motors, generators, and trans-
formers
12. Optimum design of electrical networks
13. Shortest route taken by a salesperson visiting various cities during one tour
14. Optimal production planning, controlling, and scheduling
15. Analysis of statistical data and building empirical models from experimental
results to obtain the most accurate representation of the physical phenomenon
16. Optimum design of chemical processing equipment and plants
17. Design of optimum pipeline networks for process industries
18. Selection of a site for an industry
19. Planning of maintenance and replacement of equipment to reduce operating
costs
20. Inventory control
21. Allocation of resources or services among several activities to maximize the
benefit
22. Controlling the waiting and idle times and queueing in production lines to reduce
the costs
23. Planning the best strategy to obtain maximum profit in the presence of a com-
petitor
24. Optimum design of control systems
6 Introduction to Optimization
1.4 STATEMENT OF AN OPTIMIZATION PROBLEM
An optimization or a mathematical programming problem can be stated as follows.
Find X =









x1
x2
...
xn









which minimizes f (X)
subject to the constraints
gj (X) ≤ 0, j = 1, 2, . . . , m
lj (X) = 0, j = 1, 2, . . . , p
(1.1)
where X is an n-dimensional vector called the design vector , f (X) is termed the objec-
tive function , and gj (X) and lj (X) are known as inequality and equality constraints,
respectively. The number of variables n and the number of constraints m and/or p
need not be related in any way. The problem stated in Eq. (1.1) is called a constrained
optimization problem.† Some optimization problems do not involve any constraints and
can be stated as
Find X =









x1
x2
...
xn









which minimizes f (X) (1.2)
Such problems are called unconstrained optimization problems .
1.4.1 Design Vector
Any engineering system or component is defined by a set of quantities some of which
are viewed as variables during the design process. In general, certain quantities are
usually fixed at the outset and these are called preassigned parameters . All the other
quantities are treated as variables in the design process and are called design or decision
variables xi, i = 1, 2, . . . , n. The design variables are collectively represented as a
design vector X = {x1, x2, . . . , xn}T. As an example, consider the design of the gear
pair shown in Fig. 1.3, characterized by its face width b, number of teeth T1 and
T2, center distance d , pressure angle ψ , tooth profile, and material. If center distance
d , pressure angle ψ , tooth profile, and material of the gears are fixed in advance,
these quantities can be called preassigned parameters . The remaining quantities can be
collectively represented by a design vector X = {x1, x2, x3}T = {b, T1, T2}T. If there are
no restrictions on the choice of b, T1, and T2, any set of three numbers will constitute a
design for the gear pair. If an n-dimensional Cartesian space with each coordinate axis
representing a design variable xi (i = 1, 2, . . . , n) is considered, the space is called
†In the mathematical programming literature, the equality constraints lj (X) = 0, j = 1, 2, . . . , p are often
neglected, for simplicity, in the statement of a constrained optimization problem, although several methods
are available for handling problems with equality constraints.
1.4 Statement of an Optimization Problem 7
Figure 1.3 Gear pair in mesh.
the design variable space or simply design space. Each point in the n-dimensional
design space is called a design point and represents either a possible or an impossible
solution to the design problem. In the case of the design of a gear pair, the design
point {1.0, 20, 40}T, for example, represents a possible solution, whereas the design
point {1.0, −20, 40.5}T represents an impossible solution since it is not possible to
have either a negative value or a fractional value for the number of teeth.
1.4.2 Design Constraints
In many practical problems, the design variables cannot be chosen arbitrarily; rather,
they have to satisfy certain specified functional and other requirements. The restrictions
that must be satisfied to produce an acceptable design are collectively called design
constraints . Constraints that represent limitations on the behavior or performance of
the system are termed behavior or functional constraints . Constraints that represent
physical limitations on design variables, such as availability, fabricability, and trans-
portability, are known as geometric or side constraints . For example, for the gear pair
shown in Fig. 1.3, the face width b cannot be taken smaller than a certain value, due
to strength requirements. Similarly, the ratio of the numbers of teeth, T1/T2, is dictated
by the speeds of the input and output shafts, N1 and N2. Since these constraints depend
on the performance of the gear pair, they are called behavior constraints. The values
of T1 and T2 cannot be any real numbers but can only be integers. Further, there can
be upper and lower bounds on T1 and T2 due to manufacturing limitations. Since these
constraints depend on the physical limitations, they are called side constraints .
8 Introduction to Optimization
1.4.3 Constraint Surface
For illustration, consider an optimization problem with only inequality constraints
gj (X) ≤ 0. The set of values of X that satisfy the equation gj (X) = 0 forms a hyper-
surface in the design space and is called a constraint surface. Note that this is an
(n − 1)-dimensional subspace, where n is the number of design variables. The constraint
surface divides the design space into two regions: one in which gj (X) < 0 and the other
in which gj (X) > 0. Thus the points lying on the hypersurface will satisfy the constraint
gj (X) critically, whereas the points lying in the region where gj (X) > 0 are infeasible
or unacceptable, and the points lying in the region where gj (X) < 0 are feasible or
acceptable. The collection of all the constraint surfaces gj (X) = 0, j = 1, 2, . . . ,m,
which separates the acceptable region is called the composite constraint surface.
Figure 1.4 shows a hypothetical two-dimensional design space where the infeasible
region is indicated by hatched lines. A design point that lies on one or more than one
constraint surface is called a bound point , and the associated constraint is called an
active constraint . Design points that do not lie on any constraint surface are known as
free points . Depending on whether a particular design point belongs to the acceptable
or unacceptable region, it can be identified as one of the following four types:
1. Free and acceptable point
2. Free and unacceptable point
3. Bound and acceptable point
4. Bound and unacceptable point
All four types of points are shown in Fig. 1.4.
Figure 1.4 Constraint surfaces in a hypothetical two-dimensional design space.
1.4 Statement of an Optimization Problem 9
1.4.4 Objective Function
The conventional design procedures aim at finding an acceptable or adequate design
that merely satisfies the functional and other requirements of the problem. In general,
there will be more than one acceptable design, and the purpose of optimization is
to choose the best one of the many acceptable designs available. Thus a criterion
has to be chosen for comparing the different alternative acceptable designs and for
selecting the best one. The criterion with respect to which the design is optimized,
when expressed as a function of the design variables, is known as the criterion or merit
or objective function . The choice of objective function is governed by the nature of
problem. The objective function for minimization is generally taken as weight in aircraft
and aerospace structural design problems. In civil engineering structural designs, the
objective is usually taken as the minimization of cost. The maximization of mechanical
efficiency is the obvious choice of an objective in mechanical engineering systems
design. Thus the choice of the objective function appears to be straightforward in most
design problems. However, there may be cases where the optimization with respect
to a particular criterion may lead to results that may not be satisfactory with respect
to another criterion. For example, in mechanical design, a gearbox transmitting the
maximum power may not have the minimum weight. Similarly, in structural design,
the minimum weight design may not correspond to minimum stress design, and the
minimum stress design, again, may not correspond to maximum frequency design. Thus
the selection of the objective function can be one of the most important decisions in
the whole optimum design process.
In some situations, there may be more than one criterion to be satisfied simul-
taneously. For example, a gear pair may have to be designed for minimum weight
and maximum efficiency while transmitting a specified horsepower. An optimization
problem involving multiple objective functions is known as a multiobjective program-
ming problem . With multiple objectives there arises a possibility of conflict, and one
simple way to handle the problem is to construct an overall objective function as a
linear combination of the conflicting multiple objective functions. Thus if f1(X) and
f2(X) denote two objective functions, construct a new (overall) objective function for
optimization as
f (X) = α1f1(X) + α2f2(X) (1.3)
where α1 and α2 are constants whose values indicate the relative importance of one
objective function relative to the other.
1.4.5 Objective Function Surfaces
The locus of all points satisfying f (X) = C = constant forms a hypersurface in the
design space, and each value of C corresponds to a different member of a family of
surfaces. These surfaces, called objective function surfaces , are shown in a hypothetical
two-dimensional design space in Fig. 1.5.
Once the objective function surfaces are drawn along with the constraint surfaces,
the optimum point can be determined without much difficulty. But the main problem
is that as the number of design variables exceeds two or three, the constraint and
objective function surfaces become complex even for visualization and the problem
10 Introduction to Optimization
Figure 1.5 Contours of the objective function.
has to be solved purely as a mathematical problem. The following example illustrates
the graphical optimization procedure.
Example 1.1 Design a uniform column of tubular section, with hinge joints at both
ends, (Fig. 1.6) to carry a compressive load P = 2500 kgf for minimum cost. The
column is made up of a material that has a yield stress (σy) of 500 kgf/cm
2, modulus
of elasticity (E) of 0.85 × 106 kgf/cm2, and weight density (ρ) of 0.0025 kgf/cm3.
The length of the column is 250 cm. The stress induced in the column should be less
than the buckling stress as well as the yield stress. The mean diameter of the column
is restricted to lie between 2 and 14 cm, and columns with thicknesses outside the
range 0.2 to 0.8 cm are not available in the market. The cost of the column includes
material and construction costs and can be taken as 5W + 2d , where W is the weight
in kilograms force and d is the mean diameter of the column in centimeters.
SOLUTION The design variables are the mean diameter (d) and tube thickness (t):
X =
{
x1
x2
}
=
{
d
t
}
(E1)
The objective function to be minimized is given by
f (X) = 5W + 2d = 5ρlπ dt + 2d = 9.82x1x2 + 2x1 (E2)
1.4 Statement of an Optimization Problem 11
i
Figure 1.6 Tubular column under compression.
The behavior constraints can be expressed as
stress induced ≤ yield stress
stress induced ≤ buckling stress
The induced stress is given by
induced stress = σi =
P
π dt
=
2500
πx1x2
(E3)
The buckling stress for a pin-connected column is given by
buckling stress = σb =
Euler buckling load
cross-sectional area
=
π2EI
l2
1
π dt
(E4)
where
I = second moment of area of the cross section of the column
=
π
64
(d4o − d
4
i )
=
π
64
(d2o + d
2
i )(do + di)(do − di) =
π
64
[(d + t)2 + (d − t)2]
× [(d + t) + (d − t)][(d + t) − (d − t)]
=
π
8
dt (d2 + t2) =
π
8
x1x2(x
2
1 + x
2
2 ) (E5)
12 Introduction to Optimization
Thus the behavior constraints can be restated as
g1(X) =
2500
πx1x2
− 500 ≤ 0 (E6)
g2(X) =
2500
πx1x2
−
π2(0.85 × 106)(x21 + x
2
2 )
8(250)2
≤ 0 (E7)
The side constraints are given by
2 ≤ d ≤ 14
0.2 ≤ t ≤ 0.8
which can be expressed in standard form as
g3(X) = −x1 + 2.0 ≤ 0 (E8)
g4(X) = x1 − 14.0 ≤ 0 (E9)
g5(X) = −x2 + 0.2 ≤ 0 (E10)
g6(X) = x2 − 0.8 ≤ 0 (E11)
Since there are only two design variables, the problem can be solved graphically as
shown below.
First, the constraint surfaces are to be plotted in a two-dimensional design space
where the two axes represent the two design variables x1 and x2. To plot the first
constraint surface, we have
g1(X) =
2500
πx1x2
− 500 ≤ 0
that is,
x1x2 ≥ 1.593
Thus the curve x1x2 = 1.593 represents the constraint surface g1(X) = 0. This curve
can be plotted by finding several points on the curve. The points on the curve can be
found by giving a series of values to x1 and finding the corresponding values of x2
that satisfy the relation x1x2 = 1.593:
x1 2.0 4.0 6.0 8.0 10.0 12.0 14.0
x2 0.7965 0.3983 0.2655 0.1990 0.1593 0.1328 0.1140
These points are plotted and a curve P1Q1 passing through all these points is drawn as
shown in Fig. 1.7, and the infeasible region, represented by g1(X) > 0 or x1x2 < 1.593,
is shown by hatched lines.† Similarly, the second constraint g2(X) ≤ 0 can be expressed
as x1x2(x
2
1 + x22) ≥ 47.3 and the points lying on the constraint surface g2(X) = 0 can
be obtained as follows for x1x2(x
2
1 + x
2
2) = 47.3:
†The infeasible region can be identified by testing whether the origin lies in the feasible or infeasible
region.
1.4 Statement of an Optimization Problem 13
Figure 1.7 Graphical optimization of Example 1.1.
x1 2 4 6 8 10 12 14
x2 2.41 0.716 0.219 0.0926 0.0473 0.0274 0.0172
These points are plotted as curve P2Q2, the feasible region is identified, and the infea-
sible region is shown by hatched lines as in Fig. 1.7. The plotting of side constraints
is very simple since they represent straight lines. After plotting all the six constraints,
the feasible region can be seen to be given by the bounded area ABCDEA.
14 Introduction to Optimization
Next, the contours of the objective function are to be plotted before finding the
optimum point. For this, we plot the curves given by
f (X) = 9.82x1x2 + 2x1 = c = constant
for a series of values of c. By giving different values to c, the contours of f can be
plotted with the help of the following points.
For 9.82x1x2 + 2x1 = 50.0:
x2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8
x1 16.77 12.62 10.10 8.44 7.24 6.33 5.64 5.07
For 9.82x1x2 + 2x1 = 40.0:
x2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8
x1 13.40 10.10 8.08 6.75 5.79 5.06 4.51 4.05
For 9.82x1x2 + 2x1 = 31.58 (passing through the corner point C):
x2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8
x1 10.57 7.96 6.38 5.33 4.57 4.00 3.56 3.20
For 9.82x1x2 + 2x1 = 26.53 (passing through the corner point B):
x2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8
x1 8.88 6.69 5.36 4.48 3.84 3.36 2.99 2.69
For 9.82x1x2 + 2x1 = 20.0:
x2 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8
x1 6.70 5.05 4.04 3.38 2.90 2.53 2.26 2.02
These contours are shown in Fig. 1.7 and it can be seen that the objective function
cannot be reduced below a value of 26.53 (corresponding to point B) without violating
some of the constraints. Thus the optimum solution is given by point B with d∗ =
x∗1 = 5.44 cm and t∗ = x
∗
2 = 0.293 cm with fmin = 26.53.
1.5 CLASSIFICATION OF OPTIMIZATION PROBLEMS
Optimization problems can be classified in several ways, as described below.
1.5.1 Classification Based on the Existence of Constraints
As indicated earlier, any optimization problem can be classified as constrained or uncon-
strained, depending on whether constraints exist in the problem.
1.5 Classification of Optimization Problems 15
1.5.2 Classification Based on the Nature of the Design Variables
Based on the nature of design variables encountered, optimization problems can be
classified into two broad categories. In the first category, the problem is to find values
to a set of design parameters that make some prescribed function of these parameters
minimum subject to certain constraints. For example, the problem of minimum-weight
design of a prismatic beam shown in Fig. 1.8a subject to a limitation on the maximum
deflection can be stated as follows:
Find X =
{
b
d
}
which minimizes
f (X) = ρlbd
(1.4)
subject to the constraints
δtip(X) ≤ δmax
b ≥ 0
d ≥ 0
where ρ is the density and δtip is the tip deflection of the beam. Such problems are
called parameter or static optimization problems . In the second category of problems,
the objective is to find a set of design parameters, which are all continuous functions
of some other parameter, that minimizes an objective function subject to a set of
constraints. If the cross-sectional dimensions of the rectangular beam are allowed to
vary along its length as shown in Fig. 1.8b, the optimization problem can be stated as
Find X(t) =
{
b(t)
d(t)
}
which minimizes
f [X(t)] = ρ
∫ l
0
b(t) d(t) dt (1.5)
subject to the constraints
δtip[X(t)] ≤ δmax, 0 ≤ t ≤ l
b(t) ≥ 0, 0 ≤ t ≤ l
d(t) ≥ 0, 0 ≤ t ≤ l
Figure 1.8 Cantilever beam under concentrated load.
16 Introduction to Optimization
Here the design variables are functions of the length parameter t . This type of problem,
where each design variable is a function of one or more parameters, is known as a
trajectory or dynamic optimization problem [1.55].
1.5.3 Classification Based on the Physical Structure of the Problem
Depending on the physical structure of the problem, optimization problems can be
classified as optimal control and nonoptimal control problems.
Optimal Control Problem. An optimal control (OC) problem is a mathematical pro-
gramming problem involving a number of stages, where each stage evolves from the
preceding stage in a prescribed manner. It is usually described by two types of vari-
ables: the control (design) and the state variables. The control variables define the
system and govern the evolution of the system from one stage to the next, and the state
variables describe the behavior or status of the system in any stage. The problem is
to find a set of control or design variables such that the total objective function (also
known as the performance index , PI) over all the stages is minimized subject to a
set of constraints on the control and state variables. An OC problem can be stated as
follows [1.55]:
Find X which minimizes f (X) =
l
∑
i=1
fi(xi , yi) (1.6)
subject to the constraints
qi(xi , yi) + yi = yi+1, i = 1, 2, . . . , l
gj (xj ) ≤ 0, j = 1, 2, . . . , l
hk(yk) ≤ 0, k = 1, 2, . . . , l
where xi is the ith control variable, yi the ith state variable, and fi the contribution
of the ith stage to the total objective function; gj , hk, and qi are functions of xj , yk,
and xi and yi , respectively, and l is the total number of stages. The control and state
variables xi and yi can be vectors in some cases. The following example serves to
illustrate the nature of an optimal control problem.
Example 1.2 A rocket is designed to travel a distance of 12s in a vertically upward
direction [1.39]. The thrust of the rocket can be changed only at the discrete points
located at distances of 0, s, 2s, 3s, . . . , 12s. If the maximum thrust that can be devel-
oped at point i either in the positive or negative direction is restricted to a value of
Fi , formulate the problem of minimizing the total time of travel under the following
assumptions:
1. The rocket travels against the gravitational force.
2. The mass of the rocket reduces in proportion to the distance traveled.
3. The air resistance is proportional to the velocity of the rocket.
1.5 Classification of Optimization Problems 17
Figure 1.9 Control points in the path of the rocket.
SOLUTION Let points (or control points) on the path at which the thrusts of the
rocket are changed be numbered as 1, 2, 3, . . . , 13 (Fig. 1.9). Denoting xi as the thrust,
vi the velocity, ai the acceleration, and mi the mass of the rocket at point i, Newton’s
second law of motion can be applied as
net force on the rocket = mass × acceleration
This can be written as
thrust − gravitational force − air resistance = mass × acceleration
18 Introduction to Optimization
or
xi − mig − k1vi = miai (E1)
where the mass mi can be expressed as
mi = mi−1 − k2s (E2)
and k1 and k2 are constants. Equation (E1) can be used to express the acceleration, ai ,
as
ai =
xi
mi
− g −
k1vi
mi
(E3)
If ti denotes the time taken by the rocket to travel from point i to point i + 1, the
distance traveled between the points i and i + 1 can be expressed as
s = vi ti + 12ai t
2
i
or
1
2
t2i
(
xi
mi
− g −
k1vi
mi
)
+ tivi − s = 0 (E4)
from which ti can be determined as
ti =
−vi ±
√
v2i + 2s
(
xi
mi
− g −
k1vi
mi
)
xi
mi
− g −
k1vi
mi
(E5)
Of the two values given by Eq. (E5), the positive value has to be chosen for ti . The
velocity of the rocket at point i + 1, vi+1, can be expressed in terms of vi as (by
assuming the acceleration between points i and i + 1 to be constant for simplicity)
vi+1 = vi + ai ti (E6)
The substitution of Eqs. (E3) and (E5) into Eq. (E6) leads to
vi+1 =
√
v2i + 2s
(
xi
mi
− g −
k1vi
mi
)
(E7)
From an analysis of the problem, the control variables can be identified as the thrusts,
xi , and the state variables as the velocities, vi . Since the rocket starts at point 1 and
stops at point 13,
v1 = v13 = 0 (E8)
1.5 Classification of Optimization Problems 19
Thus the problem can be stated as an OC problem as
Find X =









x1
x2
...
x12









which minimizes
f (X) =
12
∑
i=1
ti =
12
∑
i=1











−vi +
√
v2i + 2s
(
xi
mi
− g −
k1vi
mi
)
xi
mi
− g −
k1vi
mi











subject to
mi+1 = mi − k2s, i = 1, 2, . . . , 12
vi+1 =
√
v2i + 2s
(
xi
mi
− g −
k1vi
mi
)
, i = 1, 2, . . . , 12
|xi | ≤ Fi, i = 1, 2, . . . , 12
v1 = v13 = 0
1.5.4 Classification Based on the Nature of the Equations Involved
Another important classification of optimization problems is based on the nature of
expressions for the objective function and the constraints. According to this classi-
fication, optimization problems can be classified as linear, nonlinear, geometric, and
quadratic programming problems. This classification is extremely useful from the com-
putational point of view since there are many special methods available for the efficient
solution of a particular class of problems. Thus the first task of a designer would be
to investigate the class of problem encountered. This will, in many cases, dictate the
types of solution procedures to be adopted in solving the problem.
Nonlinear Programming Problem. If any of the functions among the objective and
constraint functions in Eq. (1.1) is nonlinear, the problem is called a nonlinear pro-
gramming (NLP) problem . This is the most general programming problem and all other
problems can be considered as special cases of the NLP problem.
Example 1.3 The step-cone pulley shown in Fig. 1.10 is to be designed for trans-
mitting a power of at least 0.75 hp. The speed of the input shaft is 350 rpm and the
output speed requirements are 750, 450, 250, and 150 rpm for a fixed center distance
of a between the input and output shafts. The tension on the tight side of the belt is to
be kept more than twice that on the slack side. The thickness of the belt is t and the
coefficient of friction between the belt and the pulleys is µ. The stress induced in the
belt due to tension on the tight side is s. Formulate the problem of finding the width
and diameters of the steps for minimum weight.
20 Introduction to Optimization
Figure 1.10 Step-cone pulley.
SOLUTION The design vector can be taken as
X =













d1
d2
d3
d4
w













where di is the diameter of the ith step on the output pulley and w is the width of the
belt and the steps. The objective function is the weight of the step-cone pulley system:
f (X) = ρw
π
4
(d21 + d
2
2 + d
2
3 + d
2
4 + d
′ 2
1 + d
′ 2
2 + d
′ 2
3 + d
′ 2
4 )
= ρw
π
4
{
d21
[
1 +
(
750
350
)2
]
+ d22
[
1 +
(
450
350
)2
]
+ d23
[
1 +
(
250
350
)2
]
+ d24
[
1 +
(
150
350
)2
]}
(E1)
where ρ is the density of the pulleys and d ′i is the diameter of the ith step on the input
pulley.
1.5 Classification of Optimization Problems 21
To have the belt equally tight on each pair of opposite steps, the total length of the
belt must be kept constant for all the output speeds. This can be ensured by satisfying
the following equality constraints:
C1 − C2 = 0 (E2)
C1 − C3 = 0 (E3)
C1 − C4 = 0 (E4)
where Ci denotes length of the belt needed to obtain output speed Ni (i = 1, 2, 3, 4)
and is given by [1.116, 1.117]:
Ci ≃
πdi
2
(
1 +
Ni
N
)
+
(
Ni
N
− 1
)2
d2i
4a
+ 2a
where N is the speed of the input shaft and a is the center distance between the shafts.
The ratio of tensions in the belt can be expressed as [1.116, 1.117]
T i1
T i2
= eµθi
where T i1 and T
i
2 are the tensions on the tight and slack sides of the ith step, µ the
coefficient of friction, and θi the angle of lap of the belt over the ith pulley step. The
angle of lap is given by
θi = π − 2 sin−1
[
(
Ni
N
− 1
)
di
2a
]
and hence the constraint on the ratio of tensions becomes
exp
{
µ
[
π − 2 sin−1
{(
Ni
N
− 1
)
di
2a
}]}
≥ 2, i = 1, 2, 3, 4 (E5)
The limitation on the maximum tension can be expressed as
T i1 = stw, i = 1, 2, 3, 4 (E6)
where s is the maximum allowable stress in the belt and t is the thickness of the belt.
The constraint on the power transmitted can be stated as (using lbf for force and ft for
linear dimensions)
(T i1 − T
i
2 )πd
′
i(350)
33,000
≥ 0.75
which can be rewritten, using T i1 = stw from Eq. (E6), as
stw
(
1 − exp
[
−µ
(
π − 2 sin−1
{(
Ni
N
− 1
)
di
2a
})])
πd ′i
×
(
350
33,000
)
≥ 0.75, i = 1, 2, 3, 4 (E7)
22 Introduction to Optimization
Finally, the lower bounds on the design variables can be taken as
w ≥ 0 (E8)
di ≥ 0, i = 1, 2, 3, 4 (E9)
As the objective function, (E1), and most of the constraints, (E2) to (E9), are nonlinear
functions of the design variables d1, d2, d3, d4, and w, this problem is a nonlinear
programming problem.
Geometric Programming Problem.
Definition A function h(X) is called a posynomial if h can be expressed as the sum
of power terms each of the form
cix
ai1
1 x
ai2
2 · · · x
ain
n
where ci and aij are constants with ci > 0 and xj > 0. Thus a posynomial with N terms
can be expressed as
h(X) = c1xa111 x
a12
2 · · · x
a1n
n + · · · + cNx
aN1
1 x
aN2
2 · · · x
aNn
n (1.7)
A geometric programming (GMP) problem is one in which the objective function
and constraints are expressed as posynomials in X. Thus GMP problem can be posed
as follows [1.59]:
Find X which minimizes
f (X) =
N0
∑
i=1
ci


n
∏
j=1
x
pij
j

 , ci > 0, xj > 0 (1.8)
subject to
gk(X) =
Nk
∑
i=1
aik


n
∏
j=1
x
qijk
j

 > 0, aik > 0, xj > 0, k = 1, 2, . . . , m
where N0 and Nk denote the number of posynomial terms in the objective and kth
constraint function, respectively.
Example 1.4 Four identical helical springs are used to support a milling machine
weighing 5000 lb. Formulate the problem of finding the wire diameter (d), coil diameter
(D), and the number of turns (N ) of each spring (Fig. 1.11) for minimum weight by
limiting the deflection to 0.1 in. and the shear stress to 10,000 psi in the spring. In
addition, the natural frequency of vibration of the spring is to be greater than 100 Hz.
The stiffness of the spring (k), the shear stress in the spring (τ ), and the natural
frequency of vibration of the spring (fn) are given by
k =
d4G
8D3N
τ = Ks
8FD
πd3
fn =
1
2
√
kg
w
=
1
2
√
d4G
8D3N
g
ρ(πd2/4)πDN
=
√
Gg d
2
√
2ρπD2N
1.5 Classification of Optimization Problems 23
Figure 1.11 Helical spring.
where G is the shear modulus, F the compressive load on the spring, w the weight of
the spring, ρ the weight density of the spring, and Ks the shear stress correction factor.
Assume that the material is spring steel with G = 12 × 106 psi and ρ = 0.3 lb/in3, and
the shear stress correction factor is Ks ≈ 1.05.
SOLUTION The design vector is given by
X =



x1
x2
x3



=



d
D
N



and the objective function by
f (X) = weight =
πd2
4
πDNρ (E1)
The constraints can be expressed as
deflection =
F
k
=
8FD3N
d4G
≤ 0.1
that is,
g1(X) =
d4G
80FD3N
> 1 (E2)
shear stress = Ks
8FD
πd3
≤ 10,000
24 Introduction to Optimization
that is,
g2(X) =
1250πd3
KsFD
> 1 (E3)
natural frequency =
√
Gg
2
√
2ρπ
d
D2N
≥ 100
that is,
g3(X) =
√
Gg d
200
√
2ρπD2N
> 1 (E4)
Since the equality sign is not included (along with the inequality symbol, >) in the
constraints of Eqs. (E2) to (E4), the design variables are to be restricted to positive
values as
d > 0, D > 0, N > 0 (E5)
By substituting the known data, F = weight of the milling machine/4 = 1250 lb, ρ =
0.3 lb/in3, G = 12 × 106 psi, and Ks = 1.05, Eqs. (E1) to (E4) become
f (X) = 1
4
π2(0.3)d2DN = 0.7402x21x2x3 (E6)
g1(X) =
d4(12 × 106)
80(1250)D3N
= 120x41x
−3
2 x
−1
3 > 1 (E7)
g2(X) =
1250πd3
1.05(1250)D
= 2.992x31x
−1
2 > 1 (E8)
g3(X) =
√
Gg d
200
√
2ρπD2N
= 139.8388x1x−22 x
−1
3 > 1 (E9)
It can be seen that the objective function, f (X), and the constraint functions, g1(X) to
g3(X), are posynomials and hence the problem is a GMP problem.
Quadratic Programming Problem. A quadratic programming problem is a nonlinear
programming problem with a quadratic objective function and linear constraints. It is
usually formulated as follows:
F(X) = c +
n
∑
i=1
qixi +
n
∑
i=1
n
∑
j=1
Qijxixj (1.9)
subject to
n
∑
i=1
aijxi = bj , j = 1, 2, . . . , m
xi ≥ 0, i = 1, 2, . . . , n
where c, qi, Qij , aij , and bj are constants.
1.5 Classification of Optimization Problems 25
Example 1.5 A manufacturing firm produces two products, A and B, using two limited
resources. The maximum amounts of resources 1 and 2 available per day are 1000 and
250 units, respectively. The production of 1 unit of product A requires 1 unit of resource
1 and 0.2 unit of resource 2, and the production of 1 unit of product B requires 0.5
unit of resource 1 and 0.5 unit of resource 2. The unit costs of resources 1 and 2 are
given by the relations (0.375 − 0.00005u1) and (0.75 − 0.0001u2), respectively, where
ui denotes the number of units of resource i used (i = 1, 2). The selling prices per unit
of products A and B,pA and pB , are given by
pA = 2.00 − 0.0005xA − 0.00015xB
pB = 3.50 − 0.0002xA − 0.0015xB
where xA and xB indicate, respectively, the number of units of products A and B sold.
Formulate the problem of maximizing the profit assuming that the firm can sell all the
units it manufactures.
SOLUTION Let the design variables be the number of units of products A and B
manufactured per day:
X =
{
xA
xB
}
The requirement of resource 1 per day is (xA + 0.5xB) and that of resource 2 is
(0.2xA + 0.5xB) and the constraints on the resources are
xA + 0.5xB ≤ 1000 (E1)
0.2xA + 0.5xB ≤ 250 (E2)
The lower bounds on the design variables can be taken as
xA ≥ 0 (E3)
xB ≥ 0 (E4)
The total cost of resources 1 and 2 per day is
(xA + 0.5xB)[0.375 − 0.00005(xA + 0.5xB)]
+ (0.2xA + 0.5xB)[0.750 − 0.0001(0.2xA + 0.5xB)]
and the return per day from the sale of products A and B is
xA(2.00 − 0.0005xA − 0.00015xB) + xB(3.50 − 0.0002xA − 0.0015xB)
The total profit is given by the total return minus the total cost. Since the objective
function to be minimized is the negative of the profit per day, f (X) is given by
f (X) = (xA + 0.5xB)[0.375 − 0.00005(xA + 0.5xB)]
+ (0.2xA + 0.5xB)[0.750 − 0.0001(0.2xA + 0.5xB)]
− xA(2.00 − 0.0005xA − 0.00015xB)
− xB(3.50 − 0.0002xA − 0.0015xB) (E5)
26 Introduction to Optimization
As the objective function [Eq. (E5)] is a quadratic and the constraints [Eqs. (E1) to
(E4)] are linear, the problem is a quadratic programming problem.
Linear Programming Problem. If the objective function and all the constraints in
Eq. (1.1) are linear functions of the design variables, the mathematical programming
problem is called a linear programming (LP) problem . A linear programming problem
is often stated in the following standard form:
Find X =









x1
x2
...
xn









which minimizes f (X) =
n
∑
i=1
cixi
subject to the constraints (1.10)
n
∑
i=1
aijxi = bj , j = 1, 2, . . . , m
xi ≥ 0, i = 1, 2, . . . , n
where ci, aij , and bj are constants.
Example 1.6 A scaffolding system consists of three beams and six ropes as shown
in Fig. 1.12. Each of the top ropes A and B can carry a load of W1, each of the
middle ropes C and D can carry a load of W2, and each of the bottom ropes E and
F can carry a load of W3. If the loads acting on beams 1, 2, and 3 are x1, x2, and x3,
respectively, as shown in Fig. 1.12, formulate the problem of finding the maximum
Figure 1.12 Scaffolding system with three beams.
1.5 Classification of Optimization Problems 27
load (x1 + x2 + x3) that can be supported by the system. Assume that the weights of
the beams 1, 2, and 3 are w1, w2, and w3, respectively, and the weights of the ropes
are negligible.
SOLUTION Assuming that the weights of the beams act through their respective
middle points, the equations of equilibrium for vertical forces and moments for each
of the three beams can be written as
For beam 3:
TE + TF = x3 + w3
x3(3l) + w3(2l) − TF (4l) = 0
For beam 2:
TC + TD − TE = x2 + w2
x2(l) + w2(l) + TE(l) − TD(2l) = 0
For beam 1:
TA + TB − TC − TD − TF = x1 + w1
x1(3l) + w1( 92 l) − TB(9l) + TC(2l) + TD(4l) + TF (7l) = 0
where Ti denotes the tension in rope i. The solution of these equations gives
TF = 34x3 +
1
2
w3
TE = 14x3 +
1
2
w3
TD = 12x2 +
1
8
x3 + 12w2 +
1
4
w3
TC = 12x2 +
1
8
x3 + 12w2 +
1
4
w3
TB = 13x1 +
1
3
x2 + 23x3 +
1
2
w1 + 13w2 +
5
9
w3
TA = 23x1 +
2
3
x2 + 13x3 +
1
2
w1 + 23w2 +
4
9
w3
The optimization problem can be formulated by choosing the design vector as
X =



x1
x2
x3



Since the objective is to maximize the total load
f (X) = −(x1 + x2 + x3) (E1)
The constraints on the forces in the ropes can be stated as
TA ≤ W1 (E2)
TB ≤ W1 (E3)
TC ≤ W2 (E4)
28 Introduction to Optimization
TD ≤ W2 (E5)
TE ≤ W3 (E6)
TF ≤ W3 (E7)
Finally, the nonnegativity requirement of the design variables can be expressed as
x1 ≥ 0
x2 ≥ 0
x3 ≥ 0 (E8)
Since all the equations of the problem (E1) to (E8), are linear functions of x1, x2, and
x3, the problem is a linear programming problem.
1.5.5 Classification Based on the Permissible Values of the Design Variables
Depending on the values permitted for the design variables, optimization problems can
be classified as integer and real-valued programming problems.
Integer Programming Problem. If some or all of the design variables x1, x2, . . . , xn
of an optimization problem are restricted to take on only integer (or discrete) values,
the problem is called an integer programming problem . On the other hand, if all the
design variables are permitted to take any real value, the optimization problem is
called a real-valued programming problem . According to this definition, the problems
considered in Examples 1.1 to 1.6 are real-valued programming problems.
Example 1.7 A cargo load is to be prepared from five types of articles. The weight
wi , volume vi , and monetary value ci of different articles are given below.
Article type wi vi ci
1 4 9 5
2 8 7 6
3 2 4 3
4 5 3 2
5 3 8 8
Find the number of articles xi selected from the ith type (i = 1, 2, 3, 4, 5), so that the
total monetary value of the cargo load is a maximum. The total weight and volume of
the cargo cannot exceed the limits of 2000 and 2500 units, respectively.
SOLUTION Let xi be the number of articles of type i (i = 1 to 5) selected. Since
it is not possible to load a fraction of an article, the variables xi can take only integer
values.
The objective function to be maximized is given by
f (X) = 5x1 + 6x2 + 3x3 + 2x4 + 8x5 (E1)
1.5 Classification of Optimization Problems 29
and the constraints by
4x1 + 8x2 + 2x3 + 5x4 + 3x5 ≤ 2000 (E2)
9x1 + 7x2 + 4x3 + 3x4 + 8x5 ≤ 2500 (E3)
xi ≥ 0 and integral, i = 1, 2, . . . , 5 (E4)
Since xi are constrained to be integers, the problem is an integer programming
problem.
1.5.6 Classification Based on the Deterministic Nature of the Variables
Based on the deterministic nature of the variables involved, optimization problems can
be classified as deterministic and stochastic programming problems.
Stochastic Programming Problem. A stochastic programming problem is an opti-
mization problem in which some or all of the parameters (design variables and/or
preassigned parameters) are probabilistic (nondeterministic or stochastic). According
to this definition, the problems considered in Examples 1.1 to 1.7 are deterministic
programming problems.
Example 1.8 Formulate the problem of designing a minimum-cost rectangular under-
reinforced concrete beam that can carry a bending moment M with a probability of at
least 0.95. The costs of concrete, steel, and formwork are given by Cc = $200/m3, Cs =
$5000/m3, and Cf = $40/m2 of surface area. The bending moment M is a probabilistic
quantity and varies between 1 × 105 and 2 × 105 N-m with a uniform probability. The
strengths of concrete and steel are also uniformly distributed probabilistic quantities
whose lower and upper limits are given by
fc = 25 and 35 MPa
fs = 500 and 550 MPa
Assume that the area of the reinforcing steel and the cross-sectional dimensions of the
beam are deterministic quantities.
SOLUTION The breadth b in meters, the depth d in meters, and the area of reinforcing
steel As in square meters are taken as the design variables x1, x2, and x3, respectively
(Fig. 1.13). The cost of the beam per meter length is given by
f (X) = cost of steet + cost of concrete + cost of formwork
= AsCs + (bd − As)Cc + 2(b + d)Cf (E1)
The resisting moment of the beam section is given by [1.119]
MR = Asfs
(
d − 0.59
Asfs
fcb
)
30 Introduction to Optimization
Figure 1.13 Cross section of a reinforced concrete beam.
and the constraint on the bending moment can be expressed as [1.120]
P [MR − M ≥ 0] = P
[
Asfs
(
d − 0.59
Asfs
fcb
)
− M ≥ 0
]
≥ 0.95 (E2)
where P [· · ·] indicates the probability of occurrence of the event [· · ·].
To ensure that the beam remains underreinforced,† the area of steel is bounded by
the balanced steel area A
(b)
s as
As ≤ A(b)s (E3)
where
A(b)s = (0.542)
fc
fs
bd
600
600 + fs
Since the design variables cannot be negative, we have
d ≥ 0
b ≥ 0
As ≥ 0 (E4)
Since the quantities M, fc, and fs are nondeterministic, the problem is a stochastic
programming problem.
1.5.7 Classification Based on the Separability of the Functions
Optimization problems can be classified as separable and nonseparable programming
problems based on the separability of the objective and constraint functions.
†If steel area is larger than A
(b)
s , the beam becomes overreinforced and failure occurs all of a sudden due
to lack of concrete strength. If the beam is underreinforced, failure occurs due to lack of steel strength and
hence it will be gradual.
1.5 Classification of Optimization Problems 31
Separable Programming Problem.
Definition A function f (X) is said to be separable if it can be expressed as the sum
of n single-variable functions, f1(x1), f2(x2), . . . , fn(xn), that is,
f (X) =
n
∑
i=1
fi(xi) (1.11)
A separable programming problem is one in which the objective function and the
constraints are separable and can be expressed in standard form as
Find X which minimizes f (X) =
n
∑
i=1
fi(xi) (1.12)
subject to
gj (X) =
n
∑
i=1
gij (xi) ≤ bj , j = 1, 2, . . . , m
where bj is a constant.
Example 1.9 A retail store stocks and sells three different models of TV sets. The
store cannot afford to have an inventory worth more than $45,000 at any time. The
TV sets are ordered in lots. It costs $aj for the store whenever a lot of TV model j
is ordered. The cost of one TV set of model j is cj . The demand rate of TV model
j is dj units per year. The rate at which the inventory costs accumulate is known to
be proportional to the investment in inventory at any time, with qj = 0.5, denoting
the constant of proportionality for TV model j . Each TV set occupies an area of
sj = 0.40 m2 and the maximum storage space available is 90 m2. The data known from
the past experience are given below.
TV model j
1 2 3
Ordering cost, aj ($) 50 80 100
Unit cost, cj ($) 40 120 80
Demand rate, dj 800 400 1200
Formulate the problem of minimizing the average annual cost of ordering and storing
the TV sets.
SOLUTION Let xj denote the number of TV sets of model j ordered in each lot
(j = 1, 2, 3). Since the demand rate per year of model j is dj , the number of times
the TV model j needs to be ordered is dj/xj . The cost of ordering TV model j per
year is thus ajdj/xj , j = 1, 2, 3. The cost of storing TV sets of model j per year is
qjcjxj/2 since the average level of inventory at any time during the year is equal to
32 Introduction to Optimization
cjxj/2. Thus the objective function (cost of ordering plus storing) can be expressed
as
f (X) =
(
a1d1
x1
+
q1c1x1
2
)
+
(
a2d2
x2
+
q2c2x2
2
)
+
(
a3d3
x3
+
q3c3x3
2
)
(E1)
where the design vector X is given by
X =





x1
x2
x3





(E2)
The constraint on the worth of inventory can be stated as
c1x1 + c2x2 + c3x3 ≤ 45,000 (E3)
The limitation on the storage area is given by
s1x1 + s2x2 + s3x3 ≤ 90 (E4)
Since the design variables cannot be negative, we have
xj ≥ 0, j = 1, 2, 3 (E5)
By substituting the known data, the optimization problem can be stated as follows:
Find X which minimizes
f (X) =
(
40,000
x1
+ 10x1
)
+
(
32,000
x2
+ 30x2
)
+
(
120,000
x3
+ 20x3
)
(E6)
subject to
g1(X) = 40x1 + 120x2 + 80x3 ≤ 45,000 (E7)
g2(X) = 0.40(x1 + x2 + x3) ≤ 90 (E8)
g3(X) = −x1 ≤ 0 (E9)
g4(X) = −x2 ≤ 0 (E10)
g5(X) = −x3 ≤ 0 (E11)
It can be observed that the optimization problem stated in Eqs. (E6) to (E11) is a
separable programming problem.
1.5.8 Classification Based on the Number of Objective Functions
Depending on the number of objective functions to be minimized, optimization prob-
lems can be classified as single- and multiobjective programming problems. According
to this classification, the problems considered in Examples 1.1 to 1.9 are single objective
programming problems.
1.5 Classification of Optimization Problems 33
Multiobjective Programming Problem. A multiobjective programming problem can
be stated as follows:
Find X which minimizes f1(X), f2(X), . . . , fk(X)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m
(1.13)
where f1, f2, . . . , fk denote the objective functions to be minimized simultaneously.
Example 1.10 A uniform column of rectangular cross section is to be constructed
for supporting a water tank of mass M (Fig. 1.14). It is required (1) to minimize the
mass of the column for economy, and (2) to maximize the natural frequency of trans-
verse vibration of the system for avoiding possible resonance due to wind. Formulate
the problem of designing the column to avoid failure due to direct compression and
buckling. Assume the permissible compressive stress to be σmax.
SOLUTION Let x1 = b and x2 = d denote the cross-sectional dimensions of the
column. The mass of the column (m) is given by
m = ρbdl = ρlx1x2 (E1)
where ρ is the density and l is the height of the column. The natural frequency of
transverse vibration of the water tank (ω), by treating it as a cantilever beam with a
tip mass M , can be obtained as [1.118]
ω =
[
3EI
(M + 33
140
m)l3
]1/2
(E2)
Figure 1.14 Water tank on a column.
34 Introduction to Optimization
where E is the Young’s modulus and I is the area moment of inertia of the column
given by
I = 1
12
bd3 (E3)
The natural frequency of the water tank can be maximized by minimizing −ω. With
the help of Eqs. (E1) and (E3), Eq. (E2) can be rewritten as
ω =
[
Ex1x
3
2
4l3(M + 33
140
ρlx1x2)
]1/2
(E4)
The direct compressive stress (σc) in the column due to the weight of the water tank
is given by
σc =
Mg
bd
=
Mg
x1x2
(E5)
and the buckling stress for a fixed-free column (σb) is given by [1.121]
σb =
(
π2EI
4l2
)
1
bd
=
π2Ex22
48l2
(E6)
To avoid failure of the column, the direct stress has to be restricted to be less than σmax
and the buckling stress has to be constrained to be greater than the direct compressive
stress induced.
Finally, the design variables have to be constrained to be positive. Thus the
multiobjective optimization problem can be stated as follows:
Find X =
{
x1
x2
}
which minimizes
f1(X) = ρlx1x2 (E7)
f2(X) = −
[
Ex1x
3
2
4l2(M + 33
140
ρlx1x2)
]1/2
(E8)
subject to
g1(X) =
Mg
x1x2
− σmax ≤ 0 (E9)
g2(X) =
Mg
x1x2
−
π2Ex22
48l2
≤ 0 (E10)
g3(X) = −x1 ≤ 0 (E11)
g4(X) = −x2 ≤ 0 (E12)
1.7 Engineering Optimization Literature 35
1.6 OPTIMIZATION TECHNIQUES
The various techniques available for the solution of different types of optimization
problems are given under the heading of mathematical programming techniques in
Table 1.1. The classical methods of differential calculus can be used to find the uncon-
strained maxima and minima of a function of several variables. These methods assume
that the function is differentiable twice with respect to the design variables and the
derivatives are continuous. For problems with equality constraints, the Lagrange multi-
plier method can be used. If the problem has inequality constraints, the Kuhn–Tucker
conditions can be used to identify the optimum point. But these methods lead to a set of
nonlinear simultaneous equations that may be difficult to solve. The classical methods
of optimization are discussed in Chapter 2.
The techniques of nonlinear, linear, geometric, quadratic, or integer programming
can be used for the solution of the particular class of problems indicated by the name
of the technique. Most of these methods are numerical techniques wherein an approx-
imate solution is sought by proceeding in an iterative manner by starting from an
initial solution. Linear programming techniques are described in Chapters 3 and 4. The
quadratic programming technique, as an extension of the linear programming approach,
is discussed in Chapter 4. Since nonlinear programming is the most general method
of optimization that can be used to solve any optimization problem, it is dealt with in
detail in Chapters 5–7. The geometric and integer programming methods are discussed
in Chapters 8 and 10, respectively. The dynamic programming technique, presented in
Chapter 9, is also a numerical procedure that is useful primarily for the solution of
optimal control problems. Stochastic programming deals with the solution of optimiza-
tion problems in which some of the variables are described by probability distributions.
This topic is discussed in Chapter 11.
In Chapter 12 we discuss calculus of variations, optimal control theory, and opti-
mality criteria methods. The modern methods of optimization, including genetic algo-
rithms, simulated annealing, particle swarm optimization, ant colony optimization,
neural network-based optimization, and fuzzy optimization, are presented in Chapter
13. Several practical aspects of optimization are outlined in Chapter 14. The reduction
of size of optimization problems, fast reanalysis techniques, the efficient computation
of the derivatives of static displacements and stresses, eigenvalues and eigenvectors,
and transient response are outlined. The aspects of sensitivity of optimum solution to
problem parameters, multilevel optimization, parallel processing, and multiobjective
optimization are also presented in this chapter.
1.7 ENGINEERING OPTIMIZATION LITERATURE
The literature on engineering optimization is large and diverse. Several text-books
are available and dozens of technical periodicals regularly publish papers related to
engineering optimization. This is primarily because optimization is applicable to all
areas of engineering. Researchers in many fields must be attentive to the developments
in the theory and applications of optimization.
36 Introduction to Optimization
The most widely circulated journals that publish papers related to engineering opti-
mization are Engineering Optimization, ASME Journal of Mechanical Design, AIAA
Journal, ASCE Journal of Structural Engineering, Computers and Structures, Interna-
tional Journal for Numerical Methods in Engineering, Structural Optimization, Journal
of Optimization Theory and Applications, Computers and Operations Research, Oper-
ations Research, Management Science, Evolutionary Computation, IEEE Transactions
on Evolutionary Computation, European Journal of Operations Research, IEEE Trans-
actions on Systems, Man and Cybernetics , and Journal of Heuristics . Many of these
journals are cited in the chapter references.
1.8 SOLUTION OF OPTIMIZATION PROBLEMS USING MATLAB
The solution of most practical optimization problems requires the use of computers.
Several commercial software systems are available to solve optimization problems that
arise in different engineering areas. MATLAB is a popular software that is used for
the solution of a variety of scientific and engineering problems.† MATLAB has several
toolboxes each developed for the solution of problems from a specific scientific area.
The specific toolbox of interest for solving optimization and related problems is called
the optimization toolbox . It contains a library of programs or m-files, which can be
used for the solution of minimization, equations, least squares curve fitting, and related
problems. The basic information necessary for using the various programs can be found
in the user’s guide for the optimization toolbox [1.124]. The programs or m-files, also
called functions, available in the minimization section of the optimization toolbox are
given in Table 1.2. The use of the programs listed in Table 1.2 is demonstrated at the end
of different chapters of the book. Basically, the solution procedure involves three steps
after formulating the optimization problem in the format required by the MATLAB
program (or function) to be used. In most cases, this involves stating the objective
function for minimization and the constraints in “≤” form with zero or constant value
on the righthand side of the inequalities. After this, step 1 involves writing an m-file
for the objective function. Step 2 involves writing an m-file for the constraints. Step 3
involves setting the various parameters at proper values depending on the characteristics
of the problem and the desired output and creating an appropriate file to invoke the
desired MATLAB program (and coupling the m-files created to define the objective and
constraints functions of the problem). As an example, the use of the program, fmincon,
for the solution of a constrained nonlinear programming problem is demonstrated in
Example 1.11.
Example 1.11 Find the solution of the following nonlinear optimization problem
(same as the problem in Example 1.1) using the MATLAB function fmincon:
Minimize f (x1, x2) = 9.82x1x2 + 2x1
subject to
g1(x1, x2) =
2500
πx1x2
− 500 ≤ 0
†The basic concepts and procedures of MATLAB are summarized in Appendix C.
1.8 Solution of Optimization Problems Using MATLAB 37
Table 1.2 MATLAB Programs or Functions for Solving Optimization Problems
Name of MATLAB program
Type of optimization Standard form for solution or function to solve
problem by MATLAB the problem
Function of one variable or
scalar minimization
Find x to minimize f (x)
with x1 < x < x2
fminbnd
Unconstrained minimization
of function of several
variables
Find x to minimize f (x) fminunc or fminsearch
Linear programming
problem
Find x to minimize fT x
subject to
[A]x ≤ b, [Aeq]x = beq,
l ≤ x ≤ u
linprog
Quadratic programming
problem
Find x to minimize
1
2
xT [H ]x + fT x subject to
[A]x ≤ b, [Aeq]x = beq,
l ≤ x ≤ u
quadprog
Minimization of function of
several variables subject
to constraints
Find x to minimize f (x)
subject to
c(x) ≤ 0, ceq = 0
[A]x ≤ b, [Aeq]x = beq,
l ≤ x ≤ u
fmincon
Goal attainment problem Find x and γ to minimize γ
such that
F(x) − wγ ≤ goal,
c(x) ≤ 0, ceq = 0
[A]x ≤ b, [Aeq]x = beq,
l ≤ x ≤ u
fgoalattain
Minimax problem Minimize Max
x [Fi}
[Fi(x)}
such that
c(x) ≤ 0, ceq = 0
[A]x ≤ b, [Aeq]x = beq,
l ≤ x ≤ u
fminimax
Binary integer programming
problem
Find x to minimize fT x
subject to
[A]x ≤ b, [Aeq]x = beq,
each component of x is
binary
bintprog
g2(x1, x2) =
2500
πx1x2
−
π2(x21 + x22)
0.5882
≤ 0
g3(x1, x2) = −x1 + 2 ≤ 0
g4(x1, x2) = x1 − 14 ≤ 0
g5(x1, x2) = −x2 + 0.2 ≤ 0
g6(x1, x2) = x2 − 0.8 ≤ 0
38 Introduction to Optimization
SOLUTION
Step 1 : Write an M-file probofminobj.m for the objective function.
function f= probofminobj (x)
f= 9.82*x(1)*x(2)+2*x(1);
Step 2 : Write an M-file conprobformin.m for the constraints.
function [c, ceq] = conprobformin(x)
% Nonlinear inequality constraints
c = [2500/(pi*x(1)*x(2))-500;2500/(pi*x(1)*x(2))-
(pi^2*(x(1)^2+x(2)^2))/0.5882;-x(1)+2;x(1)-14;-x(2)+0.2;
x(2)-0.8];
% Nonlinear equality constraints
ceq = [];
Step 3 : Invoke constrained optimization program (write this in new matlab file).
clc
clear all
warning off
x0 = [7 0.4]; % Starting guess\
fprintf ('The values of function value and constraints
at starting point\n');
f=probofminobj (x0)
[c, ceq] = conprobformin (x0)
options = optimset ('LargeScale', 'off');
[x, fval]=fmincon (@probofminobj, x0, [], [], [], [], [],
[], @conprobformin, options)
fprintf('The values of constraints at optimum solution\n');
[c, ceq] = conprobformin(x) % Check the constraint values at x
This produces the solution or output as follows:
The values of function value and constraints at starting point
f=
41.4960
c =
-215.7947
-540.6668
-5.0000
-7.0000
-0.2000
-0.4000
ceq =
[]
Optimization terminated: first-order optimality
measure less
References and Bibliography 39
than options. TolFun and maximum constraint violation
is less
than options.TolCon.
Active inequalities (to within options.TolCon = 1e-006):
lower upper ineqlin ineqnonlin
1
2
x=
5.4510 0.2920
fval =
26.5310
The values of constraints at optimum solution
c=
-0.0000
-0.0000
-3.4510
-8.5490
-0.0920
-0.5080
ceq =
[]
REFERENCES AND BIBLIOGRAPHY
Structural Optimization
1.1 K. I. Majid, Optimum Design of Structures , Wiley, New York, 1974.
1.2 D. G. Carmichael, Structural Modelling and Optimization , Ellis Horwood, Chichester,
UK, 1981.
1.3 U. Kirsch, Optimum Structural Design , McGraw-Hill, New York, 1981.
1.4 A. J. Morris, Foundations of Structural Optimization , Wiley, New York, 1982.
1.5 J. Farkas, Optimum Design of Metal Structures , Ellis Horwood, Chichester, UK, 1984.
1.6 R. T. Haftka and Z. Gürdal, Elements of Structural Optimization , 3rd ed., Kluwer Aca-
demic Publishers, Dordrecht, The Netherlands, 1992.
1.7 M. P. Kamat, Ed., Structural Optimization: Status and Promise, AIAA, Washington,
DC, 1993.
1.8 Z. Gurdal, R. T. Haftka, and P. Hajela, Design and Optimization of Laminated Composite
Materials , Wiley, New York, 1998.
1.9 A. L. Kalamkarov and A. G. Kolpakov, Analysis, Design and Optimization of Composite
Structures , 2nd ed., Wiley, New York, 1997.
Thermal System Optimization
1.10 W. F. Stoecker, Design of Thermal Systems , 3rd ed., McGraw-Hill, New York, 1989.
1.11 S. Stricker, Optimizing Performance of Energy Systems , Battelle Press, New York, 1985.
1.12 Adrian Bejan, G. Tsatsaronis, and M. Moran, Thermal Design and Optimization , Wiley,
New York, 1995.
40 Introduction to Optimization
1.13 Y. Jaluria, Design and Optimization of Thermal Systems , 2nd ed., CRC Press, Boca
Raton, FL, 2007.
Chemical and Metallurgical Process Optimization
1.14 W. H. Ray and J. Szekely, Process Optimization with Applications to Metallurgy and
Chemical Engineering , Wiley, New York, 1973.
1.15 T. F. Edgar and D. M. Himmelblau, Optimization of Chemical Processes , McGraw-Hill,
New York, 1988.
1.16 R. Aris, The Optimal Design of Chemical Reactors, a Study in Dynamic Programming ,
Academic Press, New York, 1961.
Electronics and Electrical Engineering
1.17 K. W. Cattermole and J. J. O’Reilly, Optimization Methods in Electronics and Commu-
nications , Wiley, New York, 1984.
1.18 T. R. Cuthbert, Jr., Optimization Using Personal Computers with Applications to Elec-
trical Networks , Wiley, New York, 1987.
1.19 G. D. Micheli, Synthesis and Optimization of Digital Circuits , McGraw-Hill, New York,
1994.
Mechanical Design
1.20 R. C. Johnson, Optimum Design of Mechanical Elements , Wiley, New York, 1980.
1.21 E. J. Haug and J. S. Arora, Applied Optimal Design: Mechanical and Structural Systems ,
Wiley, New York, 1979.
1.22 E. Sevin and W. D. Pilkey, Optimum Shock and Vibration Isolation , Shock and Vibration
Information Center, Washington, DC, 1971.
General Engineering Design
1.23 J. Arora, Introduction to Optimum Design , 2nd ed., Academic Press, San Diego, 2004.
1.24 P. Y. Papalambros and D. J. Wilde, Principles of Optimal Design , Cambridge University
Press, Cambridge, UK, 1988.
1.25 J. N. Siddall, Optimal Engineering Design: Principles and Applications , Marcel Dekker,
New York, 1982.
1.26 S. S. Rao, Optimization: Theory and Applications , 2nd ed., Wiley, New York, 1984.
1.27 G. N. Vanderplaats, Numerical Optimization Techniques for Engineering Design with
Applications , McGraw-Hill, New York, 1984.
1.28 R. L. Fox, Optimization Methods for Engineering Design , Addison-Wesley, Reading,
MA, 1972.
1.29 A. Ravindran, K. M. Ragsdell, and G. V. Reklaitis, Engineering Optimization: Methods
and Applications , 2nd ed., Wiley, New York, 2006.
1.30 D. J. Wilde, Globally Optimal Design , Wiley, New York, 1978.
1.31 T. E. Shoup and F. Mistree, Optimization Methods with Applications for Personal Com-
puters , Prentice-Hall, Englewood Cliffs, NJ, 1987.
1.32 A. D. Belegundu and T. R. Chandrupatla, Optimization Concepts and Applications in
Engineering , Prentice Hall, Upper Saddle River, NJ, 1999.
References and Bibliography 41
General Nonlinear Programming Theory
1.33 S. L. S. Jacoby, J. S. Kowalik, and J. T. Pizzo, Iterative Methods for Nonlinear Opti-
mization Problems , Prentice-Hall, Englewood Cliffs, NJ, 1972.
1.34 L. C. W. Dixon, Nonlinear Optimization: Theory and Algorithms , Birkhauser, Boston,
1980.
1.35 G. S. G. Beveridge and R. S. Schechter, Optimization: Theory and Practice,
McGraw-Hill, New York, 1970.
1.36 B. S. Gottfried and J. Weisman, Introduction to Optimization Theory , Prentice-Hall,
Englewood Cliffs, NJ, 1973.
1.37 M. A. Wolfe, Numerical Methods for Unconstrained Optimization , Van Nostrand Rein-
hold, New York, 1978.
1.38 M. S. Bazaraa and C. M. Shetty, Nonlinear Programming , Wiley, New York, 1979.
1.39 W. I. Zangwill, Nonlinear Programming: A Unified Approach , Prentice-Hall, Englewood
Cliffs, NJ, 1969.
1.40 J. E. Dennis and R. B. Schnabel, Numerical Methods for Unconstrained Optimization
and Nonlinear Equations , Prentice-Hall, Englewood Cliffs, NJ, 1983.
1.41 J. S. Kowalik, Methods for Unconstrained Optimization Problems , American Elsevier,
New York, 1968.
1.42 A. V. Fiacco and G. P. McCormick, Nonlinear Programming: Sequential Unconstrained
Minimization Techniques , Wiley, New York, 1968.
1.43 G. Zoutendijk, Methods of Feasible Directions , Elsevier, Amsterdam, 1960.
1.44 J. Nocedal and S. J. Wright, Numerical Optimization , Springer, New York, 2006.
1.45 R. Fletcher, Practical Methods of Optimization , Vols. 1 and 2, Wiley, Chichester, UK,
1981.
1.46 D. P. Bertsekas, Nonlinear Programming , 2nd ed., Athena Scientific, Nashua, NH,
1999.
1.47 D. G. Luenberger, Linear and Nonlinear Programming , 2nd ed., Kluwer Academic
Publishers, Norwell, MA, 2003.
1.48 A. Antoniou and W-S. Lu, Practical Optimization: Algorithms and Engineering Appli-
cations , Springer, Berlin, 2007.
1.49 S. G. Nash and A. Sofer, Linear and Nonlinear Programming , McGraw-Hill, New York,
1996.
Computer Programs
1.50 J. L. Kuester and J. H. Mize, Optimization Techniques with Fortran , McGraw-Hill, New
York, 1973.
1.51 H. P. Khunzi, H. G. Tzschach, and C. A. Zehnder, Numerical Methods of Mathemati-
cal Optimization with ALGOL and FORTRAN Programs , Academic Press, New York,
1971.
1.52 C. S. Wolfe, Linear Programming with BASIC and FORTRAN , Reston Publishing Co.,
Reston, VA, 1985.
1.53 K. R. Baker, Optimization Modeling with Spreadsheets , Thomson Brooks/Cole, Belmont,
CA, 2006.
1.54 P. Venkataraman, Applied Optimization with MATLAB Programming , Wiley, New York,
2002.
42 Introduction to Optimization
Optimal Control
1.55 D. E. Kirk, Optimal Control Theory: An Introduction , Prentice-Hall, Englewood Cliffs,
NJ, 1970.
1.56 A. P. Sage and C. C. White III, Optimum Systems Control , 2nd ed., Prentice-Hall,
Englewood Cliffs, NJ, 1977.
1.57 B. D. O. Anderson and J. B. Moore, Linear Optimal Control , Prentice-Hall, Englewood
Cliffs, NJ, 1971.
1.58 A. E. Bryson and Y. C. Ho, Applied Optimal Control: Optimization, Estimation, and
Control , Blaisdell, Waltham, MA, 1969.
Geometric Programming
1.59 R. J. Duffin, E. L. Peterson, and C. Zener, Geometric Programming: Theory and Appli-
cations , Wiley, New York, 1967.
1.60 C. M. Zener, Engineering Design by Geometric Programming , Wiley, New York, 1971.
1.61 C. S. Beightler and D. T. Phillips, Applied Geometric Programming , Wiley, New York,
1976.
1.62 B-Y. Cao, Fuzzy Geometric Programming , Kluwer Academic, Dordrecht, The Nether-
lands, 2002.
1.63 A. Paoluzzi, Geometric Programming for Computer-aided Design , Wiley, New York,
2003.
Linear Programming
1.64 G. B. Dantzig, Linear Programming and Extensions , Princeton University Press, Prince-
ton, NJ, 1963.
1.65 S. Vajda, Linear Programming: Algorithms and Applications , Methuen, New York,
1981.
1.66 S. I. Gass, Linear Programming: Methods and Applications , 5th ed., McGraw-Hill, New
York, 1985.
1.67 C. Kim, Introduction to Linear Programming , Holt, Rinehart, & Winston, New York,
1971.
1.68 P. R. Thie, An Introduction to Linear Programming and Game Theory , Wiley, New
York, 1979.
1.69 S. I. Gass, An illustrated Guide to Linear Programming , Dover, New York, 1990.
1.70 K. G. Murty, Linear Programming , Wiley, New York, 1983.
Integer Programming
1.71 T. C. Hu, Integer Programming and Network Flows , Addison-Wesley, Reading, MA,
1982.
1.72 A. Kaufmann and A. H. Labordaere, Integer and Mixed Programming: Theory and
Applications , Academic Press, New York, 1976.
1.73 H. M. Salkin, Integer Programming , Addison-Wesley, Reading, MA, 1975.
1.74 H. A. Taha, Integer Programming: Theory, Applications, and Computations , Academic
Press, New York, 1975.
1.75 A. Schrijver, Theory of Linear and Integer Programming , Wiley, New York, 1998.
References and Bibliography 43
1.76 J. K. Karlof (Ed.), Integer Programming: Theory and Practice, CRC Press, Boca Raton,
FL, 2006.
1.77 L. A. Wolsey, Integer Programming , Wiley, New York, 1998.
Dynamic Programming
1.78 R. Bellman, Dynamic Programming , Princeton University Press, Princeton, NJ, 1957.
1.79 R. Bellman and S. E. Dreyfus, Applied Dynamic Programming , Princeton University
Press, Princeton, NJ, 1962.
1.80 G. L. Nemhauser, Introduction to Dynamic Programming , Wiley, New York, 1966.
1.81 L. Cooper and M. W. Cooper, Introduction to Dynamic Programming , Pergamon Press,
Oxford, UK, 1981.
1.82 W. B. Powell, Approximate Dynamic Programming: Solving the Curses of Dimension-
ality , Wiley, Hoboken, NJ, 2007.
1.83 M. L. Puterman, Dynamic Programming and Its Applications , Academic Press, New
York, 1978.
1.84 M. Sniedovich, Dynamic Programming , Marcel Dekker, New York, 1992.
Stochastic Programming
1.85 J. K. Sengupta, Stochastic Programming: Methods and Applications , North-Holland,
Amsterdam, 1972.
1.86 P. Kall, Stochastic Linear Programming , Springer-Verlag, Berlin, 1976.
1.87 J. R. Birge and F. Louveaux, Introduction to Stochastic Programming , Springer, New
York, 1997.
1.88 P. Kall and S. W. Wallace, Stochastic Programming , Wiley, Chichester, UK, 1994.
1.89 P. Kall and J. Mayer, Stochastic Linear Programming: Models, Theory, and Computa-
tion , Springer, New York, 2005.
Multiobjective Programming
1.90 R. E. Steuer, Multiple Criteria Optimization: Theory, Computation, and Application ,
Wiley, New York, 1986.
1.91 C. L. Hwang and A. S. M. Masud, Multiple Objective Decision Making: Methods
and Applications , Lecture Notices in Economics and Mathematical Systems, Vol. 164,
Springer-Verlag, Berlin, 1979.
1.92 J. P. Ignizio, Linear Programming in Single and Multi-objective Systems , Prentice-Hall,
Englewood Cliffs, NJ, 1982.
1.93 A. Goicoechea, D. R. Hansen, and L. Duckstein, Multiobjective Decision Analysis with
Engineering and Business Applications , Wiley, New York, 1982.
1.94 Y. Collette and P. Siarry, Multiobjective Optimization: Principles and Case Studies ,
Springer, Berlin, 2004.
1.95 H. Eschenauer, J. Koski, and A. Osyczka (Eds.), Multicriteria Design Optimization:
Procedures and Applications , Springer-Verlag, Berlin, 1990.
1.96 P. Sen and J-B. Yang, Multiple Criteria Decision Support in Engineering Design ,
Springer-Verlag, Berlin, 1998.
1.97 G. Owen, Game Theory , 3rd ed., Academic Press, San Diego, 1995.
44 Introduction to Optimization
Nontraditional Optimization Techniques
1.98 M. Mitchell, An Introduction to Genetic Algorithms , MIT Press, Cambridge, MA, 1998.
1.99 D. B. Fogel, Evolutionary Computation: Toward a New Philosophy of Machine Intelli-
gence, 3rd ed., IEEE Press, Piscataway, NJ, 2006.
1.100 K. Deb, Multi-Objective Optimization Using Evolutionary Algorithms , Wiley, Chich-
ester, England, 2001.
1.101 C. A. Coello Coello, D. A. van Veldhuizen and G. B. Lamont, Evolutionary Algorithms
for Solving Multi-Objective Problems , Plenum, New York, 2002.
1.102 D. E. Goldberg, Genetic Algorithms in Search, Optimization and Machine Learning ,
Addison-Wesley, Reading, MA, 1989.
1.103 P. J. M. van Laarhoven and E. Aarts, Simulated Annealing: Theory and Applications ,
D. Reidel, Dordrecht, The Netherlands, 1987.
1.104 J. Hopfield and D. Tank, “Neural Computation of Decisions in Optimization Problems,”
Biological Cybernetics , Vol. 52, pp. 141–152, 1985.
1.105 J. J. Hopfield, Neural networks and physical systems with emergent collective compu-
tational abilities, Proceedings of the National Academy of Sciences, USA, Vol. 79, pp.
2554–2558, 1982.
1.106 N. Forbes, Imitation of Life: How Biology Is Inspiring Computing , MIT Press, Cam-
bridge, MA, 2004.
1.107 J. Harris, Fuzzy Logic Applications in Engineering Science, Springer, Dordrecht, The
Netherlands, 2006.
1.108 M. Hanss, Applied Fuzzy Arithmetic: An Introduction with Engineering Applications ,
Springer, Berlin, 2005.
1.109 G. Chen and T. T. Pham, Introduction to Fussy Systems , Chapman & Hall/CRC, Boca
Raton, FL, 2006.
1.110 T. J. Ross, Fuzzy Logic with Engineering Applications , McGraw-Hill, New York, 1995.
1.111 M. Dorigo and T. Stutzle, Ant Colony Optimization , MIT Press, Cambridge, MA, 2004.
1.112 J. Kennedy, R. C. Eberhart, and Y. Shi, Swarm Intelligence, Morgan Kaufmann, San
Francisco, CA, 2001.
1.113 J. C. Spall, Introduction to Stochastic Search and Optimization , Wiley Interscience,
2003.
1.114 A. P. Engelbrecht, Fundamentals of Computational Swarm Intelligence, Wiley, Chich-
ester, UK, 2005.
1.115 E. Bonabeau, M. Dorigo, and G. Theraulaz, Swarm Intelligence: From Natural to Arti-
ficial Systems , Oxford University Press, Oxford, UK, 1999.
Additional References
1.116 R. C. Juvinall and K. M. Marshek, Fundamentals of Machine Component Design , 2nd
ed., Wiley, New York, 1991.
1.117 J. E. Shigley and C. R. Mischke, Mechanical Engineering Design , 5th ed., McGraw-Hill,
New York, 1989.
1.118 S. S. Rao, Mechanical Vibrations , 4th ed., Pearson Prentice Hall, Upper Saddle River,
NJ, 2004.
1.119 J. M. MacGregor, Reinforced Concrete: Mechanics and Design , Prentice Hall, Engle-
wood Cliffs, NJ, 1988.
1.120 S. S. Rao, Reliability-Based Design , McGraw-Hill, New York, 1992.
Review Questions 45
1.121 N. H. Cook, Mechanics and Materials for Design , McGraw-Hill, New York, 1984.
1.122 R. Ramarathnam and B. G. Desai, Optimization of polyphase induction motor design: a
nonlinear programming approach, IEEE Transactions on Power Apparatus and Systems ,
Vol. PAS-90, No. 2, pp. 570–578, 1971.
1.123 R. M. Stark and R. L. Nicholls, Mathematical Foundations for Design: Civil Engineering
Systems , McGraw-Hill, New York, 1972.
1.124 T. F. Coleman, M. A. Branch, and A. Grace, Optimization Toolbox—for Use with
MATLAB, User’s Guide, Version 2 MathWorks Inc., Natick, MA, 1999.
REVIEW QUESTIONS
1.1 Match the following terms and descriptions:
(a) Free feasible point gj (X) = 0
(b) Free infeasible point Some gj (X) = 0 and other gj (X) < 0
(c) Bound feasible point Some gj (X) = 0 and other gj (X) ≥ 0
(d) Bound infeasible point Some gj (X) > 0 and other gj (X) < 0
(e) Active constraints All gj (X) < 0
1.2 Answer true or false:
(a) Optimization problems are also known as mathematical programming problems.
(b) The number of equality constraints can be larger than the number of design variables.
(c) Preassigned parameters are part of design data in a design optimization problem.
(d) Side constraints are not related to the functionality of the system.
(e) A bound design point can be infeasible.
(f) It is necessary that some gj (X) = 0 at the optimum point.
(g) An optimal control problem can be solved using dynamic programming techniques.
(h) An integer programming problem is same as a discrete programming problem.
1.3 Define the following terms:
(a) Mathematical programming problem
(b) Trajectory optimization problem
(c) Behavior constraint
(d) Quadratic programming problem
(e) Posynomial
(f) Geometric programming problem
1.4 Match the following types of problems with their descriptions.
(a) Geometric programming problem Classical optimization problem
(b) Quadratic programming problem Objective and constraints are quadratic
(c) Dynamic programming problem Objective is quadratic and constraints are linear
(d) Nonlinear programming problem Objective and constraints arise from a serial
system
(e) Calculus of variations problem Objective and constraints are polynomials with
positive coefficients
1.5 How do you solve a maximization problem as a minimization problem?
46 Introduction to Optimization
1.6 State the linear programming problem in standard form.
1.7 Define an OC problem and give an engineering example.
1.8 What is the difference between linear and nonlinear programming problems?
1.9 What is the difference between design variables and preassigned parameters?
1.10 What is a design space?
1.11 What is the difference between a constraint surface and a composite constraint surface?
1.12 What is the difference between a bound point and a free point in the design space?
1.13 What is a merit function?
1.14 Suggest a simple method of handling multiple objectives in an optimization problem.
1.15 What are objective function contours?
1.16 What is operations research?
1.17 State five engineering applications of optimization.
1.18 What is an integer programming problem?
1.19 What is graphical optimization, and what are its limitations?
1.20 Under what conditions can a polynomial in n variables be called a posynomial?
1.21 Define a stochastic programming problem and give two practical examples.
1.22 What is a separable programming problem?
PROBLEMS
1.1 A fertilizer company purchases nitrates, phosphates, potash, and an inert chalk base at a
cost of $1500, $500, $1000, and $100 per ton, respectively, and produces four fertilizers
A, B,C, and D. The production cost, selling price, and composition of the four fertilizers
are given below.
Percentage composition by weightProduction Selling
cost price Inert
Fertilizer ($/ton) ($/ton) Nitrates Phosphates Potash chalk base
A 100 350 5 10 5 80
B 150 550 5 15 10 70
C 200 450 10 20 10 60
D 250 700 15 5 15 65
During any week, no more than 1000 tons of nitrate, 2000 tons of phosphates, and
1500 tons of potash will be available. The company is required to supply a minimum
of 5000 tons of fertilizer A and 4000 tons of fertilizer D per week to its customers;
but it is otherwise free to produce the fertilizers in any quantities it pleases. Formulate
the problem of finding the quantity of each fertilizer to be produced by the company to
maximize its profit.
Problems 47
Figure 1.15 Two-bar truss.
1.2 The two-bar truss shown in Fig. 1.15 is symmetric about the y axis. The nondimensional
area of cross section of the members A/Aref, and the nondimensional position of joints
1 and 2, x/h, are treated as the design variables x1 and x2, respectively, where Aref
is the reference value of the area (A) and h is the height of the truss. The coordinates
of joint 3 are held constant. The weight of the truss (f1) and the total displacement of
joint 3 under the given load (f2) are to be minimized without exceeding the permissible
stress, σ0. The weight of the truss and the displacement of joint 3 can be expressed as
f1(X) = 2ρhx2
√
1 + x21Aref
f2(X) =
Ph(1 + x21 )1.5
√
1 + x41
2
√
2Ex21x2Aref
where ρ is the weight density, P the applied load, and E the Young’s modulus. The
stresses induced in members 1 and 2 (σ1 and σ2) are given by
σ1(X) =
P(1 + x1)
√
(1 + x21 )
2
√
2x1x2Aref
σ2(X) =
P(x1 − 1)
√
(1 + x21 )
2
√
2x1x2Aref
In addition, upper and lower bounds are placed on design variables x1 and x2 as
xmini ≤ xi ≤ x
max
i ; i = 1, 2
Find the solution of the problem using a graphical method with (a) f1 as the objective, (b) f2
as the objective, and (c) (f1 + f2) as the objective for the following data: E = 30 × 106 psi,
48 Introduction to Optimization
ρ = 0.283 lb/in3, P = 10,000 lb, σ0 = 20,000 psi, h = 100 in., Aref = 1 in2, xmin1 = 0.1, xmin2 =
0.1, xmax1 = 2.0, and x
max
2 = 2.5.
1.3 Ten jobs are to be performed in an automobile assembly line as noted in the following
table:
Time required to Jobs that must be
Job complete the completed before
Number job (min) starting this job
1 4 None
2 8 None
3 7 None
4 6 None
5 3 1, 3
6 5 2, 3, 4
7 1 5, 6
8 9 6
9 2 7, 8
10 8 9
It is required to set up a suitable number of workstations, with one worker assigned
to each workstation, to perform certain jobs. Formulate the problem of determining the
number of workstations and the particular jobs to be assigned to each workstation to
minimize the idle time of the workers as an integer programming problem. Hint: Define
variables xij such that xij = 1 if job i is assigned to station j , and xij = 0 otherwise.
1.4 A railroad track of length L is to be constructed over an uneven terrain by adding or
removing dirt (Fig. 1.16). The absolute value of the slope of the track is to be restricted
to a value of r1 to avoid steep slopes. The absolute value of the rate of change of the
slope is to be limited to a value r2 to avoid rapid accelerations and decelerations. The
absolute value of the second derivative of the slope is to be limited to a value of r3
Figure 1.16 Railroad track on an uneven terrain.
Problems 49
to avoid severe jerks. Formulate the problem of finding the elevation of the track to
minimize the construction costs as an OC problem. Assume the construction costs to be
proportional to the amount of dirt added or removed. The elevation of the track is equal
to a and b at x = 0 and x = L, respectively.
1.5 A manufacturer of a particular product produces x1 units in the first week and x2 units
in the second week. The number of units produced in the first and second weeks must
be at least 200 and 400, respectively, to be able to supply the regular customers. The
initial inventory is zero and the manufacturer ceases to produce the product at the end
of the second week. The production cost of a unit, in dollars, is given by 4x2i , where xi
is the number of units produced in week i(i = 1, 2). In addition to the production cost,
there is an inventory cost of $10 per unit for each unit produced in the first week that
is not sold by the end of the first week. Formulate the problem of minimizing the total
cost and find its solution using a graphical optimization method.
1.6 Consider the slider-crank mechanism shown in Fig. 1.17 with the crank rotating at
a constant angular velocity ω. Use a graphical procedure to find the lengths of the
crank and the connecting rod to maximize the velocity of the slider at a crank angle of
θ = 30◦ for ω = 100 rad/s. The mechanism has to satisfy Groshof’s criterion l ≥ 2.5r
to ensure 360
◦
rotation of the crank. Additional constraints on the mechanism are given
by 0.5 ≤ r ≤ 10, 2.5 ≤ l ≤ 25, and 10 ≤ x ≤ 20.
1.7 Solve Problem 1.6 to maximize the acceleration (instead of the velocity) of the slider at
θ = 30◦ for ω = 100 rad/s.
1.8 It is required to stamp four circular disks of radii R1, R2, R3, and R4 from a rectan-
gular plate in a fabrication shop (Fig. 1.18). Formulate the problem as an optimization
problem to minimize the scrap. Identify the design variables, objective function, and the
constraints.
1.9 The torque transmitted (T ) by a cone clutch, shown in Fig. 1.19, under uniform pressure
condition is given by
T =
2πfp
3 sin α
(R31 − R
3
2)
where p is the pressure between the cone and the cup, f the coefficient of friction, α
the cone angle, R1 the outer radius, and R2 the inner radius.
(a) Find R1 and R2 that minimize the volume of the cone clutch with α = 30◦,
F = 30 lb, and f = 0.5 under the constraints T ≥ 100 lb-in., R1 ≥ 2R2,
0 ≤ R1 ≤ 15 in., and 0 ≤ R2 ≤ 10 in.
Figure 1.17 Slider-crank mechanism.
50 Introduction to Optimization
Figure 1.18 Locations of circular disks in a rectangular plate.
Figure 1.19 Cone clutch.
(b) What is the solution if the constraint R1 ≥ 2R2 is changed to R1 ≤ 2R2?
(c) Find the solution of the problem stated in part (a) by assuming a uniform wear
condition between the cup and the cone. The torque transmitted (T ) under uniform
wear condition is given by
T =
πfpR2
sin α
(R21 − R
2
2)
Note: Use graphical optimization for the solutions.
Problems 51
1.10 A hollow circular shaft is to be designed for minimum weight to achieve a minimum
reliability of 0.99 when subjected to a random torque of (T , σT ) = (106, 104) lb-in.,
where T is the mean torque and σT is the standard deviation of the torque, T . The
permissible shear stress, τ0, of the material is given by (τ 0, στ0) = (50,000, 5000) psi,
where τ 0 is the mean value and στ0 is the standard deviation of τ0. The maximum
induced stress (τ ) in the shaft is given by
τ =
T ro
J
where ro is the outer radius and J is the polar moment of inertia of the cross section
of the shaft. The manufacturing tolerances on the inner and outer radii of the shaft are
specified as ±0.06 in. The length of the shaft is given by 50 ± 1 in. and the specific
weight of the material by 0.3 ± 0.03 lb/in3. Formulate the optimization problem and
solve it using a graphical procedure. Assume normal distribution for all the random
variables and 3σ values for the specified tolerances. Hints: (1) The minimum reliability
requirement of 0.99 can be expressed, equivalently, as [1.120]
z1 = 2.326 ≤
τ − τ 0
√
σ 2τ + σ 2τ0
(2) If f (x1, x2, . . . , xn) is a function of the random variables x1, x2, . . . , xn, the mean
value of f (f ) and the standard deviation of f (σf ) are given by
f = f (x1, x2, . . . , xn)
σf =


n
∑
i=1
(
∂f
∂xi
∣
∣
∣
∣
x1,x2,...,xn
)2
σ 2xi


1/2
where xi is the mean value of xi , and σxi is the standard deviation of xi .
1.11 Certain nonseparable optimization problems can be reduced to a separable form by
using suitable transformation of variables. For example, the product term f = x1x2 can
be reduced to the separable form f = y21 − y22 by introducing the transformations
y1 = 12 (x1 + x2), y2 =
1
2
(x1 − x2)
Suggest suitable transformations to reduce the following terms to separable form:
(a) f = x21x
3
2 , x1 > 0, x2 > 0
(b) f = xx21 , x1 > 0
1.12 In the design of a shell-and-tube heat exchanger (Fig. 1.20), it is decided to have the total
length of tubes equal to at least α1 [1.10]. The cost of the tube is α2 per unit length and
the cost of the shell is given by α3D
2.5L, where D is the diameter and L is the length of
the heat exchanger shell. The floor space occupied by the heat exchanger costs α4 per unit
area and the cost of pumping cold fluid is α5L/d
5N2 per day, where d is the diameter
of the tube and N is the number of tubes. The maintenance cost is given by α6NdL.
The thermal energy transferred to the cold fluid is given by α7/N
1.2dL1.4 + α8/d0.2L.
Formulate the mathematical programming problem of minimizing the overall cost of the
heat exchanger with the constraint that the thermal energy transferred be greater than
a specified amount α9. The expected life of the heat exchanger is α10 years. Assume
that αi, i = 1, 2, . . . , 10, are known constants, and each tube occupies a cross-sectional
square of width and depth equal to d .
52 Introduction to Optimization
Figure 1.20 Shell-and-tube heat exchanger.
Figure 1.21 Electrical bridge network.
1.13 The bridge network shown in Fig. 1.21 consists of five resistors Ri(i = 1, 2, . . . , 5).
If Ii is the current flowing through the resistance Ri , the problem is to find the resistances
R1, R2, . . . , R5 so that the total power dissipated by the network is a minimum. The
current Ii can vary between the lower and upper limits Ii,min and Ii,max, and the voltage
drop, Vi = RiIi , must be equal to a constant ci for 1 ≤ i ≤ 5. Formulate the problem as
a mathematical programming problem.
1.14 A traveling saleswoman has to cover n towns. She plans to start from a particular town
numbered 1, visit each of the other n − 1 towns, and return to the town 1. The distance
between towns i and j is given by dij . Formulate the problem of selecting the sequence
in which the towns are to be visited to minimize the total distance traveled.
1.15 A farmer has a choice of planting barley, oats, rice, or wheat on his 200-acre farm. The
labor, water, and fertilizer requirements, yields per acre, and selling prices are given in
the following table:
Labor Water Fertilizer Selling
Type of cost required required Yield price
crop ($) (m3) (lb) (lb) ($/lb)
Barley 300 10,000 100 1,500 0.5
Oats 200 7,000 120 3,000 0.2
Rice 250 6,000 160 2,500 0.3
Wheat 360 8,000 200 2,000 0.4
The farmer can also give part or all of the land for lease, in which case he gets $200 per
acre. The cost of water is $0.02/m3 and the cost of the fertilizer is $2/lb. Assume that
the farmer has no money to start with and can get a maximum loan of $50,000 from the
land mortgage bank at an interest of 8 %. He can repay the loan after six months. The
Problems 53
irrigation canal cannot supply more than 4 × 105 m3 of water. Formulate the problem of
finding the planting schedule for maximizing the expected returns of the farmer.
1.16 There are two different sites, each with four possible targets (or depths) to drill an oil
well. The preparation cost for each site and the cost of drilling at site i to target j are
given below:
Drilling cost to target j
Site i 1 2 3 4 Preparation cost
1 4 1 9 7 11
2 7 9 5 2 13
Formulate the problem of determining the best site for each target so that the total cost
is minimized.
1.17 A four-pole dc motor, whose cross section is shown in Fig. 1.22, is to be designed with
the length of the stator and rotor x1, the overall diameter of the motor x2, the unnotched
radius x3, the depth of the notches x4, and the ampere turns x5 as design variables.
Figure 1.22 Cross section of an idealized motor.
54 Introduction to Optimization
The air gap is to be less than k1
√
x2 + 7.5 where k1 is a constant. The temperature of
the external surface of the motor cannot exceed T above the ambient temperature.
Assuming that the heat can be dissipated only by radiation, formulate the problem for
maximizing the power of the motor [1.59]. Hints:
1. The heat generated due to current flow is given by k2x1x
−1
2 x
−1
4 x
2
5 , where k2 is a
constant. The heat radiated from the external surface for a temperature difference of
T is given by k3x1x2T , where k3 is a constant.
2. The expression for power is given by k4NBx1x3x5, where k4 is a constant, N is the
rotational speed of the rotor, and B is the average flux density in the air gap.
3. The units of the various quantities are as follows. Lengths: centimeter, heat generated,
heat dissipated; power: watt; temperature:
◦
C; rotational speed: rpm; flux density:
gauss.
1.18 A gas pipeline is to be laid between two cities A and E, making it pass through one
of the four locations in each of the intermediate towns B,C, and D (Fig. 1.23). The
associated costs are indicated in the following tables.
Costs for A to B and D to E
Station i
1 2 3 4
From A to point i of B 30 35 25 40
From point i of D to E 50 40 35 25
Costs for B to C and C to D
To:
From: 1 2 3 4
1 22 18 24 18
2 35 25 15 21
3 24 20 26 20
4 22 21 23 22
Figure 1.23 Possible paths of the pipeline between A and E.
Problems 55
Figure 1.24 Beam-column.
Formulate the problem of minimizing the cost of the pipeline.
1.19 A beam-column of rectangular cross section is required to carry an axial load of 25 lb
and a transverse load of 10 lb, as shown in Fig. 1.24. It is to be designed to avoid the
possibility of yielding and buckling and for minimum weight. Formulate the optimization
problem by assuming that the beam-column can bend only in the vertical (xy) plane.
Assume the material to be steel with a specific weight of 0.3 lb/in3, Young’s modulus of
30 × 106 psi, and a yield stress of 30,000 psi. The width of the beam is required to be at
least 0.5 in. and not greater than twice the depth. Also, find the solution of the problem
graphically. Hint: The compressive stress in the beam-column due to Py is Py/bd and
that due to Px is
Px ld
2Izz
=
6Px l
bd2
The axial buckling load is given by
(Py)cri =
π2EIzz
4l2
=
π2Ebd3
48l2
1.20 A two-bar truss is to be designed to carry a load of 2W as shown in Fig. 1.25. Both
bars have a tubular section with mean diameter d and wall thickness t . The material
of the bars has Young’s modulus E and yield stress σy . The design problem involves
the determination of the values of d and t so that the weight of the truss is a minimum
and neither yielding nor buckling occurs in any of the bars. Formulate the problem as a
nonlinear programming problem.
Figure 1.25 Two-bar truss.
56 Introduction to Optimization
Figure 1.26 Processing plant layout (coordinates in ft).
1.21 Consider the problem of determining the economic lot sizes for four different items.
Assume that the demand occurs at a constant rate over time. The stock for the
ith item is replenished instantaneously upon request in lots of sizes Qi . The total
storage space available is A, whereas each unit of item i occupies an area di . The
objective is to find the values of Qi that optimize the per unit cost of holding the
inventory and of ordering subject to the storage area constraint. The cost function is
given by
C =
4
∑
i=1
(
ai
Qi
+ biQi
)
, Qi > 0
where ai and bi are fixed constants. Formulate the problem as a dynamic programming
(optimal control) model. Assume that Qi is discrete.
1.22 The layout of a processing plant, consisting of a pump (P ), a water tank (T ), a com-
pressor (C), and a fan (F ), is shown in Fig. 1.26. The locations of the various units, in
terms of their (x, y) coordinates, are also indicated in this figure. It is decided to add a
new unit, a heat exchanger (H), to the plant. To avoid congestion, it is decided to locate
H within a rectangular area defined by {−15 ≤ x ≤ 15,−10 ≤ y ≤ 10}. Formulate the
problem of finding the location of H to minimize the sum of its x and y distances from
the existing units, P, T ,C, and F .
1.23 Two copper-based alloys (brasses), A and B, are mixed to produce a new alloy, C.
The composition of alloys A and B and the requirements of alloy C are given in the
following table:
Problems 57
Composition by weight
Alloy Copper Zinc Lead Tin
A 80 10 6 4
B 60 20 18 2
C ≥ 75 ≥ 15 ≥ 16 ≥ 3
If alloy B costs twice as much as alloy A, formulate the problem of determining the
amounts of A and B to be mixed to produce alloy C at a minimum cost.
1.24 An oil refinery produces four grades of motor oil in three process plants. The refinery
incurs a penalty for not meeting the demand of any particular grade of motor oil. The
capacities of the plants, the production costs, the demands of the various grades of motor
oil, and the penalties are given in the following table:
Production cost ($/day) to
manufacture motor oil of grade:Process Capacity of the plant
plant (kgal/day) 1 2 3 4
1 100 750 900 1000 1200
2 150 800 950 1100 1400
3 200 900 1000 1200 1600
Demand (kgal/day) 50 150 100 75
Penalty (per each kilogallon shortage) $10 $12 $16 $20
Formulate the problem of minimizing the overall cost as an LP problem.
1.25 A part-time graduate student in engineering is enrolled in a four-unit mathematics course
and a three-unit design course. Since the student has to work for 20 hours a week at a
local software company, he can spend a maximum of 40 hours a week to study outside
the class. It is known from students who took the courses previously that the numerical
grade (g) in each course is related to the study time spent outside the class as gm = tm/6
and gd = td/5, where g indicates the numerical grade (g = 4 for A, 3 for B, 2 for C, 1 for
D, and 0 for F), t represents the time spent in hours per week to study outside the class,
and the subscripts m and d denote the courses, mathematics and design, respectively.
The student enjoys design more than mathematics and hence would like to spend at least
75 minutes to study for design for every 60 minutes he spends to study mathematics.
Also, as far as possible, the student does not want to spend more time on any course
beyond the time required to earn a grade of A. The student wishes to maximize his grade
point P , given by P = 4gm + 3gd , by suitably distributing his study time. Formulate
the problem as an LP problem.
1.26 The scaffolding system, shown in Fig. 1.27, is used to carry a load of 10,000 lb. Assuming
that the weights of the beams and the ropes are negligible, formulate the problem of
determining the values of x1, x2, x3, and x4 to minimize the tension in ropes A and B
while maintaining positive tensions in ropes C, D,E, and F .
1.27 Formulate the problem of minimum weight design of a power screw subjected to an
axial load, F , as shown in Fig. 1.28 using the pitch (p), major diameter (d), nut height
58 Introduction to Optimization
Figure 1.27 Scaffolding system.
Figure 1.28 Power screw.
(h), and screw length (s) as design variables. Consider the following constraints in the
formulation:
1. The screw should be self-locking [1.117].
2. The shear stress in the screw should not exceed the yield strength of the material in
shear. Assume the shear strength in shear (according to distortion energy theory), to
be 0.577σy , where σy is the yield strength of the material.
3. The bearing stress in the threads should not exceed the yield strength of the material,
σy .
4. The critical buckling load of the screw should be less than the applied load, F .
1.28 (a) A simply supported beam of hollow rectangular section is to be designed for mini-
mum weight to carry a vertical load Fy and an axial load P as shown in Fig. 1.29.
The deflection of the beam in the y direction under the self-weight and Fy should
Problems 59
Figure 1.29 Simply supported beam under loads.
not exceed 0.5 in. The beam should not buckle either in the yz or the xz plane under
the axial load. Assuming the ends of the beam to be pin ended, formulate the opti-
mization problem using xi, i = 1, 2, 3, 4 as design variables for the following data:
Fy = 300 lb, P = 40,000 lb, l = 120 in., E = 30 × 106 psi, ρ = 0.284 lb/in3, lower
bound on x1 and x2 = 0.125 in, upper bound on x1, and x2 = 4 in.
(b) Formulate the problem stated in part (a) using x1 and x2 as design variables, assuming
the beam to have a solid rectangular cross section. Also find the solution of the
problem using a graphical technique.
1.29 A cylindrical pressure vessel with hemispherical ends (Fig. 1.30) is required to hold
at least 20,000 gallons of a fluid under a pressure of 2500 psia. The thicknesses of
the cylindrical and hemispherical parts of the shell should be equal to at least those
recommended by section VIII of the ASME pressure vessel code, which are given by
tc =
pR
Se + 0.4p
th =
pR
Se + 0.8p
Figure 1.30 Pressure vessel.
60 Introduction to Optimization
Figure 1.31 Crane hook carrying a load.
where S is the yield strength, e the joint efficiency, p the pressure, and R the radius.
Formulate the design problem for minimum structural volume using xi, i = 1, 2, 3, 4, as
design variables. Assume the following data: S = 30,000 psi and e = 1.0.
1.30 A crane hook is to be designed to carry a load F as shown in Fig. 1.31. The hook can
be modeled as a three-quarter circular ring with a rectangular cross section. The stresses
induced at the inner and outer fibers at section AB should not exceed the yield strength
of the material. Formulate the problem of minimum volume design of the hook using
ro, ri , b, and h as design variables. Note: The stresses induced at points A and B are
given by [1.117]
σA =
Mco
Aero
σB =
Mci
Aeri
where M is the bending moment due to the load (= FR), R the radius of the centroid,
ro the radius of the outer fiber, ri the radius of the inner fiber, co the distance of the
outer fiber from the neutral axis = Ro − rn, ci the distance of inner fiber from neutral
axis = rn − ri , rn the radius of neutral axis, given by
rn =
h
In(ro/ri)
A the cross-sectional area of the hook = bh, and e the distance between the centroidal
and neutral axes = R − rn.
1.31 Consider the four-bar truss shown in Fig. 1.32, in which members 1, 2, and 3 have
the same cross-sectional area x1 and the same length l, while member 4 has an area of
Problems 61
Figure 1.32 Four-bar truss.
cross section x2 and length
√
3 l. The truss is made of a lightweight material for which
Young’s modulus and the weight density are given by 30 × 106 psi and 0.03333 lb/in3,
respectively. The truss is subject to the loads P1 = 10,000 lb and P2 = 20,000 lb. The
weight of the truss per unit value of l can be expressed as
f = 3x1(1)(0.03333) + x2
√
3(0.03333) = 0.1x1 + 0.05773x2
The vertical deflection of joint A can be expressed as
δA =
0.6
x1
+
0.3464
x2
and the stresses in members 1 and 4 can be written as
σ1 =
5(10,000)
x1
=
50,000
x1
, σ4 =
−2
√
3(10,000)
x2
= −
34,640
x2
The weight of the truss is to be minimized with constraints on the vertical deflection of
the joint A and the stresses in members 1 and 4. The maximum permissible deflection
of joint A is 0.1 in. and the permissible stresses in members are σmax = 8333.3333 psi
(tension) and σmin = −4948.5714 psi (compression). The optimization problem can be
stated as a separable programming problem as follows:
Minimize f (x1, x2) = 0.1x1 + 0.05773x2
subject to
0.6
x1
+
0.3464
x2
− 0.1 ≤ 0, 6 − x1 ≤ 0, 7 − x2 ≤ 0
Determine the solution of the problem using a graphical procedure.
1.32 A simply supported beam, with a uniform rectangular cross section, is subjected to both
distributed and concentrated loads as shown in Fig. 1.33. It is desired to find the cross
section of the beam to minimize the weight of the beam while ensuring that the maximum
stress induced in the beam does not exceed the permissible stress (σ0) of the material
and the maximum deflection of the beam does not exceed a specified limit (δ0).
The data of the problem are P = 105 N, p0 = 106 N/m, L = 1 m, E = 207 GPa, weight
density (ρw) = 76.5 kN/m3, σ0 = 220 MPa, and δ0 = 0.02 m.
62 Introduction to Optimization
x2
x1
p0 per unit length
Cross-section
P
L
L
2
Figure 1.33 A simply supported beam subjected to concentrated and distributed loads.
(a) Formulate the problem as a mathematical programming problem assuming that
the cross-sectional dimensions of the beam are restricted as x1 ≤ x2, 0.04m ≤ x1
≤ 0.12m, and 0.06m ≤ x2 ≤ 0.20 m.
(b) Find the solution of the problem formulated in part (a) using MATLAB.
(c) Find the solution of the problem formulated in part (a) graphically.
1.33 Solve Problem 1.32, parts (a), (b), and (c), assuming the cross section of the beam to
be hollow circular with inner diameter x1 and outer diameter x2. Assume the data and
bounds on the design variables to be as given in Problem 1.32.
1.34 Find the solution of Problem 1.31 using MATLAB.
1.35 Find the solution of Problem 1.2(a) using MATLAB.
1.36 Find the solution of Problem 1.2(b) using MATLAB.
2
Classical Optimization Techniques
2.1 INTRODUCTION
The classical methods of optimization are useful in finding the optimum solution of
continuous and differentiable functions. These methods are analytical and make use
of the techniques of differential calculus in locating the optimum points. Since some
of the practical problems involve objective functions that are not continuous and/or
differentiable, the classical optimization techniques have limited scope in practical
applications. However, a study of the calculus methods of optimization forms a basis for
developing most of the numerical techniques of optimization presented in subsequent
chapters. In this chapter we present the necessary and sufficient conditions in locating
the optimum solution of a single-variable function, a multivariable function with no
constraints, and a multivariable function with equality and inequality constraints.
2.2 SINGLE-VARIABLE OPTIMIZATION
A function of one variable f (x) is said to have a relative or local minimum at x =
x∗ if f (x∗) ≤ f (x∗ + h) for all sufficiently small positive and negative values of h.
Similarly, a point x∗ is called a relative or local maximum if f (x∗) ≥ f (x∗ + h) for
all values of h sufficiently close to zero. A function f (x) is said to have a global
or absolute minimum at x∗ if f (x∗) ≤ f (x) for all x, and not just for all x close to
x∗, in the domain over which f (x) is defined. Similarly, a point x∗ will be a global
maximum of f (x) if f (x∗) ≥ f (x) for all x in the domain. Figure 2.1 shows the
difference between the local and global optimum points.
A single-variable optimization problem is one in which the value of x = x∗ is to be
found in the interval [a, b] such that x∗ minimizes f (x). The following two theorems
provide the necessary and sufficient conditions for the relative minimum of a function
of a single variable.
Theorem 2.1 Necessary Condition If a function f (x) is defined in the interval a ≤
x ≤ b and has a relative minimum at x = x∗, where a < x∗ < b, and if the derivative
df (x)/dx = f ′(x) exists as a finite number at x = x∗, then f ′(x∗) = 0.
Proof : It is given that
f ′(x∗) = lim
h→0
f (x∗ + h) − f (x∗)
h
(2.1)
63Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
64 Classical Optimization Techniques
Figure 2.1 Relative and global minima.
exists as a definite number, which we want to prove to be zero. Since x∗ is a relative
minimum, we have
f (x∗) ≤ f (x∗ + h)
for all values of h sufficiently close to zero. Hence
f (x∗ + h) − f (x∗)
h
≥ 0 if h > 0
f (x∗ + h) − f (x∗)
h
≤ 0 if h < 0
Thus Eq. (2.1) gives the limit as h tends to zero through positive values as
f ′(x∗) ≥ 0 (2.2)
while it gives the limit as h tends to zero through negative values as
f ′(x∗) ≤ 0 (2.3)
The only way to satisfy both Eqs. (2.2) and (2.3) is to have
f ′(x∗) = 0 (2.4)
This proves the theorem.
Notes:
1. This theorem can be proved even if x∗ is a relative maximum.
2. The theorem does not say what happens if a minimum or maximum occurs at
a point x∗ where the derivative fails to exist. For example, in Fig. 2.2,
lim
h→0
f (x∗ + h) − f (x∗)
h
= m+(positive) or m−(negative)
depending on whether h approaches zero through positive or negative values,
respectively. Unless the numbers m+ and m− are equal, the derivative f ′(x∗)
does not exist. If f ′(x∗) does not exist, the theorem is not applicable.
2.2 Single-Variable Optimization 65
Figure 2.2 Derivative undefined at x∗.
3. The theorem does not say what happens if a minimum or maximum occurs at
an endpoint of the interval of definition of the function. In this case
lim
h→0
f (x∗ + h) − f (x∗)
h
exists for positive values of h only or for negative values of h only, and hence
the derivative is not defined at the endpoints.
4. The theorem does not say that the function necessarily will have a minimum
or maximum at every point where the derivative is zero. For example, the
derivative f ′(x) = 0 at x = 0 for the function shown in Fig. 2.3. However, this
point is neither a minimum nor a maximum. In general, a point x∗ at which
f ′(x∗) = 0 is called a stationary point .
If the function f (x) possesses continuous derivatives of every order that come in
question, in the neighborhood of x = x∗, the following theorem provides the sufficient
condition for the minimum or maximum value of the function.
Figure 2.3 Stationary (inflection) point.
66 Classical Optimization Techniques
Theorem 2.2 Sufficient Condition Let f ′(x∗) = f ′′(x∗) = · · · = f (n−1)(x∗) = 0,
but f (n)(x∗) = 0. Then f (x∗) is (i) a minimum value of f (x) if f (n)(x∗) > 0 and n
is even; (ii) a maximum value of f (x) if f (n)(x∗) < 0 and n is even; (iii) neither a
maximum nor a minimum if n is odd.
Proof : Applying Taylor’s theorem with remainder after n terms, we have
f (x∗ + h) =f (x∗) + hf ′(x∗) +
h2
2!
f ′′(x∗) + · · · +
hn−1
(n − 1)!
f (n−1)(x∗)
+ h
n
n!
f (n)(x∗ + θh) for 0 < θ < 1 (2.5)
Since f ′(x∗) = f ′′(x∗) = · · · = f (n−1)(x∗) = 0, Eq. (2.5) becomes
f (x∗ + h) − f (x∗) =
hn
n!
f (n)(x∗ + θh)
As f (n)(x∗) = 0, there exists an interval around x∗ for every point x of which the nth
derivative f (n)(x) has the same sign, namely, that of f (n)(x∗). Thus for every point
x∗ + h of this interval, f (n)(x∗ + θh) has the sign of f (n)(x∗). When n is even, hn/n! is
positive irrespective of whether h is positive or negative, and hence f (x∗ + h) − f (x∗)
will have the same sign as that of f (n)(x∗). Thus x∗ will be a relative minimum if
f (n)(x∗) is positive and a relative maximum if f (n)(x∗) is negative. When n is odd,
hn/n! changes sign with the change in the sign of h and hence the point x∗ is neither
a maximum nor a minimum. In this case the point x∗ is called a point of inflection .
Example 2.1 Determine the maximum and minimum values of the function
f (x) = 12x5 − 45x4 + 40x3 + 5
SOLUTION Since f ′(x) = 60(x4 − 3x3 + 2x2) = 60x2(x − 1)(x − 2), f ′(x) = 0 at
x = 0, x = 1, and x = 2. The second derivative is
f ′′(x) = 60(4x3 − 9x2 + 4x)
At x = 1, f ′′(x) = −60 and hence x = 1 is a relative maximum. Therefore,
fmax = f (x = 1) = 12
At x = 2, f ′′(x) = 240 and hence x = 2 is a relative minimum. Therefore,
fmin = f (x = 2) = −11
At x = 0, f ′′(x) = 0 and hence we must investigate the next derivative:
f ′′′(x) = 60(12x2 − 18x + 4) = 240 at x = 0
Since f ′′′(x) = 0 at x = 0, x = 0 is neither a maximum nor a minimum, and it is an
inflection point.
2.2 Single-Variable Optimization 67
Example 2.2 In a two-stage compressor, the working gas leaving the first stage of
compression is cooled (by passing it through a heat exchanger) before it enters the
second stage of compression to increase the efficiency [2.13]. The total work input to
a compressor (W) for an ideal gas, for isentropic compression, is given by
W = cpT1
[
(
p2
p1
)(k−1)/k
+
(
p3
p2
)(k−1)/k
− 2
]
where cp is the specific heat of the gas at constant pressure, k is the ratio of specific
heat at constant pressure to that at constant volume of the gas, and T1 is the temperature
at which the gas enters the compressor. Find the pressure, p2, at which intercooling
should be done to minimize the work input to the compressor. Also determine the
minimum work done on the compressor.
SOLUTION The necessary condition for minimizing the work done on the compres-
sor is
dW
dp2
= cpT1
k
k − 1
[
(
1
p1
)(k−1)/k
k − 1
k
(p2)
−1/k
+(p3)(k−1)/k
−k + 1
k
(p2)
(1−2k)/k
]
= 0
which yields
p2 = (p1p3)1/2
The second derivative of W with respect to p2 gives
d2W
dp22
= cpT1
[
−
(
1
P1
)(k−1)/k
1
k
(p2)
−(1+k)/k
−(p3)(k−1)/k
1 − 2k
k
(p2)
(1−3k)/k
]
(
d2W
dp22
)
p2 = (p1 p2)1/2
=
2cpT1
k − 1
k
p
(3k−1)/2k
1 p
(k+1)/2k
3
Since the ratio of specific heats k is greater than 1, we get
d2W
dp22
> 0 at p2 = (p1p3)1/2
and hence the solution corresponds to a relative minimum. The minimum work done
is given by
Wmin = 2cpT1
k
k − 1
[
(
p3
p1
)(k−1)/2k
− 1
]
68 Classical Optimization Techniques
2.3 MULTIVARIABLE OPTIMIZATION WITH NO CONSTRAINTS
In this section we consider the necessary and sufficient conditions for the minimum
or maximum of an unconstrained function of several variables. Before seeing these
conditions, we consider the Taylor’s series expansion of a multivariable function.
Definition: r th Differential of f . If all partial derivatives of the function f through
order r ≥ 1 exist and are continuous at a point X∗, the polynomial
drf (X∗) =
n
∑
i=1
n
∑
j=1
· · ·
n
∑
k=1
︸ ︷︷ ︸
rsummations
hihj · · · hk
∂rf (X∗)
∂xi∂xj · · · ∂xk
(2.6)
is called the rth differential of f at X∗. Notice that there are r summations and one hi
is associated with each summation in Eq. (2.6).
For example, when r = 2 and n = 3, we have
d2f (X∗) = d2f (x∗1 , x∗2 , x∗3 ) =
3
∑
i=1
3
∑
j=1
hihj
∂2f (X∗)
∂xi ∂xj
= h21
∂2f
∂x21
(X∗) + h22
∂2f
∂x22
(X∗) + h23
∂2f
∂x23
(X∗)
+ 2h1h2
∂2f
∂x1∂x2
(X∗) + 2h2h3
∂2f
∂x2∂x3
(X∗) + 2h1h3
∂2f
∂x1∂x3
(X∗)
The Taylor’s series expansion of a function f (X) about a point X∗ is given by
f (X) =f (X∗) + df (X∗) + 1
2!
d2f (X∗) + 1
3!
d3f (X∗)
+ · · · + 1
N !
dNf (X∗) + RN (X∗, h) (2.7)
where the last term, called the remainder , is given by
RN (X
∗, h) = 1
(N + 1)!
dN+1f (X∗ + θh) (2.8)
where 0 < θ < 1 and h = X − X∗.
Example 2.3 Find the second-order Taylor’s series approximation of the function
f (x1, x2, x3) = x22x3 + x1ex3
about the point X∗ = {1, 0,−2}T.
SOLUTION The second-order Taylor’s series approximation of the function f about
point X∗ is given by
f (X) = f


1
0
−2

+ df


1
0
−2

+
1
2!
d2f


1
0
−2


2.3 Multivariable Optimization with No Constraints 69
where
f


1
0
−2

 = e−2
df


1
0
−2

 = h1
∂f
∂x1


1
0
−2

+ h2
∂f
∂x2


1
0
−2

+ h3
∂f
∂x3


1
0
−2


= [h1ex3 + h2(2x2x3) + h3x22 + h3x1ex3]


1
0
−2

 = h1e−2 + h3e−2
d2f


1
0
−2

 =
3
∑
i=1
3
∑
j=1
hihj
∂2f
∂xi∂xj


1
0
−2

 =
(
h21
∂2f
∂x21
+ h22
∂2f
∂x22
+ h23
∂2f
∂x23
+ 2h1h2
∂2f
∂x1∂x2
+ 2h2h3
∂2f
∂x2∂x3
+ 2h1h3
∂2f
∂x1∂x3
)


1
0
−2


= [h21(0) + h22(2x3) + h23(x1ex3) + 2h1h2(0) + 2h2h3(2x2)
+ 2h1h3(ex3)]


1
0
−2

 = −4h22 + e−2h23 + 2h1 h3e−2
Thus the Taylor’s series approximation is given by
f (X) ≃ e−2 + e−2(h1 + h3) +
1
2!
(−4h22 + e−2h23 + 2h1 h3e−2)
where h1 = x1 − 1, h2 = x2, and h3 = x3 + 2.
Theorem 2.3 Necessary Condition If f (X) has an extreme point (maximum or min-
imum) at X = X∗ and if the first partial derivatives of f (X) exist at X∗, then
∂f
∂x1
(X∗) = ∂f
∂x2
(X∗) = · · · = ∂f
∂xn
(X∗) = 0 (2.9)
Proof : The proof given for Theorem 2.1 can easily be extended to prove the present
theorem. However, we present a different approach to prove this theorem. Suppose that
one of the first partial derivatives, say the kth one, does not vanish at X∗. Then, by
Taylor’s theorem,
f (X∗ + h) = f (X∗) +
n
∑
i=1
hi
∂f
∂xi
(X∗) + R1(X∗, h)
70 Classical Optimization Techniques
that is,
f (X∗ + h) − f (X∗) = hk
∂f
∂xk
(X∗) + 1
2!
d2f (X∗ + θh), 0 < θ < 1
Since d2f (X∗ + θh) is of order h2i , the terms of order h will dominate the higher-order
terms for small h. Thus the sign of f (X∗ + h) − f (X∗) is decided by the sign of
hk ∂f (X
∗)/∂xk . Suppose that ∂f (X
∗)/∂xk > 0. Then the sign of f (X
∗ + h) − f (X∗)
will be positive for hk > 0 and negative for hk < 0. This means that X
∗ cannot be
an extreme point. The same conclusion can be obtained even if we assume that
∂f (X∗)/∂xk < 0. Since this conclusion is in contradiction with the original statement
that X∗ is an extreme point, we may say that ∂f/∂xk = 0 at X = X∗. Hence the theorem
is proved.
Theorem 2.4 Sufficient Condition A sufficient condition for a stationary point X∗
to be an extreme point is that the matrix of second partial derivatives (Hessian matrix)
of f (X) evaluated at X∗ is (i) positive definite when X∗ is a relative minimum point,
and (ii) negative definite when X∗ is a relative maximum point.
Proof : From Taylor’s theorem we can write
f (X∗ + h) = f (X∗) +
n
∑
i=1
hi
∂f
∂xi
(X∗) +
1
2!
n
∑
i=1
n
∑
j=1
hihj
∂2f
∂xi∂xj
∣
∣
∣
∣
X=X∗+ θh
,
0 < θ < 1 (2.10)
Since X∗ is a stationary point, the necessary conditions give (Theorem 2.3)
∂f
∂xi
= 0, i = 1, 2, . . . , n
Thus Eq. (2.10) reduces to
f (X∗ + h) − f (X∗) = 1
2!
n
∑
i=1
n
∑
j=1
hihj
∂2f
∂xi∂xj
∣
∣
∣
∣
X=X∗+ θh
, 0 < θ < 1
Therefore, the sign of
f (X∗ + h) − f (X∗)
will be same as that of
n
∑
i=1
n
∑
j=1
hihj
∂2f
∂xi∂xj
∣
∣
∣
∣
X=X∗+ θh
Since the second partial derivative of ∂2f (X)/∂xi∂xj is continuous in the neighborhood
of X∗,
∂2f
∂xi∂xj
∣
∣
∣
∣
X=X∗+ θh
2.3 Multivariable Optimization with No Constraints 71
will have the same sign as (∂2f/∂xi∂xj )| X = X∗ for all sufficiently small h. Thus
f (X∗ + h) − f (X∗) will be positive, and hence X∗ will be a relative minimum, if
Q =
n
∑
i=1
n
∑
j=1
hihj
∂2f
∂xi∂xj
∣
∣
∣
∣
X=X∗
(2.11)
is positive. This quantity Q is a quadratic form and can be written in matrix form as
Q = hTJh|X=X∗ (2.12)
where
J|X=X∗ =
[
∂2f
∂xi∂xj
∣
∣
∣
∣
X=X∗
]
(2.13)
is the matrix of second partial derivatives and is called the Hessian matrix of f (X).
It is known from matrix algebra that the quadratic form of Eq. (2.11) or (2.12)
will be positive for all h if and only if [J] is positive definite at X = X∗. This means
that a sufficient condition for the stationary point X∗ to be a relative minimum is that
the Hessian matrix evaluated at the same point be positive definite. This completes the
proof for the minimization case. By proceeding in a similar manner, it can be proved
that the Hessian matrix will be negative definite if X∗ is a relative maximum point.
Note: A matrix A will be positive definite if all its eigenvalues are positive; that
is, all the values of λ that satisfy the determinantal equation
|A − λI| = 0 (2.14)
should be positive. Similarly, the matrix [A] will be negative definite if its eigenvalues
are negative.
Another test that can be used to find the positive definiteness of a matrix A of
order n involves evaluation of the determinants
A = |a11| ,
A2 =
∣
∣
∣
∣
a11 a12
a21 a22
∣
∣
∣
∣
,
A3 =
∣
∣
∣
∣
∣
∣
a11 a12 a13
a21 a22 a23
a31 a32 a32
∣
∣
∣
∣
∣
∣
, . . . ,
An =
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
a11 a12 a13 · · · a1n
a21 a22 a23 · · · a2n
a31 a32 a33 · · · a3n
...
an1 an2 an3 · · · ann
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
(2.15)
The matrix A will be positive definite if and only if all the values A1, A2, A3, . . . , An
are positive. The matrix A will be negative definite if and only if the sign of Aj is
(–1)j for j = 1, 2, . . . , n. If some of the Aj are positive and the remaining Aj are
zero, the matrix A will be positive semidefinite.
Example 2.4 Figure 2.4 shows two frictionless rigid bodies (carts) A and B connected
by three linear elastic springs having spring constants k1, k2, and k3. The springs are
at their natural positions when the applied force P is zero. Find the displacements x1
and x2 under the force P by using the principle of minimum potential energy.
72 Classical Optimization Techniques
Figure 2.4 Spring–cart system.
SOLUTION According to the principle of minimum potential energy, the system will
be in equilibrium under the load P if the potential energy is a minimum. The potential
energy of the system is given by
potential energy (U)
= strain energy of springs − work done by external forces
= [ 1
2
k2x
2
1 +
1
2
k3(x2 − x1)2 + 12k1 x
2
2 ] − Px2
The necessary conditions for the minimum of U are
∂U
∂x1
= k2x1 − k3(x2 − x1) = 0 (E1)
∂U
∂x2
= k3(x2 − x1) + k1x2 − P = 0 (E2)
The values of x1 and x2 corresponding to the equilibrium state, obtained by solving
Eqs. (E1) and (E2), are given by
x∗1 =
Pk3
k1k2 + k1k3 + k2k3
x∗2 =
P(k2 + k3)
k1k2 + k1k3 + k2k3
The sufficiency conditions for the minimum at (x∗1 , x
∗
2 ) can also be verified by testing
the positive definiteness of the Hessian matrix of U . The Hessian matrix of U evaluated
at (x∗1 , x
∗
2 ) is
J
∣
∣
∣(x∗1 ,x
∗
2 )
=






∂2U
∂x21
∂2U
∂x1∂x2
∂2U
∂x1∂x2
∂2U
∂x22






(x∗
1
,x∗
2
)
=
[
k2 + k3 −k3
−k3 k1 + k3
]
2.3 Multivariable Optimization with No Constraints 73
The determinants of the square submatrices of J are
J1 =
∣
∣k2 + k3
∣
∣ = k2 + k3 > 0
J2 =
∣
∣
∣
∣
∣
k2 + k3 −k3
−k3 k1 + k3
∣
∣
∣
∣
∣
= k1k2 + k1k3 + k2k3 > 0
since the spring constants are always positive. Thus the matrix J is positive definite
and hence (x∗1 , x
∗
2 ) corresponds to the minimum of potential energy.
2.3.1 Semidefinite Case
We now consider the problem of determining the sufficient conditions for the case
when the Hessian matrix of the given function is semidefinite. In the case of a func-
tion of a single variable, the problem of determining the sufficient conditions for
the case when the second derivative is zero was resolved quite easily. We simply
investigated the higher-order derivatives in the Taylor’s series expansion. A simi-
lar procedure can be followed for functions of n variables. However, the algebra
becomes quite involved, and hence we rarely investigate the stationary points for suf-
ficiency in actual practice. The following theorem, analogous to Theorem 2.2, gives
the sufficiency conditions for the extreme points of a function of several variables.
Theorem 2.5 Let the partial derivatives of f of all orders up to the order k ≥ 2 be
continuous in the neighborhood of a stationary point X∗, and
drf |X=X∗ = 0, 1 ≤ r ≤ k − 1
dkf |X=X∗ = 0
so that dkf |X=X∗ is the first nonvanishing higher-order differential of f at X∗. If k is
even, then (i) X∗ is a relative minimum if dkf |X=X∗ is positive definite, (ii) X∗ is a
relative maximum if dkf |X=X∗ is negative definite, and (iii) if dkf |X=X∗ is semidefinite
(but not definite), no general conclusion can be drawn. On the other hand, if k is odd,
X∗ is not an extreme point of f (X).
Proof : A proof similar to that of Theorem 2.2 can be found in Ref. [2.5].
2.3.2 Saddle Point
In the case of a function of two variables, f (x, y), the Hessian matrix may be neither
positive nor negative definite at a point (x∗, y∗) at which
∂f
∂x
= ∂f
∂y
= 0
In such a case, the point (x∗, y∗) is called a saddle point . The characteristic of a
saddle point is that it corresponds to a relative minimum or maximum of f (x, y) with
respect to one variable, say, x (the other variable being fixed at y = y∗) and a relative
maximum or minimum of f (x, y) with respect to the second variable y (the other
variable being fixed at x∗).
74 Classical Optimization Techniques
As an example, consider the function f (x, y) = x2 − y2. For this function,
∂f
∂x
= 2x and ∂f
∂y
= −2y
These first derivatives are zero at x∗ = 0 and y∗ = 0. The Hessian matrix of f at
(x∗, y∗) is given by
J =
[
2 0
0 −2
]
Since this matrix is neither positive definite nor negative definite, the point (x∗ = 0,
y∗ = 0) is a saddle point. The function is shown graphically in Fig. 2.5. It can be seen
that f (x, y∗) = f (x, 0) has a relative minimum and f (x∗, y) = f (0, y) has a relative
maximum at the saddle point (x∗, y∗). Saddle points may exist for functions of more
than two variables also. The characteristic of the saddle point stated above still holds
provided that x and y are interpreted as vectors in multidimensional cases.
Example 2.5 Find the extreme points of the function
f (x1, x2) = x31 + x32 + 2x21 + 4x22 + 6
SOLUTION The necessary conditions for the existence of an extreme point are
∂f
∂x1
= 3x21 + 4x1 = x1(3x1 + 4) = 0
∂f
∂x2
= 3x22 + 8x2 = x2(3x2 + 8) = 0
Figure 2.5 Saddle point of the function f (x, y) = x2 − y2.
2.4 Multivariable Optimization with Equality Constraints 75
These equations are satisfied at the points
(0, 0), (0, − 8
3
), (− 4
3
, 0), and (− 4
3
, − 8
3
)
To find the nature of these extreme points, we have to use the sufficiency conditions.
The second-order partial derivatives of f are given by
∂2f
∂x21
= 6x1 + 4
∂2f
∂x22
= 6x2 + 8
∂2f
∂x1∂x2
= 0
The Hessian matrix of f is given by
J =
[
6x1 + 4 0
0 6x2 + 8
]
If J1 = |6x1 + 4| and J2 =
∣
∣
∣
∣
6x1 + 4 0
0 6x2 + 8
∣
∣
∣
∣
, the values of J1 and J2 and the nature
of the extreme point are as given below:
Point X Value of J1 Value of J2 Nature of J Nature of X f (X)
(0, 0) +4 +32 Positive definite Relative minimum 6
(0,− 8
3
) +4 –32 Indefinite Saddle point 418/27
(− 4
3
, 0) –4 –32 Indefinite Saddle point 194/27
(− 4
3
, − 8
3
) –4 +32 Negative definite Relative maximum 50/3
2.4 MULTIVARIABLE OPTIMIZATION WITH EQUALITY
CONSTRAINTS
In this section we consider the optimization of continuous functions subjected to equal-
ity constraints:
Minimizef = f (X)
subject to
gj (X) = 0, j = 1, 2, . . . , m
(2.16)
where
X =









x1
x2
...
xn









76 Classical Optimization Techniques
Here m is less than or equal to n; otherwise (if m >n), the problem becomes overdefined
and, in general, there will be no solution. There are several methods available for the
solution of this problem. The methods of direct substitution, constrained variation, and
Lagrange multipliers are discussed in the following sections.
2.4.1 Solution by Direct Substitution
For a problem with n variables and m equality constraints, it is theoretically possible
to solve simultaneously the m equality constraints and express any set of m variables
in terms of the remaining n − m variables. When these expressions are substituted into
the original objective function, there results a new objective function involving only
n − m variables. The new objective function is not subjected to any constraint, and
hence its optimum can be found by using the unconstrained optimization techniques
discussed in Section 2.3.
This method of direct substitution, although it appears to be simple in theory, is
not convenient from a practical point of view. The reason for this is that the con-
straint equations will be nonlinear for most of practical problems, and often it becomes
impossible to solve them and express any m variables in terms of the remaining n − m
variables. However, the method of direct substitution might prove to be very simple
and direct for solving simpler problems, as shown by the following example.
Example 2.6 Find the dimensions of a box of largest volume that can be inscribed
in a sphere of unit radius.
SOLUTION Let the origin of the Cartesian coordinate system x1, x2, x3 be at the
center of the sphere and the sides of the box be 2x1, 2x2, and 2x3. The volume of the
box is given by
f (x1, x2, x3) = 8x1x2x3 (E1)
Since the corners of the box lie on the surface of the sphere of unit radius, x1, x2, and
x3 have to satisfy the constraint
x21 + x22 + x23 = 1 (E2)
This problem has three design variables and one equality constraint. Hence the
equality constraint can be used to eliminate any one of the design variables from the
objective function. If we choose to eliminate x3, Eq. (E2) gives
x3 = (1 − x21 − x22)1/2 (E3)
Thus the objective function becomes
f (x1, x2) = 8x1x2(1 − x21 − x22 )1/2 (E4)
which can be maximized as an unconstrained function in two variables.
2.4 Multivariable Optimization with Equality Constraints 77
The necessary conditions for the maximum of f give
∂f
∂x1
= 8x2
[
(1 − x21 − x22)1/2 −
x21
(1 − x21 − x22 )1/2
]
= 0 (E5)
∂f
∂x2
= 8x1
[
(1 − x21 − x22)1/2 −
x22
(1 − x21 − x22 )1/2
]
= 0 (E6)
Equations (E5) and (E6) can be simplified to obtain
1 − 2x21 − x22 = 0
1 − x21 − 2x22 = 0
from which it follows that x∗1 = x∗2 = 1/
√
3 and hence x∗3 = 1/
√
3. This solution gives
the maximum volume of the box as
fmax =
8
3
√
3
To find whether the solution found corresponds to a maximum or a minimum,
we apply the sufficiency conditions to f (x1, x2) of Eq. (E4). The second-order partial
derivatives of f at (x∗1 , x
∗
2 ) are given by
∂2f
∂x21
= −
32
√
3
at (x∗1 , x
∗
2 )
∂2f
∂x22
= − 32√
3
at (x∗1 , x
∗
2 )
∂2f
∂x1∂x2
= − 16√
3
at (x∗1 , x
∗
2 )
Since
∂2f
∂x21
< 0 and
∂2f
∂x21
∂2f
∂x22
−
(
∂2f
∂x1∂x2
)2
> 0
the Hessian matrix of f is negative definite at (x∗1 , x
∗
2 ). Hence the point (x
∗
1 , x
∗
2 )
corresponds to the maximum of f .
2.4.2 Solution by the Method of Constrained Variation
The basic idea used in the method of constrained variation is to find a closed-form
expression for the first-order differential of f (df) at all points at which the constraints
gj (X) = 0, j = 1, 2, . . . , m, are satisfied. The desired optimum points are then obtained
by setting the differential df equal to zero. Before presenting the general method,
78 Classical Optimization Techniques
we indicate its salient features through the following simple problem with n = 2 and
m = 1:
Minimize f (x1, x2) (2.17)
subject to
g(x1, x2) = 0 (2.18)
A necessary condition for f to have a minimum at some point (x∗1 , x
∗
2 ) is that the total
derivative of f (x1, x2) with respect to x1 must be zero at (x
∗
1 , x
∗
2 ). By setting the total
differential of f (x1, x2) equal to zero, we obtain
df = ∂f
∂x1
dx1 +
∂f
∂x2
dx2 = 0 (2.19)
Since g(x∗1 , x
∗
2 ) = 0 at the minimum point, any variations dx1 and dx2 taken about
the point (x∗1 , x
∗
2 ) are called admissible variations provided that the new point lies on
the constraint:
g(x∗1 + dx1, x∗2 + dx2) = 0 (2.20)
The Taylor’s series expansion of the function in Eq. (2.20) about the point (x∗1 , x
∗
2 )
gives
g(x∗1 + dx1, x∗2 + dx2)
≃ g(x∗1 , x∗2 ) +
∂g
∂x1
(x∗1 , x
∗
2 ) dx1 +
∂g
∂x2
(x∗1 , x
∗
2 ) dx2 = 0 (2.21)
where dx1 and dx2 are assumed to be small. Since g(x
∗
1 , x
∗
2 ) = 0, Eq. (2.21) reduces
to
dg = ∂g
∂x1
dx1 +
∂g
∂x2
dx2 = 0 at (x∗1 , x∗2 ) (2.22)
Thus Eq. (2.22) has to be satisfied by all admissible variations. This is illustrated
in Fig. 2.6, where PQ indicates the curve at each point of which Eq. (2.18) is sat-
isfied. If A is taken as the base point (x∗1 , x
∗
2 ), the variations in x1 and x2 leading
to points B and C are called admissible variations . On the other hand, the varia-
tions in x1 and x2 representing point D are not admissible since point D does not
Figure 2.6 Variations about A.
2.4 Multivariable Optimization with Equality Constraints 79
lie on the constraint curve, g(x1, x2) = 0. Thus any set of variations (dx1, dx2) that
does not satisfy Eq. (2.22) leads to points such as D, which do not satisfy constraint
Eq. (2.18).
Assuming that ∂g/∂x2 = 0, Eq. (2.22) can be rewritten as
dx2 = −
∂g/∂x1
∂g/∂x2
(x∗1 , x
∗
2 )dx1 (2.23)
This relation indicates that once the variation in x1(dx1) is chosen arbitrarily, the
variation in x2 (dx2) is decided automatically in order to have dx1 and dx2 as a set of
admissible variations. By substituting Eq. (2.23) in Eq. (2.19), we obtain
df =
(
∂f
∂x1
− ∂g/∂x1
∂g/∂x2
∂f
∂x2
)∣
∣
∣
∣
(x∗1 , x
∗
2 )
dx1 = 0 (2.24)
The expression on the left-hand side is called the constrained variation of f . Note that
Eq. (2.24) has to be satisfied for all values of dx1. Since dx1 can be chosen arbitrarily,
Eq. (2.24) leads to
(
∂f
∂x1
∂g
∂x2
− ∂f
∂x2
∂g
∂x1
)∣
∣
∣
∣
(x∗
1
, x∗
2
)
= 0 (2.25)
Equation (2.25) represents a necessary condition in order to have (x∗1 , x
∗
2 ) as an extreme
point (minimum or maximum).
Example 2.7 A beam of uniform rectangular cross section is to be cut from a log
having a circular cross section of diameter 2a. The beam has to be used as a cantilever
beam (the length is fixed) to carry a concentrated load at the free end. Find the dimen-
sions of the beam that correspond to the maximum tensile (bending) stress carrying
capacity.
SOLUTION From elementary strength of materials, we know that the tensile stress
induced in a rectangular beam (σ ) at any fiber located a distance y from the neutral
axis is given by
σ
y
=
M
I
where M is the bending moment acting and I is the moment of inertia of the cross
section about the x axis. If the width and depth of the rectangular beam shown in
Fig. 2.7 are 2x and 2y, respectively, the maximum tensile stress induced is given by
σmax =
M
I
y = My
1
12
(2x)(2y)3
= 3
4
M
xy2
Thus for any specified bending moment, the beam is said to have maximum tensile
stress carrying capacity if the maximum induced stress (σmax) is a minimum. Hence
we need to minimize k/xy2 or maximize Kxy2, where k = 3M/4 and K = 1/k, subject
to the constraint
x2 + y2 = a2
80 Classical Optimization Techniques
Figure 2.7 Cross section of the log.
This problem has two variables and one constraint; hence Eq. (2.25) can be applied
for finding the optimum solution. Since
f = kx−1y−2 (E1)
g = x2 + y2 − a2 (E2)
we have
∂f
∂x
= −kx−2y−2
∂f
∂y
= −2kx−1y−3
∂g
∂x
= 2x
∂g
∂y
= 2y
Equation (2.25) gives
−kx−2y−2(2y) + 2kx−1y−3(2x) = 0 at (x∗, y∗)
that is,
y∗ =
√
2x∗ (E3)
Thus the beam of maximum tensile stress carrying capacity has a depth of
√
2 times
its breadth. The optimum values of x and y can be obtained from Eqs. (E3) and (E2)
as
x∗ = a√
3
and y∗ =
√
2
a
√
3
2.4 Multivariable Optimization with Equality Constraints 81
Necessary Conditions for a General Problem. The procedure indicated above can
be generalized to the case of a problem in n variables with m constraints. In this case,
each constraint equation gj (X) = 0, j = 1, 2, . . . , m, gives rise to a linear equation in
the variations dxi , i = 1, 2, . . . , n. Thus there will be in all m linear equations in n
variations. Hence any m variations can be expressed in terms of the remaining n − m
variations. These expressions can be used to express the differential of the objective
function, df , in terms of the n − m independent variations. By letting the coefficients
of the independent variations vanish in the equation df = 0, one obtains the necessary
conditions for the constrained optimum of the given function. These conditions can be
expressed as [2.6]
J
(
f, g1, g2, . . . , gm
xk, x1, x2, x3, . . . , xm
)
=
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∂f
∂xk
∂f
∂x1
∂f
∂x2
· · · ∂f
∂xm
∂g1
∂xk
∂g1
∂x1
∂g1
∂x2
· · · ∂g1
∂xm
∂g2
∂xk
∂g2
∂x1
∂g2
∂x2
· · · ∂g2
∂xm
...
∂gm
∂xk
∂gm
∂x1
∂gm
∂x2
· · · ∂gm
∂xm
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
= 0 (2.26)
where k = m + 1,m + 2, . . . , n. It is to be noted that the variations of the first m vari-
ables (dx1, dx2, . . . , dxm) have been expressed in terms of the variations of the remain-
ing n − m variables (dxm+1, dxm+2, . . . , dxn) in deriving Eqs. (2.26). This implies that
the following relation is satisfied:
J
(
g1, g2, . . . , gm
x1, x2, . . . , xm
)
= 0 (2.27)
The n − m equations given by Eqs. (2.26) represent the necessary conditions for the
extremum of f (X) under the m equality constraints, gj (X) = 0, j = 1, 2, . . . , m.
Example 2.8
Minimize f (Y) = 1
2
(y21 + y22 + y23 + y24) (E1)
subject to
g1(Y) = y1 + 2y2 + 3y3 + 5y4 − 10 = 0 (E2)
g2(Y) = y1 + 2y2 + 5y3 + 6y4 − 15 = 0 (E3)
SOLUTION This problem can be solved by applying the necessary conditions given
by Eqs. (2.26). Since n = 4 and m = 2, we have to select two variables as independent
variables. First we show that any arbitrary set of variables cannot be chosen as indepen-
dent variables since the remaining (dependent) variables have to satisfy the condition
of Eq. (2.27).
82 Classical Optimization Techniques
In terms of the notation of our equations, let us take the independent variables as
x3 = y3 and x4 = y4 so that x1 = y1 and x2 = y2
Then the Jacobian of Eq. (2.27) becomes
J
(
g1, g2
x1, x2
)
=
∣
∣
∣
∣
∣
∣
∣
∣
∂g1
∂y1
∂g1
∂y2
∂g2
∂y1
∂g2
∂y2
∣
∣
∣
∣
∣
∣
∣
∣
=
∣
∣
∣
∣
1 2
1 2
∣
∣
∣
∣
= 0
and hence the necessary conditions of Eqs. (2.26) cannot be applied.
Next, let us take the independent variables as x3 = y2 and x4 = y4 so that x1 = y1
and x2 = y3. Then the Jacobian of Eq. (2.27) becomes
J
(
g1, g2
x1, x2
)
=
∣
∣
∣
∣
∣
∣
∣
∣
∂g1
∂y1
∂g1
∂y3
∂g2
∂y1
∂g2
∂y3
∣
∣
∣
∣
∣
∣
∣
∣
=
∣
∣
∣
∣
1 3
1 5
∣
∣
∣
∣
= 2 = 0
and hence the necessary conditions of Eqs. (2.26) can be applied. Equations (2.26) give
for k = m + 1 = 3
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∂f
∂x3
∂f
∂x1
∂f
∂x2
∂g1
∂x3
∂g1
∂x1
∂g1
∂x2
∂g2
∂x3
∂g2
∂x1
∂g2
∂x2
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
=
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∂f
∂y2
∂f
∂y1
∂f
∂y3
∂g1
∂y2
∂g1
∂y1
∂g1
∂y3
∂g2
∂y2
∂g2
∂y1
∂g2
∂y3
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
=
∣
∣
∣
∣
∣
∣
∣
∣
y2 y1 y3
2 1 3
2 1 5
∣
∣
∣
∣
∣
∣
∣
∣
= y2(5 − 3) − y1(10 − 6) + y3(2 − 2)
= 2y2 − 4y1 = 0 (E4)
and for k = m + 2 = n = 4,
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∂f
∂x4
∂f
∂x1
∂f
∂x2
∂g1
∂x4
∂g1
∂x1
∂g1
∂x2
∂g2
∂x4
∂g2
∂x1
∂g2
∂x2
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
=
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∂f
∂y4
∂f
∂y1
∂f
∂y3
∂g1
∂y4
∂g1
∂y1
∂g1
∂y3
∂g2
∂y4
∂g2
∂y1
∂g2
∂y3
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
2.4 Multivariable Optimization with Equality Constraints 83
=
∣
∣
∣
∣
∣
∣
∣
∣
y4 y1 y3
5 1 3
6 1 5
∣
∣
∣
∣
∣
∣
∣
∣
= y4(5 − 3) − y1(25 − 18) + y3(5 − 6)
= 2y4 − 7y1 − y3 = 0 (E5)
Equations (E4) and (E5) give the necessary conditions for the minimum or the maxi-
mum of f as
y1 = 12y2
y3 = 2y4 − 7y1 = 2y4 − 72y2
(E6)
When Eqs. (E6) are substituted, Eqs. (E2) and (E3) take the form
−8y2 + 11y4 = 10
−15y2 + 16y4 = 15
from which the desired optimum solution can be obtained as
y∗1 = − 574
y∗2 = − 537
y∗3 = 15574
y∗4 = 3037
Sufficiency Conditions for a General Problem. By eliminating the first m variables,
using the m equality constraints (this is possible, at least in theory), the objective func-
tion f can be made to depend only on the remaining variables, xm+1, xm+2, . . . , xn.
Then the Taylor’s series expansion of f , in terms of these variables, about the extreme
point X∗ gives
f (X∗ + dX) ≃ f (X∗) +
n
∑
i=m+1
(
∂f
∂xi
)
g
dxi
+ 1
2!
n
∑
i=m+1
n
∑
j=m+1
(
∂2f
∂xi ∂xj
)
g
dxi dxj (2.28)
where (∂f/∂xi)g is used to denote the partial derivative of f with respect to xi
(holding all the other variables xm+1, xm+2, . . . , xi−1, xi+1, xi+2, . . . , xn constant)
when x1, x2, . . . , xm are allowed to change so that the constraints gj (X
∗ + dX) = 0,
j = 1, 2, . . . , m, are satisfied; the second derivative, (∂2f/∂xi∂xj )g , is used to denote
a similar meaning.
84 Classical Optimization Techniques
As an example, consider the problem of minimizing
f (X) = f (x1, x2, x3)
subject to the only constraint
g1(X) = x21 + x22 + x23 − 8 = 0
Since n = 3 and m = 1 in this problem, one can think of any of the m variables,
say x1, to be dependent and the remaining n − m variables, namely x2 and x3, to be
independent. Here the constrained partial derivative (∂f/∂x2)g , for example, means
the rate of change of f with respect to x2 (holding the other independent variable x3
constant) and at the same time allowing x1 to change about X
∗ so as to satisfy the
constraint g1(X) = 0. In the present case, this means that dx1 has to be chosen to
satisfy the relation
g1(X
∗ + dX) ≃ g1(X∗) +
∂g1
∂x1
(X∗)dx1 +
∂g1
∂x2
(X∗)dx2 +
∂g1
∂x3
(X∗)dx3 = 0
that is,
2x∗1 dx1 + 2x∗2 dx2 = 0
since g1(X
∗) = 0 at the optimum point and dx3 = 0 (x3 is held constant).
Notice that (∂f/∂xi)g has to be zero for i = m + 1, m + 2, . . . , n since the dxi
appearing in Eq. (2.28) are all independent. Thus the necessary conditions for the
existence of constrained optimum at X∗ can also be expressed as
(
∂f
∂xi
)
g
= 0, i = m + 1, m + 2, . . . , n (2.29)
Of course, with little manipulation, one can show that Eqs. (2.29) are nothing but
Eqs. (2.26). Further, as in the case of optimization of a multivariable function with no
constraints, one can see that a sufficient condition for X∗ to be a constrained relative
minimum (maximum) is that the quadratic form Q defined by
Q =
n
∑
i = m + 1
n
∑
j = m + 1
(
∂2f
∂xi ∂xj
)
g
dxi dxj (2.30)
is positive (negative) for all nonvanishing variations dxi . As in Theorem 2.4, the matrix











(
∂2f
∂x2m+1
)
g
(
∂2f
∂xm+1 ∂xm+2
)
g
· · ·
(
∂2f
∂xm+1 ∂xn
)
g
...
(
∂2f
∂xn ∂xm+1
)
g
(
∂2f
∂xn ∂xm+2
)
g
· · ·
(
∂2f
∂x2n
)
g











has to be positive (negative) definite to have Q positive (negative) for all choices of
dxi . It is evident that computation of the constrained derivatives (∂
2f/∂xi ∂xj )g is a
2.4 Multivariable Optimization with Equality Constraints 85
difficult task and may be prohibitive for problems with more than three constraints.
Thus the method of constrained variation, although it appears to be simple in theory, is
very difficult to apply since the necessary conditions themselves involve evaluation of
determinants of order m + 1. This is the reason that the method of Lagrange multipliers,
discussed in the following section, is more commonly used to solve a multivariable
optimization problem with equality constraints.
2.4.3 Solution by the Method of Lagrange Multipliers
The basic features of the Lagrange multiplier method is given initially for a simple
problem of two variables with one constraint. The extension of the method to a general
problem of n variables with m constraints is given later.
Problem with Two Variables and One Constraint. Consider the problem
Minimize f (x1, x2) (2.31)
subject to
g(x1, x2) = 0
For this problem, the necessary condition for the existence of an extreme point at
X = X∗ was found in Section 2.4.2 to be
(
∂f
∂x1
− ∂f/∂x2
∂g/∂x2
∂g
∂x1
)∣
∣
∣
∣
(x∗
1
, x∗
2
)
= 0 (2.32)
By defining a quantity λ, called the Lagrange multiplier , as
λ = −
(
∂f/∂x2
∂g/∂x2
)∣
∣
∣
∣
(x∗
1
, x∗
2
)
(2.33)
Equation (2.32) can be expressed as
(
∂f
∂x1
+ λ ∂g
∂x1
)∣
∣
∣
∣
(x∗1 , x
∗
2 )
= 0 (2.34)
and Eq. (2.33) can be written as
(
∂f
∂x2
+ λ ∂g
∂x2
)∣
∣
∣
∣
(x∗
1
, x∗
2
)
= 0 (2.35)
In addition, the constraint equation has to be satisfied at the extreme point, that is,
g(x1, x2)|(x∗
1
,x∗
2
) = 0 (2.36)
Thus Eqs. (2.34) to (2.36) represent the necessary conditions for the point (x∗1 , x
∗
2 ) to
be an extreme point.
Notice that the partial derivative (∂g/∂x2)|(x∗
1
, x∗
2
) has to be nonzero to be able
to define λ by Eq. (2.33). This is because the variation dx2 was expressed in terms
of dx1 in the derivation of Eq. (2.32) [see Eq. (2.23)]. On the other hand, if we
86 Classical Optimization Techniques
choose to express dx1 in terms of dx2, we would have obtained the requirement that
(∂g/∂x1)|(x∗
1
, x∗
2
) be nonzero to define λ. Thus the derivation of the necessary conditions
by the method of Lagrange multipliers requires that at least one of the partial derivatives
of g(x1, x2) be nonzero at an extreme point.
The necessary conditions given by Eqs. (2.34) to (2.36) are more commonly gen-
erated by constructing a function L, known as the Lagrange function, as
L(x1, x2, λ) = f (x1, x2) + λg(x1, x2) (2.37)
By treating L as a function of the three variables x1, x2, and λ, the necessary conditions
for its extremum are given by
∂L
∂x1
(x1, x2, λ) =
∂f
∂x1
(x1, x2) + λ
∂g
∂x1
(x1, x2) = 0
∂L
∂x2
(x1, x2, λ) =
∂f
∂x2
(x1, x2) + λ
∂g
∂x2
(x1, x2) = 0
∂L
∂λ
(x1, x2, λ) = g(x1, x2) = 0
(2.38)
Equations (2.38) can be seen to be same as Eqs. (2.34) to (2.36). The sufficiency
conditions are given later.
Example 2.9 Find the solution of Example 2.7 using the Lagrange multiplier method:
Minimize f (x, y) = kx−1y−2
subject to
g(x, y) = x2 + y2 − a2 = 0
SOLUTION The Lagrange function is
L(x, y, λ) = f (x, y) + λg(x, y) = kx−1y−2 + λ(x2 + y2 − a2)
The necessary conditions for the minimum of f (x, y) [Eqs. (2.38)] give
∂L
∂x
= −kx−2y−2 + 2xλ = 0 (E1)
∂L
∂y
= −2kx−1y−3 + 2yλ = 0 (E2)
∂L
∂λ
= x2 + y2 − a2 = 0 (E3)
Equations (E1) and (E2) yield
2λ = k
x3y2
= 2k
xy4
from which the relation x∗ = (1/
√
2)y∗ can be obtained. This relation, along with
Eq. (E3), gives the optimum solution as
x∗ = a√
3
and y∗ =
√
2
a
√
3
2.4 Multivariable Optimization with Equality Constraints 87
Necessary Conditions for a General Problem. The equations derived above can be
extended to the case of a general problem with n variables and m equality constraints:
Minimize f (X) (2.39)
subject to
gj (X) = 0, j = 1, 2, . . . , m
The Lagrange function, L, in this case is defined by introducing one Lagrange multiplier
λj for each constraint gj (X) as
L(x1, x2, . . . , xn, λ1, λ2, . . . , λm)
= f (X) + λ1g1(X) + λ2g2(X) + · · · + λmgm(X) (2.40)
By treating L as a function of the n + m unknowns, x1, x2, . . . , xn, λ1, λ2, . . . , λm,
the necessary conditions for the extremum of L, which also correspond to the solution
of the original problem stated in Eq. (2.39), are given by
∂L
∂xi
=
∂f
∂xi
+
m
∑
j=1
λj
∂gj
∂xi
= 0, i = 1, 2, . . . , n (2.41)
∂L
∂λj
= gj (X) = 0, j = 1, 2, . . . , m (2.42)
Equations (2.41) and (2.42) represent n + m equations in terms of the n + m unknowns,
xi and λj . The solution of Eqs. (2.41) and (2.42) gives
X∗ =









x∗1
x∗2
...
x∗n









and λ∗ =









λ∗1
λ∗2
...
λ∗m









The vector X∗ corresponds to the relative constrained minimum of f (X) (sufficient
conditions are to be verified) while the vector λ∗ provides the sensitivity information,
as discussed in the next subsection.
Sufficiency Conditions for a General Problem. A sufficient condition for f (X) to
have a constrained relative minimum at X∗ is given by the following theorem.
Theorem 2.6 Sufficient Condition A sufficient condition for f (X) to have a relative
minimum at X∗ is that the quadratic, Q, defined by
Q =
n
∑
i=1
n
∑
j=1
∂2L
∂xi ∂xj
dxi dxj (2.43)
evaluated at X = X∗ must be positive definite for all values of dX for which the
constraints are satisfied.
88 Classical Optimization Techniques
Proof : The proof is similar to that of Theorem 2.4.
Notes:
1. If
Q =
n
∑
i=1
n
∑
j=1
∂2L
∂xi ∂xj
(X∗, λ∗)dxi dxj
is negative for all choices of the admissible variations dxi , X
∗ will be a con-
strained maximum of f (X).
2. It has been shown by Hancock [2.1] that a necessary condition for the quadratic
form Q, defined by Eq. (2.43), to be positive (negative) definite for all admissi-
ble variations dX is that each root of the polynomial zi , defined by the following
determinantal equation, be positive (negative):
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
L11 − z L12 L13 . . . L1n g11 g21 . . . gm1
L21 L22 − z L23 . . . L2n g12 g22 . . . gm2
...
Ln1 Ln2 Ln3 . . . Lnn − z g1n g2n . . . gmn
g11 g12 g13 . . . g1n 0 0 . . . 0
g21 g22 g23 . . . g2n 0 0 . . . 0
...
gm1 gm2 gm3 . . . gmn 0 0 . . . 0
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
∣
= 0 (2.44)
where
Lij =
∂2L
∂xi ∂xj
(X∗, λ∗) (2.45)
gij =
∂gi
∂xj
(X∗) (2.46)
3. Equation (2.44), on expansion, leads to an (n − m)th-order polynomial in z. If
some of the roots of this polynomial are positive while the others are negative,
the point X∗ is not an extreme point.
The application of the necessary and sufficient conditions in the Lagrange multiplier
method is illustrated with the help of the following example.
Example 2.10 Find the dimensions of a cylindrical tin (with top and bottom) made
up of sheet metal to maximize its volume such that the total surface area is equal to
A0 = 24π .
SOLUTION If x1 and x2 denote the radius of the base and length of the tin, respec-
tively, the problem can be stated as
Maximize f (x1, x2) = πx21x2
2.4 Multivariable Optimization with Equality Constraints 89
subject to
2πx21 + 2πx1x2 = A0 = 24π
The Lagrange function is
L(x1, x2, λ) = πx21x2 + λ(2πx21 + 2πx1x2 − A0)
and the necessary conditions for the maximum of f give
∂L
∂x1
= 2πx1x2 + 4πλx1 + 2πλx2 = 0 (E1)
∂L
∂x2
= πx21 + 2πλx1 = 0 (E2)
∂L
∂λ
= 2πx21 + 2πx1x2 − A0 = 0 (E3)
Equations (E1) and (E2) lead to
λ = − x1x2
2x1 + x2
= −1
2
x1
that is,
x1 = 12x2 (E4)
and Eqs. (E3) and (E4) give the desired solution as
x∗1 =
(
A0
6π
)1/2
, x∗2 =
(
2A0
3π
)1/2
, and λ∗ = −
(
A0
24π
)1/2
This gives the maximum value of f as
f ∗ =
(
A30
54π
)1/2
If A0 = 24π , the optimum solution becomes
x∗1 = 2, x∗2 = 4, λ∗ = −1, and f ∗ = 16π
To see that this solution really corresponds to the maximum of f , we apply the suffi-
ciency condition of Eq. (2.44). In this case
L11 =
∂2L
∂x21
∣
∣
∣
∣
(X∗,λ∗)
= 2πx∗2 + 4πλ∗ = 4π
L12 =
∂2L
∂x1∂x2
∣
∣
∣
∣
(X∗,λ∗)
= L21 = 2πx∗1 + 2πλ∗ = 2π
90 Classical Optimization Techniques
L22 =
∂2L
∂x22
∣
∣
∣
∣
(X∗,λ∗)
= 0
g11 =
∂g1
∂x1
∣
∣
∣
∣
(X∗,λ∗)
= 4πx∗1 + 2πx∗2 = 16π
g12 =
∂g1
∂x2
∣
∣
∣
∣
(X∗,λ∗)
= 2πx∗1 = 4π
Thus Eq. (2.44) becomes
∣
∣
∣
∣
∣
∣
∣
4π − z 2π 16π
2π 0 − z 4π
16π 4π 0
∣
∣
∣
∣
∣
∣
∣
= 0
that is,
272π2z + 192π3 = 0
This gives
z = − 12
17
π
Since the value of z is negative, the point (x∗1 , x
∗
2 ) corresponds to the maximum of f .
Interpretation of the Lagrange Multipliers. To find the physical meaning of the
Lagrange multipliers, consider the following optimization problem involving only a
single equality constraint:
Minimize f (X) (2.47)
subject to
˜
g(X) = b or g(X) = b −
˜
g(X) = 0 (2.48)
where b is a constant. The necessary conditions to be satisfied for the solution of the
problem are
∂f
∂xi
+ λ ∂g
∂xi
= 0, i = 1, 2, . . . , n (2.49)
g = 0 (2.50)
Let the solution of Eqs. (2.49) and (2.50) be given by X∗, λ∗, and f ∗ = f (X∗).
Suppose that we want to find the effect of a small relaxation or tightening of the
constraint on the optimum value of the objective function (i.e., we want to find the
effect of a small change in b on f ∗). For this we differentiate Eq. (2.48) to obtain
db − d
˜
g = 0
2.4 Multivariable Optimization with Equality Constraints 91
or
db = d
˜
g =
n
∑
i=1
∂
˜
g
∂xi
dxi (2.51)
Equation (2.49) can be rewritten as
∂f
∂xi
+ λ
∂g
∂xi
=
∂f
∂xi
− λ
∂
˜
g
∂xi
= 0 (2.52)
or
∂
˜
g
∂xi
=
∂f /∂xi
λ
, i = 1, 2, . . . , n (2.53)
Substituting Eq. (2.53) into Eq. (2.51), we obtain
db =
n
∑
i=1
1
λ
∂f
∂xi
dxi =
df
λ
(2.54)
since
df =
n
∑
i=1
∂f
∂xi
dxi (2.55)
Equation (2.54) gives
λ = df
db
or λ∗ = df
∗
db
(2.56)
or
df ∗ = λ∗db (2.57)
Thus λ∗ denotes the sensitivity (or rate of change) of f with respect to b or the marginal
or incremental change in f ∗ with respect to b at x∗. In other words, λ∗ indicates how
tightly the constraint is binding at the optimum point. Depending on the value of λ∗
(positive, negative, or zero), the following physical meaning can be attributed to λ∗:
1. λ∗ > 0. In this case, a unit decrease in b is positively valued since one gets a
smaller minimum value of the objective function f . In fact, the decrease in f ∗
will be exactly equal to λ∗ since df = λ∗(−1) = −λ∗ < 0. Hence λ∗ may be
interpreted as the marginal gain (further reduction) in f ∗ due to the tightening
of the constraint. On the other hand, if b is increased by 1 unit, f will also
increase to a new optimum level, with the amount of increase in f ∗ being
determined by the magnitude of λ∗ since df = λ∗(+1) > 0. In this case, λ∗
may be thought of as the marginal cost (increase) in f ∗ due to the relaxation
of the constraint.
2. λ∗ < 0. Here a unit increase in b is positively valued. This means that it
decreases the optimum value of f . In this case the marginal gain (reduction)
in f ∗ due to a relaxation of the constraint by 1 unit is determined by the value
of λ∗ as df ∗ = λ∗(+1) < 0. If b is decreased by 1 unit, the marginal cost
(increase) in f ∗ by the tightening of the constraint is df ∗ = λ∗(−1) > 0 since,
in this case, the minimum value of the objective function increases.
92 Classical Optimization Techniques
3. λ∗ = 0. In this case, any incremental change in b has absolutely no effect on the
optimum value of f and hence the constraint will not be binding. This means
that the optimization of f subject to g = 0 leads to the same optimum point
X∗ as with the unconstrained optimization of f .
In economics and operations research, Lagrange multipliers are known as shadow prices
of the constraints since they indicate the changes in optimal value of the objective
function per unit change in the right-hand side of the equality constraints.
Example 2.11 Find the maximum of the function f (X) = 2x1 + x2 + 10 subject to
g(X) = x1 + 2x22 = 3 using the Lagrange multiplier method. Also find the effect of
changing the right-hand side of the constraint on the optimum value of f .
SOLUTION The Lagrange function is given by
L(X, λ) = 2x1 + x2 + 10 + λ(3 − x1 − 2x22) (E1)
The necessary conditions for the solution of the problem are
∂L
∂x1
= 2 − λ = 0
∂L
∂x2
= 1 − 4λx2 = 0
∂L
∂λ
= 3 − x1 − 2x22 = 0
(E2)
The solution of Eqs. (E2) is
X∗ =
{
x∗1
x∗2
}
=
{
2.97
0.13
}
λ∗ = 2.0
(E3)
The application of the sufficiency condition of Eq. (2.44) yields
∣
∣
∣
∣
∣
∣
∣
∣
L11 − z L12 g11
L21 L22 − z g12
g11 g12 0
∣
∣
∣
∣
∣
∣
∣
∣
= 0
∣
∣
∣
∣
∣
∣
∣
∣
−z 0 −1
0 −4λ − z −4x2
−1 −4x2 0
∣
∣
∣
∣
∣
∣
∣
∣
=
∣
∣
∣
∣
∣
∣
∣
∣
−z 0 −1
0 −8 − z −0.52
−1 −0.52 0
∣
∣
∣
∣
∣
∣
∣
∣
= 0
0.2704z + 8 + z = 0
z = −6.2972
Hence X∗ will be a maximum of f with f ∗ = f (X∗) = 16.07.
2.5 Multivariable Optimization with Inequality Constraints 93
One procedure for finding the effect on f ∗ of changes in the value of b (right-hand
side of the constraint) would be to solve the problem all over with the new value of
b. Another procedure would involve the use of the value of λ∗. When the original
constraint is tightened by 1 unit (i.e., db = −1), Eq. (2.57) gives
df ∗ = λ∗db = 2(−1) = −2
Thus the new value of f ∗ is f ∗ + df ∗ = 14.07. On the other hand, if we relax the
original constraint by 2 units (i.e., db = 2), we obtain
df ∗ = λ∗db = 2(+2) = 4
and hence the new value of f ∗ is f ∗ + df ∗ = 20.07.
2.5 MULTIVARIABLE OPTIMIZATION WITH INEQUALITY
CONSTRAINTS
This section is concerned with the solution of the following problem:
Minimize f (X)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m (2.58)
The inequality constraints in Eq. (2.58) can be transformed to equality constraints by
adding nonnegative slack variables, y2j , as
gj (X) + y2j = 0, j = 1, 2, . . . , m (2.59)
where the values of the slack variables are yet unknown. The problem now becomes
Minimize f (X)
subject to
Gj (X, Y) = gj (X) + y2j = 0, j = 1, 2, . . . , m (2.60)
where Y = {y1, y2, . . . , ym}T is the vector of slack variables.
This problem can be solved conveniently by the method of Lagrange multipliers.
For this, we construct the Lagrange function L as
L(X, Y, λ) = f (X) +
m
∑
j=1
λjGj (X, Y) (2.61)
where λ = {λ1, λ2, . . . , λm}T is the vector of Lagrange multipliers. The stationary
points of the Lagrange function can be found by solving the following equations
94 Classical Optimization Techniques
(necessary conditions):
∂L
∂xi
(X, Y, λ) = ∂f
∂xi
(X) +
m
∑
j=1
λj
∂gj
∂xi
(X) = 0, i = 1, 2, . . . , n (2.62)
∂L
∂λj
(X, Y, λ) = Gj (X, Y) = gj (X) + y2j = 0, j = 1, 2, . . . , m (2.63)
∂L
∂yj
(X, Y, λ) = 2λjyj = 0, j = 1, 2, . . . , m (2.64)
It can be seen that Eqs. (2.62) to (2.64) represent (n + 2m) equations in the (n + 2m)
unknowns, X, λ, and Y. The solution of Eqs. (2.62) to (2.64) thus gives the optimum
solution vector, X∗; the Lagrange multiplier vector, λ∗; and the slack variable
vector, Y∗.
Equations (2.63) ensure that the constraints gj (X) ≤ 0, j = 1, 2, . . . ,m, are satis-
fied, while Eqs. (2.64) imply that either λj = 0 or yj = 0. If λj = 0, it means that the
j th constraint is inactive† and hence can be ignored. On the other hand, if yj = 0, it
means that the constraint is active (gj = 0) at the optimum point. Consider the division
of the constraints into two subsets, J1 and J2, where J1 + J2 represent the total set of
constraints. Let the set J1 indicate the indices of those constraints that are active at the
optimum point and J2 include the indices of all the inactive constraints.
Thus for j ∈ J1,‡ yj = 0 (constraints are active), for j ∈ J2, λj = 0 (constraints
are inactive), and Eqs. (2.62) can be simplified as
∂f
∂xi
+
∑
j∈J1
λj
∂gj
∂xi
= 0, i = 1, 2, . . . , n (2.65)
Similarly, Eqs. (2.63) can be written as
gj (X) = 0, j ∈ J1 (2.66)
gj (X) + y2j = 0, j ∈ J2 (2.67)
Equations (2.65) to (2.67) represent n + p + (m − p) = n + m equations in the n + m
unknowns xi(i = 1, 2, . . . , n), λj (j ∈ J1), and yj (j ∈ J2), where p denotes the number
of active constraints.
Assuming that the first p constraints are active, Eqs. (2.65) can be expressed as
−
∂f
∂xi
= λ1
∂g1
∂xi
+ λ2
∂g2
∂xi
+ . . . + λp
∂gp
∂xi
, i = 1, 2, . . . , n (2.68)
These equations can be written collectively as
−∇f = λ1∇g1 + λ2∇g2 + · · · + λp ∇gp (2.69)
†Those constraints that are satisfied with an equality sign, gj = 0, at the optimum point are called the
active constraints , while those that are satisfied with a strict inequality sign, gj < 0, are termed inactive
constraints .
‡The symbol ∈ is used to denote the meaning “belongs to” or “element of ”.
2.5 Multivariable Optimization with Inequality Constraints 95
where ∇f and ∇gj are the gradients of the objective function and the j th constraint,
respectively:
∇f =









∂f /∂x1
∂f /∂x2
...
∂f /∂xn









and ∇gj =









∂gj/∂x1
∂gj/∂x2
...
∂gj/∂xn









Equation (2.69) indicates that the negative of the gradient of the objective function can
be expressed as a linear combination of the gradients of the active constraints at the
optimum point.
Further, we can show that in the case of a minimization problem, the λj values
(j ∈ J1) have to be positive. For simplicity of illustration, suppose that only two con-
straints are active (p = 2) at the optimum point. Then Eq. (2.69) reduces to
−∇f = λ1∇g1 + λ2∇g2 (2.70)
Let S be a feasible direction† at the optimum point. By premultiplying both sides of
Eq. (2.70) by ST , we obtain
−ST ∇f = λ1ST ∇g1 + λ2ST ∇g2 (2.71)
where the superscript T denotes the transpose. Since S is a feasible direction, it should
satisfy the relations
ST∇g1 < 0
ST∇g2 < 0 (2.72)
Thus if λ1 > 0 and λ2 > 0, the quantity S
T ∇f can be seen always to be positive. As
∇f indicates the gradient direction, along which the value of the function increases at
the maximum rate,‡ ST ∇f represents the component of the increment of f along the
direction S. If ST ∇f > 0, the function value increases as we move along the direction S.
Hence if λ1 and λ2 are positive, we will not be able to find any direction in the feasible
domain along which the function value can be decreased further. Since the point at
which Eq. (2.72) is valid is assumed to be optimum, λ1 and λ2 have to be positive.
This reasoning can be extended to cases where there are more than two constraints
active. By proceeding in a similar manner, one can show that the λj values have to be
negative for a maximization problem.
†A vector S is called a feasible direction from a point X if at least a small step can be taken along S
that does not immediately leave the feasible region. Thus for problems with sufficiently smooth constraint
surfaces, vector S satisfying the relation
ST ∇gj < 0
can be called a feasible direction. On the other hand, if the constraint is either linear or concave, as shown
in Fig. 2.8b and c, any vector satisfying the relation
ST ∇gj ≤ 0
can be called a feasible direction. The geometric interpretation of a feasible direction is that the vector
S makes an obtuse angle with all the constraint normals, except that for the linear or outward-curving
(concave) constraints, the angle may go to as low as 90
◦
.
‡See Section 6.10.2 for a proof of this statement.
96 Classical Optimization Techniques
Figure 2.8 Feasible direction S.
Example 2.12 Consider the following optimization problem:
Minimizef (x1, x2) = x21 + x22
subject to
x1 + 2x2 ≤ 15
1 ≤ xi ≤ 10; i = 1, 2
Derive the conditions to be satisfied at the point X1 = {1, 7}T by the search direction
S = {s1, s2}T if it is a (a) usable direction, and (b) feasible direction.
SOLUTION The objective function and the constraints can be stated as
f (x1, x2) = x21 + x22
g1(X) = x1 + 2x2 ≤ 15
2.5 Multivariable Optimization with Inequality Constraints 97
g2(X) = 1 − x1 ≤ 0
g3(X) = 1 − x2 ≤ 0
g4(X) = x1 − 10 ≤ 0
g5(X) = x2 − 10 ≤ 0
At the given point X1 = {1, 7}T, all the constraints can be seen to be satisfied with g1
and g2 being active. The gradients of the objective and active constraint functions at
point X1 = {1, 7}T are given by
∇f =









∂f
∂x1
∂f
∂x2









X1
=



2x1
2x2



X1
=
{
2
14
}
∇g1 =









∂g1
∂x1
∂g1
∂x2









X1
=
{
1
2
}
∇g2 =









∂g2
∂x1
∂g2
∂x2









X1
=
{
−1
0
}
For the search direction S = {s1, s2}T, the usability and feasibility conditions can be
expressed as
(a) Usability condition:
ST∇f ≤ 0 or (s1 s2)
{
2
14
}
≤ 0 or 2s1 + 14s2 ≤ 0 (E1)
(b) Feasibility conditions:
ST∇g1 ≤ 0 or (s1 s2)
{
1
2
}
≤ 0 or s1 + 2s2 ≤ 0 (E2)
ST∇g2 ≤ 0 or (s1 s2)
{
−1
0
}
≤ 0 or − s1 ≤ 0 (E3)
Note: Any two numbers for s1 and s2 that satisfy the inequality (E1) will constitute
a usable direction S. For example, s1 = 1 and s2 = −1 gives the usable direction
S = {1, −1}T. This direction can also be seen to be a feasible direction because it
satisfies the inequalities (E2) and (E3).
98 Classical Optimization Techniques
2.5.1 Kuhn–Tucker Conditions
As shown above, the conditions to be satisfied at a constrained minimum point, X∗, of
the problem stated in Eq. (2.58) can be expressed as
∂f
∂xi
+
∑
j∈J1
λj
∂gj
∂xi
= 0, i = 1, 2, . . . , n (2.73)
λj > 0, j ∈ J1 (2.74)
These are called Kuhn–Tucker conditions after the mathematicians who derived them
as the necessary conditions to be satisfied at a relative minimum of f (X) [2.8]. These
conditions are, in general, not sufficient to ensure a relative minimum. However, there is
a class of problems, called convex programming problems ,† for which the Kuhn–Tucker
conditions are necessary and sufficient for a global minimum.
If the set of active constraints is not known, the Kuhn–Tucker conditions can be
stated as follows:
∂f
∂xi
+
m
∑
j=1
λj
∂gj
∂xi
= 0, i = 1, 2, . . . , n
λjgj = 0,‡ j = 1, 2, . . . ,m
gj ≤ 0, j = 1, 2, . . . , m
λj ≥ 0, j = 1, 2, . . . , m
(2.75)
Note that if the problem is one of maximization or if the constraints are of the type
gj ≥ 0, the λj have to be nonpositive in Eqs. (2.75). On the other hand, if the problem is
one of maximization with constraints in the form gj ≥ 0, the λj have to be nonnegative
in Eqs. (2.75).
2.5.2 Constraint Qualification
When the optimization problem is stated as
Minimize f (X)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m
hk(X) = 0 k = 1, 2, . . . , p
(2.76)
the Kuhn–Tucker conditions become
∇f +
m
∑
j=1
λj∇gj −
p
∑
k=1
βk∇hk = 0
λjgj = 0, j = 1, 2, . . . , m
†See Sections 2.6 and 7.14 for a detailed discussion of convex programming problems.
‡This condition is the same as Eq. (2.64).
2.5 Multivariable Optimization with Inequality Constraints 99
gj ≤ 0, j = 1, 2, . . . , m
hk = 0, k = 1, 2, . . . , p
λj ≥ 0, j = 1, 2, . . . , m
(2.77)
where λj and βk denote the Lagrange multipliers associated with the constraints
gj ≤ 0 and hk = 0, respectively. Although we found qualitatively that the
Kuhn–Tucker conditions represent the necessary conditions of optimality, the
following theorem gives the precise conditions of optimality.
Theorem 2.7 Let X∗ be a feasible solution to the problem of Eqs. (2.76). If ∇gj (X∗),
j ∈ J1 and ∇hk(X∗), k = 1, 2, . . . , p, are linearly independent, there exist λ∗ and β∗
such that (X∗, λ∗, β∗) satisfy Eqs. (2.77).
Proof : See Ref. [2.11].
The requirement that ∇gj (X∗), j ∈ J1 and ∇hk(X∗), k = 1, 2, . . . , p, be linearly
independent is called the constraint qualification . If the constraint qualification is vio-
lated at the optimum point, Eqs. (2.77) may or may not have a solution. It is difficult
to verify the constraint qualification without knowing X∗ beforehand. However, the
constraint qualification is always satisfied for problems having any of the following
characteristics:
1. All the inequality and equality constraint functions are linear.
2. All the inequality constraint functions are convex, all the equality constraint
functions are linear, and at least one feasible vector X̃ exists that lies strictly
inside the feasible region, so that
gj (X̃) < 0, j = 1, 2, . . . , m and hk(X̃) = 0, k = 1, 2, . . . , p
Example 2.13 Consider the following problem:
Minixize f (x1, x2) = (x1 − 1)2 + x22 (E1)
subject to
g1(x1, x2) = x31 − 2x2 ≤ 0 (E2)
g2(x1, x2) = x31 + 2x2 ≤ 0 (E3)
Determine whether the constraint qualification and the Kuhn–Tucker conditions are
satisfied at the optimum point.
SOLUTION The feasible region and the contours of the objective function are shown
in Fig. 2.9. It can be seen that the optimum solution is (0, 0). Since g1 and g2 are both
active at the optimum point (0, 0), their gradients can be computed as
∇g1(X∗) =
{
3x21
−2
}
(0, 0)
=
{
0
−2
}
and ∇g2(X∗) =
{
3x21
2
}
(0, 0)
=
{
0
2
}
100 Classical Optimization Techniques
Figure 2.9 Feasible region and contours of the objective function.
It is clear that ∇g1(X∗) and ∇g2(X∗) are not linearly independent. Hence the constraint
qualification is not satisfied at the optimum point. Noting that
∇f (X∗) =
{
2(x1 − 1)
2x2
}
(0, 0)
=
{
−2
0
}
the Kuhn–Tucker conditions can be written, using Eqs. (2.73) and (2.74), as
−2 + λ1(0) + λ2(0) = 0 (E4)
0 + λ1(−2) + λ2(2) = 0 (E5)
λ1 > 0 (E6)
λ2 > 0 (E7)
Since Eq. (E4) is not satisfied and Eq. (E5) can be satisfied for negative values of
λ1 = λ2 also, the Kuhn–Tucker conditions are not satisfied at the optimum point.
2.5 Multivariable Optimization with Inequality Constraints 101
Example 2.14 A manufacturing firm producing small refrigerators has entered into
a contract to supply 50 refrigerators at the end of the first month, 50 at the end of the
second month, and 50 at the end of the third. The cost of producing x refrigerators
in any month is given by $(x2 + 1000). The firm can produce more refrigerators in
any month and carry them to a subsequent month. However, it costs $20 per unit for
any refrigerator carried over from one month to the next. Assuming that there is no
initial inventory, determine the number of refrigerators to be produced in each month
to minimize the total cost.
SOLUTION Let x1, x2, and x3 represent the number of refrigerators produced in the
first, second, and third month, respectively. The total cost to be minimized is given by
total cost = production cost + holding cost
or
f (x1, x2, x3) = (x21 + 1000) + (x22 + 1000) + (x23 + 1000) + 20(x1 − 50)
+ 20(x1 + x2 − 100)
= x21 + x22 + x23 + 40x1 + 20x2
The constraints can be stated as
g1(x1, x2, x3) = x1 − 50 ≥ 0
g2(x1, x2, x3) = x1 + x2 − 100 ≥ 0
g3(x1, x2, x3) = x1 + x2 + x3 − 150 ≥ 0
The Kuhn–Tucker conditions are given by
∂f
∂xi
+ λ1
∂g1
∂xi
+ λ2
∂g2
∂xi
+ λ3
∂g3
∂xi
= 0, i = 1, 2, 3
that is,
2x1 + 40 + λ1 + λ2 + λ3 = 0 (E1)
2x2 + 20 + λ2 + λ3 = 0 (E2)
2x3 + λ3 = 0 (E3)
λjgj = 0, j = 1, 2, 3
that is,
λ1(x1 − 50) = 0 (E4)
λ2(x1 + x2 − 100) = 0 (E5)
λ3(x1 + x2 + x3 − 150) = 0 (E6)
gj ≥ 0, j = 1, 2, 3
102 Classical Optimization Techniques
that is,
x1 − 50 ≥ 0 (E7)
x1 + x2 − 100 ≥ 0 (E8)
x1 + x2 + x3 − 150 ≥ 0 (E9)
λj ≤ 0, j = 1, 2, 3
that is,
λ1 ≤ 0 (E10)
λ2 ≤ 0 (E11)
λ3 ≤ 0 (E12)
The solution of Eqs. (E1) to (E12) can be found in several ways. We proceed to solve
these equations by first nothing that either λ1 = 0 or x1 = 50 according to Eq. (E4).
Using this information, we investigate the following cases to identify the optimum
solution of the problem.
Case 1: λ1 = 0.
Equations (E1) to (E3) give
x3 = −
λ3
2
x2 = −10 −
λ2
2
−
λ3
2
(E13)
x1 = −20 −
λ2
2
− λ3
2
Substituting Eqs. (E13) in Eqs. (E5) and (E6), we obtain
λ2(−130 − λ2 − λ3) = 0
λ3(−180 − λ2 − 32λ3) = 0 (E14)
The four possible solutions of Eqs. (E14) are
1. λ2 = 0, −180 − λ2 −
3
2
λ3 = 0. These equations, along with Eqs. (E13), yield
the solution
λ2 = 0, λ3 = −120, x1 = 40, x2 = 50, x3 = 60
This solution satisfies Eqs. (E10) to (E12) but violates Eqs. (E7) and (E8) and
hence cannot be optimum.
2. λ3 = 0, −130 − λ2 − λ3 = 0. The solution of these equations leads to
λ2 = −130, λ3 = 0, x1 = 45, x2 = 55, x3 = 0
2.5 Multivariable Optimization with Inequality Constraints 103
This solution can be seen to satisfy Eqs. (E10) to (E12) but violate Eqs. (E7)
and (E9).
3. λ2 = 0, λ3 = 0. Equations (E13) give
x1 = −20, x2 = −10, x3 = 0
This solution satisfies Eqs. (E10) to (E12) but violates the constraints, Eqs. (E7)
to (E9).
4. −130 − λ2 − λ3 = 0, −180 − λ2 − 32λ3 = 0. The solution of these equations
and Eqs. (E13) yields
λ2 = −30, λ3 = −100, x1 = 45, x2 = 55, x3 = 50
This solution satisfies Eqs. (E10) to (E12) but violates the constraint, Eq. (E7).
Case 2: x1 = 50.
In this case, Eqs. (E1) to (E3) give
λ3 = −2x3
λ2 = −20 − 2x2 − λ3 = −20 − 2x2 + 2x3
λ1 = −40 − 2x1 − λ2 − λ3 = −120 + 2x2
(E15)
Substitution of Eqs. (E15) in Eqs. (E5) and (E6) leads to
(−20 − 2x2 + 2x3)(x1 + x2 − 100) = 0
(−2x3)(x1 + x2 + x3 − 150) = 0 (E16)
Once again, it can be seen that there are four possible solutions to Eqs. (E16), as
indicated below:
1. −20 − 2x2 + 2x3 = 0, x1 + x2 + x3 − 150 = 0: The solution of these
equations yields
x1 = 50, x2 = 45, x3 = 55
This solution can be seen to violate Eq. (E8).
2. −20 − 2x2 + 2x3 = 0, −2x3 = 0: These equations lead to the solution
x1 = 50, x2 = −10, x3 = 0
This solution can be seen to violate Eqs. (E8) and (E9).
3. x1 + x2 − 100 = 0, −2x3 = 0: These equations give
x1 = 50, x2 = 50, x3 = 0
This solution violates the constraint Eq. (E9).
104 Classical Optimization Techniques
4. x1 + x2 − 100 = 0, x1 + x2 + x3 − 150 = 0: The solution of these equations
yields
x1 = 50, x2 = 50, x3 = 50
This solution can be seen to satisfy all the constraint Eqs. (E7) to (E9). The
values of λ1, λ2, and λ3 corresponding to this solution can be obtained from
Eqs. (E15) as
λ1 = −20, λ2 = −20, λ3 = −100
Since these values of λi satisfy the requirements [Eqs. (E10) to (E12)], this
solution can be identified as the optimum solution. Thus
x∗1 = 50, x∗2 = 50, x∗3 = 50
2.6 CONVEX PROGRAMMING PROBLEM
The optimization problem stated in Eq. (2.58) is called a convex programming problem
if the objective function f (X) and the constraint functions gj (X) are convex. The
definition and properties of a convex function are given in Appendix A. Suppose that
f (X) and gj (X), j = 1, 2, . . . , m, are convex functions. The Lagrange function of
Eq. (2.61) can be written as
L(X, Y, λ) = f (X) +
m
∑
j=1
λj [gj (X) + y2j ] (2.78)
If λj ≥ 0, then λjgj (X) is convex, and since λjyj = 0 from Eq. (2.64), L(X, Y, λ)
will be a convex function. As shown earlier, a necessary condition for f (X) to be a
relative minimum at X∗ is that L(X, Y, λ) have a stationary point at X∗. However, if
L(X, Y, λ) is a convex function, its derivative vanishes only at one point, which must
be an absolute minimum of the function f (X). Thus the Kuhn–Tucker conditions are
both necessary and sufficient for an absolute minimum of f (X) at X∗.
Notes:
1. If the given optimization problem is known to be a convex programming prob-
lem, there will be no relative minima or saddle points, and hence the extreme
point found by applying the Kuhn–Tucker conditions is guaranteed to be an
absolute minimum of f (X). However, it is often very difficult to ascertain
whether the objective and constraint functions involved in a practical engineer-
ing problem are convex.
2. The derivation of the Kuhn–Tucker conditions was based on the development
given for equality constraints in Section 2.4. One of the requirements for these
conditions was that at least one of the Jacobians composed of the m constraints
and m of the n + m variables (x1, x2, . . . , xn; y1, y2, . . . , ym) be nonzero. This
requirement is implied in the derivation of the Kuhn–Tucker conditions.
Review Questions 105
REFERENCES AND BIBLIOGRAPHY
2.1 H. Hancock, Theory of Maxima and Minima , Dover, New York, 1960.
2.2 M. E. Levenson, Maxima and Minima , Macmillan, New York, 1967.
2.3 G. B. Thomas, Jr., Calculus and Analytic Geometry , Addison-Wesley, Reading, MA,
1967.
2.4 A. E. Richmond, Calculus for Electronics , McGraw-Hill, New York, 1972.
2.5 B. Kolman and W. F. Trench, Elementary Multivariable Calculus , Academic Press, New
York, 1971.
2.6 G. S. G. Beveridge and R. S. Schechter, Optimization: Theory and Practice, McGraw-Hill,
New York, 1970.
2.7 R. Gue and M. E. Thomas, Mathematical Methods of Operations Research , Macmillan,
New York, 1968.
2.8 H. W. Kuhn and A. Tucker, Nonlinear Programming, in Proceedings of the 2nd Berkeley
Symposium on Mathematical Statistics and Probability , University of California Press,
Berkeley, 1951.
2.9 F. Ayres, Jr., Theory and Problems of Matrices , Schaum’s Outline Series, Schaum, New
York, 1962.
2.10 M. J. Panik, Classical Optimization: Foundations and Extensions , North-Holland, Ams-
terdam, 1976.
2.11 M. S. Bazaraa and C. M. Shetty, Nonlinear Programming: Theory and Algorithms , Wiley,
New York, 1979.
2.12 D. M. Simmons, Nonlinear Programming for Operations Research , Prentice Hall, Engle-
wood Cliffs, NJ, 1975.
2.13 J. R. Howell and R. O. Buckius, Fundamentals of Engineering Thermodynamics , 2nd ed.,
McGraw-Hill, New York, 1992.
REVIEW QUESTIONS
2.1 State the necessary and sufficient conditions for the minimum of a function f (x).
2.2 Under what circumstances can the condition df (x)/dx = 0 not be used to find the mini-
mum of the function f (x)?
2.3 Define the rth differential, drf (X), of a multivariable function f (X).
2.4 Write the Taylor’s series expansion of a function f (X).
2.5 State the necessary and sufficient conditions for the maximum of a multivariable function
f (X).
2.6 What is a quadratic form?
2.7 How do you test the positive, negative, or indefiniteness of a square matrix [A]?
2.8 Define a saddle point and indicate its significance.
2.9 State the various methods available for solving a multivariable optimization problem with
equality constraints.
2.10 State the principle behind the method of constrained variation.
2.11 What is the Lagrange multiplier method?
106 Classical Optimization Techniques
2.12 What is the significance of Lagrange multipliers?
2.13 Convert an inequality constrained problem into an equivalent unconstrained problem.
2.14 State the Kuhn–Tucker conditions.
2.15 What is an active constraint?
2.16 Define a usable feasible direction.
2.17 What is a convex programming problem? What is its significance?
2.18 Answer whether each of the following quadratic forms is positive definite, negative defi-
nite, or neither:
(a) f = x21 − x22
(b) f = 4x1x2
(c) f = x21 + 2x22
(d) f = −x21 + 4x1x2 + 4x22
(e) f = −x21 + 4x1x2 − 9x22 + 2x1x3 + 8x2x3 − 4x23
2.19 State whether each of the following functions is convex, concave, or neither:
(a) f = −2x2 + 8x + 4
(b) f = x2 + 10x + 1
(c) f = x21 − x22
(d) f = −x21 + 4x1x2
(e) f = e−x , x > 0
(f) f =
√
x, x > 0
(g) f = x1x2
(h) f = (x1 − 1)2 + 10(x2 − 2)2
2.20 Match the following equations and their characteristics:
(a) f = 4x1 − 3x2 + 2 Relative maximum at (1, 2)
(b) f = (2x1 − 2)2 + (x2 − 2)2 Saddle point at origin
(c) f = −(x1 − 1)2 − (x2 − 2)2 No minimum
(d) f = x1x2 Inflection point at origin
(e) f = x3 Relative minimum at (1, 2)
PROBLEMS
2.1 A dc generator has an internal resistance R ohms and develops an open-circuit voltage of
V volts (Fig. 2.10). Find the value of the load resistance r for which the power delivered
by the generator will be a maximum.
2.2 Find the maxima and minima, if any, of the function
f (x) = x
4
(x − 1)(x − 3)3
Problems 107
Figure 2.10 Electric generator with load.
2.3 Find the maxima and minima, if any, of the function
f (x) = 4x3 − 18x2 + 27x − 7
2.4 The efficiency of a screw jack is given by
η = tan α
tan(α + φ)
where α is the lead angle and φ is a constant. Prove that the efficiency of the screw jack
will be maximum when α = 45◦ − φ/2 with ηmax = (1 − sin φ)/(1 + sin φ).
2.5 Find the minimum of the function
f (x) = 10x6 − 48x5 + 15x4 + 200x3 − 120x2 − 480x + 100
2.6 Find the angular orientation of a cannon to maximize the range of the projectile.
2.7 In a submarine telegraph cable the speed of signaling varies as x2 log(1/x), where x is
the ratio of the radius of the core to that of the covering. Show that the greatest speed is
attained when this ratio is 1 :
√
e.
2.8 The horsepower generated by a Pelton wheel is proportional to u(V − u), where u is the
velocity of the wheel, which is variable, and V is the velocity of the jet, which is fixed.
Show that the efficiency of the Pelton wheel will be maximum when u = V /2.
2.9 A pipe of length l and diameter D has at one end a nozzle of diameter d through which
water is discharged from a reservoir. The level of water in the reservoir is maintained at
a constant value h above the center of nozzle. Find the diameter of the nozzle so that the
kinetic energy of the jet is a maximum. The kinetic energy of the jet can be expressed
as
1
4
πρd2
(
2gD5h
D5 + 4f ld4
)3/2
where ρ is the density of water, f the friction coefficient and g the gravitational constant.
2.10 An electric light is placed directly over the center of a circular plot of lawn 100 m in
diameter. Assuming that the intensity of light varies directly as the sine of the angle at
which it strikes an illuminated surface, and inversely as the square of its distance from
the surface, how high should the light be hung in order that the intensity may be as great
as possible at the circumference of the plot?
108 Classical Optimization Techniques
2.11 If a crank is at an angle θ from dead center with θ = ωt , where ω is the angular velocity
and t is time, the distance of the piston from the end of its stroke (x) is given by
x = r(1 − cos θ) +
r2
4l
(1 − cos 2θ)
where r is the length of the crank and l is the length of the connecting rod. For r = 1
and l = 5, find (a) the angular position of the crank at which the piston moves with
maximum velocity, and (b) the distance of the piston from the end of its stroke at that
instant.
Determine whether each of the matrices in Problems 2.12–2.14 is positive definite, negative
definite, or indefinite by finding its eigenvalues.
2.12 [A] =


3 1 −1
1 3 −1
−1 −1 5


2.13 [B] =


4 2 −4
2 4 −2
−4 −2 4


2.14 [C] =


−1 −1 −1
−1 −2 −2
−1 −2 −3


Determine whether each of the matrices in Problems 2.15–2.17 is positive definite, negative
definite, or indefinite by evaluating the signs of its submatrices.
2.15 [A] =


3 1 −1
1 3 −1
−1 −1 5


2.16 [B] =


4 2 −4
2 4 −2
−4 −2 4


2.17 [C] =


−1 −1 −1
−1 −2 −2
−1 −2 −3


2.18 Express the function
f (x1, x2, x3) = −x21 − x22 + 2x1x2 − x23 + 6x1x3 + 4x1 − 5x3 + 2
in matrix form as
f (X) = 1
2
XT[A] X + BT X + C
and determine whether the matrix [A] is positive definite, negative definite, or indefinite.
2.19 Determine whether the following matrix is positive or negative definite:
[A] =


4 −3 0
−3 0 4
0 4 2


Problems 109
2.20 Determine whether the following matrix is positive definite:
[A] =


−14 3 0
3 −1 4
0 4 2


2.21 The potential energy of the two-bar truss shown in Fig. 2.11 is given by
f (x1, x2) =
EA
s
(
1
2s
)2
x21 +
EA
s
(
h
s
)2
x22 − Px1 cos θ − Px2 sin θ
where E is Young’s modulus, A the cross-sectional area of each member, l the span of
the truss, s the length of each member, h the height of the truss, P the applied load,
θ the angle at which the load is applied, and x1 and x2 are, respectively, the horizontal
and vertical displacements of the free node. Find the values of x1 and x2 that minimize
the potential energy when E = 207 × 109 Pa, A = 10−5 m2, l = 1.5 m, h = 4.0 m,
P = 104 N, and θ = 30◦.
2.22 The profit per acre of a farm is given by
20x1 + 26x2 + 4x1x2 − 4x21 − 3x22
where x1 and x2 denote, respectively, the labor cost and the fertilizer cost. Find the values
of x1 and x2 to maximize the profit.
2.23 The temperatures measured at various points inside a heated wall are as follows:
Distance from the heated surface as
a percentage of wall thickness, d 0 25 50 75 100
Temperature, t (
◦
C) 380 200 100 20 0
It is decided to approximate this table by a linear equation (graph) of the form t = a + bd
, where a and b are constants. Find the values of the constants a and b that minimize the
sum of the squares of all differences between the graph values and the tabulated values.
Figure 2.11 Two-bar truss.
110 Classical Optimization Techniques
2.24 Find the second-order Taylor’s series approximation of the function
f (x1, x2) = (x1 − 1)2ex2 + x1
at the points (a) (0,0) and (b) (1,1).
2.25 Find the third-order Taylor’s series approximation of the function
f (x1, x2, x3) = x22x3 + x1ex3
at point (1, 0, −2).
2.26 The volume of sales (f ) of a product is found to be a function of the number of newspaper
advertisements (x) and the number of minutes of television time (y) as
f = 12xy − x2 − 3y2
Each newspaper advertisement or each minute on television costs $1000. How should
the firm allocate $48,000 between the two advertising media for maximizing its sales?
2.27 Find the value of x∗ at which the following function attains its maximum:
f (x) =
1
10
√
2π
e−(1/2)[(x−100)/10]
2
2.28 It is possible to establish the nature of stationary points of an objective function based
on its quadratic approximation. For this, consider the quadratic approximation of a
two-variable function as
f (X) ≈ a + bT X + 1
2
XT[c] X
where
X =
{
x1
x2
}
, b =
{
b1
b2
}
, and [c] =
[
c11 c12
c12 c22
]
If the eigenvalues of the Hessian matrix, [c], are denoted as β1 and β2, identify the nature
of the contours of the objective function and the type of stationary point in each of the
following situations.
(a) β1 = β2; both positive
(b) β1 > β2; both positive
(c) |β1| = |β2|; β1 and β2 have opposite signs
(d) β1 > 0, β2 = 0
Plot the contours of each of the following functions and identify the nature of its stationary
point.
2.29 f = 2 − x2 − y2 + 4xy
2.30 f = 2 + x2 − y2
2.31 f = xy
2.32 f = x3 − 3xy2
Problems 111
2.33 Find the admissible and constrained variations at the point X = {0, 4}T for the following
problem:
Minimize f = x21 + (x2 − 1)2
subject to
−2x21 + x2 = 4
2.34 Find the diameter of an open cylindrical can that will have the maximum volume for a
given surface area, S.
2.35 A rectangular beam is to be cut from a circular log of radius r . Find the cross-sectional
dimensions of the beam to (a) maximize the cross-sectional area of the beam, and (b)
maximize the perimeter of the beam section.
2.36 Find the dimensions of a straight beam of circular cross section that can be cut from a
conical log of height h and base radius r to maximize the volume of the beam.
2.37 The deflection of a rectangular beam is inversely proportional to the width and the cube
of depth. Find the cross-sectional dimensions of a beam, which corresponds to minimum
deflection, that can be cut from a cylindrical log of radius r .
2.38 A rectangular box of height a and width b is placed adjacent to a wall (Fig. 2.12). Find
the length of the shortest ladder that can be made to lean against the wall.
2.39 Show that the right circular cylinder of given surface (including the ends) and maximum
volume is such that its height is equal to the diameter of the base.
2.40 Find the dimensions of a closed cylindrical soft drink can that can hold soft drink of
volume V for which the surface area (including the top and bottom) is a minimum.
2.41 An open rectangular box is to be manufactured from a given amount of sheet metal
(area S). Find the dimensions of the box to maximize the volume.
Figure 2.12 Ladder against a wall.
112 Classical Optimization Techniques
2.42 Find the dimensions of an open rectangular box of volume V for which the amount of
material required for manufacture (surface area) is a minimum.
2.43 A rectangular sheet of metal with sides a and b has four equal square portions (of side d)
removed at the corners, and the sides are then turned up so as to form an open rectangular
box. Find the depth of the box that maximizes the volume.
2.44 Show that the cone of the greatest volume that can be inscribed in a given sphere has
an altitude equal to two-thirds of the diameter of the sphere. Also prove that the curved
surface of the cone is a maximum for the same value of the altitude.
2.45 Prove Theorem 2.6.
2.46 A log of length l is in the form of a frustum of a cone whose ends have radii a and
b(a > b). It is required to cut from it a beam of uniform square section. Prove that the
beam of greatest volume that can be cut has a length of al /[3(a − b)].
2.47 It has been decided to leave a margin of 30 mm at the top and 20 mm each at the left
side, right side, and the bottom on the printed page of a book. If the area of the page is
specified as 5 × 104 mm2, determine the dimensions of a page that provide the largest
printed area.
2.48 Minimize f = 9 − 8x1 − 6x2 − 4x3 + 2x21
+ 2x22 + x23 + 2x1x2 + 2x1x3
subject to
x1 + x2 + 2x3 = 3
by (a) direct substitution, (b) constrained variation, and (c) Lagrange multiplier method.
2.49 Minimize f (X) = 12 (x
2
1 + x22 + x23 )
subject to
g1(X) = x1 − x2 = 0
g2(X) = x1 + x2 + x3 − 1 = 0
by (a) direct substitution, (b) constrained variation, and (c) Lagrange multiplier method.
2.50 Find the values of x, y, and z that maximize the function
f (x, y, z) =
6xyz
x + 2y + 2z
when x, y, and z are restricted by the relation xyz = 16.
2.51 A tent on a square base of side 2a consists of four vertical sides of height b surmounted
by a regular pyramid of height h. If the volume enclosed by the tent is V , show that the
area of canvas in the tent can be expressed as
2V
a
−
8ah
3
+ 4a
√
h2 + a2
Also show that the least area of the canvas corresponding to a given volume V , if a and
h can both vary, is given by
a =
√
5h
2
and h = 2b
Problems 113
2.52 A department store plans to construct a one-story building with a rectangular planform.
The building is required to have a floor area of 22,500 ft2 and a height of 18 ft. It is
proposed to use brick walls on three sides and a glass wall on the fourth side. Find the
dimensions of the building to minimize the cost of construction of the walls and the roof
assuming that the glass wall costs twice as much as that of the brick wall and the roof
costs three times as much as that of the brick wall per unit area.
2.53 Find the dimensions of the rectangular building described in Problem 2.52 to minimize
the heat loss, assuming that the relative heat losses per unit surface area for the roof,
brick wall, glass wall, and floor are in the proportion 4:2:5:1.
2.54 A funnel, in the form of a right circular cone, is to be constructed from a sheet metal.
Find the dimensions of the funnel for minimum lateral surface area when the volume of
the funnel is specified as 200 in3.
2.55 Find the effect on f ∗ when the value of A0 is changed to (a) 25π and (b) 22π in
Example 2.10 using the property of the Lagrange multiplier.
2.56 (a) Find the dimensions of a rectangular box of volume V = 1000 in3 for which the
total length of the 12 edges is a minimum using the Lagrange multiplier method.
(b) Find the change in the dimensions of the box when the volume is changed to
1200 in3 by using the value of λ∗ found in part (a).
(c) Compare the solution found in part (b) with the exact solution.
2.57 Find the effect on f ∗ of changing the constraint to (a) x + x2 + 2x3 = 4 and (b) x + x2 +
2x3 = 2 in Problem 2.48. Use the physical meaning of Lagrange multiplier in finding the
solution.
2.58 A real estate company wants to construct a multistory apartment building on a
500 ×500-ft lot. It has been decided to have a total floor space of 8 × 105 ft2. The height
of each story is required to be 12 ft, the maximum height of the building is to be restricted
to 75 ft, and the parking area is required to be at least 10 % of the total floor area accord-
ing to the city zoning rules. If the cost of the building is estimated at $(500, 000h +
2000F + 500P ), where h is the height in feet, F is the floor area in square feet, and P
is the parking area in square feet. Find the minimum cost design of the building.
2.59 The Brinell hardness test is used to measure the indentation hardness of materials. It
involves penetration of an indenter, in the form of a ball of diameter D (mm), under a
load P (kgf), as shown in Fig. 2.13a . The Brinell hardness number (BHN) is defined as
BHN = P
A
≡ 2P
πD(D −
√
D2 − d2)
(1)
where A (in mm2) is the spherical surface area and d (in mm) is the diameter of the
crater or indentation formed. The diameter d and the depth h of indentation are related
by (Fig. 2.13b)
d = 2
√
h(D − h) (2)
It is desired to find the size of indentation, in terms of the values of d and h, when a
tungsten carbide ball indenter of diameter 10 mm is used under a load of P = 3000 kgf
on a stainless steel test specimen of BHN 1250. Find the values of d and h by formulating
and solving the problem as an unconstrained minimization problem.
Hint: Consider the objective function as the sum of squares of the equations implied by
Eqs. (1) and (2).
114 Classical Optimization Techniques
d
d
h
h
D
P
(a)
(b)
Indentation or crater
of diameter d and depth h
Spherical (ball)
indenter of
diameter D
Figure 2.13 Brinell hardness test.
2.60 A manufacturer produces small refrigerators at a cost of $60 per unit and sells them to
a retailer in a lot consisting of a minimum of 100 units. The selling price is set at $80
per unit if the retailer buys 100 units at a time. If the retailer buys more than 100 units
at a time, the manufacturer agrees to reduce the price of all refrigerators by 10 cents for
each unit bought over 100 units. Determine the number of units to be sold to the retailer
to maximize the profit of the manufacturer.
2.61 Consider the following problem:
Minimizef = (x1 − 2)2 + (x2 − 1)2
subject to
2 ≥ x1 + x2
x2 ≥ x21
Using Kuhn–Tucker conditions, find which of the following vectors are local minima:
X1 =
{
1.5
0.5
}
, X2 =
{
1
1
}
, X3 =
{
2
0
}
2.62 Using Kuhn–Tucker conditions, find the value(s) of β for which the point x∗1 = 1, x∗2 = 2
will be optimal to the problem:
Maximize f (x1, x2) = 2x1 + βx2
subject to
g1(x1, x2) = x21 + x22 − 5 ≤ 0
g2(x1, x2) = x1 − x2 − 2 ≤ 0
Verify your result using a graphical procedure.
Problems 115
2.63 Consider the following optimization problem:
Maximize f = −x1 − x2
subject to
x21 + x2 ≥ 2
4 ≤ x1 + 3x2
x1 + x42 ≤ 30
(a) Find whether the design vector X = {1, 1}T satisfies the Kuhn–Tucker conditions for
a constrained optimum.
(b) What are the values of the Lagrange multipliers at the given design vector?
2.64 Consider the following problem:
Maximize f (X) = x21 + x22 + x23
subject to
x1 + x2 + x3 ≥ 5
2 − x2x3 ≤ 0
x1 ≥ 0, x2 ≥ 0, x3 ≥ 2
Determine whether the Kuhn–Tucker conditions are satisfied at the following points:
X1 =





3
2
3
2
2





, X2 =





4
3
2
3
3





, X3 =



2
1
2



2.65 Find a usable and feasible direction S at (a) X1 = {−1, 5}T and (b) X2 = {2, 3} for the
following problem:
Minimize f (X) = (x1 − 1)2 + (x2 − 5)2
subject to
g1(X) = −x21 + x2 − 4 ≤ 0
g2(X) = −(x1 − 2)2 + x2 − 3 ≤ 0
2.66 Consider the following problem:
Maximize f = x21 − x2
subject to
26 ≥ x21 + x22
x1 + x2 ≥ 6
x1 ≥ 0
116 Classical Optimization Techniques
Determine whether the following search direction is usable, feasible, or both at the design
vector X =
{
5
1
}
:
S =
{
0
1
}
, S =
{
−1
1
}
, S =
{
1
0
}
, S =
{
−1
2
}
2.67 Consider the following problem:
Minimize f = x31 − 6x21 + 11x1 + x3
subject to
x21 + x22 − x23 ≤ 0
4 − x21 − x22 − x23 ≤ 0
xi ≥ 0, i = 1, 2, 3, x3 ≤ 5
Determine whether the following vector represents an optimum solution:
X =





0
√
2
√
2





2.68 Minimize f = x21 + 2x22 + 3x23
subject to the constraints
g1 = x1 − x2 − 2x3 ≤ 12
g2 = x1 + 2x2 − 3x3 ≤ 8
using Kuhn–Tucker conditions.
2.69 Minimize f (x1, x2) = (x1 − 1)2 + (x2 − 5)2
subject to
−x21 + x2 ≤ 4
−(x1 − 2)2 + x2 ≤ 3
by (a) the graphical method and (b) Kuhn–Tucker conditions.
2.70 Maximize f = 8x1 + 4x2 + x1x2 − x21 − x22
subject to
2x1 + 3x2 ≤ 24
−5x1 + 12x2 ≤ 24
x2 ≤ 5
by applying Kuhn–Tucker conditions.
Problems 117
2.71 Consider the following problem:
Maximize f (x) = (x − 1)2
subject to
−2 ≤ x ≤ 4
Determine whether the constraint qualification and Kuhn–Tucker conditions are satisfied
at the optimum point.
2.72 Consider the following problem:
Minimize f = (x1 − 1)2 + (x2 − 1)2
subject to
2x2 − (1 − x1)3 ≤ 0
x1 ≥ 0
x2 ≥ 0
Determine whether the constraint qualification and the Kuhn–Tucker conditions are sat-
isfied at the optimum point.
2.73 Verify whether the following problem is convex:
Minimize f (X) = −4x1 + x21 − 2x1x2 + 2x22
subject to
2x1 + x2 ≤ 6
x1 − 4x2 ≤ 0
x1 ≥ 0, x2 ≥ 0
2.74 Check the convexity of the following problems.
(a) Minimize f (X) = 2x1 + 3x2 − x31 − 2x22
subject to
x1 + 3x2 ≤ 6
5x1 + 2x2 ≤ 10
x1 ≥ 0, x2 ≥ 0
(b) Minimize f (X) = 9x21 − 18x1x2 + 13x1 − 4
subject to
x21 + x22 + 2x1 ≥ 16
2.75 Identify the optimum point among the given design vectors, X1, X2, and X3, by applying
the Kuhn–Tlucker conditions to the following problem:
Minimize f (X) = 100(x2 − x21 )2 + (1 − x1)2
118 Classical Optimization Techniques
subject to
x22 − x1 ≥ 0
x21 − x2 ≥ 0
− 1
2
≤ x1 ≤ 12 , x2 ≤ 1
X1 =
{
0
0
}
, X2 =
{
0
−1
}
, X3 =
{
− 1
2
1
4
}
2.76 Consider the following optimization problem:
Minimize f = −x21 − x22 + x1x2 + 7x1 + 4x2
subject to
2x1 + 3x2 ≤ 24
−5x1 + 12x2 ≤ 24
x1 ≥ 0, x2 ≥ 0, x2 ≤ 4
Find a usable feasible direction at each of the following design vectors:
X1 =
{
1
1
}
, X2 =
{
6
4
}
3
Linear Programming I:
Simplex Method
3.1 INTRODUCTION
Linear programming is an optimization method applicable for the solution of prob-
lems in which the objective function and the constraints appear as linear functions
of the decision variables. The constraint equations in a linear programming problem
may be in the form of equalities or inequalities. The linear programming type of opti-
mization problem was first recognized in the 1930s by economists while developing
methods for the optimal allocation of resources. During World War II the U.S. Air
Force sought more effective procedures of allocating resources and turned to linear
programming. George B. Dantzig, who was a member of the Air Force group, for-
mulated the general linear programming problem and devised the simplex method of
solution in 1947. This has become a significant step in bringing linear programming into
wider use. Afterward, much progress was made in the theoretical development and in
the practical applications of linear programming. Among all the works, the theoretical
contributions made by Kuhn and Tucker had a major impact in the development of the
duality theory in LP. The works of Charnes and Cooper were responsible for industrial
applications of LP.
Linear programming is considered a revolutionary development that permits us to
make optimal decisions in complex situations. At least four Nobel Prizes were awarded
for contributions related to linear programming. For example, when the Nobel Prize
in Economics was awarded in 1975 jointly to L. V. Kantorovich of the former Soviet
Union and T. C. Koopmans of the United States, the citation for the prize mentioned
their contributions on the application of LP to the economic problem of allocating
resources [3.14]. George Dantzig, the inventor of LP, was awarded the National Medal
of Science by President Gerald Ford in 1976.
Although several other methods have been developed over the years for solving LP
problems, the simplex method continues to be the most efficient and popular method for
solving general LP problems. Among other methods, Karmarkar’s method, developed in
1984, has been shown to be up to 50 times as fast as the simplex algorithm of Dantzig. In
this chapter we present the theory, development, and applications of the simplex method
for solving LP problems. Additional topics, such as the revised simplex method, duality
119Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
120 Linear Programming I: Simplex Method
theory, decomposition method, postoptimality analysis, and Karmarkar’s method, are
considered in Chapter 4.
3.2 APPLICATIONS OF LINEAR PROGRAMMING
The number of applications of linear programming has been so large that it is not
possible to describe all of them here. Only the early applications are mentioned here
and the exercises at the end of this chapter give additional example applications of
linear programming. One of the early industrial applications of linear programming
was made in the petroleum refineries. In general, an oil refinery has a choice of buying
crude oil from several different sources with differing compositions and at differing
prices. It can manufacture different products, such as aviation fuel, diesel fuel, and
gasoline, in varying quantities. The constraints may be due to the restrictions on the
quantity of the crude oil available from a particular source, the capacity of the refinery
to produce a particular product, and so on. A mix of the purchased crude oil and the
manufactured products is sought that gives the maximum profit.
The optimal production plan in a manufacturing firm can also be decided using
linear programming. Since the sales of a firm fluctuate, the company can have various
options. It can build up an inventory of the manufactured products to carry it through
the period of peak sales, but this involves an inventory holding cost. It can also pay
overtime rates to achieve higher production during periods of higher demand. Finally,
the firm need not meet the extra sales demand during the peak sales period, thus losing
a potential profit. Linear programming can take into account the various cost and loss
factors and arrive at the most profitable production plan.
In the food-processing industry, linear programming has been used to determine
the optimal shipping plan for the distribution of a particular product from different
manufacturing plants to various warehouses. In the iron and steel industry, linear pro-
gramming is used to decide the types of products to be made in their rolling mills to
maximize the profit. Metalworking industries use linear programming for shop loading
and for determining the choice between producing and buying a part. Paper mills use
it to decrease the amount of trim losses. The optimal routing of messages in a commu-
nication network and the routing of aircraft and ships can also be decided using linear
programming.
Linear programming has also been applied to formulate and solve several types
of engineering design problems, such as the plastic design of frame structures, as
illustrated in the following example.
Example 3.1 In the limit design of steel frames, it is assumed that plastic hinges
will be developed at points with peak moments. When a sufficient number of hinges
develop, the structure becomes an unstable system referred to as a collapse mechanism .
Thus a design will be safe if the energy-absorbing capacity of the frame (U) is greater
than the energy imparted by the externally applied loads (E) in each of the deformed
shapes as indicated by the various collapse mechanisms [3.9].
For the rigid frame shown in Fig. 3.1, plastic moments may develop at the points of
peak moments (numbered 1 through 7 in Fig. 3.1). Four possible collapse mechanisms
are shown in Fig. 3.2 for this frame. Assuming that the weight is a linear function
3.2 Applications of Linear Programming 121
Figure 3.1 Rigid frame.
Figure 3.2 Collapse mechanisms of the frame. Mb, moment carrying capacity of beam; Mc,
moment carrying capacity of column [3.9].
of the plastic moment capacities, find the values of the ultimate moment capacities
Mb and Mc for minimum weight. Assume that the two columns are identical and that
P1 = 3, P2 = 1, h = 8, and l = 10.
SOLUTION The objective function can be expressed as
f (Mb, Mc) = weight of beam + weight of columns
= α(2lMb + 2hMc)
122 Linear Programming I: Simplex Method
where α is a constant indicating the weight per unit length of the member with a
unit plastic moment capacity. Since a constant multiplication factor does not affect the
result, f can be taken as
f = 2lMb + 2hMc = 20Mb + 16Mc (E1)
The constraints (U ≥ E) from the four collapse mechanisms can be expressed as
Mc ≥ 6
Mb ≥ 2.5
2Mb + Mc ≥ 17
Mb + Mc ≥ 12 (E2)
3.3 STANDARD FORM OF A LINEAR PROGRAMMING PROBLEM
The general linear programming problem can be stated in the following standard
forms:
Scalar Form
Minimize f (x1, x2, . . . , xn) = c1x1 + c2x2 + · · · + cnxn (3.1a)
subject to the constraints
a11x1 + a12x2 + · · · + a1nxn = b1
a21x1 + a22x2 + · · · + a2nxn = b2
...
am1x1 + am2x2 + · · · + amnxn = bm
(3.2a)
x1 ≥ 0
x2 ≥ 0
...
xn ≥ 0
(3.3a)
where cj , bj , and aij (i = 1, 2, . . . , m; j = 1, 2, . . . , n) are known constants, and xj
are the decision variables.
Matrix Form
Minimize f (X) = cTX (3.1b)
subject to the constraints
aX = b (3.2b)
X ≥ 0 (3.3b)
3.3 Standard Form of a Linear Programming Problem 123
where
X =









x1
x2
...
xn









, b =









b1
b2
...
bm









, c =









c1
c2
...
cn









,
a =





a11 a12 · · · a1n
a21 a22 · · · a2n
...
am1 am2 · · · amn





The characteristics of a linear programming problem, stated in standard form, are
1. The objective function is of the minimization type.
2. All the constraints are of the equality type.
3. All the decision variables are nonnegative.
It is now shown that any linear programming problem can be expressed in standard
form by using the following transformations.
1. The maximization of a function f (x1, x2, . . . , xn) is equivalent to the minimiza-
tion of the negative of the same function. For example, the objective function
minimize f = c1x1 + c2x2 + · · · + cnxn
is equivalent to
maximize f ′ = −f = −c1x1 − c2x2 − · · · − cnxn
Consequently, the objective function can be stated in the minimization form in
any linear programming problem.
2. In most engineering optimization problems, the decision variables represent
some physical dimensions, and hence the variables xj will be nonnegative.
However, a variable may be unrestricted in sign in some problems. In such
cases, an unrestricted variable (which can take a positive, negative, or zero
value) can be written as the difference of two nonnegative variables. Thus if xj
is unrestricted in sign, it can be written as xj = x
′
j − x
′′
j , where
x′j ≥ 0 and x
′′
j ≥ 0
It can be seen that xj will be negative, zero, or positive, depending on whether
x′′j is greater than, equal to, or less than x
′
j .
3. If a constraint appears in the form of a “less than or equal to” type of
inequality as
ak1x1 + ak2x2 + · · · + aknxn ≤ bk
it can be converted into the equality form by adding a nonnegative slack variable
xn+1 as follows:
ak1x1 + ak2x2 + · · · + aknxn + xn+1 = bk
124 Linear Programming I: Simplex Method
Similarly, if the constraint is in the form of a “greater than or equal to” type of
inequality as
ak1x1 + ak2x2 + · · · + aknxn ≥ bk
it can be converted into the equality form by subtracting a variable as
ak1x1 + ak2x2 + · · · + aknxn − xn+1 = bk
where xn+1 is a nonnegative variable known as a surplus variable.
It can be seen that there are m equations in n decision variables in a linear pro-
gramming problem. We can assume that m < n; for if m>n, there would be m − n
redundant equations that could be eliminated. The case n = m is of no interest, for then
there is either a unique solution X that satisfies Eqs. (3.2) and (3.3) (in which case there
can be no optimization) or no solution, in which case the constraints are inconsistent.
The case m < n corresponds to an underdetermined set of linear equations, which, if
they have one solution, have an infinite number of solutions. The problem of linear
programming is to find one of these solutions that satisfies Eqs. (3.2) and (3.3) and
yields the minimum of f .
3.4 GEOMETRY OF LINEAR PROGRAMMING PROBLEMS
A linear programming problem with only two variables presents a simple case for which
the solution can be obtained by using a rather elementary graphical method. Apart
from the solution, the graphical method gives a physical picture of certain geometrical
characteristics of linear programming problems. The following example is considered
to illustrate the graphical method of solution.
Example 3.2 A manufacturing firm produces two machine parts using lathes, milling
machines, and grinding machines. The different machining times required for each part,
the machining times available on different machines, and the profit on each machine
part are given in the following table.
Machining time required (min)
Maximum time available
Type of machine Machine part I Machine part II per week (min)
Lathes 10 5 2500
Milling machines 4 10 2000
Grinding machines 1 1.5 450
Profit per unit $50 $100
Determine the number of parts I and II to be manufactured per week to maximize the
profit.
SOLUTION Let the number of machine parts I and II manufactured per week be
denoted by x and y, respectively. The constraints due to the maximum time limitations
3.4 Geometry of Linear Programming Problems 125
on the various machines are given by
10x + 5y ≤ 2500 (E1)
4x + 10y ≤ 2000 (E2)
x + 1.5y ≤ 450 (E3)
Since the variables x and y cannot take negative values, we have
x ≥ 0
y ≥ 0
(E4)
The total profit is given by
f (x, y) = 50x + 100y (E5)
Thus the problem is to determine the nonnegative values of x and y that satisfy the
constraints stated in Eqs. (E1) to (E3) and maximize the objective function given by
Eq. (E5). The inequalities (E1) to (E4) can be plotted in the xy plane and the feasible
region identified as shown in Fig. 3.3 Our objective is to find at least one point out of the
infinite points in the shaded region of Fig. 3.3 that maximizes the profit function (E5).
The contours of the objective function, f , are defined by the linear equation
50x + 100y = k = constant
As k is varied, the objective function line is moved parallel to itself. The maximum
value of f is the largest k whose objective function line has at least one point in
common with the feasible region. Such a point can be identified as point G in Fig. 3.4.
The optimum solution corresponds to a value of x∗ = 187.5, y∗ = 125.0 and a profit
of $21,875.00.
Figure 3.3 Feasible region given by Eqs. (E1) to (E4).
126 Linear Programming I: Simplex Method
Figure 3.4 Contours of objective function.
In some cases, the optimum solution may not be unique. For example, if the
profit rates for the machine parts I and II are $40 and $100 instead of $50 and $100,
respectively, the contours of the profit function will be parallel to side CG of the
feasible region as shown in Fig. 3.5. In this case, line P ′′Q′′, which coincides with the
boundary line CG , will correspond to the maximum (feasible) profit. Thus there is no
unique optimal solution to the problem and any point between C and G on line P ′′Q′′
Figure 3.5 Infinite solutions.
3.5 Definitions and Theorems 127
Figure 3.6 Unbounded solution.
can be taken as an optimum solution with a profit value of $20,000. There are three
other possibilities. In some problems, the feasible region may not be a closed convex
polygon. In such a case, it may happen that the profit level can be increased to an
infinitely large value without leaving the feasible region, as shown in Fig. 3.6. In this
case the solution of the linear programming problem is said to be unbounded. On the
other extreme, the constraint set may be empty in some problems. This could be due
to the inconsistency of the constraints; or, sometimes, even though the constraints may
be consistent, no point satisfying the constraints may also satisfy the nonnegativity
restrictions. The last possible case is when the feasible region consists of a single
point. This can occur only if the number of constraints is at least equal to the number
of variables. A problem of this kind is of no interest to us since there is only one
feasible point and there is nothing to be optimized.
Thus a linear programming problem may have (1) a unique and finite optimum
solution, (2) an infinite number of optimal solutions, (3) an unbounded solution, (4) no
solution, or (5) a unique feasible point. Assuming that the linear programming problem
is properly formulated, the following general geometrical characteristics can be noted
from the graphical solution:
1. The feasible region is a convex polygon.†
2. The optimum value occurs at an extreme point or vertex of the feasible region.
3.5 DEFINITIONS AND THEOREMS
The geometrical characteristics of a linear programming problem stated in Section 3.4
can be proved mathematically. Some of the more powerful methods of solving linear
programming problems take advantage of these characteristics. The terminology used
in linear programming and some of the important theorems are presented in this section.
†A convex polygon consists of a set of points having the property that the line segment joining any two
points in the set is entirely in the convex set. In problems having more than two decision variables, the
feasible region is called a convex polyhedron, which is defined in the next section.
128 Linear Programming I: Simplex Method
Definitions
1. Point in n-dimensional space. A point X in an n-dimensional space is char-
acterized by an ordered set of n values or coordinates (x1, x2, . . . , xn). The
coordinates of X are also called the components of X.
2. Line segment in n dimensions (L). If the coordinates of two points A and B
are given by x
(1)
j and x
(2)
j (j = 1, 2, . . . , n), the line segment (L) joining these
points is the collection of points X(λ) whose coordinates are given by xj =
λx
(1)
j + (1 − λ)x
(2)
j , j = 1, 2, . . . , n, with 0 ≤ λ ≤ 1.
Thus
L = {X | X = λX(1) + (1 − λ)X(2)} (3.4)
In one dimension, for example, it is easy to see that the definition is in accor-
dance with out experience (Fig. 3.7):
x(2) − x(λ) = λ[x(2) − x(1)], 0 ≤ λ ≤ 1 (3.5)
whence
x(λ) = λx(1) + (1 − λ)x(2), 0 ≤ λ ≤ 1 (3.6)
3. Hyperplane. In n-dimensional space, the set of points whose coordinates satisfy
a linear equation
a1x1 + · · · + anxn = a
TX = b (3.7)
is called a hyperplane. A hyperplane, H , is represented as
H(a, b) = {X | aTX = b} (3.8)
A hyperplane has n − 1 dimensions in an n-dimensional space. For example,
in three-dimensional space it is a plane, and in two-dimensional space it is a
line. The set of points whose coordinates satisfy a linear inequality like a1x1 +
· · · + anxn ≤ b is called a closed half-space, closed due to the inclusion of an
equality sign in the inequality above. A hyperplane partitions the n-dimensional
space (En) into two closed half-spaces, so that
H+ = {X | aTX ≥ b} (3.9)
H− = {X | aTX ≤ b} (3.10)
This is illustrated in Fig. 3.8 in the case of a two-dimensional space (E2).
Figure 3.7 Line segment.
3.5 Definitions and Theorems 129
Figure 3.8 Hyperplane in two dimensions.
4. Convex set. A convex set is a collection of points such that if X(1) and X(2) are
any two points in the collection, the line segment joining them is also in the
collection. A convex set, S, can be defined mathematically as follows:
If X(1), X(2) ∈ S, then X ∈ S
where
X = λX(1) + (1 − λ)X(2), 0 ≤ λ ≤ 1
A set containing only one point is always considered to be convex. Some
examples of convex sets in two dimensions are shown shaded in Fig. 3.9. On
the other hand, the sets depicted by the shaded region in Fig. 3.10 are not
convex. The L-shaped region, for example, is not a convex set because it is
possible to find two points a and b in the set such that not all points on the line
joining them belong to the set.
5. Convex polyhedron and convex polytope. A convex polyhedron is a set of points
common to one or more half-spaces. A convex polyhedron that is bounded is
called a convex polytope.
Figure 3.11a and b represents convex polytopes in two and three dimensions,
and Fig. 3.11c and d denotes convex polyhedra in two and three dimensions. It
Figure 3.9 Convex sets.
Figure 3.10 Nonconvex sets.
130 Linear Programming I: Simplex Method
Figure 3.11 Convex polytopes in two and three dimensions (a, b) and convex polyhedra in
two and three dimensions (c, d).
can be seen that a convex polygon, shown in Fig. 3.11a and c, can be considered
as the intersection of one or more half-planes.
6. Vertex or extreme point. This is a point in the convex set that does not lie on a
line segment joining two other points of the set. For example, every point on
the circumference of a circle and each corner point of a polygon can be called
a vertex or extreme point.
7. Feasible solution. In a linear programming problem, any solution that satisfies
the constraints
aX = b (3.2)
X ≥ 0 (3.3)
is called a feasible solution.
8. Basic solution. A basic solution is one in which n − m variables are set equal
to zero. A basic solution can be obtained by setting n − m variables to zero and
solving the constraint Eqs. (3.2) simultaneously.
9. Basis. The collection of variables not set equal to zero to obtain the basic
solution is called the basis.
3.5 Definitions and Theorems 131
10. Basic feasible solution. This is a basic solution that satisfies the nonnegativity
conditions of Eq. (3.3).
11. Nondegenerate basic feasible solution. This is a basic feasible solution that has
got exactly m positive xi .
12. Optimal solution. A feasible solution that optimizes the objective function is
called an optimal solution.
13. Optimal basic solution. This is a basic feasible solution for which the objective
function is optimal.
Theorems. The basic theorems of linear programming can now be stated and proved
†.
Theorem 3.1 The intersection of any number of convex sets is also convex.
Proof : Let the given convex sets be represented as Ri(i = 1, 2, . . . , K) and their
intersection as R, so that‡
R =
K
⋂
i=1
Ri
If the points X(1), X(2) ∈ R, then from the definition of intersection,
X = λX(1) + (1 − λ)X(2) ∈ Ri (i = 1, 2, . . . , K)
0 ≤ λ ≤ 1
Thus
X ∈ R =
K
⋂
i=1
Ri
and the theorem is proved. Physically, the theorem states that if there are a number of
convex sets represented by R1, R2, . . ., the set of points R common to all these sets
will also be convex. Figure 3.12 illustrates the meaning of this theorem for the case
of two convex sets.
Theorem 3.2 The feasible region of a linear programming problem is convex.
Figure 3.12 Intersection of two convex sets.
†The proofs of the theorems are not needed for an understanding of the material presented in subsequent
sections.
‡The symbol ∩ represents the intersection of sets.
132 Linear Programming I: Simplex Method
Proof : The feasible region S of a standard linear programming problem is defined as
S = {X | aX = b, X ≥ 0} (3.11)
Let the points X1 and X2 belong to the feasible set S so that
aX1 = b, X1 ≥ 0 (3.12)
aX2 = b, X2 ≥ 0 (3.13)
Multiply Eq. (3.12) by λ and Eq. (3.13) by (1 − λ) and add them to obtain
a[λX1 + (1 − λ)X2] = λb + (1 − λ)b = b
that is,
aXλ = b
where
Xλ = λX1 + (1 − λ)X2
Thus the point Xλ satisfies the constraints and if
0 ≤ λ ≤ 1, Xλ ≥ 0
Hence the theorem is proved.
Theorem 3.3 Any local minimum solution is global for a linear programming problem.
Proof : In the case of a function of one variable, the minimum (maximum) of a function
f (x) is obtained at a value x at which the derivative is zero. This may be a point like
A(x = x1) in Fig. 3.13, where f (x) is only a relative (local) minimum, or a point like
B(x = x2), where f (x) is a global minimum. Any solution that is a local minimum
solution is also a global minimum solution for the linear programming problem. To see
this, let A be the local minimum solution and assume that it is not a global minimum
solution so that there is another point B at which fB < fA. Let the coordinates of A
and B be given by {x1, x2, . . . , xn}
T and {y1, y2, . . . , yn}
T, respectively. Then any point
C = {z1, z2, . . . , zn}
T that lies on the line segment joining the two points A and B is
Figure 3.13 Local and global minima.
3.6 Solution of a System of Linear Simultaneous Equations 133
a feasible solution and fC = λfA + (1 − λ)fB . In this case, the value of f decreases
uniformly from fA to fB , and thus all points on the line segment between A and B
(including those in the neighborhood of A) have f values less than fA and correspond
to feasible solutions. Hence it is not possible to have a local minimum at A and at the
same time another point B such that fA >fB . This means that for all B, fA ≤ fB , so
that fA is the global minimum value.
The generalized version of this theorem is proved in Appendix A so that it can be
applied to nonlinear programming problems also.
Theorem 3.4 Every basic feasible solution is an extreme point of the convex set of
feasible solutions.
Theorem 3.5 Let S be a closed, bounded convex polyhedron with Xei , i = 1 to p, as
the set of its extreme points. Then any vector X ∈ S can be written as
X =
p
∑
i=1
λiX
e
i
λi ≥ 0
p
∑
i=1
λi = 1
Theorem 3.6 Let S be a closed convex polyhedron. Then the minimum of a linear
function over S is attained at an extreme point of S.
The proofs of Theorems 3.4 to 3.6 can be found in Ref. [3.1].
3.6 SOLUTION OF A SYSTEM OF LINEAR SIMULTANEOUS
EQUATIONS
Before studying the most general method of solving a linear programming problem, it
will be useful to review the methods of solving a system of linear equations. Hence
in the present section we review some of the elementary concepts of linear equations.
Consider the following system of n equations in n unknowns:
a11x1 + a12x2 + · · · + a1nxn = b1 (E1)
a21x1 + a22x2 + · · · + a2nxn = b2 (E2)
a31x1 + a32x2 + · · · + a3nxn = b3 (E3)
...
...
an1x1 + an2x2 + · · · + annxn = bn (En)
(3.14)
Assuming that this set of equations possesses a unique solution, a method of solving
the system consists of reducing the equations to a form known as canonical form .
It is well known from elementary algebra that the solution of Eqs. (3.14) will not be
altered under the following elementary operations: (1) any equation Er is replaced by
134 Linear Programming I: Simplex Method
the equation kEr , where k is a nonzero constant, and (2) any equation Er is replaced by
the equation Er + kEs , where Es is any other equation of the system. By making use of
these elementary operations, the system of Eqs. (3.14) can be reduced to a convenient
equivalent form as follows. Let us select some variable xi and try to eliminate it from all
the equations except the j th one (for which aj i is nonzero). This can be accomplished
by dividing the j th equation by aj i and subtracting aki times the result from each of the
other equations, k = 1, 2, . . ., j − 1, j + 1, . . . , n. The resulting system of equations
can be written as
a′11x1 + a
′
12x2 + · · · + a
′
1,i−1xi−1 + 0xi + a
′
1,i+1xi+1 + · · ·
+ a′1nxn = b
′
1
a′21x1 + a
′
22x2 + · · · + a
′
2,i−1xi−1 + 0xi + a
′
2,i+1xi+1 + · · ·
+ a′2nxn = b
′
2
...
a′j−1,1x1 + a
′
j−1,2x2 + · · · + a
′
j−1,i−1 + 0xi + a
′
j−1,i+1xi+1
+ · · · + a′j−1,nxn = b
′
j−1
a′j1x1 + a
′
j2x2 + · · · + a
′
j,i−1xi−1 + 1xi + a
′
j,i+1xi+1
+ · · · + a′jnxn = b
′
j
a′j+1,1x1 + a
′
j+1,2x2 + · · · + a
′
j+1,i−1xi−1 + 0xi + a
′
j+1,i+1xi+1
+ · · · + a′j+1,nxn = b
′
j+1
...
a′n1x1 + a
′
n2x2 + · · · + a
′
n,i−1xi−1 + 0xi + a
′
n,i+1xi+1 + · · ·
+ a′nnxn = b
′
n (3.15)
where the primes indicate that the a′ij and b
′
j are changed from the original system.
This procedure of eliminating a particular variable from all but one equations is called
a pivot operation . The system of Eqs. (3.15) produced by the pivot operation have
exactly the same solution as the original set of Eqs. (3.14). That is, the vector X that
satisfies Eqs. (3.14) satisfies Eqs. (3.15), and vice versa.
Next time, if we take the system of Eqs. (3.15) and perform a new pivot operation
by eliminating xs , s = i, in all the equations except the t th equation, t = j , the zeros
or the 1 in the ith column will not be disturbed. The pivotal operations can be repeated
by using a different variable and equation each time until the system of Eqs. (3.14) is
reduced to the form
1x1 + 0x2 + 0x3 + · · · + 0xn = b
′′
1
0x1 + 1x2 + 0x3 + · · · + 0xn = b
′′
2
3.7 Pivotal Reduction of a General System of Equations 135
0x1 + 0x2 + 1x3 + · · · + 0xn = b
′′
3 (3.16)
...
0x1 + 0x2 + 0x3 + · · · + 1xn = b
′′
n
This system of Eqs. (3.16) is said to be in canonical form and has been obtained after
carrying out n pivot operations. From the canonical form, the solution vector can be
directly obtained as
xi = b
′′
i , i = 1, 2, . . . , n (3.17)
Since the set of Eqs. (3.16) has been obtained from Eqs. (3.14) only through elementary
operations, the system of Eqs. (3.16) is equivalent to the system of Eqs. (3.14). Thus
the solution given by Eqs. (3.17) is the desired solution of Eqs. (3.14).
3.7 PIVOTAL REDUCTION OF A GENERAL SYSTEM OF
EQUATIONS
Instead of a square system, let us consider a system of m equations in n variables with
n ≥ m. This system of equations is assumed to be consistent so that it will have at
least one solution:
a11x1 + a12x2 + · · · + a1nxn = b1
a21x1 + a22x2 + · · · + a2nxn = b2
...
am1x1 + am2x2 + · · · + amnxn = bm
(3.18)
The solution vector(s) X that satisfy Eqs. (3.18) are not evident from the equations.
However, it is possible to reduce this system to an equivalent canonical system from
which at least one solution can readily be deduced. If pivotal operations with respect
to any set of m variables, say, x1, x2, . . . , xm, are carried, the resulting set of equations
can be written as follows:
Canonical system with pivotal variables x1, x2, . . . , xm
1x1 + 0x2 + · · · + 0xm + a
′′
1,m+1xm+1 + · · · + a
′′
1nxn = b
′′
1
0x1 + 1x2 + · · · + 0xm + a
′′
2,m+1xm+1 + · · · + a
′′
2nxn = b
′′
2 (3.19)
...
0x1 + 0x2 + · · · + 1xm + a
′′
m,m+1xm+1 + · · · + a
′′
mnxn = b
′′
m
Pivotal Nonpivotal or Constants
variables independent
variables
136 Linear Programming I: Simplex Method
One special solution that can always be deduced from the system of Eqs. (3.19) is
xi =
{
b′′i , i = 1, 2, . . . ,m
0, i = m + 1, m + 2, . . . , n
(3.20)
This solution is called a basic solution since the solution vector contains no more
than m nonzero terms. The pivotal variables xi , i = 1, 2, . . . , m, are called the basic
variables and the other variables xi , i = m + 1, m + 2, . . . , n, are called the nonbasic
variables . Of course, this is not the only solution, but it is the one most readily deduced
from Eqs. (3.19). If all b′′i , i = 1, 2, . . . , m, in the solution given by Eqs. (3.20) are
nonnegative, it satisfies Eqs. (3.3) in addition to Eqs. (3.2), and hence it can be called
a basic feasible solution .
It is possible to obtain the other basic solutions from the canonical system of Eqs.
(3.19). We can perform an additional pivotal operation on the system after it is in
canonical form, by choosing a′′pq (which is nonzero) as the pivot term, q >m, and
using any row p (among 1, 2, . . . ,m). The new system will still be in canonical form
but with xq as the pivotal variable in place of xp. The variable xp, which was a basic
variable in the original canonical form, will no longer be a basic variable in the new
canonical form. This new canonical system yields a new basic solution (which may or
may not be feasible) similar to that of Eqs. (3.20). It is to be noted that the values of
all the basic variables change, in general, as we go from one basic solution to another,
but only one zero variable (which is nonbasic in the original canonical form) becomes
nonzero (which is basic in the new canonical system), and vice versa.
Example 3.3 Find all the basic solutions corresponding to the system of equations
2x1 + 3x2 − 2x3 − 7x4 = 1 (I0)
x1 + x2 + x3 + 3x4 = 6 (II0)
x1 − x2 + x3 + 5x4 = 4 (III0)
SOLUTION First we reduce the system of equations into a canonical form with x1,
x2, and x3 as basic variables. For this, first we pivot on the element a11 = 2 to obtain
x1 +
3
2
x2 − x3 −
7
2
x4 =
1
2
I1 =
1
2
I0
0 − 1
2
x2 + 2x3 +
13
2
x4 =
11
2
II1 = II0 − I1
0 − 5
2
x2 + 2x3 +
17
2
x4 =
7
2
III1 = III0 − I1
Then we pivot on a′22 = −
1
2
, to obtain
x1 + 0 + 5x3 + 16x4 = 17 I2 = I1 −
3
2
II2
0 + x2 − 4x3 − 13x4 = −11 II2 = −2II1
0 + 0 − 8x3 − 24x4 = −24 III2 = III1 +
5
2
II2
3.7 Pivotal Reduction of a General System of Equations 137
Finally we pivot on a′33 to obtain the required canonical form as
x1 + x4 = 2 I3 = I2 − 5III3
x2 − x4 = 1 II3 = II2 + 4III3
x3 + 3x4 = 3 III3 = −
1
8
III2
From this canonical form, we can readily write the solution of x1, x2, and x3 in terms
of the other variable x4 as
x1 = 2 − x4
x2 = 1 + x4
x3 = 3 − 3x4
If Eqs. (I0), (II0), and (III0) are the constraints of a linear programming problem, the
solution obtained by setting the independent variable equal to zero is called a basic
solution. In the present case, the basic solution is given by
x1 = 2, x2 = 1, x3 = 3 (basic variables)
and x4 = 0 (nonbasic or independent variable). Since this basic solution has all xj ≥
0 (j = 1, 2, 3, 4), it is a basic feasible solution.
If we want to move to a neighboring basic solution, we can proceed from the
canonical form given by Eqs. (I3), (II3), and (III3). Thus if a canonical form in terms
of the variables x1, x2, and x4 is required, we have to bring x4 into the basis in place
of the original basic variable x3. Hence we pivot on a
′′
34 in Eq. (III3). This gives the
desired canonical form as
x1 −
1
3
x3 = 1 I4 = I3 − III4
x2 +
1
3
x3 = 2 II4 = II3 + III4
x4 +
1
3
x3 = 1 III4 =
1
3
III3
This canonical system gives the solution of x1, x2, and x4 in terms of x3 as
x1 = 1 +
1
3
x3
x2 = 2 −
1
3
x3
x4 = 1 −
1
3
x3
and the corresponding basic solution is given by
x1 = 1, x2 = 2, x4 = 1 (basic variables)
x3 = 0 (nonbasic variable)
This basic solution can also be seen to be a basic feasible solution. If we want to move
to the next basic solution with x1, x3, and x4 as basic variables, we have to bring x3
138 Linear Programming I: Simplex Method
into the current basis in place of x2. Thus we have to pivot a
′′
23 in Eq. (II4). This leads
to the following canonical system:
x1 + x2 = 3 I5 = I4 +
1
3
II5
x3 + 3x2 = 6 II5 = 3II4
x4 − x2 = −1 III5 = III4 −
1
3
II5
The solution for x1, x3, and x4 is given by
x1 = 3 − x2
x3 = 6 − 3x2
x4 = −1 + x2
from which the basic solution can be obtained as
x1 = 3, x3 = 6, x4 = −1 (basic variables)
x2 = 0 (nonbasic variable)
Since all the xj are not nonnegative, this basic solution is not feasible.
Finally, to obtain the canonical form in terms of the basic variables x2, x3, and x4,
we pivot on a′′12 in Eq. (I5), thereby bringing x2 into the current basis in place of x1.
This gives
x2 + x1 = 3 I6 = I5
x3 − 3x1 = −3 II6 = II5 − 3I6
x4 + x1 = 2 III6 = III5 + I6
This canonical form gives the solution for x2, x3, and x4 in terms of x1 as
x2 = 3 − x1
x3 = −3 + 3x1
x4 = 2 − x1
and the corresponding basic solution is
x2 = 3, x3 = −3, x4 = 2 (basic variables)
x1 = 0 (nonbasic variable)
This basic solution can also be seen to be infeasible due to the negative value for x3.
3.8 MOTIVATION OF THE SIMPLEX METHOD
Given a system in canonical form corresponding to a basic solution, we have seen how
to move to a neighboring basic solution by a pivot operation. Thus one way to find the
optimal solution of the given linear programming problem is to generate all the basic
3.9 Simplex Algorithm 139
solutions and pick the one that is feasible and corresponds to the optimal value of the
objective function. This can be done because the optimal solution, if one exists, always
occurs at an extreme point or vertex of the feasible domain. If there are m equality
constraints in n variables with n ≥ m, a basic solution can be obtained by setting any
of the n − m variables equal to zero. The number of basic solutions to be inspected is
thus equal to the number of ways in which m variables can be selected from a set of
n variables, that is,
(
n
m
)
=
n!
(n − m)! m!
For example, if n = 10 and m = 5, we have 252 basic solutions, and if n = 20 and
m = 10, we have 184,756 basic solutions. Usually, we do not have to inspect all these
basic solutions since many of them will be infeasible. However, for large values of n
and m, this is still a very large number to inspect one by one. Hence what we really need
is a computational scheme that examines a sequence of basic feasible solutions, each
of which corresponds to a lower value of f until a minimum is reached. The simplex
method of Dantzig is a powerful scheme for obtaining a basic feasible solution; if the
solution is not optimal, the method provides for finding a neighboring basic feasible
solution that has a lower or equal value of f . The process is repeated until, in a finite
number of steps, an optimum is found.
The first step involved in the simplex method is to construct an auxiliary prob-
lem by introducing certain variables known as artificial variables into the standard
form of the linear programming problem. The primary aim of adding the artificial
variables is to bring the resulting auxiliary problem into a canonical form from which
its basic feasible solution can be obtained immediately. Starting from this canonical
form, the optimal solution of the original linear programming problem is sought in
two phases. The first phase is intended to find a basic feasible solution to the orig-
inal linear programming problem. It consists of a sequence of pivot operations that
produces a succession of different canonical forms from which the optimal solution
of the auxiliary problem can be found. This also enables us to find a basic feasible
solution, if one exists, of the original linear programming problem. The second phase
is intended to find the optimal solution of the original linear programming problem.
It consists of a second sequence of pivot operations that enables us to move from
one basic feasible solution to the next of the original linear programming problem.
In this process, the optimal solution of the problem, if one exists, will be identified.
The sequence of different canonical forms that is necessary in both the phases of
the simplex method is generated according to the simplex algorithm described in the
next section. That is, the simplex algorithm forms the main subroutine of the simplex
method.
3.9 SIMPLEX ALGORITHM
The starting point of the simplex algorithm is always a set of equations, which includes
the objective function along with the equality constraints of the problem in canonical
form. Thus the objective of the simplex algorithm is to find the vector X ≥ 0 that
140 Linear Programming I: Simplex Method
minimizes the function f (X) and satisfies the equations:
1x1 + 0x2 + · · · + 0xm + a
′′
1,m+1xm+1 + · · · + a
′′
1nxn = b
′′
1
0x1 + 1x2 + · · · + 0xm + a
′′
2,m+1xm+1 + · · · + a
′′
2nxn = b
′′
2
...
0x1 + 0x2 + · · · + 1xm + a
′′
m,m+1xm+1 + · · · + a
′′
mnxn = b
′′
m
0x1 + 0x2 + · · · + 0xm − f
+ c′′m+1xm+1 + · · · + c
′′
mnxn = −f
′′
0
(3.21)
where a′′ij , c
′′
j , b
′′
i , and f
′′
0 are constants. Notice that (−f ) is treated as a basic variable
in the canonical form of Eqs. (3.21). The basic solution that can readily be deduced
from Eqs. (3.21) is
xi = b
′′
i , i = 1, 2, . . . , m
f = f n0
xi = 0, i = m + 1, m + 2, . . . , n
(3.22)
If the basic solution is also feasible, the values of xi , i = 1, 2, . . . , n, are nonnegative
and hence
b′′i ≥ 0, i = 1, 2, . . . , m (3.23)
In phase I of the simplex method, the basic solution corresponding to the canonical form
obtained after the introduction of the artificial variables will be feasible for the auxiliary
problem. As stated earlier, phase II of the simplex method starts with a basic feasible
solution of the original linear programming problem. Hence the initial canonical form
at the start of the simplex algorithm will always be a basic feasible solution.
We know from Theorem 3.6 that the optimal solution of a linear programming
problem lies at one of the basic feasible solutions. Since the simplex algorithm is
intended to move from one basic feasible solution to the other through pivotal oper-
ations, before moving to the next basic feasible solution, we have to make sure that
the present basic feasible solution is not the optimal solution. By merely glancing at
the numbers c′′j , j = 1, 2, . . . , n, we can tell whether or not the present basic feasible
solution is optimal. Theorem 3.7 provides a means of identifying the optimal point.
3.9.1 Identifying an Optimal Point
Theorem 3.7 A basic feasible solution is an optimal solution with a minimum objec-
tive function value of f ′′0 if all the cost coefficients c
′′
j , j = m + 1, m + 2, . . . , n, in
Eqs. (3.21) are nonnegative.
Proof : From the last row of Eqs. (3.21), we can write that
f ′′0 +
n
∑
i=m+1
c′′i xi = f (3.24)
3.9 Simplex Algorithm 141
Since the variables xm+1, xm+2, . . . , xn are presently zero and are constrained to be
nonnegative, the only way any one of them can change is to become positive. But if
c′′i > 0 for i = m + 1, m + 2, . . . , n, then increasing any xi cannot decrease the value
of the objective function f . Since no change in the nonbasic variables can cause f to
decrease, the present solution must be optimal with the optimal value of f equal to f ′′0 .
A glance over c′′i can also tell us if there are multiple optima. Let all c
′′
i
> 0,
i = m + 1, m + 2, . . . , k − 1, k + 1, . . . , n, and let c′′k = 0 for some nonbasic variable
xk. Then if the constraints allow that variable to be made positive (from its present
value of zero), no change in f results, and there are multiple optima. It is possible,
however, that the variable may not be allowed by the constraints to become positive;
this may occur in the case of degenerate solutions. Thus as a corollary to the discussion
above, we can state that a basic feasible solution is the unique optimal feasible solution
if c′′j > 0 for all nonbasic variables xj , j = m + 1, m + 2, . . . , n. If, after testing for
optimality, the current basic feasible solution is found to be nonoptimal, an improved
basic solution is obtained from the present canonical form as follows.
3.9.2 Improving a Nonoptimal Basic Feasible Solution
From the last row of Eqs. (3.21), we can write the objective function as
f = f ′′0 +
m
∑
i=1
c′′i xi +
n
∑
j=m+1
c′′jxj
= f ′′0 for the solution given by Eqs. (3.22)
(3.25)
If at least one c′′j is negative, the value of f can be reduced by making the corresponding
xj > 0. In other words, the nonbasic variable xj , for which the cost coefficient c
n
j is
negative, is to be made a basic variable in order to reduce the value of the objective
function. At the same time, due to the pivotal operation, one of the current basic
variables will become nonbasic and hence the values of the new basic variables are to be
adjusted in order to bring the value of f less than f ′′0 . If there are more than one c
′′
j < 0,
the index s of the nonbasic variable xs which is to be made basic is chosen such that
c′′s = minimum c
′′
j < 0 (3.26)
Although this may not lead to the greatest possible decrease in f (since it may not be
possible to increase xs very far), this is intuitively at least a good rule for choosing the
variable to become basic. It is the one generally used in practice because it is simple
and it usually leads to fewer iterations than just choosing any c′′j < 0. If there is a
tie-in applying Eq. (3.26), (i.e., if more than one c′′j has the same minimum value),
we select one of them arbitrarily as c′′s .
Having decided on the variable xs to become basic, we increase it from zero,
holding all other nonbasic variables zero, and observe the effect on the current basic
variables. From Eqs. (3.21), we can obtain
x1 = b
′′
1 − a
′′
1sxs, b
′′
1 ≥ 0
x2 = b
′′
2 − a
′′
2sxs, b
′′
2 ≥ 0 (3.27)
...
142 Linear Programming I: Simplex Method
xm = b
′′
m − a
′′
msxs, b
′′
m ≥ 0
f = f ′′0 + c
′′
s xs, c
′′
s < 0 (3.28)
Since c′′s < 0, Eq. (3.28) suggests that the value of xs should be made as large as
possible in order to reduce the value of f as much as possible. However, in the process
of increasing the value of xs , some of the variables xi(i = 1, 2, . . . , m) in Eqs. (3.27)
may become negative. It can be seen that if all the coefficients a′′is ≤ 0, i = 1, 2, . . . ,m,
then xs can be made infinitely large without making any xi < 0, i = 1, 2, . . . , m. In
such a case, the minimum value of f is minus infinity and the linear programming
problem is said to have an unbounded solution .
On the other hand, if at least one a′′is is positive, the maximum value that xs can
take without making xi negative is b
′′
i /a
′′
is . If there are more than one a
′′
is > 0, the
largest value x∗s that xs can take is given by the minimum of the ratios b
′′
i /a
′′
is for
which a′′is > 0. Thus
x∗s =
b′′r
a′′rs
= minimum
a′′
is
> 0
(
b′′i
a′′is
)
(3.29)
The choice of r in the case of a tie, assuming that all b′′i > 0, is arbitrary. If any b
′′
i
for which a′′is > 0 is zero in Eqs. (3.27), xs cannot be increased by any amount. Such
a solution is called a degenerate solution .
In the case of a nondegenerate basic feasible solution, a new basic feasible solu-
tion can be constructed with a lower value of the objective function as follows. By
substituting the value of x∗s given by Eq. (3.29) into Eqs. (3.27) and (3.28), we obtain
xs = x
∗
s
xi = b
′′
i − a
′′
isx
∗
s ≥ 0, i = 1, 2, . . . ,m and i = r (3.30)
xr = 0
xj = 0, j = m + 1, m + 2, . . . , n and j = s
f = f ′′0 + c
′′
s x
∗
s ≤ f
′′
0 (3.31)
which can readily be seen to be a feasible solution different from the previous one.
Since a′′rs > 0 in Eq. (3.29), a single pivot operation on the element a
′′
rs in the system
of Eqs. (3.21) will lead to a new canonical form from which the basic feasible solution
of Eqs. (3.30) can easily be deduced. Also, Eq. (3.31) shows that this basic feasible
solution corresponds to a lower objective function value compared to that of Eqs. (3.22).
This basic feasible solution can again be tested for optimality by seeing whether all
c′′i > 0 in the new canonical form. If the solution is not optimal, the entire procedure
of moving to another basic feasible solution from the present one has to be repeated.
In the simplex algorithm, this procedure is repeated in an iterative manner until the
algorithm finds either (1) a class of feasible solutions for which f → −∞ or (2) an
optimal basic feasible solution with all c′′i ≥ 0, i = 1, 2, . . . , n. Since there are only
a finite number of ways to choose a set of m basic variables out of n variables, the
iterative process of the simplex algorithm will terminate in a finite number of cycles.
The iterative process of the simplex algorithm is shown as a flowchart in Fig. 3.14.
3.9 Simplex Algorithm 143
Figure 3.14 Flowchart for finding the optimal solution by the simplex algorithm.
144 Linear Programming I: Simplex Method
Example 3.4
Maximize F = x1 + 2x2 + x3
subject to
2x1 + x2 − x3 ≤ 2
−2x1 + x2 − 5x3 ≥ −6
4x1 + x2 + x3 ≤ 6
xi ≥ 0, i = 1, 2, 3
SOLUTION We first change the sign of the objective function to convert it to a
minimization problem and the signs of the inequalities (where necessary) so as to
obtain nonnegative values of bi (to see whether an initial basic feasible solution can
be obtained readily). The resulting problem can be stated as
Minimize f = −x1 − 2x2 − x3
subject to
2x1 + x2 − x3 ≤ 2
2x1 − x2 + 5x3 ≤ 6
4x1 + x2 + x3 ≤ 6
xi ≥ 0, i = 1 to 3
By introducing the slack variables x4 ≥ 0, x5 ≥ 0, and x6 ≥ 0, the system of equations
can be stated in canonical form as
2x1 + x2 − x3 + x4 = 2
2x1 − x2 + 5x3 + x5 = 6
4x1 + x2 + x3 + x6 = 6
−x1 − 2x2 − x3 −f = 0
(E1)
where x4, x5, x6, and −f can be treated as basic variables. The basic solution corre-
sponding to Eqs. (E1) is given by
x4 = 2, x5 = 6, x6 = 6 (basic variables)
x1 = x2 = x3 = 0 (nonbasic variables) (E2)
f = 0
which can be seen to be feasible.
Since the cost coefficients corresponding to nonbasic variables in Eqs. (E1) are
negative (c′′1 = −1, c
′′
2 = −2, c
′′
3 = −1), the present solution given by Eqs. (E2) is not
optimum. To improve the present basic feasible solution, we first decide the variable
(xs) to be brought into the basis as
c′′s = min(c
′′
j < 0) = c
′′
2 = −2
3.9 Simplex Algorithm 145
Thus x2 enters the next basic set. To obtain the new canonical form, we select the pivot
element a′′rs such that
b′′r
a′′rs
= min
a′′
is
> 0
(
b′′i
a′′is
)
In the present case, s = 2 and a′′12 and a
′′
32 are ≥ 0. Since b
′′
1/a
′′
12 = 2/1 and b
′′
3/a
′′
32 =
6/1, xr = x1. By pivoting an a
′′
12, the new system of equations can be obtained as
2x1 + 1x2 − x3 + x4 = 2
4x1 + 0x2 + 4x3 + x4 + x5 = 8
2x1 + 0x2 + 2x3 − x4 + x6 = 4
3x1 + 0x2 − 3x3 + 2x4 − f = 4
(E3)
The basic feasible solution corresponding to this canonical form is
x2 = 2, x5 = 8, x6 = 4 (basic variables)
x1 = x3 = x4 = 0 (nonbasic variables) (E4)
f = −4
Since c′′3 = −3, the present solution is not optimum. As c
′′
s = min(c
′′
i < 0) = c
′′
3 , xs = x3
enters the next basis.
To find the pivot element a′′rs , we find the ratios b
′′
i /a
′′
is for a
′′
is
> 0. In Eqs. (E3),
only a′′23 and a
′′
33 are > 0, and hence
b′′2
a′′23
=
8
4
and
b′′3
a′′33
=
4
2
Since both these ratios are same, we arbitrarily select a′′23 as the pivot element. Pivoting
on a′′23 gives the following canonical system of equations:
3x1 + 1x2 + 0x3 +
5
4
x4 +
1
4
x5 = 4
1x1 + 0x2 + 1x3 +
1
4
x4 +
1
4
x5 = 2
0x1 + 0x2 + 0x3 −
3
2
x4 −
1
2
x5 + x6 = 0
6x1 + 0x2 + 0x3 +
11
4
x4 +
3
4
x5 − f = 10
(E5)
The basic feasible solution corresponding to this canonical system is given by
x2 = 4, x3 = 2, x6 = 0 (basic variables)
x1 = x4 = x5 = 0 (nonbasic variables) (E6)
f = −10
Since all c′′i are ≥ 0 in the present canonical form, the solution given in (E6) will be
optimum. Usually, starting with Eqs. (E1), all the computations are done in a tableau
146 Linear Programming I: Simplex Method
form as shown below:
Basic Variables b
′′
i /a
′′
is for
variables x1 x2 x3 x4 x5 x6 −f b
′′
i a
′′
is > 0
x4 2 1
Pivot
element
−1 1 0 0 0 2 2 ← Smaller one
(x4 drops from
next basis)
x5 2 −1 5 0 1 0 0 6
x6 4 1 1 0 0 1 0 6 6
−f −1 −2 −1 0 0 0 1 0
↑
Most negative c′′i (x2 enters next basis)
Result of pivoting:
x2 2 1 −1 1 0 0 0 2
x5 4 0 4
Pivot
element
1 1 0 0 8 2 (Select this
arbitrarily. x5
drops from next
basis)
x6 2 0 2 −1 0 1 0 4 2
−f 3 0 −3 2 0 0 1 4
↑
Most negative c′′i (x3 enters the next basis)
Result of pivoting:
x2 3 1 0
5
4
1
4
0 0 4
x3 1 0 1
1
4
1
4
0 0 2
x6 0 0 0 −
3
2
− 1
2
1 0 0
−f 6 0 0 11
4
3
4
0 1 10
All c′′i are ≥ 0 and hence the present solution is optimum.
Example 3.5 Unbounded Solution
Minimize f = −3x1 − 2x2
subject to
x1 − x2 ≤ 1
3x1 − 2x2 ≤ 6
x1 ≥ 0, x2 ≥ 0
3.9 Simplex Algorithm 147
SOLUTION Introducing the slack variables x3 ≥ 0 and x4 ≥ 0, the given system of
equations can be written in canonical form as
x1 − x2 + x3 = 1
3x1 − 2x2 + x4 = 6
−3x1 − 2x2 −f = 0
(E1)
The basic feasible solution corresponding to this canonical form is given by
x3 = 1, x4 = 6 (basic variables)
x1 = x2 = 0 (nonbasic variables) (E2)
f = 0
Since the cost coefficients corresponding to the nonbasic variables are negative, the
solution given by Eq. (E2) is not optimum. Hence the simplex procedure is applied to
the canonical system of Eqs. (E1) starting from the solution, Eqs. (E2). The computa-
tions are done in tableau form as shown below:
Basic Variables b
′′
i /a
′′
is for
variables x1 x2 x3 x4 −f b
′′
i a
′′
is > 0
x3 1
Pivot
element
−1 1 0 0 1 1 ← Smaller value
(x3 leaves the
basis)
x4 3 −2 0 1 0 6 2
−f −3 −2 0 0 1 0
↑
Most negative c′′i (x1 enters the next basis)
Result of pivoting:
x1 1 −1 1 0 0 1
x4 0 1
Pivot
element
−3 1 0 3 3 (x4 leaves the
basis)
−f 0 −5 3 0 1 3
↑
Most negative c′′i (x2 enters the next basis)
Result of pivoting:
x1 1 0 −2 1 0 4 Both a
′′
is are
negative (i.e.,
no variable
leaves the basis)
x2 0 1 −3 1 0 3
−f 0 0 −12 5 1 18
↑
Most negative c′′i (x3 enters the basis)
148 Linear Programming I: Simplex Method
At this stage we notice that x3 has the most negative cost coefficient and hence
it should be brought into the next basis. However, since all the coefficients a′′i3 are
negative, the value of f can be decreased indefinitely without violating any of the
constraints if we bring x3 into the basis. Hence the problem has no bounded solution.
In general, if all the coefficients of the entering variable xs(a
′′
is) have negative or
zero values at any iteration, we can conclude that the problem has an unbounded
solution.
Example 3.6 Infinite Number of Solutions To demonstrate how a problem having
infinite number of solutions can be solved, Example 3.2 is again considered with a
modified objective function:
Minimize f = −40x1−100x2
subject to
10x1 + 5x2 ≤ 2500
4x1 + 10x2 ≤ 2000
2x1 + 3x2 ≤ 900
x1 ≥ 0, x2 ≥ 0
SOLUTION By adding the slack variables x3 ≥ 0, x4 ≥ 0 and x5 ≥ 0, the equations
can be written in canonical form as follows:
10x1 + 5x2 + x3 = 2500
4x1 + 10x2 + x4 = 2000
2x1 + 3x2 + x5 = 900
−40x1 − 100x2 − f = 0
The computations can be done in tableau form as shown below:
Basic Variables
variables x1 x2 x3 x4 x5 −f b
′′
i b
′′
i /a
′′
is for a
′′
is > 0
x3 10 5 1 0 0 0 2,500 500
x4 4 10
Pivot
element
0 1 0 0 2,000 200 ← Smaller value
(x4 leaves the
basis)
x5 2 3 0 0 1 0 900 300
−f −40 −100 0 0 0 1 0
↑
Most negative c′′i (x2 enters the basis)
3.9 Simplex Algorithm 149
Result of pivoting:
x3 8 0 1 −
1
2
0 0 1,500
x2
4
10
1 0 1
10
0 0 200
x5
8
10
0 0 − 3
10
1 0 300
−f 0 0 0 10 0 1 20,000
Since all c′′i ≥ 0, the present solution is optimum. The optimum values are
given by
x2 = 200, x3 = 1500, x5 = 300 (basic variables)
x1 = x4 = 0 (nonbasic variables)
fmin = −20,000
Important note: It can be observed from the last row of the preceding tableau that
the cost coefficient corresponding to the nonbasic variable x1(c
′′
1) is zero. This is an
indication that an alternative solution exists. Here x1 can be brought into the basis and
the resulting new solution will also be an optimal basic feasible solution. For example,
introducing x1 into the basis in place of x3 (i.e., by pivoting on a
′′
13), we obtain the
new canonical system of equations as shown in the following tableau:
Basic Variables b
′′
i /a
′′
is for
variables x1 x2 x3 x4 x5 −f b
′′
i a
′′
is > 0
x1 1 0
1
8
− 1
16
0 0 1500
8
x2 0 1 −
1
20
1
8
0 0 125
x5 0 0 −
1
10
− 1
4
1 0 150
−f 0 0 0 10 0 1 20,000
The solution corresponding to this canonical form is given by
x1 =
1500
8
, x2 = 125, x5 = 150 (basic variables)
x3 = x4 = 0 (nonbasic variables)
fmin = −20,000
Thus the value of f has not changed compared to the preceding value since x1 has a
zero cost coefficient in the last row of the preceding tableau. Once two basic (optimal)
feasible solutions, namely,
X1 =













0
200
1500
0
300













and X2 =















1500
8
125
0
0
150















150 Linear Programming I: Simplex Method
are known, an infinite number of nonbasic (optimal) feasible solutions can be obtained
by taking any weighted average of the two solutions as
X∗ = λX1 + (1 − λ)X2
X∗ =

















x∗1
x∗2
x∗3
x∗4
x∗5

















=

















(1 − λ) 1500
8
200λ + (1 − λ)125
1500λ
0
300λ + (1 − λ)150

















=

















(1 − λ) 1500
8
125 + 75λ
1500λ
0
150 + 150λ

















0 ≤ λ ≤ 1
It can be verified that the solution X∗ will always give the same value of −20,000 for
f for all 0 ≤ λ ≤ 1.
3.10 TWO PHASES OF THE SIMPLEX METHOD
The problem is to find nonnegative values for the variables x1, x2, . . . , xn that satisfy
the equations
a11x1 + a12x2 + · · · + a1nxn = b1
a21x1 + a22x2 + · · · + a2nxn = b2
...
am1x1 + am2x2 + · · · + amnxn = bm
(3.32)
and minimize the objective function given by
c1x1 + c2x2 + · · · + cnxn = f (3.33)
The general problems encountered in solving this problem are
1. An initial feasible canonical form may not be readily available. This is the case
when the linear programming problem does not have slack variables for some
of the equations or when the slack variables have negative coefficients.
2. The problem may have redundancies and/or inconsistencies, and may not be
solvable in nonnegative numbers.
The two-phase simplex method can be used to solve the problem.
Phase I of the simplex method uses the simplex algorithm itself to find whether
the linear programming problem has a feasible solution. If a feasible solution exists,
it provides a basic feasible solution in canonical form ready to initiate phase II of the
method. Phase II, in turn, uses the simplex algorithm to find whether the problem has
a bounded optimum. If a bounded optimum exists, it finds the basic feasible solution
that is optimal. The simplex method is described in the following steps.
3.10 Two Phases of the Simplex Method 151
1. Arrange the original system of Eqs. (3.32) so that all constant terms bi are
positive or zero by changing, where necessary, the signs on both sides of any
of the equations.
2. Introduce to this system a set of artificial variables y1, y2, . . . , ym (which serve
as basic variables in phase I), where each yi ≥ 0, so that it becomes
a11x1 + a12x2 + · · · + a1nxn + y1 = b1
a21x1 + a22x2 + · · · + a2nxn + y2 = b2
...
am1x1 + am2x2 + · · · + amnxn + ym = bm
bi ≥ 0
(3.34)
Note that in Eqs. (3.34), for a particular i, the aij ’s and the bi may be the
negative of what they were in Eq. (3.32) because of step 1.
The objective function of Eq. (3.33) can be written as
c1x1 + c2x2 + · · · + cnxn + (−f ) = 0 (3.35)
3. Phase I of the method . Define a quantity w as the sum of the artificial variables
w = y1 + y2 + · · · + ym (3.36)
and use the simplex algorithm to find xi ≥ 0 (i = 1, 2, . . . , n) and yi ≥ 0 (i =
1, 2, . . . , m) which minimize w and satisfy Eqs. (3.34) and (3.35). Consequently,
consider the array
a11x1 + a12x2 + · · · + a1nxn + y1 = b1
a21x1 + a22x2 + · · · + a2nxn + y2 = b2
...
...
am1x1 + am2x2 + · · · + amnxn + ym = bm
c1x1 + c2x2 + · · · + cnxn + (−f ) = 0
y1 + y2 + · · · + ym + (−w) = 0
(3.37)
This array is not in canonical form; however, it can be rewritten as a canonical
system with basic variables y1, y2, . . . , ym, −f , and −w by subtracting the sum
of the first m equations from the last to obtain the new system
a11x1 + a12x2 + · · · + a1nxn + y1 = b1
a21x1 + a22x2 + · · · + a2nxn + y2 = b2
...
...
am1x1 + am2x2 + · · · + amnxn + ym = bm
c1x1 + c2x2 + · · · + cnxn + (−f ) = 0
d1x1 + d2x2 + · · · + dnxn + (−w) = −w0
(3.38)
152 Linear Programming I: Simplex Method
where
di = −(a1i + a2i + · · · + ami), i = 1, 2, . . . , n (3.39)
−w0 = −(b1 + b2 + · · · + bm) (3.40)
Equations (3.38) provide the initial basic feasible solution that is necessary for
starting phase I.
4. In Eq. (3.37), the expression of w, in terms of the artificial variables
y1, y2, . . . , ym is known as the infeasibility form. w has the property that if
as a result of phase I, with a minimum of w > 0, no feasible solution exists
for the original linear programming problem stated in Eqs. (3.32) and (3.33),
and thus the procedure is terminated. On the other hand, if the minimum of
w = 0, the resulting array will be in canonical form and hence initiate phase
II by eliminating the w equation as well as the columns corresponding to each
of the artificial variables y1, y2, . . . , ym from the array.
5. Phase II of the method . Apply the simplex algorithm to the adjusted canonical
system at the end of phase I to obtain a solution, if a finite one exists, which
optimizes the value of f .
The flowchart for the two-phase simplex method is given in Fig. 3.15.
Example 3.7
Minimize f = 2x1 + 3x2 + 2x3−x4 + x5
subject to the constraints
3x1 − 3x2 + 4x3 + 2x4 − x5 = 0
x1 + x2 + x3 + 3x4 + x5 = 2
xi ≥ 0, i = 1 to 5
SOLUTION
Step 1 As the constants on the right-hand side of the constraints are already nonneg-
ative, the application of step 1 is unnecessary.
Step 2 Introducing the artificial variables y1 ≥ 0 and y2 ≥ 0, the equations can be
written as follows:
3x1 − 3x2 + 4x3 + 2x4 − x5 + y1 = 0
x1 + x2 + x3 + 3x4 + x5 + y2 = 2
2x1 + 3x2 + 2x3 − x4 + x5 − f = 0
(E1)
Step 3 By defining the infeasibility form w as
w = y1 + y2
3.10 Two Phases of the Simplex Method 153
Figure 3.15 Flowchart for the two-phase simplex method.
154 Linear Programming I: Simplex Method
Figure 3.15 (continued )
the complete array of equations can be written as
3x1 − 3x2 + 4x3 + 2x4 − x5 + y1 = 0
x1 + x2 + x3 + 3x4 + x5 + y2 = 2
2x1 + 3x2 + 2x3 − x4 + x5 − f = 0
y1 + y2 − w = 0
(E2)
3.10 Two Phases of the Simplex Method 155
This array can be rewritten as a canonical system with basic variables as y1,
y2, −f , and −w by subtracting the sum of the first two equations of (E2) from
the last equation of (E2). Thus the last equation of (E2) becomes
−4x1 + 2x2 − 5x3 − 5x4 + 0x5 − w = −2 (E3)
Since this canonical system [first three equations of (E2), and (E3)] provides
an initial basic feasible solution, phase I of the simplex method can be started.
The phase I computations are shown below in tableau form.
Artificial Value of
Basic Admissible variables variables b′′i /a
′′
is for
variables x1 x2 x3 x4 x5 y1 y2 b
′′
i a
′′
is
> 0
y1 3 −3 4 2
Pivot
element
−1 1 0 0 0 ← Smaller value
(y1 drops from
next basis)
y2 1 1 1 3 1 0 1 2
2
3
−f 2 3 2 −1 1 0 0 0
−w −4 2 −5 −5 0 0 0 −2
↑ ↑
Most negative
Since there is a tie between d ′′3 and d
′′
4 , d
′′
4 is selected arbitrarily as the most
negative d ′′i for pivoting (x4 enters the next basis).
Result of pivoting:
x4
3
2
− 3
2
2 1 − 1
2
1
2
0 0
y2 −
7
2
11
2
Pivot
element
−5 0 5
2
− 3
2
1 2 1
11
← y2 drops
from next
basis
−f 7
2
3
2
4 0 1
2
1
2
0 0
−w 7
2
− 11
2
5 0 − 5
2
5
2
0 −2
↑
Most negative d ′′i (x2 enters next basis)
Result of pivoting (since y1 and y2 are dropped from basis, the columns cor-
responding to them need not be filled):
x4
6
11
0 7
11
1 2
11
Dropped 6
11
6
2
x2 −
7
11
1 − 10
11
0 5
11
4
11
4
5
−f 98
22
0 118
22
0 − 4
22
− 6
11
−w 0 0 0 0 0 0
156 Linear Programming I: Simplex Method
Step 4 At this stage we notice that the present basic feasible solution does not contain
any of the artificial variables y1 and y2, and also the value of w is reduced to
0. This indicates that phase I is completed.
Step 5 Now we start phase II computations by dropping the w row from further
consideration. The results of phase II are again shown in tableau form:
Basic Original variables Constant Value of b
′′
i /a
′′
is for
variables x1 x2 x3 x4 x5 b
′′
i a
′′
is > 0
x4
6
11
0 7
11
1 2
11
6
11
6
2
x2 −
7
11
1 − 10
11
0 5
11
Pivot
element
4
11
4
5
← Smaller value
(x2 drops from
next basis)
−f 98
22
0 118
22
0 − 4
22
− 6
11
↑
Most negative c′′i (x5 enters next basis)
Result of pivoting:
x4
4
5
− 2
5
1 1 0 2
5
x5 −
7
5
11
5
−2 0 1 4
5
−f 21
5
2
5
5 0 0 − 2
5
Now, since all c′′i are nonnegative, phase II is completed. The (unique) optimal
solution is given by
x1 = x2 = x3 = 0 (nonbasic variables)
x4 =
2
5
, x5 =
4
5
(basic variables)
fmin =
2
5
3.11 MATLAB SOLUTION OF LP PROBLEMS
The solution of linear programming problems, using simplex method, can be found as
illustrated by the following example.
Example 3.8 Find the solution of the following linear programming problem using
MATLAB (simplex method):
Minimize f = −x1 − 2x2 − x3
subject to
2x1 + x2 − x3 ≤ 2
2x1 − x2 + 5x3 ≤ 6
3.11 MATLAB Solution of LP Problems 157
4x1 + x2 + x3 ≤ 6
xi ≥ 0; i = 1, 2, 3
SOLUTION
Step 1 Express the objective function in the form f (x) = f T x and identify the vectors
x and f as
x =



x1
x2
x3



and f =



−1
−2
−1



Express the constraints in the form Ax ≤ b and identify the matrix A and the
vector b as
A =


2 1 −1
2 −1 5
4 1 1

 and b =



2
6
6



Step 2 Use the command for executing linear programming program using simplex
method as indicated below:
clc
clear all
f=[-1;-2;-1];
A=[2 1 - 1;
2 -1 5;
4 1 1];
b=[2;6;6];
lb=zeros(3,1);
Aeq=[];
beq=[];
options = optimset('LargeScale', 'off', 'Simplex', 'on');
[x,fval,exitflag,output] = linprog(f,A,b,Aeq,beq,lb,[],[],•
optimset('Display','iter'))
This produces the solution or output as follows:
Optimization terminated.
x=
0
4
2
fval =
-10
exitflag =
1
output =
iterations:3
algorithm: 'medium scale: simplex'
158 Linear Programming I: Simplex Method
cgiterations: []
message: 'Optimization terminated.'
REFERENCES AND BIBLIOGRAPHY
3.1 G. B. Dantzig, Linear Programming and Extensions , Princeton University Press,
Princeton, NJ, 1963.
3.2 W. J. Adams, A. Gewirtz, and L. V. Quintas, Elements of Linear Programming , Van
Nostrand Reinhold, New York, 1969.
3.3 W.W. Garvin, Introduction to Linear Programming , McGraw-Hill, New York, 1960.
3.4 S. I. Gass, Linear Programming: Methods and Applications , 5th ed., McGraw-Hill, New
York, 1985.
3.5 G. Hadley, Linear Programming , Addison-Wesley, Reading, MA, 1962.
3.6 S. Vajda, An Introduction to Linear Programming and the Theory of Games , Wiley, New
York, 1960.
3.7 W. Orchard-Hays, Advanced Linear Programming Computing Techniques , McGraw-Hill,
New York, 1968.
3.8 S. I. Gass, An Illustrated Guide to Linear Programming , McGraw-Hill, New York, 1970.
3.9 M. F. Rubinstein and J. Karagozian, Building design using linear programming, Journal
of the Structural Division, Proceedings of ASCE , Vol. 92, No. ST6, pp. 223−245, Dec.
1966.
3.10 T. Au, Introduction to Systems Engineering: Deterministic Models , Addison-Wesley,
Reading, MA, 1969.
3.11 H. A. Taha, Operations Research: An Introduction , 5th ed., Macmillan, New York, 1992.
3.12 W. F. Stoecker, Design of Thermal Systems , 3rd ed., McGraw-Hill, New York, 1989.
3.13 K. G. Murty, Linear Programming , Wiley, New York, 1983.
3.14 W. L. Winston, Operations Research: Applications and Algorithms , 2nd ed., PWS-Kent,
Boston, 1991.
3.15 R. M. Stark and R. L. Nicholls, Mathematical Foundations for Design: Civil Engineering
Systems , McGraw-Hill, New York, 1972.
3.16 N. Karmarkar, A new polynomial-time algorithm for linear programming, Combinatorica ,
Vol. 4, No. 4, pp. 373−395, 1984.
3.17 A. Maass et al., Design of Water Resources Systems , Harvard University Press,
Cambridge, MA, 1962.
REVIEW QUESTIONS
3.1 Define a line segment in n-dimensional space.
3.2 What happens when m = n in a (standard) LP problem?
3.3 How many basic solutions can an LP problem have?
3.4 State an LP problem in standard form.
3.5 State four applications of linear programming.
3.6 Why is linear programming important in several types of industries?
3.7 Define the following terms: point, hyperplane, convex set, extreme point.
Review Questions 159
3.8 What is a basis?
3.9 What is a pivot operation?
3.10 What is the difference between a convex polyhedron and a convex polytope?
3.11 What is a basic degenerate solution?
3.12 What is the difference between the simplex algorithm and the simplex method?
3.13 How do you identify the optimum solution in the simplex method?
3.14 Define the infeasibility form.
3.15 What is the difference between a slack and a surplus variable?
3.16 Can a slack variable be part of the basis at the optimum solution of an LP problem?
3.17 Can an artificial variable be in the basis at the optimum point of an LP problem?
3.18 How do you detect an unbounded solution in the simplex procedure?
3.19 How do you identify the presence of multiple optima in the simplex method?
3.20 What is a canonical form?
3.21 Answer true or false:
(a) The feasible region of an LP problem is always bounded.
(b) An LP problem will have infinite solutions whenever a constraint is redundant.
(c) The optimum solution of an LP problem always lies at a vertex.
(d) A linear function is always convex.
(e) The feasible space of some LP problems can be nonconvex.
(f) The variables must be nonnegative in a standard LP problem.
(g) The optimal solution of an LP problem can be called the optimal basic solution.
(h) Every basic solution represents an extreme point of the convex set of feasible solu-
tions.
(i) We can generate all the basic solutions of an LP problem using pivot operations.
(j) The simplex algorithm permits us to move from one basic solution to another basic
solution.
(k) The slack and surplus variables can be unrestricted in sign.
(l) An LP problem will have an infinite number of feasible solutions.
(m) An LP problem will have an infinite number of basic feasible solutions.
(n) The right-hand-side constants can assume negative values during the simplex proce-
dure.
(o) All the right-hand-side constants can be zero in an LP problem.
(p) The cost coefficient corresponding to a nonbasic variable can be positive in a basic
feasible solution.
(q) If all elements in the pivot column are negative, the LP problem will not have a
feasible solution.
(r) A basic degenerate solution can have negative values for some of the variables.
(s) If a greater-than or equal-to type of constraint is active at the optimum point, the
corresponding surplus variable must have a positive value.
(t) A pivot operation brings a nonbasic variable into the basis.
160 Linear Programming I: Simplex Method
(u) The optimum solution of an LP problem cannot contain slack variables in the basis.
(v) If the infeasibility form has a nonzero value at the end of phase I, it indicates an
unbounded solution to the LP problem.
(w) The solution of an LP problem can be a local optimum.
(x) In a standard LP problem, all the cost coefficients will be positive.
(y) In a standard LP problem, all the right-hand-side constants will be positive.
(z) In a LP problem, the number of inequality constraints cannot exceed the number of
variables.
(aa) A basic feasible solution cannot have zero value for any of the variables.
PROBLEMS
3.1 State the following LP problem in standard form:
Maximize f = −2x1 − x2 + 5x3
subject to
x1 − 2x2 + x3 ≤ 8
3x1 − 2x2 ≥ −18
2x1 + x2 − 2x3 ≤ −4
3.2 State the following LP problem in standard form:
Maximize f = x1 − 8x2
subject to
3x1 + 2x2 ≥ 6
9x1 + 7x2 ≤ 108
2x1 − 5x2 ≥ −35
x1, x2 unrestricted in sign
3.3 Solve the following system of equations using pivot operations:
6x1 − 2x2 + 3x3 = 11
4x1 + 7x2 + x3 = 21
5x1 + 8x2 + 9x3 = 48
3.4 It is proposed to build a reservoir of capacity x1 to better control the supply of water to
an irrigation district [3.15, 3.17]. The inflow to the reservoir is expected to be 4.5 × 106
acre-ft during the wet (rainy) season and 1.1 × 106 acre-ft during the dry (summer)
season. Between the reservoir and the irrigation district, one stream (A) adds water to
and another stream (B) carries water away from the main stream, as shown in Fig. 3.16.
Stream A adds 1.2 × 106 and 0.3 × 106 acre-ft of water during the wet and dry seasons,
respectively. Stream B takes away 0.5 × 106 and 0.2 × 106 acre-ft of water during the
Problems 161
Figure 3.16 Reservoir in an irrigation district.
wet and dry seasons, respectively. Of the total amount of water released to the irrigation
district per year (x2), 30% is to be released during the wet season and 70% during the
dry season. The yearly cost of diverting the required amount of water from the main
stream to the irrigation district is given by 18(0.3x2) + 12(0.7x2). The cost of building
and maintaining the reservoir, reduced to an yearly basis, is given by 25x1. Determine
the values of x1 and x2 to minimize the total yearly cost.
3.5 Solve the following system of equations using pivot operations:
4x1 − 7x2 + 2x3 = −8
3x1 + 4x2 − 5x3 = −8
5x1 + x2 − 8x3 = −34
162 Linear Programming I: Simplex Method
3.6 What elementary operations can be used to transform
2x1 + x2 + x3 = 9
x1 + x2 + x3 = 6
2x1 + 3x2 + x3 = 13
into
x1 = 3
x2 = 2
x1 + 3x2 + x3 = 10
Find the solution of this system by reducing into canonical form.
3.7 Find the solution of the following LP problem graphically:
Maximize f = 2x1 + 6x2
subject to
−x1 + x2 ≤ 1
2x1 + x2 ≤ 2
x1 ≥ 0, x2 ≥ 0
3.8 Find the solution of the following LP problem graphically:
Minimize f = −3x1 + 2x2
subject to
0 ≤ x1 ≤ 4
1 ≤ x2 ≤ 6
x1 + x2 ≤ 5
3.9 Find the solution of the following LP problem graphically:
Minimize f = 3x1 + 2x2
subject to
8x1 + x2 ≥ 8
2x1 + x2 ≥ 6
x1 + 3x2 ≥ 6
x1 + 6x2 ≥ 8
x1 ≥ 0, x2 ≥ 0
Problems 163
3.10 Find the solution of the following problem by the graphical method:
Minimize f = x21x
2
2
subject to
x31x
2
2 ≥ e
3
x1x
4
2 ≥ e
4
x21x
3
2 ≤ e
x1 ≥ 0, x2 ≥ 0
where e is the base of natural logarithms.
3.11 Prove Theorem 3.6.
For Problems 3.12 to 3.42, use a graphical procedure to identify (a) the feasible region,
(b) the region where the slack (or surplus) variables are zero, and (c) the optimum
solution.
3.12 Maximize f = 6x + 7y
subject to
7x + 6y ≤ 42
5x + 9y ≤ 45
x − y ≤ 4
x ≥ 0, y ≥ 0
3.13 Rework Problem 3.12 when x and y are unrestricted in sign.
3.14 Maximize f = 19x + 7y
subject to
7x + 6y ≤ 42
5x + 9y ≤ 45
x − y ≤ 4
x ≥ 0, y ≥ 0
3.15 Rework Problem 3.14 when x and y are unrestricted in sign.
3.16 Maximize f = x + 2y
subject to
x − y ≥ −8
5x − y ≥ 0
x + y ≥ 8
164 Linear Programming I: Simplex Method
−x + 6y ≥ 12
5x + 2y ≤ 68
x ≤ 10
x ≥ 0, y ≥ 0
3.17 Rework Problem 3.16 by changing the objective to Minimize f = x − y.
3.18 Maximize f = x + 2y
subject to
x − y ≥ −8
5x − y ≥ 0
x + y ≥ 8
−x + 6y ≥ 12
5x + 2y ≥ 68
x ≤ 10
x ≥ 0, y ≥ 0
3.19 Rework Problem 3.18 by changing the objective to Minimize f = x − y.
3.20 Maximize f = x + 3y
subject to
−4x + 3y ≤ 12
x + y ≤ 7
x − 4y ≤ 2
x ≥ 0, y ≥ 0
3.21 Minimize f = x + 3y
subject to
−4x + 3y ≤ 12
x + y ≤ 7
x − 4y ≤ 2
x and y are unrestricted in sign
3.22 Rework Problem 3.20 by changing the objective to Maximize f = x + y.
Problems 165
3.23 Maximize f = x + 3y
subject to
−4x + 3y ≤ 12
x + y ≤ 7
x − 4y ≥ 2
x ≥ 0, y ≥ 0
3.24 Minimize f = x − 8y
subject to
3x + 2y ≥ 6
x − y ≤ 6
9x + 7y ≤ 108
3x + 7y ≤ 70
2x − 5y ≥ −35
x ≥ 0, y ≥ 0
3.25 Rework Problem 3.24 by changing the objective to Maximize f = x − 8y.
3.26 Maximize f = x − 8y
subject to
3x + 2y ≥ 6
x − y ≤ 6
9x + 7y ≤ 108
3x + 7y ≤ 70
2x − 5y ≥ −35
x ≥ 0, y is unrestricted in sign
3.27 Maximize f = 5x − 2y
subject to
3x + 2y ≥ 6
x − y ≤ 6
166 Linear Programming I: Simplex Method
9x + 7y ≤ 108
3x + 7y ≤ 70
2x − 5y ≥ −35
x ≥ 0, y ≥ 0
3.28 Minimize f = x − 4y
subject to
x − y ≥ −4
4x + 5y ≤ 45
5x − 2y ≤ 20
5x + 2y ≤ 10
x ≥ 0, y ≥ 0
3.29 Maximize f = x − 4y
subject to
x − y ≥ −4
4x + 5y ≤ 45
5x − 2y ≤ 20
5x + 2y ≥ 10
x ≥ 0, y is unrestricted in sign
3.30 Minimize f = x−4y
subject to
x − y ≥ −4
4x + 5y ≤ 45
5x − 2y ≤ 20
5x + 2y ≥ 10
x ≥ 0, y ≥ 0
3.31 Rework Problem 3.30 by changing the objective to Maximize f = x − 4y.
3.32 Minimize f = 4x + 5y
Problems 167
subject to
10x + y ≥ 10
5x + 4y ≥ 20
3x + 7y ≥ 21
x + 12y ≥ 12
x ≥ 0, y ≥ 0
3.33 Rework Problem 3.32 by changing the objective to Maximize f = 4x + 5y.
3.34 Rework Problem 3.32 by changing the objective to Minimize f = 6x + 2y.
3.35 Minimize f = 6x + 2y
subject to
10x + y ≥ 10
5x + 4y ≥ 20
3x + 7y ≥ 21
x + 12y ≥ 12
x and y are unrestricted in sign
3.36 Minimize f = 5x + 2y
subject to
3x + 4y ≤ 24
x − y ≤ 3
x + 4y ≥ 4
3x + y ≥ 3
x ≥ 0, y ≥ 0
3.37 Rework Problem 3.36 by changing the objective to Maximize f = 5x + 2y.
3.38 Rework Problem 3.36 when x is unrestricted in sign and y ≥ 0.
3.39 Maximize f = 5x + 2y
168 Linear Programming I: Simplex Method
subject to
3x + 4y ≤ 24
x − y ≤ 3
x + 4y ≤ 4
3x + y ≥ 3
x ≥ 0, y ≥ 0
3.40 Maximize f = 3x + 2y
subject to
9x + 10y ≤ 330
21x − 4y ≥ −36
x + 2y ≥ 6
6x − y ≤ 72
3x + y ≤ 54
x ≥ 0, y ≥ 0
3.41 Rework Problem 3.40 by changing the constraint x + 2y ≥ 6 to x + 2y ≤ 6.
3.42 Maximize f = 3x + 2y
subject to
9x + 10y ≤ 330
21x − 4y ≥ −36
x + 2y ≤ 6
6x − y ≤ 72
3x + y ≥ 54
x ≥ 0, y ≥ 0
3.43 Maximize f = 3x + 2y
subject to
21x − 4y ≥ −36
x + 2y ≥ 6
6x − y ≤ 72
x ≥ 0, y ≥ 0
Problems 169
3.44 Reduce the system of equations
2x1 + 3x2 − 2x3 − 7x4 = 2
x1 + x2 − x3 + 3x4 = 12
x1 − x2 + x3 + 5x4 = 8
into a canonical system with x1, x2, and x3 as basic variables. From this derive all other
canonical forms.
3.45 Maximize f = 240x1 + 104x2 + 60x3 + 19x4
subject to
20x1 + 9x2 + 6x3 + x4 ≤ 20
10x1 + 4x2 + 2x3 + x4 ≤ 10
xi ≥ 0, i = 1 to 4
Find all the basic feasible solutions of the problem and identify the optimal solution.
3.46 A progressive university has decided to keep its library open round the clock and gathered
that the following number of attendants are required to reshelve the books:
Time of day Minimum number of
(hours) attendants required
0–4 4
4–8 7
8–12 8
12–16 9
16–20 14
20–24 3
If each attendant works eight consecutive hours per day, formulate the problem of finding
the minimum number of attendants necessary to satisfy the requirements above as a LP
problem.
3.47 A paper mill received an order for the supply of paper rolls of widths and lengths as
indicated below:
Number of rolls Width of roll Length
ordered (m) (m)
1 6 100
1 8 300
1 9 200
The mill produces rolls only in two standard widths, 10 and 20 m. The mill cuts the
standard rolls to size to meet the specifications of the orders. Assuming that there is no
170 Linear Programming I: Simplex Method
limit on the lengths of the standard rolls, find the cutting pattern that minimizes the trim
losses while satisfying the order above.
3.48 Solve the LP problem stated in Example 1.6 for the following data: l = 2 m,
W1 = 3000 N, W2 = 2000 N, W3 = 1000 N, and w1 = w2 = w3 = 200 N.
3.49 Find the solution of Problem 1.1 using the simplex method.
3.50 Find the solution of Problem 1.15 using the simplex method.
3.51 Find the solution of Example 3.1 using (a) the graphical method and (b) the simplex
method.
3.52 In the scaffolding system shown in Fig. 3.17, loads x1 and x2 are applied on beams 2 and
3, respectively. Ropes A and B can carry a load of W1 = 300 lb each; the middle ropes,
C and D, can withstand a load of W2 = 200 lb each, and ropes E and F are capable
of supporting a load W3 = 100 lb each. Formulate the problem of finding the loads x1
and x2 and their location parameters x3 and x4 to maximize the total load carried by the
system, x1 + x2, by assuming that the beams and ropes are weightless.
3.53 A manufacturer produces three machine parts, A, B, and C. The raw material costs
of parts A, B, and C are $5, $10, and $15 per unit, and the corresponding prices of
the finished parts are $50, $75, and $100 per unit. Part A requires turning and drilling
operations, while part B needs milling and drilling operations. Part C requires turning
and milling operations. The number of parts that can be produced on various machines
per day and the daily costs of running the machines are given below:
Number of parts that can be produced on
Machine part Turning lathes Drilling machines Milling machines
A 15 15
B 20 30
C 25 10
Cost of running the
machines per day $250 $200 $300
Formulate the problem of maximizing the profit.
Figure 3.17 Scaffolding system with three beams.
Problems 171
Solve Problems 3.54–3.90 by the simplex method.
3.54 Problem 1.22
3.55 Problem 1.23
3.56 Problem 1.24
3.57 Problem 1.25
3.58 Problem 3.7
3.59 Problem 3.12
3.60 Problem 3.13
3.61 Problem 3.14
3.62 Problem 3.15
3.63 Problem 3.16
3.64 Problem 3.17
3.65 Problem 3.18
3.66 Problem 3.19
3.67 Problem 3.20
3.68 Problem 3.21
3.69 Problem 3.22
3.70 Problem 3.23
3.71 Problem 3.24
3.72 Problem 3.25
3.73 Problem 3.26
3.74 Problem 3.27
3.75 Problem 3.28
3.76 Problem 3.29
3.77 Problem 3.30
3.78 Problem 3.31
3.79 Problem 3.32
3.80 Problem 3.33
3.81 Problem 3.34
3.82 Problem 3.35
3.83 Problem 3.36
3.84 Problem 3.37
172 Linear Programming I: Simplex Method
3.85 Problem 3.38
3.86 Problem 3.39
3.87 Problem 3.40
3.88 Problem 3.41
3.89 Problem 3.42
3.90 Problem 3.43
3.91 The temperatures measured at various points inside a heated wall are given below:
Distance from the heated surface as a
percentage of wall thickness, xi 0 20 40 60 80 100
Temperature, ti (
◦
C) 400 350 250 175 100 50
It is decided to use a linear model to approximate the measured values as
t = a + bx (1)
where t is the temperature, x the percentage of wall thickness, and a and b the coefficients
that are to be estimated. Obtain the best estimates of a and b using linear programming
with the following objectives.
(a) Minimize the sum of absolute deviations between the measured values and those
given by Eq. (1): i |a + bxi − ti |.
(b) Minimize the maximum absolute deviation between the measured values and those
given by Eq. (1):
Max
i
|a + bxi − ti |
3.92 A snack food manufacturer markets two kinds of mixed nuts, labeled A and B. Mixed
nuts A contain 20% almonds, 10% cashew nuts, 15% walnuts, and 55% peanuts. Mixed
nuts B contain 10% almonds, 20% cashew nuts, 25% walnuts, and 45% peanuts. A
customer wants to use mixed nuts A and B to prepare a new mix that contains at least
4 lb of almonds, 5 lb of cashew nuts, and 6 lb of walnuts, for a party. If mixed nuts A
and B cost $2.50 and $3.00 per pound, respectively, determine the amounts of mixed
nuts A and B to be used to prepare the new mix at a minimum cost.
3.93 A company produces three types of bearings, B1, B2, and B3, on two machines, A1
and A2. The processing times of the bearings on the two machines are indicated in the
following table:
Processing time (min) for bearing:
Machine B1 B2 B3
A1 10 6 12
A2 8 4 4
Problems 173
The times available on machines A1 and A2 per day are 1200 and 1000 minutes, respec-
tively. The profits per unit of B1, B2, and B3 are $4, $2, and $3, respectively. The
maximum number of units the company can sell are 500, 400, and 600 for B1, B2, and
B3, respectively. Formulate and solve the problem for maximizing the profit.
3.94 Two types of printed circuit boards A and B are produced in a computer manufacturing
company. The component placement time, soldering time, and inspection time required
in producing each unit of A and B are given below:
Time required per unit (min) for:
Circuit board Component placement Soldering Inspection
A 16 10 4
B 10 12 8
If the amounts of time available per day for component placement, soldering, and inspec-
tion are 1500, 1000, and 500 person-minutes, respectively, determine the number of units
of A and B to be produced for maximizing the production. If each unit of A and B
contributes a profit of $10 and $15, respectively, determine the number of units of A
and B to be produced for maximizing the profit.
3.95 A paper mill produces paper rolls in two standard widths; one with width 20 in. and
the other with width 50 in. It is desired to produce new rolls with different widths as
indicated below:
Width (in.) Number of rolls required
40 150
30 200
15 50
6 100
The new rolls are to be produced by cutting the rolls of standard widths to minimize
the trim loss. Formulate the problem as an LP problem.
3.96 A manufacturer produces two types of machine parts, P1 and P2, using lathes and
milling machines. The machining times required by each part on the lathe and the
milling machine and the profit per unit of each part are given below:
Machine time (hr) required by
each unit on:
Machine part Lathe Milling machine Cost per unit
P1 5 2 $200
P2 4 4 $300
If the total machining times available in a week are 500 hours on lathes and 400 hours
on milling machines, determine the number of units of P1 and P2 to be produced per
week to maximize the profit.
174 Linear Programming I: Simplex Method
3.97 A bank offers four different types of certificates of deposits (CDs) as indicated below:
CD type Duration (yr) Total interest at maturity (%)
1 0.5 5
2 1.0 7
3 2.0 10
4 4.0 15
If a customer wants to invest $50,000 in various types of CDs, determine the plan that
yields the maximum return at the end of the fourth year.
3.98 The production of two machine parts A and B requires operations on a lathe (L), a
shaper (S), a drilling machine (D), a milling machine (M), and a grinding machine
(G). The machining times required by A and B on various machines are given below.
Machine time required (hours per unit) on:
Machine part L S D M G
A 0.6 0.4 0.1 0.5 0.2
B 0.9 0.1 0.2 0.3 0.3
The number of machines of different types available is given by L : 10, S : 3, D : 4,M:
6, and G: 5. Each machine can be used for 8 hours a day for 30 days in a month.
(a) Determine the production plan for maximizing the output in a month
(b) If the number of units of A is to be equal to the number of units of B, find the
optimum production plan.
3.99 A salesman sells two types of vacuum cleaners, A and B. He receives a commission of
20% on all sales, provided that at least 10 units each of A and B are sold per month.
The salesman needs to make telephone calls to make appointments with customers and
demonstrate the products in order to sell the products. The selling price of the products,
the average money to be spent on telephone calls, the time to be spent on demonstrations,
and the probability of a potential customer buying the product are given below:
Vacuum
cleaner
Selling
price per
unit
Money to be spent on
telephone calls to find
a potential customer
Time to be spent in
demonstrations to a
potential customer (hr)
Probability of a
potential customer
buying the product
A $250 $3 3 0.4
B $100 $1 1 0.8
In a particular month, the salesman expects to sell at most 25 units of A and 45 units of
B. If he plans to spend a maximum of 200 hours in the month, formulate the problem
of determining the number of units of A and B to be sold to maximize his income.
3.100 An electric utility company operates two thermal power plants, A and B, using three
different grades of coal, C1, C2, and C3. The minimum power to be generated at plants A
and B is 30 and 80 MWh, respectively. The quantities of various grades of coal required
to generate 1 MWh of power at each power plant, the pollution caused by the various
grades of coal at each power plant, and the costs of coal are given in the following table:
Problems 175
Quantity of coal
required to generate 1 Pollution Cost of coal
MWh at the power caused at at power
plant (tons) power plant plant
Coal type A B A B A B
C1 2.5 1.5 1.0 1.5 20 18
C2 1.0 2.0 1.5 2.0 25 28
C3 3.0 2.5 2.0 2.5 18 12
Formulate the problem of determining the amounts of different grades of coal to be used
at each power plant to minimize (a) the total pollution level, and (b) the total cost of
operation.
3.101 A grocery store wants to buy five different types of vegetables from four farms in a
month. The prices of the vegetables at different farms, the capacities of the farms, and
the minimum requirements of the grocery store are indicated in the following table:
Price ($/ton) of vegetable type Maximum (of all
1 2 3 4 5 types combined)
Farm (Potato) (Tomato) (Okra) (Eggplant) (Spinach) they can supply
1 200 600 1600 800 1200 180
2 300 550 1400 850 1100 200
3 250 650 1500 700 1000 100
4 150 500 1700 900 1300 120
Minimum amount
required (tons) 100 60 20 80 40
Formulate the problem of determining the buying scheme that corresponds to a
minimum cost.
3.102 A steel plant produces steel using four different types of processes. The iron ore, coal,
and labor required, the amounts of steel and side products produced, the cost information,
and the physical limitations on the system are given below:
Side
Iron ore Coal Steel products
required required Labor required Produced Produced
Process type (tons/day) (tons/day) (person-days) (tons/day) (tons/day)
1 5 3 6 4 1
2 8 5 12 6 2
3 3 2 5 2 1
4 10 7 12 6 4
Cost $50/ton $10/ton $150/person-day $350/ton $100/ton
Limitations 600 tons
available
per
month
250 tons
available
per
month
No limita-
tions on
availability
of labor
All steel
produced
can be
sold
Only 200
tons can
be sold
per month
176 Linear Programming I: Simplex Method
Assuming that a particular process can be employed for any number of days in a
30-day month, determine the operating schedule of the plant for maximizing the profit.
3.103 Solve Example 3.7 using MATLAB (simplex method).
3.104 Solve Problem 3.12 using MATLAB (simplex method).
3.105 Solve Problem 3.24 using MATLAB (simplex method).
3.106 Find the optimal solution of the LP problem stated in Problem 3.45 using MATLAB
(simplex method).
3.107 Find the optimal solution of the LP problem described in Problem 3.101 using MATLAB.
4
Linear Programming II:
Additional Topics and Extensions
4.1 INTRODUCTION
If a LP problem involving several variables and constraints is to be solved by using the
simplex method described in Chapter 3, it requires a large amount of computer storage
and time. Some techniques, which require less computational time and storage space
compared to the original simplex method, have been developed. Among these tech-
niques, the revised simplex method is very popular. The principal difference between
the original simplex method and the revised one is that in the former we transform all
the elements of the simplex tableau, while in the latter we need to transform only the
elements of an inverse matrix. Associated with every LP problem, another LP problem,
called the dual , can be formulated. The solution of a given LP problem, in many cases,
can be obtained by solving its dual in a much simpler manner.
As stated above, one of the difficulties in certain practical LP problems is that the
number of variables and/or the number of constraints is so large that it exceeds the
storage capacity of the available computer. If the LP problem has a special structure,
a principle known as the decomposition principle can be used to solve the problem
more efficiently. In many practical problems, one will be interested not only in finding
the optimum solution to a LP problem, but also in finding how the optimum solution
changes when some parameters of the problem, such as cost coefficients change. Hence
the sensitivity or postoptimality analysis becomes very important.
An important special class of LP problems, known as transportation problems ,
occurs often in practice. These problems can be solved by algorithms that are more
efficient (for this class of problems) than the simplex method. Karmarkar’s method is
an interior method and has been shown to be superior to the simplex method of Dantzig
for large problems. The quadratic programming problem is the best-behaved nonlinear
programming problem. It has a quadratic objective function and linear constraints and
is convex (for minimization problems). Hence the quadratic programming problem can
be solved by suitably modifying the linear programming techniques. All these topics
are discussed in this chapter.
4.2 REVISED SIMPLEX METHOD
We notice that the simplex method requires the computing and recording of an entirely
new tableau at each iteration. But much of the information contained in the tableau is
not used; only the following items are needed.
177Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
178 Linear Programming II: Additional Topics and Extensions
1. The relative cost coefficients cj to compute
†
cs = min(cj ) (4.1)
cs determines the variable xs that has to be brought into the basis in the next
iteration.
2. By assuming that cs < 0, the elements of the updated column
As =









a1s
a2s
...
ams









and the values of the basic variables
XB =









b1
b2
...
bm









have to be calculated. With this information, the variable xr that has to be
removed from the basis is found by computing the quantity
br
ars
= min
ais > 0
{
bi
ais
}
(4.2)
and a pivot operation is performed on ars . Thus only one nonbasic column As of
the current tableau is useful in finding xr . Since most of the linear programming
problems involve many more variables (columns) than constraints (rows), con-
siderable effort and storage is wasted in dealing with the Aj for j = s. Hence
it would be more efficient if we can generate the modified cost coefficients cj
and the column As , from the original problem data itself. The revised simplex
method is used for this purpose; it makes use of the inverse of the current basis
matrix in generating the required quantities.
Theoretical Development. Although the revised simplex method is applicable for
both phase I and phase II computations, the method is initially developed by considering
linear programming in phase II for simplicity. Later, a step-by-step procedure is given
to solve the general linear programming problem involving both phases I and II.
Let the given linear programming problem (phase II) be written in column
form as
Minimize
f (X) = c1x1 + c2x2 + · · · + cnxn (4.3)
†The modified values of bi , aij , and cj are denoted by overbars in this chapter (they were denoted by primes
in Chapter 3).
4.2 Revised Simplex Method 179
subject to
AX = A1x1 + A2x2 + · · · + Anxn = b (4.4)
X
n×1
≥ 0
n×1
(4.5)
where the j th column of the coefficient matrix A is given by
Aj
m×1
=









a1j
a2j
...
amj









Assuming that the linear programming problem has a solution, let
B = [Aj1 Aj2 · · · Ajm]
be a basis matrix with
XB
m×1
=









xj1
xj2
...
xjm









and cB
m×1
=









cj1
cj2
...
cjm









representing the corresponding vectors of basic variables and cost coefficients, respec-
tively. If XB is feasible, we have
XB = B−1b = b ≥ 0
As in the regular simplex method, the objective function is included as the (m + 1)th
equation and −f is treated as a permanent basic variable. The augmented system can
be written as
n
∑
j=1
Pjxj + Pn+1(−f ) = q (4.6)
where
Pj =













a1j
a2j
...
amj
cj













, j = 1 to n, Pn+1 =













0
0
...
0
1













and q =













b1
b2
...
bm
0













Since B is a feasible basis for the system of Eqs. (4.4), the matrix D defined by
D
m+1×m+1
= [Pj1 Pj2 · · · Pjm Pn+1] =
[
B 0
cTB 1
]
will be a feasible basis for the augmented system of Eqs. (4.6). The inverse of D can
be found to be
D−1 =
[
B−1 0
−cTBB−1 1
]
180 Linear Programming II: Additional Topics and Extensions
Definition. The row vector
cTBB
−1 = πT =









π1
π2
...
πm









T
(4.7)
is called the vector of simplex multipliers relative to the f equation. If the computations
correspond to phase I, two vectors of simplex multipliers, one relative to the f equation,
and the other relative to the w equation are to be defined as
π
T = cTBB
−1 =









π1
π2
...
πm









T
σ T = dTBB
−1 =









σ1
σ2
...
σm









T
By premultiplying each column of Eq. (4.6) by D−1, we obtain the following canonical
system of equations†:
xj1 b1
xj2 b2
... +
∑
jnonbasic
Ajxj = ...
xjm bm
−f +
∑
jnonbasic
cjxj = −f0
where
{
Aj
cj
}
= D−1Pj =
[
B−1 0
−πT 1
]{
Aj
cj
}
(4.8)
From Eq. (4.8), the updated column Aj can be identified as
Aj = B−1Aj (4.9)
†Premultiplication of Pjxj by D
−1 gives
D−1Pjxj =
[
B−1 0
−πT 1
] {
Aj
cj
}
xj
=
{
B−1Aj
−πTAj + cj
}
xj =
{
xj if xj is a basic variable
D−1Pjxj if xj is not a basic variable
4.2 Revised Simplex Method 181
and the modified cost coefficient cj as
cj = cj − πTAj (4.10)
Equations (4.9) and (4.10) can be used to perform a simplex iteration by generating
Aj and cj from the original problem data, Aj and cj .
Once Aj and cj are computed, the pivot element ars can be identified by using
Eqs. (4.1) and (4.2). In the next step, Ps is introduced into the basis and Pjr is removed.
This amounts to generating the inverse of the new basis matrix. The computational
procedure can be seen by considering the matrix:









Ps
︸︷︷︸
a1s
Pj1 Pj2 · · · Pjm Pn+1
︸ ︷︷ ︸
D
e1 e2 · · · em+1
︸ ︷︷ ︸
I
a2s
...
m + 1 × m + 1 m + 1 × m + 1 ams
cs









(4.11)
where ei is a (m + 1)-dimensional unit vector with a one in the ith row. Premultipli-
cation of the above matrix by D−1 yields


















e1 e2 · · · er · · · em+1
︸ ︷︷ ︸
I
D−1 a1s
m + 1 × m + 1 a2s
m + 1 × m + 1
...
ars
Pivot
element
...
ams
cs
m + 1 × 1


















(4.12)
By carrying out a pivot operation on ars , this matrix transforms to
[[e1 e2 · · · er−1 β er+1 · · · em+1] D−1new er ] (4.13)
where all the elements of the vector β are, in general, nonzero and the second partition
gives the desired matrix D−1new.
† It can be seen that the first partition (matrix I) is included
†This can be verified by comparing the matrix of Eq. (4.13) with the one given in Eq. (4.11). The columns
corresponding to the new basis matrix are given by
Dnew = [Pj1 Pj2 · · · Pjr−1 Ps Pjr+1 · · · Pjm Pn+1]
brought in
place of Pr
These columns are modified and can be seen to form a unit matrix in Eq. (4.13). The sequence of pivot
operations that did this must be equivalent to multiplying the original matrix, Eq. (4.11), by D−1new. Thus the
second partition of the matrix in Eq. (4.13) gives the desired D−1new.
182 Linear Programming II: Additional Topics and Extensions
only to illustrate the transformation, and it can be dropped in actual computations. Thus
in practice, we write the m + 1 × m + 2 matrix












a1s
a2s
...
D−1 ars
...
ams
cs












and carry out a pivot operation on ars . The first m + 1 columns of the resulting matrix
will give us the desired matrix D−1new.
Procedure. The detailed iterative procedure of the revised simplex method to solve
a general linear programming problem is given by the following steps.
1. Write the given system of equations in canonical form, by adding the artificial
variables xn+1, xn+2, . . . , xn+m, and the infeasibility form for phase I as shown
below:
a11x1 + a12x2 + · · · + a1nxn + xn+1 = b1
a21x1 + a22x2 + · · · + a2nxn +xn+2 = b2
...
am1x1 + am2x2 + · · · + amnxn +xn+m = bm
c1x1 + c2x2 + · · · + cnxn −f = 0
d1x1 + d2x2 + · · · + dnxn −w = −w0
(4.14)
Here the constants bi, i = 1 to m, are made nonnegative by changing, if nec-
essary, the signs of all terms in the original equations before the addition of
the artificial variables xn+i, i = 1 to m. Since the original infeasibility form is
given by
w = xn+1 + xn+2 + · · · + xn+m (4.15)
the artificial variables can be eliminated from Eq. (4.15) by adding the first m
equations of Eqs. (4.14) and subtracting the result from Eq. (4.15). The resulting
equation is shown as the last equation in Eqs. (4.14) with
dj = −
m
∑
i=1
aij and w0 =
m
∑
i=1
bi (4.16)
Equations (4.14) are written in tableau form as shown in Table 4.1.
2. The iterative procedure (cycle 0) is started with xn+1, xn+2, . . . , xn+m, −f , and
−w as the basic variables. A tableau is opened by entering the coefficients of
the basic variables and the constant terms as shown in Table 4.2. The starting
basis matrix is, from Table 4.1, B = I, and its inverse B−1 = [βij ] can also be
T
a
b
le
4
.1
O
ri
g
in
al
S
y
st
em
o
f
E
q
u
at
io
n
s
A
d
m
is
si
b
le
(o
ri
g
in
al
)
v
ar
ia
b
le
A
rt
ifi
ci
al
v
ar
ia
b
le
O
b
je
ct
iv
e
v
ar
ia
b
le
x
1
x
2
··
·x
j
··
·x
n
x
n
+
1
x
n
+
2
··
·
x
n
+
m
−
f
−
w
C
o
n
st
an
t
←−
−−
−−
−
In
it
ia
l
b
as
is
−−
−−
−−
→
a
1
1
a
1
2
a
1
j
a
1
n
1
b
1
a
2
1
a
2
2
a
2
j
a
2
n
1
b
2
      
A
1
      
A
2
      
A
j
      
A
n
. . .
. . .
. . .
. . .
a
m
1
a
m
2
a
m
j
a
m
n
1
b
m
c
1
c
2
c
j
c
n
0
0
0
1
0
0
d
1
d
2
d
j
d
n
0
0
0
0
1
−
w
0
183
184 Linear Programming II: Additional Topics and Extensions
Table 4.2 Tableau at the Beginning of Cycle 0
Columns of the canonical form Value of the
Basic variables xn+1 xn+2 · · · xn+r · · · xn+m −f −w basic variable xsa
xn+1 1 b1
xn+2 1 b2
...
...
xn+r 1 br
...
...
xn+m 1 bm
←−−−−−− Inverse of the basis ←−−−−−−
−f 0 0 · · · 0 · · · 0 1 0
−w 0 0 · · · 0 · · · 0 1 −w0 = −
m∑
i=1
bi
aThis column is blank at the beginning of cycle 0 and filled up only at the end of cycle 0.
seen to be an identity matrix in Table 4.2. The rows corresponding to −f and
−w in Table 4.2 give the negative of simplex multipliers πi and σi (i = 1 to m),
respectively. These are also zero since cB = dB = 0 and hence
πT = cTBB
−1 = 0
σ T = dTBB
−1 = 0
In general, at the start of some cycle k (k = 0 to start with) we open a tableau
similar to Table 4.2, as shown in Table 4.4. This can also be interpreted as
composed of the inverse of the current basis, B−1 = [βij ], two rows for the
simplex multipliers πi and σi , a column for the values of the basic variables in
the basic solution, and a column for the variable xs . At the start of any cycle,
all entries in the tableau, except the last column, are known.
3. The values of the relative cost factors dj (for phase I) or cj (for phase II) are
computed as
dj = dj − σ TAj
cj = cj − πTAj
and entered in a tableau form as shown in Table 4.3. For cycle 0, σ T = 0 and
hence dj ≡ dj .
4. If the current cycle corresponds to phase I, find whether all dj ≥ 0. If all
dj ≥ 0 and w0 > 0, there is no feasible solution to the linear programming
problem, so the process is terminated. If all dj ≥ 0 and w0 = 0, the current basic
solution is a basic feasible solution to the linear programming problem and hence
phase II is started by (a) dropping all variables xj with dj > 0, (b) dropping
the w row of the tableau, and (c) restarting the cycle (step 3) using phase
II rules.
4.2 Revised Simplex Method 185
Table 4.3 Relative Cost Factor dj or cj
Variable xj
Cycle number x1 x2 · · · xn xn+1 xn+2 · · · xn+m
Phase I











0
1
...
l
d1 d2 · · · dn 0 0 · · · 0
Use the values of σi (if phase I) or πi (if phase II) of the
current cycle and compute
dj = dj − (σ1a1j + σ2a2j + · · · + σmamj )
or
Phase II







l + 1
l + 2
...
cj = cj − (π1a1j + π2a2j + · · · + πmamj )
Enter dj or cj in the row corresponding to the current cycle
and choose the pivot column s such that ds = min dj
(if phase I) or cs = min cj (if phase II)
Table 4.4 Tableau at the Beginning of Cycle k
Columns of the original canonical form
Basic variable xn+1 · · · xn+m −f −w
Value of the basic
variable xs
a
[βij ] = [ai,n+j ]
← Inverse of the basis →
xj1 β11 · · · β1m b1 a1s =
m∑
i=1
β1iais
...
...
...
...
xjr βr1 · · · βrm br ars =
m∑
i=1
βriais
...
...
...
...
xjm βm1 · · · βmm bm ams =
m∑
i=1
βmiais
−f −π1 · · · − πm 1 −f 0 cs = cs −
m∑
i=1
πiais
(−πj = +cn+j )
−w −σ1 · · · − σm 1 −w0 ds = ds −
m∑
i=1
σiais
(−σj = +dn+j )
aThis column is blank at the start of cycle k and is filled up only at the end of cycle k.
If some dj < 0, choose xs as the variable to enter the basis in the next
cycle in place of the present rth basic variable (r will be determined later) such
that
ds = min(dj < 0)
On the other hand, if the current cycle corresponds to phase II, find whether
all cj ≥ 0. If all cj ≥ 0, the current basic feasible solution is also an optimal
solution and hence terminate the process. If some cj < 0, choose xs to enter
186 Linear Programming II: Additional Topics and Extensions
the basic set in the next cycle in place of the rth basic variable (r to be found
later), such that
cs = min(cj < 0)
5. Compute the elements of the xs column from Eq. (4.9) as
As = B−1As = β ij As
that is,
a1s = β11a1s + β12a2s + · · · + β1mams
a2s = β21a1s + β22a2s + · · · + β2mams
...
ams = βm1a1s + βm2a2s + · · · + βmmams
and enter in the last column of Table 4.2 (if cycle 0) or Table 4.4 (if cycle k).
6. Inspect the signs of all entries ais, i = 1 to m. If all ais ≤ 0, the class of
solutions
xs ≥ 0 arbitrary
xj i = bi − ais · xs if xj i is a basic variable, and xj = 0 if xj is a nonbasic
variable (j = s), satisfies the original system and has the property
f = f 0 + csxs → −∞ as xs → +∞
Hence terminate the process. On the other hand, if some ais > 0, select the
variable xr that can be dropped in the next cycle as
br
ars
= min
ais > 0
(bi/ais)
In the case of a tie, choose r at random.
7. To bring xs into the basis in place of xr , carry out a pivot operation on the
element ars in Table 4.4 and enter the result as shown in Table 4.5. As usual,
the last column of Table 4.5 will be left blank at the beginning of the current
cycle k + 1. Also, retain the list of basic variables in the first column of Table 4.5
the same as in Table 4.4, except that jr is changed to the value of s determined
in step 4.
8. Go to step 3 to initiate the next cycle, k + 1.
Example 4.1
Maximize F = x1 + 2x2 + x3
subject to
2x1 + x2 − x3 ≤ 2
−2x1 + x2 − 5x3 ≥ −6
4.2 Revised Simplex Method 187
Table 4.5 Tableau at the Beginning of Cycle k + 1
Columns of the canonical form
Basic variables xn+1 · · · xn+m −f −w Value of the basic variable xsa
xj1 β11 − a1sβ∗r1 · · · β1m − a1sβ∗rm b1 − a1sbr ∗
...
xs β
∗
r1 · · · β∗rm br∗
...
xjm βm1 − amsβ∗r1 · · · βmm − amsβ∗rm bm − amsb
∗
r
−f −π1 − csβ∗r1 · · · −πm − csβ∗rm 1 −f 0 − csb
∗
r
−w −σ1 − dsβ∗r1 · · · −σm − dsβ∗rm 1 −w0 − dsb
∗
r
β∗ri =
βri
ars
(i = 1 to m) and b∗r =
br
ars
aThis column is blank at the start of the cycle.
4x1 + x2 + x3 ≤ 6
x1 ≥ 0, x2 ≥ 0, x3 ≥ 0
SOLUTION This problem can be stated in standard form as (making all the constants
bi positive and then adding the slack variables):
Minimize
f = −x1 − 2x2 − x3 (E1)
subject to
2x1 + x2 − x3 + x4 = 2
2x1 − x2 + 5x3 + x5 = 6
4x1 + x2 + x3 + x6 = 6
xi ≥ 0, i = 1 to 6
(E2)
where x4, x5, and x6 are slack variables. Since the set of equations (E2) are in canonical
form with respect to x4, x5, and x6, xi = 0 (i = 1, 2, 3) and x4 = 2, x5 = 6, and x6 = 6
can be taken as an initial basic feasible solution and hence there is no need for phase I.
Step 1 All the equations (including the objective function) can be written in canonical
form as
2x1 + x2 − x3 + x4 = 2
2x1 − x2 + 5x3 + x5 = 6
4x1 + x2 + x3 + x6 = 6
−x1 − 2x2 − x3 −f = 0
(E3)
These equations are written in tableau form in Table 4.6.
188 Linear Programming II: Additional Topics and Extensions
Table 4.6 Detached Coefficients of the Original System
Admissible variables
x1 x2 x3 x4 x5 x6 −f Constants
2 1 −1 1 0 0 2
2 −1 5 0 1 0 6
4 1 1 0 0 1 6
−1 −2 −1 0 0 0 1 0
Table 4.7 Tableau at the Beginning of Cycle 0
Columns of the canonical form
Basic variables x4 x5 x6 −f
Value of the basic
variable (constant) x2
a
x4 1 0 0 0 2 a42 = 1
Pivot element
x5 0 1 0 0 6 a52 = −1
x6 0 0 1 0 6 a62 = 1
Inverse of the basis = [βij ]
−f 0 0 0 1 0 c2 = −2
aThis column is entered at the end of step 5.
Step 2 The iterative procedure (cycle 0) starts with x4, x5, x6, and −f as basic vari-
ables. A tableau is opened by entering the coefficients of the basic variables
and the constant terms as shown in Table 4.7. Since the basis matrix is B =
I, its inverse B−1 = [βij ] = I. The row corresponding to −f in Table 4.7
gives the negative of simplex multipliers πi, i = 1, 2, 3. These are all zero
in cycle 0. The entries of the last column of the table are, of course, not yet
known.
Step 3 The relative cost factors cj are computed as
cj = cj − πTAj = cj , j = 1 to 6
since all πi are zero. Thus
c1 = c1 = −1
c2 = c2 = −2
c3 = c3 = −1
c4 = c4 = 0
c5 = c5 = 0
c6 = c6 = 0
These cost coefficients are entered as the first row of a tableau (Table 4.8).
4.2 Revised Simplex Method 189
Table 4.8 Relative Cost Factors cj
Variable xj
Cycle number x1 x2 x3 x4 x5 x6
Phase II
Cycle 0 −1 −2 −1 0 0 0
Cycle 1 3 0 −3 2 0 0
Cycle 2 6 0 0 11
4
3
4
0
Step 4 Find whether all cj ≥ 0 for optimality. The present basic feasible solution is
not optimal since some cj are negative. Hence select a variable xs to enter
the basic set in the next cycle such that cs = min(cj < 0) = c2 in this case.
Therefore, x2 enters the basic set.
Step 5 Compute the elements of the xs column as
As = [βij ]As
where [βij ] is available in Table 4.7 and As in Table 4.6.
A2 = IA2 =



1
−1
1



These elements, along with the value of c2, are entered in the last column of
Table 4.7.
Step 6 Select a variable (xr) to be dropped from the current basic set as
br
ars
= min
ais > 0
(
bi
ais
)
In this case,
b4
a42
=
2
1
= 2
b6
a62
=
6
1
= 6
Therefore, xr = x4.
Step 7 To bring x2 into the basic set in place of x4, pivot on ars = a42 in Table 4.7.
Enter the result as shown in Table 4.9, keeping its last column blank. Since a
new cycle has to be started, we go to step 3.
Step 3 The relative cost factors are calculated as
cj = cj − (π1a1j + π2a2j + π3a3j )
190 Linear Programming II: Additional Topics and Extensions
Table 4.9 Tableau at the Beginning of Cycle 1
Columns of the original canonical form
Basic variables x4 x5 x6 −f
Value of the basic
variable x3
a
x2 1 0 0 0 2 a23 = −1
x5 1 1 0 0 8 a53 = 4
Pivot element
x6 −1 0 1 1 4 a63 = 2
←Inverse of the basis = [βij ] →
−f 2 = −π1 0 = −π2 0 = −π3 1 4 c3 = −3
aThis column is entered at the end of step 5.
where the negative values of π1, π2, and π3 are given by the row of −f in
Table 4.9, and aij and ci are given in Table 4.6. Here π1 = −2, π2 = 0, and
π3 = 0.
c1 = c1 − π1a11 = −1 − (−2) (2) = 3
c2 = c2 − π1a12 = −2 − (−2) (1) = 0
c3 = c3 − π1a13 = −1 − (−2) (−1) = −3
c4 = c4 − π1a14 = 0 − (−2) (1) = 2
c5 = c5 − π1a15 = 0 − (−2) (0) = 0
c6 = c6 − π1a16 = 0 − (−2) (0) = 0
Enter these values in the second row of Table 4.8.
Step 4 Since all cj are not ≥ 0, the current solution is not optimum. Hence
select a variable (xs) to enter the basic set in the next cycle such that
cs = min(cj < 0) = c3 in this case. Therefore, xs = x3.
Step 5 Compute the elements of the xs column as
As = [βij ]As
where [βij ] is available in Table 4.9 and As in Table 4.6:
A3 =



a23
a53
a63



=


1 0 0
1 1 0
−1 0 1





−1
5
1



=



−1
4
2



Enter these elements and the value of cs = c3 = −3 in the last column of
Table 4.9.
Step 6 Find the variable (xr ) to be dropped from the basic set in the next cycle as
br
ars
= min
ais > 0
(
bi
ais
)
4.2 Revised Simplex Method 191
Table 4.10 Tableau at the Beginning of Cycle 2
Columns of the original canonical form
Basic variables x4 x5 x6 −f
Value of the basic
variable xs
a
x2
5
4
1
4
0 0 4
x3
1
4
1
4
0 0 2
x6 − 64 −
2
4
1 1 0
−f 11
4
3
4
0 1 10
aThis column is blank at the beginning of cycle 2.
Here
b5
a53
=
8
4
= 2
b6
a63
=
4
2
= 2
Since there is a tie between x5 and x6, we select xr = x5 arbitrarily.
Step 7 To bring x3 into the basic set in place of x5, pivot on ars = a53 in Table 4.9.
Enter the result as shown in Table 4.10, keeping its last column blank. Since a
new cycle has to be started, we go to step 3.
Step 3 The simplex multipliers are given by the negative values of the numbers appear-
ing in the row of −f in Table 4.10. Therefore, π1 = − 114 , π2 = −
3
4
, and π3 = 0.
The relative cost factors are given by
cj = cj = −πTAj
Then
c1 = c1 − π1a11 − π2a21 = −1 − (− 114 )(2) − (−
3
4
)(2) = 6
c2 = c2 − π1a12 − π2a22 = −2 − (− 114 )(1) − (−
3
4
)(−1) = 0
c3 = c3 − π1a13 − π2a23 = −1 − (− 114 )(−1) − (−
3
4
)(5) = 0
c4 = c4 − π1a14 − π2a24 = 0 − (− 114 )(1) − (−
3
4
)(0) = 11
4
c5 = c5 − π1a15 − π2a25 = 0 − (− 114 )(0) − (−
3
4
)(1) = 3
4
c6 = c6 − π1a16 − π2a26 = 0 − (− 114 )(0) − (−
3
4
)(0) = 0
These values are entered as third row in Table 4.8.
Step 4 Since all cj are ≥ 0, the present solution will be optimum. Hence the optimum
solution is given by
x2 = 4, x3 = 2, x6 = 0 (basic variables)
x1 = x4 = x5 = 0 (nonbasic variables)
fmin = −10
192 Linear Programming II: Additional Topics and Extensions
4.3 DUALITY IN LINEAR PROGRAMMING
Associated with every linear programming problem, called the primal , there is another
linear programming problem called its dual . These two problems possess very inter-
esting and closely related properties. If the optimal solution to any one is known, the
optimal solution to the other can readily be obtained. In fact, it is immaterial which
problem is designated the primal since the dual of a dual is the primal. Because of
these properties, the solution of a linear programming problem can be obtained by
solving either the primal or the dual, whichever is easier. This section deals with
the primal–dual relations and their application in solving a given linear programming
problem.
4.3.1 Symmetric Primal–Dual Relations
A nearly symmetric relation between a primal problem and its dual problem can be
seen by considering the following system of linear inequalities (rather than equations).
Primal Problem.
a11x1 + a12x2 + · · · + a1nxn ≥ b1
a21x1 + a22x2 + · · · + a2nxn ≥ b2
... (4.17)
am1x1 + am2x2 + · · · + amnxn ≥ bm
c1x1 + c2x2 + · · · + cnxn = f
(xi ≥ 0, i = 1 to n, and f is to be minimized)
Dual Problem. As a definition, the dual problem can be formulated by transposing
the rows and columns of Eq. (4.17) including the right-hand side and the objective
function, reversing the inequalities and maximizing instead of minimizing. Thus by
denoting the dual variables as y1, y2, . . . , ym, the dual problem becomes
a11y1 + a21y2 + · · · + am1ym ≤ c1
a12y1 + a22y2 + · · · + am2xm ≤ c2
... (4.18)
a1ny1 + a2ny2 + · · · + amnym ≤ cn
b1y1 + b2y2 + · · · + bmym = v
(yi ≥ 0, i = 1 to m, and v is to be maximized)
Equations (4.17) and (4.18) are called symmetric primal–dual pairs and it is easy to
see from these relations that the dual of the dual is the primal.
4.3 Duality in Linear Programming 193
4.3.2 General Primal–Dual Relations
Although the primal–dual relations of Section 4.3.1 are derived by considering a system
of inequalities in nonnegative variables, it is always possible to obtain the primal–dual
relations for a general system consisting of a mixture of equations, less than or greater
than type of inequalities, nonnegative variables or variables unrestricted in sign by
reducing the system to an equivalent inequality system of Eqs. (4.17). The correspon-
dence rules that are to be applied in deriving the general primal–dual relations are
given in Table 4.11 and the primal–dual relations are shown in Table 4.12.
4.3.3 Primal–Dual Relations When the Primal Is in Standard Form
If m∗ = m and n∗ = n, primal problem shown in Table 4.12 reduces to the standard
form and the general primal–dual relations take the special form shown in Table 4.13.
It is to be noted that the symmetric primal–dual relations, discussed in Section 4.3.1,
can also be obtained as a special case of the general relations by setting m∗ = 0 and
n∗ = n in the relations of Table 4.12.
Table 4.11 Correspondence Rules for Primal–Dual Relations
Primal quantity Corresponding dual quantity
Objective function: Minimize cTX Maximize YTb
Variable xi ≥ 0 ith constraint YTAi ≤ ci (inequality)
Variable xi unrestricted in sign ith constraint Y
TAi = ci (equality)
j th constraint, Aj X = bj (equality) j th variable yj unrestricted in sign
j th constraint, Aj X ≥ bj (inequality) j th variable yj ≥ 0
Coefficient matrix A ≡ [A1 . . . Am] Coefficient matrix AT ≡ [A1, . . . , Am]T
Right-hand-side vector b Right-hand-side vector c
Cost coefficients c Cost coefficients b
Table 4.12 Primal–Dual Relations
Primal problem Corresponding dual problem
Minimize f =
n∑
i=1
cixi subject to Maximize v =
m∑
i=1
yibi subject to
n∑
j=1
aijxj = bi, i = 1, 2, . . . , m∗
m∑
i=1
yiaij = cj , j = n∗ + 1, n∗ + 2,
n∑
j=1
aijxj ≥ bi, i = m∗ + 1, m∗ + 2, . . . , n
. . . , m
m∑
i=1
yiaij ≤ cj , j = 1, 2, . . . , n∗
where where
xi ≥ 0, i = 1, 2, . . . , n∗; yi ≥ 0, i = m∗ + 1,m∗ + 2, . . . , m;
and and
xi unrestricted in sign, i = n∗ + 1, yi unrestricted in sign, i = 1, 2, . . . , m∗
n∗ + 2, . . . , n
194 Linear Programming II: Additional Topics and Extensions
Table 4.13 Primal–Dual Relations Where m∗ = m and n∗ = n
Primal problem Corresponding dual problem
Minimize f =
n∑
i=1
cixi Maximize ν =
m∑
i=1
biyi
subject to subject to
n∑
j=1
aijxj = bi, i = 1, 2, . . . , m
m∑
i=1
yiaij ≤ cj , j = 1, 2, . . . , n
where where
xi ≥ 0, i = 1, 2, . . . , n yi is unrestricted in sign, i = 1, 2, · · · , m
In matrix form In matrix form
Minimize f = cTX Maximize ν = YTb
subject to subject to
AX = b ATY ≤ c
where where
X ≥ 0 Y is unrestricted in sign
Example 4.2 Write the dual of the following linear programming problem:
Maximize f = 50x1 + 100x2
subject to
2x1 + x2 ≤ 1250
2x1 + 5x2 ≤ 1000
2x1 + 3x2 ≤ 900
x2 ≤ 150











n = 2, m = 4
where
x1 ≥ 0 and x2 ≥ 0
SOLUTION Let y1, y2, y3, and y4 be the dual variables. Then the dual problem can
be stated as
Minimize ν = 1250y1 + 1000y2 + 900y3 + 150y4
subject to
2y1 + 2y2 + 2y3 ≥ 50
y1 + 5y2 + 3y3 + y4 ≥ 100
where y1 ≥ 0, y2 ≥ 0, y3 ≥0, and y4 ≥ 0.
Notice that the dual problem has a lesser number of constraints compared to the
primal problem in this case. Since, in general, an additional constraint requires more
computational effort than an additional variable in a linear programming problem, it
is evident that it is computationally more efficient to solve the dual problem in the
present case. This is one of the advantages of the dual problem.
4.3 Duality in Linear Programming 195
4.3.4 Duality Theorems
The following theorems are useful in developing a method for solving LP problems
using dual relationships. The proofs of these theorems can be found in Ref. [4.10].
Theorem 4.1 The dual of the dual is the primal.
Theorem 4.2 Any feasible solution of the primal gives an f value greater than or at
least equal to the ν value obtained by any feasible solution of the dual.
Theorem 4.3 If both primal and dual problems have feasible solutions, both have
optimal solutions and minimum f = maximum ν.
Theorem 4.4 If either the primal or the dual problem has an unbounded solution, the
other problem is infeasible.
4.3.5 Dual Simplex Method
There exist a number of situations in which it is required to find the solution of a
linear programming problem for a number of different right-hand-side vectors b(i).
Similarly, in some cases, we may be interested in adding some more constraints to a
linear programming problem for which the optimal solution is already known. When
the problem has to be solved for different vectors b(i), one can always find the desired
solution by applying the two phases of the simplex method separately for each vector
b(i). However, this procedure will be inefficient since the vectors b(i) often do not
differ greatly from one another. Hence the solution for one vector, say, b(1) may be
close to the solution for some other vector, say, b(2). Thus a better strategy is to solve
the linear programming problem for b(1) and obtain an optimal basis matrix B. If this
basis happens to be feasible for all the right-hand-side vectors, that is, if
B−1b(i) ≥ 0 for all i (4.19)
then it will be optimal for all cases. On the other hand, if the basis B is not feasible
for some of the right-hand-side vectors, that is, if
B−1b(r) < 0 for some r (4.20)
then the vector of simplex multipliers
πT = cTBB
−1 (4.21)
will form a dual feasible solution since the quantities
cj = cj − πTAj ≥ 0
are independent of the right-hand-side vector b(r). A similar situation exists when the
problem has to be solved with additional constraints.
In both the situations discussed above, we have an infeasible basic (primal) solu-
tion whose associated dual solution is feasible. Several methods have been proposed,
196 Linear Programming II: Additional Topics and Extensions
as variants of the regular simplex method, to solve a linear programming problem by
starting from an infeasible solution to the primal. All these methods work in an iterative
manner such that they force the solution to become feasible as well as optimal simulta-
neously at some stage. Among all the methods, the dual simplex method developed by
Lemke [4.2] and the primal–dual method developed by Dantzig, Ford, and Fulkerson
[4.3] have been most widely used. Both these methods have the following important
characteristics:
1. They do not require the phase I computations of the simplex method. This is a
desirable feature since the starting point found by phase I may be nowhere near
optimal, since the objective of phase I ignores the optimality of the problem
completely.
2. Since they work toward feasibility and optimality simultaneously, we can expect
to obtain the solution in a smaller total number of iterations.
We shall consider only the dual simplex algorithm in this section.
Algorithm. As stated earlier, the dual simplex method requires the availability of
a dual feasible solution that is not primal feasible to start with. It is the same as the
simplex method applied to the dual problem but is developed such that it can make use
of the same tableau as the primal method. Computationally, the dual simplex algorithm
also involves a sequence of pivot operations, but with different rules (compared to the
regular simplex method) for choosing the pivot element.
Let the problem to be solved be initially in canonical form with some of the bi < 0,
the relative cost coefficients corresponding to the basic variables cj = 0, and all other
cj ≥ 0. Since some of the bi are negative, the primal solution will be infeasible, and
since all cj ≥ 0, the corresponding dual solution will be feasible. Then the simplex
method works according to the following iterative steps.
1. Select row r as the pivot row such that
br = min bi < 0 (4.22)
2. Select column s as the pivot column such that
cs
−ars
= min
arj <0
(
cj
−arj
)
(4.23)
If all arj ≥ 0, the primal will not have any feasible (optimal) solution.
3. Carry out a pivot operation on ars
4. Test for optimality: If all bi ≥ 0, the current solution is optimal and hence stop
the iterative procedure. Otherwise, go to step 1.
Remarks:
1. Since we are applying the simplex method to the dual, the dual solution will
always be maintained feasible, and hence all the relative cost factors of the
primal (cj ) will be nonnegative. Thus the optimality test in step 4 is valid
because it guarantees that all bi are also nonnegative, thereby ensuring a feasible
solution to the primal.
4.3 Duality in Linear Programming 197
2. We can see that the primal will not have a feasible solution when all arj are
nonnegative from the following reasoning. Let (x1, x2, . . . , xm) be the set of
basic variables. Then the rth basic variable, xr , can be expressed as
xr = br −
n
∑
j=m+1
arjxj
It can be seen that if br < 0 and arj ≥ 0 for all j, xr cannot be made non-
negative for any nonnegative value of xj . Thus the primal problem contains
an equation (the rth one) that cannot be satisfied by any set of nonnegative
variables and hence will not have any feasible solution.
The following example is considered to illustrate the dual simplex method.
Example 4.3
Minimize f = 20x1 + 16x2
subject to
x1 ≥ 2.5
x2 ≥ 6
2x1 + x2 ≥ 17
x1 + x2 ≥ 12
x1 ≥ 0, x2 ≥ 0
SOLUTION By introducing the surplus variables x3, x4, x5, and x6, the problem can
be stated in canonical form as
Minimize f
with
−x1 + x3 = −2.5
− x2 + x4 = −6
−2x1 − x2 + x5 = −17
−x1 − x2 + x6 = −12
20x1 + 16x2 − f = 0
xi ≥ 0, i = 1 to 6
(E1)
The basic solution corresponding to (E1) is infeasible since x3 = −2.5, x4 =
−6, x5 = −17, and x6 = −12. However, the objective equation shows optimality
since the cost coefficients corresponding to the nonbasic variables are nonnegative
(c1 = 20, c2 = 16). This shows that the solution is infeasible to the primal but feasible
to the dual. Hence the dual simplex method can be applied to solve this problem as
follows.
198 Linear Programming II: Additional Topics and Extensions
Step 1 Write the system of equations (E1) in tableau form:
VariablesBasic
variables x1 x2 x3 x4 x5 x6 −f bi
x3 −1 0 1 0 0 0 0 −2.5
x4 0 −1 0 1 0 0 0 −6
x5 −2 −1 0 0 1 0 0 −17 ← Minimum,
pivot row
Pivot element
x6 −1 −1 0 0 0 1 0 −12
−f 20 16 0 0 0 0 1 0
Select the pivotal row r such that
br = min(bi < 0) = b3 = −17
in this case. Hence r = 3.
Step 2 Select the pivotal column s as
cs
−ars
= min
arj <0
(
cj
−arj
)
Since
c1
−a31
=
20
2
= 10,
c2
−a32
=
16
1
= 16, and s = 1
Step 3 The pivot operation is carried on a31 in the preceding table, and the result is
as follows:
VariablesBasic
variables x1 x2 x3 x4 x5 x6 −f bi
x3 0
1
2
1 0 − 1
2
0 0 6
x4 0 −1 0 1 0 0 0 −6 ← Minimum,
pivot row
Pivot element
x1 1
1
2
0 0 − 1
2
0 0 17
2
x6 0 − 12 0 0 −
1
2
1 0 − 7
2
−f 0 6 0 0 10 0 1 −170
Step 4 Since some of the bi are < 0, the present solution is not optimum. Hence we
proceed to the next iteration.
Step 1 The pivot row corresponding to minimum (bi < 0) can be seen to be 2 in the
preceding table.
4.3 Duality in Linear Programming 199
Step 2 Since a22 is the only negative coefficient, it is taken as the pivot element.
Step 3 The result of pivot operation on a22 in the preceding table is as follows:
VariablesBasic
variables x1 x2 x3 x4 x5 x6 −f bi
x3 0 0 1
1
2
− 1
2
0 0 3
x2 0 1 0 −1 0 0 0 6
x1 1 0 0
1
2
− 1
2
0 0 11
2
x6 0 0 0 − 12 −
1
2
1 0 − 1
2
← Minimum,
pivot row
Pivot element
−f 0 0 0 6 10 0 1 −206
Step 4 Since all bi are not ≥ 0, the present solution is not optimum. Hence we go to
the next iteration.
Step 1 The pivot row (corresponding to minimum bi ≤ 0) can be seen to be the fourth
row.
Step 2 Since
c4
−a44
= 12 and
c5
−a45
= 20
the pivot column is selected as s = 4.
Step 3 The pivot operation is carried on a44 in the preceding table, and the result is
as follows:
VariablesBasic
variables x1 x2 x3 x4 x5 x6 −f bi
x3 0 0 1 0 −1 1 0 52
x2 0 1 0 0 1 −2 0 7
x1 1 0 0 0 −1 1 0 5
x4 0 0 0 1 1 −2 0 1
−f 0 0 0 0 4 12 1 −212
Step 4 Since all bi are ≥ 0, the present solution is dual optimal and primal feasible.
The solution is
x1 = 5, x2 = 7, x3 = 52 , x4 = 1 (dual basic variables)
x5 = x6 = 0 (dual nonbasic variables)
fmin = 212
200 Linear Programming II: Additional Topics and Extensions
4.4 DECOMPOSITION PRINCIPLE
Some of the linear programming problems encountered in practice may be very large
in terms of the number of variables and/or constraints. If the problem has some special
structure, it is possible to obtain the solution by applying the decomposition principle
developed by Dantzing and Wolfe [4.4]. In the decomposition method, the original
problem is decomposed into small subproblems and then these subproblems are solved
almost independently. The procedure, when applicable, has the advantage of making
it possible to solve large-scale problems that may otherwise be computationally very
difficult or infeasible. As an example of a problem for which the decomposition prin-
ciple can be applied, consider a company having two factories, producing three and
two products, respectively. Each factory has its own internal resources for production,
namely, workers and machines. The two factories are coupled by the fact that there
is a shared resource that both use, for example, a raw material whose availability is
limited. Let b2 and b3 be the maximum available internal resources for factory 1, and
let b4 and b5 be the similar availabilities for factory 2. If the limitation on the common
resource is b1, the problem can be stated as follows:
Minimize f (x1, x2, x3, y1, y2) = c1x1 + c2x2 + c3x3 + c4y1 + c5y2
subject to
a11x1 + a12x2 + a13x3 + a14y1 + a15y2 ≤ b1
a21x1 + a22x2 + a23x3
a31x1 + a32x2 + a33x2
≤ b2
≤ b3
a41y1 + a42y2
a51y1 + a52y2
≤ b4
≤ b5
(4.24)
where xi and yj are the quantities of the various products produced by the two factories
(design variables) and the aij are the quantities of resource i required to produce 1 unit
of product j .
xi ≥ 0,
(i=1,2,3)
yj ≥ 0
(j=1,2)
An important characteristic of the problem stated in Eqs. (4.24) is that its constraints
consist of two independent sets of inequalities. The first set consists of a coupling
constraint involving all the design variables, and the second set consists of two groups
of constraints, each group containing the design variables of that group only. This
problem can be generalized as follows:
Minimize f (X) = cT1 X1 + c
T
2 X2 + · · · + c
T
pXp (4.25a)
subject to
4.4 Decomposition Principle 201
A1X1 + A2X2 + · · · + ApXp = b0 (4.25b)
B1X1 = b1
B2X2 = b2
...
BpXp = bp









(4.25c)
X1 ≥ 0, X2 ≥ 0, · · · , Xp ≥ 0
where
X1 =









x1
x2
...
xm1









, X2 =









xm1+1
xm1+2
...
xm1+m2









, . . . ,
Xp =



xm1+m2+···+mp−1+1
xm1+m2+···+mp−1+2
xm1+m2+···+mp−1+mp



X =









X1
X2
...
Xp









It can be noted that if the size of the matrix Ak is (r0 × mk) and that of Bk is (rk × mk),
the problem has
∑p
k=0 rk constraints and
∑p
k=1 mk variables.
Since there are a large number of constraints in the problem stated in Eqs. (4.25),
it may not be computationally efficient to solve it by using the regular simplex
method. However, the decomposition principle can be used to solve it in an efficient
manner. The basic solution procedure using the decomposition principle is given by
the following steps.
1. Define p subsidiary constraint sets using Eqs. (4.25) as
B1X1 = b1
B2X2 = b2
...
BkXk = bk
...
BpXp = bp
(4.26)
The subsidiary constraint set
BkXk = bk, k = 1, 2, . . . , p (4.27)
represents rk equality constraints. These constraints along with the requirement
Xk ≥ 0 define the set of feasible solutions of Eqs. (4.27). Assuming that this set
202 Linear Programming II: Additional Topics and Extensions
of feasible solutions is a bounded convex set, let sk be the number of vertices
of this set. By using the definition of convex combination of a set of points,†
any point Xk satisfying Eqs. (4.27) can be represented as
Xk =µk,1X(k)1 + µk,2X
(k)
2 + · · · + µk,sk X
(k)
sk
(4.28)
µk,1 + µk,2 + · · · + µk,sk = 1 (4.29)
0 ≤ µk,i ≤ 1, i = 1, 2, . . . , sk, k = 1, 2, . . . , p (4.30)
where X
(k)
1 , X
(k)
2 , . . . , X
(k)
sk are the extreme points of the feasible set defined by
Eqs. (4.27). These extreme points X
(k)
1 , X
(k)
2 , . . . , X
(k)
sk ; k = 1, 2, . . . , p, can be
found by solving the Eqs. (4.27).
2. These new Eqs. (4.28) imply the complete solution space enclosed by the con-
straints
BkXk = bk
Xk ≥ 0, k = 1, 2, . . . , p
(4.31)
By substituting Eqs. (4.28) into Eqs. (4.25), it is possible to eliminate the
subsidiary constraint sets from the original problem and obtain the following
equivalent form:
Minimize f (X) = cT1
(
s1
∑
i=1
µ1,iX
(1)
i
)
+ cT2
(
s2
∑
i=1
µ2,iX
(2)
i
)
+ · · · + cTp
(
sp
∑
i=1
µp,iX
(p)
i
)
subject to
A1
(
s1∑
i=1
µ1,iX
(1)
i
)
+ A2
(
s2∑
i=1
µ2,iX
(2)
i
)
+ · · ·+ Ap
( sp∑
i=1
µp,iX
(p)
i
)
= b0
s1∑
i=1
µ1,i = 1
s2∑
i=1
µ2,i = 1
sp∑
i=1
µp,i = 1
†If X(1) and X(2) are any two points in an n-dimensional space, any point lying on the line segment joining
X(1) and X(2) is given by a convex combination of X(1) and X(2) as
X(µ) = µ X(1) + (1 − µ) X(2), 0 ≤ µ ≤ 1
This idea can be generalized to define the convex combination of r points X(1), X(2), . . ., X(r) as
X(µ1, µ2, · · · , µr ) = µ1X(1) + µ2X(2) + · · · + µrX(r)
where µ1 + µ2 + · · · + µr = 1 and 0 ≤ µi ≤ 1, i = 1, 2, . . . , r .
4.4 Decomposition Principle 203
µj,i ≥ 0, i = 1, 2, . . . , sj , j = 1, 2, . . . , p (4.32)
Since the extreme points X
(k)
1 , X
(k)
2 , . . . , X
(k)
sk are known from the solu-
tion of the set BkXk = bk, Xk ≥ 0, k = 1, 2, . . . , p, and since ck and
Ak, k = 1, 2, . . . , p, are known as problem data, the unknowns in Eqs. (4.32)
are µj,i, i = 1, 2, . . . , sj ; j = 1, 2, . . . , p. Hence µj,i will be the new decision
variables of the modified problem stated in Eqs. (4.32).
3. Solve the linear programming problem stated in Eqs. (4.32) by any of the known
techniques and find the optimal values of µj,i . Once the optimal values µ
∗
j,i are
determined, the optimal solution of the original problem can be obtained as
X∗ =









X∗1
X∗2
...
X∗p









where
X∗k =
sk
∑
i=1
µ∗k,iX
(k)
i , k = 1, 2, . . . , p
Remarks:
1. It is to be noted that the new problem in Eqs. (4.32) has (r0 + p) equality con-
straints only as against r0 +
∑p
k=1 rk in the original problem of Eq. (4.25). Thus
there is a substantial reduction in the number of constraints due to the applica-
tion of the decomposition principle. At the same time, the number of variables
might increase from
∑p
k=1 mk to
∑p
k=1 sk , depending on the number of extreme
points of the different subsidiary problems defined by Eqs. (4.31). The modified
problem, however, is computationally more attractive since the computational
effort required for solving any linear programming problem depends primarily
on the number of constraints rather than on the number of variables.
2. The procedure outlined above requires the determination of all the extreme
points of every subsidiary constraint set defined by Eqs. (4.31) before the opti-
mal values µ∗j,i are found. However, this is not necessary when the revised
simplex method is used to implement the decomposition algorithm [4.5].
3. If the size of the problem is small, it will be convenient to enumerate all the
extreme points of the subproblems and use the simplex method to solve the
problem. This procedure is illustrated in the following example.
Example 4.4 A fertilizer mixing plant produces two fertilizers, A and B, by mixing
two chemicals, C1 and C2, in different proportions. The contents and costs of the
chemicals C1 and C2 are as follows:
Contents
Chemical Ammonia Phosphates Cost ($/lb)
C1 0.70 0.30 5
C2 0.40 0.60 4
204 Linear Programming II: Additional Topics and Extensions
Fertilizer A should not contain more than 60% of ammonia and B should contain
at least 50% of ammonia. On the average, the plant can sell up to 1000 lb/hr and due
to limitations on the production facilities, not more than 600 lb of fertilizer A can be
produced per hour. The availability of chemical C1 is restricted to 500 lb/hr. Assuming
that the production costs are same for both A and B, determine the quantities of A
and B to be produced per hour for maximum return if the plant sells A and B at the
rates of $6 and $7 per pound, respectively.
SOLUTION Let x1 and x2 indicate the amounts of chemicals C1 and C2 used in
fertilizer A, and y1 and y2 in fertilizer B per hour. Thus the total amounts of A and
B produced per hour are given by x1 + x2 and y1 + y2, respectively. The objective
function to be maximized is given by
f = selling price − cost of chemical C1 and C2
= 6(x1 + x2) + 7(y1 + y2) − 5(x1 + y1) − 4(x2 + y2)
The constraints are given by
(x1 + x2) + (y1 + y2) ≤ 1000 (amount that can be sold)
x1 + y1 ≤ 500 (availability of C1)
x1 + x2 ≤ 600 (production limitations on A)
7
10
x1 + 410x2 ≤
6
10
(x1 + x2) (A should not contain more
than 60% of ammonia)
7
10
y1 + 410y2 ≥
5
10
(y1 + y2) (B should contain at least
50% of ammonia)
Thus the problem can be restated as
Maximize f = x1 + 2x2 + 2y1 + 3y2 (E1)
subject to
x1 + x2 + y1 + y2
x1 + y1
≤ 1000
≤ 500 (E2)
x1 + x2
x1 − 2x2
≤ 600
≤ 0 (E3)
−2y1 + y2 ≤ 0 (E4)
xi ≥ 0, yi ≥ 0, i = 1, 2
This problem can also be stated in matrix notation as follows:
Maximize f (X) = cT1 X1 + c
T
2 X2
4.4 Decomposition Principle 205
subject to
A1X1+ A2X2 ≤ b0
B1X1 ≤ b1
B2X2 ≤ b2
X1 ≥ 0, X2 ≥ 0
(E5)
where
X1 =
{
x1
x2
}
, X2 =
{
y1
y2
}
, c1 =
{
1
2
}
, c2 =
{
2
3
}
,
A1 =
[
1 1
1 0
]
, [A2] =
[
1 1
1 0
]
, b0 =
{
1000
500
}
,
B1 =
[
1 1
1 −2
]
, b1 =
{
600
0
}
, B2 =
{
−2 1
}
, b2 = {0} ,
X =
{
X1
X2
}
Step 1 We first consider the subsidiary constraint sets
B1X1 ≤ b1, X1 ≥ 0 (E6)
B2X2 ≤ b2, X2 ≥ 0 (E7)
The convex feasible regions represented by (E6) and (E7) are shown in Fig. 4.1a
and b, respectively. The vertices of the two feasible regions are given by
X
(1)
1 = point P =
{
0
0
}
X
(1)
2 = point Q =
{
0
600
}
X
(1)
3 = point R =
{
400
200
}
Figure 4.1 Vertices of feasible regions. To make the feasible region bounded, the constraint
y1 ≤ 1000 is added in view of Eq. (E2).
206 Linear Programming II: Additional Topics and Extensions
X
(2)
1 = point S =
{
0
0
}
X
(2)
2 = point T =
{
1000
2000
}
X
(2)
3 = point U =
{
1000
0
}
Thus any point in the convex feasible sets defined by Eqs. (E6) and (E7) can
be represented, respectively, as
X1 = µ11
{
0
0
}
+ µ12
{
0
600
}
+ µ13
{
400
200
}
=
{
400µ13
600µ12 + 200µ13
}
with
µ11 + µ12 + µ13 = 1, 0 ≤ µ1i ≤ 1, i = 1, 2, 3











(E8)
and
X2 = µ21
{
0
0
}
+ µ22
{
1000
2000
}
+ µ23
{
1000
0
}
=
{
1000µ22 + 1000µ23
2000µ22
}
with
µ21 +µ22 + µ23 = 1; 0 ≤ µ2i ≤ 1, i = 1, 2, 3





















(E9)
Step 2 By substituting the relations of (E8) and (E9), the problem stated in Eqs. (E5)
can be rewritten as
Maximize f (µ11, µ12, . . . , µ23) = (1 2)
{
400µ13
600µ12 + 200µ13
}
+ (2 3)
{
1000µ22 + 1000µ23
2000µ22
}
= 800µ13 + 1200µ12 + 8000µ22 + 2000µ23
subject to
[
1 1
1 0
]{
400µ13
600µ12 + 200µ13
}
+
[
1 1
1 0
]{
1000µ22 + 1000µ23
2000µ22
}
≤
{
1000
500
}
that is,
600µ12 + 600µ13 + 3000µ22 + 1000µ23 ≤ 1000
400µ13 + 1000µ22 + 1000µ23 ≤ 500
4.5 Sensitivity or Postoptimality Analysis 207
µ11 + µ12 + µ13 = 1
µ21 + µ22 + µ23 = 1
with
µ11 ≥ 0, µ12 ≥ 0, µ13 ≥ 0, µ21 ≥ 0, µ22 ≥ 0, µ23 ≥ 0
The optimization problem can be stated in standard form (after adding the slack
variables α and β) as
Minimize f = −1200µ12 − 800µ13 − 8000µ22 − 2000µ23
subject to
600µ12 + 600µ13 + 3000µ22 + 1000µ23 + α = 1000
400µ13 + 1000µ22 + 1000µ23 + β = 500
µ11 + µ12 + µ13 = 1
µ21 + µ22 + µ23 = 1
µij ≥ 0 (i = 1, 2; j = 1, 2, 3), α ≥ 0, β ≥ 0
(E10)
Step 3 The problem (E10) can now be solved by using the simplex method.
4.5 SENSITIVITY OR POSTOPTIMALITY ANALYSIS
In most practical problems, we are interested not only in optimal solution of the LP
problem, but also in how the solution changes when the parameters of the problem
change. The change in the parameters may be discrete or continuous. The study of
the effect of discrete parameter changes on the optimal solution is called sensitivity
analysis and that of the continuous changes is termed parametric programming . One
way to determine the effects of changes in the parameters is to solve a series of new
problems once for each of the changes made. This is, however, very inefficient from a
computational point of view. Some techniques that take advantage of the properties of
the simplex solution are developed to make a sensitivity analysis. We study some of
these techniques in this section. There are five basic types of parameter changes that
affect the optimal solution:
1. Changes in the right-hand-side constants bi
2. Changes in the cost coefficients cj
3. Changes in the coefficients of the constraints aij
4. Addition of new variables
5. Addition of new constraints
In general, when a parameter is changed, it results in one of three cases:
1. The optimal solution remains unchanged; that is, the basic variables and their
values remain unchanged.
2. The basic variables remain the same but their values are changed.
3. The basic variables as well as their values are changed.
208 Linear Programming II: Additional Topics and Extensions
4.5.1 Changes in the Right-Hand-Side Constants bi
Suppose that we have found the optimal solution to a LP problem. Let us now change
the bi to bi + bi so that the new problem differs from the original only on the
right-hand side. Our interest is to investigate the effect of changing bi to bi + bi on
the original optimum. We know that a basis is optimal if the relative cost coefficients
corresponding to the nonbasic variables cj are nonnegative. By considering the pro-
cedure according to which cj are obtained, we can see that the values of cj are not
related to the bi . The values of cj depend only on the basis, on the coefficients of the
constraint matrix, and the original coefficients of the objective function. The relation
is given in Eq. (4.10):
cj = cj − πTAj = cj − cTBB
−1Aj (4.33)
Thus changes in bi will affect the values of basic variables in the optimal solution and
the optimality of the basis will not be affected provided that the changes made in bi do
not make the basic solution infeasible. Thus if the new basic solution remains feasible
for the new right-hand side, that is, if
X′B = B
−1(b + b) ≥ 0 (4.34)
then the original optimal basis, B, also remains optimal for the new problem. Since the
original solution, say†
XB =









x1
x2
...
xm









is given by
XB = B−1b (4.35)
Equation (4.34) can also be expressed as
x′i = xi +
m
∑
j=1
βij bj ≥ 0, i = 1, 2, . . . , m (4.36)
where
B−1 = [βij ] (4.37)
Hence the original optimal basis B remains optimal provided that the changes made in
bi,bi , satisfy the inequalities (4.36). The change in the value of the ith optimal basic
variable, xi , due to the change in bi is given by
X′B − XB = XB = B−1b
†It is assumed that the variables are renumbered such that the first m variables represent the basic variables
and the remaining n − m the nonbasic variables.
4.5 Sensitivity or Postoptimality Analysis 209
that is,
xi =
m
∑
j=1
βijbj , i = 1, 2, . . . , m (4.38)
Finally, the change in the optimal value of the objective function (f ) due to the
change bi can be obtained as
f = cTBXB = c
T
BB
−1b = πT b =
m
∑
j=1
πjbj (4.39)
Suppose that the changes made in bi(bi) are such that the inequality (4.34) is violated
for some variables so that these variables become infeasible for the new right-hand-side
vector. Our interest in this case will be to determine the new optimal solution. This can
be done without reworking the problem from the beginning by proceeding according
to the following steps:
1. Replace the bi of the original optimal tableau by the new values, b
′ = B−1(b +
b) and change the signs of all the numbers that are lying in the rows in which
the infeasible variables appear, that is, in rows for which b
′
i < 0.
2. Add artificial variables to these rows, thereby replacing the infeasible variables
in the basis by the artificial variables.
3. Go through the phase I calculations to find a basic feasible solution for the
problem with the new right-hand side.
4. If the solution found at the end of phase I is not optimal, we go through the
phase II calculations to find the new optimal solution.
The procedure outlined above saves considerable time and effort compared to the
reworking of the problem from the beginning if only a few variables become infea-
sible with the new right-hand side. However, if the number of variables that become
infeasible are not few, the procedure above might also require as much effort as the
one involved in reworking of the problem from the beginning.
Example 4.5 A manufacturer produces four products, A, B,C, and D, by using two
types of machines (lathes and milling machines). The times required on the two machines
to manufacture 1 unit of each of the four products, the profit per unit of the product, and
the total time available on the two types of machines per day are given below:
Time required per unit (min) for product: Total time available
Machine A B C D per day (min)
Lathe machine 7 10 4 9 1200
Milling machine 3 40 1 1 800
Profit per unit ($) 45 100 30 50
Find the number of units to be manufactured of each product per day for maximizing
the profit.
Note: This is an ordinary LP problem and is given to serve as a reference problem
for illustrating the sensitivity analysis.
210 Linear Programming II: Additional Topics and Extensions
SOLUTION Let x1, x2, x3, and x4 denote the number of units of products A, B,C,
and D produced per day. Then the problem can be stated in standard form as follows:
Minimize f = −45x1 − 100x2 − 30x3 − 50x4
subject to
7x1 + 10x2 + 4x3 + 9x4 ≤ 1200
3x1 + 40x2 + x3 + x4 ≤ 800
xi ≥ 0, i = 1 to 4
By introducing the slack variables x5 ≥ 0 and x6 ≥ 0, the problem can be stated in
canonical form and the simplex method can be applied. The computations are shown
in tableau form below:
Basic Variables Ratio bi/ais
variables x1 x2 x3 x4 x5 x6 −f bi for ais > 0
x5 7 10 4 9 1 0 0 1200 120
x6 3 40 1 1 0 1 0 800 20 ← Smaller
one, x6 leaves
the basisPivot element
−f −45 −100 −30 −50 0 0 1 0
↑
Minimum cj < 0; x2 enters the next basis
Result of pivot operation:
x5
25
4
0 15
4
35
4
1 − 1
4
0 1000 4000
35
←Smaller
one, x5 leaves
the basisPivot element
x2
3
40
1 1
40
1
40
0 1
40
0 20 800
−f − 75
2
0 − 55
2
− 95
2
0 − 5
2
1 2000
↑
Minimum cj < 0, x4 enters the basis
Result of pivot operation:
x4
5
7
0 3
7
1 4
35
− 1
35
0 4,000
35
800
3
←Smaller
one, x4 leaves
the basisPivot element
x2
2
35
1 1
70
0 − 1
350
9
350
0 120
7
1200
−f − 25
7
0 − 50
7
0 38
7
8
7
1 52,000
7
↑
Minimum cj < 0, x3 enters the basis
4.5 Sensitivity or Postoptimality Analysis 211
Result of pivot operation:
x3
5
3
0 1 7
3
4
15
− 1
15
0 800
3
x2
1
30
1 0 − 1
30
− 1
150
2
75
0 40
3
−f 25
3
0 0 50
3
22
3
2
3
1 28,000
3
The optimum solution is given by
x2 =
40
3
, x3 =
800
3
(basic variables)
x1 = x4 = x5 = x6 = 0 (nonbasic variables)
fmin =
−28,000
3
or maximum profit =
$28,000
3
From the final tableau, one can find that
XB =
{
x3
x2
}
=
{
800
3
40
3
}
= vector of basic variables in
the optimum solution
(E1)
cB =
{
c3
c2
}
=
{
−30
−100
}
=
vector of original cost
coefficients corresponding
to the basic variables
(E2)
B =
[
4 10
1 40
]
= matrix of original coefficients
corresponding to the basic variables
(E3)
B−1 =
[
β33 β32
β23 β22
]
=
[
4
15
− 1
15
− 1
150
2
75
]
=
inverse of the coefficient
matrix B, which appears
in the final tableau also
(E4)
π = cTBB
−1 = (−30 − 100)
[
4
15
− 1
15
− 1
150
2
75
]
=
{
− 22
3
− 2
3
}
=
simplex multipliers, the
negatives of which appear
in the final tableau also
(E5)
Example 4.6 Find the effect of changing the total time available per day on the two
machines from 1200 and 800 min to 1500 and 1000 min in Example 4.5.
SOLUTION Equation (4.36) gives
xi +
m
∑
j=1
βijbj ≥ 0, i = 1, 2, . . . , m (4.36)
where xi is the optimum value of the ith basic variable. (This equation assumes that
the variables are renumbered such that x1 to xm represent the basic variables.)
212 Linear Programming II: Additional Topics and Extensions
If the variables are not renumbered, Eq. (4.36) will be applicable for i = 3 and
2 in the present problem with b3 = 300 and b2 = 200. From Eqs. (E1) to (E5) of
Example 4.5, the left-hand sides of Eq. (4.36) become
x3 + β33b3 + β32b2 = 8003 +
4
15
(300) − 1
15
(200) = 5000
15
x2 + β23b3 + β22b2 = 403 −
1
150
(300) + 2
75
(200) = 2500
150
Since both these values are ≥ 0, the original optimal basis B remains optimal even
with the new values of bi . The new values of the (optimal) basic variables are given
by Eq. (4.38) as
X′B =
{
x′3
x′2
}
= XB + XB = XB + B−1b
=
{
800
3
40
3
}
+
[
4
15
− 1
15
− 1
150
2
75
]
{
300
200
}
=
{
1000
3
50
3
}
and the optimum value of the objective function by Eq. (4.39) as
f ′min = fmin + f = fmin + c
T
BXB = −
28,000
3
+ (−30 − 100)
{
200
3
10
3
}
= −
35,000
3
Thus the new profit will be $35,000/3.
4.5.2 Changes in the Cost Coefficients cj
The problem here is to find the effect of changing the cost coefficients from cj to
cj + cj on the optimal solution obtained with cj . The relative cost coefficients cor-
responding to the nonbasic variables, xm+1, xm+2, . . . , xn are given by Eq. (4.10):
cj = cj − πTAj = cj −
m
∑
i=1
πiaij , j = m + 1, m + 2, . . . , n (4.40)
where the simplex multipliers πi are related to the cost coefficients of the basic variables
by the relation
πT = cTBB
−1
that is,
πi =
m
∑
k=1
ckβki, i = 1, 2, · · · , m (4.41)
From Eqs. (4.40) and (4.41), we obtain
cj = cj −
m
∑
i=1
aij
(
m
∑
k=1
ckβki
)
= cj −
m
∑
k=1
ck
(
m
∑
i=1
aijβki
)
,
i = m + 1, m + 2, . . . , n (4.42)
4.5 Sensitivity or Postoptimality Analysis 213
If the cj are changed to cj + cj , the original optimal solution remains optimal, pro-
vided that the new values of cj , c
′
j satisfy the relation
c ′j = cj + cj −
m
∑
k=1
(ck + ck)
(
m
∑
i=1
aijβki
)
≥ 0
= cj + cj −
m
∑
k=1
ck
(
m
∑
i=1
aijβki
)
≥ 0,
j = m + 1,m + 2, · · · , n (4.43)
where cj indicate the values of the relative cost coefficients corresponding to the
original optimal solution.
In particular, if changes are made only in the cost coefficients of the nonbasic
variables, Eq. (4.43) reduces to
cj + cj ≥ 0, j = m + 1, m + 2, . . . , n (4.44)
If Eq. (4.43) is satisfied, the changes made in cj , cj , will not affect the optimal basis
and the values of the basic variables. The only change that occurs is in the optimal
value of the objective function according to
f =
m
∑
j=1
xjcj (4.45)
and this change will be zero if only the cj of nonbasic variables are changed.
Suppose that Eq. (4.43) is violated for some of the nonbasic variables. Then it
is possible to improve the value of the objective function by bringing any nonbasic
variable that violates Eq. (4.43) into the basis provided that it can be assigned a nonzero
value. This can be done easily with the help of the previous optimal tableau. Since
some of the c ′j are negative, we start the optimization procedure again by using the old
optimum as an initial feasible solution. We continue the iterative process until the new
optimum is found. As in the case of changing the right-hand-side bi , the effectiveness
of this procedure depends on the number of violations made in Eq. (4.43) by the new
values cj + cj .
In some of the practical problems, it may become necessary to solve the opti-
mization problem with a series of objective functions. This can be accomplished
without reworking the entire problem for each new objective function. Assume that
the optimum solution for the first objective function is found by the regular proce-
dure. Then consider the second objective function as obtained by changing the first
one and evaluate Eq. (4.43). If the resulting c ′j ≥ 0, the old optimum still remains
as optimum and one can proceed to the next objective function in the same manner.
On the other hand, if one or more of the resulting c ′j < 0, we can adopt the proce-
dure outlined above and continue the iterative process using the old optimum as the
starting feasible solution. After the optimum is found, we switch to the next objective
function.
214 Linear Programming II: Additional Topics and Extensions
Example 4.7 Find the effect of changing c3 from −30 to −24 in Example 4.5.
SOLUTION Here c3 = 6 and Eq. (4.43) gives that
c′1 = c1 + c1 − c3[a21β32 + a31β33] = 253 + 0 − 6[3(−
1
15
) + 7( 4
15
)] = − 5
3
c′4 = c4 + c4 − c3[a24β32 + a34β33] = 503 + 0 − 6[1(−
1
15
) + 9( 4
15
)] = 8
3
c′5 = c5 + c5 − c3[a25β32 + a35β33] = 223 + 0 − 6[0(−
1
15
) + 1( 4
15
)] = 86
15
c′6 = c6 + c6 − c3[a26β32 + a36β33] = 23 + 0 − 6[1(−
1
15
) + 0( 4
15
)] = 16
15
The change in the value of the objective function is given by Eq. (4.45) as
f = c3x3 =
4800
3
so that f = −
28,000
3
+
4800
3
= −
23,200
3
Since c′1 is negative, we can bring x1 into the basis. Thus we start with the optimal
tableau of the original problem with the new values of relative cost coefficients and
improve the solution according to the regular procedure.
Variables Ratio bi/aij
Basic variables x1 x2 x3 x4 x5 x6 −f bi for aij > 0
x3
5
3
0 1 7
3
4
15
− 1
15
0 800
3
160 ←
Pivot element
x2
1
30
1 0 − 1
30
− 1
150
2
75
0 40
3
400
−f − 5
3
0 0 8
3
86
15
16
15
1 23,200
3
↑
x1 1 0
3
5
7
5
4
25
− 1
25
0 160
x2 0 1 − 150 −
2
25
− 3
250
7
250
0 8
−f 0 0 1 5 6 1 1 8000
Since all the relative cost coefficients are nonnegative, the present solution is optimum
with
x1 = 160, x2 = 8 (basic variables)
x3 = x4 = x5 = x6 = 0 (nonbasic variables)
fmin = −8000 and maximum profit = $8000
4.5.3 Addition of New Variables
Suppose that the optimum solution of a LP problem with n variables x1, x2, . . . , xn
has been found and we want to examine the effect of adding some more variables
xn+k, k = 1, 2, . . ., on the optimum solution. Let the constraint coefficients and the
4.5 Sensitivity or Postoptimality Analysis 215
cost coefficients corresponding to the new variables xn+k be denoted by ai,n+k, i = 1
to m and cn+k, respectively. If the new variables are treated as additional nonbasic
variables in the old optimum solution, the corresponding relative cost coefficients are
given by
cn+k = cn+k −
m
∑
i=1
πiai,n+k (4.46)
where π1, π2, . . . , πm are the simplex multipliers corresponding to the original optimum
solution. The original optimum remains optimum for the new problem also provided
that cn+k ≥ 0 for all k. However, if one or more cn+k < 0, it pays to bring some of
the new variables into the basis provided that they can be assigned a nonzero value.
For bringing a new variable into the basis, we first have to transform the coefficients
ai,n+k into ai,n+k so that the columns of the new variables correspond to the canonical
form of the old optimal basis. This can be done by using Eq. (4.9) as
An+k
m×1
= B−1
m×m
An+k
m×1
that is,
ai,n+k =
m
∑
j=1
βijaj,n+k, i = 1 to m (4.47)
where B−1 = [βij ] is the inverse of the old optimal basis. The rules for bringing a new
variable into the basis, finding a new basic feasible solution, testing this solution for
optimality, and the subsequent procedure is same as the one outlined in the regular
simplex method.
Example 4.8 In Example 4.5, if a new product, E, which requires 15 min of work on
the lathe and 10 min on the milling machine per unit, is available, will it be worthwhile
to manufacture it if the profit per unit is $40?
SOLUTION Let xk be the number of units of product E manufactured per day. Then
ck = −40, a1k = 15, and a2k = 10; therefore,
ck = ck − π1a1k − π2a2k = −40 + ( 223 )(15) + (
2
3
)(10) = 230
3
≥ 0
Since the relative cost coefficient ck is nonnegative, the original optimum solution
remains optimum for the new problem also and the variable xk will remain as a nonbasic
variable. This means that it is not worth manufacturing product E.
4.5.4 Changes in the Constraint Coefficients aij
Here the problem is to investigate the effect of changing the coefficient aij to aij + aij
after finding the optimum solution with aij . There are two possibilities in this case. The
first possibility occurs when all the coefficients aij , in which changes are made, belong
to the columns of those variables that are nonbasic in the old optimal solution. In this
case, the effect of changing aij on the optimal solution can be investigated by adopting
216 Linear Programming II: Additional Topics and Extensions
the procedure outlined in the preceding section. The second possibility occurs when
the coefficients changed aij correspond to a basic variable, say, xj0 of the old optimal
solution. The following procedure can be adopted to examine the effect of changing
ai,j0 to ai,j0 + ai,j0.
1. Introduce a new variable xn+1 to the original system with constraint coefficients
ai,n+1 = ai,j0 + ai,j0 (4.48)
and cost coefficient
cn+1 = cj0 (original value itself) (4.49)
2. Transform the coefficients ai,n+1 to ai,n+1 by using the inverse of the old optimal
basis, B−1 = [βij ], as
ai,n+1 =
m
∑
j=1
βijaj,n+1, i = 1 to m (4.50)
3. Replace the original cost coefficient (cj0) of xj0 by a large positive number N ,
but keep cn+1 equal to the old value cj0.
4. Compute the modified cost coefficients using Eq. (4.43):
c ′j = cj + cj −
m
∑
k=1
ck
(
m
∑
i=1
aijβki
)
,
j = m + 1, m + 2, · · · , n, n + 1 (4.51)
where ck = 0 for k = 1, 2, . . . , j0 − 1, j0 + 1, . . . , m and cj0 = N − cj0.
5. Carry the regular iterative procedure of simplex method with the new objective
function and the augmented matrix found in Eqs. (4.50) and (4.51) until the
new optimum is found.
Remarks:
1. The number N has to be taken sufficiently large to ensure that xj0 cannot be
contained in the new optimal basis that is ultimately going to be found.
2. The procedure above can easily be extended to cases where changes in coeffi-
cients aij of more than one column are made.
3. The present procedure will be computationally efficient (compared to reworking
of the problem from the beginning) only for cases where there are not too many
number of basic columns in which the aij are changed.
Example 4.9 Find the effect of changing A1 from
{
7
3
}
to
{
6
10
}
in Example 4.5 (i.e.,
changes are made in the coefficients aij of nonbasic variables only).
SOLUTION The relative cost coefficients of the nonbasic variables (of the original
optimum solution) corresponding to the new aij are given by
cj = cj − πTAj , j = nonbasic (1, 4, 5, 6)
4.5 Sensitivity or Postoptimality Analysis 217
Since A1 is changed, we have
c1 = c1 − πT A1 = −45 − (− 223 −
2
3
)
{
6
10
}
= 17
3
As c1 is positive, the original optimum solution remains optimum for the new problem
also.
Example 4.10 Find the effect of changing A1 from
{
7
3
}
to
{
5
6
}
in Example 4.5.
SOLUTION The relative cost coefficient of the nonbasic variable x1 for the new A1
is given by
c1 = c1 − πT A1 = −45 − (− 223 −
2
3
)
{
5
6
}
= − 13
3
Since c1 is negative, x1 can be brought into the basis to reduce the objective function
further. For this we start with the original optimum tableau with the new values of A1
given by
A1 = B−1A1 =
[
4
15
− 1
15
− 1
150
2
75
]{
5
6
}
=
[
20
15
− 6
15
− 1
30
+ 4
25
]
=
{
14
15
19
150
}
Variables
Basic variables x1 x2 x3 x4 x5 x6 −f bi (bi/ais)
x3
14
15
0 1 7
3
4
15
− 1
15
0 800
3
4000
14
x2
19
150
1 0 − 1
30
− 1
150
2
75
0 40
3
2000
19
←
Pivot element
−f − 13
3
0 0 50
3
22
3
2
3
1 28,000
3
↑
x3 0 − 14019 1
49
19
6
19
− 5
19
0 3,200
19
x1 1
150
19
0 − 5
19
− 1
19
4
19
0 2,000
19
−f 0 650
19
0 295
19
135
19
30
19
1 186,000
19
Since all cj are nonnegative, the present tableau gives the new optimum solution as
x1 = 2000/19, x3 = 3200/19 (basic variables)
x2 = x4 = x5 = x6 = 0 (nonbasic variables)
fmin = −
186,000
19
and maximum profit =
$186,000
19
218 Linear Programming II: Additional Topics and Extensions
4.5.5 Addition of Constraints
Suppose that we have solved a LP problem with m constraints and obtained the optimal
solution. We want to examine the effect of adding some more inequality constraints on
the original optimum solution. For this we evaluate the new constraints by substituting
the old optimal solution and see whether they are satisfied. If they are satisfied, it means
that the inclusion of the new constraints in the old problem would not have affected
the old optimum solution, and hence the old optimal solution remains optimal for the
new problem also. On the other hand, if one or more of the new constraints are not
satisfied by the old optimal solution, we can solve the problem without reworking the
entire problem by proceeding as follows.
1. The simplex tableau corresponding to the old optimum solution expresses all the
basic variables in terms of the nonbasic ones. With this information, eliminate
the basic variables from the new constraints.
2. Transform the constraints thus obtained by multiplying throughout by −1.
3. Add the resulting constraints to the old optimal tableau and introduce one arti-
ficial variable for each new constraint added. Thus the enlarged system of
equations will be in canonical form since the old basic variables were elim-
inated from the new constraints in step 1. Hence a new basis, consisting of the
old optimal basis plus the artificial variables in the new constraint equations,
will be readily available from this canonical form.
4. Go through phase I computations to eliminate the artificial variables.
5. Go through phase II computations to find the new optimal solution.
Example 4.11 If each of the products A, B,C, and D require, respectively, 2, 5, 3,
and 4 min of time per unit on grinding machine in addition to the operations specified
in Example 4.5, find the new optimum solution. Assume that the total time available
on grinding machine per day is 600 min and all this time has to be utilized fully.
SOLUTION The present data correspond to the addition of a constraint that can be
stated as
2x1 + 5x2 + 3x3 + 4x4 = 600 (E1)
By substituting the original optimum solution,
x2 = 403 , x3 =
800
3
, x1 = x4 = x5 = x6 = 0
the left-hand side of Eq. (E1) gives
2(0) + 5( 40
3
) + 3( 800
3
) + 4(0) = 2600
3
= 600
Thus the new constraint is not satisfied by the original optimum solution. Hence we
proceed as follows.
Step 1 From the original optimum tableau, we can express the basic variables as
x3 = 8003 −
5
3
x1 − 73x4 −
4
15
x5 + 115x6
x2 = 403 −
1
30
x1 + 130x4 +
1
150
x5 − 175x6
4.5 Sensitivity or Postoptimality Analysis 219
Thus Eq. (E1) can be expressed as
2x1 + 5( 403 −
1
30
x1 + 130x4 +
1
150
x5 − 275x6)
+ 3( 800
3
− 5
3
x1 − 73x4 −
4
15
x5 + 115x6) + 4x4 = 600
that is,
− 19
6
x1 − 176 x4 −
23
30
x5 + 115x6 = −
800
3
(E2)
Step 2 Transform this constraint such that the right-hand side becomes positive,
that is,
19
6
x1 + 176 x4 +
23
30
x5 − 115x6 =
800
3
(E3)
Step 3 Add an artifical variable, say, xk , the new constraint given by Eq. (E3) and the
infeasibility form w = xk into the original optimum tableau to obtain the new
canonical system as follows:
Basic Variables
variables x1 x2 x3 x4 x5 x6 xk −f −w bi (bi/ais)
x3
5
3
0 1 7
3
4
5
− 1
15
0 0 0 800
3
160
x2
1
30
1 0 − 1
30
− 1
150
2
75
0 0 0 40
3
400
xk
19
6
0 0 17
6
23
30
− 1
15
1 0 0 800
3
1600
19
Pivot element
−f 25
3
0 0 50
3
22
3
2
3
0 1 0 28,000
3
−w − 19
6
0 0 − 17
6
− 23
30
1
15
0 0 1 − 800
3
↑
Step 4 Eliminate the artificial variable by applying the phase I procedure:
Basic Variables
variables x1 x2 x3 x4 x5 x6 xk −f −w bi
x3 0 0 1
16
19
113
285
− 3
95
− 10
19
0 0 2,400
19
x2 0 1 0 − 695 −
7
475
13
475
− 1
95
0 0 200
19
x1 1 0 0
17
19
23
95
− 2
95
6
19
0 0 1,600
19
−f 0 0 0 175
19
101
19
16
19
− 50
19
1 0 164,000
19
−w 0 0 0 0 0 0 0 0 1 0
Thus the new optimum solution is given by
x1 = 160019 , x2 =
200
19
, x3 = 240019 (basic variables)
x4 = x5 = x6 = 0 (nonbasic variables)
fmin = −
164,000
19
and maximum profit =
$164,000
19
220 Linear Programming II: Additional Topics and Extensions
4.6 TRANSPORTATION PROBLEM
This section deals with an important class of LP problems called the transportation
problem. As the name indicates, a transportation problem is one in which the objec-
tive for minimization is the cost of transporting a certain commodity from a number
of origins to a number of destinations. Although the transportation problem can be
solved using the regular simplex method, its special structure offers a more convenient
procedure for solving this type of problems. This procedure is based on the same the-
ory of the simplex method, but it makes use of some shortcuts that yield a simpler
computational scheme.
Suppose that there are m origins R1, R2, · · · , Rm (e.g., warehouses) and n des-
tinations, D1,D2, · · · , Dn (e.g., factories). Let ai be the amount of a commodity
available at origin i (i = 1, 2, . . . , m) and bj be the amount required at destination
j (j = 1, 2, . . . , n). Let cij be the cost per unit of transporting the commodity from
origin i to destination j . The objective is to determine the amount of commodity (xij )
transported from origin i to destination j such that the total transportation costs are
minimized. This problem can be formulated mathematically as
Minimize f =
m
∑
i=1
n
∑
j=1
cij (4.52)
subject to
n
∑
j=1
xij = ai, i = 1, 2, . . . , m (4.53)
m
∑
i=1
xij = bj , j = 1, 2, . . . , n (4.54)
xij ≥ 0, i = 1, 2, . . . , m, j = 1, 2, . . . , n (4.55)
Clearly, this is a LP problem in mn variables and m + n equality constraints.
Equations (4.53) state that the total amount of the commodity transported from
the origin i to the various destinations must be equal to the amount available at origin
i (i = 1, 2, . . . , m), while Eqs. (4.54) state that the total amount of the commodity
received by destination j from all the sources must be equal to the amount required at
the destination j (j = 1, 2, . . . , n). The nonnegativity conditions Eqs. (4.55) are added
since negative values for any xij have no physical meaning. It is assumed that the total
demand equals the total supply, that is,
m
∑
i=1
ai =
n
∑
j=1
bj (4.56)
Equation (4.56), called the consistency condition , must be satisfied if a solution is to
exist. This can be seen easily since
m
∑
i=1
ai =
m
∑
i=1


n
∑
j=1
xij

 =
n
∑
j=1
(
m
∑
i=1
xij
)
=
n
∑
j=1
bj (4.57)
4.6 Transportation Problem 221
The problem stated in Eqs. (4.52) to (4.56) was originally formulated and solved by
Hitchcock in 1941 [4.6]. This was also considered independently by Koopmans in
1947 [4.7]. Because of these early investigations the problem is sometimes called the
Hitchcock-Koopmans transportation problem. The special structure of the transportation
matrix can be seen by writing the equations in standard form:
x11 + x12 + · · · + x1n = a1
x21 + x22 + · · · + x2n = a2
...
...
xm1 + xm2 + · · · + xmn= am
(4.58a)
x11 + x21 + xm1 = b1
x12 + x22 + xm2 = b2
...
...
...
x1n + x2n + xmn = bn
(4.58b)
c11x11 + c12x12 + · · · + c1nx1n + c21x21 + · · · + c2nx2n + · · ·
+ cm1xm1 + · · · + cmnxmn = f (4.58c)
We notice the following properties from Eqs. (4.58):
1. All the nonzero coefficients of the constraints are equal to 1.
2. The constraint coefficients appear in a triangular form.
3. Any variable appears only once in the first m equations and once in the next n
equations.
These are the special properties of the transportation problem that allow devel-
opment of the transportation technique. To facilitate the identification of a starting
solution, the system of equations (4.58) is represented in the form of an array, called
the transportation array , as shown in Fig. 4.2. In all the techniques developed for solv-
ing the transportation problem, the calculations are made directly on the transportation
array.
Computational Procedure. The solution of a LP problem, in general, requires a
calculator or, if the problem is large, a high-speed digital computer. On the other hand,
the solution of a transportation problem can often be obtained with the use of a pencil
and paper since additions and subtractions are the only calculations required. The basic
steps involved in the solution of a transportation problem are
1. Determine a starting basic feasible solution.
2. Test the current basic feasible solution for optimality. If the current solution is
optimal, stop the iterative process; otherwise, go to step 3.
3. Select a variable to enter the basis from among the current nonbasic variables.
222 Linear Programming II: Additional Topics and Extensions
Figure 4.2 Transportation array.
4. Select a variable to leave from the basis from among the current basic variables
(using the feasibility condition).
5. Find a new basic feasible solution and return to step 2.
The details of these steps are given in Ref. [4.10].
4.7 KARMARKAR’S INTERIOR METHOD
Karmarkar proposed a new method in 1984 for solving large-scale linear programming
problems very efficiently. The method is known as an interior method since it finds
improved search directions strictly in the interior of the feasible space. This is in
contrast with the simplex method, which searches along the boundary of the feasible
space by moving from one feasible vertex to an adjacent one until the optimum point
is found. For large LP problems, the number of vertices will be quite large and hence
the simplex method would become very expensive in terms of computer time. Along
with many other applications, Karmarkar’s method has been applied to aircraft route
scheduling problems. It was reported [4.19] that Karmarkar’s method solved problems
involving 150,000 design variables and 12,000 constraints in 1 hour while the simplex
method required 4 hours for solving a smaller problem involving only 36,000 design
variables and 10,000 constraints. In fact, it was found that Karmarkar’s method is as
much as 50 times faster than the simplex method for large problems.
4.7 Karmarkar’s Interior Method 223
Figure 4.3 Improvement of objective function from different points of a polytope.
Karmarkar’s method is based on the following two observations:
1. If the current solution is near the center of the polytope, we can move along the
steepest descent direction to reduce the value of f by a maximum amount. From
Fig. 4.3, we can see that the current solution can be improved substantially by
moving along the steepest descent direction if it is near the center (point 2) but
not near the boundary point (points 1 and 3).
2. The solution space can always be transformed without changing the nature of
the problem so that the current solution lies near the center of the polytope.
It is well known that in many numerical problems, by changing the units of data or
rescaling (e.g., using feet instead of inches), we may be able to reduce the numerical
instability. In a similar manner, Karmarkar observed that the variables can be trans-
formed (in a more general manner than ordinary rescaling) so that straight lines remain
straight lines while angles and distances change for the feasible space.
4.7.1 Statement of the Problem
Karmarkar’s method requires the LP problem in the following form:
Minimize f = cTX
subject to
[a]X = 0
x1 + x2 + · · · + xn = 1 (4.59)
X ≥ 0
224 Linear Programming II: Additional Topics and Extensions
where X = {x1, x2, . . . , xn}T, c = {c1, c2, . . . , cn}T, and [a] is an m × n matrix. In
addition, an interior feasible starting solution to Eqs. (4.59) must be known. Usually,
X =
{
1
n
,
1
n
, · · ·
1
n
}T
is chosen as the starting point. In addition, the optimum value of f must be zero for
the problem. Thus
X(1) =
{
1
n
1
n
· · ·
1
n
}T
= interior feasible
fmin = 0
(4.60)
Although most LP problems may not be available in the form of Eq. (4.59) while
satisfying the conditions of Eq. (4.60), it is possible to put any LP problem in a form
that satisfies Eqs. (4.59) and (4.60) as indicated below.
4.7.2 Conversion of an LP Problem into the Required Form
Let the given LP problem be of the form
Minimize dTX
subject to
[α]X = b
X ≥ 0
(4.61)
To convert this problem into the form of Eq. (4.59), we use the procedure suggested
in Ref. [4.20] and define integers m and n such that X will be an (n − 3)-component
vector and [α] will be a matrix of order m − 1 × n − 3. We now define the vector
z = {z1, z2, · · · , zn−3}T as
z =
X
β
(4.62)
where β is a constant chosen to have a sufficiently large value such that
β >
n−3
∑
i=1
xi (4.63)
for any feasible solution X (assuming that the solution is bounded). By using Eq. (4.62),
the problem of Eq. (4.61) can be stated as follows:
Minimize βdTz
subject to
[α]z =
1
β
b
z ≥ 0
(4.64)
4.7 Karmarkar’s Interior Method 225
We now define a new vector z as
z =







z
zn−2
zn−1
zn







and solve the following related problem instead of the problem in Eqs. (4.64):
Minimize {βdT 0 0 M} z
subject to


[α] 0 −
n
β
b
(
n
β
b − [α]e
)
0 0 n 0

 z =
{
0
1
}
eT z + zn−2 + zn−1 + zn = 1
z ≥ 0
(4.65)
where e is an (m − 1)-component vector whose elements are all equal to 1, zn−2 is a
slack variable that absorbs the difference between 1 and the sum of other variables,
zn−1 is constrained to have a value of 1/n, and M is given a large value (corresponding
to the artificial variable zn) to force zn to zero when the problem stated in Eqs. (4.61)
has a feasible solution. Equations (4.65) are developed such that if z is a solution to
these equations, X = βz will be a solution to Eqs. (4.61) if Eqs. (4.61) have a feasible
solution. Also, it can be verified that the interior point z = (1/n)e is a feasible solution
to Eqs. (4.65). Equations (4.65) can be seen to be the desired form of Eqs. (4.61) except
for a 1 on the right-hand side. This can be eliminated by subtracting the last constraint
from the next-to-last constraint, to obtain the required form:
Minimize {βdT 0 0 M}z
subject to


[α] 0 −
n
β
b
(
n
β
b − [α]e
)
−eT −1 (n − 1) −1

 z =
{
0
0
}
eTz + zn−2 + zn−1 + zn = 1
z ≥ 0
(4.66)
Note: When Eqs. (4.66) are solved, if the value of the artificial variable zn > 0,
the original problem in Eqs. (4.61) is infeasible. On the other hand, if the value
of the slack variable zn−2 = 0, the solution of the problem given by Eqs. (4.61) is
unbounded.
Example 4.12 Transform the following LP problem into a form required by Kar-
markar’s method:
Minimize 2x1 + 3x2
226 Linear Programming II: Additional Topics and Extensions
subject to
3x1 + x2 − 2x3 = 3
5x1 − 2x2 = 2
xi ≥ 0, i = 1, 2, 3
SOLUTION It can be seen that
d = {2 3 0}T, [α] =
[
3 1 −2
5 −2 0
]
, b =
{
3
2
}
, and X =



x1
x2
x3



We define the integers m and n as n = 6 and m = 3 and choose β = 10 so that
z =
1
10



z1
z2
z3



Noting that e = {1, 1, 1}T, Eqs. (4.66) can be expressed as
Minimize {20 30 0 0 0 M} z
subject to


[
3 1 −2
5 −2 0
] {
0
0
}
−
6
10
{
3
2
}
×


6
10
{
3
2
}
−
[
3 1 −2
5 −2 0
]



1
1
1






 z = 0
{−{1 1 1} − 1 5 − 1} z = 0
z1 + z2 + z3 + z4 + z5 + z6 = 1
z = {z1 z2 z3 z4 z5 z6}T ≥ 0
where M is a very large number. These equations can be seen to be in the desired
form.
4.7.3 Algorithm
Starting from an interior feasible point X(1), Karmarkar’s method finds a sequence of
points X(2), X(3), · · · using the following iterative procedure:
1. Initialize the iterative process. Begin with the center point of the simplex as the
initial feasible point
X(1) =
{
1
n
1
n
· · ·
1
n
}T
.
Set the iteration number as k = 1.
4.7 Karmarkar’s Interior Method 227
2. Test for optimality. Since f = 0 at the optimum point, we stop the procedure
if the following convergence criterion is satisfied:
||cT X(k)|| ≤ ε (4.67)
where ε is a small number. If Eq. (4.67) is not satisfied, go to step 3.
3. Compute the next point, X(k+1). For this, we first find a point Y(k+1) in the
transformed unit simplex as
Y(k+1) =
{
1
n
1
n
· · ·
1
n
}T
−
α([I ] − [P ]T([P ][P ]T)−1[P ])[D(X(k))]c
||c||
√
n(n − 1)
(4.68)
where ||c|| is the length of the vector c, [I ] the identity matrix of order n,
[D(X(k))] an n × n matrix with all off-diagonal entries equal to 0, and diagonal
entries equal to the components of the vector X(k) as
[D(X(k))]ii = x(k)i , i = 1, 2, . . . , n (4.69)
[P ] is an (m + 1) × n matrix whose first m rows are given by [a] [D(X(k))]
and the last row is composed of 1’s:
[P ] =
[
[a][D(X(k))]
1 1 · · · 1
]
(4.70)
and the value of the parameter α is usually chosen as α = 1
4
to ensure con-
vergence. Once Y(k+1) is found, the components of the new point X(k+1) are
determined as
x
(k+1)
i =
x
(k)
i y
(k+1)
i
∑n
r=1 x
(k)
r y
(k+1)
r
, i = 1, 2, . . . , n (4.71)
Set the new iteration number as k = k + 1 and go to step 2.
Example 4.13 Find the solution of the following problem using Karmarkar’s method:
Minimize f = 2x1 + x2 − x3
subject to
x2 − x3 = 0
x1 + x2 + x3 = 1
xi ≥ 0, i = 1, 2, 3 (E.1)
Use the value of ε = 0.05 for testing the convergence of the procedure.
SOLUTION The problem is already in the required form of Eq. (4.59), and hence
the following iterative procedure can be used to find the solution of the problem.
228 Linear Programming II: Additional Topics and Extensions
Step 1 We choose the initial feasible point as
X(1) =







1
3
1
3
1
3







and set k = 1.
Step 2 Since |f (X(1))| = | 2
3
|> 0.05, we go to step 3.
Step 3 Since [a] = {0, 1, −1}, c = {2, 1, −1}T, ||c|| =
√
(2)2 + (1)2 + (−1)2 =
√
6,
we find that
[D(X(1))] =




1
3
0 0
0 1
3
0
0 0 1
3




[a][D(X(1))] = {0 1
3
− 1
3
}
[P ] =
[
[a][D(X(1))]
1 1 1
]
=
[
0 1
3
− 1
3
1 1 1
]
([P ][P ]T)−1 =
[
2
9
0
0 3
]−1
=
[
9
2
0
0 1
3
]
[D(X(1))]c =




1
3
0 0
0 1
3
0
0 0 1
3







2
1
−1



=







2
3
1
3
− 1
3







([I ] − [P ]T([P ][P ]T)−1[P ])[D(X(1))]c
=





1 0 0
0 1 0
0 0 1

 −



0 1
1
3
1
− 1
3
1



[
9
2
0
0 1
3
][
0 1
3
− 1
3
1 1 1
]










2
3
1
3
− 1
3







=




2
3
− 1
3
− 1
3
− 1
3
1
6
1
6
− 1
3
1
6
1
6











2
3
1
3
− 1
3







=







4
9
− 2
9
− 2
9







Using α = 1
4
, Eq. (4.68) gives
Y(2) =







1
3
1
3
1
3







− 1
4







4
9
− 2
9
− 2
9







1
√
3(2)
√
6
=







34
108
37
108
37
108







4.8 Quadratic Programming 229
Noting that
n
∑
r=1
x(1)r y
(2)
r = 13 (
34
108
) + 1
3
( 37
108
) + 1
3
( 37
108
) = 1
3
Eq. (4.71) can be used to find
{x(2)i } =









x
(1)
i y
(2)
i
3∑
r=1
x
(1)
r y
(2)
r









= 3









34
324
37
324
37
324









=







34
108
37
108
37
108







Set the new iteration number as k = k + 1 = 2 and go to step 2. The procedure
is to be continued until convergence is achieved.
Notes:
1. Although X(2) = Y(2) in this example, they need not be, in general, equal to
one another.
2. The value of f at X(2) is
f (X(2)) = 2( 34
108
) + 37
108
− 37
108
= 17
27
< f (X(1)) = 18
27
4.8 QUADRATIC PROGRAMMING
A quadratic programming problem can be stated as
Minimize f (X) = CTX + 1
2
XT DX (4.72)
subject to
AX ≤ B (4.73)
X ≥ 0 (4.74)
where
X =









x1
x2
...
xn









, C =









c1
c2
...
cn









, B =









b1
b2
...
bm









,
D =





d11 d12 · · · d1n
d21 d22 · · · d2n
...
dn1 dn2 · · · dnn





, and A =





a11 a12 · · · a1n
a21 a22 · · · a2n
...
am1 am2 · · · amn





In Eq. (4.72) the term XTDX/2 represents the quadratic part of the objective
function with D being a symmetric positive-definite matrix. If D = 0, the problem
230 Linear Programming II: Additional Topics and Extensions
reduces to a LP problem. The solution of the quadratic programming problem stated
in Eqs. (4.72) to (4.74) can be obtained by using the Lagrange multiplier technique.
By introducing the slack variables s2i , i = 1, 2, . . . , m, in Eqs. (4.73) and the surplus
variables t2j , j = 1, 2, . . . , n, in Eqs. (4.74), the quadratic programming problem can
be written as
Minimize f (X) = CTX + 1
2
XTDX (4.72)
subject to the equality constraints
ATi X + s
2
i = bi, i = 1, 2, . . . , m (4.75)
−xj + t2j = 0, j = 1, 2, . . . , n (4.76)
where
Ai =









ai1
ai2
...
ain









The Lagrange function can be written as
L(X, S, T,λ, θ) = CTX + 1
2
XTDX +
m∑
i=1
λi(A
T
i X + s2i − bi)
+
n
∑
j=1
θj (−xj + t2j ) (4.77)
The necessary conditions for the stationariness of L give
∂L
∂xj
= cj +
n
∑
i=1
dijxi +
m
∑
i=1
λiaij − θj = 0, j = 1, 2, . . . , n (4.78)
∂L
∂si
= 2λisi = 0, i = 1, 2, . . . , m (4.79)
∂L
∂tj
= 2θj tj = 0, j = 1, 2, . . . , n (4.80)
∂L
∂λi
= ATi X + s
2
i − bi = 0, i = 1, 2, . . . , m (4.81)
∂L
∂θj
= −xj + t2j = 0, j = 1, 2, . . . , n (4.82)
By defining a set of new variables Yi as
Yi = s2i ≥ 0, i = 1, 2, . . . , m (4.83)
Equations (4.81) can be written as
ATi X − bi = −s
2
i = −Yi, i = 1, 2, . . . , m (4.84)
4.8 Quadratic Programming 231
Multiplying Eq. (4.79) by si and Eq. (4.80) by tj , we obtain
λis
2
i = λiYi = 0, i = 1, 2, . . . , m (4.85)
θj t
2
j = 0, j = 1, 2, . . . , n (4.86)
Combining Eqs. (4.84) and (4.85), and Eqs. (4.82) and (4.86), we obtain
λi(A
T
i X − bi) = 0, i = 1, 2, . . . , m (4.87)
θjxj = 0, j = 1, 2, . . . , n (4.88)
Thus the necessary conditions can be summarized as follows:
cj − θj +
n
∑
i=1
xidij +
m
∑
i=1
λiaij = 0, j = 1, 2, . . . , n (4.89)
ATi X − bi = −Yi, i = 1, 2, . . . , m (4.90)
xj ≥ 0, j = 1, 2, . . . , n (4.91)
Yi ≥ 0, i = 1, 2, . . . , m (4.92)
λi ≥ 0, i = 1, 2, . . . , m (4.93)
θj ≥ 0, j = 1, 2, . . . , n (4.94)
λiYi = 0, i = 1, 2, . . . , m (4.95)
θjxj = 0, j = 1, 2, . . . , n (4.96)
We can notice one important thing in Eqs. (4.89) to (4.96). With the exception of
Eqs. (4.95) and (4.96), the necessary conditions are linear functions of the variables
xj , Yi, λi , and θj . Thus the solution of the original quadratic programming problem
can be obtained by finding a nonnegative solution to the set of m + n linear equations
given by Eqs. (4.89) and (4.90), which also satisfies the m + n equations stated in Eqs.
(4.95) and (4.96).
Since D is a positive-definite matrix, f (X) will be a strictly convex function,† and
the feasible space is convex (because of linear equations), any local minimum of the
problem will be the global minimum. Further, it can be seen that there are 2 (n + m)
variables and 2 (n + m) equations in the necessary conditions stated in Eqs. (4.89) to
(4.96). Hence the solution of the Eqs. (4.89), (4.90), (4.95), and (4.96) must be unique.
Thus the feasible solution satisfying all the Eqs. (4.89) to (4.96), if it exists, must give
the optimum solution of the quadratic programming problem directly. The solution
of the system of equations above can be obtained by using phase I of the simplex
method. The only restriction here is that the satisfaction of the nonlinear relations, Eqs.
(4.95) and (4.96), has to be maintained all the time. Since our objective is just to find
a feasible solution to the set of Eqs. (4.89) to (4.96), there is no necessity of phase
II computations. We shall follow the procedure developed by Wolfe [4.21] to apply
†See Appendix A for the definition and properties of a convex function.
232 Linear Programming II: Additional Topics and Extensions
phase I. This procedure involves the introduction of n nonnegative artificial variables
zi into the Eqs. (4.89) so that
cj − θj +
n
∑
i=1
xidij +
m
∑
i=1
λiaij + zj = 0, j = 1, 2, . . . , n (4.97)
Then we minimize
F =
n
∑
j=1
zj (4.98)
subject to the constraints
cj − θj +
n
∑
i=1
xidij +
m
∑
i=1
λiaij + zj = 0, j = 1, 2, . . . , n
ATi X + Yi = bi, i = 1, 2, . . . , m
X ≥ 0, Y ≥ 0, λ ≥ 0, θ ≥ 0
While solving this problem, we have to take care of the additional conditions
λiYi = 0, j = 1, 2, . . . , m
θjxj = 0, j = 1, 2, . . . , n
(4.99)
Thus when deciding whether to introduce Yi into the basic solution, we first have to
ensure that either λi is not in the solution or λi will be removed when Yi enters the
basis. Similar care has to be taken regarding the variables θj and xj . These additional
checks are not very difficult to make during the solution procedure.
Example 4.14
Minimize f = −4x1 + x21 − 2x1x2 + 2x
2
2
subject to
2x1 + x2 ≤ 6
x1 − 4x2 ≤ 0
x1 ≥ 0, x2 ≥ 0
SOLUTION By introducing the slack variables Y1 = s21 and Y2 = s22 and the surplus
variables θ1 = t21 and θ2 = t22 , the problem can be stated as follows:
Minimize f = (−4 0)
{
x1
x2
}
+
1
2
(x1 x2)
[
2 −2
−2 4
]{
x1
x2
}
subject to
[
2 1
1 −4
]{
x1
x2
}
+
{
Y1
Y2
}
=
{
6
0
}
−x1 + θ1 = 0
−x2 + θ2 = 0
(E1)
4.8 Quadratic Programming 233
By comparing this problem with the one stated in Eqs. (4.72) to (4.74), we find that
c1 = −4, c2 = 0, D =
[
2 −2
−2 4
]
, A =
[
2 1
1 −4
]
,
A1 =
{
2
1
}
, A2 =
{
1
−4
}
, and B =
{
6
0
}
The necessary conditions for the solution of the problem stated in Eqs. (E1) can be
obtained, using Eqs. (4.89) to (4.96), as
−4 − θ1 + 2x1 − 2x2 + 2λ1 + λ2 = 0
0 − θ2 − 2x1 + 4x2 + λ1 − 4λ2 = 0
2x1 + x2 − 6 = −Y1
x1 − 4x2 − 0 = −Y2
(E2)
x1 ≥ 0, x2 ≥ 0, Y1 ≥ 0, Y2 ≥ 0, λ1 ≥ 0,
λ2 ≥ 0, θ1 ≥ 0, θ2 ≥ 0
(E3)
λ1Y1 = 0, θ1x1 = 0
λ2Y2 = 0, θ2x2 = 0
(E4)
(If Yi is in the basis, λi cannot be in the basis, and if xj is in the basis, θj cannot be
in the basis to satisfy these equations.) Equations (E2) can be rewritten as
2x1 − 2x2 + 2λ1 + λ2 − θ1 + z1 = 4
−2x1 + 4x2 + λ1 − 4λ2 − θ2 + z2 = 0
2x1 + x2 + Y1 = 6
x1 − 4x2 + Y2 = 0
(E5)
where z1 and z2 are artificial variables. To find a feasible solution to Eqs. (E2) to (E4)
by using phase I of simplex method, we minimize w = z1 + z2 with constraints stated
in Eqs. (E5), (E3), and (E4). The initial simplex tableau is shown below:
Basic Variables bi/ais
variables x1 x2 λ1 λ2 θ1 θ2 Y1 Y2 z1 z2 w bi for ais > 0
Y1 2 1 0 0 0 0 1 0 0 0 0 6 6
Y2 1 −4 0 0 0 0 0 1 0 0 0 0
z1 2 −2 2 1 −1 0 0 0 1 0 0 4
z2 −2 4 1 −4 0 −1 0 0 0 1 0 0 0 ← Smaller
one
−w 0 −2 −3 3 1 1 0 0 0 0 1 −4
↑ ↑
x2 selected for Most negative
entering next basis
234 Linear Programming II: Additional Topics and Extensions
According to the regular procedure of simplex method, λ1 enters the next basis since
the cost coefficient of λ1 is most negative and z2 leaves the basis since the ratio bi/ais
is smaller for z2. However, λ1 cannot enter the basis, as Y1 is already in the basis [to
satisfy Eqs. (E4)]. Hence we select x2 for entering the next basis. According to this
choice, z2 leaves the basis. By carrying out the required pivot operation, we obtain the
following tableau:
Basic Variables bi/ais
variables x1 x2 λ1 λ2 θ1 θ2 Y1 Y2 z1 z2 w bi for ais > 0
Y1
5
2
0 − 1
4
1 0 1
4
1 0 0 − 1
4
0 6 12
5
←Smaller
one
Y2 −1 0 1 −4 0 −1 0 1 0 1 0 0
z1 1 0
5
2
−1 −1 − 1
2
0 0 1 1
2
0 4 4
x2 − 12 1
1
4
−1 0 − 1
4
0 0 0 1
4
0 0
−w −1 0 − 5
2
1 1 1
2
0 0 0 1
2
1 −4
↑ ↑
x1 selected to Most negative
enter the basis
This tableau shows that λ1 has to enter the basis and Y2 or x2 has to leave the basis.
However, λ1 cannot enter the basis since Y1 is already in the basis [to satisfy the
requirement of Eqs. (E4)]. Hence x1 is selected to enter the basis and this gives Y1 as
the variable that leaves the basis. The pivot operation on the element 5
2
results in the
following tableau:
Basic Variables bi/ais
variables x1 x2 λ1 λ2 θ1 θ2 Y1 Y2 z1 z2 w bi for ais > 0
x1 1 0 − 110
2
5
0 1
10
2
5
0 0 − 1
10
0 12
5
Y2 0 0
9
10
− 18
5
0 − 9
10
2
5
1 0 9
10
0 12
5
8
3
z1 0 0
13
5
− 7
5
−1 − 3
5
− 2
5
0 1 3
5
0 8
5
8
13
←Smaller
one
x2 0 1
1
5
− 4
5
0 − 1
5
1
5
0 0 1
5
0 6
5
6
−w 0 0 − 13
5
7
5
1 3
5
2
5
0 0 2
5
1 − 8
5
↑
Most negative
From this tableau we find that λ1 enters the basis (this can be permitted this time since
Y1 is not in the basis) and z1 leaves the basis. The necessary pivot operation gives the
following tableau:
4.9 MATLAB Solutions 235
Basic Variables bi/ais
variables x1 x2 λ1 λ2 θ1 θ2 Y1 Y2 z1 z2 w bi for ais>0
x1 1 0 0
9
26
− 1
26
1
13
5
13
0 1
26
− 1
13
0 32
13
Y2 0 0 0 − 8126
9
26
− 9
13
7
13
1 − 9
26
9
13
0 24
13
λ1 0 0 1 − 713 −
5
13
− 3
13
− 2
13
0 5
13
3
13
0 8
13
x2 0 1 0 − 913
1
13
− 2
13
3
13
0 − 1
13
2
13
0 14
13
−w 0 0 0 0 0 0 0 0 1 1 1 0
Since both the artificial variables z1 and z2 are driven out of the basis, the present tableau
gives the desired solution as x1 = 3213 , x2 =
14
13
, Y2 = 2413 , λ1 =
8
13
(basic variables),
λ2 = 0, Y1 = 0, θ1 = 0, θ2 = 0 (nonbasic variables). Thus the solution of the original
quadratic programming problem is given by
x∗1 = 3213 , x
∗
2 =
14
13
, and fmin = f (x∗1 , x∗2 ) = −
88
13
4.9 MATLAB SOLUTIONS
The solutions of linear programming problems, based on interior point method, and
quadratic programming problems using MATLAB are illustrated by the following
examples.
Example 4.15 Find the solution of the following linear programming problem using
MATLAB (interior point method):
Minimize f = −x1 − 2x2 − x3
subject to
2x1 + x2 − x3 ≤ 2
2x1 − x2 + 5x3 ≤ 6
4x1 + x2 + x3 ≤ 6
xi ≥ 0 ; i = 1, 2, 3
SOLUTION
Step 1 Express the objective function in the form f (x) = f Tx and identify the vectors
x and f as
x =



x1
x2
x3



and f =



−1
−2
−1



236 Linear Programming II: Additional Topics and Extensions
Express the constraints in the form A x ≤ b and identify the matrix A and the
vector b as
A =


2 1 −1
2 −1 5
4 1 1

 and b =



2
6
6



Step 2 Use the command for executing linear programming program using interior
point method as indicated below:
clc
clear all
f=[–1;–2;–1];
A=[2 1—1;
2—1 5;
4 1 1];
b=[2;6;6];
lb=zeros(3,1);
Aeq=[];
beq=[];
options = optimset('Display', 'iter');
[x,fval,exitflag,output] = linprog(f,A,b,Aeq,beq,lb,[],[],
options)
This produces the solution or ouput as follows:
Iter 0: 1.03e+003 7.97e+000 1.50e+003 4.00e+002
Iter 1: 4.11e+002 2.22e–016 2.78e+002 4.72e+001
Iter 2: 1.16e–013 1.90e–015 2.85e+000 2.33e–001
Iter 3: 1.78e–015 1.80e–015 3.96e–002 3.96e–003
Iter 4: 7.48e–014 1.02e–015 1.99e–006 1.99e–007
Iter 5: 2.51e–015 4.62e–015 1.99e–012 1.98e–013
Optimization terminated.
x =
0.0000
4.0000
2.0000
fval = -10.0000
exitflag = 1
output =
iterations: 5
algorithm: 'large-scale: interior point'
cgiterations: 0
message: 'Optimization terminated.'
References and Bibliography 237
Example 4.16 Find the solution of the following quadratic programming problem
using MATLAB:
Minimize f = −4x1 + x21 − 2x1x2 + 2x
2
2
subject to 2x1 + x2 ≤ 6, x1 − 4x2 ≤ 0, x1 ≥ 0, x2 ≥ 0
SOLUTION
Step 1 Express the objective function in the form f (x) = 1
2
xTHx + f Tx and identify
the matrix H and vectors f and x:
H =
(
2 −2
−2 4
)
f =
(
−4
0
)
x =
(
x1
x2
)
Step 2 State the constraints in the form: A x ≤ b and identify the matrix A and vector
b:
A =
(
2 1
1 −4
)
b =
(
6
0
)
Step 3 Use the command for executing quadratic programming as
[x,fval] = quadprog(H,f,A,b)
which returns the solution vector x that minimizes
f = 1
2
xTHx + f Tx subject to Ax ≤ b
The MATLAB solution is given below:
clear;clc;
H = [2—2;–2 4];
f = [–4 0];
A = [2 1;1—4];
b = [6; 0];
[x,fval] = quadprog(H,f,A,b)
Warning: Large-scale method does not currently solve this
problem formulation, switching to medium-scale method.
x =
2.4615
1.0769
fval =
-6.7692
REFERENCES AND BIBLIOGRAPHY
4.1 S. Gass, Linear Programming , McGraw-Hill, New York, 1964.
4.2 C. E. Lemke, The dual method of solving the linear programming problem, Naval
Research and Logistics Quarterly , Vol. 1, pp. 36–47, 1954.
238 Linear Programming II: Additional Topics and Extensions
4.3 G. B. Dantzig, L. R. Ford, and D. R. Fulkerson, A primal–dual algorithm for linear
programs, pp. 171–181 in Linear Inequalities and Related Systems , H. W. Kuhn and
A. W. Tucker, Eds., Annals of Mathematics Study No. 38, Princeton University Press,
Princeton, NJ, 1956.
4.4 G. B. Dantzig and P. Wolfe, Decomposition principle for linear programming, Operations
Research , Vol. 8, pp. 101–111, 1960.
4.5 L. S. Lasdon, Optimization Theory for Large Systems , Macmillan, New York, 1970.
4.6 F. L. Hitchcock, The distribution of a product from several sources to numerous localities,
Journal of Mathematical Physics , Vol. 20, pp. 224–230, 1941.
4.7 T. C. Koopmans, Optimum utilization of the transportation system, Proceedings of the
International Statistical Conference, Washington, DC, 1947.
4.8 S. Zukhovitskiy and L. Avdeyeva, Linear and Convex Programming , W. B. Saunders,
Philadelphia, pp. 147–155, 1966.
4.9 W.W. Garvin, Introduction to Linear Programming , McGraw-Hill, New York, 1960.
4.10 G. B. Dantzig, Linear Programming and Extensions , Princeton University Press, Prince-
ton, NJ, 1963.
4.11 C. E. Lemke, On complementary pivot theory, in Mathematics of the Decision Sciences ,
G. B. Dantzig and A. F. Veinott, Eds., Part 1, pp. 95–136, American Mathematical
Society, Providence, RI, 1968.
4.12 K. Murty, Linear and Combinatorial Programming , Wiley, New York, 1976.
4.13 G. R. Bitran and A. G. Novaes, Linear programming with a fractional objective function,
Operations Research , Vol. 21, pp. 22–29, 1973.
4.14 E. U. Choo and D. R. Atkins, Bicriteria linear fractional programming, Journal of Opti-
mization Theory and Applications , Vol. 36, pp. 203–220, 1982.
4.15 C. Singh, Optimality conditions in fractional programming, Journal of Optimization The-
ory and Applications , Vol. 33, pp. 287–294, 1981.
4.16 J. B. Lasserre, A property of certain multistage linear programs and some applications,
Journal of Optimization Theory and Applications , Vol. 34, pp. 197–205, 1981.
4.17 G. Cohen, Optimization by decomposition and coordination: a unified approach, IEEE
Transactions on Automatic Control , Vol. AC-23, pp. 222–232, 1978.
4.18 N. Karmarkar, A new polynomial-time algorithm for linear programming, Combinatorica ,
Vol. 4, No. 4, pp. 373–395, 1984.
4.19 W. L. Winston, Operations Research Applications and Algorithms , 2nd ed. , PWS-Kent,
Boston, 1991.
4.20 J. N. Hooker, Karmarkar’s linear programming algorithm, Interfaces , Vol. 16, No. 4, pp.
75–90, 1986.
4.21 P. Wolfe, The simplex method for quadratic programming, Econometrica , Vol. 27, pp.
382–398, 1959.
4.22 J.C.G. Boot, Quadratic Programming , North-Holland, Amsterdam, 1964.
4.23 C. Van de Panne, Methods for Linear and Quadratic Programming , North-Holland, Ams-
terdam, 1974.
4.24 C. Van de Panne and A. Whinston, The symmetric formulation of the simplex method
for quadratic programming, Econometrica , Vol. 37, pp. 507–527, 1969.
Problems 239
REVIEW QUESTIONS
4.1 Is the decomposition method efficient for all LP problems?
4.2 What is the scope of postoptimality analysis?
4.3 Why is Karmarkar’s method called an interior method?
4.4 What is the major difference between the simplex and Karmarkar methods?
4.5 State the form of LP problem required by Karmarkar’s method.
4.6 What are the advantages of the revised simplex method?
4.7 Match the following terms and descriptions:
(a) Karmarkar’s method Moves from one vertex to another
(b) Simplex method Interior point algorithm
(c) Quadratic programming Phase I computations not required
(d) Dual simplex method Dantzig and Wolfe method
(e) Decomposition method Wolfe’s method
4.8 Answer true or false:
(a) The quadratic programming problem is a convex programming problem.
(b) It is immaterial whether a given LP problem is designated the primal or dual.
(c) If the primal problem involves minimization of f subject to greater-than constraints,
its dual deals with the minimization of f subject to less-than constraints.
(d) If the primal problem has an unbounded solution, its dual will also have an unbounded
solution.
(e) The transportation problem can be solved by simplex method.
4.9 Match the following in the context of duality theory:
(a) xi is nonnegative ith constraint is of less-than or
equal-to type
(b) xi is unrestricted Maximization type
(c) ith constraint is of equality type ith variable is unrestricted
(d) ith constraint is of greater-than or
equal-to type
ith variable is nonnegative
(e) Minimization type ith constraint is of equality type
PROBLEMS
Solve LP problems 4.1 to 4.3 by the revised simplex method.
4.1 Minimize f = −5x1 + 2x2 + 5x3 − 3x4
subject to
2x1 + x2 − x3 = 6
3x1 + 8x3 + x4 = 7
xi ≥ 0, i = 1 to 4
240 Linear Programming II: Additional Topics and Extensions
4.2 Maximize f = 15x1 + 6x2 + 9x3 + 2x4
subject to
10x1 + 5x2 + 25x3 + 3x4 ≤ 50
12x1 + 4x2 + 12x3 + x4 ≤ 48
7x1 + x4 ≤ 35
xi ≥ 0, i = 1 to 4
4.3 Minimize f = 2x1 + 3x2 + 2x3 − x4 + x5
subject to
3x1 − 3x2 + 4x3 + 2x4 − x5 = 0
x1 + x2 + x3 + 3x4 + x5 = 2
xi ≥ 0, i = 1, 2, . . . , 5
4.4 Discuss the relationships between the regular simplex method and the revised simplex
method.
4.5 Solve the following LP problem graphically and by the revised simplex method:
Maximize f = x2
subject to
−x1 + x2 ≤ 0
−2x1 − 3x2 ≤ 6
x1, x2 unrestricted in sign
4.6 Consider the following LP problem:
Minimize f = 3x1 + x3 + 2x5
subject to
x1 + x3 − x4 + x5 = −1
x2 − 2x3 + 3x4 + 2x5 = −2
xi ≥ 0, i = 1 to 5
Solve this problem using the dual simplex method.
4.7 Maximize f = 4x1 + 2x2
subject to
x1 − 2x2 ≥ 2
x1 + 2x2 = 8
Problems 241
x1 − x2 ≤ 11
x1 ≥ 0, x2 unrestricted in sign
(a) Write the dual of this problem.
(b) Find the optimum solution of the dual.
(c) Verify the solution obtained in part (b) by solving the primal problem graphically.
4.8 A water resource system consisting of two reservoirs is shown in Fig. 4.4. The flows and
storages are expressed in a consistent set of units. The following data are available:
Quantity Stream 1 (i = 1) Stream 2 (i = 2)
Capacity of reservoir i 9 7
Available release from
reservoir i
9 6
Capacity of channel
below reservoir i
4 4
Actual release from
reservoir i
x1 x2
The capacity of the main channel below the confluence of the two streams is 5 units.
If the benefit is equivalent to $2 × 106 and $3 × 106 per unit of water released from
reservoirs 1 and 2, respectively, determine the releases x1 and x2 from the reserovirs to
maximize the benefit. Solve this problem using duality theory.
4.9 Solve the following LP problem by the dual simplex method:
Minimize f = 2x1 + 9x2 + 24x3 + 8x4 + 5x5
Figure 4.4 Water resource system.
242 Linear Programming II: Additional Topics and Extensions
subject to
x1 + x2 + 2x3 − x5 − x6 = 1
−2x1 + x3 + x4 + x5 − x7 = 2
xi ≥ 0, i = 1 to 7
4.10 Solve Problem 3.1 by solving its dual.
4.11 Show that neither the primal nor the dual of the problem
Maximize f = −x1 + 2x2
subject to
−x1 + x2 ≤ −2
x1 − x2 ≤ 1
x1 ≥ 0, x2 ≥ 0
has a feasible solution. Verify your result graphically.
4.12 Solve the following LP problem by decomposition principle, and verify your result by
solving it by the revised simplex method:
Maximize f = 8x1 + 3x2 + 8x3 + 6x4
subject to
4x1 + 3x2 + x3 + 3x4 ≤ 16
4x1 − x2 + x3 ≤ 12
x1 + 2x2 ≤ 8
3x1 + x2 ≤ 10
2x3 + 3x4 ≤ 9
4x3 + x4 ≤ 12
xi ≥ 0, i = 1 to 4
4.13 Apply the decomposition principle to the dual of the following problem and solve it:
Minimize f = 10x1 + 2x2 + 4x3 + 8x4 + x5
subject to
x1 + 4x2 − x3 ≥ 16
2x1 + x2 + x3 ≥ 4
3x1 + x4 + x5 ≥ 8
x1 + 2x4 − x5 ≥ 20
xi ≥ 0, i = 1 to 5
Problems 243
4.14 Express the dual of the following LP problem:
Maximize f = 2x1 + x2
subject to
x1 − 2x2 ≥ 2
x1 + 2x2 = 8
x1 − x2 ≤ 11
x1 ≥ 0, x2 is unrestricted in sign
4.15 Find the effect of changing b =
{
1200
800
}
to
{
1180
120
}
in Example 4.5 using sensitivity analysis.
4.16 Find the effect of changing the cost coefficients c1 and c4 from −45 and −50 to −40
and −60, respectively, in Example 4.5 using sensitivity analysis.
4.17 Find the effect of changing c1 from −45 to −40 and c2 from −100 to −90 in Example
4.5 using sensitivity analysis.
4.18 If a new product, E, which requires 10 min of work on lathe and 10 min of work on
milling machine per unit, with a profit of $120 per unit is available in Example 4.5,
determine whether it is worth manufacturing E.
4.19 A metallurgical company produces four products, A, B,C, and D, by using copper and
zinc as basic materials. The material requirements and the profit per unit of each of the
four products, and the maximum quantities of copper and zinc available are given below:
Product
A B C D
Maximum quantity
available
Copper (lb) 4 9 7 10 6000
Zinc (lb) 2 1 3 20 4000
Profit per unit ($) 15 25 20 60
Find the number of units of the various products to be produced for maximizing the
profit.
Solve Problems 4.20–4.28 using the data of Problem 4.19.
4.20 Find the effect of changing the profit per unit of product D to $30.
4.21 Find the effect of changing the profit per unit of product A to $10, and of product B to
$20.
4.22 Find the effect of changing the profit per unit of product B to $30 and of product C to
$25.
4.23 Find the effect of changing the available quantities of copper and zinc to 4000 and
6000 lb, respectively.
4.24 What is the effect of introducing a new product, E, which requires 6 lb of copper and
3 lb of zinc per unit if it brings a profit of $30 per unit?
244 Linear Programming II: Additional Topics and Extensions
4.25 Assume that products A, B,C, and D require, in addition to the stated amounts of copper
and zinc, 4, 3, 2 and 5 lb of nickel per unit, respectively. If the total quantity of nickel
available is 2000 lb, in what way the original optimum solution is affected?
4.26 If product A requires 5 lb of copper and 3 lb of zinc (instead of 4 lb of copper and 2 lb
of zinc) per unit, find the change in the optimum solution.
4.27 If product C requires 5 lb of copper and 4 lb of zinc (instead of 7 lb of copper and 3 lb
of zinc) per unit, find the change in the optimum solution.
4.28 If the available quantities of copper and zinc are changed to 8000 lb and 5000 lb, respec-
tively, find the change in the optimum solution.
4.29 Solve the following LP problem:
Minimize f = 8x1 − 2x2
subject to
−4x1 + 2x2 ≤ 1
5x1 − 4x2 ≤ 3
x1 ≥ 0, x2 ≥ 0
Investigate the change in the optimum solution of Problem 4.29 when the following changes are
made (a) by using sensitivity analysis and (b) by solving the new problem graphically:
4.30 b1 = 2
4.31 b2 = 4
4.32 c1 = 10
4.33 c2 = −4
4.34 a11 = −5
4.35 a22 = −2
4.36 Perform one iteration of Karmarkar’s method for the LP problem:
Minimize f = 2x1 − 2x2 + 5x3
subject to
x1 − x2 = 0
x1 + x2 + x3 = 1
xi ≥ 0, i = 1, 2, 3
4.37 Perform one iteration of Karmarkar’s method for the following LP problem:
Minimize f = 3x1 + 5x2 − 3x3
subject to
x1 − x3 = 0
x1 + x2 + x3 = 1
xi ≥ 0, i = 1, 2, 3
Problems 245
4.38 Transform the following LP problem into the form required by Karmarkar’s method:
Minimize f = x1 + x2 + x3
subject to
x1 + x2 − x3 = 4
3x1 − x2 = 0
xi ≥ 0, i = 1, 2, 3
4.39 A contractor has three sets of heavy construction equipment available at both New York
and Los Angeles. He has construction jobs in Seattle, Houston, and Detroit that require
two, three, and one set of equipment, respectively. The shipping costs per set between
cities i and j (cij ) are shown in Fig. 4.5. Formulate the problem of finding the shipping
pattern that minimizes the cost.
4.40
Minimize f (X) = 3x21 + 2x
2
2 + 5x
3
2 − 4x1x2 − 2x1x3 − 2x2x3
subject to
3x1 + 5x2 + 2x3 ≥ 10
3x1 + 5x3 ≤ 15
xi ≥ 0, i = 1, 2, 3
by quadratic programming.
4.41 Find the solution of the quadratic programming problem stated in Example 1.5.
4.42 According to elastic–plastic theory, a frame structure fails (collapses) due to the formation
of a plastic hinge mechanism. The various possible mechanisms in which a portal frame
(Fig. 4.6) can fail are shown in Fig. 4.7. The reserve strengths of the frame in various
failure mechanisms (Zi) can be expressed in terms of the plastic moment capacities of the
hinges as indicated in Fig. 4.7. Assuming that the cost of the frame is proportional to 200
times each of the moment capacities M1, M2, M6, and M7, and 100 times each of the
moment capacities M3, M4, and M5, formulate the problem of minimizing the total cost
Figure 4.5 Shipping costs between cities.
246 Linear Programming II: Additional Topics and Extensions
Figure 4.6 Plastic hinges in a frame.
Figure 4.7 Possible failure mechanisms of a portal frame.
Problems 247
to ensure nonzero reserve strength in each failure mechanism. Also, suggest a suitable
technique for solving the problem. Assume that the moment capacities are restricted as
0 ≤ Mi ≤ 2 × 105 lb-in., i = 1, 2, . . . , 7. Data: x = 100 in., y = 150 in., P1 = 1000 lb,
and P2 = 500 lb.
4.43 Solve the LP problem stated in Problem 4.9 using MATLAB (interior method).
4.44 Solve the LP problem stated in Problem 4.12 using MATLAB (interior method).
4.45 Solve the LP problem stated in Problem 4.13 using MATLAB (interior method).
4.46 Solve the LP problem stated in Problem 4.36 using MATLAB (interior method).
4.47 Solve the LP problem stated in Problem 4.37 using MATLAB (interior method).
4.48 Solve the following quadratic programming problem using MATLAB:
Maximize f = 2x1 + x2 − x21
subject to 2x1 + 3x2 ≤ 6, 2x1 + x2 ≤ 4, x1 ≥ 0, x2 ≥ 0
4.49 Solve the following quadratic programming problem using MATLAB:
Maximize f = 4x1 + 6x2 − x21 − x22
subject to x1 + x2 ≤ 2, x1 ≥ 0, x2 ≥ 0
4.50 Solve the following quadratic programming problem using MATLAB:
Minimize f = (x1 − 1)2 + x2 − 2
subject to − x1 + x2 − 1 = 0, x1 + x2 − 2 ≤ 0, x1 ≥ 0, x2 ≥ 0
4.51 Solve the following quadratic programming problem using MATLAB:
Minimize f = x21 + x22 − 3x1x2 − 6x1 + 5x2
subject to x1 + x2 ≤ 4, 3x1 + 6x2 ≤ 20, x1 ≥ 0, x2 ≥ 0
5
Nonlinear Programming I:
One-Dimensional Minimization
Methods
5.1 INTRODUCTION
In Chapter 2 we saw that if the expressions for the objective function and the constraints
are fairly simple in terms of the design variables, the classical methods of optimization
can be used to solve the problem. On the other hand, if the optimization problem
involves the objective function and/or constraints that are not stated as explicit functions
of the design variables or which are too complicated to manipulate, we cannot solve it
by using the classical analytical methods. The following example is given to illustrate a
case where the constraints cannot be stated as explicit functions of the design variables.
Example 5.2 illustrates a case where the objective function is a complicated one for
which the classical methods of optimization are difficult to apply.
Example 5.1 Formulate the problem of designing the planar truss shown in Fig. 5.1
for minimum weight subject to the constraint that the displacement of any node, in
either the vertical or the horizontal direction, should not exceed a value δ.
SOLUTION Let the density ρ and Young’s modulus E of the material, the length
of the members l, and the external loads Q, R, and S be known as design data. Let
the member areas A1, A2, . . . , A11 be taken as the design variables x1, x2, . . . , x11,
respectively. The equations of equilibrium can be derived in terms of the unknown
nodal displacements u1, u2, . . . , u10 as
† (the displacements u11, u12, u13, and u14 are
†According to the matrix methods of structural analysis, the equilibrium equations for the j th member are
given by [5.1]
[kj ]
4×4
uj
4×1
= Pj
4×1
where the stiffness matrix can be expressed as
[kj ] =
AjEj
lj





cos2 θj cos θj sin θj − cos2 θj − cos θj sin θj
cos θj sin θj sin
2 θj − cos θj sin θj − sin2 θj
− cos2 θj − cos θj sin θj cos2 θj cos θj sin θj
− cos θj sin θj − sin2 θj cos θj sin θj sin2 θj





where θj is the inclination of the j th member with respect to the x-axis, Aj the cross-sectional area of the
j th member, lj the length of the j th member, uj the vector of displacements for the j th member, and Pj
248 Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
5.1 Introduction 249
Figure 5.1 Planar truss: (a) nodal and member numbers; (b) nodal degrees of freedom.
zero, as they correspond to the fixed nodes)
(4x4 + x6 + x7)u1 +
√
3(x6 − x7)u2 − 4x4u3 − x7u7 +
√
3x7u8 = 0 (E1)
√
3(x6 − x7)u1 + 3(x6 + x7)u2 +
√
3x7u7 − 3x7u8 = −
4Rl
E
(E2)
− 4x4u1 + (4x4 + 4x5 + x8 + x9)u3 +
√
3(x8 − x9)u4 − 4x5u5
− x8u7 −
√
3x8u8 − x9u9 +
√
3x9u10 = 0 (E3)
√
3(x8 − x9)u3 + 3(x8 + x9)u4 −
√
3x8u7
− 3x8u8 +
√
3x9u9 − 3x9u10 = 0 (E4)
− 4x5u3 + (4x5 + x10 + x11)u5 +
√
3(x10 − x11)u6
− x10u9 −
√
3x10u10 =
4Ql
E
(E5)
√
3(x10 − x11)u5 + 3(x10 + x11)u6 −
√
3x10u9 − 3x10u10 = 0 (E6)
− x7u1 +
√
3x7u2 − x8u3 −
√
3x8u4 + (4x1 + 4x2
+ x7 + x8)u7 −
√
3(x7 − x8)u8 − 4x2u9 = 0 (E7)
√
3x7u1 − 3x7u2 −
√
3x8u3 − 3x8u4 −
√
3(x7 − x8)u7
+ 3(x7 + x8)u8 = 0 (E8)
− x9u3 +
√
3x9u4 − x10u5 −
√
3x10u6 − 4x2u7
+ (4x2 + 4x3 + x9 + x10)u9 −
√
3(x9 − x10)u10 = 0 (E9)
√
3x9u3 − 3x9u4 −
√
3x10u5 − 3x10u6 −
√
3(x9 − x10)u9
+ 3(x9 + x10)u10 = −
4Sl
E
(E10)
the vector of loads for the j th member. The formulation of the equilibrium equations for the complete truss
follows fairly standard procedure [5.1].
250 Nonlinear Programming I: One-Dimensional Minimization Methods
It is important to note that an explicit closed-form solution cannot be obtained for
the displacements as the number of equations becomes large. However, given any
vector X, the system of Eqs. (E1) to (E10) can be solved numerically to find the nodal
displacement u1, u2, . . . , u10.
The optimization problem can be stated as follows:
Minimize f (X) =
11
∑
i=1
ρxi li (E11)
subject to the constraints
gj (X) = |uj (X)| − δ ≤ 0, j = 1, 2, . . . , 10 (E12)
xi ≥ 0, i = 1, 2, . . . , 11 (E13)
The objective function of this problem is a straightforward function of the design vari-
ables as given in Eq. (E11). The constraints, although written by the abstract expressions
gj (X), cannot easily be written as explicit functions of the components of X. How-
ever, given any vector X we can calculate gj (X) numerically. Many engineering design
problems possess this characteristic (i.e., the objective and/or the constraints cannot be
written explicitly in terms of the design variables). In such cases we need to use the
numerical methods of optimization for solution.
Example 5.2 The shear stress induced along the z-axis when two spheres are in contact
with each other is given by
τzx
pmax
=
1
2




3
2
{
1 +
( z
a
)2
} − (1 + ν)





1 −
z
a
tan−1



1
z
a












(E1)
where a is the radius of the contact area and pmax is the maximum pressure developed
at the center of the contact area (Fig. 5.2):
a =







3F
8
1 − ν21
E1
+
1 − ν22
E2
1
d1
+ 1
d2







1/3
(E2)
pmax =
3F
2πa2
(E3)
where F is the contact force, E1 and E2 are Young’s moduli of the two spheres, ν1
and ν2 are Poisson’s ratios of the two spheres, and d1 and d2 the diameters of the
two spheres. In many practical applications, such as ball bearings, when the contact
load (F ) is large, a crack originates at the point of maximum shear stress and prop-
agates to the surface, leading to a fatigue failure. To locate the origin of a crack, it
is necessary to find the point at which the shear stress attains its maximum value.
Formulate the problem of finding the location of maximum shear stress for ν = ν1 =
ν2 = 0.3.
5.1 Introduction 251
Figure 5.2 Contact stress between two spheres.
SOLUTION For ν1 = ν2 = 0.3, Eq. (E1) reduces to
f (λ) =
0.75
1 + λ2
+ 0.65λ tan−1
1
λ
− 0.65 (E4)
where f = τzx/pmax and λ = z/a. Since Eq. (E4) is a nonlinear function of the distance,
λ, the application of the necessary condition for the maximum of f, df/dλ = 0, gives
rise to a nonlinear equation from which a closed-form solution for λ∗ cannot easily be
obtained. In such cases, numerical methods of optimization can be conveniently used
to find the value of λ∗.
The basic philosophy of most of the numerical methods of optimization is to
produce a sequence of improved approximations to the optimum according to the
following scheme:
1. Start with an initial trial point X1.
2. Find a suitable direction Si (i = 1 to start with) that points in the general
direction of the optimum.
3. Find an appropriate step length λ∗i for movement along the direction Si .
4. Obtain the new approximation Xi+1 as
Xi+1 = Xi + λ∗i Si (5.1)
5. Test whether Xi+1 is optimum. If Xi+1 is optimum, stop the procedure.
Otherwise, set a new i = i + 1 and repeat step (2) onward.
252 Nonlinear Programming I: One-Dimensional Minimization Methods
x2
Figure 5.3 Iterative process of optimization.
The iterative procedure indicated by Eq. (5.1) is valid for unconstrained as well as
constrained optimization problems. The procedure is represented graphically for a hypo-
thetical two-variable problem in Fig. 5.3. Equation (5.1) indicates that the efficiency
of an optimization method depends on the efficiency with which the quantities λ∗i and
Si are determined. The methods of finding the step length λ
∗
i are considered in this
chapter and the methods of finding Si are considered in Chapters 6 and 7.
If f (X) is the objective function to be minimized, the problem of determining λ∗i
reduces to finding the value λi = λ∗i that minimizes f (Xi+1) = f (Xi + λiSi) = f (λi)
for fixed values of Xi and Si . Since f becomes a function of one variable λi only, the
methods of finding λ∗i in Eq. (5.1) are called one-dimensional minimization methods .
Several methods are available for solving a one-dimensional minimization problem.
These can be classified as shown in Table 5.1.
We saw in Chapter 2 that the differential calculus method of optimization is an
analytical approach and is applicable to continuous, twice-differentiable functions. In
this method, calculation of the numerical value of the objective function is virtually the
last step of the process. The optimal value of the objective function is calculated after
determining the optimal values of the decision variables. In the numerical methods
of optimization, an opposite procedure is followed in that the values of the objective
function are first found at various combinations of the decision variables and conclu-
sions are then drawn regarding the optimal solution. The elimination methods can be
used for the minimization of even discontinuous functions. The quadratic and cubic
5.2 Unimodal Function 253
Table 5.1 One-dimensional Minimization Methods
Elimination
methods
Unrestricted
search Requiring no
derivatives
(quadratic)
Requiring
derivatives
Cubic
Direct root
Newton
Quasi-Newton
Secant
Exhaustive search
Dichotomous
search
Fibonacci method
Golden section
method
Numerical methodsAnalytical methods
(differential calculus methods)
Interpolation
methods
interpolation methods involve polynomial approximations to the given function. The
direct root methods are root finding methods that can be considered to be equivalent
to quadratic interpolation.
5.2 UNIMODAL FUNCTION
A unimodal function is one that has only one peak (maximum) or valley (minimum)
in a given interval. Thus a function of one variable is said to be unimodal if, given
that two values of the variable are on the same side of the optimum, the one nearer
the optimum gives the better functional value (i.e., the smaller value in the case of a
minimization problem). This can be stated mathematically as follows:
A function f (x) is unimodal if (i) x1 < x2 < x
∗ implies that f (x2) <
f (x1), and (ii) x2 >x1 >x
∗ implies that f (x1) < f (x2), where x
∗ is the
minimum point.
Some examples of unimodal functions are shown in Fig. 5.4. Thus a unimodal function
can be a nondifferentiable or even a discontinuous function. If a function is known to
be unimodal in a given range, the interval in which the minimum lies can be narrowed
down provided that the function values are known at two different points in the range.
Figure 5.4 Unimodal function.
254 Nonlinear Programming I: One-Dimensional Minimization Methods
Figure 5.5 Outcome of first two experiments: (a) f1 < f2; (b) f1 > f2; (c) f1 = f2.
For example, consider the normalized interval [0, 1] and two function evaluations
within the interval as shown in Fig. 5.5. There are three possible outcomes, namely,
f1 < f2, f1 >f2, or f1 = f2. If the outcome is that f1 < f2, the minimizing x cannot
lie to the right of x2. Thus that part of the interval [x2, 1] can be discarded and a new
smaller interval of uncertainty, [0, x2], results as shown in Fig. 5.5a. If f (x1) >f (x2),
the interval [0, x1] can be discarded to obtain a new smaller interval of uncertainty,
[x1, 1] (Fig. 5.5b), while if f (x1) = f (x2), intervals [0, x1] and [x2, 1] can both be
discarded to obtain the new interval of uncertainty as [x1, x2] (Fig. 5.5c). Further,
if one of the original experiments† remains within the new interval, as will be the
situation in Fig. 5.5a and b, only one other experiment need be placed within the new
interval in order that the process be repeated. In situations such as Fig. 5.5c, two more
experiments are to be placed in the new interval in order to find a reduced interval of
uncertainty.
The assumption of unimodality is made in all the elimination techniques. If a
function is known to be multimodal (i.e., having several valleys or peaks), the range of
the function can be subdivided into several parts and the function treated as a unimodal
function in each part.
Elimination Methods
5.3 UNRESTRICTED SEARCH
In most practical problems, the optimum solution is known to lie within restricted
ranges of the design variables. In some cases this range is not known, and hence the
search has to be made with no restrictions on the values of the variables.
5.3.1 Search with Fixed Step Size
The most elementary approach for such a problem is to use a fixed step size and move
from an initial guess point in a favorable direction (positive or negative). The step size
†Each function evaluation is termed as an experiment or a trial in the elimination methods.
5.3 Unrestricted Search 255
used must be small in relation to the final accuracy desired. Although this method is
very simple to implement, it is not efficient in many cases. This method is described
in the following steps:
1. Start with an initial guess point, say, x1.
2. Find f1 = f (x1).
3. Assuming a step size s, find x2 = x1 + s.
4. Find f2 = f (x2).
5. If f2 < f1, and if the problem is one of minimization, the assumption of uni-
modality indicates that the desired minimum cannot lie at x < x1. Hence the
search can be continued further along points x3, x4, . . . using the unimodality
assumption while testing each pair of experiments. This procedure is con-
tinued until a point, xi = x1+ (i − 1)s, shows an increase in the function
value.
6. The search is terminated at xi , and either xi−1 or xi can be taken as the optimum
point.
7. Originally, if f2 >f1, the search should be carried in the reverse direction at
points x−2, x−3, . . . , where x−j = x1 − (j − 1)s.
8. If f2 = f1, the desired minimum lies in between x1 and x2, and the minimum
point can be taken as either x1 or x2.
9. If it happens that both f2 and f−2 are greater than f1, it implies that the desired
minimum will lie in the double interval x−2 < x < x2.
5.3.2 Search with Accelerated Step Size
Although the search with a fixed step size appears to be very simple, its major limitation
comes because of the unrestricted nature of the region in which the minimum can lie.
For example, if the minimum point for a particular function happens to be xopt =
50, 000 and, in the absence of knowledge about the location of the minimum, if x1 and
s are chosen as 0.0 and 0.1, respectively, we have to evaluate the function 5,000,001
times to find the minimum point. This involves a large amount of computational work.
An obvious improvement can be achieved by increasing the step size gradually until
the minimum point is bracketed. A simple method consists of doubling the step size
as long as the move results in an improvement of the objective function. Several other
improvements of this method can be developed. One possibility is to reduce the step
length after bracketing the optimum in (xi−1, xi). By starting either from xi−1 or xi ,
the basic procedure can be applied with a reduced step size. This procedure can be
repeated until the bracketed interval becomes sufficiently small. The following example
illustrates the search method with accelerated step size.
Example 5.3 Find the minimum of f = x(x − 1.5) by starting from 0.0 with an initial
step size of 0.05.
SOLUTION The function value at x1 is f1 = 0.0. If we try to start moving in the
negative x direction, we find that x−2 = −0.05 and f−2 = 0.0775. Since f−2 >f1, the
assumption of unimodality indicates that the minimum cannot lie toward the left of
x−2. Thus we start moving in the positive x direction and obtain the following results:
256 Nonlinear Programming I: One-Dimensional Minimization Methods
i Value of s xi = x1 + s fi = f (xi) Is fi > fi−1?
1 — 0.0 0.0 —
2 0.05 0.05 −0.0725 No
3 0.10 0.10 −0.140 No
4 0.20 0.20 −0.260 No
5 0.40 0.40 −0.440 No
6 0.80 0.80 −0.560 No
7 1.60 1.60 +0.160 Yes
From these results, the optimum point can be seen to be xopt ≈ x6 = 0.8. In this case,
the points x6 and x7 do not really bracket the minimum point but provide information
about it. If a better approximation to the minimum is desired, the procedure can be
restarted from x5 with a smaller step size.
5.4 EXHAUSTIVE SEARCH
The exhaustive search method can be used to solve problems where the interval in
which the optimum is known to lie is finite. Let xs and xf denote, respectively, the
starting and final points of the interval of uncertainty.† The exhaustive search method
consists of evaluating the objective function at a predetermined number of equally
spaced points in the interval (xs, xf ), and reducing the interval of uncertainty using the
assumption of unimodality. Suppose that a function is defined on the interval (xs, xf )
and let it be evaluated at eight equally spaced interior points x1 to x8. Assuming that
the function values appear as shown in Fig. 5.6, the minimum point must lie, according
to the assumption of unimodality, between points x5 and x7. Thus the interval (x5, x7)
can be considered as the final interval of uncertainty.
In general, if the function is evaluated at n equally spaced points in the original
interval of uncertainty of length L0 = xf − xs , and if the optimum value of the function
(among the n function values) turns out to be at point xj , the final interval of uncertainty
Figure 5.6 Exhaustive search.
†Since the interval (xs , xf ), but not the exact location of the optimum in this interval, is known to us, the
interval (xs , xf ) is called the interval of uncertainty .
5.5 Dichotomous Search 257
is given by
Ln = xj+1 − xj−1 =
2
n + 1
L0 (5.2)
The final interval of uncertainty obtainable for different number of trials in the exhaus-
tive search method is given below:
Number of trials 2 3 4 5 6 · · · n
Ln/L0 2/3 2/4 2/5 2/6 2/7 · · · 2/(n + 1)
Since the function is evaluated at all n points simultaneously, this method can be called
a simultaneous search method . This method is relatively inefficient compared to the
sequential search methods discussed next, where the information gained from the initial
trials is used in placing the subsequent experiments.
Example 5.4 Find the minimum of f = x(x − 1.5) in the interval (0.0, 1.00) to within
10% of the exact value.
SOLUTION If the middle point of the final interval of uncertainty is taken as the
approximate optimum point, the maximum deviation could be 1/(n + 1) times the
initial interval of uncertainty. Thus to find the optimum within 10% of the exact value,
we should have
1
n + 1
≤
1
10
or n ≥ 9
By taking n = 9, the following function values can be calculated:
i 1 2 3 4 5 6 7 8 9
xi 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
fi = f (xi) −0.14 −0.26 −0.36 −0.44 −0.50 −0.54 −0.56 −0.56 −0.54
Since x7 = x8, the assumption of unimodality gives the final interval of uncertainty as
L9 = (0.7, 0.8). By taking the middle point of L9 (i.e., 0.75) as an approximation to
the optimum point, we find that it is, in fact, the true optimum point.
5.5 DICHOTOMOUS SEARCH
The exhaustive search method is a simultaneous search method in which all the exper-
iments are conducted before any judgment is made regarding the location of the
optimum point. The dichotomous search method , as well as the Fibonacci and the
golden section methods discussed in subsequent sections, are sequential search meth-
ods in which the result of any experiment influences the location of the subsequent
experiment.
In the dichotomous search, two experiments are placed as close as possible at
the center of the interval of uncertainty. Based on the relative values of the objective
258 Nonlinear Programming I: One-Dimensional Minimization Methods
Figure 5.7 Dichotomous search.
function at the two points, almost half of the interval of uncertainty is eliminated. Let
the positions of the two experiments be given by (Fig. 5.7)
x1 =
L0
2
− δ
2
x2 =
L0
2
+ δ
2
where δ is a small positive number chosen so that the two experiments give significantly
different results. Then the new interval of uncertainty is given by (L0/2 + δ/2). The
building block of dichotomous search consists of conducting a pair of experiments
at the center of the current interval of uncertainty. The next pair of experiments is,
therefore, conducted at the center of the remaining interval of uncertainty. This results
in the reduction of the interval of uncertainty by nearly a factor of 2. The intervals
of uncertainty at the end of different pairs of experiments are given in the following
table:
Number of experiments 2 4 6
Final interval of uncertainty
1
2
(L0 + δ)
1
2
(
L0 + δ
2
)
+
δ
2
1
2
(
L0 + δ
4
+
δ
2
)
+
δ
2
In general, the final interval of uncertainty after conducting n experiments (n even) is
given by
Ln =
L0
2n/2
+ δ
(
1 − 1
2n/2
)
(5.3)
The following example is given to illustrate the method of search.
Example 5.5 Find the minimum of f = x(x − 1.5) in the interval (0.0, 1.00) to within
10% of the exact value.
SOLUTION The ratio of final to initial intervals of uncertainty is given by [from
Eq. (5.3)]
Ln
L0
= 1
2n/2
+ δ
L0
(
1 − 1
2n/2
)
5.5 Dichotomous Search 259
where δ is a small quantity, say 0.001, and n is the number of experiments. If the
middle point of the final interval is taken as the optimum point, the requirement can
be stated as
1
2
Ln
L0
≤
1
10
i.e.,
1
2n/2
+ δ
L0
(
1 − 1
2n/2
)
≤ 1
5
Since δ = 0.001 and L0 = 1.0, we have
1
2n/2
+ 1
1000
(
1 − 1
2n/2
)
≤ 1
5
i.e.,
999
1000
1
2n/2
≤ 995
5000
or 2n/2 ≥ 999
199
≃ 5.0
Since n has to be even, this inequality gives the minimum admissible value of n as 6.
The search is made as follows. The first two experiments are made at
x1 =
L0
2
− δ
2
= 0.5 − 0.0005 = 0.4995
x2 =
L0
2
+ δ
2
= 0.5 + 0.0005 = 0.5005
with the function values given by
f1 = f (x1) = 0.4995(−1.0005) ≃ −0.49975
f2 = f (x2) = 0.5005(−0.9995) ≃ −0.50025
Since f2 < f1, the new interval of uncertainty will be (0.4995, 1.0). The second pair
of experiments is conducted at
x3 =
(
0.4995 +
1.0 − 0.4995
2
)
− 0.0005 = 0.74925
x4 =
(
0.4995 + 1.0 − 0.4995
2
)
+ 0.0005 = 0.75025
which give the function values as
f3 = f (x3) = 0.74925(−0.75075) = −0.5624994375
f4 = f (x4) = 0.75025(−0.74975) = −0.5624999375
Since f3 >f4, we delete (0.4995, x3) and obtain the new interval of uncertainty as
(x3, 1.0) = (0.74925, 1.0)
260 Nonlinear Programming I: One-Dimensional Minimization Methods
The final set of experiments will be conducted at
x5 =
(
0.74925 + 1.0 − 0.74925
2
)
− 0.0005 = 0.874125
x6 =
(
0.74925 + 1.0 − 0.74925
2
)
+ 0.0005 = 0.875125
The corresponding function values are
f5 = f (x5) = 0.874125(−0.625875) = −0.5470929844
f6 = f (x6) = 0.875125(−0.624875) = −0.5468437342
Since f5 < f6, the new interval of uncertainty is given by (x3, x6) = (0.74925,
0.875125). The middle point of this interval can be taken as optimum, and hence
xopt ≃ 0.8121875 and fopt ≃ −0.5586327148
5.6 INTERVAL HALVING METHOD
In the interval halving method , exactly one-half of the current interval of uncertainty
is deleted in every stage. It requires three experiments in the first stage and two exper-
iments in each subsequent stage. The procedure can be described by the following
steps:
1. Divide the initial interval of uncertainty L0 = [a, b] into four equal parts and
label the middle point x0 and the quarter-interval points x1 and x2.
2. Evaluate the function f (x) at the three interior points to obtain f1 = f (x1),
f0 = f (x0), and f2 = f (x2).
3. (a) If f2 >f0 >f1 as shown in Fig. 5.8a, delete the interval (x0, b), label x1
and x0 as the new x0 and b, respectively, and go to step 4.
(b) If f2 < f0 < f1 as shown in Fig. 5.8b, delete the interval (a, x0), label x2
and x0 as the new x0 and a, respectively, and go to step 4.
(c) If f1 >f0 and f2 >f0 as shown in Fig. 5.8c, delete both the intervals
(a, x1) and (x2, b), label x1 and x2 as the new a and b, respectively, and
go to step 4.
4. Test whether the new interval of uncertainty, L = b − a, satisfies the conver-
gence criterion L ≤ ε, where ε is a small quantity. If the convergence criterion
is satisfied, stop the procedure. Otherwise, set the new L0 = L and go to step 1.
Remarks:
1. In this method, the function value at the middle point of the interval of uncer-
tainty, f0, will be available in all the stages except the first stage.
2. The interval of uncertainty remaining at the end of n experiments (n ≥ 3 and
odd) is given by
Ln =
(
1
2
)(n−1)/2
L0 (5.4)
5.6 Interval Halving Method 261
Figure 5.8 Possibilities in the interval halving method: (a) f2 >f0 >f1; (b) f1 >f0 > f2;
(c) f1 > f0 and f2 >f0.
262 Nonlinear Programming I: One-Dimensional Minimization Methods
Example 5.6 Find the minimum of f = x(x − 1.5) in the interval (0.0, 1.0) to within
10% of the exact value.
SOLUTION If the middle point of the final interval of uncertainty is taken as the
optimum point, the specified accuracy can be achieved if
1
2
Ln ≤
L0
10
or
(
1
2
)(n−1)/2
L0 ≤
L0
5
(E1)
Since L0 = 1, Eq. (E1) gives
1
2(n−1)/2
≤ 1
5
or 2(n−1)/2 ≥ 5 (E2)
Since n has to be odd, inequality (E2) gives the minimum permissible value of n as 7.
With this value of n = 7, the search is conducted as follows. The first three experiments
are placed at one-fourth points of the interval L0 = [a = 0, b = 1] as
x1 = 0.25, f1 = 0.25(−1.25) = −0.3125
x0 = 0.50, f0 = 0.50(−1.00) = −0.5000
x2 = 0.75, f2 = 0.75(−0.75) = −0.5625
Since f1 >f0 >f2, we delete the interval (a, x0) = (0.0, 0.5), label x2 and x0 as the
new x0 and a so that a = 0.5, x0 = 0.75, and b = 1.0. By dividing the new interval of
uncertainty, L3 = (0.5, 1.0) into four equal parts, we obtain
x1 = 0.625, f1 = 0.625(−0.875) = −0.546875
x0 = 0.750, f0 = 0.750(−0.750) = −0.562500
x2 = 0.875, f2 = 0.875(−0.625) = −0.546875
Since f1 > f0 and f2 >f0, we delete both the intervals (a, x1) and (x2, b), and label
x1, x0, and x2 as the new a, x0, and b, respectively. Thus the new interval of uncer-
tainty will be L5 = (0.625, 0.875). Next, this interval is divided into four equal parts
to obtain
x1 = 0.6875, f1 = 0.6875(−0.8125) = −0.558594
x0 = 0.75, f0 = 0.75(−0.75) = −0.5625
x2 = 0.8125, f2 = 0.8125(−0.6875) = −0.558594
Again we note that f1 > f0 and f2 >f0 and hence we delete both the intervals (a, x1)
and (x2, b) to obtain the new interval of uncertainty as L7 = (0.6875, 0.8125). By
taking the middle point of this interval (L7) as optimum, we obtain
xopt ≈ 0.75 and fopt ≈ −0.5625
(This solution happens to be the exact solution in this case.)
5.7 Fibonacci Method 263
5.7 FIBONACCI METHOD
As stated earlier, the Fibonacci method can be used to find the minimum of a function
of one variable even if the function is not continuous. This method, like many other
elimination methods, has the following limitations:
1. The initial interval of uncertainty, in which the optimum lies, has to be known.
2. The function being optimized has to be unimodal in the initial interval of uncer-
tainty.
3. The exact optimum cannot be located in this method. Only an interval known as
the final interval of uncertainty will be known. The final interval of uncertainty
can be made as small as desired by using more computations.
4. The number of function evaluations to be used in the search or the resolution
required has to be specified beforehand.
This method makes use of the sequence of Fibonacci numbers, {Fn}, for placing the
experiments. These numbers are defined as
F0 = F1 = 1
Fn = Fn−1 + Fn−2, n = 2, 3, 4, . . .
which yield the sequence 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89,. . . .
Procedure. Let L0 be the initial interval of uncertainty defined by a ≤ x ≤ b and n
be the total number of experiments to be conducted. Define
L∗2 =
Fn−2
Fn
L0 (5.5)
and place the first two experiments at points x1 and x2, which are located at a distance
of L∗2 from each end of L0.
† This gives‡
x1 = a + L∗2 = a +
Fn−2
Fn
L0
x2 = b − L∗2 = b −
Fn−2
Fn
L0 = a +
Fn−1
Fn
L0
(5.6)
Discard part of the interval by using the unimodality assumption. Then there remains
a smaller interval of uncertainty L2 given by
§
L2 = L0 − L∗2 = L0
(
1 − Fn−2
Fn
)
= Fn−1
Fn
L0 (5.7)
†If an experiment is located at a distance of (Fn−2/Fn)L0 from one end, it will be at a distance of
(Fn−1/Fn)L0 from the other end. Thus L
∗
2 = (Fn−1/Fn)L0 will yield the same result as with L∗2 =
(Fn−2/Fn)L0.
‡It can be seen that
L∗2 =
Fn−2
Fn
L0 ≤
1
2
L0 for n ≥ 2
§The symbol Lj is used to denote the interval of uncertainty remaining after conducting j experiments,
while the symbol L∗j is used to define the position of the j th experiment.
264 Nonlinear Programming I: One-Dimensional Minimization Methods
and with one experiment left in it. This experiment will be at a distance of
L∗2 =
Fn−2
Fn
L0 =
Fn−2
Fn−1
L2 (5.8)
from one end and
L2 − L∗2 =
Fn−3
Fn
L0 =
Fn−3
Fn−1
L2 (5.9)
from the other end. Now place the third experiment in the interval L2 so that the current
two experiments are located at a distance of
L∗3 =
Fn−3
Fn
L0 =
Fn−3
Fn−1
L2 (5.10)
from each end of the interval L2. Again the unimodality property will allow us to
reduce the interval of uncertainty to L3 given by
L3 = L2 − L∗3 = L2 −
Fn−3
Fn−1
L2 =
Fn−2
Fn−1
L2 =
Fn−2
Fn
L0 (5.11)
This process of discarding a certain interval and placing a new experiment in the
remaining interval can be continued, so that the location of the j th experiment and the
interval of uncertainty at the end of j experiments are, respectively, given by
L∗j =
Fn−j
Fn−(j−2)
Lj−1 (5.12)
Lj =
Fn−(j−1)
Fn
L0 (5.13)
The ratio of the interval of uncertainty remaining after conducting j of the n predeter-
mined experiments to the initial interval of uncertainty becomes
Lj
L0
=
Fn−(j−1)
Fn
(5.14)
and for j = n, we obtain
Ln
L0
= F1
Fn
= 1
Fn
(5.15)
The ratio Ln/L0 will permit us to determine n, the required number of experiments,
to achieve any desired accuracy in locating the optimum point. Table 5.2 gives
the reduction ratio in the interval of uncertainty obtainable for different number of
experiments.
5.7 Fibonacci Method 265
Table 5.2 Reduction Ratios
Value of n Fibonacci number, Fn Reduction ratio, Ln/L0
0 1 1.0
1 1 1.0
2 2 0.5
3 3 0.3333
4 5 0.2
5 8 0.1250
6 13 0.07692
7 21 0.04762
8 34 0.02941
9 55 0.01818
10 89 0.01124
11 144 0.006944
12 233 0.004292
13 377 0.002653
14 610 0.001639
15 987 0.001013
16 1,597 0.0006406
17 2,584 0.0003870
18 4,181 0.0002392
19 6,765 0.0001479
20 10,946 0.00009135
Position of the Final Experiment. In this method the last experiment has to be
placed with some care. Equation (5.12) gives
L∗n
Ln−1
= F0
F2
= 1
2
for all n (5.16)
Thus after conducting n − 1 experiments and discarding the appropriate interval in each
step, the remaining interval will contain one experiment precisely at its middle point.
However, the final experiment, namely, the nth experiment, is also to be placed at the
center of the present interval of uncertainty. That is, the position of the nth experiment
will be same as that of (n − 1)th one, and this is true for whatever value we choose
for n. Since no new information can be gained by placing the nth experiment exactly
at the same location as that of the (n − 1)th experiment, we place the nth experi-
ment very close to the remaining valid experiment, as in the case of the dichotomous
search method. This enables us to obtain the final interval of uncertainty to within
1
2
Ln−1. A flowchart for implementing the Fibonacci method of minimization is given
in Fig. 5.9.
Example 5.7 Minimize f (x) = 0.65 − [0.75/(1 + x2)] − 0.65x tan−1(1/x) in the
interval [0,3] by the Fibonacci method using n = 6. (Note that this objective is
equivalent to the one stated in Example 5.2.)
266 Nonlinear Programming I: One-Dimensional Minimization Methods
Figure 5.9 Flowchart for implementing Fibonacci search method.
5.8 Golden Section Method 267
SOLUTION Here n = 6 and L0 = 3.0, which yield
L∗2 =
Fn−2
Fn
L0 =
5
13
(3.0) = 1.153846
Thus the positions of the first two experiments are given by x1 = 1.153846 and
x2 = 3.0 − 1.153846 = 1.846154 with f1 = f (x1) = −0.207270 and f2 = f (x2) =
−0.115843. Since f1 is less than f2, we can delete the interval [x2, 3.0] by using
the unimodality assumption (Fig. 5.10a). The third experiment is placed at x3 = 0 +
(x2 − x1) = 1.846154 − 1.153846 = 0.692308, with the corresponding function value
of f3 = −0.291364.
Since f1 >f3, we delete the interval [x1, x2] (Fig. 5.10b). The next experiment
is located at x4 = 0 + (x1 − x3) = 1.153846 − 0.692308 = 0.461538 with f4 =
−0.309811. Nothing that f4 < f3, we delete the interval [x3, x1] (Fig. 5.10c). The
location of the next experiment can be obtained as x5 = 0 + (x3 − x4) = 0.692308 −
0.461538 = 0.230770 with the corresponding objective function value of f5 =
−0.263678. Since f5 > f4, we delete the interval [0, x5] (Fig. 5.10d). The final exper-
iment is positioned at x6 = x5 + (x3 − x4) = 0.230770 + (0.692308 − 0.461538) =
0.461540 with f6 = −0.309810. (Note that, theoretically, the value of x6 should be
same as that of x4; however, it is slightly different from x4, due to round-off error).
Since f6 >f4, we delete the interval [x6, x3] and obtain the final interval of uncer-
tainty as L6 = [x5, x6] = [0.230770, 0.461540] (Fig. 5.10e). The ratio of the final to
the initial interval of uncertainty is
L6
L0
=
0.461540 − 0.230770
3.0
= 0.076923
This value can be compared with Eq. (5.15), which states that if n experiments (n = 6)
are planned, a resolution no finer than 1/Fn = 1/F6 = 113 = 0.076923 can be expected
from the method.
5.8 GOLDEN SECTION METHOD
The golden section method is same as the Fibonacci method except that in the Fibonacci
method the total number of experiments to be conducted has to be specified before
beginning the calculation, whereas this is not required in the golden section method.
In the Fibonacci method, the location of the first two experiments is determined by
the total number of experiments, N . In the golden section method we start with the
assumption that we are going to conduct a large number of experiments. Of course,
the total number of experiments can be decided during the computation.
The intervals of uncertainty remaining at the end of different number of experiments
can be computed as follows:
L2 = lim
N→∞
FN−1
FN
L0 (5.17)
L3 = lim
N→∞
FN−2
FN
L0 = lim
N→∞
FN−2
FN−1
FN−1
FN
L0
≃ lim
N→∞
(
FN−1
FN
)2
L0 (5.18)
268 Nonlinear Programming I: One-Dimensional Minimization Methods
Figure 5.10 Graphical representation of the solution of Example 5.7.
5.8 Golden Section Method 269
Figure 5.10 (continued )
This result can be generalized to obtain
Lk = lim
N→∞
(
FN−1
FN
)k−1
L0 (5.19)
Using the relation
FN = FN−1 + FN−2 (5.20)
we obtain, after dividing both sides by FN−1,
FN
FN−1
= 1 + FN−2
FN−1
(5.21)
By defining a ratio γ as
γ = lim
N→∞
FN
FN−1
(5.22)
270 Nonlinear Programming I: One-Dimensional Minimization Methods
Eq. (5.21) can be expressed as
γ ≃ 1
γ
+ 1
that is,
γ 2 − γ − 1 = 0 (5.23)
This gives the root γ = 1.618, and hence Eq. (5.19) yields
Lk =
(
1
γ
)k−1
L0 = (0.618)k−1L0 (5.24)
In Eq. (5.18) the ratios FN−2/FN−1 and FN−1/FN have been taken to be same
for large values of N . The validity of this assumption can be seen from the following
table:
Value of N 2 3 4 5 6 7 8 9 10 ∞
Ratio
FN−1
FN
0.5 0.667 0.6 0.625 0.6156 0.619 0.6177 0.6181 0.6184 0.618
The ratio γ has a historical background. Ancient Greek architects believed that a
building having the sides d and b satisfying the relation
d + b
d
= d
b
= γ (5.25)
would have the most pleasing properties (Fig. 5.11). The origin of the name, golden
section method , can also be traced to the Euclid’s geometry. In Euclid’s geometry,
when a line segment is divided into two unequal parts so that the ratio of the whole to
the larger part is equal to the ratio of the larger to the smaller, the division is called
the golden section and the ratio is called the golden mean.
Procedure. The procedure is same as the Fibonacci method except that the location
of the first two experiments is defined by
L∗2 =
FN−2
FN
L0 =
FN−2
FN−1
FN−1
FN
L0 =
L0
γ 2
= 0.382L0 (5.26)
The desired accuracy can be specified to stop the procedure.
Figure 5.11 Rectangular building of sides b and d .
5.9 Comparison of Elimination Methods 271
Example 5.8 Minimize the function
f (x) = 0.65 − [0.75/(1 + x2)] − 0.65x tan−1(1/x)
using the golden section method with n = 6.
SOLUTION The locations of the first two experiments are defined by L∗2 =
0.382L0 = (0.382)(3.0) = 1.1460. Thus x1 = 1.1460 and x2 = 3.0 − 1.1460 = 1.8540
with f1 = f (x1) = −0.208654 and f2 = f (x2) = −0.115124. Since f1 < f2, we
delete the interval [x2, 3.0] based on the assumption of unimodality and obtain the new
interval of uncertainty as L2 = [0, x2] = [0.0, 1.8540]. The third experiment is placed
at x3 = 0 + (x2 − x1) = 1.8540 − 1.1460 = 0.7080. Since f3 = −0.288943 is smaller
than f1 = −0.208654, we delete the interval [x1, x2] and obtain the new interval of
uncertainty as [0.0, x1] = [0.0, 1.1460]. The position of the next experiment is given
by x4 = 0 + (x1 − x3) = 1.1460 − 0.7080 = 0.4380 with f4 = −0.308951.
Since f4 < f3, we delete [x3, x1] and obtain the new interval of uncertainty as [0,
x3] = [0.0, 0.7080]. The next experiment is placed at x5 = 0 + (x3 − x4) = 0.7080 −
0.4380 = 0.2700. Since f5 = −0.278434 is larger than f4 = −0.308951, we delete the
interval [0, x5] and obtain the new interval of uncertainty as [x5, x3] = [0.2700, 0.7080].
The final experiment is placed at x6 = x5 + (x3 − x4) = 0.2700 + (0.7080 − 0.4380) =
0.5400 with f6 = −0.308234. Since f6 >f4, we delete the interval [x6, x3] and obtain
the final interval of uncertainty as [x5, x6] = [0.2700, 0.5400]. Note that this final
interval of uncertainty is slightly larger than the one found in the Fibonacci method,
[0.461540, 0.230770]. The ratio of the final to the initial interval of uncertainty in the
present case is
L6
L0
=
0.5400 − 0.2700
3.0
=
0.27
3.0
= 0.09
5.9 COMPARISON OF ELIMINATION METHODS
The efficiency of an elimination method can be measured in terms of the ratio of the
final and the initial intervals of uncertainty, Ln/L0. The values of this ratio achieved
in various methods for a specified number of experiments (n = 5 and n = 10) are
compared in Table 5.3. It can be seen that the Fibonacci method is the most effi-
cient method, followed by the golden section method, in reducing the interval of
uncertainty.
A similar observation can be made by considering the number of experiments (or
function evaluations) needed to achieve a specified accuracy in various methods. The
results are compared in Table 5.4 for maximum permissible errors of 0.1 and 0.01. It
can be seen that to achieve any specified accuracy, the Fibonacci method requires the
least number of experiments, followed by the golden section method.
Interpolation Methods
The interpolation methods were originally developed as one-dimensional searches
within multivariable optimization techniques, and are generally more efficient than
Fibonacci-type approaches. The aim of all the one-dimensional minimization methods
272 Nonlinear Programming I: One-Dimensional Minimization Methods
Table 5.3 Final Intervals of Uncertainty
Method Formula n = 5 n = 10
Exhaustive search Ln =
2
n + 1
L0 0.33333L0 0.18182L0
Dichotomous search
(δ = 0.01 and
n = even)
Ln =
L0
2n/2
+ δ
(
1 −
1
2n/2
)
1
4
L0 + 0.0075 with
n = 4, 1
8
L0 + 0.00875
with n = 6
0.03125L0 + 0.0096875
Interval halving (n ≥ 3
and odd)
Ln = ( 12 )
(n−1)/2L0 0.25L0 0.0625L0 with n = 9,
0.03125L0 with
n = 11
Fibonacci Ln =
1
Fn
L0 0.125L0 0.01124L0
Golden section Ln = (0.618)n−1L0 0.1459L0 0.01315L0
Table 5.4 Number of Experiments for a Specified Accuracy
Method Error:
1
2
Ln
L0
≤ 0.1 Error:
1
2
Ln
L0
≤ 0.01
Exhaustive search n ≥ 9 n ≥ 99
Dichotomous search (δ = 0.01, L0 = 1) n ≥ 6 n ≥ 14
Interval halving (n ≥ 3 and odd) n ≥ 7 n ≥ 13
Fibonacci n ≥ 4 n ≥ 9
Golden section n ≥ 5 n ≥ 10
is to find λ∗, the smallest nonnegative value of λ, for which the function
f (λ) = f (X + λS) (5.27)
attains a local minimum. Hence if the original function f (X) is expressible as an explicit
function of xi (i = 1, 2, . . . , n), we can readily write the expression for f (λ) = f (X
+ λS) for any specified vector S, set
df
dλ
(λ) = 0 (5.28)
and solve Eq. (5.28) to find λ∗ in terms of X and S. However, in many practical
problems, the function f (λ) cannot be expressed explicitly in terms of λ (as shown in
Example 5.1). In such cases the interpolation methods can be used to find the value
of λ∗.
Example 5.9 Derive the one-dimensional minimization problem for the following
case:
Minimize f (X) = (x21 − x2)2 + (1 − x1)2 (E1)
from the starting point X1 =
{−2
−2
}
along the search direction S =
{
1.00
0.25
}
.
5.10 Quadratic Interpolation Method 273
SOLUTION The new design point X can be expressed as
X =
{
x1
x2
}
= X1 + λS =
{
−2 + λ
−2 + 0.25λ
}
By substituting x1 = −2 + λ and x2 = −2 + 0.25λ in Eq. (E1), we obtain f as a
function of λ as
f (λ) = f
(
−2 + λ
−2 + 0.25λ
)
= [(−2 + λ)2 − (−2 + 0.25λ)]2
+ [1 − (−2 + λ)]2 = λ4 − 8.5λ3 + 31.0625λ2 − 57.0λ + 45.0
The value of λ at which f (λ) attains a minimum gives λ∗.
In the following sections, we discuss three different interpolation methods with
reference to one-dimensional minimization problems that arise during multivariable
optimization problems.
5.10 QUADRATIC INTERPOLATION METHOD
The quadratic interpolation method uses the function values only; hence it is useful
to find the minimizing step (λ∗) of functions f (X) for which the partial derivatives
with respect to the variables xi are not available or difficult to compute [5.2, 5.5].
This method finds the minimizing step length λ∗ in three stages. In the first stage the
S-vector is normalized so that a step length of λ = 1 is acceptable. In the second stage
the function f (λ) is approximated by a quadratic function h(λ) and the minimum, λ̃∗,
of h(λ) is found. If λ̃∗ is not sufficiently close to the true minimum λ∗, a third stage is
used. In this stage a new quadratic function (refit) h′(λ) = a′ + b′λ + c′λ2 is used to
approximate f (λ), and a new value of λ̃∗ is found. This procedure is continued until
a λ̃∗ that is sufficiently close to λ∗ is found.
Stage 1. In this stage,† the S vector is normalized as follows: Find  = max
i
|si |,
where si is the ith component of S and divide each component of S by . Another
method of normalization is to find  = (s21 + s22 + · · · + s2n)1/2 and divide each com-
ponent of S by.
Stage 2. Let
h(λ) = a + bλ + cλ2 (5.29)
be the quadratic function used for approximating the function f (λ). It is worth noting
at this point that a quadratic is the lowest-order polynomial for which a finite minimum
can exist. The necessary condition for the minimum of h(λ) is that
dh
dλ
= b + 2cλ = 0
†This stage is not required if the one-dimensional minimization problem has not arisen within a multivariable
minimization problem.
274 Nonlinear Programming I: One-Dimensional Minimization Methods
that is,
λ̃∗ = −
b
2c
(5.30)
The sufficiency condition for the minimum of h(λ) is that
d2h
dλ2
∣
∣
∣
∣
λ̃∗
> 0
that is,
c > 0 (5.31)
To evaluate the constants a, b, and c in Eq. (5.29), we need to evaluate the function
f (λ) at three points. Let λ = A, λ = B, and λ = C be the points at which the function
f (λ) is evaluated and let fA, fB , and fC be the corresponding function values, that is,
fA = a + bA + cA2
fB = a + bB + cB2
fC = a + bC + cC2 (5.32)
The solution of Eqs. (5.32) gives
a =
fABC(C − B) + fBCA(A − C) + fCAB(B − A)
(A − B)(B − C)(C − A)
(5.33)
b = fA(B
2 − C2) + fB(C2 − A2) + fC(A2 − B2)
(A − B)(B − C)(C − A)
(5.34)
c = −fA(B − C) + fB(C − A) + fC(A − B)
(A − B)(B − C)(C − A)
(5.35)
From Eqs. (5.30), (5.34), and (5.35), the minimum of h(λ) can be obtained as
λ̃∗ =
−b
2c
=
fA(B
2 − C2) + fB(C2 − A2) + fC(A2 − B2)
2[fA(B − C) + fB(C − A) + fC(A − B)]
(5.36)
provided that c, as given by Eq. (5.35), is positive.
To start with, for simplicity, the points A,B, and C can be chosen as 0, t , and 2t ,
respectively, where t is a preselected trial step length. By this procedure, we can save
one function evaluation since fA = f (λ = 0) is generally known from the previous
iteration (of a multivariable search). For this case, Eqs. (5.33) to (5.36) reduce to
a = fA (5.37)
b = 4fB − 3fA − fC
2t
(5.38)
c =
fC + fA − 2fB
2t2
(5.39)
λ̃∗ = 4fB − 3fA − fC
4fB − 2fC − 2fA
t (5.40)
5.10 Quadratic Interpolation Method 275
provided that
c =
fC + fA − 2fB
2t2
> 0 (5.41)
The inequality (5.41) can be satisfied if
fA + fC
2
>fB (5.42)
(i.e., the function value fB should be smaller than the average value of fA and fC).
This can be satisfied if fB lies below the line joining fA and fC as shown in Fig. 5.12.
The following procedure can be used not only to satisfy the inequality (5.42) but
also to ensure that the minimum λ̃∗ lies in the interval 0 < λ̃∗ < 2t .
1. Assuming that fA = f (λ = 0) and the initial step size t0 are known, evaluate
the function f at λ = t0 and obtain f1 = f (λ = t0). The possible outcomes are
shown in Fig. 5.13.
2. If f1 >fA is realized (Fig. 5.13c), set fC = f1 and evaluate the function f at
λ = t0/2 and λ̃∗ using Eq. (5.40) with t = t0/2.
3. If f1 ≤ fA is realized (Fig. 5.13a or b), set fB = f1, and evaluate the function f
at λ = 2t0 to find f2 = f (λ = 2t0). This may result in any one of the situations
shown in Fig. 5.14.
4. If f2 turns out to be greater than f1 (Fig. 5.14b or c), set fC = f2 and compute
λ̃∗ according to Eq. (5.40) with t = t0.
5. If f2 turns out to be smaller than f1, set new f1 = f2 and t0 = 2t0, and repeat
steps 2 to 4 until we are able to find λ̃∗.
Stage 3. The λ̃∗ found in stage 2 is the minimum of the approximating quadratic
h(λ) and we have to make sure that this λ̃∗ is sufficiently close to the true minimum λ∗
of f (λ) before taking λ∗ ≃ λ̃∗. Several tests are possible to ascertain this. One possible
test is to compare f (λ̃∗) with h(λ̃∗) and consider λ̃∗ a sufficiently good approximation
f (l)
l
Figure 5.12 fB smaller than (fA + fC)/2.
276 Nonlinear Programming I: One-Dimensional Minimization Methods
l l
l
l
~
* l
~
*
l
~
*
Figure 5.13 Possible outcomes when the function is evaluated at λ = t0: (a) f1 < fA and
t0 < λ̃
∗; (b) f1 < fA and t0 > λ̃
∗; (c) f1 >fA and t0 > λ̃
∗.
f (l) f (l) f (l) f (l)
l l l l
Figure 5.14 Possible outcomes when function is evaluated at λ = t0 and 2t0: (a) f2 < f1 and
f2 < fA; (b) f2 < fA and f2 >f1; (c) f2 > fA and f2 >f1.
if they differ not more than by a small amount. This criterion can be stated as
∣
∣
∣
∣
∣
h(λ̃∗) − f (λ̃∗)
f (λ̃∗)
∣
∣
∣
∣
∣
≤ ε1 (5.43)
Another possible test is to examine whether df/dλ is close to zero at λ̃∗. Since the
derivatives of f are not used in this method, we can use a finite-difference formula for
5.10 Quadratic Interpolation Method 277
df/dλ and use the criterion
∣
∣
∣
∣
∣
f (λ̃∗ + λ̃∗) − f (λ̃∗ − λ̃∗)
2λ̃∗
∣
∣
∣
∣
∣
≤ ε2 (5.44)
to stop the procedure. In Eqs. (5.43) and (5.44), ε1 and ε2 are small numbers to be
specified depending on the accuracy desired.
If the convergence criteria stated in Eqs. (5.43) and (5.44) are not satisfied, a new
quadratic function
h′(λ) = a′ + b′λ + c′λ2
is used to approximate the function f (λ). To evaluate the constants a′, b′, and c′,
the three best function values of the current fA = f (λ = 0), fB = f (λ = t0), fC =
f (λ = 2t0), and f̃ = f (λ = λ̃∗) are to be used. This process of trying to fit
another polynomial to obtain a better approximation to λ̃∗ is known as refitting the
polynomial.
For refitting the quadratic, we consider all possible situations and select the best
three points of the present A, B,C, and λ̃∗. There are four possibilities, as shown
in Fig. 5.15. The best three points to be used in refitting in each case are given in
Table 5.5. A new value of λ̃∗ is computed by using the general formula, Eq. (5.36). If
this λ̃∗ also does not satisfy the convergence criteria stated in Eqs. (5.43) and (5.44),
a new quadratic has to be refitted according to the scheme outlined in Table 5.5.
f (l)
f (l) f (l)
f (l)
l
l
l
l
l
~
*
l
~
*
l
~
*l
~
*
Figure 5.15 Various possibilities for refitting.
278 Nonlinear Programming I: One-Dimensional Minimization Methods
Table 5.5 Refitting Scheme
New points for refitting
Case Characteristics New Old
1 λ̃∗ >B A B
f̃ < fB B λ̃
∗
C C
Neglect old A
2 λ̃∗ >B A A
f̃ > fB B B
C λ̃∗
Neglect old C
3 λ̃∗ < B A A
f̃ < fB B λ̃
∗
C B
Neglect old C
4 λ̃∗ < B A λ̃∗
f̃ > fB B B
C C
Neglect old A
Example 5.10 Find the minimum of f = λ5 − 5λ3 − 20λ + 5.
SOLUTION Since this is not a multivariable optimization problem, we can proceed
directly to stage 2. Let the initial step size be taken as t0 = 0.5 and A = 0.
Iteration 1
fA = f (λ = 0) = 5
f1 = f (λ = t0) = 0.03125 − 5(0.125) − 20(0.5) + 5 = −5.59375
Since f1 < fA, we set fB = f1 = −5.59375, and find that
f2 = f (λ = 2t0 = 1.0) = −19.0
As f2 < f1, we set new t0 = 1 and f1 = −19.0. Again we find that f1 < fA and hence
set fB = f1 = −19.0, and find that f2 = f (λ = 2t0 = 2) = −43. Since f2 < f1, we
again set t0 = 2 and f1 = −43. As this f1 < fA, set fB = f1 = −43 and evaluate
f2 = f (λ = 2t0 = 4) = 629. This time f2 >f1 and hence we set fC = f2 = 629 and
compute λ̃∗ from Eq. (5.40) as
λ̃∗ = 4(−43) − 3(5) − 629
4(−43) − 2(629) − 2(5)
(2) = 1632
1440
= 1.135
Convergence test : Since A = 0, fA = 5, B = 2, fB = −43, C = 4, and fC = 629,
the values of a, b, and c can be found to be
a = 5, b = −204, c = 90
5.10 Quadratic Interpolation Method 279
and
h(λ̃∗) = h(1.135) = 5 − 204(1.135) + 90(1.135)2 = −110.9
Since
f̃ = f (λ̃∗) = (1.135)5 − 5(1.135)3 − 20(1.135) + 5.0 = −23.127
we have
∣
∣
∣
∣
∣
h(λ̃∗) − f (λ̃∗)
f (λ̃∗)
∣
∣
∣
∣
∣
=
∣
∣
∣
∣
−116.5 + 23.127
−23.127
∣
∣
∣
∣
= 3.8
As this quantity is very large, convergence is not achieved and hence we have to use
refitting .
Iteration 2
Since λ̃∗ < B and f̃ > fB , we take the new values of A,B, and C as
A = 1.135, fA = −23.127
B = 2.0, fB = −43.0
C = 4.0, fC = 629.0
and compute new λ̃∗, using Eq. (5.36), as
λ̃∗ =
(−23.127)(4.0 − 16.0) + (−43.0)(16.0 − 1.29)
+ (629.0)(1.29 − 4.0)
2[(−23.127)(2.0 − 4.0) + (−43.0)(4.0 − 1.135)
+ (629.0)(1.135 − 2.0)]
= 1.661
Convergence test : To test the convergence, we compute the coefficients of the
quadratic as
a = 288.0, b = −417.0, c = 125.3
As
h(λ̃∗) = h(1.661) = 288.0 − 417.0(1.661) + 125.3(1.661)2 = −59.7
f̃ = f (λ̃∗) = 12.8 − 5(4.59) − 20(1.661) + 5.0 = −38.37
we obtain
∣
∣
∣
∣
∣
h(λ̃∗) − f (λ̃∗)
f (λ̃∗)
∣
∣
∣
∣
∣
=
∣
∣
∣
∣
−59.70 + 38.37
−38.37
∣
∣
∣
∣
= 0.556
Since this quantity is not sufficiently small, we need to proceed to the next refit.
280 Nonlinear Programming I: One-Dimensional Minimization Methods
5.11 CUBIC INTERPOLATION METHOD
The cubic interpolation method finds the minimizing step length λ∗ in four stages [5.5,
5.11]. It makes use of the derivative of the function f :
f ′(λ) = df
dλ
= d
dλ
f (X + λS) = ST∇f (X + λS)
The first stage normalizes the S vector so that a step size λ = 1 is acceptable. The
second stage establishes bounds on λ∗, and the third stage finds the value of λ̃∗ by
approximating f (λ) by a cubic polynomial h(λ). If the λ̃∗ found in stage 3 does
not satisfy the prescribed convergence criteria, the cubic polynomial is refitted in the
fourth stage.
Stage 1. Calculate  = maxi |si |, where |si | is the absolute value of the ith compo-
nent of S, and divide each component of S by . An alternative method of normalization
is to find
 = (s21 + s22 + · · · + s2n)1/2
and divide each component of S by .
Stage 2. To establish lower and upper bounds on the optimal step size λ∗, we need
to find two points A and B at which the slope df/dλ has different signs. We know that
at λ = 0,
df
dλ
∣
∣
∣
∣
λ=0
= ST∇f (X) < 0
since S is presumed to be a direction of descent.†
Hence to start with we can take A = 0 and try to find a point λ = B at which the
slope df/dλ is positive. Point B can be taken as the first value out of t0, 2t0, 4t0, 8t0, . . .
at which f ′ is nonnegative, where t0 is a preassigned initial step size. It then follows
that λ∗ is bounded in the interval A < λ∗ ≤ B (Fig. 5.16).
Stage 3. If the cubic equation
h(λ) = a + bλ + cλ2 + λ3 (5.45)
f (l)
l
Figure 5.16 Minimum of f (λ) lies between A and B.
†In this case the angle between the direction of steepest descent and S will be less than 90
◦
.
5.11 Cubic Interpolation Method 281
is used to approximate the function f (λ) between points A and B, we need to find the
values fA = f (λ = A), f ′A = df/dλ(λ = A), fB = f (λ = B), and f ′B = df/dλ(λ =
B) in order to evaluate the constants, a, b, c, and d in Eq. (5.45). By assuming that
A = 0, we can derive a general formula for λ̃∗. From Eq. (5.45) we have
fA = a + bA + cA2 + dA3
fB = a + bB + cB2 + dB3
f ′A = b + 2cA + 3dA2
f ′B = b + 2cB + 3dB2 (5.46)
Equations (5.46) can be solved to find the constants as
a = fA − bA − cA2 − dA3 (5.47)
with
b = 1
(A − B)2
(B2f ′A + A2f ′B + 2ABZ) (5.48)
c = −
1
(A − B)2
[(A + B)Z + Bf ′A + Af ′B ] (5.49)
and
d =
1
3(A − B)2
(2Z + f ′A + f ′B) (5.50)
where
Z = 3(fA − fB)
B − A
+ f ′A + f ′B (5.51)
The necessary condition for the minimum of h(λ) given by Eq. (5.45) is that
dh
dλ
= b + 2cλ + 3dλ2 = 0
that is,
λ̃∗ = −c ± (c
2 − 3bd)1/2
3d
(5.52)
The application of the sufficiency condition for the minimum of h(λ) leads to the
relation
d2h
dλ2
∣
∣
∣
∣
λ̃∗
= 2c + 6dλ̃∗ > 0 (5.53)
By substituting the expressions for b, c, and d given by Eqs. (5.48) to (5.50) into
Eqs. (5.52) and (5.53), we obtain
λ̃∗ = A +
f ′A + Z ± Q
f ′A + f ′B + 2Z
(B − A) (5.54)
282 Nonlinear Programming I: One-Dimensional Minimization Methods
where
Q = (Z2 − f ′Af ′B)1/2 (5.55)
2(B − A)(2Z + f ′A + f ′B)(f ′A + Z ± Q)
−2(B − A)(f ′ 2A + Zf ′B + 3Zf ′A + 2Z2)
−2(B + A)f ′Af ′B > 0 (5.56)
By specializing Eqs. (5.47) to (5.56) for the case where A = 0, we obtain
a = fA
b = f ′A
c = − 1
B
(Z + f ′A)
d = 1
3B2
(2Z + f ′A + f ′B)
λ̃∗ = B
f ′A + Z ± Q
f ′A + f ′B + 2Z
(5.57)
Q = (Z2 − f ′Af ′B)1/2 > 0 (5.58)
where
Z = 3(fA − fB)
B
+ f ′A + f ′B (5.59)
The two values of λ̃∗ in Eqs. (5.54) and (5.57) correspond to the two possibilities
for the vanishing of h′(λ) [i.e., at a maximum of h(λ) and at a minimum]. To avoid
imaginary values of Q, we should ensure the satisfaction of the condition
Z2 − f ′Af ′B ≥ 0
in Eq. (5.55). This inequality is satisfied automatically since A and B are selected
such that f ′A < 0 and f
′
B ≥ 0. Furthermore, the sufficiency condition (when A = 0)
requires that Q > 0, which is already satisfied. Now we compute λ̃∗ using Eq. (5.57)
and proceed to the next stage.
Stage 4. The value of λ̃∗ found in stage 3 is the true minimum of h(λ) and may
not be close to the minimum of f (λ). Hence the following convergence criteria can be
used before choosing λ∗ ≈ λ̃∗ :
∣
∣
∣
∣
∣
h(λ̃∗) − f (λ̃∗)
f (λ̃∗)
∣
∣
∣
∣
∣
≤ ε1 (5.60)
∣
∣
∣
∣
df
dλ
∣
∣
∣
∣
λ̃∗
= | ST∇f |λ̃∗ | ≤ ε2 (5.61)
5.11 Cubic Interpolation Method 283
where ε1 and ε2 are small numbers whose values depend on the accuracy desired. The
criterion of Eq. (5.61) can be stated in nondimensional form as
∣
∣
∣
∣
ST∇f
|S||∇f |
∣
∣
∣
∣
λ̃∗
≤ ε2 (5.62)
If the criteria stated in Eqs. (5.60) and (5.62) are not satisfied, a new cubic equation
h′(λ) = a′ + b′λ + c′λ2 + d ′λ3
can be used to approximate f (λ). The constants a′, b′, c′, and d ′ can be evaluated
by using the function and derivative values at the best two points out of the three
points currently available: A, B, and λ̃∗. Now the general formula given by Eq. (5.54)
is to be used for finding the optimal step size λ̃∗. If f ′(λ̃∗) < 0, the new points A
and B are taken as λ̃∗ and B, respectively; otherwise [if f ′(λ̃∗) > 0], the new points
A and B are taken as A and λ̃∗, and Eq. (5.54) is applied to find the new value of
λ̃∗. Equations (5.60) and (5.62) are again used to test for the convergence of λ̃∗. If
convergence is achieved, λ̃∗ is taken as λ∗ and the procedure is stopped. Otherwise,
the entire procedure is repeated until the desired convergence is achieved.
The flowchart for implementing the cubic interpolation method is given in Fig. 5.17.
Example 5.11 Find the minimum of f = λ5 − 5λ3 − 20λ + 5 by the cubic interpola-
tion method.
SOLUTION Since this problem has not arisen during a multivariable optimization
process, we can skip stage 1. We take A = 0 and find that
df
dλ
(λ = A = 0) = 5λ4 − 15λ2 − 20
∣
∣
∣
∣
λ=0
= −20 < 0
To find B at which df/dλ is nonnegative, we start with t0 = 0.4 and evaluate the
derivative at t0, 2t0, 4t0, . . . . This gives
f ′(t0 = 0.4) = 5(0.4)4 − 15(0.4)2 − 20.0 = −22.272
f ′(2t0 = 0.8) = 5(0.8)4 − 15(0.8)2 − 20.0 = −27.552
f ′(4t0 = 1.6) = 5(1.6)4 − 15(1.6)2 − 20.0 = −25.632
f ′(8t0 = 3.2) = 5(3.2)4 − 15(3.2)2 − 20.0 = 350.688
Thus we find that†
A = 0.0, fA = 5.0, f ′A = −20.0
B = 3.2, fB = 113.0, f ′B = 350.688
A < λ∗ < B
†As f ′ has been found to be negative at λ = 1.6 also, we can take A = 1.6 for faster convergence.
284 Nonlinear Programming I: One-Dimensional Minimization Methods
Figure 5.17 Flowchart for cubic interpolation method.
5.11 Cubic Interpolation Method 285
Iteration 1
To find the value of λ̃∗ and to test the convergence criteria, we first compute Z and Q
as
Z =
3(5.0 − 113.0)
3.2
− 20.0 + 350.688 = 229.588
Q = [229.5882 + (20.0)(350.688)]1/2 = 244.0
Hence
λ̃∗ = 3.2
(
−20.0 + 229.588 ± 244.0
−20.0 + 350.688 + 459.176
)
= 1.84 or − 0.1396
By discarding the negative value, we have
λ̃∗ = 1.84
Convergence criterion: If λ̃∗ is close to the true minimum, λ∗, then f ′(λ̃∗) =
df (λ̃∗)/dλ should be approximately zero. Since f ′ = 5λ4 −15λ2 − 20,
f ′(λ̃∗) = 5(1.84)4 − 15(1.84)2 − 20 = −13.0
Since this is not small, we go to the next iteration or refitting. As f ′(λ̃∗) < 0, we take
A = λ̃∗ and
fA = f (λ̃∗) = (1.84)5 − 5(1.84)3 − 20(1.84) + 5 = −41.70
Thus
A = 1.84, fA = −41.70, f ′A = −13.0
B = 3.2, fB = 113.0, f ′B = 350.688
A < λ̃∗ < B
Iteration 2
Z = 3(−41.7 − 113.0)
3.20 − 1.84
− 13.0 + 350.688 = −3.312
Q = [(−3.312)2 + (13.0)(350.688)]1/2 = 67.5
Hence
λ̃∗ = 1.84 + −13.0 − 3.312 ± 67.5
−13.0 + 350.688 − 6.624
(3.2 − 1.84) = 2.05
Convergence criterion:
f ′(λ̃∗) = 5.0(2.05)4 − 15.0(2.05)2 − 20.0 = 5.35
Since this value is large, we go the next iteration with B = λ̃∗ = 2.05 [as f ′(λ̃∗) > 0]
and
fB = (2.05)5 − 5.0(2.05)3 − 20.0(2.05) + 5.0 = −42.90
286 Nonlinear Programming I: One-Dimensional Minimization Methods
Thus
A = 1.84, fA = −41.70, f ′A = −13.00
B = 2.05, fB = −42.90, f ′B = 5.35
A < λ∗ < B
Iteration 3
Z = 3.0(−41.70 + 42.90)
(2.05 − 1.84)
− 13.00 + 5.35 = 9.49
Q = [(9.49)2 + (13.0)(5.35)]1/2 = 12.61
Therefore,
λ̃∗ = 1.84 + −13.00 + 9.49 ± 12.61
−13.00 + 5.35 + 18.98
(2.05 − 1.84) = 2.0086
Convergence criterion:
f ′(λ̃∗) = 5.0(2.0086)4 − 15.0(2.0086)2 − 20.0 = 0.855
Assuming that this value is close to zero, we can stop the iterative process and take
λ∗ ≃ λ̃∗ = 2.0086
5.12 DIRECT ROOT METHODS
The necessary condition for f (λ) to have a minimum of λ∗ is that f ′ (λ∗) = 0. The
direct root methods seek to find the root (or solution) of the equation, f ′(λ) = 0. Three
root-finding methods—the Newton, the quasi-Newton, and the secant methods—are
discussed in this section.
5.12.1 Newton Method
Consider the quadratic approximation of the function f (λ) at λ = λi using the Taylor’s
series expansion:
f (λ) = f (λi) + f ′(λi)(λ − λi) + 12f
′′(λi)(λ − λi)2 (5.63)
By setting the derivative of Eq. (5.63) equal to zero for the minimum of f (λ), we
obtain
f ′(λ) = f ′(λi) + f ′′(λi)(λ − λi) = 0 (5.64)
If λi denotes an approximation to the minimum of f (λ), Eq. (5.64) can be rearranged
to obtain an improved approximation as
λi+1 = λi −
f ′(λi)
f ′′(λi)
(5.65)
5.12 Direct Root Methods 287
Thus the Newton method , Eq. (5.65), is equivalent to using a quadratic approximation
for the function f (λ) and applying the necessary conditions. The iterative process given
by Eq. (5.65) can be assumed to have converged when the derivative, f ′(λi+1), is close
to zero:
|f ′(λi+1)| ≤ ε (5.66)
where ε is a small quantity. The convergence process of the method is shown graphi-
cally in Fig. 5.18a.
Remarks:
1. The Newton method was originally developed by Newton for solving nonlinear
equations and later refined by Raphson, and hence the method is also known as
Newton–Raphson method in the literature of numerical analysis.
2. The method requires both the first- and second-order derivatives of f (λ).
3. If f ′′(λi) = 0 [in Eq. (5.65)], the Newton iterative method has a powerful
(fastest) convergence property, known as quadratic convergence.†
4. If the starting point for the iterative process is not close to the true solution λ∗,
the Newton iterative process might diverge as illustrated in Fig. 5.18b.
li
li
l*
l*
f ′(l)
l
f ′(l)
l
Tangent at li
o
(a)
(b)
o
Tangent at li
Tangent at li + 1
Tangent at li + 1
li + 2
li + 2
li + 1
li + 1
Figure 5.18 Iterative process of Newton method: (a) convergence; (b) divergence.
†The definition of quadratic convergence is given in Section 6.7.
288 Nonlinear Programming I: One-Dimensional Minimization Methods
Example 5.12 Find the minimum of the function
f (λ) = 0.65 − 0.75
1 + λ2
− 0.65λ tan−1 1
λ
using the Newton–Raphson method with the starting point λ1 = 0.1. Use ε = 0.01 in
Eq. (5.66) for checking the convergence.
SOLUTION The first and second derivatives of the function f (λ) are given by
f ′(λ) = 1.5λ
(1 + λ2)2
+ 0.65λ
1 + λ2
− 0.65 tan−1 1
λ
f ′′(λ) = 1.5(1 − 3λ
2)
(1 + λ2)3
+ 0.65(1 − λ
2)
(1 + λ2)2
+ 0.65
1 + λ2
= 2.8 − 3.2λ
2
(1 + λ2)3
Iteration 1
λ1 = 0.1, f (λ1) = −0.188197, f ′(λ1) = −0.744832, f ′′(λ1) = 2.68659
λ2 = λ1 −
f ′(λ1)
f ′′(λ1)
= 0.377241
Convergence check: |f ′(λ2)| = |−0.138230|>ε.
Iteration 2
f (λ2) = −0.303279, f ′(λ2) = −0.138230, f ′′(λ2) = 1.57296
λ3 = λ2 −
f ′(λ2)
f ′′(λ2)
= 0.465119
Convergence check: |f ′(λ3)| = |−0.0179078| >ε.
Iteration 3
f (λ3) = −0.309881, f ′(λ3) = −0.0179078, f ′′(λ3) = 1.17126
λ4 = λ3 −
f ′(λ3)
f ′′(λ3)
= 0.480409
Convergence check: |f ′(λ4)| = |−0.0005033| < ε.
Since the process has converged, the optimum solution is taken as λ∗ ≈ λ4 =
0.480409.
5.12.2 Quasi-Newton Method
If the function being minimized f (λ) is not available in closed form or is difficult to
differentiate, the derivatives f ′(λ) and f ′′(λ) in Eq. (5.65) can be approximated by the
5.12 Direct Root Methods 289
finite difference formulas as
f ′(λi) =
f (λi + λ) − f (λi − λ)
2λ
(5.67)
f ′′(λi) =
f (λi + λ) − 2f (λi) + f (λi − λ)
λ2
(5.68)
where λ is a small step size. Substitution of Eqs. (5.67) and (5.68) into Eq. (5.65)
leads to
λi+1 = λi −
λ[f (λi + λ) − f (λi − λ)]
2[f (λi + λ) − 2f (λi) + f (λi − λ)]
(5.69)
The iterative process indicated by Eq. (5.69) is known as the quasi-Newton method .
To test the convergence of the iterative process, the following criterion can be used:
|f ′(λi+1)| =
∣
∣
∣
∣
f (λi+1 + λ) − f (λi+1 − λ)
2λ
∣
∣
∣
∣
≤ ε (5.70)
where a central difference formula has been used for evaluating the derivative of f
and ε is a small quantity.
Remarks:
1. The central difference formulas have been used in Eqs. (5.69) and (5.70). How-
ever, the forward or backward difference formulas can also be used for this
purpose.
2. Equation (5.69) requires the evaluation of the function at the points λi + λ
and λi − λ in addition to λi in each iteration.
Example 5.13 Find the minimum of the function
f (λ) = 0.65 −
0.75
1 + λ2
− 0.65λ tan−1
1
λ
using quasi-Newton method with the starting point λ1 = 0.1 and the step size λ =
0.01 in central difference formulas. Use ε = 0.01 in Eq. (5.70) for checking the con-
vergence.
SOLUTION
Iteration 1
λ1 = 0.1, λ = 0.01, ε = 0.01, f1 = f (λ1) = −0.188197,
f +1 = f (λ1 + λ) = −0.195512, f
−
1 = f (λ1 − λ) = −0.180615
λ2 = λ1 −
λ(f +1 − f
−
1 )
2(f +1 − 2f1 + f
−
1 )
= 0.377882
Convergence check:
|f ′(λ2)| =
∣
∣
∣
∣
f +2 − f
−
2
2λ
∣
∣
∣
∣
= 0.137300 > ε
290 Nonlinear Programming I: One-Dimensional Minimization Methods
Iteration 2
f2 = f (λ2) = −0.303368, f +2 = f (λ2 + λ) = −0.304662,
f −2 = f (λ2 − λ) = −0.301916
λ3 = λ2 −
λ(f +2 − f
−
2 )
2(f +2 − 2f2 + f
−
2 )
= 0.465390
Convergence check:
|f ′(λ3)| =
∣
∣
∣
∣
f +3 − f
−
3
2λ
∣
∣
∣
∣
= 0.017700 >ε
Iteration 3
f3 = f (λ3) = −0.309885, f +3 = f (λ3 + λ) = −0.310004,
f −3 = f (λ3 − λ) = −0.309650
λ4 = λ3 −
λ(f +3 − f
−
3 )
2(f +3 − 2f3 + f
−
3 )
= 0.480600
Convergence check:
|f ′(λ4)| =
∣
∣
∣
∣
f +4 − f
−
4
2λ
∣
∣
∣
∣
= 0.000350 < ε
Since the process has converged, we take the optimum solution as λ∗ ≈ λ4 = 0.480600.
5.12.3 Secant Method
The secant method uses an equation similar to Eq. (5.64) as
f ′(λ) = f ′(λi) + s(λ − λi) = 0 (5.71)
where s is the slope of the line connecting the two points (A, f ′(A)) and (B, f ′(B)),
where A and B denote two different approximations to the correct solution, λ∗. The
slope s can be expressed as (Fig. 5.19)
s =
f ′(B) − f ′(A)
B − A
(5.72)
Equation (5.71) approximates the function f ′(λ) between A and B as a linear equation
(secant), and hence the solution of Eq. (5.71) gives the new approximation to the root
of f ′(λ) as
λi+1 = λi −
f ′(λi)
s
= A −
f ′(A)(B − A)
f ′(B) − f ′(A)
(5.73)
The iterative process given by Eq. (5.73) is known as the secant method (Fig. 5.19).
Since the secant approaches the second derivative of f (λ) at A as B approaches A,
5.12 Direct Root Methods 291
f ′(l)
l
A = li
li + 2
li + 1
l*
Figure 5.19 Iterative process of the secant method.
the secant method can also be considered as a quasi-Newton method. It can also be
considered as a form of elimination technique since part of the interval, (A, λi+1) in
Fig. 5.19, is eliminated in every iteration. The iterative process can be implemented by
using the following step-by-step procedure.
1. Set λ1 = A = 0 and evaluate f ′(A). The value of f ′(A) will be negative.
Assume an initial trial step length t0. Set i = 1.
2. Evaluate f ′(t0).
3. If f ′(t0) < 0, set A = λi = t0, f ′(A) = f ′(t0), new t0 = 2t0, and go to step 2.
4. If f ′(t0) ≥ 0, set B = t0, f ′(B) = f ′(t0), and go to step 5.
5. Find the new approximate solution of the problem as
λi+1 = A −
f ′(A)(B − A)
f ′(B) − f ′(A)
(5.74)
6. Test for convergence:
|f ′(λi + 1)| ≤ ε (5.75)
where ε is a small quantity. If Eq. (5.75) is satisfied, take λ∗ ≈ λi+1 and stop
the procedure. Otherwise, go to step 7.
7. If f ′(λi+1) ≥ 0, set new B = λi+1, f ′(B) = f ′(λi+1), i = i + 1, and go to
step 5.
8. If f ′(λi+1) < 0, set new A = λi+1, f ′(A) = f ′(λi+1), i = i + 1, and go to
step 5.
292 Nonlinear Programming I: One-Dimensional Minimization Methods
f ′(l)
l
l
~
1
* l
~
2
*
l
~
3
*
Figure 5.20 Situation when f ′A varies very slowly.
Remarks:
1. The secant method is identical to assuming a linear equation for f ′(λ). This
implies that the original function, f (λ), is approximated by a quadratic equation.
2. In some cases we may encounter a situation where the function f ′(λ) varies
very slowly with λ, as shown in Fig. 5.20. This situation can be identified
by noticing that the point B remains unaltered for several consecutive refits.
Once such a situation is suspected, the convergence process can be improved
by taking the next value of λi+1 as (A + B)/2 instead of finding its value from
Eq. (5.74).
Example 5.14 Find the minimum of the function
f (λ) = 0.65 − 0.75
1 + λ2
− 0.65λ tan−1 1
λ
using the secant method with an initial step size of t0 = 0.1, λ1 = 0.0, and ε = 0.01.
SOLUTION λ1 = A = 0.0, t0 = 0.1, f ′(A) = −1.02102, B = A + t0 = 0.1,
f ′(B) = −0.744832. Since f ′(B) < 0, we set new A = 0.1, f ′(A) = −0.744832, t0 =
2(0.1) = 0.2, B = λ1 + t0 = 0.2, and compute f ′(B) = −0.490343. Since f ′(B) < 0,
we set new A = 0.2, f ′(A) = −0.490343, t0 = 2(0.2) = 0.4, B = λ1 + t0 = 0.4,
and compute f ′(B) = −0.103652. Since f ′(B) < 0, we set new A = 0.4, f ′(A) =
−0.103652, t0 = 2(0.4) = 0.8, B = λ1 + t0 = 0.8, and compute f ′(B) = +0.180800.
Since f ′(B) > 0, we proceed to find λ2.
Iteration 1
Since A = λ1 = 0.4, f ′(A) = −0.103652, B = 0.8, f ′(B) = +0.180800, we compute
λ2 = A −
f ′(A)(B − A)
f ′(B) − f ′(A)
= 0.545757
Convergence check: |f ′(λ2)| = |+0.0105789| >ε.
5.13 Practical Considerations 293
Iteration 2
Since f ′(λ2) = +0.0105789 > 0, we set new A = 0.4, f ′(A) = −0.103652, B = λ2 =
0.545757, f ′(B) = f ′(λ2) = +0.0105789, and compute
λ3 = A −
f ′(A)(B − A)
f ′(B) − f ′(A)
= 0.490632
Convergence check: |f ′(λ3)| = |+0.00151235| < ε.
Since the process has converged, the optimum solution is given by λ∗ ≈ λ3 =
0.490632.
5.13 PRACTICAL CONSIDERATIONS
5.13.1 How to Make the Methods Efficient and More Reliable
In some cases, some of the interpolation methods discussed in Sections 5.10 to 5.12
may be very slow to converge, may diverge, or may predict the minimum of the func-
tion, f (λ), outside the initial interval of uncertainty, especially when the interpolating
polynomial is not representative of the variation of the function being minimized. In
such cases we can use the Fibonacci or golden section method to find the minimum. In
some problems it might prove to be more efficient to combine several techniques. For
example, the unrestricted search with an accelerated step size can be used to bracket
the minimum and then the Fibonacci or the golden section method can be used to find
the optimum point. In some cases the Fibonacci or golden section method can be used
in conjunction with an interpolation method.
5.13.2 Implementation in Multivariable Optimization Problems
As stated earlier, the one-dimensional minimization methods are useful in multivariable
optimization problems to find an improved design vector Xi+1 from the current design
vector Xi using the formula
Xi+1 = Xi + λ∗i Si (5.76)
where Si is the known search direction and λ
∗
i is the optimal step length found by
solving the one-dimensional minimization problem as
λ∗i = min
λi
[f (Xi + λiSi)] (5.77)
Here the objective function f is to be evaluated at any trial step length t0 as
f (t0) = f (Xi + t0Si) (5.78)
Similarly, the derivative of the function f with respect to λ corresponding to the trial
step length t0 is to be found as
df
dλ
∣
∣
∣
∣
λ=t0
= STi f |λ=t0 (5.79)
Separate function programs or subroutines can be written conveniently to implement
Eqs. (5.78) and (5.79).
294 Nonlinear Programming I: One-Dimensional Minimization Methods
5.13.3 Comparison of Methods
It has been shown in Section 5.9 that the Fibonacci method is the most efficient elimina-
tion technique in finding the minimum of a function if the initial interval of uncertainty
is known. In the absence of the initial interval of uncertainty, the quadratic interpo-
lation method or the quasi-Newton method is expected to be more efficient when the
derivatives of the function are not available. When the first derivatives of the function
being minimized are available, the cubic interpolation method or the secant method are
expected to be very efficient. On the other hand, if both the first and second derivatives
of the function are available, the Newton method will be the most efficient one in
finding the optimal step length, λ∗.
In general, the efficiency and reliability of the various methods are problem depen-
dent and any efficient computer program must include many heuristic additions not
indicated explicitly by the method. The heuristic considerations are needed to handle
multimodal functions (functions with multiple extreme points), sharp variations in the
slopes (first derivatives) and curvatures (second derivatives) of the function, and the
effects of round-off errors resulting from the precision used in the arithmetic opera-
tions. A comparative study of the efficiencies of the various search methods is given in
Ref. [5.10].
5.14 MATLAB SOLUTION OF ONE-DIMENSIONAL
MINIMIZATION PROBLEMS
The solution of one-dimensional minimization problems, using the MATLAB program
optimset, is illustrated by the following example.
Example 5.15 Find the minimum of the following function:
f (x) = 0.65 − 0.75
1 + x2
− 0.65x tan−1
(
1
x
)
SOLUTION
Step 1 : Write an M-file objfun.m for the objective function.
function f= objfun(x)
f= 0.65–(0.75/(1+x^2))–0.65*x*atan(1/x);
Step 2 : Invoke unconstrained optimization program (write this in new MATLAB
file).
clc
clear all
warning off
options = optimset('LargeScale','off');
[x,fval] = fminbnd(@objfun,0,0.5,options)
Review Questions 295
This produces the solution or ouput as follows:
x=
0.4809
fval =
-0.3100
REFERENCES AND BIBLIOGRAPHY
5.1 J. S. Przemieniecki, Theory of Matrix Structural Analysis , McGraw-Hill, New York, 1968.
5.2 M. J. D. Powell, An efficient method for finding the minimum of a function of sev-
eral variables without calculating derivatives, Computer Journal , Vol. 7, pp. 155–162,
1964.
5.3 R. Fletcher and C. M. Reeves, Function minimization by conjugate gradients, Computer
Journal , Vol. 7, pp. 149–154, 1964.
5.4 B. Carnahan, H. A. Luther, and J. O. Wilkes, Applied Numerical Methods , Wiley, New
York, 1969.
5.5 R. L. Fox, Optimization Methods for Engineering Design , Addison-Wesley, Reading, MA,
1971.
5.6 D. J. Wilde, Optimum Seeking Methods , Prentice Hall, Englewood Cliffs, NJ, 1964.
5.7 A. I. Cohen, Stepsize analysis for descent methods, Journal of Optimization Theory and
Applications , Vol. 33, pp. 187–205, 1981.
5.8 P. E. Gill, W. Murray, and M. H. Wright, Practical Optimization , Academic Press, New
York, 1981.
5.9 J. E. Dennis and R. B. Schnabel, Numerical Methods for Unconstrained Optimization and
Nonlinear Equations , Prentice Hall, Englewood Cliffs, NJ, 1983.
5.10 R. P. Brent, Algorithms for Minimization Without Derivatives , Prentice Hall, Englewood
Cliffs, NJ, 1973.
5.11 W. C. Davidon, Variable metric method for minimization, Argonne National Laboratory,
ANL-5990 (rev), 1959.
REVIEW QUESTIONS
5.1 What is a one-dimensional minimization problem?
5.2 What are the limitations of classical methods in solving a one-dimensional minimization
problem?
5.3 What is the difference between elimination and interpolation methods?
5.4 Define Fibonacci numbers.
5.5 What is the difference between Fibonacci and golden section methods?
5.6 What is a unimodal function?
5.7 What is an interval of uncertainty?
5.8 Suggest a method of finding the minimum of a multimodal function.
5.9 What is an exhaustive search method?
296 Nonlinear Programming I: One-Dimensional Minimization Methods
5.10 What is a dichotomous search method?
5.11 Define the golden mean.
5.12 What is the difference between quadratic and cubic interpolation methods?
5.13 Why is refitting necessary in interpolation methods?
5.14 What is a direct root method?
5.15 What is the basis of the interval halving method?
5.16 What is the difference between Newton and quasi-Newton methods?
5.17 What is the secant method?
5.18 Answer true or false:
(a) A unimodal function cannot be discontinuous.
(b) All elimination methods assume the function to be unimodal.
(c) The golden section method is more accurate than the Fibonacci method.
(d) Nearly 50% of the interval of uncertainty is eliminated with each pair of experiments
in the dichotomous search method.
(e) The number of experiments to be conducted is to be specified beforehand in both the
Fibonacci and golden section methods.
PROBLEMS
5.1 Find the minimum of the function
f (x) = 0.65 − 0.75
1 + x2
− 0.65x tan−1 1
x
using the following methods:
(a) Unrestricted search with a fixed step size of 0.1 from the starting point 0.0
(b) Unrestricted search with an accelerated step size using an initial step size of 0.1 and
starting point of 0.0
(c) Exhaustive search method in the interval (0, 3) to achieve an accuracy of within 5%
of the exact value
(d) Dichotomous search method in the interval (0, 3) to achieve an accuracy of within
5% of the exact value using a value of δ = 0.0001
(e) Interval halving method in the interval (0, 3) to achieve an accuracy of within 5% of
the exact value
5.2 Find the minimum of the function given in Problem 5.1 using the quadratic interpolation
method with an initial step size of 0.1.
5.3 Find the minimum of the function given in Problem 5.1 using the cubic interpolation
method with an initial step size of t0 = 0.1.
5.4 Plot the graph of the function f (x) given in Problem 5.1 in the range (0, 3) and identify
its minimum.
Problems 297
5.5 The shear stress induced along the z-axis when two cylinders are in contact with each
other is given by
τzy
pmax
= − 1
2




− 1√
1 +
( z
b
)2
+





2 − 1
1 +
( z
b
)2





×
√
1 +
( z
b
)2
− 2
( z
b
)




(1)
where 2b is the width of the contact area and pmax is the maximum pressure developed
at the center of the contact area (Fig. 5.21):
b =




2F
πl
1 − v21
E1
+
1 − v22
E2
1
d1
+ 1
d2




1/2
(2)
pmax =
2F
πbl
(3)
F is the contact force; E1 and E2 are Young’s moduli of the two cylinders; ν1 and ν2 are
Poisson’s ratios of the two cylinders; d1 and d2 the diameters of the two cylinders, and l
the axial length of contact (length of the shorter cylinder). In many practical applications,
Figure 5.21 Contact stress between two cylinders.
298 Nonlinear Programming I: One-Dimensional Minimization Methods
such as roller bearings, when the contact load (F ) is large, a crack originates at the point
of maximum shear stress and propagates to the surface leading to a fatigue failure. To
locate the origin of a crack, it is necessary to find the point at which the shear stress
attains its maximum value. Show that the problem of finding the location of the maximum
shear stress for ν1 = ν2 = 0.3 reduces to maximizing the function
f (λ) =
0.5
√
1 + λ2
−
√
1 + λ2
(
1 −
0.5
1 + λ2
)
+ λ (4)
where f = τzy/pmax and λ = z/b.
5.6 Plot the graph of the function f (λ) given by Eq. (4) in Problem 5.5 in the range (0, 3)
and identify its maximum.
5.7 Find the maximum of the function given by Eq. (4) in Problem 5.5 using the following
methods:
(a) Unrestricted search with a fixed step size of 0.1 from the starting point 0.0
(b) Unrestricted search with an accelerated step size using an initial step length of 0.1
and a starting point of 0.0
(c) Exhaustive search method in the interval (0, 3) to achieve an accuracy of within 5%
of the exact value
(d) Dichotomous search method in the interval (0, 3) to achieve an accuracy of within
5% of the exact value using a value of δ = 0.0001
(e) Interval halving method in the interval (0, 3) to achieve an accuracy of within 5%
of the exact value
5.8 Find the maximum of the function given by Eq. (4) in Problem 5.5 using the following
methods:
(a) Fibonacci method with n = 8
(b) Golden section method with n = 8
5.9 Find the maximum of the function given by Eq. (4) in Problem 5.5 using the quadratic
interpolation method with an initial step length of 0.1.
5.10 Find the maximum of the function given by Eq. (4) in Problem 5.5 using the cubic
interpolation method with an initial step length of t0 = 0.1.
5.11 Find the maximum of the function f (λ) given by Eq. (4) in Problem 5.5 using the
following methods:
(a) Newton method with the starting point 0.6
(b) Quasi-Newton method with the starting point 0.6 and a finite difference step size of
0.001
(c) Secant method with the starting point λ1 = 0.0 and t0 = 0.1
5.12 Prove that a convex function is unimodal.
5.13 Compare the ratios of intervals of uncertainty (Ln/L0) obtainable in the following meth-
ods for n = 2, 3, . . . , 10:
(a) Exhaustive search
(b) Dichotomous search with δ = 10−4
Problems 299
(c) Interval halving method
(d) Fibonacci method
(e) Golden section method
5.14 Find the number of experiments to be conducted in the following methods to obtain a
value of Ln/L0 = 0.001:
(a) Exhaustive search
(b) Dichotomous search with δ = 10−4
(c) Interval halving method
(d) Fibonacci method
(e) Golden section method
5.15 Find the value of x in the interval (0, 1) which minimizes the function f = x(x − 1.5)
to within ±0.05 by (a) the golden section method and (b) the Fibonacci method.
5.16 Find the minimum of the function f = λ5 − 5λ3 − 20λ + 5 by the following methods:
(a) Unrestricted search with a fixed step size of 0.1 starting from λ = 0.0
(b) Unrestricted search with accelerated step size from the initial point 0.0 with a starting
step length of 0.1
(c) Exhaustive search in the interval (0, 5)
(d) Dichotomous search in the interval (0, 5) with δ = 0.0001
(e) Interval halving method in the interval (0, 5)
(f) Fibonacci search in the interval (0, 5)
(g) Golden section method in the interval (0, 5)
5.17 Find the minimum of the function f = (λ/log λ) by the following methods (take the
initial trial step length as 0.1):
(a) Quadratic interpolation method
(b) Cubic interpolation method
5.18 Find the minimum of the function f = λ/log λ using the following methods:
(a) Newton method
(b) Quasi-Newton method
(c) Secant method
5.19 Consider the function
f =
2x21 + 2x22 + 3x23 − 2x1x2 − 2x2x3
x21 + x22 + 2x23
Substitute X = X1 + λS into this function and derive an exact formula for the minimizing
step length λ∗.
5.20 Minimize the function f = x1 − x2 + 2x21 + 2x1x2 + x22 starting from the point X1 =
{
0
0
}
along the direction S =
{−1
0
}
using the quadratic interpolation method with an initial step
length of 0.1.
300 Nonlinear Programming I: One-Dimensional Minimization Methods
5.21 Consider the problem
Minimize f (X) = 100(x2 − x21 )2 + (1 − x1)2
and the starting point, X1 =
{−1
1
}
. Find the minimum of f (X) along the direction, S1 =
{
4
0
}
using quadratic interpolation method. Use a maximum of two refits.
5.22 Solve Problem 5.21 using the cubic interpolation method. Use a maximum of two refits.
5.23 Solve Problem 5.21 using the direct root method. Use a maximum of two refits.
5.24 Solve Problem 5.21 using the Newton method. Use a maximum of two refits.
5.25 Solve Problem 5.21 using the Fibonacci method with L0 = (0, 0.1).
5.26 Write a computer program, in the form of a subroutine, to implement the Fibonacci
method.
5.27 Write a computer program, in the form of a subroutine, to implement the golden section
method.
5.28 Write a computer program, in the form of a subroutine, to implement the quadratic
interpolation method.
5.29 Write a computer program, in the form of a subroutine, to implement the cubic interpo-
lation method.
5.30 Write a computer program, in the form of a subroutine, to implement the secant method.
5.31 Find the maximum of the function given by Eq. (4) in Problem 5.5 using MATLAB.
Assume the bounds on λ as 0 and 3.
5.32 Find the minimum of the function f(λ) given in Problem 5.16, in the range 0 and 5, using
MATLAB.
5.33 Find the minimum of f (x) = x(x − 1.5) in the interval (0, 1) using MATLAB.
5.34 Find the minimum of the function f (x) = x3
16
− 27x
4
in the range (0, 10) using MATLAB.
5.35 Find the minimum of the function f (x) = x3 + x2 −x − 2 in the interval −4 and 4 using
MATLAB.
5.36 Find the minimum of the function f (x) = − 1.5
x
+ 6(10
−6)
x9
in the interval −4 and 4 using
MATLAB.
6
Nonlinear Programming II:
Unconstrained Optimization
Techniques
6.1 INTRODUCTION
This chapter deals with the various methods of solving the unconstrained minimization
problem:
Find X =









x1
x2
...
xn









which minimizes f (X) (6.1)
It is true that rarely a practical design problem would be unconstrained; still, a study
of this class of problems is important for the following reasons:
1. The constraints do not have significant influence in certain design problems.
2. Some of the powerful and robust methods of solving constrained minimization
problems require the use of unconstrained minimization techniques.
3. The study of unconstrained minimization techniques provide the basic under-
standing necessary for the study of constrained minimization methods.
4. The unconstrained minimization methods can be used to solve certain complex
engineering analysis problems. For example, the displacement response (linear
or nonlinear) of any structure under any specified load condition can be found
by minimizing its potential energy. Similarly, the eigenvalues and eigenvectors
of any discrete system can be found by minimizing the Rayleigh quotient.
As discussed in Chapter 2, a point X∗ will be a relative minimum of f (X) if the
necessary conditions
∂f
∂xi
(X = X∗) = 0, i = 1, 2, . . . , n (6.2)
301Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
302 Nonlinear Programming II: Unconstrained Optimization Techniques
are satisfied. The point X∗ is guaranteed to be a relative minimum if the Hessian matrix
is positive definite, that is,
JX∗ = [J ]X∗ =
[
∂2f
∂xi ∂xj
(X∗)
]
= positive definite (6.3)
Equations (6.2) and (6.3) can be used to identify the optimum point during numerical
computations. However, if the function is not differentiable, Eqs. (6.2) and (6.3) cannot
be applied to identify the optimum point. For example, consider the function
f (x) =
{
ax for x ≥ 0
−bx for x ≤ 0
where a > 0 and b > 0. The graph of this function is shown in Fig. 6.1. It can be
seen that this function is not differentiable at the minimum point, x∗ = 0, and hence
Eqs. (6.2) and (6.3) are not applicable in identifying x∗. In all such cases, the commonly
understood notion of a minimum, namely, f (X∗) < f (X) for all X, can be used only
to identify a minimum point. The following example illustrates the formulation of a
typical analysis problem as an unconstrained minimization problem.
Example 6.1 A cantilever beam is subjected to an end force P0 and an end moment
M0 as shown in Fig. 6.2a. By using a one-finite-element model indicated in Fig. 6.2b,
the transverse displacement, w(x), can be expressed as [6.1]
w(x) = {N1(x) N2(x) N3(x) N4(x)}







u1
u2
u3
u4







(E1)
where Ni(x) are called shape functions and are given by
N1(x) = 2α3 − 3α2 + 1 (E2)
N2(x) = (α3 − 2α2 + α)l (E3)
N3(x) = −2α3 + 3α2 (E4)
N4(x) = (α3 − α2)l (E5)
α = x/l, and u1, u2, u3, and u4 are the end displacements (or slopes) of the beam.
The deflection of the beam at point A can be found by minimizing the potential energy
Figure 6.1 Function is not differentiable at mini-
mum point.
6.1 Introduction 303
Figure 6.2 Finite-element model of a cantilever beam.
of the beam (F ), which can be expressed as [6.1]
F =
1
2
∫ 1
0
EI
(
d2w
dx2
)2
dx − P0u3 − M0u4 (E6)
where E is Young’s modulus and I is the area moment of inertia of the beam. Formulate
the optimization problem in terms of the variables x1 = u3 and x2 = u4l for the case
P0l
3/EI = 1 and M0l2/EI = 2.
SOLUTION Since the boundary conditions are given by u1 = u2 = 0, w(x) can be
expressed as
w(x) = (−2α3 + 3α2)u3 + (α3 − α2)lu4 (E7)
so that
d2w
dx2
=
6u3
l2
(−2α + 1) +
2u4
l
(3α − 1) (E8)
304 Nonlinear Programming II: Unconstrained Optimization Techniques
Equation (E6) can be rewritten as
F = 1
2
∫ 1
0
EI
(
d2w
dx2
)2
l dα − P0u3 − M0u4
= EIl
2
∫ 1
0
[
6u3
l2
(−2α + 1) + 2u4
l
(3α − 1)
]2
dα − P0u3 − M0u4
= EI
l3
(6u23 + 2u24l2 − 6u3u4l) − P0u3 − M0u4 (E9)
By using the relations u3 = x1, u4l = x2, P0l3/EI = 1, and M0l2/EI = 2, and intro-
ducing the notation f = F l3/EI , Eq. (E9) can be expressed as
f = 6x21 − 6x1x2 + 2x22 − x1 − 2x2 (E10)
Thus the optimization problem is to determine x1 and x2, which minimize the function
f given by Eq. (E10).
6.1.1 Classification of Unconstrained Minimization Methods
Several methods are available for solving an unconstrained minimization problem.
These methods can be classified into two broad categories as direct search methods
and descent methods as indicated in Table 6.1. The direct search methods require only
the objective function values but not the partial derivatives of the function in finding
the minimum and hence are often called the nongradient methods . The direct search
methods are also known as zeroth-order methods since they use zeroth-order derivatives
of the function. These methods are most suitable for simple problems involving a
relatively small number of variables. These methods are, in general, less efficient than
the descent methods. The descent techniques require, in addition to the function values,
the first and in some cases the second derivatives of the objective function. Since
more information about the function being minimized is used (through the use of
derivatives), descent methods are generally more efficient than direct search techniques.
The descent methods are known as gradient methods . Among the gradient methods,
Table 6.1 Unconstrained Minimization Methods
Direct search methodsa Descent methodsb
Random search method Steepest descent (Cauchy) method
Grid search method Fletcher–Reeves method
Univariate method Newton’s method
Pattern search methods Marquardt method
Powell’s method Quasi-Newton methods
Davidon–Fletcher–Powell method
Broyden–Fletcher–Goldfarb–Shanno method
Simplex method
aDo not require the derivatives of the function.
bRequire the derivatives of the function.
6.1 Introduction 305
those requiring only first derivatives of the function are called first-order methods; those
requiring both first and second derivatives of the function are termed second-order
methods .
6.1.2 General Approach
All the unconstrained minimization methods are iterative in nature and hence they start
from an initial trial solution and proceed toward the minimum point in a sequential
manner as shown in Fig. 5.3. The iterative process is given by
Xi+1 = Xi + λ∗i Si (6.4)
where Xi is the starting point, Si is the search direction, λ
∗
i is the optimal step length,
and Xi+1 is the final point in iteration i. It is important to note that all the unconstrained
minimization methods (1) require an initial point X1 to start the iterative procedure,
and (2) differ from one another only in the method of generating the new point Xi+1
(from Xi) and in testing the point Xi+1 for optimality.
6.1.3 Rate of Convergence
Different iterative optimization methods have different rates of convergence. In general,
an optimization method is said to have convergence of order p if [6.2]
||Xi+1 − X∗||
||Xi − X∗||p
≤ k, k ≥ 0, p ≥ 1 (6.5)
where Xi and Xi+1 denote the points obtained at the end of iterations i and i + 1,
respectively, X∗ represents the optimum point, and ||X|| denotes the length or norm of
the vector X:
||X|| =
√
x21 + x22 + · · · + x2n
If p = 1 and 0 ≤ k ≤ 1, the method is said to be linearly convergent (corresponds
to slow convergence). If p = 2, the method is said to be quadratically convergent
(corresponds to fast convergence). An optimization method is said to have superlinear
convergence (corresponds to fast convergence) if
lim
i→∞
||Xi+1 − X∗||
||Xi − X∗||
→ 0 (6.6)
The definitions of rates of convergence given in Eqs. (6.5) and (6.6) are applica-
ble to single-variable as well as multivariable optimization problems. In the case of
single-variable problems, the vector, Xi , for example, degenerates to a scalar, xi .
6.1.4 Scaling of Design Variables
The rate of convergence of most unconstrained minimization methods can be improved
by scaling the design variables. For a quadratic objective function, the scaling of the
306 Nonlinear Programming II: Unconstrained Optimization Techniques
design variables changes the condition number† of the Hessian matrix. When the con-
dition number of the Hessian matrix is 1, the steepest descent method, for example,
finds the minimum of a quadratic objective function in one iteration.
If f = 1
2
XT[A]X denotes a quadratic term, a transformation of the form
X = [R]Y or
{
x1
x2
}
=
[
r11 r12
r21 r22
]{
y1
y2
}
(6.7)
can be used to obtain a new quadratic term as
1
2
YT[Ã]Y = 1
2
YT[R]T[A][R]Y (6.8)
The matrix [R] can be selected to make [Ã] = [R]T[A][R] diagonal (i.e., to eliminate
the mixed quadratic terms). For this, the columns of the matrix [R] are to be chosen
as the eigenvectors of the matrix [A]. Next the diagonal elements of the matrix [Ã]
can be reduced to 1 (so that the condition number of the resulting matrix will be 1) by
using the transformation
Y = [S]Z or
{
y1
y2
}
=
[
s11 0
0 s22
]{
z1
z2
}
(6.9)
where the matrix [S] is given by
[S] =


s11 = 1√
ã11
0
0 s22 = 1√
ã22

 (6.10)
Thus the complete transformation that reduces the Hessian matrix of f to an identity
matrix is given by
X = [R][S]Z ≡ [T ]Z (6.11)
so that the quadratic term 1
2
XT[A]X reduces to 1
2
ZT[I ]Z.
If the objective function is not a quadratic, the Hessian matrix and hence the
transformations vary with the design vector from iteration to iteration. For example,
†The condition number of an n × n matrix, [A], is defined as
cond([A]) = ||[A]|| ||[A]−1|| ≥ 1
where ||[A]|| denotes a norm of the matrix [A]. For example, the infinite norm of [A] is defined as the
maximum row sum given by
||[A]||∞ = max
1≤i≤n
n
∑
j=1
|aij |
If the condition number is close to 1, the round-off errors are expected to be small in dealing with the
matrix [A]. For example, if cond[A] is large, the solution vector X of the system of equations [A]X = B is
expected to be very sensitive to small variations in [A] and B. If cond[A] is close to 1, the matrix [A] is
said to be well behaved or well conditioned . On the other hand, if cond[A] is significantly greater than 1,
the matrix [A] is said to be not well behaved or ill conditioned .
6.1 Introduction 307
the second-order Taylor’s series approximation of a general nonlinear function at the
design vector Xi can be expressed as
f (X) = c + BTX + 1
2
XT[A]X (6.12)
where
c = f (Xi) (6.13)
B =















∂f
∂x1
∣
∣
∣
∣
Xi
...
∂f
∂xn
∣
∣
∣
∣
Xi















(6.14)
[A] =









∂2f
∂x21
∣
∣
∣
∣
Xi
· · · ∂
2f
∂x1∂xn
∣
∣
∣
∣
Xi
...
...
∂2f
∂xn∂x1
∣
∣
∣
∣
Xi
· · · ∂
2f
∂x2n
∣
∣
∣
∣
Xi









(6.15)
The transformations indicated by Eqs. (6.7) and (6.9) can be applied to the matrix [A]
given by Eq. (6.15). The procedure of scaling the design variables is illustrated with
the following example.
Example 6.2 Find a suitable scaling (or transformation) of variables to reduce the
condition number of the Hessian matrix of the following function to 1:
f (x1, x2) = 6x21 − 6x1x2 + 2x22 − x1 − 2x2 (E1)
SOLUTION The quadratic function can be expressed as
f (X) = BTX + 1
2
XT[A]X (E2)
where
X =
{
x1
x2
}
, B =
{
−1
−2
}
, and [A] =
[
12 −6
− 6 4
]
As indicated above, the desired scaling of variables can be accomplished in two
stages.
Stage 1: Reducing [A] to a Diagonal Form, [Ã]
The eigenvectors of the matrix [A] can be found by solving the eigenvalue problem
[[A] − λi[I ]] ui = 0 (E3)
308 Nonlinear Programming II: Unconstrained Optimization Techniques
where λi is the ith eigenvalue and ui is the corresponding eigenvector. In the present
case, the eigenvalues, λi , are given by
∣
∣
∣
∣
12 − λi − 6
− 6 4 − λi
∣
∣
∣
∣
= λ2i − 16λi + 12 = 0 (E4)
which yield λ1 = 8 +
√
52 = 15.2111 and λ2 = 8 −
√
52 = 0.7889. The eigenvector
ui corresponding to λi can be found by solving Eq. (E3):
[
12 − λ1 − 6
− 6 4 − λ1
]{
u11
u21
}
=
{
0
0
}
or (12 − λ1)u11 − 6u21 = 0
or u21 = −0.5332u11
that is,
u1 =
{
u11
u21
}
=
{
1.0
−0.5332
}
and
[
12 − λ2 − 6
− 6 4 − λ2
]{
u12
u22
}
=
{
0
0
}
or (12 − λ2)u12 − 6u22 = 0
or u22 = 1.8685u12
that is,
u2 =
{
u12
u22
}
=
{
1.0
1.8685
}
Thus the transformation that reduces [A] to a diagonal form is given by
X = [R]Y = [u1 u2]Y =
[
1 1
−0.5352 1.8685
]{
y1
y2
}
(E5)
that is,
x1 = y1 + y2
x2 = −0.5352y1 + 1.8685y2
This yields the new quadratic term as 1
2
YT[Ã]Y, where
[Ã] = [R]T[A][R] =
[
19.5682 0.0
0.0 3.5432
]
and hence the quadratic function becomes
f (y1, y2) = BT[R]Y + 12 Y
T[Ã]Y
= 0.0704y1 − 4.7370y2 + 12 (19.8682)y
2
1 +
1
2
(3.5432)y22 (E6)
6.2 Random Search Methods 309
Stage 2: Reducing [Ã] to a Unit Matrix
The transformation is given by Y = [S]Z, where
[S] =




1
√
19.5682
0
0
1
√
3.5432




=
[
0.2262 0.0
0.0 0.5313
]
Stage 3: Complete Transformation
The total transformation is given by
X = [R]Y = [R][S]Z = [T ]Z (E7)
where
[T ] = [R][S] =
[
1 1
−0.5352 1.8685
][
0.2262 0
0 0.5313
]
=
[
0.2262 0.5313
−0.1211 0.9927
]
(E8)
or
x1 = 0.2262z1 + 0.5313z2
x2 = −0.1211z1 + 0.9927z2
With this transformation, the quadratic function of Eq. (E1) becomes
f (z1, z2) = BT[T ]Z + 12 Z
T[T ]T[A][T ]Z
= 0.0160z1 − 2.5167z2 + 12z
2
1 +
1
2
z22 (E9)
The contours of the quadratic functions given by Eqs. (E1), (E6), and (E9) are shown
in Fig. 6.3a, b, and c, respectively.
Direct Search Methods
6.2 RANDOM SEARCH METHODS
Random search methods are based on the use of random numbers in finding the min-
imum point. Since most of the computer libraries have random number generators,
these methods can be used quite conveniently. Some of the best known random search
methods are presented in this section.
310 Nonlinear Programming II: Unconstrained Optimization Techniques
Figure 6.3 Contours of the original and transformed functions.
6.2 Random Search Methods 311
Figure 6.3 (continued ).
6.2.1 Random Jumping Method
Although the problem is an unconstrained one, we establish the bounds li and ui for
each design variable xi, i = 1, 2, . . . , n, for generating the random values of xi :
li ≤ xi ≤ ui, i = 1, 2, . . . , n (6.16)
In the random jumping method, we generate sets of n random numbers, (r1, r2, . . . , rn),
that are uniformly distributed between 0 and 1. Each set of these numbers is used to
find a point, X, inside the hypercube defined by Eqs. (6.16) as
X =









x1
x2
...
xn









=











l1 + r1(u1 − l1)
l2 + r2(u2 − l2)
...
ln + rn(un − ln)











(6.17)
and the value of the function is evaluated at this point X. By generating a large number
of random points X and evaluating the value of the objective function at each of these
points, we can take the smallest value of f (X) as the desired minimum point.
312 Nonlinear Programming II: Unconstrained Optimization Techniques
6.2.2 Random Walk Method
The random walk method is based on generating a sequence of improved approxima-
tions to the minimum, each derived from the preceding approximation. Thus if Xi is
the approximation to the minimum obtained in the (i − 1)th stage (or step or iteration),
the new or improved approximation in the ith stage is found from the relation
Xi+1 = Xi + λui (6.18)
where λ is a prescribed scalar step length and ui is a unit random vector generated in the
ith stage. The detailed procedure of this method is given by the following steps [6.3]:
1. Start with an initial point X1, a sufficiently large initial step length λ, a minimum
allowable step length ε, and a maximum permissible number of iterations N .
2. Find the function value f1 = f (X1).
3. Set the iteration number as i = 1.
4. Generate a set of n random numbers r1, r2, . . . , rn each lying in the interval
[−1, 1] and formulate the unit vector u as
u =
1
(r21 + r22 + · · · + r2n)1/2









r1
r2
...
rn









(6.19)
The directions generated using Eq. (6.19) are expected to have a bias toward
the diagonals of the unit hypercube [6.3]. To avoid such a bias, the length
of the vector, R, is computed as
R = (r21 + r22 + · · · + r2n)1/2
and the random numbers generated (r1, r2, . . . , rn) are accepted only if R ≤ 1
but are discarded if R > 1. If the random numbers are accepted, the unbiased
random vector ui is given by Eq. (6.19).
5. Compute the new vector and the corresponding function value as X = X1 + λu
and f = f (X).
6. Compare the values of f and f1. If f < f1, set the new values as X1 = X and
f1 = f and go to step 3. If f ≥ f1, go to step 7.
7. If i ≤ N , set the new iteration number as i = i + 1 and go to step 4. On the
other hand, if i >N , go to step 8.
8. Compute the new, reduced, step length as λ = λ/2. If the new step length is
smaller than or equal to ε, go to step 9. Otherwise (i.e., if the new step length
is greater than ε), go to step 4.
9. Stop the procedure by taking Xopt ≈ X1 and fopt ≈ f1.
This method is illustrated with the following example.
Example 6.3 Minimize f (x1, x2) = x1 − x2 + 2x21 + 2x1x2 + x22 using random walk
method from the point X1 =
{
0.0
0.0
}
with a starting step length of λ = 1.0. Take ε = 0.05
and N = 100.
6.2 Random Search Methods 313
Table 6.2 Minimization of f by Random Walk Method
Step Number of Current objective
length, trials Components of X1 + λu function value,
λ requireda 1 2 f1 = f (X1 + λu)
1.0 1 −0.93696 0.34943 −0.06329
1.0 2 −1.15271 1.32588 −1.11986
Next 100 trials did not reduce the function value.
0.5 1 −1.34361 1.78800 −1.12884
0.5 3 −1.07318 1.36744 −1.20232
Next 100 trials did not reduce the function value.
0.25 4 −0.86419 1.23025 −1.21362
0.25 2 −0.86955 1.48019 −1.22074
0.25 8 −1.10661 1.55958 −1.23642
0.25 30 −0.94278 1.37074 −1.24154
0.25 6 −1.08729 1.57474 −1.24222
0.25 50 −0.92606 1.38368 −1.24274
0.25 23 −1.07912 1.58135 −1.24374
Next 100 trials did not reduce the function value.
0.125 1 −0.97986 1.50538 −1.24894
Next 100 trials did not reduce the function value.
0.0625 100 trials did not reduce the function value.
0.03125 As this step length is smaller than ǫ, the program is terminated.
aOut of the directions generated that satisfy R ≤ 1, number of trials required to find a direction that also
reduces the value of f .
SOLUTION The results are summarized in Table 6.2, where only the trials that pro-
duced an improvement are shown.
6.2.3 Random Walk Method with Direction Exploitation
In the random walk method described in Section 6.2.2, we proceed to generate a new
unit random vector ui+1 as soon as we find that ui is successful in reducing the function
value for a fixed step length λ. However, we can expect to achieve a further decrease
in the function value by taking a longer step length along the direction ui . Thus the
random walk method can be improved if the maximum possible step is taken along
each successful direction. This can be achieved by using any of the one-dimensional
minimization methods discussed in Chapter 5. According to this procedure, the new
vector Xi+1 is found as
Xi+1 = Xi + λ∗i ui (6.20)
where λ∗i is the optimal step length found along the direction ui so that
fi+1 = f (Xi + λ∗i ui) = min
λi
f (Xi + λiui) (6.21)
The search method incorporating this feature is called the random walk method with
direction exploitation .
314 Nonlinear Programming II: Unconstrained Optimization Techniques
6.2.4 Advantages of Random Search Methods
1. These methods can work even if the objective function is discontinuous and
nondifferentiable at some of the points.
2. The random methods can be used to find the global minimum when the objective
function possesses several relative minima.
3. These methods are applicable when other methods fail due to local difficulties
such as sharply varying functions and shallow regions.
4. Although the random methods are not very efficient by themselves, they can be
used in the early stages of optimization to detect the region where the global
minimum is likely to be found. Once this region is found, some of the more effi-
cient techniques can be used to find the precise location of the global minimum
point.
6.3 GRID SEARCH METHOD
This method involves setting up a suitable grid in the design space, evaluating the
objective function at all the gird points, and finding the grid point corresponding to
the lowest function value. For example, if the lower and upper bounds on the ith
design variable are known to be li and ui , respectively, we can divide the range (li , ui)
into pi − 1 equal parts so that x(1)i , x
(2)
i , . . . , x
(pi)
i denote the grid points along the xi
axis (i = 1, 2, . . . , n). This leads to a total of p1p2 · · · pn grid points in the design
space. A grid with pi = 4 is shown in a two-dimensional design space in Fig. 6.4. The
grid points can also be chosen based on methods of experimental design [6.4, 6.5].
It can be seen that the grid method requires prohibitively large number of function
evaluations in most practical problems. For example, for a problem with 10 design
Figure 6.4 Grid with pi = 4.
6.4 Univariate Method 315
variables (n = 10), the number of grid points will be 310 = 59,049 with pi = 3 and
410 = 1,048,576 with pi = 4. However, for problems with a small number of design
variables, the grid method can be used conveniently to find an approximate minimum.
Also, the grid method can be used to find a good starting point for one of the more
efficient methods.
6.4 UNIVARIATE METHOD
In this method we change only one variable at a time and seek to produce a sequence
of improved approximations to the minimum point. By starting at a base point Xi in the
ith iteration, we fix the values of n − 1 variables and vary the remaining variable. Since
only one variable is changed, the problem becomes a one-dimensional minimization
problem and any of the methods discussed in Chapter 5 can be used to produce a new
base point Xi+1. The search is now continued in a new direction. This new direction
is obtained by changing any one of the n − 1 variables that were fixed in the previous
iteration. In fact, the search procedure is continued by taking each coordinate direction
in turn. After all the n directions are searched sequentially, the first cycle is complete
and hence we repeat the entire process of sequential minimization. The procedure is
continued until no further improvement is possible in the objective function in any of
the n directions of a cycle. The univariate method can be summarized as follows:
1. Choose an arbitrary staring point X1 and set i = 1.
2. Find the search direction Si as
STi =















(1, 0, 0, . . . , 0) for i = 1, n + 1, 2n + 1, . . .
(1, 0, 0, . . . , 0) for i = 2, n + 2, 2n + 2, . . .
(0, 0, 1, . . . , 0) for i = 3, n + 3, 2n + 3, . . .
...
(0, 0, 0, . . . , 1) for i = n, 2n, 3n, . . .
(6.22)
3. Determine whether λi should be positive or negative. For the current direction
Si , this means find whether the function value decreases in the positive or
negative direction. For this we take a small probe length (ε) and evaluate fi =
f (Xi), f
+ = f (Xi + εSi), and f − = f (Xi − εSi). If f + < fi , Si will be the
correct direction for decreasing the value of f and if f − < fi , −Si will be the
correct one. If both f + and f − are greater than fi , we take Xi as the minimum
along the direction Si .
4. Find the optimal step length λ∗i such that
f (Xi ± λ∗i Si) = min
λi
(Xi ± λiSi) (6.23)
where + or − sign has to be used depending upon whether Si or −Si is the
direction for decreasing the function value.
5. Set Xi+1 = Xi ± λ∗i Si depending on the direction for decreasing the function
value, and fi+1 = f (Xi+1).
6. Set the new value of i = i + 1 and go to step 2. Continue this procedure until
no significant change is achieved in the value of the objective function.
316 Nonlinear Programming II: Unconstrained Optimization Techniques
The univariate method is very simple and can be implemented easily. However,
it will not converge rapidly to the optimum solution, as it has a tendency to oscil-
late with steadily decreasing progress toward the optimum. Hence it will be better to
stop the computations at some point near to the optimum point rather than trying to
find the precise optimum point. In theory, the univariate method can be applied to find
the minimum of any function that possesses continuous derivatives. However, if the
function has a steep valley, the method may not even converge. For example, consider
the contours of a function of two variables with a valley as shown in Fig. 6.5. If the
univariate search starts at point P , the function value cannot be decreased either in
the direction ±S1 or in the direction ±S2. Thus the search comes to a halt and one
may be misled to take the point P , which is certainly not the optimum point, as the
optimum point. This situation arises whenever the value of the probe length ε needed
for detecting the proper direction (±S1 or ±S2) happens to be less than the number of
significant figures used in the computations.
Example 6.4 Minimize f (x1, x2) = x1 − x2 + 2x21 + 2x1x2 + x22 with the starting
point (0, 0).
SOLUTION We will take the probe length (ε) as 0.01 to find the correct direction for
decreasing the function value in step 3. Further, we will use the differential calculus
method to find the optimum step length λ∗i along the direction ±Si in step 4.
Iteration i = 1
Step 2: Choose the search direction S1 as S1 =
{
1
0
}
.
Figure 6.5 Failure of the univariate method on a steep valley.
6.4 Univariate Method 317
Step 3: To find whether the value of f decreases along S1 or −S1, we use the probe
length ε. Since
f1 = f (X1) = f (0, 0) = 0,
f + = f (X1 + εS1) = f (ε, 0) = 0.01 − 0 + 2(0.0001)
+ 0 + 0 = 0.0102 >f1
f − = f (X1 − εS1) = f (−ε, 0) = −0.01 − 0 + 2(0.0001)
+ 0 + 0 = −0.0098 < f1,
−S1 is the correct direction for minimizing f from X1.
Step 4: To find the optimum step length λ∗1, we minimize
f (X1 − λ1S1) = f (−λ1, 0)
= (−λ1) − 0 + 2(−λ1)2 + 0 + 0 = 2λ21 − λ1
As df/dλ1 = 0 at λ1 = 14 , we have λ
∗
1 =
1
4
.
Step 5: Set
X2 = X1 − λ∗1S1 =
{
0
0
}
− 1
4
{
1
0
}
=
{
− 1
4
0
}
f2 = f (X2) = f (− 14 , 0) = −
1
8
.
Iteration i = 2
Step 2: Choose the search direction S2 as S2 =
{
0
1
}
.
Step 3: Since f2 = f (X2) = −0.125,
f + = f (X2 + εS2) = f (−0.25, 0.01) = −0.1399 < f2
f − = f (X2 + εS2) = f (−0.25, −0.01) = −0.1099 >f2
S2 is the correct direction for decreasing the value of f from X2.
Step 4: We minimize f (X2 + λ2S2) to find λ∗2.
Here
f (X2 + λ2S2) = f (−0.25, λ2)
= −0.25 − λ2 + 2(0.25)2 − 2(0.25)(λ2) + λ22
= λ22 − 1.5λ2 − 0.125
df
dλ2
= 2λ2 − 1.5 = 0 at λ∗2 = 0.75
Step 5: Set
X3 = X2 + λ∗2S2 =
{
−0.25
0
}
+ 0.75
{
0
1
}
=
{
−0.25
0.75
}
f3 = f (X3) = −0.6875
318 Nonlinear Programming II: Unconstrained Optimization Techniques
Next we set the iteration number as i = 3, and continue the procedure until the optimum
solution X∗ =
{−1.0
1.5
}
with f (X∗) = −1.25 is found.
Note: If the method is to be computerized, a suitable convergence criterion has to
be used to test the point Xi+1(i = 1, 2, . . .) for optimality.
6.5 PATTERN DIRECTIONS
In the univariate method, we search for the minimum along directions parallel to the
coordinate axes. We noticed that this method may not converge in some cases, and that
even if it converges, its convergence will be very slow as we approach the optimum
point. These problems can be avoided by changing the directions of search in a favorable
manner instead of retaining them always parallel to the coordinate axes. To understand
this idea, consider the contours of the function shown in Fig. 6.6. Let the points
1, 2, 3, . . . indicate the successive points found by the univariate method. It can be
noticed that the lines joining the alternate points of the search (e.g., 1, 3; 2, 4; 3, 5; 4,
6; . . .) lie in the general direction of the minimum and are known as pattern directions .
It can be proved that if the objective function is a quadratic in two variables, all such
lines pass through the minimum. Unfortunately, this property will not be valid for
multivariable functions even when they are quadratics. However, this idea can still
be used to achieve rapid convergence while finding the minimum of an n-variable
function. Methods that use pattern directions as search directions are known as pattern
search methods .
One of the best-known pattern search methods, the Powell’s method, is discussed
in Section 6.6. In general, a pattern search method takes n univariate steps, where n
Figure 6.6 Lines defined by the alternate points lie in the general direction of the minimum.
6.6 Powell’s Method 319
denotes the number of design variables and then searches for the minimum along the
pattern direction Si , defined by
Si = Xi − Xi−n (6.24)
where Xi is the point obtained at the end of n univariate steps and Xi−n is the starting
point before taking the n univariate steps. In general, the directions used prior to taking
a move along a pattern direction need not be univariate directions.
6.6 POWELL’S METHOD
Powell’s method is an extension of the basic pattern search method. It is the most
widely used direct search method and can be proved to be a method of conjugate
directions [6.7]. A conjugate directions method will minimize a quadratic function in
a finite number of steps. Since a general nonlinear function can be approximated rea-
sonably well by a quadratic function near its minimum, a conjugate directions method
is expected to speed up the convergence of even general nonlinear objective functions.
The definition, a method of generation of conjugate directions, and the property of
quadratic convergence are presented in this section.
6.6.1 Conjugate Directions
Definition: Conjugate Directions. Let A = [A] be an n × n symmetric matrix. A set
of n vectors (or directions) {Si} is said to be conjugate (more accurately A-conjugate) if
STi ASj = 0 for all i 
= j, i = 1, 2, . . . , n, j = 1, 2, . . . , n (6.25)
It can be seen that orthogonal directions are a special case of conjugate directions
(obtained with [A] = [I ] in Eq. (6.25)).
Definition: Quadratically Convergent Method. If a minimization method, using
exact arithmetic, can find the minimum point in n steps while minimizing a quadratic
function in n variables, the method is called a quadratically convergent method .
Theorem 6.1 Given a quadratic function of n variables and two parallel hyperplanes
1 and 2 of dimension k < n. Let the constrained stationary points of the quadratic
function in the hyperplanes be X1 and X2, respectively. Then the line joining X1 and
X2 is conjugate to any line parallel to the hyperplanes.
Proof : Let the quadratic function be expressed as
Q(X) = 1
2
XTAX + BTX + C (6.26)
The gradient of Q is given by
∇Q(X) = AX + B
320 Nonlinear Programming II: Unconstrained Optimization Techniques
and hence
∇Q(X1) − ∇Q(X2) = A(X1 − X2) (6.27)
If S is any vector parallel to the hyperplanes, it must be orthogonal to the gradients
∇Q(X1) and ∇Q(X2). Thus
ST∇Q(X1) = STAX1 + STB = 0 (6.28)
ST∇Q(X2) = STAX2 + STB = 0 (6.29)
By subtracting Eq. (6.29) from Eq. (6.28), we obtain
ST A(X1 − X2) = 0 (6.30)
Hence S and (X1 − X2) are A-conjugate.
The meaning of this theorem is illustrated in a two-dimensional space in Fig. 6.7.
If X1 and X2 are the minima of Q obtained by searching along the direction S from two
Figure 6.7 Conjugate directions.
6.6 Powell’s Method 321
different starting points Xa and Xb, respectively, the line (X1 − X2) will be conjugate
to the search direction S.
Theorem 6.2 If a quadratic function
Q(X) = 1
2
XTAX + BTX + C (6.31)
is minimized sequentially, once along each direction of a set of n mutually conjugate
directions, the minimum of the function Q will be found at or before the nth step
irrespective of the starting point.
Proof : Let X∗ minimize the quadratic function Q(X). Then
∇Q(X∗) = B + AX∗ = 0 (6.32)
Given a point X1 and a set of linearly independent directions S1, S2, . . . , Sn, constants
βi can always be found such that
X∗ = X1 +
n
∑
i=1
βiSi (6.33)
where the vectors S1, S2, . . . , Sn have been used as basis vectors. If the directions Si
are A-conjugate and none of them is zero, the Si can easily be shown to be linearly
independent and the βi can be determined as follows.
Equations (6.32) and (6.33) lead to
B + AX1 + A
(
n
∑
i=1
βiSi
)
= 0 (6.34)
Multiplying this equation throughout by STj , we obtain
STj (B + AX1) + STj A
(
n
∑
i=1
βiSi
)
= 0 (6.35)
Equation (6.35) can be rewritten as
(B + AX1)TSj + βj STj ASj = 0 (6.36)
that is,
βj = −
(B + AX1)TSj
STj ASj
(6.37)
Now consider an iterative minimization procedure starting at point X1, and successively
minimizing the quadratic Q(X) in the directions S1, S2, . . . , Sn, where these directions
satisfy Eq. (6.25). The successive points are determined by the relation
Xi+1 = Xi + λ∗i Si, i = 1 to n (6.38)
322 Nonlinear Programming II: Unconstrained Optimization Techniques
where λ∗i is found by minimizing Q(Xi + λiSi) so that†
STi ∇Q(Xi+1) = 0 (6.39)
Since the gradient of Q at the point Xi+1 is given by
∇Q(Xi+1) = B + AXi+1 (6.40)
Eq. (6.39) can be written as
STi {B + A(Xi + λ∗i Si)} = 0 (6.41)
This equation gives
λ∗i = −
(B + AXi)TSi
STi ASi
(6.42)
From Eq. (6.38), we can express Xi as
Xi = X1 +
i−1
∑
j=1
λ∗j Sj (6.43)
so that
XTi ASi = XT1 ASi +
i−1
∑
j=1
λ∗j S
T
j ASi
= XT1 ASi (6.44)
using the relation (6.25). Thus Eq. (6.42) becomes
λ∗i = −(B + AX1)T
Si
STi ASi
(6.45)
which can be seen to be identical to Eq. (6.37). Hence the minimizing step lengths are
given by βi or λ
∗
i . Since the optimal point X
∗ is originally expressed as a sum of n
quantities β1, β2, . . . , βn, which have been shown to be equivalent to the minimizing
step lengths, the minimization process leads to the minimum point in n steps or less.
Since we have not made any assumption regarding X1 and the order of S1, S2, . . . , Sn,
the process converges in n steps or less, independent of the starting point as well as
the order in which the minimization directions are used.
†STi ∇Q(Xi+1) = 0 is equivalent to dQ/dλi = 0 at Y = Xi+1:
dQ
dλi
=
n
∑
j=1
∂Q
∂yj
∂yj
∂λi
where yj are the components of Y = Xi+1.
6.6 Powell’s Method 323
Example 6.5 Consider the minimization of the function
f (x1, x2) = 6x21 + 2x22 − 6x1x2 − x1 − 2x2
If S1 =
{
1
2
}
denotes a search direction, find a direction S2 that is conjugate to the
direction S1.
SOLUTION The objective function can be expressed in matrix form as
f (X) = BT X + 1
2
XT[A]X
= {−1 −2}
{
x1
x2
}
+ 1
2
{x1 x2}
[
12 −6
−6 4
]{
x1
x2
}
and the Hessian matrix [A] can be identified as
[A] =
[
12 −6
−6 4
]
The direction S2 =
{
s1
s2
}
will be conjugate to S1 =
{
1
2
}
if
ST1 [A]S2 = (1 2)
[
12 −6
−6 4
]{
s1
s2
}
= 0
which upon expansion gives 2s2 = 0 or s1 = arbitrary and s2 = 0. Since s1 can have
any value, we select s1 = 1 and the desired conjugate direction can be expressed as
S2 =
{
1
0
}
.
6.6.2 Algorithm
The basic idea of Powell’s method is illustrated graphically for a two-variable func-
tion in Fig. 6.8. In this figure the function is first minimized once along each of the
coordinate directions starting with the second coordinate direction and then in the cor-
responding pattern direction. This leads to point 5. For the next cycle of minimization,
we discard one of the coordinate directions (the x1 direction in the present case) in
favor of the pattern direction. Thus we minimize along u2 and S1 and obtain point 7.
Then we generate a new pattern direction S2 as shown in the figure. For the next
cycle of minimization, we discard one of the previously used coordinate directions
(the x2 direction in this case) in favor of the newly generated pattern direction. Then,
by starting from point 8, we minimize along directions S1 and S2, thereby obtaining
points 9 and 10, respectively. For the next cycle of minimization, since there is no
coordinate direction to discard, we restart the whole procedure by minimizing along
the x2 direction. This procedure is continued until the desired minimum point is found.
The flow diagram for the version of Powell’s method described above is given
in Fig. 6.9. Note that the search will be made sequentially in the directions Sn;
S1, S2, S3, . . . , Sn−1, Sn; S
(1)
p ; S2, S3, . . . , Sn−1, Sn, S
(1)
p ; S
(2)
p ; S3, S4, . . . , Sn−1, Sn,
S
(1)
p , S
(2)
p ; S
(3)
p , . . . until the minimum point is found. Here Si indicates the coordi-
nate direction ui and S
(j)
p the j th pattern direction. In Fig. 6.9, the previous base point
324 Nonlinear Programming II: Unconstrained Optimization Techniques
Figure 6.8 Progress of Powell’s method.
is stored as the vector Z in block A, and the pattern direction is constructed by sub-
tracting the previous base point from the current one in block B. The pattern direction
is then used as a minimization direction in blocks C and D. For the next cycle, the
first direction used in the previous cycle is discarded in favor of the current pattern
direction. This is achieved by updating the numbers of the search directions as shown
in block E. Thus both points Z and X used in block B for the construction of pattern
6.6 Powell’s Method 325
l
l l
l
l
l
l
ll
Figure 6.9 Flowchart for Powell’s Method.
direction are points that are minima along Sn in the first cycle, the first pattern direction
S
(1)
p in the second cycle, the second pattern direction S
(2)
p in the third cycle, and so on.
Quadratic Convergence. It can be seen from Fig. 6.9 that the pattern direc-
tions S
(1)
p , S
(2)
p , S
(3)
p , . . . are nothing but the lines joining the minima found along
the directions Sn, S
(1)
p , S
(2)
p , . . ., respectively. Hence by Theorem 6.1, the pairs of
directions (Sn, S
(1)
p ), (S
(1)
p , S
(2)
p ), and so on, are A-conjugate. Thus all the directions
326 Nonlinear Programming II: Unconstrained Optimization Techniques
Sn, S
(1)
p , S
(2)
p , . . . are A-conjugate. Since, by Theorem 6.2, any search method involv-
ing minimization along a set of conjugate directions is quadratically convergent,
Powell’s method is quadratically convergent. From the method used for construct-
ing the conjugate directions S
(1)
p , S
(2)
p , . . ., we find that n minimization cycles are
required to complete the construction of n conjugate directions. In the ith cycle,
the minimization is done along the already constructed i conjugate directions and
the n − i nonconjugate (coordinate) directions. Thus after n cycles, all the n search
directions are mutually conjugate and a quadratic will theoretically be minimized in
n2 one-dimensional minimizations. This proves the quadratic convergence of Powell’s
method.
It is to be noted that as with most of the numerical techniques, the convergence in
many practical problems may not be as good as the theory seems to indicate. Powell’s
method may require a lot more iterations to minimize a function than the theoretically
estimated number. There are several reasons for this:
1. Since the number of cycles n is valid only for quadratic functions, it will take
generally greater than n cycles for nonquadratic functions.
2. The proof of quadratic convergence has been established with the assumption
that the exact minimum is found in each of the one-dimensional minimizations.
However, the actual minimizing step lengths λ∗i will be only approximate, and
hence the subsequent directions will not be conjugate. Thus the method requires
more number of iterations for achieving the overall convergence.
3. Powell’s method, described above, can break down before the minimum point
is found. This is because the search directions Si might become dependent or
almost dependent during numerical computation.
Convergence Criterion. The convergence criterion one would generally adopt in a
method such as Powell’s method is to stop the procedure whenever a minimization
cycle produces a change in all variables less than one-tenth of the required accuracy.
However, a more elaborate convergence criterion, which is more likely to prevent
premature termination of the process, was given by Powell [6.7].
Example 6.6 Minimize f (x1, x2) = x1 − x2 + 2x21 + 2x1x2 + x22 from the starting
point X1 =
{
0
0
}
using Powell’s method.
SOLUTION
Cycle 1: Univariate Search
We minimize f along S2 = Sn =
{
0
1
}
from X1. To find the correct direction (+S2
or −S2) for decreasing the value of f , we take the probe length as ε = 0.01. As
f1 = f (X1) = 0.0, and
f + = f (X1 + εS2) = f (0.0, 0.01) = −0.0099 < f1
f decreases along the direction +S2. To find the minimizing step length λ∗ along S2,
we minimize
f (X1 + λS2) = f (0.0, λ) = λ2 − λ
6.6 Powell’s Method 327
As df/dλ = 0 at λ∗ = 1
2
, we have X2 = X1 + λ∗S2 =
{
0
0.5
}
.
Next we minimize f along S1 =
{
1
0
}
from X2 =
{
0.5
0.0
}
. Since
f2 = f (X2) = f (0.0, 0.5) = −0.25
f + = f (X2 + εS1) = f (0.01, 0.50) = −0.2298 >f2
f − = f (X2 − εS1) = f (−0.01, 0.50) = −0.2698
f decreases along −S1. As f (X2 − λS1) = f (−λ, 0.50) = 2λ2 − 2λ − 0.25, df/dλ =
0 at λ∗ = 1
2
. Hence X3 = X2 − λ∗S1 =
{−0.5
0.5
}
.
Now we minimize f along S2 =
{
0
1
}
from X3 =
{−0.5
0.5
}
. As f3 = f (X3) = −0.75,
f + = f (X3 + εS2) = f (−0.5, 0.51) = −0.7599 < f3, f decreases along +S2 direc-
tion. Since
f (X3 + λS2) = f (−0.5, 0.5 + λ) = λ2 − λ − 0.75,
df
dλ
= 0 at λ∗ = 1
2
This gives
X4 = X3 + λ∗S2 =
{
−0.5
1.0
}
Cycle 2: Pattern Search
Now we generate the first pattern direction as
S(1)p = X4 − X2 =
{
− 1
2
1
}
−
{
0
1
2
}
=
{
−0.5
0.5
}
and minimize f along S
(1)
p from X4. Since
f4 = f (X4) = −1.0
f + = f (X4 + εS(1)p ) = f (−0.5 − 0.005, 1 + 0.005)
= f (−0.505, 1.005) = −1.004975
f decreases in the positive direction of S
(1)
p . As
f (X4 + λS(1)p ) = f (−0.5 − 0.5λ, 1.0 + 0.5λ)
= 0.25λ2 − 0.50λ − 1.00,
df
dλ
= 0 at λ∗ = 1.0 and hence
X5 = X4 + λ∗S(1)p =
{
− 1
2
1
}
+ 1.0
{
− 1
2
1
2
}
=
{
−1.0
1.5
}
The point X5 can be identified to be the optimum point.
328 Nonlinear Programming II: Unconstrained Optimization Techniques
If we do not recognize X5 as the optimum point at this stage, we proceed to
minimize f along the direction S2 =
{
0
1
}
from X5. Then we would obtain
f5 = f (X5) = −1.25, f + = f (X5 + εS2) >f5,
and f − = f (X5 − εS2)> f5
This shows that f cannot be minimized along S2, and hence X5 will be the optimum
point. In this example the convergence has been achieved in the second cycle itself.
This is to be expected in this case, as f is a quadratic function, and the method is a
quadratically convergent method.
6.7 SIMPLEX METHOD
Definition: Simplex. The geometric figure formed by a set of n + 1 points in an
n-dimensional space is called a simplex . When the points are equidistant, the simplex
is said to be regular . Thus in two dimensions, the simplex is a triangle, and in three
dimensions, it is a tetrahedron.
The basic idea in the simplex method† is to compare the values of the objective
function at the n + 1 vertices of a general simplex and move the simplex gradu-
ally toward the optimum point during the iterative process. The following equations
can be used to generate the vertices of a regular simplex (equilateral triangle in
two-dimensional space) of size a in the n-dimensional space [6.10]:
Xi = X0 + pui +
n
∑
j=1,j 
=i
quj , i = 1, 2, . . . , n (6.46)
where
p =
a
n
√
2
(
√
n + 1 + n − 1) and q =
a
n
√
2
(
√
n + 1 − 1) (6.47)
where X0 is the initial base point and uj is the unit vector along the j th coordinate axis.
This method was originally given by Spendley, Hext, and Himsworth [6.10] and was
developed later by Nelder and Mead [6.11]. The movement of the simplex is achieved
by using three operations, known as reflection, contraction, and expansion.
6.7.1 Reflection
If Xh is the vertex corresponding to the highest value of the objective function among
the vertices of a simplex, we can expect the point Xr obtained by reflecting the point
Xh in the opposite face to have the smallest value. If this is the case, we can construct
a new simplex by rejecting the point Xh from the simplex and including the new point
Xr . This process is illustrated in Fig. 6.10. In Fig. 6.10a, the points X1, X2, and X3
form the original simplex, and the points X1, X2, and Xr form the new one. Similarly,
in Fig. 6.10b, the original simplex is given by points X1, X2, X3, and X4, and the new
one by X1, X2, X3, and Xr . Again we can construct a new simplex from the present one
†This simplex method should not be confused with the simplex method of linear programming.
6.7 Simplex Method 329
Figure 6.10 Reflection.
by rejecting the vertex corresponding to the highest function value. Since the direction
of movement of the simplex is always away from the worst result, we will be moving
in a favorable direction. If the objective function does not have steep valleys, repetitive
application of the reflection process leads to a zigzag path in the general direction of
the minimum as shown in Fig. 6.11. Mathematically, the reflected point Xr is given
by
Xr = (1 + α)X0 − αXh (6.48)
where Xh is the vertex corresponding to the maximum function value:
f (Xh) = max
i=1 to n+1
f (Xi), (6.49)
Figure 6.11 Progress of the reflection process.
330 Nonlinear Programming II: Unconstrained Optimization Techniques
X0 is the centroid of all the points Xi except i = h:
X0 =
1
n
n+1
∑
i = 1
i 
= h
Xi (6.50)
and α > 0 is the reflection coefficient defined as
α =
distance between Xr and X0
distance between Xh and X0
(6.51)
Thus Xr will lie on the line joining Xh and X0, on the far side of X0 from Xh with
|Xr − X0| = α|Xh − X0|. If f (Xr) lies between f (Xh) and f (Xl), where Xl is the
vertex corresponding to the minimum function value,
f (Xl) = min
i=1 to n+1
f (Xi) (6.52)
Xh is replaced by Xr and a new simplex is started.
If we use only the reflection process for finding the minimum, we may encounter
certain difficulties in some cases. For example, if one of the simplexes (triangles in
two dimensions) straddles a valley as shown in Fig. 6.12 and if the reflected point Xr
happens to have an objective function value equal to that of the point Xh, we will
enter into a closed cycle of operations. Thus if X2 is the worst point in the simplex
defined by the vertices X1, X2, and X3, the reflection process gives the new simplex
with vertices X1, X3, and Xr . Again, since Xr has the highest function value out of
the vertices X1, X3, and Xr , we obtain the old simplex itself by using the reflection
process. Thus the optimization process is stranded over the valley and there is no way
of moving toward the optimum point. This trouble can be overcome by making a rule
that no return can be made to points that have just been left.
Figure 6.12 Reflection process not leading to a new simplex.
6.7 Simplex Method 331
Whenever such situation is encountered, we reject the vertex corresponding to the
second worst value instead of the vertex corresponding to the worst function value.
This method, in general, leads the process to continue toward the region of the desired
minimum. However, the final simplex may again straddle the minimum, or it may lie
within a distance of the order of its own size from the minimum. In such cases it may
not be possible to obtain a new simplex with vertices closer to the minimum compared
to those of the previous simplex, and the pattern may lead to a cyclic process, as shown
in Fig. 6.13. In this example the successive simplexes formed from the simplex 123
are 234, 245, 456, 467, 478, 348, 234, 245, . . ., † which can be seen to be forming
a cyclic process. Whenever this type of cycling is observed, one can take the vertex
that is occurring in every simplex (point 4 in Fig. 6.13) as the best approximation to
the optimum point. If more accuracy is desired, the simplex has to be contracted or
reduced in size, as indicated later.
6.7.2 Expansion
If a reflection process gives a point Xr for which f (Xr) < f (Xl), (i.e., if the reflection
produces a new minimum), one can generally expect to decrease the function value
further by moving along the direction pointing from X0 to Xr . Hence we expand Xr
Figure 6.13 Reflection process leading to a cyclic process.
†Simplexes 456, 467, and 234 are formed by reflecting the second-worst point to avoid the difficulty
mentioned earlier.
332 Nonlinear Programming II: Unconstrained Optimization Techniques
to Xe using the relation
Xe = γ Xr + (1 − γ )X0 (6.53)
where γ is called the expansion coefficient , defined as
γ =
distance between Xe and X0
distance between Xr and X0
> 1
If f (Xe) < f (Xl), we replace the point Xh by Xe and restart the process of reflec-
tion. On the other hand, if f (Xe) >f (Xl), it means that the expansion process is not
successful and hence we replace point Xh by Xr and start the reflection process again.
6.7.3 Contraction
If the reflection process gives a point Xr for which f (Xr) >f (Xi) for all i except
i = h, and f (Xr) < f (Xh), we replace point Xh by Xr . Thus the new Xh will be Xr .
In this case we contract the simplex as follows:
Xc = βXh + (1 − β)X0 (6.54)
where β is called the contraction coefficient (0 ≤ β ≤ 1) and is defined as
β = distance between Xe and X0
distance between Xh and X0
If f (Xr) >f (Xh), we still use Eq. (6.54) without changing the previous point Xh. If
the contraction process produces a point Xc for which f (Xc) < min[f (Xh), f (Xr)], we
replace the point Xh in X1, X2, . . . , Xn+1 by Xc and proceed with the reflection process
again. On the other hand, if f (Xc) ≥ min[f (Xh), f (Xr)], the contraction process will
be a failure, and in this case we replace all Xi by (Xi + Xl)/2 and restart the reflection
process.
The method is assumed to have converged whenever the standard deviation of the
function at the n + 1 vertices of the current simplex is smaller than some prescribed
small quantity ε, that is,
Q =
{
n+1
∑
i=1
[f (Xi) − f (X0)]2
n + 1
}1/2
≤ ε (6.55)
Example 6.7 Minimize f (x1, x2) = x1 − x2 + 2x21 + 2x1x2 + x22 . Take the points
defining the initial simplex as
X1 =
{
4.0
4.0
}
, X2 =
{
5.0
4.0
}
, and X3 =
{
4.0
5.0
}
and α = 1.0, β = 0.5, and γ = 2.0. For convergence, take the value of ε as 0.2.
6.7 Simplex Method 333
SOLUTION
Iteration 1
Step 1: The function value at each of the vertices of the current simplex is given by
f1 = f (X1) = 4.0 − 4.0 + 2(16.0) + 2(16.0) + 16.0 = 80.0
f2 = f (X2) = 5.0 − 4.0 + 2(25.0) + 2(20.0) + 16.0 = 107.0
f3 = f (X3) = 4.0 − 5.0 + 2(16.0) + 2(20.0) + 25.0 = 96.0
Therefore,
Xh = X2 =
{
5.0
4.0
}
, f (Xh) = 107.0,
Xl = X1 =
{
4.0
4.0
}
, and f (Xl) = 80.0
Step 2: The centroid X0 is obtained as
X0 =
1
2
(X1 + X3) =
1
2
{
4.0 + 4.0
4.0 + 5.0
}
=
{
4.0
4.5
}
with f (X0) = 87.75
Step 3: The reflection point is found as
Xr = 2X0 − Xh =
{
8.0
9.0
}
−
{
5.0
4.0
}
=
{
3.0
5.0
}
Then
f (Xr) = 3.0 − 5.0 + 2(9.0) + 2(15.0) + 25.0 = 71.0
Step 4: As f (Xr) < f (Xl), we find Xe by expansion as
Xe = 2Xr − X0 =
{
6.0
10.0
}
−
{
4.0
4.5
}
=
{
2.0
5.5
}
Then
f (Xe) = 2.0 − 5.5 + 2(4.0) + 2(11.0) + 30.25 = 56.75
Step 5: Since f (Xe) < f (Xl), we replace Xh by Xe and obtain the vertices of the new
simplex as
X1 =
{
4.0
4.0
}
, X2 =
{
2.0
5.5
}
, and X3 =
{
4.0
5.0
}
Step 6: To test for convergence, we compute
Q =
[
(80.0 − 87.75)2 + (56.75 − 87.75)2 + (96.0 − 87.75)2
3
]1/2
= 19.06
As this quantity is not smaller than ε, we go to the next iteration.
334 Nonlinear Programming II: Unconstrained Optimization Techniques
Iteration 2
Step 1: As f (X1) = 80.0, f (X2) = 56.75, and f (X3) = 96.0,
Xh = X3 =
{
4.0
5.0
}
and Xl = X2 =
{
2.0
5.5
}
Step 2: The centroid is
X0 =
1
2
(X1 + X2) =
1
2
{
4.0 + 2.0
4.0 + 5.5
}
=
{
3.0
4.75
}
f (X0) = 67.31
Step 3:
Xr = 2X0 − Xh =
{
6.0
9.5
}
−
{
4.0
5.0
}
=
{
2.0
4.5
}
f (Xr) = 2.0 − 4.5 + 2(4.0) + 2(9.0) + 20.25 = 43.75
Step 4: As f (Xr) < f (Xl), we find Xe as
Xe = 2Xr − X0 =
{
4.0
9.0
}
−
{
3.0
4.75
}
=
{
1.0
4.25
}
f (Xe) = 1.0 − 4.25 + 2(1.0) + 2(4.25) + 18.0625 = 25.3125
Step 5: As f (Xe) < f (Xl), we replace Xh by Xe and obtain the new vertices as
X1 =
{
4.0
4.0
}
, X2 =
{
2.0
5.5
}
, and X3 =
{
1.0
4.25
}
Step 6: For convergence, we compute Q as
Q =
[
(80.0 − 67.31)2 + (56.75 − 67.31)2 + (25.3125 − 67.31)2
3
]1/2
= 26.1
Since Q>ε, we go to the next iteration.
This procedure can be continued until the specified convergence is satisfied. When
the convergence is satisfied, the centroid X0 of the latest simplex can be taken as the
optimum point.
6.8 Gradient of a Function 335
Indirect Search (Descent) Methods
6.8 GRADIENT OF A FUNCTION
The gradient of a function is an n-component vector given by
∇f
n×1
=











∂f/∂x1
∂f/∂x2
...
∂f/∂xn











(6.56)
The gradient has a very important property. If we move along the gradient direction
from any point in n-dimensional space, the function value increases at the fastest rate.
Hence the gradient direction is called the direction of steepest ascent . Unfortunately, the
direction of steepest ascent is a local property and not a global one. This is illustrated
in Fig. 6.14, where the gradient vectors ∇f evaluated at points 1, 2, 3, and 4 lie along
the directions 11′, 22′, 33′, and 44′, respectively. Thus the function value increases at
the fastest rate in the direction 11′ at point 1, but not at point 2. Similarly, the function
value increases at the fastest rate in direction 22′(33′) at point 2 (3), but not at point
3 (4). In other words, the direction of steepest ascent generally varies from point to
point, and if we make infinitely small moves along the direction of steepest ascent, the
path will be a curved line like the curve 1–2–3–4 in Fig. 6.14.
Figure 6.14 Steepest ascent directions.
336 Nonlinear Programming II: Unconstrained Optimization Techniques
Since the gradient vector represents the direction of steepest ascent, the negative
of the gradient vector denotes the direction of steepest descent. Thus any method that
makes use of the gradient vector can be expected to give the minimum point faster
than one that does not make use of the gradient vector. All the descent methods make
use of the gradient vector, either directly or indirectly, in finding the search directions.
Before considering the descent methods of minimization, we prove that the gradient
vector represents the direction of steepest ascent.
Theorem 6.3 The gradient vector represents the direction of steepest ascent.
Proof : Consider an arbitary point X in the n-dimensional space. Let f denote the value
of the objective function at the point X. Consider a neighboring point X + dX with
dX =









dx1
dx2
...
dxn









(6.57)
where dx1, dx2, . . . , dxn represent the components of the vector dX. The magnitude
of the vector dX, ds, is given by
dXT dX = (ds)2 =
n
∑
i=1
(dxi)
2 (6.58)
If f + df denotes the value of the objective function at X + dX, the change in f , df ,
associated with dX can be expressed as
df =
n
∑
i=1
∂f
∂xi
dxi = ∇f T dX (6.59)
If u denotes the unit vector along the direction dX and ds the length of dX, we can
write
dX = u ds (6.60)
The rate of change of the function with respect to the step length ds is given by
Eq. (6.59) as
df
ds
=
n
∑
i=1
∂f
∂xi
dxi
ds
= ∇f T dX
ds
= ∇f T u (6.61)
The value of df/ds will be different for different directions and we are interested in
finding the particular step dX along which the value of df/ds will be maximum. This
will give the direction of steepest ascent.† By using the definition of the dot product,
†In general, if df/ds = ∇f T u > 0 along a vector dX, it is called a direction of ascent , and if df/ds < 0,
it is called a direction of descent .
6.8 Gradient of a Function 337
Eq. (6.61) can be rewritten as
df
ds
= ||∇f || ||u|| cos θ (6.62)
where ||∇f || and ||u|| denote the lengths of the vectors ∇f and u, respectively, and θ
indicates the angle between the vectors ∇f and u. It can be seen that df/ds will be
maximum when θ = 0◦ and minimum when θ = 180◦. This indicates that the function
value increases at a maximum rate in the direction of the gradient (i.e., when u is
along ∇f ).
Theorem 6.4 The maximum rate of change of f at any point X is equal to the mag-
nitude of the gradient vector at the same point.
Proof : The rate of change of the function f with respect to the step length s along a
direction u is given by Eq. (6.62). Since df/ds is maximum when θ = 0◦ and u is a
unit vector, Eq. (6.62) gives
(
df
ds
)∣
∣
∣
∣
max
= ||∇f ||
which proves the theorem.
6.8.1 Evaluation of the Gradient
The evaluation of the gradient requires the computation of the partial derivatives ∂f/∂xi ,
i = 1, 2, . . . , n. There are three situations where the evaluation of the gradient poses
certain problems:
1. The function is differentiable at all the points, but the calculation of the com-
ponents of the gradient, ∂f/∂xi , is either impractical or impossible.
2. The expressions for the partial derivatives ∂f/∂xi can be derived, but they
require large computational time for evaluation.
3. The gradient ∇f is not defined at all the points.
In the first case, we can use the forward finite-difference formula
∂f
∂xi
∣
∣
∣
∣
Xm
≃ f (Xm + 
xiui) − f (Xm)

xi
, i = 1, 2, . . . , n (6.63)
to approximate the partial derivative ∂f/∂xi at Xm. If the function value at the base
point Xm is known, this formula requires one additional function evaluation to find
(∂f/∂xi)|Xm. Thus it requires n additional function evaluations to evaluate the approxi-
mate gradient ∇f |Xm. For better results we can use the central finite difference formula
to find the approximate partial derivative ∂f/∂xi |Xm:
∂f
∂xi
∣
∣
∣
∣
Xm
≃ f (Xm + 
xtui) − f (Xm − 
xiui)
2
xi
, i = 1, 2, . . . , n (6.64)
338 Nonlinear Programming II: Unconstrained Optimization Techniques
This formula requires two additional function evaluations for each of the partial deriva-
tives. In Eqs. (6.63) and (6.64), 
xi is a small scalar quantity and ui is a vector of order
n whose ith component has a value of 1, and all other components have a value of zero.
In practical computations, the value of 
xi has to be chosen with some care. If 
xi is
too small, the difference between the values of the function evaluated at (Xm + 
xiui)
and (Xm − 
xiui) may be very small and numerical round-off error may predominate.
On the other hand, if 
xi is too large, the truncation error may predominate in the
calculation of the gradient.
In the second case also, the use of finite-difference formulas is preferred whenever
the exact gradient evaluation requires more computational time than the one involved
in using Eq. (6.63) or (6.64).
In the third case, we cannot use the finite-difference formulas since the gradient
is not defined at all the points. For example, consider the function shown in Fig. 6.15.
If Eq. (6.64) is used to evaluate the derivative df/ds at Xm, we obtain a value of
α1 for a step size 
x1 and a value of α2 for a step size 
x2. Since, in reality, the
derivative does not exist at the point Xm, use of finite-difference formulas might lead
to a complete breakdown of the minimization process. In such cases the minimization
can be done only by one of the direct search techniques discussed earlier.
6.8.2 Rate of Change of a Function along a Direction
In most optimization techniques, we are interested in finding the rate of change of a
function with respect to a parameter λ along a specified direction, Si , away from a
point Xi . Any point in the specified direction away from the given point Xi can be
expressed as X = Xi + λSi . Our interest is to find the rate of change of the function
along the direction Si (characterized by the parameter λ), that is,
df
dλ
=
n
∑
j=1
∂f
∂xj
∂xj
∂λ
(6.65)
a2
a1
Figure 6.15 Gradient not defined at xm.
6.9 Steepest Descent (Cauchy) Method 339
where xj is the j th component of X. But
∂xj
∂λ
=
∂
∂λ
(xij + λsij ) = sij (6.66)
where xij and sij are the j th components of Xi and Si , respectively. Hence
df
dλ
=
n
∑
j=1
∂f
∂xj
sij = ∇f TSi (6.67)
If λ∗ minimizes f in the direction Si , we have
df
dλ
∣
∣
∣
∣
λ=λ∗
= ∇f |Tλ∗Si = 0 (6.68)
at the point Xi + λ∗Si .
6.9 STEEPEST DESCENT (CAUCHY) METHOD
The use of the negative of the gradient vector as a direction for minimization was
first made by Cauchy in 1847 [6.12]. In this method we start from an initial trial
point X1 and iteratively move along the steepest descent directions until the optimum
point is found. The steepest descent method can be summarized by the following
steps:
1. Start with an arbitrary initial point X1. Set the iteration number as i = 1.
2. Find the search direction Si as
Si = −∇fi = −∇f (Xi) (6.69)
3. Determine the optimal step length λ∗i in the direction Si and set
Xi+1 = Xi + λ∗i Si = Xi − λ∗i ∇fi (6.70)
4. Test the new point, Xi+1, for optimality. If Xi+1 is optimum, stop the process.
Otherwise, go to step 5.
5. Set the new iteration number i = i + 1 and go to step 2.
The method of steepest descent may appear to be the best unconstrained minimization
technique since each one-dimensional search starts in the “best” direction. However,
owing to the fact that the steepest descent direction is a local property, the method is
not really effective in most problems.
Example 6.8 Minimize f (x1, x2) = x1 − x2 + 2x21 + 2x1x2 + x22 starting from the
point X1 =
{
0
0
}
.
340 Nonlinear Programming II: Unconstrained Optimization Techniques
SOLUTION
Iteration 1
The gradient of f is given by
∇f =
{
∂f/∂x1
∂f/∂x2
}
=
{
1 + 4x1 + 2x2
−1 + 2x1 + 2x2
}
∇f1 = ∇f (X1) =
{
1
−1
}
Therefore,
S1 = −∇f1 =
{
−1
1
}
To find X2, we need to find the optimal step length λ
∗
1. For this, we minimize f (X1 +
λ1S1) = f (−λ1, λ1) = λ21 − 2λ1 with respect to λ1. Since df/dλ1 = 0 at λ∗1 = 1, we
obtain
X2 = X1 + λ∗1S1 =
{
0
0
}
+ 1
{
−1
1
}
=
{
−1
1
}
As ∇f2 = ∇f (X2) =
{
−1
−1
}

=
{
0
0
}
, X2 is not optimum.
Iteration 2
S2 = −∇f2 =
{
1
1
}
To minimize
f (X2 + λ2S2) = f (−1 + λ2, 1 + λ2)
= 5λ22 − 2λ2 − 1
we set df/dλ2 = 0. This gives λ∗2 =
1
5
, and hence
X3 = X2 + λ∗2S2 =
{
−1
1
}
+
1
5
{
1
1
}
=
{
−0.8
1.2
}
Since the components of the gradient at X3,∇f3 =
{
0.2
−0.2
}
, are not zero, we proceed
to the next iteration.
Iteration 3
S3 = −∇f3 =
{
−0.2
0.2
}
6.10 Conjugate Gradient (Fletcher–Reeves) Method 341
As
f (X3 + λ3S3) = f (−0.8 − 0.2λ3, 1.2 + 0.2λ3)
= 0.04λ23 − 0.08λ3 − 1.20,
df
dλ3
= 0 at λ∗3 = 1.0
Therefore,
X4 = X3 + λ∗3S3 =
{
−0.8
1.2
}
+ 1.0
{
−0.2
0.2
}
=
{
−1.0
1.4
}
The gradient at X4 is given by
∇f4 =
{
−0.20
−0.20
}
Since ∇f4 
=
{
0
0
}
, X4 is not optimum and hence we have to proceed to the next iteration.
This process has to be continued until the optimum point, X∗ =
{−1.0
1.5
}
, is found.
Convergence Criteria: The following criteria can be used to terminate the iterative
process.
1. When the change in function value in two consecutive iterations is small:
∣
∣
∣
∣
f (Xi+1) − f (Xi)
f (Xi)
∣
∣
∣
∣
≤ ε1 (6.71)
2. When the partial derivatives (components of the gradient) of f are small:
∣
∣
∣
∣
∂f
∂xi
∣
∣
∣
∣
≤ ε2, i = 1, 2, . . . , n (6.72)
3. When the change in the design vector in two consecutive iterations is small:
|Xi+1 − Xi | ≤ ε3 (6.73)
6.10 CONJUGATE GRADIENT (FLETCHER–REEVES) METHOD
The convergence characteristics of the steepest descent method can be improved greatly
by modifying it into a conjugate gradient method (which can be considered as a con-
jugate directions method involving the use of the gradient of the function). We saw
(in Section 6.6.) that any minimization method that makes use of the conjugate direc-
tions is quadratically convergent. This property of quadratic convergence is very useful
because it ensures that the method will minimize a quadratic function in n steps or
less. Since any general function can be approximated reasonably well by a quadratic
near the optimum point, any quadratically convergent method is expected to find the
optimum point in a finite number of iterations.
342 Nonlinear Programming II: Unconstrained Optimization Techniques
We have seen that Powell’s conjugate direction method requires n single-variable
minimizations per iteration and sets up a new conjugate direction at the end of each
iteration. Thus it requires, in general, n2 single-variable minimizations to find the mini-
mum of a quadratic function. On the other hand, if we can evaluate the gradients of the
objective function, we can set up a new conjugate direction after every one-dimensional
minimization, and hence we can achieve faster convergence. The construction of con-
jugate directions and development of the Fletcher–Reeves method are discussed in this
section.
6.10.1 Development of the Fletcher–Reeves Method
The Fletcher–Reeves method is developed by modifying the steepest descent method
to make it quadratically convergent. Starting from an arbitrary point X1, the quadratic
function
f (X) = 1
2
XT[A]X + BTX + C (6.74)
can be minimized by searching along the search direction S1 = −∇f1 (steepest descent
direction) using the step length (see Problem 6.40):
λ∗1 = −
ST1
ST1
∇f1
AS1
(6.75)
The second search direction S2 is found as a linear combination of S1 and −∇f2:
S2 = −∇f2 + β2S1 (6.76)
where the constant β2 can be determined by making S1 and S2 conjugate with respect
to [A]. This leads to (see Problem 6.41):
β2 = −
∇f T2 ∇f2
∇f T1 S1
=
∇f T2 ∇f2
∇f T1 ∇f1
(6.77)
This process can be continued to obtain the general formula for the ith search
direction as
Si = −∇fi + βiSi−1 (6.78)
where
βi =
∇f Ti ∇fi
∇f Ti−1∇fi−1
(6.79)
Thus the Fletcher–Reeves algorithm can be stated as follows.
6.10 Conjugate Gradient (Fletcher–Reeves) Method 343
6.10.2 Fletcher–Reeves Method
The iterative procedure of Fletcher–Reeves method can be stated as follows:
1. Start with an arbitrary initial point X1.
2. Set the first search direction S1 = −∇f (X1) = −∇f1.
3. Find the point X2 according to the relation
X2 = X1 + λ∗1S1 (6.80)
where λ∗1 is the optimal step length in the direction S1. Set i = 2 and go to the
next step.
4. Find ∇fi = ∇f (Xi), and set
Si = −∇fi +
|∇fi |2
|∇fi−1|2
Si−1 (6.81)
5. Compute the optimum step length λ∗i in the direction Si , and find the new point
Xi+1 = Xi + λ∗i Si (6.82)
6. Test for the optimality of the point Xi+1. If Xi+1 is optimum, stop the process.
Otherwise, set the value of i = i + 1 and go to step 4.
Remarks:
1. The Fletcher–Reeves method was originally proposed by Hestenes and Stiefel
[6.14] as a method for solving systems of linear equations derived from the
stationary conditions of a quadratic. Since the directions Si used in this method
are A-conjugate, the process should converge in n cycles or less for a quadratic
function. However, for ill-conditioned quadratics (whose contours are highly
eccentric and distorted), the method may require much more than n cycles for
convergence. The reason for this has been found to be the cumulative effect
of rounding errors. Since Si is given by Eq. (6.81), any error resulting from
the inaccuracies involved in the determination of λ∗i , and from the round-off
error involved in accumulating the successive |∇fi |2Si−1/|∇fi−1|2 terms, is
carried forward through the vector Si . Thus the search directions Si will be
progressively contaminated by these errors. Hence it is necessary, in practice,
to restart the method periodically after every, say, m steps by taking the new
search direction as the steepest descent direction. That is, after every m steps,
Sm+1 is set equal to −∇fm+1 instead of the usual form. Fletcher and Reeves
have recommended a value of m = n + 1, where n is the number of design
variables.
2. Despite the limitations indicated above, the Fletcher–Reeves method is vastly
superior to the steepest descent method and the pattern search methods, but
it turns out to be rather less efficient than the Newton and the quasi-Newton
(variable metric) methods discussed in the latter sections.
Example 6.9 Minimize f (x1, x2) = x1 − x2 + 2x21 + 2x1x2 + x22 starting from the
point X1 =
{
0
0
}
.
344 Nonlinear Programming II: Unconstrained Optimization Techniques
SOLUTION
Iteration 1
∇f =
{
∂f/∂x1
∂f/∂x2
}
=
{
1 + 4x1 + 2x2
−1 + 2x1 + 2x2
}
∇f1 = ∇f (X1) =
{
1
−1
}
The search direction is taken as S1 = −∇f1 =
{−1
1
}
. To find the optimal step length
λ∗1 along S1, we minimize f (X1 + λ1S1) with respect to λ1. Here
f (X1 + λ1S1) = f (−λ1, +λ1) = λ21 − 2λ1
df
dλ1
= 0 at λ∗1 = 1
Therefore,
X2 = X1 + λ∗1S1 =
{
0
0
}
+ 1
{
−1
1
}
=
{
−1
1
}
Iteration 2
Since ∇f2 = ∇f (X2) =
{−1
−1
}
, Eq. (6.81) gives the next search direction as
S2 = −∇f2 +
|∇f2|2
|∇f1|2
S1
where
|∇f1|2 = 2 and |∇f2|2 = 2
Therefore,
S2 = −
{
−1
−1
}
+
(
2
2
){
−1
1
}
=
{
0
+2
}
To find λ∗2, we minimize
f (X2 + λ2S2) = f (−1, 1 + 2λ2)
= −1 − (1 + 2λ2) + 2 − 2(1 + 2λ2) + (1 + 2λ2)2
= 4λ22 − 2λ2 − 1
with respect to λ2. As df/dλ2 = 8λ2 − 2 = 0 at λ∗2 =
1
4
, we obtain
X3 = X2 + λ∗2S2 =
{
−1
1
}
+ 1
4
{
0
2
}
=
{
−1
1.5
}
6.11 Newton’s Method 345
Thus the optimum point is reached in two iterations. Even if we do not know this point
to be optimum, we will not be able to move from this point in the next iteration. This
can be verified as follows.
Iteration 3
Now
∇f3 = ∇f (X3) =
{
0
0
}
, |∇f2|2 = 2, and |∇f3|2 = 0.
Thus
S3 = −∇f3 + (|∇f3|2/|∇f2|2)S2 = −
{
0
0
}
+
(
0
2
){
0
0
}
=
{
0
0
}
This shows that there is no search direction to reduce f further, and hence X3 is
optimum.
6.11 NEWTON’S METHOD
Newton’s method presented in Section 5.12.1 can be extended for the minimization of
multivariable functions. For this, consider the quadratic approximation of the function
f (X) at X = Xi using the Taylor’s series expansion
f (X) = f (Xi) + ∇f Ti (X − Xi) + 12 (X − Xi)
T[Ji](X − Xi) (6.83)
where [Ji] = [J ]|Xi is the matrix of second partial derivatives (Hessian matrix) of f
evaluated at the point Xi . By setting the partial derivatives of Eq. (6.83) equal to zero
for the minimum of f (X), we obtain
∂f (X)
∂xj
= 0, j = 1, 2, . . . , n (6.84)
Equations (6.84) and (6.83) give
∇f = ∇fi + [Ji](X − Xi) = 0 (6.85)
If [Ji] is nonsingular, Eqs. (6.85) can be solved to obtain an improved approximation
(X = Xi+1) as
Xi+1 = Xi − [Ji]−1 ∇fi (6.86)
Since higher-order terms have been neglected in Eq. (6.83), Eq. (6.86) is to be used
iteratively to find the optimum solution X∗.
The sequence of points X1, X2, . . . , Xi+1 can be shown to converge to the actual
solution X∗ from any initial point X1 sufficiently close to the solution X
∗, provided
that [J1] is nonsingular. It can be seen that Newton’s method uses the second partial
derivatives of the objective function (in the form of the matrix [Ji]) and hence is a
second-order method.
346 Nonlinear Programming II: Unconstrained Optimization Techniques
Example 6.10 Show that the Newton’s method finds the minimum of a quadratic
function in one iteration.
SOLUTION Let the quadratic function be given by
f (X) = 1
2
XT[A]X + BTX + C
The minimum of f (X) is given by
∇f = [A]X + B = 0
or
X∗ = −[A]−1B
The iterative step of Eq. (6.86) gives
Xi+1 = Xi − [A]−1([A]Xi + B) (E1)
where Xi is the starting point for the ith iteration. Thus Eq. (E1) gives the exact solution
Xi+1 = X∗ = −[A]−1B
Figure 6.16 illustrates this process.
Example 6.11 Minimize f (x1, x2) = x1 − x2 + 2x21 + 2x1x2 + x22 by taking the start-
ing point as X1 =
{
0
0
}
.
SOLUTION To find X2 according to Eq. (6.86), we require [J1]
−1, where
[J1] =





∂2f
∂x21
∂2f
∂x1∂x2
∂2f
∂x2∂x1
∂2f
∂x22





X1
=
[
4 2
2 2
]
Figure 6.16 Minimization of a quadratic function in one step.
6.11 Newton’s Method 347
Therefore,
[J1]
−1 = 1
4
[+2 −2
−2 4
]
=
[
1
2
− 1
2
− 1
2
1
]
As
g1 =
{
∂f/∂x1
∂f/∂x2
}
X1
=
{
1 + 4x1 + 2x2
−1 + 2x1 + 2x2
}
(0,0)
=
{
1
−1
}
Equation (6.86) gives
X2 = X1 − [J1]−1g1 =
{
0
0
}
−
[
1
2
− 1
2
− 1
2
1
]
{
1
−1
}
=
{
−1
3
2
}
To see whether or not X2 is the optimum point, we evaluate
g2 =
{
∂f/∂x1
∂f/∂x2
}
X2
=
{
1 + 4x1 + 2x2
−1 + 2x1 + 2x2
}
(−1,3/2)
=
{
0
0
}
As g2 = 0, X2 is the optimum point. Thus the method has converged in one iteration
for this quadratic function.
If f (X) is a nonquadratic function, Newton’s method may sometimes diverge, and
it may converge to saddle points and relative maxima. This problem can be avoided
by modifying Eq. (6.86) as
Xi+1 = Xi + λ∗i Si = Xi − λ∗i [Ji]−1∇fi (6.87)
where λ∗i is the minimizing step length in the direction Si = −[Ji]−1∇fi . The mod-
ification indicated by Eq. (6.87) has a number of advantages. First, it will find the
minimum in lesser number of steps compared to the original method. Second, it finds
the minimum point in all cases, whereas the original method may not converge in some
cases. Third, it usually avoids convergence to a saddle point or a maximum. With all
these advantages, this method appears to be the most powerful minimization method.
Despite these advantages, the method is not very useful in practice, due to the following
features of the method:
1. It requires the storing of the n × n matrix [Ji].
2. It becomes very difficult and sometimes impossible to compute the elements of
the matrix [Ji].
3. It requires the inversion of the matrix [Ji] at each step.
4. It requires the evaluation of the quantity [Ji]
−1∇fi at each step.
These features make the method impractical for problems involving a complicated
objective function with a large number of variables.
348 Nonlinear Programming II: Unconstrained Optimization Techniques
6.12 MARQUARDT METHOD
The steepest descent method reduces the function value when the design vector Xi is
away from the optimum point X∗. The Newton method, on the other hand, converges
fast when the design vector Xi is close to the optimum point X
∗. The Marquardt method
[6.15] attempts to take advantage of both the steepest descent and Newton methods.
This method modifies the diagonal elements of the Hessian matrix, [Ji], as
[J̃i] = [Ji] + αi[I ] (6.88)
where [I ] is an identity matrix and αi is a positive constant that ensures the positive
definiteness of [J̃i] when [Ji] is not positive definite. It can be noted that when αi is
sufficiently large (on the order of 104), the term αi[I ] dominates [Ji] and the inverse
of the matrix [J̃i] becomes
[J̃i]
−1 = [[Ji] + αi[I ]]−1 ≈ [αi[I ]]−1 =
1
αi
[I ] (6.89)
Thus if the search direction Si is computed as
Si = −[J̃i]−1∇fi (6.90)
Si becomes a steepest descent direction for large values of αi . In the Marquardt method,
the value of αi is taken to be large at the beginning and then reduced to zero gradually
as the iterative process progresses. Thus as the value of αi decreases from a large value
to zero, the characteristics of the search method change from those of a steepest descent
method to those of the Newton method. The iterative process of a modified version of
Marquardt method can be described as follows.
1. Start with an arbitrary initial point X1 and constants α1 (on the order of
104), c1(0 < c1 < 1), c2(c2 > 1), and ε (on the order of 10
−2). Set the iteration
number as i = 1.
2. Compute the gradient of the function, ∇fi = ∇f (Xi).
3. Test for optimality of the point Xi . If ||∇fi || = ||∇f (Xi)|| ≤ ε, Xi is optimum
and hence stop the process. Otherwise, go to step 4.
4. Find the new vector Xi+1 as
Xi+1 = Xi + Si = Xi − [[Ji]] + αi[I ]]−1 ∇fi (6.91)
5. Compare the values of fi+1 and fi . If fi+1 < fi , go to, step 6. If fi+1 ≥ fi , go
to step 7.
6. Set αi+1 = c1αi , i = i + 1, and go to step 2.
7. Set αi = c2αi and go to step 4.
An advantage of this method is the absence of the step size λi along the search
direction Si . In fact, the algorithm above can be modified by introducing an optimal
step length in Eq. (6.91) as
Xi+1 = Xi + λ∗i Si = Xi − λ∗i [[Ji] + αi[I ]]−1∇fi (6.92)
6.12 Marquardt Method 349
where λ∗i is found using any of the one-dimensional search methods described in
Chapter 5.
Example 6.12 Minimize f (x1, x2) = x1 − x2 + 2x21 + 2x1x2 + x22 from the starting
point X1 =
{
0
0
}
using Marquardt method with α1 = 104, c1 = 14 , c2 = 2, and
ε = 10−2.
SOLUTION
Iteration 1 (i = 1)
Here f1 = f (X1) = 0.0 and
∇f1 =







∂f
∂x1
∂f
∂x2







(0,0)
=
{
1 + 4x1 + 2x2
−1 + 2x1 + 2x2
}
(0,0)
=
{
1
−1
}
Since ||∇f1|| = 1.4142 >ε, we compute
[J1] =






∂2f
∂x21
∂2f
∂x1x2
∂2
∂x1x2
∂2f
∂x22






(0,0)
=
[
4 2
2 2
]
X2 = X1 − [[J1] + α1[I ]]−1∇f1
=
{
0
0
}
−
[
4 + 104 2
2 2 + 104
]−1
{
1
−1
}
=
{
−0.9998
1.0000
}
10−4
As f2 = f (X2) = −1.9997 × 10−4 < f1, we set α2 = c1α1 = 2500, i = 2, and proceed
to the next iteration.
Iteration 2 (i = 2)
The gradient vector corresponding to X2 is given by ∇f2 =
{
0.9998
−1.0000
}
, ||∇f2|| =
1.4141 >ε, and hence we compute
X3 = X2 − [[J2] + α2[I ]]−1∇f2
=
{
−0.9998 × 10−4
1.0000 × 10−4
}
−
[
2504 2
2 2502
]−1 {
0.9998
−1.0000
}
=
{
−4.9958 × 10−4
5.0000 × 10−4
}
Since f3 = f (X3) = −0.9993 × 10−3 < f2, we set α3 = c1α2 = 625, i = 3, and pro-
ceed to the next iteration. The iterative process is to be continued until the convergence
criterion, ||∇fi || < ε, is satisfied.
350 Nonlinear Programming II: Unconstrained Optimization Techniques
6.13 QUASI-NEWTON METHODS
The basic iterative process used in the Newton’s method is given by Eq. (6.86):
Xi+1 = Xi − [Ji]−1∇f (Xi) (6.93)
where the Hessian matrix [Ji] is composed of the second partial derivatives of f
and varies with the design vector Xi for a nonquadratic (general nonlinear) objective
function f . The basic idea behind the quasi-Newton or variable metric methods is to
approximate either [Ji] by another matrix [Ai] or [Ji]
−1 by another matrix [Bi], using
only the first partial derivatives of f . If [Ji]
−1 is approximated by [Bi], Eq. (6.93) can
be expressed as
Xi+1 = Xi − λ∗i [Bi]∇f (Xi) (6.94)
where λ∗i can be considered as the optimal step length along the direction
Si = −[Bi]∇f (Xi) (6.95)
It can be seen that the steepest descent direction method can be obtained as a special
case of Eq. (6.95) by setting [Bi] = [I ].
Computation of [Bi]. To implement Eq. (6.94), an approximate inverse of the Hes-
sian matrix, [Bi] ≡ [Ai]−1, is to be computed. For this, we first expand the gradient of
f about an arbitrary reference point, X0, using Taylor’s series as
∇f (X) ≈ ∇f (X0) + [J0](X − X0) (6.96)
If we pick two points Xi and Xi+1 and use [Ai] to approximate [J0], Eq. (6.96) can
be rewritten as
∇fi+1 = ∇f (X0) + [Ai](Xi+1 − X0) (6.97)
∇fi = ∇f (X0) + [Ai](Xi − X0) (6.98)
Subtracting Eq. (6.98) from (6.97) yields
[Ai]di = gi (6.99)
where
di = Xi+1 − Xi (6.100)
gi = ∇fi+1 − ∇fi (6.101)
The solution of Eq. (6.99) for di can be written as
di = [Bi]gi (6.102)
where [Bi] = [Ai]−1 denotes an approximation to the inverse of the Hessian matrix,
[J0]
−1. It can be seen that Eq. (6.102) represents a system of n equations in n2 unknown
elements of the matrix [Bi]. Thus for n> 1, the choice of [Bi] is not unique and one
would like to choose [Bi] that is closest to [J0]
−1, in some sense. Numerous techniques
6.13 Quasi-Newton Methods 351
have been suggested in the literature for the computation of [Bi] as the iterative process
progresses (i.e., for the computation of [Bi+1] once [Bi] is known). A major concern
is that in addition to satisfying Eq. (6.102), the symmetry and positive definiteness of
the matrix [Bi] is to be maintained; that is, if [Bi] is symmetric and positive definite,
[Bi+1] must remain symmetric and positive definite.
6.13.1 Rank 1 Updates
The general formula for updating the matrix [Bi] can be written as
[Bi+1] = [Bi] + [
Bi] (6.103)
where [
Bi] can be considered to be the update (or correction) matrix added to [Bi].
Theoretically, the matrix [
Bi] can have its rank as high as n. However, in practice,
most updates, [
Bi], are only of rank 1 or 2. To derive a rank 1 update, we simply
choose a scaled outer product of a vector z for [
Bi] as
[
Bi] = czzT (6.104)
where the constant c and the n-component vector z are to be determined. Equations
(6.103) and (6.104) lead to
[Bi+1] = [Bi] + czzT (6.105)
By forcing Eq. (6.105) to satisfy the quasi-Newton condition, Eq. (6.102),
di = [Bi+1]gi (6.106)
we obtain
di = ([Bi] + czzT )gi = [Bi]gi + cz(zT gi) (6.107)
Since (zT gi) in Eq. (6.107) is a scalar, we can rewrite Eq. (6.107) as
cz = di − [Bi]gi
zT gi
(6.108)
Thus a simple choice for z and c would be
z = di − [Bi]gi (6.109)
c = 1
zT gi
(6.110)
This leads to the unique rank 1 update formula for [Bi+1]:
[Bi+1] = [Bi] + [
Bi] ≡ [Bi] +
(di − [Bi]gi)(di − [Bi]gi)T
(di − [Bi]gi)T gi
(6.111)
This formula has been attributed to Broyden [6.16]. To implement Eq. (6.111), an initial
symmetric positive definite matrix is selected for [B1] at the start of the algorithm, and
the next point X2 is computed using Eq. (6.94). Then the new matrix [B2] is computed
352 Nonlinear Programming II: Unconstrained Optimization Techniques
using Eq. (6.111) and the new point X3 is determined from Eq. (6.94). This iterative
process is continued until convergence is achieved. If [Bi] is symmetric, Eq. (6.111)
ensures that [Bi+1] is also symmetric. However, there is no guarantee that [Bi+1]
remains positive definite even if [Bi] is positive definite. This might lead to a breakdown
of the procedure, especially when used for the optimization of nonquadratic functions.
It can be verified easily that the columns of the matrix [
Bi] given by Eq. (6.111) are
multiples of each other. Thus the updating matrix has only one independent column and
hence the rank of the matrix will be 1. This is the reason why Eq. (6.111) is considered
to be a rank 1 updating formula. Although the Broyden formula, Eq. (6.111), is not
robust, it has the property of quadratic convergence [6.17]. The rank 2 update formulas
given next guarantee both symmetry and positive definiteness of the matrix [Bi+1]
and are more robust in minimizing general nonlinear functions, hence are preferred in
practical applications.
6.13.2 Rank 2 Updates
In rank 2 updates we choose the update matrix [
Bi] as the sum of two rank 1
updates as
[
Bi] = c1z1zT1 + c2z2zT2 (6.112)
where the constants c1 and c2 and the n-component vectors z1 and z2 are to be deter-
mined. Equations (6.103) and (6.112) lead to
[Bi+1] = [Bi] + c1z1zT1 + c2z2zT2 (6.113)
By forcing Eq. (6.113) to satisfy the quasi-Newton condition, Eq. (6.106), we obtain
di = [Bi]gi + c1z1(zT1 gi) + c2z2(zT2 gi) (6.114)
where (zT1 gi) and (z
T
2 gi) can be identified as scalars. Although the vectors z1 and z2 in
Eq. (6.114) are not unique, the following choices can be made to satisfy Eq. (6.114):
z1 = di (6.115)
z2 = [Bi]gi (6.116)
c1 =
1
zT1 gi
(6.117)
c2 = −
1
zT2 gi
(6.118)
Thus the rank 2 update formula can be expressed as
[Bi+1] = [Bi] + [
Bi] ≡ [Bi] +
did
T
i
dTi gi
−
([Bi]gi)([Bi]gi)
T
([Bi]gi)Tgi
(6.119)
This equation is known as the Davidon–Fletcher–Powell (DFP) formula [6.20, 6.21].
Since
Xi+1 = Xi + λ∗i Si (6.120)
6.13 Quasi-Newton Methods 353
where Si is the search direction, di = Xi+1 − Xi can be rewritten as
di = λ∗i Si (6.121)
Thus Eq. (6.119) can be expressed as
[Bi+1] = [Bi] +
λ∗i SiS
T
i
STi gi
−
[Bi]gig
T
i [Bi]
gTi [Bi]gi
(6.122)
Remarks:
1. Equations (6.111) and (6.119) are known as inverse update formulas since these
equations approximate the inverse of the Hessian matrix of f .
2. It is possible to derive a family of direct update formulas in which approx-
imations to the Hessian matrix itself are considered. For this we express the
quasi-Newton condition as [see Eq. (6.99)]
gi = [Ai]di (6.123)
The procedure used in deriving Eqs. (6.111) and (6.119) can be followed
by using [Ai], di , and gi in place of [Bi], gi , and di , respectively. This
leads to the rank 2 update formula (similar to Eq. (6.119), known as the
Broydon–Fletcher–Goldfarb–Shanno (BFGS) formula [6.22–6.25]:
[Ai+1] = [Ai] +
gig
T
i
gTi di
− ([Ai]di)([Ai]di)
T
([Ai]di)T di
(6.124)
In practical computations, Eq. (6.124) is rewritten more conveniently in terms
of [Bi], as
[Bi+1] = [Bi] +
did
T
i
dTi gi
(
1 +
gTi [Bi]gi
dTi gi
)
−
[Bi]gid
T
i
dTi gi
−
dig
T
i [Bi]
dTi gi
(6.125)
3. The DFP and the BFGS formulas belong to a family of rank 2 updates known
as Huang’s family of updates [6.18], which can be expressed for updating the
inverse of the Hessian matrix as
[Bi+1] = ρi
(
[Bi] −
[Bi]gig
T
i [Bi]
gTi [Bi]gi
+ θiyiyTi
)
+
did
T
i
dTi gi
(6.126)
where
yi = (gTi [Bi]gi)1/2
(
di
dTi gi
− [Bi]gi
gTi [Bi]gi
)
(6.127)
and ρi and θi are constant parameters. It has been shown [6.18] that Eq. (6.126)
maintains the symmetry and positive definiteness of [Bi+1] if [Bi] is symmetric
and positive definite. Different choices of ρi and θi in Eq. (6.126) lead to
different algorithms. For example, when ρi = 1 and θi = 0, Eq. (6.126) gives
the DFP formula, Eq. (6.119). When ρi = 1 and θi = 1, Eq. (6.126) yields the
BFGS formula, Eq. (6.125).
354 Nonlinear Programming II: Unconstrained Optimization Techniques
4. It has been shown that the BFGS method exhibits superlinear convergence near
X∗ [6.17].
5. Numerical experience indicates that the BFGS method is the best unconstrained
variable metric method and is less influenced by errors in finding λ∗i compared
to the DFP method.
6. The methods discussed in this section are also known as secant methods since
Eqs. (6.99) and (6.102) can be considered as secant equations (see Section 5.12).
The DFP and BFGS iterative methods are described in detail in the following sections.
6.14 DAVIDON–FLETCHER–POWELL METHOD
The iterative procedure of the Davidon–Fletcher–Powell (DFP) method can be
described as follows:
1. Start with an initial point X1 and a n × n positive definite symmetric matrix
[B1] to approximate the inverse of the Hessian matrix of f . Usually, [B1] is
taken as the identity matrix [I ]. Set the iteration number as i = 1.
2. Compute the gradient of the function, ∇fi , at point Xi , and set
Si = −[Bi]∇fi (6.128)
3. Find the optimal step length λ∗i in the direction Si and set
Xi+1 = Xi + λ∗i Si (6.129)
4. Test the new point Xi+1 for optimality. If Xi+1 is optimal, terminate the iterative
process. Otherwise, go to step 5.
5. Update the matrix [Bi] using Eq. (6.119) as
[Bi+1] = [Bi] + [Mi] + [Ni] (6.130)
where
[Mi] = λ∗i
SiS
T
i
STi gi
(6.131)
[Ni] = −
([Bi]gi)([Bi]gi)
T
gTi [Bi]gi
(6.132)
gi = ∇f (Xi+1) − ∇f (Xi) = ∇fi+1 − ∇fi (6.133)
6. Set the new iteration number as i = i + 1, and go to step 2.
Note: The matrix [Bi+1], given by Eq. (6.130), remains positive definite only if λ
∗
i
is found accurately. Thus if λ∗i is not found accurately in any iteration, the matrix [Bi]
should not be updated. There are several alternatives in such a case. One possibility is to
compute a better value of λ∗i by using more number of refits in the one-dimensional min-
imization procedure (until the product STi ∇fi+1 becomes sufficiently small). However,
6.14 Davidon–Fletcher–Powell Method 355
this involves more computational effort. Another possibility is to specify a maximum
number of refits in the one-dimensional minimization method and to skip the updating
of [Bi] if λ
∗
i could not be found accurately in the specified number of refits. The last
possibility is to continue updating the matrix [Bi] using the approximate values of λ
∗
i
found, but restart the whole procedure after certain number of iterations, that is, restart
with i = 1 in step 2 of the method.
Example 6.13 Show that the DFP method is a conjugate gradient method.
SOLUTION Consider the quadratic function
f (X) = 1
2
XT[A]X + BTX + C (E1)
for which the gradient is given by
∇f = [A]X + B (E2)
Equations (6.133) and (E2) give
gi = ∇fi+1 − ∇fi = [A](Xi+1 − Xi) (E3)
Since
Xi+1 = Xi + λ∗i Si (E4)
Eq. (E3) becomes
gi = λ∗i [A]Si (E5)
or
[A]Si =
1
λ∗i
gi (E6)
Premultiplication of Eq. (E6) by [Bi+1] leads to
[Bi+1][A]Si =
1
λ∗i
([Bi] + [Mi] + [Ni])gi (E7)
Equations (6.131) and (E5) yield
[Mi]gi = λ∗i
SiS
T
i gi
STi gi
= λ∗i Si (E8)
Equation (6.132) can be used to obtain
[Ni]gi = −
([Bi]gi)(g
T
i [Bi]
Tgi)
gTi [Bi]gi
= −[Bi]gi (E9)
since [Bi] is symmetric. By substituting Eqs. (E8) and (E9) into Eq. (E7), we obtain
[Bi+1][A]Si =
1
λ∗i
([Bi]gi + λ∗i Si − [Bi]gi) = Si (E10)
356 Nonlinear Programming II: Unconstrained Optimization Techniques
The quantity STi+1[A]Si can be written as
STi+1[A]Si = −([Bi+1]∇fi+1)T[A]Si
= −∇f Ti+1[Bi+1][A]Si = −∇f Ti+1Si = 0 (E11)
since λ∗i is the minimizing step in the direction Si . Equation (E11) proves that the
successive directions generated in the DFP method are [A]-conjugate and hence the
method is a conjugate gradient method.
Example 6.14 Minimize f (x1, x2) = 100(x21 − x2)2 + (1 − x1)2 taking X1 =
{−2
−2
}
as
the starting point. Use cubic interpolation method for one-dimensional minimization.
SOLUTION Since this method requires the gradient of f , we find that
∇f =
{
∂f /∂x1
∂f /∂x2
}
=
{
400x1(x
2
1 − x2) − 2(1 − x1)
−200(x21 − x2)
}
Iteration 1
We take
[B1] =
[
1 0
0 1
]
At X1 =
{−2
−2
}
, ∇f1 = ∇f (X1) =
{−4806
−1200
}
and f1 = 3609. Therefore,
S1 = −[B1]∇f1 =
{
4806
1200
}
By normalizing, we obtain
S1 =
1
[(4806)2 + (1200)2]1/2
{
4806
1200
}
=
{
0.970
0.244
}
To find λ∗i , we minimize
f (X1 + λ1S1) = f (−2 + 0.970λ1, −2 + 0.244λ1)
= 100(6 − 4.124λ1 + 0.938λ21)2 + (3 − 0.97λ1)2 (E1)
with respect to λ1. Equation (E1) gives
df
dλ1
= 200(6 − 4.124λ1 + 0.938λ21)(1.876λ1 − 4.124) − 1.94(3 − 0.97λ1)
Since the solution of the equation df/dλ1 = 0 cannot be obtained in a simple manner,
we use the cubic interpolation method for finding λ∗i .
6.14 Davidon–Fletcher–Powell Method 357
Cubic Interpolation Method (First Fitting)
Stage 1: As the search direction S1 is normalized already, we go to stage 2.
Stage 2: To establish lower and upper bounds on the optimal step size λ∗1, we have to
find two points A and B at which the slope df/dλ1 has different signs. We
take A = 0 and choose an initial step size of t0 = 0.25 to find B.
At λ1 = A = 0:
fA = f (λ1 = A = 0) = 3609
f ′A =
df
dλ1
∣
∣
∣
∣
λ1=A=0
= −4956.64
At λ1 = t0 = 0.25:
f = 2535.62
df
dλ1
= −3680.82
As df/dλ1 is negative, we accelerate the search by taking λ1 = 4t0 = 1.00.
At λ1 = 1.00:
f = 795.98
df
dλ1
= −1269.18
Since df/dλ1 is still negative, we take λ1 = 2.00.
At λ1 = 2.00:
f = 227.32
df
dλ1
= −113.953
Although df/dλ1 is still negative, it appears to have come close to zero and
hence we take the next value of λ1 as 2.50.
At λ1 = 2.50:
f = 241.51
df
dλ1
= 174.684 = positive
Since df/dλ1 is negative at λ1 = 2.0 and positive at λ1 = 2.5, we take A =
2.0 (instead of zero for faster convergence) and B = 2.5. Therefore,
A = 2.0, fA = 227.32, f ′A = −113.95
B = 2.5, fB = 241.51, f ′B = 174.68
Stage 3: To find the optimal step length λ̃∗1 using Eq. (5.54), we compute
Z = 3(227.32 − 241.51)
2.5 − 2.0
− 113.95 + 174.68 = −24.41
Q = [(24.41)2 + (113.95)(174.68)]1/2 = 143.2
358 Nonlinear Programming II: Unconstrained Optimization Techniques
Therefore,
λ̃∗i = 2.0 +
−113.95 − 24.41 + 143.2
−113.95 + 174.68 − 48.82
(2.5 − 2.0)
= 2.2
Stage 4: To find whether λ̃∗1 is close to λ
∗
1, we test the value of df/dλ1.
df
dλ1
∣
∣
∣
∣
λ̃∗
1
= −0.818
Also,
f (λ1 = λ̃∗1) = 216.1
Since df/dλ1 is not close to zero at λ̃
∗
1, we use a refitting technique.
Second Fitting: Now we take A = λ̃∗1 since df/dλ1 is negative at λ̃∗1 and B = 2.5.
Thus
A = 2.2, fA = 216.10, f ′A = −0.818
B = 2.5, fB = 241.51, f ′B = 174.68
With these values we find that
Z = 3(216.1 − 241.51)
2.5 − 2.2
− 2.818 + 174.68 = −80.238
Q = [(80.238)2 + (0.818)(174.68)]1/2 = 81.1
λ̃∗1 = 2.2 +
−0.818 − 80.238 + 81.1
−0.818 + 174.68 − 160.476
(2.5 − 2.2) = 2.201
To test for convergence, we evaluate df/dλ at λ̃∗1. Since df/dλ|λ1=λ̃∗1 = −0.211, it can
be assumed to be sufficiently close to zero and hence we take λ∗1 ≃ λ̃∗1 = 2.201. This
gives
X2 = X1 + λ∗1S1 =
{
−2 + 0.970λ∗1
−2 + 0.244λ∗1
}
=
{
0.135
−1.463
}
Testing X2 for convergence: To test whether the D-F-P method has converged,
we compute the gradient of f at X2:
∇f2 =
{
∂f /∂x1
∂f /∂x2
}
X2
=
{
78.29
−296.24
}
As the components of this vector are not close to zero, X2 is not optimum and hence
the procedure has to be continued until the optimum point is found.
Example 6.15 Minimize f (x1, x2) = x1 − x2 + 2x21 + 2x1x2 + x22 from the starting
point X1 =
{
0
0
}
using the DFP method with
[B1] =
[
1 0
0 1
]
ε = 0.01
6.14 Davidon–Fletcher–Powell Method 359
SOLUTION
Iteration 1 (i = 1)
Here
∇f1 = ∇f (X1) =
{
1 + 4x1 + 2x2
−1 + 2x1 + 2x2
}
∣
∣
∣
∣
(0,0)
=
{
1
−1
}
and hence
S1 = −[B1]∇f1 = −
[
1 0
0 1
]{
1
−1
}
=
{
−1
1
}
To find the minimizing step length λ∗1 along S1, we minimize
f (X1 + λ1S1) = f
({
0
0
}
+ λ1
{
−1
1
})
= f (−λ1, λ1) = λ21 − 2λ1
with respect to λ1. Since df/dλ1 = 0 at λ∗1 = 1, we obtain
X2 = X1 + λ∗1S1 =
{
0
0
}
+ 1
{
−1
1
}
=
{
−1
1
}
Since ∇f2 = ∇f (X2) =
{−1
−1
}
and ||∇f2|| = 1.4142 > ε, we proceed to update the
matrix [Bi] by computing
g1 = ∇f2 − ∇f1 =
{
−1
−1
}
−
{
1
−1
}
=
{
−2
0
}
ST1 g1 =
{
−1 1
}
{
−2
0
}
= 2
S1S
T
1 =
{
−1
1
}
{
−1 1
}
=
[
1 −1
−1 1
]
[B1]g1 =
[
1 0
0 1
]{
−2
0
}
=
{
−2
0
}
([B1]g1)
T =
{
−2
0
}T
=
{
−2 0
}
gT1 [B1]g1 =
{
−2 0
}
[
1 0
0 1
]{
−2
0
}
=
{
−2 0
}
{
−2
0
}
= 4
[M1] = λ∗1
S1S
T
1
ST1 g1
= 1
(
1
2
)[
1 −1
−1 1
]
=




1
2
−
1
2
−
1
2
1
2




360 Nonlinear Programming II: Unconstrained Optimization Techniques
[N1] = −
([B1]g1)([B1]g1)
T
gT1 [B1]g1
= −
{
−2
0
}
{−2 0}
4
= −
1
4
[
4 0
0 0
]
= −
[
1 0
0 0
]
[B2] = [B1] + [M1] + [N1] =
[
1 0
0 1
]
+




1
2
−1
2
−1
2
1
2




+
[
−1 0
0 0
]
=
[
0.5 −0.5
−0.5 1.5
]
Iteration 2 (i = 2)
The next search direction is determined as
S2 = −[B2]∇f2 = −
[
0.5 −0.5
−0.5 1.5
]{
−1
−1
}
=
{
0
1
}
To find the minimizing step length λ∗2 along S2, we minimize
f (X2 + λ2S2) = f
({
−1
1
}
+ λ2
{
0
1
})
= f
({
−1
1 + λ2
})
= −1 − (1 + λ2) + 2(−1)2 + 2(−1)(1 + λ2) + (1 + λ2)2
= λ22 − λ2 − 1
with respect to λ2. Since df/dλ2 = 0 at λ∗2 =
1
2
, we obtain
X3 = X2 + λ∗2 =
{
−1
1
}
+ 1
2
{
0
1
}
=
{
−1
1.5
}
This point can be identified to be optimum since
∇f3 =
{
0
0
}
and ||∇f3|| = 0 < ε
6.15 BROYDEN–FLETCHER–GOLDFARB–SHANNO METHOD
As stated earlier, a major difference between the DFP and BFGS methods is that in
the BFGS method, the Hessian matrix is updated iteratively rather than the inverse of
the Hessian matrix. The BFGS method can be described by the following steps.
1. Start with an initial point X1 and a n × n positive definite symmetric matrix [B1]
as an initial estimate of the inverse of the Hessian matrix of f . In the absence
of additional information, [B1] is taken as the identity matrix [I ]. Compute the
gradient vector ∇f1 = ∇f (X1) and set the iteration number as i = 1.
2. Compute the gradient of the function, ∇fi , at point Xi , and set
Si = −[Bi]∇fi (6.134)
6.15 Broyden–Fletcher–Goldfarb–Shanno Method 361
3. Find the optimal step length λ∗i in the direction Si and set
Xi+1 = Xi + λ∗i Si (6.135)
4. Test the point Xi+1 for optimality. If ||∇fi+1|| ≤ ε, where ε is a small quantity,
take X∗ ≈ Xi+1 and stop the process. Otherwise, go to step 5.
5. Update the Hessian matrix as
[Bi+1] = [Bi] +
(
1 +
gTi [Bi]gi
dTi gi
)
did
T
i
dTi gi
−
dig
T
i [Bi]
dTi gi
−
[Bi]gid
T
i
dTi gi
(6.136)
where
di = Xi+1 − Xi = λ∗i Si (6.137)
gi = ∇fi+1 − ∇fi = ∇f (Xi+1) − ∇f (Xi) (6.138)
6. Set the new iteration number as i = i + 1 and go to step 2.
Remarks:
1. The BFGS method can be considered as a quasi-Newton, conjugate gradient,
and variable metric method.
2. Since the inverse of the Hessian matrix is approximated, the BFGS method can
be called an indirect update method.
3. If the step lengths λ∗i are found accurately, the matrix, [Bi], retains its positive
definiteness as the value of i increases. However, in practical application, the
matrix [Bi] might become indefinite or even singular if λ
∗
i are not found accu-
rately. As such, periodical resetting of the matrix [Bi] to the identity matrix [I ]
is desirable. However, numerical experience indicates that the BFGS method is
less influenced by errors in λ∗i than is the DFP method.
4. It has been shown that the BFGS method exhibits superlinear convergence near
X* [6.19].
Example 6.16 Minimize f (x1, x2) = x1 − x2 + 2x21 + 2x1x2 + x22 from the starting
point X1 =
{
0
0
}
using the BFGS method with
[B1] =
[
1 0
0 1
]
ε = 0.01.
SOLUTION
Iteration 1 (i = 1)
Here
∇f1 = ∇f (X1) =
{
1 + 4x1 + 2x2
−1 + 2x1 + 2x2
}
∣
∣
∣
∣
(0,0)
=
{
1
−1
}
and hence
S1 = −[B1]∇f1 = −
[
1 0
0 1
]{
1
−1
}
=
{
−1
1
}
362 Nonlinear Programming II: Unconstrained Optimization Techniques
To find the minimizing step length λ∗1 along S1, we minimize
f (X1 + λ1S1) = f
({
0
0
}
+ λ1
{
−1
1
})
= f (−λ1, λ1) = λ21 − 2λ1
with respect to λ1. Since df/dλ1 = 0 at λ∗1 = 1, we obtain
X2 = X1 + λ∗1S1 =
{
0
0
}
+ 1
{
−1
1
}
=
{
−1
1
}
Since ∇f2 = ∇f (X2) =
{−1
−1
}
and ||∇f2|| = 1.4142 > ε, we proceed to update the
matrix [Bi] by computing
g1 = ∇f2 − ∇f1 =
{
−1
−1
}
−
{
1
−1
}
=
{
−2
0
}
d1 = λ∗1S1 = 1
{
−1
1
}
=
{
−1
1
}
d1d
T
1 =
{
−1
1
}
{−1 1} =
[
1 −1
−1 1
]
dT1 g1 = {−1 1}
{
−2
0
}
= 2
d1g
T
1 =
{
−1
1
}
{−2 0} =
[
2 0
−2 0
]
g1d
T
1 =
{
−2
0
}
{−1 1} =
[
2 −2
0 0
]
gT1 [B1]g1 = {−2 0}
[
1 0
0 1
]{
−2
0
}
= {−2 0}
{
−2
0
}
= 4
d1g
T
1 [B1] =
[
2 0
−2 0
] [
1 0
0 1
]
=
[
2 0
−2 0
]
[B1]g1d
T
1 =
[
1 0
0 1
] [
2 −2
0 0
]
=
[
2 −2
0 0
]
Equation (6.136) gives
[B2]| =
[
1 0
0 1
]
+
(
1 + 4
2
)
1
2
[
1 −1
−1 1
]
− 1
2
[
2 0
−2 0
]
− 1
2
[
2 −2
0 0
]
=
[
1 0
0 1
]
+
[
3
2
− 3
2
− 3
2
3
2
]
−
[
1 0
−1 0
]
−
[
1 −1
0 0
]
=
[
1
2
− 1
2
− 1
2
5
2
]
6.16 Test Functions 363
Iteration 2 (i = 2)
The next search direction is determined as
S2 = −[B2]∇f2 = −
[
1
2
− 1
2
− 1
2
5
2
]
{
−1
−1
}
=
{
0
2
}
To find the minimizing step length λ∗2 along S2, we minimize
f (X2 + λ2S2) = f
({
−1
1
}
+ λ2
{
0
2
})
= f (−1, 1 + 2λ2) = 4λ22 − 2λ2 − 1
with respect to λ2. Since df/dλ2 = 0 at λ∗2 =
1
4
, we obtain
X3 = X2 + λ∗2S2 =
{
−1
1
}
+ 1
4
{
0
2
}
=
{
−1
3
2
}
This point can be identified to be optimum since
∇f3 =
{
0
0
}
and ||∇f3|| = 0 < ε
6.16 TEST FUNCTIONS
The efficiency of an optimization algorithm is studied using a set of standard func-
tions. Several functions, involving different number of variables, representing a variety
of complexities have been used as test functions. Almost all the test functions pre-
sented in the literature are nonlinear least squares; that is, each function can be
represented as
f (x1, x2, . . . , xn) =
m
∑
i=1
fi(x1, x2, . . . , xn)
2 (6.139)
where n denotes the number of variables and m indicates the number of functions (fi)
that define the least-squares problem. The purpose of testing the functions is to show
how well the algorithm works compared to other algorithms. Usually, each test function
is minimized from a standard starting point. The total number of function evaluations
required to find the optimum solution is usually taken as a measure of the efficiency of
the algorithm. References [6.29] to [6.32] present a comparative study of the various
unconstrained optimization techniques. Some of the commonly used test functions are
given below.
1. Rosenbrock’s parabolic valley [6.8]:
f (x1, x2) = 100(x2 − x21)2 + (1 − x1)2 (6.140)
X1 =
{
−1.2
1.0
}
, X∗ =
{
1
1
}
f1 = 24.0, f ∗ = 0.0
364 Nonlinear Programming II: Unconstrained Optimization Techniques
2. A quadratic function:
f (x1, x2) = (x1 + 2x2 − 7)2 + (2x1 + x2 − 5)2 (6.141)
X1 =
{
0
0
}
, X∗ =
{
1
3
}
f1 = 7.40, f ∗ = 0.0
3. Powell’s quartic function [6.7]:
f (x1, x2, x3, x4) = (x1 + 10x2)2 + 5(x3 − x4)2
+ (x2 − 2x3)4 + 10(x1 − x4)4 (6.142)
XT1 = {x1 x2 x3 x4}1 = {3 − 1 0 1} , X∗T = {0 0 0 0}
f1 = 215.0, f ∗ = 0.0
4. Fletcher and Powell’s helical valley [6.21]:
f (x1, x2, x3) = 100
{
[x3 − 10θ(x1, x2)]2 + [
√
x21 + x22 − 1]
2
}
+ x23 (6.143)
where
2πθ(x1, x2) =







arctan
x2
x1
if x1>0
π + arctan x2
x1
if x1<0
X1 =



−1
0
0



, X∗ =



1
0
0



f1 = 25,000.0, f ∗ = 0.0
5. A nonlinear function of three variables [6.7]:
f (x1, x2, x3) =
1
1 + (x1 − x2)2
+ sin
(
1
2
πx2x3
)
+ exp
[
−
(
x1 + x3
x2
− 2
)2
]
(6.144)
X1 =



0
1
2



, X∗ =



1
1
1



f1 = 1.5, f ∗ = fmax = 3.0
6. Freudenstein and Roth function [6.27]:
f (x1, x2) = {−13 + x1 + [(5 − x2)x2 − 2]x2}2
+ {−29 + x1 + [(x2 + 1)x2 − 14]x2}2 (6.145)
6.17 MATLAB Solution of Unconstrained Optimization Problems 365
X1 =
{
0.5
−2
}
, X∗ =
{
5
4
}
, X∗alternate =
{
11.41 . . .
−0.8968 . . .
}
f1 = 400.5, f ∗ = 0.0, f ∗alternate = 48.9842 . . .
7. Powell’s badly scaled function [6.28]:
f (x1, x2) = (10,000x1x2 − 1)2 + [exp(−x1) + exp(−x2) − 1.0001]2 (6.146)
X1 =
{
0
1
}
, X∗ =
{
1.098 . . . × 10−5
9.106 . . .
}
f1 = 1.1354, f * = 0.0
8. Brown’s badly scaled function [6.29]:
f (x1, x2) = (x1 − 106)2 + (x2 − 2 × 10−6)2 + (x1x2 − 2)2 (6.147)
X1 =
{
1
1
}
, X∗ =
{
106
2 × 10−6
}
f1 ≈ 1012, f ∗ = 0.0
9. Beale’s function [6.29]:
f (x1, x2) = [1.5 − x1(1 − x2)]2 + [2.25 − x1(1 − x22)]2
+ [2.625 − x1(1 − x32 )]2 (6.148)
X1 =
{
1
1
}
, X∗ =
{
3
0.5
}
f1 = 14.203125, f ∗ = 0.0
10. Wood’s function [6.30]:
f (x1, x2, x3, x4) = [10(x2 − x21)]2 + (1 − x1)2 + 90(x4 − x23)2
+ (1 − x3)2 + 10(x2 + x4 − 2)2 + 0.1(x2 − x4) (6.149)
X1 =







−3
−1
−3
−1







, X∗ =







1
1
1
1







f1 = 19192.0, f ∗ = 0.0
6.17 MATLAB SOLUTION OF UNCONSTRAINED OPTIMIZATION
PROBLEMS
The solution of multivariable unconstrained minimization problems using the MATLAB
function fminunc is illustrated in this section.
Example 6.17 Find the minimum of the Rosenbrock’s parabolic valley function, given
by Eq. (6.140), starting from initial point X1 = {−1.2 1.0}T.
366 Nonlinear Programming II: Unconstrained Optimization Techniques
SOLUTION
Step 1: Write an M-file objfun.m for the objective function.
function f= objfun (x)
f= 100* (x(2)-x(1) *x(1))^2+(1-x(1))^2;
Step 2: Invoke unconstrained optimization program (write this in new MATLAB file).
clc
clear all
warning off
x0 = [-1.2,1.0]; % Starting guess
fprintf ('The values of function value at starting
pointn');
f=objfun(x0)
options = optimset('LargeScale', 'off');
[x, fval] = fminunc (@objfun,x0,options)
This produces the solution or ouput as follows:
The values of function value at starting point
f=
24.2000
Optimization terminated: relative infinity-norm of gradi-
ent less than options.TolFun.
x=
1.0000 1.0000
fval=
2.8336e-011
REFERENCES AND BIBLIOGRAPHY
6.1 S. S. Rao, The Finite Element Method in Engineering , 4th ed., Elsevier Butterworth
Heinemann, Burlington, MA, 2005.
6.2 T. F. Edgar and D. M. Himmelblau, Optimization of Chemical Processes , McGraw-Hill,
New York, 1988.
6.3 R. L. Fox, Optimization Methods for Engineering Design , Addison-Wesley, Reading, MA,
1971.
6.4 W. E. Biles and J. J. Swain, Optimization and Industrial Experimentation , Wiley, New
York, 1980.
6.5 C. R. Hicks, Fundamental Concepts in the Design of Experiments , Saunders College
Publishing, Fort Worth, TX, 1993.
6.6 R. Hooke and T. A. Jeeves, Direct search solution of numerical and statistical problems,
Journal of the ACM , Vol. 8, No. 2, pp. 212–229, 1961.
6.7 M.J.D. Powell, An efficient method for finding the minimum of a function of several
variables without calculating derivatives, Computer Journal , Vol. 7, No. 4, pp. 303–307,
1964.
References and Bibliography 367
6.8 H. H. Rosenbrock, An automatic method for finding the greatest or least value of a
function, Computer Journal , Vol. 3, No. 3, pp. 175–184, 1960.
6.9 S. S. Rao, Optimization: Theory and Applications , 2nd ed., Wiley Eastern, New Delhi,
1984.
6.10 W. Spendley, G. R. Hext, and F. R. Himsworth, Sequential application of simplex designs
in optimization and evolutionary operation, Technometrics , Vol. 4, p. 441, 1962.
6.11 J. A. Nelder and R. Mead, A simplex method for function minimization, Computer Jour-
nal , Vol. 7, p. 308, 1965.
6.12 A. L. Cauchy, Méthode générale pour la résolution des systèmes d’équations simultanées,
Comptes Rendus de l’Academie des Sciences , Paris, Vol. 25, pp. 536–538, 1847.
6.13 R. Fletcher and C. M. Reeves, Function minimization by conjugate gradients, Computer
Journal , Vol. 7, No. 2, pp. 149–154, 1964.
6.14 M. R. Hestenes and E. Stiefel, Methods of Conjugate Gradients for Solving Linear Sys-
tems , Report 1659, National Bureau of Standards, Washington, DC, 1952.
6.15 D. Marquardt, An algorithm for least squares estimation of nonlinear parameters, SIAM
Journal of Applied Mathematics , Vol. 11, No. 2, pp. 431–441, 1963.
6.16 C. G. Broyden, Quasi-Newton methods and their application to function minimization,
Mathematics of Computation , Vol. 21, p. 368, 1967.
6.17 C. G. Broyden, J. E. Dennis, and J. J. More, On the local and superlinear convergence of
quasi-Newton methods, Journal of the Institute of Mathematics and Its Applications , Vol.
12, p. 223, 1975.
6.18 H. Y. Huang, Unified approach to quadratically convergent algorithms for function min-
imization, Journal of Optimization Theory and Applications , Vol. 5, pp. 405–423, 1970.
6.19 J. E. Dennis, Jr., and J. J. More, Quasi-Newton methods, motivation and theory, SIAM
Review , Vol. 19, No. 1, pp. 46–89, 1977.
6.20 W. C. Davidon, Variable Metric Method of Minimization , Report ANL-5990, Argonne
National Laboratory, Argonne, IL, 1959.
6.21 R. Fletcher and M.J.D. Powell, A rapidly convergent descent method for minimization,
Computer Journal , Vol. 6, No. 2, pp. 163–168, 1963.
6.22 G. G. Broyden, The convergence of a class of double-rank minimization algorithms, Parts
I and II, Journal of the Institute of Mathematics and Its Applications , Vol. 6, pp. 76–90,
222-231, 1970.
6.23 R. Fletcher, A new approach to variable metric algorithms, Computer Journal , Vol. 13,
pp. 317–322, 1970.
6.24 D. Goldfarb, A family of variable metric methods derived by variational means, Mathe-
matics of Computation , Vol. 24, pp. 23–26, 1970.
6.25 D. F. Shanno, Conditioning of quasi-Newton methods for function minimization, Math-
ematics of Computation , Vol. 24, pp. 647–656, 1970.
6.26 M.J.D. Powell, An iterative method for finding stationary values of a function of several
variables, Computer Journal , Vol. 5, pp. 147–151, 1962.
6.27 F. Freudenstein and B. Roth, Numerical solution of systems of nonlinear equations, Jour-
nal of ACM , Vol. 10, No. 4, pp. 550–556, 1963.
6.28 M.J.D. Powell, A hybrid method for nonlinear equations, pp. 87–114 in Numerical Meth-
ods for Nonlinear Algebraic Equations , P. Rabinowitz, Ed., Gordon & Breach, New York,
1970.
6.29 J. J. More, B. S. Garbow, and K. E. Hillstrom, Testing unconstrained optimization soft-
ware, ACM Transactions on Mathematical Software, Vol. 7, No. 1, pp. 17–41, 1981.
368 Nonlinear Programming II: Unconstrained Optimization Techniques
6.30 A. R. Colville, A Comparative Study of Nonlinear Programming Codes , Report 320-2949,
IBM New York Scientific Center, 1968.
6.31 E. D. Eason and R. G. Fenton, A comparison of numerical optimization methods for
engineering design, ASME Journal of Engineering Design , Vol. 96, pp. 196–200, 1974.
6.32 R.W.H. Sargent and D. J. Sebastian, Numerical experience with algorithms for uncon-
strained minimization, pp. 45–113 in Numerical Methods for Nonlinear Optimization ,
F. A. Lootsma, Ed., Academic Press, London, 1972.
6.33 D. F. Shanno, Recent advances in gradient based unconstrained optimization techniques
for large problems, ASME Journal of Mechanisms, Transmissions, and Automation in
Design , Vol. 105, pp. 155–159, 1983.
6.34 S. S. Rao, Mechanical Vibrations , 4th ed., Pearson Prentice Hall, Upper Saddle River,
NJ, 2004.
6.35 R. T. Haftka and Z. Gürdal, Elements of Structural Optimization , 3rd ed., Kluwer Aca-
demic, Dordrecht, The Netherlands, 1992.
6.36 J. Kowalik and M. R. Osborne, Methods for Unconstrained Optimization Problems , Amer-
ican Elsevier, New York, 1968.
REVIEW QUESTIONS
6.1 State the necessary and sufficient conditions for the unconstrained minimum of a function.
6.2 Give three reasons why the study of unconstrained minimization methods is important.
6.3 What is the major difference between zeroth-, first-, and second-order methods?
6.4 What are the characteristics of a direct search method?
6.5 What is a descent method?
6.6 Define each term:
(a) Pattern directions
(b) Conjugate directions
(c) Simplex
(d) Gradient of a function
(e) Hessian matrix of a function
6.7 State the iterative approach used in unconstrained optimization.
6.8 What is quadratic convergence?
6.9 What is the difference between linear and superlinear convergence?
6.10 Define the condition number of a square matrix.
6.11 Why is the scaling of variables important?
6.12 What is the difference between random jumping and random walk methods?
6.13 Under what conditions are the processes of reflection, expansion, and contraction used in
the simplex method?
6.14 When is the grid search method preferred in minimizing an unconstrained function?
6.15 Why is a quadratically convergent method considered to be superior for the minimization
of a nonlinear function?
Review Questions 369
6.16 Why is Powell’s method called a pattern search method?
6.17 What are the roles of univariate and pattern moves in the Powell’s method?
6.18 What is univariate method?
6.19 Indicate a situation where a central difference formula is not as accurate as a forward
difference formula.
6.20 Why is a central difference formula more expensive than a forward or backward difference
formula in finding the gradient of a function?
6.21 What is the role of one-dimensional minimization methods in solving an unconstrained
minimization problem?
6.22 State possible convergence criteria that can be used in direct search methods.
6.23 Why is the steepest descent method not efficient in practice, although the directions used
are the best directions?
6.24 What are rank 1 and rank 2 updates?
6.25 How are the search directions generated in the Fletcher–Reeves method?
6.26 Give examples of methods that require n2, n, and 1 one-dimensional minimizations for
minimizing a quadratic in n variables.
6.27 What is the reason for possible divergence of Newton’s method?
6.28 Why is a conjugate directions method preferred in solving a general nonlinear problem?
6.29 What is the difference between Newton and quasi-Newton methods?
6.30 What is the basic difference between DFP and BFGS methods?
6.31 Why are the search directions reset to the steepest descent directions periodically in the
DFP method?
6.32 What is a metric? Why is the DFP method considered as a variable metric method?
6.33 Answer true or false:
(a) A conjugate gradient method can be called a conjugate directions method.
(b) A conjugate directions method can be called a conjugate gradient method.
(c) In the DFP method, the Hessian matrix is sequentially updated directly.
(d) In the BFGS method, the inverse of the Hessian matrix is sequentially updated.
(e) The Newton method requires the inversion of an n × n matrix in each iteration.
(f) The DFP method requires the inversion of an n × n matrix in each iteration.
(g) The steepest descent directions are the best possible directions.
(h) The central difference formula always gives a more accurate value of the gradient
than does the forward or backward difference formula.
(i) Powell’s method is a conjugate directions method.
(j) The univariate method is a conjugate directions method.
370 Nonlinear Programming II: Unconstrained Optimization Techniques
PROBLEMS
6.1 A bar is subjected to an axial load, P0, as shown in Fig. 6.17. By using a one-finite-element
model, the axial displacement, u(x), can be expressed as [6.1]
u(x) = {N1(x) N2(x)}
{
u1
u2
}
where Ni(x) are called the shape functions:
N1(x) = 1 −
x
l
, N2(x) =
x
l
and u1 and u2 are the end displacements of the bar. The deflection of the bar at point
Q can be found by minimizing the potential energy of the bar (f ), which can be
expressed as
f =
1
2
∫ l
0
EA
(
∂u
∂x
)2
dx − P0u2
where E is Young’s modulus and A is the cross-sectional area of the bar. Formulate the
optimization problem in terms of the variables u1 and u2 for the case P0l/EA = 1.
6.2 The natural frequencies of the tapered cantilever beam (ω) shown in Fig. 6.18, based on
the Rayleigh-Ritz method, can be found by minimizing the function [6.34]:
f (c1, c2) =
Eh3
3l2
(
c21
4
+
c22
10
+ c1c2
5
)
ρhl
(
c21
30
+
c22
280
+
2c1c2
105
)
with respect to c1 and c2, where f = ω2, E is Young’s modulus, and ρ is the density.
Plot the graph of 3fρl3/Eh2 in (c1, c2) space and identify the values of ω1 and ω2.
6.3 The Rayleigh’s quotient corresponding to the three-degree-of-freedom spring–mass sys-
tem shown in Fig. 6.19 is given by [6.34]
R(X) = X
T [K]X
XT [M]X
where
[K] = k


2 −1 0
−1 2 −1
0 −1 1

 , [M] =


1 0 0
0 1 0
0 0 1

 , X =



x1
x2
x3



It is known that the fundamental natural frequency of vibration of the system can be
found by minimizing R(X). Derive the expression of R(X) in terms of x1, x2, and x3 and
suggest a suitable method for minimizing the function R(X).
Figure 6.17 Bar subjected to an axial load.
Problems 371
Figure 6.18 Tapered cantilever beam.
Figure 6.19 Three-degree-of-freedom spring–mass system.
6.4 The steady-state temperatures at points 1 and 2 of the one-dimensional fin (x1 and x2)
shown in Fig. 6.20 correspond to the minimum of the function [6.1]:
f (x1, x2) = 0.6382x21 + 0.3191x22 − 0.2809x1x2
− 67.906x1 − 14.290x2
Plot the function f in the (x1, x2) space and identify the steady-state temperatures of
points 1 and 2 of the fin.
372 Nonlinear Programming II: Unconstrained Optimization Techniques
Figure 6.20 Straight fin.
6.5 Figure 6.21 shows two bodies, A and B, connected by four linear springs. The springs are
at their natural positions when there is no force applied to the bodies. The displacements
x1 and x2 of the bodies under any applied force can be found by minimizing the potential
energy of the system. Find the displacements of the bodies when forces of 1000 lb and
2000 lb are applied to bodies A and B, respectively, using Newton’s method. Use the
starting vector, X1 =
{
0
0
}
. Hint:
Potential energy of the system = strain energy of springs − potential of applied loads
where the strain energy of a spring of stiffness k and end displacements x1 and x2 is
given by 1
2
k(x2 − x1)2 and the potential of the applied force, Fi , is given by xiFi .
6.6 The potential energy of the two-bar truss shown in Fig. 6.22 under the applied load P is
given by
f (x1, x2) =
EA
s
(
l
2s
)2
x21 +
EA
s
(
h
s
)2
x22 − Px1 cos θ − Px2 sin θ
where E is Young’s modulus, A the cross-sectional area of each member, l the span of
the truss, s the length of each member, h the depth of the truss, θ the angle at which load
is applied, x1 the horizontal displacement of free node, and x2 the vertical displacement
of the free node.
(a) Simplify the expression of f for the data E = 207 × 109 Pa, A = 10−5 m2, l = 1.5 m,
h = 4 m, P = 10,000 N, and θ = 30◦.
Figure 6.21 Two bodies connected by springs.
Problems 373
q
Figure 6.22 Two-bar truss.
(b) Find the steepest descent direction, S1, of f at the trial vector X1 =
{
0
0
}
.
(c) Derive the one-dimensional minimization problem, f (λ), at X1 along the direction
S1.
(d) Find the optimal step length λ∗ using the calculus method and find the new design
vector X2.
6.7 Three carts, interconnected by springs, are subjected to the loads P1, P2, and P3 as shown
in Fig. 6.23. The displacements of the carts can be found by minimizing the potential
energy of the system (f ):
f (X) = 1
2
XT[K]X − XTP
where
[K] =


k1 + k4 + k5 −k4 −k5
−k4 k2 + k4 + k6 −k6
−k5 −k6 k3 + k5 + k6 + k7 + k8


P =





P1
P2
P3





and X =





x1
x2
x3





Derive the function f (x1, x2, x3) for the following data: k1 = 5000 N/m , k2 = 1500 N/m,
k3 = 2000 N/m, k4 = 1000 N/m, k5 = 2500 N/m, k6 = 500 N/m, k7 = 3000 N/m, k8 =
3500 N/m, P1 = 1000 N, P2 = 2000 N, and P3 = 3000 N. Complete one iteration of
Newton’s method and find the equilibrium configuration of the carts. Use X1 = {0 0 0}T.
6.8 Plot the contours of the following function over the region (−5 ≤ x1 ≤ 5,−3 ≤ x2 ≤ 6)
and identify the optimum point:
f (x1, x2) = (x1 + 2x2 − 7)2 + (2x1 + x2 − 5)2
374 Nonlinear Programming II: Unconstrained Optimization Techniques
Figure 6.23 Three carts interconnected by springs.
6.9 Plot the contours of the following function in the two dimensional (x1, x2) space over the
region (−4 ≤ x1 ≤ 4,−3 ≤ x2 ≤ 6) and identify the optimum point:
f (x1, x2) = 2(x2 − x21 )2 + (1 − x1)2
6.10 Consider the problem
f (x1, x2) = 100(x2 − x21 )2 + (1 − x1)2
Plot the contours of f over the region (−4 ≤ x1 ≤ 4,−3 ≤ x2 ≤ 6) and identify the
optimum point.
6.11 It is required to find the solution of a system of linear algebraic equations given by
[A]X = b, where [A] is a known n × n symmetric positive-definite matrix and b is an
n-component vector of known constants. Develop a scheme for solving the problem as
an unconstrained minimization problem.
6.12 Solve the following equations using the steepest descent method (two iterations only)
with the starting point, X1 = {0 0 0}:
2x1 + x2 = 4, x1 + 2x2 + x3 = 8, x2 + 3x3 = 11
6.13 An electric power of 100 MW generated at a hydroelectric power plant is to be transmitted
400 km to a stepdown transformer for distribution at 11 kV. The power dissipated due to
the resistance of conductors is i2c−1, where i is the line current in amperes and c is the
conductance in mhos. The resistance loss, based on the cost of power delivered, can be
expressed as 0.15i2c−1 dollars. The power transmitted (k) is related to the transmission
line voltage at the power plant (e) by the relation k =
√
3ei, where e is in kilovolts. The
cost of conductors is given by 2c millions of dollars, and the investment in equipment
needed to accommodate the voltage e is given by 500e dollars. Find the values of e and
c to minimize the total cost of transmission using Newton’s method (one iteration only).
6.14 Find a suitable transformation of variables to reduce the condition number of the Hessian
matrix of the following function to one:
f = 2x21 + 16x22 − 2x1x2 − x1 − 6x2 − 5
Problems 375
6.15 Find a suitable transformation or scaling of variables to reduce the condition number of
the Hessian matrix of the following function to one:
f = 4x21 + 3x22 − 5x1x2 − 8x1 + 10
6.16 Determine whether the following vectors serve as conjugate directions for minimizing the
function f = 2x21 + 16x22 − 2x1x2 − x1 − 6x2 − 5.
(a) S1 =
{
15
−1
}
, S2 =
{
1
1
}
(b) S1 =
{
−1
15
}
, S2 =
{
1
1
}
6.17 Consider the problem:
Minimize f = x1 − x2 + 2x21 + 2x1x2 + x22
Find the solution of this problem in the range −10 ≤ xi ≤ 10, i = 1, 2, using the random
jumping method. Use a maximum of 10,000 function evaluations.
6.18 Consider the problem:
Minimize f = 6x21 − 6x1x2 + 2x22 − x1 − 2x2
Find the minimum of this function in the range −5 ≤ xi ≤ 5, i = 1, 2, using the random
walk method with direction exploitation.
6.19 Find the condition number of each matrix.
(a) [A] =
[
1 2
1.0001 2
]
(b) [B] =
[
3.9 1.6
6.8 2.9
]
6.20 Perform two iterations of the Newton’s method to minimize the function
f (x1, x2) = 100(x2 − x21 )2 + (1 − x1)2
from the starting point
{−1.2
1.0
}
.
6.21 Perform two iterations of univariate method to minimize the function given in Prob-
lem 6.20 from the stated starting vector.
6.22 Perform four iterations of Powell’s method to minimize the function given in Problem
6.20 from the stated starting point.
6.23 Perform two iterations of the steepest descent method to minimize the function given in
Problem 6.20 from the stated starting point.
6.24 Perform two iterations of the Fletcher–Reeves method to minimize the function given in
Problem 6.20 from the stated starting point.
6.25 Perform two iterations of the DFP method to minimize the function given in Problem
6.20 from the stated starting vector.
6.26 Perform two iterations of the BFGS method to minimize the function given in Problem
6.20 from the indicated starting point.
376 Nonlinear Programming II: Unconstrained Optimization Techniques
6.27 Perform two iterations of the Marquardt’s method to minimize the function given in
Problem 6.20 from the stated starting point.
6.28 Prove that the search directions used in the Fletcher–Reeves method are [A]-conjugate
while minimizing the function
f (x1, x2) = x21 + 4x22
6.29 Generate a regular simplex of size 4 in a two-dimensional space using each base point:
(a)
{
4
−3
}
(b)
{
1
1
}
(c)
{
−1
−2
}
6.30 Find the coordinates of the vertices of a simplex in a three-dimensional space such that
the distance between vertices is 0.3 and one vertex is given by (2, −1, −8).
6.31 Generate a regular simplex of size 3 in a three-dimensional space using each base point.
(a)



0
0
0



(b)



4
3
2



(c)



1
−2
3



6.32 Find a vector S2 that is conjugate to the vector
S1 =



2
−3
6



with respect to the matrix:
[A] =


1 2 3
2 5 6
3 6 9


6.33 Compare the gradients of the function f (X) = 100(x2 − x21 )2 + (1 − x1)2 at X =
{
0.5
0.5
}
given by the following methods:
(a) Analytical differentiation
(b) Central difference method
(c) Forward difference method
(d) Backward difference method
Use a perturbation of 0.005 for x1 and x2 in the finite-difference methods.
6.34 It is required to evaluate the gradient of the function
f (x1, x2) = 100(x2 − x21 )2 + (1 − x1)2
at point X =
{
0.5
0.5
}
using a finite-difference scheme. Determine the step size 
x to be
used to limit the error in any of the components, ∂f/∂xi , to 1 % of the exact value, in
the following methods:
(a) Central difference method
(b) Forward difference method
(c) Backward difference method
Problems 377
6.35 Consider the minimization of the function
f = 1
x21 + x22 + 2
Perform one iteration of Newton’s method from the starting point X1 =
{
4
0
}
using
Eq. (6.86). How much improvement is achieved with X2?
6.36 Consider the problem:
Minimize f = 2(x1 − x21 )2 + (1 − x1)2
If a base simplex is defined by the vertices
X1 =
{
0
0
}
, X2 =
{
1
0
}
, X3 =
{
0
1
}
find a sequence of four improved vectors using reflection, expansion, and/or contraction.
6.37 Consider the problem:
Minimize f = (x1 + 2x2 − 7)2 + (2x1 + x2 − 5)2
If a base simplex is defined by the vertices
X1 =
{
−2
−2
}
, X2 =
{
−3
0
}
, X3 =
{
−1
−1
}
find a sequence of four improved vectors using reflection, expansion, and/or contraction.
6.38 Consider the problem:
f = 100(x2 − x21 )2 + (1 − x1)2
Find the solution of the problem using grid search with a step size 
xi = 0.1 in the range
−3 ≤ xi ≤ 3, i = 1, 2.
6.39 Show that the property of quadratic convergence of conjugate directions is independent
of the order in which the one-dimensional minimizations are performed by considering
the minimization of
f = 6x21 + 2x22 − 6x1x2 − x1 − 2x2
using the conjugate directions S1 =
{
1
2
}
and S2 =
{
1
0
}
and the starting point X1 =
{
0
0
}
.
6.40 Show that the optimal step length λ∗i that minimizes f (X) along the search direction
Si = −∇fi is given by Eq. (6.75).
6.41 Show that β2 in Eq. (6.76) is given by Eq. (6.77).
6.42 Minimize f = 2x21 + x22 from the starting point (1, 2) using the univariate method (two
iterations only).
6.43 Minimize f = 2x21 + x22 by using the steepest descent method with the starting point
(1, 2) (two iterations only).
6.44 Minimize f = x21 + 3x22 + 6x23 by the Newton’s method using the starting point as
(2,−1, 1).
378 Nonlinear Programming II: Unconstrained Optimization Techniques
6.45 Minimize f = 4x21 + 3x22 − 5x1x2 − 8x1 starting from point (0, 0) using Powell’s method.
Perform four iterations.
6.46 Minimize f (x1, x2) = x41 − 2x21x2 + x21 + x22 + 2x1 + 1 by the simplex method. Perform
two steps of reflection, expansion, and/or contraction.
6.47 Solve the following system of equations using Newton’s method of unconstrained mini-
mization with the starting point
X1 =



0
0
0



2x1 − x2 + x3 = −1, x1 + 2x2 = 0, 3x1 + x2 + 2x3 = 3
6.48 It is desired to solve the following set of equations using an unconstrained optimization
method:
x2 + y2 = 2, 10x2 − 10y − 5x + 1 = 0
Formulate the corresponding problem and complete two iterations of optimization using
the DFP method starting from X1 =
{
0
0
}
.
6.49 Solve Problem 6.48 using the BFGS method (two iterations only).
6.50 The following nonlinear equations are to be solved using an unconstrained optimization
method:
2xy = 3, x2 − y = 2
Complete two one-dimensional minimization steps using the univariate method starting
from the origin.
6.51 Consider the two equations
7x3 − 10x − y = 1, 8y3 − 11y + x = 1
Formulate the problem as an unconstrained optimization problem and complete two steps
of the Fletcher–Reeves method starting from the origin.
6.52 Solve the equations 5x1 + 3x2 = 1 and 4x1 − 7x2 = 76 using the BFGS method with the
starting point (0, 0).
6.53 Indicate the number of one-dimensional steps required for the minimization of the function
f = x21 + x22 − 2x1 − 4x2 + 5 according to each scheme:
(a) Steepest descent method
(b) Fletcher–Reeves method
(c) DFP method
(d) Newton’s method
(e) Powell’s method
(f) Random search method
(g) BFGS method
(h) Univariate method
Problems 379
6.54 Same as Problem 6.53 for the following function:
f = (x2 − x21 )2 + (1 − x1)2
6.55 Verify whether the following search directions are [A]-conjugate while minimizing the
function
f = x1 − x2 + 2x21 + 2x1x2 + x22
(a) S1 =
{
−1
1
}
, S2 =
{
1
0
}
(b) S1 =
{
−1
1
}
, S2 =
{
0
1
}
6.56 Solve the equations x1 + 2x2 + 3x3 = 14, x1 − x2 + x3 = 1, and 3x1 − 2x2 + x3 = 2
using Marquardt’s method of unconstrained minimization. Use the starting point
X1 = {0, 0, 0}T.
6.57 Apply the simplex method to minimize the function f given in Problem 6.20. Use the
point (−1.2, 1.0) as the base point to generate an initial regular simplex of size 2 and go
through three steps of reflection, expansion, and/or contraction.
6.58 Write a computer program to implement Powell’s method using the golden section method
of one-dimensional search.
6.59 Write a computer program to implement the Davidon–Fletcher–Powell method using the
cubic interpolation method of one-dimensional search. Use a finite-difference scheme to
evaluate the gradient of the objective function.
6.60 Write a computer program to implement the BFGS method using the cubic interpolation
method of one-dimensional minimization. Use a finite-difference scheme to evaluate the
gradient of the objective function.
6.61 Write a computer program to implement the steepest descent method of unconstrained
minimization with the direct root method of one-dimensional search.
6.62 Write a computer program to implement the Marquardt method coupled with the direct
root method of one-dimensional search.
6.63 Find the minimum of the quadratic function given by Eq. (6.141) starting from the solution
X1 = {0, 0}T using MATLAB.
6.64 Find the minimum of the Powell’s quatic function given by Eq. (6.142) starting from the
solution X1 = {3,−1, 0, 1}T using MATLAB.
6.65 Find the minimum of the Fletcher and Powell’s helical valley function given by Eq.
(6.143) starting from the solution X1 = {−1, 0, 0}T using MATLAB.
6.66 Find the minimum of the nonlinear function given by Eq. (6.144) starting from the solution
X1 = {0, 1, 2}T using MATLAB.
6.67 Find the minimum of the Wood’s function given by Eq. (6.149) starting from the solution
X1 = {−3,−1,−3,−1}T using MATLAB.
7
Nonlinear Programming III:
Constrained Optimization
Techniques
7.1 INTRODUCTION
This chapter deals with techniques that are applicable to the solution of the constrained
optimization problem:
Find X which minimizes f (X)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m
hk(X) = 0, k = 1, 2, . . . , p (7.1)
There are many techniques available for the solution of a constrained nonlinear pro-
gramming problem. All the methods can be classified into two broad categories: direct
methods and indirect methods, as shown in Table 7.1. In the direct methods , the con-
straints are handled in an explicit manner, whereas in most of the indirect methods , the
constrained problem is solved as a sequence of unconstrained minimization problems.
We discuss in this chapter all the methods indicated in Table 7.1.
7.2 CHARACTERISTICS OF A CONSTRAINED PROBLEM
In the presence of constraints, an optimization problem may have the following features
[7.1, 7.51]:
1. The constraints may have no effect on the optimum point; that is, the constrained
minimum is the same as the unconstrained minimum as shown in Fig. 7.1. In
this case the minimum point X∗ can be found by making use of the necessary
and sufficient conditions
∇f |X∗ = 0 (7.2)
JX∗ =
[
∂2f
∂xi∂xj
]
X∗
= positive definite (7.3)
380 Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
7.2 Characteristics of a Constrained Problem 381
Table 7.1 Constrained Optimization Techniques
Direct methods Indirect methods
Random search methods Transformation of variables technique
Heuristic search methods Sequential unconstrained minimization
Complex method techniques
Objective and constraint approximation Interior penalty function method
methods Exterior penalty function method
Sequential linear programming method Augmented Lagrange multiplier method
Sequential quadratic programming method
Methods of feasible directions
Zoutendijk’s method
Rosen’s gradient projection method
Generalized reduced gradient method
Figure 7.1 Constrained and unconstrained minima are the same (linear constraints).
However, to use these conditions, one must be certain that the constraints are not
going to have any effect on the minimum. For simple optimization problems like
the one shown in Fig. 7.1, it may be possible to determine beforehand whether
or not the constraints have an influence on the minimum point. However, in
most practical problems, even if we have a situation as shown in Fig. 7.1, it will
be extremely difficult to identify it. Thus one has to proceed with the general
assumption that the constraints have some influence on the optimum point.
2. The optimum (unique) solution occurs on a constraint boundary as shown in
Fig. 7.2. In this case the Kuhn–Tucker necessary conditions indicate that the
negative of the gradient must be expressible as a positive linear combination of
the gradients of the active constraints.
382 Nonlinear Programming III: Constrained Optimization Techniques
Figure 7.2 Constrained minimum occurring on a nonlinear constraint.
3. If the objective function has two or more unconstrained local minima, the con-
strained problem may have multiple minima as shown in Fig. 7.3.
4. In some cases, even if the objective function has a single unconstrained
minimum, the constraints may introduce multiple local minima as shown in
Fig. 7.4.
A constrained optimization technique must be able to locate the minimum in all the
situations outlined above.
Figure 7.3 Relative minima introduced by objective function.
7.3 Random Search Methods 383
Figure 7.4 Relative minima introduced by constraints.
Direct Methods
7.3 RANDOM SEARCH METHODS
The random search methods described for unconstrained minimization (Section 6.2)
can be used, with minor modifications, to solve a constrained optimization problem.
The basic procedure can be described by the following steps:
1. Generate a trial design vector using one random number for each design variable.
2. Verify whether the constraints are satisfied at the trial design vector. Usually,
the equality constraints are considered satisfied whenever their magnitudes lie
within a specified tolerance. If any constraint is violated, continue generating
new trial vectors until a trial vector that satisfies all the constraints is found.
3. If all the constraints are satisfied, retain the current trial vector as the best
design if it gives a reduced objective function value compared to the previous
best available design. Otherwise, discard the current feasible trial vector and
proceed to step 1 to generate a new trial design vector.
4. The best design available at the end of generating a specified maximum number
of trial design vectors is taken as the solution of the constrained optimization
problem.
It can be seen that several modifications can be made to the basic procedure indicated
above. For example, after finding a feasible trial design vector, a feasible direction can
be generated (using random numbers) and a one-dimensional search can be conducted
along the feasible direction to find an improved feasible design vector.
384 Nonlinear Programming III: Constrained Optimization Techniques
Another procedure involves constructing an unconstrained function, F(X), by
adding penalty for violating any constraint as (as described in Section 7.12):
F(X) = f (X) + a
m
∑
j=1
[Gj (X)]
2 + b
p
∑
k=1
[Hk(X)]
2 (7.4)
where
[Gj (X)]
2 = [max(0, gj (X))]2 (7.5)
[Hk(X)]
2 = h2k(X) (7.6)
indicate the squares of violations of inequality and equality constraints, respectively,
and a and b are constants. Equation (7.4) indicates that while minimizing the objective
function f (X), a positive penalty is added whenever a constraint is violated, the penalty
being proportional to the square of the amount of violation. The values of the constants
a and b can be adjusted to change the contributions of the penalty terms relative to the
magnitude of the objective function.
Note that the random search methods are not efficient compared to the other meth-
ods described in this chapter. However, they are very simple to program and usually
are reliable in finding a nearly optimal solution with a sufficiently large number of
trial vectors. Also, these methods can find near global optimal solution even when the
feasible region is nonconvex.
7.4 COMPLEX METHOD
In 1965, Box extended the simplex method of unconstrained minimization (discussed
in Section 6.7) to solve constrained minimization problems of the type [7.2]:
Minimize f (X) (7.7a)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m (7.7b)
x
(l)
i ≤ xi ≤ x
(u)
i , i = 1, 2, . . . , n (7.7c)
In general, the satisfaction of the side constraints (lower and upper bounds on the
variables xi) may not correspond to the satisfaction of the constraints gj (X) ≤ 0. This
method cannot handle nonlinear equality constraints. The formation of a sequence of
geometric figures each having k = n + 1 vertices in an n-dimensional space (called
the simplex ) is the basic idea in the simplex method. In the complex method also,
a sequence of geometric figures each having k ≥ n + 1 vertices is formed to find the
constrained minimum point. The method assumes that an initial feasible point X1 (which
satisfies all the m constraints) is available.
Iterative Procedure
1. Find k ≥ n + 1 points, each of which satisfies all m constraints. In actual prac-
tice, we start with only one feasible point X1, and the remaining k − 1 points
7.4 Complex Method 385
are found one at a time by the use of random numbers generated in the range
0 to 1, as
xi,j = x(l)i + ri,j (x
(u)
i − x
(l)
i ), i = 1, 2, . . . , n, j = 2, 3, . . . , k (7.8)
where xi,j is the ith component of the point Xj , and ri,j is a random number
lying in the interval (0, 1). It is to be noted that the points X2, X3, . . . , Xk
generated according to Eq. (7.8) satisfy the side constraints, Eqs. (7.7c) but
may not satisfy the constraints given by Eqs. (7.7b).
As soon as a new point Xj is generated (j = 2, 3, . . . , k), we find whether
it satisfies all the constraints, Eqs. (7.7b). If Xj violates any of the constraints
stated in Eqs. (7.7b), the trial point Xj is moved halfway toward the centroid
of the remaining, already accepted points (where the given initial point X1 is
included). The centroid X0 of already accepted points is given by
X0 =
1
j − 1
j−1
∑
l=1
Xl (7.9)
If the trial point Xj so found still violates some of the constraints, Eqs. (7.7b),
the process of moving halfway in toward the centroid X0 is continued until
a feasible point Xj is found. Ultimately, we will be able to find a feasible
point Xj by this procedure provided that the feasible region is convex. By
proceeding in this way, we will ultimately be able to find the required feasible
points X2, X3, . . . , Xk .
2. The objective function is evaluated at each of the k points (vertices). If the
vertex Xh corresponds to the largest function value, the process of reflection is
used to find a new point Xr as
Xr = (1 + α)X0 − αXh (7.10)
where α ≥ 1 (to start with) and X0 is the centroid of all vertices except Xh:
X0 =
1
k − 1
k
∑
l=1
l =k
Xl (7.11)
3. Since the problem is a constrained one, the point Xr has to be tested for feasi-
bility. If the point Xr is feasible and f (Xr) < f (Xh), the point Xh is replaced
by Xr , and we go to step 2. If f (Xr) ≥ f (Xh), a new trial point Xr is found
by reducing the value of α in Eq. (7.10) by a factor of 2 and is tested for
the satisfaction of the relation f (Xr) < f (Xh). If f (Xr) ≥ f (Xh), the proce-
dure of finding a new point Xr with a reduced value of α is repeated again.
This procedure is repeated, if necessary, until the value of α becomes smaller
than a prescribed small quantity ε, say, 10−6. If an improved point Xr , with
f (Xr) < f (Xh), cannot be obtained even with that small value of α, the point
Xr is discarded and the entire procedure of reflection is restarted by using the
point Xp (which has the second-highest function value) instead of Xh.
386 Nonlinear Programming III: Constrained Optimization Techniques
4. If at any stage, the reflected point Xr (found in step 3) violates any of the
constraints [Eqs. (7.7b)], it is moved halfway in toward the centroid until it
becomes feasible, that is,
(Xr)new = 12 (X0 + Xr) (7.12)
This method will progress toward the optimum point as long as the complex
has not collapsed into its centroid.
5. Each time the worst point Xh of the current complex is replaced by a new
point, the complex gets modified and we have to test for the convergence of the
process. We assume convergence of the process whenever the following two
conditions are satisfied:
(a) The complex shrinks to a specified small size (i.e., the distance between
any two vertices among X1, X2, . . . , Xk becomes smaller than a prescribed
small quantity, ε1.
(b) The standard deviation of the function value becomes sufficiently small
(i.e., when



1
k
k
∑
j=1
[f (X) − f (Xj )]2



1/2
≤ ε2 (7.13)
where X is the centroid of all the k vertices of the current complex, and
ε2 > 0 is a specified small number).
Discussion. This method does not require the derivatives of f (X) and gj (X) to find
the minimum point, and hence it is computationally very simple. The method is very
simple from programming point of view and does not require a large computer storage.
1. A value of 1.3 for the initial value of α in Eq. (7.10) has been found to be
satisfactory by Box.
2. Box recommended a value of k ≃ 2n (although a lesser value can be chosen
if n is greater than, say, 5). If k is not sufficiently large, the complex tends to
collapse and flatten along the first constraint boundary encountered.
3. From the procedure above, it can be observed that the complex rolls over and
over, normally expanding. However, if a boundary is encountered, the complex
contracts and flattens itself. It can then roll along this constraint boundary and
leave it if the contours change. The complex can also accommodate more than
one boundary and can turn corners.
4. If the feasible region is nonconvex, there is no guarantee that the centroid of all
feasible points is also feasible. If the centroid is not feasible, we cannot apply
the procedure above to find the new points Xr .
5. The method becomes inefficient rapidly as the number of variables increases.
6. It cannot be used to solve problems having equality constraints.
7. This method requires an initial point X1 that is feasible. This is not a major
restriction. If an initial feasible point is not readily available, the method
described in Section 7.13 can be used to find a feasible point X1.
7.5 Sequential Linear Programming 387
7.5 SEQUENTIAL LINEAR PROGRAMMING
In the sequential linear programming (SLP) method , the solution of the original nonlin-
ear programming problem is found by solving a series of linear programming problems.
Each LP problem is generated by approximating the nonlinear objective and constraint
functions using first-order Taylor series expansions about the current design vector, Xi .
The resulting LP problem is solved using the simplex method to find the new design
vector Xi+1. If Xi+1 does not satisfy the stated convergence criteria, the problem is
relinearized about the point Xi+1 and the procedure is continued until the optimum
solution X∗ is found.
If the problem is a convex programming problem, the linearized constraints always
lie entirely outside the feasible region. Hence the optimum solution of the approximating
LP problem, which lies at a vertex of the new feasible region, will lie outside the
original feasible region. However, by relinearizing the problem about the new point
and repeating the process, we can achieve convergence to the solution of the original
problem in few iterations. The SLP method, also known as the cutting plane method ,
was originally presented by Cheney and Goldstein [7.3] and Kelly [7.4].
Algorithm. The SLP algorithm can be stated as follows:
1. Start with an initial point X1 and set the iteration number as i = 1. The point
X1 need not be feasible.
2. Linearize the objective and constraint functions about the point Xi as
f (X) ≈ f (Xi) + ∇f (Xi)T(X − Xi) (7.14)
gj (X) ≈ gj (Xi) + ∇gj (Xi)T(X − Xi) (7.15)
hk(X) ≈ hk(Xi) + ∇hk(Xi)T(X − Xi) (7.16)
3. Formulate the approximating linear programming problem as†
Minimize f (Xi) + ∇f Ti (X − Xi)
subject to
gj (Xi) + ∇gj (Xi)T (X − Xi) ≤ 0, j = 1, 2, . . . , m
hk(Xi) + ∇hk(Xi)T (X − Xi) = 0, k = 1, 2, . . . , p (7.17)
4. Solve the approximating LP problem to obtain the solution vector Xi+1.
5. Evaluate the original constraints at Xi+1; that is, find
gj (Xi+1), j = 1, 2, . . . , m and hk(Xi+1), k = 1, 2, . . . , p
†Notice that the LP problem stated in Eq. (7.17) may sometimes have an unbounded solution. This can be
avoided by formulating the first approximating LP problem by considering only the following constraints:
li ≤ xi ≤ ui, i = 1, 2, . . . , n (7.18)
In Eq. (7.18), li and ui represent the lower and upper bounds on xi , respectively. The values of li and
ui depend on the problem under consideration, and their values have to be chosen such that the optimum
solution of the original problem does not fall outside the range indicated by Eq. (7.18).
388 Nonlinear Programming III: Constrained Optimization Techniques
If gj (Xi+1) ≤ ε for j = 1, 2, . . . , m, and |hk(Xi+1)| ≤ ε, k = 1, 2, . . . , p,
where ε is a prescribed small positive tolerance, all the original constraints can
be assumed to have been satisfied. Hence stop the procedure by taking
Xopt ≃ Xi+1
If gj (Xi+1) > ε for some j , or |hk(Xi+1)| >ε for some k, find the most violated
constraint, for example, as
gk(Xi+1) = max
j
[gj (Xi+1)] (7.19)
Relinearize the constraint gk(X) ≤ 0 about the point Xi+1 as
gk(X) ≃ gk(Xi+1) + ∇gk(Xi+1)T(X − Xi+1) ≤ 0 (7.20)
and add this as the (m + 1)th inequality constraint to the previous LP problem.
6. Set the new iteration number as i = i + 1, the total number of constraints in
the new approximating LP problem as m + 1 inequalities and p equalities, and
go to step 4.
The sequential linear programming method has several advantages:
1. It is an efficient technique for solving convex programming problems with
nearly linear objective and constraint functions.
2. Each of the approximating problems will be a LP problem and hence can be
solved quite efficiently. Moreover, any two consecutive approximating LP prob-
lems differ by only one constraint, and hence the dual simplex method can be
used to solve the sequence of approximating LP problems much more effi-
ciently.†
3. The method can easily be extended to solve integer programming problems. In
this case, one integer LP problem has to be solved in each stage.
Geometric Interpretation of the Method. The SLP method can be illustrated with
the help of a one-variable problem:
Minimize f (x) = c1x
subject to
g(x) ≤ 0 (7.21)
where c1 is a constant and g(x) is a nonlinear function of x. Let the feasible region and
the contour of the objective function be as shown in Fig. 7.5. To avoid any possibility
of unbounded solution, let us first take the constraints on x as c ≤ x ≤ d , where c and
d represent the lower and upper bounds on x. With these constraints, we formulate the
LP problem:
Minimize f (x) = c1x
†The dual simplex method was discussed in Section 4.3.
7.5 Sequential Linear Programming 389
Figure 7.5 Graphical representation of the problem stated by Eq. (7.21).
subject to
c ≤ x ≤ d (7.22)
The optimum solution of this approximating LP problem can be seen to be x∗ = c.
Next, we linearize the constraint g(x) about point c and add it to the previous constraint
set. Thus the new LP problem becomes
Minimize f (x) = c1x (7.23a)
subject to
c ≤ x ≤ d (7.23b)
g(c) +
dg
dx
(c)(x − c) ≤ 0 (7.23c)
The feasible region of x, according to the constraints (7.23b) and (7.23c), is given by
e ≤ x ≤ d (Fig. 7.6). The optimum solution of the approximating LP problem given
by Eqs. (7.23) can be seen to be x∗ = e. Next, we linearize the constraint g(x) ≤ 0
about the current solution x∗ = e and add it to the previous constraint set to obtain the
next approximating LP problem as
Minimize f (x) = c1x (7.24a)
subject to
c ≤ x ≤ d (7.24b)
390 Nonlinear Programming III: Constrained Optimization Techniques
Figure 7.6 Linearization of constraint about c.
g(c) + dg
dx
(c)(x − c) ≤ 0 (7.24c)
g(e) +
dg
dx
(e)(x − e) ≤ 0 (7.24d )
The permissible range of x, according to the constraints (7.24b), (7.24c), and (7.24d),
can be seen to be f ≤ x ≤ d from Fig. 7.7. The optimum solution of the LP problem
of Eqs. (7.24) can be obtained as x∗ = f .
We then linearize g(x) ≤ 0 about the present point x∗ = f and add it to the
previous constraint set [Eqs. (7.24)] to define a new approximating LP problem. This
procedure has to be continued until the optimum solution is found to the desired level of
accuracy. As can be seen from Figs. 7.6 and 7.7, the optimum of all the approximating
LP problems (e.g., points c, e, f, . . .) lie outside the feasible region and converge toward
the true optimum point, x = a. The process is assumed to have converged whenever
the solution of an approximating problem satisfies the original constraint within some
specified tolerance level as
g(x∗k ) ≤ ε
where ε is a small positive number and x∗k is the optimum solution of the kth approx-
imating LP problem. It can be seen that the lines (hyperplanes in a general problem)
defined by g(x∗k ) + dg/dx(x∗k )(x − x∗k ) cut off a portion of the existing feasible region.
Hence this method is called the cutting plane method .
7.5 Sequential Linear Programming 391
Figure 7.7 Linearization of constraint about e.
Example 7.1
Minimize f (x1, x2) = x1 − x2
subject to
g1(x1, x2) = 3x21 − 2x1x2 + x22 − 1 ≤ 0
using the cutting plane method. Take the convergence limit in step 5 as ε = 0.02.
Note: This example was originally given by Kelly [7.4]. Since the constraint
boundary represents an ellipse, the problem is a convex programming problem. From
graphical representation, the optimum solution of the problem can be identified as
x∗1 = 0, x∗2 = 1, and fmin = −1.
SOLUTION
Steps 1, 2, 3: Although we can start the solution from any initial point X1, to avoid
the possible unbounded solution, we first take the bounds on x1 and x2
as −2 ≤ x1 ≤ 2 and −2 ≤ x2 ≤ 2 and solve the following LP problem:
Minimize f = x1 − x2
392 Nonlinear Programming III: Constrained Optimization Techniques
subject to
− 2 ≤ x1 ≤ 2
− 2 ≤ x2 ≤ 2 (E1)
The solution of this problem can be obtained as
X =
[
−2
2
]
with f (X) = −4
Step 4: Since we have solved one LP problem, we can take
Xi+1 = X2 =
{
−2
2
}
Step 5: Since g1(X2) = 23 >ε, we linearize g1(X) about point X2 as
g1(X) ≃ g1(X2) + ∇g1(X2)T(X − X2) ≤ 0 (E2)
As
g1(X2) = 23,
∂g1
∂x1
∣
∣
∣
∣
X2
= (6x1 − 2x2)|X2 = −16
∂g1
∂x2
∣
∣
∣
∣
X2
= (−2x1 + 2x2)|X2 = 8
Eq. (E2) becomes
g1(X) ≃ −16x1 + 8x2 − 25 ≤ 0
By adding this constraint to the previous LP problem, the new LP prob-
lem becomes
Minimize f = x1 − x2
subject to
−2 ≤ x1 ≤ 2
−2 ≤ x2 ≤ 2 (E3)
−16x1 + 8x2 − 25 ≤ 0
Step 6: Set the iteration number as i = 2 and go to step 4.
Step 4: Solve the approximating LP problem stated in Eqs. (E3) and obtain the
solution
X3 =
{
−0.5625
2.0
}
with f3 = f (X3) = −2.5625
This procedure is continued until the specified convergence criterion,
g1(Xi) ≤ ε, in step 5 is satisfied. The computational results are summa-
rized in Table 7.2.
7.6 Basic Approach in the Methods of Feasible Directions 393
Table 7.2 Results for Example 7.1
Solution of the
Iteration New linearized approximating LP
number, constraint problem
i considered Xi+1 f (Xi+1) g1(Xi+1)
1 −2 ≤ x1 ≤ 2 and
−2 ≤ x2 ≤ 2
(−2.0, 2.0) −4.00000 23.00000
2 −16.0x1 + 8.0x2 − 25.0 ≤ 0 (−0.56250, 2.00000) −2.56250 6.19922
3 −7.375x1 + 5.125x2
−8.19922 ≤ 0
(0.27870, 2.00000) −1.72193 2.11978
4 −2.33157x1 + 3.44386x2
−4.11958 ≤ 0
(−0.52970, 0.83759) −1.36730 1.43067
5 −4.85341x1 + 2.73459x2
−3.43067 ≤ 0
(−0.05314, 1.16024) −1.21338 0.47793
6 −2.63930x1 + 2.42675x2
−2.47792 ≤ 0
(0.42655, 1.48490) −1.05845 0.48419
7 −0.41071x1 + 2.11690x2
−2.48420 ≤ 0
(0.17058, 1.20660) −1.03603 0.13154
8 −1.38975x1 + 2.07205x2
−2.13155 ≤ 0
(0.01829, 1.04098) −1.02269 0.04656
9 −1.97223x1 + 2.04538x2
−2.04657 ≤ 0
(−0.16626, 0.84027) −1.00653 0.06838
10 −2.67809x1 + 2.01305x2
−2.06838 ≤ 0
(−0.07348, 0.92972) −1.00321 0.01723
7.6 BASIC APPROACH IN THE METHODS OF FEASIBLE
DIRECTIONS
In the methods of feasible directions, basically we choose a starting point satisfying all
the constraints and move to a better point according to the iterative scheme
Xi+1 = Xi + λSi (7.25)
where Xi is the starting point for the ith iteration, Si the direction of movement, λ
the distance of movement (step length), and Xi+1 the final point obtained at the end
of the ith iteration. The value of λ is always chosen so that Xi+1 lies in the feasible
region. The search direction Si is found such that (1) a small move in that direction
violates no constraint, and (2) the value of the objective function can be reduced in
that direction. The new point Xi+1 is taken as the starting point for the next iteration
and the entire procedure is repeated several times until a point is obtained such that
no direction satisfying both properties 1 and 2 can be found. In general, such a point
denotes the constrained local minimum of the problem. This local minimum need not
be a global one unless the problem is a convex programming problem. A direction
satisfying property 1 is called feasible while a direction satisfying both properties 1
and 2 is called a usable feasible direction . This is the reason that these methods are
394 Nonlinear Programming III: Constrained Optimization Techniques
known as methods of feasible directions . There are many ways of choosing usable
feasible directions, and hence there are many different methods of feasible directions.
As seen in Chapter 2, a direction S is feasible at a point Xi if it satisfies the relation
d
dλ
gj (Xi + λS)|λ=0 = ST∇gj (Xi) ≤ 0 (7.26)
where the equality sign holds true only if a constraint is linear or strictly concave,
as shown in Fig. 2.8. A vector S will be a usable feasible direction if it satisfies the
relations
d
dλ
f (Xi + λS)|λ=0 = ST∇f (Xi) < 0 (7.27)
d
dλ
gj (Xi + λS)|λ=0 = ST∇gj (Xi) ≤ 0 (7.28)
It is possible to reduce the value of the objective function at least by a small amount
by taking a step length λ > 0 along such a direction.
The detailed iterative procedure of the methods of feasible directions will be con-
sidered in terms of two well-known methods: Zoutendijk’s method of feasible directions
and Rosen’s gradient projection method.
7.7 ZOUTENDIJK’S METHOD OF FEASIBLE DIRECTIONS
In Zoutendijk’s method of feasible directions , the usable feasible direction is taken as
the negative of the gradient direction if the initial point of the iteration lies in the
interior (not on the boundary) of the feasible region. However, if the initial point
lies on the boundary of the feasible region, some constraints will be active and the
usable feasible direction is found so as to satisfy Eqs. (7.27) and (7.28). The iterative
procedure of Zoutendijk’s method can be stated as follows (only inequality constraints
are considered in Eq. (7.1), for simplicity.
Algorithm
1. Start with an initial feasible point X1 and small numbers ε1, ε2, and ε3 to test
the convergence of the method. Evaluate f (X1) and gj (X1), j = 1, 2, . . . ,m.
Set the iteration number as i = 1.
2. If gj (Xi) < 0, j = 1, 2, . . . , m (i.e., Xi is an interior feasible point), set the
current search direction as
Si = −∇f (Xi) (7.29)
Normalize Si in a suitable manner and go to step 5. If at least one gj (Xi) = 0,
go to step 3.
3. Find a usable feasible direction S by solving the direction-finding problem:
Minimize − α (7.30a)
7.7 Zoutendijk’s Method of Feasible Directions 395
subject to
ST∇gj (Xi) + θjα ≤ 0, j = 1, 2, . . . , p (7.30b)
ST∇f + α ≤ 0 (7.30c)
− 1 ≤ si ≤ 1, i = 1, 2, . . . , n (7.30d )
where si is the ith component of S, the first p constraints have been assumed
to be active at the point Xi (the constraints can always be renumbered to satisfy
this requirement), and the values of all θj can be taken as unity. Here α can be
taken as an additional design variable.
4. If the value of α∗ found in step 3 is very nearly equal to zero, that is, if α∗ ≤ ε1,
terminate the computation by taking Xopt ≃ Xi . If α∗ >ε1, go to step 5 by taking
Si = S.
5. Find a suitable step length λi along the direction Si and obtain a new point
Xi+1 as
Xi+1 = Xi + λiSi (7.31)
The methods of finding the step length λi will be considered later.
6. Evaluate the objective function f (Xi+1).
7. Test for the convergence of the method. If
∣
∣
∣
∣
f (Xi) − f (Xi+1)
f (Xi)
∣
∣
∣
∣
≤ ε2 and ||Xi − Xi+1|| ≤ ε3 (7.32)
terminate the iteration by taking Xopt ≃ Xi+1. Otherwise, go to step 8.
8. Set the new iteration number as i = i + 1, and repeat from step 2 onward.
There are several points to be considered in applying this algorithm. These are
related to (1) finding an appropriate usable feasible direction (S), (2) finding a suitable
step size along the direction S, and (3) speeding up the convergence of the process.
All these aspects are discussed below.
7.7.1 Direction-Finding Problem
If the point Xi lies in the interior of the feasible region [i.e., gj (Xi) < 0 for j =
1, 2, . . . , m], the usable feasible direction is taken as
Si = −∇f (Xi) (7.33)
The problem becomes complicated if one or more of the constraints are critically
satisfied at Xi , that is, when some of the gj (Xi) = 0. One simple way to find a usable
feasible direction at a point Xi at which some of the constraints are active is to generate
a random vector and verify whether it satisfies Eqs. (7.27) and (7.28). This approach
is a crude one but is very simple and easy to program. The relations to be checked for
each random vector are also simple, and hence it will not require much computer time.
However, a more systematic procedure is generally adopted to find a usable feasible
direction in practice. Since there will be, in general, several directions that satisfy
396 Nonlinear Programming III: Constrained Optimization Techniques
Eqs. (7.27) and (7.28), one would naturally be tempted to choose the “best” possible
usable feasible direction at Xi .
Thus we seek to find a feasible direction that, in addition to decreasing the value
of f , also points away from the boundaries of the active nonlinear constraints. Such a
direction can be found by solving the following optimization problem. Given the point
Xi , find the vector S and the scalar α that maximize α subject to the constraints
ST∇gj (Xi) + θjα ≤ 0, j ∈ J (7.34)
ST∇f (Xi) + α ≤ 0 (7.35)
where J represents the set of active constraints and S is normalized by one of the
following relations:
STS =
n
∑
i=1
s2i = 1 (7.36)
−1 ≤ si ≤ 1, i = 1, 2, . . . , n (7.37)
ST∇f (Xi) ≤ 1 (7.38)
In this problem, θj are arbitrary positive scalar constants, and for simplicity, we can
take all θj = 1. Any solution of this problem with α > 0 is a usable feasible direction.
The maximum value of α gives the best direction (S) that makes the value of ST∇fi
negative and the values of ST∇gj (Xi) as negative as possible simultaneously. In other
words, the maximum value of α makes the direction S steer away from the active
nonlinear constraint boundaries. It can easily be seen that by giving different values for
different θj , we can give more importance to certain constraint boundaries compared to
others. Equations (7.36) to (7.38) represent the normalization of the vector S so as to
ensure that the maximum of α will be a finite quantity. If the normalization condition
is not included, the maximum of α may be made to approach ∞ without violating the
constraints [Eqs. (7.34) and (7.35)].
Notice that the objective function α, and the constraint equations (7.34) and (7.35)
are linear in terms of the variables s1, s2, . . . , sn, α. The normalization constraint will
also be linear if we use either Eq. (7.37) or (7.38). However, if we use Eq. (7.36)
for normalization, it will be a quadratic function. Thus the direction-finding problem
can be posed as a linear programming problem by using either Eq. (7.37) or (7.38)
for normalization. Even otherwise, the problem will be a LP problem except for one
quadratic constraint. It was shown by Zoutendijk [7.5] that this problem can be han-
dled by a modified version of linear programming. Thus the direction-finding problem
can be solved with reasonable efficiency. We use Eq. (7.37) in our presentation. The
direction-finding problem can be stated more explicitly as
Minimize − α
subject to
s1
∂g1
∂x1
+ s2
∂g1
∂x2
+ · · · + sn
∂g1
∂xn
+ θ1α ≤ 0
7.7 Zoutendijk’s Method of Feasible Directions 397
s1
∂g2
∂x1
+ s2
∂g2
∂x2
+ · · · + sn
∂g2
∂xn
+ θ2α ≤ 0
...
s1
∂gp
∂x1
+ s2
∂gp
∂x2
+ · · · + sn
∂gp
∂xn
+ θpα ≤ 0 (7.39)
s1
∂f
∂x1
+ s2
∂f
∂x2
+ · · · + sn
∂f
∂xn
+ α ≤ 0
s1 − 1 ≤ 0
s2 − 1 ≤ 0
...
sn − 1 ≤ 0
−1 − s1 ≤ 0
−1 − s2 ≤ 0
...
−1 − sn ≤ 0
where p is the number of active constraints and the partial derivatives ∂g1/∂x1, ∂g1/∂x2,
. . . , ∂gp/∂xn, ∂f/∂x1, . . . , ∂f/∂xn have been evaluated at point Xi . Since the com-
ponents of the search direction, si , i = 1 to n, can take any value between −1 and 1,
we define new variables ti as ti = si + 1, i = 1 to n, so that the variables will always
be nonnegative. With this change of variables, the problem above can be restated as
a standard linear programming problem as follows:
Find (t1, t2, . . . , tn, α, y1, y2, . . . , yp+n+1) which
minimizes − α
subject to
t1
∂g1
∂x1
+ t2
∂g1
∂x2
+ · · · + tn
∂g1
∂xn
+ θ1α + y1 =
n
∑
i=1
∂g1
∂xi
t1
∂g2
∂x1
+ t2
∂g2
∂x2
+ · · · + tn
∂g2
∂xn
+ θ2α + y2 =
n
∑
i=1
∂g2
∂xi
...
t1
∂gp
∂x1
+ t2
∂gp
∂x2
+ · · · + tn
∂gp
∂xn
+ θpα + yp =
n
∑
i=1
∂gp
∂xi
(7.40)
398 Nonlinear Programming III: Constrained Optimization Techniques
t1
∂f
∂x1
+ t2
∂f
∂x2
+ · · · + tn
∂f
∂xn
+ α + yp+1 =
n
∑
i=1
∂f
∂xi
t1 + yp+2 = 2
t2 + yp+3 = 2
...
tn + yp+n+1 = 2
t1 ≥ 0
t2 ≥ 0
...
tn ≥ 0
α ≥ 0
where y1, y2, . . . , yp+n+1 are the nonnegative slack variables. The simplex method
discussed in Chapter 3 can be used to solve the direction-finding problem stated in
Eqs. (7.40). This problem can also be solved by more sophisticated methods that treat
the upper bounds on ti in a special manner instead of treating them as constraints
[7.6]. If the solution of the direction-finding problem gives a value of α∗ > 0, f (X)
can be improved by moving along the usable feasible direction
S =









s1
s2
...
sn









=











t∗1 − 1
t∗2 − 1
...
t∗n − 1











If, however, α∗ = 0, it can be shown that the Kuhn–Tucker optimality conditions are
satisfied at Xi and hence point Xi can be taken as the optimal solution.
7.7.2 Determination of Step Length
After finding a usable feasible direction Si at any point Xi , we have to determine a
suitable step length λi to obtain the next point Xi+1 as
Xi+1 = Xi + λiSi (7.41)
There are several ways of computing the step length. One of the methods is to determine
an optimal step length (λi) that minimizes f (Xi + λSi) such that the new point Xi+1
given by Eq. (7.41) lies in the feasible region. Another method is to choose the step
length (λi) by trial and error so that it satisfies the relations
f (Xi + λiSi) ≤ f (Xi)
gj (Xi + λiSi) ≤ 0, j = 1, 2, . . . , m
(7.42)
7.7 Zoutendijk’s Method of Feasible Directions 399
Method 1. The optimal step length, λi , can be found by any of the one-dimensional
minimization methods described in Chapter 5. The only drawback with these methods
is that the constraints will not be considered while finding λi . Thus the new point
Xi+1 = Xi + λiSi may lie either in the interior of the feasible region (Fig. 7.8a), or on
the boundary of the feasible region (Fig. 7.8b), or in the infeasible region (Fig. 7.8c).
If the point Xi+1 lies in the interior of the feasible region, there are no active
constraints and hence we proceed to the next iteration by setting the new usable feasible
direction as Si+1 = −∇f (Xi+1) (i.e., we go to step 2 of the algorithm). On the other
hand, if Xi+1 lies on the boundary of the feasible region, we generate a new usable
feasible direction S = Si+1 by solving a new direction-finding problem (i.e., we go to
step 3 of the algorithm). One practical difficulty has to be noted at this stage. To detect
that point Xi+1 is lying on the constraint boundary, we have to find whether one or
more gj (Xi+1) are zero. Since the computations are done numerically, will we say that
Figure 7.8 Effect of taking optimal step length.
400 Nonlinear Programming III: Constrained Optimization Techniques
the constraint gj is active if gj (Xi+1) = 10−2, 10−3, 10−8, and so on? We immediately
notice that a small margin ε has to be specified to detect an active constraint. Thus we
can accept a point X to be lying on the constraint boundary if |gj (X)| ≤ ε where ε is
a prescribed small number. If point Xi+1 lies in the infeasible region, the step length
has to be reduced (corrected) so that the resulting point lies in the feasible region only.
It is to be noted that an initial trial step size (ε1) has to be specified to initiate the
one-dimensional minimization process.
Method 2. Even if we do not want to find the optimal step length, some sort of
a trial-and-error method has to be adopted to find the step length λi so as to satisfy
the relations (7.42). One possible method is to choose an arbitrary step length ε and
compute the values of
f̃ = f (Xi + εSi) and g̃j = gj (Xi + εSi)
Depending on the values of f̃ and g̃j , we may need to adjust the value of ε until we
improve the objective function value without violating the constraints.
Initial Trial Step Length. It can be seen that in whatever way we want to find the
step size λi , we need to specify an initial trial step length ε. The value of ε can be
chosen in several ways. Some of the possibilities are given below.
1. The average of the final step lengths λi obtained in the last few iterations can
be used as the initial trial step length ε for the next step. Although this method
is often satisfactory, it has a number of disadvantages:
(a) This method cannot be adopted for the first iteration.
(b) This method cannot take care of the rate of variation of f (X) in different
directions.
(c) This method is quite insensitive to rapid changes in the step length that take
place generally as the optimum point is approached.
2. At each stage, an initial step length ε is calculated so as to reduce the objective
function value by a given percentage. For doing this, we can approximate the
behavior of the function f (λ) to be linear in λ. Thus if
f (Xi) = f (λ = 0) = f1 (7.43)
df
dλ
(Xi) =
df
dλ
(Xi + λSi)
∣
∣
∣
∣
λ=0
= ST∇fi = f ′1 (7.44)
are known to us, the linear approximation of f (λ) is given by
f (λ) ≃ f1 + f ′1λ
To obtain a reduction of δ% in the objective function value compared to |f1|,
the step length λ = ε is given by
f1 + f ′1ε = f1 −
δ
100
|f1|
7.7 Zoutendijk’s Method of Feasible Directions 401
that is,
ε = −
δ
100
|f1|
f ′1
(7.45)
It is to be noted that the value of ε will always be positive since f ′1 given in
Eq. (7.44) is always negative. This method yields good results if the percentage
reduction (δ) is restricted to small values on the order of 1 to 5.
7.7.3 Termination Criteria
In steps 4 and 5 of the algorithm, the optimization procedure is assumed to have
converged whenever the maximum value of α(α∗) becomes approximately zero and
the results of the current iteration satisfy the relations stated in Eq. (7.32). In addition,
one can always test the Kuhn–Tucker necessary conditions before terminating the
procedure.
However, we can show that if the Kuhn–Tucker conditions are satisfied, the value
of α∗ will become zero. The Kuhn–Tucker conditions are given by
∇f +
p
∑
j=1
λj∇gj = 0 (7.46)
λj > 0, = 1, 2, . . . , p (7.47)
where the first p constraints are assumed to be the active constraints. Equation (7.46)
gives
ST∇f = −
p
∑
j=1
λj S
T∇gj > 0 (7.48)
if S is a usable feasible direction. Thus if the Kuhn–Tucker conditions are satisfied at
a point Xi , we will not be able to find any search direction S that satisfies the strict
inequalities in the relations
ST∇gj ≤ 0, j = 1, 2, . . . , p
ST∇f ≤ 0 (7.49)
However, these relations can be satisfied with strict equality sign by taking the trivial
solution S = 0, which means that the value of α∗ in the direction-finding problem,
Eqs. (7.39), is zero. Some modifications and accelerating techniques have been sug-
gested to improve the convergence of the algorithm presented in this section and the
details can be found in Refs. [7.7] and [7.8].
Example 7.2
Minimize f (x1, x2) = x21 + x22 − 4x1 − 4x2 + 8
subject to
g1(x1, x2) = x1 + 2x2 − 4 ≤ 0
with the starting point X1 =
{
0
0
}
. Take ε1 = 0.001, ε2 = 0.001, and ε3 = 0.01.
402 Nonlinear Programming III: Constrained Optimization Techniques
SOLUTION
Step 1: At X1 =
{
0
0
}
:
f (X1) = 8 and g1(X1) = −4
Iteration 1
Step 2: Since g1(X1) < 0, we take the search direction as
S1 = −∇f (X1) = −
{
∂f/∂x1
∂f/∂x2
}
X1
=
{
4
4
}
This can be normalized to obtain S1 =
{
1
1
}
.
Step 5: To find the new point X2, we have to find a suitable step length along S1. For
this, we choose to minimize f (X1 + λS1) with respect to λ. Here
f (X1 + λS1) = f (0 + λ, 0 + λ) = 2λ2 − 8λ + 8
df
dλ
= 0 at λ = 2
Thus the new point is given by X2 =
{
2
2
}
and g1(X2) = 2. As the constraint is
violated, the step size has to be corrected.
As g′1 = g1|λ=0 = −4 and g′′1 = g1|λ=2 = 2, linear interpolation gives the
new step length as
λ̃ = −
g′1
g′′1 − g′1
λ =
4
3
This gives g1|λ=λ̃ = 0 and hence X2 =
{
4
3
4
3
}
.
Step 6: f (X2) = 89 .
Step 7: Here
∣
∣
∣
∣
f (X1) − f (X2)
f (X1)
∣
∣
∣
∣
=
∣
∣
∣
∣
∣
8 − 8
9
8
∣
∣
∣
∣
∣
=
8
9
> ε2
||X1 − X2|| = [(0 − 43 )
2 + (0 − 4
3
)2]1/2 = 1.887 >ε2
and hence the convergence criteria are not satisfied.
Iteration 2
Step 2: As g1 = 0 at X2, we proceed to find a usable feasible direction.
Step 3: The direction-finding problem can be stated as [Eqs. (7.40)]:
Minimize f = −α
7.7 Zoutendijk’s Method of Feasible Directions 403
subject to
t1 + 2t2 + α + y1 = 3
− 4
3
t1 − 43 t2 + α + y2 = −
8
3
t1 + y3 = 2
t2 + y4 = 2
t1 ≥ 0
t2 ≥ 0
α ≥ 0
where y1 to y4 are the nonnegative slack variables. Since an initial basic feasible
solution is not readily available, we introduce an artificial variable y5 ≥ 0 into
the second constraint equation. By adding the infeasibility form w = y5, the
LP problem can be solved to obtain the solution:
t∗1 = 2, t∗2 = 310 , α
∗ = 4
10
, y∗4 =
17
10
, y∗1 = y∗2 = y∗3 = 0
−fmin = −α∗ = − 410
As α∗ > 0, the usable feasible direction is given by
S =
{
s1
s2
}
=
{
t∗1 − 1
t∗2 − 1
}
=
{
1.0
−0.7
}
Step 4: Since α∗ >ε1, we go to the next step.
Step 5: We have to move along the direction S2 =
{
1.0
−0.7
}
from the point X2 =
{
1.333
1.333
}
.
To find the minimizing step length, we minimize
f (X2 + λS2) = f (1.333 + λ, 1.333 − 0.7λ)
= 1.49λ2 − 0.4λ + 0.889
As df/dλ = 2.98λ − 0.4 = 0 at λ = 0.134, the new point is given by
X3 = X2 + λS2 =
{
1.333
1.333
}
+ 0.134
{
1.0
−0.7
}
=
{
1.467
1.239
}
At this point, the constraint is satisfied since g1(X3) = −0.055. Since point X3
lies in the interior of the feasible domain, we go to step 2.
The procedure is continued until the optimum point X∗ =
{
1.6
1.2
}
and fmin = 0.8
are obtained.
404 Nonlinear Programming III: Constrained Optimization Techniques
7.8 ROSEN’S GRADIENT PROJECTION METHOD
The gradient projection method of Rosen [7.9, 7.10] does not require the solution of an
auxiliary linear optimization problem to find the usable feasible direction. It uses the
projection of the negative of the objective function gradient onto the constraints that
are currently active. Although the method has been described by Rosen for a general
nonlinear programming problem, its effectiveness is confined primarily to problems in
which the constraints are all linear. Consider a problem with linear constraints:
Minimize f (X)
subject to
gj (X) =
n
∑
i=1
aijxi − bj ≤ 0, j = 1, 2, . . . ,m (7.50)
Let the indices of the active constraints at any point be j1, j2, . . . , jp. The gradients of
the active constraints are given by
∇gj (X) =









a1j
a2j
...
anj









, j = j1, j2, . . . , jp (7.51)
By defining a matrix N of order n × p as
N = [∇gj1∇gj2 . . . ∇gjp] (7.52)
the direction-finding problem for obtaining a usable feasible direction S can be posed
as follows.
Find S which minimizes ST ∇f (X) (7.53)
subject to
NT S = 0 (7.54)
ST S − 1 = 0 (7.55)
where Eq. (7.55) denotes the normalization of the vector S. To solve this
equality-constrained problem, we construct the Lagrangian function as
L(S, λ, β) = ST∇f (X) + λTNTS + β(STS − 1) (7.56)
where
λ =









λ1
λ2
...
λp









7.8 Rosen’s Gradient Projection Method 405
is the vector of Lagrange multipliers associated with Eqs. (7.54) and β is the Lagrange
multiplier associated with Eq. (7.55). The necessary conditions for the minimum are
given by
∂L
∂S
= ∇f (X) + Nλ + 2βS = 0 (7.57)
∂L
∂λ
= NTS = 0 (7.58)
∂L
∂β
= STS − 1 = 0 (7.59)
Equation (7.57) gives
S = − 1
2β
(∇f + Nλ) (7.60)
Substitution of Eq. (7.60) into Eq. (7.58) gives
NTS = −
1
2β
(NT∇f + NTNλ) = 0 (7.61)
If S is normalized according to Eq. (7.59), β will not be zero, and hence Eq. (7.61)
gives
NT∇f + NTNλ = 0 (7.62)
from which λ can be found as
λ = −(NTN)−1NT∇f (7.63)
This equation, when substituted in Eq. (7.60), gives
S = − 1
2β
(I − N(NTN)−1NT)∇f = − 1
2β
P∇f (7.64)
where
P = I − N(NTN)−1NT (7.65)
is called the projection matrix . Disregarding the scaling constant 2β, we can say that
the matrix P projects the vector −∇f (X) onto the intersection of all the hyperplanes
perpendicular to the vectors
∇gj , j = j1, j2, . . . , jp
We assume that the constraints gj (X) are independent so that the columns of the
matrix N will be linearly independent, and hence NTN will be nonsingular and can be
inverted. The vector S can be normalized [without having to know the value of β in
Eq. (7.64)] as
S = − P∇f
||P∇f ||
(7.66)
406 Nonlinear Programming III: Constrained Optimization Techniques
If Xi is the starting point for the ith iteration (at which gj1, gj2, . . . , gjp are critically
satisfied), we find Si from Eq. (7.66) as
Si = −
Pi∇f (Xi)
||Pi∇f (Xi)||
(7.67)
where Pi indicates the projection matrix P evaluated at the point Xi . If Si = 0, we start
from Xi and move along the direction Si to find a new point Xi+1 according to the
familiar relation
Xi+1 = Xi + λiSi (7.68)
where λi is the step length along the search direction Si . The computational details for
calculating λi will be considered later. However, if Si = 0, we have from Eqs. (7.64)
and (7.63),
−∇f (Xi) = Nλ = λ1∇gj1 + λ2∇gj2 + · · · + λp∇gjp (7.69)
where
λ = −(NTN)−1NT∇f (Xi) (7.70)
Equation (7.69) denotes that the negative of the gradient of the objective function is
given by a linear combination of the gradients of the active constraints at Xi . Further, if
all λj , given by Eq. (7.63), are nonnegative, the Kuhn–Tucker conditions [Eqs. (7.46)
and (7.47) will be satisfied and hence the procedure can be terminated.
However, if some λj are negative and Si = 0, Eq. (7.69) indicates that some
constraint normals ∇gj make an obtuse angle with −∇f at Xi . This also means
that the constraints gj , for which λj are negative, are active at Xi but should not be
considered in finding a new search direction S that will be both feasible and usable. (If
we consider all of them, the search direction S comes out to be zero.) This is illustrated
in Fig. 7.9, where the constraint normal ∇g1(Xi) should not be considered in finding
a usable feasible direction S at point Xi .
In actual practice we do not discard all the active constraints for which λj are
negative in forming the matrix N. Rather, we delete only one active constraint that
corresponds to the most negative value of λj . That is, the new N matrix is taken as
Nnew = [∇gj1 ∇gj2 · · · ∇gjq−1 ∇gjq+1 ∇gjq+2 · · · ∇gjp] (7.71)
where ∇gjq is dropped from N by assuming that λq is most negative among λj obtained
from Eq. (7.63). The new projection matrix is formed, by dropping the constraint
gjq , as
Pnew = (I − Nnew(NTnewNnew)−1NTnew) (7.72)
and the new search direction (Si)new as
(Si)new = −
Pnew∇f (Xi)
||Pnew∇f (Xi)||
(7.73)
7.8 Rosen’s Gradient Projection Method 407
Figure 7.9 Situation when Si = 0 and some λj are negative.
and this vector will be a nonzero vector in view of the new computations we have
made. The new approximation Xi+1 is found as usual by using Eq. (7.68). At the
new point Xi+1, a new constraint may become active (in Fig. 7.9, the constraint g3
becomes active at the new point Xi+1). In such a case, the new active constraint
has to be added to the set of active constraints to find the new projection matrix
at Xi+1.
We shall now consider the computational details for computing the step length λi
in Eq. (7.68).
7.8.1 Determination of Step Length
The step length λi in Eq. (7.68) may be taken as the minimizing step length λ
∗
i along
the direction Si , that is,
f (Xi + λ∗i Si) = min
λ
f (Xi + λSi) (7.74)
However, this minimizing step length λ∗i may give the point
Xi+1 = Xi + λ∗i Si
408 Nonlinear Programming III: Constrained Optimization Techniques
that lies outside the feasible region. Hence the following procedure is generally adopted
to find a suitable step length λi . Since the constraints gj (X) are linear, we have
gj (λ) = gj (Xi + λSi) =
n
∑
i=1
aij (xi + λsi) − bj
=
n
∑
i=1
aijxi − bj + λ
n
∑
i=1
aij si
= gj (Xi) + λ
n
∑
i=1
aij si, j = 1, 2, . . . , m (7.75)
where
Xi =









x1
x2
...
xn









and Si =









s1
s2
...
sn









.
This equation shows that gj (λ) will also be a linear function of λ. Thus if a particular
constraint, say the kth, is not active at Xi , it can be made to become active at the point
Xi + λkSi by taking a step length λk where
gk(λk) = gk(Xi) + λk
n
∑
i=1
aiksi = 0
that is,
λk = −
gk(Xi)
∑n
i=1 aiksi
(7.76)
Since the kth constraint is not active at Xi , the value of gk(Xi) will be negative and
hence the sign of λk will be same as that of the quantity
(
∑n
i=1 aiksi
)
. From Eqs. (7.75)
we have
dgk
dλ
(λ) =
n
∑
i=1
aiksi (7.77)
and hence the sign of λk depends on the rate of change of gk with respect to λ. If
this rate of change is negative, we will be moving away from the kth constraint in the
positive direction of λ. However, if the rate of change (dgk/dλ) is positive, we will be
violating the constraint gk if we take any step length λ larger than λk . Thus to avoid
violation of any constraint, we have to take the step length (λM) as
λM = min
λk > 0 and k
is any integer among
1to m other than
j1,j2,...,jp
(λk) (7.78)
In some cases, the function f (λ) may have its minimum along the line Si in
between λ = 0 and λ = λM . Such a situation can be detected by calculating the
7.8 Rosen’s Gradient Projection Method 409
value of
df
dλ
= STi ∇f (λ) at λ = λM
If the minimum value of λ, λ∗i , lies in between λ = 0 and λ = λM , the quantity
df/dλ(λM) will be positive. In such a case we can find the minimizing step length λ
∗
i
by interpolation or by using any of the techniques discussed in Chapter 5.
An important point to be noted is that if the step length is given by λi (not by
λ∗i ), at least one more constraint will be active at Xi+1 than at Xi . These additional
constraints will have to be considered in generating the projection matrix at Xi+1. On
the other hand, if the step length is given by λ∗i , no new constraint will be active at
Xi+1, and hence the projection matrix at Xi+1 involves only those constraints that were
active at Xi .
Algorithm. The procedure involved in the application of the gradient projection
method can be described by the following steps:
1. Start with an initial point X1. The point X1 has to be feasible, that is,
gj (X1) ≤ 0, j = 1, 2, . . . ,m
2. Set the iteration number as i = 1.
3. If Xi is an interior feasible point [i.e., if gj (Xi) < 0 for j = 1, 2, . . . , m], set
the direction of search as Si = −∇f (Xi), normalize the search direction as
Si =
−∇f (Xi)
||∇f (Xi)||
and go to step 5. However, if gj (Xi) = 0 for j = j1, j2, . . . , jp, go to step 4.
4. Calculate the projection matrix Pi as
Pi = I − Np(NTpNp)−1NTp
where
Np = [∇gj1(Xi)∇gj2(Xi) . . .∇gjp(Xi)]
and find the normalized search direction Si as
Si =
−Pi∇f (Xi)
||Pi∇f (Xi)||
5. Test whether or not Si = 0. If Si = 0, go to step 6. If Si = 0, compute the
vector λ at Xi as
λ = −(NTpNp)−1NTp∇f (Xi)
If all the components of the vector λ are nonnegative, take Xopt = Xi and stop
the iterative procedure. If some of the components of λ are negative, find the
component λq that has the most negative value and form the new matrix Np as
Np = [∇gj1 ∇gj2 · · · ∇gjq−1 ∇gjq+1 · · · ∇gjp]
and go to step 3.
410 Nonlinear Programming III: Constrained Optimization Techniques
6. If Si = 0, find the maximum step length λM that is permissible without violating
any of the constraints as λM = min(λk), λk > 0 and k is any integer among 1 to
m other than j1, j2, . . . , jp. Also find the value of df/dλ(λM ) = STi ∇f (Xi +
λMSi). If df/dλ(λM ) is zero or negative, take the step length as λi = λM . On
the other hand, if df/dλ(λM ) is positive, find the minimizing step length λ
∗
i
either by interpolation or by any of the methods discussed in Chapter 5, and
take λi = λ∗i .
7. Find the new approximation to the minimum as
Xi+1 = Xi + λiSi
If λi = λM or if λM ≤ λ∗i , some new constraints (one or more) become active
at Xi+1 and hence generate the new matrix Np to include the gradients of all
active constraints evaluated at Xi+1. Set the new iteration number as i = i + 1,
and go to step 4. If λi = λ∗i and λ∗i < λM , no new constraint will be active at
Xi+1 and hence the matrix Np remains unaltered. Set the new value of i as
i = i + 1, and go to step 3.
Example 7.3
Minimize f (x1, x2) = x21 + x22 − 2x1 − 4x2
subject to
g1(x1, x2) = x1 + 4x2 − 5 ≤ 0
g2(x1, x2) = 2x1 + 3x2 − 6 ≤ 0
g3(x1, x2) = −x1 ≤ 0
g4(x1, x2) = −x2 ≤ 0
starting from the point X1 =
{
1.0
1.0
}
.
SOLUTION
Iteration i = 1
Step 3: Since gj (X1) = 0 for j = 1, we have p = 1 and j1 = 1.
Step 4: As N1 = [∇g1(X1)] =
[
1
4
]
, the projection matrix is given by
P1 =
[
1 0
0 1
]
−
[
1
4
] [
[1 4]
[
1
4
]]−1
[1 4]
=
1
17
[
16 −4
− 4 1
]
The search direction S1 is given by
S1 = −
1
17
[
16 −4
− 4 1
]{
0
−2
}
=
{
− 8
17
2
17
}
=
{
−0.4707
0.1177
}
7.8 Rosen’s Gradient Projection Method 411
as
∇f (X1) =
{
2x1 − 2
2x2 − 4
}
X1
=
{
0
−2
}
The normalized search direction can be obtained as
S1 =
1
[(−0.4707)2 + (0.1177)2]1/2
{
−0.4707
0.1177
}
=
{
−0.9701
0.2425
}
Step 5: Since S1 = 0, we go step 6.
Step 6: To find the step length λM , we set
X =
{
x1
x2
}
= X1 + λS
=
{
1.0 − 0.9701λ
1.0 + 0.2425λ
}
For j = 2:
g2(X) = (2.0 − 1.9402λ) + (3.0 + 0.7275λ) − 6.0 = 0 at λ = λ2
= −0.8245
For j = 3:
g3(X) = −(1.0 − 0.9701λ) = 0 at λ = λ3 = 1.03
For j = 4:
g4(X) = −(1.0 + 0.2425λ) = 0 at λ = λ4 = −4.124
Therefore,
λM = λ3 = 1.03
Also,
f (X) = f (λ) = (1.0 − 0.9701λ)2 + (1.0 + 0.2425λ)2
− 2(1.0 − 0.9701λ) − 4(1.0 + 0.2425λ)
= 0.9998λ2 − 0.4850λ − 4.0
df
dλ
= 1.9996λ − 0.4850
df
dλ
(λM ) = 1.9996(1.03) − 0.4850 = 1.5746
As df/dλ(λM ) > 0, we compute the minimizing step length λ
∗
1 by setting
df/dλ = 0. This gives
λ1 = λ∗1 =
0.4850
1.9996
= 0.2425
412 Nonlinear Programming III: Constrained Optimization Techniques
Step 7: We obtain the new point X2 as
X2 = X1 + λ1S1 =
{
1.0
1.0
}
+ 0.2425
{
−0.9701
0.2425
}
=
{
0.7647
1.0588
}
Since λ1 = λ∗1 and λ∗1 < λM , no new constraint has become active at X2 and
hence the matrix N1 remains unaltered.
Iteration i = 2
Step 3: Since g1(X2) = 0, we set p = 1, j1 = 1 and go to step 4.
Step 4:
N1 =
[
1
4
]
P2 =
1
17
[
16 −4
− 4 1
]
	f (X2) =
{
2x1 − 2
2x2 − 4
}
X2
=
{
1.5294 − 2.0
2.1176 − 4.0
}
=
{
−0.4706
−1.8824
}
S2 = −P2∇f (X2) =
1
17
[
16 −4
− 4 1
]{
0.4706
1.8824
}
=
{
0.0
0.0
}
Step 5: Since S2 = 0, we compute the vector λ at X2 as
λ = −(NT1 N1)−1NT1 ∇f (X2)
= −
1
17
[1 4]
{
−0.4706
−1.8824
}
= 0.4707 > 0
The nonnegative value of λ indicates that we have reached the optimum point
and hence that
Xopt = X2 =
{
0.7647
1.0588
}
with fopt = −4.059
7.9 GENERALIZED REDUCED GRADIENT METHOD
The generalized reduced gradient (GRG) method is an extension of the reduced gradi-
ent method that was presented originally for solving problems with linear constraints
only [7.11]. To see the details of the GRG method, consider the nonlinear programming
problem:
Minimize f (X) (7.79)
subject to
hj (X) ≤ 0, j = 1, 2, . . . , m (7.80)
lk(X) = 0, k = 1, 2, . . . , l (7.81)
x
(l)
i ≤ xi ≤ x
(u)
i , i = 1, 2, . . . , n (7.82)
7.9 Generalized Reduced Gradient Method 413
By adding a nonnegative slack variable to each of the inequality constraints in
Eq. (7.80), the problem can be stated as
Minimize f (X) (7.83)
subject to
hj (X) + xn+j = 0, j = 1, 2, . . . , m (7.84)
hk(X) = 0, k = 1, 2, . . . , l (7.85)
x
(l)
i ≤ xi ≤ x
(u)
i , i = 1, 2, . . . , n (7.86)
xn+j ≥ 0, j = 1, 2, . . . , m (7.87)
with n + m variables (x1, x2, . . . , xn, xn+1, . . . , xn+m). The problem can be rewritten
in a general form as:
Minimize f (X) (7.88)
subject to
gj (X) = 0, j = 1, 2, . . . , m + l (7.89)
x
(l)
i ≤ xi ≤ x
(u)
i , i = 1, 2, . . . , n + m (7.90)
where the lower and upper bounds on the slack variable, xi , are taken as 0 and a large
number (infinity), respectively (i = n + 1, n + 2, . . . , n + m).
The GRG method is based on the idea of elimination of variables using the equality
constraints (see Section 2.4.1). Thus theoretically, one variable can be reduced from
the set xi (i = 1, 2, . . . , n + m) for each of the m + l equality constraints given by
Eqs. (7.84) and (7.85). It is convenient to divide the n + m design variables arbitrarily
into two sets as
X =
{
Y
Z
}
(7.91)
Y =









y1
y2
...
yn−l









= design or independent variables (7.92)
Z =









z1
z2
...
zm+l









= state or dependent variables (7.93)
and where the design variables are completely independent and the state variables
are dependent on the design variables used to satisfy the constraints gj (X) = 0, j =
1, 2, . . . , m + l.
414 Nonlinear Programming III: Constrained Optimization Techniques
Consider the first variations of the objective and constraint functions:
df (X) =
n−l
∑
i=1
∂f
∂yi
dyi +
m+l
∑
i=1
∂f
∂zi
dzi = ∇TYf dY + ∇TZf dZ (7.94)
dgi(X) =
n−l
∑
j=1
∂gi
∂yj
dyj +
m+l
∑
j=1
∂gi
∂zj
dzj
or
dg = [C] dY + [D] dZ (7.95)
where
∇Yf =

























∂f
∂y1
∂f
∂y2
...
∂f
∂yn−l

























(7.96)
∇Zf =

























∂f
∂z1
∂f
∂z2
...
∂f
∂zm+l

























(7.97)
[C] =








∂g1
∂y1
· · · ∂g1
∂yn−l
...
...
∂gm+l
∂y1
· · · ∂gm+l
∂yn−l








(7.98)
[D] =








∂g1
∂z1
· · · ∂g1
∂zm+l
...
...
∂gm+l
∂z1
· · · ∂gm+l
∂zm+l








(7.99)
7.9 Generalized Reduced Gradient Method 415
dY =

















dy1
dy2
...
dyn−l

















(7.100)
dZ =

















dz1
dz2
...
dzm+l

















(7.101)
Assuming that the constraints are originally satisfied at the vector X, (g(X) = 0), any
change in the vector dX must correspond to dg = 0 to maintain feasibility at X + dX.
Equation (7.95) can be solved to express dZ as
dZ = −[D]−1[C]dY (7.102)
The change in the objective function due to the change in X is given by Eq. (7.94),
which can be expressed, using Eq. (7.102), as
df (X) = (∇TYf − ∇TZf [D]−1[C])dY (7.103)
or
df
dY
(X) = GR (7.104)
where
GR = ∇Yf − ([D]−1[C])T∇Zf (7.105)
is called the generalized reduced gradient . Geometrically, the reduced gradient
can be described as a projection of the original n-dimensional gradient onto the
(n − m)-dimensional feasible region described by the design variables.
We know that a necessary condition for the existence of a minimum of an uncon-
strained function is that the components of the gradient vanish. Similarly, a constrained
function assumes its minimum value when the appropriate components of the reduced
gradient are zero. This condition can be verified to be same as the Kuhn–Tucker con-
ditions to be satisfied at a relative minimum. In fact, the reduced gradient GR can be
used to generate a search direction S to reduce the value of the constrained objective
function similar to the gradient ∇f that can be used to generate a search direction S
for an unconstrained function. A suitable step length λ is to be chosen to minimize
the value of f along the search direction S. For any specific value of λ, the dependent
variable vector Z is updated using Eq. (7.102). Noting that Eq. (7.102) is based on
using a linear approximation to the original nonlinear problem, we find that the con-
straints may not be exactly equal to zero at λ, that is, dg = 0. Hence when Y is held
416 Nonlinear Programming III: Constrained Optimization Techniques
fixed, in order to have
gi(X) + dgi(X) = 0, i = 1, 2, . . . ,m + l (7.106)
we must have
g(X) + dg(X) = 0 (7.107)
Using Eq. (7.95) for dg in Eq. (7.107), we obtain
dZ = [D]−1(−g(X) − [C]dY) (7.108)
The value of dZ given by Eq. (7.108) is used to update the value of Z as
Zupdate = Zcurrent + dZ (7.109)
The constraints evaluated at the updated vector X, and the procedure [of finding dZ
using Eq. (7.108)] is repeated until dZ is sufficiently small. Note that Eq. (7.108) can
be considered as Newton’s method of solving simultaneous equations for dZ.
Algorithm
1. Specify the design and state variables . Start with an initial trial vector X. Identify
the design and state variables (Y and Z) for the problem using the following
guidelines.
(a) The state variables are to be selected to avoid singularity of the matrix, [D].
(b) Since the state variables are adjusted during the iterative process to maintain
feasibility, any component of X that is equal to its lower or upper bound
initially is to be designated a design variable.
(c) Since the slack variables appear as linear terms in the (originally inequality)
constraints, they should be designated as state variables. However, if the
initial value of any state variable is zero (its lower bound value), it should
be designated a design variable.
2. Compute the generalized reduced gradient . The GRG is determined using
Eq. (7.105). The derivatives involved in Eq. (7.105) can be evaluated
numerically, if necessary.
3. Test for convergence. If all the components of the GRG are close to zero, the
method can be considered to have converged and the current vector X can be
taken as the optimum solution of the problem. For this, the following test can
be used:
||GR|| ≤ ε
where ε is a small number. If this relation is not satisfied, we go to step 4.
4. Determine the search direction. The GRG can be used similar to a gra-
dient of an unconstrained objective function to generate a suitable search
direction, S. The techniques such as steepest descent, Fletcher–Reeves,
Davidon–Fletcher–Powell, or Broydon–Fletcher–Goldfarb–Shanno methods
7.9 Generalized Reduced Gradient Method 417
can be used for this purpose. For example, if a steepest descent method is
used, the vector S is determined as
S = −GR (7.110)
5. Find the minimum along the search direction . Although any of the one
-dimensional minimization procedures discussed in Chapter 5 can be used
to find a local minimum of f along the search direction S, the following
procedure can be used conveniently.
(a) Find an estimate for λ as the distance to the nearest side constraint. When
design variables are considered, we have
λ =









y
(u)
i − (yi)old
si
if si > 0
y
(l)
i − (yi)old
si
if si < 0
(7.111)
where si is the ith component of S. Similarly, when state variables are
considered, we have, from Eq. (7.102),
dZ = −[D]−1[C] dY (7.112)
Using dY = λS, Eq. (7.112) gives the search direction for the variables
Z as
T = −[D]−1[C]S (7.113)
Thus
λ =









z
(u)
i − (zi)old
ti
if ti > 0
z
(l)
i − (zi)old
ti
if ti < 0
(7.114)
where ti is the ith component of T.
(b) The minimum value of λ given by Eq. (7.111), λ1, makes some design
variable attain its lower or upper bound. Similarly, the minimum value of
λ given by Eq. (7.114), λ2, will make some state variable attain its lower
or upper bound. The smaller of λ1 or λ2 can be used as an upper bound
on the value of λ for initializing a suitable one-dimensional minimization
procedure. The quadratic interpolation method can be used conveniently for
finding the optimal step length λ∗.
(c) Find the new vector Xnew:
Xnew =
{
Yold + dY
Zold + dZ
}
=
{
Yold + λ∗S
Zold + λ∗T
}
(7.115)
418 Nonlinear Programming III: Constrained Optimization Techniques
If the vector Xnew corresponding to λ
∗ is found infeasible, then Ynew is held
constant and Znew is modified using Eq. (7.108) with dZ = Znew − Zold.
Finally, when convergence is achieved with Eq. (7.108), we find that
Xnew =
{
Yold + 	Y
Zold + 	Z
}
(7.116)
and go to step 1.
Example 7.4
Minimize f (x1, x2, x3) = (x1 − x2)2 + (x2 − x3)4
subject to
g1(X) = x1(1 + x22) + x43 − 3 = 0
−3 ≤ xi ≤ 3, i = 1, 2, 3
using the GRG method.
SOLUTION
Step 1: We choose arbitrarily the independent and dependent variables as
Y =
{
y1
y2
}
=
{
x1
x2
}
, Z = {z1} = {x3}
Let the starting vector be
X1 =



−2.6
2
2



with f (X1) = 21.16.
Step 2: Compute the GRG at X1. Noting that
∂f
∂x1
= 2(x1 − x2)
∂f
∂x2
= −2(x1 − x2) + 4(x2 − x3)3
∂f
∂x3
= −4(x2 − x3)3
∂g1
∂x1
= 1 + x22
∂g1
∂x2
= 2x1x2
∂g1
∂x3
= 4x33
7.9 Generalized Reduced Gradient Method 419
we find, at X1,
∇Yf =







∂f
∂x1
∂f
∂x2







X1
=
{
2(−2.6 − 2)
−2(−2.6 − 2) + 4(2 − 2)3
}
=
{
−9.2
9.2
}
∇Zf =
{
∂f
∂x3
}
X1
= {−4(x2 − x3)3}X1 = 0
[C] =
[
∂g1
∂x1
∂g1
∂x2
]
X1
= [5 −10.4]
[D] =
[
∂g1
∂x3
]
X1
= [32]
D−1 = [ 1
32
], [D]−1[C] = 1
32
[5 −10.4] = [0.15625 −0.325]
GR = ∇Yf − [[D]−1[C]]T∇Zf
=
{
−9.2
9.2
}
−
{
0.15625
−0.325
}
(0) =
{
−9.2
9.2
}
Step 3: Since the components of GR are not zero, the point X1 is not optimum, and
hence we go to step 4.
Step 4: We use the steepest descent method and take the search direction as
S = −GR =
{
9.2
−9.2
}
Step 5: We find the optimal step length along S.
(a) Considering the design variables, we use Eq. (7.111) to obtain For y1 = x1:
λ = 3 − (−2.6)
9.2
= 0.6087
For y2 = x2:
λ = −3 − (2)
−9.2
= 0.5435
Thus the smaller value gives λ1 = 0.5435. Equation (7.113) gives
T = −([D]−1[C])S = −(0.15625 −0.325)
{
9.2
−9.2
}
= −4.4275
and hence Eq. (7.114) leads to
For z1 = x3 : λ =
−3 − (2)
−4.4275
= 1.1293
Thus λ2 = 1.1293.
420 Nonlinear Programming III: Constrained Optimization Techniques
(b) The upper bound on λ is given by the smaller of λ1 and λ2, which is equal
to 0.5435. By expressing
X =
{
Y + λS
Z + λT
}
we obtain
X =



x1
x2
x3



=



−2.6
2
2



+ λ



9.2
−9.2
−4.4275



=



−2.6 + 9.2λ
2 − 9.2λ
2 − 4.4275λ



and hence
f (λ) = f (X) = (−2.6 + 9.2λ − 2 + 9.2λ)2
+ (2 − 9.2λ − 2 + 4.4275λ)4
= 518.7806λ4 + 338.56λ2 − 169.28λ + 21.16
df/dλ = 0 gives
2075.1225λ3 + 677.12λ − 169.28 = 0
from which we find the root as λ∗ ≈ 0.22. Since λ∗ is less than the upper
bound value 0.5435, we use λ∗.
(c) The new vector Xnew is given by
Xnew =
{
Yold + dY
Zold + dZ
}
=
{
Yold + λ∗S
Zold + λ∗T
}
=







−2.6 + 0.22(9.2)
2 + 0.22(−9.2)
2 + 0.22(−4.4275)







=







−0.576
−0.024
1.02595







with
dY =
{
2.024
−2.024
}
, dZ = {−0.97405}
Now, we need to check whether this vector is feasible. Since
g1(Xnew) = (−0.576)[1 + (−0.024)2] + (1.02595)4 − 3 = −2.4684 = 0
the vector Xnew is infeasible. Hence we hold Ynew constant and modify
Znew using Newton’s method [Eq. (7.108)] as
dZ = [D]−1[−g(X) − [C]dY]
7.9 Generalized Reduced Gradient Method 421
Since
[D] =
[
∂g1
∂z1
]
= [4x33 ] = [4(1.02595)3] = [4.319551]
g1(X) = {−2.4684}
[C] =
[
∂g1
∂y1
∂g1
∂y2
]
= {[2(−0.576 + 0.024)][−2(−0.576 + 0.024)
+ 4(−0.024 − 1.02595)3]}
= [−1.104 −3.5258]
dZ = 1
4.319551
[
2.4684 − {−1.104 −3.5258}
×
{
2.024
−2.024
}]
= {−0.5633}
we have Znew = Zold + dZ = {2 − 0.5633} = {1.4367}. The current Xnew
becomes
Xnew =
{
Yold + dY
Zold + dZ
}
=



−0.576
−0.024
1.4367



The constraint becomes
g1 = (−0.576)(1−(−0.024)2) + (1.4367)4 − 3 = 0.6842 = 0
Since this Xnew is infeasible, we need to apply Newton’s method
[Eq. (7.108)] at the current Xnew. In the present case, instead of repeating
Newton’s iteration, we can find the value of Znew = {x3}new by satisfying
the constraint as
g1(X) = (−0.576)[1 + (−0.024)2] + x43 − 3 = 0
or x3 = (2.4237)0.25 = 1.2477
This gives
Xnew =



−0.576
−0.024
1.2477



and
f (Xnew) = (−0.576 + 0.024)2 + (−0.024 − 1.2477)4 = 2.9201
Next we go to step 1.
Step 1: We do not have to change the set of independent and dependent variables and
hence we go to the next step.
422 Nonlinear Programming III: Constrained Optimization Techniques
Step 2: We compute the GRG at the current X using Eq. (7.105). Since
∇Yf =







∂f
∂x1
∂f
∂x2







=
{
2(−0.576 + 0.024)
−2(−0.576 + 0.024) + 4(−0.024 − 1.2477)3
}
=
{
−1.104
−7.1225
}
∇Zf =
{
∂f
∂z1
}
=
{
∂f
∂x3
}
= {−4(−0.024 − 1.2477)3} = {8.2265}
[C] =
[
∂g1
∂x1
∂g1
∂x2
]
= [(1 + (−0.024)2) 2(−0.576)(−0.024)]
= [1.000576 0.027648]
[D] =
[
∂g1
∂x3
]
= [4x33 ] = [4(1.2477)3] = [7.7694]
[D]−1[C] = 1
7.7694
[1.000576 0.027648] = [0.128784 0.003558]
GR = ∇Yf − [[D]−1[C]]T∇Zf
=
{
−1.104
−7.1225
}
−
{
0.128784
0.003558
}
(8.2265) =
{
−2.1634
−7.1518
}
Since GR = 0, we need to proceed to the next step.
Note: It can be seen that the value of the objective function reduced from an initial
value of 21.16 to 2.9201 in one iteration.
7.10 SEQUENTIAL QUADRATIC PROGRAMMING
The sequential quadratic programming is one of the most recently developed and per-
haps one of the best methods of optimization. The method has a theoretical basis that
is related to (1) the solution of a set of nonlinear equations using Newton’s method,
and (2) the derivation of simultaneous nonlinear equations using Kuhn–Tucker con-
ditions to the Lagrangian of the constrained optimization problem. In this section we
present both the derivation of the equations and the solution procedure of the sequential
quadratic programming approach.
7.10.1 Derivation
Consider a nonlinear optimization problem with only equality constraints:
Find X which minimizes f (X)
subject to
hk(X) = 0, k = 1, 2, . . . , p (7.117)
7.10 Sequential Quadratic Programming 423
The extension to include inequality constraints will be considered at a later stage. The
Lagrange function, L(X, λ), corresponding to the problem of Eq. (7.117) is given by
L = f (X) +
p
∑
k=1
λkhk(X) (7.118)
where λk is the Lagrange multiplier for the kth equality constraint. The Kuhn–Tucker
necessary conditions can be stated as
∇L = 0 or ∇f +
p
∑
k=1
λk∇hk = 0 or ∇f + [A]Tλ = 0 (7.119)
hk(X) = 0, k = 1, 2, . . . , p (7.120)
where [A] is an n × p matrix whose kth column denotes the gradient of the function
hk. Equations (7.119) and (7.120) represent a set of n + p nonlinear equations in
n + p unknowns (xi, i = 1, . . . , n and λk, k = 1, . . . , p). These nonlinear equations
can be solved using Newton’s method. For convenience, we rewrite Eqs. (7.119) and
(7.120) as
F(Y) = 0 (7.121)
where
F =
{
∇L
h
}
(n+p)×1
, Y =
{
X
λ
}
(n+p)×1
, 0 =
{
0
0
}
(n+p)×1
(7.122)
According to Newton’s method, the solution of Eqs. (7.121) can be found iteratively
as (see Section 6.11)
Yj+1 = Yj + 	Yj (7.123)
with
[∇F ]Tj 	Yj = −F(Yj ) (7.124)
where Yj is the solution at the start of j th iteration and 	Yj is the change in Yj
necessary to generate the improved solution, Yj+1, and [∇F ]j = [∇F(Yj )] is the (n +
p) × (n + p) Jacobian matrix of the nonlinear equations whose ith column denotes the
gradient of the function Fi(Y) with respect to the vector Y. By substituting Eqs. (7.121)
and (7.122) into Eq. (7.124), we obtain
[
[∇2L] [H ]
[H ]T [0]
]
j
{
	X
	λ
}
j
= −
{
∇L
h
}
j
(7.125)
	Xj = Xj+1 − Xj (7.126)
	λj = λj+1 − λj (7.127)
424 Nonlinear Programming III: Constrained Optimization Techniques
where [∇2L]n×n denotes the Hessian matrix of the Lagrange function. The first set of
equations in (7.125) can be written separately as
[∇2L]j	Xj + [H ]j	λj = −∇Lj (7.128)
Using Eq. (7.127) for 	λj and Eq. (7.119) for ∇Lj , Eq. (7.128) can be expressed as
[∇2L]j	Xj + [H ]j (λj+1 − λj ) = −∇fj − [H ]Tj λj (7.129)
which can be simplified to obtain
[∇2L]j	Xj + [H ]jλj+1 = −∇fj (7.130)
Equation (7.130) and the second set of equations in (7.125) can now be combined as
[
[∇2L] [H ]
[H ]T [0]
]
j
{
	Xj
λj+1
}
= −
{
∇fj
hj
}
(7.131)
Equations (7.131) can be solved to find the change in the design vector 	Xj and
the new values of the Lagrange multipliers, λj+1. The iterative process indicated by
Eq. (7.131) can be continued until convergence is achieved.
Now consider the following quadratic programming problem:
Find 	X that minimizes the quadratic objective function
Q = ∇f T	X + 1
2
	XT[∇2L]	X
subject to the linear equality constraints (7.132)
hk + ∇hTk 	X = 0, k = 1, 2, . . . , p or h + [H ]T	X = 0
The lagrange function, L̃, corresponding to the problem of Eq. (7.132) is given by
L̃ = ∇f T 	X + 1
2
	XT[∇2L]	X +
p
∑
k=1
λk(hk + ∇hTk 	X) (7.133)
where λk is the Lagrange multiplier associated with the kth equality constraint.
The Kuhn–Tucker necessary conditions can be stated as
∇f + [∇2L]	X + [H ]λ = 0 (7.134)
hk + ∇hTk 	X = 0, k = 1, 2, . . . , p (7.135)
Equations (7.134) and (7.135) can be identified to be same as Eq. (7.131) in matrix
form. This shows that the original problem of Eq. (7.117) can be solved iteratively
by solving the quadratic programming problem defined by Eq. (7.132). In fact, when
inequality constraints are added to the original problem, the quadratic programming
problem of Eq. (7.132) becomes
Find X which minimizes Q = ∇f T	X + 1
2
	XT[∇2L]	X
7.10 Sequential Quadratic Programming 425
subject to
gj + ∇gTj 	X ≤ 0, j = 1, 2, . . . , m
hk + ∇hTk 	X = 0, k = 1, 2, . . . , p (7.136)
with the Lagrange function given by
L̃ = f (X) +
m
∑
j=1
λjgj (X) +
p
∑
k=1
λm+khk(X) (7.137)
Since the minimum of the augmented Lagrange function is involved, the sequential
quadratic programming method is also known as the projected Lagrangian method .
7.10.2 Solution Procedure
As in the case of Newton’s method of unconstrained minimization, the solution vector
	X in Eq. (7.136) is treated as the search direction, S, and the quadratic programming
subproblem (in terms of the design vector S) is restated as:
Find S which minimizes Q(S) = ∇f (X)TS + 1
2
ST[H ]S
subject to
βjgj (X) + ∇gj (X)TS ≤ 0, j = 1, 2, . . . , m
βhk(X) + ∇hk(X)TS = 0, k = 1, 2, . . . , p (7.138)
where [H ] is a positive definite matrix that is taken initially as the identity matrix
and is updated in subsequent iterations so as to converge to the Hessian matrix of the
Lagrange function of Eq. (7.137), and βj and β are constants used to ensure that the
linearized constraints do not cut off the feasible space completely. Typical values of
these constants are given by
β ≈ 0.9; βj =
{
1 if gj (X) ≤ 0
β if gj (X) ≥ 0
(7.139)
The subproblem of Eq. (7.138) is a quadratic programming problem and hence the
method described in Section 4.8 can be used for its solution. Alternatively, the problem
can be solved by any of the methods described in this chapter since the gradients of the
function involved can be evaluated easily. Since the Lagrange multipliers associated
with the solution of the problem, Eq. (7.138), are needed, they can be evaluated using
Eq. (7.263). Once the search direction, S, is found by solving the problem in Eq. (7.138),
the design vector is updated as
Xj+1 = Xj + α∗S (7.140)
where α∗ is the optimal step length along the direction S found by minimizing the
function (using an exterior penalty function approach):
φ = f (X) +
m
∑
j=1
λj (max[0, gj (X)]) +
p
∑
k=1
λm+k|hk(X)| (7.141)
426 Nonlinear Programming III: Constrained Optimization Techniques
with
λj =
{
|λj |, j = 1, 2, . . . , m + p in first iteration
max{|λj |, 12 (λ̃j , |λj |)}in subsequent iterations
(7.142)
and λ̃j = λj of the previous iteration. The one-dimensional step length α∗ can be found
by any of the methods discussed in Chapter 5.
Once Xj+1 is found from Eq. (7.140), for the next iteration the Hessian matrix [H ]
is updated to improve the quadratic approximation in Eq. (7.138). Usually, a modified
BFGS formula, given below, is used for this purpose [7.12]:
[Hi+1] = [Hi] −
[Hi]PiP
T
i [Hi]
PTi [Hi]Pi
+
γ γ T
PTi Pi
(7.143)
Pi = Xi+1 − Xi (7.144)
γ = θQi + (1 − θ)[Hi]Pi (7.145)
Qi = ∇xL̃(Xi+1, λi+1) − ∇xL̃(Xi, λi) (7.146)
θ =





1.0 if PTi Qi ≥ 0.2PTi [Hi]Pi
0.8PTi [Hi]Pi
PTi [Hi]Pi − PTi Qi
if PTi Qi < 0.2P
T
i [Hi]Pi
(7.147)
where L̃ is given by Eq. (7.137) and the constants 0.2 and 0.8 in Eq. (7.147) can be
changed, based on numerical experience.
Example 7.5 Find the solution of the problem (see Problem 1.31):
Minimize f (X) = 0.1x1 + 0.05773x2 (E1)
subject to
g1(X) =
0.6
x1
+
0.3464
x2
− 0.1 ≤ 0 (E2)
g2(X) = 6 − x1 ≤ 0 (E3)
g3(X) = 7 − x2 ≤ 0 (E4)
using the sequential quadratic programming technique.
SOLUTION Let the starting point be X1 = (11.8765, 7.0)T with g1(X1) = g3(X1) =
0, g2(X1) = −5.8765, and f (X1) = 1.5917. The gradients of the objective and con-
straint functions at X1 are given by
∇f (X1) =
{
0.1
0.05773
}
, ∇g1(X1) =









−0.6
x21
−0.3464
x22









X1
=
{
−0.004254
−0.007069
}
∇g2(X1) =
{
−1
0
}
, ∇g3(X1) =
{
0
−1
}
7.10 Sequential Quadratic Programming 427
We assume the matrix [H1] to be the identity matrix and hence the objective function
of Eq. (7.138) becomes
Q(S) = 0.1s1 + 0.05773s2 + 0.5s21 + 0.5s22 (E5)
Equation (7.139) gives β1 = β3 = 0 since g1 = g3 = 0 and β2 = 1.0 since g2 < 0, and
hence the constraints of Eq. (7.138) can be expressed as
g̃1 = −0.004254s1 − 0.007069s2 ≤ 0 (E6)
g̃2 = −5.8765 − s1 ≤ 0 (E7)
g̃3 = −s2 ≤ 0 (E8)
We solve this quadratic programming problem [Eqs. (E5) to (E8)] directly with the use
of the Kuhn–Tucker conditions. The Kuhn–Tucker conditions are given by
∂Q
∂s1
+
3
∑
j=1
λj
∂g̃j
∂s1
= 0 (E9)
∂Q
∂s2
+
3
∑
j=1
λj
∂g̃j
∂s2
= 0 (E10)
λj g̃j = 0, j = 1, 2, 3 (E11)
g̃j ≤ 0, j = 1, 2, 3 (E12)
λj ≥ 0, j = 1, 2, 3 (E13)
Equations (E9) and (E10) can be expressed, in this case, as
0.1 + s1 − 0.004254λ1 − λ2 = 0 (E14)
0.05773 + s2 − 0.007069λ1 − λ3 = 0 (E15)
By considering all possibilities of active constraints, we find that the optimum solution
of the quadratic programming problem [Eqs. (E5) to (E8)] is given by
s∗1 = −0.04791, s∗2 = 0.02883, λ∗1 = 12.2450, λ∗2 = 0, λ∗3 = 0
The new design vector, X, can be expressed as
X = X1 + αS =
{
11.8765 − 0.04791α
7.0 + 0.02883α
}
where α can be found by minimizing the function φ in Eq. (7.141):
φ = 0.1(11.8765 − 0.04791α) + 0.05773(7.0 + 0.02883α)
+ 12.2450
(
0.6
11.8765 − 0.04791α
+ 0.3464
7.0 + 0.02883α
− 0.1
)
428 Nonlinear Programming III: Constrained Optimization Techniques
By using quadratic interpolation technique (unrestricted search method can also be used
for simplicity), we find that φ attains its minimum value of 1.48 at α∗ = 64.93, which
corresponds to the new design vector
X2 =
{
8.7657
8.8719
}
with f (X2) = 1.38874 and g1(X2) = +0.0074932 (violated slightly). Next we update
the matrix [H ] using Eq. (7.143) with
L̃ = 0.1x1 + 0.05773x2 + 12.2450
(
0.6
x1
+
0.3464
x2
− 0.1
)
∇xL̃ =









∂L̃
∂x1
∂L̃
∂x2









with
∂L̃
∂x1
= 0.1 − 7.3470
x21
and
∂L̃
∂x2
= 0.05773 − 4.2417
x22
P1 = X2 − X1 =
{
−3.1108
1.8719
}
Q1 = ∇xL̃(X2) − ∇xL̃(X1) =
{
0.00438
0.00384
}
−
{
0.04791
−0.02883
}
=
{
−0.04353
0.03267
}
PT1 [H1]P1 = 13.1811, PT1 Q1 = 0.19656
This indicates that PT1 Q1 < 0.2P
T
1 [H1]P1, and hence θ is computed using Eq. (7.147) as
θ = (0.8)(13.1811)
13.1811 − 0.19656
= 0.81211
γ = θQ1 + (1 − θ)[H1]P1 =
{
0.54914
−0.32518
}
Hence
[H2] =
[
0.2887 0.4283
0.4283 0.7422
]
We can now start another iteration by defining a new quadratic programming problem
using Eq. (7.138) and continue the procedure until the optimum solution is found.
Note that the objective function reduced from a value of 1.5917 to 1.38874 in one
iteration when X changed from X1 to X2.
Indirect Methods
7.11 TRANSFORMATION TECHNIQUES
If the constraints gj (X) are explicit functions of the variables xi and have certain simple
forms, it may be possible to make a transformation of the independent variables such
7.11 Transformation Techniques 429
that the constraints are satisfied automatically [7.13]. Thus it may be possible to convert
a constrained optimization problem into an unconstrained one by making a change of
variables. Some typical transformations are indicated below:
1. If lower and upper bounds on xi are specified as
li ≤ xi ≤ ui (7.148)
these can be satisfied by transforming the variable xi as
xi = li + (ui − li)sin2yi (7.149)
where yi is the new variable, which can take any value.
2. If a variable xi is restricted to lie in the interval (0, 1), we can use the transfor-
mation:
xi = sin2 yi, xi = cos2 yi
xi =
eyi
eyi + e−yi
or xi =
y2i
1 + y2i
(7.150)
3. If the variable xi is constrained to take only positive values, the transformation
can be
xi = abs(yi), xi = y2i or xi = eyi (7.151)
4. If the variable is restricted to take values lying only in between −1 and 1, the
transformation can be
xi = sin yi, xi = cos yi, or xi =
2yi
1 + y2i
(7.152)
Note the following aspects of transformation techniques:
1. The constraints gj (X) have to be very simple functions of xi .
2. For certain constraints it may not be possible to find the necessary transfor-
mation.
3. If it is not possible to eliminate all the constraints by making a change of
variables, it may be better not to use the transformation at all. The partial
transformation may sometimes produce a distorted objective function which
might be more difficult to minimize than the original function.
To illustrate the method of transformation of variables, we consider the following
problem.
Example 7.6 Find the dimensions of a rectangular prism-type box that has the largest
volume when the sum of its length, width, and height is limited to a maximum value
of 60 in. and its length is restricted to a maximum value of 36 in.
SOLUTION Let x1, x2, and x3 denote the length, width, and height of the box,
respectively. The problem can be stated as follows:
Maximize f (x1, x2, x3) = x1x2x3 (E1)
430 Nonlinear Programming III: Constrained Optimization Techniques
subject to
x1 + x2 + x3 ≤ 60 (E2)
x1 ≤ 36 (E3)
xi ≥ 0, i = 1, 2, 3 (E4)
By introducing new variables as
y1 = x1, y2 = x2, y3 = x1 + x2 + x3 (E5)
or
x1 = y1, x2 = y2, x3 = y3 − y1 − y2 (E6)
the constraints of Eqs. (E2) to (E4) can be restated as
0 ≤ y1 ≤ 36, 0 ≤ y2 ≤ 60, 0 ≤ y3 ≤ 60 (E7)
where the upper bound, for example, on y2 is obtained by setting x1 = x3 = 0 in
Eq. (E2). The constraints of Eq. (E7) will be satisfied automatically if we define new
variables zi , i = 1, 2, 3, as
y1 = 36 sin2 z1, y2 = 60 sin2 z2, y3 = 60 sin2 z3 (E8)
Thus the problem can be stated as an unconstrained problem as follows:
Maximize f (z1, z2, z3)
= y1y2(y3 − y1 − y2) (E9)
= 2160 sin2 z1 sin2 z2(60 sin2 z3 − 36 sin2 z1 − 60 sin2 z2)
The necessary conditions of optimality yield the relations
∂f
∂z1
= 259,200 sin z1 cos z1 sin2 z2(sin2 z3 − 65 sin
2 z1 − sin2 z2) = 0 (E10)
∂f
∂z2
= 518,400 sin2 z1 sin z2 cos z2( 12 sin
2 z3 − 310 sin
2 z1 − sin2 z2) = 0 (E11)
∂f
∂z3
= 259,200 sin2 z1 sin2 z2 sin z3 cos z3 = 0 (E12)
Equation (E12) gives the nontrivial solution as cos z3 = 0 or sin2 z3 = 1. Hence
Eqs. (E10) and (E11) yield sin
2 z1 = 59 and sin
2 z2 = 13 . Thus the optimum solution is
given by x∗1 = 20 in., x∗2 = 20 in., x∗3 = 20 in., and the maximum volume = 8000 in
3.
7.12 BASIC APPROACH OF THE PENALTY FUNCTION METHOD
Penalty function methods transform the basic optimization problem into alternative
formulations such that numerical solutions are sought by solving a sequence of
7.12 Basic Approach of the Penalty Function Method 431
unconstrained minimization problems. Let the basic optimization problem, with
inequality constraints, be of the form:
Find X which minimizes f (X)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m (7.153)
This problem is converted into an unconstrained minimization problem by constructing
a function of the form
φk = φ(X, rk) = f (X) + rk
m
∑
j=1
Gj [gj (X)] (7.154)
where Gj is some function of the constraint gj , and rk is a positive constant known
as the penalty parameter . The significance of the second term on the right side of
Eq. (7.154), called the penalty term , will be seen in Sections 7.13 and 7.15. If the
unconstrained minimization of the φ function is repeated for a sequence of values of
the penalty parameter rk(k = 1, 2, . . .), the solution may be brought to converge to
that of the original problem stated in Eq. (7.153). This is the reason why the penalty
function methods are also known as sequential unconstrained minimization techniques
(SUMTs).
The penalty function formulations for inequality constrained problems can be
divided into two categories: interior and exterior methods. In the interior formulations,
some popularly used forms of Gj are given by
Gj = −
1
gj (X)
(7.155)
Gj = log[−gj (X)] (7.156)
Some commonly used forms of the function Gj in the case of exterior penalty function
formulations are
Gj = max[0, gj (X)] (7.157)
Gj = {max[0, gi(X)]}2 (7.158)
In the interior methods, the unconstrained minima of φk all lie in the feasible region
and converge to the solution of Eq. (7.153) as rk is varied in a particular manner. In
the exterior methods, the unconstrained minima of φk all lie in the infeasible region
and converge to the desired solution from the outside as rk is changed in a specified
manner. The convergence of the unconstrained minima of φk is illustrated in Fig. 7.10
for the simple problem
Find X = {x1} which minimizes f (X) = αx1
subject to (7.159)
g1(X) = β − x1 ≤ 0
432 Nonlinear Programming III: Constrained Optimization Techniques
Figure 7.10 Penalty function methods: (a) exterior method; (b) interior method.
It can be seen from Fig. 7.10a that the unconstrained minima of φ(X, rk) converge
to the optimum point X∗ as the parameter rk is increased sequentially. On the other
hand, the interior method shown in Fig. 7.10b gives convergence as the parameter rk
is decreased sequentially.
There are several reasons for the appeal of the penalty function formulations. One
main reason, which can be observed from Fig. 7.10, is that the sequential nature of
the method allows a gradual or sequential approach to criticality of the constraints. In
addition, the sequential process permits a graded approximation to be used in analysis
of the system. This means that if the evaluation of f and gj [and hence φ(X, rk)]
for any specified design vector X is computationally very difficult, we can use coarse
approximations during the early stages of optimization (when the unconstrained minima
of φk are far away from the optimum) and finer or more detailed analysis approximation
during the final stages of optimization. Another reason is that the algorithms for the
unconstrained minimization of rather arbitrary functions are well studied and generally
are quite reliable. The algorithms of the interior and the exterior penalty function
methods are given in Sections 7.13 and 7.15.
7.13 INTERIOR PENALTY FUNCTION METHOD
As indicated in Section 7.12, in the interior penalty function methods, a new function
(φ function) is constructed by augmenting a penalty term to the objective function. The
penalty term is chosen such that its value will be small at points away from the con-
straint boundaries and will tend to infinity as the constraint boundaries are approached.
Hence the value of the φ function also “blows up” as the constraint boundaries are
7.13 Interior Penalty Function Method 433
approached. This behavior can also be seen from Fig. 7.10b. Thus once the uncon-
strained minimization of φ(X, rk) is started from any feasible point X1, the subsequent
points generated will always lie within the feasible domain since the constraint bound-
aries act as barriers during the minimization process. This is why the interior penalty
function methods are also known as barrier methods . The φ function defined originally
by Carroll [7.14] is
φ(X, rk) = f (X) − rk
m
∑
j=1
1
gj (X)
(7.160)
It can be seen that the value of the function φ will always be greater than f since gj (X)
is negative for all feasible points X. If any constraint gj (X) is satisfied critically (with
equality sign), the value of φ tends to infinity. It is to be noted that the penalty term in
Eq. (7.160) is not defined if X is infeasible. This introduces serious shortcoming while
using the Eq. (7.160). Since this equation does not allow any constraint to be violated,
it requires a feasible starting point for the search toward the optimum point. However,
in many engineering problems, it may not be very difficult to find a point satisfying
all the constraints, gj (X) ≤ 0, at the expense of large values of the objective function,
f (X). If there is any difficulty in finding a feasible starting point, the method described
in the latter part of this section can be used to find a feasible point. Since the initial
point as well as each of the subsequent points generated in this method lies inside the
acceptable region of the design space, the method is classified as an interior penalty
function formulation . Since the constraint boundaries act as barriers, the method is also
known as a barrier method. The iteration procedure of this method can be summarized
as follows.
Iterative Process
1. Start with an initial feasible point X1 satisfying all the constraints with strict
inequality sign, that is, gj (X1) < 0 for j = 1, 2, . . . ,m, and an initial value of
r1 > 0. Set k = 1.
2. Minimize φ(X, rk) by using any of the unconstrained minimization methods
and obtain the solution X∗k .
3. Test whether X∗k is the optimum solution of the original problem. If X
∗
k is found
to be optimum, terminate the process. Otherwise, go to the next step.
4. Find the value of the next penalty parameter, rk+1, as
rk+1 = crk
where c < 1.
5. Set the new value of k = k + 1, take the new starting point as X1 = X∗k , and
go to step 2.
Although the algorithm is straightforward, there are a number of points to be considered
in implementing the method:
1. The starting feasible point X1 may not be readily available in some cases.
2. A suitable value of the initial penalty parameter (r1) has to be found.
3. A proper value has to be selected for the multiplication factor, c.
434 Nonlinear Programming III: Constrained Optimization Techniques
4. Suitable convergence criteria have to be chosen to identify the optimum point.
5. The constraints have to be normalized so that each one of them vary between
−1 and 0 only.
All these aspects are discussed in the following paragraphs.
Starting Feasible Point X1. In most engineering problems, it will not be very difficult
to find an initial point X1 satisfying all the constraints, gj (X1) < 0. As an example,
consider the problem of minimum weight design of a beam whose deflection under a
given loading condition has to remain less than or equal to a specified value. In this
case one can always choose the cross section of the beam to be very large initially so
that the constraint remains satisfied. The only problem is that the weight of the beam
(objective) corresponding to this initial design will be very large. Thus in most of the
practical problems, we will be able to find a feasible starting point at the expense of a
large value of the objective function. However, there may be some situations where the
feasible design points could not be found so easily. In such cases, the required feasible
starting points can be found by using the interior penalty function method itself as
follows:
1. Choose an arbitrary point X1 and evaluate the constraints gj (X) at the point
X1. Since the point X1 is arbitrary, it may not satisfy all the constraints with
strict inequality sign. If r out of a total of m constraints are violated, renumber
the constraints such that the last r constraints will become the violated ones,
that is,
gj (X1) < 0, j = 1, 2, . . . , m − r
gj (X1) ≥ 0, j = m − r + 1, m − r + 2, . . . , m (7.161)
2. Identify the constraint that is violated most at the point X1, that is, find the
integer k such that
gk(X1) = max[gj (X1)]
for j = m − r + 1, m − r + 2, . . . ,m (7.162)
3. Now formulate a new optimization problem as
Find X which minimizes gk(X)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m − r
gj (X) − gk(X1) ≤ 0, j = m − r + 1, m − r + 2, . . . ,
k − 1, k + 1, . . . , m (7.163)
4. Solve the optimization problem formulated in step 3 by taking the point X1 as
a feasible starting point using the interior penalty function method. Note that
this optimization method can be terminated whenever the value of the objective
function gk(X) drops below zero. Thus the solution obtained XM will satisfy at
least one more constraint than did the original point X1.
7.13 Interior Penalty Function Method 435
5. If all the constraints are not satisfied at the point XM , set the new starting point
as X1 = XM , and renumber the constraints such that the last r constraints will
be the unsatisfied ones (this value of r will be different from the previous value),
and go to step 2.
This procedure is repeated until all the constraints are satisfied and a point X1 =
XM is obtained for which gj (X1) < 0, j = 1, 2, . . . , m.
If the constraints are consistent, it should be possible to obtain, by applying the
procedure, a point X1 that satisfies all the constraints. However, there may exist situa-
tions in which the solution of the problem formulated in step 3 gives the unconstrained
or constrained local minimum of gk(X) that is positive. In such cases one has to start
afresh with a new point X1 from step 1 onward.
Initial Value of the Penalty Parameter (r1). Since the unconstrained minimization
of φ(X, rk) is to be carried out for a decreasing sequence of rk , it might appear that by
choosing a very small value of r1, we can avoid an excessive number of minimizations
of the function φ. But from a computational point of view, it will be easier to minimize
the unconstrained function φ(X, rk) if rk is large. This can be seen qualitatively from
Fig. 7.10b. As the value of rk becomes smaller, the value of the function φ changes
more rapidly in the vicinity of the minimum φ∗k . Since it is easier to find the minimum of
a function whose graph is smoother, the unconstrained minimization of φ will be easier
if rk is large. However, the minimum of φk, X
∗
k , will be farther away from the desired
minimum X∗ if rk is large. Thus it requires an excessive number of unconstrained
minimizations of φ(X, rk) (for several values of rk) to reach the point X
∗ if r1 is
selected to be very large. Thus a moderate value has to be choosen for the initial
penalty parameter (r1). In practice, a value of r1 that gives the value of φ(X1, r1)
approximately equal to 1.1 to 2.0 times the value of f (X1) has been found to be quite
satisfactory in achieving quick convergence of the process. Thus for any initial feasible
starting point X1, the value of r1 can be taken as
r1 ≃ 0.1 to 1.0
f (X1)
−
∑m
j=1 1/gj (X1)
(7.164)
Subsequent Values of the Penalty Parameter. Once the initial value of rk is chosen,
the subsequent values of rk+1 have to be chosen such that
rk+1 < rk (7.165)
For convenience, the values of rk are chosen according to the relation
rk+1 = crk (7.166)
where c < 1. The value of c can be taken as 0.1, 0.2, or 0.5.
Convergence Criteria. Since the unconstrained minimization of φ(X, rk) has to be
carried out for a decreasing sequence of values rk , it is necessary to use proper con-
vergence criteria to identify the optimum point and to avoid an unnecessarily large
number of unconstrained minimizations. The process can be terminated whenever the
following conditions are satisfied.
436 Nonlinear Programming III: Constrained Optimization Techniques
1. The relative difference between the values of the objective function obtained
at the end of any two consecutive unconstrained minimizations falls below a
small number ε1, that is,
∣
∣
∣
∣
f (X∗k) − f (X∗k−1)
f (X∗k)
∣
∣
∣
∣
≤ ε1 (7.167)
2. The difference between the optimum points X∗k and X
∗
k−1 becomes very small.
This can be judged in several ways. Some of them are given below:
|(	X)i | ≤ ε2 (7.168)
where 	X = X∗k − X∗k−1, and (	X)i is the ith component of the vector 	X.
max |(	X)i | ≤ ε3 (7.169)
|	X| = [(	X)21 + (	X)22 + · · · + (	X)2n]1/2 ≤ ε4 (7.170)
Note that the values of ε1 to ε4 have to be chosen depending on the character-
istics of the problem at hand.
Normalization of Constraints. A structural optimization problem, for example, might
be having constraints on the deflection (δ) and the stress (σ ) as
g1(X) = δ(X) − δmax ≤ 0 (7.171)
g2(X) = σ(X) − σmax ≤ 0 (7.172)
where the maximum allowable values are given by δmax = 0.5 in. and σmax =
20,000 psi. If a design vector X1 gives the values of g1 and g2 as −0.2 and −10,000,
the contribution of g1 will be much larger than that of g2 (by an order of 10
4)
in the formulation of the φ function given by Eq. (7.160). This will badly affect
the convergence rate during the minimization of φ function. Thus it is advisable to
normalize the constraints so that they vary between −1 and 0 as far as possible. For
the constraints shown in Eqs. (7.171) and (7.172), the normalization can be done as
g′1(X) =
g1(X)
δmax
=
δ(X)
δmax
− 1 ≤ 0 (7.173)
g′2(X) =
g2(X)
σmax
= σ(X)
σmax
− 1 ≤ 0 (7.174)
If the constraints are not normalized as shown in Eqs. (7.173) and (7.174), the problem
can still be solved effectively by defining different penalty parameters for different
constraints as
φ(X, rk) = f (X) − rk
m
∑
j=1
Rj
gj (X)
(7.175)
where R1, R2, . . . , Rm are selected such that the contributions of different gj (X) to the
φ function will be approximately the same at the initial point X1. When the uncon-
strained minimization of φ(X, rk) is carried for a decreasing sequence of values of
rk , the values of R1, R2, . . . , Rm will not be altered; however, they are expected to be
7.13 Interior Penalty Function Method 437
effective in reducing the disparities between the contributions of the various constraints
to the φ function.
Example 7.7
Minimize f (x1, x2) = 13 (x1 + 1)
3 + x2
subject to
g1(x1, x2) = −x1 + 1 ≤ 0
g2(x1, x2) = −x2 ≤ 0
SOLUTION To illustrate the interior penalty function method, we use the calculus
method for solving the unconstrained minimization problem in this case. Hence there
is no need to have an initial feasible point X1. The φ function is
φ(X, r) =
1
3
(x1 + 1)3 + x2 − r
(
1
−x1 + 1
−
1
x2
)
To find the unconstrained minimum of φ, we use the necessary conditions:
∂φ
∂x1
= (x1 + 1)2 −
r
(1 − x1)2
= 0, that is, (x21 − 1)2 = r
∂φ
∂x2
= 1 − r
x22
= 0, that is, x22 = r
These equations give
x∗1 (r) = (r1/2 + 1)1/2, x∗2 (r) = r1/2
φmin(r) = 13 [(r
1/2 + 1)1/2 + 1]3 + 2r1/2 − 1
(1/r)−(1/r3/2+1/r2)1/2
To obtain the solution of the original problem, we know that
fmin = lim
r→0
φmin(r)
x∗1 = lim
r→0
x∗1 (r)
x∗2 = lim
r→0
x∗2 (r)
The values of f , x∗1 , and x
∗
2 corresponding to a decreasing sequence of values of r are
shown in Table 7.3.
Example 7.8
Minimize f (X) = x31 − 6x21 + 11x1 + x3
subject to
x21 + x22 − x23 ≤ 0
4 − x21 − x22 − x23 ≤ 0
x3 − 5 ≤ 0
−xi ≤ 0, i = 1, 2, 3
438 Nonlinear Programming III: Constrained Optimization Techniques
Table 7.3 Results for Example 7.7
Value of r x∗1 (r) = (r1/2 + 1)1/2 x∗2 (r) = r1/2 φmin(r) f (r)
1000 5.71164 31.62278 376.2636 132.4003
100 3.31662 10.00000 89.9772 36.8109
10 2.04017 3.16228 25.3048 12.5286
1 1.41421 1.00000 9.1046 5.6904
0.1 1.14727 0.31623 4.6117 3.6164
0.01 1.04881 0.10000 3.2716 2.9667
0.001 1.01569 0.03162 2.8569 2.7615
0.0001 1.00499 0.01000 2.7267 2.6967
0.00001 1.00158 0.00316 2.6856 2.6762
0.000001 1.00050 0.00100 2.6727 2.6697
Exact solution 0 1 0 8/3 8/3
SOLUTION The interior penalty function method, coupled with the Davidon–Fletcher
–Powell method of unconstrained minimization and cubic interpolation method of
one-dimensional search, is used to solve this problem. The necessary data are assumed
as follows:
Starting feasible point, X1 =



0.1
0.1
3.0



r1 = 1.0, f (X1) = 4.041, φ(X1, r1) = 25.1849
The optimum solution of this problem is known to be [7.15]
X =





0
√
2
√
2





, f ∗ =
√
2
The results of numerical optimization are summarized in Table 7.4.
Convergence Proof. The following theorem proves the convergence of the interior
penalty function method.
Theorem 7.1 If the function
φ(X, rk) = f (X) − rk
m
∑
j=1
1
gj (X)
(7.176)
is minimized for a decreasing sequence of values of rk , the unconstrained minima X
∗
k
converge to the optimal solution of the constrained problem stated in Eq. (7.153) as
rk → 0.
7.13 Interior Penalty Function Method 439
Table 7.4 Results for Example 7.8
Number of
Starting point iterations taken
for minimizing for minimizing
k Value of rk φk φk Optimum X
∗
k φ
∗
k f
∗
k
1 1.0 × 100


0.1
0.1
3.0

 9


0.37898
1.67965
2.34617

 10.36219 5.70766
2 1.0 × 10−1


0.37898
1.67965
2.34617

 7


0.10088
1.41945
1.68302

 4.12440 2.73267
3 1.0 × 10−2


0.10088
1.41945
1.68302

 5


0.03066
1.41411
1.49842

 2.25437 1.83012
4 1.0 × 10−3


0.03066
1.41411
1.49842

 3


0.009576
1.41419
1.44081

 1.67805 1.54560
5 1.0 × 10−4


0.009576
1.41419
1.44081

 7


0.003020
1.41421
1.42263

 1.49745 1.45579
6 1.0 × 10−5


0.003020
1.41421
1.42263

 3


0.0009530
1.41421
1.41687

 1.44052 1.42735
7 1.0 × 10−6


0.0009530
1.41421
1.41687

 3


0.0003013
1.41421
1.41505

 1.42253 1.41837
8 1.0 × 10−7


0.0003013
1.41421
1.41505

 3


0.00009535
1.41421
1.41448

 1.41684 1.41553
9 1.0 × 10−8


0.00009535
1.41421
1.41448

 5


0.00003019
1.41421
1.41430

 1.41505 1.41463
10 1.0 × 10−9


0.00003019
1.41421
1.41430

 4


0.000009567
1.41421
1.41424

 1.41448 1.41435
11 1.0 × 10−10


0.000009567
1.41421
1.41424

 3


0.00003011
1.41421
1.41422

 1.41430 1.41426
12 1.0 × 10−11


0.000003011
1.41421
1.41422

 3


0.9562 × 10−6
1.41421
1.41422

 1.41424 1.41423
13 1.0 × 10−12


0.9562 × 10−6
1.41421
1.41422

 4


0.3248 × 10−6
1.41421
1.41421

 1.41422 1.41422
440 Nonlinear Programming III: Constrained Optimization Techniques
Proof : If X∗ is the optimum solution of the constrained problem, we have to prove
that
lim
rk→0
[min φ(X, rk)] = φ(X∗k, rk) = f (X∗) (7.177)
Since f (X) is continous and f (X∗) ≤ f (X) for all feasible points X, we can choose
feasible point
˜
X such that
f (
˜
X) < f (X∗) + ε
2
(7.178)
for any value of ε > 0. Next select a suitable value of k, say K , such that
rk ≤
{
ε
2m
/
min
j
[
−
1
gj (
˜
X)
]}
(7.179)
From the definition of the φ function, we have
f (X∗) ≤ min φ(X, rk) = φ(X∗k, rk) (7.180)
where X∗k is the unconstrained minimum of φ(X, rk). Further,
φ(X∗k, rk) ≤ φ(X∗K , rk) (7.181)
since X∗k minimizes φ(X, rk) and any X other than X
∗
k leads to a value of φ greater
than or equal to φ(X∗k, rk). Further, by choosing rk < rK , we obtain
φ(X∗K , rK ) = f (X∗K) − rK
m
∑
j=1
1
gj (X
∗
K)
>f (X∗K ) − rk
m
∑
j=1
1
gj (X
∗
K)
>φ(X∗k, rk) (7.182)
as X∗k is the unconstrained minimum of φ(X, rk). Thus
f (X∗) ≤ φ(X∗k, rk) ≤ φ(X∗K , rk) < φ(X∗K , rK) (7.183)
But
φ(X∗K , rK ) ≤ φ( ˜X, rK) = f ( ˜X) − rK
m
∑
j=1
1
gj (
˜
X)
(7.184)
Combining the inequalities (7.183) and (7.184), we have
f (X∗) ≤ φ(X∗k, rk) ≤ f ( ˜X) − rK
m
∑
j=1
1
gj (
˜
X)
(7.185)
Inequality (7.179) gives
−rK
m
∑
j=1
1
gj (
˜
X)
<
ε
2
(7.186)
7.13 Interior Penalty Function Method 441
By using inequalities (7.178) and (7.186), inequality (7.185) becomes
f (X∗) ≤ φ(X∗k, rk) < f (X∗) +
ε
2
+ ε
2
= f (X∗) + ε
or
φ(X∗k, rk) − f (X∗) < ε (7.187)
Given any ε > 0 (however small it may be), it is possible to choose a value of k so as
to satisfy the inequality (7.187). Hence as k → ∞(rk → 0), we have
lim
rk→0
φ(X∗k, rk) = f (X∗)
This completes the proof of the theorem.
Additional Results. From the proof above, it follows that as rk → 0,
lim
k→∞
f (X∗k) = f (X∗) (7.188)
lim
k→∞
rk

−
m
∑
j=1
1
gj (X
∗
k)

 = 0 (7.189)
It can also be shown that if r1, r2, . . . is a strictly decreasing sequence of positive values,
the sequence f (X∗1), f (X
∗
2), . . . will also be strictly decreasing. For this, consider two
consecutive parameters, say, rk and rk+1, with
0 < rk+1 < rk (7.190)
Then we have
f (X∗k+1) − rk+1
m
∑
j=1
1
gj (X
∗
k+1)
< f (X∗k) − rk+1
m
∑
j=1
1
gj (X
∗
k)
(7.191)
since X∗k+1 alone minimizes φ(X, rk+1). Similarly,
f (X∗k) − rk
m
∑
j=1
1
gj (X
∗
k)
< f (X∗k+1) − rk
m
∑
j=1
1
gj (X
∗
k+1)
(7.192)
Divide Eq. (7.191) by rk+1, Eq. (7.192) by rk , and add the resulting inequalities to
obtain
1
rk+1
f (X∗k+1) −
m
∑
j=1
1
gj (X
∗
k+1)
+ 1
rk
f (X∗k) −
m
∑
j=1
1
gj (X
∗
k)
<
1
rk+1
f (X∗k) −
m
∑
j=1
1
gj (X
∗
k)
+
1
rk
f (X∗k+1) −
m
∑
j=1
1
gj (X
∗
k+1)
(7.193)
442 Nonlinear Programming III: Constrained Optimization Techniques
Canceling the common terms from both sides, we can write the inequality (7.193) as
f (X∗k+1)
(
1
rk+1
−
1
rk
)
< f (X∗k)
(
1
rk+1
−
1
rk
)
(7.194)
since
1
rk+1
−
1
rk
=
rk − rk+1
rkrk+1
> 0 (7.195)
we obtain
f (X∗k+1) < f (X
∗
k) (7.196)
7.14 CONVEX PROGRAMMING PROBLEM
In Section 7.13 we saw that the sequential minimization of
φ(X, rk) = f (X) − rk
m
∑
j=1
1
gj (X)
, rk > 0 (7.197)
for a decreasing sequence of values of rk gives the minima X
∗
k . As k → ∞, these points
X∗k converge to the minimum of the constrained problem:
Minimize f (X)
subject to (7.198)
gj (X) ≤ 0, j = 1, 2, . . . , m
To ensure the existence of a global minimum of φ(X, rk) for every positive value
of rk , φ has to be strictly convex function of X. The following theorem gives the
sufficient conditions for the φ function to be strictly convex. If φ is convex, for every
rk > 0 there exists a unique minimum of φ(X, rk).
Theorem 7.2 If f (X) and gj (X) are convex and at least one of f (X) and gj (X) is
strictly convex, the function φ(X, rk) defined by Eq. (7.197) will be a strictly convex
function of X.
Proof : This theorem can be proved in two steps. In the first step we prove that if a
function gk(X) is convex, 1/gk(X) will be concave. In the second step, we prove that
a positive combination of convex functions is convex, and strictly convex if at least
one of the functions is strictly convex.
Thus Theorem A.3 of Appendix A guarantees that the sequential minimization of
φ(X, rk) for a decreasing sequence of values of rk leads to the global minimum of the
original constrained problem. When the convexity conditions are not satisfied, or when
the functions are so complex that we do not know beforehand whether the convexity
conditions are satisfied, it will not be possible to prove that the minimum found by the
7.15 Exterior Penalty Function Method 443
SUMT method is a global one. In such cases one has to satisfy with a local minimum
only. However, one can always reapply the SUMT method from different feasible
starting points and try to find a better local minimum point if the problem has several
local minima. Of course, this procedure requires more computational effort.
7.15 EXTERIOR PENALTY FUNCTION METHOD
In the exterior penalty function method, the φ function is generally taken as
φ(X, rk) = f (X) + rk
m
∑
j=1
〈gj (X)〉q (7.199)
where rk is a positive penalty parameter, the exponent q is a nonnegative constant, and
the bracket function 〈gj (X)〉 is defined as
〈gj (X)〉 = max〈gj (X), 0〉
=









gj (X) if gj (X) > 0
(constraint is violated)
0 if gj (X) ≤ 0
(constraint is satisfied)
(7.200)
It can be seen from Eq. (7.199) that the effect of the second term on the right side is to
increase φ(X, rk) in proportion to the qth power of the amount by which the constraints
are violated. Thus there will be a penalty for violating the constraints, and the amount of
penalty will increase at a faster rate than will the amount of violation of a constraint (for
q > 1). This is the reason why the formulation is called the penalty function method.
Usually, the function φ(X, rk) possesses a minimum as a function of X in the infeasible
region. The unconstrained minima X∗k converge to the optimal solution of the original
problem as k → ∞ and rk → ∞. Thus the unconstrained minima approach the feasible
domain gradually, and as k → ∞, the X∗k eventually lies in the feasible region. Let us
consider Eq. (7.199) for various values of q.
1. q = 0. Here the φ function is given by
φ(X, rk) = f (X) + rk
m
∑
j=1
〈gj (X)〉0
=
{
f (X) + mrk if all gj (X) > 0
f (X) if all gj (X) ≤ 0
(7.201)
This function is discontinuous on the boundary of the acceptable region as
shown in Fig. 7.11 and hence it would be very difficult to minimize this function.
2. 0 < q < 1. Here the φ function will be continuous, but the penalty for violating
a constraint may be too small. Also, the derivatives of the function are discon-
tinuous along the boundary. Thus it will be difficult to minimize the φ function.
Typical contours of the φ function are shown in Fig. 7.12.
444 Nonlinear Programming III: Constrained Optimization Techniques
Figure 7.11 A φ function discontinuous for q = 0.
Figure 7.12 Derivatives of a φ function discontinuous for 0 < q < 1.
3. q = 1. In this case, under certain restrictions, it has been shown by Zangwill
[7.16] that there exists an r0 so large that the minimum of φ(X, rk) is exactly
the constrained minimum of the original problem for all rk > r0. However, the
contours of the φ function look similar to those shown in Fig. 7.12 and possess
discontinuous first derivatives along the boundary. Hence despite the conve-
nience of choosing a single rk that yields the constrained minimum in one
unconstrained minimization, the method is not very attractive from computa-
tional point of view.
7.15 Exterior Penalty Function Method 445
Figure 7.13 A φ function for q > 1.
4. q > 1. The φ function will have continuous first derivatives in this case as shown
in Fig. 7.13. These derivatives are given by
∂φ
∂xi
=
∂f
∂xi
+ rk
m
∑
j=1
q〈gj (X)〉q−1
∂gj (X)
∂xi
(7.202)
Generally, the value of q is chosen as 2 in practical computation. We assume a
value of q > 1 in subsequent discussion of this method.
Algorithm. The exterior penalty function method can be stated by the following
steps:
1. Start from any design X1 and a suitable value of r1. Set k = 1.
2. Find the vector X∗k that minimizes the function
φ(X, rk) = f (X) + rk
m
∑
j=1
〈gj (X)〉q
3. Test whether the point X∗k satisfies all the constraints. If X
∗
k is feasible, it is the
desired optimum and hence terminate the procedure. Otherwise, go to step 4.
4. Choose the next value of the penalty parameter that satisfies the relation
rk+1 >rk
and set the new value of k as original k plus 1 and go to step 2. Usually,
the value of rk+1 is chosen according to the relation rk+1 = crk , where c is a
constant greater than 1.
446 Nonlinear Programming III: Constrained Optimization Techniques
Example 7.9
Minimize f (x1, x2) = 13 (x1 + 1)
3 + x2
subject to
g1(x1, x2) = 1 − x1 ≤ 0
g2(x1, x2) = −x2 ≤ 0
SOLUTION To illustrate the exterior penalty function method, we solve the uncon-
strained minimization problem by using differential calculus method. As such, it is not
necessary to have an initial trial point X1. The φ function is
φ(X1, r) = 13 (x1 + 1)
3 + x2 + r[max(0, 1 − x1)]2 + r[max(0, −x2)]2
The necessary conditions for the unconstrained minimum of φ(X, r) are
∂φ
∂x1
= (x1 + 1)2 − 2r[max(0, 1 − x1)] = 0
∂φ
∂x2
= 1 − 2r[max(0, −x2)] = 0
These equations can be written as
min[(x1 + 1)2, (x1 + 1)2 − 2r(1 − x1)] = 0 (E1)
min[1, 1 + 2rx2] = 0 (E2)
In Eq. (E1), if (x1 + 1)2 = 0, x1 = −1 (this violates the first constraint), and if
(x1 + 1)2 − 2r(1 − x1) = 0, x1 = −1 − r +
√
r2 + 4r
In Eq. (E2), the only possibility is that 1 + 2rx2 = 0 and hence x2 = −1/2r . Thus the
solution of the unconstrained minimization problem is given by
x∗1 (r) = −1 − r + r
(
1 + 4
r
)1/2
(E3)
x∗2 (r) = −
1
2r
(E4)
From this, the solution of the original constrained problem can be obtained as
x∗1 = lim
r→∞
x∗1 (r) = 1, x∗2 = lim
r→∞
x∗2 (r) = 0
fmin = lim
r→∞
φmin(r) = 83
The convergence of the method, as r increases gradually, can be seen from Table 7.5.
7.16 Extrapolation Techniques in the Interior Penalty Function Method 447
Table 7.5 Results for Example 7.9
Value of r x∗1 x
∗
2 φmin(r) fmin(r)
0.001 −0.93775 −500.00000 −249.9962 −500.0000
0.01 −0.80975 −50.00000 −24.9650 −49.9977
0.1 −0.45969 −5.00000 −2.2344 −4.9474
1 0.23607 −0.50000 0.9631 0.1295
10 0.83216 −0.05000 2.3068 2.0001
100 0.98039 −0.00500 2.6249 2.5840
1,000 0.99800 −0.00050 2.6624 2.6582
10,000 0.99963 −0.00005 2.6655 2.6652
∞ 1 0 8
3
8
3
Convergence Proof. To prove the convergence of the algorithm given above, we
assume that f and gj , j = 1, 2, . . . , m, are continuous and that an optimum solution
exists for the given problem. The following results are useful in proving the convergence
of the exterior penalty function method.
Theorem 7.3 If
φ(X, rk) = f (X) + rkG[g(X)] = f (X) + rk
m
∑
j=1
〈gj (X)〉q
the following relations will be valid for any 0 < rk < rk+1:
1. φ(X∗k, rk) ≤ φ(X∗k+1, rk+1).
2. f (X∗k) ≤ f (X∗k+1).
3. G[g(X∗k)] ≥ G[g(X∗k+1)].
Proof : The proof is similar to that of Theorem 7.1.
Theorem 7.4 If the function φ(X, rk) given by Eq. (7.199) is minimized for an increas-
ing sequence of values of rk, the unconstrained minima X
∗
k converge to the optimum
solution (X∗) of the constrained problem as rk → ∞.
Proof : The proof is similar to that of Theorem 7.1 (see Problem 7.46).
7.16 EXTRAPOLATION TECHNIQUES IN THE INTERIOR
PENALTY FUNCTION METHOD
In the interior penalty function method, the φ function is minimized sequentially for
a decreasing sequence of values r1 >r2 > · · · >rk to find the unconstrained minima
X∗1, X
∗
2, . . . , X
∗
k , respectively. Let the values of the objective function corresponding to
X∗1, X
∗
2, . . . , X
∗
k be f
∗
1 , f
∗
2 , . . . , f
∗
k , respectively. It has been proved that the sequence
448 Nonlinear Programming III: Constrained Optimization Techniques
X∗1, X
∗
2, . . . , X
∗
k converges to the minimum point X
∗, and the sequence f ∗1 , f
∗
2 , . . . , f
∗
k
to the minimum value f ∗ of the original constrained problem stated in Eq. (7.153) as
rk → 0. After carrying out a certain number of unconstrained minimizations of φ, the
results obtained thus far can be used to estimate the minimum of the original constrained
problem by a method known as the extrapolation technique. The extrapolations of the
design vector and the objective function are considered in this section.
7.16.1 Extrapolation of the Design Vector X
Since different vectors X∗i , i = 1, 2, . . . , k, are obtained as unconstrained minima of
φ(X, ri) for different ri , i = 1, 2, . . . , k, the unconstrained minimum φ(X, r) for any
value of r , X∗(r), can be approximated by a polynomial in r as
X∗(r) =
k−1
∑
j=0
Aj (r)
j = A0 + rA1 + r2A2 + · · · + rk−1Ak−1 (7.203)
where Aj are n-component vectors. By substituting the known conditions
X∗(r = ri) = X∗i , i = 1, 2, . . . , k (7.204)
in Eq. (7.203), we can determine the vectors Aj , j = 0, 1, 2, . . . , k − 1 uniquely. Then
X∗(r), given by Eq. (7.203), will be a good approximation for the unconstrained min-
imum of φ(X, r) in the interval (0, r1). By setting r = 0 in Eq. (7.203), we can obtain
an estimate to the true minimum, X∗, as
X∗ = X∗(r = 0) = A0 (7.205)
It is to be noted that it is not necessary to approximate X∗(r) by a (k − 1) st-order
polynomial in r . In fact, any polynomial of order 1 ≤ p ≤ k − 1 can be used to approx-
imate X∗(r). In such a case we need only p + 1 points out of X∗1, X∗2, . . . , X∗k to define
the polynomial completely.
As a simplest case, let us consider approximating X∗(r) by a first-order polynomial
(linear equation) in r as
X∗(r) = A0 + rA1 (7.206)
To evaluate the vectors A0 and A1, we need the data of two unconstrained minima. If
the extrapolation is being done at the end of the kth unconstrained minimization, we
generally use the latest information to find the constant vectors A0 and A1. Let X
∗
k−1
and X∗k be the unconstrained minima corresponding to rk−1 and rk, respectively. Since
rk = crk−1 (c < 1), Eq. (7.206) gives
X∗(r = rk−1) = A0 + rk−1A1 = X∗k−1
X∗(r = rk) = A0 + crk−1A1 = X∗k
(7.207)
These equations give
A0 =
X∗k − cX∗k−1
1 − c
A1 =
X∗k−1 − X∗k
rk−1(1 − c)
(7.208)
7.16 Extrapolation Techniques in the Interior Penalty Function Method 449
From Eqs. (7.206) and (7.208), the extrapolated value of the true minimum can be
obtained as
X∗(r = 0) = A0 =
X∗k − cX∗k−1
1 − c
(7.209)
The extrapolation technique [Eq. (7.203)] has several advantages:
1. It can be used to find a good estimate to the optimum of the original problem
with the help of Eq. (7.205).
2. It can be used to provide an additional convergence criterion to terminate the
minimization process. The point obtained at the end of the kth iteration, X∗k ,
can be taken as the true minimum if the relation
|X∗k − X∗(r = 0)| ≤ ε (7.210)
is satisfied, where ε is the vector of prescribed small quantities.
3. This method can also be used to estimate the next minimum of the φ function
after a number of minimizations have been completed. This estimate† can be
used as a starting point for the (k + 1)st minimization of the φ function. The
estimate of the (k + 1)st minimum, based on the information collected from the
previous k minima, is given by Eq. (7.203) as
X∗k+1 ≃ X∗(r = rk+1 = r1ck)
= A0 + (r1ck)A1 + (r1ck)2A2 + · · · + Ak−1(r1ck)k−1 (7.211)
If Eqs. (7.206) and (7.208) are used, this estimate becomes
Xk+1 ≃ X∗(r = c2rk−1) = A0 + c2rk−1A1
= (1 + c)X∗k − cX∗k−1 (7.212)
Discussion. It has been proved that under certain conditions, the difference between
the true minimum X∗ and the estimate X∗(r = 0) = A0 will be of the order rk1 [7.17].
Thus as r1 → 0, A0 → X∗. Moreover, if r1 < 1, the estimates of X∗ obtained by
using k minima will be better than those using (k − 1) minima, and so on. Hence as
more minima are achieved, the estimate of X∗ or X∗k+1 presumably gets better. This
estimate can be used as the starting point for the (k + 1)st minimization of the φ
function. This accelerates the entire process by substantially reducing the effort needed
to minimize the successive φ functions. However, the computer storage requirements
and accuracy considerations (such as numerical round-off errors that become important
for higher-order estimates) limit the order of polynomial in Eq. (7.203). It has been
found in practice that extrapolations with the help of even quadratic and cubic equations
in r generally yield good estimates for X∗k+1 and X
∗. Note that the extrapolated points
given by any of Eqs. (7.205), (7.209), (7.211), and (7.212) may sometimes violate the
constraints. Hence we have to check any extrapolated point for feasibility before using
it as a starting point for the next minimization of φ. If the extrapolated point is found
infeasible, it has to be rejected.
†The estimate obtained for X∗ can also be used as a starting point for the (k + 1)st minimization of the φ
function.
450 Nonlinear Programming III: Constrained Optimization Techniques
7.16.2 Extrapolation of the Function f
As in the case of the design vector, it is possible to use extrapolation technique
to estimate the optimum value of the original objective function, f ∗. For this, let
f ∗1 , f
∗
2 , . . . , f
∗
k be the values of the objective function corresponding to the vectors
X∗1, X
∗
2, . . . , X
∗
k . Since the points X
∗
1, X
∗
2, . . . , X
∗
k have been found to be the uncon-
strained minima of the φ function corresponding to r1, r2, . . . , rk , respectively, the
objective function, f ∗, can be assumed to be a function of r . By approximating f ∗ by
a (k − 1)st-order polynomial in r , we have
f ∗(r) =
k−1
∑
j=0
aj (r)
j = a0 + a1r + a2r2 + · · · + ak−1rk−1 (7.213)
where the k constants aj , j = 0, 1, 2, . . . , k − 1 can be evaluated by substituting the
known conditions
f ∗(r = ri) = f ∗i = a0 + a1ri + a2r2i + · · · + ak−1rk−1i , i = 1, 2, . . . , k (7.214)
Since Eq. (7.213) is a good approximation for the true f ∗ in the interval (0, r1), we
can obtain an estimate for the constrained minimum of f as
f ∗ ≃ f ∗(r = 0) = a0 (7.215)
As a particular case, a linear approximation can be made for f ∗ by using the last two
data points. Thus if f ∗k−1 and f
∗
k are the function values corresponding to rk−1 and
rk = crk−1, we have
f ∗k−1 = a0 + rk−1a1
f ∗k = a0 + crk−1a1
(7.216)
These equations yield
a0 =
f ∗k − cf ∗k−1
1 − c
(7.217)
a1 =
f ∗k−1 − f ∗k
rk−1(1 − c)
(7.218)
f ∗(r) =
f ∗k − cf ∗k−1
1 − c
+ r
rk−1
f ∗k−1 − f ∗k
1 − c
(7.219)
Equation (7.219) gives an estimate of f ∗ as
f ∗ ≃ f ∗(r = 0) = a0 =
f ∗k − cf ∗k−1
1 − c
(7.220)
The extrapolated value a0 can be used to provide an additional convergence criterion
for terminating the interior penalty function method. The criterion is that whenever the
value of f ∗k obtained at the end of kth unconstrained minimization of φ is sufficiently
close to the extrapolated value a0, that is, when
∣
∣
∣
∣
f ∗k − a0
f ∗k
∣
∣
∣
∣
≤ ε (7.221)
where ε is a specified small quantity, the process can be terminated.
7.17 Extended Interior Penalty Function Methods 451
Example 7.10 Find the extrapolated values of X and f in Example 7.8 using the
results of minimization of φ(X, r1) and φ(X, r2).
SOLUTION From the results of Example 7.8, we have for r1 = 1.0,
X∗1 =



0.37898
1.67965
2.34617



, f ∗1 = 5.70766
and for r2 = 0.1,
c = 0.1, X∗2 =



0.10088
1.41945
1.68302



, f ∗2 = 2.73267
By using Eq. (7.206) for approximating X∗(r), the extrapolated vector X∗ is given by
Eq. (7.209) as
X∗ ≃ A0 =
X∗2 − cX∗1
1 − c
=
1
0.9





0.10088
1.41945
1.68302



− 0.1



0.37898
1.67865
2.34617




 (E1)
=



0.06998
1.39053
1.60933



(E2)
Similarly, the linear resltionships f ∗(r) = a0 + a1r leads to [from Eq. (7.220)]
f ∗ ≃
f ∗2 − cf ∗1
1 − c
= 1
0.9
[2.73267 − 0.1(5.707667)] = 2.40211 (E3)
It can be verified that the extrapolated design vector X∗ is feasible and hence can be
used as a better starting point for the subsequent minimization of the function φ.
7.17 EXTENDED INTERIOR PENALTY FUNCTION METHODS
In the interior penalty function approach, the φ function is defined within the feasible
domain. As such, if any of the one-dimensional minimization methods discussed in
Chapter 5 is used, the resulting optimal step lengths might lead to infeasible designs.
Thus the one-dimensional minimization methods have to be modified to avoid this prob-
lem. An alternative method, known as the extended interior penalty function method ,
has been proposed in which the φ function is defined outside the feasible region. The
extended interior penalty function method combines the best features of the interior and
exterior methods for inequality constraints. Several types of extended interior penalty
function formulations are described in this section.
7.17.1 Linear Extended Penalty Function Method
The linear extended penalty function method was originally proposed by Kavlie and
Moe [7.18] and later improved by Cassis and Schmit [7.19]. In this method, the φk
452 Nonlinear Programming III: Constrained Optimization Techniques
function is constructed as follows:
φk = φ(X, rk) = f (X) + rk
m
∑
j=1
g̃j (X) (7.222)
where
g̃j (X) =







− 1
gj (X)
if gj (X) ≤ ε
−
2ε − gj (X)
ε2
if gj (X) > ε
(7.223)
and ε is a small negative number that marks the transition from the interior penalty
[gj (X) ≤ ε] to the extended penalty [gj (X) > ε]. To produce a sequence of improved
feasible designs, the value of ε is to be selected such that the function φk will have a
positive slope at the constraint boundary. Usually, ε is chosen as
ε = −c(rk)a (7.224)
where c and a are constants. The constant a is chosen such that 1
3
≤ a ≤ 1
2
, where
the value of a = 1
3
guarantees that the penalty for violating the constraints increases
as rk goes to zero while the value of a = 12 is required to help keep the minimum
point X∗ in the quadratic range of the penalty function. At the start of optimization,
ε is selected in the range −0.3 ≤ ε ≤ −0.1. The value of r1 is selected such that the
values of f (X) and r1
∑m
j=1 g̃j (X) are equal at the initial design vector X1. This defines
the value of c in Eq. (7.224). The value of ε is computed at the beginning of each
unconstrained minimization using the current value of rk from Eq. (7.224) and is kept
constant throughout that unconstrained minimization. A flowchart for implementing the
linear extended penalty function method is given in Fig. 7.14.
7.17.2 Quadratic Extended Penalty Function Method
The φk function defined by Eq. (7.222) can be seen to be continuous with continuous
first derivatives at gj (X) = ε. However, the second derivatives can be seen to be
discontinuous at gj (X) = ε. Hence it is not possible to use a second-order method for
unconstrained minimization [7.20]. The quadratic extended penalty function is defined
so as to have continuous second derivatives at gj (X) = ε as follows:
φk = φ(X, rk) = f (X) + rk
m
∑
j=1
g̃j (X) (7.225)
where
g̃j (X) =











−
1
gj (X)
if gj (X) ≤ ε
{
−
1
ε
[
gj (X)
ε
]2
− 3
gj (X)
ε
+ 3
}
if gj (X) > ε
(7.226)
With this definition, second-order methods can be used for the unconstrained mini-
mization of φk. It is to be noted that the degree of nonlinearity of φk is increased in
7.18 Penalty Function Method for Problems with Mixed Equality and Inequality Constraints 453
Figure 7.14 Linear extended penalty function method.
Eq. (7.225) compared to Eq. (7.222). The concept of extended interior penalty function
approach can be generalized to define a variable penalty function method from which
the linear and quadratic methods can be derived as special cases [7.24].
Example 7.11 Plot the contours of the φk function using the linear extended interior
penalty function for the following problem:
Minimize f (x) = (x − 1)2
subject to
g1(x) = 2 − x ≤ 0
g2(x) = x − 4 ≤ 0
SOLUTION We choose c = 0.2 and a = 0.5 so that ε = −0.2√rk . The φk function
is defined by Eq. (7.222). By selecting the values of rk as 10.0, 1.0, 0.1, and 0.01
sequentially, we can determine the values of φk for different values of x, which can
then be plotted as shown in Fig. 7.15. The graph of f (x) is also shown in Fig. 7.15
for comparison.
7.18 PENALTY FUNCTION METHOD FOR PROBLEMS
WITH MIXED EQUALITY AND INEQUALITY CONSTRAINTS
The algorithms described in previous sections cannot be directly applied to solve prob-
lems involving strict equality constraints. In this section we consider some of the
454 Nonlinear Programming III: Constrained Optimization Techniques
Figure 7.15 Graphs of φk .
methods that can be used to solve a general class of problems.
Minimize f (X)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m
lj (X) = 0, j = 1, 2, . . . , p
(7.227)
7.18.1 Interior Penalty Function Method
Similar to Eq. (7.154), the present problem can be converted into an unconstrained
minimization problem by constructing a function of the form
φk = φ(X, rk) = f (X) + rk
m
∑
j=1
Gj [gj (X)] + H(rk)
p
∑
j=1
l2j (X) (7.228)
where Gj is some function of the constraint gj tending to infinity as the constraint
boundary is approached, and H (rk) is some function of the parameter rk tending to
infinity as rk tends to zero. The motivation for the third term in Eq. (7.228) is that as
7.18 Penalty Function Method for Problems with Mixed Equality and Inequality Constraints 455
H(rk) → ∞, the quantity pj=1l2j (X) must tend to zero. If 
p
j=1l
2
j (X) does not tend to
zero, φk would tend to infinity, and this cannot happen in a sequential minimization
process if the problem has a solution. Fiacco and McCormick [7.17, 7.21] used the
following form of Eq. (7.228):
φk = φ(X, rk) = f (X) − rk
m
∑
j=1
1
gj (X)
+ 1√
rk
p
∑
j=1
l2j (X) (7.229)
If φk is minimized for a decreasing sequence of values rk, the following theorem proves
that the unconstrained minima X∗k will converge to the solution X
∗ of the original
problem stated in Eq. (7.227).
Theorem 7.5 If the problem posed in Eq. (7.227) has a solution, the unconstrained min-
ima, X∗k , of φ(X, rk), defined by Eq. (7.229) for a sequence of values r1 >r2 > · · · >rk ,
converge to the optimal solution of the constrained problem [Eq. (7.227)] as rk → 0.
Proof : A proof similar to that of Theorem 7.1 can be given to prove this theorem.
Further, the solution obtained at the end of sequential minimization of φk is guaranteed
to be the global minimum of the problem, Eqs. (7.227), if the following conditions are
satisfied:
(i) f (X) is convex.
(ii) gj (X), j = 1, 2, . . . , m are convex.
(iii) 
p
j=1l
2
j (X) is convex in the interior feasible domain defined by the inequality
constraints.
(iv) One of the functions among f (X), g1(X), g2(X), . . . , gm(X), and 
p
j=1l
2
j (X)
is strictly convex.
Note:
1. To start the sequential unconstrained minimization process, we have to start from
a point X1 at which the inequality constraints are satisfied and not necessarily
the equality constraints.
2. Although this method has been applied to solve a variety of practical problems,
it poses an extremely difficult minimization problem in many cases, mainly
because of the scale disparities that arise between the penalty terms
−rk
m
∑
j=1
1
gj (X)
and
1
r
1/2
k
p
∑
j=1
l2j (X)
as the minimization process proceeds.
7.18.2 Exterior Penalty Function Method
To solve an optimization problem involving both equality and inequality constraints as
stated in Eqs. (7.227), the following form of Eq. (7.228) has been proposed:
φk = φ(X, rk) = f (X) + rk
m
∑
j=1
〈gj (X)〉2 + rk
p
∑
j=1
l2j (X) (7.230)
456 Nonlinear Programming III: Constrained Optimization Techniques
As in the case of Eq. (7.199), this function has to be minimized for an increasing
sequence of values of rk. It can be proved that as rk → ∞, the unconstrained minima,
X∗k , of φ(X, rk) converge to the minimum of the original constrained problem stated
in Eq. (7.227).
7.19 PENALTY FUNCTION METHOD FOR PARAMETRIC
CONSTRAINTS
7.19.1 Parametric Constraint
In some optimization problems, a particular constraint may have to be satisfied over a
range of some parameter (θ ) as
gj (X, θ) ≤ 0, θl ≤ θ ≤ θu (7.231)
where θl and θu are lower and the upper limits on θ , respectively. These types of
constraints are called parametric constraints . As an example, consider the design of
a four-bar linkage shown in Fig. 7.16. The angular position of the output link φ will
depend on the angular position of the input link, θ , and the lengths of the links, l1, l2,
l3, and l4. If li(i = 1 to 4) are taken as the design variables xi(i = 1 to 4), the angular
position of the output link, φ(X, θ), for any fixed value of θ(θi) can be changed by
changing the design vector, X. Thus if φ(θ) is the output desired, the output φ(X, θ)
generated will, in general, be different from that of φ(θ), as shown in Fig. 7.17. If the
linkage is used in some precision equipment, we would like to restrict the difference
|φ(θ) − φ(X, θ)| to be smaller than some permissible value, say, ε. Since this restriction
has to be satisfied for all values of the parameter θ , the constraint can be stated as a
parametric constraint as
|φ(θ) − φ(X, θ)| ≤ ε, 0◦ ≤ θ ≤ 360◦ (7.232)
Sometimes the number of parameters in a parametric constraint may be more than
one. For example, consider the design of a rectangular plate acted on by an arbitrary load
as shown in Fig. 7.18. If the magnitude of the stress induced under the given loading,
|σ(x, y)|, is restricted to be smaller than the allowable value σmax, the constraint can
Figure 7.16 Four-bar linkage.
7.19 Penalty Function Method for Parametric Constraints 457
Figure 7.17 Output angles generated and desired.
Figure 7.18 Rectangular plate under arbitrary load.
be stated as a parametric constraint as
|σ(x, y)| − σmax ≤ 0, 0 ≤ x ≤ a, 0 ≤ y ≤ b (7.233)
Thus this constraint has to be satisfied at all the values of parameters x and y.
7.19.2 Handling Parametric Constraints
One method of handling a parametric constraint is to replace it by a number of ordinary
constraints as
gj (X, θi) ≤ 0, i = 1, 2, . . . , r (7.234)
where θ1, θ2, . . . , θr are discrete values taken in the range of θ . This method is not
efficient, for the following reasons:
1. It results in a very large number of constraints in the optimization problem.
2. Even if all the r constraints stated in Eq. (7.234) are satisfied, the constraint may
still be violated at some other value of θ [i.e., gj (X, θ) > 0 where θk < θ < θk+1
for some k].
458 Nonlinear Programming III: Constrained Optimization Techniques
Another method of handling the parametric constraints is to construct the φ function
in a different manner as follows [7.1, 7.15].
Interior Penalty Function Method
φ(X, rk) = f (X) − rk
m
∑
j=1
[
∫ θu
θl
1
gj (X, θ)
dθ
]
(7.235)
The idea behind using the integral in Eq. (7.235) for a parametric constraint is to
make the integral tend to infinity as the value of the constraint gj (X, θ) tends to zero
even at one value of θ in its range. If a gradient method is used for the unconstrained
minimization of φ(X, rk), the derivatives of φ with respect to the design variables
xi(i = 1, 2, . . . , n) are needed. Equation (7.235) gives
∂φ
∂xi
(X, rk) =
∂f
∂xi
(X) + rk
m
∑
j=1
[
∫ θu
θl
1
g2j (X, θ)
∂gj
∂xi
(X, θ)dθ
]
(7.236)
by assuming that the limits of integration, θl and θu, are indepdnent of the design
variables xi . Thus it can be noticed that the computation of φ(X, rk) or ∂φ(X, rk)/∂xi
involves the evaluation of an integral. In most of the practical problems, no closed-form
expression will be available for gj (X, θ ), and hence we have to use some sort of a
numerical integration process to evaluate φ or ∂φ/∂xi . If trapezoidal rule [7.22] is used
to evaluate the integral in Eq. (7.235), we obtain†
φ(X, rk) = f (X) − rk
m
∑
r=1



	θ
2
[
1
gj (X, θl)
+ 1
gj (X, θu)
]
+	θ
r−1
∑
p=2
1
gj (X, θp)



(7.237)
†Let the interval of the parameter θ be divided into r − 1 equal divisions so that
θ1 = θl, θ2 = θ1 + 	θ, θ3 = θ1 + 2. 	θ, . . . , θr = θ1 + (r − 1)	θ = θu,
	θ =
θu − θl
r − 1
If the graph of the function gj (X, θ) looks as shown in Fig. 7.19, the integral of 1/gj (X, θ) can be found
approximately by adding the areas of all the trapeziums, like ABCD . This is the reason why the method is
known as trapezoidal rule. The sum of all the areas is given by
∫ θu
θl
dθ
gj (X, θ)
≈
r−1
∑
l=1
Al =
r−1
∑
p=1
[
1
gj (X, θp)
+
1
gj (X, θp+1)
]
	θ
2
=
	θ
2
[
1
gj (X, θl)
+
1
gj (X, θu)
]
+
r−1
∑
p=2
	θ
gj (X, θp)
7.20 Augmented Lagrange Multiplier Method 459
Figure 7.19 Numerical integration procedure.
where r is the number of discrete values of θ , and 	θ is the uniform spacing between
the discrete values so that
θ1 = θl, θ2 = θ1 + 	θ,
θ3 = θ1 + 2	θ, . . . , θr = θ1 + (r − 1)	θ = θu
If gj (X, θ) cannot be expressed as a closed-form function of X, the derivative ∂gj/∂xi
occurring in Eq. (7.236) has to be evaluated by using some form of a finite-difference
formula.
Exterior Penalty Function Method
φ(X, rk) = f (X) + rk
m
∑
j=1
[∫ θu
θl
〈gj (X, θ)〉2dθ
]
(7.238)
The method of evaluating φ(X, rk) will be similar to that of the interior penalty function
method.
7.20 AUGMENTED LAGRANGE MULTIPLIER METHOD
7.20.1 Equality-Constrained Problems
The augmented Lagrange multiplier (ALM) method combines the Lagrange multiplier
and the penalty function methods. Consider the following equality-constrained problem:
Minimize f (X) (7.239)
460 Nonlinear Programming III: Constrained Optimization Techniques
subject to
hj (X) = 0, j = 1, 2, . . . , p, p < n (7.240)
The Lagrangian corresponding to Eqs. (7.239) and (7.240) is given by
L(X, λ) = f (X) +
p
∑
j=1
λjhj (X) (7.241)
where λj , j = 1, 2, . . . , p, are the Lagrange multipliers. The necessary conditions for
a stationary point of L(X, λ) include the equality constraints, Eq. (7.240). The exterior
penalty function approach is used to define the new objective function A(X, λ, rk),
termed the augmented Lagrangian function , as
A(X, λ, rk) = f (X) +
p
∑
j=1
λjhj (X) + rk
p
∑
j=1
h2j (X) (7.242)
where rk is the penalty parameter. It can be noted that the function A reduces to the
Lagrangian if rk = 0 and to the φ function used in the classical penalty function method
if all λj = 0. It can be shown that if the Lagrange multipliers are fixed at their optimum
values λ∗j , the minimization of A(X, λ, rk) gives the solution of the problem stated in
Eqs. (7.239) and (7.240) in one step for any value of rk . In such a case there is no need
to minimize the function A for an increasing sequence of values of rk. Since the values
of λ∗j are not known in advance, an iterative scheme is used to find the solution of the
problem. In the first iteration (k = 1), the values of λ(k)j are chosen as zero, the value
of rk is set equal to an arbitrary constant, and the function A is minimized with respect
to X to find X∗(k). The values of λ(k)j and rk are then updated to start the next iteration.
For this, the necessary conditions for the stationary point of L, given by Eq. (7.241),
are written as
∂L
∂xi
= ∂f
∂xi
+
p
∑
j=1
λ∗j
∂hj
∂xi
= 0, i = 1, 2, . . . , n (7.243)
where λ∗j denote the values of Lagrange multipliers at the stationary point of L. Simi-
larly, the necessary conditions for the minimum of A can be expressed as
∂A
∂xi
= ∂f
∂xi
+
p
∑
j=1
(λj + 2rkhj )
∂hj
∂xi
= 0, i = 1, 2, . . . , n (7.244)
A comparison of the right-hand sides of Eqs. (7.243) and (7.244) yields
λ∗j = λj + 2rkhj , j = 1, 2, . . . , p (7.245)
These equations are used to update the values of λj as
λ
(k+1)
j = λ
(k)
j + 2rkhj (X
(k)), j = 1, 2, . . . , p (7.246)
7.20 Augmented Lagrange Multiplier Method 461
where X(k) denotes the starting vector used in the minimization of A. The value of rk
is updated as
rk+1 = crk, c > 1 (7.247)
The function A is then minimized with respect to X to find X∗(k+1) and the iterative
process is continued until convergence is achieved for λ
(k)
j or X
∗. If the value of rk+1
exceeds a prespecified maximum value rmax, it is set equal to rmax. The iterative process
is indicated as a flow diagram in Fig. 7.20.
Figure 7.20 Flowchart of augmented Lagrange multiplier method.
462 Nonlinear Programming III: Constrained Optimization Techniques
7.20.2 Inequality-Constrained Problems
Consider the following inequality-constrained problem:
Minimize f (X) (7.248)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m (7.249)
To apply the ALM method, the inequality constraints of Eq. (7.249) are first converted
to equality constraints as
gj (X) + y2j = 0, j = 1, 2, . . . , m (7.250)
where y2j are the slack variables. Then the augmented Lagrangian function is con-
structed as
A(X, λ, Y, rk) = f (X) +
m
∑
j=1
λj [gj (X) + y2j ] +
m
∑
j=1
rk[gj (X) + y2j ]2 (7.251)
where the vector of slack variables, Y, is given by
Y =









y1
y2
...
ym









If the slack variables yj , j = 1, 2, . . . , m, are considered as additional unknowns, the
function A is to be minimized with respect to X and Y for specified values of λj and
rk . This increases the problem size. It can be shown [7.23] that the function A given
by Eq. (7.251) is equivalent to
A(X, λ, rk) = f (X) +
m
∑
j=1
λjαj + rk
m
∑
j=1
α2j (7.252)
where
αj = max
{
gj (X), −
λj
2rk
}
(7.253)
Thus the solution of the problem stated in Eqs. (7.248) and (7.249) can be obtained by
minimizing the function A, given by Eq. (7.252), as in the case of equality-constrained
problems using the update formula
λ
(k+1)
j = λ
(k)
j + 2rkα
(k)
j , j = 1, 2, . . . , m (7.254)
in place of Eq. (7.246). It is to be noted that the function A, given by Eq. (7.252), is
continuous and has continuous first derivatives but has discontinuous second derivatives
with respect to X at gj (X) = −λj/2rk . Hence a second-order method cannot be used
to minimize the function A.
7.20 Augmented Lagrange Multiplier Method 463
7.20.3 Mixed Equality–Inequality-Constrained Problems
Consider the following general optimization problem:
Minimize f (X) (7.255)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m (7.256)
hj (X) = 0, j = 1, 2, . . . , p (7.257)
This problem can be solved by combining the procedures of the two preceding sections.
The augmented Lagrangian function, in this case, is defined as
A(X, λ, rk) = f (X) +
m
∑
j=1
λjαj +
p
∑
j=1
λm+jhj (X)
+ rk
m
∑
j=1
α2j + rk
p
∑
j=1
h2j (X) (7.258)
where αj is given by Eq. (7.253). The solution of the problem stated in Eqs. (7.255)
to (7.257) can be found by minimizing the function A, defined by Eq. (7.258), as in
the case of equality-constrained problems using the update formula
λ(k+1) = λ(k)j + 2rk max
{
gj (X), −
λ
(k)
j
2rk
}
, j = 1, 2, . . . , m (7.259)
λ
(k+1)
m+j = λ
(k)
m+j + 2rkhj (X), j = 1, 2, . . . , p (7.260)
The ALM method has several advantages. As stated earlier, the value of rk need not
be increased to infinity for convergence. The starting design vector, X(1), need not
be feasible. Finally, it is possible to achieve gj (X) = 0 and hj (X) = 0 precisely and
the nonzero values of the Lagrange multipliers (λj = 0) identify the active contraints
automatically.
Example 7.12
Minimize f (X) = 6x21 + 4x1x2 + 3x22 (E1)
subject to
h(X) = x1 + x2 − 5 = 0 (E2)
using the ALM method.
SOLUTION The augmented Lagrangian function can be constructed as
A(X, λ, rk) = 6x21 + 4x1x2 + 3x22 + λ(x1 + x2 − 5)
+ rk(x1 + x2 − 5)2 (E3)
464 Nonlinear Programming III: Constrained Optimization Techniques
Table 7.6 Results for Example 7.12
λ(i) rk x
∗(i)
1 x
∗(i)
2 Value of h
0.00000 1.00000 −0.23810 2.22222 −3.01587
−6.03175 1.00000 −0.38171 3.56261 −1.81910
−9.66994 1.00000 −0.46833 4.37110 −1.09723
−11.86441 1.00000 −0.52058 4.85876 −0.66182
−13.18806 1.00000 −0.55210 5.15290 −0.39919
−13.98645 1.00000 −0.57111 5.33032 −0.24078
−14.46801 1.00000 −0.58257 5.43734 −0.14524
−14.75848 1.00000 −0.58949 5.50189 −0.08760
−14.93369 1.00000 −0.59366 5.54082 −0.05284
−15.03937 1.00000 −0.59618 5.56430 −0.03187
For the stationary point of A, the necessary conditions, ∂A/∂xi = 0, i = 1, 2, yield
x1(12 + 2rk) + x2(4 + 2rk) = 10rk − λ (E4)
x1(4 + 2rk) + x2(6 + 2rk) = 10rk − λ (E5)
The solution of Eqs. (E4) and (E5) gives
x1 =
−90r2k + 9rkλ − 6λ + 60rk
(14 − 5rk)(12 + 2rk)
(E6)
x2 =
20rk − 2λ
14 − 5rk
(E7)
Let the value of rk be fixed at 1 and select a value of λ
(1) = 0. This gives
x
∗(1)
1 = −
5
21
, x
∗(1)
2 =
20
9
with h = − 5
21
+ 20
9
− 5 = −3.01587
For the next iteration,
λ(2) = λ(1) + 2rkh(X∗(1)) = 0 + 2(1)(−3.01587) = −6.03175
Substituting this value for λ along with rk = 1 in Eqs. (E6) and (E7), we get
x
∗(2)
1 = −0.38171, x
∗(2)
2 = 3.56261
with h = −0.38171 + 3.56261 − 5 = −1.81910
This procedure can be continued until some specified convergence is satisfied. The
results of the first ten iterations are given in Table 7.6.
7.21 CHECKING THE CONVERGENCE OF CONSTRAINED
OPTIMIZATION PROBLEMS
In all the constrained optimization techniques described in this chapter, identification
of the optimum solution is very important from the points of view of stopping the
7.21 Checking the Convergence of Constrained Optimization Problems 465
iterative process and using the solution with confidence. In addition to the convergence
criteria discussed earlier, the following two methods can also be used to test the point
for optimality.
7.21.1 Perturbing the Design Vector
Since the optimum point
X∗ =









x∗1
x∗2
...
x∗n









corresponds to the minimum function value subject to the satisfaction of the constraints
gj (X
∗) ≤ 0, j = 1, 2, . . . , m (the equality constraints can also be included, if neces-
sary), we perturb X∗ by changing each of the design variables, one at a time, by a
small amount, and evaluate the values of f and gj , j = 1, 2, . . . , m. Thus if
X+i = X
∗ + 	Xi
X−i = X
∗ − 	Xi
where
	Xi =























0
...
0
	xi
0
...
0























← ith row
	xi is a small perturbation in xi that can be taken as 0.1 to 2.0 % of x
∗
i . Evaluate
f (X+i ); f (X
−
i ); gj (X
+
i )
gj (X
−
i ), j = 1, 2, . . . , m for i = 1, 2, . . . , n
If
f (X+i ) ≥ f (X
∗); gj (X+i ) ≤ 0, j = 1, 2, . . . , m
f (X−i ) ≥ f (X
∗); gj (X−i ) ≤ 0, j = 1, 2, . . . , m
for i = 1, 2, . . . , n, X∗ can be taken as the constrained optimum point of the original
problem.
7.21.2 Testing the Kuhn–Tucker Conditions
Since the Kuhn–Tucker conditions, Eqs. (2.73) and (2.74), are necessarily to be sat-
isfied† by the optimum point of any nonlinear programming problem, we can at least
†These may not be sufficient to guarantee a global minimum point for nonconvex programming problems.
466 Nonlinear Programming III: Constrained Optimization Techniques
test for the satisfaction of these conditions before taking a point X as optimum.
Equations (2.73) can be written as
∑
j∈j1
λj
∂gj
∂xi
= −
∂f
∂xi
, i = 1, 2, . . . , n (7.261)
where J1 indicates the set of active constraints at the point X. If gj1(X) = gj2(X) =
· · · = gjp(X) = 0, Eqs. (7.261) can be expressed as
G
n×p
λ
p×1
= F
n×1
(7.262)
where
G =













∂gj1
∂x1
∂gj2
∂x1
· · ·
∂gjp
∂x1
∂gj1
∂x2
∂gj2
∂x2
· · ·
∂gjp
∂x2
...
∂gj1
∂xn
∂gj2
∂xn
· · ·
∂gjp
∂xn













X
λ =









λj1
λj2
...
λjp









and F =

























−
∂f
∂x1
− ∂f
∂x2
...
− ∂f
∂xn

























X
From Eqs. (7.262) we can obtain an expression for λ as
λ = (GTG)−1GT F (7.263)
If all the components of λ, given by Eq. (7.263) are positive, the Kuhn–Tucker
conditions will be satisfied. A major difficulty in applying Eq. (7.263) arises from the
fact that it is very difficult to ascertain which constraints are active at the point X.
Since no constraint will have exactly the value of 0.0 at the point X while working
on the computer, we have to take a constraint gj to be active whenever it satisifes the
relation
|gj (X)| ≤ ε (7.264)
where ε is a small number on the order of 10−2 to 10−6. Notice that Eq. (7.264)
assumes that the constraints were originally normalized.
7.22 Test Problems 467
7.22 TEST PROBLEMS
As discussed in previous sections, a number of algorithms are available for solving
a constrained nonlinear programming problem. In recent years, a variety of computer
programs have been developed to solve engineering optimization problems. Many of
these are complex and versatile and the user needs a good understanding of the algo-
rithms/computer programs to be able to use them effectively. Before solving a new
engineering design optimization problem, we usually test the behavior and conver-
gence of the algorithm/computer program on simple test problems. Five test problems
are given in this section. All these problems have appeared in the optimization literature
and most of them have been solved using different techniques.
7.22.1 Design of a Three-Bar Truss
The optimal design of the three-bar truss shown in Fig. 7.21 is considered using two
different objectives with the cross-sectional areas of members 1 (and 3) and 2 as design
variables [7.38].
Design vector:
X =
{
x1
x2
}
=
{
A1
A2
}
Objective functions:
f1(X) = weight = 2
√
2x1 + x2
f2(X) = vertical deflection of loaded joint =
PH
E
1
x1 +
√
2x2
Constraints:
σ1(X) − σ (u) ≤ 0
σ2(X) − σ (u) ≤ 0
σ3(X) − σ (l) ≤ 0
x
(l)
i ≤ xi ≤ x
(u)
i , i = 1, 2
Figure 7.21 Three-bar truss [7.38].
468 Nonlinear Programming III: Constrained Optimization Techniques
where σi is the stress induced in member i, σ
(u) the maximum permissible stress in
tension, σ (l) the maximum permissible stress in compression, x
(l)
i the lower bound
on xi , and x
(u)
i the upper bound on xi . The stresses are given by
σ1(X) = P
x2 +
√
2x1√
2x21 + 2x1x2
σ2(X) = P
1
x1 +
√
2x2
σ3(X) = −P
x2√
2x21 + 2x1x2
Data: σ (u) = 20, σ (l) = −15, x(l)i = 0.1(i = 1, 2), x
(u)
i = 5.0(i = 1, 2), P = 20,
and E = 1.
Optimum design:
X∗1 =
{
0.78706
0.40735
}
, f ∗1 =
2.6335, stress constraint of
member 1 is active at X∗1
X∗2 =
{
5.0
5.0
}
, f ∗2 = 1.6569
7.22.2 Design of a Twenty-Five-Bar Space Truss
The 25-bar space truss shown in Fig. 7.22 is required to support the two load condi-
tions given in Table 7.7 and is to be designed with constraints on member stresses as
well as Euler buckling [7.38]. A minimum allowable area is specified for each mem-
ber. The allowable stresses for all members are specified as σmax in both tension and
compression. The Young’s modulus and the material density are taken as E = 107 psi
and ρ = 0.1 lb/in3. The members are assumed to be tubular with a nominal diame-
ter/thickness ratio of 100, so that the buckling stress in member i becomes
pi = −
100.01πEAi
8l2i
, i = 1, 2, . . . , 25
where Ai and li denote the cross-sectional area and length, respectively, of member i.
The member areas are linked as follows:
A1, A2 = A3 = A4 = A5, A6 = A7 = A8 = A9,
A10 = A11, A12 = A13, A14 = A15 = A16 = A17,
A18 = A19 = A20 = A21, A22 = A23 = A24 = A25
Thus there are eight independent area design variables in the problem. Three problems
are solved using different objective functions:
f1(X) =
25
∑
i=1
ρAi li = weight
f2(X) = (δ21x + δ21y + δ21z)1/2 + (δ22x + δ22y + δ22z)1/2
7.22 Test Problems 469
Figure 7.22 A 25-bar space truss [7.38].
= sum of deflections of nodes 1 and 2
f3(X) = −ω1 = negative of fundamental natural frequency of vibration
where δix = deflection of node i along x direction.
Table 7.7 Loads Acting on the 25-Bar Truss
Joint
1 2 3 6
Load condition 1, loads in pounds
Fx 0 0 0 0
Fy 20,000 −20,000 0 0
Fz −5,000 −5,000 0 0
Load condition 2, loads in pounds
Fx 1,000 0 500 500
Fy 10,000 10,000 0 0
Fz −5,000 −5,000 0 0
470 Nonlinear Programming III: Constrained Optimization Techniques
Constraints:
|σij (X)| ≤ σmax, i = 1, 2, . . . , 25, j = 1, 2
σij (X) ≤ pi(X), i = 1, 2, . . . , 25, j = 1, 2
x
(l)
i ≤ xi ≤ x
(u)
i , i = 1, 2, . . . , 8
where σij is the stress induced in member i under load condition j , x
(l)
i the lower
bound on xi , and x
(u)
i the upper bound on xi .
Data: σmax = 40,000 psi, x(l)i = 0.1 in
2, x
(u)
i = 5.0 in
2 for i = 1, 2, . . . , 25.
Optimum solution: See Table 7.8.
7.22.3 Welded Beam Design
The welded beam shown in Fig. 7.23 is designed for minimum cost subject to con-
straints on shear stress in weld (τ ), bending stress in the beam (σ ), buckling load on
the bar (Pc), end deflection of the beam (δ), and side constraints [7.39].
Design vector:







x1
x2
x3
x4







=







h
l
t
b







Table 7.8 Optimization Results of the 25-Bar Truss [7.38]
Optimization problem
Minimization Minimization Maximization
Quantity of weight of deflection of frequency
Design vector, X 0.1a 3.7931 0.1a
0.80228 5.0a 0.79769
0.74789 5.0a 0.74605
0.1a 3.3183 0.72817
0.12452 5.0a 0.84836
0.57117 5.0a 1.9944
0.97851 5.0a 1.9176
0.80247 5.0a 4.1119
Weight (lb) 233.07265 1619.3258 600.87891
Deflection (in.) 1.924989 0.30834 1.35503
Fundamental frequency (Hz) 73.25348 70.2082 108.6224
Number of active behavior
constraints
9b 0 4c
aActive side constraint.
bBuckling stress in members, 2, 5, 7, 8, 19, and 20 in load condition 1 and in members 13, 16, and 24 in
load condition 2.
cBuckling stress in members 2, 5, 7, and 8 in load condition 1.
7.22 Test Problems 471
l
L
Ph
h
b
t
Figure 7.23 Welded beam [7.39].
Objective function: f (X) = 1.10471x21x2 + 0.04811x3x4(14.0 + x2)
Constraints:
g1(X) = τ(X) − τmax ≤ 0
g2(X) = σ(X) − σmax ≤ 0
g3(X) = x1 − x4 ≤ 0
g4(X) = 0.10471x21 + 0.04811x3x4(14.0 + x2) − 5.0 ≤ 0
g5(X) = 0.125 − x1 ≤ 0
g6(X) = δ(X) − δmax ≤ 0
g7(X) = P − Pc(X) ≤ 0
g8(X) to g11(X) : 0.1 ≤ xi ≤ 2.0, i = 1, 4
g12(X) to g15(X) : 0.1 ≤ xi ≤ 10.0, i = 2, 3
where
τ(X) =
√
(τ ′)2 + 2τ ′τ ′′ x2
2R
+ (τ ′′)2
τ ′ =
P
√
2x1x2
, τ ′′ =
MR
J
, M = P
(
L +
x2
2
)
R =
√
x22
4
+
(
x1 + x3
2
)2
472 Nonlinear Programming III: Constrained Optimization Techniques
J = 2
{
x1x2√
2
[
x22
12
+
(
x1 + x3
2
)2
]}
σ(X) = 6PL
x4x
2
3
δ(X) = 4PL
3
Ex33x4
Pc(X) =
4.013
√
EG(x23x
6
4/36)
L2
(
1 −
x3
2L
√
E
4G
)
Data: P = 6000 lb, L = 14 in., E = 30 × 106 psi, G = 12 × 106 psi, τmax =
13,600 psi, σmax = 30,000 psi, and δmax = 0.25 in.
Starting and optimum solutions:
Xstart =







h
l
t
b







=







0.4
6.0
9.0
0.5







in., f start = $5.3904, X∗ =







h
l
t
b







∗
=







0.2444
6.2177
8.2915
0.2444







in.,
f ∗ = $2.3810
7.22.4 Speed Reducer (Gear Train) Design
The design of the speed reducer, shown in Fig. 7.24, is considered with the face width
(b), module of teeth (m), number of teeth on pinion (z), length of shaft 1 between bear-
ings (l1), length of shaft 2 between bearings (l2), diameter of shaft 1 (d1), and diameter
of shaft 2 (d2) as design variables x1, x2, . . . , x7, respectively. The constraints include
limitations on the bending stress of gear teeth, surface stress, transverse deflections of
shafts 1 and 2 due to transmitted force, and stresses in shafts 1 and 2 [7.40, 7.41].
Figure 7.24 Speed reducer (gear pair) [7.40].
7.22 Test Problems 473
Objective (minimization of weight of speed reducer):
f (X) = 0.7854x1x22 (3.3333x23 + 14.9334x3 − 43.0934) − 1.508x1(x26 + x27)
+ 7.477(x36 + x37) + 0.7854(x4x26 + x5x27)
Constraints:
g1(x) =27x−11 x
−2
2 x
−1
3 ≤ 1
g2(x) =397.5x−11 x
−2
2 x
−2
3 ≤ 1
g3(x) =1.93x−12 x
−1
3 x
3
4x
−4
6 ≤ 1
g4(x) =1.93x−12 x
−1
3 x
3
5x
−4
7 ≤ 1
g5(x) =
[
(
745x4
x2x3
)2
+ (16.9)106
]0.5
/
0.1x36 ≤ 1100
g6(x) =
[
(
745x5
x2x3
)2
+ (157.5)106
]0.5
/
0.1x37 ≤ 850
g7(x) =x2x3 ≤ 40
g8(x) : 5 ≤
x1
x2
≤ 12 : g9(x)
g10(x) : 2.6 ≤ x1 ≤ 3.6 : g11(x)
g12(x) : 0.7 ≤ x2 ≤ 0.8 : g13(x)
g14(x) : 17 ≤ x3 ≤ 28 : g15(x)
g16(x) : 7.3 ≤ x4 ≤ 8.3 : g17(x)
g18(x) : 7.3 ≤ x5 ≤ 8.3 : g19(x)
g20(x) : 2.9 ≤ x6 ≤ 3.9 : g21(x)
g22(x) : 5.0 ≤ x7 ≤ 5.5 : g23(x)
g24(x) = (1.5x6 + 1.9)x−14 ≤ 1
g25(x) = (1.1x7 + 1.9)x−15 ≤ 1
Optimum solution:
X∗ = {3.5 0.7 17.0 7.3 7.3 3.35 5.29}T, f ∗ = 2985.22
7.22.5 Heat Exchanger Design [7.42]
Objective function: Minimize f (X) = x1 + x2 + x3
474 Nonlinear Programming III: Constrained Optimization Techniques
Constraints:
g1(X) = 0.0025(x4 + x6) − 1 ≤ 0
g2(X) = 0.0025(−x4 + x5 + x7) − 1 ≤ 0
g3(X) = 0.01(−x5 + x8) − 1 ≤ 0
g4(X) = 100x1 − x1x6 + 833.33252x4 − 83,333.333 ≤ 0
g5(X) = x2x4 − x2x7 − 1250x4 + 1250x5 ≤ 0
g6(X) = x3x5 − x3x8 − 2500x5 + 1,250,000 ≤ 0
g7 : 100 ≤ x1 ≤ 10,000 : g8
g9 : 1000 ≤ x2 ≤ 10,000 : g10
g11 : 1000 ≤ x3 ≤ 10,000 : g12
g13 to g22 : 10 ≤ xi ≤ 1000, i = 4, 5, . . . , 8
Optimum solution: X∗ = {567 1357 5125 181 295 219 286 395}T,
f ∗ = 7049
7.23 MATLAB SOLUTION OF CONSTRAINED OPTIMIZATION
PROBLEMS
The solution of multivariable minimization problems, with inequality and equality con-
straints, using the MATLAB function fmincon is illustrated in this section.
Example 7.13 Find the solution of Example 7.8 starting from the initial point
X1 = {0.1 0.1 3.0}T
SOLUTION
Step 1: Write an M-file objfun.m for the objective function.
function f= objfun (x)
f= x(1)^3-6*x(1)^2+11*x(1)+x(3);
Step 2: Write an M-file constraints.m for the constraints.
function [c, ceq] = constraints (x)
% Nonlinear inequality constraints
c = [x(1)^2+x(2)^2-x(3)^2;4-x(1)^2-x(2)^2-x(3)^2;x(3)-5;
-x(1);-x(2);-x(3)];•
% Nonlinear equality constraints
ceq = [];
7.23 MATLAB Solution of Constrained Optimization Problems 475
Step 3: Invoke constrained optimization program (write this in new MATLAB file).
clc
clear all
warning off
x0 = [.1,.1, 3.0]; % Starting guess
fprintf ('The values of function value and constraints at
starting pointn');
f=objfun (x0)
[c, ceq] = constraints (x0)
options = optimset ('LargeScale', 'off');
[x, fval]=fmincon (@objfun, x0, [], [], [], [], [], [],
@constraints, options)
fprintf ('The values of constraints at optimum solutionn');
[c, ceq] = constraints (x)
% Check the constraint values at x
This Produces the Solution or Ouput as follows:
The values of function value and constraints at
starting point
f=
4.0410
c=
-8.9800
-5.0200
-2.0000
-0.1000
-0.1000
-3.0000
ceq =
[]
Optimization terminated: first-order optimality measure
less
than options. TolFun and maximum constraint violation is
less
than options.TolCon.
Active inequalities (to within options.TolCon = 1e-006):
lower upper ineqlin ineqnonlin
1
2
4
x=
0 1.4142 1.4142
fval =
1.4142
The values of constraints at optimum solution
c=
476 Nonlinear Programming III: Constrained Optimization Techniques
-0.0000
-0.0000
-3.5858
0
-1.4142
-1.4142
ceq =
[]
REFERENCES AND BIBLIOGRAPHY
7.1 R. L. Fox, Optimization Methods for Engineering Design , Addison-Wesley, Reading, MA,
1971.
7.2 M. J. Box, A new method of constrained optimization and a comparison with other
methods, Computer Journal , Vol. 8, No. 1, pp. 42–52, 1965.
7.3 E. W. Cheney and A. A. Goldstein, Newton’s method of convex programming and
Tchebycheff approximation, Numerische Mathematik , Vol. 1, pp. 253–268, 1959.
7.4 J. E. Kelly, The cutting plane method for solving convex programs, Journal of SIAM ,
Vol. VIII, No. 4, pp. 703–712, 1960.
7.5 G. Zoutendijk, Methods of Feasible Directions , Elsevier, Amsterdam, 1960.
7.6 W.W. Garvin, Introduction to Linear Programming , McGraw-Hill, New York, 1960.
7.7 S. L. S. Jacoby, J. S. Kowalik, and J. T. Pizzo, Iterative Methods for Nonlinear Optimiza-
tion Problems , Prentice Hall, Englewood Cliffs, NJ, 1972.
7.8 G. Zoutendijk, Nonlinear programming: a numerical survey, SIAM Journal of Control
Theory and Applications , Vol. 4, No. 1, pp. 194–210, 1966.
7.9 J. B. Rosen, The gradient projection method of nonlinear programming, Part I: linear
constraints, SIAM Journal , Vol. 8, pp. 181–217, 1960.
7.10 J. B. Rosen, The gradient projection method for nonlinear programming, Part II: nonlinear
constraints, SIAM Journal , Vol. 9, pp. 414–432, 1961.
7.11 G. A. Gabriele and K. M. Ragsdell, The generalized reduced gradient method: a reliable
tool for optimal design, ASME Journal of Engineering for Industry , Vol. 99, pp. 384–400,
1977.
7.12 M. J. D. Powell, A fast algorithm for nonlinearity constrained optimization calculations,
in Lecture Notes in Mathematics , G. A. Watson et al., Eds., Springer-Verlag, Berlin,
1978.
7.13 M. J. Box, A comparison of several current optimization methods and the use of trans-
formations in constrained problems, Computer Journal , Vol. 9, pp. 67–77, 1966.
7.14 C. W. Carroll, The created response surface technique for optimizing nonlinear restrained
systems, Operations Research , Vol. 9, pp. 169–184, 1961.
7.15 A. V. Fiacco and G. P. McCormick, Nonlinear Programming: Sequential Unconstrained
Minimization Techniques , Wiley, New York, 1968.
7.16 W. I. Zangwill, Nonlinear programming via penalty functions, Management Science, Vol.
13, No. 5, pp. 344–358, 1967.
7.17 A. V. Fiacco and G. P. McCormick, Extensions of SUMT for nonlinear program-
ming: equality constraints and extrapolation, Management Science, Vol. 12, No. 11,
pp. 816–828, July 1966.
References and Bibliography 477
7.18 D. Kavlie and J. Moe, Automated design of frame structure, ASCE Journal of the Struc-
tural Division , Vol. 97, No. ST1, pp. 33–62, Jan. 1971.
7.19 J. H. Cassis and L. A. Schmit, On implementation of the extended interior penalty func-
tion, International Journal for Numerical Methods in Engineering , Vol. 10, pp. 3–23,
1976.
7.20 R. T. Haftka and J. H. Starnes, Jr., Application of a quadratic extended interior penalty
function for structural optimization, AIAA Journal , Vol. 14, pp. 718–728, 1976.
7.21 A. V. Fiacco and G. P. McCormick, SUMT Without Parmaeters , System Research Mem-
orandum 121, Technical Institute, Northwestern University, Evanston, IL, 1965.
7.22 A. Ralston, A First Course in Numerical Analysis , McGraw-Hill, New York, 1965.
7.23 R. T. Rockafellar, The multiplier method of Hestenes and Powell applied to convex pro-
gramming, Journal of Optimization Theory and Applications , Vol. 12, No. 6, pp. 555–562,
1973.
7.24 B. Prasad, A class of generalized variable penalty methods for nonlinear programming,
Journal of Optimization Theory and Applications , Vol. 35, pp. 159–182, 1981.
7.25 L. A. Schmit and R. H. Mallett, Structural synthesis and design parameter hierarchy,
Journal of the Structural Division, Proceedings of ASCE , Vol. 89, No. ST4, pp. 269–299,
1963.
7.26 J. Kowalik and M. R. Osborne, Methods for Unconstrained Optimization Problems , Amer-
ican Elsevier, New York, 1968.
7.27 N. Baba, Convergence of a random optimization method for constrained optimization
problems, Journal of Optimization Theory and Applications , Vol. 33, pp. 451–461, 1981.
7.28 J. T. Betts, A gradient projection-multiplier method for nonlinear programming, Journal
of Optimization Theory and Applications , Vol. 24, pp. 523–548, 1978.
7.29 J. T. Betts, An improved penalty function method for solving constrained parameter opti-
mization problems, Journal of Optimization Theory and Applications , Vol. 16, pp. 1–24,
1975.
7.30 W. Hock and K. Schittkowski, Test examples for nonlinear programming codes, Journal
of Optimization Theory and Applications , Vol. 30, pp. 127–129, 1980.
7.31 J. C. Geromel and L. F. B. Baptistella, Feasible direction method for large-scale noncon-
vex programs: decomposition approach, Journal of Optimization Theory and Applications ,
Vol. 35, pp. 231–249, 1981.
7.32 D. M. Topkis, A cutting-plane algorithm with linear and geometric rates of convergence,
Journal of Optimization Theory and Applications , Vol. 36, pp. 1–22, 1982.
7.33 M. Avriel, Nonlinear Programming: Analysis and Methods , Prentice Hall, Englewood
Cliffs, NJ, 1976.
7.34 H. W. Kuhn, Nonlinear programming: a historical view, in Nonlinear Programming,
SIAM-AMS Proceedings , Vol. 9, American Mathematical Society, Providence, RI, 1976.
7.35 J. Elzinga and T. G. Moore, A central cutting plane algorithm for the convex programming
problem, Mathematical Programming , Vol. 8, pp. 134–145, 1975.
7.36 V. B. Venkayya, V. A. Tischler, and S. M. Pitrof, Benchmarking in structural optimization,
Proceedings of the 4th AIAA/USAF/NASA/OAI Symposium on Multidisciplinary Analysis
and Optimization , Sept. 21–23, 1992, Cleveland, Ohio, AIAA Paper AIAA-92-4794.
7.37 W. Hock and K. Schittkowski, Test Examples for Nonlinear Programming Codes , Lecture
Notes in Economics and Mathematical Systems, No. 187, Springer-Verlag, Berlin, 1981.
7.38 S. S. Rao, Multiobjective optimization of fuzzy structural systems, International Journal
for Numerical Methods in Engineering , Vol. 24, pp. 1157–1171, 1987.
478 Nonlinear Programming III: Constrained Optimization Techniques
7.39 K. M. Ragsdell and D. T. Phillips, Optimal design of a class of welded structures
using geometric programming, ASME Journal of Engineering for Industry , Vol. 98,
pp. 1021–1025, 1976.
7.40 J. Golinski, An adaptive optimization system applied to machine synthesis, Mechanism
and Machine Synthesis , Vol. 8, pp. 419–436, 1973.
7.41 H. L. Li and P. Papalambros, A production system for use of global optimization knowl-
edge, ASME Journal of Mechanisms, Transmissions, and Automation in Design , Vol. 107,
pp. 277–284, 1985.
7.42 M. Avriel and A. C. Williams, An extension of geometric programming with application
in engineering optimization, Journal of Engineering Mathematics , Vol. 5, pp. 187–194,
1971.
7.43 G. A. Gabriele and K. M. Ragsdell, Large scale nonlinear programming using the gener-
alized reduced gradient method, ASME Journal of Mechanical Design , Vol. 102, No. 3,
pp. 566–573, 1980.
7.44 A. D. Belegundu and J. S. Arora, A recursive quadratic programming algorithm with
active set strategy for optimal design, International Journal for Numerical Methods in
Engineering , Vol. 20, No. 5, pp. 803–816, 1984.
7.45 G. A. Gabriele and T. J. Beltracchi, An investigation of Pschenichnyi’s recursive quadratic
programming method for engineering optimization, ASME Journal of Mechanisms, Trans-
missions, and Automation in Design , Vol. 109, pp. 248–253, 1987.
7.46 F. Moses, Optimum structural design using linear programming, ASCE Journal of the
Structural Division , Vol. 90, No. ST6, pp. 89–104, 1964.
7.47 S. L. Lipson and L. B. Gwin, The complex method applied to optimal truss configuration,
Computers and Structures , Vol. 7, pp. 461–468, 1977.
7.48 G. N. Vanderplaats, Numerical Optimization Techniques for Engineering Design with
Applications , McGraw-Hill, New York, 1984.
7.49 T. F. Edgar and D. M. Himmelblau, Optimization of Chemical Processes , McGraw-Hill,
New York, 1988.
7.50 A. Ravindran, K. M. Ragsdell, and G. V. Reklaitis, Engineering Optimization Methods
and Applications , 2nd ed., Wiley, New York, 2006.
7.51 L. S. Lasdon, Optimization Theory for Large Systems , Macmillan, New York, 1970.
7.52 R. T. Haftka and Z. Gürdal, Elements of Structural Optimization , 3rd ed., Kluwer Aca-
demic, Dordrecht, The Netherlands, 1992.
REVIEW QUESTIONS
7.1 Answer true or false:
(a) The complex method is similar to the simplex method.
(b) The optimum solution of a constrained problem can be the same as the unconstrained
optimum.
(c) The constraints can introduce local minima in the feasible space.
(d) The complex method can handle both equality and inequality constraints.
(e) The complex method can be used to solve both convex and nonconvex problems.
(f) The number of inequality constraints cannot exceed the number of design variables.
(g) The complex method requires a feasible starting point.
Review Questions 479
(h) The solutions of all LP problems in the SLP method lie in the infeasible domain of
the original problem.
(i) The SLP method is applicable to both convex and nonconvex problems.
(j) The usable feasible directions can be generated using random numbers.
(k) The usable feasible direction makes an obtuse angle with the gradients of all the
constraints.
(l) If the starting point is feasible, all subsequent unconstrained minima will be feasible
in the exterior penalty function method.
(m) The interior penalty function method can be used to find a feasible starting point.
(n) The penalty parameter rk approaches zero as k approaches infinity in the exterior
penalty function method.
(o) The design vector found through extrapolation can be used as a starting point for the
next unconstrained minimization in the interior penalty function method.
7.2 Why is the SLP method called the cutting plane method?
7.3 How is the direction-finding problem solved in Zoutendijk’s method?
7.4 What is SUMT?
7.5 How is a parametric constraint handled in the interior penalty function method?
7.6 How can you identify an active constraint during numerical optimization?
7.7 Formulate the equivalent unconstrained objective function that can be used in random
search methods.
7.8 How is the perturbation method used as a convergence check?
7.9 How can you compute Lagrange multipliers during numerical optimization?
7.10 What is the use of extrapolating the objective function in the penalty function approach?
7.11 Why is handling of equality constraints difficult in the penalty function methods?
7.12 What is the geometric interpretation of the reduced gradient?
7.13 Is the generalized reduced gradient zero at the optimum solution?
7.14 What is the relation between the sequential quadratic programming method and the
Lagrangian function?
7.15 Approximate the nonlinear function f (X) as a linear function at X0.
7.16 What is the limitation of the linear extended penalty function?
7.17 What is the difference between the interior and extended interior penalty function
methods?
7.18 What is the basic principle used in the augmented Lagrangian method?
7.19 When can you use the steepest descent direction as a usable feasible direction in
Zoutendijk’s method?
7.20 Construct the augmented Lagrangian function for a constrained optimization problem.
480 Nonlinear Programming III: Constrained Optimization Techniques
7.21 Construct the φk function to be used for a mixed equality–inequality constrained problem
in the interior penalty function approach.
7.22 What is a parametric constraint?
7.23 Match the following methods:
(a) Zoutendijk method Heuristic method
(b) Cutting plane method Barrier method
(c) Complex method Feasible directions method
(d) Projected Lagrangian method Sequential linear programming method
(e) Penalty function method Gradient projection method
(f) Rosen’s method Sequential unconstrained minimization method
(g) Interior penalty function method Sequential quadratic programming method
7.24 Answer true or false:
(a) The Rosen’s gradient projection method is a method of feasible directions.
(b) The starting vector can be infeasible in Rosen’s gradient projection method.
(c) The transformation methods seek to convert a constrained problem into an uncon-
strained one.
(d) The φk function is defined over the entire design space in the interior penalty function
method.
(e) The sequence of unconstrained minima generated by the interior penalty function
method lies in the feasible space.
(f) The sequence of unconstrained minima generated by the exterior penalty function
method lies in the feasible space.
(g) The random search methods are applicable to convex and nonconvex optimization
problems.
(h) The GRG method is related to the method of elimination of variables.
(i) The sequential quadratic programming method can handle only equality constraints.
(j) The augmented Lagrangian method is based on the concepts of penalty function and
Lagrange multiplier methods.
(k) The starting vector can be infeasible in the augmented Lagrangiam method.
PROBLEMS
7.1 Find the solution of the problem:
Minimize f (X) = x21 + 2x22 − 2x1x2 − 14x1 − 14x2 + 10
subject to
4x21 + x22 − 25 ≤ 0
using a graphical procedure.
7.2 Generate four feasible design vectors to the welded beam design problem (Section 7.22.3)
using random numbers.
7.3 Generate four feasible design vectors to the three-bar truss design problem (Section 7.22.1)
using random numbers.
Problems 481
7.4 Consider the tubular column described in Example 1.1. Starting from the design vector
(d = 8.0 cm, t = 0.4 cm), complete two steps of reflection, expansion, and/or contraction
of the complex method.
7.5 Consider the problem:
Minimize f (X) = x1 − x2
subject to
3x21 − 2x1x2 + x22 − 1 ≤ 0
(a) Generate the approximating LP problem at the vector, X1 =
{−2
2
}
.
(b) Solve the approximating LP problem using graphical method and find whether the
resulting solution is feasible to the original problem.
7.6 Approximate the following optimization problem as (a) a quadratic programming problem,
and (b) a linear programming problem at X =
{
1
−2
}
.
Minimize f (X) = 2x31 + 15x22 − 8x1x2 + 15
subject to
x21 + x1x2 + 1 = 0
4x1 − x22 ≤ 4
7.7 The problem of minimum volume design subject to stress constraints of the three-bar
truss shown in Fig. 7.21 can be stated as follows:
Minimize f (X) = 282.8x1 + 100.0x2
subject to
σ1 − σ0 =
20(x2 +
√
2x1)
2x1x2 +
√
2x21
− 20 ≤ 0
−σ3 − σ0 =
20x2
2x1x2 +
√
2x21
− 20 ≤ 0
0 ≤ xi ≤ 0.3, i = 1, 2
where σi is the stress induced in member i, σ0 = 20 the permissible stress, x1 the area
of cross section of members 1 and 3, and x2 the area of cross section of member 2.
Approximate the problem as a LP problem at (x1 = 1, x2 = 1).
7.8 Minimize f (X) = x21 + x22 − 6x1 − 8x2 + 10
subject to
4x21 + x22 ≤ 16
3x1 + 5x2 ≤ 15
xi ≥ 0, i = 1, 2
with the starting point X1 =
{
1
1
}
. Using the cutting plane method, complete one step of
the process.
482 Nonlinear Programming III: Constrained Optimization Techniques
7.9 Minimize f (X) = 9x21 + 6x22 + x23 − 18x1 − 12x2 − 6x3 − 8
subject to
x1 + 2x2 + x3 ≤ 4
xi ≥ 0, i = 1, 2, 3
Using the starting point X1 = {0, 0, 0}T, complete one step of sequential linear program-
ming method.
7.10 Complete one cycle of the sequential linear programming method for the truss of
Section 7.22.1 using the starting point, X1 =
{
1
1
}
.
7.11 A flywheel is a large mass that can store energy during coasting of an engine and feed
it back to the drive when required. A solid disk-type flywheel is to be designed for an
engine to store maximum possible energy with the following specifications: maximum
permissible weight = 150 lb, maximum permissible diameter (d) = 25 in., maximum
rotational speed = 3000 rpm, maximum allowable stress (σmax) = 20,000 psi, unit weight
(γ ) = 0.283 lb/in3, and Poisson’s ratio (ν) = 0.3. The energy stored in the flywheel is
given by 1
2
Iω2, where I is the mass moment of inertia and ω is the angular velocity, and
the maximum tangential and radial stresses developed in the flywheel are given by
σt = σr =
γ (3 + ν)ω2d2
8g
where g is the acceleration due to gravity and d the diameter of the flywheel. The distortion
energy theory of failure is to be used, which leads to the stress constraint
σ 2t + τ 2r − σtσr ≤ σ 2max
Considering the diameter (d) and the width (w) as design variables, formulate the opti-
mization problem. Starting from (d = 15 in., w = 2 in.), complete one iteration of the
SLP method.
7.12 Derive the necessary conditions of optimality and find the solution for the following
problem:
Minimize f (X) = 5x1x2
subject to
25 − x21 − x22 ≥ 0
7.13 Consider the following problem:
Minimize f = (x1 − 5)2 + (x2 − 5)2
subject to
x1 + 2x2 ≤ 15
1 ≤ xi ≤ 10, i = 1, 2
Derive the conditions to be satisfied at the point X =
{
1
7
}
by the search direction S =
{
s1
s2
}
if it is to be a usable feasible direction.
Problems 483
7.14 Consider the problem:
Minimize f = (x1−1)2 + (x2−5)2
subject to
g1 = −x21 + x2 − 4 ≤ 0
g2 = −(x1 − 2)2 + x2 − 3 ≤ 0
Formulate the direction-finding problem at Xi =
{−1
5
}
as a linear programming problem
(in Zoutendijk method).
7.15 Minimize f (X) = (x1 − 1)2 + (x2 − 5)2
subject to
−x21 + x2 ≤ 4
−(x1 − 2)2 + x2 ≤ 3
starting from the point X1 =
{
1
1
}
and using Zoutendijk’s method. Complete two
one-dimensional minimization steps.
7.16 Minimize f (X) = (x1 − 1)2 + (x2 − 2)2 − 4
subject to
x1 + 2x2 ≤ 5
4x1 + 3x2 ≤ 10
6x1 + x2 ≤ 7
xi ≥ 0, i = 1, 2
by using Zoutendijk’s method from the starting point X1 =
{
1
1
}
. Perform two
one-dimensional minimization steps of the process.
7.17 Complete one iteration of Rosen’s gradient projection method for the following problem:
Minimize f = (x1 − 1)2 + (x2 − 2)2 − 4
subject to
x1 + 2x2 ≤ 5
4x1 + 3x2 ≤ 10
6x1 + x2 ≤ 7
xi ≥ 0, i = 1, 2
Use the starting point, X1 =
{
1
1
}
.
7.18 Complete one iteration of the GRG method for the problem:
Minimize f = x21 + x22
subject to
x1x2 − 9 = 0
starting from X1 =
{
2.0
4.5
}
.
484 Nonlinear Programming III: Constrained Optimization Techniques
7.19 Approximate the following problem as a quadratic programming problem at (x1 = 1,
x2 = 1):
Minimize f = x21 + x22 − 6x1 − 8x2 + 15
subject to
4x21 + x22 ≤ 16
3x21 + 5x22 ≤ 15
xi ≥ 0, i = 1, 2
7.20 Consider the truss structure shown in Fig. 7.25. The minimum weight design of the truss
subject to a constraint on the deflection of node S along with lower bounds on the cross
sectional areas of members can be started as follows:
Minimize f = 0.1847x1 + 0.1306x2
subject to
26.1546
x1
+
30.1546
x2
≤ 1.0
xi ≥ 25 mm2, i = 1, 2
Complete one iteration of sequential quadratic programming method for this problem.
7.21 Find the dimensions of a rectangular prism type parcel that has the largest volume when
each of its sides is limited to 42 in. and its depth plus girth is restricted to a maximum
value of 72 in. Solve the problem as an unconstrained minimization problem using suitable
transformations.
7.22 Transform the following constrained problem into an equivalent unconstrained problem:
Maximize f (x1, x2) = [9 − (x1 − 3)2]
x32
27
√
3
Figure 7.25 Four-bar truss.
Problems 485
subject to
0 ≤ x1
0 ≤ x2 ≤
x1√
3
0 ≤ x1 +
√
3x2 ≤ 6
7.23 Construct the φk function, according to (a) interior and (b) exterior penalty function
methods and plot its contours for the following problem:
Maximize f = 2x
subject to
2 ≤ x ≤ 10
7.24 Construct the φk function according to the exterior penalty function approach and complete
the minimization of φk for the following problem.
Minimize f (x) = (x − 1)2
subject to
g1(x) = 2 − x ≤ 0, g2(x) = x − 4 ≤ 0
7.25 Plot the contours of the φk function using the quadratic extended interior penalty function
method for the following problem:
Minimize f (x) = (x − 1)2
subject to
g1(x) = 2 − x ≤ 0, g2(x) = x − 4 ≤ 0
7.26 Consider the problem:
Minimize f (x) = x2 − 10x − 1
subject to
1 ≤ x ≤ 10
Plot the contours of the φk function using the linear extended interior penalty function
method.
7.27 Consider the problem:
Minimize f (x1, x2) = (x1 − 1)2 + (x2 − 2)2
subject to
2x1 − x2 = 0 and x1 ≤ 5
Construct the φk function according to the interior penalty function approach and complete
the minimization of φ1.
486 Nonlinear Programming III: Constrained Optimization Techniques
7.28 Solve the following problem using an interior penalty function approach coupled with the
calculus method of unconstrained minimization:
Minimize f = x2 − 2x − 1
subject to
1 − x ≥ 0
Note: Sequential minimization is not necessary.
7.29 Consider the problem:
Minimize f = x21 + x22 − 6x1 − 8x2 + 15
subject to
4x21 + x22 ≥ 16, 3x1 + 5x2 ≤ 15
Normalize the constraints and find a suitable value of r1 for use in the interior penalty
function method at the starting point (x1, x2) = (0, 0).
7.30 Determine whether the following optimization problem is convex, concave, or neither
type:
Minimize f = −4x1 + x21 − 2x1x2 + 2x22
subject to
2x1 + x2 ≤ 6, x1 − 4x2 ≤ 0, xi ≥ 0, i = 1, 2
7.31 Find the solution of the following problem using an exterior penalty function method with
classical method of unconstrained minimization:
Minimize f (x1, x2) = (2x1 − x2)2 + (x2 + 1)2
subject to
x1 + x2 = 10
Consider the limiting case as rk → ∞ analytically.
7.32 Minimize f = 3x21 + 4x22 subject to x1 + 2x2 = 8 using an exterior penalty function
method with the calculus method of unconstrained minimization.
7.33 A beam of uniform rectangular cross section is to be cut from a log having a circular
cross section of diameter 2a. The beam is to be used as a cantilever beam to carry a
concentrated load at the free end. Find the cross-sectional dimensions of the beam which
will have the maximum bending stress carrying capacity using an exterior penalty function
approach with analytical unconstrained minimization.
7.34 Consider the problem:
Minimize f = 1
3
(x1 + 1)3 + x2
subject to
1 − x1 ≤ 0, x2 ≥ 0
The results obtained during the sequential minimization of this problem according to the
exterior penalty function approach are given below:
Problems 487
Starting point for Unconstrained
Value of minimization of minimum of
k rk φ(X, rk) φ(X, rk) = X∗k f (X∗k) = f ∗k
1 1 (−0.4597, −5.0) (0.2361, −0.5) 0.1295
2 10 (0.2361, −0.5) (0.8322, −0.05) 2.0001
Estimate the optimum solution, X∗ and f ∗, using a suitable extrapolation technique.
7.35 The results obtained in an exterior penalty function method of solution for the optimization
problem stated in Problem 7.15 are given below:
r1 = 0.01, X∗1 =
{
− 0.80975
−50.0
}
, φ∗1 = −24.9650, f ∗1 = −49.9977
r2 = 1.0, X∗2 =
{
0.23607
−0.5
}
, φ∗2 = 0.9631, f ∗2 = 0.1295
Estimate the optimum design vector and optimum objective function using an extrapola-
tion method.
7.36 The following results have been obtained during an exterior penalty function approach:
r1 = 10−10, X∗1 =
{
0.66
28.6
}
r2 = 10−9, X∗2 =
{
1.57
18.7
}
Find the optimum solution, X∗, using an extrapolation technique.
7.37 The results obtained in a sequential unconstrained minimization technique (using an exte-
rior penalty function approach) from the starting point X1 =
{
6.0
30.0
}
are
r1 = 10−10, X∗1 =
{
0.66
28.6
}
; r2 = 10−9, X∗2 =
{
1.57
18.7
}
r3 = 10−8, X∗3 =
{
1.86
18.8
}
Estimate the optimum solution using a suitable extrapolation technique.
7.38 The two-bar truss shown in Fig. 7.26 is acted on by a varying load whose magnitude
is given by P(θ) = P0 cos 2θ; 0◦ ≤ θ ≤ 360◦. The bars have a tubular section with
mean diameter d and wall thickness t . Using P0 = 50,000 lb, σyield = 30,000 psi, and
E = 30 × 106 psi, formulate the problem as a parametric optimization problem for min-
imum volume design subject to buckling and yielding constraints. Assume the bars to be
pin connected for the purpose of buckling analysis. Indicate the procedure that can be
used for a graphical solution of the problem.
7.39 Minimize f (X) = (x1 − 1)2 + (x2 − 2)2
subject to
x1 + 2x2 − 2 = 0
using the augmented Lagrange multiplier method with a fixed value of rp = 1. Use a
maximum of three iterations.
488 Nonlinear Programming III: Constrained Optimization Techniques
Figure 7.26 Two-bar truss subjected to a parametric load.
7.40 Solve the following optimization problem using the augmented Lagrange multiplier
method keeping rp = 1 throughout the iterative process and λ(1) = 0:
Minimize f = (x1 − 1)2 + (x2 − 2)2
subject to
−x1 + 2x2 = 2
7.41 Consider the problem:
Minimize f = (x1 − 1)2 + (x2 − 5)2
subject to
x1 + x2 − 5 = 0
(a) Write the expression for the augmented Lagrange function with rp = 1.
(b) Start with λ
(1)
1 = 0 and perform two iterations.
(c) Find λ
(3)
1 .
7.42 Consider the optimization problem:
Minimize f = x31 − 6x21 + 11x1 + x3
subject to
x21 + x22 − x23 ≤ 0, 4 − x21 − x22 − x23 ≤ 0, x3 ≤ 5,
xi ≥ 0, i = 1, 2, 3
Problems 489
Determine whether the solution
X =



0√
2√
2



is optimum by finding the values of the Lagrange multipliers.
7.43 Determine whether the solution
X =



0√
2√
2



is optimum for the problem considered in Example 7.8 using a perturbation method with
	xi = 0.001, i = 1, 2, 3.
7.44 The following results are obtained during the minimization of
f (X) = 9 − 8x1 − 6x2 − 4x3 + 2x21 + 2x22 + x23 + 2x1x2 + 2x1x3
subject to
x1 + x2 + 2x3 ≤ 3
xi ≥ 0, i = 1, 2, 3
using the interior penalty function method:
Starting point for
minimization of Unconstrained minimum
Value of ri φ(X, ri) of φ(X, ri) = X∗i f (X∗i ) = f ∗i
1



0.1
0.1
0.1






0.8884
0.7188
0.7260



0.7072
0.01



0.8884
0.7188
0.7260






1.3313
0.7539
0.3710



0.1564
0.0001



1.3313
0.7539
0.3710






1.3478
0.7720
0.4293



0.1158
Use an extrapolation technique to predict the optimum solution of the-problem using the
following relations:
(a) X(r) = A0 + rA1; f (r) = a0 + ra1
(b) X(r) = A0 + r1/2A1; f (r) = a0 + r1/2a1
Compare your results with the exact solution
X∗ =







12
9
7
9
4
9







, fmin = 19
490 Nonlinear Programming III: Constrained Optimization Techniques
7.45 Find the extrapolated solution of Problem 7.44 by using quadratic relations for X(r) and
f (r).
7.46 Give a proof for the convergence of exterior penalty function method.
7.47 Write a computer program to implement the interior penalty function method with
the DFP method of unconstrained minimization and the cubic interpolation method of
one-dimensional search.
7.48 Write a computer program to implement the exterior penalty function method with
the BFGS method of unconstrained minimization and the direct root method of
one-dimensional search.
7.49 Write a computer program to implement the augmented Lagrange multiplier method with
a suitable method of unconstrained minimization.
7.50 Write a computer program to implement the sequential linear programming method.
7.51 Find the solution of the welded beam design problem formulated in Section 7.22.3 using
the MATLAB function fmincon with the starting point X1 = {0.4, 6.0, 9.0, 0.5}T
7.52 Find the solution of the following problem (known as Rosen–Suzuki problem) using the
MATLAB function fmincon with the starting point X1 = {0, 0, 0, 0}T:
Minimize
f (X) = x21 + x22 + 2x23 − x24 − 5x1 − 5x2 − 21x3 + 7x4 + 100
subject to
x21 + x22 + x23 + x24 + x1 − x2 + x3 − x4 − 100 ≤ 0
x21 + 2x22 + x23 + 2x24 − x1 − x4 − 10 ≤ 0
2x21 + x22 + x23 + 2x1 − x2 − x4 − 5 ≤ 0
− 100 ≤ xi ≤ 100, i = 1, 2, 3, 4
7.53 Find the solution of the following problem using the MATLAB function fmincon with
the starting point X1 = {0.5, 1.0}T:
Minimize
f (X) = x21 + x22 − 4x1 − 6x2
subject to
x1 + x2 ≤ 2
2x1 + 3x2 ≤ 12
xi ≥ 0, i = 1, 2
7.54 Find the solution of the following problem using the MATLAB function fmincon with
the starting point: X1 = {0.5, 1.0, 1.0}:
Minimize f (X) = x21 + 3x22 + x3
subject to
x21 + x22 + x23 = 16
Problems 491
7.55 Find the solution of the following problem using the MATLAB function fmincon with
the starting point: X1 = {1.0, 1.0}T:
Minimize f (X) = x21 + x22
subject to
4 − x1 − x22 ≤ 0
3x2 − x1 ≤ 0
− 3x2 − x1 ≤ 0
8
Geometric Programming
8.1 INTRODUCTION
Geometric programming is a relatively new method of solving a class of nonlinear
programming problems. It was developed by Duffin, Peterson, and Zener [8.1]. It is
used to minimize functions that are in the form of posynomials subject to constraints of
the same type. It differs from other optimization techniques in the emphasis it places on
the relative magnitudes of the terms of the objective function rather than the variables.
Instead of finding optimal values of the design variables first, geometric programming
first finds the optimal value of the objective function. This feature is especially advan-
tageous in situations where the optimal value of the objective function may be all that
is of interest. In such cases, calculation of the optimum design vectors can be omitted.
Another advantage of geometric programming is that it often reduces a complicated
optimization problem to one involving a set of simultaneous linear algebraic equations.
The major disadvantage of the method is that it requires the objective function and
the constraints in the form of posynomials. We will first see the general form of a
posynomial.
8.2 POSYNOMIAL
In an engineering design situation, frequently the objective function (e.g., the total cost)
f (X) is given by the sum of several component costs Ui(X) as
f (X) = U1 + U2 + · · · + UN (8.1)
In many cases, the component costs Ui can be expressed as power functions of the
type
Ui = ci xa1i1 x
a2i
2 · · · x
ani
n (8.2)
where the coefficients ci are positive constants, the exponents aij are real constants
(positive, zero, or negative), and the design parameters x1, x2, . . . , xn are taken to be
positive variables. Functions like f , because of the positive coefficients and variables
and real exponents, are called posynomials . For example,
f (x1, x2, x3) = 6 + 3x1 − 8x2 + 7x3 + 2x1x2
− 3x1x3 + 43x2x3 +
8
7
x21 − 9x22 + x23
492 Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
8.4 Solution Using Differential Calculus 493
is a second-degree polynomial in the variables, x1, x2, and x3 (coefficients of the various
terms are real) while
g(x1, x2, x3) = x1x2x3 + x21x2 + 4x3 +
2
x1x2
+ 5x−1/23
is a posynomial. If the natural formulation of the optimization problem does not lead to
posynomial functions, geometric programming techniques can still be applied to solve
the problem by replacing the actual functions by a set of empirically fitted posynomials
over a wide range of the parameters xi .
8.3 UNCONSTRAINED MINIMIZATION PROBLEM
Consider the unconstrained minimization problem:
Find X =









x1
x2
...
xn









that minimizes the objective function
f (X) =
N
∑
j=1
Uj (X) =
N
∑
j=1
(
cj
n
∏
i=1
x
aij
i
)
=
N
∑
j=1
(cj x
a1j
1 x
a2j
2 · · · x
anj
n ) (8.3)
where cj > 0, xi > 0, and the aij are real constants.
The solution of this problem can be obtained by various procedures. In the fol-
lowing sections, two approaches—one based on the differential calculus and the other
based on the concept of geometric inequality—are presented for the solution of the
problem stated in Eq. (8.3).
8.4 SOLUTION OF AN UNCONSTRAINED GEOMETRIC
PROGRAMMING PROGRAM USING
DIFFERENTIAL CALCULUS
According to the differential calculus methods presented in Chapter 2, the necessary
conditions for the minimum of f are given by
∂f
∂xk
=
N
∑
j=1
∂Uj
∂xk
=
N
∑
j=1
(cj x
a1j
1 x
a2j
2 · · · x
ak−1,j
k−1 akjx
akj −1
k a
ak+1,j
k+1 · · · x
anj
n ) = 0,
k = 1, 2, . . . , n (8.4)
494 Geometric Programming
By multiplying Eq. (8.4) by xk, we can rewrite it as
xk
∂f
∂xk
=
N
∑
j=1
akj (cj x
a1j
1 x
a2j
2 · · · x
ak−1,j
k−1 x
akj
k x
ak+1,j
k+1 · · · x
anj
n )
=
N
∑
j=1
akjUj (X) = 0, k = 1, 2, . . . , n (8.5)
To find the minimizing vector
X∗ =









x∗1
x∗2
...
x∗n









we have to solve the n equations given by Eqs. (8.4), simultaneously. To ensure that the
point X∗ corresponds to the minimum of f (but not to the maximum or the stationary
point of X), the sufficiency condition must be satisfied. This condition states that the
Hessian matrix of f is evaluated at X∗:
JX∗ =
[
∂2f
∂xk ∂xl
]
X∗
must be positive definite. We will see this condition at a latter stage. Since the vector
X∗ satisfies Eqs. (8.5), we have
N
∑
j=1
akjUj (X
∗) = 0, k = 1, 2, . . . , n (8.6)
After dividing by the minimum value of the objective function f ∗, Eq. (8.6) becomes
N
∑
j=1
∗jakj = 0, k = 1, 2, . . . , n (8.7)
where the quantities ∗j are defined as
∗j =
Uj (X
∗)
f ∗
=
U∗j
f ∗
(8.8)
and denote the relative contribution of j th term to the optimal objective function. From
Eq. (8.8), we obtain
N
∑
j=1
∗j = ∗1 + ∗2 + · · · + ∗N
= 1
f ∗
(U∗1 + U∗2 + · · · + U∗N ) = 1 (8.9)
8.4 Solution Using Differential Calculus 495
Equations (8.7) are called the orthogonality conditions and Eq. (8.9) is called the
normality condition . To obtain the minimum value of the objective function f ∗, the
following procedure can be adopted. Consider
f ∗ = (f ∗)1 = (f ∗)
N
j=1
∗
j = (f ∗)∗1(f ∗)∗2 · · · (f ∗)∗N (8.10)
Since
f ∗ =
U∗1
∗1
=
U∗2
∗2
= · · · =
U∗N
∗N
(8.11)
from Eq. (8.8), Eq. (8.10) can be rewritten as
f ∗ =
(
U∗1
∗1
)∗
1
(
U∗2
∗2
)∗
2
· · ·
(
U∗N
∗N
)∗
N
(8.12)
By substituting the relation
U∗j = cj
n
∏
i=1
(x∗i )
aij , j = 1, 2, . . . , N
Eq. (8.12) becomes
f ∗ =



(
c1
∗1
)∗
1
[
n
∏
i=1
(x∗i )
ai1
]∗
1






(
c2
∗2
)∗
2
[
n
∏
i=1
(x∗i )
ai2
]∗
2



· · ·



(
cN
∗N
)∗
N
[
n
∏
i=1
(x∗i )
aiN
]∗
N



=



N
∏
j=1
(
cj
∗j
)∗
j






N
∏
j=1
[
n
∏
i=1
(x∗i )
aij
]∗
j



=



N
∏
j=1
(
cj
∗j
)∗j



[
n
∏
i=1
(x∗i )
∑N
j=1 aij 
∗
j
]
=
N
∏
j=1
(
cj
∗j
)∗j
(8.13)
since
N
∑
j=1
aij
∗
j = 0 for any i from Eq. (8.7)
Thus the optimal objective function f ∗ can be found from Eq. (8.13) once ∗j are
determined. To determine ∗j (j = 1, 2, . . . , N ), Eqs. (8.7) and (8.9) can be used. It
can be seen that there are n + 1 equations in N unknowns. If N = n + 1, there will
be as many linear simultaneous equations as there are unknowns and we can find a
unique solution.
496 Geometric Programming
Degree of Difficulty. The quantity N − n − 1 is termed a degree of difficulty in
geometric programming. In the case of a constrained geometric programming problem,
N denotes the total number of terms in all the posynomials and n represents the number
of design variables. If N − n − 1 = 0, the problem is said to have a zero degree of
difficulty. In this case, the unknowns ∗j (j = 1, 2, . . . , N ) can be determined uniquely
from the orthogonality and normality conditions. If N is greater than n + 1, we have
more number of variables (∗j s) than the equations, and the method of solution for
this case will be discussed in subsequent sections. It is to be noted that geometric
programming is not applicable to problems with negative degree of difficulty.
Sufficiency Condition. We can see that ∗j are found by solving Eqs. (8.7) and (8.9),
which in turn are obtained by using the necessary conditions only. We can show that
these conditions are also sufficient.
Finding the Optimal Values of Design Variables. Since f ∗ and ∗j (j =
1, 2, . . . , N ) are known, we can determine the optimal values of the design variables
from the relations
U∗j = ∗jf ∗ = cj
n
∏
i=1
(x∗i )
aij , j = 1, 2, . . . , N (8.14)
The simultaneous solution of these equations will yield the desired quantities x∗i (i =
1, 2, . . . , n). It can be seen that Eqs. (8.14) are nonlinear in terms of the variables
x∗1 , x
∗
2 , . . . , x
∗
n , and hence their simultaneous solution is not easy if we want to solve
them directly. To simplify the simultaneous solution of Eqs. (8.14), we rewrite them as
∗jf
∗
cj
= (x∗1 )a1j (x∗2 )a2j · · · (x∗n)anj , j = 1, 2, . . . , N (8.15)
By taking logarithms on both the sides of Eqs. (8.15), we obtain
ln
∗jf
∗
cj
= a1j ln x∗1 + a2j ln x∗2 + · · · + anj ln x∗n,
j = 1, 2, . . . , N (8.16)
By letting
wi = ln x∗i , i = 1, 2, . . . , n (8.17)
Eqs. (8.16) can be written as
a11w1 + a21w2 + · · · + an1wn = ln
f ∗∗1
c1
a12w1 + a22w2 + · · · + an2wn = ln
f ∗∗2
c2
...
a1Nw1 + a2Nw2 + · · · + anNwn = ln
f ∗∗N
cN
(8.18)
8.4 Solution Using Differential Calculus 497
These equations, in the case of problems with a zero degree of difficulty, give a unique
solution to w1, w2, . . . , wn. Once wi are found, the desired solution can be obtained as
x∗i = ewi, i = 1, 2, . . . , n (8.19)
In a general geometric programming problem with a nonnegative degree of difficulty,
N ≥ n + 1, and hence Eqs. (8.18) denote N equations in n unknowns. By choosing
any n linearly independent equations, we obtain a set of solutions wi and hence x
∗
i .
The solution of an unconstrained geometric programming problem is illustrated
with the help of the following zero-degree-of-difficulty example [8.1].
Example 8.1 It has been decided to shift grain from a warehouse to a factory in an
open rectangular box of length x1 meters, width x2 meters, and height x3 meters. The
bottom, sides, and the ends of the box cost, respectively, $80, $10, and $20/m2. It costs
$1 for each round trip of the box. Assuming that the box will have no salvage value,
find the minimum cost of transporting 80 m3 of grain.
SOLUTION The total cost of transportation is given by
total cost = cost of box + cost of transportation
= (cost of sides + cost of bottom + cost of ends of the box)
+ (number of round trips required for transporting the grain
× cost of each round trip)
f (X) = [(2x1x3)10 + (x1x2)80 + (2x2x3)20] +
[
80
x1x2x3
(1)
]
= $
(
80x1x2 + 40x2x3 + 20x1x3 +
80
x1x2x3
)
(E1)
where x1, x2, and x3 indicate the dimensions of the box, as shown in Fig. 8.1. By
comparing Eq. (E1) with the general posynomial of Eq. (8.1), we obtain
c1 = 80, c2 = 40, c3 = 20, c4 = 80


a11 a12 a13 a14
a21 a22 a23 a24
a31 a32 a33 a34

 =


1 0 1 −1
1 1 0 −1
0 1 1 −1


The orthogonality and normality conditions are given by




1 0 1 −1
1 1 0 −1
0 1 1 −1
1 1 1 1











1
2
3
4







=







0
0
0
1







498 Geometric Programming
Figure 8.1 Open rectangular box.
that is,
1 + 3 − 4 = 0 (E2)
1 + 2 − 4 = 0 (E3)
2 + 3 − 4 = 0 (E4)
1 + 2 + 3 + 4 = 1 (E5)
From Eqs. (E2) and (E3), we obtain
4 = 1 + 3 = 1 + 2 or 2 = 3 (E6)
Similarly, Eqs. (E3) and (E4) give us
4 = 1 + 2 = 2 + 3 or 1 = 3 (E7)
Equations (E6) and (E7) yield
1 = 2 = 3
while Eq. (E6) gives
4 = 1 + 3 = 21
Finally, Eq. (E5) leads to the unique solution
∗1 = ∗2 = ∗3 = 15 and 
∗
4 =
2
5
Thus the optimal value of the objective function can be found from Eq. (8.13) as
f ∗ =
(
80
1/5
)1/5 (
40
1/5
)1/5 (
20
1/5
)1/5 (
80
2/5
)2/5
= (4 × 102)1/5(2 × 102)1/5(1 × 102)1/5(4 × 104)1/5
= (32 × 1010)1/5 = $200
8.4 Solution Using Differential Calculus 499
It can be seen that the minimum total cost has been obtained before finding the
optimal size of the box. To find the optimal values of the design variables, let us write
Eqs. (8.14) as
U∗1 = 80x∗1x∗2 = ∗1f ∗ =
1
5
(200) = 40 (E8)
U∗2 = 40x∗2x∗3 = ∗2f ∗ =
1
5
(200) = 40 (E9)
U∗3 = 20x∗1x∗3 = ∗3f ∗ =
1
5
(200) = 40 (E10)
U∗4 =
80
x∗1x
∗
2x
∗
3
= ∗4f ∗ =
2
5
(200) = 80 (E11)
From these equations, we obtain
x∗2 = 12
1
x∗1
= 1
x∗3
, x∗1 =
x∗3
2
, x∗2 =
1
x∗3
1
x∗1x
∗
2x
∗
3
= 1 =
2x∗3
x∗3x
∗
3
, x∗3 = 2
Therefore,
x∗1 = 1 m, x∗2 = 12 m, x
∗
3 = 2 m (E12)
It is to be noticed that there is one redundant equation among Eqs. (E8) to (E11), which
is not needed for the solution of x∗i (i = 1 to n).
The solution given in Eq. (E12) can also be obtained using Eqs. (8.18). In the
present case, Eqs. (8.18) lead to
1w1 + 1w2 + 0w3 = ln
200 × 1
5
80
= ln 1
2
(E13)
0w1 + 1w2 + 1w3 = ln
200 × 1
5
40
= ln 1 (E14)
1w1 + 0w2 + 1w3 = ln
200 × 1
5
20
= ln 2 (E15)
−1w1 − 1w2 − 1w3 = ln
200 × 2
5
80
= ln 1 (E16)
By adding Eqs. (E13), (E14), and (E16), we obtain
w2 = ln 12 + ln 1 + ln 1 = ln(
1
2
· 1 · 1) = ln 1
2
= ln x∗2
or
x∗2 = 12
Similarly, by adding Eqs. (E13), (E15), and (E16), we get
w1 = ln 12 + ln 2 + ln 1 = ln 1 = ln x
∗
1
500 Geometric Programming
or
x∗1 = 1
Finally, we can obtain x∗3 by adding Eqs. (E14), (E15), and (E16) as
w3 = ln 1 + ln 2 + ln 1 = ln 2 = ln x∗3
or
x∗3 = 2
It can be noticed that there are four equations, Eqs. (E13) to (E16) in three unknowns
w1, w2, and w3. However, not all of them are linearly independent. In this case, the
first three equations only are linearly independent, and the fourth equation, (E16), can
be obtained by adding Eqs. (E13), (E14), and (E15), and dividing the result by −2.
8.5 SOLUTION OF AN UNCONSTRAINED GEOMETRIC
PROGRAMMING PROBLEM USING
ARITHMETIC–GEOMETRIC INEQUALITY
The arithmetic mean–geometric mean inequality (also known as the arithmetic–
geometric inequality or Cauchy’s inequality) is given by [8.1]
1u1 + 2u2 + · · · + NuN ≥ u11 u
2
2 · · ·u
N
N (8.20)
with
1 + 2 + · · · + N = 1 (8.21)
This inequality is found to be very useful in solving geometric programming problems.
Using the inequality of (8.20), the objective function of Eq. (8.3) can be written as (by
setting Ui = uii, i = 1, 2, . . . , N)
U1 + U2 + · · · + UN ≥
(
U1
1
)1
(
U2
2
)2
· · ·
(
UN
N
)N
(8.22)
where Ui = Ui(X), i = 1, 2, . . . , N , and the weights 1, 2, . . . ,N , satisfy
Eq. (8.21). The left-hand side of the inequality (8.22) [i.e., the original function f (X)]
is called the primal function . The right side of inequality (8.22) is called the predual
function . By using the known relations
Uj = cj
n
∏
i=1
x
aij
i , j = 1, 2, . . . , N (8.23)
the predual function can be expressed as
(
U1
1
)1
(
U2
2
)2
· · ·
(
UN
N
)N
=




c1
n
∏
i=1
x
ai1
i
1




1 



c2
n
∏
i=1
x
ai2
i
2




2
· · ·




cN
n
∏
i=1
x
aiN
i
N




N
8.6 Primal–Dual Relationship and Sufficiency Conditions in the Unconstrained Case 501
=
(
c1
1
)1
(
c2
2
)2
· · ·
(
CN
N
)N



(
n
∏
i=1
x
ai1
i
)1
(
n
∏
i=1
x
ai2
i
)2
· · ·
(
n
∏
i=1
x
aiN
i
)N



=
(
c1
1
)1
(
c2
2
)2
· · ·
(
cN
N
)N
{(
x
∑N
j=1 a1j j
1
)(
x
∑N
j=1 a2j j
2
)
· · ·
(
x
∑N
j=1 anj j
n
)}
(8.24)
If we select the weights j so as to satisfy the normalization condition, Eq. (8.21),
and also the orthogonality relations
N
∑
j=1
aijj = 0, i = 1, 2, . . . , n (8.25)
Eq. (8.24) reduces to
(
U1
1
)1
(
U2
2
)2
· · ·
(
UN
N
)N
=
(
c1
1
)1
(
c2
2
)2
· · ·
(
cN
N
)N
(8.26)
Thus the inequality (8.22) becomes
U1 + U2 + · · · + UN ≥
(
c1
1
)1
(
c2
2
)2
· · ·
(
cN
N
)N
(8.27)
In this inequality, the right side is called the dual function , v(1, 2, . . . ,N ). The
inequality (8.27) can be written simply as
f ≥ v (8.28)
A basic result is that the maximum of the dual function equals the minimum of the
primal function. Proof of this theorem is given in the next section. The theorem enables
us to accomplish the optimization by minimizing the primal or by maximizing the dual,
whichever is easier. Also, the maximization of the dual function subject to the orthog-
onality and normality conditions is a sufficient condition for f , the primal function, to
be a global minimum.
8.6 PRIMAL–DUAL RELATIONSHIP AND SUFFICIENCY
CONDITIONS IN THE UNCONSTRAINED CASE
If f ∗ indicates the minimum of the primal function and v∗ denotes the maximum of
the dual function, Eq. (8.28) states that
f ≥ f ∗ ≥ v∗ ≥ v (8.29)
502 Geometric Programming
In this section we prove that f ∗ = v∗ and also that f ∗ corresponds to the global
minimum of f (X). For convenience of notation, let us denote the objective function
f (X) by x0 and make the exponential transformation
ewi = xi or wi = ln xi, i = 0, 1, 2, . . . , n (8.30)
where the variables wi are unrestricted in sign. Define the new variables j , also
termed weights , as
j =
Uj
x0
=
cj
n
∏
i=1
x
aij
i
x0
, j = 1, 2, . . . , N (8.31)
which can be seen to be positive and satisfy the relation
N
∑
j=1
j = 1 (8.32)
By taking logarithms on both sides of Eq. (8.31), we obtain
ln j = ln cj +
n
∑
i=1
aij ln xi − ln x0 (8.33)
or
ln
j
cj
=
n
∑
i=1
aijwi − w0, j = 1, 2, . . . , N (8.34)
Thus the original problem of minimizing f (X) with no constraints can be replaced
by one of minimizing w0 subject to the equality constraints given by Eqs. (8.32) and
(8.34). The objective function x0 is given by
x0 = ew0 =
N
∑
j=1
cj
n
∏
i=1
eaij wi
=
N
∑
j=1
cje
∑n
i=1 aij wi (8.35)
Since the exponential function (eaij wi ) is convex with respect to wi , the objective
function x0, which is a positive combination of exponential functions, is also convex
(see Problem 8.15). Hence there is only one stationary point for x0 and it must be the
global minimum. The global minimum point of w0 can be obtained by constructing the
following Lagrangian function and finding its stationary point:
L(w, , λ) = w0 + λ0
(
N
∑
i=1
i − 1
)
+
N
∑
j=1
λj
(
n
∑
i=1
aijwi − w0 − ln
j
cj
)
(8.36)
8.6 Primal–Dual Relationship and Sufficiency Conditions in the Unconstrained Case 503
where
w =









w0
w1
...
wn









,  =









1
2
...
N









, λ =









λ0
λ1
...
λN









(8.37)
with λ denoting the vector of Lagrange multipliers. At the stationary point of L, we
have
∂L
∂wi
= 0, i = 0, 1, 2, . . . , n
∂L
∂j
= 0, j = 1, 2, . . . , N
∂L
∂λi
= 0, i = 0, 1, 2, . . . , N
(8.38)
These equations yield the following relations:
1 −
N
∑
j=1
λj = 0 or
N
∑
j=1
λj = 1 (8.39)
N
∑
j=1
λjaij = 0, i = 1, 2, . . . , n (8.40)
λ0 −
λj
j
= 0 or λ0 =
λj
j
, j = 1, 2, . . . , N (8.41)
N
∑
j=1
j − 1 = 0 or
N
∑
j=1
j = 1 (8.42)
− ln
j
cj
+
n
∑
i=1
aijwi − w0 = 0, j = 1, 2, . . . , N (8.43)
Equations (8.39), (8.41), and (8.42) give the relation
N
∑
j=1
λj = 1 =
N
∑
j=1
λ0j = λ0
N
∑
j=1
j = λ0 (8.44)
Thus the values of the Lagrange multipliers are given by
λj =
{
1 for j = 0
j for j = 1, 2, . . . , N
(8.45)
504 Geometric Programming
By substituting Eq. (8.45) into Eq. (8.36), we obtain
L(, w) = −
N
∑
j=1
j ln
j
cj
+ (1 − w0)


N
∑
j=1
j − 1

+
n
∑
i=1
wi


N
∑
j=1
aijj


(8.46)
The function given in Eq. (8.46) can be considered as the Lagrangian function cor-
responding to a new optimization problem whose objective function ṽ() is given by
ṽ() = −
N
∑
j=1
j ln
j
cj
= ln


N
∏
j=1
(
cj
j
)j

 (8.47)
and the constraints by
N
∑
j=1
j − 1 = 0 (8.48)
N
∑
j=1
aijj = 0, i = 1, 2, . . . , n (8.49)
This problem will be the dual for the original problem. The quantities (1 − w0),
w1, w2, . . . , wn can be regarded as the Lagrange multipliers for the constraints given
by Eqs. (8.48) and (8.49).
Now it is evident that the vector  which makes the Lagrangian of Eq. (8.46)
stationary will automatically give a stationary point for that of Eq. (8.36). It can be
proved that the function
j ln
j
cj
, j = 1, 2, . . . , N
is convex (see Problem 8.16) since j is positive. Since the function ṽ() is given
by the negative of a sum of convex functions, it will be a concave function. Hence
the function ṽ() will have a unique stationary point that will be its global maximum
point. Hence the minimum of the original primal function is same as the maximum of
the function given by Eq. (8.47) subject to the normality and orthogonality conditions
given by Eqs. (8.48) and (8.49) with the variables j constrained to be positive.
By substituting the optimal solution ∗, the optimal value of the objective function
becomes
ṽ∗ = ṽ(∗) = L(w∗, ∗) = w∗0 = L(w∗, ∗, λ∗)
= −
N
∑
j=1
∗j ln
∗j
cj
(8.50)
By taking the exponentials and using the transformation relation (8.30), we get
f ∗ =
N
∏
j=1
(
cj
∗j
)∗
j
(8.51)
8.6 Primal–Dual Relationship and Sufficiency Conditions in the Unconstrained Case 505
Primal and Dual Problems. We saw that geometric programming treats the prob-
lem of minimizing posynomials and maximizing product functions. The minimization
problems are called primal programs and the maximization problems are called dual
programs . Table 8.1 gives the primal and dual programs corresponding to an uncon-
strained minimization problem.
Computational Procedure. To solve a given unconstrained minimization problem,
we construct the dual function v() and maximize either v() or ln v(), whichever
is convenient, subject to the constraints given by Eqs. (8.48) and (8.49). If the degree
of difficulty of the problem is zero, there will be a unique solution for the ∗j ’s.
For problems with degree of difficulty greater than zero, there will be more vari-
ables j (j = 1, 2, . . . , N) than the number of equations (n + 1). Sometimes it will
be possible for us to express any (n + 1) number of j ’s in terms of the remaining
(N − n − 1) number of j ’s. In such cases, our problem will be to maximize v() or
ln v() with respect to the (N − n − 1) independent j ’s. This procedure is illustrated
with the help of the following one-degree-of-difficulty example.
Example 8.2 In a certain reservoir pump installation, the first cost of the pipe is given
by (100D + 50D2), where D is the diameter of the pipe in centimeters. The cost of
the reservoir decreases with an increase in the quantity of fluid handled and is given
by 20/Q, where Q is the rate at which the fluid is handled (cubic meters per second).
Table 8.1 Primal and Dual Programs Corresponding to an Unconstrained
Minimization Problem
Primal program Dual program
Find X =









x1
x2
...
xn









Find  =









1
2
...
N









so that so that
f (X) =
N
∑
j=1
cjx
a1j
1 x
a2j
2 · · ·x
anj
n v() =
N
∏
j=1
(
cj
j
)j
→ minimum or
x1 > 0, x2 > 0, . . . , xn > 0
ln v() = ln
[
N
∏
j=1
(
cj
j
)j
]
→ maximum
(8.47)
subject to the constraints
N
∑
j=1
j = 1 (8.48)
N
∑
j=1
aijj = 0, i = 1, 2, . . . , n (8.49)
506 Geometric Programming
The pumping cost is given by (300Q2/D5). Find the optimal size of the pipe and the
amount of fluid handled for minimum overall cost.
SOLUTION
f (D, Q) = 100D1Q0 + 50D2Q0 + 20D0Q−1 + 300D−5Q2 (E1)
Here we can see that
c1 = 100, c2 = 50, c3 = 20, c4 = 300
(
a11 a12 a13 a14
a21 a22 a23 a24
)
=
(
1 2 0 −5
0 0 −1 2
)
The orthogonality and normality conditions are given by



1 2 0 −5
0 0 −1 2
1 1 1 1












1
2
3
4









=





0
0
1





Since N >(n + 1), these equations do not yield the required j (j = 1 to 4) directly.
But any three of the j ’s can be expressed in terms of the remaining one. Hence by
solving for 1, 2, and 3 in terms of 4, we obtain
1 = 2 − 114
2 = 84 − 1 (E2)
3 = 24
The dual problem can now be written as
Maximize v(1, 2, 3,4)
=
(
c1
1
)1
(
c2
2
)2
(
c3
3
)3
(
c4
4
)4
=
(
100
2 − 114
)2−114 ( 50
84 − 1
)84−1 ( 20
24
)24
(
300
4
)4
Since the maximization of v is equivalent to the maximization of ln v, we will maximize
ln v for convenience. Thus
ln v = (2 − 114)[ln 100 − ln(2 − 114)] + (84 − 1)
× [ln 50 − ln(84 − 1)] + 24[ln 20 − ln(24)]
+ 4[ln 300 − ln(4)]
8.6 Primal–Dual Relationship and Sufficiency Conditions in the Unconstrained Case 507
Since ln v is expressed as a function of 4 alone, the value of 4 that maximizes ln v
must be unique (because the primal problem has a unique solution). The necessary
condition for the maximum of ln v gives
∂
∂4
(ln v) = −11[ln 100 − ln(2 − 114)] + (2 − 114)
11
2 − 114
+ 8 [ln 50 − ln(84 − 1)] + (84 − 1)
(
−
8
84 − 1
)
+ 2 [ln 20 − ln(24)] + 24
(
− 2
24
)
+ 1 [ln 300 − ln(4)] + 4
(
− 1
4
)
= 0
This gives after simplification
ln
(2 − 114)11
(84 − 1)8(24)24
− ln
(100)11
(50)8(20)2(300)
= 0
i.e.,
(2 − 114)11
(84 − 1)8(24)24
=
(100)11
(50)8(20)2(300)
= 2130 (E3)
from which the value of ∗4 can be obtained by using a trial-and-error process as
follows:
Value of ∗4 Value of left-hand side of Eq. (E3)
2/11 = 0.182 0.0
0.15
(0.35)11
(0.2)8(0.3)2(0.15)
≃ 284
0.147
(0.385)11
(0.175)8(0.294)2(0.147)
≃ 2210
0.146
(0.39)11
(0.169)8(0.292)2(0.146)
≃ 4500
Thus we find that ∗4 ≃ 0.147, and Eqs. (E2) give
∗1 = 2 − 11∗4 = 0.385
∗2 = 8∗4 − 1 = 0.175
∗3 = 2∗4 = 0.294
The optimal value of the objective function is given by
v∗ = f ∗ =
(
100
0.385
)0.385 (
50
0.175
)0.175 (
20
0.294
)0.294 (
300
0.147
)0.147
= 8.5 × 2.69 × 3.46 × 3.06 = 242
508 Geometric Programming
The optimum values of the design variables can be found from
U∗1 = ∗1f ∗ = (0.385)(242) = 92.2
U∗2 = ∗2f ∗ = (0.175)(242) = 42.4
U∗3 = ∗3f ∗ = (0.294)(242) = 71.1
U∗4 = ∗4f ∗ = (0.147)(242) = 35.6
(E4)
From Eqs. (E1) and (E4), we have
U∗1 = 100D∗ = 92.2
U∗2 = 50D∗2 = 42.4
U∗3 =
20
Q∗
= 71.1
U∗4 =
300Q∗2
D∗5
= 35.6
These equations can be solved to find the desired solution D∗ = 0.922 cm, Q∗ =
0.281 m3/s.
8.7 CONSTRAINED MINIMIZATION
Most engineering optimization problems are subject to constraints. If the objective
function and all the constraints are expressible in the form of posynomials, geometric
programming can be used most conveniently to solve the optimization problem. Let
the constrained minimization problem be stated as
Find X =









x1
x2
...
xn









which minimizes the objective function
f (X) =
N0
∑
j=1
c0j
n
∏
i=1
x
a0ij
i (8.52)
and satisfies the constraints
gk(X) =
Nk
∑
j=1
ckj
n
∏
i=1
x
akij
i ⋚ 1, k = 1, 2, . . . , m (8.53)
where the coefficients c0j (j = 1, 2, . . . , N0) and ckj (k = 1, 2, . . . , m; j = 1, 2,
. . . , Nk) are positive numbers, the exponents a0ij (i = 1, 2, . . . , n; j = 1, 2, . . . , N0)
8.8 Solution of a Constrained Geometric Programming Problem 509
and akij (k = 1, 2, . . . , m; i = 1, 2, . . . , n; j = 1, 2, . . . , Nk) are any real numbers,
m indicates the total number of constraints, N0 represents the number of terms in
the objective function, and Nk denotes the number of terms in the kth constraint.
The design variables x1, x2, . . . , xn are assumed to take only positive values in
Eqs. (8.52) and (8.53). The solution of the constrained minimization problem stated
above is considered in the next section.
8.8 SOLUTION OF A CONSTRAINED GEOMETRIC
PROGRAMMING PROBLEM
For simplicity of notation, let us denote the objective function as
x0 = g0(X) = f (X) =
N0
∑
i=1
c0j
n
∏
j=1
x
a0ij
i (8.54)
The constraints given in Eq. (8.53) can be rewritten as
fk = σk[1 − gk(X)] ≥ 0, k = 1, 2, . . . , m (8.55)
where σk , the signum function , is introduced for the kth constraint so that it takes on
the value +1 or −1, depending on whether gk(X) is ≤ 1 or ≥ 1, respectively. The
problem is to minimize the objective function, Eq. (8.54), subject to the inequality
constraints given by Eq. (8.55). This problem is called the primal problem and can be
replaced by an equivalent problem (known as the dual problem) with linear constraints,
which is often easier to solve. The dual problem involves the maximization of the dual
function, v(λ), given by
v(λ) =
m
∏
k=0
Nk
∏
j=1
(
ckj
λkj
Nk
∑
l=1
λkl
)σkλkj
(8.56)
subject to the normality and orthogonality conditions
N0
∑
j=1
λ0j = 1 (8.57)
m
∑
k=0
Nk
∑
j=1
σkakijλkj = 0, i = 1, 2, . . . , n (8.58)
If the problem has zero degree of difficulty, the normality and orthogonality conditions
[Eqs. (8.57) and (8.58)] yield a unique solution for λ∗ from which the stationary value
of the original objective function can be obtained as
f ∗ = x∗0 = v(λ∗) =
m
∏
k=0
Nk
∏
j=1
(
ckj
λ∗kj
Nk
∑
l=1
λ∗kl
)σkλ
∗
kj
(8.59)
510 Geometric Programming
If the function f (X) is known to possess a minimum, the stationary value f ∗ given
by Eq. (8.59) will be the global minimum of f since, in this case, there is a unique
solution for λ∗.
The degree of difficulty of the problem (D) is defined as
D = N − n − 1 (8.60)
where N denotes the total number of posynomial terms in the problem:
N =
m
∑
k=0
Nk (8.61)
If the problem has a positive degree of difficulty, the linear Eqs. (8.57) and (8.58)
can be used to express any (n + 1) of the λkj ’s in terms of the remaining D of the
λkj ’s. By using these relations, v can be expressed as a function of the D independent
λkj ’s. Now the stationary points of v can be found by using any of the unconstrained
optimization techniques.
If calculus techniques are used, the first derivatives of the function v with respect
to the independent dual variables are set equal to zero. This results in as many simul-
taneous nonlinear equations as there are degrees of difficulty (i.e., N − n − 1). The
solution of these simultaneous nonlinear equations yields the best values of the dual
variables, λ∗. Hence this approach is occasionally impractical due to the computa-
tions required. However, if the set of nonlinear equations can be solved, geometric
programming provides an elegant approach.
Optimum Design Variables. For problems with a zero degree of difficulty, the solu-
tion of λ∗ is unique. Once the optimum values of λkj are obtained, the maximum of the
dual function v∗ can be obtained from Eq. (8.59), which is also the minimum of the pri-
mal function, f ∗. Once the optimum value of the objective function f ∗ = x∗0 is known,
the next step is to determine the values of the design variables x∗i (i = 1, 2, . . . , n).
This can be achieved by solving simultaneously the following equations:
∗0j = λ∗0j ≡
c0j
n
∏
i=1
(x∗i )
a0ij
x∗0
, j = 1, 2, . . . , N0 (8.62)
∗kj =
λ∗kj
Nk
∑
l=1
λ∗kl
= ckj
n
∏
i=1
(x∗i )
akij , j = 1, 2, . . . , Nk (8.63)
k = 1, 2, . . . , m
8.9 PRIMAL AND DUAL PROGRAMS IN THE CASE
OF LESS-THAN INEQUALITIES
If the original problem has a zero degree of difficulty, the minimum of the primal
problem can be obtained by maximizing the corresponding dual function. Unfortunately,
this cannot be done in the general case where there are some greater than type of
inequality constraints. However, if the problem has all the constraints in the form of
8.9 Primal and Dual Programs in the Case of Less-Than Inequalities 511
gk(X) ≤ 1, the signum functions σk are all equal to +1, and the objective function
g0(X) will be a strictly convex function of the transformed variables w1, w2, . . . , wn,
where
xi = ewi, i = 0, 1, 2, . . . , n (8.64)
In this case, the following primal–dual relationship can be shown to be valid:
f (X) ≥ f ∗ ≡ v∗ ≥ v(λ) (8.65)
Table 8.2 gives the primal and the corresponding dual programs. The following char-
acteristics can be noted from this table:
1. The factors ckj appearing in the dual function v(λ) are the coefficients of the
posynomials gk(X), k = 0, 1, 2, . . . , m.
2. The number of components in the vector λ is equal to the number of terms
involved in the posynomials g0, g1, g2, . . . , gm. Associated with every term in
gk(X), there is a corresponding kj .
3. Each factor
(
∑Nk
l=1 λkl
)λkj
of v(λ) comes from an inequality constraint gk(X) ≤
1. No such factor appears from the primal function g0(X) as the normality
condition forces
∑N0
j=1 λ0j to be unity.
4. The coefficient matrix [akij ] appearing in the orthogonality condition is same
as the exponent matrix appearing in the posynomials of the primal program.
The following examples are considered to illustrate the method of solving geometric
programming problems with less-than inequality constraints.
Example 8.3 Zero-degree-of-difficulty Problem Suppose that the problem considered
in Example 8.1 is restated in the following manner. Minimize the cost of constructing
the open rectangular box subject to the constraint that a maximum of 10 trips only are
allowed for transporting the 80 m3 of grain.
SOLUTION The optimization problem can be stated as
Find X =



x1
x2
x3



so as to minimize
f (X) = 20x1x2 + 40x2x3 + 80x1x2
subject to
80
x1x2x3
≤ 10 or
8
x1x2x3
≤ 1
Since n = 3 and N = 4, this problem has zero degree of difficulty. As N0 = 3, N1 = 1,
and m = 1, the dual problem can be stated as follows:
Find λ =







λ01
λ02
λ03
λ11







to maximize
512 Geometric Programming
Table 8.2 Corresponding Primal and Dual Programs
Primal program Dual program
Find X =









x1
x2
...
xn









so that
g0(X) ≡ f (X) → minimum
subject to the constraints
x1 > 0
x2 > 0
...
xn > 0,
g1(X) ≤ 1
g2(X) ≤ 1
...
gm(X) ≤ 1,
Find λ =

































































λ01
λ02
...
λ0N0
· · ·
λ11
λ12
...
λ1N1
· · ·
...
· · ·
λm1
λm2
...
λmNm

































































so that
v(λ) =
m
∏
k=0
Nk
∏
j=1
(
ckj
λkj
Nk
∑
l=1
λkl
)λkj
→ maximum
with subject to the constraints
g0(X) =
N0
∑
j=1
c0jx
a01j
1 x
a02j
2 · · · x
a0nj
n
g1(X) =
N1
∑
j=1
c1jx
a11j
1 x
a12j
2 · · · x
a1nj
n
g2(X) =
N2
∑
j=1
c2jx
a21j
1 x
a22j
2 · · · x
a2nj
n
...
gm(X) =
Nm
∑
j=1
cmjx
am1j
1 x
am2j
2 · · · x
amnj
n
λ01 ≥ 0
λ02 ≥ 0
...
λ0N0 ≥ 0
λ11 ≥ 0
...
λ1N1 ≥ 0
...
λm1 ≥ 0
λm2 ≥ 0
...
λmNm ≥ 0
(continues)
8.9 Primal and Dual Programs in the Case of Less-Than Inequalities 513
Table 8.2 (continued )
Primal program Dual program
the exponents akij are real numbers, and
the coefficients ckj are positive numbers.
N0
∑
j=1
λ0j = 1
m
∑
k=0
Nk
∑
j=1
akijλkj = 0, i = 1, 2, . . . , n
the factors ckj are positive, and the
coefficients akij are real numbers.
Terminology
g0 = f = primal function
x1, x2, . . . , xn = primal variables
gk ≤ 1 are primal constraints
(k = 1, 2, . . . , m)
xi > 0, i = 1, 2, . . . , n positive restrictions.
n = number of primal variables
m = number of primal constriants
N = N0 + N1 + · · · + Nm = total number
of terms in the posynomials
N − n − 1 = degree of difficulty of the
problem
ν = dual function
λ01, λ02, . . . , λmNm = dual variables
N0
∑
j=1
λ0j = 1 is the normality constraint
m
∑
k=0
Nk
∑
j=1
akijλkj = 0, i = 1, 2, . . . , n are the
orthogonality constraints
λkj ≥ 0, j = 1, 2, . . . , Nk;
k = 0, 1, 2, . . . , m
are nonnegativity restrictions
N = N0 + N1 + · · · + Nm
= number of dual variables
n + 1 number of dual constraints
v(λ) =
1
∏
k = 0
Nk
∏
j=1
(
ckj
λkj
Nk
∑
l=1
λkl
)λkj
=
N0=3
∏
j=1


c0j
λ0j
N0=3
∑
l=1
λ0l


λ0j N1=1
∏
j=1
(
c1j
λ1j
N1=1
∑
l=1
λ1l
)λ1j
=
[
c01
λ01
(λ01 + λ02 + λ03)
]λ01
[
c02
λ02
(λ01 + λ02 + λ03)
]λ02
·
[
c03
λ03
(λ01 + λ02 + λ03)
]λ03
(
c11
λ11
λ11
)λ11
(E1)
subject to the constraints
λ01 + λ02 + λ03 = 1
a011λ01 + a012λ02 + a013λ03 + a111λ11 = 0
514 Geometric Programming
a021λ01 + a022λ02 + a023λ03 + a121λ11 = 0
a031λ01 + a032λ02 + a033λ03 + a131λ11 = 0 (E2)
λ0j ≥ 0, j = 1, 2, 3
λ11 ≥ 0
In this problem, c01 = 20, c02 = 40, c03 = 80, c11 = 8, a011 = 1, a021 = 0, a031 = 1,
a012 = 0, a022 = 1, a032 = 1, a013 = 1, a023 = 1, a033 = 0, a111 = −1, a121 = −1, and
a131 = −1. Hence Eqs. (E1) and (E2) become
v(λ) =
[
20
λ01
(λ01 + λ02 + λ03)
]λ01
[
40
λ02
(λ01 + λ02 + λ03)
]λ02
×
[
80
λ03
(λ01 + λ02 + λ03)
]λ03
(
8
λ11
λ11
)λ11
(E3)
subject to
λ01 + λ02 + λ03 = 1
λ01 + λ03 − λ11 = 0
λ02 + λ03 − λ11 = 0 (E4)
λ01 + λ02 − λ11 = 0
λ01 ≥ 0, λ02 ≥ 0, λ03 ≥ 0, λ11 ≥ 0
The four linear equations in Eq. (E4) yield the unique solution
λ∗01 = λ∗02 = λ∗03 = 13 , λ
∗
11 =
2
3
Thus the maximum value of v or the minimum value of x0 is given by
v∗ = x∗0 = (60)1/3(120)1/3(240)1/3(8)2/3
= [(60)3]1/3(8)1/3(8)2/3 = (60)(8) = 480
The values of the design variables can be obtained by applying Eqs. (8.62) and (8.63)
as
λ∗01 =
c01(x
∗
1 )
a011(x∗2 )
a021(x∗3 )
a031
x∗0
1
3
=
20(x∗1 )(x
∗
3 )
480
=
x∗1x
∗
3
24
(E5)
λ∗02 =
c02(x
∗
1 )
a012(x∗2 )
a022(x∗3 )
a032
x∗0
1
3
=
40(x∗2 )(x
∗
3 )
480
=
x∗2x
∗
3
12
(E6)
8.9 Primal and Dual Programs in the Case of Less-Than Inequalities 515
λ∗03 =
c03(x
∗
1 )
a013(x∗2 )
a023(x∗3 )
a033
x∗0
1
3
=
80(x∗1 )(x
∗
2 )
480
=
x∗1x
∗
2
6
(E7)
λ∗11
λ∗11
= c11(x∗1 )a111(x∗2 )a121(x∗3 )a131
1 = 8(x∗1 )−1(x∗2 )−1(x∗3 )−1 =
8
x∗1x
∗
2x
∗
3
(E8)
Equations (E5) to (E8) give
x∗1 = 2, x∗2 = 1, x∗3 = 4
Example 8.4 One-degree-of-difficulty Problem
Minimize f = x1x22x−13 + 2x
−1
1 x
−3
2 x4 + 10x1x3
subject to
3x−11 x3x
−2
4 + 4x3x4 ≤ 1
5x1x2 ≤ 1
SOLUTION Here N0 = 3, N1 = 2, N2 = 1, N = 6, n = 4, m = 2, and the degree
of difficulty of this problem is N − n − 1 = 1. The dual problem can be stated as
follows:
Maximixze v(λ) =
m
∏
k=0
Nk
∏
j=1
(
ckj
λkj
Nk
∑
l=1
λkl
)λkj
subject to
N0
∑
j=1
λ0j = 1
m
∑
k=0
Nk
∑
j=1
akijλkj = 0, i = 1, 2, . . . , n
Nk
∑
j=1
λkj ≥ 0, k = 1, 2, . . . , m
(E1)
As c01 = 1, c02 = 2, c03 = 10, c11 = 3, c12 = 4, c21 = 5, a011 = 1, a021 = 2, a031 =
−1, a041 = 0, a012 = −1, a022 = −3, a032 = 0, a042 = 1, a013 = 1, a023 = 0, a033 =
1, a043 = 0, a111 = −1, a121 = 0, a131 = 1, a141 = −2, a112 = 0, a122 = 0, a132 = 1,
516 Geometric Programming
a142 = 1, a211 = 1, a221 = 1, a231 = 0, and a241 = 0, Eqs. (E1) become
Maximize v(λ) =
[
c01
λ01
(λ01 + λ02 + λ03)
]λ01
[
c02
λ02
(λ01 + λ02 + λ03)
]λ02
×
[
c03
λ03
(λ01 + λ02 + λ03)
]λ03
[
c11
λ11
(λ11 + λ12)
]λ11
×
[
c12
λ12
(λ11 + λ12)
]λ12
(
c21
λ21
λ21
)λ21
subject to
λ01 + λ02 + λ03 = 1
a011λ01 + a012λ02 + a013λ03 + a111λ11 + a112λ12 + a211λ21 = 0
a021λ01 + a022λ02 + a023λ03 + a121λ11 + a122λ12 + a221λ21 = 0
a031λ01 + a032λ02 + a033λ03 + a131λ11 + a132λ12 + a231λ21 = 0
a041λ01 + a042λ02 + a043λ03 + a141λ11 + a142λ12 + a241λ21 = 0
λ11 + λ12 ≥ 0
λ21 ≥ 0
or
Maximize v(λ) =
(
1
λ01
)λ01 (
2
λ02
)λ02 (
10
λ03
)λ03
[
3
λ11
(λ11 + λ12)
]λ11
×
[
4
λ12
(λ11 + λ12)
]λ12
(5)λ21 (E2)
subject to
λ01 + λ02 + λ03 = 1
λ01 − λ02 + λ03 − λ11 + λ21 = 0
2λ01 − 3λ02 + λ21 = 0
−λ01 + λ03 + λ11 + λ12 = 0
λ02 − 2λ11 + λ12 = 0
(E3)
λ11 + λ12 ≥ 0
λ21 ≥ 0
Equations (E3) can be used to express any five of the λ’s in terms of the remaining
one as follows: Equations (E3) can be rewritten as
λ02 + λ03 = 1 − λ01 (E4)
λ02 − λ03 + λ11 − λ21 = λ01 (E5)
3λ02 − λ21 = 2λ01 (E6)
8.9 Primal and Dual Programs in the Case of Less-Than Inequalities 517
λ12 = λ01 − λ03 − λ11 (E7)
λ12 = 2λ11 − λ02 (E8)
From Eqs. (E7) and (E8), we have
λ12 = λ01 − λ03 − λ11 = 2λ11 − λ02
3λ11 − λ02 + λ03 = λ01 (E9)
Adding Eqs. (E5) and (E9), we obtain
λ21 = 4λ11 − 2λ01 (E10)
= 3λ02 − 2λ01 from Eq. (E6)
λ11 = 34λ02 (E11)
Substitution of Eq. (E11) in Eq. (E8) gives
λ12 = 32λ02 − λ02 =
1
2
λ02 (E12)
Equations (E11), (E12), and (E7) give
λ03 = λ01 − λ11 − λ12 = λ01 − 34λ02 −
1
2
λ02 = λ01 − 54λ02 (E13)
By substituting for λ03, Eq. (E4) gives
λ02 = 8λ01 − 4 (E14)
Using this relation for λ02, the expressions for λ03, λ11, λ12, and λ21 can be obtained
as
λ03 = λ01 − 54λ02 = −9λ01 + 5 (E15)
λ11 = 34λ02 = 6λ01 − 3 (E16)
λ12 = 12λ02 = 4λ01 − 2 (E17)
λ21 = 4λ11 − 2λ01 = 22λ01 − 12 (E18)
Thus the objective function in Eq. (E2) can be stated in terms of λ01 as
v(λ01) =
(
1
λ01
)λ01
(
2
8λ01 − 4
)8λ01−4 ( 10
5 − 9λ01
)5−9λ01
×
(
30λ01 − 15
6λ01 − 3
)6λ01−3 (40λ01 − 20
4λ01 − 2
)4λ01−2
(5)22λ01−12
=
(
1
λ01
)λ01
(
1
4λ01 − 2
)8λ01−4 ( 10
5 − 9λ01
)5−9λ01
× (5)6λ01−3(10)4λ01−2(5)22λ01−12
=
(
1
λ01
)λ01
(
1
4λ01 − 2
)8λ01−4 ( 10
5 − 9λ01
)5−9λ01
(5)32λ01−17(2)4λ01−2
518 Geometric Programming
To find the maximum of v, we set the derivative of v with respect to λ01 equal to
zero. To simplify the calculations, we set d (ln v)/dλ01 = 0 and find the value of λ∗01.
Then the values of λ∗02, λ
∗
03, λ
∗
11, λ
∗
12, and λ
∗
21 can be found from Eqs. (E14) to (E18).
Once the dual variables (λ∗kj ) are known, Eqs. (8.62) and (8.63) can be used to find
the optimum values of the design variables as in Example 8.3.
8.10 GEOMETRIC PROGRAMMING WITH MIXED
INEQUALITY CONSTRAINTS
In this case the geometric programming problem contains at least one signum function
with a value of σk = −1 among k = 1, 2, . . . , m. (Note that σ0 = +1 corresponds to
the objective function.) Here no general statement can be made about the convexity
or concavity of the constraint set. However, since the objective function is continuous
and is bounded below by zero, it must have a constrained minimum provided that there
exist points satisfying the constraints.
Example 8.5
Minimize f = x1x22x−13 + 2x
−1
1 x
−3
2 x4 + 10x1x3
subject to
3x1x
−1
3 x
2
4 + 4x−13 x
−1
4 ≥ 1
5x1x2 ≤ 1
SOLUTION In this problem, m = 2, N0 = 3, N1 = 2, N2 = 1, N = 6, n = 4, and the
degree of difficulty is 1. The signum functions are σ0 = 1, σ1 = −1, and σ2 = 1. The
dual objective function can be stated, using Eq. (8.56), as follows:
Maximize v(λ) =
2
∏
k=0
Nk
∏
j=1
(
ckj
λkj
Nk
∑
l=1
λkl
)σkλkj
=
[
c01
λ01
(λ01 + λ02 + λ03)
]λ01
[
c02
λ02
(λ01 + λ02 + λ03)
]λ02
×
[
c03
λ03
(λ01 + λ02 + λ03)
]λ03
×
[
c11
λ11
(λ11 + λ12)
]−λ11 [ c12
λ12
(λ11 + λ12)
]−λ12 ( c21
λ21
λ21
)λ21
=
(
1
λ01
)λ01
(
2
λ02
)λ02
(
10
λ03
)λ03
[
3(λ11 + λ12)
λ11
]−λ11
×
[
4(λ11 + λ12)
λ12
]−λ12
(5)λ21 (E1)
8.10 Geometric Programming with Mixed Inequality Constraints 519
The constraints are given by (see Table 8.2)
N0
∑
j=1
λ0j = 1
m
∑
k=0
Nk
∑
j=1
σkakijλkj = 0, i = 1, 2, . . . , n
Nk
∑
j=1
λkj ≥ 0, k = 1, 2, . . . ,m
that is,
λ01 + λ02 + λ03 = 1
σ0a011λ01 + σ0a012λ02 + σ0a013λ03 + σ1a111λ11 + σ1a112λ12 + σ2a211λ21 = 0
σ0a021λ01 + σ0a022λ02 + σ0a023λ03 + σ1a121λ11 + σ1a122λ12 + σ2a221λ21 = 0
σ0a031λ01 + σ0a032λ02 + σ0a033λ03 + σ1a131λ11 + σ1a132λ12 + σ2a231λ21 = 0
σ0a041λ01 + σ0a042λ02 + σ0a043λ03 + σ1a141λ11 + σ1a142λ12 + σ2a241λ21 = 0
λ11 + λ12 ≥ 0
λ21 ≥ 0
that is,
λ01 + λ02 + λ03 = 1
λ01 − λ02 + λ03 − λ11 + λ21 = 0
2λ01 − 3λ02 + λ21 = 0
−λ01 + λ03 + λ11 + λ12 = 0
λ02 − 2λ11 + λ12 = 0
(E2)
λ11 + λ12 ≥ 0
λ21 ≥ 0
Since Eqs. (E2) are same as Eqs. (E3) of the preceding example, the equality constraints
can be used to express λ02, λ03, λ11, λ12, and λ21 in terms of λ01 as
λ02 = 8λ01 − 4
λ03 = −9λ01 + 5
λ11 = 6λ01 − 3
λ12 = 4λ01 − 2
λ21 = 22λ01 − 12
(E3)
520 Geometric Programming
By using Eqs. (E3), the dual objective function of Eq. (E1) can be expressed as
v (λ01) =
(
1
λ01
)λ01
(
2
8λ01 − 4
)8λ01−4 ( 10
−9λ01 + 5
)5−9λ01
×
[
3(10λ01 − 5)
6λ01 − 3
]−6λ01+3 [4(10λ01 − 5)
4λ01 − 2
]−4λ01+2
(5)22λ01−12
=
(
1
λ01
)λ01
(
1
4λ01 − 2
)8λ01−4 ( 10
5 − 9λ01
)5−9λ01
(5)3−6λ01(10)2−4λ01
× (5)22λ01−12
=
(
1
λ01
)λ01
(
1
4λ01 − 2
)8λ01−4 ( 10
5 − 9λ01
)5−9λ01
(5)12λ01−7(2)2−4λ01
To maximize v, set d (ln v)/dλ01 = 0 and find λ∗01. Once λ∗01 is known, λ∗kj can be
obtained from Eqs. (E3) and the optimum design variables from Eqs. (8.62) and (8.63).
8.11 COMPLEMENTARY GEOMETRIC PROGRAMMING
Avriel and Williams [8.4] extended the method of geometric programming to include
any rational function of posynomial terms and called the method complementary geo-
metric programming .† The case in which some terms may be negative will then become
a special case of complementary geometric programming. While geometric program-
ming problems have the remarkable property that every constrained local minimum is
also a global minimum, no such claim can generally be made for complementary geo-
metric programming problems. However, in many practical situations, it is sufficient
to find a local minimum.
The algorithm for solving complementary geometric programming problems con-
sists of successively approximating rational functions of posynomial terms by posyn-
omials. Thus solving a complementary geometric programming problem by this algo-
rithm involves the solution of a sequence of ordinary geometric programming problems.
It has been proved that the algorithm produces a sequence whose limit is a local
minimum of the complementary geometric programming problem (except in some
pathological cases).
Let the complementary geometric programming problem be stated as follows:
Minimize R0(X)
subject to
Rk(X) ≤ 1, k = 1, 2, . . . , m
where
Rk(X) =
Ak(X) − Bk(X)
Ck(X) − Dk(X)
, k = 0, 1, 2, . . . , m (8.66)
†The application of geometric programming to problems involving generalized polynomial functions was
presented by Passy and Wilde [8.2].
8.11 Complementary Geometric Programming 521
where Ak(X), Bk(X), Ck(X), and Dk(X) are posynomials in X and possibly some of
them may be absent. We assume that R0(X) > 0 for all feasible X. This assumption
can always be satisfied by adding, if necessary, a sufficiently large constant to R0(X).
To solve the problem stated in Eq. (8.66), we introduce a new variable x0 > 0,
constrained to satisfy the relation x0 ≥ R0(X) [i.e., R0(X)/x0 ≤ 1], so that the problem
can be restated as
Minimize x0 (8.67)
subject to
Ak(X) − Bk(X)
Ck(X) − Dk(X)
≤ 1, k = 0, 1, 2, . . . , m (8.68)
where
A0(X) = R0(X), C0(X) = x0, B0(X) = 0, and D0(X) = 0
It is to be noted that the constraints have meaning only if Ck(X) − Dk(X) has a constant
sign throughout the feasible region. Thus if Ck(X) − Dk(X) is positive for some feasible
X, it must be positive for all other feasible X. Depending on the positive or negative
nature of the term Ck(X) − Dk(X), Eq. (8.68) can be rewritten as
Ak(X) + Dk(X)
Bk(X) + Ck(X)
≤ 1
or (8.69)
Bk(X) + Ck(X)
Ak(X) + Dk(X)
≤ 1
Thus any complementary geometric programming problem (CGP) can be stated in
standard form as
Minimize x0 (8.70)
subject to
Pk(X)
Qk(X)
≤ 1, k = 1, 2, . . . , m (8.71)
X =















x0
x1
x2
...
xn















> 0 (8.72)
where Pk(X) and Qk(X) are posynomials of the form
Pk(X) =
∑
j
ckj
n
∏
i=0
(xi)
akij =
∑
j
pkj (X) (8.73)
Qk(X) =
∑
j
dkj
n
∏
i=0
(xi)
bkij =
∑
j
qkj (X) (8.74)
522 Geometric Programming
Solution Procedure.
1. Approximate each of the posynomials Q(X)† by a posynomial term. Then all
the constraints in Eq. (8.71) can be expressed as a posynomial to be less than
or equal to 1. This follows because a posynomial divided by a posynomial
term is again a posynomial. Thus with this approximation, the problem reduces
to an ordinary geometric programming problem. To approximate Q(X) by a
single-term posynomial, we choose any
˜
X > 0 and let
Uj = qj (X) (8.75)
j =
qj (
˜
X)
Q(
˜
X)
(8.76)
where qj denotes the j th term of the posynomial Q(X). Thus we obtain, by
using the arithmetic–geometric inequality, Eq. (8.22),
Q(X) =
∑
j
qj (X) ≥
∏
j
[
qj (X)
qj (
˜
X)
Q(
˜
X)
]qj (
˜
X)/Q(
˜
X)
(8.77)
By using Eq. (8.74), the inequality (8.77) can be restated as
Q(X) ≥
˜
Q(X,
˜
X) ≡ Q(
˜
X)
∏
i
(
xi
˜
xi
)
∑
j [bij qj (
˜
X)/Q(
˜
X)]
(8.78)
where the equality sign holds true if xi =
˜
xi . We can take Q(X,
˜
X) as an
approximation for Q(X) at
˜
X.
2. At any feasible point X(1), replace Qk(X) in Eq. (8.71) by their approximations
˜
Qk(X, X
(1)), and solve the resulting ordinary geometric programming problem
to obtain the next point X(2).
3. By continuing in this way, we generate a sequence {X(α)}, where X(α+1) is an
optimal solution for the αth ordinary geometric programming problem (OGPα):
Minimize x0
subject to
Pk(X)
˜
Qk(X, X
(α))
≤ 1, k = 1, 2, . . . , m
X =













x0
x1
x2
...
xn













> 0 (8.79)
It has been proved [8.4] that under certain mild restrictions, the sequence of
points {X(α)} converges to a local minimum of the complementary geometric
programming problem.
†The subscript k is removed for Q(X) for simplicity.
8.11 Complementary Geometric Programming 523
Degree of Difficulty. The degree of difficulty of a complementary geometric pro-
gramming problem (CGP) is also defined as
degree of difficulty = N − n − 1
where N indicates the total number of terms appearing in the numerators of Eq. (8.71).
The relation between the degree of difficulty of a CGP and that of the OGPα, the
approximating ordinary geometric program, is important. The degree of difficulty of a
CGP is always equal to that of the approximating OGPα , solved at each iteration. Thus
a CGP with zero degree of difficulty and an arbitrary number of negative terms can
be solved by a series of solutions to square systems of linear equations. If the CGP
has one degree of difficulty, at each iteration we solve an OGP with one degree of
difficulty, and so on. The degree of difficulty is independent of the choice of X(α) and
is fixed throughout the iterations. The following example is considered to illustrate the
procedure of complementary geometric programming.
Example 8.6
Minimize x1
subject to
−4x21 + 4x2 ≤ 1
x1 + x2 ≥ 1
x1 > 0, x2 > 0
SOLUTION This problem can be stated as a complementary geometric programming
problem as
Minimize x1 (E1)
subject to
4x2
1 + 4x21
≤ 1 (E2)
x−11
1 + x−11 x2
≤ 1 (E3)
x1 > 0 (E4)
x2 > 0 (E5)
Since there are two variables (x1 and x2) and three posynomial terms [one term in the
objective function and one term each in the numerators of the constraint Eqs. (E2) and
(E3)], the degree of difficulty of the CGP is zero. If we denote the denominators of
Eqs. (E2) and (E3) as
Q1(X) = 1 + 4x21
Q2(X) = 1 + x−11 x2
524 Geometric Programming
they can each be approximated by a single-term posynomial with the help of Eq. (8.78)
as
˜
Q1(X,
˜
X) = (1 + 4
˜
x21)
(
x1
˜
x2
)8
˜
x21/(1+4
˜
x21)
˜
Q2(X,
˜
X) =
(
1 + ˜
x2
˜
x1
)(
x1
˜
x1
)−
˜
x2/(
˜
x1+
˜
x2) (x2
˜
x1
)
˜
x2/(
˜
x1+
˜
x2)
Let us start the iterative process from the point X(1) =
{
1
1
}
, which can be seen to be
feasible. By taking
˜
X = X(1), we obtain
˜
Q1(X, X
(1)) = 5x8/51
˜
Q2(X, X
(1)) = 2x−1/21 x
1/2
2
and we formulate the first ordinary geometric programming problem (OGP1) as
Minimize x1
subject to
4
5
x
−8/5
1 x2 ≤ 1
1
2
x
−1/2
1 x
−1/2
2 ≤ 1
x1 > 0
x2 > 0
Since this (OGP1) is a geometric programming problem with zero degree of difficulty,
its solution can be found by solving a square system of linear equations, namely
λ1 = 1
λ1 − 85λ2 −
1
2
λ3 = 0
λ2 − 12λ3 = 0
The solution is λ∗1 = 1, λ∗2 =
5
13
, λ∗3 =
10
13
. By substituting this solution into the dual
objective function, we obtain
v(λ∗) = ( 4
5
)5/13 ( 1
2
)10/13 ≃ 0.5385
From the duality relations, we get
x1 ≃ 0.5385 and x2 = 54 (x1)
8/15 ≃ 0.4643
Thus the optimal solution of OGP1 is given by
X
(1)
opt =
{
0.5385
0.4643
}
8.12 Applications of Geometric Programming 525
Next we choose X(2) to be the optimal solution of OGP1 [i.e., X
(1)
opt ] and approx-
imate Q1 and Q2 about this point, solve OGP2, and so on. The sequence of optimal
solutions of OGPα as generated by the iterative procedure is shown below:
Xopt
Iteration number, α x1 x2
0 1.0 1.0
1 0.5385 0.4643
2 0.5019 0.5007
3 0.5000 0.5000
The optimal values of the variables for the CGP are x∗1 = 0.5 and x∗2 = 0.5. It can be
seen that in three iterations, the solution of the approximating geometric programming
problems OGPα is correct to four significant figures.
8.12 APPLICATIONS OF GEOMETRIC PROGRAMMING
Example 8.7 Determination of Optimum Machining Conditions [8.9, 8.10] Geomet-
ric programming has been applied for the determination of optimum cutting speed and
feed which minimize the unit cost of a turning operation.
Formulation as a Zero-degree-of-difficulty Problem
The total cost of turning per piece is given by
f0(X) = machining cost + tooling cost + handling cost
= Kmtm +
tm
T
(Kmtc + Kt) + Kmth (E1)
where Km is the cost of operating time ($/min), Kt the tool cost ($/cutting edge),
tm the machining time per piece (min) = πDL/(12VF ), T the tool life (min/cutting
edge) = (a/VFb)1/c, tc the tool changing time (minutes/workpiece), th the handling
time (min/workpiece), D the diameter of the workpiece (in), L the axial length of the
workpiece (in.), V the cutting speed (ft/min), F the feed (in./revolution), a, b, and c
are constants in tool life equation, and
X =
{
x1
x2
}
=
{
V
F
}
Since the constant term will not affect the minimization, the objective function can be
taken as
f (X) = C01V −1F−1 + C02V 1/c−1F b/c−1 (E2)
where
C01 =
KmπDL
12
and C02 =
πDL(Kmtc + Kt )
12 a1/c
(E3)
526 Geometric Programming
If the maximum feed allowable on the lathe is Fmax, we have the constraint
C11F ≤ 1 (E4)
where
C11 = F−1max (E5)
Since the total number of terms is three and the number of variables is two, the degree
of difficulty of the problem is zero. By using the data
Km = 0.10, Kt = 0.50, tc = 0.5, th = 2.0, D = 6.0,
L = 8.0, a = 140.0, b = 0.29, c = 0.25, Fmax = 0.005
the solution of the problem [minimize f given in Eq. (E2) subject to the constraint
(E4)] can be obtained as
f ∗ = $1.03 per piece, V ∗ = 323 ft/min, F ∗ = 0.005 in./rev
Formulation as a One-degree-of-difficulty Problem
If the maximum horsepower available on the lathe is given by Pmax, the power required
for machining should be less than Pmax. Since the power required for machining can
be expressed as a1V
b1F c1 , where a1, b1, and c1 are constants, this constraint can be
stated as follows:
C21V
b1F c1 ≤ 1 (E6)
where
C21 = a1P −1max (E7)
If the problem is to minimize f given by Eq. (E2) subject to the constraints (E4) and
(E6), it will have one degree of difficulty. By taking Pmax = 2.0 and the values of a1,
b1, and c1 as 3.58, 0.91, and 0.78, respectively, in addition to the previous data, the
following result can be obtained:
f ∗ = $1.05 per piece, V ∗ = 290.0 ft/min, F ∗ = 0.005 in./rev
Formulation as a Two-degree-of-difficulty Problem
If a constraint on the surface finish is included as
a2V
b2F c2 ≤ Smax
where a2, b2, and c2 are constants and Smax is the maximum permissible surface rough-
ness in microinches, we can restate this restriction as
C31V
b2F c2 ≤ 1 (E8)
8.12 Applications of Geometric Programming 527
where
C31 = a2S−1max (E9)
If the constraint (E8) is also included, the problem will have a degree of difficulty
two. By taking a2 = 1.36 × 108, b2 = −1.52, c2 = 1.004, Smax = 100 µin., Fmax =
0.01, and Pmax = 2.0 in addition to the previous data, we obtain the following result:
f ∗ = $1.11 per piece, V ∗ = 311 ft/min, F ∗ = 0.0046 in./rev
Example 8.8 Design of a Hydraulic Cylinder [8.11] The minimum volume design
of a hydraulic cylinder (subject to internal pressure) is considered by taking the pis-
ton diameter (d), force (f ), hydraulic pressure (p), stress (s), and the cylinder wall
thickness (t) as design variables. The following constraints are considered:
Minimum force required is F , that is,
f = p
πd2
4
≥ F (E1)
Hoop stress induced should be less than S, that is,
s = pd
2t
≤ S (E2)
Side constraints:
d + 2t ≤ D (E3)
p ≤ P (E4)
t ≥ T (E5)
where D is the maximum outside diameter permissible, P the maximum pressure
of the hydraulic system and T the minimum cylinder wall thickness required.
Equations (E1) to (E5) can be stated in normalized form as
4
π
Fp−1d−2 ≤ 1
1
2
S−1pdt−1 ≤ 1
D−1d + 2D−1t ≤ 1
P −1p ≤ 1
T t−1 ≤ 1
The volume of the cylinder per unit length (objective) to be minimized is given by
πt(d + t).
Example 8.9 Design of a Cantilever Beam Formulate the problem of determining
the cross-sectional dimensions of the cantilever beam shown in Fig. 8.2 for minimum
weight. The maximum permissible bending stress is σy .
528 Geometric Programming
Figure 8.2 Cantilever beam of rectangular cross section.
SOLUTION The width and depth of the beam are considered as design variables.
The objective function (weight) is given by
f (X) = ρlx1x2 (E1)
where ρ is the weight density and l is the length of the beam. The maximum stress
induced at the fixed end is given by
σ =
Mc
I
= P l
x2
2
1
1
12
x1x
3
2
=
6P l
x1x
2
2
(E2)
and the constraint becomes
6P l
σy
x−11 x
−2
2 ≤ 1 (E3)
Example 8.10 Design of a Cone Clutch [8.23] Find the minimum volume design
of the cone clutch shown in Fig.1.18 such that it can transmit a specified minimum
torque.
SOLUTION By selecting the outer and inner radii of the cone, R1 and R2, as design
variables, the objective function can be expressed as
f (R1, R2) = 13πh(R
2
1 + R1R2 + R22) (E1)
where the axial thickness, h, is given by
h =
R1 − R2
tan α
(E2)
Equations (E1) and (E2) yield
f (R1, R2) = k1(R31 − R32) (E3)
where
k1 =
π
3 tan α
(E4)
8.12 Applications of Geometric Programming 529
The axial force applied (F) and the torque developed (T ) are given by [8.37]
F =
∫
p dA sin α =
∫ R1
R2
p
2πr dr
sin α
sin α = πp(R21 − R22) (E5)
T =
∫
rfp dA =
∫ R1
R2
rfp
2πr
sin α
dr = 2πfp
3 sin α
(R31 − R32) (E6)
where p is the pressure, f the coefficient of friction, and A the area of contact.
Substitution of p from Eq. (E5) into (E6) leads to
T =
k2(R
2
1 + R1R2 + R22)
R1 + R2
(E7)
where
k2 =
2Ff
3 sin α
(E8)
Since k1 is a constant, the objective function can be taken as f = R31 − R32 . The min-
imum torque to be transmitted is assumed to be 5k2. In addition, the outer radius R1
is assumed to be equal to at least twice the inner radius R2. Thus the optimization
problem becomes
Minimize f (R1, R2) = R31 − R32
subject to
R21 + R2R2 + R22
R1 + R2
≥ 5 (E9)
R1
R2
≥ 2
This problem has been solved using complementary geometric programming [8.23]
and the solution was found iteratively as shown in Table 8.3. Thus the final solution is
taken as R∗1 = 4.2874, R∗2 = 2.1437, and f ∗ = 68.916.
Example 8.11 Design of a Helical Spring Formulate the problem of minimum
weight design of a helical spring under axial load as a geometric programming prob-
lem. Consider constraints on the shear stress, natural frequency, and buckling of the
spring.
SOLUTION By selecting the mean diameter of the coil and the diameter of the wire
as the design variables, the design vector is given by
X =
{
x1
x2
}
=
{
D
d
}
(E1)
The objective function (weight) of the helical spring can be expressed as
f (X) =
πd2
4
(πD)ρ(n + Q) (E2)
530 Geometric Programming
Table 8.3 Results for Example 8.10
Iteration Starting Ordinary geometric programming Solution
number design problem of OGP
1 x1 = R0 = 40 Minimize x11x02x03 x1 = 162.5
x2 = R1 = 3 subject to x2 = 5.0
x3 = R2 = 3 0.507x−0.5971 x32x
−1.21
3 ≤ 1 x3 = 2.5
1.667(x−12 + x
−1
3 ) ≤ 1
2 x1 = R0 = 162.5 Minimize x11x02x03 x1 = 82.2
x2 = R1 = 5.0 subject to x2 = 4.53
x3 = R2 = 2.5 0.744x−0.9121 x32x
−0.2635
3 ≤ 1 x3 = 2.265
3.05(x−0.432 x
−0.571
3 + x
−1.43
2 x
0.429
3 ) ≤ 1
2x−12 x3 ≤ 1
3 x1 = R0 = 82.2 Minimize x11x02x03 x1 = 68.916
x2 = R1 = 4.53 subject to x2 = 4.2874
x3 = R2 = 2.265 0.687x−0.8761 x32x
−0.372
3 ≤ 1 x3 = 2.1437
1.924x01x
−0.429
2 x
−0.571
3 +
1.924x01x
−1.492
2 x
0.429
3 ≤ 1
2x−12 x3 ≤ 1
where n is the number of active turns, Q the number of inactive turns, and ρ the weight
density of the spring. If the deflection of the spring is δ, we have
δ = 8PC
3n
Gd
or n = Gdδ
8PC3
(E3)
where G is the shear modulus, P the axial load on the spring, and C the spring index
(C = D/d). Substitution of Eq. (E3) into (E2) gives
f (X) = π
2ρGδ
32P
d6
D2
+ π
2ρQ
4
d2D (E4)
If the maximum shear stress in the spring (τ ) is limited to τmax, the stress constraint
can be expressed as
τ = 8KPC
πd2
≤ τmax or
8KPC
πd2τmax
≤ 1 (E5)
where K denotes the stress concentration factor given by
K ≈ 2
C0.25
(E6)
The use of Eq. (E6) in (E5) results in
16P
πτmax
D3/4
d11/4
≤ 1 (E7)
8.12 Applications of Geometric Programming 531
To avoid fatigue failure, the natural frequency of the spring (fn) is to be restricted to
be greater than (fn)min. The natural frequency of the spring is given by
fn =
2d
πD2n
(
Gg
32ρ
)1/2
(E8)
where g is the acceleration due to gravity. Using g = 9.81 m/s2, G = 8.56 ×
1010 N/m2, and (fn)min = 13, Eq. (E8) becomes
13(fn)minδG
288,800P
d3
D
≤ 1 (E9)
Similarly, in order to avoid buckling, the free length of the spring is to be limited
as
L ≤ 11.5(D/2)
2
P/K1
(E10)
Using the relations
K1 = Gd
4
8D3n
(E11)
L = nd(1 + Z) (E12)
and Z = 0.4, Eq. (E10) can be expressed as
0.0527
(
Gδ2
P
)
d5
D5
≤ 1 (E13)
It can be seen that the problem given by the objective function of Eq. (E4) and con-
straints of Eqs. (E7), (E9), and (E13) is a geometric programming problem.
Example 8.12 Design of a Lightly Loaded Bearing [8.29] A lightly loaded bearing
is to be designed to minimize a linear combination of frictional moment and angle of
twist of the shaft while carrying a load of 1000 lb. The angular velocity of the shaft is
to be greater than 100 rad/s.
SOLUTION
Formulation as a Zero-Degree-of-Difficulty Problem
The frictional moment of the bearing (M) and the angle of twist of the shaft (φ) are
given by
M = 8π√
1 − n2
µ
c
R2L (E1)
φ = Sel
GR
(E2)
where µ is the viscosity of the lubricant, n the eccentricity ratio (= e/c), e the eccentric-
ity of the journal relative to the bearing, c the radial clearance,  the angular velocity
532 Geometric Programming
of the shaft, R the radius of the journal, L the half-length of the bearing, Se the shear
stress, l the length between the driving point and the rotating mass, and G the shear
modulus. The load on each bearing (W ) is given by
W = 2µRL
2n
c2(1 − n2)2
[π2(1 − n2) + 16n2]1/2 (E3)
For the data W = 1000 lb, c/R = 0.0015, n = 0.9, l = 10 in., Se = 30,000 psi,
µ = 10−6 lb-s/in2, and G = 12 × 106 psi, the objective function and the constraint
reduce to
f (R, L) = aM + bφ = 0.038R2L + 0.025R−1 (E4)
R−1L3 = 11.6 (E5)
 ≥ 100 (E6)
where a and b are constants assumed to be a = b = 1. Using the solution of Eq. (E5)
gives
 = 11.6RL−3 (E7)
the optimization problem can be stated as
Minimize f (R, L) = 0.45R3L−2 + 0.025R−1 (E8)
subject to
8.62R−1L3 ≤ 1 (E9)
The solution of this zero-degree-of-difficulty problem can be determined as R∗ =
0.212 in., L∗ = 0.291 in., and f ∗ = 0.17.
Formulation as a One-Degree-of-Difficulty Problem
By considering the objective function as a linear combination of the frictional moment
(M), the angle of twist of the shaft (φ), and the temperature rise of the oil (T ),
we have
f = aM + bφ + cT (E10)
where a, b, and c are constants. The temperature rise of the oil in the bearing is given
by
T = 0.045 µR
2
c2n
√
(1 − n2)
(E11)
By assuming that 1 in.-lb of frictional moment in bearing is equal to 0.0025 rad of angle
of twist, which, in turn, is equivalent to 1
◦
F rise in temperature, the constants a, b,
and c can be determined. By using Eq. (E7), the optimization problem can be stated
as
Minimize f (R, L) = 0.44R3L−2 + 10R−1 + 0.592RL−3 (E12)
8.12 Applications of Geometric Programming 533
subject to
8.62R−1L3 ≤ 1 (E13)
The solution of this one-degree-of-difficulty problem can be found as R∗ = 1.29, L∗ =
0.53, and f ∗ = 16.2.
Example 8.13 Design of a Two-bar Truss [8.33] The two-bar truss shown in Fig. 8.3
is subjected to a vertical load 2P and is to be designed for minimum weight. The
members have a tubular section with mean diameter d and wall thickness t and the
maximum permissible stress in each member (σ0) is equal to 60,000 psi. Determine the
values of h and d using geometric programming for the following data: P = 33,000 lb,
t = 0.1 in., b = 30 in., σ0 = 60,000 psi, and ρ (density) = 0.3 lb/in3.
SOLUTION The objective function is given by
f (d, h) = 2ρπdt
√
b2 + h2
= 2(0.3)πd(0.1)
√
900 + h2 = 0.188d
√
900 + h2 (E1)
The stress constraint can be expressed as
σ = P
πdt
√
900 + h2
h
≤ σ0
or
33,000
πd(0.1)
√
900 + h2
h
≤ 60,000
Figure 8.3 Two-bar truss under load.
534 Geometric Programming
or
1.75
√
900 + h2
dh
≤ 1 (E2)
It can be seen that the functions in Eqs. (E1) and (E2) are not posynomials, due to the
presence of the term
√
900 + h2. The functions can be converted to posynomials by
introducing a new variable y as
y =
√
900 + h2 or y2 = 900 + h2
and a new constraint as
900 + h2
y2
≤ 1 (E3)
Thus the optimization problem can be stated, with x1 = y, x2 = h, and x3 = d as
design variables, as
Minimize f = 0.188yd (E4)
subject to
1.75yh−1d−1 ≤ 1 (E5)
900y−2 + y−2h2 ≤ 1 (E6)
For this zero-degree-of-difficulty problem, the associated dual problem can be stated
as
Maximize v(λ01, λ11, λ21, λ22)
=
(
0.188
λ01
)λ01
(
1.75
λ11
)λ11
(
900
λ21
)λ21
(
1
λ22
)λ22
(λ21 + λ22)λ21+λ22 (E7)
subject to
λ01 = 1 (E8)
λ01 + λ11 − 2λ21 − 2λ22 = 0 (E9)
−λ11 + 2λ22 = 0 (E10)
λ01 − λ11 = 0 (E11)
The solution of Eqs. (E8) to (E11) gives λ
∗
01 = 1, λ∗11 = 1, λ∗21 =
1
2
, and λ∗22 =
1
2
. Thus
the maximum value of v and the minimum value of f is given by
v∗ =
(
0.188
1
)1
(1.75)1
(
900
0.5
)0.5 (
1
0.5
)0.5
(0.5 + 0.5)0.5+0.5 = 19.8 = f ∗
8.12 Applications of Geometric Programming 535
The optimum values of xi can be found from Eqs. (8.62) and (8.63):
1 = 0.188y
∗d∗
19.8
1 = 1.75y∗h∗−1d∗−1
1
2
= 900y∗−2
1
2
= y∗−2h∗2
These equations give the solution: y∗ = 42.426, h∗ = 30 in., and d∗ = 2.475 in.
Example 8.14 Design of a Four-bar Mechanism [8.24] Find the link lengths of the
four-bar linkage shown in Fig. 8.4 for minimum structural error.
SOLUTION Let a, b, c, and d denote the link lengths, θ the input angle, and φ
the output angle of the mechanism. The loop closure equation of the linkage can be
expressed as
2ad cos θ − 2cd cos φ + (a2 − b2 + c2 + d2)
− 2ac cos(θ − φ) = 0 (E1)
In function-generating linkages, the value of φ generated by the mechanism is made
equal to the desired value, φd , only at some values of θ . These are known as precision
points . In general, for arbitrary values of the link lengths, the actual output angle (φi)
generated for a particular input angle (θi) involves some error (εi) compared to the
desired value (φdi), so that
φi = φdi + εi (E2)
where εi is called the structural error at θi . By substituting Eq. (E2) into (E1) and
assuming that sin εi ≈ εi and cos εi ≈ 1 for small values of εi , we obtain
εi =
K + 2ad cos θi − 2cd cos θdi − 2ac cos θi cos(φdi − θi)
−2ac sin(φdi − θi) − 2cd sin φdi
(E3)
where
K = a2 − b2 + c2 + d2 (E4)
Figure 8.4 Four-bar linkage.
536 Geometric Programming
The objective function for minimization is taken as the sum of squares of structural
error at a number of precision or design positions, so that
f =
n
∑
i=1
ε2i (E5)
where n denotes the total number of precision points considered. Note that the error εi
is minimized when f is minimized (εi will not be zero, usually).
For simplicity, we assume that a ≪ d and that the error εi is zero at θ0. Thus
ε0 = 0 at θi = θ0, and Eq. (E3) yields
K = 2cd cos φdi + 2ac cos θ0 cos(φd0 − θ0) − 2ad cos θ0 (E6)
In view of the assumption a ≪ d , we impose the constraint as (for convenience)
3a
d
≤ 1 (E7)
where any larger number can be used in place of 3. Thus the objective function for
minimization can be expressed as
f =
n
∑
i=1
a2(cos θi − cos θ0)2 − 2ac(cos θi − cos θ0)(cos φdi − cos φd0)
c2 sin2 φdi
(E8)
Usually, one of the link lengths is taken as unity. By selecting a and c as the design
variables, the normality and orthogonality conditions can be written as
∗1 + ∗2 = 1 (E9)
2∗1 + ∗2 = 0 (E10)
2∗1 + 0.5∗2 + ∗3 = 0 (E11)
These equations yield the solution ∗1 = −1, ∗2 = 2, and ∗3 = 1, and the maximum
value of the dual function is given by
v(∗) =
(
c1
∗1
)∗1
(
c2
∗2
)∗2
(
c3
∗3
)∗3
(E12)
where c1, c2, and c3 denote the coefficients of the posynomial terms in Eqs. (E7)
and (E8).
For numerical computation, the following data are considered:
Precision point, i 1 2 3 4 5 6
Input, θi (deg) 0 10 20 30 40 45
Desired output, φdi (deg) 30 38 47 58 71 86
If we select the precision point 4 as the point where the structural error is zero (θ0 = 30◦,
φd0 = 58◦), Eq. (E8) gives
f = 0.1563
a2
c2
−
0.76a
c
(E13)
References and Bibliography 537
subject to
3a
d
≤ 1
Noting that c1 = 0.1563, c2 = 0.76, and c3 = 3/d , we see that Eq. (E12) gives
v() =
(
0.1563
−1
)−1 (−0.76
2
)2 (
3
d
)1
(1)1 =
2.772
d
Noting that
0.1563
a2
c2
=
(
−2.772
d
)
(−1) = 2.772
d
−0.76
a
c
= −
2.772
d
(2) = −
5.544
d
and using a = 1, we find that c∗ = 0.41 and d∗ = 3.0. In addition, Eqs. (E6) and
(E4) yield
a2 − b2 + c2 + d2
= 2cd cos φd0 + 2ac cos θ0 cos(φd0 − θ0) − 2ad cos θ0
or b∗ = 3.662. Thus the optimal link dimensions are given by a∗ = 1, b∗ = 3.662,
c∗ = 0.41, and d∗ = 3.0.
REFERENCES AND BIBLIOGRAPHY
8.1 R. J. Duffin, E. Peterson, and C. Zener, Geometric Programming , Wiley, New York,
1967.
8.2 U. Passy and D. J. Wilde, Generalized polynomial optimization, SIAM Journal of Applied
Mathematics , Vol. 15, No. 5, pp. 1344–1356, Sept. 1967.
8.3 D. J. Wilde and C. S. Beightler, Foundations of Optimization , Prentice-Hall, Englewood
Cliffs, NJ, 1967.
8.4 M. Avriel and A. C. Williams, Complementary geometric programming, SIAM Journal
of Applied Mathematics , Vol. 19, No. 1, pp. 125–141, July 1970.
8.5 R. M. Stark and R. L. Nicholls, Mathematical Foundations for Design: Civil Engineering
Systems , McGraw-Hill, New York, 1972.
8.6 C. McMillan, Jr., Mathematical Programming: An Introduction to the Design and Appli-
cation of Optimal Decision Machines , Wiley, New York, 1970.
8.7 C. Zener, A mathematical aid in optimizing engineering designs, Proceedings of the
National Academy of Science, Vol. 47, p. 537, 1961.
8.8 C. Zener, Engineering Design by Geometric Programming , Wiley-Interscience, New York,
1971.
8.9 D. S. Ermer, Optimization of the constrained machining economics problem by geometric
programming, Journal of Engineering for Industry, Transactions of ASME , Vol. 93, pp.
1067–1072, Nov. 1971.
8.10 S. K. Hati and S. S. Rao, Determination of optimum machining conditions: deterministic
and probabilistic approaches, Journal of Engineering for Industry, Transactions of ASME ,
Vol. 98, pp. 354–359, May 1976.
538 Geometric Programming
8.11 D. Wilde, Monotonicity and dominance in optimal hydraulic cylinder design, Jour-
nal of Engineering for Industry, Transactions of ASME , Vol. 97, pp. 1390–1394, Nov.
1975.
8.12 A. B. Templeman, On the solution of geometric programs via separable programming,
Operations Research Quarterly , Vol. 25, pp. 184–185, 1974.
8.13 J. J. Dinkel and G. A. Kochenberger, On a cofferdam design optimization, Mathematical
Programming , Vol. 6, pp. 114–117, 1974.
8.14 A. J. Morris, A transformation for geometric programming applied to the minimum weight
design of statically determinate structure, International Journal of Mechanical Science,
Vol. 17, pp. 395–396, 1975.
8.15 A. B. Templeman, Optimum truss design by sequential geometric programming, Journal
of Structural Engineering , Vol. 3, pp. 155–163, 1976.
8.16 L. J. Mancini and R. L. Piziali, Optimum design of helical springs by geometric pro-
gramming, Engineering Optimization , Vol. 2, pp. 73–81, 1976.
8.17 K. M. Ragsdell and D. T. Phillips, Optimum design of a class of welded structures using
geometric programming, Journal of Engineering for Industry , Vol. 98, pp. 1021–1025,
1976.
8.18 R. S. Dembo, A set of geometric programming test problems and their solutions, Math-
ematical Programming , Vol. 10, pp. 192–213, 1976.
8.19 M. J. Rijckaert and X. M. Martens, Comparison of generalized geometric programming
algorithms, Journal of Optimization Theory and Applications , Vol. 26, pp. 205–242,
1978.
8.20 P.V.L.N. Sarma, X. M. Martens, G. V. Reklaitis, and M. J. Rijckaert, A comparison
of computational strategies for geometric programs, Journal of Optimization Theory and
Applications , Vol. 26, pp. 185–203, 1978.
8.21 R. S. Dembo, Current state of the art of algorithms and computer software for geometric
programming, Journal of Optimization Theory and Applications , Vol. 26, pp. 149–183,
1978.
8.22 R. S. Dembo, Sensitivity analysis in geometric programming, Journal of Optimization
Theory and Applications , Vol. 37, pp. 1–22, 1982.
8.23 S. S. Rao, Application of complementary geometric programming to mechanical design
problems, International Journal of Mechanical Engineering Education , Vol. 13, No. 1,
pp. 19–29, 1985.
8.24 A. C. Rao, Synthesis of 4-bar function generators using geometric programming, Mech-
anism and Machine Theory , Vol. 14, pp. 141–149, 1979.
8.25 M. Avriel and J. D. Barrett, Optimal design of pitched laminated wood beams, pp.
407–419 in Advances in Geometric Programming , M. Avriel, Ed., Plenum Press, New
York, 1980.
8.26 P. Petropoulos, Optimal selection of machining rate variables by geometric programming,
International Journal of Production Research , Vol. 11, pp. 305–314, 1973.
8.27 G. K. Agrawal, Helical torsion springs for minimum weight by geometric programming,
Journal of Optimization Theory and Applications , Vol. 25, No. 2, pp. 307–310, 1978.
8.28 C. S. Beightler and D. T. Phillips, Applied Geometric Programming , Wiley, New York,
1976.
8.29 C. S. Beightler, T.-C. Lo, and H. G. Rylander, Optimal design by geometric programming,
ASME Journal of Engineering for Industry , Vol. 92, No. 1, pp. 191–196, 1970.
8.30 Y. T. Sin and G. V. Reklaitis, On the computational utility of generalized geometric
programming solution methods: Review and test procedure design, pp. 7–14, Results and
Review Questions 539
interpretation , pp. 15–21, in Progress in Engineering Optimization–1981 , R. W. Mayne
and K. M. Ragsdell, Eds., ASME, New York, 1981.
8.31 M. Avriel, R. Dembo, and U. Passey, Solution of generalized geometric programs, Inter-
national Journal for Numerical Methods in Engineering , Vol. 9, pp. 149–168, 1975.
8.32 Computational aspects of geometric programming: 1. Introduction and basic notation,
pp. 115–120 (A. B. Templeman), 2. Polynomial programming, pp. 121–145 (J. Bradley),
3. Some primal and dual algorithms for posynomial and signomial geometric programs,
pp. 147–160 ( J. G. Ecker, W. Gochet, and Y. Smeers), 4. Computational experiments in
geometric programming, pp. 161–173 ( R. S. Dembo and M. J. Rijckaert), Engineering
Optimization , Vol. 3, No. 3, 1978.
8.33 A. J. Morris, Structural optimization by geometric programming, International Journal
of Solids and Structures , Vol. 8, pp. 847–864, 1972.
8.34 A. J. Morris, The optimisation of statically indeterminate structures by means of approx-
imate geometric programming, pp. 6.1–6.17 in Proceedings of the 2nd Symposium on
Structural Optimization, AGARD Conference Proceedings 123 , Milan, 1973.
8.35 A. B. Templeman and S. K. Winterbottom, Structural design applications of geometric pro-
gramming, pp. 5.1–5.15 in Proceedings of the 2nd Symposium on Structural Optimization,
AGARD Conference Proceedings 123 , Milan, 1973.
8.36 A. B. Templeman, Structural design for minimum cost using the method of geomet-
ric programming, Proceedings of the Institute of Civil Engineers , London, Vol. 46,
pp. 459–472, 1970.
8.37 J. E. Shigley and C. R. Mischke, Mechanical Engineering Design , 5th ed., McGraw-Hill,
New York, 1989.
REVIEW QUESTIONS
8.1 State whether each of the following functions is a polynomial, posynomial, or both.
(a) f = 4 − x21 + 6x1x2 + 3x22
(b) f = 4 + 2x21 + 5x1x2 + x22
(c) f = 4 + 2x21x
−1
2 + 3x
−4
2 + 5x
−1
1 x
3
2
8.2 Answer true or false:
(a) The optimum values of the design variables are to be known before finding the
optimum value of the objective function in geometric programming.
(b) ∗j denotes the relative contribution of the j th term to the optimum value of the
objective function.
(c) There are as many orthogonality conditions as there are design variables in a geometric
programming problem.
(d) If f is the primal and v is the dual, f ≤ v.
(e) The degree of difficulty of a complementary geometric programming problem is given
by (N − n − 1), where n denotes the number of design variables and N represents the
total number of terms appearing in the numerators of the rational functions involved.
(f) In a geometric programming problem, there are no restrictions on the number of
design variables and the number of posynomial terms.
8.3 How is the degree of difficulty defined for a constrained geometric programming problem?
8.4 What is arithmetic–geometric inequality?
540 Geometric Programming
8.5 What is normality condition in a geometric programming problem?
8.6 Define a complementary geometric programming problem.
PROBLEMS
Using arithmetic mean–geometric mean inequality, obtain a lower bound v for each function
[f (x) ≥ v, where v is a constant] in Problems 8.1–8.3.
8.1 f (x) =
x−2
3
+
2
3
x−3 +
4
3
x3/2
8.2 f (x) = 1 + x +
1
x
+
1
x2
8.3 f (x) = 1
2
x−3 + x2 + 2x
8.4 An open cylindrical vessel is to be constructed to transport 80 m3 of grain from a ware-
house to a factory. The sheet metal used for the bottom and sides cost $80 and $10 per
square meter, respectively. If it costs $1 for each round trip of the vessel, find the dimen-
sions of the vessel for minimizing the transportation cost. Assume that the vessel has no
salvage upon completion of the operation.
8.5 Find the solution of the problem stated in Problem 8.4 by assuming that the sides cost
$20 per square meter, instead of $10.
8.6 Solve the problem stated in Problem 8.4 if only 10 trips are allowed for transporting the
80 m3 of grain.
8.7 An automobile manufacturer needs to allocate a maximum sum of $2.5 × 106 between
the development of two different car models. The profit expected from both the models
is given by x1.51 x2, where xi denotes the money allocated to model i (i = 1, 2). Since
the success of each model helps the other, the amount allocated to the first model should
not exceed four times the amount allocated to the second model. Determine the amounts
to be allocated to the two models to maximize the profit expected. Hint: Minimize the
inverse of the profit expected.
8.8 Write the dual of the heat exchanger design problem stated in Problem 1.12.
8.9 Minimize the following function:
f (X) = x1x2x−23 + 2x
−1
1 x
−1
2 x3 + 5x2 + 3x1x
−2
2
8.10 Minimize the following function:
f (X) = 1
2
x21 + x2 +
3
2
x−11 x
−1
2
8.11 Minimize f (X) = 20x2x3x44 + 20x21x−13 + 5x2x
2
3
subject to
5x−52 x
−1
3 ≤ 1
10x−11 x
3
2x
−1
4 ≤ 1
xi > 0, i = 1 to 4
Problems 541
8.12 Minimize f (X) = x−21 +
1
4
x22x3
subject to
3
4
x21x
−2
2 +
3
8
x2x
−2
3 ≤ 1
xi > 0, i = 1, 2, 3
8.13 Minimize f (X) = x−31 x2 + x
3/2
1 x
−1
3
subject to
x21x
−1
2 +
1
2
x−21 x
3
3 ≤ 1
x1 > 0, x2 > 0, x3 > 0
8.14 Minimize f = x−11 x
−2
2 x
−2
3
subject to
x31 + x22 + x3 ≤ 1
xi > 0, i = 1, 2, 3
8.15 Prove that the function y = c1ea1x1 + c2ea2x2 + · · · + cneanxn , ci ≥ 0, i = 1, 2, . . . , n, is
a convex function with respect to x1, x2, . . . , xn.
8.16 Prove that f = ln x is a concave function for positive values of x.
8.17 The problem of minimum weight design of a helical torsional spring subject to a stress
constraint can be expressed as [8.27]
Minimize f (d,D) = π
2ρEφ
14,680M
d6 + π
2ρQ
4
Dd2
subject to
14.5M
d2.885D0.115σmax
≤ 1
where d is the wire diameter, D the mean coil diameter, ρ the density, E is Young’s
modulus, φ the angular deflection in degrees, M the torsional moment, and Q the number
of inactive turns. Solve this problem using geometric programming approach for the
following data: E = 20 × 1010 Pa, σmax = 15 × 107 Pa, φ = 20◦, Q = 2,M = 0.3 N-m,
and ρ = 7.7 × 104 N/m3.
8.18 Solve the machining economics problem given by Eqs. (E2) and (E4) of Example 8.7 for
the given data.
8.19 Solve the machining economics problem given by Eqs. (E2), (E4), and (E6) of Example
8.7 for the given data.
8.20 Determine the degree of difficulty of the problem stated in Example 8.8.
542 Geometric Programming
Figure 8.5 Floor consisting of a plate with supporting beams [8.36].
8.21 A rectangular area of dimensions A and B is to be covered by steel plates with supporting
beams as shown in Fig. 8.5. The problem of minimum cost design of the floor subject to a
constraint on the maximum deflection of the floor under a specified uniformly distributed
live load can be stated as [8.36]
Minimize f (X) = cost of plates + cost of beams
= kf γABt + kbγAk1nZ2/3 (1)
subject to
56.25WB4
EA
t−3n−4 +
(
4.69WBA3
Ek2
)
n−1Z−4/3 ≤ 1 (2)
where W is the live load on the floor per unit area, kf and kb are the unit costs of plates
and beams, respectively, γ the weight density of steel, t the thickness of plates, n the
number of beams, k1Z
2/3 the cross-sectional area of each beam, k2Z
4/3 the area moment
of inertia of each beam, k1 and k2 are constants, Z the section modulus of each beam,
and E the elastic modulus of steel. The two terms on the left side of Eq. (2) denote the
contributions of steel plates and beams to the deflection of the floor. By assuming the data
as A = 10 m, B = 50 m, W = 1000 kgf/m2, kb = $0.05/ kgf, kf = $0.06/ kgf, γ = 7850
kgf/m
3, E = 2.1 × 105 MN/m2, k1 = 0.78, and k2 = 1.95, determine the solution of the
problem (i.e., the values of t∗, n∗, and Z∗).
8.22 Solve the zero-degree-of-difficulty bearing problem given by Eqs. (E8) and (E9) of
Example 8.12.
8.23 Solve the one-degree-of-difficulty bearing problem given by Eqs. (E12) and (E13) of
Example 8.12.
8.24 The problem of minimum volume design of a statically determinate truss consisting of n
members (bars) with m unsupported nodes and subject to q load conditions can be stated
as follows [8.14]:
Minimize f =
n
∑
i=1
lixi (1)
Problems 543
subject to
F
(k)
i
xiσ
∗
i
≤ 1, i = 1, 2, . . . , n, k = 1, 2, . . . , q (2)
n
∑
i=1
F
(k)
i li
xiE
∗
i
sij ≤ 1, j = 1, 2, . . . , m, k = 1, 2, . . . , q (3)
where F
(k)
i is the tension in the ith member in the kth load condition, xi the cross-sectional
area of member i, li the length of member i, E is Young’s modulus, σ
∗
i the maximum
permissible stress in member i, and ∗j the maximum allowable displacement of node j .
Develop a suitable transformation technique and express the problem of Eqs. (1) to (3)
as a geometric programming problem in terms of the design variables xi .
9
Dynamic Programming
9.1 INTRODUCTION
In most practical problems, decisions have to be made sequentially at different points
in time, at different points in space, and at different levels, say, for a component, for
a subsystem, and/or for a system. The problems in which the decisions are to be made
sequentially are called sequential decision problems . Since these decisions are to be
made at a number of stages, they are also referred to as multistage decision problems .
Dynamic programming is a mathematical technique well suited for the optimization of
multistage decision problems. This technique was developed by Richard Bellman in
the early 1950s [9.2, 9.6].
The dynamic programming technique, when applicable, represents or decomposes
a multistage decision problem as a sequence of single-stage decision problems. Thus
an N -variable problem is represented as a sequence of N single-variable problems that
are solved successively. In most cases, these N subproblems are easier to solve than
the original problem. The decomposition to N subproblems is done in such a manner
that the optimal solution of the original N -variable problem can be obtained from
the optimal solutions of the N one-dimensional problems. It is important to note that
the particular optimization technique used for the optimization of the N single-variable
problems is irrelevant. It may range from a simple enumeration process to a differential
calculus or a nonlinear programming technique.
Multistage decision problems can also be solved by direct application of the clas-
sical optimization techniques. However, this requires the number of variables to be
small, the functions involved to be continuous and continuously differentiable, and the
optimum points not to lie at the boundary points. Further, the problem has to be rela-
tively simple so that the set of resultant equations can be solved either analytically or
numerically. The nonlinear programming techniques can be used to solve slightly more
complicated multistage decision problems. But their application requires the variables
to be continuous and prior knowledge about the region of the global minimum or max-
imum. In all these cases, the introduction of stochastic variability makes the problem
extremely complex and renders the problem unsolvable except by using some sort of an
approximation such as chance constrained programming.† Dynamic programming, on
the other hand, can deal with discrete variables, nonconvex, noncontinuous, and nondif-
ferentiable functions. In general, it can also take into account the stochastic variability
by a simple modification of the deterministic procedure. The dynamic programming
†The chance constrained programming is discussed in Chapter 11.
544 Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
9.2 Multistage Decision Processes 545
technique suffers from a major drawback, known as the curse of dimensionality . How-
ever, despite this disadvantage, it is very suitable for the solution of a wide range of
complex problems in several areas of decision making.
9.2 MULTISTAGE DECISION PROCESSES
9.2.1 Definition and Examples
As applied to dynamic programming, a multistage decision process is one in which
a number of single-stage processes are connected in series so that the output of one
stage is the input of the succeeding stage. Strictly speaking, this type of process should
be called a serial multistage decision process since the individual stages are connected
head to tail with no recycle. Serial multistage decision problems arise in many types
of practical problems. A few examples are given below and many others can be found
in the literature.
Consider a chemical process consisting of a heater, a reactor, and a distillation tower
connected in series. The objective is to find the optimal value of temperature in the
heater, the reaction rate in the reactor, and the number of trays in the distillation tower
such that the cost of the process is minimum while satisfying all the restrictions placed
on the process. Figure 9.1 shows a missile resting on a launch pad that is expected to
hit a moving aircraft (target) in a given time interval. The target will naturally take
evasive action and attempts to avoid being hit. The problem is to generate a set of
commands to the missile so that it can hit the target in the specified time interval.
This can be done by observing the target and, from its actions, generate periodically a
new direction and speed for the missile. Next, consider the minimum cost design of a
water tank. The system consists of a tank, a set of columns, and a foundation. Here the
tank supports the water, the columns support the weights of water and tank, and the
foundation supports the weights of water, tank, and columns. The components can be
Figure 9.1 Ground-radar-controlled missile chasing a moving target.
546 Dynamic Programming
seen to be in series and the system has to be treated as a multistage decision problem.
Finally, consider the problem of loading a vessel with stocks of N items. Each unit
of item i has a weight wi and a monetary value ci . The maximum permissible cargo
weight is W . It is required to determine the cargo load that corresponds to maximum
monetary value without exceeding the limitation of the total cargo weight. Although the
multistage nature of this problem is not directly evident, it can be posed as a multistage
decision problem by considering each item of the cargo as a separate stage.
9.2.2 Representation of a Multistage Decision Process
A single-stage decision process (which is a component of the multistage problem) can
be represented as a rectangular block (Fig. 9.2). A decision process can be character-
ized by certain input parameters, S (or data), certain decision variables (X), and certain
output parameters (T) representing the outcome obtained as a result of making the
decision. The input parameters are called input state variables , and the output param-
eters are called output state variables . Finally, there is a return or objective function
R, which measures the effectiveness of the decisions made and the output that results
from these decisions. For a single-stage decision process shown in Fig. 9.2, the output
is related to the input through a stage transformation function denoted by
T = t(X, S) (9.1)
Since the input state of the system influences the decisions we make, the return function
can be represented as
R = r(X, S) (9.2)
A serial multistage decision process can be represented schematically as shown
in Fig. 9.3. Because of some convenience, which will be seen later, the stages n,
n − 1, . . . , i, . . . , 2, 1 are labeled in decreasing order. For the ith stage, the input state
vector is denoted by si+1 and the output state vector as si . Since the system is a serial
one, the output from stage i + 1 must be equal to the input to stage i. Hence the state
transformation and return functions can be represented as
si = ti(si+1, xi) (9.3)
Ri = ri(si+1, xi) (9.4)
Figure 9.2 Single-stage decision problem.
9.2 Multistage Decision Processes 547
Figure 9.3 Multistage decision problem (initial value problem).
where xi denotes the vector of decision variables at stage i. The state transformation
equations (9.3) are also called design equations .
The objective of a multistage decision problem is to find x1, x2, . . . , xn so as
to optimize some function of the individual statge returns, say, f (R1, R2, . . . , Rn)
and satisfy Eqs. (9.3) and (9.4). The nature of the n-stage return function, f , deter-
mines whether a given multistage problem can be solved by dynamic programming.
Since the method works as a decomposition technique, it requires the separability
and monotonicity of the objective function. To have separability of the objective
function, we must be able to represent the objective function as the composition
of the individual stage returns. This requirement is satisfied for additive objective
functions:
f =
n
∑
i=1
Ri =
n
∑
i=1
Ri(xi, si+1) (9.5)
where xi are real, and for multiplicative objective functions,
f =
n
∏
i=1
Ri =
n
∏
i=1
Ri(xi , si+1) (9.6)
where xi are real and nonnegative. On the other hand, the following objective function
is not separable:
f = [R1(x1, s2) + R2(x2, s3)][R3(x3, s4) + R4(x4, s5)] (9.7)
Fortunately, there are many practical problems that satisfy the separability condition.
The objective function is said to be monotonic if for all values of a and b that
make
Ri(xi = a, si+1) ≥ Ri(xi = b, si+1)
the following inequality is satisfied:
f (xn, xn−1, . . . , xi+1, xi = a, xi−1, . . . , x1, sn+1)
≥ f (xn, xn−1, . . . , xi+1, xi = b, xi−1, . . . , x1, sn+1), i = 1, 2, . . . , n (9.8)
548 Dynamic Programming
9.2.3 Conversion of a Nonserial System to a Serial System
According to the definition, a serial system is one whose components (stages) are con-
nected in such a way that the output of any component is the input of the succeeding
component. As an example of a nonserial system, consider a steam power plant con-
sisting of a pump, a feedwater heater, a boiler, a superheater, a steam turbine, and an
electric generator, as shown in Fig. 9.4. If we assume that some steam is taken from the
turbine to heat the feedwater, a loop will be formed as shown in Fig. 9.4a. This nonserial
system can be converted to an equivalent serial system by regrouping the components
so that a loop is redefined as a single element as shown in Fig. 9.4b and c. Thus the
new serial multistage system consists of only three components: the pump, the boiler
and turbine system, and the electric generator. This procedure can easily be extended
to convert multistage systems with more than one loop to equivalent serial systems.
9.2.4 Types of Multistage Decision Problems
The serial multistage decision problems can be classified into three categories as
follows.
1. Initial value problem. If the value of the initial state variable, sn+1, is prescribed,
the problem is called an initial value problem.
2. Final value problem. If the value of the final state variable, s1 is prescribed, the
problem is called a final value problem. Notice that a final value problem can
be transformed into an initial value problem by reversing the directions of si ,
i = 1, 2, . . . , n + 1. The details of this are given in Section 9.7.
Figure 9.4 Serializing a nonserial system.
9.3 Concept of Suboptimization and Principle of Optimality 549
Figure 9.5 Types of multistage problems: (a) initial value problem; (b) final value problem;
(c) boundary value problem.
3. Boundary value problem. If the values of both the input and output variables
are specified, the problem is called a boundary value problem. The three types
of problems are shown schematically in Fig. 9.5, where the symbol |→ is used
to indicate a prescribed state variable.
9.3 CONCEPT OF SUBOPTIMIZATION AND PRINCIPLE
OF OPTIMALITY
A dynamic programming problem can be stated as follows.† Find x1, x2, . . . , xn, which
optimizes
f (x1, x2, . . . , xn) =
n
∑
i=1
Ri =
n
∑
i=1
ri(si+1, xi)
and satisfies the design equations
si = ti(si+1, xi), i = 1, 2, . . . , n
The dynamic programming makes use of the concept of suboptimization and the prin-
ciple of optimality in solving this problem. The concept of suboptimization and the
principle of optimality will be explained through the following example of an initial
value problem.
†In the subsequent discussion, the design variables xi and state variables si are denoted as scalars for
simplicity, although the theory is equally applicable even if they are vectors.
550 Dynamic Programming
Figure 9.6 Water tank system.
Example 9.1 Explain the concept of suboptimization in the context of the design of
the water tank shown in Fig. 9.6a. The tank is required to have a capacity of 100,000
liters of water and is to be designed for minimum cost [9.10].
SOLUTION Instead of trying to optimize the complete system as a single unit, it
would be desirable to break the system into components which could be optimized
more or less individually. For this breaking and component suboptimization, a logical
procedure is to be used; otherwise, the procedure might result in a poor solution. This
concept can be seen by breaking the system into three components: component i (tank),
component j (columns), and component k (foundation). Consider the suboptimization
of component j (columns) without a consideration of the other components. If the cost
of steel is very high, the minimum cost design of component j may correspond to
heavy concrete columns without reinforcement. Although this design may be accept-
able for columns, the entire weight of the columns has to be carried by the foundation.
This may result in a foundation that is prohibitively expensive. This shows that the
suboptimization of component j has adversely influenced the design of the following
component k. This example shows that the design of any interior component affects the
designs of all the subsequent (downstream) components. As such, it cannot be subop-
timized without considering its effect on the downstream components. The following
mode of suboptimization can be adopted as a rational optimization strategy. Since the
last component in a serial system influences no other component, it can be suboptimized
independently. Then the last two components can be considered together as a single
(larger) component and can be suboptimized without adversely influencing any of the
downstream components. This process can be continued to group any number of end
components as a single (larger) end component and suboptimize them. This process of
9.3 Concept of Suboptimization and Principle of Optimality 551
Figure 9.7 Suboptimization (principle of optimality).
suboptimization is shown in Fig. 9.7. Since the suboptimizations are to be done in the
reverse order, the components of the system are also numbered in the same manner for
convenience (see Fig. 9.3).
The process of suboptimization was stated by Bellman [9.2] as the principle of
optimality:
An optimal policy (or a set of decisions) has the property that whatever the
initial state and initial decision are, the remaining decisions must constitute
an optimal policy with regard to the state resulting from the first decision.
Recurrence Relationship. Suppose that the desired objective is to minimize the
n-stage objective function f , which is given by the sum of the individual stage returns:
Minimize f = Rn(xn, sn+1) + Rn−1(xn−1, sn) + · · · + R1(x1, s2) (9.9)
where the state and decision variables are related as
si = ti(si+1, xi), i = 1, 2, . . . , n (9.10)
552 Dynamic Programming
Consider the first subproblem by starting at the final stage, i = 1. If the input to this
stage s2 is specified, then according to the principle of optimality, x1 must be selected
to optimize R1. Irrespective of what happens to the other stages, x1 must be selected
such that R1(x1, s2) is an optimum for the input s2. If the optimum is denoted as f
∗
1 ,
we have
f ∗1 (s2) = opt
x1
[R1(x1, s2)] (9.11)
This is called a one-stage policy since once the input state s2 is specified, the optimal
values of R1, x1, and s1 are completely defined. Thus Eq. (9.11) is a parametric equation
giving the optimum f ∗1 as a function of the input parameter s2.
Next, consider the second subproblem by grouping the last two stages together.
If f ∗2 denotes the optimum objective value of the second subproblem for a specified
value of the input s3, we have
f ∗2 (s3) = opt
x1,x2
[R2(x2, s3) + R1(x1, s2)] (9.12)
The principle of optimality requires that x1 be selected so as to optimize R1 for a given
s2. Since s2 can be obtained once x2 and s3 are specified, Eq. (9.12) can be written
as
f ∗2 (s3) = opt
x2
[R2(x2, s3) + f
∗
1 (s2)] (9.13)
Thus f ∗2 represents the optimal policy for the two-stage subproblem. It can be seen
that the principle of optimality reduced the dimensionality of the problem from two
[in Eq. (9.12)] to one [in Eq. (9.13)]. This can be seen more clearly by rewriting
Eq. (9.13) using Eq. (9.10) as
f ∗2 (s3) = opt
x2
[R2(x2, s3) + f
∗
1 {t2(x2, s3)}] (9.14)
In this form it can be seen that for a specified input s3, the optimum is determined solely
by a suitable choice of the decision variable x2. Thus the optimization problem stated
in Eq. (9.12), in which both x2 and x1 are to be simultaneously varied to produce the
optimum f ∗2 , is reduced to two subproblems defined by Eqs. (9.11) and (9.13). Since
the optimization of each of these subproblems involves only a single decision variable,
the optimization is, in general, much simpler.
This idea can be generalized and the ith subproblem defined by
f ∗i (si+1) = opt
xi ,xi−1,...,x1
[Ri(xi, si+1) + Ri−1(xi−1, si) + · · · + R1(x1, s2)] (9.15)
which can be written as
f ∗i (si+1) = opt
xi
[Ri(xi , si+1) + f
∗
i−1(si)] (9.16)
where f ∗i−1 denotes the optimal value of the objective function corresponding to the last
i − 1 stages, and si is the input to the stage i − 1. The original problem in Eq. (9.15)
requires the simultaneous variation of i decision variables, x1, x2, . . . , xi , to determine
9.4 Computational Procedure in Dynamic Programming 553
the optimum value of fi =
∑i
k=1 Rk for any specified value of the input si+1. This
problem, by using the principle of optimality, has been decomposed into i separate
problems, each involving only one decision variable. Equation (9.16) is the desired
recurrence relationship valid for i = 2, 3, . . . , n.
9.4 COMPUTATIONAL PROCEDURE IN DYNAMIC
PROGRAMMING
The use of the recurrence relationship derived in Section 9.3 in actual computations is
discussed in this section [9.10]. As stated, dynamic programming begins by subopti-
mizing the last component, numbered 1. This involves the determination of
f ∗1 (s2) = opt
x1
[R1(x1, s2)] (9.17)
The best value of the decision variable x1, denoted as x
∗
1 , is that which makes the
return (or objective) function R1 assume its optimum value, denoted by f
∗
1 . Both x
∗
1
and f ∗1 depend on the condition of the input or feed that the component 1 receives from
the upstream, that is, on s2. Since the particular value s2 will assume after the upstream
components are optimized is not known at this time, this last-stage suboptimization
problem is solved for a “range” of possible values of s2 and the results are entered
into a graph or a table. This graph or table contains a complete summary of the results
of suboptimization of stage 1. In some cases, it may be possible to express f ∗1 as a
function of s2. If the calculations are to be performed on a computer, the results of
suboptimization have to be stored in the form of a table in the computer. Figure 9.8
shows a typical table in which the results obtained from the suboptimization of
stage 1 are entered.
Next we move up the serial system to include the last two components. In this
two-stage suboptimization, we have to determine
f ∗2 (s3) = opt
x2,x1
[R2(x2, s3) + R1(x1, s2)] (9.18)
Since all the information about component 1 has already been encoded in the table
corresponding to f ∗1 , this information can then be substituted for R1 in Eq. (9.18) to
Figure 9.8 Suboptimization of component 1 for various settings of the input state variable s2.
554 Dynamic Programming
get the following simplified statement:
f ∗2 (s3) = opt
x2
[R2(x2, s3) + f
∗
1 (s2)] (9.19)
Thus the number of variables to be considered has been reduced from two (x1 and x2)
to one (x2). A range of possible values of s3 must be considered and for each one, x
∗
2
must be found so as to optimize [R2 + f
∗
1 (s2)]. The results (x
∗
2 and f
∗
2 for different
s3) of this suboptimization are entered in a table as shown in Fig. 9.9.
Figure 9.9 Suboptimization of components 1 and 2 for various settings of the input state
variable s3.
9.5 Example Illustrating the Calculus Method of Solution 555
Assuming that the suboptimization sequence has been carried on to include i − 1
of the end components, the next step will be to suboptimize the i end components.
This requires the solution of
f ∗i (si+1) = opt
xi ,xi−1,...,x1
[Ri + Ri−1 + · · · + R1] (9.20)
However, again, all the information regarding the suboptimization of i − 1 end com-
ponents is known and has been entered in the table corresponding to f ∗i−1. Hence this
information can be substituted in Eq. (9.20) to obtain
f ∗i (si+1) = opt
xi
[Ri(xi, si+1) + f
∗
i−1(si)] (9.21)
Thus the dimensionality of the i-stage suboptimization has been reduced to 1, and the
equation si = ti(si+1, xi) provides the functional relation between xi and si . As before,
a range of values of si+1 are to be considered, and for each one, x
∗
i is to be found so
as to optimize [Ri + f
∗
i−1]. A table showing the values of x
∗
i and f
∗
i for each of the
values of si+1 is made as shown in Fig. 9.10.
The suboptimization procedure above is continued until stage n is reached.
At this stage only one value of sn+1 needs to be considered (for initial value
problems), and the optimization of the n components completes the solution of the
problem.
The final thing needed is to retrace the steps through the tables generated, to gather
the complete set of x∗i (i = 1, 2, . . . , n) for the system. This can be done as follows.
The nth suboptimization gives the values of x∗n and f
∗
n for the specified value of sn+1
(for initial value problem). The known design equation sn = tn(sn+1, x
∗
n) can be used
to find the input, s∗n , to the (n − 1)th stage. From the tabulated results for f
∗
n−1(sn), the
optimum values f ∗n−1 and x
∗
n−1 corresponding to s
∗
n can readily be obtained. Again the
known design equation sn−1 = tn−1(sn, x
∗
n−1) can be used to find the input, s
∗
n−1, to the
(n − 2)th stage. As before, from the tabulated results of f ∗n−2(sn−1), the optimal values
x∗n−2 and f
∗
n−2 corresponding to s
∗
n−1 can be found. This procedure is continued until
the values x∗1 and f
∗
1 corresponding to s
∗
2 are obtained. Then the optimum solution
vector of the original problem is given by (x∗1 , x
∗
2 , . . . , x
∗
n) and the optimum value of
the objective function by f ∗n .
9.5 EXAMPLE ILLUSTRATING THE CALCULUS METHOD
OF SOLUTION
Example 9.2 The four-bar truss shown in Fig. 9.11 is subjected to a vertical load of
2 × 105 lb at joint A as shown. Determine the cross-sectional areas of the members
(bars) such that the total weight of the truss is minimum and the vertical deflection
of joint A is equal to 0.5 in. Assume the unit weight as 0.01 lb/in3 and the Young’s
modulus as 20 × 106 psi.
SOLUTION Let xi denote the area of cross section of member i(i = 1, 2, 3, 4). The
lengths of members are given by l1 = l3 = 100 in., l2 = 120 in., and l4 = 60 in. The
556 Dynamic Programming
Figure 9.10 Suboptimization of components 1, 2, . . . , i for various settings of the input state
variable si+1.
weight of the truss is given by
f (x1, x2, x3, x4) = 0.01(100x1 + 120x2 + 100x3 + 60x4)
= x1 + 1.2x2 + x3 + 0.6x4 (E1)
From structural analysis [9.5], the force developed in member i due to a unit load acting
at joint A(pi), the deformation of member i (di), and the contribution of member i to
the vertical deflection of A (δi = pidi) can be determined as follows:
9.5 Example Illustrating the Calculus Method of Solution 557
Figure 9.11 Four-bar truss.
Member i pi di =
(stressi)li
E
=
Ppi li
xiE
(in.) δi = pidi (in.)
1 −1.25 −1.25/x1 1.5625/x1
2 0.75 0.9/x2 0.6750/x2
3 1.25 1.25/x3 1.5625/x3
4 −1.50 −0.9/x4 1.3500/x4
The vertical deflection of joint A is given by
dA =
4
∑
i=1
δi =
1.5625
x1
+
0.6750
x2
+
1.5625
x3
+
1.3500
x4
(E2)
Thus the optimization problem can be stated as
Minimize f (X) = x1 + 1.2x2 + x3 + 0.6x4
subject to
1.5625
x1
+
0.6750
x2
+
1.5625
x3
+
1.3500
x4
= 0.5 (E3)
x1 ≥ 0, x2 ≥ 0, x3 ≥ 0, x4 ≥ 0
Since the deflection of joint A is the sum of contributions of the various members,
we can consider the 0.5 in. deflection as a resource to be allocated to the various
activities xi and the problem can be posed as a multistage decision problem as shown
in Fig. 9.12. Let s2 be the displacement (resource) available for allocation to the first
member (stage 1), δ1 the displacement contribution due to the first member, and f
∗
1 (s2)
the minimum weight of the first member. Then
f ∗1 (s2) = min[R1 = x1] =
1.5625
s2
(E4)
such that
δ1 =
1.5625
x1
and x1 ≥ 0
558 Dynamic Programming
Figure 9.12 Example 9.2 as a four-stage decision problem.
since δ1 = s2, and
x∗1 =
1.5625
s2
(E5)
Let s3 be the displacement available for allocation to the first two members, δ2 the
displacement contribution due to the second member, and f ∗2 (s3) the minimum weight
of the first two members. Then we have, from the recurrence relationship of Eq. (9.16),
f ∗2 (s3) = min
x2≥0
[R2 + f
∗
1 (s2)] (E6)
where s2 represents the resource available after allocation to stage 2 and is given by
s2 = s3 − δ2 = s3 −
0.6750
x2
Hence from Eq. (E4), we have
f ∗1 (s2) = f
∗
1
(
s3 −
0.6750
x2
)
=
[
1.5625
/ (
s3 −
0.6750
x2
)]
(E7)
Thus Eq. (E6) becomes
f ∗2 (s3) = min
x2≥0
[
1.2x2 +
1.5625
s3 − 0.6750/x2
]
(E8)
Let
F(s3, x2) = 1.2x2 +
1.5625
s3 − 0.6750/x2
= 1.2x2 +
1.5625x2
s3x2 − 0.6750
For any specified value of s3, the minimum of F is given by
∂F
∂x2
= 1.2 −
(1.5625)(0.6750)
(s3x2 − 0.6750)2
= 0 or x∗2 =
1.6124
s3
(E9)
f ∗2 (s3) = 1.2x
∗
2 +
1.5625
s3 − 0.6750/x
∗
2
=
1.9349
s3
+
2.6820
s3
=
4.6169
s3
(E10)
9.5 Example Illustrating the Calculus Method of Solution 559
Let s4 be the displacement available for allocation to the first three members. Let
δ3 be the displacement contribution due to the third member and f
∗
3 (s4) the minimum
weight of the first three members. Then
f ∗3 (s4) = min
x3≥0
[x3 + f
∗
2 (s3)] (E11)
where s3 is the resource available after allocation to stage 3 and is given by
s3 = s4 − δ3 = s4 −
1.5625
x3
From Eq. (E10) we have
f ∗2 (s3) =
4.6169
s4 − 1.5625/x3
(E12)
and Eq. (E11) can be written as
f ∗3 (s4) = min
x3≥0
[
x3 +
4.6169x3
s4x3 − 1.5625
]
(E13)
As before, by letting
F(s4, x3) = x3 +
4.6169x3
s4x3 − 1.5625
(E14)
the minimum of F , for any specified value of s4, can be obtained as
∂F
∂x3
= 1.0 −
(4.6169)(1.5625)
(s4x3 − 1.5625)2
= 0 or x∗3 =
4.2445
s4
(E15)
f ∗3 (s4) = x
∗
3 +
4.6169x∗3
s4x
∗
3 − 1.5625
=
4.2445
s4
+
7.3151
s4
=
11.5596
s4
(E16)
Finally, let s5 denote the displacement available for allocation to the first four
members. If δ4 denotes the displacement contribution due to the fourth member, and
f ∗4 (s5) the minimum weight of the first four members, then
f ∗4 (s5) = min
x4≥0
[0.6x4 + f
∗
3 (s4)] (E17)
where the resource available after allocation to the fourth member (s4) is given by
s4 = s5 − δ4 = s5 −
1.3500
x4
(E18)
From Eqs. (E16), (E17), and (E18), we obtain
f ∗4 (s5) = min
x4≥0
[
0.6x4 +
11.5596
s5 − 1.3500/x4
]
(E19)
By setting
F(s5, x4) = 0.6x4 +
11.5596
s5 − 1.3500/x4
560 Dynamic Programming
the minimum of F(s5, x4), for any specified value of s5, is given by
∂F
∂x4
= 0.6 −
(11.5596)(1.3500)
(s5x4 − 1.3500)2
= 0 or x∗4 =
6.44
s5
(E20)
f ∗4 (s5) = 0.6x
∗
4 +
11.5596
s5 − 1.3500/x
∗
4
=
3.864
s5
+
16.492
s5
=
20.356
s5
(E21)
Since the value of s5 is specified as 0.5 in., the minimum weight of the structure can
be calculated from Eq. (E21) as
f ∗4 (s5 = 0.5) =
20.356
0.5
= 40.712 lb (E22)
Once the optimum value of the objective function is found, the optimum values of the
design variables can be found with the help of Eqs. (E20), (E15), (E9), and (E5) as
x∗4 = 12.88 in
2
s4 = s5 −
1.3500
x∗4
= 0.5 − 0.105 = 0.395 in.
x∗3 =
4.2445
s4
= 10.73 in2
s3 = s4 −
1.5625
x∗3
= 0.3950 − 0.1456 = 0.2494 in.
x∗2 =
1.6124
s3
= 6.47 in2
s2 = s3 −
0.6750
x∗2
= 0.2494 − 0.1042 = 0.1452 in.
x∗1 =
1.5625
s2
= 10.76 in2
9.6 EXAMPLE ILLUSTRATING THE TABULAR METHOD
OF SOLUTION
Example 9.3 Design the most economical reinforced cement concrete (RCC) water
tank (Fig. 9.6a) to store 100,000 liters of water. The structural system consists of a
tank, four columns each 10 m high, and a foundation to transfer all loads safely to the
ground [9.10]. The design involves the selection of the most appropriate types of tank,
columns, and foundation among the seven types of tanks, three types of columns, and
three types of foundations available. The data on the various types of tanks, columns,
and foundations are given in Tables 9.1, 9.2, and 9.3, respectively.
SOLUTION The structural system can be represented as a multistage decision pro-
cess as shown in Fig. 9.13. The decision variables x1, x2, and x3 represent the type of
9.6 Example Illustrating the Tabular Method of Solution 561
Table 9.1 Component 3 (Tank)
Type of tank
Load acting on
the tank, s4
(kgf) R3 cost ($)
Self-weight of
the component
(kgf)
s3 = s4 +
self-weight
(kgf)
(a) Cylindrical RCC tank 100,000 5,000 45,000 145,000
(b) Spherical RCC tank 100,000 8,000 30,000 130,000
(c) Rectangular RCC tank 100,000 6,000 25,000 125,000
(d) Cylindrical steel tank 100,000 9,000 15,000 115,000
(e) Spherical steel tank 100,000 15,000 5,000 105,000
(f) Rectangular steel tank 100,000 12,000 10,000 110,000
(g) Cylindrical RCC tank with
hemispherical RCC dome 100,000 10,000 15,000 115,000
Table 9.2 Component 2 (Columns)
s2 = s3 +
Type of columns s3 (kgf) R2 cost ($) Self-weight (kgf) self-weight (kgf)
(a) RCC columns 150,000 6,000 70,000 220,000
130,000 5,000 50,000 180,000
110,000 4,000 40,000 150,000
100,000 3,000 40,000 140,000
(b) Concrete columns 150,000 8,000 60,000 210,000
130,000 6,000 50,000 180,000
110,000 4,000 30,000 140,000
100,000 3,000 15,000 115,000
(c) Steel columns 150,000 15,000 30,000 180,000
130,000 10,000 20,000 150,000
110,000 9,000 15,000 125,000
100,000 8,000 10,000 110,000
foundation, columns, and the tank used in the system, respectively. Thus the vari-
able x1 can take three discrete values, each corresponding to a particular type of
foundation (among mat, concrete pile, and steel pile types). Similarly the variable
x2 is assumed to take three discrete values, each corresponding to one of the columns
(out of RCC columns, concrete columns, and steel columns). Finally, the variable x3
can take seven discrete values, each corresponding to a particular type of tank listed
in Table 9.1.
Since the input load, that is, the weight of water, is known to be 100,000 kgf, s4
is fixed and the problem can be considered as an initial value problem. We assume
that the theories of structural analysis and design in the various materials provide the
design equations
si = ti(xi , si+1)
562 Dynamic Programming
Table 9.3 Component 1 (Foundation)
s1 = s2 +
Type of foundation s2 (kgf) R1 cost ($) Self-weight (kgf) self-weight (kgf)
(a) Mat foundation 220,000 5,000 60,000 280,000
200,000 4,000 45,000 245,000
180,000 3,000 35,000 215,000
140,000 2,500 25,000 165,000
100,000 500 20,000 120,000
(b) Concrete pile foundation 220,000 3,500 55,000 275,000
200,000 3,000 40,000 240,000
180,000 2,500 30,000 210,000
140,000 1,500 20,000 160,000
100,000 1,000 15,000 115,000
(c) Steel pile foundation 220,000 3,000 10,000 230,000
200,000 2,500 9,000 209,000
180,000 2,000 8,000 188,000
140,000 2,000 6,000 146,000
100,000 1,500 5,000 105,000
Figure 9.13 Example 9.3 as a three-stage decision problem.
which yield information for the various system components as shown in Tables 9.1
to 9.3 (these values are given only for illustrative purpose).
Suboptimization of Stage 1 (Component 1)
For the suboptimization of stage 1, we isolate component 1 as shown in Fig. 9.14a
and minimize its cost R1(x1, s2) for any specified value of the input state s2 to obtain
f ∗1 (s2) as
f ∗1 (s2) = min
x1
[R1(x1, s2)]
Since five settings of the input state variable s2 are given in Table 9.3, we obtain f
∗
1
for each of these values as shown below:
9.6 Example Illustrating the Tabular Method of Solution 563
Figure 9.14 Various stages of suboptimization of Example 9.3: (a) suboptimization of com-
ponent 1; (b) suboptimization of components 1 and 2; (c) suboptimization of components 1, 2,
and 3.
564 Dynamic Programming
Specific value x∗1 (type of foundation f
∗
1 Corresponding value
of s2 (kgf) for minimum cost) ($) of s1 (kgf)
220,000 (c) 3,000 230,000
200,000 (c) 2,500 209,000
180,000 (c) 2,000 188,000
140,000 (b) 1,500 160,000
100,000 (a) 500 120,000
Suboptimization of Stages 2 and 1 (Components 2 and 1)
Here we combine components 2 and 1 as shown in Fig. 9.14b and minimize
the cost (R2 + R1) for any specified value s3 to obtain f
∗
2 (s3) as
f ∗2 (s3) = min
x2,x1
[R2(x2, s3) + R1(x1, s2)] = min
x2
[R2(x2, s3) + f
∗
1 (s2)]
Since four settings of the input state variable s3 are given in Table 9.2, we can find f
∗
2
for each of these four values. Since this number of settings for s3 is small, the values of
the output state variable s2 that result will not necessarily coincide with the values of
s2 tabulated in Table 9.3. Hence we interpolate linearly the values of s2 (if it becomes
necessary) for the purpose of present computation. However, if the computations are
done on a computer, more settings, more closely spaced, can be considered without
much difficulty. The suboptimization of stages 2 and 1 gives the following results:
Value of
the
output
Specific Value of Cost of state
value of x2 (type columns, variable x
∗
1 (Type of f
∗
1 R2 + f
∗
1
s3 (kgf) of columns) R2 ($) s2 (kgf) foundation) ($) ($)
150,000 (a) 6,000 220,000 (c) 3,000 9, 000
(b) 8,000 210,000 (c) 2,750** 10,750
(c) 15,000 180,000 (c) 2,000 17,000
130,000 (a) 5,000 180,000 (c) 2,000 7, 000
(b) 6,000 180,000 (c) 2,000 8,000
(c) 10,000 150,000 (b) 1,625** 11,625
110,000 (a) 4,000 150,000 (b) 1,625** 5,625
(b) 4,000 140,000 (b) 1,500 5, 500
(c) 9,000 125,000 (b) 1,125** 10,125
100,000 (a) 3,000 140,000 (b) 1,500 4,500
(b) 3,000 115,000 (a) 875** 3, 875
(c) 8,000 110,000 (a) 750** 8,750
Notice that the double-starred quantities indicate interpolated values and the boxed
quantities the minimum cost solution for the specified value of s3. Now the desired
9.6 Example Illustrating the Tabular Method of Solution 565
quantities (i.e., f ∗2 and x
∗
2 ) corresponding to the various discrete values of s3 can be
summarized as follows:
Specified value of
s3 (kgf)
Type of columns
corresponding to
minimum cost of
stages 2 and 1, (x∗2 )
Minimum cost of
stages 2 and 1, f ∗2
($)
Value of the
corresponding
state variable, s2
(kgf)
150,000 (a) 9,000 220,000
130,000 (a) 7,000 180,000
110,000 (b) 5,500 140,000
100,000 (b) 3,875 115,000
Suboptimization of Stages 3, 2, and 1 (Components 3, 2, and 1)
For the suboptimization of stages 3, 2, and 1, we consider all three compo-
nents together as shown in Fig. 9.14c and minimize the cost (R3 + R2 + R1) for any
specified value of s4 to obtain f
∗
3 (s4). However, since there is only one value of s4
(initial value problem) to be considered, we obtain the following results by using the
information given in Table 9.1:
f ∗3 (s4) = min
x3,x2,x1
[R3(x3, s4) + R2(x2, s3) + R1(x1, s2)]
= min
x3
[R3(x3, s4) + f
∗
2 (s3)]
Specific
value of
s4 (kgf)
Type of
tank (x3)
Cost of
tank R3
($)
Corresponding
output state, s3
(kgf)
x∗2 (type of
columns for
minimum
cost) f ∗2 ($) R3 + f
∗
2 ($)
100,000 (a) 5,000 145,000 (a) 8,500∗∗ 13,500
(b) 8,000 130,000 (a) 7,000 15,000
(c) 6,000 125,000 (a) 6,625∗∗ 12,625
(d) 9,000 115,000 (b) 5,875∗∗ 14,875
(e) 15,000 105,000 (b) 4,687 1
2
∗∗
19,687 1
2
(f) 12,000 110,000 (b) 5,500 17,500
(g) 10,000 115,000 (b) 5,875∗∗ 15,875
Here also the double-starred quantities indicate the interpolated values and the boxed
quantity the minimum cost solution. From the results above, the minimum cost solution
is given by
s4 = 100,000 kgf
x∗3 = type (c) tank
f ∗3 (s4 = 100,000) = $12,625
s3 = 125, 000 kgf
566 Dynamic Programming
Now, we retrace the steps to collect the optimum values of x∗3 , x
∗
2 , and x
∗
1 and obtain
x∗3 = type (c) tank, s3 = 125,000 kgf
x∗2 = type (a) columns, s2 = 170,000 kgf
x∗1 = type (c) foundation, s1 = 181,000 kgf
and the total minimum cost of the water tank is $12,625. Thus the minimum cost water
tank consists of a rectangular RCC tank, RCC columns, and a steel pile foundation.
9.7 CONVERSION OF A FINAL VALUE PROBLEM INTO
AN INITIAL VALUE PROBLEM
In previous sections the dynamic programming technique has been described with
reference to an initial value problem. If the problem is a final value problem as shown
in Fig. 9.15a, it can be solved by converting it into an equivalent initial value problem.
Let the stage transformation (design) equation be given by
si = ti(si+1, xi), i = 1, 2, . . . , n (9.22)
Assuming that the inverse relations exist, we can write Eqs. (9.22) as
si+1 = t i(si, xi), i = 1, 2, . . . , n (9.23)
where the input state to stage i is expressed as a function of its output state and the
decision variable. It can be noticed that the roles of input and output state variables
are interchanged in Eqs. (9.22) and (9.23). The procedure of obtaining Eq. (9.23) from
Eq. (9.22) is called state inversion . If the return (objective) function of stage i is
originally expressed as
Ri = ri(si+1, xi), i = 1, 2, . . . , n (9.24)
Eq. (9.23) can be used to express it in terms of the output state and the decision
variable as
Ri = ri[t i(si, xi), xi] = r i(si , xi), i = 1, 2, . . . , n (9.25)
The optimization problem can now be stated as follows:
Find x1, x2, . . . , xn so that
f (x1, x2, . . . , xn) =
n
∑
i=1
Ri =
n
∑
i=1
r i(si , xi) (9.26)
will be optimum where the si are related by Eq. (9.23).
The use of Eq. (9.23) amounts to reversing the direction of the flow of information
through the state variables. Thus the optimization process can be started at stage n and
stages n − 1, n − 2, . . . , 1 can be reached in a sequential manner. Since s1 is specified
(fixed) in the original problem, the problem stated in Eq. (9.26) will be equivalent to
9.7 Conversion of a Final Value Problem into an Initial Value Problem 567
Figure 9.15 Conversion of a final value problem to an initial value problem: (a) final value
problem; (b) initial value problem.
an initial value problem as shown in Fig. 9.15b. This initial value problem is identical
to the one considered in Fig. 9.3 except for the stage numbers. If the stage numbers
1, 2, . . . , n are reversed to n, n − 1, . . . , 1, Fig. 9.15b will become identical to Fig. 9.3.
Once this is done, the solution technique described earlier can be applied for solving
the final value problem shown in Fig. 9.15a.
Example 9.4 A small machine tool manufacturing company entered into a contract
to supply 80 drilling machines at the end of the first month and 120 at the end of the
second month. The unit cost of manufacturing a drilling machine in any month is given
by $(50x + 0.2x2), where x denotes the number of drilling machines manufactured in
that month. If the company manufactures more units than needed in the first month,
there is an inventory carrying cost of $8 for each unit carried to the next month. Find
the number of drilling machines to be manufactured in each month to minimize the
total cost. Assume that the company has enough facilities to manufacture up to 200
drilling machines per month and that there is no initial inventory. Solve the problem
as a final value problem.
SOLUTION The problem can be stated as follows:
Minimize f (x1, x2) = (50x1 + 0.2x
2
1 ) + (50x2 + 0.2x
2
2) + 8(x1 − 80)
subject to
x1 ≥ 80
x1 + x2 = 200
x1 ≥ 0, x2 ≥ 0
568 Dynamic Programming
where x1 and x2 indicate the number of drilling machines manufactured in the first
month and the second month, respectively. To solve this problem as a final value
problem, we start from the second month and go backward. If I2 is the inventory at
the beginning of the second month, the optimum number of drilling machines to be
manufactured in the second month is given by
x∗2 = 120 − I2 (E1)
and the cost incurred in the second month by
R2(x
∗
2 , I2) = 8I2 + 50x
∗
2 + 0.2x
∗2
2
By using Eq. (E1), R2 can be expressed as
R2(I2) = 8I2 + 50(120 − I2) + 0.2(120 − I2)
2 = 0.2I 22 − 90I2 + 8880 (E2)
Since the inventory at the beginning of the first month is zero, the cost involved in the
first month is given by
R1(x1) = 50x1 + 0.2x
2
1
Thus the total cost involved is given by
f2(I2, x1) = (50x1 + 0.2x
2
1) + (0.2I
2
2 − 90I2 + 8880) (E3)
But the inventory at the beginning of the second month is related to x1 as
I2 = x1 − 80 (E4)
Equations (E3) and (E4) lead to
f = f2(I2) = (50x1 + 0.2x
2
1 ) + 0.2(x1 − 80)
2 − 90(x1 − 80) + 8880
= 0.4x21 − 72x1 + 17,360 (E5)
Since f is a function of x1 only, the optimum value of x1 can be obtained as
df
dx1
= 0.8x1 − 72 = 0 or x
∗
1 = 90
As d2f (x∗1 )/dx
2
1 = 0.8 > 0, the value of x
∗
1 corresponds to the minimum of f . Thus
the optimum solution is given by
fmin = f (x
∗
1 ) = $14,120
x∗1 = 90 and x
∗
2 = 110
9.8 Linear Programming as a Case of Dynamic Programming 569
9.8 LINEAR PROGRAMMING AS A CASE OF DYNAMIC
PROGRAMMING
A linear programming problem with n decision variables and m constraints can
be considered as an n-stage dynamic programming problem with m state vari-
ables. In fact, a linear programming problem can be formulated as a dynamic
programming problem. To illustrate the conversion of a linear programming problem
into a dynamic programming problem, consider the following linear programming
problem:
Maximize f (x1, x2, . . . , xn) =
n
∑
j=1
cjxj
subject to
n
∑
j=1
aijxj ≤ bi, i = 1, 2, . . . ,m
xj ≥ 0, j = 1, 2, . . . , n
(9.27)
This problem can be considered as an n-stage decision problem where the value of
the decision variable xj must be determined at stage j . The right-hand sides of the
constraints, bi , i = 1, 2, . . . , m, can be treated as m types of resources to be allocated
among different kinds of activities xj . For example, b1 may represent the available
machines, b2 the available time, and so on, in a workshop. The variable x1 may denote
the number of castings produced, x2 the number of forgings produced, x3 the number
of machined components produced, and so on, in the workshop. The constant cj may
represent the profit per unit of xj . The coefficients aij represent the amount of ith
resource bi needed for 1 unit of j th activity xj (e.g., the amount of material required
to produce one casting). Hence when the value of the decision variable xj at the j th
stage is determined, a1jxj units of resource 1, a2jxj units of resource 2, . . . , amjxj
units of resource m will be allocated to j th activity if sufficient unused resources exist.
Thus the amounts of the available resources must be determined before allocating
them to any particular activity. For example, when the value of the first activity x1 is
determined at stage 1, there must be sufficient amounts of resources bi for allocation
to activity 1. The resources remaining after allocation to activity 1 must be determined
before the value of x2 is found at stage 2, and so on. In other words, the state of the
system (i.e., the amounts of resources remaining for allocation) must be known before
making a decision (about allocation) at any stage of the n-stage system. In this problem
there are m state parameters constituting the state vector.
By denoting the optimal value of the composite objective function over n stages
as f ∗n , we can state the problem as
Find
f ∗n = f
∗
n (b1, b2, . . . , bm) = max
x1,x2,...,xn


n
∑
j=1
cjxj

 (9.28)
570 Dynamic Programming
such that
n
∑
j=1
aijxj ≤ bi, i = 1, 2, . . . , m (9.29)
xj ≥ 0, j = 1, 2, . . . , n (9.30)
The recurrence relationship (9.16), when applied to this problem yields
f ∗1 (β1, β2, . . . , βm) = max
0≤xi≤β
[cixi + f
∗
i−1(β1 − a1ixi,
β2 − a2ixi, . . . , βm − amixi)], i = 2, 3, . . . , n (9.31)
where β1, β2, . . . , βm are the resources available for allocation at stage i; a1ixi, . . . ,
amixi are the resources allocated to the activity xi , β1 − a1ixi, β2 − a2ixi, . . . , βm −
amixi are the resources available for allocation to the activity i − 1, and β indicates
the maximum value that xi can take without violating any of the constraints stated in
Eqs. (9.29). The value of β is given by
β = min
(
β1
a1i
,
β2
a2i
, . . . ,
βm
ami
)
(9.32)
since any value larger than β would violate at least one constraint. Thus at the ith
stage, the optimal values x∗i and f
∗
i can be determined as functions of β1, β2, . . . , βm.
Finally, at the nth stage, since the values of β1, β2, . . ., βm are known to be
b1, b2, . . . , bm, respectively, we can determine x
∗
n and f
∗
n . Once x
∗
n is known, the
remaining values, x∗n−1, x
∗
n−2, . . . , x
∗
1 can be determined by retracing the suboptimiza-
tion steps.
Example 9.5†
Maximize f (x1, x2) = 50x1 + 100x2
subject to
10x1 + 5x2 ≤ 2500
4x1 + 10x2 ≤ 2000
x1 + 1.5x2 ≤ 450
x1 ≥ 0, x2 ≥ 0
SOLUTION Since n = 2 and m = 3, this problem can be considered as a two-stage
dynamic programming problem with three state parameters. The first-stage problem is
to find the maximum value of f1:
max f1(β1, β2, β3, x1) = max
0≤x1≤β
(50x1)
†This problem is the same as the one stated in Example 3.2.
9.8 Linear Programming as a Case of Dynamic Programming 571
where β1, β2, and β3 are the resources available for allocation at stage 1, and x1 is a
nonnegative value that satisfies the side constraints 10x1 ≤ β1, 4x1 ≤ β2, and x1 ≤ β3.
Here β1 = 2500 − 5x2, β2 = 2000 − 10x2, and β3 = 450 − 1.5x2, and hence the max-
imum value β that x1 can assume is given by
β = x∗1 = min
[
2500 − 5x2
10
,
2000 − 10x2
4
, 450 − 1.5x2
]
(E1)
Thus
f ∗1
(
2500 − 5x2
10
,
2000 − 10x2
4
, 450 − 1.5x2
)
= 50x∗1
= 50 min
(
2500 − 5x2
10
,
2000 − 10x2
4
, 450 − 1.5x2
)
The second-stage problem is to find the maximum value of f2:
max f2(β1, β2, β3) = max
0≤x2≤β
[
100x2 + f
∗
1
(
2500 − 5x2
10
,
2000 − 10x2
4
, 450 − 1.5x2
)]
(E2)
where β1, β2, and β3 are the resources available for allocation at stage 2, which are
equal to 2500, 2000, and 450, respectively. The maximum value that x2 can assume
without violating any constraint is given by
β = min
(
2500
5
,
2000
10
,
450
1.5
)
= 200
Thus the recurrence relation, Eq. (E2), can be restated as
max f2(2500, 2000, 450)
= max
0 ≤ x2 ≤ 200
{
100x2 + 50 min
(
2500 − 5x2
10
,
2000 − 10x2
4
, 450 − 1.5x2
)}
Since
min
(
2500 − 5x2
10
,
2000 − 10x2
4
, 450 − 1.5x2
)
=







2500 − 5x2
10
if 0 ≤ x2 ≤ 125
2000 − 10x2
4
if 125 ≤ x2 ≤ 200
572 Dynamic Programming
we obtain
max
0 ≤ x2 ≤ 200
[
100x2 + 50 min
(
2500 − 5x2
10
,
2000 − 10x2
4
, 450 − 1.5x2
)]
= max









100x2 + 50
(
2500 − 5x2
10
)
if 0 ≤ x2 ≤ 125
100x2 + 50
(
2000 − 10x2
4
)
if 125 ≤ x2 ≤ 200
= max



75x2 + 12,500 if 0 ≤ x2 ≤ 125
25,000 − 25x2 if 125 ≤ x2 ≤ 200
Now,
max(75x2 + 12,500) = 21,875 at x2 = 125
max(25,000 − 25x2) = 21,875 at x2 = 125
Hence
f ∗2 (2500, 2000, 450) = 21,875 at x
∗
2 = 125.0
From Eq. (E1) we have
x∗1 = min
(
2500 − 5x∗2
10
,
2000 − 10x∗2
4
, 450 − 1.5x∗2
)
= min(187.5,187.5,262.5) = 187.5
Thus the optimum solution of the problem is given by x∗1 = 187.5, x
∗
2 = 125.0, and
fmax = 21,875.0, which can be seen to be identical with the one obtained earlier.
Problem of Dimensionality in Dynamic Programming. The application of dynamic
programming for the solution of a linear programming problem has a serious limitation
due to the dimensionality restriction. The number of calculations needed will increase
very rapidly as the number of decision variables and state parameters increases. As an
example, consider a linear programming problem with 100 constraints. This means that
there are 100 state variables. By the procedure outlined in Section 9.4, if a table of f ∗i
is to be constructed in which 100 discrete values (settings) are given to each parameter,
the table contains 100100 entries. This is a gigantic number, and if the calculations are
to be performed on a high-speed digital computer, it would require 10096 seconds or
about 10092 years† merely to compute one table of f ∗i . Like this, 100 tables have
to be prepared, one for each decision variable. Thus it is totally out of the question
to solve a general linear programming problem of any reasonable size‡ by dynamic
programming.
†The computer is assumed to be capable of computing 108 values of f ∗i per second.
‡As stated in Section 4.7, LP problems with 150,000 variables and 12,000 constraints have been solved in
a matter of a few hours using some special techniques.
9.9 Continuous Dynamic Programming 573
These comments are equally applicable for all dynamic programming problems
involving many state variables, since the computations have to be performed for dif-
ferent possible values of each of the state variables. Thus this problem causes not only
an increase in the computational time, but also requires a large computer memory. This
problem is known as the problem of dimensionality or the curse of dimensionality , as
termed by Bellman. This presents a serious obstacle in solving medium- and large-size
dynamic programming problems.
9.9 CONTINUOUS DYNAMIC PROGRAMMING
If the number of stages in a multistage decision problem tends to infinity, the problem
becomes an infinite stage or continuous problem and dynamic programming can still
be used to solve the problem. According to this notion, the trajectory optimization
problems, defined in Section 1.5, can also be considered as infinite-stage or continuous
problems .
An infinite-stage or continuous decision problem may arise in several practical
problems. For example, consider the problem of a missile hitting a target in a specified
(finite) time interval. Theoretically, the target has to be observed and commands to the
missile for changing its direction and speed have to be given continuously. Thus an
infinite number of decisions have to be made in a finite time interval. Since a stage has
been defined as a point where decisions are made, this problem will be an infinite-stage
or continuous problem. Another example where an infinite-stage or continuous decision
problem arises is in planning problems. Since large industries are assumed to function
for an indefinite amount of time, they have to do their planning on this basis. They
make their decisions at discrete points in time by anticipating a maximum profit in the
long run (essentially over an infinite period of time). In this section we consider the
application of continuous decision problems.
We have seen that the objective function in dynamic programming formulation
is given by the sum of individual stage returns. If the number of stages tends
to infinity, the objective function will be given by the sum of infinite terms,
which amounts to having the objective function in the form of an integral. The
following examples illustrate the formulation of continuous dynamic programming
problems.
Example 9.6 Consider a manufacturing firm that produces a certain product. The rate
of demand of this product (p) is known to be p = p[x(t), t], where t is the time of
the year and x(t) is the amount of money spent on advertisement at time t . Assume
that the rate of production is exactly equal to the rate of demand. The production cost,
c, is known to be a function of the amount of production (p) and the production rate
(dp/dt) as c = c(p, dp/dt). The problem is to find the advertisement strategy, x(t),
so as to maximize the profit between t1 and t2. The unit selling price (s) of the product
is known to be a function of the amount of production as s = s(p) = a + b/p, where
a and b are known positive constants.
SOLUTION Since the profit is given by the difference between the income from sales
and the expenditure incurred for production and advertisement, the total profit over the
574 Dynamic Programming
period t1 to t2 is given by
f =
∫ t2
t1
[
p
(
a +
b
p
)
− c
(
p,
dp
dt
, t
)
− x(t)
]
dt (E1)
where p = p{x(t), t}. Thus the optimization problem can be stated as follows: Find
x(t), t1 ≤ t ≤ t2, which maximizes the total profit, f given by Eq. (E1).
Example 9.7 Consider the problem of determining the optimal temperature distribu-
tion in a plug-flow tubular reactor [9.1]. Let the reactions carried in this type of reactor
be shown as follows:
X1
k1
⇄
k2
X2
k3
−−−→X3
where X1 is the reactant, X2 the desired product, and X3 the undesired product, and
k1, k2, and k3 are called rate constants. Let x1 and x2 denote the concentrations of the
products X1 and X2, respectively. The equations governing the rate of change of the
concentrations can be expressed as
dx1
dy
+ k1x1 = k2x2 (E1)
dx2
dy
+ k2x2 + k3x2 = k1x1 (E2)
with the initial conditions x1(y = 0) = c1 and x2(y = 0) = c2, where y is the normal-
ized reactor length such that 0 ≤ y ≤ 1. In general, the rate constants depend on the
temperature (t) and are given by
ki = aie
−(bi/t), i = 1, 2, 3 (E3)
where ai and bi are constants.
If the objective is to determine the temperature distribution t (y), 0 ≤ y ≤ 1, to
maximize the yield of the product X2, the optimization problem can be stated as
follows:
Find t (y), 0 ≤ y ≤ 1, which maximizes
x2(1) − x2(0) =
∫ 1
y=0
dx2 =
∫ 1
0
(k1x1 − k2x2 − k3x2) dy
where x1(y) and x2(y) have to satisfy Eqs. (E1) and (E2). Here it is assumed that the
desired temperature can be produced by some external heating device.
The classical method of approach to continuous decision problems is by the calcu-
lus of variations.† However, the analytical solutions, using calculus of variations, cannot
be obtained except for very simple problems. The dynamic programming approach, on
the other hand, provides a very efficient numerical approximation procedure for solving
continuous decision problems. To illustrate the application of dynamic programming
†See Section 12.2 for additional examples of continuous decision problems and the solution techniques using
calculus of variations.
9.9 Continuous Dynamic Programming 575
to the solution of continuous decision problems, consider the following simple (uncon-
strained) problem. Find the function y(x) that minimizes the integral
f =
∫ b
x=a
R
(
dy
dx
, y, x
)
dx (9.33)
subject to the known end conditions y(x = a) = α, and y(x = b) = β. We shall see
how dynamic programming can be used to determine y(x) numerically. This approach
will not yield an analytical expression for y(x) but yields the value of y(x) at a finite
number of points in the interval a ≤ x ≤ b. To start with, the interval (a, b) is divided
into n segments each of length x (all the segments are assumed to be of equal length
only for convenience). The grid points defining the various segments are given by
x1 = a, x2 = a + x, . . . ,
xi = a + (i − 1)x, . . . , xn+1 = a + nx = b
If x is small, the derivative dy/dx at xi can be approximated by a forward difference
formula as
dy
dx
(xi) ≃
yi+1 − yi
x
(9.34)
where yi = y(xi), i = 1, 2, . . . , n + 1. The integral in Eq. (9.33) can be approxi-
mated as
f ≃
n
∑
i=1
R
[
dy
dx
(xi), y(xi), xi
]
x (9.35)
Thus the problem can be restated as
Find y(x2), y(x3), . . ., y(xn), which minimizes
f ≃ x
n
∑
i=1
R
{
yi+1 − yi
x
, yi, xi
}
(9.36)
subject to the known conditions y1 = α and yn+1 = β.
This problem can be solved as a final value problem. Let
f ∗i (θ) = min
yi+1,yi+2,...,yn
{
n
∑
k=1
R
(
yk+1 − yk
x
, yk, xk
)
x
}
(9.37)
where θ is a parameter representing the various values taken by yi . Then f
∗
i (θ) can
also be written as
f ∗i (θ) = min
yi+1
[
R
{
yi+1 − θ
x
, θ, xi
}
x + f ∗i+1(yi+1)
]
(9.38)
This relation is valid for i = 1, 2, . . . , n − 1, and
f ∗n (θ) = R
(
β − θ
x
, θ, xn
)
x (9.39)
Finally the desired minimum value is given by f ∗0 (θ = α).
576 Dynamic Programming
In Eqs. (9.37) to (9.39), θ or yi is a continuous variable. However, for simplicity,
we treat θ or yi as a discrete variable. Hence for each value of i, we find a set of
discrete values that θ or yi can assume and find the value of f
∗
i (θ) for each discrete
value of θ or yi . Thus f
∗
i (θ) will be tabulated for only those discrete values that θ can
take. At the final stage, we find the values of f ∗0 (α) and y
∗
1 . Once y
∗
1 is known, the
optimal values of y2, y3, . . . , yn can easily be found without any difficulty, as outlined
in the previous sections.
It can be seen that the solution of a continuous decision problem by dynamic
programming involves the determination of a whole family of extremal trajectories as
we move from b toward a. In the last step we find the particular extremal trajectory that
passes through both points (a, α) and (b, β). This process is illustrated in Fig. 9.16. In
this figure, f ∗i (θ) is found by knowing which of the extremal trajectories that terminate
at xi+1 pass through the point (xi , θ ). If this procedure is followed, the solution of a
continuous decision problem poses no additional difficulties. Although the simplest type
of continuous decision problem is considered in this section, the same procedure can be
adopted to solve any general continuous decision problem involving the determination
of several functions, y1(x), y2(x), . . . , yN (x) subject to m constraints (m < N ) in the
form of differential equations [9.3].
9.10 ADDITIONAL APPLICATIONS
Dynamic programming has been applied to solve several types of engineering problems.
Some representative applications are given in this section.
9.10.1 Design of Continuous Beams
Consider a continuous beam that rests on n rigid supports and carries a set of pre-
scribed loads P1, P2, . . . , Pn as shown in Fig. 9.17 [9.11]. The locations of the supports
are assumed to be known and the simple plastic theory of beams is assumed to
Figure 9.16 Solution of a continuous dynamic programming problem.
9.10 Additional Applications 577
Figure 9.17 Continuous beam on rigid supports.
be applicable. Accordingly, the complete bending moment distribution can be deter-
mined once the reactant support moments m1, m2, . . . , mn are known. Once the support
moments are known (chosen), the plastic limit moment necessary for each span can be
determined and the span can be designed. The bending moment at the center of the ith
span is given by −Pi li /4 and the largest bending moment in the ith span, Mi , can be
computed as
Mi = max
{
|mi−1|, |mi |,
∣
∣
∣
∣
mi−1 + mi
2
−
Pi li
4
∣
∣
∣
∣
}
, i = 1, 2, . . . , n (9.40)
If the beam is uniform in each span, the limit moment for the ith span should be greater
than or equal to Mi . The cross section of the beam should be selected so that it has
the required limit moment. Thus the cost of the beam depends on the limit moment it
needs to carry. The optimization problem becomes
Find X = {m1, m2, . . . , mn}
T which minimizes
n
∑
i=1
Ri(X)
while satisfying the constraints mi ≥ Mi , i = 1, 2, . . . , n, where Ri denotes the cost of
the beam in the ith span. This problem has a serial structure and hence can be solved
using dynamic programming.
9.10.2 Optimal Layout (Geometry) of a Truss
Consider the planar, multibay, pin-jointed cantilever truss shown in Fig. 9.18 [9.11,
9.12, 9.22]. The configuration of the truss is defined by the x and y coordinates of
the nodes. By assuming the lengths of the bays to be known (assumed to be unity in
Fig. 9.18) and the truss to be symmetric about the x axis, the coordinates y1, y2, . . . , yn
define the layout (geometry) of the truss. The truss is subjected to a load (assumed to
be unity in Fig. 9.18) at the left end. The truss is statically determinate and hence the
forces in the bars belonging to bay i depend only on yi−1 and yi and not on other
coordinates y1, y2, . . . , yi−2, yi+1, . . . , yn. Once the length of the bar and the force
developed in it are known, its cross-sectional area can be determined. This, in turn,
dictates the weight/cost of the bar. The problem of optimal layout of the truss can be
formulated and solved as a dynamic programming problem.
578 Dynamic Programming
Figure 9.18 Multibay cantilever truss.
For specificness, consider a three-bay truss for which the following relationships
are valid (see Fig. 9.18):
yi+1 = yi + di, i = 1, 2, 3 (9.41)
Since the value of y1 is fixed, the problem can be treated as an initial value problem.
If the y coordinate of each node is limited to a finite number of alternatives that can
take one of the four values 0.25, 0.5, 0.75, 1 (arbitrary units are used), there will be
64 possible designs, as shown in Fig. 9.19. If the cost of each bay is denoted by Ri ,
the resulting multistage decision problem can be represented as shown in Fig. 9.5a.
Figure 9.19 Possible designs of the cantilever truss.
9.10 Additional Applications 579
9.10.3 Optimal Design of a Gear Train
Consider the gear train shown in Fig. 9.20, in which the gear pairs are numbered from
1 to n. The pitch diameters (or the number of teeth) of the gears are assumed to be
known and the face widths of the gear pairs are treated as design variables [9.19, 9.20].
The minimization of the total weight of the gear train is considered as the objective.
When the gear train transmits power at any particular speed, bending and surface wear
stresses will be developed in the gears. These stresses should not exceed the respective
permissible values for a safe design. The optimization problem can be stated as
Find X = {x1, x2, . . . , xn}
T which minimizes
n
∑
i=1
Ri(X) (9.42)
subject to
σbi(X) ≤ σb max, σwi(X) ≤ σw max, i = 1, 2, . . . , n
where xi is the face width of gear pair i, Ri the weight of gear pair i, σbi (σwi) the
bending (surface wear) stress induced in gear pair i, and σb max (σw max) the maxi-
mum permissible bending (surface wear) stress. This problem can be considered as a
multistage decision problem and can be solved using dynamic programming.
9.10.4 Design of a Minimum-Cost Drainage System
Underground drainage systems for stormwater or foul waste can be designed efficiently
for minimum construction cost by dynamic programming [9.14]. Typically, a drainage
system forms a treelike network in plan as shown in Fig. 9.21. The network slopes
downward toward the outfall, using gravity to convey the wastewater to the outfall.
Manholes are provided for cleaning and maintenance purposes at all pipe junctions.
A representative three-element pipe segment is shown in Fig. 9.22. The design of an
Figure 9.20 Gear train.
580 Dynamic Programming
Figure 9.21 Typical drainage network.
1 2 3
R1 R2 R3
h0
h1 h2
h3
D1 D2 D3
h0
h1
h2
D3
Element 3
D2
Element 2
D1
Element 1
h3
1 2 30
l1 l2 l3
(a)
(b)
Figure 9.22 Representation of a three-element pipe segment [9.14].
References and Bibliography 581
element consists of selecting values for the diameter of the pipe, the slope of the
pipe, and the mean depth of the pipe (Di , hi−1, and hi). The construction cost of an
element, Ri , includes cost of the pipe, cost of the upstream manhole, and earthwork
related to excavation, backfilling, and compaction. Some of the constraints can be stated
as follows:
1. The pipe must be able to discharge the specified flow.
2. The flow velocity must be sufficiently large.
3. The pipe slope must be greater than a specified minimum value.
4. The depth of the pipe must be sufficient to prevent damage from surface
activities.
The optimum design problem can be formulated and solved as a dynamic programming
problem.
REFERENCES AND BIBLIOGRAPHY
9.1 R. S. Schechter, The Variational Method in Engineering , McGraw-Hill, New York,
1967.
9.2 R. E. Bellman, Dynamic Programming , Princeton University Press, Princeton, NJ,
1957.
9.3 G. Hadley, Nonlinear and Dynamic Programming , Addison-Wesley, Reading, MA, 1964.
9.4 L. S. Lasdon, Optimization Theory for Large Systems , Macmillan, New York, 1970.
9.5 B. G. Neal, Structural Theorems and Their Applications , Pergamon Press, Oxford, UK,
1964.
9.6 R. E. Bellman and S. E. Dreyfus, Applied Dynamic Programming , Princeton University
Press, Princeton, NJ, 1962.
9.7 G. L. Nemhauser, Introduction to Dynamic Programming , Wiley, New York, 1966.
9.8 S. Vajda, Mathematical Programming , Addison-Wesley, Reading, MA, 1961.
9.9 O.L.R. Jacobs, An Introduction to Dynamic Programming , Chapman & Hall, London,
1967.
9.10 R. J. Aguilar, Systems Analysis and Design in Engineering, Architecture, Construction
and Planning , Prentice-Hall, Englewood Cliffs, NJ, 1973.
9.11 A. C. Palmer, Optimal structure design by dynamic programming, ASCE Journal of the
Structural Division , Vol. 94, No. ST8, pp. 1887–1906, 1968.
9.12 D. J. Sheppard and A. C. Palmer, Optimal design of transmission towers by dynamic
programming, Computers and Structures , Vol. 2, pp. 455–468, 1972.
9.13 J. A. S. Ferreira and R. V. V. Vidal, Optimization of a pump–pipe system by dynamic
programming, Engineering Optimization , Vol. 7, pp. 241–251, 1984.
9.14 G. A. Walters and A. B. Templeman, Non-optimal dynamic programming algorithms
in the design of minimum cost drainage systems, Engineering Optimization , Vol. 4,
pp. 139–148, 1979.
9.15 J. S. Gero, P. J. Sheehan, and J. M. Becker, Building design using feedforward nonserial
dynamic programming, Engineering Optimization , Vol. 3, pp. 183–192, 1978.
9.16 J. S. Gero and A. D. Radford, A dynamic programming approach to the optimum lighting
problem, Engineering Optimization , Vol. 3, pp. 71–82, 1978.
582 Dynamic Programming
9.17 W. S. Duff, Minimum cost solar thermal electric power systems: a dynamic programming
based approach, Engineering Optimization , Vol. 2, pp. 83–95, 1976.
9.18 M. J. Harley and T. R. E. Chidley, Deterministic dynamic programming for long term
reservoir operating policies, Engineering Optimization , Vol. 3, pp. 63–70, 1978.
9.19 S. G. Dhande, Reliability Based Design of Gear Trains: A Dynamic Programming
Approach , Design Technology Transfer, ASME, New York, pp. 413–422, 1974.
9.20 S. S. Rao and G. Das, Reliability based optimum design of gear trains, ASME Journal
of Mechanisms, Transmissions, and Automation in Design , Vol. 106, pp. 17–22, 1984.
9.21 A. C. Palmer and D. J. Sheppard, Optimizing the shape of pin-jointed structures,
Proceedings of the Institution of Civil Engineers , Vol. 47, pp. 363–376, 1970.
9.22 U. Kirsch, Optimum Structural Design: Concepts, Methods, and Applications ,
McGraw-Hill, New York, 1981.
9.23 A. Borkowski and S. Jendo, Structural Optimization , Vol. 2—Mathematical Program-
ming , M. Save and W. Prager (eds.), Plenum Press, New York, 1990.
9.24 L. Cooper and M. W. Cooper, Introduction to Dynamic Programming , Pergamon Press,
Oxford, UK, 1981.
9.25 R. E. Larson and J. L. Casti, Principles of Dynamic Programming, Part I—Basic Analytic
and Computational Methods , Marcel Dekker, New York, 1978.
9.26 D. K. Smith, Dynamic Programming: A Practical Introduction , Ellis Horwood, Chich-
ester, UK, 1991.
9.27 W. F. Stoecker, Design of Thermal Systems , 3rd ed., McGraw-Hill, New York, 1989.
REVIEW QUESTIONS
9.1 What is a multistage decision problem?
9.2 What is the curse of dimensionality?
9.3 State two engineering examples of serial systems that can be solved by dynamic
programming.
9.4 What is a return function?
9.5 What is the difference between an initial value problem and a final value problem?
9.6 How many state variables are to be considered if an LP problem with n variables and m
constraints is to be solved as a dynamic programming problem?
9.7 How can you solve a trajectory optimization problem using dynamic programming?
9.8 Why are the components numbered in reverse order in dynamic programming?
9.9 Define the following terms:
(a) Principle of optimality
(b) Boundary value problem
(c) Monotonic function
(d) Separable function
9.10 Answer true or false:
(a) Dynamic programming can be used to solve nonconvex problems.
(b) Dynamic programming works as a decomposition technique.
Problems 583
(c) The objective function, f = (R1 + R2)R3, is separable.
(d) A nonserial system can always be converted to an equivalent serial system by
regrouping the components.
(e) Both the input and the output variables are specified in a boundary value problem.
(f) The state transformation equations are same as the design equations.
(g) The principle of optimality and the concept of suboptimization are same.
(h) A final value problem can always be converted into an initial value problem.
PROBLEMS
9.1 Four types of machine tools are to be installed (purchased) in a production shop. The
costs of the various machine tools and the number of jobs that can be performed on each
are given below.
Machine tool type
Cost of machine
tool ($)
Number of jobs that can be
performed
1 3500 9
2 2500 4
3 2000 3
4 1000 2
If the total amount available is $10,000, determine the number of machine tools of various
types to be purchased to maximize the number of jobs performed. Note: The number of
machine tools purchased must be integers.
9.2 The routes of an airline, which connects 16 cities (A, B, . . . , P ), are shown in Fig. 9.23.
Journey from one city to another is possible only along the lines (routes) shown, with
the associated costs indicated on the path segments. If a person wants to travel from city
A to city P with minimum cost, without any backtracking, determine the optimal path
(route) using dynamic programming.
9.3 A system consists of three subsystems in series, with each subsystem consisting of several
components in parallel, as shown in Fig. 9.24. The weights and reliabilities of the various
components are given below:
Subsystem, i
Weight of each component,
wi (lb)
Reliability of each
component, ri
1 4 0.96
2 2 0.92
3 6 0.98
The reliability of subsystem i is given by Ri = 1 − (1 − ri)
ni , i = 1, 2, 3, where ni is the
number of components connected in parallel in subsystem i, and the overall reliability of
the system is given by R0 = R1R2R3. It was decided to use at least one and not more
than three components in any subsystem. The system is to be transported into space by
a space shuttle. If the total payload is restricted to 20 lb, find the number of components
to be used in the three subsystems to maximize the overall reliability of the system.
584 Dynamic Programming
Figure 9.23 Possible paths from A to P .
Figure 9.24 Three subsystems connected in series.
9.4 The altitude of an airplane flying between two cities A and F , separated by a distance of
2000 miles, can be changed at points B, C, D, and E (Fig. 9.25). The fuel cost involved
in changing from one altitude to another between any two consecutive points is given in
the following table. Determine the altitudes of the airplane at the intermediate points for
minimum fuel cost.
Problems 585
Figure 9.25 Altitudes of the airplane in Example 9.4.
To altitude (ft):
From altitude (ft): 0 8,000 16,000 24,000 32,000 40,000
0 — 4000 4800 5520 6160 6720
8,000 800 1600 2680 4000 4720 6080
16,000 320 480 800 2240 3120 4640
24,000 0 160 320 560 1600 3040
32,000 0 0 80 240 480 1600
40,000 0 0 0 0 160 240
9.5 Determine the path (route) corresponding to minimum cost in Problem 9.2 if a person
wants to travel from city D to city M .
9.6 Each of the n lathes available in a machine shop can be used to produce two types of
parts. If z lathes are used to produce the first part, the expected profit is 3z and if z
of them are used to produce the second part, the expected profit is 2.5z. The lathes are
subject to attrition so that after completing the first part, only z/3 out of z remain available
for further work. Similarly, after completing the second part, only 2z/3 out of z remain
available for further work. The process is repeated with the remaining lathes for two more
stages. Find the number of lathes to be allocated to each part at each stage to maximize the
total expected profit. Assume that any nonnegative real number of lathes can be assigned
at each stage.
9.7 A minimum-cost pipeline is to be laid between points (towns) A and E. The pipeline is
required to pass through one node out of B1, B2, and B3, one out of C1, C2, and C3,
and one out of D1, D2, and D3 (see Fig. 9.26). The costs associated with the various
segments of the pipeline are given below:
For the segment starting at A For the segment ending at E
A–B1 10 D1 –E 9
A–B2 15 D2 –E 6
A–B3 12 D3 –E 12
586 Dynamic Programming
Figure 9.26 Pipe network.
For the segments Bi to Cj and Ci to Dj
To node j
From node i 1 2 3
1 8 12 19
2 9 11 13
3 7 15 14
Find the solution using dynamic programming.
9.8 Consider the problem of controlling a chemical reactor. The desired concentration of
material leaving the reactor is 0.8 and the initial concentration is 0.2. The concentration
at any time t , x(t), is given by
dx
dt
=
1 − x
1 + x
u(t)
where u(t) is a design variable (control function).
Find u(t) which minimizes
f =
∫ T
0
{[x(t) − 0.8]2 + u2(t)} dt
subject to
0 ≤ u(t) ≤ 1
Choose a grid and solve u(t) numerically using dynamic programming.
9.9 It is proposed to build thermal stations at three different sites. The total budget available
is 3 units (1 unit = $10 million) and the feasible levels of investment on any thermal
station are 0, 1, 2, or 3 units. The electric power obtainable (return function) for different
investments is given below:
Problems 587
Thermal Station, i
Return function, Ri(x) 1 2 3
Ri(0) 0 0 0
Ri(1) 2 1 3
Ri(2) 4 5 5
Ri(3) 6 6 6
Find the investment policy for maximizing the total electric power generated.
9.10 Solve the following LP problem by dynamic programming:
Maximize f (x1, x2) = 10x1 + 8x2
subject to
2x1 + x2 ≤ 25
3x1 + 2x2 ≤ 45
x2 ≤ 10
x1 ≥ 0, x2 ≥ 0
Verify your solution by solving it graphically.
9.11 A fertilizer company needs to supply 50 tons of fertilizer at the end of the first month,
70 tons at the end of second month, and 90 tons at the end of third month. The cost of
producing x tons of fertilizer in any month is given by $(4500x + 20x2). It can produce
more fertilizer in any month and supply it in the next month. However, there is an
inventory carrying cost of $400 per ton per month. Find the optimal level of production
in each of the three periods and the total cost involved by solving it as an initial value
problem.
9.12 Solve Problem 9.11 as a final value problem.
9.13 Solve the following problem by dynamic programming:
Maximize
di ≥ 0
3
∑
i=1
d2i
subject to
di = xi+1 − xi, i = 1, 2, 3
xi = 0, 1, 2, . . . , 5, i = 1, 2
x3 = 5, x4 = 0
10
Integer Programming
10.1 INTRODUCTION
In all the optimization techniques considered so far, the design variables are assumed
to be continuous, which can take any real value. In many situations it is entirely
appropriate and possible to have fractional solutions. For example, it is possible to use
a plate of thickness 2.60 mm in the construction of a boiler shell, 3.34 hours of labor
time in a project, and 1.78 lb of nitrate to produce a fertilizer. Also, in many engineering
systems, certain design variables can only have discrete values. For example, pipes
carrying water in a heat exchanger may be available only in diameter increments of 1
8
in. However, there are practical problems in which the fractional values of the design
variables are neither practical nor physically meaningful. For example, it is not possible
to use 1.6 boilers in a thermal power station, 1.9 workers in a project, and 2.76 lathes
in a machine shop. If an integer solution is desired, it is possible to use any of the
techniques described in previous chapters and round off the optimum values of the
design variables to the nearest integer values. However, in many cases, it is very
difficult to round off the solution without violating any of the constraints. Frequently,
the rounding of certain variables requires substantial changes in the values of some
other variables to satisfy all the constraints. Further, the round-off solution may give
a value of the objective function that is very far from the original optimum value. All
these difficulties can be avoided if the optimization problem is posed and solved as an
integer programming problem.
When all the variables are constrained to take only integer values in an opti-
mization problem, it is called an all-integer programming problem . When the vari-
ables are restricted to take only discrete values, the problem is called a discrete
programming problem . When some variables only are restricted to take integer (dis-
crete) values, the optimization problem is called a mixed-integer (discrete) program-
ming problem. When all the design variables of an optimization problem are allowed
to take on values of either zero or 1, the problem is called a zero–one program-
ming problem. Among the several techniques available for solving the all-integer and
mixed-integer linear programming problems, the cutting plane algorithm of Gomory
[10.7] and the branch-and-bound algorithm of Land and Doig [10.8] have been quite
popular. Although the zero–one linear programming problems can be solved by the
general cutting plane or the branch-and-bound algorithms, Balas [10.9] developed an
efficient enumerative algorithm for solving those problems. Very little work has been
done in the field of integer nonlinear programming. The generalized penalty function
method and the sequential linear integer (discrete) programming method can be used to
588 Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
10.2 Graphical Representation 589
Table 10.1 Integer Programming Methods
Linear programming problems Nonlinear programming problems
All-integer
problem
Mixed-integer
problem
Mixed-integer
problem
Zero–one
problem
Polynomial
programming
problem
General nonlinear
problem
Cutting plane method
Branch-and-bound method
Cutting plane method
Branch-and-bound method
Balas method
All-integer
problem
Generalized penalty function
method
Sequential linear integer
(discrete) programming
method
solve all integer and mixed-integer nonlinear programming problems. The various solu-
tion techniques of solving integer programming problems are summarized in Table 10.1.
All these techniques are discussed briefly in this chapter.
Integer Linear Programming
10.2 GRAPHICAL REPRESENTATION
Consider the following integer programming problem:
Maximize f (X) = 3x1 + 4x2
subject to
3x1 − x2 ≤ 12
3x1 + 11x2 ≤ 66
x1 ≥ 0
x2 ≥ 0
x1 and x2 are integers
(10.1)
The graphical solution of this problem, by ignoring the integer requirements, is shown in
Fig. 10.1. It can be seen that the solution is x1 = 5 12 , x2 = 4
1
2
with a value of f = 34 1
2
.
Since this is a noninteger solution, we truncate the fractional parts and obtain the new
solution as x1 = 5, x2 = 4, and f = 31. By comparing this solution with all other
integer feasible solutions (shown by dots in Fig. 10.1), we find that this solution is
optimum for the integer LP problem stated in Eqs. (10.1).
It is to be noted that truncation of the fractional part of a LP problem will not
always give the solution of the corresponding integer LP problem. This can be illustrated
590 Integer Programming
Figure 10.1 Graphical solution of the problem stated in Eqs. (10.1).
by changing the constraint 3x1 + 11x2 ≤ 66 to 7x1 + 11x2 ≤ 88 in Eqs. (10.1). With
this altered constraint, the feasible region and the solution of the LP problem, without
considering the integer requirement, are shown in Fig. 10.2. The optimum solution
of this problem is identical with that of the preceding problem: namely, x1 = 5 12 ,
Figure 10.2 Graphical solution with modified constraint.
10.3 Gomory’s Cutting Plane Method 591
x2 = 4 12 , and f = 34
1
2
. The truncation of the fractional part of this solution gives
x1 = 5, x2 = 4, and f = 31. Although this truncated solution happened to be optimum
to the corresponding integer problem in the earlier case, it is not so in the present case.
In this case the optimum solution of the integer programming problem is given by
x∗1 = 0, x∗2 = 8, and f ∗ = 32.
10.3 GOMORY’S CUTTING PLANE METHOD
10.3.1 Concept of a Cutting Plane
Gomory’s method is based on the idea of generating a cutting plane. To illustrate
the concept of a cutting plane, we again consider the problem stated in Eqs. (10.1).
The feasible region of the problem is denoted by ABCD in Fig. 10.1. The optimal
solution of the problem, without considering the integer requirement, is given by point
C. This point corresponds to x1 = 5 12 , x2 = 4
1
2
, and f = 34 1
2
, which is not optimal to
the integer programming problem since the values of x1 and x2 are not integers. The
feasible integer solutions of the problem are denoted by dots in Fig. 10.1. These points
are called the integer lattice points .
In Fig. 10.3, the original feasible region is reduced to a new feasible region
ABEFGD by including the additional (arbitrarily selected) constraints. The idea behind
Figure 10.3 Effect of additional constraints.
592 Integer Programming
adding these additional constraints is to reduce the original feasible convex region
ABCD to a new feasible convex region (such as ABEFGD) such that an extreme
point of the new feasible region becomes an integer optimal solution to the integer
programming problem. There are two main considerations to be taken while select-
ing the additional constraints: (1) the new feasible region should also be a convex
set, and (2) the part of the original feasible region that is sliced off because of the
additional constraints should not include any feasible integer solutions of the original
problem.
In Fig. 10.3, the inclusion of the two arbitrarily selected additional constraints PQ
and P ′Q′ gives the extreme point F(x1 = 5, x2 = 4, f = 31) as the optimal solution
of the integer programming problem stated in Eqs. (10.1). Gomory’s method is one in
which the additional constraints are developed in a systematic manner.
10.3.2 Gomory’s Method for All-Integer Programming Problems
In this method the given problem [Eqs. (10.1)] is first solved as an ordinary LP problem
by neglecting the integer requirement. If the optimum values of the variables of the
problem happen to be integers, there is nothing more to be done since the integer
solution is already obtained. On the other hand, if one or more of the basic variables
have fractional values, some additional constraints, known as Gomory constraints ,
that will force the solution toward an all-integer point will have to be introduced. To
see how the Gomory constraints are generated, let the tableau corresponding to the
optimum (noninteger) solution of the ordinary LP problem be as shown in Table 10.2.
Here it is assumed that there are a total of m + n variables (n original variables plus
m slack variables). At the optimal solution, the basic variables are represented as
xi(i = 1, 2, . . . , m) and the nonbasic variables as yj (j = 1, 2, . . . , n) for convenience.
Gomory’s Constraint. From Table 10.2, choose the basic variable with the largest
fractional value. Let this basic variable be xi . When there is a tie in the fractional
values of the basic variables, any of them can be taken as xi . This variable can be
Table 10.2 Optimum Noninteger Solution of Ordinary LP Problem
Coefficient corresponding to:Basic
variables x1 x2 . . . xi . . . xm y1 y2 . . . yj . . . yn
Objective
function Constants
x1 1 0 0 0 a11 a12 a1j a1n 0 b1
x2 0 1 0 0 a21 a22 a2j a2n 0 b2
...
xi 0 0 1 0 ai1 ai2 aij ain 0 bi
...
xm 0 0 0 1 am1 am2 amj amn 0 bm
f 0 0 . . . 0 . . . 0 c1 c2 cj cn 1 f
10.3 Gomory’s Cutting Plane Method 593
expressed, from the ith equation of Table 10.2, as
xi = bi −
n
∑
j=1
aijyj (10.2)
where bi is a noninteger. Let us write
bi = b̂i + βi (10.3)
aij = âij + αij (10.4)
where b̂i and âij denote the integers obtained by truncating the fractional parts from bi
and aij , respectively. Thus βi will be a strictly positive fraction (0 < βi < 1) and αij
will be a nonnegative fraction (0 ≤ αij < 1). With the help of Eqs. (10.3) and (10.4),
Eq. (10.2) can be rewritten as
βi −
n
∑
j=1
αijyj = xi − b̂i +
n
∑
j=1
âijyj (10.5)
Since all the variables xi and yj must be integers at an optimal integer solution, the
right-hand side of Eq. (10.5) must be an integer. Thus we obtain
βi −
n
∑
j=1
αijyj = integer (10.6)
Notice that αij are nonnegative fractions and yj are nonnegative integers. Hence the
quantity
∑n
j=1 αijyj will always be a nonnegative number. Since βi is a strictly positive
fraction, we have

βi −
n
∑
j=1
αijyj

 ≤ βi < 1 (10.7)
As the quantity
(
βi −
∑n
j=1 αijyj
)
has to be an integer [from Eq. (10.6)], it can be
either a zero or a negative integer. Hence we obtain the desired constraint as
+βi −
n
∑
j=1
αijyj ≤ 0 (10.8)
By adding a nonnegative slack variable si , the Gomory constraint equation becomes
si −
n
∑
j=1
αijyj = −βi (10.9)
where si must also be an integer by definition.
594 Integer Programming
Table 10.3 Optimal Solution with Gomory Constraint
Coefficient corresponding to:Basic
variables x1 x2 . . . xi . . . xm y1 y2 . . . yj . . . yn f si Constants
x1 1 0 0 0 a11 a12 a1j a1n 0 0 b1
x2 0 1 0 0 a21 a22 a2j a2n 0 0 b2
...
xi 0 0 1 0 ai1 ai2 aij ain 0 0 bi
...
xm 0 0 0 1 am1 am2 amj amn 0 0 bm
f 0 0 0 0 c1 c2 cj cn 1 0 f
si 0 0 0 0 −αi1 −αi2 −αij −αin 0 1 −βi
Computational Procedure. Once the Gomory constraint is derived, the coefficients of
this constraint are inserted in a new row of the final tableau of the ordinary LP problem
(i.e., Table 10.2). Since all yj = 0 in Table 10.2, the Gomory constraint equation (10.9),
becomes
si = −βi = negative
which is infeasible. This means that the original optimal solution is not satisfying this
new constraint. To obtain a new optimal solution that satisfies the new constraint,
Eq. (10.9), the dual simplex method discussed in Chapter 4 can be used. The new
tableau, after adding the Gomory constraint, is as shown in Table 10.3.
After finding the new optimum solution by applying the dual simplex method, test
whether the new solution is all-integer or not. If the new optimum solution is all-integer,
the process ends. On the other hand, if any of the basic variables in the new solution
take on fractional values, a new Gomory constraint is derived from the new simplex
tableau and the dual simplex method is applied again. This procedure is continued until
either an optimal integer solution is obtained or the dual simplex method indicates that
the problem has no feasible integer solution.
Remarks:
1. If there is no feasible integer solution to the given (primal) problem, this can
be detected by noting an unbounded condition for the dual problem.
2. The application of the dual simplex method to remove the infeasibility of
Eq. (10.9) is equivalent to cutting off the original feasible solution toward the
optimal integer solution.
3. This method has a serious drawback. This is associated with the round-off
errors that arise during numerical computations. Due to these round-off errors,
we may ultimately get a wrong optimal integer solution. This can be rectified by
storing the numbers as fractions instead of as decimal quantities. However, the
magnitudes of the numerators and denominators of the fractional numbers, after
some calculations, may exceed the capacity of the computer. This difficulty can
10.3 Gomory’s Cutting Plane Method 595
be avoided by using the all-integer integer programming algorithm developed
by Gomory [10.10].
4. For obtaining the optimal solution of an ordinary LP problem, we start from a
basic feasible solution (at the start of phase II) and find a sequence of improved
basic feasible solutions until the optimum basic feasible solution is found. Dur-
ing this process, if the computations have to be terminated at any stage (for
some reason), the current basic feasible solution can be taken as an approx-
imation to the optimum solution. However, this cannot be done if we apply
Gomory’s method for solving an integer programming problem. This is due to
the fact that the problem remains infeasible in the sense that no integer solu-
tion can be obtained until the whole problem is solved. Thus we will not be
having any good integer solution that can be taken as an approximate optimum
solution in case the computations have to be terminated in the middle of the
process.
5. From the description given above, the number of Gomory constraints to be
generated might appear to be very large, especially if the solution converges
slowly. If the number of constraints really becomes very large, the size of the
problem also grows without bound since one (slack) variable and one constraint
are added with the addition of each Gomory constraint. However, it can be
observed that the total number of constraints in the modified tableau will not
exceed the number of variables in the original problem, namely, n + m. The
original problem has m equality constraints in n + m variables and we observe
that there are n nonbasic variables. When a Gomory constraint is added, the
number of constraints and the number of variables will each be increased by
one, but the number of nonbasic variables will remain n. Hence at most n
slack variables of Gomory constraints can be nonbasic at any time, and any
additional Gomory constraint must be redundant. In other words, at most n
Gomory constraints can be binding at a time. If at all a (n + 1)th constraint is
there (with its slack variable as a basic and positive variable), it must be implied
by the remaining constraints. Hence we drop any Gomory constraint once its
slack variable becomes basic in a feasible solution.
Example 10.1
Minimize f = −3x1 − 4x2
subject to
3x1 − x2 + x3 = 12
3x1 + 11x2 + x4 = 66
xi ≥ 0, i = 1 to 4
all xi are integers
This problem can be seen to be same as the one stated in Eqs. (10.1) with the addition
of slack variables x3 and x4.
596 Integer Programming
SOLUTION
Step 1: Solve the LP problem by neglecting the integer requirement of the variables
xi , i = 1 to 4, using the regular simplex method as shown below:
Coefficients of variablesBasic
variables x1 x2 x3 x4 −f bi bi/ais for ais > 0
x3 3 −1 1 0 0 12
x4 3 11 0 1 0 66 6 ←
Pivot
element
−f −3 −4 0 0 1 0
↑
Most negative cj
Result of pivoting:
x3
36
11
0 1 1
11
0 18 11
2
← Smaller
onePivot
element
x2
3
11
1 0 1
11
0 6 22
−f − 21
11
0 0 4
11
1 24
↑
Most negative cj
Result of pivoting:
x1 1 0
11
36
1
36
0 11
2
x2 0 1 − 112
1
12
0 9
2
−f 0 0 7
12
5
12
1 69
2
Since all the cost coefficients are nonnegative, the last tableau gives the opti-
mum solution as
x1 = 112 , x2 =
9
2
, x3 = 0, x4 = 0, fmin = − 692
which can be seen to be identical to the graphical solution obtained in
Section 10.2.
Step 2: Generate a Gomory constraint . Since the solution above is noninteger, a
Gomory constraint has to be added to the last tableau. Since there is a tie
10.3 Gomory’s Cutting Plane Method 597
between x1 and x2, let us select x1 as the basic variable having the largest
fractional value. From the row corresponding to x1 in the last tableau, we can
write
x1 = 112 −
11
36
y1 − 136y2 (E1)
where y1 and y2 are used in place of x3 and x4 to denote the nonbasic variables.
By comparing Eq. (E1) with Eq. (10.2), we find that
i = 1, b1 = 112 , b̂1 = 5, β1 =
1
2
, a11 = 1136 ,
â11 = 0, α11 = 1136 , a12 =
1
36
, â12 = 0, and α12 = 136
From Eq. (10.9), the Gomory constraint can be expressed as
s1 − α11y1 − α12y2 = −β1 (E2)
where s1 is a new nonnegative (integer) slack variable. Equation (E2) can be
written as
s1 − 1136y1 −
1
36
y2 = − 12 (E3)
By introducing this constraint, Eq. (E3), into the previous optimum tableau,
we obtain the new tableau shown below:
Coefficients of variablesBasic
variables x1 x2 y1 y2 −f s1 bi
bi/ais
for ais > 0
x1 1 0
11
36
1
36
0 0 11
2
x2 0 1 − 112
1
12
0 0 9
2
−f 0 0 7
12
5
12
1 0 69
2
s1 0 0 − 1136 −
1
36
0 1 − 1
2
Step 3: Apply the dual simplex method to find a new optimum solution. For this, we
select the pivotal row r such that br = min(bi < 0) = − 12 corresponding to s1
in this case. The first column s is selected such that
cs
−ars
= min
arj < 0
(
cj
−arj
)
598 Integer Programming
Here
cj
−arj
= 7
12
× 36
11
= 21
11
for column y1
= 5
12
× 36
1
= 15 for column y2.
Since 21
11
is minimum out of 21
11
and 15, the pivot element will be − 11
36
. The
result of pivot operation is given in the following tableau:
Coefficients of variablesBasic
variables x1 x2 y1 y2 −f s1 bi
bi/ais
for ais > 0
x1 1 0 0 0 0 1 5
x2 0 1 0
1
11
0 − 3
11
51
11
−f 0 0 0 4
11
1 21
11
369
11
y1 0 0 1
1
11
0 − 36
11
18
11
The solution given by the present tableau is x1 = 5, x2 = 4 711 , y1 = 1
7
11
, and
f = −33 6
11
, in which some variables are still nonintegers.
Step 4: Generate a new Gomory constraint. To generate the new Gomory constraint,
we arbitrarily select x2 as the variable having the largest fractional value (since
there is a tie between x2 and y1). The row corresponding to x2 gives
x2 = 5111 −
1
11
y2 + 311s1
From this equation, the Gomory constraint [Eq. (10.9)] can be written as
s2 − 111y2 +
3
11
s1 = − 711
When this constraint is added to the previous tableau, we obtain the following
tableau:
Coefficients of variablesBasic
variables x1 x2 y1 y2 −f s1 s2 bi
x1 1 0 0 0 0 1 0 5
x2 0 1 0
1
11
0 − 3
11
0 51
11
y1 0 0 1
1
11
0 − 36
11
0 18
11
−f 0 0 0 4
11
1 21
11
0 369
11
s2 0 0 0 − 111 0
3
11
1 − 7
11
Step 5: Apply the dual simplex method to find a new optimum solution. To carry the
pivot operation, the pivot row is selected to correspond to the most negative
value of bi . This is the s2 row in this case.
10.3 Gomory’s Cutting Plane Method 599
Since only arj corresponding to column y2 is negative, the pivot element
will be − 1
11
in the s2 row. The pivot operation on this element leads to the
following tableau:
Coefficients of variablesBasic
variables x1 x2 y1 y2 −f s1 s2 bi
x1 1 0 0 0 0 1 0 5
x2 0 1 0 0 0 0 1 4
y1 0 0 1 0 0 −3 1 1
−f 0 0 0 0 1 3 4 31
y2 0 0 0 1 0 −3 −11 7
The solution given by this tableau is x1 = 5, x2 = 4, y1 = 1, y2 = 7, and
f = −31, which can be seen to satisfy the integer requirement. Hence this is
the desired solution.
10.3.3 Gomory’s Method for Mixed-Integer Programming Problems
The method discussed in Section 10.3.2 is applicable to solve all integer programming
problems where both the decision and slack variables are restricted to integer values in
the optimal solution. In the mixed-integer programming problems, only a subset of the
decision and slack variables are restricted to integer values. The procedure for solving
mixed-integer programming problems is similar to that of all-integer programming
problems in many respects.
Solution Procedure. As in the case of an all-integer programming problem, the first
step involved in the solution of a mixed-integer programming problem is to obtain an
optimal solution of the ordinary LP problem without considering the integer restrictions.
If the values of the basic variables, which were restricted to integer values, happen to
be integers in this optimal solution, there is nothing more to be done. Otherwise, a
Gomory constraint is formulated by taking the integer-restricted basic variable, which
has the largest fractional value in the optimal solution of the ordinary LP problem.
Let xi be the basic variable that has the largest fractional value in the optimal
solution (as shown in Table 10.2), although it is restricted to take on only integer
values. If the nonbasic variables are denoted as yj , j = 1, 2, . . . , n, the basic variable
xi can be expressed as (from Table 10.2)
xi = bi −
n
∑
j=1
aijyj (10.2)
We can write
bi = b̂i + βi (10.3)
where b̂i is the integer obtained by truncating the fractional part of bi and βi is the
fractional part of bi . By defining
aij = a+ij + a−ij (10.10)
600 Integer Programming
where
a+ij =
{
aij if aij ≥ 0
0 if aij < 0
(10.11)
a−ij =
{
0 if aij ≥ 0
aij if aij < 0
(10.12)
Eq. (10.2) can be rewritten as
n
∑
j=1
(a+ij + a−ij )yj = βi + (b̂i − xi) (10.13)
Here, by assumption, xi is restricted to integer values while bi is not an integer. Since
0 < βi < 1 and b̂i is an integer, we can have the value of βi + (b̂i − xi) either ≥ 0 or
< 0. First, we consider the case where
βi + (b̂i − xi) ≥ 0 (10.14)
In this case, in order for xi to be an integer, we must have
βi + (b̂i − xi) = βi or βi + 1 or βi + 2, . . . (10.15)
Thus Eq. (10.13) gives
n
∑
j=1
(a+ij + a−ij )yj ≥ βi (10.16)
Since aij are nonpositive and yj are nonnegative by definition, we have
n
∑
j=1
a+ij yj ≥
n
∑
j=1
(a+ij − a−ij )yj (10.17)
and hence
n
∑
j=1
a+ij yj ≥ βi (10.18)
Next, we consider the case where
βi + (b̂i − xi) < 0 (10.19)
For xi to be an integer, we must have (since 0 < βi < 1)
βi + (b̂i − xi) = −1 + βi or − 2 + βi or − 3 + βi, . . . (10.20)
10.3 Gomory’s Cutting Plane Method 601
Thus Eq. (10.13) yields
n
∑
j=1
(a+ij + a−ij )yj ≤ βi − 1 (10.21)
Since
n
∑
j=1
a−ij yj ≤
n
∑
j=1
(a+ij + a−ij )yj
we obtain
n
∑
j=1
a−ij yj ≤ βi − 1 (10.22)
Upon dividing this inequality by the negative quantity (βi − 1), we obtain
1
βi − 1
n
∑
j=1
a−ij yj ≥ 1 (10.23)
Multiplying both sides of this inequality by βi > 0, we can write the inequality
(10.23) as
βi
βi − 1
n
∑
j=1
a−ij yj ≥ βi (10.24)
Since one of the inequalities in (10.18) and (10.24) must be satisfied, the following
inequality must hold true:
n
∑
j=1
a+ij yj +
βi
βi − 1
n
∑
j=1
(a−ij )yj ≥ βi (10.25)
By introducing a slack variable si , we obtain the desired Gomory constraint as
si =
n
∑
j=1
a+ij yj +
βi
βi − 1
n
∑
j=1
aijyj − βi (10.26)
This constraint must be satisfied before the variable xi becomes an integer. The slack
variable si is not required to be an integer. At the optimal solution of the ordinary LP
problem (given by Table 10.2), all yj = 0 and hence Eq. (10.26) becomes
si = −βi = negative
602 Integer Programming
which can be seen to be infeasible. Hence the constraint Eq. (10.26) is added at the
end of Table 10.2, and the dual simplex method applied. This procedure is repeated
the required number of times until the optimal mixed integer solution is found.
Discussion. In the derivation of the Gomory constraint, Eq. (10.26), we have not
made use of the fact that some of the variables (yj ) might be integer variables. We
notice that any integer value can be added to or subtracted from the coefficient of
aik(= a+ik + a−ik) of an integer variable yk provided that we subtract or add, respectively,
the same value to xi in Eq. (10.13), that is,
n
∑
j = 1
j = k
aijyj + (aik ± δ)yk = βi + b̂i − (xi ∓ δ) (10.27)
From Eq. (10.27), the same logic as was used in the derivation of Eqs. (10.18) and
(10.24) can be used to obtain the same final equation, Eq. (10.26). Of course, the
coefficients of integer variables yk will be altered by integer amounts in Eq. (10.26).
It has been established that to cut the feasible region as much as possible (through the
Gomory constraint), we have to make the coefficients of integer variables yk as small
as possible. We can see that the smallest positive coefficient we can have for yj in
Eq. (10.13) is
αij = aij − âij
and the largest negative coefficient as
1 − αij = 1 − aij + âij
where âij is the integer obtained by truncating the fractional part of aij and αij is the
fractional part. Thus we have a choice of two expressions, (aij − âij ) and (1 − aij +
âij ), for the coefficients of yj in Eq. (10.26). We choose the smaller one out of the
two to make the Gomory constraint, Eq. (10.26), cut deeper into the original feasible
space. Thus Eq. (10.26) can be rewritten as
si =
∑
j
a+ij yj +
βi
βi − 1
∑
j
(+a−ij )yj
︸ ︷︷ ︸
for noninterger variables yj
+
∑
j
(aij − âij )yj
︸ ︷︷ ︸
for integer variables yj
and for aij − âij ≤ βi
+ βi
βi − 1
∑
j
(1 − aij + âij )yj−
︸ ︷︷ ︸
for integer variables yj
and for aij − âij > βi
βi
where the slack variable si is not restricted to be an integer.
Example 10.2 Solve the problem of Example 10.1 with x2 only restricted to take
integer values.
10.3 Gomory’s Cutting Plane Method 603
SOLUTION
Step 1: Solve the LP problem by simplex method by neglecting the integer requirement.
This gives the following optimal tableau:
Coefficients of variablesBasic
variables x1 x2 y1 y2 −f bi
x1 1 0
11
36
1
36
0 11
2
x2 0 1 − 112
1
12
0 9
2
−f 0 0 7
12
5
12
1 69
2
The noninteger solution given by this tableau is
x1 = 5 12 , x2 = 4
1
2
, y1 = y2 = 0, and fmin = −34 12 .
Step 2: Formulate a Gomory constraint . Since x2 is the only variable that is restricted
to take integer values, we construct the Gomory constraint for x2. From the
tableau of step 1, we obtain
x2 = b2 − a21y1 − a22y2
where
b2 = 92 , a21 = −
1
12
, and a22 = 112
According to Eq. (10.3), we write b2 as b2 = b̂2 + β2 where b̂2 = 4 and β2 = 12 .
Similarly, we write from Eq. (10.10)
a21 = a+21 + a−21
a22 = a+22 + a−22
where
a+21 = 0, a−21 = − 112 (since a21 is negative)
a+22 = 112 , a
−
22 = 0 (since a22 is nonnegative)
The Gomory constraint can be expressed as [from Eq. (10.26)]:
s2 −
2
∑
j=1
a+2jyj +
β2
β2 − 1
2
∑
j=1
a−2jyj = −β2
where s2 is a slack variable that is not required to take integer values. By
substituting the values of a+ij , a
−
ij , and βi , this constraint can be written as
s2 + 112y1 −
1
12
y2 = − 12
604 Integer Programming
When this constraint is added to the tableau above, we obtain the following:
Coefficients of variablesBasic
variables x1 x2 y1 y2 −f s2 bi
x1 1 0
11
36
1
36
0 0 11
2
x2 0 1 − 112
1
12
0 0 9
2
−f 0 0 7
12
5
12
1 0 69
2
s2 0 0
1
12
− 1
12
0 1 − 1
2
Step 3: Apply the dual simplex method to find a new optimum solution. Since − 1
2
is the
only negative bi term, the pivot operation has to be done in s2 row. Further, aij
corresponding to y2 column is the only negative coefficient in s2 row and hence
pivoting has to be done on this element, − 1
12
. The result of pivot operation is
shown in the following tableau:
Coefficients of variablesBasic
variables x1 x2 y1 y2 −f s2 bi
x1 1 0
1
3
0 0 1
3
16
3
x2 0 1 0 0 0 1 4
−f 0 0 1 0 1 5 32
y2 0 0 −1 1 0 −12 6
This tableau gives the desired integer solution as
x1 = 5 12 , x2 = 4, y2 = 6, y1 = 0, s2 = 0, and fmin = −32
10.4 BALAS’ ALGORITHM FOR ZERO–ONE PROGRAMMING
PROBLEMS
When all the variables of a LP problem are constrained to take values of 0 or 1 only, we
have a zero–one (or binary) LP problem. A study of the various techniques available
for solving zero–one programming problems is important for the following reasons:
1. As we shall see later in this chapter (Section 10.5), a certain class of integer
nonlinear programming problems can be converted into equivalent zero–one
LP problems,
2. A wide variety of industrial, management, and engineering problems can be for-
mulated as zero–one problems. For example, in structural control, the problem
of selecting optimal locations of actuators (or dampers) can be formulated as a
zero–one problem. In this case, if a variable is zero or 1, it indicates the absence
or presence of the actuator, respectively, at a particular location [10.31].
The zero–one LP problems can be solved by using any of the general integer LP
techniques like Gomory’s cutting plane method and Land and Doig’s branch-and-bound
10.4 Balas’ Algorithm for Zero–One Programming Problems 605
method by introducing the additional constraint that all the variables must be less than
or equal to 1. This additional constraint will restrict each of the variables to take a
value of either zero (0) or one (1). Since the cutting plane and the branch-and-bound
algorithms were developed primarily to solve a general integer LP problem, they do not
take advantage of the special features of zero–one LP problems. Thus several methods
have been proposed to solve zero–one LP problems more efficiently. In this section
we present an algorithm developed by Balas (in 1965) for solving LP problems with
binary variables only [10.9].
If there are n binary variables in a problem, an explicit enumeration process will
involve testing 2n possible solutions against the stated constraints and the objective
function. In Balas method, all the 2n possible solutions are enumerated, explicitly or
implicitly. The efficiency of the method arises out of the clever strategy it adopts in
selecting only a few solutions for explicit enumeration.
The method starts by setting all the n variables equal to zero and consists of a
systematic procedure of successively assigning to certain variables the value 1, in such
a way that after trying a (small) part of all the 2n possible combinations, one obtains
either an optimal solution or evidence of the fact that no feasible solution exists. The
only operations required in the computation are additions and subtractions, and hence
the round-off errors will not be there. For this reason the method is some times referred
to as additive algorithm .
Standard Form of the Problem. To describe the algorithm, consider the following
form of the LP problem with zero–one variables:
Find X =









x1
x2
...
xn









such that f (X) = CT X → minimum
subject to
AX + Y = B
xi = 0 or 1
Y ≥ 0
(10.28)
where
C =









c1
c2
...
cn









≥ 0, Y =









y1
y2
...
ym









, B =









b1
b2
...
bm









A =





a11 a12 · · · a1n
a21 a22 · · · a2n
...
am1 am2 · · · amn





where Y is the vector of slack variables and ci and aij need not be integers.
606 Integer Programming
Initial Solution. An initial solution for the problem stated in Eqs. (10.28) can be
taken as
f0 = 0
xi = 0, i = 1, 2, . . . , n (10.29)
Y(0) = B
If B ≥ 0, this solution will be feasible and optimal since C ≥ 0 in Eqs. (10.28). In this
case there is nothing more to be done as the starting solution itself happens to be opti-
mal. On the other hand, if some of the components bj are negative, the solution given
by Eqs. (10.29) will be optimal (since C ≥ 0) but infeasible. Thus the method starts
with an optimal (actually better than optimal) and infeasible solution. The algorithm
forces this solution toward feasibility while keeping it optimal all the time. This is the
reason why Balas called his method the pseudo dual simplex method . The word pseudo
has been used since the method is similar to the dual simplex method only as far as
the starting solution is concerned and the subsequent procedure has no similarity at all
with the dual simplex method. The details can be found in Ref. [10.9].
Integer Nonlinear Programming
10.5 INTEGER POLYNOMIAL PROGRAMMING
Watters [10.2] has developed a procedure for converting integer polynomial program-
ming problems to zero–one LP problems. The resulting zero–one LP problem can
be solved conveniently by the Balas method discussed in Section 10.4. Consider the
optimization problem:
Find X =









x1
x2
...
xn









which minimizes f (X)
subject to the constraints (10.30)
gj (X) ≤ 0, j = 1, 2, . . . , m
xi = integer, i = 1, 2, . . . , n
where f and gj , j = 1, 2, . . . ,m, are polynomials in the variables x1, x2, . . . , xn. A
typical term in the polynomials can be represented as
ck
nk∏
l=1
(xl)
akl (10.31)
where ck is a constant, akl a nonnegative constant exponent, and nk the number
of variables appearing in the kth term. We shall convert the integer polynomial
programming problem stated in Eq. (10.30) into an equivalent zero–one LP problem
10.5 Integer Polynomial Programming 607
in two stages. In the first stage we see how an integer variable, xi , can be represented
by an equivalent system of zero–one (binary) variables. We consider the conversion
of a zero–one polynomial programming problem into a zero–one LP problem in the
second stage.
10.5.1 Representation of an Integer Variable by an Equivalent System
of Binary Variables
Let xi be any integer variable whose upper bound is given by ui so that
xi ≤ ui < ∞ (10.32)
We assume that the value of the upper bound ui can be determined from the constraints
of the given problem.
We know that in the decimal number system, an integer p is represented as
p = p0 + 101p1 + 102p2 + · · · , 0 ≤ pi ≤ (10 − 1 = 9)
for i = 0, 1, 2, . . .
and written as p = · · · p2p1p0 by neglecting the zeros to the left. For example, we write
the number p = 008076 as 8076 to represent p = 6 + (101)7 + (102)(0) + (103)8 +
(104)0 + (105)0. In a similar manner, the integer p can also be represented in binary
number system as
p = q0 + 21q1 + 22q2 + 23q3 + · · ·
where 0 ≤ qi ≤ (2 − 1 = 1) for i = 0, 1, 2, . . . .
In general, if y
(0)
i , y
(1)
i , y
(2)
i , . . . denote binary numbers (which can take a value of
0 or 1), the variable xi can be expressed as
xi =
Ni∑
k=0
2ky
(k)
i (10.33)
where Ni is the smallest integer such that
ui + 1
2
≤ 2Ni (10.34)
Thus the value of Ni can be selected for any integer variable xi once its upper bound
ui is known. For example, for the number 97, we can take ui = 97 and hence the
relation
ui + 1
2
= 98
2
= 49 ≤ 2Ni
is satisfied for Ni ≥ 6. Hence by taking Ni = 6, we can represent ui as
97 = q0 + 21q1 + 22q2 + 23q3 + 24q4 + 25q5 + 26q6
where q0 = 1, q1 = q2 = q3 = q4 = 0, and q5 = q6 = 1. A systematic method of find-
ing the values of q0, q1, q2, . . . is given below.
608 Integer Programming
Method of Finding q0, q1, q2, . . . . Let M be the given positive integer. To find its
binary representation qnqn−1 . . . q1q0, we compute the following recursively:
b0 = M (10.35)
b1 =
b0 − q0
2
b2 =
b1 − q1
2
...
bk =
bk−1 − qk−1
2
where qk = 1 if bk is odd and qk = 0 if bk is even. The procedure terminates when
bk = 0.
Equation (10.33) guarantees that xi can take any feasible integer value less than
or equal to ui . The use of Eq. (10.33) in the problem stated in Eq. (10.30) will convert
the integer programming problem into a binary one automatically. The only difference
is that the binary problem will have N1 + N2 + · · · + Nn zero–one variables instead
of the n original integer variables.
10.5.2 Conversion of a Zero–One Polynomial Programming Problem
into a Zero–One LP Problem
The conversion of a polynomial programming problem into a LP problem is based on
the fact that
x
aki
i ≡ xi (10.36)
if xi is a binary variable (0 or 1) and aki is a positive exponent. If aki = 0, then
obviously the variable xi will not be present in the kth term. The use of Eq. (10.36)
permits us to write the kth term of the polynomial, Eq. (10.31), as
ck
nk∏
l=1
(xl)
akl = ck
nk∏
l=1
xl = ck(x1, x2, . . . , xnk ) (10.37)
Since each of the variables x1, x2, . . . can take a value of either 0 or 1, the product
(x1x2 · · · xnk) also will take a value of 0 or 1. Hence by defining a binary variable
yk as
yk = x1x2 · · · xnk =
nk∏
l=1
xl (10.38)
10.6 Branch-and-Bound Method 609
the kth term of the polynomial simply becomes ckyk . However, we need to add the
following constraints to ensure that yk = 1 when all xi = 1 and zero otherwise:
yk ≥
(
nk∑
i=1
xi
)
− (nk − 1) (10.39)
yk ≤
1
nk
(
nk∑
i=1
xi
)
(10.40)
It can be seen that if all xi = 1,
∑nk
i=1 xi = nk, and Eqs. (10.39) and (10.40) yield
yk ≥ 1 (10.41)
yk ≤ 1 (10.42)
which can be satisfied only if yk = 1. If at least one xi = 0, we have
∑nk
i=1 xi < nk,
and Eqs. (10.39) and (10.40) give
yk ≥ −(nk − 1) (10.43)
yk < 1 (10.44)
Since nk is a positive integer, the only way to satisfy Eqs. (10.43) and (10.44) under
all circumstances is to have yk = 0.
This procedure of converting an integer polynomial programming problem into an
equivalent zero–one LP problem can always be applied, at least in theory.
10.6 BRANCH-AND-BOUND METHOD
The branch-and-bound method is very effective in solving mixed-integer linear and
nonlinear programming problems. The method was originally developed by Land and
Doig [10.8] to solve integer linear programming problems and was later modified
by Dakin [10.23]. Subsequently, the method has been extended to solve nonlinear
mixed-integer programming problems. To see the basic solution procedure, consider
the following nonlinear mixed-integer programming problem:
Minimizef (X) (10.45)
subject to
gj (X) ≥ 0, j = 1, 2, . . . , m (10.46)
hk(X) = 0, k = 1, 2, . . . , p (10.47)
xj = integer, j = 1, 2, . . . , n0 (n0 ≤ n) (10.48)
where X = {x1, x2, . . . , xn}T. Note that in the design vector X, the first n0 variables
are identified as the integer variables. If n0 = n, the problem becomes an all-integer
programming problem. A design vector X is called a continuous feasible solution if
610 Integer Programming
X satisfies constraints (10.46) and (10.47). A design vector X that satisfies all the
constraints, Eqs. (10.46) to (10.48), is called an integer feasible solution .
The simplest method of solving an integer optimization problem involves enumer-
ating all integer points, discarding infeasible ones, evaluating the objective function
at all integer feasible points, and identifying the point that has the best objective
function value. Although such an exhaustive search in the solution space is simple
to implement, it will be computationally expensive even for moderate-size problems.
The branch-and-bound method can be considered as a refined enumeration method in
which most of the nonpromising integer points are discarded without testing them. Also
note that the process of complete enumeration can be used only if the problem is an
all-integer programming problem. For mixed-integer problems in which one or more
variables may assume continuous values, the process of complete enumeration cannot
be used.
In the branch-and-bound method, the integer problem is not directly solved. Rather,
the method first solves a continuous problem obtained by relaxing the integer restric-
tions on the variables. If the solution of the continuous problem happens to be an
integer solution, it represents the optimum solution of the integer problem. Otherwise,
at least one of the integer variables, say xi , must assume a nonintegral value. If xi is
not an integer, we can always find an integer [xi] such that
[xi] < xi < [xi] + 1 (10.49)
Then two subproblems are formulated, one with the additional upper bound
constraint
xi ≤ [xi] (10.50)
and another with the lower bound constraint
xi ≥ [xi] + 1 (10.51)
The process of finding these subproblems is called branching .
The branching process eliminates some portion of the continuous space that is not
feasible for the integer problem, while ensuring that none of the integer feasible solu-
tions are eliminated. Each of these two subproblems are solved again as a continuous
problem. It can be seen that the solution of a continuous problem forms a node and
from each node two branches may originate.
The process of branching and solving a sequence of continuous problems discussed
above is continued until an integer feasible solution is found for one of the two con-
tinuous problems. When such a feasible integer solution is found, the corresponding
value of the objective function becomes an upper bound on the minimum value of the
objective function. At this stage we can eliminate from further consideration all the
continuous solutions (nodes) whose objective function values are larger than the upper
bound. The nodes that are eliminated are said to have been fathomed because it is
not possible to find a better integer solution from these nodes (solution spaces) than
what we have now. The value of the upper bound on the objective function is updated
whenever a better bound is obtained.
10.6 Branch-and-Bound Method 611
It can be seen that a node can be fathomed if any of the following conditions
are true:
1. The continuous solution is an integer feasible solution.
2. The problem does not have a continuous feasible solution.
3. The optimal value of the continuous problem is larger than the current upper
bound.
The algorithm continues to select a node for further branching until all the nodes have
been fathomed. At that stage, the particular fathomed node that has the integer feasible
solution with the lowest value of the objective function gives the optimum solution of
the original nonlinear integer programming problem.
Example 10.3 Solve the following LP problem using the branch-and-bound method:
Maximize f = 3x1 + 4x2
subject to (E1)
7x1 + 11x2 ≤ 88, 3x1 − x2 ≤ 12, x1 ≥ 0, x2 ≥ 0
xi = integer, i = 1, 2 (E2)
SOLUTION The various steps of the procedure are illustrated using graphical method.
Step 1: First the problem is solved as a continuous variable problem [without Eq. (E2)]
to obtain:
Problem (E1) : Fig. 10.2; (x∗1 = 5.5, x∗2 = 4.5, f ∗ = 34.5)
Step 2: The branching process, with integer bounds on x1, yields the problems:
Maximize f = 3x1 + 4x2
subject to (E3)
7x1 + 11x2 ≤ 88, 3x1 − x2 ≤ 12, x1 ≤ 5, x2 ≥ 0
and
Maximize f = 3x1 + 4x2
subject to (E4)
7x1 + 11x2 ≤ 88, 3x1 − x2 ≤ 12, x1 ≥ 6, x2 ≥ 0
The solutions of problems (E3) and (E4) are given by
Problem (E3) : Fig. 10.4; (x∗1 = 5, x∗2 = 4.8182, f ∗ = 34.2727)
Problem (E4) : Fig. 10.5; no feasible solution exists.
612 Integer Programming
x1
Figure 10.4 Graphical solution of problem (E3).
Step 3: The next branching process, with integer bounds on x2, leads to the following
problems:
Maximize f = 3x1 + 4x2
subject to (E5)
7x1 + 11x2 ≤ 88, 3x1 − x2 ≤ 12, x1 ≤ 5, x2 ≤ 4
and
Maximize f = 3x1 + 4x2
subject to (E6)
7x1 + 11x2 ≤ 88, 3x1 − x2 ≤ 12, x1 ≤ 5, x2 ≥ 5
10.6 Branch-and-Bound Method 613
Figure 10.5 Graphical solution of problem (E4).
The solutions of problems (E5) and (E6) are given by
Problem (E5) : Fig. 10.6; (x∗1 = 5, x∗2 = 4, f ∗ = 31)
Problem (E6) : Fig. 10.7; (x∗1 = 0, x∗2 = 8, f ∗ = 32)
Since both the variables assumed integer values, the optimum solution of the
integer LP problem, Eqs. (E1) and (E2), is given by (x
∗
1 = 0, x∗2 = 8, f ∗ = 32).
Example 10.4 Find the solution of the welded beam problem of Section 7.22.3 by
treating it as a mixed-integer nonlinear programming problem by requiring x3 and x4
to take integer values.
SOLUTION The solution of this problem using the branch-and-bound method was
reported in Ref. [10.25]. The optimum solution of the continuous variable nonlinear
programming problem is given by
X∗ = {0.24, 6.22, 8.29, 0.24}T, f ∗ = 2.38
614 Integer Programming
Figure 10.6 Graphical solution of problem (E5).
Next, the branching problems, with integer bounds on x3, are solved and the pro-
cedure is continued until the desired optimum solution is found. The results are shown
in Fig. 10.8.
10.7 SEQUENTIAL LINEAR DISCRETE PROGRAMMING
Let the nonlinear programming problem with discrete variables be stated as follows:
Minimize f (X) (10.52)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m (10.53)
hk(X) = 0, k = 1, 2, . . . , p (10.54)
xi ∈ {di1, di2, . . . , diq}, i = 1, 2, . . . , n0 (10.55)
x
(l)
i ≤ xi ≤ x
(u)
i , i = n0 + 1, n0 + 2, . . . , n (10.56)
10.7 Sequential Linear Discrete Programming 615
Figure 10.7 Graphical solution of problem (E6).
where the first n0 design variables are assumed to be discrete, dij is the j th discrete
value for the variable i, and X = {x1, x2, . . . , xn}T. It is possible to find the solution
of this problem by solving a series of mixed-integer linear programming problems.
The nonlinear expressions in Eqs. (10.52) to (10.54) are linearized about a point
X0 using a first-order Taylor’s series expansion and the problem is stated as
Minimize f (X) ≈ f (X0) + ∇f (X0)δX (10.57)
subject to
gj (X) ≈ gj (X0) + ∇gj (X0)δX ≤ 0, j = 1, 2, . . . , m (10.58)
hk(X) ≈ hk(X0) + ∇hk(X0)δX = 0, k = 1, 2, . . . , p (10.59)
x0i + δxi ∈ {di1, di2, . . . , diq}, i = 1, 2, . . . , n0 (10.60)
x
(l)
i ≤ x0i + δxi ≤ x
(u)
i , i = n0 + 1, n0 + 2, . . . , n (10.61)
δX = X − X0 (10.62)
616 Integer Programming
Figure 10.8 Solution of the welded beam problem using branch-and-bound method. [10.25]
The problem stated in Eqs. (10.57) to (10.62) cannot be solved using mixed-integer
linear programming techniques since some of the design variables are discrete and
noninteger. The discrete variables are redefined as [10.26]
xi = yi1di1 + yi2di2 + · · · + yiqdiq =
q
∑
j=1
yijdij , i = 1, 2, . . . , n0 (10.63)
with
yi1 + yi2 + · · · + yiq =
q
∑
j=1
yij = 1 (10.64)
yij = 0 or 1, i = 1, 2, . . . , n0, j = 1, 2, . . . , q (10.65)
Using Eqs. (10.63) to (10.65) in Eqs. (10.57) to (10.62), we obtain
Minimize f (X) ≈ f (X0) +
n0∑
i=1
∂f
∂xi


q
∑
j=1
yijdij − x0i


+
n
∑
i=n0+1
∂f
∂xi
(xi − x0i ) (10.66)
10.7 Sequential Linear Discrete Programming 617
subject to
gj (X) ≈ gj (X0) +
n0∑
i=1
∂gi
∂xi
(
n0∑
l=1
yildil − x0i
)
+
n∑
i=n0+1
∂gj
∂xi
(xi − x0i ) ≤ 0,
j = 1, 2, . . . , m (10.67)
hk(X) ≈ hk(X0) +
n0∑
i=1
∂hk
∂xi
(
n0∑
l=1
yildil − x0i
)
+
n∑
i=n0+1
∂hk
∂xi
(xi − x0i ) = 0,
k = 1, 2, . . . , p (10.68)
q
∑
j=1
yij = 1, i = 1, 2, . . . , n0 (10.69)
yij = 0 or 1, i = 1, 2, . . . , n0, j = 1, 2, . . . , q (10.70)
x
(l)
i ≤ x0i + δxi ≤ x
(u)
i , i = n0 + 1, n0 + 2, . . . , n (10.71)
The problem stated in Eqs. (10.66) to (10.71) can now be solved as a mixed-integer
LP problem by treating both yij (i = 1, 2, . . . , n0, j = 1, 2, . . . , q) and xi(i = n0 + 1,
n0 + 2, . . . , n) as unknowns.
In practical implementation, the initial linearization point X0 is to be selected
carefully. In many cases the solution of the discrete problem is expected to lie in
the vicinity of the continuous optimum. Hence the original problem can be solved as
a continuous nonlinear programming problem (by ignoring the discrete nature of the
variables) using any of the standard nonlinear programming techniques. If the resulting
continuous optimum solution happens to be a feasible discrete solution, it can be used as
X0. Otherwise, the values of xi from the continuous optimum solution are rounded (in
a direction away from constraint violation) to obtain an initial feasible discrete solution
X0. Once the first linearized discrete problem is solved, the subsequent linearizations
can be made using the result of the previous optimization problem.
Example 10.5 [10.26 ]
Minimize f (X) = 2x21 + 3x22
subject to
g(X) = 1
x1
+ 1
x2
− 4 ≤ 0
x1 ∈ {0.3, 0.7, 0.8, 1.2, 1.5, 1.8}
x2 ∈ {0.4, 0.8, 1.1, 1.4, 1.6}
SOLUTION In this example, the set of discrete values of each variable is truncated
by allowing only three values—its current value, the adjacent higher value, and the
618 Integer Programming
adjacent lower value—for simplifying the computations. Using X0 =
{
1.2
1.1
}
, we have
f (X0) = 6.51, g(X0) = −2.26
∇f (X0) =
{
4x1
6x2
}
X0
=
{
4.8
6.6
}
, ∇g(X0) =









− 1
x21
− 1
x22









X0
=
{
−0.69
−0.83
}
Now
x1 = y11(0.8) + y12(1.2) + y13(1.5)
x2 = y21(0.8) + y22(1.1) + y23(1.4)
δx1 = y11(0.8 − 1.2) + y12(1.2 − 1.2) + y13(1.5 − 1.2)
δx2 = y21(0.8 − 1.1) + y22(1.1 − 1.1) + y23(1.4 − 1.1)
f ≈ 6.51 + {4.8 6.6}
{−0.4y11 + 0.3y13
−0.3y21 + 0.3y23
}
g ≈ −2.26 + {−0.69 − 0.83}
{−0.4y11 + 0.3y13
−0.3y21 + 0.3y23
}
Thus the first approximate problem becomes (in terms of the unknowns y11, y12, y13,
y21, y22, and y23):
Minimize f = 6.51 − 1.92y11 + 1.44y13 − 1.98y21 + 1.98y23
subject to
−2.26 + 0.28y11 + 0.21y13 + 0.25y21 − 0.25y23 ≤ 0
y11 + y12 + y13 = 1
y21 + y22 + y23 = 1
yij = 0 or 1, i = 1, 2, j = 1, 2, 3
In this problem, there are only nine possible solutions and hence they can all be
enumerated and the optimum solution can be found as
y11 = 1, y12 = 0, y13 = 0, y21 = 1, y22 = 0, y23 = 0
Thus the solution of the first approximate problem, in terms of original variables, is
given by
x1 = 0.8, x2 = 0.8, f (X) = 2.61, and g(X) = −1.5
This point can be used to generate a second approximate problem and the process can
be repeated until the final optimum solution is found.
10.8 Generalized Penalty Function Method 619
10.8 GENERALIZED PENALTY FUNCTION METHOD
The solution of an integer nonlinear programming problem, based on the concept of
penalty functions, was originally suggested by Gellatly and Marcal in 1967 [10.5].
This approach was later applied by Gisvold and Moe [10.4] and Shin et al. [10.24]
to solve some design problems that have been formulated as nonlinear mixed-integer
programming problems. The method can be considered as an extension of the interior
penalty function approach considered in Section 7.13. To see the details of the approach,
let the problem be stated as follows:
FindX =









x1
x2
...
xn









=
{
Xd
Xc
}
which minimizes f (X)
subject to the constraints (10.72)
gj (X) ≥ 0, j = 1, 2, . . . , m
Xc ∈ Sc and Xd ∈ Sd ,
where the vector of variables (X) is composed of two vectors Xd and Xc, with Xd
representing the set of integer variables and Xc representing the set of continuous
variables. Notice that Xc will not be there if all the variables are constrained to take
only integer values and Xd will not be there if none of the variables is restricted to
take only integer values. The sets Sc and Sd denote the feasible sets of continuous and
integer variables, respectively. To extend the interior penalty function approach to solve
the present problem, given by Eq. (10.72), we first define the following transformed
problem:
Minimize φk(X, rk, sk)
where
φk(X, rk, sk) = f (X) + rk
m
∑
j=1
Gj [gj (X)] + skQk(Xd) (10.73)
In this equation, rk is a weighing factor (penalty parameter) and
rk
m
∑
j=1
Gj [gj (X)]
is the contribution of the constraints to the φk function, which can be taken as
rk
m
∑
j=1
Gj [gj (X)] = +rk
m
∑
j=1
1
gj (X)
(10.74)
It can be noted that this term is positive for all X satisfying the relations gj (X) > 0 and
tends to +∞ if any one particular constraint tends to have a value of zero. This property
ensures that once the minimization of the φk function is started from a feasible point,
620 Integer Programming
the point always remains in the feasible region. The term skQk(Xd) can be considered
as a penalty term with sk playing the role of a weighing factor (penalty parameter). The
function Qk(Xd) is constructed so as to give a penalty whenever some of the variables
in Xd take values other than integer values. Thus the function Qk(Xd) has the property
that
Qk(Xd) =
{
0 if Xd ∈ Sd
µ> 0 if Xd /∈ Sd
(10.75)
We can take, for example,
Qk(Xd) =
∑
xi∈Xd
{
4
(
xi − yi
zi − yi
)(
1 − xi − yi
zi − yi
)}βk
(10.76)
where yi ≤ xi , zi ≥ xi , and βk ≥ 1 is a constant. Here yi and zi are the two neighbor-
ing integer values for the value xi . The function Qk(Xd) is a normalized, symmetric
beta function integrand. The variation of each of the terms under summation sign in
Eq. (10.76) for different values of βk is shown in Fig. 10.9. The value of βk has to be
greater than or equal to 1 if the function Qk is to be continuous in its first derivative
over the discretization or integer points.
The use of the penalty term defined by Eq. (10.76) makes it possible to change
the shape of the φk function by changing βk , while the amplitude can be controlled by
the weighting factor sk . The φk function given in Eq. (10.73) is now minimized for a
sequence of values of rk and sk such that for k → ∞, we obtain
Min φk(X, rk, sk) → Min f (X)
gj (X) ≥ 0, j = 1, 2, . . . , m
Qk(Xd) → 0
(10.77)
In most of the practical problems, one can obtain a reasonably good solution by carrying
out the minimization of φk even for 5 to 10 values of k. The method is illustrated in
Fig. 10.10 in the case of a single-variable problem. It can be noticed from Fig. 10.10
that the shape of the φ function (also called the response function) depends strongly
on the numerical values of rk , sk , and βk .
1.0
1.0
0.5
0.5
0 )(
Ri = [4(
xi − yi
zi − yi
xi − yi
zi − yi
)  )](1−
xi − yi
zi − yi
bk = 1.0
bk = 2.0
bk = 4.0
bk = 6.0
bk = 8.0
bk
Figure 10.9 Contour of typical term in Eq. (10.62) [10.4].
10.8 Generalized Penalty Function Method 621
Figure 10.10 Solution of a single-variable integer problem by penalty function method. x1,
discrete variable; x
j
1 , j th value of x1 [10.4].
Choice of the Initial Values of rk, sk, and βk. The numerical values of rk , sk, and
βk have to be chosen carefully to achieve fast convergence. If these values are chosen
such that they give the response surfaces of φ function as shown in Fig. 10.10c, several
local minima will be introduced and the risk in finding the global minimum point will
be more. Hence the initial value of sk (namely, s1) is to be chosen sufficiently small
to yield a unimodal response surface. This can be achieved by setting
skQ
′
k ≪ P ′k (10.78)
where Q′k is an estimate of the maximum magnitude of the gradient to the Qk surface
and P ′k is a measure of the gradient of the function Pk defined by
Pk = f (X) + rk
m
∑
j=1
Gj [gj (X)] (10.79)
Gisvold and Moe [10.4] have taken the values of Q′k and P
′
k as
Q′k = 12 · 4βkβk(βk − 1)βk−1(2βk − 1)1/2−βk (10.80)
P ′k =
(∇P Tk ∇Pk
n
)1/2
(10.81)
622 Integer Programming
where
∇Pk =









∂Pk/∂x1
∂Pk/∂x2
...
∂Pk/∂xn









(10.82)
The initial value of s1, according to the requirement of Eq. (10.78), is given by
s1 = c1
P ′1(X1, r1)
Q′1(X
(d)
1 , β1)
(10.83)
where X1 is the initial starting point for the minimization of φ1, X
(d)
1 the set of starting
values of integer-restricted variables, and c1 a constant whose value is generally taken
in the range 0.001 and 0.1.
To choose the weighting factor r1, the same consideration as discussed in
Section 7.13 are to be taken into account. Accordingly, the value of r1 is chosen as
r1 = c2
f (X1)
+
∑m
j=1 1/gj (X1)
(10.84)
with the value of c2 ranging between 0.1 and 1.0. Finally, the parameter βk must be
taken greater than 1 to maintain the continuity of the first derivative of the function φk
over the discretization points. Although no systematic study has been conducted to find
the effect of choosing different values for βk , the value of β1 ≃ 2.2 has been found to
give satisfactory convergence in some of the design problems.
Once the initial values of rk , sk , and βk (for k = 1) are chosen, the subsequent
values also have to be chosen carefully based on the numerical results obtained on
similar formulations. The sequence of values rk are usually determined by using the
relation
rk+1 = c3rk, k = 1, 2, . . . (10.85)
where c3 < 1. Generally, the value of c3 is taken in the range 0.05 to 0.5. To select the
values of sk , we first notice that the effect of the term Qk(Xd) is somewhat similar to
that of an equality constraint. Hence the method used in finding the weighting factors
for equality constraints can be used to find the factor sk+1. For equality constraints,
we use
sk+1
sk
= r
1/2
k
r
1/2
k+1
(10.86)
From Eqs. (10.85) and (10.86), we can take
sk+1 = c4sk (10.87)
with c4 approximately lying in the range
√
1/0.5 and
√
1/0.05 (i.e., 1.4 and 4.5). The
values of βk can be selected according to the relation
βk+1 = c5βk (10.88)
with c5 lying in the range 0.7 to 0.9.
10.8 Generalized Penalty Function Method 623
Figure 10.11 Three-bar truss.
A general convergence proof of the penalty function method, including the integer
programming problems, was given by Fiacco [10.6]. Hence the present method is
guaranteed to converge at least to a local minimum if the recovery procedure is applied
the required number of times.
Example 10.6 [10.24] Find the minimum weight design of the three-bar truss shown
in Fig. 10.11 with constraints on the stresses induced in the members. Treat the areas
of cross section of the members as discrete variables with permissible values of the
parameter Aiσmax/P given by 0.1, 0.2, 0.3, 0.5, 0.8, 1.0, and 1.2.
SOLUTION By defining the nondimensional quantities f and xi as
f = Wσmax
Pρl
, xi =
Aiσmax
P
, i = 1, 2, 3
where W is the weight of the truss, σmax the permissible (absolute) value of stress,
P the load, ρ the density, l the depth, and Ai the area of cross section of member
i(i = 1, 2, 3), the discrete optimization problem can be stated as follows:
Minimize f = 2x1 + x2 +
√
2x3
subject to
g1(X) = 1 −
√
3x2 + 1.932x3
1.5x1x2 +
√
2x2x3 + 1.319x1x3
≥ 0
g2(X) = 1 −
0.634x1 + 2.828x3
1.5x1x2 +
√
2x2x3 + 1.319x1x3
≥ 0
624 Integer Programming
g3(X) = 1 −
0.5x1 − 2x2
1.5x1x2 +
√
2x2x3 + 1.319x1x3
≥ 0
g4(X) = 1 +
0.5x1 − 2x2
1.5x1x2 +
√
2x2x3 + 1.319x1x3
≥ 0
xi ∈ {0.1, 0.2, 0.3, 0.5, 0.8, 1.0, 1.2}, i = 1, 2, 3
The optimum solution of the continuous variable problem is given by f ∗ = 2.7336,
x∗1 = 1.1549, x∗2 = 0.4232, and x∗3 = 0.0004. The optimum solution of the discrete
variable problem is given by f ∗ = 3.0414, x∗1 = 1.2, x∗2 = 0.5, and x∗3 = 0.1.
10.9 SOLUTION OF BINARY PROGRAMMING PROBLEMS USING
MATLAB
The MATLAB function bintprog can be used to solve a binary (or zero–one) pro-
gramming problem. The following example illustrates the procedure.
Example 10.7 Find the solution of the following binary programming problem using
the MATLAB function bintprog:
Minimize f (X) = −5x1 − 5x2 − 8x3 + 4x4 + 4x5
subject to
3x1 − 6x2 + 7x3 − 9x4 − 9x5 ≤ −10, x1 + 2x2 − x4 − 3x5 ≤ 0
xi binary; i = 1, 2, 3, 4, 5
SOLUTION
Step 1: State the problem in the form required by the program bintprog:
Minimize f (x) = f Tx subject to Ax ≤ b and Aeqx = beq
Here
f T = {−5 −5 −8 2 4}, x = {x1 x2 x3 x4 x5}T
A =
[
3 −6 7 −9 −9
1 2 0 −1 −3
]
, b =
{−10
0
}
Step 2: The input is directly typed on the MATLAB command window and the program
bintprog is called as indicated below:
clear; clc;
f = [-5 -5 -8 2 4]′;
A = [3 -6 7 -9 -9; 1 2 0 -1 -3];
b = [-10 0]′;
x = bintprog (f, A, b,[])
References and Bibliography 625
Step 3: The output of the program is shown below:
Optimization terminated.
x =
1
1
1
1
1
REFERENCES AND BIBLIOGRAPHY
10.1 M. L. Balinski, Integer programming: methods, uses, computation, Management Science,
Vol. 12, pp. 253–313, 1965.
10.2 L. J. Watters, Reduction of integer polynomial programming problems to zero–one linear
programming problems, Operations Research , Vol. 15, No. 6, pp. 1171–1174, 1967.
10.3 S. Retter and D. B. Rice, Discrete optimizing solution procedures for linear and nonlinear
integer programming problems, Management Science, Vol. 12, pp. 829–850, 1966.
10.4 K. M. Gisvold and J. Moe, A method for nonlinear mixed-integer programming and
its application to design problems, Journal of Engineering for Industry, Transactions of
ASME , Vol. 94, pp. 353–364, May 1972.
10.5 R. A. Gellatly and P. B. Marcal, Investigation of Advanced Spacecraft Structural Design
Technology , NASA Report 2356–950001, 1967.
10.6 A. V. Fiacco, Penalty methods for mathematical programming in En with general con-
straints sets, Journal of Optimization Theory and Applications , Vol. 6, pp. 252–268,
1970.
10.7 R. E. Gomory, An Algorithm for the Mixed Integer Problem , Rand Report R.M. 25797,
July 1960.
10.8 A. H. Land and A. Doig, An automatic method of solving discrete programming prob-
lems, Econometrica , Vol. 28, pp. 497–520, 1960.
10.9 E. Balas, An additive algorithm for solving linear programs with zero–one variables,
Operations Research , Vol. 13, pp. 517–546, 1965.
10.10 R. E. Gomory, An all-integer integer programming algorithm, Chapter 13 in Industrial
Scheduling , J. F. Muth and G. L. Thompson, Eds., Prentice-Hall, Englewood Cliffs, NJ,
1963.
10.11 H. A. Taha, Operations Research: An Introduction , Macmillan, New York, 1971.
10.12 S. Zionts, Linear and Integer Programming , Prentice-Hall, Englewood Cliffs, NJ, 1974.
10.13 C. McMillan, Jr., Mathematical Programming: An Introduction to the Design and Appli-
cation of Optimal Decision Machines , Wiley, New York, 1970.
10.14 N. K. Kwak, Mathematical Programming with Business Applications , McGraw-Hill,
New York, 1973.
10.15 H. Greenberg, Integer Programming , Academic Press, New York, 1971.
10.16 G. B. Dantzig and A. F. Veinott, Jr., Eds., Mathematics of the Decision Sciences , Part
1, American Mathematical Society, Providence, R I, 1968.
10.17 R. S. Garfinkel and G. L. Nemhauser, Integer Programming , Wiley, New York, 1972.
626 Integer Programming
10.18 C. A. Trauth, Jr., and R. E. Woolsey, Integer linear programming: a study in computa-
tional efficiency, Management Science, Vol. 15, No. 9, pp. 481–493, 1969.
10.19 E. L. Lawler and M. D. Bell, A method for solving discrete optimization problems,
Operations Research , Vol. 14, pp. 1098–1112, 1966.
10.20 P. Hansen, Quadratic zero–one programming by implicit enumeration, pp. 265–278 in
Numerical Methods for Nonlinear Optimization , F. A. Lootsma, Ed., Academic Press,
London, 1972.
10.21 R. R. Meyer, Integer and mixed-integer programming models: general properties, Jour-
nal of Optimization Theory and Applications , Vol. 16, pp. 191–206, 1975.
10.22 R. Karni, Integer linear programming formulation of the material requirements planning
problem, Journal of Optimization Theory and Applications , Vol. 35, pp. 217–230, 1981.
10.23 R. J. Dakin, A tree-search algorithm for mixed integer programming problems, Computer
Journal , Vol. 8, No. 3, pp. 250–255, 1965.
10.24 D. K. Shin, Z. Gürdal, and O. H. Griffin, Jr., A penalty approach for nonlinear opti-
mization with discrete design variables, Engineering Optimization , Vol. 16, pp. 29–42,
1990.
10.25 O. K. Gupta and A. Ravindran, Nonlinear mixed integer programming and discrete
optimization, pp. 27–32 in Progress in Engineering Optimization—1981 , R. W. Mayne
and K. M. Ragsdell, Eds., ASME, New York, 1981.
10.26 G. R. Olsen and G. N. Vanderplaats, Method for nonlinear optimization with discrete
variables, AIAA Journal , Vol. 27, No. 11, pp. 1584–1589, 1989.
10.27 K. V. John, C. V. Ramakrishnan, and K. G. Sharma, Optimum design of trusses from
available sections: use of sequential linear programming with branch and bound algo-
rithm, Engineering Optimization , Vol. 13, pp. 119–145, 1988.
10.28 M. W. Cooper, A survey of methods for pure nonlinear integer programming, Manage-
ment Science, Vol. 27, No. 3, pp. 353–361, 1981.
10.29 A. Glankwahmdee, J. S. Liebman, and G. L. Hogg, Unconstrained discrete nonlinear
programming, Engineering Optimization , Vol. 4, pp. 95–107, 1979.
10.30 K. Hager and R. Balling, New approach for discrete structural optimization, ASCE
Journal of the Structural Division , Vol. 114, No. ST5, pp. 1120–1134, 1988.
10.31 S. S. Rao, T. S. Pan, and V. B. Venkayya, Optimal placement of actuators in
actively controlled structures using genetic algorithms, AIAA Journal , Vol. 29, No. 6,
pp. 942–943, 1991.
10.32 R. G. Parker and R. L. Rardin, Discrete Optimization , Academic Press, Boston, 1988.
REVIEW QUESTIONS
10.1 Answer true or false:
(a) The integer and discrete programming problems are one and the same.
(b) Gomory’s cutting plane method is applicable to mixed-integer programming
problems.
(c) The Balas method was developed for the solution of all-integer programming
problems.
(d) The branch-and-bound method can be used to solve zero–one programming
problems.
(e) The branch-and-bound method is applicable to nonlinear integer programming
problems.
Problems 627
10.2 Define the following terms:
(a) Cutting plane
(b) Gomory’s constraint
(c) Mixed-integer programming problem
(d) Additive algorithm
10.3 Give two engineering examples of a discrete programming problem.
10.4 Name two engineering systems for which zero–one programming is applicable.
10.5 What are the disadvantages of truncating the fractional part of a continuous solution for
an integer problem?
10.6 How can you solve an integer nonlinear programming problem?
10.7 What is a branch-and-bound method?
10.8 Match the following methods:
(a) Land and Doig Cutting plane method
(b) Gomory Zero–one programming method
(c) Balas Generalized penalty function method
(d) Gisvold and Moe Branch-and-bound method
(e) Reiter and Rice Generalized quadratic programming method
PROBLEMS
Find the solution for Problems 10.1–10.5 using a graphical procedure.
10.1 Minimize f = 4x1 + 5x2
subject to
3x1 + x2 ≥ 2
x1 + 4x2 ≥ 5
3x1 + 2x2 ≥ 7
x1, x2 ≥ 0, integers
10.2 Maximize f = 4x1 + 8x2
subject to
4x1 + 5x2 ≤ 40
x1 + 2x2 ≤ 12
x1, x2 ≥ 0, integers
628 Integer Programming
10.3 Maximize f = 4x1 + 3x2
subject to
3x1 + 2x2 ≤ 18
x1, x2 ≥ 0, integers
10.4 Maximize f = 3x1 − x2
subject to
3x1 − 2x2 ≤ 3
−5x1 − 4x2 ≤ −10
x1, x2 ≥ 0, integers
10.5 Maximize f = 2x1 + x2
subject to
8x1 + 5x2 ≤ 15
x1, x2 ≥ 0, integers
10.6 Solve the following problem using Gomory’s cutting plane method:
Maximize f = 6x1 + 7x2
subject to
7x1 + 6x2 ≤ 42
5x1 + 9x2 ≤ 45
x1 − x2 ≤ 4
xi ≥ 0 and integer, i = 1, 2
10.7 Solve the following problem using Gomory’s cutting plane method:
Maximize f = x1 + 2x2
subject to
x1 + x2 ≤ 7
2x1 ≤ 11, 2x2 ≤ 7
xi ≥ 0 and integer, i = 1, 2
10.8 Express 187 in binary form.
10.9 Three cities A, B, and C are to be connected by a pipeline. The distances between A and
B, B and C, and C and A are 5, 3, and 4 units, respectively. The following restrictions
are to be satisfied by the pipeline:
1. The pipes leading out of A should have a total capacity of at least 3.
Problems 629
2. The pipes leading out of B or of C should have total capacities of either 2 or 3.
3. No pipe between any two cities must have a capacity exceeding 2.
Only pipes of an integer number of capacity units are available and the cost of a pipe is
proportional to its capacity and to its length. Determine the capacities of the pipe lines
to minimize the total cost.
10.10 Convert the following integer quadratic problem into a zero–one linear programming
problem:
Minimize f = 2x21 + 3x22 + 4x1x2 − 6x1 − 3x2
subject to
x1 + x2 ≤ 1
2x1 + 3x2 ≤ 4
x1, x2 ≥ 0, integers
10.11 Convert the following integer programming problem into an equivalent zero–one pro-
gramming problem:
Minimize f = 6x1 − x2
subject to
3x1 − x2 ≥ 4
2x1 + x2 ≥ 3
−x1 − x2 ≥ −3
x1, x2 nonnegative integers
10.12 Solve the following zero–one programming problem using an exhaustive enumeration
procedure:
Maximize f = −10x1 − 5x2 − 3x3
subject to
x1 + 2x2 + x3 ≥ 4
2x1 + x2 + x3 ≤ 6
xi = 0 or 1, i = 1, 2, 3
10.13 Solve the following binary programming problem using an exhaustive enumeration pro-
cedure:
Minimize f = −5x1 + 7x2 + 10x3 − 3x4 + x5
subject to
x1 + 3x2 − 5x3 + x4 + 4x5 ≤ 0
2x1 + 6x2 − 3x3 + 2x4 + 2x5 ≥ 4
x2 − 2x3 − x4 + x5 ≤ −2
xi = 0 or 1, i = 1, 2, . . . , 5
630 Integer Programming
10.14 Find the solution of Problem 10.1 using the branch-and-bound method coupled with the
graphical method of solution for the branching problems.
10.15 Find the solution of the following problem using the branch-and-bound method coupled
with the graphical method of solution for the branching problems:
Maximize f = x1 − 4x2
subject to
x1 − x2 ≥ −4, 4x1 + 5x2 ≤ 45
5x1 − 2x2 ≤ 20, 5x1 + 2x2 ≥ 10
xi ≥ 0 and integer, i = 1, 2
10.16 Solve the following mixed integer programming problem using a graphical method:
Minimize f = 4x1 + 5x2
subject to
10x1 + x2 ≥ 10, 5x1 + 4x2 ≥ 20
3x1 + 7x2 ≥ 21, x2 + 12x2 ≥ 12
x1 ≥ 0 and integer, x2 ≥ 0
10.17 Solve Problem 10.16 using the branch-and-bound method coupled with a graphical
method for the solution of the branching problems.
10.18 Convert the following problem into an equivalent zero–one LP problem:
Maximize f = x1x2
subject to
x21 + x22 ≤ 25, xi ≥ 0 and integer, i = 1, 2
10.19 Consider the discrete variable problem:
Maximize f = x1x2
subject to
x21 + x22 ≤ 4
x1 ∈ {0.1, 0.5, 1.1, 1.6, 2.0}
x2 ∈ {0.4, 0.8, 1.5, 2.0}
Approximate this problem as a zero–one LP problem at the vector, X0 =
{
1.1
0.8
}
.
Problems 631
10.20 Find the solution of the following problem using a graphical method based on the
generalized penalty function approach:
Minimize f = x
subject to
x − 1 ≥ 0 with x = {1, 2, 3, . . .}
Select suitable values of rk and sk to construct the φk function.
10.21 Find the solution of the following binary programming problem using the MATLAB
function bintprog:
Minimize f Tx subject to Ax ≤ b and Aeq x = beq
where
A =







−1 1 0 0 0 0 0 0 0
0 −1 1 0 0 0 0 0 0
0 0 0 −1 1 0 0 0 0
0 0 0 0 −1 1 0 0 0
0 0 0 0 0 0 −1 1 0
0 0 0 0 0 0 0 −1 1







, b =













0
0
0
0
0
0













Aeq = [1 1 1 1 1 1 1 1 1] and beq = {5}
10.22 Find the solution of the following binary programming problem using the MATLAB
function bintprog:
Minimize f Tx subject to Ax ≤ b
where
f T = {−2 −3 −1 −4 −3 −2 −2 −1 −3}
x = {x1 x2 x3 x4 x5 x6 x7 x8 x9}T
A =






0 −3 0 −1 −1 0 0 0 0
1 1 0 0 0 0 0 0 0
0 1 0 1 −1 −1 0 0 0
0 −1 0 0 0 −2 −3 −1 −2
0 0 −1 0 2 1 2 −2 1






, b =











−3
1
−1
−4
5











11
Stochastic Programming
11.1 INTRODUCTION
Stochastic or probabilistic programming deals with situations where some or all of
the parameters of the optimization problem are described by stochastic (or random or
probabilistic) variables rather than by deterministic quantities. The sources of random
variables may be several, depending on the nature and the type of problem. For instance,
in the design of concrete structures, the strength of concrete is a random variable since
the compressive strength of concrete varies considerably from sample to sample. In
the design of mechanical systems, the actual dimension of any machined part is a
random variable since the dimension may lie anywhere within a specified (permissible)
tolerance band. Similarly, in the design of aircraft and rockets the actual loads acting
on the vehicle depend on the atmospheric conditions prevailing at the time of the flight,
which cannot be predicted precisely in advance. Hence the loads are to be treated as
random variables in the design of such flight vehicles.
Depending on the nature of equations involved (in terms of random variables) in
the problem, a stochastic optimization problem is called a stochastic linear, geometric,
dynamic, or nonlinear programming problem. The basic idea used in stochastic pro-
gramming is to convert the stochastic problem into an equivalent deterministic problem.
The resulting deterministic problem is then solved by using familiar techniques such as
linear, geometric, dynamic, and nonlinear programming. A review of the basic concepts
of probability theory that are necessary for understanding the techniques of stochastic
programming is given in Section 11.2. The stochastic linear, nonlinear, and geometric
programming techniques are discussed in subsequent sections.
11.2 BASIC CONCEPTS OF PROBABILITY THEORY
The material of this section is by no means exhaustive of probability theory. Rather,
it provides the basic background necessary for the continuity of presentation of this
chapter. The reader interested in further details should consult Parzen [11.1], Ang and
Tang [11.2], or Rao [11.3].
11.2.1 Definition of Probability
Every phenomenon in real life has a certain element of uncertainty. For example,
the wind velocity at a particular locality, the number of vehicles crossing a bridge,
the strength of a beam, and the life of a machine cannot be predicted exactly. These
632 Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
11.2 Basic Concepts of Probability Theory 633
phenomena are chance dependent and one has to resort to probability theory to describe
the characteristics of such phenomena.
Before introducing the concept of probability, it is necessary to define certain terms
such as experiment and event. An experiment denotes the act of performing something
the outcome of which is subject to uncertainty and is not known exactly. For example,
tossing a coin, rolling a die, and measuring the yield strength of steel can be called
experiments. The number of possible outcomes in an experiment may be finite or
infinite, depending on the nature of the experiment. The outcome is a head or a tail
in the case of tossing a coin, and any one of the numbers 1, 2, 3, 4, 5, and 6 in the
case of rolling a die. On the other hand, the outcome may be any positive real number
in the case of measuring the yield strength of steel. An event represents the outcome
of a single experiment. For example, realizing a head on tossing a coin, getting the
number 3 or 5 on rolling a die, and observing the yield strength of steel to be greater
than 20,000 psi in measurement can be called events.
The probability is defined in terms of the likelihood of a specific event. If E
denotes an event, the probability of occurrence of the event E is usually denoted by
P(E). The probability of occurrence depends on the number of observations or trials.
It is given by
P(E) = lim
n→∞
m
n
(11.1)
where m is the number of successful occurrences of the event E and n is the total
number of trials. From Eq. (11.1) we can see that probability is a nonnegative number
and
0 ≤ P(E) ≤ 1.0 (11.2)
where P(E) = 0 denotes that the event is impossible to realize while P(E) = 1.0
signifies that it is certain to realize that event. For example, the probability associated
with the event of realizing both the head and the tail on tossing a coin is zero (impossible
event), while the probability of the event that a rolled die will show up any number
between 1 and 6 is 1 (certain event).
Independent Events. If the occurrence of an event E1 in no way affects the probabil-
ity of occurrence of another event E2, the events E1 and E2 are said to be statistically
independent . In this case the probability of simultaneous occurrence of both the events
is given by
P(E1E2) = P(E1)P (E2) (11.3)
For example, if P(E1) = P (raining at a particular location) = 0.4 and P(E2) =
P (realizing the head on tossing a coin) = 0.7, obviously E1 and E2 are statistically
independent and
P(E1E2) = P(E1)P (E2) = 0.28
11.2.2 Random Variables and Probability Density Functions
An event has been defined as a possible outcome of an experiment. Let us assume that
a random event is the measurement of a quantity X, which takes on various values in
634 Stochastic Programming
the range −∞ to ∞. Such a quantity (like X) is called a random variable. We denote
a random variable by a capital letter and the particular value taken by it by a lowercase
letter. Random variables are of two types: (1) discrete and (2) continuous. If the random
variable is allowed to take only discrete values x1, x2, . . . , xn, it is called a discrete
random variable. On the other hand, if the random variable is permitted to take any
real value in a specified range, it is called a continuous random variable. For example,
the number of vehicles crossing a bridge in a day is a discrete random variable,
whereas the yield strength of steel can be treated as a continuous random variable.
Probability Mass Function (for Discrete Random Variables). Corresponding to each
xi that a discrete random variable X can take, we can associate a probability of occur-
rence P(xi). We can describe the probabilities associated with the random variable X
by a table of values, but it will be easier to write a general formula that permits one to
calculate P(xi) by substituting the appropriate value of xi . Such a formula is called the
probability mass function of the random variable X and is usually denoted as fX(xi),
or simply as f (xi). Thus the function that gives the probability of realizing the random
variable X = xi is called the probability mass function fX(xi). Therefore,
f (xi) = fX(xi) = P(X = xi) (11.4)
Cumulative Distribution Function (Discrete Case). Although a random variable X
is described completely by the probability mass function, it is often convenient to
deal with another, related function known as the probability distribution function. The
probability that the value of the random variable X is less than or equal to some number
x is defined as the cumulative distribution function FX(x).
FX(x) = P(X ≤ x) =
∑
i
fX(xi) (11.5)
where summation expends over those values of i such that xi ≤ x. Since the distribu-
tion function is a cumulative probability, it is also called the cumulative distribution
function.
Example 11.1 Find the probability mass and distribution functions for the number
realized when a fair die is thrown.
SOLUTION Since each face is equally likely to show up, the probability of realizing
any number between 1 and 6 is 1
6
.
P(X = 1) = P(X = 2) = · · · = P(X = 6) = 1
6
fX(1) = fX(2) = · · · = fX(6) = 16
The analytical form of FX (x) is
FX(x) =
x
6
for 1 ≤ x ≤ 6
It can be seen that for any discrete random variable, the distribution function will
be a step function. If the least possible value of a variable X is S and the greatest
11.2 Basic Concepts of Probability Theory 635
possible value is T , then
FX(x) = 0 for all x < S and FX(x) = 1 for all x >T
Probability Density Function (Continuous Case). The probability density function
of a random variable is defined by
fX(x) dx = P(x ≤ X ≤ x + dx) (11.6)
which is equal to the probability of detecting X in the infinitesimal interval (x, x+
dx ). The distribution function of X is defined as the probability of detecting X less
than or equal to x, that is,
FX(x) =
∫ x
−∞
fX(x
′) dx′ (11.7)
where the condition FX(–∞) = 0 has been used. As the upper limit of the integral
goes to infinity, we have
∫ ∞
−∞
fX(x) dx = FX(∞) = 1 (11.8)
This is called the normalization condition . A typical probability density function and
the corresponding distribution functions are shown in Fig. 11.1.
11.2.3 Mean and Standard Deviation
The probability density or distribution function of a random variable contains all the
information about the variable. However, in many cases we require only the gross
properties, not entire information about the random variable. In such cases one computes
only the mean and the variation about the mean of the random variable as the salient
features of the variable.
Mean. The mean value (also termed the expected value or average) is used to
describe the central tendency of a random variable.
Figure 11.1 Probability density and distribution functions of a continuous random variable X:
(a) density function; (b) distribution function.
636 Stochastic Programming
Discrete Case. Let us assume that there are n trials in which the random variable
X is observed to take on the value x1 (n1 times), x2 (n2 times), and so on, and
n1 + n2 + · · · + nm = n. Then the arithmetic mean of X, denoted as X, is given by
X =
∑m
k=1 xknk
n
=
m
∑
k=1
xk
nk
n
=
m
∑
k=1
xkfX(xk) (11.9)
where nk/n is the relative frequency of occurrence of xk and is same as the probability
mass function fX(xk). Hence in general, the expected value, E(X), of a discrete random
variable can be expressed as
X = E(X) =
∑
i
xifX(xi), sum over all i (11.10)
Continuous Case. If fX(x) is the density function of a continuous random variable,
X, the mean is given by
X = µx = E(X) =
∫ ∞
−∞
xfX(x) dx (11.11)
Standard Deviation. The expected value or mean is a measure of the central
tendency, indicating the location of a distribution on some coordinate axis. A measure
of the variability of the random variable is usually given by a quantity known as the
standard deviation . The mean-square deviation or variance of a random variable X is
defined as
σ 2X = Var(X) = E[(X − µX)
2]
= E[X2 − 2XµX + µ2X]
= E(X2) − 2µXE(X) + E(µ2X)
= E(X2) − µ2X (11.12)
and the standard deviation as
σX = +
√
Var(X) =
√
E(X2) − µ2X (11.13)
The coefficient of variation (a measure of dispersion in nondimensional form) is
defined as
coefficient of variation of X = γX =
standard deviation
mean
=
σX
µX
(11.14)
Figure 11.2 shows two density functions with the same mean µX but with different
variances. As can be seen, the variance measures the breadth of a density function.
Example 11.2 The number of airplane landings at an airport in a minute (X) and
their probabilities are given by
xi 0 1 2 3 4 5 6
pX(xi) 0.02 0.15 0.22 0.26 0.17 0.14 0.04
Find the mean and standard deviation of X.
11.2 Basic Concepts of Probability Theory 637
Figure 11.2 Two density functions with same mean.
SOLUTION
X =
6
∑
i=0
xipX(xi) = 0(0.02) + 1(0.15) + 2(0.22) + 3(0.26)
+ 4(0.17) + 5(0.14) + 6(0.04)
= 2.99
X2 =
6
∑
i=0
x2i pX(xi) = 0(0.02) + 1(0.15) + 4(0.22) + 9(0.26)
+ 16(0.17) + 25(0.14) + 36(0.04)
= 11.03
Thus
σ 2X = X 2 − (X)
2 = 11.03 − (2.99)2 = 2.0899 or σX = 1.4456
Example 11.3 The force applied on an engine brake (X) is given by
fX(x) =







x
48
, 0 ≤ x ≤ 8 lb
12 − x
24
, 8 ≤ x ≤ 12 lb
Determine the mean and standard deviation of the force applied on the brake.
SOLUTION
µX = E[X] =
∫ ∞
−∞
xfX(x) dx =
∫ 8
0
x
x
48
dx +
∫ 12
8
x
12 − x
24
dx = 6.6667
E[X2] =
∫ ∞
−∞
x2fX(x) dx =
∫ 8
0
x2
x
48
dx +
∫ 12
8
x2
12 − x
24
dx
638 Stochastic Programming
= 21.3333 + 29.3333 = 50.6666
σ 2X = E[X
2] − (E[X])2 = 50.6666 − (6.6667)2
= 6.2222 or σX = 2.4944
11.2.4 Function of a Random Variable
If X is a random variable, any other variable Y defined as a function of X will also be
a random variable. If fX(x) and FX(x) denote, respectively, the probability density and
distribution functions of X, the problem is to find the density function fY (y) and the
distribution function FY (y) of the random variable Y . Let the functional relation be
Y = g(X) (11.15)
By definition, the distribution function of Y is the probability of realizing Y less than
or equal to y:
FY (y) = P(Y ≤ y) = P(g ≤ y)
=
∫
g(x)≤ y
fX(x) dx (11.16)
where the integration is to be done over all values of x for which g(x) ≤ y.
For example, if the functional relation between y and x is as shown in Fig. 11.3,
the range of integration is shown as x1 + x2 + x3 + · · ·. The probability density
function of Y is given by
fY (y) =
∂
∂y
[FY (y)] (11.17)
If Y = g(X), the mean and variance of Y are defined, respectively, by
E(Y ) =
∫ ∞
−∞
g(x)fX(x) dx (11.18)
Var[Y ] =
∫ ∞
−∞
[g(x) − E(Y )]2fX(x) dx (11.19)
Figure 11.3 Range of integration in Eq. (11.16).
11.2 Basic Concepts of Probability Theory 639
11.2.5 Jointly Distributed Random Variables
When two or more random variables are being considered simultaneously, their joint
behavior is determined by a joint probability distribution function. The probability
distributions of single random variables are called univariate distributions and the
distributions that involve two random variables are called bivariate distributions . In
general, if a distribution involves more than one random variable, it is called a multi-
variate distribution .
Joint Density and Distribution Functions. We can define the joint density function
of n continuous random variables X1, X2, . . . , Xn as
fX1,...,Xn(x1, . . . , xn) dx1 · · · dxn = P(x1 ≤ X1 ≤ x1 + dx1,
x2 ≤ X2 ≤ x2 + dx2, . . . , xn ≤ Xn ≤ xn + dxn) (11.20)
If the random variables are independent, the joint density function is given by the
product of individual or marginal density functions as
fX1,...,Xn(x1, . . . , xn) = fX1(x1) · · · fXn(xn) (11.21)
The joint distribution function
FX1,X2,...,Xn(x1, x2, . . . , xn)
associated with the density function of Eq. (11.20) is given by
FX1,...,Xn(x1, . . . , xn)
= P [X1 ≤ x1, . . . , Xn ≤ xn]
=
∫ x1
−∞
· · ·
∫ xn
−∞
fX1,...,Xn (x
′
1, x
′
2, . . . , x
′
n) dx
′
1 dx
′
2 · · · dx
′
n (11.22)
If X1, X2, . . . , Xn are independent random variables, we have
FX1,...,Xn (x1, . . . , xn) = FX1(x1) FX2(x2) · · · FXn(xn) (11.23)
It can be seen that the joint density function can be obtained by differentiating the joint
distribution function as
fX1,...,Xn(x1, . . . , xn) =
∂n
∂x1 ∂x2 · · · ∂xn
FX1,...,Xn(x1, . . . , xn) (11.24)
Obtaining the Marginal or Individual Density Function from the Joint Density
Function. Let the joint density function of two random variables X and Y be denoted
by f (x, y) and the marginal density functions of X and Y by fX(x) and fY (y), respec-
tively. Take the infinitesimal rectangle with corners located at the points (x, y), (x + dx,
y), (x, y + dy), and (x + dx, y + dy). The probability of a random point (x′, y′) falling
in this rectangle is fX,Y (x, y) dx dy . The integral of such probability elements with
respect to y (for a fixed value of x) is the sum of the probabilities of all the mutually
640 Stochastic Programming
exclusive ways of obtaining the points lying between x and x + dx. Let the lower and
upper limits of y be a1(x) and b1(x). Then
P [x ≤ x′ ≤ x + dx] =
[∫ b1(x)
a1(x)
fX,Y (x, y) dy
]
dx = fX(x) dx
fX(x) =
∫ y2=b1(x)
y1=a1(x)
fX,Y (x, y) dy (11.25)
Similarly, we can show that
fY (y) =
∫ x2=b2(y)
x1=a2(y)
fX,Y (x, y) dx (11.26)
11.2.6 Covariance and Correlation
If X and Y are two jointly distributed random variables, the variances of X and Y are
defined as
E[(X − X)2] = Var[X] =
∫ ∞
−∞
(x − X)2fX(x) dx (11.27)
E[(Y − Y)2] = Var[Y ] =
∫ ∞
−∞
(y − Y )2fY (y) dy (11.28)
and the covariance of X and Y as
E[(X − X)(Y − Y )] = Cov(X, Y )
=
∫ ∞
−∞
∫ ∞
−∞
(x − X)(y − Y )fX,Y (x, y)dxdy
= σX,Y (11.29)
The correlation coefficient, ρX,Y , for the random variables is defined as
ρX,Y =
Cov(X, Y )
σXσY
(11.30)
and it can be proved that −1 ≤ ρX,Y ≤ 1.
11.2.7 Functions of Several Random Variables
If Y is a function of several random variables X1, X2, . . . , Xn, the distribution and den-
sity functions of Y can be found in terms of the joint density function of X1, X2, . . . , Xn
as follows:
Let
Y = g(X1, X2, . . . , Xn) (11.31)
11.2 Basic Concepts of Probability Theory 641
Then the joint distribution function FY (y), by definition, is given by
FY (y) = P(Y ≤ y)
=
∫
x1
∫
x2
· · ·
∫
xn
fX1,X2,...,Xn(x1, x2, . . . , xn)dx1 dx2 · · · dxn
g(x1,x2,...,xn) ≤ y (11.32)
where the integration is to be done over the domain of the n-dimensional
(X1,X2, . . . , Xn) space in which the inequality g(x1, x2, . . . , xn) ≤ y is satisfied. By
differentiating Eq. (11.32), we can get the density function of y, fY (y).
As in the case of a function of a single random variable, the mean and variance
of a function of several random variables are given by
E(Y ) = E[g(X1, X2, . . . , Xn)] =
∫ ∞
−∞
· · ·
∫ ∞
−∞
g(x1, x2, . . . ,xn)fX1,X2,...,Xn
× (x1, x2, . . . , xn)dx1 dx2 · · · dxn (11.33)
and
Var(Y ) =
∫ ∞
−∞
· · ·
∫ ∞
−∞
[g(x1, x2, . . . , xn) − Y ]
2
× fX1,X2...Xn(x1, x2, . . . , xn)dx1 dx2 · · · dxn (11.34)
In particular, if Y is a linear function of two random variables X1 and X2, we have
Y = a1X1 + a2X2
where a1 and a2 are constants. In this case
E(Y ) =
∫ ∞
−∞
∫ ∞
−∞
(a1x1 + a2x2)fX1,X2(x1, x2)dx1 dx2
= a1
∫ ∞
−∞
x1fX1(x1)dx1 + a2
∫ ∞
−∞
x2fX2(x2)dx2
= a1E(X1) + a2E(X2) (11.35)
Thus the expected value of a sum is given by the sum of the expected values. The
variance of Y can be obtained as
Var(Y ) = E[(a1X1 + a2X2) − (a1X + a2X2)]2
= E[a1(X1 − X1) + a2(X2 − X2)]2
= E[a21(X1 − X1)
2 + 2a1a2(X1 − X1)(X2 − X2) + a22(X2 − X2)
2] (11.36)
Noting that the expected values of the first and the third terms are variances, whereas
that the middle term is a covariance, we obtain
Var(Y ) = a21 Var(X1) + a
2
2 Var(X2) + 2a1a2 Cov(X1, X2) (11.37)
642 Stochastic Programming
These results can be generalized to the case when Y is a linear function of several
random variables. Thus if
Y =
n
∑
i=1
aiXi (11.38)
then
E(Y ) =
n
∑
i=1
aiE(Xi) (11.39)
Var(Y ) =
n
∑
i=1
a2i Var(Xi) +
n
∑
i=1
n
∑
j=1
aiaj Cov(Xi, Xj ), i = j (11.40)
Approximate Mean and Variance of a Function of Several Random Variables.
If Y = g(X1, . . . , Xn), the approximate mean and variance of Y can be obtained as
follows. Expand the function g in a Taylor series about the mean values X1, X2, . . . , Xn
to obtain
Y = g(X1, X2, . . . , Xn) +
n
∑
i=1
(Xi − Xi)
∂g
∂Xi
+
1
2
n
∑
i=1
n
∑
j=1
(Xi − Xi) (Xj − Xj )
∂2g
∂Xi∂Xj
+ · · · (11.41)
where the derivatives are evaluated at (X1, X2, . . . , Xn). By truncating the series at
the linear terms, we obtain the first-order approximation to Y as
Y ≃ g(X1, X2, . . . , Xn) +
n
∑
i=1
(Xi − Xi)
∂g
∂Xi
∣
∣
∣
∣
(X1,X2,...,Xn)
(11.42)
The mean and variance of Y given by Eq. (11.42) can now be expressed as [using
Eqs. (11.39) and (11.40)]
E(Y ) ≃ g(X1,X2, . . . , Xn) (11.43)
Var(Y ) ≃
n
∑
i=1
c2i Var(Xi) +
n
∑
i=1
n
∑
j=1
cicj Cov(Xi ,Xj ), i = j (11.44)
where ci and cj are the values of the partial derivatives ∂g/∂Xi and ∂g/∂Xj , respec-
tively, evaluated at (X1, X2, . . . , Xn).
It is worth noting at this stage that the approximation given by Eq. (11.42)
is frequently used in most of the practical problems to simplify the computations
involved.
11.2 Basic Concepts of Probability Theory 643
11.2.8 Probability Distributions
There are several types of probability distributions (analytical models) for describ-
ing various types of discrete and continuous random variables. Some of the common
distributions are given below:
Discrete case Continuous case
Discrete uniform distribution Uniform distribution
Binomial Normal or Gaussian
Geometric Gamma
Multinomial Exponential
Poisson Beta
Hypergeometric Rayleigh
Negative binomial (or Pascal’s) Weibull
In any physical problem, one chooses a particular type of probability distribution
depending on (1) the nature of the problem, (2) the underlying assumptions associated
with the distribution, (3) the shape of the graph between f (x) or F(x) and x obtained
after plotting the available data, and (4) the convenience and simplicity afforded by the
distribution.
Normal Distribution. The best known and most widely used probability distribution
is the Gaussian or normal distribution. The normal distribution has a probability density
function given by
fX(x) =
1
√
2πσX
e−1/2[(x−µX)/σX]
2
, −∞ < x < ∞ (11.45)
where µX and σX are the parameters of the distribution, which are also the mean and
standard deviation of X, respectively. The normal distribution is often identified as
N (µX, σX).
Standard Normal Distribution. A normal distribution with parameters µX = 0 and
σX = 1, called the standard normal distribution , is denoted as N (0, 1). Thus the density
function of a standard normal variable (Z) is given by
fZ(z) =
1
√
2π
e−(z
2/2), −∞ < z < ∞ (11.46)
The distribution function of the standard normal variable (Z) is often designated as
φ(z) so that, with reference to Fig. 11.4,
φ(z1) = p and z1 = φ−1(p) (11.47)
where p is the cumulative probability. The distribution function N (0, 1) [i.e., φ(z)] is
tabulated widely as standard normal tables . For example, Table 11.1, gives the values
of z, f (z), and φ(z) for positive values of z. This is because the density function is
symmetric about the mean value (z = 0) and hence
f (−z) = f (z) (11.48)
φ(−z) = 1 − φ(z) (11.49)
644 Stochastic Programming
Figure 11.4 Standard normal density function.
By the same token, the values of z corresponding to p < 0.5 can be obtained as
z = φ−1(p) = −φ−1(1 − p) (11.50)
Notice that any normally distributed variable (X) can be reduced to a standard normal
variable by using the transformation
z =
x − µX
σX
(11.51)
For example, if P(a < X ≤ b) is required, we have
P(a < X ≤ b) =
1
σX
√
2π
∫ b
a
e−(1/2)[(x−µX)/σX]
2
dx (11.52)
By using Eq. (11.51) and dx = σX dz , Eq. (11.52) can be rewritten as
P(a < X ≤ b) =
1
√
2π
∫ (b−µX)/σX
(a−µX)/σX
e−z
2/2dz (11.53)
This integral can be recognized to be the area under the standard normal density curve
between (a − µX)/σX and (b − µX)/σX and hence
P(a < X ≤ b) = φ
(
b − µX
σX
)
− φ
(
a − µX
σX
)
(11.54)
Example 11.4 The width of a slot on a duralumin forging is normally distributed.
The specification of the slot width is 0.900 ± 0.005. The parameters µ = 0.9 and
σ = 0.003 are known from past experience in production process. What is the percent
of scrap forgings?
SOLUTION If X denotes the width of the slot on the forging, the usable region is
given by
0.895 ≤ x ≤ 0.905
11.2 Basic Concepts of Probability Theory 645
Table 11.1 Standard Normal Distribution Table
z f (z) φ(z)
0.0 0.398942 0.500000
0.1 0.396952 0.539828
0.2 0.391043 0.579260
0.3 0.381388 0.617912
0.4 0.368270 0.655422
0.5 0.352065 0.691463
0.6 0.333225 0.725747
0.7 0.312254 0.758036
0.8 0.289692 0.788145
0.9 0.266085 0.815940
1.0 0.241971 0.841345
1.1 0.217852 0.864334
1.2 0.194186 0.884930
1.3 0.171369 0.903199
1.4 0.149727 0.919243
1.5 0.129518 0.933193
1.6 0.110921 0.945201
1.7 0.094049 0.955435
1.8 0.078950 0.964070
1.9 0.065616 0.971284
2.0 0.053991 0.977250
2.1 0.043984 0.982136
2.2 0.035475 0.986097
2.3 0.028327 0.989276
2.4 0.022395 0.991802
2.5 0.017528 0.993790
2.6 0.013583 0.995339
2.7 0.010421 0.996533
2.8 0.007915 0.997445
2.9 0.005952 0.998134
3.0 0.004432 0.998650
3.5 0.000873 0.999767
4.0 0.000134 0.999968
4.5 0.000016 0.999996
5.0 0.0000015 0.9999997
and the amount of scrap is given by
scrap = P(x ≤ 0.895) + P(x ≥ 0.905)
In terms of the standardized normal variable,
scrap = P
(
Z ≤
−0.9 + 0.895
0.003
)
+ P
(
Z ≥
−0.9 + 0.905
0.003
)
= P(Z ≤ −1.667) + P(Z ≥ +1.667)
646 Stochastic Programming
= [1 − P(Z ≤ 1.667)] + [1 − P(Z ≤ 1.667)]
= 2.0 − 2P(Z ≤ 1.667)
= 2.0 − 2(0.9525) = 0.095
= 9.5 %
Joint Normal Density Function. If X1, X2, . . . , Xn follow normal distribution, any
linear function, Y = a1X1 + a2X2 + · · · + anXn, also follows normal distribution with
mean
Y = a1X1 + a2X2 + · · · + anXn (11.55)
and variance
Var(Y ) = a21 Var(X1) + a
2
2 Var(X2) + · · · + a
2
n Var(Xn) (11.56)
if X1,X2, . . . , Xn are independent. In general, the joint normal density function for
n-independent random variables is given by
fX1,X2,...,Xn(x1, x2, . . . , xn) =
1
√
(2π)nσ1σ2 · · · σn
exp

−
1
2
n
∑
k=1
(
xk − Xk
σk
)2


= fX1(x1)fX2(x2) · · · fXn(xn) (11.57)
where σi = σXi . If the correlation between the random variables Xk and Xj is not zero,
the joint density function is given by
fX1,X2,...,Xn(x1, x2, . . . , xn)
=
1
√
(2π)n|K|
exp

−
1
2
n
∑
j=1
n
∑
k=1
{K−1}jk(xj − Xj )(xk − Xk)

 (11.58)
where
KXj Xk = Kjk = E[(xj − Xj )(xk − Xk)]
=
∫ ∞
−∞
∫ ∞
−∞
(xj − Xj )(xk − Xk)fXj ,Xk (xj , xk)dxjdxk
= convariance between Xj and Xk
K = correlation matrix =






K11 K12 · · · K1n
K21 K22 · · · K2n
...
Kn1 Kn2 · · · Knn






(11.59)
and {K−1}jk = jkth element of K−1. It is to be noted that KXj Xk = 0 for j = k and =
σ 2Xj for j = k in case there is no correlation between Xj and Xk .
11.3 Stochastic Linear Programming 647
11.2.9 Central Limit Theorem
If X1,X2, . . . , Xn are n mutually independent random variables with finite mean and
variance (they may follow different distributions), the sum
Sn =
n
∑
i=1
Xi (11.60)
tends to a normal variable if no single variable contributes significantly to the sum as
n tends to infinity. Because of this theorem, we can approximate most of the physical
phenomena as normal random variables. Physically, Sn may represent, for example, the
tensile strength of a fiber-reinforced material, in which case the total tensile strength
is given by the sum of the tensile strengths of individual fibers. In this case the ten-
sile strength of the material may be represented as a normally distributed random
variable.
11.3 STOCHASTIC LINEAR PROGRAMMING
A stochastic linear programming problem can be stated as follows:
Minimize f (X) = CT X =
n
∑
j=1
cjxj (11.61)
subject to
ATi X =
n
∑
j=1
aijxj ≤ bi, i = 1, 2, . . . , m (11.62)
xj ≥ 0, j = 1, 2, . . . , n (11.63)
where cj , aij , and bi are random variables (the decision variables xj are assumed to
be deterministic for simplicity) with known probability distributions. Several methods
are available for solving the problem stated in Eqs. (11.61) to (11.63). We consider a
method known as the chance-constrained programming technique, in this section.
As the name indicates, the chance-constrained programming technique can be used
to solve problems involving chance constraints, that is, constraints having finite proba-
bility of being violated. This technique was originally developed by Charnes and Cooper
[11.5]. In this method the stochastic programming problem is stated as follows:
Minimize f (X) =
n
∑
j=1
cjxj (11.64)
subject to
P


n
∑
j=1
aijxj ≤ bi

 ≥ pi, i = 1, 2, . . . , m (11.65)
xj ≥ 0, j = 1, 2, . . . , n (11.66)
648 Stochastic Programming
where cj , aij , and bi are random variables and pi are specified probabilities. Notice
that Eqs. (11.65) indicate that the ith constraint,
n
∑
j=1
aijxj ≤ bi
has to be satisfied with a probability of at least pi where 0 ≤ pi ≤ 1. For simplicity,
we assume that the design variables xj are deterministic and cj , aij , and bi are random
variables. We shall further assume that all the random variables are normally distributed
with known mean and standard deviations.
Since cj are normally distributed random variables, the objective function f (X)
will also be a normally distributed random variable. The mean and variance of f are
given by
f =
n
∑
j=1
cjxj (11.67)
Var(f ) = XT VX (11.68)
where cj is the mean value of cj and the matrix V is the covariance matrix of cj
defined as
V =






Var(c1) Cov(c1, c2) · · · Cov(c1, cn)
Cov(c2, c1) Var(c2) · · · Cov(c2, cn)
...
Cov(cn, c1) Cov(cn, c2) · · · Var(cn)






(11.69)
with Var(cj ) and Cov(ci, cj ) denoting the variance of cj and covariance between ci
and cj , respectively. A new deterministic objective function for minimization can be
formulated as
F(X) = k1f + k2
√
Var(f ) (11.70)
where k1 and k2 are nonnegative constants whose values indicate the relative importance
of f and standard deviation of f for minimization. Thus k2 = 0 indicates that the
expected value of f is to be minimized without caring for the standard deviation of
f . On the other hand, if k1 = 0, it indicates that we are interested in minimizing the
variability of f about its mean value without bothering about what happens to the mean
value of f . Similarly, if k1 = k2 = 1, it indicates that we are giving equal importance
to the minimization of the mean as well as the standard deviation of f . Notice that the
new objective function stated in Eq. (11.70) is a nonlinear function in X in view of the
expression for the variance of f .
The constraints of Eq. (11.65) can be expressed as
P [hi ≤ 0] ≥ pi, i = 1, 2, . . . , m (11.71)
11.3 Stochastic Linear Programming 649
where hi is a new random variable defined as
hi =
n
∑
j=1
aijxj − bi =
n+1
∑
k=1
qikyk (11.72)
where
qik = aik, k = 1, 2, . . . , n qi,n+1 = bi
yk = xk, k = 1, 2, . . . , n, yn+1 = −1
Notice that the constant yn+1 is introduced for convenience. Since hi is given by a
linear combination of the normally distributed random variables qik , it will also follow
normal distribution. The mean and the variance of hi are given by
hi =
n+1
∑
k=1
q ikyk =
n
∑
j=1
aijxj − bi (11.73)
Var(hi) = YT ViY (11.74)
where
Y =









y1
y2
...
yn+1









(11.75)
Vi =






Var(qi1) Cov(qi1, qi2) · · · Cov(qi1, qi,n+1)
Cov(qi2, qi1) Var(qi2) · · · Cov(qi2, qi,n+1)
...
Cov(qi,n+1, qi1) Cov(qi,n+1, qi2) · · · Var(qi,n+1)






(11.76)
This can be written more explicitly as
Var(hi) =
n+1
∑
k=1
[
y2k Var(qik) + 2
n+1
∑
l=k+1
ykyl Cov(qik, qil)
]
=
n
∑
k=1
[
y2k Var(qik) + 2
n
∑
l=k+1
ykyl Cov(qik, qil)
]
+ y2n+1 Var(qi,n+1) + 2y
2
n+1 Cov(qi,n+1, qi,n+1)
+
n
∑
k=1
[2ykyn+1 Cov(qik, qi,n+1)]
650 Stochastic Programming
=
n
∑
k=1
[
x2k Var(aik) + 2
n
∑
l=k+1
xkxl Cov(aik, ail)
]
+ Var(bi) − 2
n
∑
k=1
xk Cov(aik, bi) (11.77)
Thus the constraints in Eqs. (11.71) can be restated as
P
[
hi − hi√
Var(hi)
≤
−hi√
Var(hi)
]
≥ pi, i = 1, 2, . . . , m (11.78)
where [(hi − hi)]/
√
Var(hi) represents a standard normal variable with a mean value
of zero and a variance of 1.
Thus if si denotes the value of the standard normal variable at which
φ(si) = pi (11.79)
the constraints of Eq. (11.78) can be stated as
φ
(
−hi√
Var(hi)
)
≥ φ(si), i = 1, 2, . . . , m (11.80)
These inequalities will be satisfied only if the following deterministic nonlinear inequal-
ities are satisfied:
−hi√
Var(hi)
≥ si, i = 1, 2, . . . , m
or
hi + si
√
Var(hi) ≤ 0, i = 1, 2, . . . , m (11.81)
Thus the stochastic linear programming problem of Eqs. (11.64) to (11.66) can be
stated as an equivalent deterministic nonlinear programming problem as
Minimize F(X) = k1
n
∑
j=1
cjxj + k2
√
XT VX, k1 ≥ 0, k2 ≥ 0,
subject to
hi + si
√
Var(hi) ≤ 0, i = 1, 2, . . . , m
xj ≥ 0, j = 1, 2, . . . , n (11.82)
Example 11.5 A manufacturing firm produces two machine parts using lathes, milling
machines, and grinding machines. If the machining times required, maximum times
available, and the unit profits are all assumed to be normally distributed random vari-
ables with the following data, find the number of parts to be manufactured per week
to maximize the profit. The constraints have to be satisfied with a probability of at
least 0.99.
11.3 Stochastic Linear Programming 651
Machining time required per unit (min) Maximum time
available
Part I Part II per week (min)
Type of
machine Mean
Standard
deviation Mean
Standard
deviation Mean
Standard
deviation
Lathes a11 = 10 σa11 = 6 a12 = 5 σa12 = 4 b1 = 2500 σb1 = 500
Milling
machines a21 = 4 σa21 = 4 a22 = 10 σa22 = 7 b2 = 2000 σb2 = 400
Grinding
machines a31 = 1 σa31 = 2 a32 = 1.5 σa32 = 3 b3 = 450 σb3 = 50
Profit per unit c1 = 50 σc1 = 20 c2 = 100 σc2 = 50
SOLUTION By defining new random variables hi as
hi =
n
∑
j=1
aijxj − bi,
we find that hi are also normally distributed. By assuming that there is no correlation
between aij ’s and bi’s, the means and variances of hi can be obtained from Eqs. (11.73)
and (11.77) as
h1 = a11x1 + a12x2 − b1 = 10x1 + 5x2 − 2500
h2 = a21x1 + a22x2 − b2 = 4x1 + 10x2 − 2000
h3 = a31x1 + a32x2 − b3 = x1 + 1.5x2 − 450
σ 2h1 = x
2
1σ
2
a11
+ x22σ
2
a12
+ σ 2b1 = 36x
2
1 + 16x
2
2 + 250,000
σ 2h2 = x
2
1σ
2
a21
+ x22σ
2
a22
+ σ 2b2 = 16x
2
1 + 49x
2
2 + 160,000
σ 2h3 = x
2
1σ
2
a31
+ x22σ
2
a32
+ σ 2b3 = 4x
2
1 + 9x
2
2 + 2500
Assuming that the profits are independent random variables, the covariance matrix of
cj is given by
V =
[
Var(c1) 0
0 Var(c2)
]
=
[
400 0
0 2500
]
and the variance of the objective function by
Var(f ) = XT VX = 400x21 + 2500x
2
2
Thus the objective function can be taken as
F = k1(50x1 + 100x2) + k2
√
400x21 + 2500x22
The constraints can be stated as
P [hi ≤ 0] ≥ pi = 0.99, i = 1, 2, 3
652 Stochastic Programming
As the value of the standard normal variate (si) corresponding to the probability 0.99
is 2.33 (obtained from Table 11.1), we can state the equivalent deterministic nonlinear
optimization problem as follows:
Minimize F = k1(50x1 + 100x2) + k2
√
400x21 + 2500x
2
2
subject to
10x1 + 5x2 + 2.33
√
36x21 + 16x22 + 250,000 − 2500 ≤ 0
4x1 + 10x2 + 2.33
√
16x21 + 49x22 + 160,000 − 2000 ≤ 0
x1 + 1.5x2 + 2.33
√
4x21 + 9x22 + 2500 − 450 ≤ 0
x1 ≥ 0, x2 ≥ 0
This problem can be solved by any of the nonlinear programming techniques once the
values of k1 and k2 are specified.
11.4 STOCHASTIC NONLINEAR PROGRAMMING
When some of the parameters involved in the objective function and constraints vary
about their mean values, a general optimization problem has to be formulated as a
stochastic nonlinear programming problem. For the present purpose we assume that
all the random variables are independent and follow normal distribution. A stochastic
nonlinear programming problem can be stated in standard form as
Find X which minimizes f (Y) (11.83)
subject to
P [gj (Y) ≥ 0] ≥ pj , j = 1, 2, . . . ,m (11.84)
where Y is the vector of N random variables y1, y2, . . . , yN and it includes the decision
variables x1, x2, . . . , xn. The case when X is deterministic can be obtained as a special
case of the present formulation. Equations (11.84) denote that the probability of real-
izing gj (Y) greater than or equal to zero must be greater than or equal to the specified
probability pj . The problem stated in Eqs. (11.83) and (11.84) can be converted into
an equivalent deterministic nonlinear programming problem by applying the chance
constrained programming technique as follows.
11.4.1 Objective Function
The objective function f (Y) can be expanded about the mean values of yi , yi , as
f (Y) = f (Y) +
N
∑
i=1
(
∂f
∂yi
∣
∣
∣
∣Y
)
(yi − yi) + higher-order derivative terms (11.85)
11.4 Stochastic Nonlinear Programming 653
If the standard deviations of yi , σyi , are small, f (Y) can be approximated by the first
two terms of Eq. (11.85):
f (Y) ≃ (Y) −
N
∑
i=1
(
∂f
∂yi
∣
∣
∣
∣Y
)
yi +
N
∑
i=1
(
∂f
∂yi
∣
∣
∣
∣Y
)
yi = ψ(Y) (11.86)
If all yi (i = 1, 2, . . . , N) follow normal distribution, ψ(Y), which is a linear function
of Y, also follows normal distribution. The mean and the variance of ψ are given
by
ψ = ψ(Y) (11.87)
Var(ψ) = σ 2ψ =
N
∑
i=1
(
∂f
∂yi
∣
∣
∣
∣Y
)2
σ 2yi (11.88)
since all yi are independent. For the purpose of optimization, a new objective function
F(Y) can be constructed as
F(Y) = k1ψ + k2σψ (11.89)
where k1 ≥ 0 and k2 ≥ 0, and their numerical values indicate the relative importance
of ψ and σψ for minimization. Another way of dealing with the standard deviation of
ψ is to minimize ψ subject to the constraint σψ ≤ k3ψ , where k3 is a constant, along
with the other constraints.
11.4.2 Constraints
If some parameters are random in nature, the constraints will also be probabilistic and
one would like to have the probability that a given constraint is satisfied to be greater
than a certain value. This is precisely what is stated in Eqs. (11.84) also. The constraint
inequality (11.84) can be written as
∫ ∞
0
fgj (gj )dgj ≥ pj (11.90)
where fgj (gj ) is the probability density function of the random variable gj (a function
of several random variables is also a random variable) whose range is assumed to be
−∞ to ∞. The constraint function gj (Y) can be expanded around the vector of mean
values of the random variables, Y, as
gj (Y) ≃ gj (Y) +
N
∑
i−1
(
∂gj
∂yi
∣
∣
∣
∣Y
)
(yi − yi) (11.91)
From this equation, the mean value, gj , and the standard deviation, σgj , of gj can be
obtained as
gj = gj (Y) (11.92)
σgj =
{
N
∑
i=1
(
∂gj
∂yi
∣
∣
∣
∣Y
)2
σ 2yi
}1/2
(11.93)
654 Stochastic Programming
By introducing the new variable
θ =
gj − gj
σgj
(11.94)
and noting that
∫ ∞
−∞
1
√
2π
e−t
2/2dt = 1 (11.95)
Eq. (11.90) can be expressed as
∫ ∞
−(gj /σgj )
1
√
2π
e−θ
2/2dθ ≥
∫ ∞
−φj (pj )
1
√
2π
e−t
2/2dt (11.96)
where φj (pj ) is the value of the standard normal variate corresponding to the proba-
bility pj . Thus
−
gj
σgj
≤ −φj (pj )
or
−gj + σgjφj (pj ) ≤ 0 (11.97)
Equation (11.97) can be rewritten as
gj − φj (pj )
[
N
∑
i=1
(
∂gj
∂yi
∣
∣
∣
∣Y
)2
σ 2yi
]1/2
≥ 0, j = 1, 2, . . . , m (11.98)
Thus the optimization problem of Eqs. (11.83) and (11.84) can be stated in its equivalent
deterministic form as: minimize F(Y) given by Eq. (11.89) subject to the m constraints
given by Eq. (11.98).
Example 11.6 Design a uniform column of tubular section shown in Fig. 11.5 to
carry a compressive load P for minimum cost. The column is made up of a material
that has a modulus of elasticity E and density ρ. The length of the column is l. The
stress induced in the column should be less than the buckling stress as well as the yield
stress. The mean diameter is restricted to lie between 2.0 and 14.0 cm, and columns
with thickness outside the range 0.2 to 0.8 cm are not available in the market. The
cost of the column includes material costs and construction costs and can be taken as
5W + 2d , where W is the weight and d is the mean diameter of the column. The
constraints have to be satisfied with a probability of at least 0.95.
The following quantities are probabilistic and follow normal distribution with mean
and standard deviations as indicated:
Compressive load = (P , σP ) = (2500, 500) kg
Young’s modulus = (E, σE) = (0.85 × 106, 0.085 × 106) kgf/cm2
Density = (ρ, σρ) = (0.0025, 0.00025) kgf/cm3
Yield stress = (f y, σfy ) = (500, 50) kgf/cm2
11.4 Stochastic Nonlinear Programming 655
Figure 11.5 Column under compressive load.
Mean diameter of the section = (d, σd) = (d, 0.01d)
Column length = (l, σl) = (250, 2.5) cm
SOLUTION This problem, by neglecting standard deviations of the various quantities,
can be seen to be identical to the one considered in Example 1.1. We will take the
design variables as the mean tubular diameter (d) and the tube thickness (t):
X =
{
x1
x2
}
=
{
d
t
}
Notice that one of the design variables (d) is probabilistic in this case and we assume
that d is unknown since σd is given in term of (d). By denoting the vector of random
variables as
Y =

















y1
y2
y3
y4
y5
y6

















=

















P
E
ρ
fy
l
d

















656 Stochastic Programming
the objective function can be expressed as f (Y) = 5 W + 2d = 5ρlπ dt + 2d . Since
Y =



















P
E
ρ
f y
l
d



















=

















2500
0.85 × 106
0.0025
500
250
d

















f (Y) = 5ρlπdt + 2d = 9.8175dt + 2d
∂f
∂y1
∣
∣
∣
∣Y
=
∂f
∂y2
∣
∣
∣
∣Y
=
∂f
∂y4
∣
∣
∣
∣Y
= 0
∂f
∂y3
∣
∣
∣
∣Y
= 5πl dt = 3927.0dt
∂f
∂y5
∣
∣
∣
∣Y
= 5πρdt = 0.03927dt
∂f
∂y6
∣
∣
∣
∣Y
= 5πρlt + 2 = 9.8175t + 2.0
Equations (11.87) and (11.88) give
ψ(Y) = 9.8175dt + 2d (E1)
σ 2ψ = (3927.0dt)
2σ 2ρ + (0.03927dt)
2σ 2l + (9.8175t + 2.0)
2σ 2d
= 0.9835d2t2 + 0.0004d2 + 0.003927d2t (E2)
Thus the new objective function for minimization can be expressed as
F(d, t) = k1ψ + k2σψ
= k1(9.8175dt + 2d) + k2(0.9835d
2
t2 + 0.0004d2 + 0.003927d2t)1/2 (E3)
where k1 ≥ 0 and k2 ≥ 0 indicate the relative importances of ψ and σψ for minimiza-
tion. By using the expressions derived in Example 1.1, the constraints can be expressed
as
P [g1(Y) ≤ 0] = P
(
P
πdt
− fy ≤ 0
)
≥ 0.95 (E4)
P [g2(Y) ≤ 0] = P
[
P
πdt
−
π2E
8l2
(d2 + t2) ≤ 0
]
≥ 0.95 (E5)
P [g3(Y) ≤ 0] = P [−d + 2.0 ≤ 0] ≥ 0.95 (E6)
P [g4(Y) ≤ 0] = P [d − 14.0 ≤ 0] ≥ 0.95 (E7)
P [g5(Y) ≤ 0] = P [−t + 0.2 ≤ 0] ≥ 0.95 (E8)
P [g6(Y) ≤ 0] = P [t − 0.8 ≤ 0] ≥ 0.95 (E9)
11.4 Stochastic Nonlinear Programming 657
The mean values of the constraint functions are given by Eq. (11.92) as
g1 =
P
πdt
− f y =
2500
πdt
− 500
g2 =
P
πdt
−
π2E(d
2 + t2)
8l
2
=
2500
πdt
−
π2(0.85 × 106)(d2 + t2)
8(250)2
g3 = −d + 2.0
g4 = d − 14.0
g5 = −t + 0.2
g6 = t − 0.8
The partial derivatives of the constraint functions can be computed as follows:
∂g1
∂y2
∣
∣
∣
∣Y
=
∂g1
∂y3
∣
∣
∣
∣Y
=
∂g1
∂y5
∣
∣
∣
∣Y
= 0
∂g1
∂y1
∣
∣
∣
∣Y
=
1
πdt
∂g1
∂y4
∣
∣
∣
∣Y
= −1
∂g1
∂y6
∣
∣
∣
∣Y
= −
P
πd
2
t
= −
2500
πd
2
t
∂g2
∂y3
∣
∣
∣
∣Y
=
∂g2
∂y4
∣
∣
∣
∣Y
= 0
∂g2
∂y1
∣
∣
∣
∣Y
=
1
πdt
∂g2
∂y2
∣
∣
∣
∣Y
= −
π2(d
2 + t2)
8l
2
= −
π2(d
2 + t2)
500,000
∂g2
∂y5
∣
∣
∣
∣Y
=
π2E(d
2 + t2)
4l
3
= 0.0136π2(d2 + t2)
∂g2
∂y6
∣
∣
∣
∣Y
= −
P
πd
2
t
−
π2E(2d)
8l
2
= −
2500
πd
2
t
− π2(3.4)d
∂g3
∂yi
∣
∣
∣
∣Y
= 0 for i = 1 to 5
∂g3
∂y6
∣
∣
∣
∣Y
= −1.0
∂g4
∂yi
∣
∣
∣
∣Y
= 0 for i = 1 to 5
658 Stochastic Programming
∂g4
∂y6
∣
∣
∣
∣Y
= 1.0
∂g5
∂yi
∣
∣
∣
∣Y
=
∂g6
∂yi
∣
∣
∣
∣Y
= 0 for i = 1 to 6
Since the value of the standard normal variate φj (pj ) corresponding to the probability
pj = 0.95 is 1.645 (obtained from Table 11.1), the constraints in Eq. (11.98) can be
expressed as follows.
For j = 1†:
2500
πdt
− 500 − 1.645
[
σ 2P
π2d
2
t2
+ σ 2fy +
(2500)2
π2d
4
t2
σ 2d
]1/2
≤ 0
795
dt
− 500 − 1.645
(
25, 320
d
2
t2
+ 2500 +
63.3
d
2
t2
)1/2
≤ 0 (E10)
For j = 2:
2500
πdt
− 16.78(d2 + t2) − 1.645
[
σ 2P
π2d
2
t2
+
π4(d
2 + t2)2σ 2E
25 × 1010
+ (0.0136π2)2(d2 + t2)2σ 2l +
(
2500
πd
2
t
+ 3.4π2d
)2
σ 2d
]1/2
≤ 0
795
dt
− 16.78(d2 + t2) − 1.645
[
25,320
d
2
t2
+ 2.82(d2 + t2)2
+ 0.113(d2 + t2)2 +
63.20
d
2
t2
+ 0.1126d4 +
5.34d
t
]1/2
≤ 0 (E11)
For j = 3:
−d + 2.0 − 1.645[(10−4)d2]1/2 ≤ 0
−1.01645d + 2.0 ≤ 0 (E12)
For j = 4:
d − 14.0 − 1.645[(10−4)d2]1/2 ≤ 0
0.98335d − 14.0 ≤ 0 (E13)
For j = 5:
−t + 0.2 ≤ 0 (E14)
For j = 6:
t − 0.8 ≤ 0 (E15)
†The inequality sign is different from that of Eq. (11.98) due to the fact that the constraints are stated as
P [gj (Y) ≤ 0] ≥ pj .
11.5 Stochastic Geometric Programming 659
Thus the equivalent deterministic optimization problem can be stated as follows: Min-
imize F(d, t) given by Eq. (E3) subject to the constraints given by Eqs. (E10) to (E15).
The solution of the problem can be found by applying any of the standard nonlinear
programming techniques discussed in Chapter 7. In the present case, since the number
of design variables is only two, a graphical method can also be used to find the solution.
11.5 STOCHASTIC GEOMETRIC PROGRAMMING
The deterministic geometric programming problem has been considered in Chapter 8. If
the constants involved in the posynomials are random variables, the chance-constrained
programming methods discussed in Sections 11.3 and 11.4 can be applied to this
problem. The probabilistic geometric programming problem can be stated as follows:
Find X = {x1x2 · · · xn}T which minimizes f (Y)
subject to (11.99)
P [gj (Y) > 0] ≥ pj , j = 1, 2, . . . ,m
where Y = {y1, y2, . . . , yN }T is the vector of N random variables (may include the
variables x1, x2, . . . , xn), and f (Y) and gj (Y), j = 1, 2, . . . , m, are posynomials. By
expanding the objective function about the mean values of the random variables yi ,
yi , and retaining only the first two terms, we can express the mean and variance of
f (Y) as in Eqs. (11.87) and (11.88). Thus the new objective function, F(Y), can be
expressed as in Eq. (11.89):
F(Y) = k1ψ + k2σψ (11.100)
The probabilistic constraints of Eq. (11.99) can be converted into deterministic form
as in Section 11.4:
gj − φj (pj )
[
N
∑
i=1
(
∂gj
∂yi
∣
∣
∣
∣Y
)2
σ 2yi
]1/2
≥ 0, j = 1, 2, . . . ,m (11.101)
Thus the optimization problem of Eq. (11.99) can be stated equivalently as follows:
Find Y which minimizes F(Y) given by Eq. (11.100) subject to the constraints of
Eq. (11.101). The procedure is illustrated through the following example.
Example 11.7 Design a helical spring for minimum weight subject to a constraint on
the shear stress (τ ) induced in the spring under a compressive load P .
SOLUTION By selecting the coil diameter (D) and wire diameter (d) of the spring
as design variables, we have x1 = D and x2 = d . The objective function can be stated
in deterministic form as [11.14, 11.15]:
f (X) =
π2d2D
4
(Nc + Q)ρ (E1)
660 Stochastic Programming
where Nc is the number of active turns, Q the number of inactive turns, and ρ the
weight density. Noting that the deflection of the spring (δ) is given by
δ =
8PC3Nc
Gd
(E2)
where P is the load, C = D/d , and G is the shear modulus. By substituting the
expression of Nc given by Eq. (E2) into Eq. (E1), the objective function can be expressed
as
f (X) =
π2ρGδ
32P
d6
D2
+
π2ρQ
4
d2D (E3)
The yield constraint can be expressed, in deterministic form, as
τ =
8KPC
πd2
≤ τmax (E4)
where τmax is the maximum permissible value of shear stress and K the shear stress
concentration factor given by (for 2 ≤ C ≤ 12):
K =
2
C0.25
(E5)
Using Eq. (E5), the constraint of Eq. (E4) can be rewritten as
16P
πτmax
D0.75
d2.75
< 1 (E6)
By considering the design variables to be normally distributed with (d, σd) = d(1, 0.05)
and (D, σD) = D(1, 0.05), k1 = 1 and k2 = 0 in Eq. (11.100) and using pj = 0.95,
the problem [Eqs. (11.100) and (11.101)] can be stated as follows:
Minimize F(Y) =
0.041π2ρδG
P
d
6
D
2
+ 0.278π2ρQd2D (E7)
subject to
12.24P
πτmax
D
0.75
d
2.75
≤ 1 (E8)
The data are assumed as P = 510N , ρ = 78,000 N/m3, δ = 0.02 m, τmax = 0.306 ×
109Pa, and Q = 2. The degree of difficulty of the problem can be seen to be zero and
the normality and orthogonality conditions yield
δ1 + δ2 = 1
6δ1 + 2δ2 − 2.75δ3 = 0 (E9)
−2δ1 + δ2 + 0.75δ3 = 0
The solution of Eqs. (E9) gives δ1 = 0.81, δ2 = 0.19, and δ3 = 1.9, which corresponds
to d = 0.0053 m, D = 0.0358 m, and fmin = 2.266 N.
References and Bibliography 661
REFERENCES AND BIBLIOGRAPHY
11.1 E. Parzen, Modern Probability Theory and Its Applications , Wiley, New York, 1960.
11.2 A. H. S. Ang and W. H. Tang, Probability Concepts in Engineering Planning and Design ,
Vol. I, Basic Principles , Wiley, New York, 1975.
11.3 S. S. Rao, Reliability-based Design , McGraw-Hill, New York, 1992.
11.4 G. B. Dantzig, Linear programming under uncertainty, Management Science, Vol. 1, pp.
197–207, 1955.
11.5 A. Charnes and W.W. Cooper, Chance constrained programming, Management Science,
Vol. 6, pp. 73–79, 1959.
11.6 J. K. Sengupta and K. A. Fox, Economic Analysis and Operations Research: Optimiza-
tion Techniques in Quantitative Economic Models , North-Holland, Amsterdam, 1971.
11.7 R. J. Aguilar, Systems Analysis and Design in Engineering, Architecture, Construction
and Planning , Prentice-Hall, Englewood Cliffs, NJ, 1973.
11.8 G. L. Nemhauser, Introduction to Dynamic Programming , Wiley, New York, 1966.
11.9 A. Kaufmann and R. Cruon, Dynamic Programming: Sequential Scientific Management ,
tr. by H. C. Sneyd, Academic Press, New York, 1967.
11.10 G. E. Thompson, Linear Programming: An Elementary Introduction , Macmillan, New
York, 1971.
11.11 M. Avriel and D. J. Wilde, Stochastic geometric programming, pp. 73–91 in Proceedings
of the Princeton Symposium on Mathematical Programming , H. W. Kuhn, Ed., Princeton
University Press, Princeton, NJ, 1970.
11.12 M. J. L. Kirby, The current state of chance constrained programming, pp. 93–111 in
Proceedings of the Princeton Symposium on Mathematical Programming , H. W. Kuhn,
Ed., Princeton University Press, Princeton, NJ, 1970.
11.13 W. K. Grassmann, Stochastic Systems for Management , North-Holland, New York,
1981.
11.14 J. E. Shigley and C. R. Mischke, Mechanical Engineering Design , 5th ed., McGraw-Hill,
New York, 1989.
11.15 S. B. L. Beohar and A. C. Rao, Optimum design of helical springs using stochastic
geometric programming, pp. 147–151 in Progress in Engineering Optimization—1981 ,
R. W. Mayne and K. M. Ragsdell, Eds., ASME, New York, 1981.
11.16 L. L. Howell, S. S. Rao, and A. Midha, Reliability-based optimal design of a bistable
compliant mechanism, ASME Journal of Mechanical Design , Vol. 116, pp. 1115–1121,
1995.
11.17 R. H. Crawford and S. S. Rao, Probabilistic analysis of function generating mechanisms,
ASME Journal of Mechanisms, Transmissions, and Automation in Design , Vol. 111,
pp. 479–481, 1989.
11.18 S. K. Hati and S. S. Rao, Determination of optimum machining conditions: determin-
istic and probabilistic approaches, ASME Journal of Engineering for Industry , Vol. 98,
pp. 354–359, 1976.
11.19 S. S. Rao, Multiobjective optimization in structural design in the presence of uncertain
parameters and stochastic process, AIAA Journal , Vol. 22, pp. 1670–1678, 1984.
11.20 S. S. Rao, Automated optimum design of wing structures: a probabilistic approach,
Computers and Structures , Vol. 24, No. 5, pp. 799–808, 1986.
11.21 S. S. Rao, Reliability-based optimization under random vibration environment, Comput-
ers and Structures , Vol. 14, pp. 345–355, 1981.
662 Stochastic Programming
11.22 S. S. Rao and C. P. Reddy, Mechanism design by chance constrained programming,
Mechanism and Machine Theory , Vol. 14, pp. 413–424, 1979.
REVIEW QUESTIONS
11.1 Define the following terms:
(a) Mean
(b) Variance
(c) Standard deviation
(d) Probability
(e) Independent events
(f) Joint density function
(g) Covariance
(h) Central limit theorem
(i) Chance constrained programming
11.2 Match the following terms and descriptions:
(a) Marginal density function Describes sum of several random variables
(b) Bivariate distribution Described by probability density function
(c) Normal distribution Describes one random variable
(d) Discrete distribution Describes two random variables
(e) Continuous distribution Described by probability mass function
11.3 Answer true or false:
(a) The uniform distribution can be used to describe only continuous random variables.
(b) The area under the probability density function can have any positive value.
(c) The standard normal variate has zero mean and unit variance.
(d) The magnitude of the correlation coefficient is bounded by one.
(e) Chance constrained programming method can be used to solve only stochastic LP
problems.
(f) Chance constrained programming permits violation of constraints to some extent.
(g) Chance constrained programming assumes the random variables to be normally dis-
tributed.
(h) The design variables need not be random in a stochastic programming problem.
(i) Chance constrained programming always gives rise to a two-part objective function.
(j) Chance constrained programming converts a stochastic LP problem into a determin-
stic LP problem.
(k) Chance constrained programming converts a stochastic geometric programming
problem into a deterministic geometric programming problem.
(l) The introduction of random variables increases the number of state variables in
stochastic dynamic programming.
11.4 Explain the notation N(µ, σ ).
Problems 663
11.5 What is a random variable?
11.6 Give two examples of random design parameters.
11.7 What is the difference between probability density and probability distribution functions?
11.8 What is the difference between discrete and continuous random variables?
11.9 How does correlation coefficient relate two random variables?
11.10 Identify possible random variables in a LP problem.
11.11 How do you find the mean and standard deviation of a sum of several random variables?
PROBLEMS
11.1 A contractor plans to use four tractors to work on a project in a remote area. The
probability of a tractor functioning for a year without a break-down is known to be
80 %. If X denotes the number of tractors operating at the end of a year, determine the
probability mass and distribution functions of X.
11.2 The absolute value of the velocity of a molecule in a perfect gas (V ) obeys the Maxwell
distribution
fV (ν) =
4h3
√
π
ν2e−h
2ν2 , ν ≥ 0
where h2 = (m/2kT ) is a constant (m is the mass of the molecule, k is Boltzmann’s
constant, and T is the absolute temperature). Find the mean and the standard deviation
of the velocity of a molecule.
11.3 Find the expected value and the standard deviation of the number of tractors operating
at the end of one year in Problem 11.1.
11.4 Mass-produced items always show random variation in their dimensions due to small
unpredictable and uncontrollable disturbing influences. Suppose that the diameter, X, of
the bolts manufactured in a production shop follow the distribution
fX(x) = a(x − 0.9)(1.1 − x) for 0.9 ≤ x ≤ 1.1
0 elsewhere
Find the values of a, µX and σ
2
X .
11.5 (a) The voltage V across a constant resistance R is known to fluctuate between 0 and
2 volts. If V follows uniform distribution, what is the distribution of the power
expended in the resistance?
(b) Find the distribution of the instantaneous voltage (V ) given by V = A cos(ωt +φ),
where A is a constant, ω the frequency, t the time, and φ the random phase angle
uniformly distributed from 0 to 2π radians.
11.6 The hydraulic head loss (H) in a pipe due to friction is given by the Darcy–Weisbach
equation,
H = f
L
2gD
V 2
where f is the friction factor, L the length of pipe, V the velocity of flow in pipe, g the
acceleration due to gravity, and D the diameter of the pipe. If V follows exponential
664 Stochastic Programming
distribution,
fV (ν) =





1
V0
e−(ν/V0) for ν ≥ 0
0 for ν < 0
where V0 is the mean velocity, derive the density function for the head loss H .
11.7 The joint density function of two random variables X and Y is given by
fX,Y (x, y) =
{
3x2y + 3y2x for 0 ≤ x ≤ 1, 0 ≤ y ≤ 1
0 elsewhere
Find the marginal density functions of X and Y .
11.8 Steel rods, manufactured with a nominal diameter of 3 cm, are considered acceptable
if the diameter falls within the limits of 2.99 and 3.01 cm. It is observed that about 5
% are rejected oversize and 5 % are rejected undersize. Assuming that the diameters
are normally distributed, find the standard deviation of the distribution. Compute the
proportion of rejects if the permissible limits are changed to 2.985 and 3.015 cm.
11.9 Determine whether the random variables X and Y are dependent or independent when
their joint density function is given by
fX,Y (x, y) =
{
4xy for 0 ≤ x ≤ 1, 0 ≤ y ≤ 1
0 elsewhere
11.10 Determine whether the random variables X and Y are dependent or independent when
their joint density function is given by
fX,Y (x, y) =





1
4π2
[1 − sin(x + y)] for − π ≤ x ≤ π, −π ≤ y ≤ π
0 elsewhere
11.11 The stress level at which steel yields (X) has been found to follow normal distribution.
For a particular batch of steel, the mean and standard deviation of X are found to be
4000 and 300 kgf/cm
2, respectively. Find
(a) The probability that a steel bar taken from this batch will have a yield stress between
3000 and 5000 kgf/cm
2
(b) The probability that the yield stress will exceed 4500 kgf/cm
2
(c) The value of X at which the distribution function has a value of 0.10
11.12 An automobile body is assembled using a large number of spot welds. The number of
defective welds (X) closely follows the distribution
P(X = d) =
e−22d
d!
, d = 0, 1, 2, . . .
Find the probability that the number of defective welds is less than or equal to 2.
Problems 665
11.13 The range (R) of a projectile is given by
R =
V 20
g
sin 2φ
where V0 is the initial velocity of the projectile, g the acceleration due to gravity, and φ
the angle from the horizontal as shown in Fig. 11.6. If the mean and standard deviations
of V0 and φ are given by V 0 = 100 ft/s, σV0 = 10 ft/s, φ = 30
◦
, and σφ = 3◦, find
the first-order mean and standard deviation of the range R, assuming that V0 and φ
are statistically independent. Evaluate also the second-order mean range. Assume that
g = 32.2 ft/s2.
11.14 Maximize f = 4x1 + 2x2 + 3x3 + c4x4
subject to
x1 + x3 + x4 ≤ 24
3x1 + x2 + 2x3 + 4x4 ≤ 48
2x1 + 2x2 + 3x3 + 2x4 ≤ 36
xi ≥ 0, i = 1 to 4
where c4 is a discrete random variable that can take values of 4, 5, 6, or 7 with probabil-
ities of 0.1, 0.2, 0.3, and 0.4, respectively. Using the simplex method, find the solution
that maximizes the expected value of f .
11.15 Find the solution of Problem 11.14 if the objective is to maximize the variance of f .
11.16 A manufacturing firm can produce 1, 2, or 3 units of a product in a month, but the
demand is uncertain. The demand is a discrete random variable that can take a value of
1, 2, or 3 with probabilities 0.2, 0.2, and 0.6, respectively. If the unit cost of production
is $400, unit revenue is $1000, and unit cost of unfulfilled demand is $0, determine the
output that maximizes the expected total profit.
11.17 A factory manufactures products A, B, and C. Each of these products is processed
through three different production stages. The times required to manufacture 1 unit of
each of the three products at different stages and the daily capacity of the stages are
probabilistic with means and standard deviations as indicated below.
Figure 11.6 Range of a projectile.
666 Stochastic Programming
Time per unit (min) for product: Stage capacity
A B C (mins/day)
Stage Mean
Standard
deviation Mean
Standard
deviation Mean
Standard
deviation Mean
Standard
deviation
1 4 1 8 3 4 4 1720 172
2 12 2 0 0 8 2 1840 276
3 4 2 16 4 0 0 1680 336
The profit per unit is also a random variable with the following data:
Profit($)
Product Mean Standard deviation
A 6 2
B 4 1
C 10 3
Assuming that all amounts produced are absorbed by the market, determine the daily
number of units to be manufactured of each product for the following cases.
(a) The objective is to maximize the expected profit.
(b) The objective is to maximize the standard deviation of the profit.
(c) The objective is to maximize the sum of expected profit and the standard deviation
of the profit.
Assume that all the random variables follow normal distribution and the constraints have
to be satisfied with a probability of 0.95.
11.18 In a belt-and-pulley drive, the belt embraces the shorter pulley 165
◦
and runs over it
at a mean speed of 1700 m/min with a standard deviation of 51 m/min. The density of
the belt has a mean value of 1 g/cm3 and a standard deviation of 0.05 g/cm3. The mean
and standard deviations of the permissible stress in the belt are 25 and 2.5 kgf /cm
2,
respectively. The coefficient of friction (µ) between the belt and the pulley is given
by µ = 0.25 and σµ = 0.05. Assuming a coefficient of variation of 0.02 for the belt
dimensions, find the width and thickness of the belt to maximize the mean horsepower
transmitted. The minimum permissible values for the width and the thickness of the belt
are 10.0 and 0.5 cm, respectively. Assume that all the random variables follow normal
distribution and the constraints have to be satisfied with a minimum probability of 0.95.
Hint: Horsepower transmitted = (T1 − T2)ν/75, where T1 and T2 are the tensions on
the tight side and slack sides of the belt in kgf and ν is the linear velocity of the belt
in m/s:
T1 = Tmax − Tc = Tmax −
wν2
g
and
T1
T2
= eµθ
where Tmax is the maximum permissible tension, Tc the centrifugal tension, w the weight
of the belt per meter length, g the acceleration due to gravity in m/s, and θ the angle of
contact between the belt and the pulley.
Problems 667
11.19 An article is to be restocked every three months in a year. The quarterly demand U is
random and its law of probability in any of the quarters is as given below:
U Probability mass function, PU (u)
0 0.2
1 0.3
2 0.4
3 0.1
> 3 0.0
The cost of stocking an article for a unit of time is 4, and when the stock is exhausted,
there is a scarcity charge of 12. The orders that are not satisfied are lost, in other words,
are not carried forward to the next period. Further, the stock cannot exceed three articles,
owing to the restrictions on space. Find the annual policy of restocking the article so as
to minimize the expected value of the sum of the cost of stocking and of the scarcity
charge.
11.20 A close-coiled helical spring, made up of a circular wire of diameter d , is to be designed
to carry a compressive load P . The permissible shear stress is σmax and the permissible
deflection is δmax. The number of active turns of the spring is n and the solid height of
the spring has to be greater than h. Formulate the problem of minimizing the volume
of the material so as to satisfy the constraints with a minimum probability of p. Take
the mean diameter of the coils (D) and the diameter of the wire (d) as design variables.
Assume d,D, P , σmax, δmax, h, and the shear modulus of the material, G, to be normally
distributed random variables. The coefficient of variation of d and D is k. The maximum
shear stress, σ , induced in the spring is given by
σ =
8PDK
πd3
where K is the Wahl’s stress factor defined by
K =
4D − d
4(D − d)
+
0.615d
D
and the deflection (δ) by
δ =
8PD3n
Gd4
Formulate the optimization problem for the following data:
G = N(840,000, 84,000) kgf /cm2, δmax = N(2, 0.1) cm,
σmax = N(3000, 150) kgf /cm2,
P = N(12, 3) kgf , n = 8, h = N(2.0, 0.4) cm, k = 0.05,
p = 0.99
11.21 Solve Problem 11.20 using a graphical technique.
12
Optimal Control and Optimality
Criteria Methods
12.1 INTRODUCTION
In this chapter we give a brief introduction to the following techniques of optimization:
1. Calculus of variations
2. Optimal control theory
3. Optimality criteria methods
If an optimization problem involves the minimization (or maximization) of a functional
subject to the constraints of the same type, the decision variable will not be a number,
but it will be a function. The calculus of variations can be used to solve this type of
optimization problems. An optimization problem that is closely related to the calculus of
variations problem is the optimal control problem. An optimal control problem involves
two types of variables: the control and state variables, which are related to each other
by a set of differential equations. Optimal control theory can be used for solving such
problems. In some optimization problems, especially those related to structural design,
the necessary conditions of optimality, for specialized design conditions, are used to
develop efficient iterative techniques to find the optimum solution. Such techniques are
known as optimality criteria methods .
12.2 CALCULUS OF VARIATIONS
12.2.1 Introduction
The calculus of variations is concerned with the determination of extrema (maxima and
minima) or stationary values of functionals. A functional can be defined as a function of
several other functions. Hence the calculus of variations can be used to solve trajectory
optimization problems.† The subject of calculus of variations is almost as old as the
calculus itself. The foundations of this subject were laid down by Bernoulli brothers and
later important contributions were made by Euler, Lagrange, Weirstrass, Hamilton, and
Bolzane. The calculus of variations is a powerful method for the solution of problems in
several fields, such as statics and dynamics of rigid bodies, general elasticity, vibrations,
optics, and optimization of orbits and controls. We shall see some of the fundamental
concepts of calculus of variations in this section.
†See Section 1.5 for the definition of a trajectory optimization problem.
668 Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
12.2 Calculus of Variations 669
12.2.2 Problem of Calculus of Variations
A simple problem in the theory of the calculus of variations with no constraints can
be stated as follows:
Find a function u(x) that minimizes the functional (integral)
A =
∫ x2
x1
F(x, u, u′, u′′) dx (12.1)
where A and F can be called functionals (functions of other functions). Here x is the
independent variable,
u = u(x), u′ =
du(x)
dx
, and u′′ =
d2u(x)
dx2
In mechanics, the functional usually possesses a clear physical meaning. For example,
in the mechanics of deformable solids, the potential energy (π) plays the role of the
functional (π is a function of the displacement components u, v, and w, which, in turn,
are functions of the coordinates x, y, and z).
The integral in Eq. (12.1) is defined in the region or domain [x1, x2]. Let the values
of u be prescribed on the boundaries as u(x1) = u1 and u(x2) = u2. These are called
the boundary conditions of the problem. One of the procedures that can be used to
solve the problem in Eq. (12.1) will be as follows:
1. Select a series of trial or tentative solutions u(x) for the given problem and
express the functional A in terms of each of the tentative solutions.
2. Compare the values of A given by the different tentative solutions.
3. Find the correct solution to the problem as that particular tentative solution
which makes the functional A assume an extreme or stationary value.
The mathematical procedure used to select the correct solution from a number of
tentative solutions is called the calculus of variations.
Stationary Values of Functionals. Any tentative solution u(x) in the neighborhood
of the exact solution u(x) may be represented as (Fig. 12.1)
u(x) = u(x) + δu(x)
tentative exact variation
solution solution of u
(12.2)
The variation in u (i.e., δu) is defined as an infinitesimal, arbitrary change in u for a
fixed value of the variable x (i.e., for δx = 0). Here δ is called the variational operator
(similar to the differential operator d). The operation of variation is commutative with
both integration and differentiation, that is,
δ
(∫
F dx
)
=
∫
(δF ) dx (12.3)
δ
(
du
dx
)
=
d
dx
(δu) (12.4)
670 Optimal Control and Optimality Criteria Methods
Figure 12.1 Tentative and exact solutions.
Also, we define the variation of a function of several variables or a functional in a
manner similar to the calculus definition of a total differential:
δF =
∂F
∂u
δu +
∂F
∂u′
δu′ +
∂F
∂u′′
δu′′+
∂F
∂x
δx (12.5)
↑
0
(since we are finding variation of F for a fixed value of x, i.e., δx = 0).
Now, let us consider the variation in A(δA) corresponding to variations in the
solution (δu). If we want the condition for the stationariness of A, we take the nec-
essary condition as the vanishing of first derivative of A (similar to maximization or
minimization of simple functions in ordinary calculus).
δA =
∫ x2
x1
(
∂F
∂x
δu +
∂F
∂u′
δu′ +
∂F
∂u′′
δu′′
)
dx =
∫ x2
x1
δF dx = 0 (12.6)
Integrate the second and third terms by parts to obtain
∫ x2
x1
∂F
∂u′
δu′ dx =
∫ x2
x1
∂F
∂u′
δ
(
∂u
∂x
)
dx =
∫ x2
x1
∂F
∂u′
∂
∂x
(δu) dx
=
∂F
∂u′
δu
∣
∣
∣
∣
x2
x1
−
∫ x2
x1
d
dx
(
∂F
∂u′
)
δu dx (12.7)
∫ x2
x1
∂F
∂u′′
δu′′ dx =
∫ x2
x1
∂F
∂u′′
∂
∂x
(δu′)dx =
∂F
∂u′′
δu′
∣
∣
∣
∣
x2
x1
−
∫ x2
x1
d
dx
(
∂F
∂u′′
)
δu′ dx
=
∂F
∂u′′
δu′
∣
∣
∣
∣
x2
x1
−
d
dx
(
∂F
∂u′′
)
δu
∣
∣
∣
∣
x2
x1
+
∫ x2
x1
d2
dx2
(
∂F
∂u′′
)
δu dx (12.8)
12.2 Calculus of Variations 671
Thus
δA =
∫ x2
x1
[
∂F
∂u
−
d
dx
(
∂F
∂u′
)
+
d2
dx2
(
∂F
∂u′′
)]
δu dx
+
[
∂F
∂u′
−
d
dx
(
∂F
∂u′′
)]
δu
∣
∣
∣
∣
x2
x1
+
[(
∂F
∂u′′
)
δu′
]
∣
∣
∣
∣
x2
x1
= 0 (12.9)
Since δu is arbitrary, each term must vanish individually:
∂F
∂u
−
d
dx
(
∂F
∂u′
)
+
d2
dx2
(
∂F
∂u′′
)
= 0 (12.10)
[
∂F
∂u′
−
d
dx
(
∂F
∂u′′
)]
δu
∣
∣
∣
∣
x2
x1
= 0 (12.11)
∂F
∂u′′
δu′
∣
∣
∣
∣
x2
x1
= 0 (12.12)
Equation (12.10) will be the governing differential equation for the given problem and
is called Euler equation or Euler–Lagrange equation. Equations (12.11) and (12.12)
give the boundary conditions.
The conditions
[
∂F
∂u′
−
d
dx
(
∂F
∂u′′
)]
∣
∣
∣
∣
x2
x1
= 0 (12.13)
∂F
∂u′′
∣
∣
∣
∣
x2
x1
= 0 (12.14)
are called natural boundary conditions (if they are satisfied, they are called free bound-
ary conditions). If the natural boundary conditions are not satisfied, we should have
δu(x1) = 0, δu(x2) = 0 (12.15)
δu′(x1) = 0, δu′(x2) = 0 (12.16)
in order to satisfy Eqs. (12.11) and (12.12). These are called geometric or forced
boundary conditions.
Example 12.1 Brachistochrone Problem In June 1696, Johann Bernoulli set the fol-
lowing problem before the scholars of his time. “Given two points A and B in a
vertical plane, find the path from A to B along which a particle of mass m will slide
under the force of gravity, without friction, in the shortest time” (Fig. 12.2). The term
brachistochrone derives from the Greek brachistos (shortest) and chronos (time).
If s is the distance along the path and ν the velocity, we have
ν =
ds
dt
=
(dx2 + dy2)1/2
dt
=
[1 + (y′)2]1/2
dt
dx
dt =
1
ν
[1 + (y′)2]1/2 dx
672 Optimal Control and Optimality Criteria Methods
Figure 12.2 Curve of minimum time of
descent.
Since potential energy is converted to kinetic energy as the particle moves down the
path, we can write
1
2
mν2 = mgx
Hence
dt =
[
1 + (y′)2
2gx
]1/2
dx (E1)
and the integral to be stationary is
t =
∫ xB
0
[
1 + (y′)2
2gx
]1/2
dx (E2)
The integrand is a function of x and y′ and so is a special case of Eq. (12.1). Using
the Euler–Lagrange equation,
d
dx
(
∂F
∂y′
)
−
∂F
∂y
= 0 with F =
[
1 + (y′)2
2gx
]1/2
we obtain
d
dx
(
y′
{x[1 + (y′)2]}1/2
)
= 0
Integrating yields
y′ =
dy
dx
=
(
C1x
1 − C1x
)1/2
(E3)
where C1 is a constant of integration. The ordinary differential equation (E3) yields on
integration the solution to the problem as
y(x) = C1 sin−1(x/C1) − (2C1x − x2)1/2 + C2 (E4)
Example 12.2 Design of a Solid Body of Revolution for Minimum Drag Next we
consider the problem of determining the shape of a solid body of revolution for mini-
mum drag. In the general case, the forces exerted on a solid body translating in a fluid
12.2 Calculus of Variations 673
depend on the shape of the body and the relative velocity in a very complex manner.
However, if the density of the fluid is sufficiently small, the normal pressure (p) acting
on the solid body can be approximately taken as [12.3]
p = 2ρν2 sin2 θ (E1)
where ρ is the density of the fluid, v the velocity of the fluid relative to the solid body,
and θ the angle between the direction of the velocity of the fluid and the tangent to the
surface as shown in Fig. 12.3.
Since the pressure (p) acts normal to the surface, the x-component of the force
acting on the surface of a slice of length dx and radius y(x) shown in Fig. 12.4 can
be written as
dP = (normal pressure) (surface area) sin θ
= (2ρv2 sin2 θ)(2πy
√
1 + (y′)2 dx) sin θ (E2)
where y′ = dy/dx. The total drag force, P , is given by the integral of Eq. (E2) as
P =
∫ L
0
4πρν2y sin3 θ
√
1 + (y′)2 dx (E3)
where L is the length of the body. To simplify the calculations, we assume that y′ ≪ 1
so that
sin θ =
y′
√
1 + (y′)2
≃ y′ (E4)
Thus Eq. (E3) can be approximated as
P = 4πρν2
∫ L
0
(y′)3y dx (E5)
Now the minimum drag problem can be stated as follows.
Figure 12.3 Solid body of revolution translating in a fluid medium.
674 Optimal Control and Optimality Criteria Methods
Figure 12.4 Element of surface area acted on by the
pressure p.
Find y(x) which minimizes the drag P given by Eq. (E5) subject to the condition
that y(x) satisfies the end conditions
y(x = 0) = 0 and y(x = L) = R (E6)
By comparing the functional P of Eq. (E5) with A of Eq. (12.1), we find that
F(x, y, y′, y′′) = 4πρν2(y′)3y (E7)
The Euler–Lagrange equation, Eq. (12.10), corresponding to this functional can be
obtained as
(y′)3 − 3
d
dx
[y(y′)2] = 0 (E8)
The boundary conditions, Eqs. (12.11) and (12.12), reduce to
[3y(y′)2]δy
∣
∣
∣
∣
x2=L
x1=0
= 0 (E9)
Equation (E8) can be written as
(y′)3 − 3[y′(y′)2 + y(2)y′y′′] = 0
or
(y′)3 + 3yy′y′′ = 0 (E10)
This equation, when integrated once, gives
y(y′)3 = k31 (E11)
where k31 is a constant of integration. Integrating Eq. (E11), we obtain
y(x) = (k1x + k2)3/4 (E12)
The application of the boundary conditions, Eqs. (E6), gives the values of the
constants as
k1 =
R4/3
L
and k2 = 0
12.2 Calculus of Variations 675
Hence the shape of the solid body having minimum drag is given by the equation
y(x) = R
( x
L
)3/4
12.2.3 Lagrange Multipliers and Constraints
If the variable x is not completely independent but has to satisfy some condition(s) of
constraint, the problem can be stated as follows:
Find the function y(x) such that the integral
A =
∫ x2
x1
F
(
x, y,
dy
dx
)
dx → minimum
subject to the constraint (12.17)
g
(
x, y,
dy
dx
)
= 0
where g may be an integral function. The stationary value of a constrained calculus of
variations problem can be found by the use of Lagrange multipliers. To illustrate the
method, let us consider a problem known as isoperimetric problem given below.
Example 12.3 Optimum Design of a Cooling Fin Cooling fins are used on radiators
to increase the rate of heat transfer from a hot surface (wall) to the surrounding
fluid. Often, we will be interested in finding the optimum tapering of a fin (of
rectangular cross section) of specified total mass which transfers the maximum
heat energy.
The configuration of the fin is shown in Fig. 12.5. If T0 and T∞ denote the wall
and the ambient temperatures, respectively, the temperature of the fin at any point,
T (x), can be nondimensionalized as
t (x) =
T (x) − T∞
T0 − T∞
(E1)
so that t (0) = 1 and t (∞) = 0.
Figure 12.5 Geometry of a cooling fin.
676 Optimal Control and Optimality Criteria Methods
To formulate the problem, we first write the heat balance equation for an elemental
length, dx , of the fin:
heat inflow by conduction = heat outflow by conduction and convection
that is,
(
−kA
dt
dx
)
x
=
(
−kA
dt
dx
)
x+dx
+ hS (t − t∞) (E2)
where k is the thermal conductivity, A the cross-sectional area of the fin = 2y(x)
per unit width of the fin, h the heat transfer coefficient, S the surface area of the fin
element = 2
√
1 + (y′)2 dx per unit width, and 2y(x) the depth of the fin at any section
x. By writing
(
−kA
dt
dx
)
x+dx
=
(
−kA
dt
dx
)
x
+
d
dx
(
−kA
dt
dx
)
dx (E3)
and noting that t∞ = 0, we can simplify Eq. (E2) as
d
dx
(
ky
dt
dx
)
= ht
√
1 + (y′)2 (E4)
Assuming that y′ ≪ 1 for simplicity, this equation can be written as
k
d
dx
(
y
dt
dx
)
= ht (E5)
The amount of heat dissipated from the fin to the surroundings per unit time is
given by
H = 2
∫ L
0
ht dx (E6)
by assuming that the heat flow from the free end of the fin is zero. Since the mass of
the fin is specified as m, we have
2
∫ L
0
ρy dx − m = 0 (E7)
where ρ is the density of fin.
Now the problem can be stated as follows: Find t (x) that maximizes the integral
in Eq. (E6) subject to the constraint equation (E7). Since y(x) in Eq. (E7) is also not
known, it can be expressed in terms of t (x) using the heat balance equation (E5). By
integrating Eq. (E5) between the limits x and L, we obtain
−ky(x)
dt
dx
(x) = h
∫ L
x
t (x) dx (E8)
by assuming the heat flow from the free end to be zero. Equation (E8) gives
y(x) = −
h
k
1
dt/dx
∫ L
x
t (x) dx (E9)
12.2 Calculus of Variations 677
By substituting Eq. (E9) in (E7), the variational problem can be restated as
Find y(x) which maximizes
H = 2h
∫ L
0
t (x) dx (E10)
subject to the constraint
g(x, t, t ′) = 2ρ
h
k
∫ L
0
1
dt/dx
[∫ L
x
t (x) dx
]
dx + m = 0 (E11)
This problem can be solved by using the Lagrange multiplier method. The functional
I to be extremized is given by
I =
∫ L
0
(H + λg) dx = 2h
∫ L
0
[
t (x) +
λρ
k
1
dt/dx
∫ L
x
t (x) dx
]
dx (E12)
where λ is the Lagrange multiplier.
By comparing Eq. (E12) with Eq. (12.1) we find that
F(x, t, t ′) = 2ht +
2hλρ
k
1
t ′
∫ L
x
t (x) dx (E13)
The Euler–Lagrange equation, Eq. (12.10), gives
h −
λhρ
k
[
2t ′′
(t ′)3
∫ L
x
t (x) dx +
t (x)
(t ′)2
−
∫ x
0
dx
t ′
]
= 0 (E14)
This integrodifferential equation has to be solved to find the solution t (x). In this case
we can verify that
t (x) = 1 − x
(
λρ
k
)1/2
(E15)
satisfies Eq. (E14). The thickness profile of the fin can be obtained from Eq. (E9) as
y(x) = −
h
k
1
t ′
∫ L
x
t (x) dx =
h
k
(
k
λρ
)1/2 ∫ L
x
[
1 −
(
λρ
k
)1/2
x
]
dx
=
h
(kλρ)1/2
[
L −
(
λρ
k
)1/2
L2
2
− x +
(
λρ
k
)1/2
x2
2
]
= c1 + c2x + c3x2 (E16)
where
c1 =
h
(kλρ)1/2
[
L −
(
λρ
k
)1/2
L2
2
]
(E17)
c2 = −
h
(kλρ)1/2
(E18)
c3 =
h
2(kλρ)1/2
(
λρ
k
)1/2
=
h
2k
(E19)
678 Optimal Control and Optimality Criteria Methods
The value of the unknown constant λ can be found by using Eq. (E7) as
m = 2ρ
∫ L
0
y(x) dx = 2ρ
(
c1L + c2
L2
2
+ c3
L3
3
)
that is,
m
2ρL
= c1 + c2
L
2
+ c3
L2
3
=
hL
2(kρλ)1/2
−
1
3
hL2
k
(E20)
Equation (E20) gives
λ1/2 =
hL
(kρ)1/2
1
(m/ρL) + 2
3
(hL2/k)
(E21)
Hence the desired solution can be obtained by substituting Eq. (E21) in Eq. (E16).
12.2.4 Generalization
The concept of including constraints can be generalized as follows. Let the problem be
to find the functions u1(x, y, z), u2(x, y, z), . . . , un(x, y, z) that make the functional
∫
V
f
(
x, y, z, u1, u2, . . . , un,
∂u1
∂x
, . . .
)
dV (12.18)
stationary subject to the m constraints
g1
(
x, y, z, u1, u2, . . . , un,
∂u1
∂x
, . . .
)
= 0
...
gm
(
x, y, z, u1, u2, . . . , un,
∂u1
∂x
, . . .
)
= 0
(12.19)
The Lagrange multiplier method consists in taking variations in the functional
A =
∫
V
(f + λ1g1 + λ2g2 + · · · + λmgm) dV (12.20)
where λi are now functions of position. In the special case where one or more of the
gi are integral conditions, the associated λi are constants.
12.3 OPTIMAL CONTROL THEORY
The basic optimal control problem can be stated as follows:
Find the control vector u =









u1
u2
...
um









12.3 Optimal Control Theory 679
which minimizes the functional, called the performance index ,
J =
∫ T
0
f0(x, u, t) dt (12.21)
where
x =









x1
x2
...
xn









is called the state vector , t the time parameter, T the terminal time, and f0 is a function
of x, u, and t . The state variables xi and the control variables ui are related as
dxi
dt
= fi(x1, x2, . . . , xn; u1, u2, . . . , um; t), i = 1, 2, . . . , n
or
ẋ = f(x, u, t) (12.22)
In many problems, the system is linear and Eq. (12.22) can be stated as
ẋ = [A]x + [B]u (12.23)
where [A] is an n × n matrix and [B] is an n × m matrix. Further, while finding the
control vector u, the state vector x is to be transferred from a known initial vector x0
at t = 0 to a terminal vector xT at t = T , where some (or all or none) of the state
variables are specified.
12.3.1 Necessary Conditions for Optimal Control
To derive the necessary conditions for the optimal control, we consider the following
simple problem:
Find u which minimizes J =
∫ T
0
f0(x, u, t) dt (12.24)
subject to
ẋ = f (x, u, t) (12.25)
with the boundary condition x(0) = k1. To solve this optimal control problem, we
introduce a Lagrange multiplier λ and define an augmented functional J ∗ as
J ∗ =
∫ T
0
{f0(x, u, t) + λ[f (x, u, t) − ẋ]} dt (12.26)
Since the integrand
F = f0 + λ (f − ẋ) (12.27)
680 Optimal Control and Optimality Criteria Methods
is a function of the two variables x and u, we can write the Euler–Lagrange equations
[with u1 = x, u′1 = ∂x/∂t = ẋ, u2 = u and u′2 = ∂u/∂t = u̇ in Eq. (12.10)] as
∂F
∂x
−
d
dt
(
∂F
∂ẋ
)
= 0 (12.28)
∂F
∂u
−
d
dt
(
∂F
∂u̇
)
= 0 (12.29)
In view of relation (12.27), Eqs. (12.28) and (12.29) can be expressed as
∂f0
∂x
+ λ
∂f
∂x
+ λ̇ = 0 (12.30)
∂f
∂u
+ λ
∂f
∂u
= 0 (12.31)
A new functional H , called the Hamiltonian , is defined as
H = f0 + λf (12.32)
and Eqs. (12.30) and (12.31) can be rewritten as
−
∂H
∂x
= λ̇ (12.33)
∂H
∂u
= 0 (12.34)
Equations (12.33) and (12.34) represent two first-order differential equations. The inte-
gration of these equations leads to two constants whose values can be found from the
known boundary conditions of the problem. If two boundary conditions are specified
as x(0) = k1 and x(T ) = k2, the two integration constants can be evaluated without
any difficulty. On the other hand, if only one boundary condition is specified as, say,
x(0) = k1, the free-end condition is used as ∂F/∂ẋ = 0 or λ = 0 at t = T .
Example 12.4 Find the optimal control u that makes the functional
J =
∫ 1
0
(x2 + u2) dt (E1)
stationary with
ẋ = u (E2)
and x(0) = 1. Note that the value of x is not specified at t = 1.
SOLUTION The Hamiltonian can be expressed as
H = f0 + λu = x2 + u2 + λu (E3)
and Eqs. (12.33) and (12.34) give
−2x = λ̇ (E4)
2u + λ = 0 (E5)
12.3 Optimal Control Theory 681
Differentiation of Eq. (E5) leads to
2u̇ + λ̇ = 0 (E6)
Equations (E4) and (E6) yield
u̇ = x (E7)
Since ẋ = u [Eq. (E2)], we obtain
ẍ = u̇ = x
that is,
ẍ − x = 0 (E8)
The solution of Eq. (E8) is given by
x(t) = c1 sinh t + c2 cosh t (E9)
where c1 and c2 are constants. By using the initial condition x(0) = 1, we obtain c2 = 1.
Since x is not fixed at the terminal point t = T = 1, we use the condition λ = 0 at
t = 1 in Eq. (E5) and obtain u(t = 1) = 0. But
u = ẋ = c1 cosh t + sinh t (E10)
Thus
u(1) = 0 = c1 cosh 1 + sinh 1
or
c1 =
− sinh 1
cosh 1
(E11)
and hence the optimal control is
u(t) =
− sinh 1
cosh 1
· cosh t + sinh t
=
− sinh 1 · cosh t + cosh 1 · sinh t
cosh 1
=
− sinh (1 − t)
cosh 1
(E12)
The corresponding state trajectory is given by
x(t) = u̇ =
cosh (1 − t)
cosh 1
(E13)
12.3.2 Necessary Conditions for a General Problem
We shall now consider the basic optimal control problem stated earlier:
Find the optimal control vector u that minimizes
J =
∫ T
0
f0(x, u, t) dt (12.35)
subject to
ẋi = fi(x, u, t), i = 1, 2, . . . , n (12.36)
682 Optimal Control and Optimality Criteria Methods
Now we introduce a Lagrange multiplier pi , also known as the adjoint variable, for
the ith constraint equation in (12.36) and form an augmented functional J ∗ as
J ∗ =
∫ T
0
[
f0 +
n
∑
i=1
pi(fi − ẋi)
]
dt (12.37)
The Hamiltonian functional, H , is defined as
H = f0 +
n
∑
i=1
pifi (12.38)
such that
J ∗ =
∫ T
0
(
H −
n
∑
i=1
pi ẋi
)
dt (12.39)
Since the integrand
F = H −
n
∑
i=1
pi ẋi (12.40)
depends on x, u, and t , there are n + m dependent variables (x and u) and hence the
Euler–Lagrange equations become
∂F
∂xi
−
d
dt
(
∂F
∂ẋi
)
= 0, i = 1, 2, . . . , n (12.41)
∂F
∂uj
−
d
dt
(
∂F
∂u̇j
)
= 0, j = 1, 2, . . . ,m (12.42)
In view of relation (12.40), Eqs. (12.41) and (12.42) can be rewritten as
−
∂H
∂xi
= pi, i = 1, 2, . . . , n (12.43)
∂H
∂ui
= 0, j = 1, 2, . . . , m (12.44)
Equations (12.43) are knowns as adjoint equations .
The optimum solutions for x, u, and p can be obtained by solving Eqs. (12.36),
(12.43), and (12.44). There are totally 2n + m equations with nx i’s, npi’s, and muj ’s
as unknowns. If we know the initial conditions xi(0), i = 1, 2, . . . , n, and the terminal
conditions xj (T ), j = 1, 2, . . . , l, with l < n, we will have the terminal values of the
remaining variables, namely xj (T ), j = l + 1, l + 2, . . . , n, free. Hence we will have
to use the free end conditions
pj (T ) = 0, j = l + 1, l + 2, . . . , n (12.45)
Equations (12.45) are called the transversality conditions .
12.4 Optimality Criteria Methods 683
12.4 OPTIMALITY CRITERIA METHODS
The optimality criteria methods are based on the derivation of an appropriate criteria for
specialized design conditions and developing an iterative procedure to find the optimum
design. The optimality criteria methods were originally developed by Prager and his
associates for distributed (continuous) systems [12.6] and extended by Venkayya, Khot,
and Berke for discrete systems [12.7–12.10]. The methods were first presented for
linear elastic structures with stress and displacement constraints and later extended to
problems with other types of constraints. We will present the basic approach using only
displacement constraints.
12.4.1 Optimality Criteria with a Single Displacement Constraint
Let the optimization problem be stated as follows:
Find X which minimizes f (X) =
n
∑
i=1
cixi (12.46)
subject to
n
∑
i=1
ai
xi
= ymax (12.47)
where ci are constants, ymax is the maximum permissible displacement, and ai depends
on the force induced in member i due to the applied loads, length of member i, and
Young’s modulus of member i. The Lagrangian function can be defined as
L(X, λ) =
n
∑
i=1
cixi + λ
(
n
∑
i=1
ai
xi
− ymax
)
(12.48)
At the optimum solution, we have
∂L
∂xk
= ck − λ
ak
x2k
+ λ
n
∑
i=1
1
xi
∂ai
∂xk
= 0, k = 1, 2, . . . , n (12.49)
It can be shown that the last term in Eq. (12.49) is zero for statically determinate as
well as indeterminate structures [12.8] so that Eq. (12.49) reduces to
ck − λ
ak
x2k
= 0, k = 1, 2, . . . , n (12.50)
or
λ =
ckx
2
k
ak
(12.51)
Equation (12.51) indicates that the quantity ckx
2
k/ak is the same for all the design
variables. If all the design variables are to be changed, this relation can be used.
However, in practice, only a subset of design variables are involved in Eq. (12.49).
Thus it is convenient to divide the design variables into two sets: active variables [those
determined by the displacement constraint of Eq. (12.51)] and passive variables (those
684 Optimal Control and Optimality Criteria Methods
determined by other considerations). Assuming that the first n variables denote the
active variables, we can rewrite Eqs. (12.46) and (12.47) as
f = f +
n
∑
i=1
cixi (12.52)
n
∑
i=1
ai
xi
= ymax − y = y∗ (12.53)
where f and y denote the contribution of the passive variables to f and y, respectively.
Equation (12.51) now gives
xk =
√
λ
√
ak
ck
, k = 1, 2, . . . , n (12.54)
Substituting Eq. (12.54) into Eq. (12.53), and solving for λ, we obtain
√
λ =
1
y∗
n
∑
k=1
√
akck (12.55)
Using Eq. (12.55) in Eq. (12.54) results in
xk =
1
y∗
√
ak
ck
n
∑
i=1
√
aici, k = 1, 2, . . . , n (12.56)
Equation (12.56) is the optimality criteria that must be satisfied at the optimum solu-
tion of the problem stated by Eqs. (12.46) and (12.47). This equation can be used to
iteratively update the design variables xk as
x
(j+1)
k =
(
1
y∗
√
ak
ck
n
∑
i=1
√
aici
)(j)
, k = 1, 2, . . . , n (12.57)
where the superscript j denotes the iteration cycle. In each iteration, the components
ak and ck are assumed to be constants (in general, they depend on the design vector).
12.4.2 Optimality Criteria with Multiple Displacement Constraints
When multiple displacement constraints are included, as in the case of a structure sub-
jected to multiple-load conditions, the optimization problem can be stated as follows:
Find a set of active variables X = {x1 x2 . . . xn}T which minimizes
f (X) = f0 +
n
∑
i=1
cixi (12.58)
subject to
yj =
n
∑
i=1
aj i
xi
= y∗j , j = 1, 2, . . . , J (12.59)
12.4 Optimality Criteria Methods 685
where J denotes the number of displacement (equality) constraints, y∗j the maximum
permissible value of the displacement yj , and aj i is a parameter that depends on the
force induced in member i due to the applied loads, length of member i, and Young’s
modulus of member i. The Lagrangian function corresponding to Eqs. (12.58) and
(12.59) can be expressed as
L(X, λ1, . . . , λJ ) = f0 +
n
∑
i=1
cixi +
J
∑
j=1
λj
(
n
∑
i=1
aj i
xi
− y∗j
)
(12.60)
and the necessary conditions of optimality are given by
∂L
∂xk
= ck −
J
∑
j=1
λj
aj i
x2k
= 0, k = 1, 2, . . . , n (12.61)
Equations (12.61) can be rewritten as
xk =


J
∑
j=1
(
λj
aj i
ck
)


1/2
, k = 1, 2, . . . , n (12.62)
Note that Eq. (12.62) can be used to iteratively update the variable xk as
x
(j+1)
k =







J
∑
j=1
(
λj
aj i
ck
)


1/2





(j)
, k = 1, 2, . . . , n (12.63)
where the values of the Lagrange multipliers λj are also not known at the beginning.
Several computational methods can be used to solve Eqs. (12.63) [12.7, 12.8].
12.4.3 Reciprocal Approximations
In some structural optimization problems, it is convenient and useful to consider the
reciprocals of member cross-sectional areas (1/Ai) as the new design variables (zi). If
the problem deals with the minimization of weight of a statically determinate structure
subject to displacement or stress constraints, the objective function and its gradient
can be expressed as explicit functions of the variables zi and the constraints can be
expressed as linear functions of the variables zi . If the structure is statically indeter-
minate, the objective function remains a simple function of zi but the constraints may
not be linear in terms of zi ; however, a first-order Taylor series (linear) approximation
of the constraints denote a very high-quality approximation of these constraints. With
reciprocal variables, the optimization problem with a single displacement constraint
can be stated as follows:
Find Z = {z1 z2 . . . zn}T which minimizes f (Z) (12.64)
subject to
g(Z) = 0 (12.65)
686 Optimal Control and Optimality Criteria Methods
The necessary condition of optimality can be expressed as
∂f
∂zi
+ λ
∂g
∂zi
= 0, i = 1, 2, . . . , n (12.66)
Assuming f to be linear in terms of the areas of cross section (original variables,
xi = Ai) and g to be linear in terms of zi , we have
∂f
∂zi
=
∂f
∂xi
∂xi
∂zi
= −
1
z2i
∂f
∂xi
(12.67)
and Eqs. (12.66) and (12.67) yield
xi =
(
λ
∂g/∂zi
∂f/∂xi
)1/2
, i = 1, 2, . . . , n (12.68)
To find λ we first find the linear approximation of g at a reference point (trial design)
Z0 (or X0) as
g(Z) ≈ g(Z0) +
n
∑
i=1
∂g
∂zi
∣
∣
∣
∣
Z0
(zi − z0i) ≈ g0 +
n
∑
i=1
∂g
∂zi
∣
∣
∣
∣
Z0
zi (12.69)
where
g0 = g(Z0) −
n
∑
i=1
∂g
∂zi
∣
∣
∣
∣
Z0
z0i = g(X0) +
n
∑
i=1
∂g
∂xi
∣
∣
∣
∣
X0
x0i (12.70)
and z0i is the ith component of Z0 with x0i = 1/z0i . By setting Eq. (12.69) equal to
zero and substituting Eq. (12.68) for xi , we obtain
λ =
[
1
g0
n
∑
i=1
(
∂f
∂xi
∂g
∂zi
)1/2
]2
(12.71)
Equations (12.71) and (12.68) can now be used iteratively to find the optimal solution
of the problem. The procedure is explained through the following example.
Example 12.5 The problem of minimum weight design subject to a constraint on the
vertical displacement of node S(U1) of the three-bar truss shown in Fig. 12.6 can be
stated as follows:
Find X =
{
x1
x2
}
which minimizes
f (X) = ρ(2
√
2 l)x1 + ρlx2 = 80.0445x1 + 28.3x2 (E1)
subject to
U1
Umax
− 1 ≤ 0
or
g(X) =
1
x1 +
√
2 x2
− 1 ≤ 0 (E2)
12.4 Optimality Criteria Methods 687
Figure 12.6 Three-bar truss.
where ρ is the weight density, E is Young’s modulus, Umax the maximum permissible
displacement, x1 the area of cross section of bars 1 and 3, x2 the area of cross section
of bar 2, and the vertical displacement of node S is given by
U1 =
P1l
E
1
x1 +
√
2 x2
(E3)
Find the solution of the problem using the optimality criteria method.
SOLUTION The partial derivatives of f and g required by Eqs. (12.68) and (12.71)
can be computed as
∂f
∂x1
= 80.0445,
∂f
∂x2
= 28.3
∂g
∂zi
=
∂g
∂xi
∂xi
∂zi
=
∂g
∂xi
(−x2i ), i = 1, 2
∂g
∂x1
=
−1
(x1 +
√
2 x2)2
,
∂g
∂x2
=
−
√
2
(x1 +
√
2 x2)2
At any design Xi , Eq. (12.70) gives
g0 = g(Xi) +
∂g
∂x1
∣
∣
∣
∣
Xi
xi1 +
∂g
∂x2
∣
∣
∣
∣
Xi
xi2
=
1
xi1 +
√
2 xi2
− 1 −
xi1
(xi1 +
√
2 xi2)2
−
√
2 xi2
(xi1 +
√
2 xi2)2
Thus the values of λ and (x1, x2) can be determined iteratively using Eqs. (12.71) and
(12.68). Starting from the initial design (x1, x2) = (2.0, 2.0) in2, the results obtained
are shown in Table 12.1.
T
a
b
le
1
2
.1
R
es
u
lt
s
fo
r
E
x
am
p
le
1
2
.5
a
S
ta
rt
in
g
v
al
u
es
g
0
λ
S
o
lu
ti
o
n
fr
o
m
E
q
.
(1
2
.6
8
)
x
1
x
2
[E
q
.
(1
2
.7
0
)]
[E
q
.
(1
2
.7
1
)]
x
1
x
2
0
.2
0
0
0
0
E
+
0
1
0
.2
0
0
0
0
E
+
0
1
–
0
.1
0
0
0
0
E
+
0
1
0
.4
0
0
2
2
E
+
0
2
0
.2
9
2
8
9
E
+
0
0
0
.5
8
5
7
9
E
+
0
0
0
.2
9
2
8
9
E
+
0
0
0
.5
8
5
7
9
E
+
0
0
–
0
.1
0
0
0
0
E
+
0
1
0
.3
1
8
3
0
E
+
0
2
0
.1
6
4
7
2
E
+
0
0
0
.6
5
8
8
6
E
+
0
0
0
.1
6
4
7
2
E
+
0
0
0
.6
5
8
8
6
E
+
0
0
–
0
.1
0
0
0
0
E
+
0
1
0
.2
6
4
7
5
E
+
0
2
0
.8
6
3
9
4
E
–
0
1
0
.6
9
1
1
5
E
+
0
0
0
.1
0
0
0
0
E
+
0
0
0
.6
9
1
1
5
E
+
0
0
–
0
.1
0
0
0
0
E
+
0
1
0
.2
3
8
9
8
E
+
0
2
0
.5
0
7
1
4
E
–
0
1
0
.7
0
1
0
2
E
+
0
0
0
.1
0
0
0
0
E
+
0
0
0
.7
0
1
0
2
E
+
0
0
–
0
.1
0
0
0
0
E
+
0
1
0
.2
3
8
4
6
E
+
0
2
0
.5
0
0
1
1
E
–
0
1
0
.7
0
1
1
7
E
+
0
0
0
.1
0
0
0
0
E
+
0
0
0
.7
0
1
1
7
E
+
0
0
–
0
.1
0
0
0
0
E
+
0
1
0
.2
3
8
4
5
E
+
0
2
0
.5
0
0
0
0
E
–
0
1
0
.7
0
1
1
7
E
+
0
0
0
.1
0
0
0
0
E
+
0
0
0
.7
0
1
1
7
E
+
0
0
–
0
.1
0
0
0
0
E
+
0
1
0
.2
3
8
4
5
E
+
0
2
0
.5
0
0
0
0
E
–
0
1
0
.7
0
1
1
7
E
+
0
0
a
W
it
h
lo
w
er
b
o
u
n
d
s
o
n
x
1
an
d
x
2
as
0
.1
.
688
Review Questions 689
REFERENCES AND BIBLIOGRAPHY
12.1 R. S. Schechter, The Variational Method in Engineering , McGraw-Hill, New York, 1967.
12.2 M. M. Denn, Optimization by Variational Methods , McGraw-Hill, New York, 1969.
12.3 M. J. Forray, Variational Calculus in Science and Engineering , McGraw-Hill, New York,
1968.
12.4 A. E. Bryson and Y. C. Ho, Applied Optimal Control , Wiley, New York, 1975.
12.5 A. Shamaly, G. S. Christensen, and M. E. El-Hawary, Optimal control of a large tur-
boalternator, Journal of Optimization Theory and Applications , Vol. 34, pp. 83–97,
1981.
12.6 W. Prager, Optimality criteria in structural design, Proceedings of the National Academy
of Science, Vol. 61, No. 3, pp. 794–796, 1968.
12.7 V. B. Venkayya, N. S. Khot, and V. S. Reddy, Energy Distribution in Optimum Structural
Design , AFFDL-TR-68-156, 1968.
12.8 L. Berke, Convergence Behavior of Optimality Criteria Based Iterative Procedures ,
AFFDL-TM-72-1-FBR, Jan. 1972.
12.9 V. B. Venkayya, Structural optimization using optimality criteria: a review and some
recommendations, International Journal for Numerical Methods in Engineering , Vol. 13,
pp. 203–228, 1978.
12.10 N. S. Khot, Algorithms based on optimality criteria to design minimum weight structures,
Engineering Optimization , Vol. 5, pp. 73–90, 1981.
12.11 S. K. Hati and S. S. Rao, Determination of optimum profile of one-dimensional cooling
fins, ASME Journal of Vibration, Acoustics, Stress and Reliability in Design , Vol. 105,
pp. 317–320, 1983.
REVIEW QUESTIONS
12.1 Answer true or false:
(a) Design variables of an optimal control problem include both state and control
variables.
(b) Reciprocal approximations consider reciprocals of member areas as design vari-
ables.
(c) Optimality criteria methods can be used for the optimization of nonlinear struc-
tures with displacement constraints.
(d) A variational operator is similar to a differential operator.
(e) Calculus of variations can be used only for finding the extrema of functionals
with no constraints.
(f) Optimality criteria methods can be used to solve any optimization problem.
12.2 Define the following terms:
(a) Brachistochrone
(b) State vector
(c) Performance index
(d) Adjoint equations
(e) Transversality condition
(f) Optimality criteria methods
690 Optimal Control and Optimality Criteria Methods
(g) Functional
(h) Hamiltonian
12.3 Match the following terms and descriptions:
(a) Adjoint variables Linear elastic structures
(b) Optimality criteria methods Lagrange multipliers
(c) Calculus of variations Necessary conditions of optimality
(d) Optimal control theory Optimization of functionals
(e) Governing equations Hamiltonian used
12.4 What are the characteristics of a variational operator?
12.5 What are Euler–Lagrange equations?
12.6 Which method can be used to solve a trajectory optimization problem?
12.7 What is an optimality criteria method?
12.8 What is the basis of optimality criteria methods?
12.9 What are the advantages of using reciprocal approximations in structural optimization?
12.10 What is the difference between free and forced boundary conditions?
12.11 What type of problems require introduction of Lagrange multipliers?
12.12 Where are reciprocal approximations used? Why?
PROBLEMS
12.1 Find the curve connecting two points A(0, 0) and B(2, 0) such that the length of the
line is a minimum and the area under the curve is π /2.
12.2 Prove that the shortest distance between two points is a straight line. Show that the
necessary conditions yield a minimum and not a maximum.
12.3 Find the function x(t) that minimizes the functional
A =
∫ T
0
[
x2 + 2xt +
(
dx
dt
)2
]
dt
with the condition that x(0) = 2.
12.4 Find the closed plane curve of length L that encloses a maximum area.
12.5 The potential energy of an elastic circular annular plate of radii r1 and r2 shown in
Fig. 12.7 is given by
π0 = πD
∫ r2
r1
[
r
(
d2w
dr2
)2
+
1
r
(
dw
dr
)2
+ 2ν
dw
dr
d2w
dr2
]
dr
− 2π
∫ r2
r1
qrw dr + 2π
[
rM
dw
dr
− rQw
]
r=r2
Problems 691
Figure 12.7 Circular annular plate under load.
where D is the flexural rigidity of the plate, w the transverse deflection of the plate, ν
the Poisson’s ratio, M the radial bending moment per unit of circumferential length, and
Q the radial shear force per unit of circumferential length. Find the differential equation
and the boundary conditions to be satisfied by minimizing π0.
12.6 Consider the two-bar truss shown in Fig. 12.8. For the minimum-weight design of the
truss with a bound on the horizontal displacement of node S, we need to solve the
following problem:
Find X = {x1 x2}Twhich minimizes
f (X) =
√
2 l(x1 + x2) =
√
2 60(x1 + x2)
subject to
g(X) =
P l
2E
(
1
x1
+
1
x2
)
− Umax
= 10−3
(
1
x1
+
1
x2
)
− 10−2 ≤ 0
0.1 in.2 ≤ xi ≤ 1.0 in.2, i = 1, 2
Find the solution of the problem using the optimality criteria method.
12.7 In the three-bar truss considered in Example 12.5 (Fig. 12.6), if the constraint is placed
on the resultant displacement of node S, the optimization problem can be stated as
Find X =
{
x1
x2
}
which minimizes
f (X) = 80.0445x1 + 28.3x2
subject to
√
U 21 + U 22 =
P1l
E
[
1
x21
+
1
(x1 +
√
2 x2)2
]1/2
≤ Umax
or
g(X) =
[
1
x21
+
1
(x1 +
√
2 x2)2
]1/2
≤ Umax
where the vertical and horizontal displacements of node S are given by
U1 =
P l
E
1
x1 +
√
2 x2
and U2 =
P l
E
1
x1
Find the solution of the problem using the optimality criteria method.
692 Optimal Control and Optimality Criteria Methods
Figure 12.8 Two-bar truss subjected to horizontal load.
12.8 The problem of the minimum-weight design of the four-bar truss shown in Fig. 1.32
(Problem 1.31) subject to a constraint on the vertical displacement of joint A and limi-
tations on design variables can be stated as follows:
Find X = {x1 x2}T which minimizes
f (X) = 0.1x1 + 0.05773x2
subject to
g(X) =
0.6
x1
+
0.3464
x2
− 0.1 ≤ 0
xi ≥ 4, i = 1, 2
where the maximum permissible vertical displacement of joint A is assumed to be 0.01 in.
Solve the problem using the optimality criteria method.
13
Modern Methods of Optimization
13.1 INTRODUCTION
In recent years, some optimization methods that are conceptually different from the tra-
ditional mathematical programming techniques have been developed. These methods
are labeled as modern or nontraditional methods of optimization. Most of these meth-
ods are based on certain characteristics and behavior of biological, molecular, swarm
of insects, and neurobiological systems. The following methods are described in this
chapter:
1. Genetic algorithms
2. Simulated annealing
3. Particle swarm optimization
4. Ant colony optimization
5. Fuzzy optimization
6. Neural-network-based methods
Most of these methods have been developed only in recent years and are emerging
as popular methods for the solution of complex engineering problems. Most require
only the function values (and not the derivatives). The genetic algorithms are based
on the principles of natural genetics and natural selection. Simulated annealing is
based on the simulation of thermal annealing of critically heated solids. Both genetic
algorithms and simulated annealing are stochastic methods that can find the global
minimum with a high probability and are naturally applicable for the solution of discrete
optimization problems. The particle swarm optimization is based on the behavior of
a colony of living things, such as a swarm of insects, a flock of birds, or a school of
fish. Ant colony optimization is based on the cooperative behavior of real ant colonies,
which are able to find the shortest path from their nest to a food source. In many
practical systems, the objective function, constraints, and the design data are known
only in vague and linguistic terms. Fuzzy optimization methods have been developed
for solving such problems. In neural-network-based methods, the problem is modeled
as a network consisting of several neurons, and the network is trained suitably to solve
the optimization problem efficiently.
693Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
694 Modern Methods of Optimization
13.2 GENETIC ALGORITHMS
13.2.1 Introduction
Many practical optimum design problems are characterized by mixed continuous–
discrete variables, and discontinuous and nonconvex design spaces. If standard nonlin-
ear programming techniques are used for this type of problem they will be inefficient,
computationally expensive, and, in most cases, find a relative optimum that is closest to
the starting point. Genetic algorithms (GAs) are well suited for solving such problems,
and in most cases they can find the global optimum solution with a high probability.
Although GAs were first presented systematically by Holland [13.1], the basic ideas
of analysis and design based on the concepts of biological evolution can be found in
the work of Rechenberg [13.2]. Philosophically, GAs are based on Darwin’s theory of
survival of the fittest.
Genetic algorithms are based on the principles of natural genetics and natural
selection. The basic elements of natural genetics—reproduction, crossover, and
mutation—are used in the genetic search procedure. GAs differ from the traditional
methods of optimization in the following respects:
1. A population of points (trial design vectors) is used for starting the procedure
instead of a single design point. If the number of design variables is n, usually
the size of the population is taken as 2n to 4n. Since several points are used as
candidate solutions, GAs are less likely to get trapped at a local optimum.
2. GAs use only the values of the objective function. The derivatives are not used
in the search procedure.
3. In GAs the design variables are represented as strings of binary variables that
correspond to the chromosomes in natural genetics. Thus the search method
is naturally applicable for solving discrete and integer programming problems.
For continuous design variables, the string length can be varied to achieve any
desired resolution.
4. The objective function value corresponding to a design vector plays the role of
fitness in natural genetics.
5. In every new generation, a new set of strings is produced by using randomized
parents selection and crossover from the old generation (old set of strings).
Although randomized, GAs are not simple random search techniques. They
efficiently explore the new combinations with the available knowledge to find
a new generation with better fitness or objective function value.
13.2.2 Representation of Design Variables
In GAs, the design variables are represented as strings of binary numbers, 0 and 1. For
example, if a design variable xi is denoted by a string of length four (or a four-bit string)
as 0 1 0 1, its integer (decimal equivalent) value will be (1) 20 + (0) 21 + (1) 22 +
(0) 23 = 1 + 0 + 4 + 0 = 5. If each design variable xi, i = 1, 2, . . . , n is coded in
a string of length q, a design vector is represented using a string of total length nq.
For example, if a string of length 5 is used to represent each variable, a total string
of length 20 describes a design vector with n = 4. The following string of 20 binary
digits denote the vector (x1 = 18, x2 = 3, x3 = 1, x4 = 4):
13.2 Genetic Algorithms 695
String of length 20
1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0
x1 x2 x3 x4
In general, if a binary number is given by bqbq−1 · · · b2b1b0, where bk = 0 or 1,
k = 0, 1, 2, . . . , q, then its equivalent decimal number y (integer) is given by
y =
q
∑
k=0
2kbk (13.1)
This indicates that a continuous design variable x can only be represented by a set
of discrete values if binary representation is used. If a variable x (whose bounds are
given by x(l) and x(u)) is represented by a string of q binary numbers, as shown in
Eq. (13.1), its decimal value can be computed as
x = x(l) +
x(u) − x(l)
2q − 1
q
∑
k=0
2kbk (13.2)
Thus if a continuous variable is to be represented with high accuracy, we need to use a
large value of q in its binary representation. In fact, the number of binary digits needed
(q) to represent a continuous variable in steps (accuracy) of x can be computed from
the relation
2q ≥
x(u) − x(l)
x
+ 1 (13.3)
For example, if a continuous variable x with bounds 1 and 5 is to be represented with
an accuracy of 0.01, we need to use a binary representation with q digits where
2q ≥
5 − 1
0.01
+ 1 = 401 or q = 9 (13.4)
Equation (13.2) shows why GAs are naturally suited for solving discrete optimization
problems.
Example 13.1 Steel plates are available in thicknesses (in inches) of
1
32
, 1
16
, 3
32
, 1
8
, 5
32
, 3
16
, 7
32
, 1
4
, 9
32
, 5
16
, 11
32
, 3
8
, 13
32
, 7
16
, 15
32
, 1
2
from a manufacturer. If the thickness of the steel plate, to be used in the construction
of a pressure vessel, is considered as a discrete design variable, determine the size of
the binary string to be used to select a thickness from the available values.
SOLUTION The lower and upper bounds on the steel plate (design variable, x) are
given by 1
32
and 1
2
in., respectively, and the resolution or difference between any two
adjacent thicknesses is 1
32
in. Equation (13.3) gives
2q ≥
x(u) − x(l)
x
+ 1 =
1
2
in. − 1
32
in.
1
32
in.
+ 1 = 15
from which the size of the binary string to be used can be obtained as q = 4.
696 Modern Methods of Optimization
13.2.3 Representation of Objective Function and Constraints
Because genetic algorithms are based on the survival-of-the-fittest principle of nature,
they try to maximize a function called the fitness function. Thus GAs are naturally
suitable for solving unconstrained maximization problems. The fitness function, F(X),
can be taken to be same as the objective function f (X) of an unconstrained maximiza-
tion problem so that F(X) = f (X). A minimization problem can be transformed into a
maximization problem before applying the GAs. Usually the fitness function is chosen
to be nonnegative. The commonly used transformation to convert an unconstrained
minimization problem to a fitness function is given by
F(X) =
1
1 + f (X)
(13.5)
It can be seen that Eq. (13.5) does not alter the location of the minimum of f (X) but
converts the minimization problem into an equivalent maximization problem.
A general constrained minimization problem can be stated as
Minimize f (X)
subject to
gi(X) ≤ 0, i = 1, 2, . . . , m (13.6)
and
hj (X) = 0, j = 1, 2, . . . , p
This problem can be converted into an equivalent unconstrained minimization problem
by using the concept of penalty function as
Minimize φ(X) = f (X) +
m
∑
i=1
ri 〈gi(X)〉
2 +
p
∑
j=1
Rj
(
hj (X)
)2
(13.7)
where ri and Rj are the penalty parameters associated with the constraints gi(X) and
hj (X), whose values are usually kept constant throughout the solution process. In
Eq. (13.7), the function 〈gi(X)〉, called the bracket function, is defined as
〈gi(X)〉 =
{
gi(X) if gi(X) > 0
0 if gi(X) ≤ 0
(13.8)
In most cases, the penalty parameters associated with all the inequality and equality
constraints are assumed to be the same constants as
ri = r, i = 1, 2, . . . , m and Rj = R, j = 1, 2, . . . , p (13.9)
where r and R are constants. The fitness function, F(X), to be maximized in the GAs
can be obtained, similar to Eq. (13.5), as
F(X) =
1
1 + φ(X)
(13.10)
13.2 Genetic Algorithms 697
Equations (13.7) and (13.8) show that the penalty will be proportional to the square of
the amount of violation of the inequality and equality constraints at the design vector
X, while there will be no penalty added to f (X) if all the constraints are satisfied at
the design vector X.
13.2.4 Genetic Operators
The solution of an optimization problem by GAs starts with a population of random
strings denoting several (population of) design vectors. The population size in GAs (n)
is usually fixed. Each string (or design vector) is evaluated to find its fitness value.
The population (of designs) is operated by three operators—reproduction, crossover,
and mutation—to produce a new population of points (designs). The new population is
further evaluated to find the fitness values and tested for the convergence of the process.
One cycle of reproduction, crossover, and mutation and the evaluation of the fitness
values is known as a generation in GAs. If the convergence criterion is not satisfied,
the population is iteratively operated by the three operators and the resulting new pop-
ulation is evaluated for the fitness values. The procedure is continued through several
generations until the convergence criterion is satisfied and the process is terminated.
The details of the three operations of GAs are given below.
Reproduction. Reproduction is the first operation applied to the population to select
good strings (designs) of the population to form a mating pool. The reproduction
operator is also called the selection operator because it selects good strings of the
population. The reproduction operator is used to pick above-average strings from the
current population and insert their multiple copies in the mating pool based on a
probabilistic procedure. In a commonly used reproduction operator, a string is selected
from the mating pool with a probability proportional to its fitness. Thus if Fi denotes
the fitness of the ith string in the population of size n, the probability for selecting the
ith string for the mating pool (pi) is given by
pi =
Fi
n
∑
j=1
Fj
; i = 1, 2, . . . , n (13.11)
Note that Eq. (13.11) implies that the sum of the probabilities of the strings of the pop-
ulation being selected for the mating pool is one. The implementation of the selection
process given by Eq. (13.11) can be understood by imagining a roulette wheel with its
circumference divided into segments, one for each string of the population, with the
segment lengths proportional to the fitness of the strings as shown in Fig. 13.1. By
spinning the roulette wheel n times (n being the population size) and selecting, each
time, the string chosen by the roulette-wheel pointer, we obtain a mating pool of size
n. Since the segments of the circumference of the wheel are marked according to the
fitness of the various strings of the original population, the roulette-wheel process is
expected to select Fi/F copies of the ith string for the mating pool, where F denotes
the average fitness of the population:
F =
1
n
n
∑
j=1
Fj (13.12)
698 Modern Methods of Optimization
Roulette wheel
Fitness
values
3
2
1
6
5
4 Pointer
16%
8% 36%
24%
12%
4%
String
numbers
Figure 13.1 Roulette-wheel selection scheme.
In Fig. 13.1, the population size is assumed to be 6 with fitness values of the strings
1, 2, 3, 4, 5, and 6 given by 12, 4, 16, 8, 36, and 24, respectively. Since the fifth
string (individual) has the highest value, it is expected to be selected most of the time
(36% of the time, probabilistically) when the roulette wheel is spun n times (n = 6 in
Fig. 13.1). The selection scheme, based on the spinning of the roulette wheel, can be
implemented numerically during computations as follows.
The probabilities of selecting different strings based on their fitness values are
calculated using Eq. (13.11). These probabilities are used to determine the cumulative
probability of string i being copied to the mating pool, Pi , by adding the individual
probabilities of strings 1 through i as
Pi =
i
∑
j=1
pj (13.13)
Thus the roulette-wheel selection process can be implemented by associating the cumu-
lative probability range (Pi−1 − Pi) to the ith string. To generate the mating pool of
Table 13.1 Roulette-Wheel Selection Process for Obtaining the Mating Pool
Probability of Cumulative Range of
selecting string i probability value cumulative
for the mating of string i, probability of
String number i Fitness value Fi pool, pi Pi =
i
∑
j=1
pj string i, (Pi−1, Pi)
1 12 0.12 0.12 0.00–0.12
2 4 0.04 0.16 0.12–0.16
3 16 0.16 0.32 0.16–0.32
4 8 0.08 0.40 0.32–0.40
5 36 0.36 0.76 0.40–0.76
6 24 0.24 1.00 0.76–1.00
13.2 Genetic Algorithms 699
size n during numerical computations, n random numbers, each in the range of zero
to one, are generated (or chosen). By treating each random number as the cumulative
probability of the string to be copied to the mating pool, n strings corresponding to the n
random numbers are selected as members of the mating pool. By this process, the string
with a higher (lower) fitness value will be selected more (less) frequently to the mating
pool because it has a larger (smaller) range of cumulative probability. Thus strings with
high fitness values in the population, probabilistically, get more copies in the mating
pool. It is to be noted that no new strings are formed in the reproduction stage; only
the existing strings in the population get copied to the mating pool. The reproduction
stage ensures that highly fit individuals (strings) live and reproduce, and less fit indi-
viduals (strings) die. Thus the GAs simulate the principle of “survival-of-the-fittest”
of nature.
Example 13.2 Consider six strings with fitness values 12, 4, 16, 8, 36, and 24 with
the corresponding roulette wheel as shown in Fig. 13.1. Find the levels of contribution
of the various strings to the mating pool using the roulette-wheel selection process with
the following 12 random numbers: 0.41, 0.65, 0.42, 0.80, 0.67, 0.39, 0.63, 0.53, 0.86,
0.88, 0.75, 0.55.
Note: (1) These random numbers are taken from Ref. [13.20]. (2) Although the original
population consists of only 6 strings, the mating pool is assumed to be composed of
12 strings to illustrate the roulette-wheel selection process.
SOLUTION If the given random numbers are assumed to represent cumulative
probabilities, the string numbers to be copied to the mating pool can be determined
from the cumulative probability ranges listed in the last column of Table 13.1 as
follows:
Random number
(cumulative probability of
the string to be copied)
0.41 0.65 0.42 0.80 0.67 0.39 0.63 0.53 0.86 0.88 0.75 0.55
String number to be copied
to the mating pool
5 5 5 6 5 4 5 5 6 6 5 5
This indicates that the mating pool consists of 1 copy of string 4, 8 copies of string 5,
and 3 copies of string 6. This shows that less fit individuals (strings 1, 2, and 3) did
not contribute to the next generation (or died) because they could not contribute to the
mating pool. String 4, although has a small fitness value, contributed 1 copy to the
mating pool based on the random selection process used.
Crossover. After reproduction, the crossover operator is implemented. The purpose
of crossover is to create new strings by exchanging information among strings of the
mating pool. Many crossover operators have been used in the literature of GAs. In most
crossover operators, two individual strings (designs) are picked (or selected) at random
from the mating pool generated by the reproduction operator and some portions of the
strings are exchanged between the strings. In the commonly used process, known as a
700 Modern Methods of Optimization
single-point crossover operator, a crossover site is selected at random along the string
length, and the binary digits (alleles) lying on the right side of the crossover site are
swapped (exchanged) between the two strings. The two strings selected for participation
in the crossover operators are known as parent strings and the strings generated by the
crossover operator are known as child strings.
For example, if two design vectors (parents), each with a string length of 10, are
given by
(Parent 1) X1 = {0 1 0 | 1 0 1 1 0 1 1}
(Parent 2) X2 = {1 0 0 | 0 1 1 1 1 0 0}
the result of crossover, when the crossover site is 3, is given by
(Offspring 1) X3 = {0 1 0 | 0 1 1 1 1 0 0}
(Offspring 2) X4 = {1 0 0 | 1 0 1 1 0 1 1}
Since the crossover operator combines substrings from parent strings (which have
good fitness values), the resulting child strings created are expected to have better
fitness values provided an appropriate (suitable) crossover site is selected. However,
the suitable or appropriate crossover site is not known before hand. Hence the crossover
site is usually chosen randomly. The child strings generated using a random crossover
site may or may not be as good or better than their parent strings in terms of their
fitness values. If they are good or better than their parents, they will contribute to a
faster improvement of the average fitness value of the new population. On the other
hand, if the child strings created are worse than their parent strings, it should not be of
much concern to the success of the GAs because the bad child strings will not survive
very long as they are less likely to be selected in the next reproduction stage (because
of the survival-of-the-fittest strategy used).
As indicated above, the effect of crossover may be useful or detrimental. Hence it
is desirable not to use all the strings of the mating pool in crossover but to preserve
some of the good strings of the mating pool as part of the population in the next
generation. In practice, a crossover probability, pc, is used in selecting the parents for
crossover. Thus only 100 pc percent of the strings in the mating pool will be used in
the crossover operator while 100 (1 − pc) percent of the strings will be retained as
they are in the new generation (of population).
Mutation. The crossover is the main operator by which new strings with better fitness
values are created for the new generations. The mutation operator is applied to the new
strings with a specific small mutation probability, pm. The mutation operator changes
the binary digit (allele’s value) 1 to 0 and vice versa. Several methods can be used
for implementing the mutation operator. In the single-point mutation, a mutation site
is selected at random along the string length and the binary digit at that site is then
changed from 1 to 0 or 0 to 1 with a probability of pm. In the bit-wise mutation, each
bit (binary digit) in the string is considered one at a time in sequence, and the digit
is changed from 1 to 0 or 0 to 1 with a probability pm. Numerically, the process can
be implemented as follows. A random number between 0 and 1 is generated/chosen.
If the random number is smaller than pm, then the binary digit is changed. Otherwise,
the binary digit is not changed.
13.2 Genetic Algorithms 701
The purpose of mutation is (1) to generate a string (design point) in the neigh-
borhood of the current string, thereby accomplishing a local search around the current
solution, (2) to safeguard against a premature loss of important genetic material at a
particular position, and (3) to maintain diversity in the population.
As an example, consider the following population of size n = 5 with a string
length 10:
1 0 0 0 1 0 0 0 1 1
1 0 1 1 1 1 0 1 0 0
1 1 0 0 0 0 1 1 0 1
1 0 1 1 0 1 0 0 1 0
1 1 1 0 0 0 1 0 0 1
Here all the five strings have a 1 in the position of the first bit. The true optimum
solution of the problem requires a 0 as the first bit. The required 0 cannot be created
by either the reproduction or the crossover operators. However, when the mutation
operator is used, the binary number will be changed from 1 to 0 in the location of the
first bit with a probability of npm.
Note that the three operators—reproduction, crossover, and mutation—are simple
to implement. The reproduction operator selects good strings for the mating pool, the
crossover operator recombines the substrings of good strings of the mating pool to
create strings (next generation of population), and the mutation operator alters the
string locally. The use of these three operators successively yields new generations
with improved values of average fitness of the population. Although, the improvement
of the fitness of the strings in successive generations cannot be proved mathematically,
the process has been found to converge to the optimum fitness value of the objective
function. Note that if any bad strings are created at any stage in the process, they will
be eliminated by the reproduction operator in the next generation. The GAs have been
successfully used to solve a variety of optimization problems in the literature.
13.2.5 Algorithm
The computational procedure involved in maximizing the fitness function F(x1,
x2, x3, . . . , xn) in the genetic algorithm can be described by the following steps.
1. Choose a suitable string length l = nq to represent the n design variables of
the design vector X. Assume suitable values for the following parameters: pop-
ulation size m, crossover probability pc, mutation probability pm, permissible
value of standard deviation of fitness values of the population (sf )max to use as
a convergence criterion, and maximum number of generations (imax) to be used
an a second convergence criterion.
2. Generate a random population of size m, each consisting of a string of length
l = nq. Evaluate the fitness values Fi, i = 1, 2, . . . , m, of the m strings.
3. Carry out the reproduction process.
4. Carry out the crossover operation using the crossover probability pc.
702 Modern Methods of Optimization
5. Carry out the mutation operation using the mutation probability pm to find the
new generation of m strings.
6. Evaluate the fitness values Fi, i = 1, 2, . . . , m, of the m strings of the new
population. Find the standard deviation of the m fitness values.
7. Test for the convergence of the algorithm or process. If sf ≤ (sf )max, the con-
vergence criterion is satisfied and hence the process may be stopped. Otherwise,
go to step 8.
8. Test for the generation number. If i ≥ imax, the computations have been per-
formed for the maximum permissible number of generations and hence the
process may be stopped. Otherwise, set the generation number as i = i + 1 and
go to step 3.
13.2.6 Numerical Results
The welded beam problem described in Section 7.22.3 (Fig. 7.23) was considered by
Deb [13.20] with the following data: population size = 100, total string length = 40,
substring length for each design variable = 10, probability of crossover = 0.9, and prob-
ability of mutation = 0.01. Different penalty parameters were considered for different
constraints in order to have the contribution of each constraint violation to the objec-
tive function be approximately the same. Nearly optimal solutions were obtained after
only about 15 generations with approximately 0.9 × 100 × 15 = 1350 function evalua-
tions. The optimum solution was found to be x∗1 = 0.2489, x
∗
2 = 6.1730, x
∗
3 = 8.1789,
x∗4 = 0.2533, and f
∗ = 2.43, which can be compared with the solution obtained from
geometric programming, x∗1 = 0.2455, x
∗
2 = 6.1960, x
∗
3 = 8.2730, x
∗
4 = 0.2455, and
f ∗ = 2.39 [13.21]. Although the optimum solution given by the GAs corresponds to
a slightly larger value of f ∗, it satisfies all the constraints (the solution obtained from
geometric programming violates three constraints slightly).
13.3 SIMULATED ANNEALING
13.3.1 Introduction
The simulated annealing method is based on the simulation of thermal annealing of
critically heated solids. When a solid (metal) is brought into a molten state by heating
it to a high temperature, the atoms in the molten metal move freely with respect to each
other. However, the movements of atoms get restricted as the temperature is reduced.
As the temperature reduces, the atoms tend to get ordered and finally form crystals
having the minimum possible internal energy. The process of formation of crystals
essentially depends on the cooling rate. When the temperature of the molten metal is
reduced at a very fast rate, it may not be able to achieve the crystalline state; instead,
it may attain a polycrystalline state having a higher energy state compared to that of
the crystalline state. In engineering applications, rapid cooling may introduce defects
inside the material. Thus the temperature of the heated solid (molten metal) needs to
be reduced at a slow and controlled rate to ensure proper solidification with a highly
ordered crystalline state that corresponds to the lowest energy state (internal energy).
This process of cooling at a slow rate is known as annealing.
13.3 Simulated Annealing 703
13.3.2 Procedure
The simulated annealing method simulates the process of slow cooling of molten
metal to achieve the minimum function value in a minimization problem. The cooling
phenomenon of the molten metal is simulated by introducing a temperature-like param-
eter and controlling it using the concept of Boltzmann’s probability distribution. The
Boltzmann’s probability distribution implies that the energy (E) of a system in thermal
equilibrium at temperature T is distributed probabilistically according to the relation
P(E) = e−E/kT (13.14)
where P(E) denotes the probability of achieving the energy level E, and k is called the
Boltzmann’s constant. Equation (13.14) shows that at high temperatures the system has
nearly a uniform probability of being at any energy state; however, at low temperatures,
the system has a small probability of being at a high-energy state. This indicates that
when the search process is assumed to follow Boltzmann’s probability distribution, the
convergence of the simulated annealing algorithm can be controlled by controlling the
temperature T . The method of implementing the Boltzmann’s probability distribution
in simulated thermodynamic systems, suggested by Metropolis et al. [13.37], can also
be used in the context of minimization of functions.
In the case of function minimization, let the current design point (state) be Xi ,
with the corresponding value of the objective function given by fi = f (Xi). Similar
to the energy state of a thermodynamic system, the energy Ei at state Xi is given by
Ei = fi = f (Xi) (13.15)
Then, according to the Metropolis criterion, the probability of the next design point
(state) Xi+1 depends on the difference in the energy state or function values at the two
design points (states) given by
E = Ei+1 − Ei = f = fi+1 − fi ≡ f (Xi+1) − f (Xi) (13.16)
The new state or design point Xi+1 can be found using the Boltzmann’s probability
distribution:
P [Ei+1] = min
{
1, e−E/kT
}
(13.17)
The Boltzmann’s constant serves as a scaling factor in simulated annealing and, as such,
can be chosen as 1 for simplicity. Note that if E ≤ 0, Eq. (13.17) gives P [Ei+1] = 1
and hence the point Xi+1 is always accepted. This is a logical choice in the context of
minimization of a function because the function value at Xi+1, fi+1, is better (smaller)
than at Xi, fi , and hence the design vector Xi+1 must be accepted. On the other
hand, when E > 0, the function value fi+1 at Xi+1 is worse (larger) than the one at
Xi . According to most conventional optimization procedures, the point Xi+1 cannot be
accepted as the next point in the iterative process. However, the probability of accepting
the point Xi+1, in spite of its being worse than Xi in terms of the objective function
value, is finite (although it may be small) according to the Metropolis criterion. Note
that the probability of accepting the point Xi+1
P [Ei+1] =
{
e−E/kT
}
(13.18)
704 Modern Methods of Optimization
is not same in all situations. As can be seen from Eq. (13.18), this probability depends
on the values of E and T . If the temperature T is large, the probability will be high
for design points Xi+1 with larger function values (with larger values of E = f ).
Thus at high temperatures, even worse design points Xi+1 are likely to be accepted
because of larger probabilities. However, if the temperature T is small, the probability
of accepting worse design points Xi+1 (with larger values of E = f ) will be small.
Thus as the temperature values get smaller (that is, as the process gets closer to the
optimum solution), the design points Xi+1 with larger function values compared to the
one at Xi are less likely to be accepted.
13.3.3 Algorithm
The SA algorithm can be summarized as follows. Start with an initial design vector
X1 (iteration number i = 1) and a high value of temperature T . Generate a new design
point randomly in the vicinity of the current design point and find the difference in
function values:
E = f = fi+1 − fi ≡ f (Xi+1) − f (Xi) (13.19)
If fi+1 is smaller than fi (with a negative value of f ), accept the point Xi+1 as
the next design point. Otherwise, when f is positive, accept the point Xi+1 as the
next design point only with a probability e−E/kT . This means that if the value of a
randomly generated number is larger than e−E/kT , accept the point Xi+1; otherwise,
reject the point Xi+1. This completes one iteration of the SA algorithm. If the point
Xi+1 is rejected, then the process of generating a new design point Xi+1 randomly in
the vicinity of the current design point, evaluating the corresponding objective function
value fi+1, and deciding to accept Xi+1 as the new design point, based on the use
of the Metropolis criterion, Eq. (13.18), is continued. To simulate the attainment of
thermal equilibrium at every temperature, a predetermined number (n) of new points
Xi+1 are tested at any specific value of the temperature T .
Once the number of new design points Xi+1 tested at any temperature T exceeds the
value of n, the temperature T is reduced by a prespecified fractional value c (0 < c < 1)
and the whole process is repeated. The procedure is assumed to have converged when
the current value of temperature T is sufficiently small or when changes in the function
values (f ) are observed to be sufficiently small.
The choices of the initial temperature T , the number of iterations n before reduc-
ing the temperature, and the temperature reduction factor c play important roles in the
successful convergence of the SA algorithm. For example, if the initial temperature
T is too large, it requires a larger number of temperature reductions for convergence.
On the other hand, if the initial temperature is chosen to be too small, the search
process may be incomplete in the sense that it might fail to thoroughly investigate
the design space in locating the global minimum before convergence. The tempera-
ture reduction factor c has a similar effect. Too large a value of c (such as 0.8 or
0.9) requires too much computational effort for convergence. On the other hand, too
small a value of c (such as 0.1 or 0.2) may result in a faster reduction in tempera-
ture that might not permit a thorough exploration of the design space for locating the
global minimum solution. Similarly, a large value of the number of iterations n will
help in achieving quasiequilibrium state at each temperature but will result in a larger
13.3 Simulated Annealing 705
computational effort. A smaller value of n, on the other hand, might result either in a
premature convergence or convergence to a local minimum (due to inadequate explo-
ration of the design space for the global minimum). Unfortunately, no unique set of
values are available for T , n, and c that will work well for every problem. However,
certain guidelines can be given for selecting these values. The initial temperature T
can be chosen as the average value of the objective function computed at a number
of randomly selected points in the design space. The number of iterations n can be
chosen between 50 and 100 based on the computing resources and the desired accu-
racy of solution. The temperature reduction factor c can be chosen between 0.4 and
0.6 for a reasonable temperature reduction strategy (also termed the cooling schedule).
More complex cooling schedules, based on the expected mathematical convergence
rates, have been used in the literature for the solution of complex practical optimiza-
tion problems [13.19]. In spite of all the research being done on SA algorithms, the
choice of the initial temperature T , the number of iterations n at any specific tem-
perature, and the temperature reduction factor (or cooling rate) c still remain an art
and generally require a trial-and-error process to find suitable values for solving any
particular type of optimization problems. The SA procedure is shown as a flowchart
in Fig. 13.2.
13.3.4 Features of the Method
Some of the features of simulated annealing are as follows:
1. The quality of the final solution is not affected by the initial guesses, except
that the computational effort may increase with worse starting designs.
2. Because of the discrete nature of the function and constraint evaluations, the
convergence or transition characteristics are not affected by the continuity or
differentiability of the functions.
3. The convergence is also not influenced by the convexity status of the feasible
space.
4. The design variables need not be positive.
5. The method can be used to solve mixed-integer, discrete, or continuous
problems.
6. For problems involving behavior constraints (in addition to lower and upper
bounds on the design variables), an equivalent unconstrained function is to be
formulated as in the case of genetic algorithms.
13.3.5 Numerical Results
The welded beam problem of Section 7.22.3 (Fig. 7.23) is solved using simu-
lated annealing. The solution is given by x∗1 = 0.2471, x
∗
2 = 6.1451, x
∗
3 = 8.2721,
x∗4 = 0.2495, and f
∗ = 2.4148. This solution can be compared with the solutions
obtained by genetic algorithms (x∗1 = 0.2489, x2 = 6.1730, x
∗
3 = 8.1789, x
∗
4 = 0.2533,
and f ∗ = 2.4331) and geometric programming (x∗1 = 0.2536, x
∗
2 = 7.1410, x
∗
3 =
7.1044, x∗4 = 0.2536, and f
∗ = 2.3398). Notice that the solution given by geometric
programming [13.21] violated three constraints slightly, while the solutions given by
the genetic algorithms [13.20] and simulated annealing satisfied all the constraints.
706 Modern Methods of Optimization
Start with initial vector, X1,
initial temperature and other parameters
(T, n, c)
Find f1 = f (X1),
Set iteration number i = 1
and cycle number p = 1
Accept or reject Xi+1 using
Metropolis criterion
Update iteration number 
as i = i + 1
Update the number of
cycles as p = p + 1
Set iteration number i = 1
Reduce temperature.
Stop
Convergence criteria
satisfied?
Is number of
Iterations i ≥ n ?
Generate new design point Xi+1
In the vicinity of Xi . Compute
fi+1 = f (Xi+1) and Df = fi+1 – fi
No
Yes
Yes
No
Figure 13.2 Simulated annealing procedure.
Example 13.3 Find the minimum of the following function using simulated annealing:
f (X) = 500 − 20x1 − 26x2 − 4x1x2 + 4x
2
1 + 3x
2
2
SOLUTION We follow the procedure indicated in the flowchart of Fig. 13.2.
13.3 Simulated Annealing 707
Step 1: Choose the parameters of the SA method. The initial temperature is taken
as the average value of f evaluated at four randomly selected points in the
design space. By selecting the random points as X(1) =
{
2
0
}
, X(2) =
{
5
10
}
,
X(3) =
{
8
5
}
, X(4) =
{
10
10
}
, we find the corresponding values of the objective
function as f (1) = 476, f (2) = 340, f (3) = 381, f (4) = 340, respectively. Not-
ing that the average value of the objective functions f (1), f (2), f (3), and f (4)
is 384.25, we assume the initial temperature to be T = 384.25. The tempera-
ture reduction factor is chosen as c = 0.5. To make the computations brief, we
choose the maximum permissible number of iterations (at any specific value
of temperature) as n = 2. We select the initial design point as X1 =
{
4
5
}
.
Step 2: Evaluate the objective function value at X1 as f1 = 349.0 and set the iteration
number as i = 1.
Step 3: Generate a new design point in the vicinity of the current design point. For
this, we select two uniformly distributed random numbers u1 and u2; u1 for
x1 in the vicinity of 4 and u2 for x2 in the vicinity of 5. The numbers u1 and
u2 are chosen as 0.31 and 0.57, respectively. By choosing the ranges of x1
and x2 as (−2, 10) and (−1, 11), which represent ranges of ±6 about their
respective current values, the uniformly distributed random numbers r1 and r2
in the ranges of x1 and x2, corresponding to u1 and u2, can be found as
r1 = −2 + u1{10 − (−2)} = −2 + 0.31(12) = 1.72
r2 = −1 + u2{11 − (−1)} = −1 + 0.57(12) = 5.84
which gives X2 =
{
r1
r2
}
=
{
1.72
5.84
}
.
Since the objective function value f2 = f (X2) = 387.7312, the value of f
is given by
f = f2 − f1 = 387.7312 − 349.0 = 38.7312
Step 4: Since the value of f is positive, we use the Metropolis criterion to decide
whether to accept or reject the current point. For this we choose a random
number in the range (0, 1) as r = 0.83. Equation (13.18) gives the probability
of accepting the new design point X2 as
P [X2] = e
−f /kT (E1)
By assuming the value of the Boltzmann’s constant k to be 1 for simplicity in
Eq. (E1), we obtain
P [X2] = e
−f /kT = e−38.7312/384.25 = 0.9041
Since r = 0.83 is smaller than 0.9041, we accept the point X2 =
{
1.72
5.84
}
as the
next design point. Note that, although the objective function value f2 is larger
than f1, we accept X2 because this is an early stage of simulation and the
current temperature is high.
Step 3: Update the iteration number as i = 2. Since the iteration number i is less than
or equal to n, we proceed to step 3.
708 Modern Methods of Optimization
Step 3: Generate a new design point in the vicinity of the current design point X2 =
{
1.72
5.84
}
. For this, we choose the range of each design variable as ±6 about
its current value so that the ranges are given by (−6 + 1.72, 6 + 1.72) =
(−4.28, 7.72) for x1 and (−6 + 5.84, 6 + 5.84) = (−0.16, 11.84) for x2. By
selecting two uniformly distributed random numbers in the range (0, 1) as
u1 = 0.92 and u2 = 0.73, the corresponding uniformly distributed random
numbers in the ranges of x1 and x2 become
r1 = −4.28 + u1{7.72 − (−4.28)} = −4.28 + 0.92(12) = 6.76
r2 = −0.16 + u2{11.84 − (−0.16)} = −0.16 + 0.73(12) = 8.60
which gives X3 =
{
r1
r2
}
=
{
6.76
8.60
}
with a function value of f3 = 313.3264.
We note that the function value f3 is better than f2 with f = f3 − f2 =
313.3264 − 387.7312 = −74.4048.
Step 4: Since f < 0, we accept the current point as X3 and increase the iteration
number to i = 3. Since i > n, we go to step 5.
Step 5: Since a cycle of iterations with the current value of temperature is completed,
we reduce the temperature to a new value of T = 0.5 (384.25) = 192.125.
Reset the current iteration number as i = 1 and go to step 3.
Step 3: Generate a new design point in the vicinity of the current design point X3 and
continue the procedure until the temperature is reduced to a small value (until
convergence).
13.4 PARTICLE SWARM OPTIMIZATION
13.4.1 Introduction
Particle swarm optimization, abbreviated as PSO, is based on the behavior of a colony
or swarm of insects, such as ants, termites, bees, and wasps; a flock of birds; or a
school of fish. The particle swarm optimization algorithm mimics the behavior of these
social organisms. The word particle denotes, for example, a bee in a colony or a
bird in a flock. Each individual or particle in a swarm behaves in a distributed way
using its own intelligence and the collective or group intelligence of the swarm. As
such, if one particle discovers a good path to food, the rest of the swarm will also be
able to follow the good path instantly even if their location is far away in the swarm.
Optimization methods based on swarm intelligence are called behaviorally inspired
algorithms as opposed to the genetic algorithms, which are called evolution-based
procedures. The PSO algorithm was originally proposed by Kennedy and Eberhart in
1995 [13.34].
In the context of multivariable optimization, the swarm is assumed to be of specified
or fixed size with each particle located initially at random locations in the multidimen-
sional design space. Each particle is assumed to have two characteristics: a position
and a velocity. Each particle wanders around in the design space and remembers the
best position (in terms of the food source or objective function value) it has discov-
ered. The particles communicate information or good positions to each other and adjust
their individual positions and velocities based on the information received on the good
positions.
13.4 Particle Swarm Optimization 709
As an example, consider the behavior of birds in a flock. Although each bird has
a limited intelligence by itself, it follows the following simple rules:
1. It tries not to come too close to other birds.
2. It steers toward the average direction of other birds.
3. It tries to fit the “average position” between other birds with no wide gaps in
the flock.
Thus the behavior of the flock or swarm is based on a combination of three simple
factors:
1. Cohesion—stick together.
2. Separation—don’t come too close.
3. Alignment—follow the general heading of the flock.
The PSO is developed based on the following model:
1. When one bird locates a target or food (or maximum of the objective function),
it instantaneously transmits the information to all other birds.
2. All other birds gravitate to the target or food (or maximum of the objective
function), but not directly.
3. There is a component of each bird’s own independent thinking as well as its
past memory.
Thus the model simulates a random search in the design space for the maximum value
of the objective function. As such, gradually over many iterations, the birds go to the
target (or maximum of the objective function).
13.4.2 Computational Implementation of PSO
Consider an unconstrained maximization problem:
Maximize f (X)
with X(l) ≤ X ≤ X(u) (13.20)
where X(l) and X(u) denote the lower and upper bounds on X, respectively. The PSO
procedure can be implemented through the following steps.
1. Assume the size of the swarm (number of particles) is N . To reduce the total
number of function evaluations needed to find a solution, we must assume a
smaller size of the swarm. But with too small a swarm size it is likely to take
us longer to find a solution or, in some cases, we may not be able to find a
solution at all. Usually a size of 20 to 30 particles is assumed for the swarm as
a compromise.
2. Generate the initial population of X in the range X(l) and X(u) randomly as
X1, X2, . . . , XN . Hereafter, for convenience, the particle (position of) j and
its velocity in iteration i are denoted as X
(i)
j and V
(i)
j , respectively. Thus the
particles generated initially are denoted X1(0), X2(0), . . . , XN (0). The vectors
Xj (0)(j = 1, 2, . . . , N) are called particles or vectors of coordinates of particles
710 Modern Methods of Optimization
(similar to chromosomes in genetic algorithms). Evaluate the objective function
values corresponding to the particles as f [X1(0)], f [X2(0)], . . . , f [XN (0)].
3. Find the velocities of particles. All particles will be moving to the optimal point
with a velocity. Initially, all particle velocities are assumed to be zero. Set the
iteration number as i = 1.
4. In the ith iteration, find the following two important parameters used by a
typical particle j :
(a) The historical best value of Xj (i) (coordinates of j th particle in the cur-
rent iteration i), Pbest,j , with the highest value of the objective function,
f [Xj (i)], encountered by particle j in all the previous iterations.
The historical best value of Xj (i) (coordinates of all particles up to that
iteration), Gbest, with the highest value of the objective function f [Xj (i)],
encountered in all the previous iterations by any of the N particles.
(b) Find the velocity of particle j in the ith iteration as follows:
Vj (i) = Vj (i − 1) + c1r1[Pbest,j − Xj (i − 1)]
+ c2r2[Gbest − Xj (i − 1)]; j = 1, 2, . . . , N (13.21)
where c1 and c2 are the cognitive (individual) and social (group) learning
rates, respectively, and r1 and r2 are uniformly distributed random numbers
in the range 0 and 1. The parameters c1 and c2 denote the relative importance
of the memory (position) of the particle itself to the memory (position) of
the swarm. The values of c1 and c2 are usually assumed to be 2 so that
c1r1 and c2r2 ensure that the particles would overfly the target about half
the time.
(c) Find the position or coordinate of the j th particle in ith iteration as
Xj (i) = Xj (i − 1) + Vj (i); j = 1, 2, . . . , N (13.22)
where a time step of unity is assumed in the velocity term in Eq. (13.22).
Evaluate the objective function values corresponding to the particles as
f [X1(i)], F [X2(i)], . . . , F [XN (i)].
5. Check the convergence of the current solution. If the positions of all particles
converge to the same set of values, the method is assumed to have converged.
If the convergence criterion is not satisfied, step 4 is repeated by updating the
iteration number as i = i + 1, and by computing the new values of Pbest,j and
Gbest. The iterative process is continued until all particles converge to the same
optimum solution.
13.4.3 Improvement to the Particle Swarm Optimization Method
It is found that usually the particle velocities build up too fast and the maximum of the
objective function is skipped. Hence an inertia term, θ , is added to reduce the velocity.
Usually, the value of θ is assumed to vary linearly from 0.9 to 0.4 as the iterative process
progresses. The velocity of the j th particle, with the inertia term, is assumed as
13.4 Particle Swarm Optimization 711
Vj (i) = θVj (i − 1) + c1r1[Pbest,j − Xj (i − 1)]
+ c2r2[Gbest − Xj (i − 1)]; j = 1, 2, . . . , N (13.23)
The inertia weight θ was originally introduced by Shi and Eberhart in 1999 [13.36] to
dampen the velocities over time (or iterations), enabling the swarm to converge more
accurately and efficiently compared to the original PSO algorthm with Eq. (13.21).
Equation (13.23) denotes an adapting velocity formulation, which improves its fine
tuning ability in solution search. Equation (13.23) shows that a larger value of θ pro-
motes global exploration and a smaller value promotes a local search. Thus a large value
of θ makes the algorithm constantly explore new areas without much local search and
hence fails to find the true optimum. To achieve a balance between global and local
exploration to speed up convergence to the true optimum, an inertia weight whose
value decreases linearly with the iteration number has been used:
θ(i) = θmax −
(
θmax − θmin
imax
)
i (13.24)
where θmax and θmin are the initial and final values of the inertia weight, respectively,
and imax is the maximum number of iterations used in PSO. The values of θmax = 0.9
and θmin = 0.4 are commonly used.
13.4.4 Solution of the Constrained Optimization Problem
Let the constrained optimization problem be given by
Maximize f (X)
subject to (13.25)
gj (X) ≤ 0; j = 1, 2, . . . , m
An equivalent unconstrained function, F(X), is constructed by using a penalty function
for the constraints. Two types of penalty functions can be used in defining the function
F(X). The first type, known as the stationary penalty function, uses fixed penalty param-
eters throughout the minimization and the penalty value depends only on the degree of
violation of the constraints. The second type, known as nonstationary penalty function,
uses penalty parameters whose values change dynamically with the iteration number
during optimization. The results obtained with the nonstationary penalty functions have
been found to be superior to those obtained with stationary penalty functions in the
numerical studies reported in the literature. As such, the nonstationary penalty function
is to be used in practical computations.
According to the nonstationary penalty function approach, the function F(X) is
defined as
F(X) = f (X) + C(i)H(X) (13.26)
where C(i) denotes a dynamically modified penalty parameter that varies with the iter-
ation number i, and H(X) represents the penalty factor associated with the constraints:
712 Modern Methods of Optimization
C(i) = (ci)α (13.27)
H(X) =
m
∑
j=1
{
ϕ[gj (X)][qj (X)]
γ [qi(X)]
}
(13.28)
ϕ[qj (X)] = a
(
1 −
1
eqj (X)
)
+ b (13.29)
qj (X) = max
{
0, gj (X)
}
; j = 1, 2, . . . , m (13.30)
where c, α, a, and b are constants. Note that the function qj (X) denotes the magnitude
of violation of the j th constraint, ϕ[qj (X)] indicates a continuous assignment function,
assumed to be of exponential form, as shown in Eq. (13.29), and γ [qi(X)] represents
the power of the violated function. The values of c = 0.5, α = 2, a = 150, and b = 10
along with
γ [qj (X)] =
{
1 if qj (X) ≤ 1
2 if qj (X) > 1
(13.31)
were used by Liu and Lin [13.35].
Example 13.4 Find the maximum of the function
f (x) = −x2 + 2x + 11
in the range −2 ≤ x ≤ 2 using the PSO method. Use 4 particles (N = 4) with the initial
positions x1 = −1.5, x2 = 0.0, x3 = 0.5, and x4 = 1.25. Show the detailed computa-
tions for iterations 1 and 2.
SOLUTION
1. Choose the number of particles N as 4.
2. The initial population, chosen randomly (given as data), can be represented
as x1(0) = −1.5, x2(0) = 0.0, x3(0) = 0.5, and x4(0) = 1.25. Evaluate the
objective function values at current xj (0), j = 1, 2, 3, 4 as f1 = f [x1(0)] =
f (−1.5) = 5.75, f2 = f [x2(0)] = f (0.0) = 11.0, f3 = f [x3(0)] = f (0.5) =
11.75, and f4 = f [x4(0)] = f (1.25) = 11.9375.
3. Set the initial velocities of each particle to zero:
v1(0) = v2(0) = v3(0) = v4(0) = 0
Set the iteration number as i = 1 and go to step 4.
4. (a) Find Pbest,1 = −1.5, Pbest,2 = 0.0, Pbest,3 = 0.5, Pbest,4 = 1.25, and Gbest =
1.25.
(b) Find the velocities of the particles as (by assuming c1 = c2 = 1 and using
the random numbers in the range (0, 1) as r1 = 0.3294 and r2 = 0.9542):
vj (i) = vj (i − 1) + r1[Pbest,j − xj (i − 1)]
+ r2[Gbest − xj (i − 1)]; j = 1 , 2 , 3 , 4
13.4 Particle Swarm Optimization 713
so that
v1(1) = 0 + 0.3294(−1.5 + 1.5) + 0.9542(1.25 + 1.5) = 2.6241
v2(1) = 0 + 0.3294(0.0 − 0.0) + 0.9542(1.25 − 0.0) = 1.1927
v3(1) = 0 + 0.3294(0.5 − 0.5) + 0.9542(1.25 − 0.5) = 0.7156
v4(1) = 0 + 0.3294(1.25 − 1.25) + 0.9542(1.25 − 1.25) = 0.0
(c) Find the new values of xj (1), j = 1 , 2 , 3 , 4 , as xj (i) = xj (i − 1) + vj (i):
x1(1) = −1.5 + 2.6241 = 1.1241
x2(1) = 0.0 + 1.1927 = 1.1927
x3(1) = 0.5 + 0.7156 = 1.2156
x4(1) = 1.25 + 0.0 = 1.25
5. Evaluate the objective function values at the current xj (i):
f [x1(1)] = 11.9846, f [x2(1)] = 11.9629, f [x3(1)] = 11.9535,
f [x4(1)] = 11.9375
Check the convergence of the current solution. Since the values of xj (i) did
not converge, we increment the iteration number as i = 2 and go to step 4.
4. (a) Find Pbest,1 = 1.1241, Pbest,2 = 1.1927, Pbest,3 = 1.2156, Pbest,4 = 1.25,
and Gbest = 1.1241.
(b) Compute the new velocities of particles (by assuming c1 = c2 = 1 and using
the random numbers in the range (0, 1) as r1 = 0.1482 and r2 = 0.4867):
vj (i) = vj (i − 1) + r1(Pbest,j − xj (i)) + r2(Gbest − xj (i)); j = 1, 2, 3, 4
so that
v1(2) = 2.6240 + 0.1482(1.1241 − 1.1241) + 0.4867(1.1241 − 1.1241) = 2.6240
v2(2) = 1.1927 + 0.1482(1.1927 − 1.1927) + 0.4867(1.1241 − 1.1927) = 1.1593
v3(2) = 0.7156 + 0.1482(1.2156 − 1.2156) + 0.4867(1.1241 − 1.2156) = 0.6711
v4(2) = 0.0 + 0.1482(1.25 − 1.25) + 0.4867(1.1241 − 1.25) = −0.0613
(c) Compute the current values of xj (i) as xj (i) = xj (i − 1) + vj (i), j = 1, 2, 3, 4:
x1(2) = 1.1241 + 2.6240 = 3.7481
x2(2) = 1.1927 + 1.1593 = 2.3520
x3(2) = 1.2156 + 0.6711 = 1.8867
x4(2) = 1.25 − 0.0613 = 1.1887
714 Modern Methods of Optimization
6. Find the objective function values at the current xj (i):
f [x1(2)] = 4.4480, f [x2(2)] = 10.1721, f [x3(2)] = 11.2138,
f [x4(2)] = 11.9644
Check the convergence of the process. Since the values of xj (i) did not con-
verge, we increment the iteration number as i = 3 and go to step 4. Repeat
step 4 until the convergence of the process is achieved.
13.5 ANT COLONY OPTIMIZATION
13.5.1 Basic Concept
Ant colony optimization (ACO) is based on the cooperative behavior of real ant
colonies, which are able to find the shortest path from their nest to a food source.
The method was developed by Dorigo and his associates in the early 1990s [13.31,
13.32]. The ant colony optimization process can be explained by representing the opti-
mization problem as a multilayered graph as shown in Fig. 13.3, where the number of
Home
Destination
(Food)
Layer 1 (x1) x11 x13 x14 x15 x16 x17 x18
x12
x21 x22
x23
x24 x25 x26 x27 x28
x31
x32 x33 x34 x35 x36 x37 x38
x41 x42 x43
x44
x45
x46 x47 x48
x51 x52 x53 x54
x55 x56 x57 x58
x61
x62 x63 x64 x65 x66
x67 x68
Layer 2 (x2)
Layer 3 (x3)
Layer 4 (x4)
Layer 5 (x5)
Layer 6 (x6)
Figure 13.3 Graphical representation of the ACO process in the form of a multi-layered
network.
13.5 Ant Colony Optimization 715
layers is equal to the number of design variables and the number of nodes in a par-
ticular layer is equal to the number of discrete values permitted for the corresponding
design variable. Thus each node is associated with a permissible discrete value of a
design variable. Figure 13.3 denotes a problem with six design variables with eight
permissible discrete values for each design variable.
The ACO process can be explained as follows. Let the colony consist of N ants.
The ants start at the home node, travel through the various layers from the first layer to
the last or final layer, and end at the destination node in each cycle or iteration. Each
ant can select only one node in each layer in accordance with the state transition rule
given by Eq. (13.32). The nodes selected along the path visited by an ant represent
a candidate solution. For example, a typical path visited by an ant is shown by thick
lines in Fig. 13.3. This path represents the solution (x12, x23, x31, x45, x56, x64).
Once the path is complete, the ant deposits some pheromone on the path based on
the local updating rule given by Eq. (13.33). When all the ants complete their paths,
the pheromones on the globally best path are updated using the global updating rule
described by Eqs. (13.32) and (13.33).
In the beginning of the optimization process (i.e., in iteration 1), all the edges or
rays are initialized with an equal amount of pheromone. As such, in iteration 1, all the
ants start from the home node and end at the destination node by randomly selecting
a node in each layer. The optimization process is terminated if either the prespecified
maximum number of iterations is reached or no better solution is found in a prespecified
number of successive cycles or iterations. The values of the design variables denoted
by the nodes on the path with largest amount of pheromone are considered as the
components of the optimum solution vector. In general, at the optimum solution, all
ants travel along the same best (converged) path.
13.5.2 Ant Searching Behavior
An ant k, when located at node i, uses the pheromone trail τij to compute the probability
of choosing j as the next node:
p
(k)
ij =





τα
ij
∑
j∈N
(k)
i
τα
ij
if j ∈ N
(k)
i
0 if j /∈ N
(k)
i
(13.32)
where α denotes the degree of importance of the pheromones and N
(k)
i indicates the
set of neighborhood nodes of ant k when located at node i. The neighborhood of node
i contains all the nodes directly connected to node i except the predecessor node (i.e.,
the last node visited before i). This will prevent the ant from returning to the same node
visited immediately before node i. An ant travels from node to node until it reaches
the destination (food) node.
13.5.3 Path Retracing and Pheromone Updating
Before returning to the home node (backward node), the kth ant deposits τ (k) of
pheromone on arcs it has visited. The pheromone value τij on the arc (i, j) traversed
716 Modern Methods of Optimization
is updated as follows:
τij ← τij + τ
(k) (13.33)
Because of the increase in the pheromone, the probability of this arc being selected by
the forthcoming ants will increase.
13.5.4 Pheromone Trail Evaporation
When an ant k moves to the next node, the pheromone evaporates from all the arcs ij
according to the relation
τij ← (1 − p)τij; ∀(i, j) ∈ A (13.34)
where p ∈ (0, 1] is a parameter and A denotes the segments or arcs traveled by ant k
in its path from home to destination. The decrease in pheromone intensity favors the
exploration of different paths during the search process. This favors the elimination of
poor choices made in the path selection. This also helps in bounding the maximum
value attained by the pheromone trails. An iteration is a complete cycle involving ant’s
movement, pheromone evaporation and pheromone deposit.
After all the ants return to the home node (nest), the pheromone information is
updated according to the relation
τij = (1 − ρ)τij +
N
∑
k=1
τ
(k)
ij (13.35)
where ρ ∈ (0, 1] is the evaporation rate (also known as the pheromone decay factor)
and τ
(k)
ij is the amount of pheromone deposited on arc ij by the best ant k. The
goal of pheromone update is to increase the pheromone value associated with good or
promising paths. The pheromone deposited on arc ij by the best ant is taken as
τ
(k)
ij =
Q
Lk
(13.36)
where Q is a constant and Lk is the length of the path traveled by the kth ant (in the case
of the travel from one city to another in a traveling salesman problem). Equation (13.36)
can be implemented as
τ
(k)
ij =





ςfbest
fworst
; if (i, j) ∈ global best tour
0; otherwise
(13.37)
where fworst is the worst value and fbest is the best value of the objective function
among the paths taken by the N ants, and ζ is a parameter used to control the scale of
the global updating of the pheromone. The larger the value of ζ , the more pheromone
deposited on the global best path, and the better the exploitation ability. The aim of
Eq. (13.37) is to provide a greater amount of pheromone to the tours (solutions) with
better objective function values.
13.5 Ant Colony Optimization 717
13.5.5 Algorithm
The step-by-step procedure of ACO algorithm for solving a minimization problem can
be summarized as follows:
Step 1: Assume a suitable number of ants in the colony (N). Assume a set of
permissible discrete values for each of the n design variables. Denote the
permissible discrete values of the design variable xi as xil, xi2, . . . , xip
(i = 1, 2, . . . , n). Assume equal amounts of pheromone τ
(1)
ij initially along all
the arcs or rays (discrete values of design variables) of the multilayered graph
shown in Fig. 13.3. The superscript to τij denotes the iteration number. For
simplicity, τ
(1)
ij = 1 can be assumed for all arcs ij. Set the iteration number
l = 1.
Step 2:
(a) Compute the probability (pij) of selecting the arc or ray (or the discrete
value) xij as
pij =
τ
(l)
ij
p
∑
m=1
τ
(l)
im
; i = 1, 2, . . . , n; j = 1, 2, . . . , p (13.38)
which can be seen to be same as Eq. (13.32) with α = 1. A larger value
can also be used for α.
(b) The specific path (or discrete values) chosen by the kth ant can be deter-
mined using random numbers generated in the range (0, 1). For this, we
find the cumulative probability ranges associated with different paths of
Fig. 13.3 based on the probabilities given by Eq. (13.38). The specific
path chosen by ant k will be determined using the roulette-wheel selection
process in step 3(a).
Step 3:
(a) Generate N random numbers r1, r2, . . . , rN in the range (0, 1), one for each
ant. Determine the discrete value or path assumed by ant k for variable i
as the one for which the cumulative probability range [found in step 2(b)]
includes the value ri .
(b) Repeat step 3(a) for all design variables i = 1, 2, . . . , n.
(c) Evaluate the objective function values corresponding to the complete
paths (design vectors X(k) or values of xij chosen for all design variables
i = 1, 2, . . . , n by ant k, k = 1, 2, . . . , N ):
fk = f (X
(k)); k = 1, 2, . . . , N (13.39)
Determine the best and worst paths among the N paths chosen by different
ants:
fbest =
min
k = 1, 2, . . . , N
{fk} (13.40)
fworst =
max
k = 1, 2, . . . , N
{fk} (13.41)
718 Modern Methods of Optimization
Step 4: Test for the convergence of the process. The process is assumed to have con-
verged if all N ants take the same best path. If convergence is not achieved,
assume that all the ants return home and start again in search of food. Set the
new iteration number as l = l + 1, and update the pheromones on different
arcs (or discrete values of design variables) as
τ
(l)
ij = τ
(old)
ij +
∑
k
τ
(k)
ij (13.42)
where τ
(old)
ij denotes the pheromone amount of the previous iteration left after
evaporation, which is taken as
τ
(old)
ij = (1 − ρ)τ
(l−1)
ij (13.43)
and τ
(k)
ij is the pheromone deposited by the best ant k on its path and the
summation extends over all the best ants k (if multiple ants take the same best
path). Note that the best path involves only one arc ij (out of p possible arcs)
for the design variable i. The evaporation rate or pheromone decay factor ρ is
assumed to be in the range 0.5 to 0.8 and the pheromone deposited τ
(k)
ij is
computed using Eq. (13.37).
With the new values of τ
(l)
ij , go to step 2. Steps 2, 3, and 4 are repeated until
the process converges, that is, until all the ants choose the same best path.
In some cases, the iterative process is stopped after completing a prespecified
maximum number of iterations (lmax).
Example 13.5 Find the minimum of the function f (x) = x2 − 2x − 11 in the range
(0, 3) using the ant colony optimization method.
SOLUTION
Step 1: Assume the number of ants is N = 4. Note that there is only one design
variable in this example (n = 1). The permissible discrete values of x = x1
are assumed, within the range of x1, as (p = 7):
x11 = 0.0, x12 = 0.5, x13 = 1.0, x14 = 1.5, x15 = 2.0, x16 = 2.5, x17 = 3.0
Each ant can choose any of the discrete values (paths or arcs) x1j ,
j = 1, 2, . . . , 7 shown in Fig. 13.4. Assume equal amounts of pheromone
along each of the paths or arcs (τ1j ) shown in Fig. 13.4. For simplicity,
τ1j = 1 is assumed for j = 1, 2, . . . , 7.
Set the iteration number as l = 1.
Step 2: For any ant k, the probability of selecting path (or discrete variable) x1j is
given by
p1j =
τ1j
7
∑
p=1
τ1p
=
1
7
13.5 Ant Colony Optimization 719
x11 = 0·0
x12 = 0·5
x13 = 1·0
x14 = 1·5
x15 = 2·0
x16 = 2·5
x17 = 3·0
Food (Destination)Home
Figure 13.4 Possible paths for an ant (possible discrete values of x ≡ x1).
To select the specific path (or discrete variable) chosen by an ant using a
random number generated in the range (0, 1), cumulative probability ranges are
associated with different paths of Fig. 13.4 as (using roulette-wheel selection
process in step 3):
x11 =
(
0, 1
7
)
= (0.0, 0.1428), x12 =
(
1
7
, 2
7
)
= (0.1428, 0.2857),
x13 =
(
2
7
, 3
7
)
= (0.2857, 0.4286),
x14 =
(
3
7
, 4
7
)
= (0.4286, 0.5714), x15 =
(
4
7
, 5
7
)
= (0.5714, 0.7143),
x16 =
(
5
7
, 6
7
)
= (0.7143, 0.8571),
x17 =
(
6
7
, 1
)
= (0.8571, 1.0)
Step 3: Generate four random numbers ri(i = 1, 2, 3, 4) in the range (0, 1), one for
each ant as r1 = 0.3122, r2 = 0.8701, r3 = 0.4729, and r4 = 0.6190. Using the
cumulative probability range (given in step 2) in which the value of ri falls,
the discrete value assumed (or the path selected in Fig. 13.4) by different ants
can be seen to be
ant 1 : x13 = 1.0; ant 2 : x17 = 3.0; ant 3 : x14 = 1.5; ant 4 : x15 = 2.0
The objective function values corresponding to the paths chosen by different
ants are given by
ant 1 :f1 = f (x13) = f (1.0) = −12.0; ant 2 : f2 = f (x17) = f (3.0) = −8.0;
ant 3 :f3 = f (x14) = f (1.5) = −11.75; ant 4 : f4 = f (x15) = f (2.0) = −11.0
It can be seen that the path taken by ant 1 is the best one (with minimum value
of the objective function): xbest = x13 = 1.0, fbest = f1 = −12.0; and the path
taken by ant 2 is the worst one (with maximum value of the objective function):
xworst = x17 = 3.0, fworst = f2 = −8.0.
720 Modern Methods of Optimization
Step 4: Assuming that the ants return home and start again in search of food, we set
the iteration number as l = 2. We need to update the pheromone array as
τ
(2)
1j = τ
(old)
1j +
∑
k
τ (k) (E1)
where
∑
k
τ (k) is the pheromone deposited by the best ant k and the summation
extends over all the best ants k (if multiple ants take the best path). In the
present case, there is only one best ant, k = 1, which used the path x13. Thus
the value of
∑
k
τ (k) can be determined in this case as
∑
k
τ (k) = τ (k=1) =
ςfbest
fworst
=
(2)(−12.0)
(−8.0)
= 3.0
where the scaling parameter ς is assumed to be 2. Using a pheromone decay
factor of ρ = 0.5 in Eq. (13.43), τ
(old)
1j can be computed as
τ
(old)
1j = (1 − 0.5)τ
(1)
1j = 0.5(1.0) = 0.5; j = 1, 2, 4, 5, 6, 7
Thus Eq. (E1) gives
τ
(2)
1j = 1.0 + 3.0 = 4.0 for j = 3 and τ
(2)
1j = 0.5 for j = 1, 2, 4, 5, 6, 7
With this, we go to step 5.
Step 2: For any ant k, the probability of selecting path x1j in Fig. 13.4 is given by
p1j =
τ1j
7
∑
p=1
τ1p
; j = 1, 2, . . . , 7
where τ1j = 0.5; j = 1, 2, 4, 5, 6, 7 and τ13 = 4. This gives
p1j =
0.5
7.0
= 0.0714; j = 1, 2, 4, 5, 6, 7; p13 =
4.0
7.0
= 0.5714
To determine the discrete value or path selected by ant using a random num-
ber selected in the range (0, 1), cumulative probabilities are associated with
different paths as (roulette wheel selection process):
x11 = (0, 0.0714), x12 = (0.0714, 0.1429), x13 = (0.1429, 0.7143),
x14 = (0.7143, 0.7857), x15 = (0.7857, 0.8571), x16 = (0.8571, 0.9286),
x17 = (0.9286, 1.0)
Step 3: Generate four random numbers in the range (0, 1), one for each of the ants
as r1 = 0.3688, r2 = 0.8577, r3 = 0.0776, r4 = 0.5791. Using the cumulative
probability range (given in step 2) in which the value of ri falls, the discrete
13.5 Ant Colony Optimization 721
value assumed (or the path selected in Fig. 13.4) by different ants can be seen
to be
ant 1 : x13 = 1.0; ant 2 : x16 = 2.5; ant 3 : x11 = 0.0; ant 4 : x13 = 1.0
This shows that two ants (probabilistically) selected the path x13 due to higher
pheromone left on the best path (x13) found in the previous iteration. The
objective function values corresponding to the paths chosen by different ants
are given by
ant 1 : f1 = f (x13) = f (1.0) = −12.0; ant 2 : f2 = f (x16) = f (2.5) = −9.75;
ant 3 : f3 = f (x11) = f (0.0) = −11.0; ant 4 : f4 = f (x13) = f (1.0) = −12.0
It can be seen that the path taken by ants 1 and 4 is the best one with
xbest = x13 = 1.0 and fbest = f1 = f4 = −12.0
and the path taken by ant 2 is the worst one with
xworst = x16 = 2.5 and fworst = f2 = −9.75
Now we go to step 4 to update the pheromone values on the various paths.
Step 4: Assuming that the ants return home and start again in search of food, we set
the iteration number as l = 3. We need to update the pheromone array as
τ
(3)
1j = τ
(old)
1j +
∑
k
τ (k) (E2)
where
∑
k
τ (k) is the pheromone deposited by the best ant k and the summation
extends over all the best ants k (if multiple ants take the best path). In the
present case, there are two best ants, k = 1 and 4, which used the path x13.
Thus the value of
∑
k
τ (k) can be determined in this case as
∑
k
τ (k) = τ (k=1) + τ (k=4) =
2ςfbest
fworst
=
(2)(2)(−12.0)
(−9.75)
= 4.9231
where the scaling parameter ς is assumed to be 2. Using a pheromone decay
factor of ρ = 0.5 in Eq. (13.43), τ
(old)
1j can be computed as
τ
(old)
1j = (1.0 − 0.5)τ
(2)
1j = 0.5(0.5) = 0.25; j = 1, 2, 4, 5, 6, 7
Thus Eq. (E2) gives
τ
(3)
1j = 4.0 + 4.9231 = 8.9231 for j = 3 and
τ
(3)
1j = 0.25 for j = 1, 2, 4, 5, 6, 7
With this, we go to step 2.
722 Modern Methods of Optimization
Step 2: For any ant k, the probability of selecting path x1j in Fig. 13.4 is given by
p1j =
τ1j
7
∑
p=1
τ1p
; j = 1, 2, . . . , 7
where τ1j = 0.25; j = 1, 2, 4, 5, 6, 7 and τ13 = 8.9231. This gives
p1j =
0.25
10.4231
= 0.0240, j = 1, 2, 4, 5, 6, 7; p13 =
8.9231
10.4231
= 0.8561
To determine the discrete value or path selected by an ant using a random num-
ber selected in the range (0, 1), cumulative probabilities are associated with
different paths as (roulette-wheel selection process):
x11 = (0, 0.0240), x12 = (0.0240, 0.0480), x13 = (0.0480, 0.9040),
x14 = (0.9040, 0.9280), x15 = (0.9280, 0.9520),
x16 = (0.9520, 0.9760), x17 = (0.9760, 1.0)
With this information, we go to step 3 and then to step 4. Steps 2, 3, and 4
are repeated until the process converges (until all the ants choose the same
best path).
13.6 OPTIMIZATION OF FUZZY SYSTEMS
In traditional designs, the optimization problem is stated in precise mathematical terms.
However, in many real-world problems, the design data, objective function, and con-
straints are stated in vague and linguistic terms. For example, the statement, “This beam
carries a load of 1000 lb with a probability of 0.8” is imprecise because of random-
ness in the material properties of the beam. On the other hand, the statement, “This
beam carries a large load” is imprecise because of the fuzzy meaning of “large load.”
Similarly, in the optimum design of a machine component, the induced stress (σ ) is con-
strained by an upper bound value (σmax) as σ ≤ σmax. If σmax = 30,000 psi, it implies
that a design with σ = 30, 000 psi is acceptable whereas a design with σ = 30, 001
psi is not acceptable. However, there is no substantive difference between designs with
σ = 30, 000 psi and σ = 30, 001 psi. It appears that it is more reasonable to have a
transition stage from absolute permission to absolute impermission. This implies that
the constraint is to be stated in fuzzy terms. Fuzzy theories can be used to model and
design systems involving vague and imprecise information [13.22, 13.26, 13.27].
13.6.1 Fuzzy Set Theory
Let X be a classical crisp set of objects, called the universe, whose generic elements are
denoted by x. Membership in a classical subset A of X can be viewed as a characteristic
function µA from X to [0, 1] such that
µA(x) =
{
1 if x ∈ A
0 if x /∈ A
(13.44)
13.6 Optimization of Fuzzy Systems 723
The set [0, 1] is called a valuation set. A set A is called a fuzzy set if the valuation set
is allowed to be the whole interval [0, 1]. The fuzzy set A is characterized by the set
of all pairs of points denoted as
A = {x, µA(x)}, x ∈ X (13.45)
where µA(x) is called the membership function of x in A. The closer the value of
µA(x) is to 1, the more x belongs to A. For example, let X = {62 64 66 68 70
72 74 76 78 80} be possible temperature settings of the thermostat (
◦
F) in an
air-conditioned building. Then the fuzzy set A of “comfortable temperatures for human
activity” may be defined as
A = {(62, 0.2) (64, 0.5) (66, 0.8) (68, 0.95) (70, 0.85) (72, 0.75)
(74, 0.6) (76, 0.4) (78, 0.2) (80, 1.0)} (13.46)
where a grade of membership of 1 implies complete comfort and 0 implies complete
discomfort. In general, if X is a finite set, {x1, x2, . . . , xn} the fuzzy set on X can be
expressed as
A = µA(x1)|x1 + µA(x2)|x2 + · · ·+µA(xn)|xn =
n
∑
i=1
µA(xi)|xi (13.47)
or in the limit, we can express A as
A =
∫
x
µA(x)|x (13.48)
Crisp set theory is concerned with membership of precisely defined sets and is
suitable for describing objective matters with countable events. Crisp set theory is
developed using binary statements and is illustrated in Fig. 13.5a, which shows the
support for y1 with no ambiguity. Since fuzzy set theory is concerned with linguistic
statements of support for membership in imprecise sets, a discrete fuzzy set is denoted
as in Fig. 13.5b, where the degree of support is shown by the membership values, µ1,
µ2, . . . , µn, corresponding to y1, y2, . . . , yn, respectively. The discrete fuzzy set can
be generalized to a continuous form as shown in Fig. 13.5c.
The basic crisp set operations of union, intersection, and complement can be rep-
resented on Venn diagrams as shown in Fig. 13.6. Similar operations can be defined
for fuzzy sets, noting that the sets A and B do not have clear boundaries in this case.
The graphs of µA and µB can be used to define the set-theoretic operations of fuzzy
sets. The union of the fuzzy sets A and B is defined as
µA∪B(y) = µA(y) ∨ µB(y) = max[µA(y), µB(y)]
=
{
µA(y) if µA >µB
µB(y) if µA < µB
(13.49)
724 Modern Methods of Optimization
0
1
m m1
m2
y2 yn
mn
y1
0
(a) (b)
1
m
y2 yny1
0
(c)
1
m
y
Figure 13.5 Crisp and fuzzy sets: (a) crisp set; (b) discrete fuzzy set; (c) continuous fuzzy
set. [13.22], with permission of ASME.
B
A
B
A A
A
–
(a) (b) (c)
Figure 13.6 Basic set operations in crisp set theory: (a) A or B or both: A ∪ B; (b) A and
B : A ∩ B; (c) not A : A. [13.22], with permission of ASME.
The result of this operation is shown in Fig. 13.7a. The intersection of the fuzzy sets
A and B is defined as
µA∩B(y) = µA(y) ∧ µB(y) = min[µA(y), µB(y)]
=
{
µA(y) if µA < µB
µB(y) if µA >µB
(13.50)
This operation is shown in Fig. 13.7b. The complement of a fuzzy set A is shown as A
in Fig. 13.7c, in which for every µA(y), there is a corresponding µA(y) = 1 − µA(y),
which defines the complement of the set A, A.
13.6 Optimization of Fuzzy Systems 725
mAUB(y)
mB(y)
m(y)
U
B(y)mA
mA(y) mA(y)
(a)
A
y
(b)
y
(c)
y
1 1 1
mB(y)
mA(y) A
–
mA(y)
–
Figure 13.7 Basic set operations in fuzzy set theory: (a) union; (b) intersection; (c) comple-
ment. [13.22], with permission of ASME.
13.6.2 Optimization of Fuzzy Systems
The conventional optimization methods deal with selection of the design variables that
optimizes an objective function subject to the satisfaction of the stated constraints.
For a fuzzy system, this notion of optimization has to be revised. Since the objective
and constraint functions are characterized by the membership functions in a fuzzy
system, a design (decision) can be viewed as the intersection of the fuzzy objective
and constraint functions. For illustration, consider the objective function: “The depth of
the crane girder (x) should be substantially greater than 80 in.” This can be represented
by a membership function, such as
µf (x) =
{
0 if x < 80 in.
[1 + (x − 80)−2]−1 if x ≥ 80 in.
(13.51)
Let the constraint be “The depth of the crane girder (x) should be in the vicinity of
83 in.” This can be described by a membership function of the type
µg(x) = [1 + (x − 83)
4]−1 (13.52)
Then the design (decision) is described by the membership function, µD(x), as
µD(x) = µf (x) ∧ µg(x)
=



0 x < 80 in.
min{[1 + (x − 80)−2]−1, [1 + (x − 83)4]−1}
if x ≥ 80 in.
(13.53)
This relationship is shown in Fig. 13.8.
The conventional optimization problem is usually stated as follows:
Find X which minimizes f (X)
subject to
g
(l)
j ≤ gj (X) ≤ g
(u)
j , j = 1, 2, . . . , m (13.54)
where the superscripts l and u denote the lower and upper bound values, respectively.
The optimization problem of a fuzzy system is stated as follows:
Find X which minimizes f (X)
726 Modern Methods of Optimization
Constraint
0
x (in.)
1
m
Objective function
Design (decision)
Figure 13.8 Concept of fuzzy decision. [13.22], with permission of ASME.
subject to
gj (X) ∈ Gj , j = 1, 2, . . . , m (13.55)
where Gj denotes the fuzzy interval to which the function gj (X) should belong. Thus
the fuzzy feasible region, S, which denotes the intersection of all Gj , is defined by the
membership function
µS(X) = min
j=1,2,...,m
{µGj [gj (X)]} (13.56)
Since a design vector X is considered feasible when µS(X) > 0, the optimum design is
characterized by the maximum value of the intersection of the objective function and
the feasible domain:
µD(X
∗) = max µD(X), X ∈ D (13.57)
where
µD(X) = min
{
µf (X), min
j=1,2,...,m
µGj [gj (X)]
}
(13.58)
13.6.3 Computational Procedure
The solution of a fuzzy optimization problem can be determined once the membership
functions of f and gj are known. In practical situations, the constructions of the mem-
bership functions is accomplished with the cooperation and assistance of experienced
engineers in specific cases. In the absence of other information, linear membership
functions are commonly used, based on the expected variations of the objective and
constraint functions. Once the membership functions are known, the problem can be
posed as a crisp optimization problem as
Find X and λ which maximize λ
13.7 Neural-Network-Based Optimization 727
subject to
λ ≤ µf (X)
λ ≤ µ
g
(l)
j (X)
, j = 1, 2, . . . , m
λ ≤ µ
g
(u)
j
(X)
, j = 1, 2, . . . , m (13.59)
13.6.4 Numerical Results
The minimization of the error between the generated and specified outputs of the
four-bar mechanism shown in Fig. 13.9 is considered. The design vector is taken as
X ={a b c  β}T. The mechanism is constrained to be a crank-rocker mecha-
nism so that
a − b ≤ 0, a − c ≤ 0, a ≤ 1
d = [(a + c) − (b + 1)][(c − a)2 − (b − 1)2] ≤ 0
The maximum deviation of the transmission angle (µ) from 90
◦
is restricted to be less
than a specified value, tmax = 35
◦
. The specified output angle is
θs(φ) =
{
20
◦
+
φ
3
, 0
◦
≤ φ ≤ 240
◦
unspecified, 240
◦
≤ φ < 360
◦
Linear membership functions are assumed for the response characteristics [13.22]. The
optimum solution is found to be X = {0.2537 0.8901 0.8865 − 0.7858 − 1.0}T
with f ∗ = 1.6562 and λ∗ = 0.4681. This indicates that the maximum level of satisfac-
tion that can be achieved in the presence of fuzziness in the problem is 0.4681. The
transmission angle constraint is found to be active at the optimum solution [13.22].
13.7 NEURAL-NETWORK-BASED OPTIMIZATION
The immense computational power of nervous system to solve perceptional problems
in the presence of massive amount of sensory data has been associated with its parallel
q2 = f
q3
b
q4w2
r2 = a
1
r3 = b
r4 = c
Ω
Figure 13.9 Four-bar function generating mechanism.
728 Modern Methods of Optimization
processing capability. The neural computing strategies have been adopted to solve
optimization problems in recent years [13.23, 13.24]. A neural network is a massively
parallel network of interconnected simple processors (neurons) in which each neuron
accepts a set of inputs from other neurons and computes an output that is propagated
to the output nodes. Thus a neural network can be described in terms of the individual
neurons, the network connectivity, the weights associated with the interconnections
between neurons, and the activation function of each neuron. The network maps an
input vector from one space to another. The mapping is not specified but is learned.
Consider a single neuron as shown in Fig. 13.10. The neuron receives a set of
n inputs, xi, i = 1, 2, . . . , n, from its neighboring neurons and a bias whose value
is equal to 1. Each input has a weight (gain) wi associated with it. The weighted
sum of the inputs determines the state or activity of a neuron, and is given by a =
∑n+1
i=1 wixi = W
T X, where X = {x1x2 · · · xn1}
T. A simple function is now used to
provide a mapping from the n-dimensional space of inputs into a one-dimensional
space of the output, which the neuron sends to its neighbors. The output of a neuron is
a function of its state and can be denoted as f (a). Usually, no output will be produced
unless the activation level of the node exceeds a threshold value. The output of a neuron
is commonly described by a sigmoid function as
f (a) =
1
1 + e−a
(13.60)
which is shown graphically in Fig. 13.10. The sigmoid function can handle large as
well as small input signals. The slope of the function f (a) represents the available
gain. Since the output of the neuron depends only on its inputs and the threshold value,
each neuron can be considered as a separate processor operating in parallel with other
neurons. The learning process consists of determining values for the weights wi that
lead to an optimal association of the inputs and outputs of the neural network.
0
1.0
0.5
f(a)
f(a)
(Bias)
x
n+1 = 1
w
n+1
w
n
w1
x
n
x1
a
a
…
Figure 13.10 Single neuron and its output. [12.23], reprinted with permission of Gordon &
Breach Science Publishers.
13.7 Neural-Network-Based Optimization 729
Several neural network architectures, such as the Hopfield and Kohonen networks,
have been proposed to reflect the basic characteristics of a single neuron. These archi-
tectures differ one from the other in terms of the number of neurons in the network,
the nature of the threshold functions, the connectivities of the various neurons, and
the learning procedures. A typical architecture, known as the multilayer feedforward
network, is shown in Fig. 13.11. In this figure the arcs represent the unidirectional
feedforward communication links between the neurons. A weight or gain associated
with each of these connections controls the output passing through a connection. The
weight can be positive or negative, depending on the excitatory or inhibitory nature
of the particular neuron. The strengths of the various interconnections (weights) act as
repositories for knowledge representation contained in the network.
The network is trained by minimizing the mean-squared error between the actual
output of the output layer and the target output for all the input patterns. The error is
minimized by adjusting the weights associated with various interconnections. A number
of learning schemes, including a variation of the steepest descent method, have been
used in the literature. These schemes govern how the weights are to be varied to
minimize the error at the output nodes. For illustration, consider the network shown
in Fig. 13.12. This network is to be trained to map the angular displacement and
angular velocity relationships, transmission angle, and the mechanical advantage of a
four-bar function-generating mechanism (Fig. 13.9). The inputs to the five neurons in
the input layer include the three link lengths of the mechanism (r2, r3, and r4) and the
angular displacement and velocities of the input link (θ2 and ω2). The outputs of the six
neurons in the output layer include the angular positions and velocities of the coupler
and the output links (θ3, ω3, θ4, and ω4), the transmission angle (γ ), and the mechanical
Outputs
Inputs
Output
layer
Hidden
layer
Input
layer
Figure 13.11 Multilayer feedforward network. [13.23], reprinted with permission of Gordon
and Breach Science Publishers.
730 Modern Methods of Optimization
q3
r2 r3 r4 q2 w2
q4 w3 w4 g h
Figure 13.12 Network used to train relationships for a four-bar mechanism. [12.23], reprinted
with permission of Gordon & Breach Science Publishers.
advantage (η) of the mechanism. The network is trained by inputting several possible
combinations of the values of r2, r3, r4, θ2, and ω2 and supplying the corresponding
values of θ3, θ4, ω3, ω4, γ , and η. The difference between the values predicted by the
network and the actual output is used to adjust the various interconnection weights
such that the mean-squared error at the output nodes is minimized. Once trained, the
network provides a rapid and efficient scheme that maps the input into the desired
output of the four-bar mechanism. It is to be noted that the explicit equations relating
r2, r3, r4, θ2, and ω2 and the output quantities θ3, θ4, ω3, ω4, γ , and η have not been
programmed into the network; rather, the network learns these relationships during the
training process by adjusting the weights associated with the various interconnections.
The same approach can be used for other mechanical and structural analyses that might
require a finite-element-based computations.
Numerical Results. The minimization of the structural weight of the three-bar
truss described in Section 7.22.1 (Fig. 7.21) was considered with constraints on
the cross-sectional areas and stresses in the members. Two load conditions were
considered with P = 20,000 lb, E = 10 × 106 psi, ρ = 0.1 lb/in3, H = 100 in., σmin =
−15,000 psi, σmax = 20,000 psi, A
(l)
i = 0.1 in
2 (i = 1, 2), and A
(u)
i = 5.0 in
2 (i = 1, 2).
The solution obtained using neural-network-based optimization is [12.23]:
x∗1 = 0.788 in
2, x∗2 = 0.4079 in
2, and f ∗ = 26.3716 lb. This can be compared
with the solution given by nonlinear programming: x∗1 = 0.7745 in
2, x∗2 = 0.4499 in
2,
and f ∗ = 26.4051 lb.
REFERENCES AND BIBLIOGRAPHY
13.1 J. H. Holland, Adaptation in Natural and Artificial Systems , University of Michigan
Press, Ann Arbor, MI, 1975.
13.2 I. Rechenberg, Cybernetic Solution Path of an Experimental Problem , Library Transla-
tion 1122, Royal Aircraft Establishment, Farnborough, Hampshire, UK, 1965.
13.3 D. E. Goldberg, Genetic Algorithms in Search, Optimization, and Machine Linearning ,
Addison-Wesley, Reading, MA, 1989.
References and Bibliography 731
13.4 S. S. Rao, T. S. Pan, A. K. Dhingra, V. B. Venkayya, and V. Kumar, Genetic-
evolution-based optimization methods for engineering design, pp. 318–323 in Pro-
ceedings of the 3rd Air Force/NASA Symposium on Recent Advances in Multidisciplinary
Analysis and Optimization, San Francisco, Sept. 24–26, 1990.
13.5 S. S. Rao, T. S. Pan, and V. B. Venkayya, Optimal placement of actuators in
actively controlled structures using genetic algorithms, AIAA Journal , Vol. 29, No. 6,
pp. 942–943, 1991.
13.6 P. Hajela, Genetic search: an approach to the nonconvex optimization problem, AIAA
Journal , Vol. 26, No. 7, pp. 1205–1210, 1990.
13.7 P. Hajela and C. Y. Lin, Genetic search strategies in multicriterion optimal design,
Structural Optimization , Vol. 4, pp. 99–107, 1992.
13.8 D. E. Goldberg, Computer-aided pipeline operation using genetic algorithms and rule
learning, Part I: Genetic algorithms in pipeline optimization, Engineering with Comput-
ers , Vol. 3, pp. 35–45, 1987.
13.9 D. E. Goldberg and C. H. Kuo, Genetic algorithms in pipeline optimization, ASCE
Journal of Computing in Civil Engineering , Vol. 1, No. 2, pp. 128–141, 1987.
13.10 C. Y. Lin and P. Hajela, Genetic algorithms in optimization problems with dis-
crete and integer design variables, Engineering Optimization , Vol. 19, pp. 309–327,
1992.
13.11 Z. Michalewicz, Genetic Algorithms + Data Structures = Evolution Programs, 2nd ed.,
Springer-Verlag, Berlin, 1994.
13.12 B. Hajek, Cooling schedules for optimal annealing, Mathematics of Operations
Research , Vol. 13, No. 4, pp. 563–571, 1988.
13.13 S. Kirkpatrick, C. D. Gelatt, Jr., and M. P. Vecchi, Optimization by simulated annealing,
Science, Vol. 220, pp. 671–680, 1983.
13.14 Y. Kim and H. Kim, A stepwise-overlapped parallel simulated annealing algorithm,
Integration, The VLSI Journal , Vol. 10, pp. 39–54, 1990.
13.15 P. van Laarhoven and E. Aarts, Simulated Annealing: Theory and Applications ,
D. Reidel, Boston, 1987.
13.16 A. Corana, M. Marchesi, C. Martini, and S. Ridella, Minimizing multimodal functions
of continuous variables with the simulated annealing algorithm, ACM Transactions on
Mathematical Software, Vol. 13, No. 3, pp. 262–280, 1987.
13.17 G.-S. Chen, R. J. Bruno, and M. Salama, Optimal placement of active/passive members
in truss structures using simulated annealing, AIAA Journal , Vol. 29, pp. 1327–1334,
1991.
13.18 M. Lundy and A. Mees, Convergence of an annealing algorithm, Mathematical Pro-
gramming , Vol. 34, pp. 111–124, 1986.
13.19 M. Atiqullah and S. S. Rao, Parallel processing in optimal structural design using
simulated annealing, AIAA Journal , Vol. 33, pp. 2386–2392, 1995.
13.20 K. Deb, Optimal design of a class of welded structures via genetic algorithms,
pp. 444–453 in Proceedings of the AIAA/ASME/ASCE/AHS/ASC 31st Structures, Struc-
tural Dynamics and Materials Conference, Long Beach, CA, Apr. 2–4, 1990.
13.21 K. M. Ragsdell and D. T. Phillips, Optimal design of a class of welded structure using
geometric programming, ASME Journal of Engineering for Industry , Vol. 98, No. 3,
pp. 1021–1025, 1976.
13.22 S. S. Rao, Description and optimum design of fuzzy mechanical systems, ASME Jour-
nal of Mechanisms, Transmissions, and Automation in Design , Vol. 109, pp. 126–132,
1987.
732 Modern Methods of Optimization
13.23 A. K. Dhingra and S. S. Rao, A neural network based approach to mechanical design
optimization, Engineering Optimization , Vol. 20, pp. 187–203, 1992.
13.24 L. Berke and P. Hajela, Applications of artificial neural nets in structural mechanics,
Structural Optimization , Vol. 4, pp. 90–98, 1992.
13.25 S. S. Rao, Multiobjective optimization of fuzzy structural systems, International Journal
for Numerical Methods in Engineering , Vol. 24, pp. 1157–1171, 1987.
13.26 S. S. Rao, K. Sundararaju, B. G. Prakash, and C. Balakrishna, A fuzzy goal
programming approach for structural optimization, AIAA Journal , Vol. 30, No. 5,
pp. 1425–1432, 1992.
13.27 A. K. Dhingra, S. S. Rao, and V. Kumar, Nonlinear membership functions in the
fuzzy optimization of mechanical and structural systems, AIAA Journal , Vol. 30, No. 1,
pp. 251–260, 1992.
13.28 A. K. Dhingra and S. S. Rao, An integrated kinematic–kinetostatic optimal design of
planar mechanisms using fuzzy theories, ASME Journal of Mechanical Design , Vol. 113,
pp. 306–311, 1991.
13.29 R. J. Balling and S. A. May, Large-scale discrete structural optimization: simulated
annealing, branch-and-bound, other techniques, Proceedings of the AIAA/ASME/ASCE/
AHS/ASC 32nd Structures, Structural Dynamics, and Materials Conference, Long
Beach, CA, 1990.
13.30 The Rand Corporation, A Million Random Digits with 100,000 Normal Deviates , The
Free Press, Glencoe, IL, 1955.
13.31 A. Colorni, M. Dorigo, and V. Maniezzo, Distributed optimization by ant colonies,
in Proceedings of the First European Conference on Artificial Life, F. J. Varela and
P. Bourgine, Eds., MIT Press, Cambridge, MA, pp. 134–142, 1992.
13.32 M. Dorigo, V. Maniezzo, and A. Colorni, The ant system optimization by a colony
of cooperating agents, IEEE Transactions on Systems, Man, and Cybernetics—Part B ,
Vol. 26, No. 1, pp. 29–41, 1996.
13.33 J. Kennedy and R. C. Eberhart, Swarm Intelligence, Morgan Kaufmann, San Francisco,
2001.
13.34 J. Kennedy and R. C. Eberhart, Particle swarm optimization, Proceedings of the 1995
IEEE International Conference on Neural Networks , IEEE Service Center, Piscataway,
NJ, 1995.
13.35 J-L. Liu and J-Horng Lin, Evolutionary computation of unconstrained and constrained
problems using a novel momentum-type particle swarm optimization, Engineering Opti-
mization , Vol. 39, No. 3, pp. 287–305, 2007.
13.36 Y. Shi and R. C. Eberhart, Parameter selection in particle swarm optimization, Pro-
ceedings of the Seventh Annual Conference on Evolutionary Programming , V. W. Porto,
N. Saravanan, D. Waagen, and A. Eibe, Eds., Springer-Verlag, pp. 591–600, Berlin,
Germany, 1998.
13.37 N. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller, Equation of
state calculations by fast computing machines, Journal of Chemical Physics , Vol. 21,
No. 6, pp. 1087–1092, 1953.
REVIEW QUESTIONS
13.1 Define the following terms:
(a) Fuzzy parameter
(b) Annealing
Review Questions 733
(c) Roulette wheel selection process
(d) Pheromone evaporation rate
(e) Neural network
(f) Fuzzy feasible domain
(g) Membership function
(h) Multilayer feedforward network
13.2 Match the following terms:
(a) Fuzzy optimization Based on shortest path
(b) Genetic algorithms Analysis equations not programmed
(c) Neural network method Linguistic data can be used
(d) Simulated annealing Based on the behavior of a flock of birds
(e) Particle swarm optimization Based on principle of survival of the fittest
(f) Ant colony optimization Based on cooling of heated solids
13.3 Answer true or false:
(a) GAs can be used to solve problems with continuous design variables.
(b) GAs do not require derivatives of the objective function.
(c) Crossover involves swapping of the binary digits between two strings.
(d) Mutation operator is used to produce offsprings.
(e) No new strings are formed in the reproduction stage in GAs.
(f) Simulated annealing can be used to solve only discrete optimization problems.
(g) Particle swarm optimization is based on cognitive and social learning rates of groups
of birds.
(h) Particle swarm optimization method uses the positions and velocities of particles.
(i) Genetic algorithms basically maximize an unconstrained function.
(j) Simulated annealing basically solves an unconstrained optimization problem.
(k) GAs seek to find a better design point from a trial design point.
(l) GAs can solve a discrete optimization problem with no additional effort.
(m) SA is a type of random search technique.
(n) GAs and SA can find the global minimum with high probability.
(o) GAs are zeroth-order methods.
(p) Discrete variables need not be represented as binary strings in GAs.
(q) SA will find a local minimum if the feasible space is nonconvex.
(r) The expressions relating the input and output are to be programmed in neural-
network-based methods.
(s) Several networks architectures can be used in neural-network-based optimization.
(t) A fuzzy quantity is same as a random quantity.
(u) Ant colony optimization solves only discrete optimization problems.
(v) Fuzzy optimization involves the maximization of the intersection of the objective
function and feasible domain.
13.4 Give brief answers:
(a) What is Boltzmann’s probability distribution?
734 Modern Methods of Optimization
(b) How is an inequality constrained optimization problem converted into an uncon-
strained problem for use in GAs?
(c) What is the difference between a crisp set and a fuzzy set?
(d) How is the output of a neuron described commonly?
(e) What are the basic operations used in GAs?
(f) What is a fitness function in GAs?
(g) Can you consider SA as a zeroth-order search method?
(h) How do you select the length of the binary string to represent a design variable?
(i) Construct the objective function to be used in GAs for a minimization problem with
mixed equality and inequality constraints.
(j) How is the crossover operation performed in GAs?
(k) What is the purpose of mutation? How is it implemented in GAs?
(l) What is the physical basis of SA?
(m) What is metropolis criterion and where is it used?
(n) What is a neural network?
(o) How is a neuron modeled in neural-network-based models?
(p) What is a sigmoid function?
(q) How is the error in the output minimized during network training?
(r) What is the difference between a random quantity and a fuzzy quantity?
(s) Give two examples of design parameters that can be considered as fuzzy.
(t) What is a valuation set?
(u) What is the significance of membership function?
(v) Define the union of two fuzzy sets A and B?
(w) How is the intersection of two fuzzy sets A and B defined?
(x) Show the complement of a fuzzy set in a Venn diagram.
(y) How is the optimum solution defined in a fuzzy environment?
(z) How is the fuzzy feasible domain defined for a problem with inequality constraints?
PROBLEMS
13.1 Consider the following two strings denoting the vectors X1 and X2:
X1 :
{
1 0 0 0 1 0 1 1 0 1
}
X2 :
{
0 1 1 1 1 1 0 1 1 0
}
Find the result of crossover at location 2. Also, determine the decimal values of the
variables before and after crossover if each string denotes a vector of two variables.
13.2 Two discrete fuzzy sets, A and B are defined as follows:
A =
{
(60, 0.1) (62, 0.5) (64, 0.7) (66, 0.9) (68, 1.0) (70, 0.8)
}
B =
{
(60, 0.0) (62, 0.2) (64, 0.4) (66, 0.8) (68, 0.9) (70, 1.0)
}
Determine the union and intersection of these sets.
13.3 Determine the size of the binary string to be used to achieve an accuracy of 0.01 for a
design variable with the following bounds:
Problems 735
(a) x(l) = 0, x(u) = 5
(b) x(l) = 0, x(u) = 10
(c) x(l) = 0, x(u) = 20
13.4 A design variable, with lower and upper bounds 2 and 13, respectively, is to be repre-
sented with an accuracy of 0.02. Determine the size of the binary string to be used.
13.5 Find the minimum of f = x5 − 5 x3 − 20 x + 5 in the range (0, 3) using the ant colony
optimization method. Show detailed calculations for 2 iterations with 4 ants.
13.6 In the ACO method, the amounts of pheromone along the various arcs from node i
are given by τij = 1, 2, 4, 3, 5, 2 for j = 1, 2, 3, 4, 5, 6, respectively. Find the arc (ij )
chosen by an ant based on the roulette-wheel selection process based on the random
number r = 0.4921.
13.7 Solve Example 13.5 by neglecting pheromone evaporation. Show the calculations for 2
iterations.
13.8 Find the maximum of the function f = −x5 + 5 x3 + 20x − 5 in the range −4 ≤ x ≤ 4
using the PSO method. Use 4 particles with the initial positions x1 = −2, x2 = 0,
x3 = 1, and x4 = 3. Show detailed calculations for 2 iterations.
13.9 Solve Example 13.4 using the inertia term when θ varies linearly from 0.9 to 0.4 in
Eq. (13.23).
13.10 Find the minimum of the following function using simulated annealing:
f (X) = 6x21 − 6x1x2 + 2x
2
2 − x1 − 2x2
Assume suitable parameters and show detailed calculations for 2 iterations.
13.11 Consider the following function for maximization using simulated annealing: f (x) =
x(1.5 − x) in the range (0, 5). If the initial point is x(0) = 2.0, generate a neighboring
point using a uniformly distributed random number in the range (0, 1). If the temperature
is 400, find the pbobability of accepting the neighboring point.
13.12 The population of binary strings in a maximization problem is given below:
String Fitness
0 0 1 1 0 0 8
0 1 0 1 0 1 12
1 0 1 0 1 1 6
1 1 0 0 0 1 2
0 0 0 1 0 0 18
1 0 0 0 0 0 9
0 1 0 1 0 0 10
Determine the expected number of copies of the best string in the above population in
the mating pool using the roulette-wheel selection process.
13.13 Consider the following constrained optimization problem:
Minimize f = x31 − 6x
2
1 + 11x1 + x3
736 Modern Methods of Optimization
subject to
x21 + x
2
2 − x
2
3 ≤ 0
4 − x21 − x
2
2 − x
2
3 ≤ 0
x3 − 5 ≤ 0
− xi ≤ 0; i = 1, 2, 3
Define the fitness function to be used in GA for this problem.
13.14 The bounds on the design variables in an optimization problem are given by
−10 ≤ x1 ≤ 10, 0 ≤ x2 ≤ 8, 150 ≤ x3 ≤ 750
Find the minimum binary string length of a design vector X = {x1, x2, x3}
T to achieve
an accuracy of 0.01.
14
Practical Aspects of Optimization
14.1 INTRODUCTION
Although the mathematical techniques described in Chapters 3 to 13 can be used
to solve all engineering optimization problems, the use of engineering judgment and
approximations help in reducing the computational effort involved. In this chapter we
consider several types of approximation techniques that can speed up the analysis time
without introducing too much error [14.1].
These techniques are especially useful in finite element analysis-based optimiza-
tion procedures. The practical computation of the derivatives of static displacements,
stresses, eigenvalues, eigenvectors, and transient response of mechanical and
structural systems is presented. The concept of decomposition, which permits the
solution of a large optimization problem through a set of smaller, coordinated sub-
problems is presented. The use of parallel processing and computation in the solution
of large-scale optimization problems is discussed. Many real-life engineering systems
involve simultaneous optimization of multiple-objective functions under a specified
set of constraints. Several multiobjective optimization techniques are summarized in
this chapter.
14.2 REDUCTION OF SIZE OF AN OPTIMIZATION PROBLEM
14.2.1 Reduced Basis Technique
In the optimum design of certain practical systems involving a large number of (n)
design variables, some feasible design vectors X1, X2, . . . , Xr may be available to start
with. These design vectors may have been suggested by experienced designers or may
be available from the design of similar systems in the past. We can reduce the size of
the optimization problem by expressing the design vector X as a linear combination of
the available feasible design vectors as
X = c1X1 + c2X2 + · · · + crXr (14.1)
where c1, c2, . . . , cr are the unknown constants. Then the optimization problem can
be solved using c1, c2, . . . , cr as design variables. This problem will have a much
smaller number of unknowns since r ≪ n. In Eq. (14.1), the feasible design vec-
tors X1, X2, . . . , Xr serve as the basis vectors. It can be seen that if c1 = c2 = · · · =
cr = 1/r , then X denotes the average of the basis vectors.
737Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
738 Practical Aspects of Optimization
14.2.2 Design Variable Linking Technique
When the number of elements or members in a structure is large, it is possible to
reduce the number of design variables by using a technique known as design variable
linking [14.25]. To see this procedure, consider the 12-member truss structure shown
in Fig. 14.1. If the area of cross section of each member is varied independently, we
will have 12 design variables. On the other hand, if symmetry of members about the
vertical (Y ) axis is required, the areas of cross section of members 4, 5, 6, 8, and 10
can be assumed to be the same as those of members 1, 2, 3, 7, and 9, respectively.
This reduces the number of independent design variables from 12 to 7. In addition, if
the cross-sectional area of member 12 is required to be three times that of member 11,
we will have six independent design variables only:
X =













x1
x2
x3
x4
x5
x6













≡













A1
A2
A3
A7
A9
A11













(14.2)
Once the vector X is known, the dependent variables can be determined as A4 =
A1, A5 = A2, A6 = A3, A8 = A7, A10 = A9, and A12 = 3A11. This procedure of treat-
ing certain variables as dependent variables is known as design variable linking . By
defining the vector of all variables as
ZT = {z1 z2 . . . z12}T ≡ {A1 A2 . . . A12}T
5
3
4
3
2
2
6
7
9
10
6
12
1 4
1
7 8
11
5
0
Y
Y6
Y7
Y4
X
Figure 14.1 Concept of design variable linking.
14.2 Reduction of Size of an Optimization Problem 739
the relationship between Z and X can be expressed as
Z
12×1
= [T ]
12×6
X
6×1 (14.3)
where the matrix [T ] is given by
[T ] =



















1 0 0 0 0 0
0 1 0 0 0 0
0 0 1 0 0 0
1 0 0 0 0 0
0 1 0 0 0 0
0 0 1 0 0 0
0 0 0 1 0 0
0 0 0 1 0 0
0 0 0 0 1 0
0 0 0 0 1 0
0 0 0 0 0 1
0 0 0 0 0 3



















(14.4)
The concept can be extended to many other situations. For example, if the geometry
of the structure is to be varied during optimization (configuration optimization) while
maintaining (1) symmetry about the Y axis and (2) alignment of the three nodes 2, 3,
and 4 (and 6, 7, and 4), we can define the following independent and dependent design
variables:
Independent variables: X5, X6, Y6, Y7, Y4
Dependent variables:
X1 = −X5, X2 = −X6, Y2 = Y6, Y3 = Y7, X7 =
Y4 − Y7
Y4 − Y6
X6,
X3 = −X7, X4 = 0, Y1 = 0, Y5 = 0
Thus the design vector X is
X =













x1
x2
x3
x4
x5













≡













X5
X6
Y6
Y7
Y4













(14.5)
The relationship between the dependent and independent variables can be defined more
systematically, by defining a vector of all geometry variables, Z, as
Z = {z1 z2 . . . z14}T
≡ {X1 Y1 X2 Y2 X3 Y3 X4 Y4 X5 Y5 X6 Y6 X7 Y7}T
which is related to X through the relations
zi = fi(X), i = 1, 2, . . . , 14 (14.6)
where fi denotes a function of X.
740 Practical Aspects of Optimization
14.3 FAST REANALYSIS TECHNIQUES
14.3.1 Incremental Response Approach
Let the displacement vector of the structure or machine, Y0, corresponding to the load
vector, P0, be given by the solution of the equilibrium equations
[K0]Y0 = P0 (14.7)
or
Y0 = [K0]−1P0 (14.8)
where [K0] is the stiffness matrix corresponding to the design vector, X0. When the
design vector is changed to X0 + X, let the stiffness matrix of the system change to
[K0] + [K], the displacement vector to Y0 + Y, and the load vector to P0 + P.
The equilibrium equations at the new design vector, X0 + X, can be expressed as
([K0] + [K])(Y0 + Y) = P0 + P (14.9)
or
[K0]Y0 + [K]Y0 + [K0]Y + [K]Y = P0 + P (14.10)
Subtracting Eq. (14.7) from Eq. (14.10), we obtain
([K0] + [K])Y = P − [K]Y0 (14.11)
By neglecting the term [K]Y, Eq. (14.11) can be reduced to
[K0]Y ≈ P − [K]Y0 (14.12)
which yields the first approximation to the increment in displacement vector Y as
Y1 = [K0]−1(P − [K]Y0) (14.13)
where [K0]
−1 is available from the solution in Eq. (14.8). We can find a better approx-
imation of Y by subtracting Eq. (14.12) from Eq. (14.11):
([K0] + [K])Y − [K0]Y1 = P − [K]Y0 − (P − [K]Y0) (14.14)
or
([K0] + [K])(Y − Y1) = −[K]Y1 (14.15)
By defining
Y2 = Y − Y1 (14.16)
Eq. (14.15) can be expressed as
([K0] + [K])Y2 = −[K]Y1 (14.17)
14.3 Fast Reanalysis Techniques 741
Neglecting the term [K]Y2, Eq. (14.17) can be used to obtain the second approxi-
mation to Y, Y2, as
Y2 = −[K0]−1([K]Y1) (14.18)
From Eq. (14.16), Y can be written as
Y =
2
∑
i=1
Yi (14.19)
This process can be continued and Y can be expressed, in general, as
Y =
∞
∑
i=1
Yi (14.20)
where Yi is found by solving the equations
[K0]Yi = −[K]Yi−1 (14.21)
Note that the series given by Eq. (14.20) may not converge if the change in the
design vector, X, is not small. Hence it is important to establish the validity of the
procedure for each problem, by determining the step sizes for which the series will
converge, before using it. The iterative process is usually stopped either by specify-
ing a maximum number of iterations and/or by prescribing a convergence criterion
such as
||Yi ||
∣
∣
∣
∣
∣
∣
∣
∣
i
∑
j=1
Yj
∣
∣
∣
∣
∣
∣
∣
∣
≤ ε (14.22)
where ||Yi || is the Euclidean norm of the vector Yi and ε is a small number on
the order of 0.01.
Example 14.1 Consider the crane (planar truss) shown in Fig. 14.2. Young’s modulus
of member e is equal to Ee = 30 × 106 psi (e = 1, 2, 3, 4), and the other data are
shown in Table 14.1. Assuming the base design to be A1 = A2 = 2 in.2 and A3 =
A4 = 1 in.2, and perturbations to be A1 = A2 = 0.4 in.2 and A3 = A4 = 0.2
in.2, determine (a) the exact displacements of nodes 3 and 4 at the base design, (b) the
displacements of nodes 3 and 4 at the perturbed design using the exact procedure, and,
(c) the displacements of nodes 3 and 4 at the perturbed design using the approximation
method.
SOLUTION The stiffness matrix of a typical element e is given by
[K (e)] = AeEe
le





l2ij lijmij −l2ij −lijmij
lijmij m
2
ij −lijmij −m2ij
−l2ij −lijmij l2ij lijmij
−lijmij −m2ij lijmij m2ij





(E1)
742 Practical Aspects of Optimization
1
4
2
3
1
3
2
4
y6
y5
y2
y1
y4
y8
y7
y3
50 in.
25 in.
1000 lb
100 in.
50 in. 100 in.
Figure 14.2 Crane (planar truss).
Table 14.1
Area of Global node of: Direction cosines of member
Member, cross Length, Corner Corner
e section, Ae le (in.) 1, i 2, j
lij =
Xj − Xi
le
mij =
Yj − Yi
le
1 A1 55.9017 1 3 0.8944 0.4472
2 A2 55.9017 3 2 0.8944 –0.4472
3 A3 167.7051 3 4 0.8944 0.4472
4 A4 141.4214 2 4 0.7071 0.7071
where Ae is the cross-sectional area, Ee is Young’s modulus, le is the length, and
(lij , mij ) are the direction cosines of member e. Equation (E1) can be used to compute
the stiffness matrices of the various members using the data of Table 14.1. When the
member stiffness matrices are assembled and the boundary conditions (y1 = y2 = y3 =
y4 = 0) are applied, the overall stiffness matrix becomes
[K] = (30 × 106)

















(
0.8A1
55.9017
+
0.8A2
55.9017
+
0.8A3
167.7051
) (
0.4A1
55.9017
−
0.4A2
55.9017
+
0.4A3
167.7051
) (
−0.8A3
167.7051
) (
−0.4A3
167.7051
)
(
0.2A1
55.9017
+
0.2A2
55.9017
+
0.2A3
167.7051
) (
−0.4A3
167.70501
) (
−0.2A3
167.7051
)
symmetric
(
0.8A3
167.7051
+ 0.5A4
141.4214
) (
0.4A3
167.7051
+ 0.5A4
141.4214
)
(
0.2A3
167.7051
+
0.5A4
141.4214
)

















(E2)
14.3 Fast Reanalysis Techniques 743
Thus the equilibrium equations of the structure can be expressed as
[K]Y = P (E3)
where
Y =







y5
y6
y7
y8







and P =







p5
p6
p7
p8







=







0
0
0
−1000







(a) At the base design, A1 = A2 = 2 in.2, A3 = A4 = 1 in.2, and the exact solution
of Eqs. (E3) gives the displacements of nodes 3 and 4 as
Ybase =







y5
y6
y7
y8







base
=







0.001165
0.002329
0.05147
−0.07032







in.
(b) At the perturbed design, A1 = A2 = 2.4 in.2, A3 = A4 = 1.2 in.2, and the exact
solution of Eq. (E3) gives the displacements of nodes 3 and 4 as
Yperturb =







y5
y6
y7
y8







perturb
=







0.0009705
0.001941
0.04289
−0.05860







in.
(c) The values of A1 = A2 = 2.4 in.2 and A3 = A4 = 1.2 in.2 at the perturbed
design are used to compute the new stiffness matrix as [K]perturb = [K] + [K],
which is then used to compute Y1, Y2, . . . using the approximation proce-
dure, Eqs. (14.13) and (14.21). The results are shown in Table 14.2. It can be
seen that the solution given by Eq. (14.20) converged very fast.
14.3.2 Basis Vector Approach
In structural optimization involving static response, it is possible to conduct an approx-
imate analysis at modified designs based on a limited number of exact analysis results.
This results in a substantial saving in computer time since, in most problems, the num-
ber of design variables is far smaller than the number of degrees of freedom of the
system. Consider the equilibrium equations of the structure in the form
[K]
m×m
Y
m×1
= P
m×1 (14.23)
where [K] is the stiffness matrix, Y the vector of displacements, and P the load vector.
Let the structure have n design variables denoted by the design vector
X =











x1
x2
...
xn











744 Practical Aspects of Optimization
Table 14.2
Exact Y0 =









0.116462E − 02
0.232923E − 02
0.514654E − 01
−0.703216E − 01









Exact (Y0 + Y) =









0.970515E − 03
0.194103E − 02
0.428879E − 01
−0.586014E − 01









Value of i Yi Yi = Y0 +
i
∑
k=1
Yk
1









−0.232922E − 03
−0.465844E − 03
−0.102930E − 01
0.140642E − 01


















0.931695E − 03
0.186339E − 02
0.411724E − 01
−0.562573E − 01









2









0.465842E − 04
0.931683E − 04
0.205859E − 02
−0.281283E − 02


















0.978279E − 03
0.195656E − 02
0.432310E − 01
−0.590702E − 01









3









−0.931678E − 05
−0.186335E − 04
−0.411716E − 03
0.562563E − 03


















0.968962E − 03
0.193792E − 02
0.428193E − 01
−0.585076E − 01









4









0.186335E − 05
0.372669E − 05
0.823429E − 04
−0.112512E − 03


















0.970825E − 03
0.194165E − 02
0.429016E − 01
−0.586201E − 01









If we find the exact solution at r basic design vectors X1, X2, . . . , Xr , the corresponding
solutions, Yi , are found by solving the equations
[Ki]Yi = P, i = 1, 2, . . . , r (14.24)
where the stiffness matrix, [Ki], is determined at the design vector Xi . If we consider a
new design vector, XN , in the neighborhood of the basic design vectors, the equilibrium
equations at XN can be expressed as
[KN ]YN = P (14.25)
where [KN ] is the stiffness matrix evaluated at XN . By approximating YN as a linear
combination of the basic displacement vectors Yi, i = 1, 2, . . . , r , we have
YN ≈ c1Y1 + c2Y2 + · · · + crYr = [Y ]c (14.26)
where [Y ] = [Y1, Y2, · · · , Yr ] is an n × r matrix and c = {c1, c2, · · · , cr}T is an
r-component column vector. Substitution of Eq. (14.26) into Eq. (14.25) gives
[KN ][Y ]c = P (14.27)
14.4 Derivatives of Static Displacements and Stresses 745
By premultiplying Eq. (14.27) by [Y ]T we obtain
[K̃]
r×r
c
r×1
= P̃
r×1 (14.28)
where
[K̃] = [Y ]T[KN ][Y ] (14.29)
P̃ = [Y ]T P (14.30)
It can be seen that an approximate displacement vector YN can be obtained by solv-
ing a smaller (r) system of equations, Eq. (14.28), instead of computing the exact
solution YN by solving a larger (n) system of equations, Eq. (14.25). The foregoing
method is equivalent to applying the Ritz–Galerkin principle in the subspace spanned
by the set of vectors Y1, Y2, . . . , Yr . The assumed modes Yi, i = 1, 2, . . . , r , can be
considered to be good basis vectors since they are the solutions of similar sets of
equations.
Fox and Miura 14.3 applied this method for the analysis of a 124-member,
96-degree-of-freedom space truss (shown in Fig. 14.3). By using a 5-degree-of-freedom
approximation, they observed that the solution of Eq. (14.28) required 0.653 s while
the solution of Eq. (14.25) required 5.454 s without exceeding 1% error in the
maximum displacement components of the structure.
14.4 DERIVATIVES OF STATIC DISPLACEMENTS AND STRESSES
The gradient-based optimization methods require the gradients of the objective and
constraint functions. Thus the partial derivatives of the response quantities with respect
to the design variables are required. Many practical applications require a finite-element
13
12
6
5
2
3
6
911
8
16
14
22
20
28
26
34
35
17 15
23 21
29 27
10
18
24
30
36
33
32
7
1
4
19
25
31
40 in.
40 in.
40 in.
30 in.
x
z
y
Figure 14.3 Space truss [13.3].
746 Practical Aspects of Optimization
analysis for computing the values of the objective function and/or constraint functions
at any design vector. Since the objective and/or constraint functions are to be evaluated
at a large number of trial design vectors during optimization, the computation of the
derivatives of the response quantities requires substantial computational effort. It is
possible to derive approximate expressions for the response quantities. The derivatives
of static displacements, stresses, eigenvalues, eigenvectors, and transient response of
structural and mechanical systems are presented in this and the following two sections.
The equilibrium equations of a machine or structure can be expressed as
[K]Y = P (14.31)
where [K] is the stiffness matrix, Y the displacement vector, and P the load vector.
By differentiating Eq. (14.31) with respect to the design variable xi , we obtain
∂[K]
∂xi
Y + [K] ∂Y
∂xi
= ∂P
∂xi
(14.32)
where ∂[K]/∂xi denotes the matrix formed by differentiating the elements of [K] with
respect to xi . Usually, the matrix is computed using a finite-difference scheme as
∂[K]
∂xi
≈ [K]
xi
= [K]new − [K]
xi
(14.33)
where [K]new is the stiffness matrix evaluated at the perturbed design vector X + Xi ,
where the vector Xi contains xi in the ith location and zero everywhere else:
Xi = {0 0 . . . 0 xi 0 . . . 0}T (14.34)
In most cases the load vector P is either independent of the design variables or a
known function of the design variables, and hence the derivatives, ∂P/∂xi , can be
evaluated with no difficulty. Equations (14.32) can be solved to find the derivatives of
the displacements as
∂Y
∂xi
= [K]−1
(
∂P
∂xi
− ∂[K]
∂xi
Y
)
(14.35)
Since [K]−1 or its equivalent is available from the solution of Eqs. (14.31), Eqs. (14.35)
can readily be solved to find the derivatives of static displacements with respect to the
design variables.
The stresses in a machine or structure (in a particular finite element) can be deter-
mined using the relation
σ = [R]Y (14.36)
where [R] denotes the matrix that relates stresses to nodal displacements. The deriva-
tives of stresses can then be computed as
∂σ
∂xi
= [R] ∂Y
∂xi
(14.37)
where the matrix [R] is usually independent of the design variables and the vector
∂Y/∂xi is given by Eq. (14.35).
14.5 Derivatives of Eigenvalues and Eigenvectors 747
14.5 DERIVATIVES OF EIGENVALUES AND EIGENVECTORS
Let the eigenvalue problem be given by [14.4, 14.6, 14.10]
[K]
m×m
Y
m×1
= λ [M]
m×m
Y
m×1
(14.38)
where λ is the eigenvalue, Y the eigenvector, [K] the stiffness matrix, and [M] the
mass matrix corresponding to the design vector X = {x1, x2, · · · , xn}T. Let the solution
of Eq. (14.38) be given by the eigenvalues λi and the eigenvectors Yi, i = 1, 2, . . . , m:
[Pi]Yi = 0 (14.39)
where [Pi] is a symmetric matrix given by
[Pi] = [K] − λi[M] (14.40)
14.5.1 Derivatives of λi
Premultiplication of Eq. (14.39) by YTi gives
YTi [Pi]Yi = 0 (14.41)
Differentiation of Eq. (14.41) with respect to the design variable xj gives
YTi,j [Pi]Yi + YTi
∂[Pi]
∂xj
Yi + YTi [Pi]Yi,j = 0 (14.42)
where Yi,j = ∂Yi/∂xj . In view of Eq. (14.39), Eq. (14.42) reduces to
YTi
∂[Pi]
∂xj
Yi = 0 (14.43)
Differentiation of Eq. (14.40) gives
∂[Pi]
∂xj
= ∂[K]
∂xj
− λi
∂[M]
∂xj
− ∂λi
∂xj
[M] (14.44)
where ∂[K]/∂xj and ∂[M]/∂xj denote the matrices formed by differentiating the ele-
ments of [K] and [M] matrices, respectively, with respect to xj . If the eigenvalues are
normalized with respect to the mass matrix, we have [14.10]
YTi [M]Yi = 1 (14.45)
Substituting Eq. (14.44) into Eq. (14.43) and using Eq. (14.45) gives the derivative of
λi with respect to xj as
∂λi
∂xj
= YTi
[
∂[K]
∂xj
− λi
∂[M]
∂xj
]
Yi (14.46)
It can be noted that Eq. (14.46) involves only the eigenvalue and eigenvector under
consideration and hence the complete solution of the eigenvalue problem is not required
to find the value of ∂λi/∂xj .
748 Practical Aspects of Optimization
14.5.2 Derivatives of Yi
The differentiation of Eqs. (14.39) and (14.45) with respect to xj results in
[Pi]
∂Yi
∂xj
= −∂[Pi]
∂xj
Yi (14.47)
2YTi [M]
∂Yi
∂xj
= −YTi
∂[M]
∂xj
Yi (14.48)
where ∂[Pi]/∂xj is given by Eq. (14.44). Equations (14.47) and (14.48) can be shown
to be linearly independent and can be written together as
[
[Pi]
2YTi [M]
]
(m+1)×m
∂Yi
∂xj
m×1
= −




∂[Pi]
∂xj
YTi
∂[M]
∂xj




(m+1)×m
Yi
m×1
(14.49)
By premultiplying Eq. (14.49) by
[
[Pi]
YTi [M]
]T
=
[
[Pi] [M]Yi
]
we obtain
[[Pi][Pi] + 2[M]YiYTi [M]]
m×m
∂Yi
∂xj
m×1
= −
[
[Pi]
∂[Pi]
∂xj
+ [M]YiYTi
∂[M]
∂xj
]
m×m
Yi
m×1
(14.50)
The solution of Eq. (14.50) gives the desired expression for the derivative of the
eigenvector, ∂Yi/∂xj , as
∂Yi
∂xj
= − [[Pi][Pi] + 2[M]YiYTi [M]]−1
×
[
[Pi]
∂[Pi]
∂xj
+ [M]YiYTi
∂[M]
∂xj
]
Yi (14.51)
Again it can be seen that only the eigenvalue and eigenvector under consideration are
involved in the evaluation of the derivatives of eigenvectors.
Y1 Y3
Y2 Y4 Y6
Y5
1 in. 1 in. 1 in.
x1 x2 x3• •
xi = 0.25″ (i = 1, 2, 3), r = 0.283 lb/in
3,
E = 30 × 106 psi
Figure 14.4 Cylindrical cantilever beam.
14.6 Derivatives of Transient Response 749
Table 14.3 Derivatives of Eigenvalues [14.4]
i Eigenvalue, λi 10
−9 ∂λi
∂x1
10−9
∂λi
∂x3
10−2
∂Y5i
∂x1
10−2
∂Y6i
∂x1
1 24.66 0.3209 –0.1582 1.478 –2.298
2 974.7 3.86 –0.4144 0.057 –3.046
3 7782.0 23.5 21.67 0.335 –5.307
For illustration, a cylindrical cantilever beam is considered [14.4]. The beam is
modeled with three finite elements with six degrees of freedom as indicated in Fig. 14.4.
The diameters of the beam are considered as the design variables, xi, i = 1, 2, 3. The
first three eigenvalues and their derivatives are shown in Table 14.3 [14.4].
14.6 DERIVATIVES OF TRANSIENT RESPONSE
The equations of motion of an n-degree-of-freedom mechanical/structural system with
viscous damping can be expressed as [14.10]
[M]Ÿ + [C]Ẏ + [K]Y = F(t) (14.52)
where [M], [C], and [K] are the n × n mass, damping, and stiffness matrices, respec-
tively, F(t) is the n-component force vector, Y is the n-component displacement vector,
and a dot over a symbol indicates differentiation with respect to time. Equations
(14.52) denote a set of n coupled second-order differential equations. In most practical
cases, n will be very large and Eqs. (14.52) are stiff; hence the numerical solution of
Eqs. (14.52) will be tedious and produces an accurate solution only for low-frequency
components. To reduce the size of the problem, the displacement solution, Y, is
expressed in terms of r basis functions 1,2, . . ., and r (with r ≪ n) as
Y = []q or yj =
r
∑
k=1
jkqk(t), j = 1, 2, . . . , n (14.53)
where
[] = [1 2 · · · r ]
is the matrix of basis functions, jk the element in row j and column k of the matrix
[], q an r-component vector of reduced coordinates, and qk(t) the kth component
of the vector q. By substituting Eq. (14.53) into Eq. (14.52) and premultiplying the
resulting equation by []T, we obtain a system of r differential equations:
[M]q̈ + [C]q̇ + [K]q = F(t) (14.54)
where
[M] = []T[M][] (14.55)
[C] = []T[C][] (14.56)
[K] = []T[K][] (14.57)
F(t) = []TF(t) (14.58)
750 Practical Aspects of Optimization
Note that if the undamped natural modes of vibration are used as basis functions and if
[C] is assumed to be a linear combination of [M] and [K] (called proportional damp-
ing), Eqs. (14.54) represent a set of r uncoupled second-order differential equations
which can be solved independently [14.10]. Once q(t) is found, the displacement solu-
tion Y(t) can be determined from Eq. (14.53).
In the formulation of optimization problems with restrictions on the dynamic
response, the constraints are placed on selected displacement components as
|yj (X, t)| ≤ ymax, j = 1, 2, . . . (14.59)
where yj is the displacement at location j on the machine/structure and ymax is the
maximum permissible value of the displacement. Constraints on dynamic stresses are
also stated in a similar manner. Since Eq. (14.59) is a parametric constraint in terms
of the parameter time (t), it is satisfied only at a set of peak or critical values of yj
for computational simplicity. Once Eq. (14.59) is satisfied at the critical points, it will
be satisfied (most likely) at all other values of t as well [14.11, 14.12]. The values
of yi at which dyj/dt = 0 or the values of yi at the end of the time interval denote
local maxima and hence are to be considered as candidate critical points. Among the
several candidate critical points, only a select number are considered for simplifying
the computations. For example, in the response shown in Fig. 14.5, peaks a, b, c, . . . , j
qualify as candidate critical points. However, peaks a, b, f , and j can be discarded
as their magnitudes are considerably smaller (less than, for example, 25%) than those
of other peaks. Noting that peaks d and e (or g and h) represent essentially a single
large peak with high-frequency undulations, we can discard peak e (or g), which has
a slightly smaller magnitude than d (or h). Thus finally, only peaks c, d, h, and i need
to be considered to satisfy the constraint, Eq. (14.59).
Once the critical points are identified at a reference design X, the sensitivity of the
response, yj (X, t) with respect to the design variable xi at the critical point t = tc can
be found using the total derivative of yj as
dyj (X, t)
dxi
=
∂yj
∂xi
+
∂yj
∂t
dtc
dxi
, i = 1, 2, . . . , n (14.60)
The second term on the right-hand side of Eq. (14.60) is always zero since ∂yj/∂t = 0
at an interior peak (0 < tc < tmax) and dt c/dx i = 0 at the boundary (tc = tmax). The
0
yj(t)
a
b
c
d
e
f
g
h
i
j
t
tmax
Figure 14.5 Critical points in a typical transient response.
14.7 Sensitivity of Optimum Solution to Problem Parameters 751
derivative, ∂yj/∂xi , can be computed using Eq. (14.53) as
∂yj
∂xi
=
r
∑
k=1
jk
∂qk(t)
∂xi
, i = 1, 2, . . . , n (14.61)
where, for simplicity, the elements of the matrix [] are assumed to be constants
(independent of the design vector X). Note that for higher accuracy, the derivatives
of jk with respect to xi (sensitivity of eigenvectors, if the mode shapes are used as
the basis vectors) obtained from an equation similar to Eq. (14.51) can be included in
finding ∂yj/∂xi .
To find the values of ∂qk/∂xi required in Eq. (14.61), Eq. (14.54) is differentiated
with respect to xi to obtain
[M]
∂q̈
∂xi
+ [C] ∂q̇
∂xi
+ [K] ∂q
∂xi
= ∂F
∂xi
− ∂[M]
∂xi
q̈ − ∂[C]
∂xi
q̇ − ∂[K]
∂xi
q, i = 1, 2, . . . , n (14.62)
The derivatives of the matrices appearing on the right-hand side of Eq. (14.62) can be
computed using formulas such as
∂[M]
∂xi
= []T ∂[M]
∂xi
[] (14.63)
where, for simplicity, [] is assumed to be constant and ∂[M]/∂xi is computed using
a finite-difference scheme. In most cases the forcing function F(t) will be known to
be independent of X or an explicit function of X. Hence the quantity ∂F/∂xi can be
evaluated without much difficulty. Once the right-hand side is known, Eqs. (14.62) can
be integrated numerically in time to find the values of ∂q̈/∂xi, ∂q̇/∂xi , and ∂q/∂xi .
Using the values of ∂q/∂xi = {∂qk/∂xi} at the critical point tc, the required sensitivity
of transient response can be found from Eq. (14.61).
14.7 SENSITIVITY OF OPTIMUM SOLUTION TO PROBLEM
PARAMETERS
Any optimum design problem involves a design vector and a set of problem param-
eters (or preassigned parameters). In many cases, we would be interested in knowing
the sensitivities or derivatives of the optimum design (design variables and objective
function) with respect to the problem parameters [14.25, 14.26]. As an example, con-
sider the minimum weight design of a machine component or structure subject to a
constraint on the induced stress. After solving the problem, we may like to find the
effect of changing the material. This means that we would like to know the changes
in the optimal dimensions and the minimum weight of the component or structure due
to a change in the value of the permissible stress. Usually, the sensitivity derivatives
are found by using a finite-difference method. But this requires a costly reoptimization
of the problem using incremented values of the parameters. Hence, it is desirable to
derive expressions for the sensitivity derivatives from appropriate equations. In this
section we discuss two approaches: one based on the Kuhn–Tucker conditions and the
other based on the concept of feasible direction.
752 Practical Aspects of Optimization
14.7.1 Sensitivity Equations Using Kuhn–Tucker Conditions
The Kuhn–Tucker conditions satisfied at the constrained optimum design X∗ are given
by [see Eqs. (2.73) and (2.74)]
∂f (X)
∂xi
+
∑
j∈J1
λj
∂gj (X)
∂xi
= 0, i = 1, 2, . . . , n (14.64)
gj (X) = 0, j ∈ J1 (14.65)
λj > 0, j ∈ J1 (14.66)
where J1 is the set of active constraints and Eqs. (14.64) to (14.66) are valid with
X = X∗ and λj = λ∗j . When a problem parameter changes by a small amount, we
assume that Eqs. (14.64) to (14.66) remain valid. Treating f, gj , X, and λj as functions
of a typical problem parameter p, differentiation of Eqs. (14.64) and (14.65) with
respect to p leads to
n
∑
k=1


∂2f (X)
∂xi∂xk
+
∑
j∈J1
λj
∂2gj (X)
∂xi∂xk


∂xk
∂p
+
∑
j∈J1
∂λj
∂p
∂gj (X)
∂xi
+
∂2f (X)
∂xi∂p
+
∑
j∈J1
λj
∂2gj (X)
∂xi∂p
= 0, i = 1, 2, . . . , n (14.67)
∂gj (X)
∂p
+
n
∑
i=1
∂gj (X)
∂xi
∂xi
∂p
= 0, j ∈ J1 (14.68)
Equations (14.67) and (14.68) can be expressed in matrix form as
[
[P ]n×n [Q]n×q
[Q]Tq×n [0]q×q
]



∂X
∂pn×1
∂λ
∂pq×1



+
{
an×1
bq×1
}
=
{
0n×1
0q×1
}
(14.69)
where q denotes the number of active constraints and the elements of the matrices and
vectors in Eq. (14.69) are given by
Pik =
∂2f (X)
∂xi∂xk
+
∑
j∈J1
λj
∂2gj (X)
∂xi∂xk
(14.70)
Qij =
∂gj (X)
∂xi
, j ∈ J1 (14.71)
ai =
∂2f (X)
∂xi∂p
+
∑
j∈J1
λj
∂gj (X)
∂xi∂p
(14.72)
bj =
∂gj (X)
∂p
, j ∈ J1 (14.73)
14.7 Sensitivity of Optimum Solution to Problem Parameters 753
∂X
∂p
=







∂x1
∂p
...
∂xn
∂p







,
∂λ
∂p
=







∂λ1
∂p
...
∂λq
∂p







(14.74)
The following can be noted in Eqs. (14.69):
1. Equations (14.69) denote (n + q) simultaneous equations in terms of the
required sensitivity derivatives, ∂xi/∂p (i = 1, 2, . . . , n) and ∂λj/∂p (j =
1, 2, . . . , q). Both X∗ and λ∗ are assumed to be known in Eqs. (14.69). If λ∗
are not computed during the optimization process, they can be computed using
Eq. (7.263).
2. Equations (14.69) can be solved only if the system is nonsingular. One of the
requirements for this is that the active constraints be independent.
3. Second derivatives of f and gj are required in computing the elements of [P ]
and a.
4. If sensitivity derivatives are required with respect to several problem parameters
p1, p2, . . . , only the vectors a and b need to be computed for each case and the
system of Eqs. (14.69) can be solved efficiently using the techniques of solving
simultaneous equations with different right-hand-side vectors.
Once Eqs. (14.69) are solved, the sensitivity of optimum objective value with respect
to p can be computed as
df (X)
dp
= ∂f (X)
∂p
+
n
∑
i=1
∂f (X)
∂xi
∂xi
∂p
(14.75)
The changes in the optimum values of xi and f necessary to satisfy the Kuhn–Tucker
conditions due to a change p in the problem parameter can be estimated as
xi =
∂xi
∂p
p, f = df
dp
p (14.76)
The changes in the values of Lagrange multiplier λj due to p can be estimated as
λj =
∂λj
∂p
p (14.77)
Equation (14.77) can be used to determine whether an originally active constraint
becomes inactive due to the change, p. Since the value of λj is zero for an inactive
constraint, we have
λj + λj = λj +
∂λj
∂p
p = 0 (14.78)
from which the value of p necessary to make the j th constraint inactive can be
found as
p = −
λj
∂λj/∂p
, j ∈ J1 (14.79)
754 Practical Aspects of Optimization
Similarly, a currently inactive constraint will become critical due to p if the new
value of gj becomes zero:
gj (X) +
dgj
dp
p = gj (X) +
(
n
∑
i=1
∂gj
∂xi
∂xi
∂p
)
p (14.80)
Thus the change p necessary to make an inactive constraint active can be
found as
p = −
gj (X)
n
∑
i=1
∂gj
∂xi
∂xi
∂p
(14.81)
14.7.2 Sensitivity Equations Using the Concept of Feasible Direction
Here we treat the problem parameter p as a design variable so that the new design
vector becomes
X = {x1 x2 · · · xn p}T (14.82)
As in the case of the method of feasible directions (see Section 7.7), we formulate the
direction finding problem as
Find X which minimizes − ST∇f (X)
subject to
ST∇gj ≤ 0, j ∈ J1
STS ≤ 1 (14.83)
where the gradients of f and gj (j ∈ J1) can be evaluated in the usual manner. The set
J1 can include nearly active constraints also (along with the active constraints) so that
we do not violate any constraint due to the change, p. The solution of the problem
stated in Eqs. (14.83) gives a usable feasible search direction, S. A new design vector
along S can be expressed as
Xnew = Xcurrent + λS = Xcurrent + X (14.84)
where λ is the step length and the components of S can be considered as
si =







∂xi
∂λ
, i = 1, 2, . . . , n
∂p
∂λ
, i = n + 1
(14.85)
so that
p = λsn+1 or λ =
p
sn+1
(14.86)
14.8 Multilevel Optimization 755
If the vector S is normalized by dividing its components by sn+1, Eq. (14.86) gives
λ = p and hence Eq. (14.85) gives the desired sensitivity derivatives as







∂x1
∂p
...
∂xn
∂p







= 1
sn+1
S (14.87)
Thus the sensitivity of the objective function with respect to p can be computed as
df (X)
dp
= ∇f (X)T S
sn+1
(14.88)
Note that unlike the previous method, this method does not require the values of λ∗
and the second derivatives of f and gj to find the sensitivity derivatives. Also, if
sensitivities with respect to several problem parameters p1, p2, . . . are required, all we
need to do is to add them to the design vector X in Eq. (14.82).
14.8 MULTILEVEL OPTIMIZATION
14.8.1 Basic Idea
The design of practical systems involving a large number of elements or subsys-
tems with multiple-load conditions involves excessive number of design variables and
constraints. The optimization problem becomes unmanageably large, and the solution
process becomes too costly and can easily saturate even the largest computers avail-
able. In such cases the optimization problem can be broken into a series of smaller
problems using different strategies. The multilevel optimization is a decomposition
technique in which the problem is reformulated as several smaller subproblems (one
for each subsystem) and a coordination problem (at system level) to preserve the cou-
pling among the subproblems (subsystems). Such approaches have been used in linear
and dynamic programming also. In linear programming, the decomposition method (see
Section 4.4) involves a number of independent linear subproblems coupled by limita-
tions on the shared resources. When an individual subsystem is solved, the cost of the
shared resources is added to its objective function. By a proper variation of the costs
of the shared resources, the proposed optimal strategies of the various subproblems
are sent to the master program, which, in turn, is optimized so that the overall cost is
minimized. In dynamic programming, the problem is treated in stages with an optimal
policy determined in each stage (see Chapter 9). This approach is particularly useful
when the problem has a serial structure.
For nonlinear design optimization problems, several decomposition methods
have been proposed [14.14–14.16]. In the following section we consider a two-level
approach in which the system is decomposed into a number of smaller subproblems,
each with its own goals and constraints. The individual subsystem optimization
problems are solved independently in the first level and the coordinated problem
is solved in the second level. The approach is known as the model-coordination
method .
756 Practical Aspects of Optimization
14.8.2 Method
Let the optimization problem be stated as follows:
Find X = {x1 x2 · · · xn}T which minimizes f (X) (14.89)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m (14.90)
hk(X) = 0, k = 1, 2, . . . , p (14.91)
x
(l)
i ≤ xi ≤ x
(u)
i , i = 1, 2, . . . , n (14.92)
where x
(l)
i and x
(u)
i denote the lower and upper bounds on xi . Most systems permit the
partitioning of the vector X into two subvectors Y and Z:
X =
{
Y
Z
}
(14.93)
where the subvector Y denotes the coordination or interaction variables between the
subsystems and the subvector Z indicates the variables confined to subsystems. The
vector Z, in turn, can be partitioned as
Z =

















Z1
...
Zk
...
ZK

















(14.94)
where Zk represents the variables associated with the kth subsystem only and K denotes
the number of subsystems. The partitioning of variables, Eq. (14.94), permits us to
regroup the constraints as











g1(X)
g2(X)
...
gm(X)











=











g(1)(Y, Z1)
g(2)(Y, Z2)
...
g(K)(Y, ZK)











≤ 0 (14.95)











l1(X)
l2(X)
...
lp(X)











=











l(1)(Y, Z1)
l(2)(Y, Z2)
...
l(K)(Y, ZK)











= 0 (14.96)
where the variables Y may appear in all the functions while the variables Zk appear
only in the constraint sets g(k) ≤ 0 and h(k) = 0. The bounds on the variables,
Eq. (14.92), can be expressed as
14.8 Multilevel Optimization 757
Y(l) ≤ Y ≤ Y(u)
Z
(l)
k ≤ Zk ≤ Z
(u)
k , k = 1, 2, . . . , K (14.97)
Similarly, the objective function f (X) can be expressed as
f (X) =
K
∑
k=1
f (k)(Y, Zk) (14.98)
where f (k)(Y, Zk) denotes the contribution of the kth subsystem to the overall objective
function. Using Eqs. (14.95) to (14.98), the two-level approach can be stated as follows.
First-level Problem. Tentatively fix the values of Y at Y∗ so that the problem of
Eqs. (14.89) to (14.92) [or Eqs. (14.95) to (14.98)] can be restated (decomposed) as K
independent optimization problems as follows:
Find Zk which minimizes f
(k)(Y, Zk)
subject to
g(k)(Y, Zk) ≤ 0
h(k)(Y, Zk) = 0 (14.99)
Z
(l)
k ≤ Zk ≤ Z
(u)
k ; k = 1, 2, . . . , K
It can be seen that the first-level problem seeks to find the minimum of the function
f (Y, Z) =
K
∑
k=1
f (k)(Y, Zk) (14.100)
for the (tentatively) fixed vector Y∗.
Second-level Problem. The following problem is solved in this stage:
Find a new Y∗ which minimizes f (Y) =
K
∑
k=1
f (k)(Y, Z∗k)
subject to
Y(l) ≤ Y ≤ Y(u) (14.101)
where Z∗k, k = 1, 2, . . . ,K , are the optimal solutions of the first-level problems. An
additional constraint to ensure a finite value of f (Y∗) is also to be included while
solving the problem of Eqs. (14.101). Once the problem is solved and a new Y∗ found,
we proceed to solve the first-level problems. This process is to be continued until
convergence is achieved. The iterative process can be summarized as follows:
1. Start with an initial coordination vector, Y∗.
2. Solve the K first-level optimization problems, stated in Eqs. (14.99), and find
the optimal vectors Z∗k(k = 1, 2, . . . ,K).
758 Practical Aspects of Optimization
3. Solve the second-level optimization problem stated in Eqs. (14.101) and find a
new vector Y∗.
4. Check for the convergence of f ∗ and Y∗ (compared to the value Y∗ used
earlier).
5. If the process has not converged, go to step 2 and repeat the process until
convergence.
The following example illustrates the procedure.
Example 14.2 Find the minimum-weight design of the two-bar truss shown in Fig. 14.6
with constraints on the depth of the truss (y = h), cross-sectional areas of the members
(z1 = A1) and (z2 = A2), and the stresses induced in the bars. Treat the depth of the
truss (y) and the cross-sectional areas of bars 1 and 2 (z1 and z2) as design variables.
The permissible stress in each bar is σ0 = 105 Pa, unit weight is 76,500 N/m3, h is
constrained as 1 m ≤ h ≤ 6 m, and the cross-sectional area of each bar is restricted to
lie between 0 and 0.1 m2.
SOLUTION The stresses induced in the bars can be expressed as
σ1 =
P
√
y2 + 36
7yz1
, σ2 =
6P
√
y2 + 1
7yz2
and hence the optimization problem can be stated as follows:
Find X = {y z1 z2}Twhich minimizes
f (X) = 76,500z1
√
y2 + 36 + 76,500z2
√
y2 + 1
subject to
P
√
y2 + 36
7σ0yz1
− 1 ≤ 0, 6P
√
y2 + 1
7σ0yz2
− 1 ≤ 0
1 ≤ y ≤ 6, 0 ≤ z1 ≤ 0.1, 0 ≤ z2 ≤ 0.1
6 m
Bar 1
(area, A1 = z1)
Bar 2
(area, A2 = z2)
P
R
Q
1 m
h = y
P = 1000N
Figure 14.6 Two-bar truss.
14.8 Multilevel Optimization 759
We treat the bars 1 and 2 as subsystems 1 and 2, respectively, with y as the coordination
variable (Y = {y}) and z1 and z2 as the subsystem variables (Z1 = {z1} and Z2 = {z2}).
By fixing the value of y at y∗, we formulate the first-level problems as follows.
Subproblem 1.
Find z1 which minimizes
f (1)(y∗, z1) = 76,500z1
√
(y∗)2 + 36 (E1)
subject to
g1(y
∗, z1) =
(1428.5714 × 10−6)
√
(y∗)2 + 36
y∗z1
− 1 ≤ 0 (E2)
0 ≤ z1 ≤ 0.1 (E3)
Subproblem 2.
Find z2 which minimizes
f (2)(y∗, z2) = 76,500z2
√
(y∗)2 + 1 (E4)
subject to
g2(y
∗, z2) =
(8571.4285 × 10−6)
√
(y∗)2 + 1
y∗z2
− 1 ≤ 0 (E5)
0 ≤ z2 ≤ 0.1 (E6)
We can see that to minimize f (1) we need to make z1 as small as possible without
violating the constraints of Eqs. (E2) and (E3). This gives the solution of subproblem
1, z∗1 (which makes g1 active) as
z∗1 =
(1428.5714 × 10−6)
√
(y∗)2 + 36
y∗
(E7)
Similarly, the solution of subproblem 2, z∗2 (which makes g2 active) can be expressed
as
z∗2 =
(8571.4285 × 10−6)
√
(y∗)2 + 1
y∗
(E8)
Now we state the second-level problem as follows:
Find y which minimizes f = f (1)(y, z∗1) + f (2)(y, z∗2)
subject to
1 ≤ y ≤ 6 (E9)
Using Eqs. (E7) and (E8), this problem can be restated as (using y for y
∗):
760 Practical Aspects of Optimization
Find y which minimizes
f = 76,500z∗1
√
y2 + 36 + 76,500z∗2
√
y2 + 1
= 109.2857y
2 + 36
y
+ 655.7143y
2 + 1
y
(E10)
subject to
1 ≤ y ≤ 6 and f must be defined
The graph of f, given by Eq. (E10), is shown in Fig. 14.7 over the range 1 ≤ y ≤ 6
from which the solution can be determined as f ∗ = 3747.7 N, y∗ = h∗ = 2.45 m, z∗1 =
A
∗
1 = 3.7790×10−3 m2, and z∗2 = A∗2 = 9.2579×10−3 m2.
14.9 PARALLEL PROCESSING
Large-scale optimization problems can be solved efficiently using parallel computers.
Parallel computers are simply multiple processing units combined in an organized
fashion such that multiple independent computations for the same problem could be
performed simultaneously or concurrently, thereby increasing the overall computational
speed. Optimization problems involving extensive analysis, such as a finite-element
analysis, can be solved on parallel computers using the following schemes:
1. A multilevel (decomposition) approach with the subproblems solved in parallel
2. A substructures approach with substructure analyses performed in parallel
3. By implementing the optimization computations in parallel
0
3200
3600
4000
4400
4800
5200
5600
6000
1 2 3 4 5 6 y(m)
f(N)
y* = 2.45 m
f* = 3747.7 N
Figure 14.7 Graphical solution of the second-level problem.
14.10 Multiobjective Optimization 761
If a multilevel (decomposition) approach is used, the optimization of various subsystems
(at different levels) can be performed on parallel processors while the solution of the
coordinating optimization problem can be accomplished on the main processor. If the
optimization problem involves an extensive analysis, such as a finite-element analysis,
the problem can be decomposed into subsystems (substructures) and the analyses of
subsystems can be conducted on parallel processors with a main processor performing
the system-level computations. Such an approach was used by El-Sayed and Hsiung
[14.17, 14.20]. The procedure can be summarized as follows:
1. Initialize the optimization process. The current (related) design variables are
sent to the various processors.
2. The finite-element analyses of the substructures are performed on different
(associated) processors.
3. The main processor collects the stiffness and force contribution matrices from
the various processors, solves for the displacements at the shared (common)
boundary nodes of substructures, and sends the data to various processors.
4. The associated processors perform the detailed calculations to find the displace-
ments and stresses needed for the evaluation of the constraints.
5. The main processor collects the constraint-related data from the associate pro-
cessors and checks the convergence of the optimization process. If convergence
is not achieved, it performs the computations of the optimization algorithm and
the procedure is repeated from step 1 onward.
Numerical examples were solved on a Cray X-MP four-processor supercomputer
[14.17]. For a 200-member planar truss, the weight was minimized with constraints on
stresses using four substructures. It was reported [14.17] that the parallel computations
required 10.585 s of CPU time, while the sequential computations required a CPU time
of 13.518 s (with a speedup factor of 1.28)
For most mechanical and structural problems, parallel computers with MIMD (mul-
tiple instruction multiple data) architecture are better suited. Atiqullah and Rao [14.21]
presented a procedure for the parallel implementation of the simulated annealing algo-
rithm. In this method, certain design variables assigned to each processor perform the
variable specific optimization. This information is later combined to complete one cycle
of optimization. Since the entire (variable-specific) optimization process is repeated on
each processor, all processors will be equally busy most of the time, except for any
input/output done by the specific processors. Thus the “divide and conquer” strategy
of optimization needs a “communicate and combine” process, which should be kept to
a minimum. The detailed procedure is shown as a flow diagram in Fig. 14.8.
The minimum-weight design of a 128-bar planar truss was considered with
stress and buckling constraints. A speedup factor of 10.2569 was achieved using the
eight-node configuration of an iPSC/860 computer.
14.10 MULTIOBJECTIVE OPTIMIZATION
A multiobjective optimization problem with inequality constraints can be stated as
(equality constraints, if they exist, can also be included in the formulation of the
problem)
762 Practical Aspects of Optimization
Initialize node i
Data from the host node
Randomly perturb one variable out of S(i)
Change the design
Exchange updated information
from other nodes
All variable perturbed
out of S(i)?
Yes
No
No
Yes
Globally assemble all
updated design
variables
All cycles done?
Final design, stop
Figure 14.8 Flow diagram of parallel simulated annealing on a single node. S(i), set of design
variables assigned to node i; node i = processor i.
Find X =











x1
x2
...
xn











(14.102)
which minimizes f1(X), f2(X), . . . , fk(X) (14.103)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m (14.104)
where k denotes the number of objective functions to be minimized. Any or all of the
functions fi(X) and gj (X) may be nonlinear. The multiobjective optimization problem
is also known as a vector minimization problem .
14.10 Multiobjective Optimization 763
60
40
20
0 1 2 3 4 5 6 7 8
f1 = (x−3)
4
f2 = (x−6)
2
P Q
x
f
Figure 14.9 Pareto optimal solutions.
In general, no solution vector X exists that minimizes all the k objective functions
simultaneously. Hence, a new concept, known as the Pareto optimum solution , is used
in multiobjective optimization problems. A feasible solution X is called Pareto optimal
if there exists no other feasible solution Y such that fi(Y) ≤ fi(X) for i = 1, 2, . . . , k
with fj (Y) < fi(X) for at least one j . In other words, a feasible vector X is called
Pareto optimal if there is no other feasible solution Y that would reduce some objective
function without causing a simultaneous increase in at least one other objective function.
For example, if the objective functions are given by f1 = (x − 3)4 and f2 = (x − 6)2,
their graphs are shown in Fig. 14.9. For this problem, all the values of x between 3
and 6 (points on the line segment PQ) denote Pareto optimal solutions.
Several methods have been developed for solving a multiobjective optimization
problem. Some of these methods are briefly described in the following paragraphs.
Most of these methods basically generate a set of Pareto optimal solutions and use
some additional criterion or rule to select one particular Pareto optimal solution as the
solution of the multiobjective optimization problem.
14.10.1 Utility Function Method
In the utility function method, a utility function Ui(fi) is defined for each objective
depending on the importance of fi compared to the other objective functions. Then a
total or overall utility function U is defined, for example, as
U =
k
∑
i=1
Ui(fi) (14.105)
The solution vector X∗ is then found by maximizing the total utility U subjected to the
constraints gj (X) ≤ 0, j = 1, 2, . . . , m. A simple form of Eq. (14.105) is given by
U =
k
∑
i=1
Ui = −
k
∑
i=1
wifi(X) (14.106)
764 Practical Aspects of Optimization
where wi is a scalar weighting factor associated with the ith objective function. This
method [Eq.(14.106)] is also known as the weighting function method .
14.10.2 Inverted Utility Function Method
In the inverted utility function method, we invert each utility and try to minimize or
reduce the total undesirability. Thus if Ui(fi) denotes the utility function corresponding
to the ith objective function, the total undesirability is obtained as
U−1 =
k
∑
i=1
U−1i =
k
∑
i=1
1
Ui
(14.107)
The solution of the problem is found by minimizing U−1 subject to the constraints
gj (X) ≤ 0, j = 1, 2, . . . , m.
14.10.3 Global Criterion Method
In the global criterion method the optimum solution X∗ is found by minimizing a
preselected global criterion, F(X), such as the sum of the squares of the relative
deviations of the individual objective functions from the feasible ideal solutions. Thus
X∗ is found by minimizing
F(X) =
k
∑
i=1
{
fi(X
∗
i ) − fi(X)
fi(X
∗
i )
}p
subject to (14.108)
gj (X) ≤ 0, j = 1, 2, . . . , m
where p is a constant (an usual value of p is 2) and X∗i is the ideal solution for the
ith objective function. The solution X∗i is obtained by minimizing fi(X) subject to the
constraints gj (X) ≤ 0, j = 1, 2, . . . , m.
14.10.4 Bounded Objective Function Method
In the bounded objective function method, the minimum and the maximum acceptable
achievement levels for each objective function fi are specified as L
(i) and U (i), respec-
tively, for i = 1, 2, . . . , k. Then the optimum solution X∗ is found by minimizing the
most important objective function, say, the rth one, as follows:
Minimize fr(X)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m
L(i) ≤ fi ≤ U (i), i = 1, 2, . . . , k, i 
= r (14.109)
14.10 Multiobjective Optimization 765
14.10.5 Lexicographic Method
In the lexicographic method, the objectives are ranked in order of importance by the
designer. The optimum solutoin X∗ is then found by minimizing the objective functions
starting with the most important and proceeding according to the order of importance
of the objectives. Let the subscripts of the objectives indicate not only the objective
function number, but also the priorities of the objectives. Thus f1(X) and fk(X) denote
the most and least important objective functions, respectively. The first problem is
formulated as
Minimize f1(X)
subject to (14.110)
gj (X) ≤ 0, j = 1, 2, . . . , m
and its solution X∗1 and f
∗
1 = f1(X∗1) is obtained. Then the second problem is
formulated as
Minimize f2(X)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m
f1(X) = f ∗1 (14.111)
The solution of this problem is obtained as X∗2 and f
∗
2 = f2(X∗2). This procedure
is repeated until all the k objectives have been considered. The ith problem is
given by
Minimize fi(X)
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m
fl(X) = f ∗l , l = 1, 2, . . . , i − 1 (14.112)
and its solution is found as X∗i and f
∗
i = fi(X∗i ). Finally, the solution obtained at
the end (i.e., X∗k) is taken as the desired solution X
∗ of the original multiobjective
optimization problem.
14.10.6 Goal Programming Method
In the simplest version of goal programming, the designer sets goals for each objective
that he or she wishes to attain. The optimum solution X∗ is then defined as the one that
minimizes the deviations from the set goals. Thus the goal programming formulation
of the multiobjective optimization problem leads to
Minimize


k
∑
j=1
(d+j + d
−
j )
p


1/p
, p ≥ 1
766 Practical Aspects of Optimization
subject to
gj (X) ≤ 0, j = 1, 2, . . . , m
fj (X) + d+j − d
−
j = bj , j = 1, 2, . . . , k
d+j ≥ 0, j = 1, 2, . . . , k (14.113)
d−j ≥ 0, j = 1, 2, . . . , k
d+j d
−
j = 0, j = 1, 2, . . . , k
where bj is the goal set by the designer for the j th objective and d
+
j and d
−
j are,
respectively, the underachievement and overachievement of the j th goal. The value of
p is based on the utility function chosen by the designer. Often the goal for the j th
objective, bj , is found by first solving the following problem:
Minimizefj (X)
subject to (14.114)
gj (X) ≤ 0, j = 1, 2, . . . , m
If the solution of the problem stated in Eq. (14.114) is denoted by X∗j , then bj is taken
as bj = fj (X∗j ).
14.10.7 Goal Attainment Method
In the goal attainment method, goals are set as bi for the objective function fi(X), i =
1, 2, . . . , k. In addition, a weight wi > 0 is defined for the objective function fi (X) to
denote the importance of the ith objective function relative to other objective functions
in meeting the goal bi , i = 1, 2, . . . , k. Often the goal bi is found by first solving the
single objective optimization problem:
Minimizefi(X)
subject to (14.115)
gj (X) ≤ 0; j = 1, 2, . . . , m
If the solution of the problem stated in Eq. (14.115) is denoted X∗j then bi can be
taken as the optimum value of the objective fi, f
∗
i = f (X∗i ). A scalar γ is introduced
as a design variable in addition to the n design variables xi , i = 1, 2, . . . , n. Then the
following problem is solved:
Find x1, x2, . . . , xn and γ
to minimize F(x1, x2, . . . , xn, γ ) = γ
subject to (14.116)
gj (X) ≤ 0; j = 1, 2, . . . , m
fi(X) − γwi ≤ bi; i = 1, 2, . . . , k
14.11 Solution of Multiobjective Problems Using MATLAB 767
with the weights satisfying the normalization condition
k
∑
i=1
wi = 1
14.11 SOLUTION OF MULTIOBJECTIVE PROBLEMS USING
MATLAB
The MATLAB function fgoalattain can be used to solve a multiobjective optimiza-
tion problem using the goal attainment method. The following example illustrates the
procedure.
Example 14.3 Find the solution of the following three-objective optimization problem
using goal attainment method using the MATLAB function fgoalattain.
Minimize
f1 = 12 (x1 − 2)
2 + 1
13
(x2 + 1)2 + 3
f2 = 1175 (x1 + x2 − 3)
2 + 1
17
(2x2 − x1)2 − 13
f3 = 18 (3x1 − 2x2 + 4)
2 + 1
27
(x1 − x2 + 1)2 + 15
subject to
− 4 ≤ xi ≤ 4; i = 1, 2
4x1 + x2 − 4 ≤ 0
− x1 − 1 ≤ 0
x1 − x2 − 2 ≤ 0
Assume the initial design variables to be x1 = x2 = 0.1, the weights to be w1 = 0.2,
w2 = 0.5, and w3 = 0.3, and the goals to be b1 = 5, b2 = −8, and b3 = 20.
SOLUTION
Step 1: Create an m-file for the objective functions and save it as fgoalat-
tain_obj.m
function f = fgoalattainobj(x)
f(1) = (x(1)-2)^2/2+(x(2)+1)^2/13+3
f(2) = (x(1)+x(2)-3)^2/175+(2*x(2)-x(1))^2/17-13
f(3) = (3*x(1)-2*x(2)+4)^2/8+(x(1)-x(2)+1)^2/27+15
Step 2: Create an m-file for the constraints and save it as fgoalattain_con.m
function [c ceq] = fgoalattaincon(x)
c= [- 4- x(1); ...
x(1)- 4; ...
768 Practical Aspects of Optimization
- 4- x(2); ...
x(2)- 4; ...
x(2)+4*x(1)- 4; ...
- 1- x(1); ...
x(1)- 2- x(2)]
ceq = [];
Step 3: Ctreate an m-file for the main program and save it as fgoalat-
tain_main.m
clc; clear all;
x0 = [0.1 0.1]
weight = [0.2 0.5 0.3]
goal = [5 -8 20]
x,fval,attainfactor,exitflag] = fgoalattain (@fgoalattainobj,
x0,goal,weight,[],[],[],[],[],[],@fgoalattaincon)
Step 4: Run the program fgoalattain_main.m to obtain the following result:
Initial design vector: 0.1,0.1
Initial objective values: 4.8981 -12.9546 17.1383
Constraints at initial design: -4.1000
-3.9000
-4.1000
-3.9000
-3.5000
-1.1000
-2.0000
Optimum design vector: 0.8308 0.6769
Optimum objective values: 3.8999 -12.9712 18.3498
Constraints at optimum design: -4.8308
-3.1692
-4.6769
-3.3231
-0.0000
-1.8308
-1.8462
REFERENCES AND BIBLIOGRAPHY
14.1 L. A. Schmidt, Jr., and B. Farshi, Some approximation concepts for structural synthesis,
AIAA Journal , Vol. 12, No. 5, pp. 692–699, 1974.
14.2 E. J. Haug, K. K. Choi, and V. Komkov, Design Sensitivity Analysis of Structural Sys-
tems , Academic Press, New York, 1986.
References and Bibliography 769
14.3 R. L. Fox and H. Miura, An approximate analysis technique for design calculations,
AIAA Journal , Vol. 9, No. 1, pp. 177–179, 1971.
14.4 R. L. Fox and M. P. Kapoor, Rates of change of eigenvalues and eigenvectors, AIAA
Journal , Vol. 6, No. 12, pp. 2426–2429, 1968.
14.5 D. V. Murthy and R. T. Haftka, Derivatives of eigenvalues and eigenvectors of general
complex matrix, International Journal for Numerical Methods in Engineering , Vol. 26,
pp. 293–311, 1988.
14.6 R. B. Nelson, Simplified calculation of eigenvector derivatives, AIAA Journal , Vol. 14,
pp. 1201–1205, 1976.
14.7 S. S. Rao, Rates of change of flutter Mach number and flutter frequency, AIAA Journal ,
Vol. 10, pp. 1526–1528, 1972.
14.8 T. R. Sutter, C. J. Camarda, J. L. Walsh, and H. M. Adelman, Comparison of several
methods for the calculation of vibration mode shape derivatives, AIAA Journal , Vol. 26,
No. 12, pp. 1506–1511, 1988.
14.9 S. S. Rao, The Finite Element Method in Engineering , 4th ed., Elsevier Butterworth
Heinemann, Burlington, MA, 2005.
14.10 S. S. Rao, Mechanical Vibrations , 4th ed., Pearson Prentice Hall, Upper Saddle River,
NJ, 2004.
14.11 R. V. Grandhi, R. T. Haftka, and L. T. Watson, Efficient identification of critical
stresses in structures subjected to dynamic loads, Computers and Structures , Vol. 22,
pp. 373–386, 1986.
14.12 W. H. Greene and R. T. Haftka, Computational aspects of sensitivity calculations in
transient structural analysis, Computers and Structures , Vol. 32, No. 2, pp. 433–443,
1989.
14.13 U. Kirsch, M. Reiss, and U. Shamir, Optimum design by partitioning into
substructures, ASCE Journal of the Structural Division , Vol. 98, No. ST1, pp. 249–267,
1972.
14.14 U. Kirsch, Multilevel approach to optimum structural design, ASCE Journal of the Struc-
tural Division , Vol. 101, No. ST4, pp. 957–974, 1975.
14.15 J. Sobieszczanski-Sobieski, B. James, and A. Dovi, Structural optimization by multilevel
decomposition, AIAA Journal , Vol. 23, No. 11, pp. 1775–1782, 1985.
14.16 J. Sobieszczanski-Sobieski, B. B. James, and M. F. Riley, Structural sizing by general-
ized, multilevel optimization, AIAA Journal , Vol. 25, No. 1, pp. 139–145, 1987.
14.17 M.E.M. El-Sayed and C.-K. Hsiung, Parallel structural optimization with parallel anal-
ysis interfaces, pp. 398–403 in Proceedings of the 3rd Air Force/NASA Symposium on
Recent Advances in Multidisciplinary Analysis and Optimization , San Francisco, Sept.
24–26, 1990.
14.18 E. S. Sikiotis and V. E. Saouma, Parallel structural optimization on a network of
computer workstations, Computers and Structures , Vol. 29, No. 1, pp. 141–150, 1988.
14.19 H. Adeli and O. Kamat, Concurrent optimization of large structures; Part I: Algo-
rithms, Part II: Applications, ASCE Journal of Aerospace Engineering , Vol. 5, No. 1,
pp. 79–110, 1992.
14.20 M.E.M. El-Sayed and C.-K. Hsiung, Optimum structural design with parallel finite ele-
ment analysis. Computers and Structures , Vol. 40, No. 6, pp. 1469–1474, 1991.
14.21 M. M. Atiqullah and S. S. Rao, Parallel processing in optimal structural design using
simulated annealing, AIAA Journal , Vol. 33, pp. 2386–2392, 1995.
14.22 L. A. Schmit, Jr., and H. Miura, Approximation Concepts for Efficient Structural Syn-
thesis , NASA CR-2552, 1976.
770 Practical Aspects of Optimization
14.23 L. A. Schmit and C. Fleury, Structural synthesis by combining approximation concepts
and dual methods, AIAA Journal , Vol. 18, pp. 1252–1260, 1980.
14.24 T. S. Pan, S. S. Rao, and V. B. Venkayya, Rates of change of closed-loop eigenvalues
and eigenvectors of actively controlled structures, International Journal for Numerical
Methods in Engineering , Vol. 30, No. 5, pp. 1013–1028, 1990.
14.25 G. N. Vanderplaats, Numerical Optimization Techniques for Engineering Design with
Applications , McGraw-Hill, New York, 1984.
14.26 J. Sobieszczanski-Sobieski, J. F. Barthelemy, and K. M. Riley, “Sensitivity of Optimum
Solutions to Problem Parameters,” AIAA Journal , Vol. 20, pp. 1291–1299, 1982.
14.27 U. Kirsch, Optimum Structural Design. Concepts, Methods, and Applications ,
McGraw-Hill, New York, 1981.
14.28 R. T. Haftka and Z. Gürdal, Elements of Structural Optimization , 3rd ed., Kluwer Aca-
demic, Dordrecht, The Netherlands, 1992.
14.29 E. E. Rosinger, Interactive algorithm for multiobjective optimization, Journal of Opti-
mization Theory and Applications , Vol. 35, pp. 339–365, 1981; Errata in Vol. 38, pp.
147–148, 1982.
14.30 T. L. Vincent and W. J. Grantham, Optimality in Parametric Systems , Wiley, New York,
1981.
14.31 W. Stadler, A survey of multicriteria optimization of the vector maximum problem,
Journal of Optimization Theory and Applications , Vol. 29, pp. 1–52, 1979.
14.32 D. Koo, Elements of Optimization , Springer-Verlag, New York, 1977.
14.33 J. P. Ignizio (Ed.), Linear Programming in Single- and Multiple-objective Systems ,
Prentice-Hall, Englewood Cliffs, NJ, 1982.
14.34 S. S. Rao, Game theory approach for multiobjective structural optimization, Computers
and Structures , Vol. 25, No. 1, pp. 119–127, 1987.
14.35 C. L. Hwang and A.S.M. Masud, Multiple Objective Decision Making: Methods and
Applications , Springer-Verlag, Berlin, 1979.
14.36 S. S. Rao, V. B. Venkayya, and N. S. Khot, Game theory approach for the
integrated design of structures and controls, AIAA Journal , Vol. 26, No. 4, pp. 463–469,
1988.
14.37 S. S. Rao and T. I. Freiheit, A modified game theory approach to multiobjective opti-
mization, ASME Journal of Mechanical Design , Vol. 113, pp. 286–291, 1991.
14.38 S. S. Rao and R. L. Kaplan, Optimal balancing of high-speed linkages using multi-
objective programming techniques, ASME Journal of Mechanisms, Transmissions, and
Automation in Design , Vol. 108, pp. 454–460, 1986.
14.39 S. S. Rao and H. R. Eslampour, Multistage multiobjective optimization of gearboxes,
ASME Journal of Mechanisms, Transmissions, and Automation in Design , Vol. 108, pp.
461–468, 1986.
14.40 S. K. Hati and S. S. Rao, Cooperative solution in the synthesis of multi-degree of freedom
shock isolation systems, ASME Journal of Vibration, Acoustics, Stress and Reliability in
Design , Vol. 105, pp. 101–103, 1983.
14.41 S. S. Rao and S. K. Hati, “Game theory approach in multicriteria optimization of function
generating mechanisms, ASME Journal of Mechanical Design , Vol: 101, pp. 398–406,
1979.
14.42 S. S. Rao, A. K. Dhingra, and H. Miura, Pareto-optimal solutions in helicopter design
problems, Engineering Optimization , Vol. 15, No. 3, pp. 211–231, 1990.
14.43 H. Eschenauer, J. Koski, and A. Osyczka, Multicriteria Design Optimization: Procedures
and Applications , Springer-Verlag, New York, 1990.
Review Questions 771
14.44 W. Stadler, Ed., Multicriteria Optimization in Engineering and in the Sciences , Plenum
Press, New York, 1988.
14.45 The Rand Corporation, A Million Random Digits with 100,000 Normal Deviates , The
Free Press, Glencoe, IL, 1955.
14.46 C. A. Coello Coello, D. A. Van Veldhuizen, and G. B. Lamont, Evolutionary Algorithms
for Solving Multi-objective Problems , Kluwer Academic/Plenum, New York, 2002.
REVIEW QUESTIONS
14.1 What is a reduced basis technique?
14.2 State two methods of reducing the size of an optimization problem.
14.3 What is design variable linking? Can it always be used?
14.4 Under what condition(s) is the convergence of the quantity 	iYi in the fast reanalysis
method ensured?
14.5 How do you compute the derivatives of the stiffness matrix with respect to a design
variable, ∂[K]/∂xi?
14.6 What is a MIMD computer?
14.7 Indicate various ways by which parallel computations can be performed in a large-scale
optimization problem.
14.8 How are the goals determined in the goal programming method?
14.9 Answer true or false:
(a) The computation of the derivatives of a particular λi requires other eigenvalues
besides λi .
(b) The derivatives of the ith eigenvector can be found without knowledge of the eigen-
vectors other than Yi .
(c) There is only one way to derive expressions for the sensitivity of optimal objective
function with respect to problem parameters.
(d) Multilevel optimization is same as decomposition.
(e) In multilevel optimization, the suboptimization problems are to be solved iteratively.
(f) All multiobjective optimization methods find only a Pareto optimum solution.
(g) All multiobjective optimization techniques convert the problem into a single objec-
tive problem.
(h) A vector optimization problem is same as a multiobjective optimization problem.
(i) Only one Pareto optimal solution exists for a multiobjective optimization problem.
(j) The weighting function method can be considered as the utility function method.
(k) It is possible to achieve the optimum value of each objective function simultaneously
in a multiobjective optimization problem.
14.10 Define the following terms:
(a) Pareto optimal point
(b) Utility function method
(c) Weighting function method
(d) Global criterion function method
772 Practical Aspects of Optimization
(e) Bounded objective function method
(f) Lexicographic method
PROBLEMS
14.1 Consider the minimum-volume design of the four-bar truss shown in Fig. 14.2 subject
to a constraint on the vertical displacement of node 4. Let X1 = {1, 1, 0.5, 0.5}T and
X2 = {0.5, 0.5, 1, 1}T be two design vectors, with xi denoting the area of cross section
of bar i(i = 1, 2, 3, 4). By expressing the optimum design vectors as X = c1X1 + c2X2,
determine the values of c1 and c2 through graphical optimization when the maximum
permissible vertical deflection of node 4 is restricted to a magnitude of 0.1 in.
14.2 Consider the configuration (shape) optimization of the 10-bar truss shown in Fig. 14.10.
The (X,Y ) coordinates of the nodes are to be varied while maintaining (a) symmetry
of the structure about the X axis, and (b) alignment of nodes 1, 2, and 3 (4, 5, and 6).
Identify the independent and dependent design variables and derive the relevant design
variable linking relationships.
14.3 For the four-bar truss considered in Example 14.1 (shown in Fig. 14.2), a base design
vector is given by X0 = {A1, A2, A3, A4}T = {2.0, 1.0, 2.0, 1.0}T in2. If X is given by
X = {0.4, 0.4,−0.4,−0.4}T in2, determine
(a) The exact displacement vector Y0 = {y5, y6, y7, y8}T at X0
(b) The exact displacement vector (Y0 + Y) at (X0 + X)
(c) The displacement vector (Y0 + Y) where Y is given by Eq. (14.20) with five
terms
14.4 Consider the 11-member truss shown in Fig. 5.1 with loads Q = −1000 lb, R = 1000 lb,
and S = 2000 lb. If Ai = xi denotes the area of cross section of member i, and
u1, u2, . . . , u10 indicate the displacement components of the nodes, the equilib-
rium equations can be expressed as shown in Eqs. (E1) to (E10) of Example 5.1.
Assuming that E = 30 × 106 psi, l = 50 in., xi = 1 in2(i = 1, 2, . . . , 11),xi = 0.1
in2(i = 1, 2, . . . , 5), and xi = −0.1 in2(i = 6, 7, . . . , 11), determine
4
4 5
6
X
Y
7
5
6
3
3
22
11
7
8 10
9
Figure 14.10 Design variable linking of a 10-bar truss.
Problems 773
(a) Exact displacement solution U0 at X0
(b) Exact displacement solution (U0 + U) at the perturbed design, (X0 + X)
(c) Approximate displacement solution, (U0 + U), at (X0 + X) using Eq. (14.20)
with four terms for U
14.5 Consider the four-bar truss shown in Fig. 14.2 whose stiffness matrix is given by
Eq. (E2) of Example 14.1. Determine the values of the derivatives of yi with respect
to the area A1, ∂yi/∂x1(i = 5, 6, 7, 8) at the reference design X0 = {A1 A2 A3 A4}T =
{2.0, 2.0, 1.0, 1.0}T in2.
14.6 Find the values of ∂yi/∂x2 (i = 5, 6, 7, 8) in Problem 14.5.
14.7 Find the values of ∂yi/∂x3 (i = 5, 6, 7, 8) in Problem 14.5.
14.8 Find the values of ∂yi/∂x4 (i = 5, 6, 7, 8) in Problem 14.5.
14.9 The equilibrium equations of the stepped bar shown in Fig. 14.11 are given by
[K]Y = P (1)
with
[K] =




A1E1
l1
+
A2E2
l2
−
A2E2
l2
−
A2E2
l2
A2E2
l2




(2)
Y =
{
Y1
Y2
}
, P =
{
P1
P2
}
(3)
If A1 = 2 in.2, A2 = 1 in.2, E1 = E2 = 30 × 106 psi, 2l1 = l2 = 50 in., P1 = 100 lb,
and P2 = 200 lb, determine
(a) Displacements, Y
(b) Values of ∂Y/∂A1 and ∂Y/∂A2 using the method of Section 14.4
(c) Values of ∂σ/∂A1 and ∂σ/∂A2, where σ = {σ1, σ2}T denotes the vector of stresses
in the bars and σ1 = E1Y1/l1 and σ2 = E2(Y2 − Y1)/ l2
Area, A1
Y1
l1 l2
Y2 P2
P1
Area, A2
Figure 14.11 Stepped bar.
774 Practical Aspects of Optimization
14.10 The eigenvalue problem for the stepped bar shown in Fig. 14.11 can be expressed as
[K]Y = λ[M]Y with the mass matrix, [M], given by
[M] =
[
(2ρ1A1l1 + ρ2A2l2) ρ2A2l2
ρ2A2l2 ρ2A2l2
]
where ρi, Ai , and li denote the mass density, area of cross section, and length of the seg-
ment i, and the stiffness matrix, [K], is given by Eq. (2) of Problem 14.9. If A1 = 2 in2,
A2 = 1 in2, E1 = E2 = 30 × 106 psi, 2l1 = l2 = 50 in., and ρ1g = ρ2g = 0.283 lb/in3,
determine
(a) Eigenvalues λi and the eigenvectors Yi, i = 1, 2
(b) Values of ∂λi/∂A1, i = 1, 2, using the method of Section 14.5
(c) Values of ∂Yi/∂Y1, i = 1, 2, using the method of Section 14.5
14.11 For the stepped bar considered in Problem 14.10, determine the following using the
method of Section 14.5.
(a) Values of ∂λi/∂A2, i = 1, 2
(b) Values of ∂Yi/∂A2, i = 1, 2
14.12 A cantilever beam with a hollow circular section with outside diameter d and wall
thickness t (Fig. 14.12) is modeled with one beam finite element. The resulting static
equilibrium equations can be expressed as
2EI
l3
[
6 −3l
−3l 2l2
]{
Y1
Y2
}
=
{
P1
P2
}
where I is the area moment of intertia of the cross section, E is Young’s modulus, and
l the length. Determine the displacements, Yi , and the sensitivities of the deflections,
∂Yi/∂d and ∂Yi/∂t (i = 1, 2), for the following data: E = 30 × 106 psi, l = 20 in., d = 2
in., t = 0.1 in., P1 = 100 lb, and P2 = 0.
14.13 The eigenvalues of the cantilever beam shown in Fig. 14.12 are governed by the equation
2EI
l3
[
6 −3l
−3l 2l2
]{
Y1
Y2
}
= λρAl
420
[
156 −22l
−22l 4l2
]{
Y1
Y2
}
0
A
A
Y2
P2
P1
Y1
x
l
y
t
Section A-A
d
Figure 14.12 Hollow circular cantilever beam.
Problems 775
Y1
Y2
k1
k2
k3
m1
m2
Figure 14.13 Two-degree-of-freedom spring–mass system.
where E is Young’s modulus, I the area moment of inertia, l the length, ρ the mass
density, A the cross-sectional area, λ the eigenvalue, and Y = {Y1, Y2}T = eigenvector. If
E = 30 × 106 psi, d = 2 in., t = 0.1 in., l = 20 in., and ρg = 0.283 lb/in3, determine
(a) Eigenvalues λi and eigenvectors Yi(i = 1, 2)
(b) Values of ∂λi/∂d and ∂λi/∂t (i = 1, 2)
14.14 In Problem 14.13, determine the derivatives of the eigenvectors ∂Yi/∂d and ∂Yi/∂t
(i = 1, 2).
14.15 The natural frequencies of the spring–mass system shown in Fig. 14.13 are given by
(for ki = k, i = 1, 2, 3 and mi = m, i = 1, 2)
λ1 =
k
m
= ω21, λ2 =
3k
m
= ω22
Y1 = c1
{
1
1
}
, Y2 = c2
{
1
−1
}
where ω1 and ω2 are the natural frequencies of vibration of the system and c1 and c2
are constants. The stiffness of each helical spring is given by
k =
d4G
8D3n
where d is the wire diameter, D the coil diameter, G the shear modulus, and n the
number of turns of the spring. Determine the values of ∂ωi/∂D and ∂Yi/∂D for the
following data: d = 0.04 in., G = 11.5 × 106 psi, D = 0.4 in., n = 10, and m = 32.2 lb
-s2/in. The stiffness and mass matrices of the system are given by
[K] = k
[
2 −1
−1 2
]
, [M] = m
[
1 0
0 1
]
14.16 Find the minimum volume design of the truss shown in Fig. 14.14 with constraints on
the depth of the truss (y), cross-sectional areas of the bars (A1 and A2), and the stresses
776 Practical Aspects of Optimization
Bar 1
(area = A1)
Bar 2
(area = A2)
P = 1000 N
1 m9 m
Figure 14.14 Two-bar truss.
induced in the bars (σ1 and σ2). Treat y, A1, and A2 as design variables with σi ≤ 105 Pa
(i = 1, 2), 1 m ≤ y ≤ 4 m, and 0 ≤ Ai ≤ 0.2 m2 (i = 1, 2). Use multilevel optimization
approach for the solution.
14.17 Find the sensitivities of x∗1 , x
∗
2 , and f
∗ with respect to Young’s modulus of the tubular
column considered in Example 1.1.
14.18 Consider the two-bar truss shown in Fig. 1.15. The problem of design of the truss for
minimum weight subject to stress constraints can be stated as follows:
Find x1, A1, and A2 which minimize
f = 28.30A1
√
1 + x2 + 14.15A2
√
1 + x2
subject to
g1 =
0.1768(1 + x)
√
1 + x2
A1x
− 1 ≤ 0
g2 =
∣
∣
∣
∣
∣
0.1768(x − 1)
√
1 + x2
A2x
∣
∣
∣
∣
∣
− 1 ≤ 0
0.1 ≤ x ≤ 2.5, 1.0 ≤ Ai ≤ 2.5 (i = 1, 2)
where the members are assumed to be made up of different materials. Solve this opti-
mization problem using the multilevel approach.
14.19 Consider the design of the two-bar truss shown in Fig. 14.15 with the location of nodes
1 and 2(x) and the area of cross section of bars (A) as design variables. If the weight
and the displacement of node 3 are to be minimized with constraints on the stresses
induced in the bars along with bounds on the design variables, the problem can be stated
as follows [14.34]:
Find X = {x1x2}T which minimizes
f1(X) = 2ρhx2
√
1 + x21
f2 =
Ph(1 + x21 )1.5
√
1 + x41
2
√
2Ex21x2
Problems 777
1 2
3
P 45°
X
Y
x x
h
Figure 14.15 Two-bar truss.
subject to
g1(X) =
P(1 + x1)
√
1 + x21
2
√
2x1x2
− σ0 ≤ 0
g2(X) =
P(x1 − 1)
√
1 + x21
2
√
2x1x2
− σ0 ≤ 0
xi ≥ x(l)i , i = 1, 2
where x1 = x/h, x2 = A/Aref, h the depth, E is Young’s modulus, ρ the weight density,
σ0 the permissible stress, and x
(l)
i the lower bound on xi . Find the optimum solutions of
the individual objective functions subject to the stated constraints using a graphical pro-
cedure. Data: P = 10,000 lb, ρ = 0.283 lb/in3, E = 30 × 106 psi, h = 100 in., Aref = 1
in.2, σ0 = 20,000 psi, x(l)1 = 0.1, and x
(l)
2 = 1.0.
14.20 Solve the two-objective optimization problem stated in Problem 14.19 using the weight-
ing method with equal weights to the two objective functions. Use a graphical method
of solution.
14.21 Solve the two-objective optimization problem stated in Problem 14.19 using the global
criterion method with p = 2. Use a graphical method of solution.
14.22 Formulate the two-objective optimization problem stated in Problem 14.19 as a goal
programming problem using the goals of 30 lb and 0.015 in. for the objectives f1 and
f2, respectively. Solve the problem using a graphical procedure.
14.23 Consider the following two-objective optimization problem:
Find X = {x1 x2 x3 x4 x5 x6}T
to minimize
778 Practical Aspects of Optimization
f1(X) = −25(x1 − 2)2 − (x2 − 2)2 − (x3 − 1)2 − (x4 − 4)2 − (x5 − 1)2
f2(X) = x21 + x22 + x23 + x24 + x25 + x26
subject to
− x1 − x2 + 2 ≤ 0; x1 + x2 − 6 ≤ 0; −x1 + x2 − 2 ≤ 0; x1 − 3x2 − 2 ≤ 0;
(x3 − 3)2 + x24 − 4 ≤ 0; −(x5 − 3)2 − x6 + 4 ≤ 0; 0 ≤ xi ≤ 10, i = 1, 2, 6
1 ≤ xi ≤ 5, i = 3, 5; 0 ≤ x4 ≤ 6
Find the minima of the individual objective functions under the stated constraints using
the MATLAB function fmincon.
14.24 Find the solution of the two-objective optimization problem stated in Problem 14.23
using the weighting function method with the weights w1 = w2 = 1. Use the MATLAB
function fmincon for the solution.
14.25 Find the solution of the two-objective optimization problem stated in Problem 14.23
using the global criterion method with p = 2. Use the MATLAB function fmincon for
the solution.
14.26 Find the solution of the two-objective optimization problem stated in Problem 14.23
using the bounded objective function method. Take the lower and upper bounds on f2
as 80 and 120% of the optimum value f ∗2 found in Problem 13.23. Use the MATLAB
function fmincon for the solution.
14.27 Find the solution of the two-objective optimization problem stated in Problem 14.23
using the goal attainment method. Use the MATLAB function fgoalattain for the
solution. Use suitable goals for the objectives.
14.28 Consider the following three-objective optimization problem:
Find X = {x1 x2}T to minimize
f1(X) = 1.5 − x1(1 − x2)
f2(X) = 2.25 − x1(1 − x22 )
f3(X) = 2.625 − x1(1 − x32 )
subject to
− x21 − (x2 − 0.5)2 + 9 ≤ 0
(x1 − 1)2 + (x2 − 0.5)2 − 6.25 ≤ 0
− 10 ≤ xi ≤ 10; i = 1, 2
Find the minima of the individual objectives under the stated constraints using the
MATLAB function fmincon.
14.29 Find the solution of the 3-objective problem stated in Problem 14.28 using the weight-
ing function method with the weights w1 = w2 = w3 = 1. Use the MATLAB function
fmincon for the solution.
14.30 Find the solution of the multiobjective problem stated in Problem 14.28 using the goal
attainment method. Use the MATLAB function fgoalattain for the solution. Use
suitable goals for the objectives.
A
Convex and Concave Functions
Convex Function. A function f (X) is said to be convex if for any pair of points
X1 =













x
(1)
1
x
(1)
2
...
x
(1)
n













and X2 =













x
(2)
1
x
(2)
2
...
x
(2)
n













and all λ, 0 ≤ λ ≤ 1,
f [λX2 + (1 − λ)X1] ≤ λf (X2) + (1 − λ)f (X1) (A.1)
that is, if the segment joining the two points lies entirely above or on the graph of
f (X). Figures A.1a and A.2a illustrate a convex function in one and two dimensions,
respectively. It can be seen that a convex function is always bending upward and
hence it is apparent that the local minimum of a convex function is also a global
minimum.
Concave Function. A function f (X) is called a concave function if for any two
points X1 and X2, and for all 0 ≤ λ ≤ 1,
f [λX2 + (1 − λ)X1] ≥ λf (X2) + (1 − λ)f (X1) (A.2)
that is, if the line segment joining the two points lies entirely below or on the graph
of f (X).
Figures A.1b and A.2b give a concave function in one and two dimensions, respec-
tively. It can be seen that a concave function bends downard and hence the local
maximum will also be its global maximum. It can be seen that the negative of a con-
vex function is a concave function, and vice versa. Also note that the sum of convex
functions is a convex function and the sum of the concave functions is a concave
function. A function f (X) is strictly convex or concave if the strict inequality holds
in Eqs. (A.1) or (A.2) for any X1 = X2. A linear function will be both convex and
concave since it satisfies both inequalities (A.1) and (A.2). A function may be con-
vex within a region and concave elsewhere. An example of such a function is shown
in Fig. A.3.
Testing for Convexity or Concavity. In addition to the definition given, the following
equivalent relations can be used to identify a convex function.
779Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
780 Convex and Concave Functions
Figure A.1 Functions of one variable: (a) convex function in one variable; (b) concave function
in one variable.
Figure A.2 Functions of two variables: (a) convex function in two variables; (b) concave
function in two variables.
Figure A.3 Function that is convex over certain region and concave over certain other region.
Convex and Concave Functions 781
Theorem A.1 A function f (X) is convex if for any two points X1 and X2, we have
f (X2) ≥ f (X1) + ∇f
T(X1)(X2 − X1)
Proof : If f (X) is convex, we have by definition
f [λX2 + (1 − λ)X1] ≤ λf (X2) + (1 − λ)f (X1)
that is,
f [X1 + λ(X2 − X1)] ≤ f (X1) + λ[f (X2) − f (X1)] (A.3)
This inequality can be rewritten as
f (X2) − f (X1) ≥
{
f [X1 + λ(X2 − X1)] − f (X1)
λ(X2 − X1)
}
(X2 − X1) (A.4)
By defining X = λ(X2 − X1), the inequality (A.4) can be written as
f (X2) − f (X1) ≥
f [X1 + X] − f (X1)
X
(X2 − X1) (A.5)
By taking the limit as X → 0, inequality (A.5) becomes
f (X2) − f (X1) ≥ ∇f
T (X1)(X2 − X1) (A.6)
which can be seen to be the desired result. If f (X) is concave, the opposite type of
inequality holds true in (A.6).
Theorem A.2 A function f (X) is convex if the Hessian matrix H(X) = [∂2f (X)/
∂xi ∂xj ] is positive semidefinite.
Proof : From Taylor’s theorem we have
f (X∗ + h) = f (X∗) +
n
∑
i=1
hi
∂f
∂xi
(X∗)
+
1
2!
n
∑
i=1
n
∑
j=1
hihj
∂2f
∂xi ∂xj
∣
∣
∣
∣
X=X∗+θh
(A.7)
where 0 < θ < 1. By letting X∗ = X1, X
∗ + h = X2 and h = X2 − X1, Eq. (A.7) can
be rewritten as
f (X2) = f (X1) + ∇f
T(X1)(X2 − X1) +
1
2
(X2 − X1)
T
×H{X1 + θ(X2 − X1)}(X2 − X1) (A.8)
It can be seen that inequality (A.6) is satisfied [and hence f (X) will be convex] if H(X)
is positive semidefinite. Further, if H(X) is positive definite, the function f (X) will be
strictly convex. It can also be proved that if f (X) is concave, the Hessian matrix is
negative semidefinite.
782 Convex and Concave Functions
The following theorem establishes a very important relation, namely, that any local
minimum is a global minimum for a convex function.
Theorem A.3 Any local minimum of a convex function f (X) is a global minimum.
Proof : Let us prove this theorem by contradiction. Suppose that there exist two different
local minima, say, X1 and X2, for the function f (X). Let f (X2) < f (X1). Since f (X)
is convex, X1 and X2 have to satisfy the relation (A.6), that is,
f (X2) − f (X1) ≥ ∇f
T(X1)(X2 − X1) (A.6)
or
∇f T (X1)S ≤ 0 (A.9)
where S = (X2 − X1) is a vector joining the points X1 to X2. Equation (A.9) indicates
that the value of the function f (X) can be decreased further by moving in the direction
S = (X2 − X1) from point X1. This conclusion contradicts the original assumption that
X1 is a local minimum. Thus there cannot exist more than one minimum for a convex
function.
Example A.1 Determine whether the following functions are convex or concave.
(a) f (x) = ex
(b) f (x) = −8x2
(c) f (x1, x2) = 3x
3
1 − 6x
2
2
(d) f (x1, x1, x3) = 4x
2
1 + 3x
2
2 + 5x
2
3 + 6x1x2 + x1x3 − 3x1 − 2x2 + 15
SOLUTION
(a) f (x) = ex: H(x) = d2f/dx2 = ex > 0 for all real values of x. Hence f (x) is
strictly convex.
(b) f (x) = −8x2: H(x) = d2f/dx 2 = −16 < 0 for all real values of x. Hence
f (x) is strictly concave.
(c) f = 2x31 − 6x
2
2 :
H(X) =
[
∂2f/∂x21 ∂
2f/∂x1 ∂x2
∂2f/∂x1 ∂x2 ∂
2f/∂x22
]
=
[
12x1 0
0 −12
]
Here ∂2f/∂x21 = 12x1 ≤ 0 for x1 ≤ 0 and ≥ 0 for x1 ≥ 0, and
∣
∣H(X)
∣
∣ = −144x1 ≥ 0 for x1 ≤ 0 and ≤ 0 for x1 ≥ 0
Hence H(X) will be negative semidefinite and f (X) is concave for x1 ≤ 0.
Convex and Concave Functions 783
(d) f = 4x21 + 3x
2
2 + 5x
2
3 + 6x1x2 + x1x3 − 3x1 − 2x2 + 15:
H(X) =




∂2f/∂x21 ∂
2f/∂x1 ∂x2 ∂
2f/∂x1 ∂x3
∂2f/∂x1 ∂x2 ∂
2f/∂x22 ∂
2f/∂x2 ∂x3
∂2f/∂x1∂x3 ∂
2f/∂x2 ∂x3 ∂
2f/∂x23




=


8 6 1
6 6 0
1 0 10


Here the principal minors are given by
|8| = 8 > 0
∣
∣
∣
∣
8 6
6 6
∣
∣
∣
∣
= 12 > 0
∣
∣
∣
∣
∣
∣
8 6 1
6 6 0
1 0 10
∣
∣
∣
∣
∣
∣
= 114 > 0
and hence the matrix H(X) is positive definite for all real values of x1, x2, and
x3. Therefore, f (X) is a strictly convex function.
B
Some Computational Aspects
of Optimization
Several methods were presented for solving different types of optimization problems
in Chapters 3 to 14. This appendix is intended to give some guidance to the reader in
choosing a suitable method for solving a particular problem along with some computa-
tional details. Most of the discussion is aimed at the solution of nonlinear programming
problems.
B.1 CHOICE OF METHOD
Several factors are to be considered in deciding a particular method to solve a given
optimization problem. Some of them are
1. The type of problem to be solved (general nonlinear programming problem,
geometric programming problem, etc.)
2. The availability of a ready-made computer program
3. The calender time required for the development of a program
4. The necessity of derivatives of the functions f and g j , j = 1, 2, . . . , m
5. The available knowledge about the efficiency of the method
6. The accuracy of the solution desired
7. The programming language and quality of coding desired
8. The robustness and dependability of the method in finding the true optimum
solution
9. The generality of the program for solving other problems
10. The ease with which the program can be used and its output interpreted
B.2 COMPARISON OF UNCONSTRAINED METHODS
A number of studies have been made to evaluate the various unconstrained minimization
methods. Moré, Garbow, and Hillstrom [B.1] provided a collection of 35 test functions
for testing the reliability and robustness of unconstrained minimization software. The
performance of eight unconstrained minimization methods was evaluated by Box [B.2]
using a set of test problems with up to 20 variables. Straeter and Hogge [B.3] compared
four gradient-based unconstrained optimization techniques using two test problems.
784 Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
B.3 Comparison of Constrained Methods 785
A comparison of several variable metric algorithms was made by Shanno and Phua
[B.4]. Sargent and Sebastian presented numerical experiences with unconstrained min-
imization algorithms [B.5]. On the basis of these studies, the following general con-
clusions can be drawn.
If the first and second derivatives of the objective function ( f ) can be evaluated
easily (either in closed form or by a finite-difference scheme), and if the number of
design variables is not large (n ≤ 50), Newton’s method can be used effectively. For
n greater than about 50, the storage and inversion of the Hessian matrix at each stage
becomes quite tedious and the variable metric methods might prove to be more useful.
As the problem size increases (beyond n = 100 or so), the conjugate gradient method
becomes more powerful.
In many practical problems, the first derivatives of f can be computed more accu-
rately than the second derivatives. In such cases, the BFGS and DFP methods become
an obvious choice of minimization. Of these two, the BFGS method is more stable
and efficient. If the evaluation of the derivatives of f is extremely difficult or if the
function does not possess continuous derivatives, Powell’s method can be used to solve
the problem efficiently.
With regard to the one-dimensional minimization required in all the unconstrained
methods, the Newton and cubic interpolation methods are most efficient when the
derivatives of f are available. Otherwise, the Fibonacci or the golden section method
has to be used.
B.3 COMPARISON OF CONSTRAINED METHODS
The comparative evaluation of nonlinear programming techniques was conducted by
several investigators. Colville [B.6] compared the efficiencies of 30 codes using eight
test problems that involve 3 to 16 design variables and 0 to 14 constraints. However,
the codes were tested at different sites on different computers and hence the study was
not considered reliable. Eason and Fenton [B.7] conducted a comparative study of 20
codes using 13 problems that also included the problems used by Colville. However,
their study was confined primarily to penalty function-type methods. Sandgren and
Ragsdell [B.8] studied the relative efficiencies of the leading nonlinear programming
methods of the day more systematically. They studied 24 codes using 35 problems,
including some of those used by Colville and Eason and Fenton.
The number of design variables varied from 2 to 48 and the number of constraints
ranged from 0 to 19; some problems involved equality constraints, too. They found
the GRG method to be most robust and efficient followed by the exterior and interior
penalty function methods.
Schittkowski published the results of his study of nonlinear programming codes in
1980 [B.9]. He experimented with 20 codes on 180 randomly generated test problems
using multiple starting points. Based on his study, the sequential quadratic program-
ming was found to be most efficient, followed by the GRG, method of multipliers,
and penalty function methods, in that order. Similar comparative studies of geomet-
ric programming codes were also conducted [B.10–B.12]. Although the studies above
were quite extensive, the conclusion may not be of much use in practice since the
studies were limited to relatively few methods and further they are limited to specially
786 Some Computational Aspects of Optimization
formulated test problems that are not related to real-life problems. Thus each new prac-
tical problem has to be tackled almost independently based on past experience. The
following guidelines are applicable for a general problem.
The sequential quadratic programming approach can be used for solving a variety of
problems efficiently. The GRG method and Zoutendijk’s method of feasible directions,
although slightly less efficient, can also be used for the efficient solution of constrained
problems. The ALM and penalty function methods are less efficient but are robust and
reliable in finding the solution of constrained problems.
B.4 AVAILABILITY OF COMPUTER PROGRAMS
Many computer programs are available to solve nonlinear programming problems.
Notable among these is the book by Kuester and Mize [B.13], which gives Fortran
programs for solving linear, quadratic, geometric, dynamic, and nonlinear programming
problems. During practical computations, it is important to note that a method that
works well for a given class of problems may work poorly for others. Hence it is
usually necessary to try more than one method to solve a particular problem efficiently.
Further, the efficiency of any nonlinear programming method depends largely on the
values of adjustable parameters such as starting point, step length, and convergence
requirements. Hence a proper set of values to these adjustable parameters can be given
only by using a trial-and-error procedure or through experience gained in working with
the method for similar problems. It is also desirable to run the program with different
starting points to avoid local and false optima. It is advisable to test the two convergence
criteria stated in Section 7.21 before accepting a point as a local minimum.
Moré and Wright present information on the current state of numerical optimization
software in [B.16]. Several software systems such as IMSL, MATLAB, and ACM
contain programs to solve optimization problems. The relevant addresses are
IMSL
7500 Bellaire Boulevard
Houston, TX 77036
MATLAB
The MathWorks, Inc.
24 Prime Park Way
Natick, MA 01760
ACM Distribution Service
c/o International Mathematics and Statistics Service
7500 Bellaire Boulevard
Houston, TX 77036
In addition, the commercial structural optimization packages listed in Table B.1
are available in the market [B.14, B.15]. Most of these softwares are based on a
finite-element-based analysis for objective and constraint function evaluations and use
several types of approximation strategies.
B.5 Scaling of Design Variables and Constraints 787
Table B.1 Summary of Some Structural Optimization Packages
Software system Source Capabilities and
(program) (developer) characteristics
ASTROS (Automated
STRuctural
Optimization System)
Air Force Wright Laboratories
FIBRA
Wright-Patterson Air Force
Base, OH 45433-6553
Structural optimization with
static, eigenvalue, modal
analysis, and flutter
constraints;
approximation concepts;
compatibility with
NASTRAN; sensitivity
analysis
ANSYS Swanson Analysis Systems,
Inc.
P.O. Box 65
Johnson Road
Houston, PA 15342-0065
Optimum design based on
curve-fitting technique to
approximate the response
using several trial design
vectors
MSC/NASTRAN
MacNeal Schwendler
Corporation/NAsa
STRuctural ANalysis)
MacNeal-Schwendler Corpo-
ration
15 Colorado Boulevard
Los Angeles, CA 90041
Structural optimization
capability based on static,
natural frequency, and
buckling analysis;
approximation concepts
and sensitivity analysis
NISAOPT Engineering Mechanics
Research Corporation
P.O. Box 696
Troy, MI 48099
Minimum-weight design
subject to displacement,
stress, natural frequency
and buckling constraints;
shape optimization
GENESIS VMA Exngineering Inc.
Manderin Avenue, Suite F
Goleta, CA 93117
Structural optimization;
approximation concepts
used to tightly couple the
analysis and redesign
tasks
B.5 SCALING OF DESIGN VARIABLES AND CONSTRAINTS
In some problems there may be an enormous difference in scale between variables
due to difference in dimensions. For example, if the speed of the engine (n) and the
cylinder wall thickness (t) are taken as design variables in the design of an IC engine,
n will be of the order of 103 (revolutions per minute) and t will be of the order of
1 (cm). These differences in scale of the variables may cause some difficulties while
selecting increments for step lengths or calculating numerical derivatives. Sometimes
the objective function contours will be distorted due to these scale disparities. Hence it
is a good practice to scale the variables so that all the variables will be dimensionless
and vary between 0 and 1 approximately. For scaling the variables, it is necessary to
establish an approximate range for each variable. For this we can take some estimates
(based on judgment and experience) for the lower and upper limits on xi(x
min
i and
788 Some Computational Aspects of Optimization
xmaxi ), i = 1, 2, . . . , n. The values of these bounds are not critical and there will not
be any harm even if they span partially the infeasible domain. Another aspect of
scaling is encountered with constraint functions. This becomes necessary whenever the
values of the constraint functions differ by large magnitudes. This aspect of scaling
(normalization) of constraints was discussed in Section 7.13.
B.6 COMPUTER PROGRAMS FOR MODERN METHODS
OF OPTIMIZATION
Fuzzy Logic Toolbox. Matlab has a fuzzy logic toolbox for designing systems based
on fuggy logic. Graphical user interfaces (GUI) are available to guide the user through
the steps of fuzzy interface system design. The toolbox can be used to model complex
system behaviors using simple logic rules and then implement the rules in a fuzzy
interface system. Fuzzy optimization can be implemented using fuzzy logic toolbox in
conjunction with an optimization program such as fmincon.
Genetic Algorithm and Direct Search Toolbox. The genetic algorithm and direct
search toolbox, which can be used to solve problems that are difficult to solve with
traditional optimization techniques, is available with Matlab. The genetic algorithm of
the toolbox can be used when the function, such as the objective or constraint function,
is discontinuous, highly nonlinear, stochastic, or has unreliable or undefined derivatives.
In this toolbox also, graphical user interfaces (GUI) are available for quick setting up of
problems, selecting algorithmic options, and monitoring progress. Naturally, the options
of creating initial population, fitness scaling, parent selection, crossover and mutation
are available in the toolbox. The Matlab optimization programs (using direct search
methods) can be integrated with the genetic algorithm.
Neural Network Toolbox. The neural network toolbox is available with Matlab for
designing, implementing, visualizing and simulating neural networks. The GUI avail-
able with the toolbox helps in creating, training and simulating neural networks. It
permits modular network representation to have any number of input-setting layers and
network interconnection and a graphical view of the network architecture. Optimization
programs can be used in conjunction with the functions of the neural network toolbox
to accomplish neural network-based optimization. The neural network toolbox can also
be used to apply neural networks for the identification and control of nonlinear systems.
Simulated Annealing Algorithm. An m-file to implement the simulated annealing
algorithm to solve function minimization problems in the Matlab environment was
created by Joachim Vandekerckhove. The link is given below:
http://www.mathworks.com/matlabcentral/fileexchange/10548
Particle Swarm Optimization. An m-file to implement the particle swarm optimiza-
tion method in the Matlab environment was created by Wael Korani. The link is given
below:
http://www.mathworks.com/matlabcentral/fileexchange/20205
References and Bibliography 789
Ant Colony Optimization. An m-file to implement the ant colony optimization
method in the Matlab environment for the solution of symmetrical and unsymmetrical
traveling salesman problem was created by H. Wang. The link is given below:
http://www.mathworks.com/matlabcentral/fileexchange/14543
Multiobjective Optimization. An m-file to implement multiobjective optimization
using evolutionary algorithms (based on nondominated sorting genetic algorithm, abbre-
viated NSGA) in the Matlab environment was created by Arvind Seshadri. The link is
given below:
http://www.mathworks.com/matlabcentral/fileexchange/10429
REFERENCES AND BIBLIOGRAPHY
B.1 J. J. Moré, B. S. Garbow, and K. E. Hillstrom, Testing unconstrained optimization soft-
ware, ACM Transactions on Mathematical Software, Vol. 7, No. 1, pp. 17–41, 1981.
B.2 M. J. Box, A comparison of several current optimization methods, and the use of trans-
formations in constrained problems, Computer Journal , Vol. 9, No. 1, pp. 67–77, 1966.
B.3 T. A. Straeter and J. E. Hogge, A comparison of gradient dependent techniques for the
minimization of an unconstrained function of several variables, AIAA Journal , Vol. 8,
No. 12, pp. 2226–2229, 1970.
B.4 D. F. Shanno and K. H. Phua, Numerical comparison of several variable-metric algo-
rithms, Journal of Optimization Theory and Applications , Vol. 25, No. 4, pp. 507–518,
1978.
B.5 R.W.H. Sargent and D. J. Sebastian, Numerical exprience with algorithms for uncon-
strained minimization, pp. 45–113 in Numerical Methods for Nonlinear Optimization , F.
A. Lootsma, Ed., Academic Press, London, 1972.
B.6 A. R. Colville, A Comparative Study of Nonlinear Programming Codes , Technical Report
320–2949, IBM New York Scientific Center, June 1968.
B.7 E. D. Eason and R. G. Fenton, A comparison of numerical optimization methods for engi-
neering design, ASME Journal of Engineering for Industry , Vol. 96, No. 1, pp. 196–200,
1974.
B.8 E. Sandgren and K. M. Ragsdell, The utility of nonlinear programming algorithms: A
comparative study, Parts I and II, ASME Journal of Mechanical Design , Vol. 102, No. 3,
pp. 540–551, 1980.
B.9 K. Schittkowski, Nonlinear Programming Codes: Information, Tests, Performance, Lec-
ture Notes in Economics and Mathematical Systems, Vol. 183, Springer-Verlag, New
York, 1980.
B.10 P.V.L.N. Sarma, X. M. Martens, G. V. Reklaitis, and M. J. Rijckaert, A comparison
of computational strategies for geometric programs, Journal of Optimization Theory and
Applications , Vol. 26, No. 2, pp. 185–203, 1978.
B.11 J. E. Fattler, Y. T. Sin, R. R. Root, K. M. Ragsdell, and G. V. Reklaitis, On the com-
putational utility of posynomial geometric programming solution methods, Mathematical
Programming , Vol. 22, pp. 163–201, 1982.
B.12 R. S. Dembo, The current state-of-the-art of algorithms and computer software for geo-
metric programming, Journal of Optimization Theory and Applications , Vol. 26, p. 149,
1978.
790 Some Computational Aspects of Optimization
B.13 J. L. Kuester and J. H. Mize, Optimization Techniques with Fortran , McGraw-Hill, New
York, 1973.
B.14 E. H. Johnson, Tools for structural optimization, Chapter 29, pp. 851–863, in Structural
Optimization: Status and Promise, M. P. Kamat, Ed., AIAA, Washington, DC, 1993.
B.15 H.R.E.M. Hörnlein and K. Schittkowski, Software Systems for Structural Optimization ,
Birkhauser, Basel, 1993.
B.16 J. J. Moré and S. J. Wright, Optimization Software Guide, Society of Industrial and
Applied Mathematics, Philadelphia, PA, 1993.
C
Introduction to MATLAB

MATLAB, derived from MATrix LABoratory, is a software package that was originally
developed in the late 1970s for the solution of scientific and engineering problems. The
software can be used to execute a single statement or a list of statements, called a script
or m-file. MATLAB family includes the Optimization Toolbox, which is a library of
programs or m-files to solve different types of optimization problems. Some basic
features of MATLAB are summarized in this appendix.
C.1 FEATURES AND SPECIAL CHARACTERS
Some of the important features and special characters used in MATLAB are indicated
below:
1. Symbol ≫ This is the default prompt symbol in MATLAB
2. Symbol ; A semicolon at the end of a line avoids the echoing the
information entered before the semicolon
3. Symbol . . . Three periods at the end of a line indicates the continuation of
the code in the next line
4. help command name This displays information on different ways the command can
be used
5. Symbol % Any text after this symbol is considered a comment and will
not be operational
6. MATLAB is case sensitive. Uppercase and lowercase letters are treated separately.
7. MATLAB assumes all variables to be arrays. As such, separate dimension statements are
not needed. Scalar quantities need not be given as arrays.
8. Names of variables: variable names should start with a letter and can have a length
of up to 31 characters in any combination of letters, digits, and
underscores.
9. The symbols for the basic arithmetic operations of addition, subtraction, multiplication,
division, and exponentiation are +, −, ∗, /, and ∧, respectively.
10. MATLAB has some built-in variable names and, as such, we should avoid using those
names for variables in writing a MATLAB program or m-file. Examples of built-in names:
pi (for π), sin (for sine of an angle), etc.
791Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
792 Introduction to MATLAB

C.2 DEFINING MATRICES IN MATLAB
Before performing arithmetic operations or using them in developing MATLAB pro-
grams or m-files, the relevant matrices need to be defined using statements such as the
following.
1. A row vector or 1 × n matrix, denoted A, can be defined by enclosing its
elements in brackets and separated by either spaces or commas.
Example: A = [1 2 3]
2. A column vector or n × 1 matrix, denoted A, can be defined by entering its
elements in different lines or in a single line using a semicolon to separate them
or in a single line using a row vector with a prime on the right-side bracket (to
denote the transpose).
Example: [1
A = 2 , A = [1; 2; 3], or A = [1 2 3]′.
3]
3. A matrix of size m × n, denoted A, can be defined as follows (similar to the
procedure used for a column vector).
Example: [1 2 3
A = 4 5 6 , or A = [1 2 3; 4 5 6; 7 8 9].
7 8 9]
4. Definitions of some special matrices:
A = eye (3)
implies an identity matrix of order 3: A =


1 0 0
0 1 0
0 0 1

 .
A = ones (3)
implies a square matrix of order 3 with all elements equal to one: A =


1 1 1
1 1 1
1 1 1

 .
A = zeros (2, 3)
implies a 2 × 3matrix with all elements equal to zero: A =
[
0 0 0
0 0 0
]
.
5. Some uses of the colon operator (:):
(i) To generate all numbers between 100 and 50 in increments of −7
>> 100 : −7 : 50
This command generates the numbers 100 93 86 79 65 58 51
C.4 Optimization Toolbox 793
(ii) To generate all numbers between 0 and π in increments of π/6
>> 0 : pi/6 : pi
This command generates the numbers
0 0.5236 1.0472 1.5708 2.0944 2.6180 3.1416
C.3 CREATING m-FILES
MATLAB can be used in an interactive mode by typing each command from the
keyboard. In this mode, MATLAB performs the operations much like an extended cal-
culator. However, there are situations in which this mode of operation is inefficient.
For example, if the same set of commands is to be repeated a number of times with dif-
ferent values of the input parameters, developing a MATLAB program will be quicker
and efficient.
A MATLAB program consists of a sequence of MATLAB instructions written
outside MATLAB and then executed in MATLAB as a single block of commands.
Such a program is called a script file, or m-file. It is necessary to give a name to the
script file. The name should end with .m (a dot followed by the letter m). A typical
m-file (called fibo.m) is
file “fibo.m“
% m-file to compute Fibonacci numbers
f=[1 1];
i=1;
while f(i)+f(i+1)<1000
f(i+2)=f(i)+f(i+1);
i=i+1;
end
C.4 OPTIMIZATION TOOLBOX
The Optimization Toolbox includes programs or m-files that can be used to solve
different types of optimization problems. The following publication gives information
on the optimization toolbox, including algorithms and examples for different programs:
T. F. Coleman, M. A. Branch, and A. Grace, Optimization Toolbox—for Use with
MATLAB, User’s Guide, Version 2, Math Works, Inc., Natick, MA, 1999.
The use of any program or m-file in the optimization toolbox requires the following:
• Selecting the appropriate program or m-file to solve the specific problem at hand.
• Formulation of the optimization problem in the format expected by MATLAB. In
general, this involves stating the objective function in a specific form such as a
“minimization” type and the constraints in a specific form such as “less than or
equal to zero” type.
794 Introduction to MATLAB

• Distinction between linear and nonlinear constraints.
• Identification of lower and upper bounds on design variables.
• Setting/changing the parameters of the optimization algorithm (based on the avail-
able options).
Using MATLAB Programs. Each program or m-file in MATLAB can be imple-
mented in several ways. The details can be found either in the reference given above
or online using the help command. For illustration, the help command and the response
for the program fmincon are shown below.
The function fmincon can be used in 12 different ways as indicated below (by
the help command). The differences depend on the available data in the mathematical
model of the problem and the information required from the solution of the problem.
In using the different function calls, any data missing in the mathematical model of
the optimization problem need to be indicated using a null vector as [ ]. Note that the
response is edited for brevity.
>> help fmincon
FMINCON Finds the constrained minimum of a function of
several variables.
FMINCON solves problems of the form:
min F(X) subject to:
A*X <= B, Aeq*X = Beq (linear constraints)
C(X) <= 0, Ceq(X) = 0 (nonlinear constraints)
LB <= X <= UB
X=FMINCON (FUN,X0,A,B)
X=FMINCON (FUN,X0,A,B,Aeq,Beq)
X=FMINCON (FUN,X0,A,B,Aeq,Beq,LB,UB)
X=FMINCON (FUN,X0,A,B,Aeq,Beq,LB,UB,NONLCON)
X=FMINCON (FUN,X0,A,B,Aeq,Beq,LB,UB,NONLCON,OPTIONS)
X=FMINCON (FUN,X0,A,B,Aeq,Beq,LB,UB,NONLCON,OPTIONS,...
P1,P2,...)
[X,FVAL] = FMINCON (FUN,X0,...)
[X,FVAL,EXITFLAG] = FMINCON (FUN,X0,...)
[X,FVAL,EXITFLAG,OUTPUT]=FMINCON (FUN,X0,...)
[X,FVAL,EXITFLAG,OUTPUT,LAMBDA] =FMINCON (FUN,X0,...)
[X,FVAL,EXITFLAG,OUTPUT,LAMBDA,GRAD]=FMINCON (FUN,X0,...)
[X,FVAL,EXITFLAG,OUTPUT,LAMBDA,GRAD,HESSIAN]=FMINCON
(FUN,X0,...).
The solution of representative constrained nonlinear programming problems using the
function fmincon is illustrated in Chapters 1 and 7.
Answers to Selected Problems
CHAPTER 1
1.1 Min. f = 5xA − 80xB + 160xC + 15xD, 0.05xA + 0.05xB + 0.1xC +
0.15xD ≤ 1000, 0.1xA + 0.15xB + 0.2xC + 0.05xD ≤ 2000, 0.05xA + 0.1xB +
0.1xC + 0.15xD ≤ 1500, xA ≥ 5000, xB ≥ 0, xC ≥ 0, xD ≥ 4000
1.2(a) X∗ = {0.65, 0.53521} (b) X∗ = {0.9, 2.5}
(c) X∗ = {0.65, 0.53521} 1.5 x∗1 = x∗2 = 300
1.9(a) R∗1 = 4.472, R∗2 = 2.236 (b) R∗1 = 3.536, R∗2 = 3.536
(c) R∗1 = 6.67, R∗2 = 3.33
1.11(a) y1 = ln x1, y2 = ln x2, ln f = 2y1 + 3y2
(b) f = 10y2x2 , x1 = 10y2, ln (log10 f ) = ln (log10 x1) + ln x2
1.14 xij = 1 if city j is visited immediately after city i, and = 0 otherwise.
Find {xij} to minimize f =
n
∑
i=1
n
∑
j=1
dijxij subject to
n
∑
i=1
xij = 1 (i = 1, 2, . . . , n),
i = j and
n
∑
j=1
xij = 1 (i = 1, 2, . . . , n), j = i
1.19 Min. f = ρlbd,
Py
bd
+ 6Px l
bd2
≤ σy,
Py
bd
+ 6Px l
bd2
≤ π
2Ed2
48l2
, b ≥ 0.5, b ≤ 2d .
1.25 Max. f = 2
3
tm + 35 td , tm + td ≤ 40, td ≥ 1.25tm, 0 ≤ tm ≤ 24, 0 ≤ td ≤ 20.
1.29 Min. f = πx3[x21 − (x1 − x2)2] +
4
3
π[x31 − (x1 − x4)3], πx3(x1 − x2)2 +
4
3
π(x1 − x4)3 − 4,619,606 ≤ 0, x2 −
pR0
S.e + 0.4p
≤ 0, x4 −
pR0
S.e + 0.8p
≤ 0
CHAPTER 2
2.1 r∗ = R 2.3 x∗ = 1.5 (inflection point)
2.5 x = −1 (not min, not max), x = 2 (min) 2.9 d =
(
D5
8f l
)1/4
2.10 35.36 m 2.11(a) 79.28
◦
(b) 0.911 from end of stroke
795Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
796 Answers to Selected Problems
2.13 positive semidefinite 2.15 positive definite
2.17 negative definite 2.19 indefinite
2.21 x∗1 = 0.2507 m, x∗2 = 5.0879 × 10−3 m
2.23 a = 328, b = −376 2.26 x∗ = 27, y∗ = 21
2.27 x∗ = 100 2.28(a) minimum (b) minimum
(c) saddle point (d) none 2.30 saddle point at (0, 0)
2.33 dx1 = arbitrary, dx2 = 0 2.36 radius = 2r/3, length = h/3
2.38 length = (a2/3 + b2/3)3/2 2.40 h∗ =
(
4V
π
)1/3
, r∗ = h∗
2
2.41 x∗1 = x∗3 = (S/3)1/2, x∗2 = (S/12)1/2
2.43 d∗ = 1
6
{(a + b) −
√
a2 − ab + b2} 2.47 200 mm × 250 mm
2.50 X∗ = {4, 2, 2} 2.53 198.43 ft × 113.39 ft
2.55(a) f ∗new = 15π (b) f ∗new = 18π 2.57(a) f ∗ = 1/3
(b) f ∗ = −1/9 2.61 X2 is local minimum
2.63(a) Kuhn–Tucker conditions satisfied
(b) λ1 = 0.4, λ2 = 0.2, λ3 = 0 2.65(a) S = {1, −3} (b) none
2.67 optimum 2.69 x∗1 =
3
4
, x∗2 = 4
9
16
2.73 convex 2.75 none optimum
CHAPTER 3
3.3 x1 = 1, x2 = 2, x3 = 3 3.5 x1 = 2, x2 = 4, x3 = 6
3.7 x∗1 = 1/3, x∗2 = 4/3 3.9 x∗1 = 2
2
5
, x∗2 = 1
1
5
3.12 x∗ = 3 3
11
, y∗ = 3 2
11
3.15 x∗ = 5 1
13
, y∗ = 1 1
13
3.17 all points on line joining (2, 10) and (7.4286, 15.4286)
3.18 x∗ = 10, y∗ = 18 3.20 x∗ = 9/7, y∗ = 40/7
3.23 x∗ = 6, y∗ = 1 3.25 x∗ = 6, y∗ = 0
3.27 x∗ = 75/8, y∗ = 27/8 3.29 x∗ = 3, y∗ = −2.5
3.31 x∗ = 4, y∗ = 0 3.33 unbounded 3.35 x∗ = 4/7, y∗ = 30/7
3.37 x∗ = 36/7, y∗ = 15/7 3.39 x∗ = 16/5, y∗ = 1/5
3.41 infeasible 3.43 unbounded
3.48 x∗1 = 3000.0, x∗2 = 416.7, x∗3 = 1200.0
3.50 x∗1 (barley) = 40, x∗2 = x∗3 = x∗4 = 0, x∗5 (leased) = 160
Answers to Selected Problems 797
3.55 x∗A = 1.5, x∗B = 0 3.57 x∗m = 16, x∗d = 20
3.60 x∗ = 36/11, y∗ = 35/11
3.66 all points on the line joining (7.4286, 15.4286) and (10, 18)
3.71 x∗ = 3.6207, y∗ = 8.4483 3.75 x∗ = 2/7, y∗ = 30/7
3.79 x∗ = 56/23, y∗ = 45/23 3.85 x∗ = −4/3, y∗ = 7
3.89 x∗ = 0, y∗ = 3
3.92 (x1, x2) = amounts of mixed nuts (A, B ) used, lb. x∗1 = 80/7, x∗2 = 120/7
3.94 x∗A = 62.5, x∗B = 31.25
3.96 xi = number of units of Pi produced per week. x∗1 = 100/3, x∗2 = 250/3
3.99 (x1, x2) = number of units of (A, B) sold per month. x∗1 = 19.17, x∗2 = 45
3.102 xi = number of days used in a month for process type i (i = 1, 2, 3, 4).
x∗1 = 30, x∗2 = x∗3 = x∗4 = 0
CHAPTER 4
4.1 X∗ = {2.333, 1.333, 0, 0}
4.3 x∗i = 0, i = 1, 2, 3, x∗4 = 2/5, x∗5 = 4/5 4.5 solution unbounded
4.9 x∗i = 0, i = 1, 2, 5, 6, 7, x∗3 = 0.5, x∗4 = 1.5
4.12 x∗1 = 2.35, x∗2 = 0.1, x∗3 = 2.7, x∗4 = 1.2
4.15 x∗1 = x∗2 = x∗3 = x∗6 = 0, x∗4 = 120, x∗5 = 100
4.17 optimum solution remains same, f ∗new = −27,600/3
4.19 (x1, x2, x3, x4) = number of units of products (A, B, C, D) produced.
x∗1 = 4000/3, x∗2 = x∗3 = 0, x∗4 = 200/3
4.23 x∗1 = 1000/3, x∗2 = x∗3 = 0, x∗4 = 800/3
4.29 x∗1 = 0, x∗2 = 0.5 4.31 x∗1 = 0, x∗2 = 0.5
4.33 infinite solutions 4.35 x∗1 = 0, x∗2 = 0.5
4.37 X(2) = {0.3367, 0.3112, 0.3250}
4.40 x∗1 = 0.9815, x∗2 = 1.2323, x∗3 = 0.4471
CHAPTER 5
5.2 0.484 5.3 0.481 5.4 0.49 5.6 0.8 5.9 0.7817
5.11(a) 0.786151 (b) 0.786142 (c) 0.786192 5.14(a) 999
798 Answers to Selected Problems
(b) 20 (c) 19 (d) 14 (e) 14 5.17(a) 2.7814
(b) 2.7183 5.18(a) 2.7183 (b) 2.7289 (c) 2.7183
5.20 0.25 5.21 0.001257 5.22 0.00126 5.24 0.00125631
CHAPTER 6
6.1 Min. f = P0(0.5u21 + 0.5u22 − u1u2 − u2)
6.2 f̃1 = 7.0751, f̃2 = 74.8087 where f̃ =
3fρl4
Eh2
6.4 x1 = 65.567, x2 = 52.974 6.5 x∗1 = 4.5454, x∗2 = 5.4545
6.7 f = 4250x21 − 1000x1x2 − 2500x1x3 + 1500x22 − 500x2x3 + 5750x23
− 1000x1 − 2000x2 − 3000x3, X∗ = {0.3241, 0.8360, 0.3677}
6.9 X∗ ≈ {1, 1} 6.12 X∗ = {0.9465, 2.0615, 2.9671}
6.14 f (z1, z2) = −5 + 1.0429z1 − 0.7244z2 + 0.5z21 + 0.5z22
6.16(a) yes (b) no 6.19(a) 60,002.0 (b) 241.3729
6.30 X1 = {2, −1,−8} X2 = {2, −0.7,−8} X3 = {2.26, −0.85,−8}
X4 = {2.15, −0.74,−7.755} 6.35 X2 = {5.57, 0}, f2 >f1
6.38 x∗1 = 1, x∗2 = 1 6.45 X5 = {2.0869, 1.7390}, f5 = −8.3477
6.47 X∗ = {−2, 1, 4} 6.48 x∗ = 1.1423, y∗ = 0.8337
6.50 x∗1 = 1.698105, x∗2 = 0.883407 6.52 X∗ = {5, −8}
6.55(a) no (b) yes
CHAPTER 7
7.1 X∗ = {2, 3}, f ∗ = −50
7.6(a) Min. f = 12x21 + 30x22 − 8x1x2 − 22x1 + 60x2 − 78, x2 + 2 = 0,
x1 + x2 ≤ 0
(b) Min. f = 18x1 − 68x2 − 70, x2 + 2 = 0, x1 + x2 ≤ 0
7.8 X∗ = {1.74558, 1.95265}, f ∗ = −9.23478
7.11 Max. f = 3.5483d4w, 2.2227 × 10−6d4 − 1 ≤ 0, 0.2223d2w − 150 ≤ 0,
d ≤ 25 7.13 −8s1 + 4s2 < 0, s1 + 2s2 ≤ 0, −s1 ≤ 0
7.15 X∗ = {0.75, 4.56249}, f ∗ = 0.25391
7.18 X∗ = {3, 3}, f ∗ = 18 7.21 x∗1 = 24 cm, x∗2 = x∗3 = 12 cm
7.23(a) φk = 2x − rk
(
1
2 − x
+ 1
x − 10
)
,
Answers to Selected Problems 799
(b) φk = 2x + rk(〈2 − x〉2 + 〈x − 10〉2)
7.27 x∗1 = 0.989637, x∗2 = 1.979274
7.29 1
4
x21 +
1
16
x22 − 1 ≤ 0, x1/5 + x2/3 − 1 ≤ 0, r1 = 1.5
7.31 x∗1 = 4.1, x∗2 = 5.9 7.34 X∗ ≈ {0.8984, 0}, f ∗ ≈ 2.2079
7.36 X∗ ≈ {1.671, 17.6} 7.39 x1 = 0.4028, x2 = 0.8056
7.42 optimum, λ1 = λ2 =
1
4
√
2
, λ3 = 11
7.45 X∗ ≈ {1.3480, 0.7722, 0.4299}, f ∗ ≈ 0.1154
CHAPTER 8
8.1 f ≥ 2.268866 8.2 f ≥ 3.464102 8.3 f ≥ 3
8.5 radius = 0.4174 m, height = 1.6695 m
8.6 radius = 0.3633 m, height = 2.9067 m
8.7 x∗1 = 1.5 × 106, x∗2 = 1.0 × 106
8.9 x∗1 = 5.7224, x∗2 = 0.8737, x∗3 = 7.2813
8.10 x∗1 = 1.0845, x∗2 = 1.1761
8.11 x∗1 = 8.6365, x∗2 = 0.9397, x∗3 = 6.8219, x∗4 = 0.9609
8.12 x∗1 = 1.1262, x∗2 = 1.1945, x∗3 = 1.6575
8.13 x∗1 = 2.2629, x∗2 = 7.1689, x∗3 = 4.5850
8.14 x∗1 = 0.3780, x∗2 = 0.5345, x∗3 = 0.5714
8.17 d∗ = 0.002808 m, D∗ = 0.02935 m
8.18 V ∗ = 323.3201 ft/min, F ∗ = 0.005 in/rev 8.20 2
8.22 R∗ = 0.2118, L∗ = 0.2907
8.23 R∗ = 1.2821, L∗ = 0.5266, f ∗ = 16.2056
CHAPTER 9
9.1 x∗1 = 2, x∗2 = x∗3 = 0, x∗4 = 3 9.2 A-B-F-J-K-L-P
9.3 n1 = 2, n2 = 3, n3 = 1 9.4 24,000 ft at B, C, D , and E
9.5 D-H-L-K-J-I-M
9.6 stage 1 (0, n), stage 2 (0, 2n/3), stage 3 (4n/9, 0)
9.7 A B1 C1 D1 E 9.9 units invested in stations 1, 2, 3: (0, 2, 1)
800 Answers to Selected Problems
9.10 x∗1 = 7.5, x∗2 = 10.0 9.11 x∗1 = 60, x∗2 = 70, x∗3 = 80
9.13 x∗1 = 5, x∗2 = 0, x∗3 = 5, x∗4 = 0
CHAPTER 10
10.1 X∗ = {2, 1}, f ∗ = 13 10.3 X∗ = {0, 9}, f ∗ = 27
10.4 X∗ = {1, 0}, f ∗ = 3 10.5 X∗ = {0, 3}, f ∗ = 3
10.6 X∗ = {3, 3}, f ∗ = 39 10.7 X∗ = {4, 3}, f ∗ = 10
10.8 187 = 1 0 1 1 1 0 1 1 10.9 X∗ = {1, 2, 0}, f ∗ = 3
10.12 X∗ = {1, 1, 1}, f ∗ = 18 10.13 X∗ = {1, 1, 1, 1, 0}, f ∗ = 9
10.15 X∗ = {4, 0}, f ∗ = 4 10.16 X∗ = {2, 2.5}, f ∗ = 20.5
CHAPTER 11
11.2 V =
2
√
πh
, σv =
2
h
√
3
8
−
1
π
11.3 X = 3.2, σX = 0.8
11.4 a = 769.2308, µX = 1, σX = 0.048038
11.7 fX(x) = x + 1.5x2, fY (y) = y + 1.5y2
11.8 σX = 0.006079 cm, rejects = 1.32% 11.9 independent
11.10 dependent 11.11(a) 0.99904, (b) 0.0475,
(c) 3616 kgf/cm
2 11.12 0.6767
11.13 R = 268.9520 ft, σR = 56.1941 ft, Rsecond order = 270.1673 ft
11.15 X∗ = {0, 0, 0, 12}, f ∗ = 12
11.17(a) X∗ = {0.0, 36.93, 174.40}, f ∗ = 1,891.72
(b) X∗ = same as in (a), σ ∗f = 524.50
(c) X∗ = same as in (a), (f + σf )∗ = 2,416.22
CHAPTER 12
12.3 x(t) = c1et + (2 − c1)e−t − t where c1 is a constant
12.4 circle of radius L/(2π)
12.6 X∗ =
{
0.2
0.2
}
in2 12.7 X∗ =
{
1.2169
0.3805
}
Answers to Selected Problems 801
CHAPTER 13
13.1 Before: X1 =
{
17
13
}
, X2 =
{
15
22
}
; After: X1 =
{
23
22
}
, X2 =
{
9
13
}
13.3 (a) 9, (b) 10, (c) 11 13.4 10 13.6 (i j) = (i 4) 13.8 x∗ = 2
13.9 x1(2) = 2.8297, x2(2) = 1.9345, x3(2) = 1.6362, x4(2) = 1.1887
13.12 Number of copies of strings 1, 2, 3, 4, 5, 6, 7 are 0, 0, 1, 2, 5, 2, 2, respectively
13.14 String length = 37
CHAPTER 14
14.1 c∗1 = 0.04, c∗2 = 0.81
14.3(a) {0.001165, 0.002329, 0.03949, −0.05635},
(b) {0.0009705, 0.001941, 0.05273, −0.084102},
(c) {0.0009704, 0.001941, 0.05265, −0.08395}
14.5
{
∂yi
∂x1
}
= {−0.000582, −0.001165, −0.002329, 0.002329}
14.7
{
∂yi
∂x3
}
= {0.4693 × 10−7, 0.9477 × 10−7, −0.027948, 0.027947}
14.9(a)
{
0.000125
0.000458
}
(b)
{
−0.000229
−0.000229
}
,
{
0.0
0.000333
}
(c)
{
−275
0
}
,
{
0
200
}
14.11
∂λ1
∂A2
= 2.28840, ∂λ2
∂A2
= 46.8649, ∂Y1
∂A2
=
{
−0.312639 × 10−12
0.391666 × 10−6
}
,
∂Y2
∂A2
=
{
0.698492 × 10−8
0.883790 × 10−2
}
14.15
∂ω1
∂D
= −1.584664, ∂ω2
∂D
= −2.744719
14.16 y∗ = 3, A∗1 = 0.316228 × 10−7, A∗2 = 0.948683 × 10−7, f ∗ = 0.6 × 10−6
14.18 y∗ = 0.25, A∗1 = 1.0, A∗2 = 1.0, f ∗ = 43.7565
14.20 X∗ = {0.7635, 1.0540}, f ∗ = 187.5670 with f = 0.625f1 + 1061.0f2
14.21 X∗ = {0.8, 1.1}, F ∗ = 3.1267
14.22 X∗ = {0.75, 1.25}
Index
A
Absolute minimum, 63
Active constraint, 8, 94
Addition of constraints, 218
Addition of new variables, 214
Additive algorithm, 605
Adjoint equations, 682
Adjoint variable, 682
Admissible variations, 78
All-integer problem, 588
Analytical methods, 253
Answers to selected problems, 795
Ant colony optimization, 3, 693, 714
algorithm, 717
ant searching behavior, 715
basic concept, 714
evaporation, 716
path retracing, 715
pheromone trail, 715
pheromone updating, 715
Applications of geometric programming,
525
Approximate mean, 642
Approximate variance, 642
Arithmetic-geometric inequality, 500
Artificial variables, 139
Augmented Lagrange multiplier method,
459
equality-constrained problems, 459
inequality-constrained problems, 462
mixed equality-inequality-constrained
problems, 463
Augmented Lagrangian function, 460
Availability of computer programs, 786
Average, 635
B
Balas algorithm, 604
Balas method, 589, 604
Barrier methods, 433
Basic feasible solution, 131, 136
Basic set operations, 724
Basic solution, 130, 136
Basic variables, 136
Basis, 130
Basis vector approach, 743
Beale’s function, 365
Beam-column, 55
Bearing, 531
Behavior constraints, 7
BFGS formula, 353
BFGS method, 360
Bias of random directions, 312
Binary numbers, 607
Binary programming, 624
Binary variables, 607
Bivariate distribution, 639
Boltzmann’s constant, 703
Boltzmann’s probability distribution,
703
Boundary value problem, 549
Bounded objective function method, 764
Bound point, 8
Brachistochrone problem, 671
Bracket function, 443, 696
Branch and bound method, 609
Branching, 610
Brown’s badly scaled function, 365
Broydon-Fletcher-Goldfarb-Shanno
method, 304, 360
C
Calculus methods, 3
Calculus of variations, 3, 668
Canonical form, 133
Cantilever beam, 527
Cauchy method, 304, 339
Cauchy’s inequality, 500
Central limit theorem, 647
Chance constrained programming, 647
803Engineering Optimization: Theory and Practice, Fourth Edition Singiresu S. Rao
Copyright © 2009 by John Wiley & Sons, Inc.
804 Index
Change in constraint coefficients, 215
Change in cost coefficients, 212
Change in right hand side constants, 208
Characteristics of constrained
problem, 380
Choice of method, 784
Circular annular plate, 690
Classical optimization techniques, 63
Classification:
of optimization problems, 14
of unconstrained minimization
methods, 304
Classification of optimization problems
based on:
deterministic nature of variables, 29
existence of constraints, 14
nature of design variables, 15
nature of equations involved, 19
number of objective functions, 32
permissible values of design
variables, 28
physical structure of the problem, 16
separability of the functions, 30
Closed half space, 128
Cluster analysis, 3
Coefficient of variation, 636
Collapse mechanism, 121
Comparison:
of constrained methods, 785
of elimination methods, 272
of methods, 294
of unconstrained methods, 784
Complementary geometric
programming, 520
degree of difficulty, 523
solution procedure, 522
Complement of a fuzzy set, 724
Complex method, 384
Composite constraint surface, 8
Computational aspects of optimization,
784
Computer programs, availability of,
786, 788
Computer program for:
ant colony optimization, 789
fuzzy logic toolbox, 788
genetic algorithm and direct search
toolbox, 788
modern optimization methods, 788
multiobjective optimization, 789
neural network toolbox, 788
particle swarm optimization, 788
simulated annealing algorithm, 788
Concave function, 779
Concept of cutting plane, 591
Concept of suboptimization, 549
Concrete beam, 29
Condition number of a matrix, 306
Cone clutch, 49, 528
Conjugate directions, 319
Conjugate gradient method, 341, 355, 361
Consistency condition, 220
Constrained minimization (GMP), 508
Constrained optimization problem, 6, 380
characteristics, 380
Constrained optimization techniques, 380
Constrained variation, 77, 79
Constraint qualification, 98
Constraint surface, 8
Contact stress between cylinders, 297
Contact stress between spheres, 250
Continuous beams, 576
Continuous dynamic programming, 573
Continuous feasible solution, 609
Continuous random variable, 634
Contours of objective function, 10
Contraction, 332
Contraction coefficient, 332
Control variables, 16
Control vector, 678
Convergence of constrained problems, 464
Convergence of order p, 305
Conversion of final to initial value
problem, 566
Conversion of nonserial to serial
system, 548
Convex:
function, 779
polygon, 127
polyhedron, 127, 129
polytope, 129
programming problem, 98, 104, 442
set, 129
Index 805
Cooling fin, 675
Correlation, 640
Correlation coefficient, 640
Correlation matrix, 646
Covariance, 640
Covariance matrix, 648
CPM and PERT, 3
Crane hook, 60
Crisp set theory, 723
Criterion function, 9
Critical points, 750
Crossover, 699
Cubic interpolation method, 253, 280
Cumulative distribution function, 634
Curse of dimensionality, 573
Curve of minimum time of descent, 672
Cutting plane method, 390, 589
algorithm, 387
geometric interpretation, 388
Cyclic process, 331
Cylinders in contact, 297
D
Darcy-Weisbach equation, 663
Darwin’s theory, 694
Davidon-Fletcher-Powell method, 304,
354
DC motor, 53
Decision variables, 6
Decomposition principle, 177, 200
Degenerate solution, 142
Degree of difficulty, 496
Derivatives
of eigenvalues and eigenvectors, 747
of static displacements and stresses, 745
of transient response, 749
Descent direction, 336
Descent methods, 304, 335
Design constraints, 7
Design equations, 547
Design of:
cantilever beam, 527
column, 11
cone clutch, 528
continuous beams, 576
drainage system, 579
four bar mechanism, 535
gear train, 579
helical spring, 529, 659
hydraulic cylinder, 527
lightly loaded bearing, 531
planar truss, 249
two bar truss, 533
Design of experiments, 3
Design point, 7
Design space, 7
Design variable linking, 738
Design variables, 6
Design vector, 6
DFP formula, 352
DFP method, 354
Dichotomous search, 253, 257
Differential calculus methods, 253, 493
Differential of f, 68
Direction finding problem, 395
Direct methods, 380, 383
Direct root method, 253, 286
Direct search methods, 309
Direct substitution, 76
Discrete programming problem, 588
Discrete random variable, 634
Discriminate analysis, 3
Drainage system, 579
Dual function, 501
Duality in linear programming, 192
Duality theorems, 195
Dual problem, 192, 509
Dual simplex method, 195
Dynamic optimization problem, 16
Dynamic programming, 3, 544
applications, 576
calculus method of solution, 555
computational procedure, 553
continuous, 573
conversion of final to initial value
problem, 566
problem of dimensionality, 572
recurrence relation, 551
tabular method of solution, 560
E
Electrical bridge network, 52
Elementary operations, 133
Elimination methods, 253, 254
806 Index
Elimination methods–comparison,
271
Engineering applications of
optimization, 5
Engineering optimization literature, 35
Equality constraints, 6
Euler equation, 671
Euler-Lagrange equation, 671
Evaluation of gradient, 337
Event, 633
Exhaustive search, 253, 256
Expansion, 331
Expansion coefficient, 332
Expected value, 635
Experiment, 633
Extended interior penalty function, 451
Exterior penalty function method,
443, 455
algorithm, 445
convergence proof, 447
mixed equality-inequality
constraints, 455
parametric constraints, 459
Extrapolation of design vector, 448
Extrapolation of objective function,
450
Extrapolation technique, 447
Extreme point, 130
F
Factor analysis, 3
Failure mechanisms of portal frame, 246
Fast reanalysis techniques, 740
Fathomed, 610
Feasible direction, 95, 393
Feasible direction methods, 393, 394
Feasible solution, 130
Feasible space, 8
Fibonacci method, 253, 263
Fibonacci numbers, 263
Final interval of uncertainty, 263, 272
Final value problem, 548
First level problem, 757
First order methods, 305
Fitness, 696
Fletcher and Powell’s helical valley
function, 364
Fletcher-Reeves method, 304, 341
algorithm, 343
Floor design, 542
Flow chart:
for augmented Lagrange multiplier
method, 461
for cubic interpolation method, 284
for Fibonacci search method, 266
for linear extended penalty function
method, 453
for parallel simulated annealing, 762
for Powell’s method, 325
for simplex algorithm, 143
for simplex method, 153
for simulated annealing, 706
for two-phase simplex method, 153
Flywheel design, 482
Forced boundary conditions, 671
Four bar mechanism, 535
Four bar truss, 60, 557
Free boundary conditions, 671
Free point, 8
Freudenstein and Roth function, 364
Functional, 669
Functional constraints, 7
Function of a random variable, 638
Function of several random variables, 640
mean, 641
variance, 641
Fuzzy decision, 726
Fuzzy feasible region, 822
Fuzzy optimization, 3, 693, 722
computational procedure, 726
fuzzy set theory, 722
Fuzzy systems, 722, 725
G
Game theory, 3
Gaussian distribution, 643
Gear train, 579
General iterative scheme of
optimization, 305
Generalized penalty function method, 619
Generalized reduced gradient, 415
Generalized reduced gradient method, 412
algorithm, 416
General primal dual relations, 193
Index 807
Genetic algorithms, 3, 693, 694, 701
Genetic operators, 697
Geometric boundary conditions, 671
Geometric constraints, 7
Geometric programming, 3, 22, 492
applications, 525
arithmetic-geometric inequality, 500
complementary geometric
programming, 520
constrained problem, 508, 509
degree of difficulty, 496
mixed inequality constraints, 518
normality condition, 495
orthogonality conditions, 495
primal dual relations, 501
unconstrained problem, 493
Geometry of linear programming
problems, 124
Global criterion method, 764
Global minimum, 63
Goal programming method, 765
Golden mean, 270
Golden section, 270
Golden section method, 253, 267
Gomory’s constraint, 592
Gomory’s cutting plane method, 591
for all integer problem, 592
graphical representation, 589
for mixed integer problem, 599
Gradient, 95, 335
Gradient evaluation, 337
Gradient of a function, 335
Gradient methods, 335
Gradient projection method, 404
algorithm, 409
Graphical optimization, 10
Graphical representation, 589
Grid search method, 304, 314
H
Hamiltonian, 682
Helical spring, 22, 529
Helical torsional spring, 541
Hessian matrix, 71, 302
Heuristic search methods, 381
Historical development, 3
Hitchcock-Koopman’s problem, 221
Hollow circular shaft, 51
Hopfield network, 729
Huang’s family of updates, 353
Hydraulic cylinder design, 527
Hyperplane, 128
I
Identifying optimal point, 140
Ill conditioned matrix, 306
Improving nonoptimal solution, 141
Inactive constraint, 94
Incremental response approach, 740
Independent events, 633
Independent random variables, 639
Indirect methods, 335, 380, 428
Indirect updated method, 361
Inequality constraints, 6, 93
Infeasibility form, 152
Infinite number of solutions, 148
Inflection point, 65
Initial value problem, 548
Input state variables, 546
Integer feasible solution, 610
Integer lattice points, 591
Integer linear programming, 589
Integer nonlinear programming, 606
Integer polynomial programming, 606
Integer programming, 3, 28, 588
Interior method, 222
Interior penalty function method,
432, 454
convergence proof, 438
extrapolation technique, 447
iterative process, 433
penalty parameter, 435
starting feasible point, 434
Interpolation methods, 253, 271
Interpretation of Lagrange multipliers, 90
Intersection of convex sets, 131
Intersection of fuzzy sets, 725
Interval halving method, 260
Interval of uncertainty, 256, 263
Introduction to optimization, 1
Inverse update formulas, 353
Inverted utility function method, 764
Iterative process of optimization, 252
808 Index
J
Jacobian, 82
Joint density function, 639
Joint distribution function, 639
Jointly distributed random variables, 639
Joint normal density function, 646
K
Karmarkar’s method, 222
algorithm, 226
conversion of problem, 224
statement of problem, 223
Kohonen network, 729
Kuhn-Tucker conditions, 98, 401
testing, 465
L
Lagrange method, 85
necessary conditions, 86
sufficiency conditions, 87
Lagrange multipliers, 85, 675, 682
Lagrangian function, 86, 230
Learning process, 728
Lexicographic method, 765
Limit design of frames, 120
Linear convergence, 305
Linear extended penalty function, 451
Linearization of constraints, 387
Linearization of objective, 387
Linear programming, 3, 26, 119, 177
additional topics, 177
applications, 120
definitions, 127
theorems, 127
two phases, 150
Linear programming problem, 26
as a dynamic programming
problem, 569
geometry, 124
infinite solutions, 126, 148
matrix form, 122
scalar form, 122
standard form, 122
unbounded solution, 127, 146
Linear simultaneous equations, 133
Line segment, 128, 202
Local minimum, 63
M
Machining economics problem, 525
Marginal density function, 639
Markov processes, 3
Marquardt method, 304, 348
Mathematical programming
techniques, 1, 3
MATLAB, 791
creating m-files, 793
defining matrices, 792
features, 791
introduction, 791
optimization toolbox, 793
special characters, 791
using programs, 794
MATLAB solutions, 37
binary programming problem, 624
constrained optimization problem, 474
goal attainment method, 767
interior point method, 235
linear programming problem, 156
one-dimensional problem, 294
quadratic programming problem, 237
unconstrained optimization
problem, 365
Matrix methods of structural analysis, 248
Maxwell distribution, 663
Mean, 635
Membership function, 723
Merit function, 9
Method of constrained variation, 77
Method of Lagrange multipliers, 85
Methods of feasible directions, 393
Methods of operations research, 2
Metropolis criterion, 703
MIMD architecture, 761
Minimum cost pipeline, 585
Minimum drag, 672
Mixed constraints, 453
exterior penalty function method, 455
interior penalty function method, 454
Mixed equality and inequality
constraints, 453
Mixed integer problem, 588
Model coordination method, 755
Modern optimization techniques, 3, 4, 693
Monotonicity, 547
Index 809
Motivation of simplex method, 138
Multibay cantilever truss, 578
Multilayer feedforward network, 729
Multilevel optimization, 755
Multimodal function, 254
Multiobjective optimization, 761
Multiobjective programming, 3, 9, 33
Multiobjective programming
problem, 9, 33
Multiple objective functions, 9
Multistage decision problem, 544, 548
Multistage decision process, 545
Multivariable optimization, 68
with equality constraints, 75
with inequality constraints, 93
necessary conditions, 69, 81, 94, 98
with no constraints, 68
sufficiency conditions, 70, 83
Multivariate distribution, 639
Mutation, 700
N
Natural boundary conditions, 671
Necessary conditions for optimal control,
679
Negative definite matrix, 71
Network methods, 3
Neural network based methods, 693, 727
Neural networks, 3, 728
Neuron, 728
Newton method, 253, 286, 304, 345
Newton Raphson method, 287
Node, 610
Nonbasic variables, 136
Nonconvex sets, 129
Nondegenerate solution, 131
Nongradient methods, 304
Nonlinear programming, 3, 248, 301, 380
Nonlinear programming problem, 19
Nonpivotal variables, 135
Nontraditional optimization techniques, 3
Normal distribution, 643
Normality condition, 495
Normalization condition, 635
Normalization of constraints, 436
Normalized beta function integrand, 620
Norm of a matrix, 306
Norm of a vector, 305
Number of experiments, 272
Numerical integration, 458
O
Objective function, 6, 9
Objective function surfaces, 9
Offspring, 700
One degree of difficulty problem, 515,
526, 532
One dimensional minimization
methods, 248
Operations research, 1, 3
Optimal basic solution, 131
Optimal control problem, 16
Optimal control theory, 668, 678
Optimality criteria, 683
multiple displacement constraints, 684
single displacement constraint, 683
Optimality criteria methods, 668, 683
Optimal layout of a truss, 577
Optimal solution, 131
Optimization, 1
Optimization of fuzzy systems, 722, 725
Optimization problems
classification, 14
statement, 6
Optimization techniques, 3, 35
Optimization toolbox, 36
Optimum machining conditions, 525
Orthogonal directions, 319
Orthogonality conditions, 495
Output state variables, 546
Overachievement, 766
P
Parallel processing, 760
Parallel simulated annealing, 761
Parameter optimization problem, 15
Parametric constraint, 456
Parametric programming, 207
Parent, 700
Pareto optimum solution, 763
Particle swarm optimization, 3, 693, 708
computational implementation, 709
inertia term, 710
inertia weight, 711
810 Index
Particle swarm optimization (continued )
particle, 708
position, 708
velocity, 708
Pattern directions, 318
Pattern recognition, 3
Pattern search methods, 304
Penalty function, 696
Penalty function method:
basic approach, 430
convergence criteria, 435
convergence proof, 438, 447
exterior method, 443
extrapolation, 447
initial value of parameter, 435
interior method, 432
iterative process, 433, 445
mixed equality and inequality
constraints, 453
normalization of constraints, 436
parametric constraints, 456
penalty parameter, 431
starting feasible point, 434
Penalty parameter, 431
Performance index, 16, 679
Perturbing the design vector, 465
Phase I of simplex method, 151
Phase II of simplex method, 152
Pivot operation, 134
Pivot reduction, 135
Point in n-dimensional space, 128
Polynomial programming problem,
589
Population, 697
Positive definite matrix, 71
Positive semidefinite matrix, 71
Post optimality analysis, 207
Posynomial, 22, 492
Powell’s badly scaled function, 365
Powell’s method, 304, 319
algorithm, 323
convergence criterion, 326
flow chart, 325
Powell’s quartic function, 364
Power screw, 57
Practical aspects of optimization, 737
Practical considerations, 293
Preassigned parameters, 6
Precision points, 535
Predual function, 500
Pressure vessel, 59
Primal and dual programs, 505, 510
Primal dual relations, 193, 501
Primal function, 500
Primal problem, 192, 509
Principle of optimality, 549
Probabilistic programming, 632
Probability, definition, 632, 633
Probability density function, 633
Probability distribution function, 634
Probability distributions, 643
Probability mass function, 634
Probability theory, 632
Problem of dimensionality, 572
Projected Lagrangian method, 425
Projection matrix, 405
Proportional damping, 749
Pseudo dual simplex method, 606
Q
Quadratically convergent method, 319
Quadratic convergence, 287, 305, 325
Quadratic extended penalty function, 452
Quadratic form, 71
Quadratic interpolation method, 253, 273
Quadratic programming, 3, 24, 229
Quasi-Newton condition, 304
Quasi-Newton method, 253, 288, 350
Queueing theory, 3
R
Railroad track, 48
Random jumping method, 311
Random search methods, 304, 309, 383
Random variables, 633
Random walk with direction
exploitation, 313
Random walk method, 312
Rank 1 updates, 351
Rank 2 updates, 352
Rate of change of a function, 338
Rate of convergence, 305
Real valued programming problem, 28
Reanalysis, 740
Index 811
Reciprocal approximation, 685
Recurrence relationship, 551
Reduced basis technique, 737
Reduction ratio, 265
Reduction of size, 737
Refitting, 277
Reflection, 328
Reflection coefficient, 330
Reflection process, 329
Regression analysis, 3
Regular simplex, 328
Relative frequency of occurrence, 636
Relative minimum, 63
Reliability theory, 3
Renewal theory, 3
Reproduction, 697
Reservoir pump installation, 505
Reservoir system, 160
Return function, 546
Revised simplex method, 177
step-by-step procedure, 182
theoretical development, 178
Rigid frame, 120
Rocket in outer space, 16
Rosenbrock’s parabolic valley
function, 363
Rosen’s gradient projection method, 404
algorithm, 409
determination of step length, 407
projection matrix, 405
Roulette-wheel selection scheme, 698
S
Saddle point, 73
Scaffolding system, 26, 57
Scaling of constraints, 787
Scaling of design variables, 305, 787
Search with accelerated step size, 255
Search with fixed step size, 254
Secant method, 253, 290
Second level problem, 757
Second order methods, 305
Semidefinite matrix, 71
Sensitivity analysis, 207
Sensitivity equations, 751
using Kuhn-Tucker conditions, 752
using the concept of feasible
direction, 754
Sensitivity of optimum solution, 751
Sensitivity to problem parameters, 751
Separability, 547
Separability of functions, 31
Separable function, 31
Separable programming, 3, 31
Sequential decision problem, 544
Sequential linear discrete programming,
614
Sequential linear integer programming,
614
Sequential linear programming, 387
geometric interpretation, 388
Sequential quadratic programming, 422
derivation, 422
solution procedure, 425
Sequential unconstrained minimization,
431
Serial multistage decision process, 545
Shadow prices, 92
Shell and tube heat exchanger, 51
Side constraints, 7
Sigmoid function, 728
Signum function, 509
Simplex, 328, 384
Simplex algorithm, 139
flow chart, 143
Simplex method, 138, 304, 328
flow chart, 153
two phases, 150
Simplex multipliers, 180
Simply supported beam, 58
Simulated annealing, 3, 693, 702
Simulation methods, 3
Simultaneous equations, 133
Simultaneous search method, 257
Single stage decision problem, 546
Single variable optimization, 63
Slack variable, 123
Slider crank mechanism, 49
Solid body of revolution, 672
Solution by direct substitution, 76
Solution of linear equations, 133
Spring-cart system, 71
Stamping of circular discs, 49
812 Index
Standard deviation, 635, 636
Standard form of LP problem, 122
Standard normal distribution, 643
Standard normal tables, 643, 645
Starting feasible point, 434
State inversion, 566
Statement of an optimization problem, 6
State transformation, 546
State variables, 16
State vector, 679
Statically determinate truss, 542
Static optimization problem, 15
Stationary point, 65
Stationary values of functionals, 669
Statistical decision theory, 3
Statistically independent events, 633
Statistical methods, 3
Steepest ascent direction, 335
Steepest descent method, 304, 339
convergence criteria, 341
Step-cone pulley, 19
Step length determination, 398, 407
Stochastic process techniques, 3
Stochastic programming, 3, 29, 632
geometric programming, 659
linear programming, 647
nonlinear programming, 652
Structural error, 535
Structural optimization packages,
787
Suboptimization, 551
SUMT, 431
Superlinear convergence, 305, 361
Surplus variable, 124
Survival of the fittest, 696
Symmetric primal-dual relations, 192
System reliability, 583
T
Taylor’s series expansion, 68, 642
Tentative solution, 670
Termination criteria, 401
Test functions (unconstrained nonlinear
programming), 363
Beale’s function, 365
Brown’s badly scaled function, 365
Fletcher and Powell’s helical
valley, 364
Freudenstein and Roth function, 364
Powell’s badly scaled function, 365
Powell’s quartic function, 364
Rosenbrock’s parabolic valley, 363
Wood’s function, 365
Testing for concavity, 779
Testing for convexity, 779
Testing Kuhn-Tucker conditions, 465
Test problems (constrained nonlinear
programming), 467
heat exchanger, 473
speed reducer (gear train), 472
three-bar truss, 467
welded beam, 470
25-bar space truss, 468
Trajectory optimization problem, 16
Transformation techniques, 428
Transformation of variables, 381, 428
Transportation array, 221
Transportation problem, 177, 220
Transportation technique, 221
Transversality conditions, 682
Trapezoidal rule, 458
Travelling salesperson, 52
Trial, 254
Truss, 47, 55, 60, 248, 481, 487, 578, 623,
686, 691, 692, 741, 745, 758, 772
Tubular column design, 10, 654
Two-bar truss, 47, 55, 487, 533, 758
Two degree of difficulty problem, 526
Two phases of simplex method, 150
Two stage compressor, 67
Types of multistage decision
problems, 548
U
Unbounded solution, 127, 142, 146
Unconstrained minimization (GMP), 493
Unconstrained optimization problem, 6,
301
Unconstrained optimization techniques,
301
Index 813
Underachievement, 766
Uniform distribution, 643
Unimodal function, 253
Union of fuzzy sets, 725
Univariate distribution, 639
Univariate method, 304, 315
Unrestricted search, 253, 254
Usable direction, 97
Usable feasible direction, 393
Utility function method, 763
V
Valuation set, 723
Variable metric method, 354, 361
Variance, 636
Variation, 669
Variational operator, 669
Vector minimization problem, 762
Vector of simplex multipliers, 180
Venn diagram, 723
Vertex, 130
W
Water resource system, 241
Water tank design, 550
Weighting function method, 764
Weights, 501
Well conditioned matrix, 306
Wood’s function, 365
Z
Zero degree of difficulty problem, 511,
525, 531
Zero-one LP problem, 608
Zero-one polynomial programming, 608
Zero-one problem, 588
Zero-one programming problems, 588,
604
Zeroth order methods, 304
Zoutendijk’s method, 381, 394
determination of step length, 398
direction finding problem, 395
termination criteria, 401

