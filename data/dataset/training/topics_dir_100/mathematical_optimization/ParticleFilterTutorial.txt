174 IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 50, NO. 2, FEBRUARY 2002
A Tutorial on Particle Filters for Online
Nonlinear/Non-Gaussian Bayesian Tracking
M. Sanjeev Arulampalam, Simon Maskell, Neil Gordon, and Tim Clapp
Abstract—Increasingly, for many application areas, it is
becoming important to include elements of nonlinearity and
non-Gaussianity in order to model accurately the underlying
dynamics of a physical system. Moreover, it is typically crucial
to process data on-line as it arrives, both from the point of view
of storage costs as well as for rapid adaptation to changing
signal characteristics. In this paper, we review both optimal and
suboptimal Bayesian algorithms for nonlinear/non-Gaussian
tracking problems, with a focus on particle filters. Particle filters
are sequential Monte Carlo methods based on point mass (or
“particle”) representations of probability densities, which can
be applied to any state-space model and which generalize the
traditional Kalman filtering methods. Several variants of the
particle filter such as SIR, ASIR, and RPF are introduced within
a generic framework of the sequential importance sampling (SIS)
algorithm. These are discussed and compared with the standard
EKF through an illustrative example.
Index Terms—Bayesian, nonlinear/non-Gaussian, particle
filters, sequential Monte Carlo, tracking.
I. INTRODUCTION
MANY problems in science require estimation of the stateof a system that changes over time using a sequence of
noisy measurements made on the system. In this paper, we will
concentrate on the state-space approach to modeling dynamic
systems, and the focus will be on the discrete-time formulation
of the problem. Thus, difference equations are used to model
the evolution of the system with time, and measurements are
assumed to be available at discrete times. For dynamic state es-
timation, the discrete-time approach is widespread and conve-
nient.
The state-space approach to time-series modeling focuses at-
tention on the state vector of a system. The state vector con-
tains all relevant information required to describe the system
under investigation. For example, in tracking problems, this in-
formation could be related to the kinematic characteristics of
the target. Alternatively, in an econometrics problem, it could be
Manuscript received February 8, 2001; revised October 15, 2001. S.
Arulampalam was supported by the Royal Academy of Engineering with
an Anglo–Australian Post-Doctoral Research Fellowship. S. Maskell was
supported by the Royal Commission for the Exhibition of 1851 with an
Industrial Fellowship. The associate editor coordinating the review of this
paper and approving it for publication was Dr. Petar M. Djurić.
M. S. Arulampalam is with the Defence Science and Technology Organisa-
tion, Adelaide, Australia (e-mail: sanjeev.arulampalam@dsto.defence.gov.au).
S. Maskell and N. Gordon are with the Pattern and Information Processing
Group, QinetiQ, Ltd., Malvern, U.K., and Cambridge University Engineering
Department, Cambridge, U.K. (e-mail: s.maskell@signal.qinetiq.com;
n.gordon@signal.qinetiq.com).
T. Clapp is with Astrium Ltd., Stevenage, U.K. (e-mail: t.clapp@iee.org).
Publisher Item Identifier S 1053-587X(02)00569-X.
related to monetary flow, interest rates, inflation, etc. The mea-
surement vector represents (noisy) observations that are related
to the state vector. The measurement vector is generally (but not
necessarily) of lower dimension than the state vector. The state-
space approach is convenient for handling multivariate data and
nonlinear/non-Gaussian processes, and it provides a significant
advantage over traditional time-series techniques for these prob-
lems. A full description is provided in [41]. In addition, many
varied examples illustrating the application of nonlinear/non-
Gaussian state space models are given in [26].
In order to analyze and make inference about a dynamic
system, at least two models are required: First, a model de-
scribing the evolution of the state with time (the system model)
and, second, a model relating the noisy measurements to the
state (the measurement model). We will assume that these
models are available in a probabilistic form. The probabilistic
state-space formulation and the requirement for the updating of
information on receipt of new measurements are ideally suited
for the Bayesian approach. This provides a rigorous general
framework for dynamic state estimation problems.
In the Bayesian approach to dynamic state estimation, one
attempts to construct the posterior probability density function
(pdf) of the state based on all available information, including
the set of received measurements. Since this pdf embodies all
available statistical information, it may be said to be the com-
plete solution to the estimation problem. In principle, an optimal
(with respect to any criterion) estimate of the state may be ob-
tained from the pdf. A measure of the accuracy of the estimate
may also be obtained. For many problems, an estimate is re-
quired every time that a measurement is received. In this case, a
recursive filter is a convenient solution. A recursive filtering ap-
proach means that received data can be processed sequentially
rather than as a batch so that it is not necessary to store the com-
plete data set nor to reprocess existing data if a new measure-
ment becomes available.1 Such a filter consists of essentially
two stages: prediction and update. The prediction stage uses the
system model to predict the state pdf forward from one mea-
surement time to the next. Since the state is usually subject to
unknown disturbances (modeled as random noise), prediction
generally translates, deforms, and spreads the state pdf. The up-
date operation uses the latest measurement to modify the pre-
diction pdf. This is achieved using Bayes theorem, which is the
mechanism for updating knowledge about the target state in the
light of extra information from new data.
1In this paper, we assume no out-of-sequence measurements; in the presence
of out-of-sequence measurements, the order of times to which the measurements
relate can differ from the order in which the measurements are processed. For a
particle filter solution to the problem of relaxing this assumption, see [32].
1053–587X/02$17.00 © 2002 IEEE
ARULAMPALAM et al.: TUTORIAL ON PARTICLE FILTERS 175
We begin in Section II with a description of the nonlinear
tracking problem and its optimal Bayesian solution. When
certain constraints hold, this optimal solution is tractable.
The Kalman filter and grid-based filter, which is described
in Section III, are two such solutions. Often, the optimal
solution is intractable. The methods outlined in Section IV
take several different approximation strategies to the optimal
solution. These approaches include the extended Kalman filter,
approximate grid-based filters, and particle filters. Finally, in
Section VI, we use a simple scalar example to illustrate some
points about the approaches discussed up to this point and
then draw conclusions in Section VII. This paper is a tutorial;
therefore, to facilitate easy implementation, the “pseudo-code”
for algorithms has been included at relevant points.
II. NONLINEAR BAYESIAN TRACKING
To define the problem of tracking, consider the evolution of
the state sequence of a target given by
(1)
where is a possibly nonlinear function
of the state , is an i.i.d. process noise se-
quence, are dimensions of the state and process noise
vectors, respectively, and is the set of natural numbers. The
objective of tracking is to recursively estimate from mea-
surements
(2)
where is a possibly nonlinear func-
tion, is an i.i.d. measurement noise sequence,
and are dimensions of the measurement and measure-
ment noise vectors, respectively. In particular, we seek filtered
estimates of based on the set of all available measurements
, up to time .
From a Bayesian perspective, the tracking problem is to re-
cursively calculate some degree of belief in the state at time
, taking different values, given the data up to time . Thus,
it is required to construct the pdf . It is assumed that
the initial pdf of the state vector, which is also
known as the prior, is available ( being the set of no measure-
ments). Then, in principle, the pdf may be obtained,
recursively, in two stages: prediction and update.
Suppose that the required pdf at time
is available. The prediction stage involves using the system
model (1) to obtain the prior pdf of the state at time via the
Chapman–Kolmogorov equation
(3)
Note that in (3), use has been made of the fact that ,
as (1) describes a Markov process
of order one. The probabilistic model of the state evolution
is defined by the system equation (1) and the
known statistics of .
At time step , a measurement becomes available, and this
may be used to update the prior (update stage) via Bayes’ rule
(4)
where the normalizing constant
(5)
depends on the likelihood function defined by the
measurement model (2) and the known statistics of . In the
update stage (4), the measurement is used to modify the
prior density to obtain the required posterior density of the
current state.
The recurrence relations (3) and (4) form the basis for the
optimal Bayesian solution.2 This recursive propagation of the
posterior density is only a conceptual solution in that in general,
it cannot be determined analytically. Solutions do exist in a re-
strictive set of cases, including the Kalman filter and grid-based
filters described in the next section. We also describe how, when
the analytic solution is intractable, extended Kalman filters, ap-
proximate grid-based filters, and particle filters approximate the
optimal Bayesian solution.
III. OPTIMAL ALGORITHMS
A. Kalman Filter
The Kalman filter assumes that the posterior density at every
time step is Gaussian and, hence, parameterized by a mean and
covariance.
If is Gaussian, it can be proved that
is also Gaussian, provided that certain assumptions
hold [21]:
• and are drawn from Gaussian distributions of
known parameters.
• is known and is a linear function of
and .
• is a known linear function of and .
That is, (1) and (2) can be rewritten as
(6)
(7)
and are known matrices defining the linear functions.
The covariances of and are, respectively, and
. Here, we consider the case when and have zero
mean and are statistically independent. Note that the system and
measurement matrices and , as well as noise parameters
and , are allowed to be time variant.
The Kalman filter algorithm, which was derived using (3) and
(4), can then be viewed as the following recursive relationship:
(8)
(9)
(10)
2For clarity, the optimal Bayesian solution solves the problem of recursively
calculating the exact posterior density. An optimal algorithm is a method for
deducing this solution.
176 IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 50, NO. 2, FEBRUARY 2002
where
(11)
(12)
(13)
(14)
and where is a Gaussian density with argument ,
mean , and covariance , and
(15)
(16)
are the covariance of the innovation term , and
the Kalman gain, respectively. In the above equations, the trans-
pose of a matrix is denoted by .
This is the optimal solution to the tracking problem—if the
(highly restrictive) assumptions hold. The implication is that no
algorithm can ever do better than a Kalman filter in this linear
Gaussian environment. It should be noted that it is possible to
derive the same results using a least squares (LS) argument [22].
All the distributions are then described by their means and co-
variances, and the algorithm remains unaltered, but are not con-
strained to be Gaussian. Assuming the means and covariances
to be unbiased and consistent, the filter then optimally derives
the mean and covariance of the posterior. However, this poste-
rior is not necessarily Gaussian, and therefore, if optimality is
the ability of an algorithm to calculate the posterior, the filter is
then not certain to be optimal.
Similarly, if smoothed estimates of the states are required,
that is, estimates of , where ,3 then the
Kalman smoother is the optimal estimator of .
This holds if is fixed (fixed-lag smoothing, if a batch of data
are considered and (fixed-interval smoothing), or if
the state at a particular time is of interest is fixed (fixed-point
smoothing). The problem of calculating smoothed densities is
of interest because the densities at time are then conditional
not only on measurements up to and including time index but
also on future measurements. Since there is more information
on which to base the estimation, these smoothed densities are
typically tighter than the filtered densities.
Although this is true, there is an algorithmic issue that should
be highlighted here. It is possible to formulate a backward-time
Kalman filter that recurses through the data sequence from the
final data to the first and then combines the estimates from the
forward and backward passes to obtain overall smoothed es-
timates [20]. A different formulation implicitly calculates the
backward-time state estimates and covariances, recursively esti-
mating the smoothed quantities [38]. Both techniques are prone
to having to calculate matrix inverses that do not necessarily
exist. Instead, it is preferable to propagate different quantities
using an information filter when carrying out the backward-time
recursion [4].
3If ` = 0, then the problem reduces to the estimation of p(x jz ) consid-
ered up to this point.
B. Grid-Based Methods
Grid-based methods provide the optimal recursion of the fil-
tered density if the state space is discrete and consists
of a finite number of states. Suppose the state space at time
consists of discrete states , . For each state
, let the conditional probability of that state, given mea-
surements up to time be denoted by , that is,
. Then, the posterior pdf
at can be written as
(17)
where is the Dirac delta measure. Substitution of (17) into
(3) and (4) yields the prediction and update equations, respec-
tively
(18)
(19)
where
(20)
(21)
The above assumes that and are known
but does not constrain the particular form of these discrete densi-
ties. Again, this is the optimal solution if the assumptions made
hold.
IV. SUBOPTIMAL ALGORITHMS
In many situations of interest, the assumptions made above
do not hold. The Kalman filter and grid-based methods cannot,
therefore, be used as described—approximations are necessary.
In this section, we consider three approximate nonlinear
Bayesian filters:
a) extended Kalman filter (EKF);
b) approximate grid-based methods;
c) particle filters.
A. Extended Kalman Filter
If (1) and (2) cannot be rewritten in the form of (6) and (7)
because the functions are nonlinear, then a local linearization of
the equations may be a sufficient description of the nonlinearity.
The EKF is based on this approximation. is approx-
imated by a Gaussian
(22)
(23)
(24)
ARULAMPALAM et al.: TUTORIAL ON PARTICLE FILTERS 177
where
(25)
(26)
(27)
(28)
and where now, and are nonlinear functions, and
and are local linearizations of these nonlinear functions (i.e.,
matrices)
(29)
(30)
(31)
(32)
The EKF as described above utilizes the first term in a Taylor
expansion of the nonlinear function. A higher order EKF that
retains further terms in the Taylor expansion exists, but the ad-
ditional complexity has prohibited its widespread use.
Recently, the unscented transform has been used in an EKF
framework [23], [42], [43]. The resulting filter, which is known
as the “unscented Kalman filter,” considers a set of points that
are deterministically selected from the Gaussian approximation
to . These points are all propagated through the true
nonlinearity, and the parameters of the Gaussian approximation
are then re-estimated. For some problems, this filter has been
shown to give better performance than a standard EKF since
it better approximates the nonlinearity; the parameters of the
Gaussian approximation are improved.
However, the EKF always approximates to
be Gaussian. If the true density is non-Gaussian (e.g., if it
is bimodal or heavily skewed), then a Gaussian can never
describe it well. In such cases, approximate grid-based filters
and particle filters will yield an improvement in performance
in comparison to that of an EKF [1].
B. Approximate Grid-Based Methods
If the state space is continuous but can be decomposed into
“cells,” : , then a grid-based method
can be used to approximate the posterior density. Specifically,
suppose the approximation to the posterior pdf at is given
by
(33)
Then, the prediction and update equations can be written as
(34)
(35)
where
(36)
(37)
Here, denotes the center of the th cell at time index .
The integrals in (36) and (37) arise due to the fact that the grid
points , , represent regions of continuous state
space, and thus, the probabilities must be integrated over these
regions. In practice, to simplify computation, a further approx-
imation is made in the evaluation of . Specifically, these
weights are computed at the center of the “cell” corresponding
to
(38)
(39)
The grid must be sufficiently dense to get a good approxi-
mation to the continuous state space. As the dimensionality of
the state space increases, the computational cost of the approach
therefore increases dramatically. If the state space is not finite in
extent, then using a grid-based approach necessitates some trun-
cation of the state space. Another disadvantage of grid-based
methods is that the state space must be predefined and, there-
fore, cannot be partitioned unevenly to give greater resolution
in high probability density regions, unless prior knowledge is
used.
Hidden Markov model (HMM) filters [30], [35], [36], [39]
are an application of such approximate grid-based methods in
a fixed-interval smoothing context and have been used exten-
sively in speech processing. In HMM-based tracking, a common
approach is to use the Viterbi algorithm [18] to calculate the
maximum a posteriori estimate of the path through the trellis,
that is, the sequence of discrete states that maximizes the prob-
ability of the state sequence given the data. Another approach,
due to Baum–Welch [35], is to calculate the probability of each
discrete state at each time epoch given the entire data sequence.4
V. PARTICLE FILTERING METHODS
A. Sequential Importance Sampling (SIS) Algorithm
The sequential importance sampling (SIS) algorithm is
a Monte Carlo (MC) method that forms the basis for most
sequential MC filters developed over the past decades; see [13],
4The Viterbi and Baum–Welch algorithms are frequently applied when the
state space is approximated to be discrete. The algorithms are optimal if and
only if the underlying state space is truly discrete in nature.
178 IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 50, NO. 2, FEBRUARY 2002
[14]. This sequential MC (SMC) approach is known variously
as bootstrap filtering [17], the condensation algorithm [29],
particle filtering [6], interacting particle approximations [10],
[11], and survival of the fittest [24]. It is a technique for imple-
menting a recursive Bayesian filter by MC simulations. The key
idea is to represent the required posterior density function by a
set of random samples with associated weights and to compute
estimates based on these samples and weights. As the number
of samples becomes very large, this MC characterization
becomes an equivalent representation to the usual functional
description of the posterior pdf, and the SIS filter approaches
the optimal Bayesian estimate.
In order to develop the details of the algorithm, let
denote a random measure that characterizes the
posterior pdf , where , is a set
of support points with associated weights ,
and , is the set of all states up to time
. The weights are normalized such that . Then, the
posterior density at can be approximated as
(40)
We therefore have a discrete weighted approximation to the
true posterior, . The weights are chosen using the
principle of importance sampling [3], [12]. This principle relies
on the following. Suppose is a probability density
from which it is difficult to draw samples but for which can
be evaluated [as well as up to proportionality]. In addition,
let , be samples that are easily gener-
ated from a proposal called an importance density. Then, a
weighted approximation to the density is given by
(41)
where
(42)
is the normalized weight of the th particle.
Therefore, if the samples were drawn from an impor-
tance density , then the weights in (40) are defined
by (42) to be
(43)
Returning to the sequential case, at each iteration, one
could have samples constituting an approximation to
and want to approximate
with a new set of samples. If the importance density is chosen
to factorize such that
(44)
then one can obtain samples by augmenting
each of the existing samples with
the new state , . To derive the weight
update equation, is first expressed in terms of
, , and . Note that (4) can
be derived by integrating (45)
(45)
(46)
By substituting (44) and (46) into (43), the weight update
equation can then be shown to be
(47)
Furthermore, if , , , then
the importance density becomes only dependent on and
. This is particularly useful in the common case when only
a filtered estimate of is required at each time step.
From this point on, we will assume such a case, except when
explicitly stated otherwise. In such scenarios, only need be
stored; therefore, one can discard the path and history of
observations . The modified weight is then
(48)
and the posterior filtered density can be approxi-
mated as
(49)
where the weights are defined in (48). It can be shown that as
, the approximation (49) approaches the true posterior
density .
The SIS algorithm thus consists of recursive propagation of
the weights and support points as each measurement is received
sequentially. A pseudo-code description of this algorithm is
given by algorithm 1.
Algorithm 1: SIS Particle Filter
SIS
FOR
— Draw ,
— Assign the particle a weight, ,
according to (48)
END FOR
1) Degeneracy Problem: A common problem with the SIS
particle filter is the degeneracy phenomenon, where after a few
iterations, all but one particle will have negligible weight. It has
ARULAMPALAM et al.: TUTORIAL ON PARTICLE FILTERS 179
been shown [12] that the variance of the importance weights can
only increase over time, and thus, it is impossible to avoid the
degeneracy phenomenon. This degeneracy implies that a large
computational effort is devoted to updating particles whose con-
tribution to the approximation to is almost zero. A
suitable measure of degeneracy of the algorithm is the effective
sample size introduced in [3] and [28] and defined as
Var
(50)
where , is referred to as the
“true weight.” This cannot be evaluated exactly, but an estimate
of can be obtained by
(51)
where is the normalized weight obtained using (47). Notice
that , and small indicates severe degeneracy.
Clearly, the degeneracy problem is an undesirable effect in par-
ticle filters. The brute force approach to reducing its effect is to
use a very large . This is often impractical; therefore, we rely
on two other methods: a) good choice of importance density and
b) use of resampling. These are described next.
2) Good Choice of Importance Density: The first method in-
volves choosing the importance density to min-
imize Var so that is maximized. The optimal impor-
tance density function that minimizes the variance of the true
weights conditioned on and has been shown [12]
to be
(52)
Substitution of (52) into (48) yields
(53)
This choice of importance density is optimal since for a given
, takes the same value, whatever sample is drawn from
, . Hence, conditional on , Var .
This is the variance of the different resulting from different
sampled .
This optimal importance density suffers from two
major drawbacks. It requires the ability to sample from
and to evaluate the integral over the new state.
In the general case, it may not be straightforward to do either
of these things. There are two cases when use of the optimal
importance density is possible.
The first case is when is a member of a finite set. In
such cases, the integral in (53) becomes a sum, and sampling
from is possible. An example of an application
when is a member of a finite set is a Jump–Markov linear
system for tracking maneuvering targets [15], whereby the dis-
crete modal state (defining the maneuver index) is tracked using
a particle filter, and (conditioned on the maneuver index) the
continuous base state is tracked using a Kalman filter.
Analytic evaluation is possible for a second class of models
for which is Gaussian [12], [9]. This can occur
if the dynamics are nonlinear and the measurements linear. Such
a system is given by
(54)
(55)
where
(56)
(57)
and : is a nonlinear function, is an
observation matrix, and and are mutually independent
i.i.d. Gaussian sequences with and . Defining
(58)
(59)
one obtains
(60)
and
(61)
For many other models, such analytic evaluations are not
possible. However, it is possible to construct suboptimal
approximations to the optimal importance density by using
local linearization techniques [12]. Such linearizations use
an importance density that is a Gaussian approximation to
. Another approach is to estimate a Gaussian ap-
proximation to using the unscented transform
[40]. The authors’ opinion is that the additional computational
cost of using such an importance density is often more than
offset by a reduction in the number of samples required to
achieve a certain level of performance.
Finally, it is often convenient to choose the importance den-
sity to be the prior
(62)
Substitution of (62) into (48) then yields
(63)
This would seem to be the most common choice of impor-
tance density since it is intuitive and simple to implement. How-
ever, there are a plethora of other densities that can be used, and
as illustrated by Section VI, the choice is the crucial design step
in the design of a particle filter.
3) Resampling: The second method by which the effects of
degeneracy can be reduced is to use resampling whenever a sig-
nificant degeneracy is observed (i.e., when falls below
some threshold ). The basic idea of resampling is to elimi-
nate particles that have small weights and to concentrate on par-
ticles with large weights. The resampling step involves gener-
ating a new set by resampling (with replacement)
times from an approximate discrete representation of
given by
(64)
so that . The resulting sample is in fact
an i.i.d. sample from the discrete density (64); therefore, the
180 IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 50, NO. 2, FEBRUARY 2002
weights are now reset to . It is possible to imple-
ment this resampling procedure in operations by sam-
pling ordered uniforms using an algorithm based on order
statistics [6], [37]. Note that other efficient (in terms of reduced
MC variation) resampling schemes, such as stratified sampling
and residual sampling [28], may be applied as alternatives to this
algorithm. Systematic resampling [25] is the scheme preferred
by the authors [since it is simple to implement, takes
time, and minimizes the MC variation], and its operation is de-
scribed in Algorithm 2, where is the uniform distribution
on the interval (inclusive of the limits). For each resam-
pled particle , this resampling algorithm also stores the index
of its parent, which is denoted by . This may appear unneces-
sary here (and is), but it proves useful in Section V-B2.
A generic particle filter is then as described by Algorithm 3.
Although the resampling step reduces the effects of the de-
generacy problem, it introduces other practical problems. First,
it limits the opportunity to parallelize since all the particles must
be combined. Second, the particles that have high weights
are statistically selected many times. This leads to a loss of di-
versity among the particles as the resultant sample will contain
many repeated points. This problem, which is known as sample
impoverishment, is severe in the case of small process noise.
In fact, for the case of very small process noise, all particles
will collapse to a single point within a few iterations.5 Third,
since the diversity of the paths of the particles is reduced, any
smoothed estimates based on the particles’ paths degenerate.6
Schemes exist to counteract this effect. One approach considers
the states for the particles to be predetermined by the forward
filter and then obtains the smoothed estimates by recalculating
the particles’ weights via a recursion from the final to the first
time step [16]. Another approach is to use MCMC [5].
Algorithm 2: Resampling Algorithm
, RESAMPLE
Initialize the CDF:
FOR
— Construct CDF:
END FOR
Start at the bottom of the CDF:
Draw a starting point:
FOR
— Move along the CDF:
— WHILE
— END WHILE
— Assign sample:
— Assign weight:
— Assign parent:
END FOR
5If the process noise is zero, then using a particle filter is not entirely ap-
propriate. Particle filtering is a method well suited to the estimation of dynamic
states. If static states, which can be regarded as parameters, need to be estimated
then alternative approaches are necessary [7], [27].
6Since the particles actually represent paths through the state space, by storing
the trajectory taken by each particle, fixed-lag and fixed-point smoothed esti-
mates of the state can be obtained [4].
Algorithm 3: Generic Particle Filter
PF ,
FOR
— Draw
— Assign the particle a weight, ,
according to (48)
END FOR
Calculate total weight: SUM
FOR
— Normalize:
END FOR
Calculate using (51)
IF
— Resample using algorithm 2:
RESAMPLE
END IF
There have been some systematic techniques proposed
recently to solve the problem of sample impoverishment. One
such technique is the resample-move algorithm [19], which is
not be described in detail in this paper. Although this technique
draws conceptually on the same technologies of importance
sampling-resampling and MCMC sampling, it avoids sample
impoverishment. It does this in a rigorous manner that ensures
the particles asymtotically approximate samples from the
posterior and, therefore, is the method of choice of the authors.
An alternative solution to the same problem is regularization
[31], which is discussed in Section V-B3. This approach
is frequently found to improve performance, despite a less
rigorous derivation and is included here in preference to the
resample-move algorithm since its use is so widespread.
4) Techniques for Circumventing the Use of a Suboptimal Im-
portance Density: It is often the case that a good importance
density is not available. For example, if the prior is
used as the importance density and is a much broader distribu-
tion than the likelihood , then only a few particles will
have a high weight. Methods exist for encouraging the particles
to be in the right place; the use of bridging densities [8] and
progressive correction [33] both introduce intermediate distri-
butions between the prior and likelihood. The particles are then
reweighted according to these intermediate distributions and re-
sampled. This “herds” the particles into the right part of the state
space.
Another approach known as partitioned sampling [29] is
useful if the likelihood is very peaked but can be factorized
into a number of broader distributions. Typically, this occurs
because each of the partitioned distributions are functions of
some (not all) of the states. By treating each of these partitioned
distributions in turn and resampling on the basis of each such
partitioned distribution, the particles are again herded toward
the peaked likelihood.
B. Other Related Particle Filters
The sequential importance sampling algorithm presented in
Section V-A forms the basis for most particle filters that have
ARULAMPALAM et al.: TUTORIAL ON PARTICLE FILTERS 181
been developed so far. The various versions of particle filters
proposed in the literature can be regarded as special cases of
this general SIS algorithm. These special cases can be derived
from the SIS algorithm by an appropriate choice of importance
sampling density and/or modification of the resampling step.
Below, we present three particle filters proposed in the literature
and show how these may be derived from the SIS algorithm. The
particle filters considered are
i) sampling importance resampling (SIR) filter;
ii) auxiliary sampling importance resampling (ASIR) filter;
iii) regularized particle filter (RPF).
1) Sampling Importance Resampling Filter: The SIR filter
proposed in [17] is an MC method that can be applied to recur-
sive Bayesian filtering problems. The assumptions required to
use the SIR filter are very weak. The state dynamics and mea-
surement functions and in (1) and (2), respec-
tively, need to be known, and it is required to be able to sample
realizations from the process noise distribution of and
from the prior. Finally, the likelihood function needs
to be available for pointwise evaluation (at least up to propor-
tionality). The SIR algorithm can be easily derived from the SIS
algorithm by an appropriate choice of i) the importance den-
sity, where is chosen to be the prior density
, and ii) the resampling step, which is to be applied
at every time index.
The above choice of importance density implies that we need
samples from . A sample can be
generated by first generating a process noise sample
and setting , , where is the
pdf of . For this particular choice of importance density, it
is evident that the weights are given by
(65)
However, noting that resampling is applied at every time index,
we have ; therefore
(66)
The weights given by the proportionality in (66) are normalized
before the resampling stage. An iteration of the algorithm is then
described by Algorithm 4.
As the importance sampling density for the SIR filter is inde-
pendent of measurement , the state space is explored without
any knowledge of the observations. Therefore, this filter can be
inefficient and is sensitive to outliers. Furthermore, as resam-
pling is applied at every iteration, this can result in rapid loss of
diversity in particles. However, the SIR method does have the
advantage that the importance weights are easily evaluated and
that the importance density can be easily sampled.
Algorithm 4: SIR Particle Filter
SIR
FOR
— Draw
— Calculate
END FOR
Calculate total weight: SUM
FOR
— Normalize:
END FOR
Resample using algorithm 2:
— RESAMPLE ,
2) Auxiliary Sampling Importance Resampling Filter: The
ASIR filter was introduced by Pitt and Shephard [34] as a variant
of the standard SIR filter. This filter can be derived from the SIS
framework by introducing an importance density ,
which samples the pair , where refers to the index
of the particle at .
By applying Bayes’ rule, a proportionality can be derived for
as
(67)
The ASIR filter operates by obtaining a sample from the joint
density and then omitting the indices in the pair
to produce a sample from the marginalized
density . The importance density used to draw the
sample is defined to satisfy the proportionality
(68)
where is some characterization of , given . This could
be the mean, in which case, or a sample
. By writing
(69)
and defining
(70)
it follows from (68) that
(71)
The sample is then assigned a weight propor-
tional to the ratio of the right-hand side of (67) to (68)
(72)
The algorithm then becomes that described by Algorithm 5.
Algorithm 5: Auxiliary Particle Filter
APF
FOR
— Calculate
— Calculate .
END FOR
Calculate total weight: SUM
FOR
— Normalize:
END FOR
Resample using algorithm 2:
— RESAMPLE
FOR
— Draw ,
as in the SIR filter.
— Assign weight using (72)
182 IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 50, NO. 2, FEBRUARY 2002
END FOR
Calculate total weight: SUM
FOR
— Normalize:
END FOR
Although unnecessary, the original ASIR filter as proposed
in [34] consisted of one more step, namely, a resampling stage,
to produce an i.i.d. sample with equal weights.
Compared with the SIR filter, the advantage of the ASIR filter
is that it naturally generates points from the sample at ,
which, conditioned on the current measurement, are most likely
to be close to the true state. ASIR can be viewed as resampling
at the previous time step, based on some point estimates that
characterize . If the process noise is small so that
is well characterized by , then ASIR is often not
so sensitive to outliers as SIR, and the weights are more even.
However, if the process noise is large, a single point does not
characterize well, and ASIR resamples based on a
poor approximation of . In such scenarios, the use
of ASIR then degrades performance.
3) Regularized Particle Filter: Recall that resampling was
suggested in Section V-B1 as a method to reduce the degen-
eracy problem, which is prevalent in particle filters. However, it
was pointed out that resampling in turn introduced other prob-
lems and, in particular, the problem of loss of diversity among
the particles. This arises due to the fact that in the resampling
stage, samples are drawn from a discrete distribution rather than
a continuous one. If this problem is not addressed properly, it
may lead to “particle collapse,” which is a severe case of sample
impoverishment where all particles occupy the same point
in the state space, giving a poor representation of the posterior
density. A modified particle filter known as the regularized par-
ticle filter (RPF) was proposed [31] as a potential solution to the
above problem.
The RPF is identical to the SIR filter, except for the resam-
pling stage. The RPF resamples from a continuous approxima-
tion of the posterior density , whereas the SIR resam-
ples from the discrete approximation (64). Specifically, in the
RPF, samples are drawn from the approximation
(73)
where
(74)
is the rescaled Kernel density , is the Kernel band-
width (a scalar parameter), is the dimension of the state
vector , and , are normalized weights. The
Kernel density is a symmetric probability density function such
that
The Kernel and bandwidth are chosen to minimize the
mean integrated square error (MISE) between the true posterior
density and the corresponding regularized empirical representa-
tion in (73), which is defined as
MISE (75)
where denotes the approximation to given by
the right-hand side of (73).7 In the special case of all the samples
having the same weight, the optimal choice of the kernel is the
Epanechnikov kernel [31]
if
otherwise
(76)
where is the volume of the unit hypersphere in . Fur-
thermore, when the underlying density is Gaussian with a unit
covariance matrix, the optimal choice for the bandwidth is [31]
(77)
(78)
Algorithm 6: Regularized Particle Filter
RPF
FOR
— Draw
— Assign the particle a weight, ,
according to (48)
END FOR
Calculate total weight: SUM
FOR
— Normalize:
END FOR
Calculate using (51)
IF
— Calculate the empirical covariance
matrix of ,
— Compute such that .
— Resample using algorithm 2:
RESAMPLE ,
— FOR
Draw from the Epanechnikov
Kernel
— END FOR
END IF
Alhough the results of (76) and (77) and (78) are optimal only
in the special case of equally weighted particles and underlying
Gaussian density, these results can still be used in the general
case to obtain a suboptimal filter. One iteration of the RPF is de-
scribed by Algorithm 6. The RPF only differs from the generic
particle filter described by Algorithm 3 as a result of the addi-
tion of the regularization steps when conducting the resampling.
Note also that the calculation of the empirical covariance matrix
7As observed by one of the anonymous reviewers, it is worth noting that the
use of the Kernel approximation become increasingly less appropriate as the
dimensionality of the state increases.
ARULAMPALAM et al.: TUTORIAL ON PARTICLE FILTERS 183
TABLE I
TABLE OF THE ALGORITHMS USED, THE SECTIONS OF THE ARTICLE,
AND FIGURES THAT RELATE TO THE ALGORITHMS, AND RMSE VALUES
(AVERAGED OVER 100 MC RUNS)
is carried out prior to the resampling and is therefore a func-
tion of both the and . This is done since the accuracy of
any estimate of a function of the distribution can only decrease
as a result of the resampling. If quantities such as the mean and
covariance of the samples are to be output, then these should be
calculated prior to resampling.
By following the above procedure, we generate an i.i.d.
random sample drawn from (73).
In terms of complexity, the RPF is comparable with SIR since
it only requires additional generations from the kernel
at each time step. The RPF has the theoretic disadvantage that
the samples are no longer guaranteed to asymtotically approx-
imate those from the posterior. In practical scenarios, the RPF
performance is better than the SIR in cases where sample im-
poverishment is severe, for example, when the process noise is
small.
VI. EXAMPLE
Here, we consider the following set of equations as an illus-
trative example:
(79)
(80)
or equivalently
(81)
(82)
where
(83)
and where and are zero mean Gaussian random
variables with variances and , respectively. We use
and . This example has been analyzed
before in many publications [5], [17], [25].
We consider the performance of the algorithms detailed in
Table I. In order to qualitatively gauge performance and dis-
cuss resulting issues, we consider one exemplar run. In order to
quantify performance, we use the traditional measure of per-
formance: the Root Mean Squared Error (RMSE). It should
be noted that this measure of performance is not exceptionally
meaningful for this multimodal problem. However, it has been
used extensively in the literature and is included here for that
reason and because it facilitates quantitative comparison.
For reference, the true states for the exemplar run are shown
in Fig. 1 and the measurements in Fig. 2.
Fig. 1. Figure of the true values of the state x as a function of k for the
exemplar run.
Fig. 2. Figure of the measurements z of the states x shown in Fig. 1 for the
same exemplar run.
The approximate grid-based method uses 50 states with cen-
ters equally spaced on . All the particle filters have 50
particles and employ resampling at every time step ( ).
The auxiliary particle filter uses . The regu-
larized particle filter uses the kernel and bandwidth described in
Section V-B3.
To visualize the densities inferred by the approximate grid-
based and particle filters, the total probability mass at any time
in each of 50 equally spaced regions on is shown as
images in Figs. 5–9. At any given time (and in any vertical slice
through the image), darker regions represent higher probability
than lighter regions. A graduated scale relating intensity to prob-
ability mass in a pixel is shown next to each image.
A. EKF
The EKFs local linearization and Gaussian approxima-
tion are not a sufficient description of the nonlinear and
non-Gaussian nature of the example. Once the EKF cannot
adequately approximate the bimodal nature of the underlying
184 IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 50, NO. 2, FEBRUARY 2002
Fig. 3. Evolution of the EKFs mean estimate of the state.
Fig. 4. Evolution of the upper and lower 2 positions of the state as estimated
by the EKF (dotted) with the true state also shown (solid).
posterior, the Gaussian approximation fails—the EKF is prone
to either choosing the “wrong” mode or just sitting on the
average between the modes. As a result of this inability to
adequately approximate the density, the linearization approxi-
mation becomes poor.
This can be seen from Fig. 3. The mean of the filter is rarely
close to the true state. Were the density to be Gaussian, one
would expect the state to be within two standard deviations of
the mean approximately 95% of the time. From Fig. 4, it is ev-
ident that there are times when the distribution is sufficiently
broad to capture the true state in this region but that there are
also times when the filter becomes highly overconfident of a bi-
ased estimate of the state. The implication of this is that it is very
difficult to detect inconsistent EKF errors automatically online.
The RMSE measure indicates that the EKF is the least accu-
rate of the algorithms at approximating the posterior. The ap-
proximations made by the EKF are inappropriate in this ex-
ample.
Fig. 5. Image representing evolution of probability density for approximate
grid-based filter.
B. Approximate Grid-Based Filter
This example is low dimensional, and therefore, one would
expect that an approximate grid-based approach would perform
well. Fig. 5 shows this is indeed the case. The grid-based ap-
proximation is able to model the multimodality of the problem.
Using the approximate grid-based filter rather than an EKF
yields a marked reduction in RMS errors. A particle filter with
particles conducts operations per iteration, whereas
an approximate grid-based filter carries out operations
with cells. It is therefore surprising that the RMS errors for
the approximate grid are larger than those of the particle filter.
The authors suspect that this is an artifact of the grid being fixed;
the resolution of the algorithm is predefined, and the fixed posi-
tion of the grid points means that the grid points near 25 con-
tribute significantly to the error when the true state is far from
these values.
C. SIR Particle Filter
Using the prior distribution as the importance density is in
some sense regarded as a standard SIR particle filter and, there-
fore, is an appropriate particle filter algorithm with which to
begin. As can be seen from Fig. 6, the SIR particle filter gives
disappointing results with the low number of particles used here.
The speckled appearance of the figure is a result of sampling a
low number of particles from the (broad) prior. It is an artifact
resulting from the inadequate amount of sampling.
The RMSE metric shows a marginal improvement over the
approximate grid-based filter. To achieve smaller errors, one
could simply increase the number of particles, but here, we will
now investigate the effect of using the alternative particle filter
algorithms described up to this point.
D. Auxiliary Particle Filter
One way to reduce errors might be that the proposed par-
ticle positions are chosen badly. One might therefore think that
choosing the proposed particles in a more intelligent manner
would yield better results. An auxiliary particle filter would then
ARULAMPALAM et al.: TUTORIAL ON PARTICLE FILTERS 185
Fig. 6. Image representing evolution of probability density for SIR particle
filter.
Fig. 7. Image representing evolution of probability density for auxiliary
particle filter.
seem to be an appropriate candidate replacement algorithm for
SIR. Here, we have as a sample from .
As shown by Fig. 7, for this example, the auxiliary particle
filter performs well. There is arguably less speckle in Fig. 7
than in Fig. 6, and the probability mass appears to be better
concentrated around the true state. However, one might think
this problem is not very well suited to an auxiliary particle filter
since the prior is often much broader than the likelihood. When
the prior is broad, those particles with a noise realization that
happens to have a high likelihood are resampled many times.
There is no guarantee that other samples from the prior will
also lie in the same region of the state space since only a single
point is being used to characterize the filtered density for each
particle.
The RMS errors are slightly reduced from those for SIR.
Fig. 8. Image representing evolution of probability density for regularized
particle filter.
E. Regularized Particle Filter
Using the regularized particle filter results in a smoothing of
the approximation to the posterior. This is apparent from Fig. 8.
The speckle is reduced and the peaks broadened when compared
with the previous particle filters’ images.
The regularized particle filter gives very similar RMS errors
to the SIR particle filter. The regularization does not result in a
significant reduction in errors for this data set.
F. “Likelihood” Particle Filter
All the aforementioned particle filters share the prior as a pro-
posal density. For this example, much of the time, the likelihood
is far tighter than the prior. As a result, the posterior is closer
in similarity to the likelihood than to the prior. The importance
density is an approximation to the posterior. Therefore, using
a better approximation based on the likelihood, rather than the
prior, can be expected to improve performance.
Fig. 9 shows that the use of such an importance density (see
the Appendix for details) yields a reduction in speckle and that
the peaks of the density are closer on average to the true state
than for any of the other particle filters.
The RMS errors are similar to those for the Auxiliary particle
filter.
G. Crucial Step in the Application of a Particle Filter
The RMS errors indicate that in highly nonlinear environ-
ments, a nonlinear filter such as an approximate grid-based filter
or particle filter offers an improvement in performance over an
EKF. This improvement results from approximating the density
rather than the models.
When using a particle filter, one can often expect and fre-
quently achieve an improvement in performance by using far
more particles or alternatively by employing regularization or
using an auxiliary particle filter. For this example, a slight im-
provement in RMS errors is possible by using an importance
density other than . The authors assert that an im-
portance density tuned to a particular problem will yield an ap-
propriate trade off between the number of particles and the com-
186 IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 50, NO. 2, FEBRUARY 2002
Fig. 9. Image representing evolution of probability density for “likelihood”
particle filter.
putational expense necessary for each particle, giving the best
qualitative performance with affordable computational effort.
The crucial point to convey is that all the refinements of
the particle filter assume that the choice of importance density
has already been made. Choosing the importance density to be
well suited to a given application requires careful thought. The
choice made is crucial.
VII. CONCLUSIONS
For a particular problem, if the assumptions of the Kalman
filter or grid-based filters hold, then no other algorithm can out-
perform them. However, in a variety of real scenarios, the as-
sumptions do not hold, and approximate techniques must be em-
ployed.
The EKF approximates the models used for the dynamics and
measurement process in order to be able to approximate the
probability density by a Gaussian. Approximate grid-based fil-
ters approximate the continuous state space as a set of discrete
regions. This necessitates the predefinition of these regions and
becomes prohibitively computationally expensive when dealing
with high-dimensional state spaces [3]. Particle filtering approx-
imates the density directly as a finite number of samples. A
number of different types of particle filter exist, and some have
been shown to outperform others when used for particular ap-
plications. However, when designing a particle filter for a par-
ticular application, it is the choice of importance density that is
critical.
APPENDIX
IMPORTANCE DENSITY FOR “LIKELIHOOD” PARTICLE FILTER
This Appendix describes the importance density for the “like-
lihood” particle filter, which is intended to illustrate the crucial
nature of the choice of importance density in a particle filter.
This importance density is not intended to be generically appli-
cable but to be one chosen to work well for the specific problem
and parameters described in Section VI.
To keep the notation simple, throughout this Appendix,
. For a uniform prior on , the density can be
written by Bayes’ rule as
otherwise.
(84)
We can then sample [samples are repeat-
edly drawn from until one is drawn such
that , i.e., one such that ]. Then,
can be chosen to be a pair of delta functions
(85)
This can then be used to form a “Likelihood” based impor-
tance density that samples conditional on and indepen-
dently from
(86)
The weight of the sample can be calculated according to (47)
(87)
(88)
(89)
Now, , and are constant; there-
fore, they disappear, leaving
(90)
Now, the ratio of to needs careful consid-
eration. Although the values of and might
be initially thought to be proportional, they are probability den-
sities defined with respect to a different measure (i.e., a dif-
ferent parameterization of the space). Since integrates
to unity over while integrates to unity over ,
the ratio of the probability densities is then proportional to the
inverse of the ratio of the lengths, and . The ratio of
to is the determinant of the Jacobian of the
transformation from to
(91)
An expression for the weight is then forthcoming:
(92)
The particle filter that results from this sampling procedure is
given in Algorithm 7.
Therefore, rather than draw samples from the state evolu-
tion distribution and then weight them according to their likeli-
hood, samples are drawn from the likelihood and then assigned
weights on the basis of the state evolution distribution.
ARULAMPALAM et al.: TUTORIAL ON PARTICLE FILTERS 187
Algorithm 7: “Likelihood” Particle Filter
LPF
FOR
— REPEAT
Draw
— UNTIL
— IF
— ELSE
— END IF
—
END FOR
Calculate total weight: SUM
FOR
— Normalize:
END FOR
Calculate using (51)
IF
— Resample using algorithm 2:
RESAMPLE
END IF
ACKNOWLEDGMENT
The authors would like to thank the anonymous reviewers
and the editors of this Special Issue for their many helpful sug-
gestions, which have greatly improved the presentation of this
paper. The authors would also like to thank various funding
sources who have contributed to this research. N. Gordon would
like to thank QinetiQ Ltd.
REFERENCES
[1] S. Arulampalam and B. Ristic, “Comparison of the particle filter with
range parameterized and modified polar EKF’s for angle-only tracking,”
Proc. SPIE, vol. 4048, pp. 288–299, 2000.
[2] Y. Bar-Shalom and X. R. Li, Multitarget–Multisensor Tracking: Princi-
ples and Techniques. Urbana, IL: YBS, 1995.
[3] N. Bergman, “Recursive Bayesian estimation: Navigation and tracking
applications,” Ph.D. dissertation, Linköping Univ., Linköping, Sweden,
1999.
[4] N. Bergman, A. Doucet, and N. Gordon, “Optimal estimation and
Cramer–Rao bounds for partial non-Gaussian state space models,” Ann.
Inst. Statist. Math., vol. 53, no. 1, pp. 97–112, 2001.
[5] B. P. Carlin, N. G. Polson, and D. S. Stoffer, “A Monte Carlo approach to
nonnormal and nonlinear state-space modeling,” J. Amer. Statist. Assoc.,
vol. 87, no. 418, pp. 493–500, 1992.
[6] J. Carpenter, P. Clifford, and P. Fearnhead, “Improved particle filter for
nonlinear problems,” Proc. Inst. Elect. Eng., Radar, Sonar, Navig., 1999.
[7] T. Clapp, “Statistical methods for the processing of communications
data,” Ph.D. dissertation, Dept. Eng., Univ. Cambridge, Cambridge,
U.K., 2000.
[8] T. Clapp and S. Godsill, “Improvement strategies for Monte Carlo par-
ticle filters,” in Sequential Monte Carlo Methods in Practice, A. Doucet,
J. F. G. de Freitas, and N. J. Gordon, Eds. New York: Springer-Verlag,
2001.
[9] P. Del Moral, “Measure valued processes and interacting particle sys-
tems. Application to nonlinear filtering problems,” Ann. Appl. Probab.,
vol. 8, no. 2, pp. 438–495, 1998.
[10] D. Crisan, P. Del Moral, and T. J. Lyons, “Non-linear filtering using
branching and interacting particle systems,” Markov Processes Related
Fields, vol. 5, no. 3, pp. 293–319, 1999.
[11] P. Del Moral, “Non-linear filtering: Interacting particle solution,”
Markov Processes Related Fields, vol. 2, no. 4, pp. 555–580.
[12] A. Doucet, “On sequential Monte Carlo methods for Bayesian filtering,”
Dept. Eng., Univ. Cambridge, UK, Tech. Rep., 1998.
[13] A. Doucet, J. F. G. de Freitas, and N. J. Gordon, “An introduction to
sequential Monte Carlo methods,” in Sequential Monte Carlo Methods
in Practice, A. Doucet, J. F. G. de Freitas, and N. J. Gordon, Eds. New
York: Springer-Verlag, 2001.
[14] A. Doucet, S. Godsill, and C. Andrieu, “On sequential Monte Carlo sam-
pling methods for Bayesian filtering,” Statist. Comput., vol. 10, no. 3, pp.
197–208.
[15] A. Doucet, N. Gordon, and V. Krishnamurthy, “Particle filters for state
estimation of jump Markov linear systems,” IEEE Trans. Signal Pro-
cessing, vol. 49, pp. 613–624, Mar. 2001.
[16] S. Godsill, A. Doucet, and M. West, “Methodology for Monte Carlo
smoothing with application to time-varying autoregressions,” in Proc.
Int. Symp. Frontiers Time Series Modeling, 2000.
[17] N. Gordon, D. Salmond, and A. F. M. Smith, “Novel approach to non-
linear and non-Gaussian Bayesian state estimation,” Proc. Inst. Elect.
Eng., F, vol. 140, pp. 107–113, 1993.
[18] G. D. Forney, “The Viterbi algorithm,” Proc. IEEE, vol. 61, pp. 268–278,
Mar. 1973.
[19] W. R. Gilks and C. Berzuini, “Following a moving target—Monte Carlo
inference for dynamic Bayesian models,” J. R. Statist. Soc. B, vol. 63,
pp. 127–146, 2001.
[20] R. E. Helmick, D. Blair, and S. A. Hoffman, “Fixed-interval smoothing
for Markovian switching systems,” IEEE Trans. Inform. Theory, vol. 41,
pp. 1845–1855, Nov. 1995.
[21] Y. C. Ho and R. C. K. Lee, “A Bayesian approach to problems in sto-
chastic estimation and control,” IEEE Trans. Automat. Contr., vol. AC-9,
pp. 333–339, 1964.
[22] A. H. Jazwinski, Stochastic Processes and Filtering Theory. New
York: Academic, 1970.
[23] S. Julier, “A skewed approach to filtering,” Proc. SPIE, vol. 3373, pp.
271–282, 1998.
[24] K. Kanazawa, D. Koller, and S. J. Russell, “Stochastic simulation al-
gorithms for dynamic probabilistic networks,” in Proc. Eleventh Annu.
Conf. Uncertainty AI, 1995, pp. 346–351.
[25] G. Kitagawa, “Monte Carlo filter and smoother for non-Gaussian non-
linear state space models,” J. Comput. Graph. Statist., vol. 5, no. 1, pp.
1–25, 1996.
[26] G. Kitagawa and W. Gersch, Smoothness Priors Analysis of Time Se-
ries. New York: Springer-Verlag, 1996.
[27] J. Liu and M. West, “Combined parameter and state estimation in sim-
ulation-based filtering,” in Sequential Monte Carlo Methods in Prac-
tice, A. Doucet, J. F. G. de Freitas, and N. J. Gordon, Eds. New York:
Springer-Verlag, 2001.
[28] J. S. Liu and R. Chen, “Sequential Monte Carlo methods for dynamical
systems,” J. Amer. Statist. Assoc., vol. 93, pp. 1032–1044, 1998.
[29] J. MacCormick and A. Blake, “A probabilistic exclusion principle for
tracking multiple objects,” in Proc. Int. Conf. Comput. Vision, 1999, pp.
572–578.
[30] F. Martinerie and P. Forster, “Data association and tracking using hidden
Markov models and dynamic programming,” in Proc. Conf. ICASSP,
1992.
[31] C. Musso, N. Oudjane, and F. LeGland, “Improving regularised particle
filters,” in Sequential Monte Carlo Methods in Practice, A. Doucet, J.
F. G. de Freitas, and N. J. Gordon, Eds. New York: Springer-Verlag,
2001.
[32] M. Orton and A. Marrs, “Particle filters for tracking with out-of-se-
quence measurements,” IEEE Trans. Aerosp. Electron. Syst., submitted
for publication.
[33] N. Oudjane and C. Musso, “Progressive correction for regularized par-
ticle filters,” in Proc. 3rd Int. Conf. Inform. Fusion, 2000.
[34] M. Pitt and N. Shephard, “Filtering via simulation: Auxiliary particle
filters,” J. Amer. Statist. Assoc., vol. 94, no. 446, pp. 590–599, 1999.
[35] L. R. Rabiner, “A tutorial on hidden Markov models and selected appli-
cations in speech recognition,” Proc. IEEE, vol. 77, no. 2, pp. 257–285,
Feb. 1989.
[36] L. R. Rabiner and B. H. Juang, “An introduction to hidden Markov
models,” IEEE Acoust., Speech, Signal Processing Mag., pp. 4–16, Jan.
1986.
[37] B. Ripley, Stochastic Simulation. New York: Wiley, 1987.
[38] R. H. Shumway and D. S. Stoffer, “An approach to time series smoothing
and forecasting using the EM algorithm,” J. Time Series Anal., vol. 3,
no. 4, pp. 253–264, 1982.
[39] R. L. Streit and R. F. Barrett, “Frequency line tracking using hidden
Markov models,” IEEE Trans. Acoust., Speech, Signal Processing, vol.
38, pp. 586–598, Apr. 1990.
188 IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 50, NO. 2, FEBRUARY 2002
[40] R. van der Merwe, A. Doucet, J. F. G. de Freitas, and E. Wan, “The
unscented particle filter,” Adv. Neural Inform. Process. Syst., Dec. 2000.
[41] M. West and J. Harrison, “Bayesian forecasting and dynamic models,”
in Springer Series in Statistics, 2nd ed. New York: Springer-Verlag,
1997.
[42] E. A. Wan and R. Van der Merwe, “The unscented Kalman filter for
nonlinear estimation,” in Proc. Symp. Adaptive Syst. Signal Process.,
Commun. Contr., Lake Louise, AB, Canada, Oct. 2000.
[43] , “The unscented Kalman filter,” in Kalman Filtering and Neural
Networks. New York: Wiley, 2001, ch. 7, to be published.
M. Sanjeev Arulampalam received the B.Sc.
degree in mathematical sciences and the B.E. degree
with first-class honors in electrical and electronic
engineering from the University of Adelaide,
Adelaide, Australia, in 1991 and 1992, respectively.
In 1993, he won a Telstra Postgraduate Fellowship
award and received the Ph.D. degree in electrical
and electronic engineering at the University of
Melbourne, Parkville, Australia, in 1997. His
doctoral dissertation was “Performance analysis of
hidden Markov model based tracking algorithms.”
In 1992, he joined the staff of Computer Sciences of Australia (CSA), where
he worked as a Software Engineer in the Safety Critical Software Systems
Group. In 1998, he joined the Defence Science and Technology Organization
(DSTO), Canberra, Australia, as a Research Scientist in the Surveillance
Systems Division, where he carried out research in many aspects of airborne
target tracking with a particular emphasis on tracking in the presence of
deception jamming. His research interests include estimation theory, target
tracking, and sequential Monte Carlo methods.
Dr. Arulampalam won the Anglo–Australian postdoctoral fellowship,
awarded by the Royal Academy of Engineering, London, in 1998.
Simon Maskell received the B.A. degree in engi-
neering and the M.Eng. degree in electronic and
information sciences from Cambridge University
Engineering Department (CUED), Cambridge, U.K.,
both in 1999. He currently pursuing the Ph.D. degree
at CUED.
He is with the Pattern and Information Processing
Group, QinetiQ Ltd., Malvern, U.K. His research
interested include Bayesian inference, signal
processing, tracking, and data fusion, with particular
emphasis on the application of particle filters.
Mr. Maskell was awarded a Royal Commission for the Exhibition of 1851
Industrial Fellowship in 2001.
Neil Gordon received the B.Sc. degree in math-
ematics and physics from Nottingham University,
Nottingham, U.K., in 1988 and the Ph.D. degree
in statistics from Imperial College, University of
London, London, U.K., in 1993.
He is currently with the Pattern and Information
Processing Group, QinetiQ Ltd., Malvern, U.K.
His research interests include Bayesian estimation
and sequential Monte Carlo methods (a.k.a. particle
filters) with a particular emphasis on target tracking
and missile guidance. He has co-edited, with A.
Doucet and J. F. G. de Freitas, Sequential Monte Carlo Methods in Practice
(New York: Springer-Verlag).
Tim Clapp received the B.A., M.Eng., and Ph.D. de-
grees from the Signal Processing and Communica-
tions Group, Cambridge University Engineering De-
partment, Cambridge, U.K.
His research interests include blind equalization,
Markov chain Monte Carlo techniques, and particle
filters. He is currently involved with telecommuni-
cations satellite system design for the Payload Pro-
cessor Group, Astrium Ltd., Stevenage, U.K.

