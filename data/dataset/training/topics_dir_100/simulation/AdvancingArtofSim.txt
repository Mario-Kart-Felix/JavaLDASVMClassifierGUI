 1 
Forthcoming in Handbook of Research on Nature Inspired Computing for Economy and 
Management, Jean-Philippe Rennard (Ed.).Hersey, PA: Idea Group. 
 
 
 
 
Advancing the Art of Simulation in the Social Sciences 
 
Robert Axelrod 
Gerald R. Ford School of Public Policy, 
University of Michigan, 
Ann Arbor, MI 48109, USA 
axe@umich.edu 
 
May 17, 2005 
 
 
 
 
 
 
Abstract. Advancing the state of the art of simulation in the social sciences requires 
appreciating the unique value of simulation as a third way of doing science, in contrast to 
both induction and deduction. Simulation can be an effective tool for discovering 
surprising consequences of simple assumptions. This essay offers advice for doing 
simulation research, focusing on the programming of a simulation model, analyzing the 
results sharing the results, and replicating other people’s simulations. Finally, suggestions 
are offered for building of a community of social scientists who do simulation. 
 
 
Note: This is an updated version of an article published in Journal of the Japanese 
Society for Management Information Systems, Vol. 12, No. 3, Dec. 2003. The article was 
originally published in Rosario Conte, Rainer Hegselmann and Pietro Terna (eds.), 
Simulating Social Phenomena (Berlin: Springer-Verlag, 1997), pp. 21-40.  Reprinted 
with permission of the Japanese Society for Management Information Systems and 
Springer-Verlag.
 2 
1. Simulation as a Young Field1 
 
Simulation is a young and rapidly growing field in the social sciences.2  As in most 
young fields, the promise is greater than the proven accomplishments. The purpose of 
this paper is to suggest what it will take for the field to become mature so that the 
potential contribution of simulation to the social sciences can be realized. 
 
One indication of the youth of the field is the extent to which published work in 
simulation is very widely dispersed. Consider these observations from the Social Science 
Citation Index of 2002. 
 
1. There were 77 articles with "simulation" in the title."3 Clearly, simulation is an 
important field. But these 77 articles were scattered among 55 different journals. 
Moreover, only two of the 55 journals had more than two of these articles.  The full set of 
journals that published articles with “simulation” in the title come from virtually all 
disciplines of the social sciences, including anthropology, business, economics, human 
evolution, environmental planning, law, information, organization theory, political 
science, and public policy. Searching by a key word in the title is bound to locate only a 
fraction of the articles using simulation, but the dispersion of these articles does 
demonstrate one of the great strengths as well as one of the great weaknesses of this 
young field. The strength of simulation is applicability in virtually all of the social 
sciences. The weakness of simulation is that it has little identity as a field in its own right. 
 
2. To take another example, consider the articles published by the 26 authors of a 
colloquium on agent-based modeling sponsored by the National Academy of Sciences 
(USA) and held October 4-6, 2001.4 In 2002 they published 17 articles that were indexed 
by the Social Science Citation Index. These 17 articles were in 13 different journals. In 
fact, of the 26 authors, only two published in the same journal. While this dispersion 
shows how diverse the field really is, it also reinforces the earlier observation that 
simulation in the social sciences has no natural home. 
 
                                                 
1 I am pleased to acknowledge the help of Ted Belding, Michael Cohen, Rick Riolo, and 
Hans Christian Siller. For financial assistance, I thank Intel Corporation, the Advanced 
Project Research Agency through a grant to the Santa Fe Institute, the National Science 
Foundation, and the University of Michigan LS&A College Enrichment Fund. Several 
paragraphs of this paper have been adapted from Axelrod (1997b), and are reprinted with 
permission of Princeton University Press. 
2 While simulation in the social sciences began over four decades ago (e.g., Cyert and 
March, 1963), only in the last fifteen years has the field begun to grow at a fast pace 
3 This excludes articles on gaming and education, the psychological process of mental 
simulation, and the use of simulation with human subjects or as a strictly statistical 
technique. 
4 The colloquium was published in the Proceedings of the National Academy of Sciences, 
vol. 99 (supl 3), 2002. It is available at 
http://www.pnas.org/content/vol99/issue90003/index.shtml. 
 3 
3. As a final way of looking at the issue, consider citations to one of the classics of social 
science simulation, Thomas Schelling’s Micro motives and Macrobehavior (1978). This 
book was cited in 21 articles in 2002, but these articles were maximally dispersed among 
21 different journals.  
 
In sum, works using social science simulation, works by social scientists interested in 
simulation, and works citing social science simulation are all very widely dispersed 
throughout the journals. There is not yet much concentration of articles in specialist 
journals, as there is in other interdisciplinary fields such as the theory of games or the 
study of China.5 
 
This essay is organized as follows: The next section discusses the variety of purposes that 
simulation can serve, giving special emphasis to the discovery of new principles and 
relationships. After this, advice is offered for how to do research with simulation. Topics 
include programming a simulation model, analyzing the results, sharing the results with 
others and replicating agent-based models. The final section suggests how to advance the 
art of simulation by fostering a community of social scientists (and others) who use 
computer simulation in their research. 
 
2. The Value of Simulation 
 
Let us begin with a definition of simulation. "Simulation means driving a model of a 
system with suitable inputs and observing the corresponding outputs."(Bratley, Fox & 
Schrage 1987, ix). 
 
While this definition is useful, it does not suggest the diverse purposes to which 
simulation can be put. These purposes include: prediction, performance, training, 
entertainment, education, proof and discovery. 
 
1. Prediction. Simulation is able to take complicated inputs, process them by taking 
hypothesized mechanisms into account, and then generate their consequences as 
predictions. For example, if the goal is to predict interest rates in the economy three 
months into the future, simulation can be the best available technique. 
 
2. Performance. Simulation can also be used to perform certain tasks. This is typically the 
domain of artificial intelligence. Tasks to be performed include medical diagnosis, speech 
recognition, and function optimization. To the extent that the artificial intelligence 
techniques mimic the way humans deal with these same tasks, the artificial intelligence 
method can be thought of as simulation of human perception, decision making or social 
interaction. To the extent that the artificial intelligence techniques exploit the special 
strengths of digital computers, simulations of task environments can also help design new 
techniques. 
                                                 
5 A potential exception is the Journal of Artificial Societies and Social Simulation.  This 
is an on-line journal available at http://jasss.soc.surrey.ac.uk/JASSS.html.  Unfortunately 
it is not yet indexed by the Social Science Citation Index. 
 4 
 
3. Training. Many of the earliest and most successful simulation systems were designed 
to train people by providing a reasonably accurate and dynamic interactive representation 
of a given environment. Flight simulators for pilots are an important example of the use 
of simulation for training. 
 
4. Entertainment. From training, it is only a small step to entertainment. Flight 
simulations on personal computers are fun. So are simulations of completely imaginary 
worlds. 
 
5. Education. From training and entertainment, it is only another small step to the use of 
simulation for education. A good example is the computer game SimCity. SimCity is an 
interactive simulation allowing the user to experiment with a hypothetical city by 
changing many variables, such as tax rates and zoning policy. For educational purposes, a 
simulation need not be rich enough to suggest a complete real or imaginary world. The 
main use of simulation in education is to allow the users to learn relationships and 
principles for themselves. 
 
6. Proof. Simulation can be used to provide an existence proof. For example, Conway’s 
Game of Life (Poundstone 1985) demonstrates that extremely complex behavior can 
result from very simple rules. 
 
7. Discovery. As a scientific methodology, simulation’s value lies principally in 
prediction, proof, and discovery. Using simulation for prediction can help validate or 
improve the model upon which the simulation is based. Prediction is the use that most 
people think of when they consider simulation as a scientific technique. But the use of 
simulation for the discovery of new relationships and principles is at least important as 
proof or prediction. In the social sciences, in particular, even highly complicated 
simulation models can rarely prove completely accurate. Physicists have accurate 
simulations of the motion of electrons and planets, but social scientists are not as 
successful in accurately simulating the movement of workers or armies. Nevertheless, 
social scientists have been quite successful in using simulation to discover important 
relationships and principles from very simple models. Indeed, as discussed below, the 
simpler the model, the easier it may be to discover and understand the subtle effects of its 
hypothesized mechanisms. 
 
Schelling’s (1974; 1978) simulation of residential tipping provides a good example of a 
simple model that provides an important insight into a general process. The model 
assumes that a family will move only if more than one third of its immediate neighbors 
are of a different type (e.g., race or ethnicity). The result is that very segregated 
neighborhoods form even though everyone is initially placed at random, and everyone is 
somewhat tolerant. 
 
To appreciate the value of simulation as a research methodology, it pays to think of it as a 
new way of conducting scientific research. Simulation as a way of doing science can be 
contrasted with the two standard methods of induction and deduction. Induction is the 
 5 
discovery of patterns in empirical data.6 For example, in the social sciences induction is 
widely used in the analysis of opinion surveys and the macro-economic data. Deduction, 
on the other hand, involves specifying a set of axioms and proving consequences that can 
be derived from those assumptions. The discovery of equilibrium results in game theory 
using rational choice axioms is a good example of deduction. 
 
Simulation is a third way of doing science. Like deduction, it starts with a set of explicit 
assumptions. But unlike deduction, it does not prove theorems. Instead, a simulation 
generates data that can be analyzed inductively. Unlike typical induction, however, the 
simulated data comes from a rigorously specified set of rules rather than direct 
measurement of the real world. While induction can be used to find patterns in data, and 
deduction can be used to find consequences of assumptions, simulation modeling can be 
used as an aid intuition.  
 
Simulation is a way of doing thought experiments. While the assumptions may be simple, 
the consequences may not be at all obvious. The large-scale effects of locally interacting 
agents are called "emergent properties" of the system. Emergent properties are often 
surprising because it can be hard to anticipate the full consequences of even simple forms 
of interaction.7 
 
There are some models, however, in which emergent properties can be formally deduced. 
Good examples include the neo-classical economic models in which rational agents 
operating under powerful assumptions about the availability of information and the 
capability to optimize can achieve an efficient reallocation of resources among 
themselves through costless trading. But when the agents use adaptive rather than 
optimizing strategies, deducing the consequences is often impossible; simulation 
becomes necessary. 
 
Throughout the social sciences today, the dominant form of modeling is based upon the 
rational choice paradigm. Game theory, in particular, is typically based upon the 
assumption of rational choice. In my view, the reason for the dominance of the rational 
choice approach is not that scholars think it is realistic. Nor is game theory used solely 
because it offers good advice to a decision maker, since its unrealistic assumptions 
undermine much of its value as a basis for advice. The real advantage of the rational 
choice assumption is that it often allows deduction. 
 
The main alternative to the assumption of rational choice is some form of adaptive 
behavior. The adaptation may be at the individual level through learning, or it may be at 
the population level through differential survival and reproduction of the more successful 
individuals. Either way, the consequences of adaptive processes are often very hard to 
deduce when there are many interacting agents following rules that have non-linear 
                                                 
6 Induction as a search for patterns in data should not be confused with mathematical 
induction, which is a technique for proving theorems. 
7 Some complexity theorists consider surprise to be part of the definition of emergence, 
but this raises the question of surprising to whom? 
 6 
effects. Thus, simulation is often the only viable way to study populations of agents who 
are adaptive rather than fully rational. While people may try to be rational, they can 
rarely meet the requirement of information, or foresight that rational models impose 
(Simon, 1955; March, 1978). One of the main advantages of simulation is that it allows 
the analysis of adaptive as well as rational agents. 
 
An important type of simulation in the social sciences is "agent-based modeling." This 
type of simulation is characterized by the existence of many agents who interact with 
each other with little or no central direction. The emergent properties of an agent-based 
model are then the result of "bottom-up” processes, rather than "top-down" direction. 
 
Although agent-based modeling employs simulation, it does not necessarily aim to 
provide an accurate representation of a particular empirical application. Instead, the goal 
of agent-based modeling is to enrich our understanding of fundamental processes that 
may appear in a variety of applications. This requires adhering to the KISS principle, 
which stands for the army slogan "keep it simple, stupid." The KISS principle is vital 
because of the character of the research community. Both the researcher and the audience 
have limited cognitive ability. When a surprising result occurs, it is very helpful to be 
confident that one can understand everything that went into the model. Simplicity is also 
helpful in giving other researchers a realistic chance of replicating one’s model, and 
extending the work in new directions. The point is that while the topic being investigated 
may be complicated, the assumptions underlying the agent-based model should be 
simple. The complexity of agent-based modeling should be in the simulated results, not 
in the assumptions of the model. 
 
As pointed out earlier, there are other uses of computer simulation in which the faithful 
reproduction of a particular setting is important. A simulation of the economy aimed at 
predicting interest rates three months into the future needs to be as accurate as possible. 
For this purpose, the assumptions that go into the model may need to be quite 
complicated. Likewise, if a simulation is used to train the crew of a supertanker, or to 
develop tactics for a new fighter aircraft, accuracy is important and simplicity of the 
model is not. But if the goal is to deepen our understanding of some fundamental process, 
then simplicity of the assumptions is important and realistic representation of all the 
details of a particular setting is not. 
 
3. Doing Simulation Research 
 
In order to advance the art of simulation in the social sciences, it is necessary to do more 
than consider the purpose of simulation. It is also necessary to be more self-conscious 
about the process of doing the research itself. To do so requires looking at three specific 
aspects of the research process which take place once the conceptual model is developed: 
the programming of the model, the analysis of the data, and the sharing of the results. 
 
 7 
3.1. Programming a Simulation Model8 
 
The first question people usually ask about programming a simulation model is,” What 
language should I use?"  For experienced programmers, I recommend Java for two 
reasons.  First, it can be run on almost any computer. Second, software packages are 
available in Java, which are designed to assist simulation.9  For beginning programmers, I 
recommend Visual Basic, which is included in the Excel spreadsheet application of 
Microsoft’s Office software package.  
 
The programming of a simulation model should achieve three goals: validity, usability, 
and extendibility. 
 
The goal of validity is for the program to correctly implement the model. This kind of 
validity is called "internal validity." Whether or not the model itself is an accurate 
representation of the real world is another kind of validity that is not considered here. 
Achieving internal validity is harder than it might seem. The program knows whether an 
unexpected result is a reflection of a mistake in the programming, or a surprising 
consequence of the model itself. For example, in one of my own models, a result was so 
counterintuitive that I had to spend several weeks to determine whether this result was a 
consequence of the model, or due to a bug in the program (Axelrod, 1997a). As is often 
the case, confirming that the model was correctly programmed was substantially more 
work than programming the model in the first place. 
 
The goal of usability is to allow the researcher and those who follow to run the program, 
interpret its output, and understand how it works. Modeling typically generates a whole 
series of programs, each version differing from the others in a variety of ways. Versions 
can differ, for example, in which data is produced, which parameters are adjustable, and 
even the rules governing agent behavior. Keeping track of all this is not trivial, especially 
when one tries to compare new results with output of an earlier version of the program to 
determine exactly what might account for the differences. 
 
The goal of extendibility is to allow a future user to adapt the program for new uses. For 
example, after writing a paper using the model, the researcher might want to respond to a 
question about what would happen if a new feature were added. In addition, another 
researcher might someday want to modify the program to try out a new variant of the 
model. A program is much more likely to be extendible if it is written and documented 
with this goal in mind. 
 
3.2. Analyzing the Results 
 
                                                 
8 This section is adapted from Axelrod (1997b, 210-11)  and is used with permission of 
Princeton University Press.  
9 A good example of such a package Repast. See 
http://www.econ.iastate.edu/tesfatsi/repastsg.htm 
 8 
Simulation typically generates huge amounts of data. In fact, one of the advantages of 
simulation is that if there is not enough data, one can always run the simulation again and 
get some more! Moreover, there are no messy problems of missing data or uncontrolled 
variables as there are in experimental or observational studies. 
 
Despite the purity and clarity of simulation data, the analysis poses real challenges. 
Multiple runs of the same model can differ from each other due to differences in initial 
conditions and stochastic events. A major challenge is that results are often path-
dependent, meaning that history matters. To understand the results often means 
understanding the details of the history of a given run. There are at least three ways in 
which history can be described. 
 
1. History can be told as "news," following a chronological order. For example, a 
simulation of international politics might describe the sequence of key events such as 
alliances and wars. This is the most straightforward type of storytelling, but often offers 
little in explanatory power. 
 
2. History can be told from the point of view of a single actor. For example, one could 
select just one of the actors, and do the equivalent of telling the story of the "Rise and 
Fall of the Roman Empire." This is often the easiest kind of history to understand, and 
can be very revealing about the ways in which the model’s mechanisms have their effects 
over time. 
 
3. History can also be told from a global point of view. For example, one would describe 
the distribution of wealth over time to analyze the extent of inequality among the agents. 
Although the global point of view is often the best for seeing large-scale patterns, the 
more detailed histories are often needed to determine the explanation for these large 
patterns. 
 
While the description of data as history is important for discovering and explaining 
patterns in a particular simulation run, the analysis of simulations all too often stops 
there. Since virtually all social science simulations include some random elements in 
their initial conditions and in the operation of their mechanisms for change, the analysis 
of a single run can be misleading. In order to determine whether the conclusions from a 
given run are typical, it is necessary to do several dozen simulation runs using identical 
parameters (using different random number seeds) to determine just which results are 
typical and which are unusual. While it may be sufficient to describe detailed history 
from a single run, it is also necessary to do statistical analysis of a whole set of runs to 
determine whether the inferences being drawn from the illustrative history are really well 
founded. The ability to do this is yet one more advantage of simulation: the researcher 
can rerun history to see whether particular patterns observed in a single history are 
idiosyncratic or typical. 
 
Using simulation, one can do even more than compare multiple histories generated from 
identical parameters. One can also systematically study the affects of changing the 
parameters. For example, the agents can be given either equal or unequal initial 
 9 
endowments of wealth to see what difference this makes over time. Likewise, the 
differences in mechanisms can be studied by doing systematic comparisons of different 
versions of the model. For example, in one version agents might interact at random 
whereas in another version the agents might be selective in whom they interact with. As 
in the simple change in parameters, the effects of changes in the mechanisms can be 
assessed by running controlled experiments with whole sets of simulation runs. 
Typically, the statistical method for studying the effects of these changes will be 
regression if the changes are quantitative and analysis of variance if the changes are 
qualitative. As always in statistical analysis, two questions need to be distinguished and 
addressed separately: are the differences statistically significant (meaning not likely to 
have been caused by chance), and are the differences substantively significant (meaning 
large enough in magnitude to be important). 
 
3.3. Sharing the Results 
 
After cycling through several iterations of constructing the model, programming the 
simulation, and doing the data analysis, the final step in the research is sharing the results 
with others. As in most fields of research, the primary method of sharing research results 
is through publication, most often in refereed journals or chapter-length reports in edited 
collections. In the case of social science simulation, there are several limitations with 
relying on this mode of sharing information. The basic problem is that it is hard to 
present a social science simulation briefly. There are at least three reasons. 
 
1. Simulation results are typically quite sensitive to the details of the model. Therefore, 
unless the model is described in great detail, the reader is unable to replicate or even fully 
understand what was done. Articles and chapters are often just not long enough to present 
the full details of the model. (The issue of replication will be addressed below.) 
 
2. The analysis of the results often includes some narrative description of histories of one 
or more runs, and such narrative often takes a good deal of space. While statistical 
analysis can usually be described quite briefly in numbers, tables or figures, the 
presentation of how inferences were drawn from the study of particular histories usually 
can not be brief. This is mainly due to the amount of detail required to explain how the 
model’s mechanisms played out in a particular historical context. In addition, the paucity 
of well known concepts and techniques for the presentation of historical data in context 
means that the writer cannot communicate this kind of information very efficiently. 
Compare this lack of shared concepts with the mature field of hypothesis testing in 
statistics. The simple phrase "p < .05" stands for the sentence, "The probability that this 
result (or a more extreme result) would have happened by chance is less than 
5%.”Perhaps over time, the community of social science modelers will develop a 
collection of standard concepts that can become common knowledge and then be 
communicated briefly, but this is not true yet. 
 
3. Simulation results often address an interdisciplinary audience. When this is the case, 
the unspoken assumptions and shorthand terminology that provide shortcuts for every 
 10 
discipline may need to be explicated at length to explain the motivation and premises of 
the work to a wider audience. 
 
4. Even if the audience is a single discipline, the computer simulations are still new 
enough in the social sciences that it may be necessary to explain very carefully both the 
power and the limitations of the methodology each time a simulation report is published. 
 
Since it is difficult to provide a complete description of a simulation model in an article-
length report, other forms of sharing information about a simulation have to be 
developed. Complete documentation should include the source code for running the 
model, a full description of the model, how to run the program, and how to understand 
the output files.  An example of such documentation is available for a study of 
ethnocentrism, Axelrod, Hammond and Grafen (2004). The documentation is at 
umich.edu/~axe/AHG/main.htm. 
  
 
3.4. Replication of Simulations 
 
Three important stages of the research process for doing simulation in the social sciences 
have been considered so far: namely the programming, analyzing and sharing computer 
simulations. All three of these aspects are done for virtually all published simulation 
models. There is, however, another stage of the research process that is virtually never 
done, but which needs to be considered. This is replication. The sad fact is that new 
simulations are produced all the time, but rarely does any one stop to replicate the results 
of any one else’s simulation model. Replication is one of the hallmarks of cumulative 
science. It is needed to confirm whether the claimed results of a given simulation are 
reliable in the sense that they can be reproduced by someone starting from scratch. 
Without this confirmation, it is possible that some published results are simply mistaken 
due to programming errors, misrepresentation of what was actually simulated, or errors in 
analyzing or reporting the results. Replication can also be useful for testing the robustness 
of inferences from models. Finally, replication is needed to determine if one model can 
subsume another, in the sense that Einstein’s treatment of gravity subsumes Newton’s.  
 
Rob Axtell, Michael Cohen, Rick Riolo and I took up the replication challenge with eight 
published agent-based models (Axtell et al., 1996).   With Murphy’s Law operating at 
full strength we identified replication problems with respect to ambiguity, gaps, and even 
errors in the published descriptions, as well as subtle differences between how different 
floating point systems calculated whether or not 9/3 equals 2+1.  More important, 
perhaps, was that we were able to clarify three decreasing levels of replication: 
“numerical identity” in which the results are reproduced precisely, “distributional 
equivalence” in which the results can not be distinguished statistically, and “relational 
equivalence” in which the qualitative relationships among the variables are reproduced. 
 
 
4. Conclusion: Building Community 
 
 11 
This paper has discussed how to advance the state of the art of simulation in the social 
sciences. It described the unique value of simulation as a third way of doing science, in 
contrast to both induction and deduction. It then offered advice for doing simulation 
research, focusing on the programming of a simulation model, analyzing the results,  
sharing the results with others, and replicating agent-based simulations.  
 
One final theme needs to be addressed, namely the building of a community of social 
scientists who do simulation. This paper began with the observation that simulation 
studies are published in very widely dispersed outlets. This is an indication that social 
science simulators are only just beginning to build strong institutional links across 
traditional disciplinary boundaries, even though the work itself is often interdisciplinary 
in content and methodology. The question now is what it would take to promote further 
the growth and success of social science simulation. My answer comes in four parts: 
methodology, standardization, education and institution building. 
 
This paper has already discussed suggestions for progress in methodology. The next step 
is to begin to develop the internal structure and boundaries of the field. In particular, 
converging on commonly accepted terminology would be very helpful. A host of terms is 
now used to describe our field. Examples are artificial society, complex system, agent-
based model, multi-agent model, individual-based model, bottom-up model, adaptive 
system, and the somewhat broader term computational model. Having commonly 
accepted distinctions between these terms could certainly help specify and communicate 
what simulation is about.  
 
Hand-in-hand with developing the terminology, a shared sense of the internal structure 
and boundaries of the field is needed. For example, simulation in the social sciences 
might continue to develop primarily within the separate disciplines of economics, 
political science, sociology and so forth. There are powerful forces supporting 
disciplinary research, including the established patterns of professional education, hiring, 
publication, and promotion. Nevertheless, if simulation is to realize its full potential there 
must be substantial interaction across the traditional disciplines. 
 
Progress requires the development of an interdisciplinary community of social scientists 
who do simulation. Progress also requires the development of an even broader 
community of researchers from all fields who are interested in the simulation of any kind 
of system with many agents. Certainly, ecology and evolutionary biology have a great 
deal to offer for the study of decentralized adaptive systems. Likewise, computer science 
has recently started to pay a great deal of attention to how large systems of more or less 
independent artificial agents can work with each other in vast networks. In addition, 
mathematics has developed some very powerful tools for the analysis of dynamic systems 
(Flake, 1998).  Even the playful field of artificial life offers many insights into the vast 
potential of complex adaptive systems. Conversely, social scientists have a great deal to 
offer evolutionary biologists, computer scientists and others because of our experience in 
the analysis of social systems with large numbers of interacting agents. 
 
 12 
The educating of modelers is typically done within the context of specific disciplines.  To 
help build bridges across disciplines, Leigh Tesfatsion and I have developed an on-guide 
for newcomers to agent-based modeling across the social sciences (Axelrod and 
Tesfatsion, 2005).10 
 
As the field of agent-based modeling matures, the value of institutional arrangements 
increases.  Such arrangements include journals devoted to simulation, professional 
organizations, conference series, funding programs, university courses, review articles, 
textbooks, and shared standards of research practice.11 To realize the full potential of 
computer simulation will require the development of these institutional arrangements for 
community building. Who should be better able to build new institutions than the 
researchers who use simulation to study real and potential societies? 
 
References 
 
Axelrod, R. (1987). The evolution of strategies in the iterated Prisoner’s Dilemma. In 
Genetic algorithms and simulated annealing, Lawrence Davis (ed.). London: Pitman; Los 
Altos, CA: Morgan Kaufman, 32-41. Reprinted in Axelrod (1997b). 
 
_____, (1997a). The dissemination of culture: a model with local convergence and global 
polarization. Journal of conflict resolution, 41, 203-26. Reprinted in Axelrod (1997b). 
 
______, (1997b). The complexity of cooperation: agent-based models of competition and 
collaboration. Princeton, NJ: Princeton University Press.  
 
_____ and L. Tesfatsion, (forthcoming), A Guide for Newcomers to Agent-Based 
Modeling in the Social Sciences in Kenneth L. Judd and Leigh Tesfatsion (Eds.), 
Handbook of Computational Economics, Vol. 2: Agent-Based Computational Economics 
(North-Holland). Available at http://www.econ.iastate.edu/tesfatsi/abmread.htm. 
 
_____, Hammond, R. A. and Grafen, A. (2004), “Altruism Via Kin-Selection Strategies 
that Rely on Arbitrary Tags with Which They Coevolve. Evolution. 58, 1833-1838. 
 
Axtell, R., Axelrod, R., Epstein, J. & Cohen, M. D. (1996). Aligning simulation models: 
a case study and results. Computational and mathematical organization theory, 1, 123-
141. 
 
Bratley, P., Fox, B. & Schrage, L. (1987). A Guide to Simulation. Second Edition. New 
York: Springer-Verlag. 
 
                                                 
10 The on-line guide is available with live links at 
http://www.econ.iastate.edu/tesfatsi/abmread.htm. 
11 For details on all of these, see  http://www.econ.iastate.edu/tesfatsi/ace.htm. 
 
 13 
Cohen, M. D., March, J. G., & Olsen, J. (1972). A garbage can theory of organizational 
choice. Administrative science quarterly, 17, 1-25. 
 
Cyert, R. and March, J. G. (1963). A behavioral theory of the firm. Englewood Cliffs, N. 
J., Prentice-Hall, 1963. 
 
Epstein, J. & Axtell, R. (1996). Growing artificial societies: social science from the 
bottom up. Washington, DC: Brookings and Cambridge, MA: MIT Press. 
 
Flake, Gary William (1998), The Computational Beauty of Nature (MIT Press, 
Cambridge, MA). 
 
March, J. G., (1978). Bounded rationality, ambiguity and the engineering of choice. Bell 
journal of economics, 9, 587-608. 
 
Poundstone, W. (1985). The recursive universe. Chicago, IL: Contemporary Books. 
 
Riolo, R. (1997). The effects of tag-mediated selection of partners in evolving 
populations playing the iterated Prisoner’s Dilemma. Santa Fe Institute Working Paper, 
97-02-016. 
 
Schelling, T. (1974). On the ecology of micromotives. In The corporate society, Robert 
Morris (ed.). 19-64 (See especially 43-54). 
 
_____ (1978). Micromotives and macrobehavior. New York: W. W. Norton. (See 
especially 137-55.) 
 
Simon, H. A., (1955). A behavioral model of rational choice. Quarterly journal of 
economics, 69, 99-118 

