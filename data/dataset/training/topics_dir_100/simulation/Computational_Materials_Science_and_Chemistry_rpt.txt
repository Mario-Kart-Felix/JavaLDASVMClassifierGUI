
Report of the Department of Energy Workshop on
Computational Materials Science  
and Chemistry for Innovation 
July 26–27, 2010
Cochairs
George Crabtree, Argonne National Laboratory
Sharon Glotzer, University of Michigan
Bill McCurdy, University of California–Davis
Jim Roberto, Oak Ridge National Laboratory
Panel leads
Materials for extreme conditions
John Sarrao, Los Alamos National Laboratory
Richard LeSar, Iowa State University
Chemical reactions
Andy McIlroy, Sandia National Laboratories
Alex Bell, University of California–Berkeley
Thin films, surfaces, and interfaces
John Kieffer, University of Michigan
Ray Bair, Argonne National Laboratory 
Self-assembly and soft matter
Clare McCabe, Vanderbilt University
Igor Aronson, Argonne National Laboratory
Strongly correlated electron systems and complex 
materials: superconducting, ferroelectric, and 
magnetic materials
Malcolm Stocks, Oak Ridge National Laboratory
Warren Pickett, University of California–Davis
Electron dynamics, excited states, and  
light-harvesting materials and processes
Gus Scuseria, Rice University
Mark Hybertsen, Brookhaven National Laboratory
Separations and fluidic processes
Peter Cummings, Vanderbilt University
Bruce Garrett, Pacific Northwest National Laboratory
Computational Materials Science and 
Chemistry: Accelerating Discovery and 
Innovation through Simulation-Based 
Engineering and Science
Executive Summary
The urgent demand for new energy technologies has greatly exceeded the capabilities 
of today’s materials and chemical processes. To convert sunlight to fuel, efficiently store 
energy, or enable a new generation of energy production and utilization technologies 
requires the development of new materials and processes of unprecedented functionality 
and performance. New materials and processes are critical pacing elements for progress in 
advanced energy systems and virtually all industrial technologies.
Over the past two decades, the United States has developed and deployed the world’s most 
powerful collection of tools for the synthesis, processing, characterization, and simulation 
and modeling of materials and chemical systems at the nanoscale, dimensions of a few 
atoms to a few hundred atoms across. These tools, which include world-leading x-ray and 
neutron sources, nanoscale science facilities, and high-performance computers, provide 
an unprecedented view of the atomic-scale structure and dynamics of materials and the 
molecular-scale basis of chemical processes. For the first time in history, we are able to 
synthesize, characterize, and model materials and chemical behavior at the length scale 
where this behavior is controlled. This ability is transformational for the discovery process 
and, as a result, confers a significant competitive advantage.
Perhaps the most spectacular increase in capability has been demonstrated in high- 
performance computing. Over the past decade, computational power has increased by a 
factor of a million due to advances in hardware and software. This rate of improvement, 
which shows no sign of abating, has enabled the development of computer simulations and 
models of unprecedented fidelity. 
We are at the threshold of a new era where the integrated synthesis, characterization, 
and modeling of complex materials and chemical processes will transform our ability to 
understand and design new materials and chemistries with predictive power. In turn, this 
predictive capability will transform technological innovation by accelerating the development 
and deployment of new materials and processes in products and manufacturing.
Harnessing the potential of computational science and engineering for the discovery and 
development of materials and chemical processes is essential to maintaining leadership in 
these foundational fields that underpin energy technologies and industrial competitiveness. 
Capitalizing on the opportunities presented by simulation-based engineering and science 
in materials and chemistry will require an integration of experimental capabilities with 
theoretical and computational modeling; the development of a robust and sustainable 
infrastructure to support the development and deployment of advanced computational 
models; and the assembly of a community of scientists and engineers to implement this 
integration and infrastructure. This community must extend to industry, where incorporating 
predictive materials science and chemistry into design tools can accelerate the product 
development cycle and drive economic competitiveness. 
 1 
The confluence of new theories, new materials synthesis capabilities, and new computer 
platforms has created an unprecedented opportunity to implement a “materials-by-design” 
paradigm with wide-ranging benefits in technological innovation and scientific discovery. 
The Workshop on Computational Materials Science and Chemistry for Innovation was 
convened in Bethesda, Maryland, on July 26–27, 2010, to assess the potential of state-
of-the-art computer simulations to accelerate understanding and discovery in materials 
science and chemistry, with a focus on potential impacts in energy technologies and 
innovation. Sponsored by the Department of Energy (DOE) Offices of Advanced Scientific 
Computing Research and Basic Energy Sciences, the workshop brought together 160 experts 
in materials science, chemistry, and computational science representing more than 65 
universities, laboratories, and industries, and four agencies.
The workshop examined seven foundational challenge areas in materials science and 
chemistry: materials for extreme conditions, self-assembly, light harvesting, chemical 
reactions, designer fluids, thin films and interfaces, and electronic structure. Each of these 
challenge areas is critical to the development of advanced energy systems, and each can be 
accelerated by the integrated application of predictive capability with theory and experiment.
The workshop concluded that emerging capabilities in predictive modeling and simulation 
have the potential to revolutionize the development of new materials and chemical 
processes. Coupled with world-leading materials characterization and nanoscale science 
facilities, this predictive capability provides the foundation for an innovation ecosystem that 
can accelerate the discovery, development, and deployment of new technologies, including 
advanced energy systems. Delivering on the promise of this innovation ecosystem requires 
the following:
• Integration of synthesis, processing, characterization, theory, and simulation 
and modeling. Many of the newly established Energy Frontier Research Centers 
and Energy Hubs are exploiting this integration.
• Achieving/strengthening predictive capability in foundational challenge 
areas. Predictive capability in the seven foundational challenge areas described in 
this report is critical to the development of advanced energy technologies.
• Developing validated computational approaches that span vast differences in 
time and length scales. This fundamental computational challenge crosscuts all of 
the foundational challenge areas. Similarly challenging is coupling of analytical data 
from multiple instruments and techniques that are required to link these length and 
time scales.
• Experimental validation and quantification of uncertainty in simulation 
and modeling. Uncertainty quantification becomes increasingly challenging as 
simulations become more complex.
• Robust and sustainable computational infrastructure, including software 
and applications. For modeling and simulation, software equals infrastructure. To 
validate the computational tools, software is critical infrastructure that effectively 
translates huge arrays of experimental data into useful scientific understanding. An 
integrated approach for managing this infrastructure is essential.
• Efficient transfer and incorporation of simulation-based engineering 
and science in industry. Strategies for bridging the gap between research 
and industrial applications and for widespread industry adoption of integrated 
computational materials engineering are needed.
 2
Contents
Materials science and chemistry: Pathway to innovation
• Energy technologies
• Industrial competitiveness
Accelerating discovery and innovation in materials science  
and chemistry
• The challenge of complexity
• Leveraging new capabilities in nanoscale science and technology
• The role of simulation-based engineering and science
Foundational challenges in predictive materials science  
and chemistry
• Materials for extreme conditions: Controlling microstructures
• Designing and engineering materials at the nanoscale: Understanding  
and controlling self-assembly
• Light harvesting: Photons to energy
• Controlling chemical reactions: Combustion and catalysis
• Designer fluids: Separations and carbon capture
• Designer interfaces: From interfacial materials to advanced batteries
• Controlling electronic structure: Modeling strongly correlated electrons  
Materials and chemistry by design: Creating an innovation 
ecosystem
• Achieving predictive capability
• Integration of synthesis, processing, characterization, theory, and modeling 
and simulation
• Simulation-based engineering and science (SBE&S) as a critical and 
sustainable national infrastructure
Benefits of predictive capability in science and engineering
• Accelerating scientific discovery
• Enabling new technologies
• Seizing the opportunity
Appendices
• Workshop agenda
• Participants
 3 
Advances in materials 
science and chemistry enable 
technological revolutions
Materials science and chemistry:  
Pathway to innovation
One can describe the history of civilization as a series of breakthroughs in materials science 
and chemistry. Beginning with the Stone Age, we have progressed through Bronze, Iron, 
Nuclear, and Silicon ages. Materials lend their names to ages because materials define 
technological capabilities. Advances in materials and chemistry have shaped history and the 
balance of economic and military power:  iron and steel, gunpowder, ammonia synthesis, 
antibiotics, uranium and plutonium, silicon-based electronics.  Materials and chemistry 
have enabled modern civilization, providing a pathway to innovation in industry, energy, 
agriculture, national security, health, and information technology. 
Energy technologies
It has been more than 100 years since the first solar cell, the first electric car, and the first 
rechargeable battery. Fossil power plants operate at two-thirds of their optimal efficiency 
and release large quantities of greenhouse gases, and a half century after the first nuclear 
power plant we have yet to reach consensus on fuel cycles or the disposal of spent fuel.  
None of these technologies are close to meeting their full 
potential, and the availability of advanced materials and 
chemical processes is the principal technological barrier. 
Virtually all energy technologies are limited by the 
performance of materials. For fossil and nuclear electric 
power, we need materials that can operate at greatly increased temperatures in extreme 
environments of corrosion and radiation. Such materials could increase the efficiency of 
existing technologies by as much as a third. We need materials and chemical processes that 
can efficiently separate greenhouse gases from effluent streams in conventional fossil plants, 
and that can separate and safely store radioactive materials from nuclear plants. We need 
materials that drive down the cost of solar cells while increasing their efficiency. We need 
materials and chemical processes for batteries that enable utilization of electric vehicles and 
intermittent solar and wind energy by storing electrical energy at densities that rival liquid 
fuels. We need lightweight materials for transportation and catalysts for the direct conversion 
of sunlight to fuels. There are no known fundamental barriers to these innovations, but they 
represent significant challenges to our science and technology.
 4
Predictive capability 
will drive innovation 
and competitiveness
Industrial competitiveness
Materials science and chemistry also underpin industrial competitiveness. Pick a technology 
and you will find that progress depends on advances in materials and chemistry:  electric 
motors on compact, high-field magnets; batteries on electrolyte materials and chemistries; 
solar cells on thin-film materials technology; computer chips on nano-
materials fabrication; polymers and plastics on chemical catalysts; 
steel on alloy science.
The company or nation with the best environment for discovering 
and deploying new materials and chemical processes that transform 
products and technologies will be more competitive than less innovative and agile companies 
or nations. These transformational advances will create new industries and force the 
evolution of others. They are rational scientific and technical goals that are well within sight. 
They will be achieved:  The question is how quickly and by whom. 
Simulation-based engineering and science offers a significant opportunity to increase 
industrial competitiveness by reducing design times, accelerating the development and 
incorporation of new materials and processes, and minimizing testing requirements. The 
development and application of a predictive capability to facilitate the development of 
industrial products, processes, and technologies are transformational. This can be seen 
in the early application of Integrated Computational Materials Engineering (ICME) in 
several industry sectors including aircraft, automobiles, and manufacturing. ICME, based 
on integrated simulation of complex materials and manufacturing systems, has reduced 
prototyping times and accelerated deployment. Reductions in testing requirements by factors 
of up to seven, acceleration of deployment times by factors of two to three, and cost savings 
of tens to hundreds of millions have been reported. Predictive capability for the performance 
of materials and chemical systems is essential to this process.
Predictive capability also drives technological innovation. Advanced technologies typically 
require increasingly complex materials systems and processes. This complexity is a 
challenge for traditional development strategies due to the extensive parameter space that 
must be explored.  Predictive capability based on simulation-based engineering and science 
offers the opportunity to significantly expand this parameter space while lowering both 
costs and development times. This will accelerate the replacement of rare or nondomestic 
source materials (such as rare earths for magnets or lithium for batteries) with abundant 
materials, the discovery of new materials with tailored properties, the deployment of “green” 
technologies and processes with lower environmental impact and improved performance, 
and the development of advanced manufacturing technologies with improved efficiency and 
flexibility. By accelerating the development and deployment of complex materials systems 
and processes, predictive capability will drive innovation and economic competitiveness.
 5 
We do not have the time or 
resources to explore all the 
options by trial and error.
Accelerating discovery and innovation  
in materials science and chemistry
The challenge of complexity
Advanced materials share a common characteristic: They are complex. Achieving the 
required performance gains depends on exploiting the many degrees of freedom of materials 
development including multiple chemical components, nanoscale architectures, and tailored 
electronic structures. This introduces enormous complexity in the discovery process, 
complexity that must be understood and managed.
Early steels consisted of three to four essential chemical components and a relatively simple 
microstructure. Today’s advanced high-strength, high-temperature steels average six to 
eight chemical components and require complex, multiphase nanostructures. The parameter 
space for exploration has increased enormously, making continued development by trial and 
error impractical. 
New catalysts are needed to improve the efficiency of industrial processes, make effective 
use of bioenergy, and drive energy conversion and environmental mitigation processes. 
There are billions of options:  chemical combinations, local morphologies, atomic-scale 
structure. Sifting through the options using predictive modeling is the only intelligent and 
efficient path forward.
The superconductors of the 1980s were typically two-component systems with a simple 
crystal structure. Today’s high-temperature superconductors boast four or more chemical 
components, layered architectures, and sensitive electronic doping. This trend is also apparent 
in new high-field magnetic materials that derive their properties from the interaction of 
multiple chemical elements in complex microstructures. Again, high performance comes with 
a significant increase in complexity—and with a corresponding need to narrow discovery 
possibilities to a manageable number of the most promising options. 
Leveraging new capabilities in nanoscale science  
and technology
Across the spectrum of new materials and chemical processes, discovery is increasingly 
confronted with complexity. We do not have the time or resources to explore all the options 
experimentally. The only solution is materials and chemistry by design, using new synthesis 
and characterization tools, theory, and simulation and 
modeling to understand complex materials and chemical 
systems and predict the most promising research directions.
Over the past two decades, the United States has developed 
and deployed the world’s most powerful collection of tools 
for the synthesis, processing, characterization, and simulation and modeling of materials 
and chemical systems at the nanoscale, dimensions of a few atoms to a few hundred 
atoms across. This length scale is critical, because the nanoscale is where the properties of 
materials and chemical reactions are determined. These tools, which include world-leading 
x-ray and neutron sources, nanoscale science facilities, and high-performance computers, 
provide an unprecedented view of the atomic-scale structure and dynamics of materials and 
the molecular-scale basis of chemical processes. For the first time in history, we are able 
to synthesize, characterize, and model materials and chemical behavior at the length scale 
where this behavior is controlled. This ability is transformational for the discovery process 
and, as a result, confers a significant competitive advantage.
 6
We are at the threshold of a new 
era where predictive modeling will 
transform our ability to design new 
materials and chemical processes.
The role of simulation-based engineering and science
Perhaps the most spectacular increase in capability has been demonstrated in high-
performance computing. Over the past decade, computational power has increased by a 
factor of a million due to advances in hardware and software. This rate of improvement, which 
shows no sign of abating, has enabled the development of computer simulations and models of 
unprecedented fidelity and speed. We are at the threshold of a new era where the integrated 
synthesis, characterization, and modeling of complex 
materials and chemical processes will transform our ability 
to understand and design new materials and chemistries 
with predictive power. This has profound implications for the 
pace of discovery and the creation of new technologies.
Simulation-based engineering and science has accelerated 
progress in scientific understanding and technology development by enabling complex systems 
such as astrophysical and climate phenomena, aircraft wings, and integrated manufacturing to 
be explored rapidly and efficiently. This leads to new scientific understanding of systems that 
are too large for experimental study, reduced time and cost of prototyping, and accelerated 
deployment of new technologies. The United States has a commanding presence in 
computational science with leadership positions in high-end computing infrastructure and high-
performance scientific applications, but the penetration of this capability has been slow and 
uneven. Harnessing the potential of computational science and engineering for the discovery 
and development of materials and chemical processes is essential to maintaining leadership in 
these foundational fields and their downstream energy and industrial applications. 
Capitalizing on the opportunities presented by simulation-based engineering and science in 
materials and chemistry will require an integration of experimental capabilities with theoretical 
and computational modeling; the development of a robust and sustainable infrastructure 
to support the development and deployment of advanced computational models; and the 
assembly of a community of scientists and engineers to implement this integration and 
infrastructure. The experimental facilities are in place, and the computational power is 
available. The goal is leadership in predictive materials science and chemistry—predictive 
power to accelerate discovery and innovation in materials and chemical processes that enable 
energy technologies and drive industrial competitiveness.
 7 
Computational techniques 
enabled the rapid development 
of alumina-forming austenitic 
(AFA) stainless steels with 
excellent creep resistance, 
ten times better corrosion 
resistance, and low alloy costs.
Courtesy of M. Brady, Oak Ridge 
National Laboratory
Foundational challenges in predictive materials 
science and chemistry
Materials for extreme conditions: Controlling microstructures
The availability of structural materials that can operate at extreme values of temperature, 
stress and strain, pressure, radiation flux, and chemical reactivity is the principal limiting 
factor in the performance of many energy systems. Fossil power plants, nuclear plants, 
and transportation systems all operate at lower efficiencies due to the limitations of existing 
structural materials. Impressive gains in efficiency of 30% and more can be achieved by the 
development of new materials capable of withstanding these demanding conditions.
The failure of materials, often at one-tenth or less of their intrinsic limits, is not understood. 
Understanding failure and achieving intrinsic properties require bridging length and time 
scales from molecular structures and their interactions to continuum models of bulk 
components. Central to this challenge is predicting and controlling the microstructure—the 
complicated arrangement of crystalline grains, defects, interfaces, and impurities that make 
up the microscale structure. Microstructure is key to understanding damage processes, 
preventing failure, and enhancing performance. 
The design space of modern structural materials is huge—much too complex to explore by 
trial and error. Predictive modeling is needed to guide experiments in the most productive 
directions, to accelerate design and testing, and to understand performance.  State-of-
the-art computational tools allow scientists to calculate from first principles the interactions 
that dominate microstructural behavior, while experimental tools can now provide time-
resolved measurements on real materials to validate these models. This integration of 
theory, simulation, and experiment will accelerate materials discovery and innovation. Key 
to achieving these advances is verification, validation, and uncertainty quantification of the 
computer models. Physical measurements must be made at relevant length and time scales 
and compared directly with theory and simulation. 
The time is ripe for development of a sustained effort in integrated computational materials 
engineering. The lack of new materials is a critical factor in design and manufacturing, 
and a barrier to sustained competitiveness. The outcome of this effort will be the rapid 
development and deployment of new materials that can be incorporated in energy 
systems and manufacturing. This can increase the efficiency of power plants and 
transportation systems, significantly reduce requirements for physical testing, and increase 
competitiveness by achieving improved functionality and reduced time-to-market of a wide 
variety of products and technologies.
 8
Early impacts of simulation-based engineering and science in industry (from top):  virtual aluminum casting at Ford 
(7:1 return on investment), airframe design and manufacturing at Boeing (estimated 3–4 year reduction in material 
certification time), diesel engine brought to market solely with modeling and analysis tools at Cummins (reduced 
development time and improved performance), new tire design at Goodyear (threefold reduction in development time).  
From Integrated Computational Materials Engineering:  A Transformational Discipline for Improved Competitiveness 
and National Security, National Academies Press (2008) and Goodyear Puts Rubber to the Road with High Performance 
Computing, Council on Competitiveness (2009).
The microstructure of a material controls a wide 
range of important properties, including strength, 
fatigue, high-temperature performance, corrosion, 
and radiation resistance. While there is substantial 
qualitative understanding of microstructural evolution, 
there are no predictive models that link materials 
processing to resultant microstructures. Further, there 
is a lack of understanding of the connections between 
microstructure and materials performance. The new 
generation of synchrotrons, neutron sources, and 
synthesis and characterization equipment, together with 
recent computational and algorithm advances, provides 
an opportunity for the first time to envision designing 
microstructures for specific purposes and bringing them 
to fruition in real materials.
The potential impact of optimizing performance through 
engineered microstructures by design is huge. A recent 
National Academies report (see below) documents Ford’s 
success in using integrated computational materials 
engineering to develop quantitative prediction of materials 
properties based on processing history. This has provided 
a substantial return on investment by reducing design 
times, lowering development costs, and accelerating the 
product cycle. The capability to tailor materials for specific 
applications, such as radiation environments, will become 
increasingly important as materials properties are pushed to 
their theoretical limits. Recent successes in demonstrating 
fourfold increases in the strength of advanced steels point 
to the dramatic gains that can be made.
Realizing this vision will require integrating and 
linking models that capture the multitude of individual 
physical phenomena that dictate material performance 
(microporosity, grain size, multiple phases, precipitates, 
etc.) and their effect on properties (fatigue, creep strength, 
corrosion, radiation resistance, etc.). This will also require 
close collaboration across the synthesis, characterization, 
theory, and computational communities, as well as 
sustained efforts in the related computer science, 
mathematics, and information science fields. Finally, 
integration with industry will be essential to develop and 
transfer the new computational tools and ensure their 
applicability to industry needs.
 9 Foundational Challenges in Predictive Materials Science and Chemistry
FOUNDATIONAL CHALLENGES IN PREDICTIVE 
MATERIALS SCIENCE AND CHEMISTRY
Designer materials made of pre-programmed building 
blocks that spontaneously organize into structures with 
unique and complex properties currently exhibited 
only by biological systems have long been a dream 
of technologists. Structures whose constituents can 
assemble, disassemble, and reassemble autonomously 
or on command enable materials capable of self-repair, 
multi-tasking, and even shape-shifting—properties 
known throughout the biological world. Imagine coatings 
that can change color or toggle between translucent 
and opaque on cue; sensors that can detect, trap, and 
dispose of pathogens; materials that can self-regulate 
porosity, strength, water or air resistance, elasticity, or 
conductivity—all these and much more are possible 
through self-assembly. 
Importantly, self-assembly also permits material structures 
far more complex than traditional metals, ceramics, and 
polymers, with many levels of hierarchical organization 
and compartmentalization typical of biological structures 
such as cells and organelles. Such structural complexity is 
demanded by the sophisticated properties and behavior 
we desire of next-generation materials capable of meeting 
future energy demands—especially active materials, which 
must perform functionally in ways not possible today for 
traditional, nonbiological matter. 
Over the past decade, investments and advances in 
nanoscience have made possible the creation, imaging, 
characterization, and manipulation of highly complex 
building blocks ranging from single molecules to 
supramolecular objects nanometers to microns in size—
precisely the size range needed for the “bricks and mortar” 
of next-generation, self- assembled materials. Nanoparticles 
and colloids of nearly any shape, made of metals, 
semiconductors, and/or polymers, and functionalized with 
organic molecules and biomolecular ligands—including 
proteins, viruses, and DNA—as well as other chemical 
“hooks” are now possible. As a result, vast palettes of 
designer building blocks, in many cases coupled with 
solvents that play an active role in mediating interactions, 
are at hand, with the propensity for self-assembly into 
structures of unprecedented complexity and function. 
The design space for self-assembled materials is now 
so vast that computational tools are required for the 
rapid screening and prototyping of building blocks that 
will predictably self-assemble into desired structures. In 
recent years, promising new theoretical and computational 
approaches to the study of self-assembly have emerged 
to guide experiments, but these are in their infancy. At the 
same time, continued investments in high-performance 
computing (HPC) have produced computing platforms 
that are now fast enough to permit predictive simulations 
of self-assembly for complex building blocks, and new 
experimental probes promise the needed resolution of 
nanoscale structure to monitor assembly processes in 
situ, parameterize models, and validate simulations. 
These combined advances in synthesis, characterization, 
and modeling capabilities set the stage for a tipping 
point in our ability to discover the underlying principles 
controlling self-assembly, and to develop robust, predictive 
simulation-based tools to achieve materials by design.
Predictive capabilities for materials self-assembly
To fully master the science and engineering of self-
assembly requires rapid and integrated progress on 
several related fronts of discovery and innovation. It 
requires harnessing the often competing theoretical 
These images show examples of assembly  phenomena 
at various scales. (Left) Patchy particle nanocolloids and 
their assemblies predicted by coarse-grained models 
and Brownian dynamics simulations (courtesy of  
C. R. Iacovella and S. C. Glotzer, University of Michigan). 
(Right) Coarse-grained simulation of hexadecanic 
acid (yellow and dark blue) and cholesterol (red and 
turquoise) in water which represents a simple skin lipid 
material. The lipids self-assemble into an experimentally 
observed bilayer and demonstrate that shortening the 
acid tails destabilizes the bilayer due to decreased solubility of the 
acid, while longer acid tails lead to bilayer unzipping (courtesy of 
K. R. Hadley and C. McCabe, Vanderbilt University). 
Scales of Assembly  
Designing and engineering materials 
at the nanoscale: Understanding and 
controlling self-assembly
 10 Foundational Challenges in Predictive Materials Science and Chemistry
principles of thermodynamics and kinetics in materials 
comprised of complex molecular and supramolecular 
building blocks whose shapes and interactions can result 
in kinetic traps that prevent assembly into equilibrium 
structures. It also requires discovering and applying the 
principles of statistical thermodynamics in active systems 
and systems driven far from equilibrium, as in biological 
systems, in which the constant input of energy creates 
and stabilizes structures. Finally, it requires developing 
simulation-based design tools that enable both the 
prediction of structures and their properties from building 
blocks and the rapid prototyping and reverse engineering 
of building blocks designed and pre-programmed to 
assemble into target structures.
Such advances are possible within the next few years due to 
the anticipated rapid convergence of synthesis capabilities, 
experimental probes, theoretical understanding, computing 
hardware, and scale-spanning algorithms. In particular, 
innovative high-resolution experimental probes (high-
resolution X-ray and neutron scattering, super-resolution 
scanning optical microscopy, real-time 3D nanotomography, 
cryo-transmission electron microscopy, scanning probe 
microscopies, and others) allow for direct measurements 
of building block interactions and in situ, real-time 
monitoring of the various stages of self-assembly. Since 
many of the most interesting new building blocks (such 
as DNA-functionalized nanoparticles) combine biological 
and nonbiological matter, new experimental probes will 
be needed. On the HPC side, graphics processing units, or 
GPUs, developed by the billion-dollar video game industry 
already provide up to 1000-fold speedups in simulations 
that are highly “data parallel,” including those used to 
study self-assembly (molecular dynamics, path sampling, 
phase diagram mapping, energy minimization, etc.). These 
architectures are ideal for rapid searching and optimizing 
of large design spaces, but significant code development 
will be required to utilize this new platform effectively 
as codes developed over the past one to two decades 
for serial or massively parallel CPU architectures cannot 
simply be ported to GPUs and perform optimally. Once 
rapid, high-throughput assembly prototyping for arbitrary 
building blocks is achieved, open databases and digital 
libraries for broad classes of self-assembling materials will 
be needed to expedite model and code validation. The new 
simulation capability that will result from these coordinated 
investments will revolutionize our ability to predict, model, 
and design self-assembled materials with desired functional 
properties for a broad host of energy and other applications. 
(Above)  Multimillion, all-atom molecular dynamics simulation of an assembled actin filament (shown in ribbon  
representation). The simulation results show that the conformation of the monomer binding loop (red) has dramatic 
effects on the structural and mechanical properties of actin (courtesy of J. Pfaendtner, D. Branduardi, T. D. Pollard, 
M. Parrinello, and G. A. Voth). 
Self-assembly and reconfigurability of nanomaterials 
By combining organic and inorganic matter into hybrid building blocks, 
hierarchically ordered nanostructures can be achieved through self-
assembly. The image at left shows the predictions of computer simulations 
of polymer-tethered rod-like nanoparticles. Depending on rod length, 
different structures result. Each structure exhibits different geometries and 
consequently different properties. By using “active” nanorods capable of 
lengthening and shortening, simulations show how the assemblies can be 
made to be reconfigurable, toggling among different structures on command.
Courtesy of T. D. Nguyen and S. C. Glotzer, ACS Nano 4(5), 2585–94 (2010).
 11 Foundational Challenges in Predictive Materials Science and Chemistry
FOUNDATIONAL CHALLENGES IN PREDICTIVE 
MATERIALS SCIENCE AND CHEMISTRY
0.8
-0.8
0
0.8
-0.8
0
0 400 800
Waiting time (fs)
1200 1600
150 K
77 K
1000 nm 5–10 nm 0.1–0.5 nm
N
or
m
al
iz
ed
 
be
at
 a
m
pl
it
ud
e
Light harvesting: Photons to energy
Developing future molecular, polymeric, and hybrid 
materials for harvesting and converting energy from 
sunlight requires sophisticated computational search 
strategies to find the optimal combination of organic 
and inorganic materials that can harvest light from the 
entire solar spectrum. Designing materials for such light 
collection requires capture of the infrared and ultraviolet 
parts of the solar spectrum and is expected to involve 
strategies based upon intermediate band gap materials, 
plasmonic excitations in clusters and molecules, and 
optimized thermoelectrical conversion complexes. 
Requisite to finding the optimal solar-harvesting “needle” in 
the materials genome “haystack” is the ability to accurately 
determine how any material specimen absorbs energy 
at every color of light (frequencies) delivered by the sun. 
Additional challenges are to determine the mechanisms by 
which the absorbed energy (exciton) migrates through the 
system prior to splitting into charges (electrons and holes) 
that are converted to electricity or chemical bonds. 
In addition to the computational design of materials for 
solar cells, photosynthetic mimics, and photochemical 
pathways to fuels, the need to computationally predict 
and optimize a material’s or chemical’s propensity toward 
absorption and transfer of optical energy is ubiquitous and 
relevant to several energy technologies including 
• radiative energy transfer in combustion,
• photocatalysis, and
• interfacial charge transfer.
Computer simulation and prediction of electronic excited 
states and their interactions with light and vibrations in 
molecules and materials can be pursued using several 
different techniques that have been developed during 
the past decade but need further refinement. Examples 
of such capabilities include the solution of the time-
dependent hybrid density-functional theory coupled 
cluster equations, the Bethe-Salpeter equations, and the 
so-called GW equations. However widespread use of 
more than any one of these methods by experts in the 
fields of computational chemistry and materials science is 
rare, and significant but well-defined efforts are required 
to avail all electron dynamics and excited state methods to 
a broad swath of the academic, laboratory, and industrial-
based scientific community. 
For light-harvesting systems, interest is in understanding 
phenomena associated with timescales for charge/energy 
transport that are comparable to the reorganization time 
of the surrounding solvent. Accounting for such dynamics, 
especially in a realistic environment containing defects, 
is difficult but can be obtained from first-principles 
calculations such as quantum mechanics/molecular 
mechanics (QM/MM). However there is no unified or 
universal code that embodies these powerful methods, and 
the development of such a tool would enable the routine 
simulation of light harvesting in realistic systems. To directly 
simulate and understand the transfer of electrons from 
an adsorbed photoexcited dye molecule at the solid-liquid 
interface, semiclassical dynamical approaches relying upon 
publicly available force fields and quantum-mechanical 
methods are required. Additionally, one must account for 
dissipation and transport through the electrode.
National materials and chemistry  
computational networks
As shown in recent work by Ceder, Jacobsen, Norskov, and 
others, it is now possible to scan hundreds of thousands 
of possible combinations of elements across the entire 
periodic table, suggesting many new materials solutions 
that far exceed the traditional intuition of experts in 
Design of molecular and polymer-based solar cells
Solar energy harvesting and processing requires understanding of phenomena mediated by exciton production, 
transfer, and splitting into carriers. Recent ultrafast experiments (above left) demonstrate unusually long-lived 
excitations in the light-harvesting bacteriochlorophyll complex which powers the green sulfur bacteria (two 
middle panels). These algae-like plants and their relatives effectively utilize the nonvisible parts of the solar 
 12 Foundational Challenges in Predictive Materials Science and Chemistry
Excited States for Photochemical 
and Voltaic Conversion
Materials for Light Harvesting 
and Charge Transport
these fields. Even incomplete and low-level theories 
have suggested novel combinations of materials for 
new energy technologies. In principle, finding the best 
solution to solar harvesting and other issues related to 
composition-dependent process optimization can now be 
accomplished using this approach. The challenge of solar 
harvesting cross-cuts the traditional domains of chemistry 
and physics as it requires coupling together capabilities 
for localized excitations, band-to-band transitions, and 
electron transport. However, recent advances in theory, 
algorithms, hardware, and materials and chemical sciences 
are yet to be made available to the majority of scientifically 
and technically capable communities in the United States, 
especially those in the commercial sector—a situation 
which seriously threatens the realization of revolutionary 
breakthroughs in complex materials chemistry and 
materials design. With the exception of the highest-
accuracy quantum-mechanical methods that are generally 
limited to small system sizes, other countries have far 
surpassed the United States in developing software for 
large-scale energy systems. This progress has been 
made possible by large groups of domain researchers 
that are networked together by schemes similar to those 
that were initiated in Europe 15 years ago. Because of its 
tradition of single principal investigator groups working on 
specific problems, the United States has no comparable 
infrastructure for scientific software development. As 
documented in a recent report (International Assessment 
of Research and Development in Simulation-Based 
Engineering and Science, World Technology Evaluation 
Center, 2009) almost all supported, user-friendly codes 
for many-atom systems now come from Europe. Reliance 
on access to nondomestic codes for technology vital to 
this nation’s economic and security interests is untenable; 
therefore, the United States must rectify this situation 
or risk falling further behind technologically. Creation 
of national web-enabled networks would facilitate the 
coordination and sharing of information pertaining to 
materials data, scalable codes, and their implementation 
in new architectures. Networks would consist of one or 
two primary colocated groups that are linked together 
and include many single investigators. Through exchange 
programs they would provide expertise to experimentalists 
in academia, industry, and government. Such exchange 
would also lead to the creation of universal standards for 
materials reseach that would minimize the use of multiple 
codes and methodologies.
Images above (left to right): H. P. Cheng et al.,  cf. J. Phys. Chem. C 113, 
20713–20718 (2009); Moore et al., cf.  JACS 130(32), 10466 (2008).
spectrum. Recent observations of quantum beats in Fenna-Mathews-Olson photosynthetic complexes [Engel et al., 
PNAS (2010)] at different temperatures agree with a computational analysis [cf. Aspuru-Guzik et al., JCP 129 (2008)] 
that identified energy transfer pathways between neighboring chlorophylls in the complex. These computationally taxing 
methods demonstrate that theory can be used to understand this process but call for vastly increasing the computational 
efficiency and complexity of methods for predicting quantum-mediated transport and energy scavenging.  A recent 
example of enhanced computational tools for multiscale computational methods and theories [cf. Wang et al., Nano. 
Lett. (2009)] demonstrated the ability to predict charge mobility in disordered conjugated polymers and can be extended 
to enable atomic-to-macroscale prediction and design of light harvesting in all types of materials such as the complex 
depicted here. At the molecular scale, quantum mechanics establishes the local properties and excited-state energies of 
the charge carriers. On scales of a few nanometers, the underlying molecular morphology determines sites for charge 
localization. Quantum mechanics also determines the rate at which the excited charges hop between locations. At scales 
larger than 10 nm, classical molecular-dynamical simulations and continuum approaches determine how the environment 
influences the active light-harvesting complexes. At scales of 100 nm or more, sophisticated sampling of carrier hopping 
rates gives a macroscopic mobility. 
 13 Foundational Challenges in Predictive Materials Science and Chemistry
Solar Fuels and Artificial 
Photosynthesis
 
FOUNDATIONAL CHALLENGES IN PREDICTIVE 
MATERIALS SCIENCE AND CHEMISTRY
oxidation
2 H2O CO2
HCOOH
CH3OH
H2CH2
4H+
4e–
O2
reduction
Cat Cat
H
H
H H
H
H
O
O
O
O
O
O
O
O
O O
O
O
C
CH3
CH3
C
Fe Ni Fe Ni
Fe Ni
Fe Ni Fe Ni
Controlling chemical reactions: 
Combustion and catalysis
The chemical bond represents the most compact 
non-nuclear energy storage medium known. Gasoline, for 
example, has more than 30 times the energy density of 
lithium-ion batteries. For this reason, chemical reactions 
hold center stage in the storage and release of energy in 
both current devices and those envisioned for a secure 
and sustainable future. The robust nature of chemical 
energy storage is embodied in the millennia between the 
photosynthesis of prehistoric plants, which stored the 
energy of the sun, and the recovery and combustion of the 
resulting fossil fuels today, which releases that energy. The 
challenge for the future is to capture, store, and release 
energy on an immediate timescale and in a sustainable way. 
The predictive simulation of chemical transformations will 
accelerate the transition from utilizing energy stored in 
prehistory to establishing a sustainable cycle of energy 
storage and utilization. There are three principal areas of 
opportunity where design using predictive simulation will 
impact energy technologies:
• Artificial Photosynthesis and Solar Fuels
• Efficient Combustion of Low-Carbon Fuels
• Converting Biomass to Transportation Fuels  
For the first of these, the sun offers an abundant and 
sustainable source of energy that can be used to convert 
water or water and carbon dioxide to fuels or intermediates 
used in the production of fuels. The essential barrier to 
developing this technology to industrial scales is finding 
appropriate photocatalysts that work together to perform 
the complete photosynthetic chemical cycle. 
In the case of low-carbon fuels, efficient combustion 
technologies make use of turbulent reacting flows. 
Development of these technologies requires a combination 
of complex fluid flow simulations and high-accuracy 
chemical kinetic reaction mechanisms that capture the 
complex chemistry of current and future fuels: hundreds of 
reactants and thousands of reactions. 
Finally, the challenge in the production of biofuels is to 
convert the principal components of biomass, a combination 
of cellulose, hemicelluloses, and lignin, into products that 
can be used as a substitute for gasoline and diesel fuel for 
various forms of transportation. The difficulty in meeting 
this challenge is the intrinsic complexity of biomass.
Further development of these three essential energy 
technologies requires predictive simulation that crosses 
many length and time scales. Combustion science is on 
the threshold of a new era of predictive modeling and 
simulation based on the convergence of new computer 
resources and the high-fidelity simulation codes ready to 
exploit them. Artificial photosynthesis, splitting water with 
sunlight, and biomass conversion into fuels all require new 
catalysts. The process of screening potential candidates, 
or synthesizing new ones, in the near future will be 
accelerated by predictive simulation of their properties. 
The computational science communities in each of these 
areas are poised to exploit existing computing technologies 
and extend their simulation algorithms and codes to 
dramatically shorten the time required to build a secure 
energy future.
Artificial photosynthesis
Artificial photosynthesis is the generation of fuels directly from sunlight, water, and carbon dioxide by 
nonbiological, molecular-level energy conversion “machines.” The realization of this process on an industrial 
scale will revolutionize our energy system. This is a very ambitious project that requires significant effort. 
 14 Foundational Challenges in Predictive Materials Science and Chemistry
Clean Combustion of 
Low-Carbon FuelsConverting Biomass to Fuels
Predictive capabilities for chemical design
Simulation and screening of photocatalysts for solar 
fuel production require the computational treatment of a 
large number of elementary processes covering a wide 
spectrum of timescales. Simulation of such processes 
requires methods to calculate the dynamics of charge 
pairs formation, separation, and mechanisms used to 
drive catalytic chemical reactions. Complete and accurate 
modeling of surface catalysis at the molecular level is 
required to predict reaction rates accurately. The tools of 
modern quantum chemistry and molecular dynamics form 
the basis for these needed new capabilities, but they must 
be extended, verified, and deployed on the most powerful 
available computing resources.
Large eddy simulation tools developed over the last decade 
will be required to simulate modern combustion engines 
and capture critical cycle-to-cycle variations in their 
performance. These tools bridge the gap between high-
fidelity, first principles–based direct numerical simulation 
tools and Reynolds-averaged Navier-Stokes tools used 
in current industrial design. In addition, new methods are 
required to automatically generate high-accuracy reaction 
rate sets for arbitrary fuels. 
For biomass conversion, efficient simulation methods 
are required to describe the multiscale dynamics and 
Recent research has yielded enormous advances in our understanding of the subtle and complex photochemistry behind 
the natural photosynthetic system, and in the use of inorganic photocatalytic methods to split water or reduce carbon 
dioxide—key steps in photosynthesis. 
The components of an artificial photosynthesis device are shown. There are two photocatalysts (far left), one to perform the 
oxidation step that converts water into oxygen and hydrogen ions and the other for the reduction step that converts carbon 
dioxide into a usable carbon fuel. Also required are photoelectrochemical membrane layers that provide ionic pathways 
and good optical and light-scattering properties, while remaining impermeable to the product fuels and to oxygen. The DOE 
has recently announced the formation of the Joint Center for Artificial Photosynthesis (JCAP) at the California Institute 
of Technology and the Lawrence Berkeley National Laboratory to develop the components and assemble a working 
device and rapidly transfer research results to private industry for commercialization. The use and further development of 
predictive simulation, including quantum chemical and molecular level treatment of surface catalysis, are key to this project.
Courtesy of (clockwise from top) Nate Lewis (California Institute of Technology), Oak Ridge National Laboratory, J. Chen (Sandia National Laboratories), and 
(left) JCAP (Caltech and Lawrence Berkely National Laboratory)
thermodynamics of solvated biopolymers. Quantum 
chemical simulation of biomass-catalyst interactions 
including the effects of solvent are also needed to help 
guide the selection of catalysts that will facilitate the 
conversion of sugars to suitable substitutes for gasoline 
and diesel. 
All of these simulation capabilities will be developed in 
close collaboration with experiments conducted at the DOE 
Combustion Research Facility and national light source 
facilities at the Advanced Photon Source, Advanced Light 
Source, Linac Coherent Light Source, and in particular the 
ultrafast light sources being developed in the United States 
and abroad.
Decades of development provide a firm foundation for 
methods and algorithms of computational chemistry 
and molecular dynamics that support these three 
technologies. Timely deployment of these technologies 
in a software infrastructure that can be used in federally 
supported projects, like the Joint Center for Artificial 
Photosynthesis, and in industry is critical to capturing the 
benefits of predictive capability in chemical design.
 15 Foundational Challenges in Predictive Materials Science and Chemistry
FOUNDATIONAL CHALLENGES IN PREDICTIVE 
MATERIALS SCIENCE AND CHEMISTRY
Designer fluids: Separations  
and carbon capture
Gases and liquids are collectively called fluids. Many of 
our most important global climate and energy challenges 
relate to fluids and separating them from other fluids or 
from solids. Examples include removing CO2 from fossil 
power plant emissions; purifying water, since sufficient 
water supplies is one of the biggest challenges to ensure 
future global health and prosperity; and extracting high-
energy-content liquid fuels for transportation applications 
from crude oil, or from the liquid mixtures obtained from 
biomass conversion.
Today, the number of possible fluids and fluid mixtures 
that have the potential to revolutionize the world’s 
energy and environmental future is virtually limitless. 
The discovery of new, large classes containing over a 
billion completely tailorable (i.e., designer) liquids, such 
as room-temperature ionic liquids, and new, equally large 
classes of tailorable solids that can be used in adsorption-
based separation processes, such as metal-organic 
frameworks, has made the design space of possible 
fluids and separations processes essentially infinite. 
Thus, computational screening of these processes for 
energy and environmental applications is no longer simply 
desirable—it is imperative. However, the properties of 
fluids, which in turn determine the nature and efficiency 
of the processes used to separate them, depend, often 
very subtly, on the atomic- and molecular-level forces 
within and between molecules (known as force fields). 
Given accurate force fields, methods exist (molecular 
simulation, statistical mechanics) to computationally derive 
the properties needed to evaluate the potential applicability 
and separability of fluids. However, our current predictive 
capabilities are limited because we do not have robust 
methods for predicting force fields in an arbitrary fluid 
mixture. Specifically, we need to be able to predict force 
fields in the absence of experimental data (for systems not 
yet synthesized or characterized).  Data-free force field 
prediction (DF3P) must be achieved by using first-principles 
calculations (quantum chemistry, density functional theory, 
etc.) as input, but given the high computational costs of 
such methods, this is an enormous challenge. Success 
in DF3P will enable true fluid properties prediction and 
revolutionize our ability to optimize and invent new energy 
and environmentally relevant systems. We can envision 
the flow of information beginning with the chemistry of 
a system (its chemical composition) and ending up with 
optimized processes. 
As DF3P is realized, we can invert the flow of information by 
the use of stochastic optimization (e.g., simulated annealing) 
at each step. For example, given a desired process, we can 
determine the properties needed to achieve that process; 
once the required properties are established, we can 
determine the optimal fluids for the process.
The result will be unlimited innovation in energy-relevant 
processes enabled by designer fluids.
Ionic liquids: Non-volatile, tailored solvents for CO2 capture 
To eliminate the single biggest source of greenhouse gases—CO2 production from fossil-fuel-fired power 
plants— CO2 must be captured (i.e., separated) from the flue gas that exits the plant’s furnace and then 
buried underground (i.e., sequestered) or used as raw material for producing other chemicals (including 
liquid fuels). Liquid solvents for CO2 capture selectively dissolve CO2 out of the flue gas and then release 
it in another condition (e.g., different temperature); radically new solvents are needed if CO2 capture is to 
be affordable (i.e., much less than the cost of producing the electricity itself). Among the most promising 
solvents are room-temperature ionic liquids (RTILs) that, unlike salts composed of simple ions (such as 
 
 16 Foundational Challenges in Predictive Materials Science and Chemistry
Designer fluids and separations for a clean energy future
Data-free force field prediction (DF3P) will enable the 
development of computational screening of solvents and 
adsorbents for carbon capture, leading to new, cost-
efficient processes. The urgency of this effort is clear: As 
nations grapple with reducing greenhouse gas emissions, 
carbon capture is poised to become a multi-trillion-dollar 
industry in the next few decades. The time to examine 
alternatives to existing technologies is now and in the near 
future, before industry becomes committed to a specific 
technology, so that most effective carbon capture processes 
can be identified and implemented. Likewise, optimizing 
the extraction of liquid fuels from the mixtures resulting 
from biomass conversion and the purification and/or 
desalination of water are just two of many other profound 
energy/environmental challenges that can be addressed by 
computational modeling made quantitative by a robust DF3P 
capability. DF3P is also a key enabling technology across all 
of chemistry, geochemistry, biochemistry, and engineering: 
any field in which molecular interactions in fluids in bulk 
or at interfaces are important is currently limited by the 
availability of robust, accurate force fields.  
Force field development today is an artisanal activity, 
practiced by many individual research groups with 
different goals, depending on their specific applications. 
For DF3P to become a reality, force field development 
must become an automated workflow utilizing petascale 
and exascale computational resources. We are at the point 
where the confluence of past experience, computational 
resources, and national need make this an imperative. In 
the field of carbon capture alone, failure to do so will result 
in potentially trillions of dollars in infrastructure cost and 
loss of U.S. competitiveness that could have been avoided 
or dramatically reduced by having better alternatives early.
The outputs of a force field–based molecular simulation 
or statistical mechanical calculation of most interest to a 
process designer are thermophysical and themochemical 
properties; however, for experimental validation purposes, 
such methods also predict structures that are much more 
sensitive measures of force field accuracy. The DOE has 
an unequalled collection of experimental facilities for 
measuring structure at the molecular level, including the 
Spallation Neutron Source and the Advanced Light Source, 
that are the perfect tools for validation.
common table salt NaCl), are liquid in their pure state at or below room temperature. RTILs have many unique and highly 
desirable properties for CO2 capture: high solubility for CO2 that can be made even higher by adding functional groups 
such as amine (NH2) that chemically react with CO2, high thermal stability, and low vapor pressure (i.e., they will not 
evaporate during use and can be regenerated in novel ways). By adding cation, anion, and functional groups to RTILs, an 
almost limitless number of ionic liquids can be prepared.
In the future, high-throughput computational screening of possible RTILs must be developed, because to synthesize, 
characterize, and evaluate billions of possible RTILs is simply not feasible. Even today, computational approaches are 
leading the way in the search for new, more effective RTILs for CO2 capture. 
For example, using density functional theory, this year engineers predicted that the addition of an NH2 functional group 
to the negative ion (e.g., see the ion on the left of the reaction shown opposite) resulted in CO2 capture efficiency that is 
twice as high as when the same group is added to the positive ion, and thus twice the efficiency of current technology 
(amines dissolved in water).  This prediction has now been confirmed by experiment.
 17 Foundational Challenges in Predictive Materials Science and Chemistry
FOUNDATIONAL CHALLENGES IN PREDICTIVE 
MATERIALS SCIENCE AND CHEMISTRY
Designer interfaces: From interfacial 
materials to advanced batteries
Fuel cells offer a way to extract twice the energy 
from hydrocarbons as internal combustion engines. 
Photovoltaics provide direct access to the most abundant 
energy source available on our planet. Fiber-reinforced 
polymer matrix composites achieve strength and stiffness 
characteristics paralleling those of steel at a fraction of the 
weight, thus providing for lighter, fuel-efficient vehicles. 
These are but a few examples of devices and structures in 
which functionality is achieved by deliberately juxtaposing 
disparate types of materials, and where the processes 
that are fundamental to the device performance occur at 
the interfaces between constituents. For example, fine-
tuning the bonding interactions between fibers and matrix 
provides for simultaneous high strength and toughness 
of the composite. In solar cells and solid-state lighting, 
the separation and recombination of charge carriers 
at interfaces provide the basis for converting light into 
electricity, or vice versa, and the efficiency of these 
processes depends on the quality and perfection of the 
interfacial region. The long-term stability of the interfaces 
between electrodes and separator membranes is essential 
for sustaining the electrochemical processes responsible 
for the generation or storage of electric energy in fuel cells 
or batteries.
Today, we cannot achieve the highest energy conversion 
efficiencies or create the strongest composites because 
interfaces are imperfect and degrade with time. The key to 
producing materials systems with the desired performance 
characteristics is the ability to fabricate them consistently 
and with nanoscale precision to design specifications. 
This entails the realization of atomically sharp definition 
and long-term stability of interfaces. Hence, detailed 
knowledge about the structure of interfaces and the 
mechanisms of interfacial phenomena, both as they govern 
the functional response of a device and contribute to the 
deterioration of the interface, is essential for advancing 
many critical technologies.
Given their small extent in one dimension and because 
they are typically buried within bulk materials, interfaces 
are difficult to resolve or access by experimental means. 
Simulation and modeling is therefore ideally suited 
to complement experiments and supply the missing 
information.  Computational science and its infrastructure 
will impact research and development with respect to 
interface science in two transformative ways: (1) we 
will be able to use modeling and simulation not simply 
to recreate experimental observations, and thereby 
provide for detailed interpretation, but to generate new 
information that is inaccessible by experiments; (2) through 
combinatorial and high throughput, rational exploration 
of interfacial phenomena, and modeling and simulation 
will yield the necessary fundamental insights to develop a 
predictive design toolset.
With the advancement of HPC, modeling and simulation 
can guide and accelerate materials development. We 
can conceive materials building blocks encoded to self-
assemble into desired configurations, numerically test and 
optimize design criteria for specific interfacial functionality, 
and achieve high figures of merit for multiple performance 
criteria simultaneously, for example, electrolytes with 
high ionic mobility and stiffness, electrodes with high 
intercalation capacity and phase stability, and low-density 
composites with high strength and thermal conductivity.
Predictive capabilities for the design of interfaces 
Unlike with new experimental probes, where breakthroughs 
occur somewhat sporadically, computational power 
10µm 10µm
Micrographs courtesy of Q. Horn and simulations courtesy of Z. Liang and E. Garcia (Purdue University)
 18 Foundational Challenges in Predictive Materials Science and Chemistry
Growth structures in 
semiconductor devices
Oxidation of aluminum 
nanoparticle
 
Polymer–metal interface
increases at a predictable rate due to relatively steady 
progress in chip circuit density and computer architectures. 
Based on the projected performance growth, we can 
mobilize resources to harness this power and engage in the 
creative process that leads to establishing new theoretical 
frameworks, modeling approaches, algorithms, and codes 
for increasingly realistic and demanding simulations that 
allow us to predict interfacial phenomena. Without these 
advances in modeling and simulation, the crucial knowledge 
gap that prevents us from developing technological 
materials with precise control of those properties governed 
by interfaces will persist.
To account for the important phenomena occurring at 
interfaces, features such as the electron distributions within 
the irregular gaps between adjacent materials must be 
resolved, while interfacial reconstructions, defects, and 
roughness are described at scales encompassing millions 
to billions of atoms. To accurately predict the behavior and 
properties of interfaces, realistic structural models must 
first be generated. This requires specialized procedures, 
such as acceleration algorithms, heuristic schemes for 
advancing structural evolution, and statistical sampling 
techniques. Such an inherently multi-scale computational 
challenge must include electronic structure calculations, 
atomistic simulations, and continuum methods, and key 
improvements in the available computational infrastructure 
still need to be achieved. Simulation algorithms and 
statistical analysis formalisms must be adapted to account 
for lack of periodicity and symmetry of interfacial regions. 
Quantum mechanical, particle-based deterministic, 
statistical, and geometric simulation techniques must 
be effectively integrated or coupled through adaptable 
information conduits. Workflow integrators that 
autonomously balance multi-scale simulation tasks, better 
order-N methods for first-principles calculations, and 
more sophisticated reactive force fields will allow us to 
eliminate the trade-off between computational speed and 
accuracy. Validation of these simulation approaches will be 
possible with in situ experimental characterization of buried 
interfaces using powerful new neutron and synchrotron 
sources, Z-contrast high-resolution electron microscopy, 
and nano-probe transport measurements that have only 
recently become available.
Modeling and simulation will provide predictive capabilities 
for the design of interfaces in materials. As a result, we will 
improve the efficiency of solar panels, solid-state lighting, 
thermoelectric generators, and fuel cells; create high-
capacity batteries; fabricate lightweight composites with 
increased strength, stiffness, and toughness; and extend 
the lifetime of materials systems, devices, and components.
Lithium batteries for high-power density
Lithium dendrite growth occurs in all currently used and emerging lithium-based rechargeable battery architectures as 
a result of the electrochemical field localization at high discharge rates, leading to battery failure. Simulations reveal for 
the first time why the dendrite tip grows fifteen times faster than the flat lithium substrate, short-circuiting the device. 
Understanding how to suppress dendrite growth will enable the development of reliable rechargeable batteries with the 
high-power densities needed for automotive applications.
Shown at left: (a and b) examples of dendrites in lithium batteries; (c) a simulation of a lithium dendrite in the presence of 
a 3 V potential difference; (d) the cross section of the electric fields and simulated dendrite growth profile.
Images (above) courtesy of J. Sethian (University of California-Berkeley); 
P. Vashista (University of Southern California); and C. Shao, K. Becher, 
and J. Kieffer (University of Michigan)
 19 Foundational Challenges in Predictive Materials Science and Chemistry
FOUNDATIONAL CHALLENGES IN PREDICTIVE 
MATERIALS SCIENCE AND CHEMISTRY
Controlling electronic structure: 
Modeling strongly correlated electrons
Strongly correlated materials, whose behavior is 
dominated by the Coulomb repulsion among electrons, 
are exceptionally rich in dramatic behavior and useful 
functionality. Magnets that enable digital memory, 
superconductors that carry electricity without loss above 
liquid nitrogen temperature, actinides that power nuclear 
reactors, and quantum dots that enable nanotechnology 
are all strongly correlated materials. These materials 
typically display a host of competing phases closely spaced 
in energy (see figure at lower left) leading to “colossal” 
response to small external stimuli, a feature with endless 
potential for technological exploitation.
Although we use some of these materials on an empirical 
basis, we cannot model, predict, or control their properties 
as we do for semiconductors like silicon. This lack of 
predictive capability is a severe bottleneck—strongly 
correlated materials are so common and their compositions 
and structures so complex that they simply overwhelm 
serendipity as a discovery and development tool. Reliable 
predictions of the behavior of strongly correlated materials 
are critical for designing the next generation of globally 
competitive information, communication, sensing, and 
clean energy technologies.
In the past decade, however, strongly correlated materials 
have begun to yield their secrets to a host of modeling 
approaches that go beyond existing density functional 
theory. The challenge set by strongly correlated electrons 
is to develop methods that can simultaneously describe the 
strong correlations that can lead to localization of electrons 
on atomic sites and the weak correlations that allow 
itinerant electrons to move freely throughout a material. 
For 50 years this problem has evaded fundamental 
treatment; we are now on the verge of cracking this 
bottleneck to the understanding and use of strongly 
correlated materials.
The density functional approach excels where dynamical 
correlations are modest in size, which is in the weakly 
correlated materials. Static extensions of density functional 
theory have proven useful, but the real need for the 
future is to treat strong dynamic correlations directly. 
Impressive advances have recently been made in this 
area, with dynamical mean field implementations providing 
the solution to several long-standing, classic problems. 
Quantum Monte Carlo techniques promise essentially 
exact solutions that, due to technical challenges and issues 
of scaling with system size, will require a longer time 
frame for broad application. Low-dimensional correlated 
systems present additional challenges, and density matrix 
methods are most promising for this class. 
Achieving predictive capability
The challenge and the opportunity are to take the 
treatment of strongly correlated materials to the same 
level of accuracy, accessibility, and confidence as we have 
achieved for weakly correlated electrons with density 
functional theory using the local density approximation. 
The opportunity has never been as clear in form or 
as ripe for harvest as it is now. The community is at a 
tipping point—a critical mass of ideas, researchers, and 
techniques is at hand.
Crucial extensions of density functional theory are 
required, with the dynamical treatment of intra-atomic 
The pressure-temperature phase diagram of manganese oxide 
(MnO) illustrating the many competing phases that depend 
on the local/itinerant character of the strongly correlated 3d 
manganese electrons. Promising advances in treating the 
behavior of strongly correlated electrons by dynamical mean 
field theory, extended density functional theory, density matrix 
renormalization group, and quantum Monte Carlo techniques 
bring within reach the capability to predict the complex phase 
diagrams and materials properties of correlated electron 
materials for technological applications. 
Courtesy of C. S. Yoo, B. Maddox, J.-H. P Klepeis, V. Iota, W. Evans, 
A. McMahan, M. Y. Hu,  P.  Chow, M. Somayazulu, D. Häusermann, 
R. T. Scalettar, and W. E. Pickett, Physical Review Letters 94, 115502. 
Copyright (2005) by the American Physical Society.
300
T(K)
P(GPa)1059030
B1 (PM)
118
Insulator
1500
B8 (PM)
MetaldB1 (AFM)
B8 (DM)
 20 Foundational Challenges in Predictive Materials Science and Chemistry
Courtesy of  M. Ferrero, P. S. Cornaglia, L. De Leo, O. Parcollet, 
G. Kotliar, and Antoine Georges, Physical Review B 80, 064501. 
Copyright (2009) by the American Physical Society.
The evolution of Fermi arcs in the pseudogap 
state of the high-temperature superconductors 
predicted by cluster extensions of dynamical 
mean field theory as hole doping increases 
from 8% to 20%. The Fermi arcs arise from the 
localization of some of the electronic states in 
momentum space, while others remain itinerant, 
one of the most startling and dramatic features 
of strong correlation in the high-temperature 
superconductors.  
interactions and of interactions of localized and itinerant 
electrons comprising the minimum requirements. The 
energy resolution of correlated electron treatments needs 
to be increased in order to treat the low energy states, 
where electrons fluctuate on short timescales between 
local and itinerant character. This rapid fluctuation 
between dual existences lies at the very heart of strongly 
correlated behavior.
One fundamental barrier to modeling strongly correlated 
materials is the continuing lack of resources and 
mechanisms for development of robust, open-source 
computer codes in the United States, a trend dating 
from the 1980s. Europe has demonstrated the power of 
supporting code development; they are now dominant 
in the world in producing codes for materials science. 
East Asia and China are rapidly emerging leaders; by 
2012 China will overtake the United States in publications 
based on first-principles density functional theory. The 
United States must develop policies and procedures 
that will nurture the collective effort of its scientists and 
engineers to establish the next generation of open-source 
materials simulation methods and community codes. The 
United States has the accumulated expertise and creative 
inspiration, but the mechanisms to develop robust, user-
friendly open-source software are missing. In addition, full 
integration of software with the revolutionary advances 
occurring in hardware and computational paradigms is 
needed if we are to achieve predictive materials capability. 
An effective implementation strategy that capitalizes on 
existing theoretical and computational capabilities will 
increase the number of productive users and the frequency 
of potentially transformative advances. 
Experimental validation is essential to developing predictive 
capabilities for strongly correlated electron materials. Many 
strongly correlated electron phenomena take place at 
ultrasmall spatial scales and ultrafast timescales. Continuing 
advances in experimental tools such as x-ray free electron 
lasers, aberration-corrected electron microcopy, high-
resolution photoemission, diffuse neutron scattering, and 
scanning probe microscopy are critical to probe, verify, and 
refine the theory and modeling predictions. 
The rewards of predicting the behavior and functionality 
of strongly correlated materials are enormous—
next-generation magnetic memories, spintronic and 
metal-insulator (“Mott-tronic”) digital logic, high-resolution 
sensors for electromagnetic radiation and environmental 
chemicals, and better performing high-temperature 
superconductors, among others. The competitive 
advantage to the institutions or countries that develop this 
new capability eminently justifies the effort. 
π
.09
.06
.03
0-π
-π π
ky0
0
kx
8%
6
4
2
0
π
-π
-π π
ky0
0
kx
20%
Momentum dependence of strong correlation
 21 Foundational Challenges in Predictive Materials Science and Chemistry
Materials and chemistry by design:  
Creating an innovation ecosystem
Modeling and simulation is today a critical part of every discipline of science and 
engineering. However, while models and methods are well understood in areas such as 
structural engineering and modeling tools are embedded within several related industry 
sectors, simulation-based engineering and science capabilities for materials research 
are much less mature. Although scientific models and algorithms are in hand for many 
materials applications, critical information is missing for others, and there is only a handful of 
simulation-based materials design tools sufficiently predictive and robust for industrial use. 
As a result, despite many successful examples of the use of simulation-based engineering 
and science, we have only just begun to exploit its full capabilities and promise for discovery 
and innovation when it comes to the critical pacing technologies of new materials. Emerging 
capabilities in predictive modeling and simulation have the potential to revolutionize the 
development of new materials and chemical processes. Coupled with world-leading materials 
characterization and nanoscale science facilities, this predictive capability provides the 
foundation for an innovation ecosystem that can accelerate discovery and the development 
of new technologies, including advanced energy systems.
Achieving predictive capability
To lead in R&D for energy and other technologies, the United States must establish a 
predictive capability based on simulation-based engineering and science that is second to 
none. Developing and sustaining this capability requires a long-term commitment that is at 
the same time financial, intellectual, and programmatic. It requires ongoing investment in all 
aspects of computational science and engineering—from theory, models, and algorithms 
to languages and compilers, to faster computers, to software and open-source databases, 
to workforce. It requires close partnership between experiment, theory, and simulation to 
advance fundamental scientific understanding and to quantify the uncertainty inherent in any 
prediction, which is required for risk assessment and decision-making. It requires expediting 
and facilitating the transformation of scientific research codes to design tools suitable 
for the industrial laboratory setting and manufacturing floor, and the training of a future 
workforce sufficiently expert to both develop and use these tools. Together, these elements of 
computational science and engineering form the foundational infrastructure for the predictive 
capability afforded by simulation-based engineering and science. 
Integration of synthesis, processing, characterization, theory, 
and modeling and simulation
Recent advances in high-performance computing have been nothing short of astounding. 
Over the past decade, computational power has increased by a factor of a million due to 
advances in hardware and software. Fast new chips developed primarily for the brilliant 
graphics needed by the billion-dollar video game industry and supported just in the last year 
or two for use by the scientific community are providing additional spectacular increases in 
speed for many codes, including those used by the materials and chemistry communities. 
Because of these advances we now have computer simulations capable of overnight results 
with unprecedented fidelity. 
At the same time, the United States has developed over the past two decades the world’s 
most powerful collection of research facilities for materials and chemical sciences. Our 
synthesis and characterization facilities enable unprecedented insight into, and manipulation 
at, the nanoscale, the length scale where properties are determined and chemical reactions 
 22
are controlled. For the first time in history, simulation and experiment now meet on 
common ground at this critical scale, providing an unparalleled opportunity for scientific 
insight and the parameterization and testing of theories and models central to predictive 
simulation for materials and chemical processes. Only through the integration of synthesis, 
characterization, and modeling and simulation of complex materials and chemical processes 
will we transform our ability to understand and design new materials and chemistries with 
predictive power. This integration requires investments in fundamental experiments and 
theory whose primary aim is to provide measurements or analytical values, respectively, as 
both inputs to and validation of materials and chemical models and codes. It also requires 
the development of open-source community databases and virtualization tools for the 
capture, sharing, and reuse of reference materials data, and a long-term commitment to the 
education and training of a new generation of data-centric and cyber-savvy scientists fluent 
in the “language” of both experiment and simulation, and capable of developing and using 
sophisticated software tools.
Simulation-based engineering and science (SBE&S) as a critical 
and sustainable national infrastructure
The United States gave birth to the modern field of electronic digital computing back in the 
early days of World War II. We have come far from the first digital predictions of ballistic 
firing trajectories, with simulations today yielding critical insights into the beginnings of 
disease, the atomistic mechanisms behind material failure, the development and likely path 
of hurricanes, and even impending crises in the stock market. The investments we have 
made as a nation in the field of computing and in computational science and engineering 
provide the foundation for the next essential step—the integration and full-scale 
deployment of computational methodologies as community tools for predictive simulation. 
This step requires investment in software as infrastructure, which in turn requires 
substantial investment in and long-term support and nurturing of software development 
communities and the codes they develop; in the development, validation, and verification of 
models, algorithms, and databases; in the preparation of a highly skilled SBE&S workforce; 
and in the continued development of both commodity and high-end computing technologies 
and the infrastructure to use them. 
Critical elements of a national infrastructure for simulation-based engineering and science 
capable of transforming our predictive capability for materials and chemical processes 
include a capacity for the following:
• ongoing development of new theories of materials and chemical processes and 
their rapid integration into robust, validated software;
• ongoing development of new computational algorithms and methods, including 
multiscale methods, as well as new computing platforms;
• validation, verification, and uncertainty quantification, including “open-data” 
community databases of validation data from experiments, theory, and simulations;
• development, dissemination, and long-term support of materials models, 
codes, and simulation platforms, with particular attention to code maintenance, 
interoperability, sharing, and reuse;
• sustainable partnering among industry, government, and academia in the 
development, application, and use of SBE&S tools; and
• educating and training the next generation of computational scientists and engineers. 
 23 
Benefits of predictive capability  
in science and engineering
Accelerating scientific discovery
The scientific discovery process is not linear—it follows an often chaotic path of intuition, 
trial and error, and serendipity. While we cannot schedule serendipity, we can strengthen 
intuition and optimize trial and error through improved predictive capability enabled by 
advances in modeling and simulation. This is essential if we are to explore the enormous 
phase space presented by the complex materials and 
processes that are key to achieving needed performance 
gains. Predictive capability accelerates discovery by guiding 
experiments in the most productive directions, by reducing 
the number of options or configurations that need to be 
tried, by suggesting specific breakthrough opportunities for 
experimental verification, and by providing powerful tests 
for theories that improve fundamental understanding. In 
many cases, progress demands predictive capability due to 
the complexity that must be navigated. 
The development and application of predictive modeling and simulation are transforming 
the discovery process. Rational discovery strategies can now be implemented for complex 
systems that were not tractable a few years ago. This greatly increases the parameter space 
that can be explored and significantly reduces the time required for this exploration. Due to 
advances in computing power, modeling and simulation have become powerful components 
of a tightly coupled discovery system dependent on the integration of experimental, 
theoretical, and computational capabilities. Building on recent advances in experimental and 
computational facilities, the United States is well positioned to lead this integration and the 
subsequent acceleration of scientific discovery. 
Enabling new technologies
Predictive capability is also driving the transformation of technological innovation. New 
materials and chemical processes are needed to meet demanding performance requirements 
across the broad spectrum of advanced energy technologies. The development of new 
materials, from discovery to deployment, has typically required two decades. On the other 
hand, the product development and manufacturing cycle has been reduced by computer-
aided design to as little as 3 years. This mismatch precludes incorporation of new materials 
in products in a timely manner, sacrificing both performance and competitiveness. 
Integrated computational materials engineering has been shown to accelerate the introduction 
of new materials and processes into the product development cycle by minimizing testing 
requirements, reducing failures, and increasing quality. Early successes in several industry 
sectors have demonstrated significant return on investment and reduced development times. 
Combining integrated computational materials engineering with accelerated discovery of new 
materials and processes offers the opportunity to incorporate new materials earlier in the 
product design cycle, increasing performance and shortening the materials development cycle 
to better align with product development. The impact is a reduction in the development cycle 
with significant impacts on technology deployment and innovation.
Predictive capability is transforming 
the discovery process, enabling 
rational discovery strategies for 
systems that were not tractable a 
few years ago.
 24
Seizing the opportunity
Recent federal investments in world-leading materials characterization, nanoscale science, 
and computational facilities have prepared the foundation for an innovation ecosystem that 
can accelerate discovery in materials science and chemistry. Creating this ecosystem is pivotal 
in order to capture the benefits of these investments and secure the resulting competitive 
advantage. Delivering on the promise of this ecosystem is dependent on the following.       
• Integration of synthesis, processing, characterization, theory, and 
simulation and modeling. Many of the newly established Energy Frontier 
Research Centers and Energy Hubs are exploiting this integration. 
• Achieving/strengthening predictive capability in foundational 
challenge areas. Predictive capability in the seven foundational challenge 
areas described in this report is critical to the development of advanced energy 
technologies.
• Developing validated computational approaches that span vast 
differences in time and length scales. This fundamental computational 
challenge crosscuts all of the foundational challenge areas. Similarly challenging is 
coupling of analytical data from multiple instruments 
and techniques that are required to cross these 
length and time scales.
• Experimental validation and quantification 
of uncertainty in simulation and modeling. 
Uncertainty quantification becomes increasingly 
challenging as simulations become more complex.
• Robust and sustainable computational 
infrastructure, including software and applications. For modeling 
and simulation, software equals infrastructure. To validate the computational 
tools, software is critical infrastructure that effectively translates huge arrays of 
experimental data into useful scientific understanding. An integrated approach for 
managing this infrastructure is essential.
• Efficient transfer and incorporation of simulation-based engineering 
and science in industry. Strategies for bridging the gap between research 
industrial applications and for widespread industry adoption of integrated 
computational materials engineering are needed.
Advances in materials and chemistry are essential to leadership in virtually all technologies. 
The integration of simulation-based engineering and science into the discovery process 
provides a transformational opportunity to accelerate innovation and achieve unprecedented 
performance, with profound implications for the pace of discovery and the development of 
new technologies.
Achieving predictive capability 
in materials and chemistry is 
critical to accelerating discovery 
and the development of new 
technologies.
 25 
Workshop Agenda
 DOE Workshop on Computational Materials Science and Chemistry for Innovation 
 Monday July 26
7:30–8:15 am Registration; Continental Breakfast 
8:15–8:30 am Welcome 
 Steve Koonin, Under Secretary for Science
8:30–8:45 am Workshop overview and goals 
 Jim Roberto, Oak Ridge National Laboratory  
8:45–9:15 am Basic research for energy 
 Harriet Kung, Associate Director, Office of Basic Energy Sciences 
9:15–9:30 am Computational materials science and chemistry for innovation
 Michael Strayer, Associate Director, Office of Advanced Scientific Computing Research  
9:30–10:00 am High performance computing: Opportunities and cross-cutting issues 
 Paul Messina, Argonne National Laboratory  
10:00–10:30 am Opportunities and challenges in computational chemistry and materials science: 
Report from the BES Workshop on Extreme-scale Computing
 Thom Dunning, University of Illinois 
10:30–10:45 am Break
10:45–11:15 am Simulation-based engineering and science for discovery and innovation
 Chuck Romine, National Institute of Standards and Technology  
11:15–11:45 am The Materials Genome Project: High-throughput ab-initio computing
 Gerd Ceder, Massachusetts Institute of Technology  
11:45 am–12:00 pm Charge to breakout groups 
 Sharon Glotzer, University of Michigan  
12:00–1:15 pm Working lunch: Designing a national research initiative
 Tom Kalil, Deputy Director for Policy, White House Office of Science and Technology Policy 
1:15–5:30 pm Panel breakouts
 Panel 1: Materials for extreme conditions 
 Panel 2: Chemical reactions  
 Panel 3: Thin films, surfaces, and interfaces   
 Panel 4: Self-assembly and soft matter  
 Panel 5: Strongly correlated electron systems and complex materials  
 Panel 6: Electron dynamics, excited states, and light-harvesting materials and processes 
 Panel 7: Separations and fluidic processes 
 
5:30–6:30 pm Working dinner: Integrated computational materials 
 John Allison, Ford/University of Michigan 
 Tuesday July 27
7:30–8:15 am Breakfast 
8:15 am–12:00 pm Panel breakouts continue  
12:00–1:00 pm Working lunch  
1:00–4:00 pm Reports from each panel  
4:00–4:15 pm Closeout  
 26
Registered participants for the DOE Workshop on Computational Materials  
Science and Chemistry for Innovation
Abild-Pedersen, Frank    SLAC National Accelerator Laboratory    Invited Observer  
Allison, John    Ford Motor Company / University of Michigan    Plenary Speaker  
Aronson, Igor    Argonne National Laboratory    Panel Co-Lead  
Aspuru-Guzik, Alan    Harvard University    Panelist  
Bair, Ray    Argonne National Laboratory    Panel Co-Lead  
Baruah, Tunna    University of Texas at El Paso    Panelist  
Bell, Alexis    University of California, Berkeley    Panel Co-Lead  
Bell, John    Lawrence Berkeley National Laboratory    Panelist  
Bishop, Alan    Los Alamos National Laboratory    Invited Observer  
Biven, Laura    Department of Energy, Office of Science    Invited Observer  
Blaisten-Barojas, Estela    National Science Foundation    Invited Observer  
Brown, David    Lawrence Livermore National Laboratory    Panelist  
Burke, Kieron    University of California, Irvine    Panelist  
Carim, Altaf    Department of Energy, Basic Energy Sciences    Invited Observer  
Carter, Emily    Princeton University    Panelist  
Ceder, Gerbrand    Massachusetts Institute of Technology    Plenary Speaker  
Chatterjee, Lali    Department of Energy, Office of Science    Invited Observer  
Chen, Chau-Chyun    Aspen Technology, Inc.    Panelist  
Chen, Gang    Massachusetts Institute of Technology    Panelist  
Chipman, Daniel    University of Notre Dame, Radiation Laboratory    Panelist  
Clark, Aurora    Washington State University,  Panelist  
Colella, Phillip    Lawrence Berkeley National Laboratory    Panelist  
Colina, Coray    Pennsylvania State University    Panelist  
Cooper, Clark    National Science Foundation    Invited Observer  
Corrales, Rene    The University of Arizona    Panelist  
Cummings, Peter    Vanderbilt University / ORNL Panel Co-Lead 
D’Azevedo, Ed    Oak Ridge National Laboratory    Panelist  
Davenport, James    Department of Energy, Basic Energy Sciences Invited Observer  
Dean, David    Department of Energy    Invited Observer  
Dehmer, Patricia Department of Energy, Office of Science Invited Observer
Devanathan, Ram    Pacific Northwest National Laboratory Panelist  
Dunietz, Barry    University of Michigan    Panelist  
Dunning, Thom    NCSA / University of Illinois  Plenary Speaker 
Falk, Michael    Johns Hopkins University    Panelist  
Farrell, Helen     Idaho National Laboratory    Invited Observer  
Fennie, Craig    Cornell University    Panelist  
Ferris, Kim    Department of Energy, Basic Energy Sciences  Invited Observer  
Fichthorn, Kristen    Pennsylvania State University    Panelist  
Foiles, Stephen    Sandia National Laboratories    Panelist  
Fong, Dillon    Argonne National Laboratory    Panelist  
Franceschetti, Alberto    National Renewable Energy Laboratory    Panelist  
Fried, Laurence    Lawrence Livermore National Laboratory    Panelist  
Galvin, Mary Department of Energy, Basic Energy Sciences    Invited Observer  
Ganesan, Venkat    The University of Texas at Austin    Panelist  
Garcia, Edwin    Purdue University    Panelist  
Garofalini, Stephen    Rutgers University    Panelist  
Garrett, Bruce    Pacific Northwest National Laboratory    Panel Co-Lead  
Garrison, Stephen    Savannah River National Laboratory    Invited Observer  
Glotzer, Sharon    University of Michigan    Workshop Co-Chair  
Glownia, Jim    Department of Energy, Office of Science    Invited Observer  
Goldfield, Evelyn    National Science Foundation    Invited Observer  
Gruzalski, Greg    Oak Ridge National Laboratory    Other  
Harding, Lawrence    Argonne National Laboratory    Panelist  
Harmon, Bruce    Ames Laboratory    Panelist  
Harrison, Judith     U.S. Naval Academy   Panelist  
Harrison, Robert    Oak Ridge National Laboratory    Panelist  
Participants
 27 
Hase, Bill    Texas Tech University    Panelist  
Hayes, Robin     Department of Energy, Basic Energy Sciences    Invited Observer  
Helland, Barbara    Department of Energy, ASCR    Invited Observer  
Hess, Daryl    National Science Foundation    Invited Observer  
Ho, Kai Ming    Ames Laboratory / Iowa State University    Panelist  
Horton, Linda    Department of Energy, Basic Energy Sciences    Invited Observer  
Hrbek, Jan    Department of Energy, Basic Energy Sciences    Invited Observer  
Hybertsen, Mark    Brookhaven National Laboratory    Panel Co-Lead  
Iyengar, Srinivasan    Indiana University    Panelist  
Jarrell, Mark    Louisiana State University    Panelist  
Johannes, Michelle    Naval Research Laboratory    Panelist  
Johnson, Duane    Ames Laboratory    Panelist  
Kalil, Tom    White House OSTP Plenary Speaker  
Kamath, Chandrika    Lawrence Livermore National Laboratory    Panelist  
Kao, Chi-Chang     National Synchrotron Light Source    Panelist  
Keblinski, Pawel    Rensselaer Polytechnic Institute    Panelist  
Kent, Paul    Oak Ridge National Laboratory    Panelist  
Khaleel, Moe    Pacific Northwest National Laboratory    Invited Observer  
Kieffer, John    University of Michigan    Panel Co-Lead  
Klippenstein, Stephen    Argonne National Laboratory    Panelist  
Koonin, Steve    Department of Energy    Plenary Speaker  
Kozemchak, Paul    Department of Defense, DARPA Invited Observer 
Krause, Jeff    Department of Energy    Invited Observer  
Kumar, Sanat    Columbia University    Panelist  
Kung, Harriet    Department of Energy, Basic Energy Sciences    Plenary Speaker  
Lahti, Paul    University of Massachusetts, Amherst    Panelist  
Laird, Brian    University of Kansas    Panelist  
Landsberg, Alexandra    Department of Energy, ASCR     Invited Observer
Lee, Steven    Department of Energy, ASCR  Invited Observer 
LeSar, Richard     Iowa State University    Panel Co-Lead  
Lewis, James    West Virginia University    Panelist  
Li, Xiaosong    University of Washington    Panelist  
Lipkowitz, Kenny     Office of Naval Research Invited Observer  
Liu, Ping    Brookhaven National Laboratory    Invited Observer  
Lucchese, Robert    Texas A&M University    Panelist  
Luijten, Erik    Northwestern University    Panelist  
Lumsden, Mark    Oak Ridge National Laboratory    Invited Observer  
Mailhiot, Christian    Lawrence Livermore National Laboratory     Panelist  
Mandrus, David    University of Tennessee / ORNL Panelist 
Markowitz, Michael    Department of Energy, Basic Energy Sciences    Invited Observer  
Marques, Osni    Department of Energy    Invited Observer  
Martin, Richard    Los Alamos National Laboratory    Panelist  
Maupin, Paul    Department of Energy, Basic Energy Sciences    Invited Observer  
McCabe, Clare    Vanderbilt University    Panel Co-Lead  
McIlroy, Andrew    Sandia National Laboratories    Panel Co-Lead  
Messina, Paul    Argonne National Laboratory    Plenary Speaker  
Metiu, Horia    University of California, Santa Barbara   Panelist  
Miller, John    Department of Energy    Invited Observer  
Miller, Thomas    California Institute of Technology    Panelist  
Miranda, Raul    Department of Energy, Office of Science    Invited Observer  
Mount, Richard    SLAC National Accelerator Laboratory    Panelist  
Mryasov, Oleg    University of Alabama    Panelist  
Muckerman, James    Brookhaven National Laboratory    Panelist  
Najm, Habib    Sandia National Laboratories    Panelist  
Neaton, Jeffrey    Lawrence Berkeley National Laboratory    Panelist  
Nguyen, Van    Department of Energy, Basic Energy Sciences    Invited Observer  
Ogut, Serdar    National Science Foundation    Invited Observer  
Olvera de la Cruz, Monica    Northwestern University    Panelist  
Ozolins, Vidvuds    University of California, Los Angeles    Panelist  
Participants continued
 28
 
Acknowledgments
Publishing services were provided by Oak Ridge National 
Laboratory (ORNL). The cochairs wish to thank LeJean Hardin, 
Debbie Stevens, and Walter Koncinski for their support in editing 
and producing this report. We also thank Katie Perine (DOE Office 
of Science), Tammy Click and Verda Hill (Oak Ridge Institute for 
Science and Education), and Greg Gruzalski and Debbie Turner 
(ORNL) for providing administrative support for the workshop.
Parkin, Stuart    IBM Research, Almaden    Panelist  
Pederson, Mark    Department of Energy, Basic Energy Sciences    Invited Observer  
Peralta, Juan    Central Michigan University    Panelist  
Perine, Katie    Department of Energy    Other  
Peterson, Brian    ExxonMobil Research & Engineering    Panelist  
Pickett, Warren    University of California, Davis    Panel Co-Lead  
Piecuch, Piotr    Michigan State University    Panelist  
Polansky, Walt    Department of Energy, ASCR   Invited Observer  
Powell, Cynthia    National Energy Technology Laboratory Invited Observer 
Pratt, Stephen    Argonne National Laboratory    Panelist  
Rahn, Larry    Department of Energy, Basic Energy Sciences    Invited Observer  
Rappe, Andy    University of Pennsylvania    Panelist  
Redondo, Antonio    Los Alamos National Laboratory    Panelist  
Roberto, James    Oak Ridge National Laboratory    Workshop Co-Chair  
Rohlfing, Celeste    National Science Foundation    Invited Observer  
Rohlfing, Eric    Department of Energy, Basic Energy Sciences    Invited Observer  
Rollett, Anthony    Carnegie Mellon University    Panelist  
Romine, Chuck    National Institute of Standards and Technology    Plenary Speaker  
Russell, Thomas    University of Massachusetts    Panelist  
Sarrao, John    Los Alamos National Laboratory    Panel Co-Lead  
Schultz, David    Oak Ridge National Laboratory    Panelist  
Schwartz, Andy    Department of Energy, Basic Energy Sciences    Invited Observer  
Scuseria, Gustavo    Rice University    Panel Co-Lead  
Sethian, James    University of California, Berkeley /LBNL Panelist  
Siepmann, Ilja    University of Minnesota    Panelist  
Singer, Marvin    Department of Energy, Basic Energy Sciences    Invited Observer  
Smith, Darryl    Los Alamos National Laboratory    Panelist  
Stevens, Mark    Sandia National Laboratories    Panelist  
Stocks, G. Malcolm    Oak Ridge National Laboratory    Panel Co-Lead  
Stoller, Roger    Oak Ridge National Laboratory    Panelist  
Strayer, Michael     Department of Energy, ASCR Plenary Speaker  
Studt, Felix    SLAC National Accelerator Laboratory    Invited Observer  
Sumpter, Bobby    Oak Ridge National Laboratory    Panelist  
Thornton, Katsuyo    University of Michigan    Panelist  
Travesset, Alex    Ames Lab and Iowa State University    Panelist  
van Schilfgaarde, Mark     Arizona State University    Panelist  
Vashishta, Priya    University of Southern California    Panelist  
Vetrano, John    Department of Energy, Basic Energy Sciences    Invited Observer  
Violi, Angela    University of Michigan    Panelist  
Wadia, Cyrus    White House OSTP    Invited Observer  
Walker, Homer    Worcester Polytechnic Institute    Panelist  
Wang, Cai-Zhuang    Ames Laboratory    Panelist  
Woodward, Nick    Department of Energy, Basic Energy Sciences    Invited Observer  
Xantheas, Sotiris    Pacific Northwest National Laboratory    Panelist  
Yang, Chao    Lawrence Berkeley National Laboratory    Panelist  
Zhu, Jane    Department of Energy, Basic Energy Sciences    Invited Observer  


