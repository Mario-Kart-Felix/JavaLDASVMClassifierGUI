System-level Energy Management for Periodic Real-Time Tasks ∗
Hakan Aydin Vinay Devadas Dakai Zhu
Department of Computer Science Department of Computer Science
George Mason University University of Texas at San Antonio
Fairfax, VA 22030 San Antonio, TX 78249
{aydin, vdevadas}@cs.gmu.edu dzhu@cs.utsa.edu
Abstract
In this paper, we consider the system-wide energy management prob-
lem for a set of periodic real-time tasks running on a DVS-enabled
processor. Our solution uses a generalized power model, in which
frequency-dependent and frequency-independent power components
are explicitly considered. Further, variations in power dissipations
and on-chip/off-chip access patterns of different tasks are encoded in
the problem formulation. Using this generalized power model, we
show that it is possible to obtain analytically the task-level energy-
efficient speed below which DVS starts to affect overall energy con-
sumption negatively. Then, we formulate the system-wide energy
management problem as a non-linear optimization problem and pro-
vide a polynomial-time solution. We also provide a dynamic slack
reclaiming extension which considers the effects of slow-down on
the system-wide energy consumption. Our experimental evaluation
shows that the optimal solution provides significant (up to 50%) gains
over the previous solutions that focused on dynamic CPU power at the
expense of ignoring other power components.
1 Introduction
With the advance of pervasive computing and on-going minia-
turization of computers, the energy management has become a
major research area in Computer Science and Engineering. A
widely popular energy management technique, Dynamic Volt-
age Scaling (DVS), is based on adjusting the CPU voltage and
frequency on-the-fly [27]. Since the dynamic CPU power is
a strictly increasing convex function of the CPU speed, the
DVS techniques attempt to reduce the CPU speed to the ex-
tent it is possible, to obtain higher energy savings. The tasks’
response times tend to increase with the reduced CPU speed:
hence, for real-time systems where timeliness is crucial, spe-
cial provisions must be taken to guarantee the timing con-
straints when DVS is applied. Consequently, the following
Real-Time DVS (RT-DVS) problem attracted much attention
in the research community: Minimize the energy consumption
through DVS while still meeting all the deadlines of the real-
time tasks. In the last decade, literally hundreds of research
studies were published, each tackling the RT-DVS problem for
∗This work was supported, in part, by US National Science Foundation
CAREER award (CNS-0546244).
a different system/task model and/or improving the existing
solutions [2, 3, 19, 22, 20].
More recently, some research groups fine-tuned the prob-
lem, by observing that the task execution times do not al-
ways scale linearly with the CPU speed [5, 9, 23]: In fact,
the off-chip access times (e.g. main memory or I/O de-
vice access latencies) are mostly independent of the CPU
frequency. These works correctly observe that the task’s
workload has a frequency-dependent (on-chip) and another
frequency-independent (off-chip) component. The latter does
not scale with the CPU frequency, and it may be possible to
further reduce the CPU speed beyond the levels suggested by
the earlier studies [2, 19, 22], without compromising the fea-
sibility. Note that an implicit assumption/motivation of this
line of research is that further reduction of the CPU speed will
bring additional energy savings.
Despite the depth and, in many cases, the analytical sophis-
tication of these RT-DVS studies, there is a growing recogni-
tion that for more effective energy management, one should
consider the global effects of DVS on the computer system.
In particular, focusing exclusively on the frequency-dependent
CPU power may hinder the system-level energy management:
the total energy consumption of the system depends on multi-
ple system components (not only CPU) and the power dissipa-
tion does not comprise solely the frequency-dependent active
power. In fact, two recent experimental studies [10, 24] report
that DVS can increase the total energy consumption; mainly
because, with increased task execution times, it may force the
components other than the CPU (e.g. memory, I/O devices) to
remain in active state for longer time intervals.
The main objective of this research effort is to provide a
generalized energy management framework for periodic real-
time tasks. Specifically, when developing our solution, we si-
multaneously consider:
(a) A generalized power model which includes the static,
frequency-independent active and frequency-dependent
active power components of the entire system,
(b) Variations in the system power dissipation during the ex-
ecution of different tasks, and
(c) On-chip / off-chip workload characteristics of individual
tasks.
Given the above information, we show how to compute
the task-level energy-efficient speed below which DVS starts
to adversely affect the overall energy consumption of the sys-
tem. We formulate the system-level energy management prob-
lem for periodic real-time tasks as a non-linear optimization
problem. Then, we show how the task-level optimal speed
assignments (to minimize the overall system energy) can be
computed in polynomial time. Finally, we provide a dynamic
reclaiming extension for settings where tasks may complete
early, to boost energy savings at run-time. As required in real-
time system design, our solutions assure that all the deadlines
are met in both static and dynamic solutions. We also present
simulation results showing the gains yielded by our optimal
algorithm, for a wide range of system parameters.
We note that a number of research groups explored the is-
sues beyond DVS-based CPU power management: for exam-
ple static/leakage power management issues were investigated
in [13, 14, 21]. The interplay between device power manage-
ment and DVS are explored in [8, 16, 18, 25] from different
aspects. Studies in [11, 31] also considered the problem of
system-wide energy minimization for real-time task sets (un-
der different power models), but they did not consider the ef-
fects of off-chip and on-chip workloads, and the proposed so-
lutions were essentially heuristic-based. To the best of our
knowledge, our work is the first research effort to provide a
provably optimal and analytical solution to the system-level
enery management problem for periodic real-time tasks, while
keeping an eye on all three fundamental dimensions (a), (b)
and (c) above.
2 System Model and Assumptions
2.1 Task and Processor Model
We consider a set of independent periodic real-time tasks
Ψ = {τ1, . . . , τn} that are be to executed on a uniproces-
sor system according to the preemptive Earliest-Deadline-First
(EDF) policy. The period of task τi is denoted by Ti, and the
relative deadline of each task instance (job) is equal to the
task period. The jth instance of task τi is denoted by τi,j .
We assume a variable speed (DVS-enabled) processor whose
speed (frequency) S can vary between a lower bound Smin
and an upper bound Smax. For convenience, we normalize
the CPU speed with respect to Smax; that is, we assume that
Smax = 1.0.
The worst-case execution time C(S) of task τi at CPU
speed S is given by Ci(S) = xiS + yi where xi is the task’s
on-chip workload at Smax, and yi is the task’s off-chip work-
load (that does not scale with the CPU speed). Similarly, we
define the task’s effective utilization Ui(S) at CPU speed S as
uxi
S + u
y
i . Here, u
x
i =
xi
Ti
and uyi =
yi
Ti
represent the utiliza-
tion of the on-chip workload (at maximum speed) and off-chip
workload of τi, respectively.
The base total utilization Utot of the task set is the aggre-
gate utilization of all the tasks at the maximum CPU speed,
that is Utot =
∑n
i=1 Ui(Smax). The necessary condition for
the feasibility of the task set is Utot ≤ 1.0, further, this is
also sufficient in the case of preemptive EDF scheduling pol-
icy [15]. Hence, throughout the paper, we will assume that
Utot does not exceed 100%.
We assume that the process descriptor of each task/job is
augmented by two extra fields, the current speed and the nomi-
nal speed. The former denotes the speed level at which the task
is executing and the latter represents the “default” speed it has
whenever it is dispatched by the operating system prior to any
dynamic adjustment. The current and nominal speeds of the
periodic task τi are denoted by Si and Ŝi, respectively. Note
that the task set’s total effective utilization on DVS-enabled
settings depends on the speed assignments of individual tasks
and is given by
∑n
i=1 Ui(Si). Although the results in this pa-
per are derived assuming a continuous CPU speed spectrum,
one can always “adapt” these solutions to discrete-speed set-
tings by using a combination of two nearest available speed
levels [12].
2.2 Power Model
In this paper, we adopt a generalized form of the system-level
power model which was originally proposed in [30] and used
in [28, 29]. In our general system-level power model, the
power consumption P is given by
P = Ps + (Pind,i + Pdep,i) (1)
where Ps represents the static power, which may be removed
only by powering off the whole system. Ps includes (but not
limited to) the power to maintain basic circuits, keep the clock
running and the memory and I/O devices in sleep (or, stand-
by) mode.
Pind,i and Pdep,i represent the frequency-independent ac-
tive power and frequency-dependent active power of the
currently running task τi, respectively. The frequency-
independent power corresponds to the power component that
does not vary with the system supply voltages and processing
frequencies. Typically, the active power consumed by off-chip
components such as main memory and/or I/O devices used by
task τi would be included in Pind,i. Note that the power of
these devices can be efficiently removed only by switching to
the sleep state(s) [10].
Pdep,i includes the processor’s dynamic power as well as
any power that depends on system supply voltages and pro-
cessing frequencies [7]. Pdep,i depends on the CPU speed
(clock frequency), as well as the effective switching capac-
itance Cf,i of task τi. Pdep,i can be usually expressed as
Cf,i · Smi , where dynamic power exponent m is a constant
between 2 and 3, and Si is the current speed of τi.
The coefficient  represents system states and whether ac-
tive powers are currently consumed in the system. Specifically,
 = 1 if the system is active (defined as having computation in
progress); otherwise (i.e. the system is in sleep mode or turned
off)  = 0.
Despite its simplicity, the above model captures the es-
sential components of power consumption in real-time sys-
tems for system-level energy management. In fact, one con-
tribution of this paper is to extend the model in [28, 30] to
the cases where the frequency-independent and frequency-
dependent active power figures can vary from task to task.
The time and energy overhead of completely turning off
and turning on a device that is actively used by any task may
be prohibitive [6]. Consequently, for the real-time embed-
ded systems considered, we assume that several components
may be put to low-power sleep states for energy savings but
they are never turned off completely during the execution. In
other words, Ps is not manageable (i.e. it is always consumed).
Hence, our target is to obtain energy savings through manag-
ing the frequency-independent and frequency-dependent ac-
tive power discussion.
3 Derivation of Energy-Efficient Speed
Consider a real-time task τ with on-chip workload x and off-
chip workload y. The execution time af τ at the CPU fre-
quency (speed) S is given by C(S) = xS + y. The sum of the
frequency-dependent and frequency-independent components
of the energy consumption of task τ at speed S is:
E(S) = (Pdep(S) + Pind) · (x
S
+ y)
= Pdep(S) · x
S
+ Pdep(S) · y + Pind · x
S
+ Pind · y
(2)
Recalling that Pdep(S) is given as Cf · Sm where m ≥ 2,
and x, y, Pind are all positive constants, we can see that each of
the four terms appearing in the latter sum is strictly convex for
all S ≥ 0. Since the sum of convex functions is also convex,
the basic principles of convex optimization [17] allow us to
deduce the following.
Proposition 1 The task energy consumption function E(S) is
a strictly convex function on the set of positive numbers. E(S)
has a single local minimum value and the speed that minimizes
E(S) can be found by setting its derivative E′(S) to zero.
Definition 1 The CPU speed that minimizes the energy con-
sumption of task τ is called the energy-efficient speed of τ and
denoted by Seff .
For the most common cases where the frequency-dependent
power is CfSm with m = 2 or m = 3, setting the derivative
of E(S) will give rise to the cubic or quartic equations that
can be solved analytically [26]. As an example, if m = 3,
we obtain a polynomial equation of fourth degree (a quartic
equation):
3 Cf y S4 + 2 Cf S3 x − Pind x = 0 (3)
If the ratio of the task’s off-chip workload to the on-chip
workload is α = yx , Equation (3) is equivalent to:
3 Cf α S4 + 2 Cf S3 − Pind = 0 (4)
Through the Descartes’ Rule of Signs [26], one can check
that this equation has exactly one positive real root, which cor-
responds to Seff . Hence, the energy-efficient speed Seff is
uniquely determined by Cf , α and Pind. Let us denote the
root of Equation (4) by Seff (Cf , α, Pind). Simple algebraic
manipulation verifies the following properties:
• Seff (Cf , α1, Pind) ≤ Seff (Cf , α2, Pind) if α1 ≥ α2.
In other words, the energy-efficient speed decreases with
increasing off-chip workload ratio for the same effective
switching capacitance and frequency-independent power
values.
• Seff (Cf1 , α, Pind) ≤ Seff (Cf2 , α, Pind) if Cf1 ≥ Cf2 .
Hence, the energy-efficient speed decreases with increas-
ing effective switching capacitance for the same off-
chip/on-chip workload ratio and frequency-independent
power values.
• Seff (Cf , α, Pind1) ≥ Seff (Cf , α, Pind2) if Pind1 ≥
Pind2 . This shows that the energy-efficient speed in-
creases with increasing frequency-independent power for
the same effective switching capacitance and α values.
Note that this result is the generalization of the energy-
efficient speed derivation in [30], where the authors did not
consider the off-chip access time of tasks. In fact, by setting
y = 0 in Equation (3), one can re-derive the result in [30].
As a concrete example, we investigate how the energy-
efficient speed of a single task changes, as we vary the
frequency-independent active power (Pind) and the ratio of
task’s off-chip workload to on-chip workload ratio (see Fig-
ure 1). The task’s effective switching capacitance is set to
unity, and the frequency-dependent active power is given by
S3. Observe that, the figure verifies the trends mentioned
above. It is interesting to note that Seff is very close to 0.375
even for Pind = 0.11, and keeps increasing with larger Pind.
The rate of increase is even higher for cases where the por-
tion of the on-chip workload grows. In fact, if y = 0 (the
1The differences between the energy-efficient speed values corresponding
to different α values at Pind = 0.1 are extremely small.
assumption of most early DVS studies), the increase in Seff
is sharpest.
 0
 0.2
 0.4
 0.6
 0.8
 1
 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1
E
n
e
rg
y 
E
ff
ic
ie
n
t 
S
p
e
e
d
Pind
α = 0.0
α = 0.25
α = 0.67
α = 1.0
Figure 1: Energy-efficient speed as a function Pind and α
 0
 0.2
 0.4
 0.6
 0.8
 1
 0.3  0.4  0.5  0.6  0.7  0.8  0.9  1
E
n
e
rg
y 
C
o
n
su
m
p
tio
n
Task Speed
Pind= 0.2
Pind = 0.4
Pind = 0.6
Pind = 0.8
Figure 2: Energy consumption as a function of the CPU speed
Figure 2 depicts the effect of varying the CPU speed on
the total energy consumption (for α = 0.25). In these set-
tings, Seff is never below 0.5, and reducing the CPU speed
below that level, in some cases, increases overall energy con-
sumption even more significantly than using very high speeds.
This example shows that violating the energy-efficient speed
boundary may be detrimental for total energy consumption.
At this point, two observations are in order: First, since dif-
ferent tasks may use different I/O devices and may have differ-
ent effective switching capacitance and off-chip/on-chip work-
load ratios, in general, the energy-efficient speed will vary
from task to task. Second, the timing constraints of the task
set may force the use of a higher speed for a given task τi, but
Si should never be reduced below Seff,i (which is τi’s energy-
efficient speed), because doing so increases the task (and sys-
tem) energy consumption.
4 Static Optimal Solution
In this section, we consider the following problem: Given a
DVS-enabled CPU and a periodic task set Ψ = {τ1, . . . , τn},
where each task may have different frequency-independent
and frequency-dependentactive power consumption character-
istics as well as different on-chip execution and off-chip access
times, find the task-level speed assignments that would mini-
mize overall energy consumption while preserving the feasi-
bility.
First, we would like to underline that it is relatively easy to
justify the same speed assignment to different instances (jobs)
of the same task: this follows from the convexity of task energy
function2.
Based on this, the energy minimization problem over the
hyperperiod (least common multiple, LCM, of all the task pe-
riods) can be casted using the utilization information of tasks.
Specifically, we can re-write Equation (2) as:
Ei(Si) = (Pdep,i(Si) + Pind,i) · (u
x
i
Si
+ uyi ) · LCM (5)
to express the energy consumption of task τi during the hyper-
period.
Then, the problem becomes finding the {Si} values so as
to:
minimize
n∑
i=1
Ei(Si) (6)
subject to
n∑
i=1
uxi
Si
≤ Ubound = 1 −
n∑
i=1
uyi (7)
Smin ≤ Si ≤ Smax i = 1, . . . , n (8)
This is a separable convex optimization problem with convex
constraints.
Above, the constraint (7) encodes the feasibility condition:
with EDF, the effective utilization of the task set cannot ex-
ceed 100%. The effective utilization of the task set is given
by
∑n
i=1
uxi
Si
+
∑n
i=1 u
y
i . Observe that the total utilization
due to off-chip access times, namely
∑n
i=1 u
y
i , does not de-
pend on the CPU speed. Hence, the total utilization due to
the on-chip computations, namely,
∑n
i=1
uxi
Si
is bounded by
Ubound = 1 −
∑n
i=1 u
y
i . The constraint set (8) gives the mini-
mum and maximum speed bounds of the processor.
As a first step, we process and modify the lower bound con-
straints as it is not beneficial to reduce the speed of any task
below its energy-efficient speed. In fact, this also allows us to
find the optimal speed values for some trivial cases.
Proposition 2 If Seff,i ≥ Smax then Si = Smax in the opti-
mal solution.
This follows from the fact that Ei(Si) is convex on positive
numbers: E′′(Si) > 0 and E′(Si) is strictly increasing. Since
we know that E′i(Seff,i) = 0, we can see that E
′
i(Si) < 0
and Ei(Si) is strictly decreasing in the interval (0, Seff,i]. If
Seff,i ≥ Smax, choosing Si = Smax would minimize Ei(Si),
2If in the optimal solution multiple jobs had different speeds, assigning all
the jobs a new and constant speed which is the arithmetical mean of existing
assignments would hurt neither feasibility nor energy savings.
and consequently, the separable objective function. Further,
running at the maximum speed can never have an adverse ef-
fect on the feasibility.
Hence, without loss of generality, in the remainder of the
paper, we assume that Seff,i < Smax for all the tasks: if this
does not hold for a given task τi, we can easily set its speed
to Si = Smax, update Ubound as Ubound − uxi and obtain a
smaller version of the problem with n − 1 unknowns.
By defining Slow,i = max{Smin, Seff,i}, we can now in-
corporate the energy-efficient speed values to the formulation
of the problem.
minimize
n∑
i=1
Ei(Si) (9)
subject to
n∑
i=1
uxi
Si
≤ Ubound = 1 −
n∑
i=1
uyi (10)
Slow,i ≤ Si ≤ Smax i = 1, . . . , n (11)
We will distinguish two cases for the solution of the op-
timization problem above, depending on whether the quan-
tity
∑n
i=1 Ui(Slow,i) (effective total utilization with Si =
Slow,i ∀ i) exceeds 100% or not. Thanks to the transformation
above, observe that Ei(Si) is strictly increasing in the interval
[Slow,i, Smax] for each task τi. Hence, if total effective utiliza-
tion does not exceed 100% when all tasks run at their energy-
efficient speeds (Case 1), then these speed assignments must
be optimal:
Proposition 3 If
∑n
i=1 Ui(Slow,i) ≤ 1.0 then Si = Slow,i ∀ i
in the optimal solution.
Proposition 3 should be contrasted against the early results
in RT-DVS research [2, 19], where the sole consideration of
dynamic CPU power suggested reducing the speed as much
as the feasibility allows. As can be seen, with frequency-
independent power considerations, some CPU capacity may
remain idle in the system-wide energy-optimal solution. For
Case 2 (
∑n
i=1 Ui(Slow,i) > 1.0), we have the following.
Proposition 4 If
∑n
i=1 Ui(Slow,i) > 1.0 then, in the optimal
solution, the total effective utilization
∑n
i=1 Ui(Si) is equal to
100 %.
Proof: Suppose that
∑n
i=1 Ui(Slow,i) > 1, yet with op-
timal speed assignments {Si},
∑n
i=1 Ui(Si) < 1. Let ∆ =
1 − ∑ni=1 Ui(Si) > 0. Note that since ∆ > 0, there must
be at least one task τj that runs at a speed Sj > Slow,j . It is
always possible to reduce Sj by a small value  in such a way
that it remains above Slow,j and that the total effective utiliza-
tion is still below 100%. Since Ei(Si) is strictly increasing
in the interval [Slow,i, Smax], this would reduce the total en-
ergy consumption and still preserve the feasibility. We reach a
contradiction since the proposed solution cannot be optimal.
Thus, in the case where
∑n
i=1 Ui(Slow,i) > 1.0, we ob-
tain the following optimization problem, denoted as problem
ENERGY-LU.
minimize
n∑
i=1
Ei(Si) (12)
subject to
n∑
i=1
uxi
Si
= 1 −
n∑
i=1
uyi (13)
Slow,i ≤ Si i = 1, . . . , n (14)
Si ≤ Smax i = 1, . . . , n (15)
This a separable convex optimization problem with n un-
knowns, 2 n inequality constraints and 1 equality constraint.
This problem can be solved in iterative fashion in time O(n3),
by carefully using the Kuhn-Tucker optimality conditions for
convex optimization [17]. Full details of our solution are given
in Appendix.
4.1 Experimental Results
In order to quantify the gains of the optimal scheme, we im-
plemented a discrete event simulator. We generated 1000 syn-
thetic task sets, each containing 20 periodic tasks. The peri-
ods of the tasks were chosen randomly in the interval [1000,
72000]. For each task set, we gradually increased the total uti-
lization, and for each utilization value, we iteratively modified
the proportion of the off-chip workload to the total (i.e. the
summation of off-chip and on-chip) workload. For each data
point, the energy consumption of the task set during the hy-
perperiod (LCM) is recorded and an average is computed. The
effective capacitance and frequency-independent active power
of each task was selected randomly according to uniform dis-
tribution in the interval [0.1, 1.0]. The frequency-dependent
active power of task τi is given by Cf,i S3. In this set of exper-
iments, each task instance is assumed to present its worst-case
workload.
We compare the performance of three schemes:
• Our optimal scheme, in which an optimal speed Si is
computed separately for each task τi through the algo-
rithm we described, considering various components of
task’s power consumption, before run-time.
• The scheme in which all tasks run with speed S = Utot.
Note that this speed is known to be optimal for periodic
EDF scheduling [2, 19], but when considering only the
dynamic CPU power.
• The scheme where all tasks run with the speed S∗ =Pn
i=1 u
x
i
1−Pni=1 uyi . This speed is known to be the minimum speed
that still guarantees the feasibility, when one takes into
account the information about the off-chip and on-chip
workloads of tasks [5, 23]. In general, S∗ ≤ Utot, hence,
this approach enables the system to adopt even lower
speed levels without compromising the feasibility.
Figure 3 presents the performance of the three schemes,
as a function of the system utilization Utot. The energy con-
sumption figures are normalized with respect to the case where
Utot = 100%. Here, the ratio of the off-chip workload to the
total workload (namely, γ =
Pn
i=1 u
y
iP
n
i=1(u
y
i +u
x
i )
) is set to 0.2. The
results show that when utilization is high (say, larger than 0.8),
there is little difference between all three schemes, as the sys-
tem has to use high CPU speed to guarantee feasibility. How-
ever, at low to medium utilization values, the advantage of us-
ing the optimal scheme becomes apparent (for Utot ≤ 0.5,
gains around or exceeding 50% are possible). It is also worth
observing that the scheme using the speed S∗ performs worse
than the scheme using S = Utot, simply because, for many
tasks, the energy-efficient speed was found to be greater than
S∗.
In Figure 4, we show the effect of modifying the off-chip
workload ratio γ, when Utot is fixed to 50%. The relative order
of three schemes are the same, however, the advantage of using
the optimal scheme over the (conventional) S = Utot approach
becomes more emphasized at low off-chip workload ratios.
 0
 0.2
 0.4
 0.6
 0.8
 1
 0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1
E
n
e
rg
y 
C
o
n
su
m
p
tio
n
Utilization
S = Utot
S = Optimal
S = S*
Figure 3: Energy consumption as a function of utilization
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0  0.1  0.2  0.3  0.4  0.5
E
n
e
rg
y 
C
o
n
su
m
p
tio
n
Off-chip workload ratio
S = Utot
S = Optimal
S = S*
Figure 4: Energy consumption as a function of off-chip work-
load ratio
5 Dynamic Reclaiming for System-
Level Power Management
The algorithm presented in Section 4 computes the optimal
speed assignments to minimize the system-level total energy
consumption, by taking into account task characteristics as
well as frequency-dependent and independent active powers.
However, in practice, even when one schedules all the tasks
with the corresponding static optimal speeds, many task in-
stances complete without presenting their worst-case workload
in practice. In fact, reclaiming unused computation time to re-
duce the CPU speed while preserving feasibility was subject to
numerous research papers in recent years [2, 3, 9, 19], though
most of them focused exclusively on dynamic CPU power. In
[2, 3], a generic dynamic reclamation algorithm (GDRA) was
proposed for power-aware scheduling of periodic tasks. Later,
the same algorithm was modified for use with power-aware
scheduling of mixed real-time workloads (Extended Dynamic
Reclaiming Algorithm - EDRA) [4] and energy-constrained
scheduling of periodic tasks [1].
The algorithm we are about to present (System-Level Dy-
namic Reclaiming Algorithm - SDRA) is a generalization of
EDRA for system-wide power management. Before present-
ing the specific enhancements, we provide a brief review of
EDRA. In EDRA, each task instance τi,j assumed a nominal
(default) speed of Ŝi. At dispatch time, this nominal speed
was reduced by computing the unused CPU time of already-
completed tasks (called the earliness factor of τi,j).
EDRA is based on dynamically comparing the actual sched-
ule to the static scheduleScan(in which each task instance runs
with its nominal speed and presents its worst-case workload).
To perform the comparison, a data structure (called α-queue)
is maintained and updated at run-time. The α-queue represents
the ready queue of Scan at time t. Specifically, at any time
t, the information about each task instance τi,j that would be
ready at t in Scanis available in α-queue, including its identity,
ready time, deadline and remaining execution time (denoted by
remi,j)3. EDRA assumes that tasks are scheduled according
to EDF* policy [2]. EDF* is the same as EDF [15], except
that, it provides a total order of all task priorities by breaking
the ties in a specific way among task instances with the same
deadlines [2]. The α-queue is also ordered according to EDF*
priorities. We denote the EDF* priority-level of task τi by d∗i
(low values denote high priorities).
The key notation and rules pertaining to SDRA are pre-
sented in Figures 5 and 6, respectively. Rules 1-3 provide the
update rules for the α-queue structure at important “events”
(task arrival/completion), while Rule 4 shows how the speed
of a task τi is reduced by evaluating its earliness at dispatch
3Since there can be at most one ready instance of a periodic task at anytime
t, we will drop the second index in remi,j and in other α−queue related
notation.
time. i(t) represents the unused computation time of tasks at
higher or equal priority level with respect to τi at time t: these
tasks would still have some non-zero remaining execution time
in Scan, but now they must have been completed because τi is
the highest priority task in the system. Observe that remi val-
ues are available in the α-queue.
The difference between SDRA and EDRA [4] lies on the
rules 4.3 and 4.4 and is justified on the following two princi-
ples:
(a.) For system-level energy-efficiency, a task’s speed should
never be reduced beyond Slow,i, even when the current
earliness suggests doing so, and,
(b.) When the additional CPU time βi to be given to τi is de-
termined, the new speed Si should be determined by tak-
ing into account both off-chip and on-chip components of
the remaining workload.
Specifically, to achieve (a.) above, Rule 4.3 takes into ac-
count the difference between the remaining worst-case exe-
cution times of the task under the speed Slow,i and current
speed Si, and compares against current earliness. Once the
extra CPU time βi to be allocated to τi is determined, the al-
gorithm computes the new speed Snew,i by making sure that
the equality wSii + βi =
x̄i(t)
Snew,i
+ ȳi holds after the speed
adjustment.
It is relatively easy to justify the correctness of SDRA, by
taking into account that the additional CPU time reclaimed
by SDRA is always smaller than or equal to the task’s earli-
ness (which means the algorithm is less aggressive than EDRA
whose correctness was proven in [4]). Note that the speed
computation at step 4.4 is determined uniquely by the extra
CPU time allocation (which also determines the feasibility),
and simply reflects the fact that the algorithm is cognizant of
the off-chip/on-chip workload information of the running task.
5.1 Experimental Results
In this section, we experimentally evaluate the performance
improvements due to dynamic reclaiming, and in particular,
SDRA. The basic experimental settings are identical to those
given in Section 4.1. However, one important addition is the
fact that we also investigated the effect of variability in the
actual workload. Specifically, for each (worst-case) utiliza-
tion and off-chip/on-chip workload ratio, we simulated the ex-
ecution of each task set 20 times over LCM, determining the
actual execution time of each task instance (job) randomly at
every release time. The actual workload of the task is deter-
mined by modifying the BCETWCET ratio (that is, the best-case to
worst-case execution time ratio). The actual execution time of
each job is chosen randomly, following a uniform probability
distribution in the interval [BCET, WCET ].
• Scan: The “canonical” schedule in which each task τi
runs with its nominal speed Ŝi and presents its worst-
case workload Ci = xicSi + yi at every instance
• remi(t): the remaining execution time of τi at time t
in Scan
• x̄i(t): the remaining on-chip workload of task τi in
the actual schedule at time t
• ȳi(t): the remaining off-chip workload of task τi in
the actual schedule at time t
• wSi (t): the remaining worst-case execution time of
task τi under the speed S at time t in the actual sched-
ule, given by: wSi (t) =
x̄i(t)
S + ȳi
• i(t): The earliness of task τi at time t in the actual
schedule, defined as:
i(t) =
∑
j|d∗j <d∗i remj(t) + remi(t) − w
cSi
i (t) =∑
j|d∗j≤d∗i remj(t) − w
cSi
i (t)
Figure 5: Key Notation for SDRA
Rules for SDRA
1. Initialize the α-queue to the empty-list.
2. At every event (arrival/completion), consider the
head of the α-queue and decrease its remi value by
the amount of elapsed-time since the last event. If
remi is smaller than the time elapsed since the last
event, remove the head, update the time elapsed since
the last event, and repeat the update with the next el-
ement. This is done until all “elapsed time” is used.
3. At every new arrival, insert into the α-queue, in the
correct EDF* order, the information regarding the
new instance of task τi,j with remi(t) = w
cSi
i .
4. Whenever τi is about to be dispatched at time t:
4.1. Set Si = Ŝi.
4.2. Consult the α-queue and compute the earliness
i(t) of τi.
4.3. Compute the extra CPU time that will be given
to τi as βi = min{i(t), wSlow,ii − wSii }.
4.4. Reduce the speed of task τi by allocating an ex-
tra βi time units:
Si = x̄i
w
Si
i +βi−ȳi
5. At every event of preemption or completion of a task,
say τi, decrease the value of the remaining execution
time: wSii = w
Si
i −∆t, where ∆t is the time elapsed
since the task τi was last dispatched.
Figure 6: System-Level Dynamic Reclaiming Algorithm
(SDRA)
Figure 7 shows the performance comparison of three
schemes with reclaiming enabled, when BCETWCET = 0.25 and
γ = 0.2. As tasks complete early, more energy savings
can be obtained when compared to Figure 3 in all three
schemes, through reclaiming, and the optimal scheme’s ad-
vantage is now emphasized even at high utilization values:
when tasks complete early, SDRA re-uses the dynamic slack
optimally, by considering energy-efficient speed threshold and
task power/workload characteristics. Figure 8 presents the ef-
fects of varying γ for the same settings, where BCETWCET = 0.25
and Utot = 0.5. Though energy gains are still more significant
(due to reclaiming), it is interesting to note that the perfor-
mance of S = Utot is highly sensitive to the the off-chip/on-
chip workload characteristics. Finally, in Figure 9, the effects
of varying the BCETWCET ratio are explored, for Utot = 0.5 and
γ = 0.2. The energy gains change almost linearly for all three
schemes with varying BCETWCET ratio, and the gains of the opti-
mal scheme are more pronounced when the variability in the
workload is highest.
 0
 0.2
 0.4
 0.6
 0.8
 1
 0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1
E
n
e
rg
y 
C
o
n
su
m
p
tio
n
Utilization
S = Utot
S = Optimal
S = S*
Figure 7: Energy consumption as a function of utilization
(with dynamic reclaiming)
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0  0.1  0.2  0.3  0.4  0.5
E
n
e
rg
y 
C
o
n
su
m
p
tio
n
Off-chip workload ratio
S = Utot
S = Optimal
S = S*
Figure 8: Energy consumption as a function of off-chip work-
load ratio (with dynamic reclaiming)
6 Conclusions
In this paper, we addressed the problem of minimizing overall
energy consumption of a real-time system, considering a gen-
eralized power model. Unlike many previous RT-DVS studies
in which the focus was dynamic CPU power, our solution takes
into account the frequency-dependent and -independent power
components, as well as the power consumption of components
 0
 0.2
 0.4
 0.6
 0.8
 1
 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1
E
n
e
rg
y 
C
o
n
su
m
p
tio
n
BCET/WCET ratio
S = Utot
S = Optimal
S = S*
Figure 9: Energy consumption as a function of workload vari-
ability
other than the CPU. We also considered the off-chip/on-chip
workload information of different tasks. After showing how
the task-level energy-efficient speed levels can be computed in
this generalized model, we formulated the problem as a convex
optimization problem and derived an iterative, polynomial-
time solution using Kuhn-Tucker optimality conditions. Fi-
nally, we provided a dynamic reclaiming extension for settings
where tasks complete early. Our experimental results show
that the gains of our optimal scheme are considerable, espe-
cially at low-to-medium utilization, or high workload variabil-
ity conditions. To the best of our knowledge, this paper is the
first research effort to provide an optimal solution for system-
level energy minimization in real-time systems with periodic
tasks, under a generalized power model.
References
[1] T. A. AlEnawy and H. Aydin. Energy-Constrained Scheduling
for Weakly Hard Real Time Systems. In Proceedings of the
IEEE Real-Time Systems Symposium (RTSS’05), 2005.
[2] H. Aydin, R. Melhem, D. Mossé and P. Mejia-Alvarez. Dy-
namic and Aggressive Power-Aware Scheduling Techniques
for Real-Time Systems. In Proceedings of the 22nd IEEE Real-
time Systems Symposium (RTSS’01), 2001.
[3] H. Aydin, R. Melhem, D. Mossé and P. Mejia-Alvarez. Power-
aware Scheduling for Periodic Real-time Tasks. IEEE Trans-
actions on Computers, vol. 53, no. 10, pp. 584-600, May 2004.
[4] H. Aydin and Q. Yang. Energy-Responsiveness Tradeoffs for
Real-time Systems with Mixed Workload. In Proceedings of
the IEEE Real-Time and Embedded Technology and Applica-
tions Symposium (RTAS’04), 2004.
[5] E. Bini, G.C. Buttazzo and G. Lipari. Speed Modulation in
Energy-Aware Real-Time Systems. in Proc. of the 17th Eu-
romicro Conference on Real-Time Systems (ECRTS), 2005.
[6] P. Bohrer, E. N. Elnozahy, T. Keller, M. Kistler, C. Lefurgy, C.
Mc- Dowell, and R. Rajamony. The case for power manage-
ment in web servers, chapter 1. In Power Aware Computing.
Plenum/Kluwer Publishers, 2002.
[7] T. D. Burd and R. W. Brodersen. Energy efficient cmos micro-
processor design. In Proc. of The HICSS Conference, 1995.
[8] H. Cheng and S. Goddard. Integrated Device Scheduling and
Processor Voltage Scaling for System-wide Energy Conserva-
tion. In Proc. of the 2nd Int’l Workshop on Power-Aware Real-
Time Computing (PARC), 2005.
[9] K. Choi, R. Soma and M. Pedram. Fine-grained dynamic volt-
age and frequency scaling for precise energy and performance
trade-off based on the ratio of off-chip access to on-chip com-
putation times. In Proceedings of Design, Automation and Test
in Europe, 2004.
[10] X. Fan, C. Ellis, and A. Lebeck. The Synergy Between Power-
aware Memory systems and Processor Voltage. In Workshop
on Power-Aware Computing Systems, December 2003.
[11] R. Jejurikar and R. Gupta. Dynamic voltage scaling for sys-
temwide energy minimization in real-time embedded systems.
In Proceedings of the 2004 International Symposium on Low
Power Electronics and Design (ISLPED), 2004.
[12] T. Ishihara and H. Yauura. Voltage scheduling problem for dy-
namically variable voltage processors. In Proc. of The 1998
International Symposium on Low Power Electronics and De-
sign, 1998.
[13] R. Jejurikar, C. Pereira, and R. Gupta. Leakage Aware Dy-
namic Voltage Scaling for Real-time Embedded Systems. In
Proceedings of the 41st Annual Conference on Design Au-
tomation (DAC’04), 2004.
[14] Y. Lee, K. P. Reddy, and C. M. Krishna. Scheduling Tech-
niques for Reducing Leakage Power in Hard Real-time
Systems. In EuroMicro Conference on Real Time Systems
(ECRTS’03), 2003.
[15] C. L. Liu and J. W. Layland. Scheduling Algorithms for Mul-
tiprogramming in Hard Real-time Environment. Journal of
ACM vol. 20. no. 1, pp. 46-61, January 1973.
[16] Y. Lu, L. Benini and G. De Micheli. Power-Aware Operating
Systems for Interactive Systems.IEEE Transactions on Very
Large Scale Integration (VLSI) Systems, v.10, n.1, April 2002.
[17] D. Luenberger, Linear and Nonlinear Programming, Addison-
Wesley, Reading Massachusetts, 1984.
[18] R. Nathuji and K. Schwan. Reducing System Level Power
Consumption for Mobile and Embedded Platforms. In Lecture
Notes in Computer Science, v. 3432, pp. 18-32, March 2005.
[19] P. Pillai and K. G. Shin. Real-time Dynamic Voltage Scal-
ing for Low-power Embedded Operating Systems. In Proceed-
ings of the ACM Symposium on Operating Systems Principles,
2001.
[20] A. Qadi, S. Goddard, and S. Farritor. A Dynamic Voltage Scal-
ing Algorithm for Sporadic Tasks. In Proceedings of the IEEE
Real-Time Systems Symposium (RTSS’03), 2003.
[21] G. Quan, L. Niu, X. S. Hu and B. Mochock. Fixed Priority
Scheduling for Reducing Overall Energy on Variable Voltage
Processors, In Proceedings of the IEEE Real-Time Systems
Symposium (RTSS’04), 2004.
[22] S. Saewong and R. Rajkumar. Practical Voltage-Scaling for
Fixed-Priority Real-time Systems. In Proceedings of the IEEE
Real-Time and Embedded Technology and Applications Sym-
posium (RTAS’03), 2003.
[23] K. Seth, A. Anantaraman, F. Mueller and E. Rotenberg. FAST:
Frequency-Aware Static Timing Analysis. In Proc. of the 24th
IEEE Real-Time System Symposium, 2003.
[24] D. Snowdon, S. Ruocco and G. Heiser. Power Management
and Dynamic Voltage Scaling: Myths and Facts. In Proc. of
the 2nd Int’l Workshop on Power-Aware Real-Time Computing
(PARC), 2005.
[25] V. Swaminathan and K. Chakrabarty. Energy-conscious, De-
terministic I/O Device Scheduling in Hard Real-time Sys-
tems. In IEEE Transactions on Computer-Aided Design of In-
tegrated Circuits and Systems, vol. 22, no.7, pp. 847-858, July
2003.
[26] H. W. Turnbull. Theory of Equations. Oliver and Boyd, Lon-
don, 1947.
[27] M. Weiser, B. Welch, A. Demers and S. Shenker. Scheduling
for Reduced CPU energy. In USENIX Symposium on Operat-
ing Systems Design and Implementation, 1994.
[28] D. Zhu. Reliability-aware dynamic energy management in de-
pendable embedded real-time systems. In Proc. of the IEEE
Real-Time and Embedded Technology and Applications Sym-
posium (RTAS), 2006.
[29] D. Zhu and H. Aydin. Energy Management for Real-time Em-
bedded Systems with Reliability Requirements. In Proc. of
the International Conference on Computer-Aided Design (IC-
CAD), 2006.
[30] D. Zhu, R. Melhem, and D. Mossé. The effects of energy man-
agement on reliability in real-time embedded systems. In Proc.
of the International Conference on Computer Aided Design
(ICCAD), 2004.
[31] J. Zhuo and C. Chakrabarti. System-level energy-efficient dy-
namic task scheduling. In Proceedings of the 42nd Annual
Conference on Design Automation (DAC), 2005.
APPENDIX: Solution of Problem ENERGY-LU
Our strategy while solving the problem ENERGY-LU will be as
follows. We will temporarily ignore the upper bound constraints (15),
and obtain a new problem (called ENERGY-L) by considering only
the inequality constraint (13) and the lower bound constraints (14). If
the solution of ENERGY-L satisfies also the upper bound constraints
(15), then it corresponds to the solution of ENERGY-LU, since the
feasible region of the latter is contained in that of the former. How-
ever, if some upper bound constraints are violated, then we will show
how to iteratively adjust the solution to solve ENERGY-LU. We first
formally define the problem ENERGY-L:
minimize
nP
i=1
Ei(Si) (16)
subject to
nP
i=1
uxi
Si
= 1 −
nP
i=1
uyi (17)
Slow,i ≤ Si i = 1, . . . , n (18)
Let Γ = {i|S2max
uxi
· E′i(Smax) ≤ S
2
max
uxj
E′j(Smax) ∀j}. In-
formally, Γ contains the indices of tasks for which the quantity
S2max
uxi
· E′i(Smax) is minimum among all tasks.
Lemma 1 If the solution of ENERGY-L violates upper bound con-
straints given by (15) then, in the solution of ENERGY-LU, Si =
Smax ∀i ∈ Γ.
Proof: A well-known result of the nonlinear optimization theory
states that the solution of Problem ENERGY-LU should satisfy so-
called Kuhn-Tucker conditions [17]. Furthermore, Kuhn-Tucker con-
ditions are also sufficient in the case of convex objective functions
[17]. For the convex optimization Problem ENERGY-LU, Kuhn-
Tucker conditions comprise the constraints (13), (14), (15) and :
E′i(Si) − λ u
x
i
S2i
+ µ̄i − µi = 0 i = 1, 2, .., n (19)
µ̄i(Smax − Si) = 0 i = 1, 2, ., .n (20)
µi (Si − Slow,i) = 0 i = 1, 2, ., .n (21)
µ̄i ≥ 0 i = 1, 2, .., n (22)
µi ≥ 0 i = 1, 2, .., n (23)
where λ, µ̄1, µ̄2, . . . , µ̄n, µ1, µ2, . . . , µn are Lagrange multipliers.
The necessary and sufficient character of Kuhn-
Tucker conditions indicates that any 3n + 1 tuple
(S1, . . . , Sn, µ1, . . . , µn, µ̄1, . . . , µ̄n, λ) which satisfies the
conditions (19) . . . (23) and constraints (13), (14), (15) provides
optimal Si values for ENERGY-L.
Similarly, the necessary and sufficient Kuhn-Tucker conditions for
the problem ENERGY-L include the constraints (17), (18), and :
E′i(Si) − λ u
x
i
S2i
− µi = 0 i = 1, 2, .., n (24)
µi (Si − Slow,i) = 0 i = 1, 2, ., .n (25)
µi ≥ 0 i = 1, 2, .., n (26)
where λ, µ2, . . . , µn are again Lagrange multipliers.
Comparing the Kuhn-Tucker conditions for problems ENERGY-
LU and ENERGY-L, we note that at least one µ̄i should be definitely
larger than zero, if the solution of ENERGY-L violates some upper
bound constraints of ENERGY-LU. This is because, if µ̄i = 0∀ i,
then in the Kuhn-Tucker conditions for problem ENERGY-LU, the
equations (20) and (22) vanish, and the equation (19) becomes iden-
tical to the equation (24); implying that both sets of Kuhn-Tucker
conditions (hence, the optimal solutions of two problems) coincide.
But this contradicts the assumption that we made.
Similarly, if µ̄i > 0 ∃ i, (which should be the case if the solu-
tion of ENERGY-L violates the constraints of ENERGY-LU), then
µi should be zero: otherwise, Equations (20) and (21) would imply
that Si = Smax = Slow,i, which is a contradiction.
Now we are ready to prove the lemma. We will essentially show
that, under the condition specified in the lemma, the Lagrange mul-
tipliers µ̄i, (i ∈ Γ) are all non-zero, which will imply (by (20)) that
Si = Smax ∀ i ∈ Γ. Suppose ∃m ∈ Γ such that µ̄m = 0. From the
discussion in the preceding paragraphs, we know that ∃j ∈ Γ such
that µ̄j > 0 and µj = 0. Using (19), we can write
S2m
uxm
E′m(Sm) − S
2
m
uxm
µm =
S2j
uxj
E′j(Sj) +
S2j
uxj
µ̄j
which gives (since Sj = Smax):
S2m
uxm
E′m(Sm) =
S2max
uxj
E′j(Smax) +
S2m
uxm
µm +
S2max
uxj
µ̄j
(µm ≥ 0, µ̄j ≥ 0) (27)
Since Sm is necessarily less than or equal to Smax, we can conclude
that S
2
max
uxj
E′j(Smax) <
S2m
uxm
E′m(Sm) ≤ S
2
max
uxm
E′m(Smax), which
contradicts the assumption that m ∈ Γ. 
Solving ENERGY-L
Having shown how to solve the problem ENERGY-LU if we have the
solution of ENERGY-L, we now address the latter. First, we state a
sufficient condition for the optimal solution of ENERGY-L.
Lemma 2 A set of speed assignments SX = {S1, . . . , Sn} is the
solution to ENERGY-L, if it satisfies the property
S2i
uxi
E′i(Si) =
S2j
uxj
E′j(Sj) ∀ i, j such that Si, Sj ∈ SX (28)
in addition to the constraint sets (17) and (18).
Proof: By re-visiting the Kuhn-Tucker conditions (24), (25), (26),
which are necessary and sufficient for optimality, we observe that
the condition given in the lemma coincides with the case where µi =
0 ∀i. Indeed, in that case, the equation (24) becomes identical to (28),
and all constraints involving µi variables vanish. If the Si values ob-
tained in this way satisfy the constraint sets (18) and (17) at the same
time, then the selection of µi = 0 ∀i should be optimal as all Kuhn-
Tucker conditions hold. 
Let us define by hi(λ) the inverse function of
S2i
uxi
E′i(Si); in other
words, hi(λ) = Si if
S2i
uxi
E′i(Si) = λ. Note that, evaluating hi(λ)
will typically involve solving a cubic or quadratic equation, for which
closed form solutions do exist. Also, if we set a given Si value to
a constant, then all other Sj values are uniquely determined by the
hi() functions. Moreover,
S2i
uxi
E′i(Si) is strictly increasing with Si ∀ i.
Hence, the unique set of speed assignments SX that satisfy (28) and
(17), can be obtained by finding the unique λ such that
Pn
i=1
uxi
hi(λ)
=
1 −
nP
i=1
uyi . If SX satisfies also the lower bound constraints, then it
is the solution of ENERGY-L, by virtue of Lemma 2. However, we
need to deal with a last case, in which SX violates the lower bound
constraints. In order to address this, we need to define a (last) set.
Let Π = {i|S
2
low,i
uxi
E′i(Slow,i) ≥ S
2
low,j
uxj
E′j(Slow,j) ∀j}. Infor-
mally, Π contains the indices of tasks for which the quantity
S2low,i
uxi
·
E′i(Slow,i) is maximum among all tasks.
Lemma 3 If SX violates the upper bound constraints given by (18),
then, in the solution of ENERGY-L, Si = Slow,i ∀i ∈ Π.
Proof: The proof of Lemma 3 is similar to that of Lemma 1.
In fact, if SX (which corresponds the the candidate solution when
all µi values set to zero) violates the lower bound constraints, then
∃j µj > 0 and Sj = Slow,j (due to (25)). We will prove that,
under the condition specified in the lemma, the Lagrange multipli-
ers µi, i ∈ Π should be all non-zero, which will imply (by 25) that
Si = Slow,i∀ i ∈ Π.
Suppose ∃m ∈ Π such that µm = 0. From the preceding dis-
cussion, we know that ∃j ∈ Π such that µj > 0. Using (24), we
can write S
2
m
uxm
E′m(Sm) =
S2j
uxj
E′j(Sj) − S
2
j
uxj
µj , which gives (since
Sj = Slow,j):
S2m
uxm
E′m(Sm) =
S2low,j
uxj
E′j(Slow,j) −
S2low,j
uxj
µj(µj ≥ 0) (29)
At this point, since Sm ≥ Slow,m, we can conclude that
S2low,j
uxj
E′j(Slow,j) >
S2m
uxm
E′m(Sm) ≥ S
2
low,m
uxm
E′m(Slow,m), which
contradicts the assumption that m ∈ Π.
Complexity: Note that ENERGY-L can be solved in time O(n2):
evaluating SX takes linear time, and if SX violates (some) lower
bound constraints, then we determine at least one optimal Si value
at each iteration. If SX satisfies all the lower bound constraints, then
the solution of ENERGY-L (at that iteration) coincides with SX .
The same observation holds for ENERGY-LU: The algorithm will in-
voke the corresponding ENERGY-L algorithm at most n times, find-
ing at least one optimal Si value at every iteration. Hence, overall
time complexity is O(n3).

