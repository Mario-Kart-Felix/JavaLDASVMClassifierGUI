1
Real-Time Systems
Stefan M. Petters
© NICTA 2007/2008 No: 2
Lecture Content
• Definition of Real-Time Systems (RTS)
• Scheduling in RTS
• Schedulability Analysis
• Worst Case Execution Time Analysis
• Time and Distributed RTS
• Rate Based Scheduling
2
© NICTA 2007/2008 No: 3
Definition
• A real-time system is any information processing 
system which has to respond to externally 
generated input stimuli within a finite and 
specified period
– the correctness depends not only on the logical 
result but also the time it was delivered
– failure to respond is as bad as the wrong 
response!
© NICTA 2007/2008 No: 4
Real-Time Systems 
3
© NICTA 2007/2008 No: 5
Real-Time Systems
© NICTA 2007/2008 No: 6
Real-Time Systems
4
© NICTA 2007/2008 No: 7
Real-Time Systems
© NICTA 2007/2008 No: 8
Real-Time Systems
Is there a pattern?
• Hard real-time systems
• Soft real-time systems
• Firm teal-time systems
• Weakly hard real-time 
• A deadline is a given time after a triggering event, by 
which a response has to be completed.
• Therac 25 example
5
© NICTA 2007/2008 No: 9
• Fast context switches?
• Small size?
• Quick response to external triggers?
• Multitasking?
• “Low Level” programming interfaces?
• High processor utilisation?
What’s needed of an RTOS
– should be fast anyway
– should be small anyway
– not necessarily quick but predictable
– often used, but not necessarily
– might be needed as with other embedded systems
– desirable in any system (avoid oversized system)
© NICTA 2007/2008 No: 10
Hard Real-Time Systems
• An overrun in response time leads to potential loss of life 
and/or big financial damage
• Many of these systems are considered to be safety 
critical.
• Sometimes they are “only” mission critical, with the 
mission being very expensive.
• In general there is a cost function associated with the 
system. 
DeadlineCost
Time
Triggering 
Event
6
© NICTA 2007/2008 No: 11
Soft Real-Time
• Deadline overruns are tolerable, but not desired.
• There are no catastrophic consequences of missing one 
or more deadlines. 
• There is a cost associated to overrunning, but this cost 
may be abstract.
• Often connected to Quality-of-Service (QoS)
Time
DeadlineCost
Triggering 
Event
Example Cost 
Function
© NICTA 2007/2008 No: 12
Firm Real-Time Systems
• The computation is obsolete if the job is not finished on 
time.
• Cost may be interpreted as loss of revenue.
• Typical example are forecast systems.
DeadlineGain
Triggering 
Event
Example Gain 
Function
7
© NICTA 2007/2008 No: 13
Weakly Hard Real-Time Systems
• Systems where m out of k deadlines have to be 
met.
• In most cases feedback control systems, in which 
the control becomes unstable with too many 
missed control cycles.
• Best suited if system has to deal with other 
failures as well (e.g. Electro Magnetic 
Interference EMI).
• Likely probabilistic guarantees sufficient.
© NICTA 2007/2008 No: 14
Non Real-Time Systems?
• Yes, those exist!
• However, in most cases the (soft) real-time 
aspect may be constructed (e.g. acceptable 
response time to user input).
• Computer system is backed up by 
hardware (e.g. end position switches)
• Quite often simply oversized computers.
8
© NICTA 2007/2008 No: 15
Requirement, Specification, Verification
• Functional requirements: Operation of the system and 
their effects. 
• Non-Functional requirements: e.g., timing constraints. 
– F & NF requirements must be precisely defined and together used 
to construct the specification of the system. 
• A specification is a mathematical statement of the 
properties to be exhibited by a system. It is abstracted 
such that 
– it can be checked for conformity against the requirement.
– its properties can be examined independently of the way in which
it will be implemented. 
© NICTA 2007/2008 No: 16
Requirement, Specification, Verification
• The usual approaches for specifying computing system 
behavior entail enumerating events or actions that the 
system participates in and describing orders in which they 
can occur. It is not well understood how to extend such 
approaches for real-time constraints.
• F18, therac-25 example
9
© NICTA 2007/2008 No: 17
Scheduling in Real-Time Systems
© NICTA 2007/2008 No: 18
Overview
• Specification and religious believes
• Preemptive vs. non preemptive scheduling
• Scheduling algorithms
• Message based synchronisation and 
communication
• Overload situations
• Blocking and Priority Inversion
10
© NICTA 2007/2008 No: 19
Requirements
• Temporal requirements of the embedded system
– Event driven
• Reactive sensor/actuator systems
• No fixed temporal relation between events (apart from 
minimum inter arrival times)
– Cyclic
• Feedback control type applications
• Fixed cycles of external triggers with minimal jitter
– Mixed
• Anything in between
© NICTA 2007/2008 No: 20
Specification
• Event triggered systems:
– Passage of a certain amount of time
– Asynchronous events
• Time triggered systems:
– Predefined temporal relation of events
– Events may be ignored until it’s their turn to be served
• Matlab/Simulink type multi rate, single base rate 
systems:
– All rates are multiples of the base rate
• Cyclic
– feedback control loop
11
© NICTA 2007/2008 No: 21
Task Model
• Periodic tasks  
– Time-driven. Characteristics are known a priori 
– Task τi is characterized by (Ti, Ci)
– E.g.: Task monitoring temperature of a patient in an ICU.
• Aperiodic tasks  
– Event-driven. Characteristics are not known a priori 
– Task τi is characterized by (Ci, Di) and some probabilistic profile 
for arrival patterns (e.g. Poisson model)
– E.g.: Task activated upon detecting change in patient’s condition.
• Sporadic Tasks
– Aperiodic tasks with known minimum inter-arrival time (Ti, Ci)
© NICTA 2007/2008 No: 22
Task Model
Ci= Computation time (usually Worst-Case 
Execution Time, WCET)
Di= Deadline
Ti = Period or minimum interarrival time
Ji = Release jitter
Pi = Priority
Bi = Worst case blocking time
Ri= Worst case response time
12
© NICTA 2007/2008 No: 23
Task Constraints
• Deadline constraint
• Resource constraints 
– Shared access (read-read), Exclusive access (write-x)
– Energy
• Precedence constraints
– τ1 ⇒ τ2: Task τ2 can start executing only after τ1
finishes its execution
• Fault-tolerant requirements 
– To achieve higher reliability for task execution
– Redundancy in execution
© NICTA 2007/2008 No: 24
Preemption
• Why preemptive scheduling is good:
– It allows for shorter response time of high priority tasks
– As a result it is likely to allow for a higher utilisation of 
the processor before the system starts missing 
deadlines
• Why preemptive scheduling is bad:
– It leads to more task switches then necessary
– The overheads of task switches are non-trivial
– The system becomes harder to analyse whether it is 
able to meet all its deadlines
– Preemption delay (cache refill etc.) becomes more 
expensive with modern processors
13
© NICTA 2007/2008 No: 25
Preemption
• Cooperative preemption?
– Applications allow preemption at given points
– Reduction of preemptions
– Increase of latency for high priority tasks
© NICTA 2007/2008 No: 26
Event Triggered Systems
‘‘... The asynchronous design of the [AFTI-F16] DFCS 
introduced a random, unpredictable characteristic into the 
system. The system became untestable in that testing for 
each of the possible time relationships between the 
computers was impossible. This random time relationship 
was a major contributor to the flight test anomalies. 
Adversely affecting testability and having only postulated 
benefits, asynchronous operation of the DFCS 
demonstrated the need to avoid random, unpredictable, 
and uncompensated design characteristics.’’
D. Mackall, flight-test engineer AFTI-F16 AFTI-F16 flight 
tests
14
© NICTA 2007/2008 No: 27
Fixed Priority Scheduling
• Priorities may assigned by 
– Deadline: shortest deadline ⇒ highest priority
– Period: shortest period ⇒ highest priority
– “Importance”
• Scheduler picks from all ready tasks the one with the highest priority 
to be dispatched.
• Benefits:
– Simple to implement
– Not much overhead
– Minimal latency for high priority tasks
• Drawbacks
– Inflexible
– Suboptimal (from analysis point of view)
© NICTA 2007/2008 No: 28
Fixed Priority Scheduling(FPS)
5050153Task τ3
203082Task τ2
202051Task τ1
DTCPriority
Task τ2
Task τ3
Task τ1
15
© NICTA 2007/2008 No: 29
Earliest Deadline First (EDF)
• Dynamic priorities
• Scheduler picks task, whose deadline is due next
• Advantages:
– Optimality
– Reduces number of task switches
– Optimal if system is not overloaded
• Drawbacks:
– Deteriorates badly under overload
– Needs smarter scheduler
– Scheduling is more expensive
© NICTA 2007/2008 No: 30
FPS vs. EDF
Task τ2
Task τ3
Task τ1
Task τ2
Task τ3
Task τ1
16
© NICTA 2007/2008 No: 31
FPS vs. EDF
Task τ2
Task τ3
Task τ1
4040153Task τ3
203082Task τ2
202051Task τ1
DTCPriority
© NICTA 2007/2008 No: 32
FPS vs. EDF
Task τ2
Task τ3
Task τ1
Task τ2
Task τ3
Task τ1
17
© NICTA 2007/2008 No: 33
Time Triggered/Driven Scheduling
• Mostly static scheduling
• Time triggered scheduling allows easier 
reasoning and monitoring of response times
• Can be used to avoid preemption
• Can be used in event triggered systems, but 
increases greatly the latency
• Most often build around a base rate
• Can be implemented in big executive, using 
simple function calls
© NICTA 2007/2008 No: 34
Time Triggered Scheduling
• Advantages:
– Very simple to implement
– Very efficient / little overhead (in suitable case) 
• Disadvantages:
– Big latency if event rate does not match base rate
– Inflexible
– Potentially big base rate (many scheduling decisions) or 
hyperperiod
τ2 τ1 τ3τ4τ3τ1 τ1 τ1τ2
Hyperperiod BMW example
18
© NICTA 2007/2008 No: 35
Message Based Synchronisation
• Tasks communicate via messages
• Task wait for messages (blocked until message 
arrives)
• Suitable to enforce precedence relations
• Enables messages to be used to transport 
deadlines
τ2τ4
τ3
τ1
τ5
© NICTA 2007/2008 No: 36
Overload Situations
• Caused by faulty components of the system
– Babbeling idiot or
– A receiver part erroneously “receiving input”
– EMI
• Or caused by wrong assumptions regarding 
the embedding environment
– Basically wrong event rates or event correlation
19
© NICTA 2007/2008 No: 37
Overload Situations in FPS
Task τ2
Task τ3
Task τ1
Old
5050153Task τ3
2020122Task τ2
202051Task τ1
DTCPriority
© NICTA 2007/2008 No: 38
Overload Situations in FPS
Task τ2
Task τ3
Task τ1
Task τ2
Task τ3
Task τ1
20
© NICTA 2007/2008 No: 39
Overload Situations in EDF
Task τ2
Task τ3
Task τ1
Task τ2
Task τ3
Task τ1
© NICTA 2007/2008 No: 40
Overload Situations in EDF
Task τ2
Task τ3
Task τ1
Task τ2
Task τ3
Task τ1
{{
21
© NICTA 2007/2008 No: 41
Priority Inversion
• Happens when task is blocked in acquiring 
semaphore from held by lower priority task 
which is preempted by medium priority 
task.
• Similar case for server tasks.
• Pathfinder example
© NICTA 2007/2008 No: 42
Non-Preemptable Critical Sections
Task τ2
Task τ3
Task τ1
Task τ5
Task τ4
• 2 shared resources
• One shared by 3 (nested by one)
• One shared by 2
22
© NICTA 2007/2008 No: 43
Non-Preemptable Critical Section
• GOOD
– Simple
– No deadlock.
– No unbounded priority inversion
– No prior knowledge about resources.
– Each task blocked by at most 1 task of lower priority
– Works with fixed and dynamic priorities. (especially good for short critical 
sections with high contention)
• BAD
– Tasks blocked even when no contention exists.
© NICTA 2007/2008 No: 44
Priority Inheritance
Task τ2
Task τ3
Task τ1
Task τ5
Task τ4
Note the indirect inheritance
23
© NICTA 2007/2008 No: 45
Priority Inheritance
• When lower priority job blocks, it inherits priority of 
blocked job.
• GOOD
– No unbounded priority inversion
– Simple
– No prior knowledge required
– Works with fixed and dynamic priorities.
• BAD
– Possible Deadlock.
– Blocking of jobs not in resource contention.
– Blocking time could be better
– Indirection a pain in the neck
© NICTA 2007/2008 No: 46
Basic Priority Ceiling Protocol
Task τ2
Task τ3
Task τ1
Task τ5
Task τ4
24
© NICTA 2007/2008 No: 47
Basic Priority Ceiling Protocol
• Lower priority task inherits priority of blocked task.
• Task may be denied resource even when available.
• Also known as Original Priority Ceiling Protocoll (OPCP)
• GOOD
– No deadlock.
– No unbounded priority inversion.
– Blocking time reduced.
• BAD
– Task may be denied resource even when available.
– Need a priori knowledge of use of resources.
)(),(max
1
kCikusageB
K
k
i
=
= ∑
=
=
K
k
i kCikusageB
1
)(),(
Basic Priority Ceiling Priority Inheritance
© NICTA 2007/2008 No: 48
Immediate Priority Ceiling Protocol
Task τ2
Task τ3
Task τ1
Task τ5
Task τ4
25
© NICTA 2007/2008 No: 49
Immediate Priority Ceiling Protocol
• Lower priority task inherits priority of potentially blocked 
task. Task may be denied resource even when available.
• GOOD
– Simple.
– Shared run-time stack.
– Reduced Context-Switching
– No deadlock.
– No unbounded priority inversion.
• BAD
– Task may be denied resource even when available
– Task may be affected by blocking effect without using any 
resources
– Need a priori knowledge of use of resources.
– No self suspension while holding a resource
© NICTA 2007/2008 No: 50
Implementation Comparison
• Non-preemptable critical sections
– Easy to implement. Either blocking interrupts or syscall to have that 
implemented on behalf of task
• Priority Inheritance
– Fairly straightforward, however requires various references (e.g. 
which thread is holding a resource)
• Basic Priority Ceiling
– Requires application designer to explicitly identify which resources 
will be requested later (when first resource request of nested 
requests is made) on top of references
• Immediate priority ceiling
– Very easy to implement: Only requires ceilings associated with each 
resource mutex (that’s something which may be automated if all tasks 
known
– Alternatively server task encapsulating the critical section
26
© NICTA 2007/2008 No: 51
Reflective/Feedback-based Scheduling
• Adaptive systems
• By definition soft real time
• Adjusts scheduling based on information 
about change
• Capable of better coping with “the 
unknown”
• Connects quite well with adaptive 
applications
© NICTA 2007/2008 No: 52
Schedulability Analysis of Real-Time Systems
27
© NICTA 2007/2008 No: 53
Schedulability Analysis
• Tries to establish, whether the task system 
described is actually schedulable
– In the classical sense this is, whether all the deadlines 
are met under all circumstances;
– Recent move to satisfaction of Quality-of-Service 
constraints;
• Relies on availability of computation time of tasks 
– WCET;
– Execution time profiles.
© NICTA 2007/2008 No: 54
Critical Instant
• Trivial for independent tasks
– All events happen at the same time;
– However, implicitly consider all possible 
phases (take nothing for granted).
• However, get’s more tricky (but tighter) 
having dependencies
– What phasing of other activities produces the 
biggest load.
– An activity is a string of tasks triggered by a 
single event.
28
© NICTA 2007/2008 No: 55
Response Time Analysis
• Does not directly consider deadlines
• Makes the assumption of jobs being 
executed in order
• Usually used in fixed priority systems
Task τ2
Task τ3
Task τ1
© NICTA 2007/2008 No: 56
Response Time Analysis
Task τ2
Task τ3
Task τ1
5050153Task τ3
203082Task τ2
202051Task τ1
DTCPriority
29
© NICTA 2007/2008 No: 57
Formal RTA
• Assumptions j<i ⇒priority j is lower than 
priority i
• Critical instant
• Iterative process
ii Cw =
0
j
ij j
n
i
i
n
i C
T
w
Cw *1 ∑
<∀
+








+=
© NICTA 2007/2008 No: 58
Blocking Time and Other Nasties
)(* ,
1
jij
ij j
n
ij
ii
n
i C
T
wJ
BCw δ+







 +
++= ∑
<∀
+
• Blocking time
• Jitter
• Pre-emption delay 
30
© NICTA 2007/2008 No: 59
Rate Monotonic Analysis
• Looks at utilisation do determine whether a task is 
schedulable
• Initial work had following requirements:
– All tasks with deadlines are periodic
– All tasks are independent of each other (there exists no 
precedence relation, nor mutual exclusion)
– Ti= Di
– Ci is known and constant
– Time required for context switching is known
© NICTA 2007/2008 No: 60
Rate Monotonic Analysis contd
• Bound is given by:
)12(*
1
−≤





= ∑
∀
n
i i
i n
T
C
µ
• Has been relaxed in various ways, but still it is only 
an approximate technique.
• Further info can be found here:
http://www.heidmann.com/paul/rma/PAPER.htm
31
© NICTA 2007/2008 No: 61
Graphical EDF Analysis
Time
Computation 
Request
Events
Deadlines
Task 1
Task 2
Task 3
© NICTA 2007/2008 No: 62
Graphical EDF Analysis
Time
Computation 
Request
Events
Deadlines
Task 1
Task 2
Task 3
32
© NICTA 2007/2008 No: 63
Worst Case Execution Time Analysis
© NICTA 2007/2008 No: 64
Problem Definition
execution time
Average
Maximum Observed
"Real" Worst-case
Safe upper bound
Best-case
• All of the scheduling analysis presented previously 
requires the Worst-Case Execution time to be known
• Target is to come up with
– a safe upper bound 
– as close as possible to the “real” worst case.
– Ideally with more than just single number (probabilistic 
analysis)
Safe upper bo nd
p WCET profile
33
© NICTA 2007/2008 No: 65
Problem Definition contd
Average
Maximum Observed
"Real" Worst-case 
Safe upper bound
execution time
Best-case
execution time
Average
Maximum Observed
"Real" Worst-case 
Safe upper bound
Best-case
Complex Code + Advanced processors
Simple Code + Simple Processors
© NICTA 2007/2008 No: 66
Is it a Problem?
• Safety critical computer systems exist and 
are deployed
• Yes, but …
– Safety critical systems have been 
• highly restrictive in terms of HW/SW used
• highly restrictive in terms of complexity
• used a lot of manual inspection and pen and paper 
work
34
© NICTA 2007/2008 No: 67
Is it a Problem? contd
– The stuff in the last slide doesn’t scale! 
– industry not in the safety critical arena have 
been using measurements with safety factors.
• Worked fine with simple architectures, but doesn’t 
work good with more advanced computers
• Excessive overestimation and underestimation with 
same factor for different programs, parameterisation 
doesn’t help too much
• Large body of academic work, but little 
industrial uptake: YET
© NICTA 2007/2008 No: 68
Generic Problem Partitioning
Structural 
Analysis
Constraint/Flow 
Analysis
Computation
Low-Level 
Analysis
Program
WCET
• Some analysis methods integrate some aspects of these, 
but the general requirements are the same
35
© NICTA 2007/2008 No: 69
Structural Analysis
• Can work on:
– Source code and/or
– Object code or
– Assembly Code
© NICTA 2007/2008 No: 70
Structural Analysis contd
• Object Code
– Pros:
– All compiler optimisations are done
– This is what really is running, no trouble with 
macros, preprocessors
– Cons:
– Needs to second guess what all the variables 
meant
– A lot of the original information is lost
• E.g. multiple conditions, indirect function calls, 
object member functions
36
© NICTA 2007/2008 No: 71
Structural Analysis contd
• Assembly Code
– Pros:
– All compiler optimisations done
– Cons:
– Same as Object Code +
– Potentially still some macros
© NICTA 2007/2008 No: 72
Structural Analysis contd
• Source Code
– Pros:
– All information the user has put there is there
– Structure in pure form (e.g. multiple loop 
continue conditions, object member functions, 
indirect calls)
– Cons:
– Trouble with macros, preprocessors etc.
– Needs to second guess what the compiler will 
do
37
© NICTA 2007/2008 No: 73
Multiple Continue conditions explained
for (; first condition || other cond;){
Func();
}
May look like
for (; first condition;){
for (; other cond;){
Func();
}
}
Func()
first
second
© NICTA 2007/2008 No: 74
Flow information
• For low level analysis and computation we 
need to restrict flow to reasonable subset.
• This information can be gained:
– By static analysis (most importantly abstract 
interpretation)
– By observation (worst case?)
– By user annotations
38
© NICTA 2007/2008 No: 75
Example program
Flow Info Characteristics
do
{
if(...) 
do
{
if(...)       
...
else
...
if(...)
...
else
...
} while(...)
else 
...
}  while(...)
...
Basic finiteness
Statically allowed
Actual feasible
paths
// A
// B
// C
// D          
// E
// F
// G
// H   
// I
// J
Structurally possible
flows (infinite)
Relation between possible 
executions and flow info
max = 10
max = 20
samepath(D,G)
WCET found here = 
desired result
A
B
C D
F G
H
E
Basic block graph
J
I
WCET found here =
overestimation
© NICTA 2007/2008 No: 76
XAB=XA
XE=XCE+XDE
XA=XfooA+XGA
XBC+XBD=XB
 Program 
structure
• Constraints:
Foo()
C
A
B
D
E
F
G
end
Constraints Generated
XA
XB
XC XD
XE
XF
XG
XGA
XAB
XBC XBD
XDE
XEG
XCE
XEF
XFG
XfooA
Xfoo=1
Xend =1
 Start and end 
condition
X
A
<=100 Loop bounds
XC+XF<=XA
 Other flow 
information
39
© NICTA 2007/2008 No: 77
Hardware
• WCET analysis requires a deep 
understanding of 
– hardware features of processors
– Interaction of software and hardware
© NICTA 2007/2008 No: 78
Static Analysis
• Looking at basic blocks in isolation (tree based, 
IPET based)
– Problem of caching effects
• Path based analysis: popular but very expensive
• Problem of conservative assumptions
• Hardware analysis is very expensive
– Data caches and modern branch prediction are very 
hard to model right.
– Call for simpler hardware, e.g. scratchpad memory 
instead of caches
40
© NICTA 2007/2008 No: 79
Measurement Based Analysis
• End-to-end measurements + safety factor used 
for industrial soft-real time system development
– Failed for modern processors as WC could hardly be 
expressed as function of AC
• Measurement on basic block level
– Safer than end-to-end measurements but potentially 
very pessimistic
• What is the worst-case on HW?
• Can it be reliably produced?
• What about preemption delay?
© NICTA 2007/2008 No: 80
Path Based Computation
• Follows each individual paths
• Becomes quickly intractable for large applications
• Altenbernd and Co have tried a simplified 
approach:
– Starting out from the entry point of a function follow a 
path in the CFG  and annotate each node with the 
execution time up to this node
– Do so with any other path, but whenever a join node is 
reached compare new value up to this point with 
annotated value
41
© NICTA 2007/2008 No: 81
Path Based Computation
– Continue if new value is larger or not smaller than the 
the old value minus the smallest of the largest 5 overall 
execution times paths computed so far. (otherwise start 
next path)
– If overall path is larger than smallest of the largest 5 
overall execution times, keep (remove the compared 
smallest of the largest 5 overall execution time paths.
– Check feasibility of 5 longest paths (path may actually 
happen)
© NICTA 2007/2008 No: 82
1
2
3
4
65
7
8
9
2
Alt
Void
Loop
Void
1 3 9
Sequence
65
Alt4 7 8
Sequence
Tree Representation
42
© NICTA 2007/2008 No: 83
• WCET=
max Σ(xentity * tentity)
– Where each xentity
satisfies all constraints
Foo()
C
A
B
D
E
F
G
end
tA=7
tD=2
tB=5
tC=12
tE=4
tF=8
tG=20
IPET Calculation
XA
XB
XC XD
XE
XF
XG
XGA
XAB
XBC XBD
XDE
XEG
XCE
XEF
XFG
XfooA
Xfoo=1
XAB=XA
XE=XCE+XDE
XA=XfooA+XGA
XBC+XBD=XB
XA<=100
XC+XF=100
© NICTA 2007/2008 No: 84
• Solution methods:
– Integer linear programming
– Constraint satisfaction
• Solution:
– Counts for each 
individual node and edge
– The value of the WCET
Foo()
C
A
B
D
E
F
G
end
Calculation methods
XA=100
XB=100
XC=100
XD=0
XE=100
XF=0
XG=100
WCET=4800
Xfoo=1
Xend=1
43
© NICTA 2007/2008 No: 85
Multiprocessor/Multithreaded Real-Time 
Systems
© NICTA 2007/2008 No: 86
WHY
• Performance
– Responsiveness in the presence of many 
external events
• Throughput
– Managing continuous load
• Fault tolerance
– Managing bugs, HW faults
• Reliability
– Ensuring uptime, HW/SW upgrades …
44
© NICTA 2007/2008 No: 87
Hardware
• Symmetric Multithreading (SMT)
– Contention on execution units, caches, memory
• Symmetric Multiprocessor (SMP)
– Contention on memory, cache coherency, eg NUMA
• Asymmetric Multiprocessor
– Specialised units, coherency
• Distributed System
– Latency in communication, loosely coupled
© NICTA 2007/2008 No: 88
SMT
Almost an SMT:
Image taken from http://www.tommesani.com/images/P3Architecture.jpg
45
© NICTA 2007/2008 No: 89
SMP
Image taken from http://linuxdevices.com/files/misc/arm-mpcore-architecture-big.jpg
© NICTA 2007/2008 No: 90
Distributed System
CPU
Caches
Memory
NIC
CPU
Caches
Memory
NIC
CPU
Caches
Memory
NIC
CPU
Caches
Memory
NIC
Network
46
© NICTA 2007/2008 No: 91
Issues
• Resource contention
– Execution units
– Caches
– Memory
– Network
• Adding a CPU does not help
– Example double the load, 2 instead of 1 CPU 
© NICTA 2007/2008 No: 92
Solutions??
• Partitioning
– Resource contention still there!
– Assignment using heuristics
• Non partitioning
– mostly theoretical so far
– Assumptions:
• Zero preemption cost
• Zero migration cost
• Infinite time slicing
– Don’t translate into reality
– Acceptance test and no task migration a way to make it work
47
© NICTA 2007/2008 No: 93
Solutions??
• Quite often non-preemptive
– Fewer context switches
– Reasoning is easy
• IEEE Computer reference to insanity
– Testing is easier??
– Reduce need for blocking
• But!
© NICTA 2007/2008 No: 94
Non-Preemptive
• But!!!
– Less efficient processor use
– Anomalies: response time can increase with
• Changing the priority list
• Increasing number of CPUs
• Reducing execution times
• Weakening the precedence constraints
– Bin packing problem NP hard
– Theoretically: time slicing into small quantums (PFAIR), 
but practically useless, as preemption and task 
migration overhead outweigh gains of Multiprocessors. 
48
© NICTA 2007/2008 No: 95
And now?
• No global solution.
• Partitioning and reducing it to single CPU problem 
good, but still contention of resources.
• Next step: After figuring out how to do the 
scheduling, what about preemption delay?
• Industry works with SMP/SMT, but most often on 
a very ad hoc basis.
• Active and unsolved research area  
• Why does it work on non-RT?
– Running the “wrong” task is not critical.
© NICTA 2007/2008 No: 96
Integrating Real-Time and 
General-Purpose 
Computing
Many thanks to: Scott A. Brandt
University of California, Santa Cruz
49
© NICTA 2007/2008 No: 97
Real-Time vs. General-Purpose OS
• Real-time and general-purpose operating systems 
implement many of the same basic operations
– Process mgmt., memory mgmt, I/O mgmt, etc.
• They aim for fundamentally different goals
– Real-time: Guaranteed performance, timeliness, reliability
– General-purpose: Responsiveness, fairness, flexibility, 
graceful degradation, rich feature set
• They have largely evolved separately
– Real-time system design lags general-purpose system 
design by decades
• They need to merge
© NICTA 2007/2008 No: 98
Why?
• We want both flexible general-purpose processing and robust real-
time processing
– Multimedia is ubiquitous in general-purpose systems
– Real-time systems are growing in size and complexity
• Such systems are possible
– Look at the popularity of RTLinux
– GP hardware has grown powerful enough to support traditional hard real-
time tasks (multimedia, soft modems, etc.)
– Windows, MacOS, etc., are already headed in this direction
• Existing solutions are ad hoc
– RTLinux, MacOS, Windows?
• The world is already headed that way
– Microsoft, HP, Intel, Dell all want to develop integrated home systems
– Complex distributed real-time systems do more than hard real-time
• We need to get out in front and lead the way
50
© NICTA 2007/2008 No: 99
How?
• We need integrated solutions for each type of resource
– CPU, storage, memory, network, …
• They must be hard real-time at their core
– This is the only way to guarantee the hardest constraints
• They must provide native hard real-time, soft real-time, 
and best-effort support
– SRT and BE support cannot be added as an afterthought
– Neither can HRT
• We need an overall model for managing the separate 
resources
– Each process must be able to specify it’s per-resource constraints
– Defaults should be reasonable, and helpful
© NICTA 2007/2008 No: 100
Kinds of Timeliness Requirements
• Hard Real-Time (HRT) [e.g. 
flight control]
– Hard deadlines, WCET
• Rate-Based (RB) [e.g. 
desktop audio]
– Continuous processing 
requirements
• Soft Real-Time (SRT) [e.g. 
desktop video]
– Non-critical deadlines and/or 
variable processing needs, 
worst-case, average-case, or 
no estimates
• Best Effort (BE) [e.g. editor or 
compiler]
– Undefined timeliness 
requirements
Constrained
Unconstrained
• We want to run processes with 
different timeliness requirements 
in the same system
– HRT, RB, SRT, and BE
• Existing schedulers largely 
provide point solutions:
– HRT or RB or one flavor of 
SRT or BE
• Hierarchical scheduling is a 
partial solution
– Allows apps with a variety of 
timeliness requirements, BUT
– Static, inflexible hierarchies 
• Goal: Uniform, fully dynamic 
integrated real-time scheduling
– Same scheduler for all types of 
applications
51
© NICTA 2007/2008 No: 101
Separate Resource Allocation and Dispatching
• Observation: Scheduling 
consists of two distinct 
questions:
Resource allocation
– How much resources to allocate 
to each process
Dispatching
– When to give each process the 
resources it has been allocated
• Existing schedulers integrate 
their management
– Real-time schedulers implicitly 
separate them somewhat via job 
admission
R
es
o
u
r
ce
 A
ll
o
c
a
ti
o
n
Missed
Deadline
SRT
Dispatching
unconstrained
u
n
co
n
st
ra
in
ed
co
n
st
ra
in
ed
Resource
Allocation
SRTSoft
Real-
Time
Best
Effort
CPU-
Bound
I/O-
Bound
Hard
Real-
Time
R
ate-B
ased
constrained
© NICTA 2007/2008 No: 102
The (RAD) Scheduling Model
• Separate management of Resource Allocation 
and Dispatching
– and separate policy and mechanism
Runtime System
Resource
Allocation
Dispatching
Scheduling
Policy
How
much?
When?
Best-Effort
Soft
Real-Time
Rate-Based
Hard
Real-Time
Packets/sec
Frames/sec
ACET
Pri
orit
y
PeriodWCET
Scheduler
P0
Scheduling
MechanismScheduling
Parameters
Feedback
52
© NICTA 2007/2008 No: 103
Rate-Based Earliest Deadline Scheduler
• Basic Idea
– EDF provides hard guarantees
– Varying rates and periods provide 
flexibility 
– Programmable timer interrupts 
guarantee isolation between 
processes
• RBED policy
– Resource allocation: Target rate-
of-progress for each process (S ≤
100%)
– Dispatching: Period based on 
process timeliness needs
• RBED mechanism
– Rate-Enforcing EDF: EDF + 
programmable timer interrupts
Runtime System
Rate
Period
Scheduling
Policy
How
much
?
When?
EDF
w/timers
P0
Scheduling
Mechanism
Period,
WCET
Dispatch,
block, etc.
rate = utilization
WCET = rate*period
RBED: RAD Scheduler using
rate and period to control
resource allocation and dispatching
© NICTA 2007/2008 No: 104
Adjusting Rates at Runtime
Now
HRT
Process
BE
Process 1
New BE process enters
Time
C
u
m
u
la
ti
v
e 
C
P
U
 T
im
e
53
© NICTA 2007/2008 No: 105
Adjusting Rates at Runtime
Now
HRT
Process
BE
Process 1
New BE process enters
Time
C
u
m
u
la
ti
v
e 
C
P
U
 T
im
e
BE
Process 2
© NICTA 2007/2008 No: 106
RBED Periodic Task Model
EDF
• Period and WCET are 
specified per task
– Ti has sequential jobs Ji,k
– Ji,k has release time ri,k, 
period pi, deadline di,k
– ri,k = di,k-1, and di,k= ri,k+ pi
– ui = ei/pi and U = Σ ui
RBED
• Period and WCET are 
specified per job
– Ti has sequential jobs Ji,k
– Ji,k has release time ri,k, 
period pi,k, deadline di,k
– ri,k=  di,k-1, and di,k = ri,k+ pi,k
– ui,k= ei,k/pi,k and U = Σui,k
• Theorem 1: EDF is optimal under the new task model
– Corollary: A new task may enter the system at any time, as long 
as resources are available for it
1
54
© NICTA 2007/2008 No: 107
Two Observations
• At deadlines, a task’s actual resource allocation is 
equal to its target resource allocation
• Actual resource allocation is bounded to the 
feasible region
deadline
p
ro
g
re
s s
timejob release
1
© NICTA 2007/2008 No: 108
Increasing Rate (= increasing WCET)
• Theorem 2: The resource usage of any task can be 
increased at any time, within the available resources
– Given a feasible EDF schedule, at any time task Ti may 
increase utilization by any amount up to 1−U without 
causing any task to miss deadlines in the resulting EDF 
schedule
p
ro
g
re
s s
time
Now
55
© NICTA 2007/2008 No: 109
Increasing Rate (= increasing WCET)
p
ro
g
re
s s
time
Now
• Theorem 2: The resource usage of any task can be 
increased at any time, within the available resources
– Given a feasible EDF schedule, at any time task Ti may 
increase utilization by any amount up to 1−U without 
causing any task to miss deadlines in the resulting EDF 
schedule
© NICTA 2007/2008 No: 110
Increasing Rate (= increasing WCET)
• Theorem 2: The resource usage of any task can be 
increased at any time, within the available resources
– Given a feasible EDF schedule, at any time task Ti may 
increase utilization by any amount up to 1−U without 
causing any task to miss deadlines in the resulting EDF 
schedule
p
ro
g
re
s s
time
Now
A task can
never be in
this region
if resources
are available!
56
© NICTA 2007/2008 No: 111
Increasing Rate (= increasing WCET)
p
ro
g
re
s s
time
Now
• Theorem 2: The resource usage of any task can be 
increased at any time, within the available resources
– Given a feasible EDF schedule, at any time task Ti may 
increase utilization by any amount up to 1−U without 
causing any task to miss deadlines in the resulting EDF 
schedule
© NICTA 2007/2008 No: 112
RBED EDF Mode Change Theory
• Theorem 1: EDF is optimal under this task model
• Corollary: A new task may enter at any time, within available resources
• Theorem 2: The rate of any task can be increased at any time, within 
available resources
• Theorem 3: The period of any task can be increased at any time
• Theorem 4: The rate of any task can be lowered at any time, down to 
what it has already used in the current period
• Theorem 5: The period of any task can be reduced at any time, down 
to the time corresponding to the current period’s resource usage
• Corollary: The period of any task can be increased at any time (without 
changing WCET)
• Corollary: The period of a job which is ahead of its target allocation can
be reduced at any time, down to the time corresponding to its current 
resource usage (without changing WCET) as long as the resources are 
available for the rate change
57
© NICTA 2007/2008 No: 113
RBED Theory Summary
• Rate and period can be changed without causing 
missed deadlines
– At deadlines, rate and period changes are 
unconstrained (except by available resources)
– In between, decreases are constrained by resource 
usage in the current period
– The changes may be combined
• Isolation between processes is guaranteed
© NICTA 2007/2008 No: 114
Better Slack Management: BACKSLASH
• Existing algorithms tend to ignore the needs of 
“background” tasks
– Slack provided when everything else is idle
– Aim for “fair” allocation and 100% utilization
• Slack reclamation is critical in an integrated real-time 
system
– Utilization is important for best-effort systems
– Soft real-time and best effort performance depends on the 
effective use of slack
• BACKSLASH improves performance via slack scheduling
– Focuses on when slack is allocated, and to which process
58
© NICTA 2007/2008 No: 115
When To Allocate Slack?
102.5T3
8.04.0T2
6.01.5T1
PeriodReservationTask
Answer: Allocate 
slack as early as 
possible
Solution
© NICTA 2007/2008 No: 116
Who To Allocate Slack To?
102.5T3
8.04.0T2
6.01.5T1
PeriodReservationTask
Answer: Allocate 
slack to the task 
with the earliest 
deadline
Solution
59
© NICTA 2007/2008 No: 117
How To Use Future Slack?
83T3
8.01.0T2
3.01.5T1
PeriodReservationTask
Answer: Borrow 
resources (potential 
slack) from the next 
job to meet the 
current deadline
Solution
© NICTA 2007/2008 No: 118
83T3
8.01.0T2
3.01.5T1
PeriodReservationTask
How to Allocate Slack to Past Overruns?
Answer: Back-
donate slack to tasks 
that borrowed from 
the future
Solution
60
© NICTA 2007/2008 No: 119
SRAND
SLAD
Principles
1. Allocate slack as early as possible
– With the priority of the donating task
2. Allocate slack to the task with highest priority 
(earliest original deadline)
– Task deadline, not server deadline
3. Allow tasks to borrow against their own future 
resource reservations to complete their current 
job
– With the priority of the donating job
4. Retroactively allocate slack to tasks that have 
borrowed from their current budget to complete a 
previous job
SLASH
BACK
SLASH
+
+
+
© NICTA 2007/2008 No: 120
BACKSLASH Conclusions
• In an integrated system supporting HRT, SRT and BE, 
the performance of SRT (and BE) depends on the 
effective reclamation and distribution of slack
• Four principles for effective slack reclamation and 
distribution:
1. Distribute slack as early as possible
2. Give slack to the ready task with the highest priority
3. Allow tasks to borrow against future reservations
4. Retroactively give slack to tasks that needed it
5. SMASH: Conserve slack across idle times!
• Our results show that these principles are effective: 
BACKSLASH significantly outperforms the other 
algorithms and improves SRT (and/or BE) performance
61
© NICTA 2007/2008 No: 121
Bandwidth Enforcement in RBED and Power 
Management 
Average
Maximum Observed
"Real" Worst-case 
Safe upper bound
Best-case
execution
time
start of
job
reserved budget
Task model
dynamic slack time
k
execution time
k
k
release
time
deadline
k
trelease 
timek+1
© NICTA 2007/2008 No: 122
Some Slack Management in SLASH
Dynamic slack donation
t
t
release time deadline t
preemption
deadline
X
Future Slack Borrowing
62
© NICTA 2007/2008 No: 123
Modelling Time
...2211 ++= PMCPMCCmem αα
...2211 ++= PMCPMCCbus ββ...+++=
bus
bus
mem
mem
cpu
cpu
f
C
f
C
f
C
T
f
CPU
performance
CPU bound application
performance
f
CPU
Memory bound application
...−−−= busmemtotcpu CCCC
© NICTA 2007/2008 No: 124
Modelling Energy
∫+=
T
dynstattot dtPTPE
0
dynstattot EEE +=
( )...2211
2 +++ PMCPMCV φφ
f
CPU
energy
f = f
opt min
f
CPU
energy
f  <  f
optmin
( ) tffVE busbuscpucpudyn ∆++= ...2 χχ
22 cyclesVtfVEdyn ∝∆∝
tfmemmem ∆+ χ
...2211 +++ PMCPMC γγ
63
© NICTA 2007/2008 No: 125
Integration of DVFS
Dynamic slack donation
t
t
t
t
Job stretching wasted cycles 
© NICTA 2007/2008 No: 126
Integration of DVFS: Do we really switch?
t
t
Job stretching
or
t
t
64
© NICTA 2007/2008 No: 127
Algorithm
• Switch to another frequency setting if
– Job can finish on time in the frequency setting 
(inclusive switching cost)
– System energy will be minimised
newEnergy = energyAtCurrentFrequency
newFrequency = currentFrequency
for frequency in frequencySetPoints
if WCETAtSwitchedFrequency + switching.WCET < remainingBudet
&& switching.Energy + energyAtSwitchedFrequency < newEnergy
newEnergy = switchingCost.Energy + energyAtSwitchedFrequency;
newFrequency = frequency;
if newFrequency != currentFrequency
switchFrequency (newFrequency);
© NICTA 2007/2008 No: 128
Effects of Switching Times
t
t
Ideal World
f
f
f
1
2
t
t
Real World
f
f
1
2
65
© NICTA 2007/2008 No: 129
Switching Time Accounting
release
time
deadline
t
reserved budget
execution time dynamic slack
New task model
release 
time
k
kkk k+1
release time tdeadline
t
t tswitch switch
© NICTA 2007/2008 No: 130
Books and other Info
Burns, Alan & Wellings, Andrew: Real-Time Systems and 
Programming Languages (3rd ed), Addison Wesley, 2001 
Kopetz, Hermann: Real-time Systems : Design Principles for 
Distributed Embedded Applications, Kluwer Academic 
Publishers, 1997 
Joseph, Mathai: Real-time Systems: Specification, Verification 
and Analysis, 2001
http://ebook.ieeelab.com/Embedded/RTSbook.pdf
Dale A. Mackall: Development and flight test experiences with 
a flight-crucial digital control system. NASA Technical Paper 
2857, NASA Ames Research Center, Dryden Flight 
Research Facility, Edwards, CA, 1988. 
66
© NICTA 2007/2008 No: 131
Basic Priority Ceiling Protocol
• Scheduling:
– Highest priority task in ready queue gets scheduled. Priority 
exceptions as below
• Each resource has a ceiling priority equivalent of highest priority using 
task
• Allocation
– If resource locked, block
– If (potentially modified) priority of task higher than the ceiling of 
any resource not used by that task but used at the time, allocate
– Else, block
• Priorities:
– If task τ1 blocked at resource held by task τ2:
• τ2 is lifted in priority to task τ1
• revert to original priority once all resources are released
© NICTA 2007/2008 No: 132
Basic Priority Ceiling and Deadlock
• At any time the priority of task τi > ceiling 
priority of resource currently in use THEN
1. task τI will not require any resource currently 
in use
2. Any task τk with priority greater than task τI 
will not require any resource currently in use
– i.e.:
– No task currently holding a resource can 
inherit a higher priority and preempt task τI w

