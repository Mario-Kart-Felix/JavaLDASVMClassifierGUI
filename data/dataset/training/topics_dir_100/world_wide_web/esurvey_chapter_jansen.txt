  
Chapter I
E-Survey Methodology
Karen J. Jansen
The Pennsylvania State University, USA
Kevin G. Corley
Arizona State University, USA
Bernard J. Jansen
The Pennsylvania State University, USA
Copyright © 2007, Idea Group Inc., distributing in print or electronic forms without written permission of IGI is prohibited.
IntroductIon
For the researcher considering the use of elec-
tronic surveys, there is a rapidly growing body of 
literature addressing design issues and providing 
laundry lists of costs and benefits associated with 
electronic survey techniques (c.f., Lazar & Preece, 
1999; Schmidt, 1997; Stanton, 1998). Perhaps the 
three most common reasons for choosing an e-sur-
vey over traditional paper-and-pencil approaches 
are (1) decreased costs, (2) faster response times, 
and (3) increased response rates (Lazar & Preece, 
AbstrAct
With computer network access nearly ubiquitous in much of the world, alternative means of data col-
lection are being made available to researchers. Recent studies have explored various computer-based 
techniques (e.g., electronic mail and Internet surveys). However, exploitation of these techniques requires 
careful consideration of conceptual and methodological issues associated with their use. We identify 
and explore these issues by defining and developing a typology of “e-survey” techniques in organiza-
tional research. We examine the strengths, weaknesses, and threats to reliability, validity, sampling, and 
generalizability of these approaches. We conclude with a consideration of emerging issues of security, 
privacy, and ethics associated with the design and implications of e-survey methodology.
1999; Oppermann, 1995; Saris, 1991). Although 
research over the past 15 years has been mixed on 
the realization of these benefits (Kiesler & Sproull, 
1986; Mehta & Sivadas, 1995; Sproull, 1986; Tse, 
Tse, Yin, Ting, Yi, Yee, & Hong, 1995), for the 
most part, researchers agree that faster response 
times and decreased costs are attainable benefits, 
while response rates differ based on variables 
beyond administration mode alone.
What has been lacking in this literature, until 
recently, is a more specific and rigorous explora-
tion of e-survey methodology. In this chapter, we 
  
E-Survey Methodology
focus on the methodological issues associated with 
designing and conducting e-surveys. We include 
additional issues relating to these methodological 
areas gathered from our own experience in con-
ducting e-survey research. We begin by defining 
the domain of electronic surveys, and develop a 
typology of the various e-survey approaches that 
are possible with today’s technology. This typol-
ogy is important because methodological issues 
can vary depending on whether we are employing 
an e-mail, Web-based, or point-of-contact survey; 
yet these different approaches have frequently 
been treated synonymously in the literature (e.g., 
Simsek & Veiga, 2000; Stanton, 1998). We then 
review what we know and what we do not know 
about e-survey data reliability, validity, and 
generalizability. Finally, we consider several 
emerging concerns associated with designing and 
implementing computer-based surveys including 
survey security, ethical issues associated with how 
and when data is captured, and privacy concerns. 
A version of this chapter was presented at the 
2000 Academy of Management Annual Meeting 
(Corley & Jansen, 2000). 
We define an electronic survey as one in 
which a computer plays a major role in both the 
delivery of a survey to potential respondents and 
the collection of survey data from actual respon-
dents. We use the term mixed-mode surveys (c.f., 
Schaefer & Dillman, 1998) to describe surveys 
that offer alternative response formats (e.g., e-mail 
solicitation with an option to print and return a 
paper-and-pencil survey).
A typology of E-surveys
One can categorize the collection of survey data via 
computers into three main categories based upon 
the type of technology relied upon to distribute the 
survey and collect the data: (1) point of contact; 
(2) e-mail-based; and (3) and Web-based. Disk 
by mail was once a common method (Higgins, 
Dimnik, & Greenwood, 1987; Witt & Bernstein, 
1992), but it is used less so now.
Point-of-contact involves having the respon-
dent fill out an e-survey on a computer provided 
by the researcher, either on-site or in a labora-
tory setting (Synodinos, Papacostas, & Okimoto, 
1994), for organization members who do not use 
computers in their jobs (Rosenfeld, Booth-Kew-
ley, Edwards, & Thomas, 1996). Point-of-contact 
surveys have also been popular among researchers 
wishing to have tight control over the context of 
the study (i.e., lab based). 
The second electronic data collection technique 
is the e-mail-based survey. E-mail-based surveys 
are generally defined as survey instruments that 
are delivered through electronic mail applications 
over the Internet or corporate intranets (Kiesler 
& Sproull, 1986; Sproull, 1986). E-mail-based 
surveys are generally seen as being delivered 
more cheaply and faster than traditional paper-
and-pencil surveys; however, they still require the 
researcher to manually code the data into a database 
after receiving completed surveys. Researchers 
have extensively used e-mail surveys within cor-
porations and online user groups (Corman, 1990; 
Kiesler & Sproull, 1986; Mehta & Sivadas, 1995; 
Sproull, 1986; Thach, 1995). 
The final form of electronic survey, and the 
technique currently receiving the most interest 
from researchers (e.g., Stanton, 1998; Zhang, 
2000), is the Web-based survey. They are generally 
defined as those survey instruments that physi-
cally reside on a network server (connected to 
either an organization’s intranet or the Internet), 
and that can be accessed only through a Web-
browser (Green, 1995; Stanton, 1998). Because 
a Web-based survey is actually created through 
the use of a coding language, the potential exists 
for the survey to change based upon previously 
answered questions (e.g., providing a different 
set of questions based on reported tenure in the 
organization). In addition, these surveys can use 
animation, voice, and video to enhance the user’s 
experience. For example, one study provided a 
sidebar of events that occurred in the year of the 
respondent’s self-reported birth date to assist the 
  
E-Survey Methodology
respondent with recall as well as to maintain mo-
tivation to respond to the survey (Witte, Amoroso, 
& Howard, 2000). Finally, Web-based surveys are 
often connected directly to a database where all 
completed survey data is categorized and stored 
for later analysis (Lazar & Preece, 1999; Schmidt, 
1997). Web-based surveys can be either sampled 
or self-selected. The sampled category describes 
respondents who were chosen using some sam-
pling method (i.e., randomly selected from larger 
population), notified of the chance to participate, 
and directed to the survey’s Web site. In contrast, 
the self-selected category includes those respon-
dents that happen across the survey in the course 
of their normal browsing (e.g., search results, 
Web advertisement, etc.) and are not proactively 
solicited by the researcher.
rEvIEw of thE lItErAturE
A rapidly expanding body of literature on elec-
tronic survey techniques reflects a growing con-
cern among researchers as to the methodological 
issues associated with their use (Couper, 2000; 
Dillman, 1978, 1991; Fink, 1995; Fowler, 1995; 
Krosnick, 1999; Sudman, Bradburn, & Schwarz, 
1996). Much of this literature has focus on the 
methodological issues of e-surveys, or compar-
ing Web versus other survey methods (Leece, 
Bhandari, Sprague, Swiontkowski, Schemitsch, 
Tornetta et al., 2004). These issues include the 
following sections.
reliability
Recent work (e.g., Davis, 1999; Richman, Kiesler, 
Weisband, & Drasgow, 1999) has found a strong 
degree of measurement equivalence between 
computer-based and paper-and-pencil formats, 
although others report lower response rate (Craw-
ford, Couper, & Lamias, 2001). There appear to 
be techniques to improve response rates, however 
(Fowler, 1995). Data quality is also a unique 
threat to e-surveys; however, recent automation 
tools (e.g., Jansen, 1999, 2004; Witte et al., 2000) 
allow for data checking.
validity
According to Cook and Campbell (1979), selec-
tion is a threat to validity when an effect may be 
attributed to the differences between the kinds of 
people in each experimental group. Instrumenta-
tion is a threat when an effect might be due to a 
change in the measuring instrument between pre-
test and posttest, rather than due to the treatment’s 
differential effect at each time interval (Cook & 
Campbell, 1979). A pervasive threat is in actually 
changing an e-survey between time periods and 
administrations. The electronic development and 
maintenance of the survey makes it quite simple 
(and tempting) to make changes during the course 
of data collection, especially when multiple waves 
of data are collected over time; for example, see 
Zhang (2000) and Jansen (1999). 
sampling and Generalizability
As with traditional survey methods, decisions 
regarding sampling and generalizability are impor-
tant ones when considering the use of e-surveys. 
The interested reader can find more detailed in-
formation about specific survey methodologies in 
Simsek and Veiga (2000) for e-mail surveys, and 
Witte et al. (2000) and Kaye and Johnson (1999) 
for Web-based surveys. 
Emerging Issues
The issues of reliability, validity, and sampling 
and generalizability are similar to those encoun-
tered when using a traditional pencil-and-paper 
survey. The presence of technology does provide 
additional issues that must be considered in order 
to effectively collect survey data electronically, 
namely security/access, privacy, and ethics. With 
security, a researcher must be able to restrict ac-
  
E-Survey Methodology
cess to only those people solicited to participate. 
Prior research has summarized the privacy issues 
associated with Internet survey research (Cho & 
LaRose, 1999); the ethical dilemmas in how data is 
captured electronically and how those procedures 
are communicated to the respondent.
ImplIcAtIons And AddItIonAl 
consIdErAtIons
A researcher must then decide which e-survey 
approach is best suited for the particular research 
project under consideration. No one e-survey type 
is inherently better than the others. Each approach 
has its benefits and drawbacks, especially when 
considering issues of time, money, and target 
population. The following section outlines the 
benefits and drawbacks of each approach as a way 
to summarize our discussion of the methodological 
implications of e-surveys (see Table 1).
The point-of-contact approach provides several 
benefits to organizational researchers. First, their 
use circumvents most software compatibility and 
computer access problems. Second, they ensure 
that all respondents, regardless of computer ac-
cess or position in the organization, complete 
the identical instrument. This approach can also 
afford the researcher (if the programming know-
how is available) the ability to take advantage 
of increasingly advanced technology to provide 
multiple-question formats on the instrument, or 
to have data captured directly into a database 
program. The drawbacks to this approach can be 
consequential though, and should be taken into 
consideration before designing a project around 
point-of-contact technology. These drawbacks 
include the cost of supplying the equipment to the 
respondents, scheduling their time to interact with 
the equipment, the potential for time-consuming 
development of the instrument as well as the 
time-consuming task of meeting with all of the 
respondents, and finally, this approach may limit 
the number of respondents a researcher can reach 
in a given amount of time.
E-mail surveys provide the researcher with 
the ability to reach a large number of potential 
respondents quickly and relatively cheaply, 
Approach Benefits Drawbacks
Web-based 
(both solicited 
and non-solicited; 
italicized applies to 
non-solicited only)
•	 Turnaround time (quick delivery and 
easy return)
•	 Ease of reaching large number of 
potential respondents
•	 Can use multiple question formats
•	 Data quality checking
•	 Ease of ensuring confidentiality
•	 Can provide customized delivery of 
items
•	 Can capture data directly in database
•	 Time-consuming development
•	 Potential for limited access within 
target population
•	 Potential for technology problems to 
decrease return rate
•	 Security issues may threaten validity or 
decrease return rate
•	 Lack of control over sample
•	 Potential for bias in sample
Email- based 
(both embedded and 
attached; italicized 
applies to attached 
only)
•	 Turnaround time (quick delivery and 
easy return)
•	 Ease of reaching large number of 
potential respondents
•	 Possibility of incompatible software
•	 Potential for limited access within 
target population
•	 Confidentiality issues may decrease 
return rate 
•	 Respondents comfort level with 
software and attachment process
Point of Contact •	 No software compatibility issues
•	 Fewer computer access issues
•	 Access to populations without 
computers
•	 Identical instrument across all 
respondents
•	 Technology available for multiple 
question formats
•	 Potential to capture data directly in 
database
•	 Cost of equipment
•	 Scheduling time with respondents
•	 Finding acceptable location 
•	 Potentially time-consuming 
development
•	 Potential for time consuming data 
collection effort
•	 May not be able to reach large sample
Table 1. Benefits and drawbacks of e-survey approaches
  
E-Survey Methodology
and to receive any completed surveys in a cor-
respondingly short amount of time. However, as 
with all technology, there can be drawbacks that 
counter these benefits of time and money. E-mail 
surveys may be limited in the number of potential 
respondents they reach due to lack of access to 
a computer, to the Internet, or to an e-mail ac-
count. Issues of software compatibility must be 
addressed, along with the potential reliability 
issues present when differences in technological 
comfort exist among participants, especially for 
attached e-mail surveys. Finally, because e-mail 
messages usually contain some identifier of the 
sender, confidentiality issues may arise with e-mail 
surveys, serving to decrease the return rate.
Finally, Web-based surveys, while the most 
technologically advanced, also come with their 
own set of positives and negatives that must be 
weighed before implementation. On the benefit 
side, Web-based surveys are similar to e-mail-
based surveys in that they provide a short turn-
around time, and can reach a large number of poten-
tial respondents quickly. In addition, Web-based 
surveys can easily take advantage of advancing 
technology to provide multiple-question formats, 
direct database connectivity, data quality checking, 
customized instrument delivery, and guaranteed 
confidentiality, all of which can serve to improve 
the reliability of the data. The drawbacks can be 
serious, depending on the targeted population and 
goal of the research project, because they involve 
time-consuming development, limited access to 
potential users (only those with Internet access), 
potential technological problems, and the possi-
bility of poor security threatening the validity of 
the study. In addition, self-selected Web surveys 
are likely to result in biased samples and provide 
little to no control over the sample.
design and planning considerations
Regardless of which type of e-survey is chosen, 
there are two additional design considerations 
that should be explored. First, the choice of a 
particular survey methodology does not imply 
that solicitation and follow-up requests use the 
same approach. We encourage researchers to 
consider using mixed-mode designs, in keeping 
with the unique requirements of the study and 
the target population (c.f., Lazar & Preece, 1999; 
Sproull, 1986).
The second consideration focuses on different 
approaches for planning for, and coping with, 
technical malfunctions. Simsek and Veiga (2000) 
state that an “advantage of a WWW survey is that 
it is always present and available while [e-mail] is 
inherently episodic.” In actuality, of course, both 
forms of delivery suffer from the same threats 
(transmission errors, network availability, or net-
work overload), while point of contact can have its 
own technical troubles. As a recommendation, we 
caution researchers to consider the possibility of 
their occurrence early in the survey design process, 
and the impact outages can have on subsequent 
response rates and substantive research issues. 
A second recommendation is that care should 
be taken to design user-friendly and informative 
error screens or instructions when the survey is 
unavailable. Additional fail-safes can be designed, 
such as providing alternate routes or means of 
completing the survey when it is inaccessible.
Once researchers get beyond the obvious 
benefits associated with using e-surveys, we must 
acknowledge the importance of careful design, 
development, and testing, which we may not be 
as familiar with in developing paper-and-pencil 
surveys. Software is now available to help cre-
ate HTML forms (Birnbaum, 2000), and many 
firms are emerging that specialize in the design 
and development of electronic surveys. Some of 
these alternatives may be quite costly, and care 
must be taken that the survey and database design 
represent the researcher’s desires. However, if used 
appropriately, these services can help to offset 
the time and knowledge requirements associated 
with effectively designing and implementing a 
computer-based survey.
  
E-Survey Methodology
conclusIon
Researchers attempting to take advantage of orga-
nizations reaching the point where computers and 
Internet access are common, and organizational 
members are comfortable interacting with elec-
tronic media, are beginning to use computer-based 
surveys as a way to reach large numbers of respon-
dents quickly and inexpensively. However, the 
design and implementation of e-surveys involves 
unique methodological issues that researchers 
must consider. We have addressed the various 
electronic techniques, and clarified their method-
ological implications in the hope that the changing 
technologies faced by researchers do not result in 
a growing suspicion of e-survey data, but instead 
serve to raise the standards of what we consider 
to be a strong survey methodology.
rEfErEncEs
Birnbaum, M. H. (2000). SurveyWiz and Fac-
torWiz: JavaScript Web pages that make HTML 
forms for research on the Internet. Behavior 
Research Methods, Instruments, & Computers, 
32(2), 339-346.
Cho, H., & LaRose, R. (1999). Privacy issues in 
Internet surveys. Social Science Computer Review, 
17(4), 421-434.
Cook, T. D., & Campbell, D. T. (1979). Quasi-ex-
perimentation: Design and analysis issues for field 
settings. Boston: Houghton Mifflin Company.
Corley, K. G., & Jansen, K.  J. (2000). Electronic 
survey techniques: Issues and Implications. Paper 
presented at the Academy of Management Annual 
Meeting, Toronto, Canada.
Corman, S. R. (1990). Computerized vs. pencil 
and paper collection of network data. Social 
Networks, 12, 375-384.
Couper, M. (2000). Web surveys: A review of is-
sues and approaches. Public Opinion Quarterly, 
64(4), 464-494.
Crawford, S. D., Couper, M. P., & Lamias, M. J. 
(2001). Web surveys: Perceptions of burden. Social 
Science Computer Review, 19(2), 146 - 162.
Davis, R. N. (1999). Web-based administration 
of a personality questionnaire: Comparison with 
traditional methods. Behavior Research Methods, 
Instruments, & Computers, 31(4), 572-577.
Dillman, D. A. (1978). Mail and telephone surveys. 
New York: John Wiley & Sons.
Dillman, D. A. (1991). The design and administra-
tion of mail surveys, Annual Review of Sociology 
(pp. 225-249). Palo Alto, CA: Annual Reviews.
Fink, A. (1995). The survey handbook (Vol. 1). 
Thousands Oaks, CA: Sage.
Fowler, F. J. (1995). Improving survey questions: 
Design and evaluation (Vol. 38). Thousand Oaks, 
CA: Sage Publications.
Green, T. M. (1995). The refusal problem and 
nonresponse in on-line organizational surveys. 
Unpublished Doctoral Dissertation, University 
of North Texas, Denton, TX.
Higgins, C. A., Dimnik, T. P., & Greenwood, H. 
P. (1987). The DISKQ survey method. Journal of 
the Market Research Society, 29, 437-445.
Jansen, K. J. (1999). Momentum in organizational 
change: Toward a multidisciplinary theory. Un-
published Doctoral Dissertation, Texas A&M 
University, College Station, TX.
Jansen, K. (2004). From persistence to pursuit: 
A longitudinal examination of momentum during 
the early stages of strategic change. Organization 
Science, 15(3), 276-294.
Kaye, B. K., & Johnson, T. J. (1999). Research 
methodology: Taming the cyber frontier. Social 
Science Computer Review, 17(3), 323-337.
  
E-Survey Methodology
Kiesler, S., & Sproull, L. S. (1986). Response 
effects in the electronic survey. Public Opinion 
Quarterly, 50, 402-413.
Krosnick, J. A. (1999). Survey research. Annual 
Review of Psychology, 50, 537-367. Annual Re-
views.
Lazar, J., & Preece, J. (1999). Designing and 
implementing Web-based surveys. Journal of 
Computer Information Systems, 39(4), 63-67.
Leece, P., Bhandari, M., Sprague, S., Swiont-
kowski, M. F., Schemitsch, E. H., Tornetta, P., 
Devereaux, P., & Guyatt, G. H. (2004). Internet 
vs. mailed questionnaires: A randomized com-
parison. Journal of Medical Internet Research, 
6(3), e30.
Mehta, R., & Sivadas, E. (1995). Comparing 
response rates and response content in mail vs. 
electronic mail surveys. Journal of the Market 
Research Society, 37(4), 429-439.
Oppermann, M. (1995). E-mail surveys: Potentials 
and pitfalls. Marketing research, 7(3), 28.
Richman, W. L., Kiesler, S., Weisband, S., & 
Drasgow, F. (1999). A meta-analytic study of 
social desirability distortion in computer admin-
istered questionnaires, traditional questionnaires, 
and interviews. Journal of Applied Psychology, 
84(5), 754-775.
Rosenfeld, P., Booth-Kewley, S., Edwards, J. E., 
& Thomas, M. D. (1996). Responses on computer 
surveys: Impression management, social desir-
ability, and the big brother syndrome. Computers 
in Human Behavior, 12(2), 263-274.
Saris, W. E. (1991). Computer-assisted interview-
ing,  80. Newbury Park: Sage.
Schaefer, D. R., & Dillman, D. A. (1998). Develop-
ment of a standard e-mail methodology: Results 
of an experiment. Public Opinion Quarterly, 62, 
378-397.
Schmidt, W. C. (1997). World-wide Web survey 
research: Benefits, potential problems, and solu-
tions. Behavior Research Methods, Instruments, 
& Computers, 29(2), 274-279.
Simsek, Z., & Veiga, J. F. (2000). The electronic 
survey technique: An integration and assess-
ment. Organizational Research Methods, 3(1), 
92-114.
Sproull, L. S. (1986). Using electronic mail for data 
collection in organizational research. Academy of 
Management Journal, 29(1), 159-169.
Stanton, J. M. (1998). An empirical assessment 
of data collection using the Internet. Personnel 
Psychology, 51, 709-725.
Sudman, S., Bradburn, N. M., & Schwarz, N. 
(1996). Thinking about answers: The application 
of cognitive processes to survey methodology. San 
Francisco: Jossey-Bass Publishers.
Synodinos, N. E., Papacostas, C. S., & Okimoto, 
G. M. (1994). Computer-administered vs. paper-
and-pencil surveys and the effect of sample selec-
tion. Behavior Research Methods, Instruments, 
and Computers, 26(4), 395-401.
Thach, L. (1995). Using electronic mail to con-
duct survey research. Educational Technology, 
March-April, 27-31.
Tse, A. C. B., Tse, K. C., Yin, C. H., Ting, C. B., Yi, 
K. W., Yee, K. P., & Hong, W. C. (1995). Compar-
ing two methods of sending out questionnaires: 
E-mail vs. mail. Journal of the Market Research 
Society, 37(4), 441-446.
Witt, K. J., & Bernstein, S. (1992). Best practices in 
disk-by-mail surveys. Paper presented at the Fifth 
Sawtooth Software conference, Sun Valley, ID.
Witte, J. C., Amoroso, L. M., & Howard, P. E. 
N. (2000). Research methodology: Method and 
representation in Internet-based survey tools 
—Mobility, community, and cultural identity in 
  
E-Survey Methodology
Survey2000. Social Science Computer Review, 
18(2), 179-195.
Zhang, Y. (2000). Using the internet for survey 
research: A case study. Journal of the American 
Society for Information Science, 51, 57-68.
KEy tErms
Electronic Survey: survey in which a computer 
plays a major role in both the delivery of a survey to 
potential respondents and the collection of survey data 
from actual respondents.
E-Mail-Based Surveys: survey instruments that 
are delivered through electronic mail applications over 
the Internet or corporate intranets.
Mixed-Mode Surveys: surveys that offer al-
ternative response formats (e.g., e-mail solicitation 
with an option to print and return a paper-and-pencil 
survey).
Point-of-Contact Survey: having the respondent 
fill out an e-survey on a computer provided by the 
researcher, either on-site or in a laboratory setting.
Web-Based Survey: survey instruments that physi-
cally reside on a network server (connected to either 
an organization’s intranet or the Internet) and that can 
be accessed only through a Web browser.

