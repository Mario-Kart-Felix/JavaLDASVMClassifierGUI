© 1999 Macmillan Magazines Ltd
5. Reboud, X. & Zeyl, C. Heredity 72, 132–140 (1994).
6. McCauley, D. E. Trends Ecol .Evol. 10, 198–202 (1995).
7. Hamilton, M. B. Mol. Ecol. 8, 521–522 (1999).
8. Taberlet, P. et al. Plant Mol. Biol. 17, 1105–1109 (1991).
9. Weir, B. S. Genetic Data Analysis II (Sinauer, Sunderland,
Massachusetts, 1996).
10.Rand, D. M. Conserv. Biol. 10, 665–671 (1996).
ki&1 outgoing (or incoming) links is less
than NPout(ki&1) (or NPin(ki&1)).
A particularly important quantity in a
search process is the shortest path between
two documents, d, defined as the smallest
number of URL links that must be followed
to navigate from one document to the
other. We find that the average of d over all
pairs of vertices is Ðd$40.35&2.06log(N)
(Fig. 1c), indicating that the web forms a
small-world network5,7, which characterizes
social or biological systems. For N482108,
Ðdweb$418.59; that is, two randomly chosen
documents on the web are on average 19
clicks away from each other.
For a given N, d follows a gaussian distri-
bution so Ðd$ can be interpreted as the diam-
eter of the web, a measure of the shortest
distance between any two points in the sys-
tem. Despite its huge size, our results indi-
cate that the web is a highly connected graph
with an average diameter of only 19 links.
The logarithmic dependence of Ðd$ on N is
important to the future potential of the web:
we find that the expected 1,000% increase in
the size of the web over the next few years
will change Ðd$ very little, from 19 to only 21.
The relatively small value of Ðd$ indicates
that an intelligent agent, who can interpret
the links and follow only the relevant one,
can find the desired information quickly by
navigating the web. But this is not the case
for a robot that locates the information
based on matching strings. We find that
such a robot, aiming to identify a docu-
ment at distance Ðd$, needs to search
M(Ðd$)ö0.53×N 0.92 documents, which,
with N482108, leads to M482107, or
10% of the whole web. This indicates that
robots cannot benefit from the highly con-
nected nature of the web, their only success-
ful strategy being to index as much of the
web as possible.
The scale-free nature of the link distrib-
utions indicates that collective phenomena
play a previously unsuspected role in the
development of the web8, forcing us to look
beyond the traditional random graph mod-
els3–5,7. A better understanding of the web’s
topology, aided by modelling efforts, is cru-
cial in developing search algorithms or
designing strategies for making information
widely accessible on the World-Wide Web.
Fortunately, the surprisingly small diameter
of the web means that all that information
is just a few clicks away.
Réka Albert, Hawoong Jeong, 
Albert-László Barabási
Department of Physics, University of Notre Dame,
Notre Dame, Indiana 46556, USA
e-mail:alb@nd.edu
1. Lawrence, S. & Giles, C. L. Nature 400, 107–109 (1999).
2. Claffy, K., Monk, T. E. & McRobb, D. Internet tomography.
Nature [online] <http://helix.nature.com/webmatters/tomog/
tomog.html> (1999).
3. Erdös, P. & Rényi, A. Publ. Math. Inst. Hung. Acad. Sci. 5, 17–61
(1960).
4. Bollobás, B. Random Graphs (Academic, London, 1985).
130 NATURE | VOL 401 | 9 SEPTEMBER 1999 | www.nature.com
brief communications
1. Chase, M. R., Moller, C., Kesseli, R. & Bawa, K. S. Nature 383,
398–399 (1996).
2. Nason, J. D., Allen Herre, E. & Hamrick, J. L. Nature 391,
685–687 (1998).
3. Crawford, T. J. Heredity 52, 273–283 (1984).
4. Chambers, J. Q., Higuchi, N. & Schimel, J. P. Nature 391,
135–136 (1998). 
incoming links, the probability of finding
very popular addresses, to which a large
number of other documents point, is non-
negligible, an indication of the flocking
nature of the web. Furthermore, while the
owner of each web page has complete free-
dom in choosing the number of links on a
document and the addresses to which they
point, the overall system obeys scaling laws
characteristic only of highly interactive self-
organized systems and critical phenomena6.
To investigate the connectivity and the
large-scale topological properties of the
web, we constructed a directed random
graph consisting of N vertices, assigning to
each vertex k outgoing (or incoming) links,
such that k is drawn from the power-law
distribution of Fig. 1a,b. To achieve this, we
randomly selected a vertex i and increased
its outgoing (or incoming) connectivity to
ki&1 if the total number of vertices with
Internet
Diameter of the 
World-Wide Web
Despite its increasing role in communica-
tion, the World-Wide Web remains uncon-
trolled: any individual or institution can
create a website with any number of docu-
ments and links. This unregulated growth
leads to a huge and complex web, which
becomes a large directed graph whose ver-
tices are documents and whose edges are
links (URLs) that point from one docu-
ment to another. The topology of this
graph determines the web’s connectivity
and consequently how effectively we can
locate information on it. But its enormous
size (estimated to be at least 82108 docu-
ments1) and the continual changing of docu-
ments and links make it impossible to
catalogue all the vertices and edges.
The extent of the challenge in obtaining
a complete topological map of the web is
illustrated by the limitations of the com-
mercial search engines: Northern Light, the
search engine with the largest coverage, is
estimated to index only 38% of the web1.
Although much work has been done to
map and characterize the Internet’s infra-
structure2, little is known about what really
matters in the search for information —
the topology of the web. Here we take a step
towards filling this gap: we have used local
connectivity measurements to construct a
topological model of the World-Wide Web,
which has enabled us to explore and char-
acterize its large-scale properties.
To determine the local connectivity of
the web, we constructed a robot that adds to
its database all URLs found on a document
and recursively follows these to retrieve the
related documents and URLs. We used the
data collected to determine the probabilities
Pout(k) and Pin(k) that a document has k
outgoing and incoming links, respectively.
We find that both Pout(k) and Pin(k) follow a
power law over several orders of magnitude,
remarkably different not only from the
Poisson distribution predicted by the classi-
cal theory of random graphs3,4, but also
from the bounded distribution found in
models of random networks5.
The power-law tail indicates that the
probability of finding documents with a
large number of links is significant, as the
network connectivity is dominated by
highly connected web pages. Similarly, for
100 10210
–8
10–6
10–4
10–5
k+1
k+1
k+1
100
10–2
10–4
10–6
10–8
100 101 102
102 103 104 105 106
103 104 100 101 102 103 104
P
ou
t(k
)
P
ou
t(k
)
P
in
(k
)
11
9
7
5
3
N
<
d>
a
c
b
Figure 1 Distribution of links on the World-Wide Web. a, Outgoing
links (URLs found on an HTML document); b, incoming links (URLs
pointing to a certain HTML document). Data were obtained from
the complete map of the nd.edu domain, which contains 325,729
documents and 1,469,680 links. Dotted lines represent analytical
fits used as input distributions in constructing the topological
model of the web; the tail of the distributions follows P(k)ök1g,
with gout42.45 and gin42.1. c, Average of the shortest path
between two documents as a function of system size, as predicted
by the model. To check the validity of our predictions, we deter-
mined d for documents in the domain nd.edu. The measured
Ðdnd.edu$411.2 agrees well with the prediction Ðd32105$411.6
obtained from our model. To show that the power-law tail of P(k) is
a universal feature of the web, the inset shows Pout(k) obtained by
starting from whitehouse.gov (squares), yahoo.com (triangles) and
snu.ac.kr (inverted triangles). The slope of the dashed line is
gout42.45, as obtained from nd.edu in a.
© 1999 Macmillan Magazines Ltd
5. Watts, D. J. & Strogatz, S. H. Nature 393, 440–442 (1998).
6. Bunde, A. & Havlin, S. Fractals in Science (Springer, Berlin, 1994).
7. Barthélémy, M. & Amaral, L. A. N. Phys. Rev. Lett. 82,
3180–3183 (1999).
8. Barabási, A.-L., Albert, R. & Jeong, H. <http://www.nd.edu/
~networks>.
Internet
Growth dynamics of the
World-Wide Web
The exponential growth of the World-Wide
Web has transformed it into an ecology of
knowledge in which highly diverse informa-
tion is linked in an extremely complex and
arbitrary manner. But even so, as we show
here, there is order hidden in the web. We
find that web pages are distributed among
sites according to a universal power law:
many sites have only a few pages, whereas
very few sites have hundreds of thousands
of pages. This universal distribution can be
explained by using a simple stochastic
dynamical growth model.
The existence of a power law in the
growth of the web not only implies the lack
of any length scale for the web, but also
allows the expected number of sites of any
given size to be determined without exhaus-
tively crawling the web. The distribution of
site sizes for crawls by Alexa and Infoseek is
shown in Fig. 1. Both data sets display a
power law over several orders of magnitude,
so on a log–log scale the distribution of the
number of pages per site appears as a
straight line. This distribution should not
be confused with Zipf ’s like distributions1,2,
where a power law arises from rank order-
ing the variables3.
In order to describe the growth process
underlying this distribution4, we assume
brief communications
NATURE | VOL 401 | 9 SEPTEMBER 1999 | www.nature.com 131
3. Gunther, R.et al. Int. J. Theor. Phys. 35, 395–417 (1996).
4. http://www.parc.xerox.com/iea/www/growth.html
5. Crow, E. L & Shimizu, K. Lognormal Distributions: Theory and
Applications (Dekker, New York, 1988).
6. Huberman, B. A., Pirolli, P., Pitkow, J. & Lukose, R. M. Science
280, 95–97 (1998).
7. Huberman, B. A. & Lukose, R. M. Science 277, 535–538 (1997).
100 101 102 103 104 105
10–10
10–8
10–6
10–4
10–2
100
Number of pages
P
ro
ba
bi
lit
y
Alexa
Infoseek
Figure 1 Log–log plot of the distribution of pages in sites for
Alexa and Infoseek crawls, which covered 259,794 and 525,882
sites, respectively. There is a drop-off at approximately 105 pages
because server limitations mean that search engines do not sys-
tematically collect more pages per site than this. A linear regres-
sion on the variables log(number of sites) and log(number of
pages) yielded [1.647, 1.853] as the 95% confidence interval for
the exponent b in the Alexa crawl, and [1.775, 1.909] for the
Infoseek crawl. These estimates for the power-law slope are con-
sistent across the two data sets and with the model, which pre-
dicts that b is greater than 1.
that the day-to-day fluctuations in site size
are proportional to the size of the site. One
would not be surprised to find that a site
with a million pages has lost or gained a few
hundred pages on any given day. On the
other hand, finding an additional hundred
pages on a site with just ten pages within a
day would be unusual. So we assume that
the number of pages on the site, n, on a
given day, is equal to the number of pages
on that site on the previous day plus or
minus a random fraction of n.
If a set of sites is allowed to grow with
the same average growth rate but with indi-
vidual random daily fluctuations in the
number of pages added, their sizes will be
distributed log-normally after a sufficiently
long period of time5. A log-normal distrib-
ution gives high probability to small sizes
and small, but significant, probability to
very large sizes. But although it is skewed
and has a long tail, the log-normal distribu-
tion is not a power-law one.
Two additional factors that determine the
growth of the web need to be considered:
sites appear at different times and grow at
different rates. The number of web sites has
been growing exponentially since its incep-
tion, which means that there are many more
young sites than old ones. Once the age of
the site is factored in to the multiplicative
growth process, P(n), the probability of find-
ing a site of size n, is a power law, that is, it is
proportional to n1b. Similarly, considering
sites with a wide range of distributions in
growth rates yields the same result: a power-
law distribution in site size. The simple
assumption of stochastic multiplicative
growth, combined with the fact that sites
appear at different times and/or grow at dif-
ferent rates, therefore leads to an explanation
of the observed power-law behaviour.
The existence of this universal power law,
which is yet another example of the strong
regularities6,7 revealed by studies of the web,
also has practical consequences. The expect-
ed number of sites of any arbitrary size can
be estimated, even if a site of that size has
not yet been observed. This can be achieved
by extrapolating the power law to any large
n; for example, P(n2)4P(n1)2(n2/n1)
1b.
The expected number of sites of size n2 in a
crawl of N sites would be NP(n2). For
instance, from the Alexa data we can infer
that, if data were collected from 250,000
sites, the probability of finding a site with a
million pages would be 1014. This informa-
tion is not readily available from the crawl
alone, as it stops at 105 pages per site.
Bernardo A. Huberman, Lada A. Adamic
Xerox Palo Alto Research Center, 
3333 Coyote Hill, 
Palo Alto, California 94304, USA
e-mail: ladamic@parc.xerox.com
1. Zipf, G. K. Human Behavior and the Principle of Least Effort
(Addison-Wesley, Cambridge, Massachusetts, 1949).
2. Mantegna, R. N. et al. Phys. Rev. E 52, 2939–2950 (1995).
Genome evolution
Global methylation in
eutherian hybrids
O’Neill et al. propose that epigenetic pro-
cesses help to drive karyotypic evolution in
marsupials1. Here we present evidence that
global methylation patterns do not undergo
dramatic changes in interspecific hybrids
among three orders of placental mammals,
indicating that the mechanisms underlying
genome evolution may be different in pla-
cental mammals and marsupials.
Interspecific hybridization in mammals
frequently results in male sterility2, abnormal
growth2 and placental dysplasia3–5, which
together may cause post-meiotic reproduc-
tive isolation. It has been proposed that
incompatibility between rapidly evolving
genes that interact normally in the intraspe-
cific context6 and genomic rearrangements7
may explain interspecific hybrid defects.
O’Neill et al. have given a striking exam-
ple for the latter mechanism in an interspe-
cific hybrid of the marsupials Macropus
eugenii and M. bicolor1. This first-genera-
tion (F1) hybrid exhibited genome-wide
demethylation, retrotransposon amplifica-
tion and centromere expansion on the
autosomes derived from M. eugenii. Under-
methylation of F1 genomes compared with
those of the parental species was also seen
in two hybrids of other species within the
genus Petrogale1. These findings were taken
to indicate that retrotransposon amplifica-
tion and chromosome expansion secondary
to genome-wide undermethylation could
be a frequent phenomenon in mammalian
hybrids, leading to rapid karyotypic evolu-
tion and finally to reproductive isolation1.
We have analysed genome-wide methyl-
ation in interspecific hybrids in the placen-
tal mammalian families of three orders,
Equidae (Perissodactyla), Muridae (Roden-
tia) and Camelidae (Artiodactyla), by fol-
lowing the digestion of genomic DNA with
the methylation-sensitive and methylation-
insensitive enzymes HpaII and MspI,
respectively, and Southern blotting the
digest. This analysis included hybrids
between horse and donkey, three species of
mouse (Mus musculus, Mus spretus and Mus
macedonicus), and llama (Lama glama) and
dromedary (Camelus dromedarius). This
analysis gave no indication for any changes
in genome-wide methylation in any of the
F1 hybrids when compared with parental
animals (Fig. 1).

