Web Usage Mining: Discovery and Applications of Usage 
Patterns from Web Data 
* Cooley:l: Jaideep Srivastava t ,  Robert , Mukund Deshpande, Pang-Ning Tan 
Department of Computer Science and Engineering 
University of Minnesota 
200 Union St SE 
Minneapolis, MN 55455 
{srivast a,cooley, deshpaqd,pt an} ~cs .umn.edu 
ABSTRACT 
Web usage mining is the application of data mining tech- 
niques to discover usage patterns from Web data, in order to 
understand and better serve the needs of Web-based appli- 
cations. Web usage mining consists of three phases, namely 
preprocessing, pattern discovery, and pattern analysis. This 
paper describes each of these phases in detail. Given its ap- 
plication potential, Web usage mining has seen a rapid in- 
crease in interest, from both the research and practice com- 
munities. This paper provides a detailed taxonomy of the 
work in this area, including research efforts as well as com- 
mercial offerings. An up-to-date survey of the existing work 
is also provided. Finally, a brief overview of the WebSIFT 
system as an example of a prototypical Web usage mining 
system is given. 
Keywords: data mining, world wide web, web usage hain- 
ing. 
1. INTRODUCTION 
The ease and speed with which business transactions can 
be carried out over the Web has been a key driving force 
in the rapid growth of electronic commerce. Specifically, e- 
commerce activity that involves the end user is undergoing 
a significant revolution. The ability to track users' browsing 
behavior down to individual mouse clicks has brought the 
vendor and end customer closer than ever before. It is now 
possible for a vendor to personalize his product message for 
individual customers at a massive scale, a phenomenon that 
is being referred to as mass customization. 
The scenario described above is one of many possible appli- 
cations of Web Usage mining, which is the process of apply- 
ing data mining techniques to the discovery of usage patterns 
]rom Web data, targeted towards various applications• Data 
mining efforts associated with the Web, called Web mining, 
can be broadly divided into three classes, i.e. content min- 
ing, usage mining, and structure mining . Web Structure 
mining projects such as [34; 54] and Web Content mining 
projects such as [47; 21] are beyond the scope of this sur- 
*Can be contacted at jaideep~amazon.com 
~Supported by NSF grant NSF/EIA-9818338 
:~Supported by NSF grant EHR-9554517 
vey. An early taxonomy of Web mining is provided in [29], 
which also describes the architecture of the WebMiner sys- 
tem [42], one of the first systems for Web Usage mining. The 
proceedings of the recent WebKDD workshop [41], held in 
conjunction with the KDD-1999 conference, provides a sam- 
pling of some of the current research being performed in the 
area of Web Usage Analysis, including Web Usage mining. 
This paper provides an up-to-date survey of Web Usage min- 
ing, including both academic and industrial research efforts, 
as well as commercial offerings. Section 2 describes the var- 
ious kinds of Web data that can be useful for Web Usage 
mining. Section 3 discusses the challenges involved in dis- 
covering usage patterns from Web data. The three phases 
are preprocessing, pattern discovery, and patterns analysis• 
Section 4 provides a detailed taxonomy and survey of the 
existing efforts in Web Usage mining, and Section 5 gives 
an overview of the WebSIFT system [31], as a prototypical 
example of a Web Usage mining system, finally, Section 6 
discusses privacy concerns and Section 7 concludes the pa- 
per. 
2. W E B  DATA 
One of the key steps in Knowledge Discovery in Databases 
[33] is to create a suitable target data set for the data mining 
tasks. In Web Mining, data can be collected at the server- 
side, client-side, proxy servers, or obtained from an organi- 
zation's database (which contains business data or consoli- 
dated Web data). Each type of data collection differs not 
only in terms of the location of the data source, but also 
the kinds of data available, the segment of population from 
which the data was collected, and its method of implemen- 
tation. 
There are many kinds of data that can be used in Web Min- 
ing. This paper classifies such data into the following types 
C o n t e n t :  The real data in the Web pages, i.e. the 
data the Web page was designed to convey to the users• 
This usually consists of, but is not limited t6;"text and 
graphics. 
S t r u c t u r e :  Data which describes the organization of 
the content. Intra-page structure information includes 
the arrangement of various HTML or XML tags within 
a given page. This can be represented as a tree struc- 
ture, where the (html) tag becomes the root of the tree. 
SIGKDD Explorations. Ja~l 2000. Volume 1, Issue 2 - page 12 
The  pr incipal  k ind  of inter-page s t ruc tu re  informat ion  
is hyper- l inks  connect ing  one page to another .  
• U s a g e :  D a t a  t h a t  describes the  p a t t e r n  of usage of 
Web pages, such as IP  addresses, page references, an d  
the  date  and  t ime  of accesses. 
* U s e r  P r o f i l e :  Data. t h a t  provides demographic  in- 
format ion abou t  users of the  Web site. This  includes 
regis t ra t ion da t a  and  cus tomer  profile informat ion.  
2.1 Data Sources 
The  usage da t a  collected at  the  different sources will rep- 
resent  the  navigat ion  pa t t e rn s  of different segments  of the  
overall Web traffic, r ang ing  from single-user, single-site brows- 
ing behavior  to  mult i-user ,  mult i -s i te  access pa t te rns .  
2.1.1 Server Level Collection 
A Web server log is an i m p o r t a n t  source for performing Web 
Usage Mining because it  explicitly records the  browsing be- 
havior of site visitors. The  da t a  recorded in server logs re- 
flects the  (possibly concurrent )  access of a Web site by mul-  
t iple users. These  log files can be  s tored in various formats  
such as C o m m o n  log or Ex tended  log formats.  An  exam- 
ple of Ex tended  log format  is given in Figure 2 (Section 3). 
However, t he  site usage da t a  recorded by server logs may  
not  be  entirely reliable due to the  presence of various levels 
of caching wi th in  the  Web envi ronment .  Cached page views 
are not  recorded in a server log. In addit ion,  arty i m p o r t a n t  
informat ion passed t h rough  the  P O S T  m e t h o d  will no t  be  
available in a server log. Packet sniffing technology is an  
a l ternat ive  m e t h o d  to collecting usage da t a  t h ro u g h  server 
logs. Packet  sniffers moni to r  network traffic coming to a 
Web server and  ex t rac t  usage da t a  directly f rom T C P / I P  
packets. The  Web server can also store o ther  kinds of usage 
informat ion such as cookies and  query da ta  in separate  logs. 
Cookies are tokens genera ted  by the  Web server for individ- 
ual client browsers in order  to  automat ica l ly  t rack the  site 
visitors. Tracking of individual  users is not  an  easy task 
due to the  stateless connect ion  model  of the  H T T P  proto-  
col. Cookies rely on implici t  user cooperat ion an d  thus  have 
raised growing concerns regarding user privacy, which will 
be  discussed in Section 6. Query da t a  is also typically gen- 
era ted  by online visi tors while searching for pages relevant  
to  the i r  informat ion  needs. Besides usage data ,  t he  server 
side also provides conten t  data ,  s t ruc tu re  informat ion and  
Web page me ta - in fo rmat ion  (such as the  size of a file and  
its last  modified t ime).  
The  Web server also relies on o ther  util i t ies such as CGI  
scripts  to handle  da t a  sent  back from client browsers. Web 
servers implement ing  the  CGI  s t a n d a r d  parse the  URI  1 of 
the  reques ted  file to  de te rmine  if it is an  appl ica t ion pro- 
gram. The  URI  for CGI  programs may  conta in  addi t ional  
pa rame te r  values to  be  passed to the  CGI  application.  Once 
the  CGI  program has  completed  its execution,  the  Web  
server send the  o u t p u t  of the  CGI  appl icat ion back to the  
browser. 
2.1.2 Client Level Collection 
1Uniform Resource Identifier  (URI)  is a more general defi- 
ni t ion t h a t  includes the  commonly  referred to Uniform Re- 
source Locator  (UI:tL). 
Client-side da t a  collection can be  imp lemen ted  by using a re- 
mote  agent  (such as Javascr ipts  or Java  applets)  or by mod- 
ifying the  source code of an  exist ing browser (such as Mo- 
saic or Mozilla) to  enhance  its da t a  collection capabilities.  
T h e  implemen ta t ion  of client-side da t a  collection me thods  
requires  user cooperat ion,  e i ther  in enabl ing  the  funct ional-  
i ty of the  Javascr ipts  and  Java  applets ,  or to  voluntar i ly  use 
the  modified browser. Client-side collection has  an advan-  
tage  over server-side collection because it  ameliorates  b o t h  
the  caching and  session identif icat ion problems.  However, 
J ava  apple ts  perform no b e t t e r  t h a n  server logs in t e rms  of 
de te rmin ing  the  actual  view t ime of a page. In fact, it may 
incur  some addi t ional  overhead especially when  the  Java  ap- 
plet  is loaded for the  first t ime.  Javascr ipts ,  on the  o ther  
hand ,  consume li t t le in te rp re ta t ion  t ime  bu t  canno t  cap- 
tu re  all user clicks (such as reload or back bu t tons ) .  These 
m e t h o d s  will collect only single-user, single-site browsing be- 
havior.  A modified browser is much  more versatile and  will 
allow da t a  collection abou t  a single user over mult!ple Web 
sites. The  most  difficult par t  of using th is  m e t h o d  is con- 
vincing the  users to  use the  browser for the i r  daily browsing 
activities.  This  can be done by offering incentives to users 
who are willing to use the  browser, similar to the  incen- 
t ive programs offered by companies  such as NetZero [9] and  
Al lAdvan tage  [2] t h a t  reward users for clicking on banne r  
adver t i sements  while surfing the  Web. 
2.1.3 Proxy Level Collection 
A Web proxy acts  as an  in te rmedia te  level of caching be- 
tween client browsers and  Web  servers. Proxy caching (:an 
be  used to reduce the  loading t ime  of a Web page expe- 
r ienced by users as well as the  network traffic load a t  the  
server an d  client sides [27]. The  per formance  of proxy caches 
depends  on the i r  abili ty to  predic t  fu ture  page requests  cor- 
rectly. Proxy traces may  reveal the  ac tual  H T T P  requests  
from mul t ip le  clients to  mul t ip le  Web  servers. This  may 
serve as a da t a  source for character iz ing the  browsing be- 
havior  of a group of anonymous  users, shar ing  a common 
proxy server. 
2.2 Data Abstractions 
The  informat ion  provided by the  da t a  sources described 
above can  all be  used to cons t ruc t / iden t i fy  several da ta  ab- 
s t ract ions,  no tab ly  users, server sessions, episodes, click- 
streams, an d  page views. In order  to  provide some consis- 
t ency  in the  way these t e rms  are defined, the  W3C ~reb 
Charac te r iza t ion  Act ivi ty  (WCA)  [14] has  publ i shed  a draft  
of Web  t e r m  definitions relevant  to  analyzing Web usage. A 
user  is defined as a single individual  t h a t  is accessing file 
from one or more Web servers t h ro u g h  a browser. While  
th is  definit ion seems trivial ,  in pract ice  i t  is very difficult to 
uniquely  and  repeatedly  identify users. A user may  access 
the  Web  t h ro u g h  different machines ,  or use more t h a n  one 
agent  on a single machine.  A page view consists  of every file 
t h a t  con t r ibu tes  to  the  display on a user ' s  browser at  one 
t ime.  Page views are usually associated wi th  a single user 
act ion (such as a mouse-click) an d  can consist  of several files 
such as frames, graphics,  and  scripts.  W h e n  discussing and  
analyzing user behaviors ,  it is really the  aggregate page view 
t h a t  is of impor tance .  The  user does not  explicitly ask for 
"n" frames and  "m" graphics to be loaded into his or her 
browser,  t he  user requests  a "Web page." All of the  infor- 
ma t ion  to de te rmine  which files cons t i tu te  a page view is 
S IGKDD Explorat ions.  • J a n  2000. Volume 1, Issue 2 - page 13 
accessible from the  Web  server. A click-stream is a sequen- 
tial series of page view requests.  Again,  the  d a t a  available 
from the  server side does not  always provide enough infor- 
ma t ion  to recons t ruc t  the  full c l ick-stream for a site. Any 
page view accessed th rough  a cl ient  or proxy-level cache will 
not  be  "visible" from the  server side. A user session is the  
cl ick-stream of page views for a singe user across the  ent i re  
Web. Typically, only the  por t ion  of each user session t h a t  is 
accessing a specific site can be  used for analysis,  since access 
in format ion  is not  publicly available f rom the  vast  major i ty  
of Web  servers. The  set of page-views in a user session 
for a par t icular  Web  site is referred to  as a server session 
(also commonly  referred to as a visit). A set of server ses- 
sious is the  necessary inpu t  for any  Web  Usage analysis or 
d a t a  min ing  tool. The  end  of a server session is defined as 
the  poin t  when  the  user 's  browsing session at  t h a t  site has  
ended.  Again,  th is  is a s imple concept  t h a t  is very difficult 
to  t rack reliably. Any semant ical ly  meaningful  subset  of a 
user or server session is referred to  as an  episode by the  W 3 C  
WCA.  
3. WEB USAGE MINING 
As shown in Figure 1, the re  are th ree  ma in  tasks  for per- 
forming Web Usage Mining or Web  Usage Analysis.  This  
section presents  an  overview of the  tasks  for each s tep and  
discusses the  challenges involved. 
3.1 Preprocessing 
Preprocess ing consists of conver t ing  the  usage, content ,  and  
s t ruc tu re  informat ion con ta ined  in the  various available da t a  
sources into the  da t a  abs t rac t ions  necessary for p a t t e r n  dis- 
covery. 
3.1.1 Usage Preprocessing 
Usage preprocessing is a rguab ly  the  mos t  difficult task  in 
t he  Web  Usage Mining process due to the  incompleteness  of 
the  available data .  Unless a client side t rack ing  mechan i sm 
is used, only the  IP  address,  agent ,  and  server side click- 
s t r e a m  are available to  identify users azld server sessions. 
Some of the  typically encounte red  problems  are: 
• Single IP  address /Mul t ip le  Server  Sessions - In te rne t  
service providers (ISPs) typical ly  have a pool of proxy 
servers t h a t  users access the  Web  through.  A single 
proxy server may have several users accessing a Web  
site, potent ia l ly  over t he  same t ime  period.  
• Mul t ip le  IP  address /Single  Server Session - Some ISPs 
or privacy tools r andomly  assign each request  from a 
user to  one of several IP  addresses.  In th is  case, a 
single server session can  have mul t ip le  IP  addresses. 
• Mult iple  IP  address /Single  User  - A user t h a t  accesses 
the  Web  from different machines  will have a different 
IP  address  from session to session. This  makes  t rack-  
ing repea t  visits from the  same user difficult. 
• Mult iple  Agen t /S inge  User  - Again,  a user t h a t  uses 
more t h a n  one browser,  even on t he  same machine,  
will appea r  as mult iple  users. 
Assuming  each user has  now been  identif ied ( th rough  cook- 
ies, logins, or I P / a g e n t / p a t h  analysis) ,  t he  cl ick-stream for 
each user mus t  be  divided into sessions. Since page requests  
from o ther  servers are no t  typical ly available, i t  is difficult 
to  know when  a user has  left a Web site. A th i r t y  m i n u t e  
t imeou t  is of ten used as the  default  m e t h o d  of b reak ing  a 
user ' s  c l ick-stream into sessions. The  th i r ty  minu te  t imeou t  
is based  on the  resul ts  of [23]. W h e n  a session ID is em- 
bedded  in each URI,  the  definit ion of a session is set  by the  
conten t  server. 
Whi le  t he  exact  con ten t  served as a resul t  of each user ac- 
t ion  is of ten available from the  request  field in t he  server 
logs, it is somet imes  necessary to have access to  the  con ten t  
server in format ion  as well. Since conten t  servers can main-  
th in  s t a t e  var iables  for each active session, the  informat ion  
necessary to de t e rmine  exactly wha t  con ten t  is served by a 
user reques t  is no t  always available in t he  URI.  The  final 
p rob lem encoun te red  when  preprocessing usage d a t a  is t h a t  
of inferr ing cached page references. As discussed in Section 
2.2, the  only verifiable m e t h o d  of t racking cached page views 
is to mon i to r  usage from the  client side. The  referrer field 
for each reques t  can be  used to detec t  some of t he  ins tances  
when  cached pages have been  viewed. 
Figure 2 shows a sample  log t h a t  i l lus t ra tes  several of the  
p rob lems  discussed above (The  first co lumn would not  be  
present  in an  ac tua l  server log, and  is for i l lustrat ive pur-  
poses only).  I P  address  1 2 3 . 4 5 6 . 7 8 . 9  is responsible  for 
th ree  server sessions, and  IP  addresses 2 0 9 . 4 5 6 . 7 8 . 2  and  
209.45.778.3 are responsible  for a four th  session. Using 
a combina t ion  of referrer and  agent  informat ion ,  lines 1 
t h rough  11 can  be  divided into th ree  sessions of A-B-F-Q-6, 
L-R, and  A-B-C-J.  P a t h  complet ion would add  two page ref- 
erences to  the  first session A-B-F-I3-F-B-G, and  one reference 
to the  t h i r d  session A-B-A-C-J.  W i t h o u t  using cookies, an  
e m b e d d e d  session ID, or a client-side d a t a  collection me thod ,  
there  is no  m e t h o d  for de te rmin ing  t h a t  lines 12 a nd  13 are 
ac tual ly  a single server session. 
3.1.2 Content  Preprocess ing 
Conten t  preprocess ing consists  of conver t ing the  tex t ,  im- 
age, scripts,  and  o ther  files such as mul t imed ia  into forms 
t h a t  are useful for the  Web  Usage Mining  process. Often,  
th i s  consis ts  of per forming conten t  min ing  such as classi- 
f ication or clustering.  Whi le  apply ing  d a t a  min ing  to t he  
con ten t  of Web  sites is an  in teres t ing  area of research in i ts 
own r ight ,  in t he  con tex t  of Web Usage Mining  the  con ten t  
of a si te  can  be  used to filter the  inpu t  to, or o u t p u t  f rom 
the  p a t t e r n  discovery algori thms.  For example,  resul ts  of 
a classification a lgor i thm could be  used to  l imit  the  discov- 
ered p a t t e r n s  to  those  conta in ing  page views a b o u t  a cer ta in  
subjec t  or class of products .  In addi t ion  to classifying or 
c lus ter ing page views based  on topics, page views c a n a l s o  
be  classified according to the i r  in tended  use [50; 30]. Page 
views can  be  in tended  to convey informat ion  ( th rough  text ,  
graphics,  or o ther  mul t imedia) ,  ga ther  in format ion  from the  
user, allow naviga t ion  ( th rough  a list of hype r t ex t  links), or 
some combina t ion  uses. The  in tended  use of a page view 
can  also filter the  sessions before or after p a t t e r n  discovery. 
In order  to  r u n  con ten t  min ing  a lgor i thms on page views~ 
the  in fo rmat ion  mus t  first be  conver ted  into a quant i f iable  
format .  Some version of the  vector space model  [51] is typ-  
ically used  to  accomplish this.  Text  files can  be  b roken  up  
into vectors  of words. Keywords or t ex t  descr ipt ions  can  
be  s u b s t i t u t e d  for graphics  or mul t imedia .  T h e  con ten t  of 
s ta t ic  page views can  be  easily preprocessed by  pars ing  the  
H T M L  a n d  r e fo rma t t ing  the  informat ion  or r u n n i n g  addi- 
S I G K D D  Explorat ions.  J an  2000. Volume 1, Issue 2 - page 14 
Prep rocess ing  
Raw Logs 
Site Files 
v 
Preprocessed "Interesting" 
Ciickstream Rules, Patterns, 
Data and Statistics Rules, Patterns, 
and Statistics 
Figure 1: High Level Web Usage Mining Process 
IP Address 
123.456.78.9 
123.456.78.9 
123.456.78.9 
123A56.78.9 
123.456.78.9 
123,456.78.9 
123.456.76.9 
123.456.78.9 
123.458,78.9 
123.456.78.9 
123.456.78.9 
209,458.782 
209.456.78.3 
Usedd Time MethodJ URU Protocol 
[25/Apr/1998:03:94:41-0580] "GET A.h~l HI-FP/1.0" 
[23/Apd1998:03:05:34 -0500] "GET B.html I..ITFP/1.0" 
'GET Lhlrnl H'ITPI1.0" [25/April998:03:05:39,0500] 
[25/April998:03:06:02 -0500] 
[25/April998:03:06:58 -0580] 
"GET F.html HTTP/1.ff' 
"GET A.h~l HTrP/1.0' 
[25/Apr/1998:03:07:42 -0500] "GET B.hlml HTTP/1.0" 
[25/April998:03:07:55 -0500] "GET R.html HTTPI1.0" 
[25/April998:03:09:50 -0500] "GET C.html HI-rP/1.0" 
[25/April998:03:10:02..0500] "GET O.hlml HTIP/1.0" 
[25/Apr/1998:03:10:45..0500] 'GET J.html HTTP/I.0" 
[25/Apr/1998:03:12:23-0500] "GET G.html HTTP/I.0" 
[25/,Apr/1998:05:05:22-0500] "GET A.html H'FrP/I.0" 
[225/Apr/1998:05:06:03 -0500] 'GET D.h~l HTTP/1.0' 
Statue 
200 
200 
200 
200 
200 
200 
200 
200 
200 
200 
200 
200 
200 
Size Referrer Agent 
3290 Mozla/3.04 (Win95, I) 
2050 A.h~l Moziga/3.94 (Win95,1) 
4130 Moziga/3.94 (Win95, I) 
5896 B.hlml Moziga/3.04 (Win95,1) 
3290 Mozilla/3.01 {Xll, I, IRIX6.2, IP22) 
2050 A.html MoziBa/3.01 (X11,I, IRIX6.2, IP22) 
8140 Lhtml Mozma/3.94 (Win95,1) 
1820 A.hknl Mozgla/3.01 (XI1.I, IRIX6.2,1P22) 
2270 F,html MoziBa/3.94 (Win95,1) 
9430 C.html Moziga/3.01 (X11,I, IRIX62, IP22) 
7220 B.htnd MoziBa/3.94 (Win95,1) 
3290 Mozgla/3.94 0Nin95, I) 
1680 A.hb'nl Moziga/3.94(Win95,1) 
Figure 2: Sample Web Server Log 
SIGKDD Explorations. Jan 2000. Volume 1, Issue 2 - page 15 
tional algorithms as desired. Dynamic page views present 
more of a challenge. Content  servers that  employ personal- 
ization techniques and /o r  draw upon databases to construct  
the page views may be capable of forming more page views 
than can be practically preprocessed. A given set of server 
sessions may only access a fraction of the page views possible 
for a large dynamic site. Also the content may be revised 
on a regular basis. The  content  of each page view to be pre- 
processed must  be "assembled", either by an H T T P  request 
from a crawler, or a combination of template,  script, and 
database accesses. If only the port ion of page views that  
are accessed are preprocessed, the output  of any classifica- 
tion or clustering algorithms may be skewed. 
3.1.3 Structure Preprocessing 
The structure of a site is created by the hyper text  links be- 
tween page views. The s tructure can be obtained and pre- 
processed in the same manner  as the content of a site. Again, 
dynamic content  (and therefore links) pose more problems 
than static page views. A different site structure may have 
to be constructed for each server session. 
3.2 Pattern Discovery 
Pat tern  discovery draws upon methods  and algorithms de- 
veloped from several fields such as statistics, data  mining, 
machine learning and pat tern  recognition. However, it is 
not the intent of this paper to describe all the  available algo- 
r i thms and techniques derived from these fields. Interested 
readers should consult references such as [33; 24]. This sec- 
tion describes the  kinds of mining activities tha t  have been 
applied to the  Web domain. Methods developed from other 
fields must take into consideration the different kinds of da ta  
abstractions and prior knowledge available for Web Mining. 
For example, in association rule discovery, the notion of a 
transaction for market-basket  analysis does not  take into 
consideration the order in which i tems are selected. How- 
ever, in Web Usage Mining, a server session is an ordered 
sequence of pages requested by a user. Furthermore,  due to 
the difficulty in identifying unique sessions, additional prior 
knowledge is required (such as imposing a default t imeout  
period, as was pointed out in the previous section). 
3.2.1 Statistical Analysis 
Statistical techniques are the most common method  to ex- 
t ract  knowledge about  visitors to a Web site. By analyzing 
the session file, one can perform different kinds of descrip- 
tive statistical analyses (frequency, mean, median, etc.) on 
variables such as page views, viewing t ime and length of a 
navigational path.  Many Web traffic analysis tools produce 
a periodic report  containing statistical information such as 
the most frequently accessed pages, average view t ime of a 
page or average length of a pa th  through a site. This report  
may include l imited low-level error analysis such as detect-  
ing unauthorized entry points or finding the most common 
invalid URI.  Despite lacking in the depth of its analysis, 
this type of knowledge can be potentially useful for improv- 
ing the system performance, enhancing the security of the  
system, facilitating the site modification task, and providing 
support  for marketing decisions. 
3.2.2 Association Rules 
Association rule generation can be used to relate pages tha t  
are most often referenced together in a single server session. 
In the context  of Web Usage Mining, association rules refer 
to sets of pages that  are accessed together with a support  
value exceeding some specified threshold. These pages may 
not be directly connected to one another  via hyperlinks. For 
example,  association rule discovery using the Apriori algo- 
r i thm [18] (or one of its variants) may reveal a correlation 
between users who visited a page containing electronic prod- 
ucts to those who access a page about  sporting equipment. 
Aside from being applicable for business and marketing ap- 
plications, the presence or absence of such rules can help 
Web designers to restructure their  Web site. The  association 
rules may also serve as a heuristic for prefetching documents 
in order to reduce user-perceived latency when loading a 
page from a remote site. 
3.2.3 Clustering 
Clustering is a technique to group together  a set of i tems 
having similar characteristics. In the Web Usage domain, 
there are two kinds of interest ing clusters to be discovered : 
usage clusters and page clusters. Clustering of users tends 
to establish groups of users exhibit ing similar browsing pat- 
terns. Such knowledge is especially useful for inferring user 
demographics in order to perform market  segmentation in 
E-commerce applications or provide personalized Web con- 
tent  to the users. On the other  hand, clustering of pages 
will discover groups of pages having related content. This 
information is useful for Internet  search engines and Web 
assistance providers. In both applications, permanent  or 
dynamic HTML pages can be created tha t  suggest related 
hyperlinks to the user according to the user's query or past 
history of information needs. 
3.2.4 Classification 
Classification is the task of mapping a data  i tem into one 
of several predefined classes [33]. In the  Web domain, one 
is interested in developing a profile of users belonging to a 
part icular  class or category. This requires extraction and 
selection of features that  best describe the  properties of a 
given class or category. Classification can be done by using 
supervised inductive learning algori thms such as decision 
tree classifiers, naive Bayesian classifiers, k-nearest neigh- 
bor classifiers, Support  Vector Machines etc. For example, 
classification on server logs may lead to the  discovery of in- 
teresting rules such as : 30% of users who placed an online 
order i n / P r o d u c t / M u s i c  are in the 18-25 age group and live 
on the West Coast. 
3.2.5 Sequential Patterns 
The technique of sequential pa t te rn  discovery a t tempts  to 
find inter-session pat terns such tha t  the  presence of a set of 
i tems is followed by another i tem in a t ime-ordered set of ses- 
sions or episodes. By using this approach, Web marketers 
can predict  future visit pat terns  which will be helpful in 
placing advert isements aimed at certain user groups. Other  
types of temporal  analysis that  can be performed on sequen- 
tim pat terns includes t rend analysis, change point detection, 
or similarity analysis. 
3.2.6 Dependency Modeling 
Dependency modeling is another  useful pat tern  discovery 
task in Web Mining. The goal here is to develop a model 
capable of representing significant dependencies among the 
various variables in the Web domain. As an example, one 
SIGKDD Explorations. Jan  2000. Volume 1, Issue 2 - page 16 
may be interested to build a model  representing the different 
stages a visitor undergoes while shopping in an online store 
based on the actions chosen (ie. from a casual visitor to a se- 
rious potential  buyer). There are several probabilistic learn- 
ing techniques that  can be employed to model  the browsing 
behavior of users. Such techniques include Hidden Markov 
Models and Bayesian Belief Networks. Modeling of Web us- 
age pat terns will not only provide a theoretical framework 
for analyzing the behavior of users but  is potentially useful 
for predicting future Web resource consumption. Such infor- 
mation may help develop strategies to increase the sales of 
products  offered by the Web site or improve the navigational 
convenience of users. 
3.3 Pattern Analysis 
Pat tern  analysis is the last step in the overall Web Usage 
mining process as described in Figure 1. The motivation 
behind pat tern analysis is to filter out  uninteresting rules or 
pat terns  from the set found in the pa t te rn  discovery phase. 
The exact analysis methodology is usually governed by the 
application for which Web mining is done. The  most com- 
mon form of pattern analysis consists of a knowledge query 
mechanism such as SQL. Another  method  is to load usage 
data  into a data  cube in order to perform O L A P  operations. 
Visualization techniques, such as graphing patterns or as- 
signing colors to different values, can often highlight overall 
pat terns or trends in the data. Content  and structure infor- 
mation can be used to filter out  pat terns  containing pages 
of a certain usage type, content type, or pages that  match 
a certain hyperlink structure. 
4. TAXONOMY AND PROJECT SURVEY 
Since 1996 there have been several research projects and 
commercial products that  have analyzed Web usage data  
for a number of different purposes. This section describes 
the dimensions and application areas tha t  can be used to 
classify Web Usage Mining projects. 
4.1 Taxonomy Dimensions 
While the number of candidate dimensions that  can be used 
to classify Web Usage Mining projects is many, there are 
five major  dimensions that  apply to every project  - the data  
sources used to gather input, the types of input  data, the 
number  of users represented in each da ta  set, the number of 
Web sites represented in each data  set, and the  application 
area focused on by the project. Usage data  can either be 
gathered at the server level, proxy level, or client level, as 
discussed in Section 2.1. As shown in Figure 3, most projects 
make use of server side data. All projects analyze usage 
da ta  and some also make use of content,  structure,  or profile 
data. The  algorithms for a project can be designed to work 
on inputs representing one or many users and one or many 
Web sites. Single user projects are generally involved in the 
personalization application axea. The projects that  provide 
multi-site analysis use either client or proxy level input data  
in order to easily access usage da ta  from more than one 
Web site. Most Web Usage Mining projects take single-site, 
multi-user, server-side usage data  (Web server logs) as input. 
4.2 Project Survey 
As shown in Figures 3 and 4, usage pat terns  extracted from 
Web data  have been applied to a wide range of applica- 
tions. Projects such as [31; 55; 56; 58; 53] have focused on 
Web Usage Mining in general, without extensive tailoring of 
the process towards one of the various sub-categories. The 
WebSIFT  project  is discussed in more detail in the next sec- 
tion. Cheu et al. [25] introduced the concept of maximal  
forward reference to characterize user episodes for the min- 
ing of traversal patterns.  A maximal forward reference is the 
sequence of pages requested by a user up to the last page be- 
fore backtracking occurs during a particular server session. 
The  SpeedTracer project [56] from IBM Watson is built on 
the work originally reported in [25]. In addition to episode 
identification, SpeedTracer makes use of referrer and agent 
information in the preprocessing routines to identify users 
and server sessions in the absence b f  additional client side 
information. The Web Utilization Miner (WUM) system 
[55] provides a robust mining language in order to specify 
characteristics of discovered frequent paths tha t  are interest- 
ing to the analyst. In their approach, individual navigation 
paths, called trails, are combined into an aggregated tree 
structure.  Queries can be answered by mapping them into 
the intermediate  nodes of the tree structure. Han et al. [58] 
have loaded Web server logs into a data  cube structure in 
order to perform data  mining as well as On-Line Analytical 
Processing (OLAP) activities such as roll-up and drill-down 
of the data. Their  WebLogMiner system has been used to 
discover association rules, perform classification and time- 
series analysis (such as event sequence analysis, transition 
analysis and t rend analysis). Shahabi et. al. [53; 59] have 
one of the  few Web Usage mining systems that  relies on 
client side data  collection. The client side agent sends back 
page request and t ime information to the server every t ime 
a page containing the Java applet (either a new page or a 
previously cached page) is loaded or destroyed. 
4.2.1 Personalization 
Personalizing the Web experience for a user is the holy grail 
of many Web-based applications, e.g. individualized mar- 
keting for e-commerce [4]. Making dynamic recommenda- 
tions to a Web user, based on her /his  profile in addition to 
usage behavior is very at t ract ive to many applications, e.g. 
cross-sales and up-sales in e-commerce. Web usage mining 
is an excellent approach for achieving this goal, as illustrated 
in [43] Exist ing recommendat ion systems, such as [8; 6], do 
not currently use data  mining for recommendations,  though 
there have been some recent proposals [16]. 
The WebWatcher  [37], SiteHelper [45], Letizia [39], and chts- 
tering work by Mobasher et. al. [43] and Yan et. al. [57] 
have all concentrated on providing Web Site personalization 
based on usage information. Web server logs were used by 
Yan et. al. [57] to discover clusters of users having sim- 
ilar access patterns. The system proposed in [57] consists 
of an offline module  that  will perform cluster analysis and 
an online module  which is responsible for dynamic link gen- 
eration of Web pages. Every site user will be assigned to 
a single cluster based on their current traversal pattern.  
The links that  are presented to a given user axe dynami- 
cally selected based on what  pages other users assigned to 
the same cluster have visited. The SiteHelper project learns 
a users preferences by looking at the page accesses for each 
user. A list of keywords from pages that  a user has spent 
a significant amount  of t ime viewing is compiled and pre- 
sented to the user. Based on feedback about  the keyword 
list, recommendat ions for other pages within the site are 
made. WebWatcher  "follows" a user as be or she browses 
S IGKDD Explorations. Jan 2000. Volume 1, Issue 2 - page 17 
. 'YJ2 ~' . . . . . . . . . . . . . . . . .  
WebSIFT (CTS99) 
Sp._yedTmcer (WYB98,CPY96) 
WUM (SF98) 
Sl~ahabi (SZAS97,ZASS97) 
$i!e Helper (NW97) 
Letizia (Lie95) 
.~b Watcher (JFM97) 
Krishnapuram(NKJ99) 
~nalog (YJGD96) 
M obasher (MCS99) 
T~zhilin(PT98) 
Surf Aid 
B.~chner(BM98) 
WebTrends,Hitlist,Aecrue,etc. 
~ebLogMiner (ZXH98) 
P-ageGather,SCML (PE98,PE99) 
M anley(Man97) 
Arlitt(AW96) 
P~tkow(PIT97,PIT98) 
A=lmeida(ABC96) 
R exford(CKR98) 
S_ehechter(SKS98) 
A ggarwal(AY97) 
£t_~J/zlUdtlUl! L/diG ~OUtlL~; I ]./~td 
Focus ~erver Proxy iC|ient :Structure 
I i 
General x x 
General x 
General x x 
General x x 
Personalization x 
Personalization x 
Personalization x 
Personalizafion x 
Pcrsonalization x 
Personalizafion x x 
Business x 
Business x 
Business x 
Business x 
Business x 
Site Modification x x 
Characterization x 
Characterization x 
Characterization x x 
Characterization x 
System Improve. x x 
System Improve. x 
System Improve. x 
! ~ yp~ 
Content 
X 
X 
X 
X 
X 
Usage 
X 
X 
X 
X 
X 
X 
X 
X 
X 
X 
X 
X 
X 
X 
X 
X 
X 
X 
X 
X 
X 
X 
X 
Profile 
Figure 3: Web Usage Mining Research Projects and Products  
Pr' Plrl 
B U l K  
a l B U m  
l U l l  
I I ~ l m  
I ~ i l m  
i n l m  
B U n K  
l u l l  
~ u n m  
R u i n  
/ u l m  
l ~ l m  
~ ~ l m  
~ ~ l m  
~ ~ l m  
/ u / n  
~i 1 eWebSlFT 
Web Usage oWUM 
• SpeedTracer 
Mining eWebLogMiner 
•Shahabi 
Personalization 
• Site Helper 
oLetizia 
eWeb Watcher 
eMobasher 
eAnalog 
eKrishnapuram 
System 
Improvement 
• Rexford 
oSchecter 
oAggarwal 
Site 
Modification 
=Adaptive Sites eSurfhid 
•Buchner 
•Tuzhilin 
Figure 4: Major Application Areas for Web Usage Mining 
Usage 
Characterization 
• Pitkow 
*Aditt 
=Manley 
=Almeida 
SIGKDD Explorations. Jan 2000. Volume 1, Issue 2 - page 18 
the Web and identifies links that  are potentially interesting 
to the user. The WebWatcher starts  with a short descrip- 
tion of a users interest. Each page request is routed througi~ 
the WebWatcher proxy server in order to easily track the 
user session across multiple Web sites and mark any inter- 
esting links. WebWatcher learns based on the particular 
user's browsing plus the browsing of other users with sim- 
ilar interests. Letizia is a client side agent that  searches 
the Web for pages similar to ones that  the user has already 
viewed or bookmarked. The page recommendations in [43] 
are based on clusters of pages found from the server log for a 
site. The system recommends pages from clusters that  most 
closely match the current session. Pages tha t  have not been 
viewed and are not directly linked from the current page axe 
recommended to the user. [44] a t t empts  to cluster user ses- 
sions using a fuzzy clustering algorithm. [44] allows a page 
or user to be assigned to more than  one cluster. 
4.2.2 System Improvement 
Performance and other service quality at t r ibutes axe crucial 
to user satisfaction from services such as databases, net- 
works, etc. Similar qualities are expected from the users of 
Web services. Web usage mining provides the key to under- 
standing Web traffic behavior, which can in turn be used 
for developing policies for Web caching, network transmis- 
sion [27], load balancing, or da ta  distribution. Security is an 
acutely growing concern for Web-based services, especially 
as electronic commerce continues to grow at an exponen- 
tial rate [32]. Web usage mining can also provide pat terns 
which are useful for detecting intrusion, fraud, a t tempted  
break-ins, etc. 
Almeida et al. [19] propose models for predicting the local- 
ity, both temporal  as well as spatial, amongst  Web pages 
requested from a particular user or a group of users access- 
ing from the same proxy server. The locality measure can 
then be used for deciding pre-fetching and caching strategies 
for the proxy server. The  increasing use of dynamic content 
has reduced the benefits of caching at both the client and 
server level. Schechter et. al. [52] have developed algorithms 
for creating path  profiles from data  contained in server logs. 
These profiles are then used to pre-generate dynamic HTML 
pages based on the current user profile in order to reduce la- 
tency due to page generation. Using proxy information from 
pre-fetching pages has also been studied by [27] and [17]. 
4.2.3 Site Modification 
The attractiveness of a Web site, in terms of both content 
and structure, is crucial to many  applications, e.g. a product 
catalog for e-commerce. Web usage mining provides detailed 
feedback on user behavior, providing the Web site designer 
information on which to base redesign decisions. 
While the results of any of the projects could lead to re- 
designing the structure and content  of a site, the adaptive 
Web site project (SCML algorithm) [48; 49] focuses on au- 
tomatically changing the s t ructure  of a site based on usage 
pat terns discovered from server logs. Clustering of pages is 
used to determine which pages should be directly linked. 
4.2.4 Business Intelligence 
Information on how customers axe using a Web site is critical 
information for marketers of e-tailing businesses. Buchner 
et al [22] have presented a knowledge discovery process in or- 
der to discover marketing intelligence from Web data. They 
define a Web log data  hypercube tha t  will consolidate Web 
usage data  along with marketing da ta  for e-commerce appli- 
cations. They identified four distinct steps in customer rela- 
t ionship life cycle that  can be supported by their knowledge 
discovery techniques : customer attraction,  customer reten- 
tion, cross sales and customer departure.  There are several 
commercial  products,  such as SurfAid [11], Accrue [1], Net- 
Genesis [7], Aria [3], Hitlist [5], and WebTrends [13] that  
provide Web traffic analysis mainly for the purpose of gath- 
ering business intelligence. Accrue, NetGenesis, and Aria 
axe designed to analyze e-commerce events such as prod- 
ucts bought and advertisement click-through rates in addi- 
t ion to straight forward usage statistics. Accrue provides a 
pa th  analysis visualization tool and IBM's  SurfAid provides 
O L A P  through a data  cube and clustering of users in addi- 
t ion to page view statistics. Padmanabhan  et. al. [46] use 
Web server logs to generate beliefs about  the access patterns 
of Web pages at a given Web site. Algori thms for finding in- 
teresting rules based on the unexpectedness of t.he rule were 
also developed. 
4.2.5 Usage Characterization 
While most projects that  work on characterizing the usage, 
content, and structure of the Web don ' t  necessarily con- 
sider themselves to be engaged in data  mining, there is a 
large amount  of overlap between Web characterization re- 
search and Web Usage mining. Catledge et al. [23] discuss 
the results of a s tudy conducted at the Georgia Inst i tute  of 
Technology, in which the Web browser Xmosaic was modi- 
fied to log client side activity. The results collected provide 
detailed information about  the user's interaction with the 
browser interface as well as the navigational strategy used go 
browse a particular site. The project also provides detailed 
statistics about occurrence of the various client side events 
such as the clicking the back/forward buttons,  saving a file, 
adding to bookmarks etc. Pitkow et al. [36] propose a model 
which can be used to predict the probabili ty distribution fi)r 
various pages a user might visit on a given site. This model 
works by assigning a value to all the  pages on a site based on 
various at t r ibutes  of that  page. The  formulas and thresh- 
old values used in the model are derived from an extensive 
empirical s tudy carried out on various browsing communi- 
ties and their  browsing patterns Arli t t  et. al. [20] discuss 
various performance metrics for Web servers along with de- 
tails about  the relationship between each of these metrics 
for different workloads. Manley [40] develops a technique 
for generating a custom made benchmark for a given site 
based on its current workload. This benchmark, which he 
calls a self-configuring benchmark, can be used to perform 
scalability and load balancing studies on a Web server. Chi 
et. al. [35] describe a system called W E E V  (Web Ecology 
and Evolution Visualization) which is a visualization tool to 
s tudy the evolving relationship of web usage, content and 
site topology with respect to time. 
5. WEBSIFT O V E R V I E W  
The WebSIFT system [31] is designed to perform Web Us- 
age Mining from server logs in the extended NSCA format 
(includes referrer and agent fields). The  preprocessing algo- 
r i thms include identifying users, server sessions, and infer- 
ring cached page references through the  use of the referrer 
field. The details of the algorithms used for these steps axe 
contained in [30]. In addition to creating a server session 
SIGKDD Explorations. Jail  2000. Volume 1, Issue 2 - page 19 
file, the WebSIFT system performs content and structure 
preprocessing, and provides the option to convert server ses- 
sions into episodes. Each episode is either the subset of all 
content pages in a server session, or all of the navigation 
pages up to and including each content page. Several algo- 
rithms for identifying episodes (referred to as transactions 
in the paper) are described and evaluated in [28]. 
The server session or episode files can be run through se- 
quential pattern analysis, association rule discovery, cluster- 
ing, or general statistics algorithms, as shown in Figure 5. 
The results of the various knowledge discovery tools can be 
analyzed through a simple knowledge query mechanism, a 
visualization tool (association rule map with confidence and 
support weighted edges), or the information filter (OLAP 
tools such as a data cube are possible as shown in Figure 5, 
but are not currently implemented). The information filter 
makes use of the preprocessed content and structure infor- 
mation to automatically filter the results of the knowledge 
discovery algorithms for patterns that are potentially inter- 
esting. For example, usage clusters that contain page views 
from multiple content clusters are potentially interesting, 
whereas usage clusters that match content clusters may not 
be interesting. The details of the method the information fil- 
ter uses to combine and compare evidence from the different 
data sources are contained in [31]. 
6. PRIVACY ISSUES 
Privacy is a sensitive topic which has been attracting a lot of 
attention recently due to rapid growth of e-commerce. It is 
further complicated by the global and self-regulatory nature 
of the Web. The issue of privacy revolves around the fact 
that most users want to maintain strict anonymity on the 
Web. They are extremely averse to the idea that someone is 
monitoring the Web sites they visit and the time they spend 
on those sites. 
On the other hand, site administrators are interested in find- 
ing out the demographics of users as well as the usage statis- 
tics of different sections of their Web site. This information 
would allow them to improve the design of the Web site and 
would ensure that the content caters to the largest popu- 
lation of users visiting their site. The site administrators 
also want the ability to identify a user uniquely every time 
she visits the site, in order to personalize the Web site and 
improve the browsing experience. 
The main challenge is to come up with guidelines and rules 
such that site administrators can perform various analyses 
on the usage data without compromising the identity of an 
individual user. Furthermore, there should be strict regula- 
tions to prevent the usage data from being exchanged/sold 
to other sites. The users should be made aware of the pri- 
vacy policies followed by any given site, so that they can 
make an informed decision about revealing their personal 
data. The success of any such guidelines can only be guar- 
anteed if they are backed up by a legal framework. 
The W3C has an ongoing initiative called Platform for Pri- 
vacy Preferences (P3P) [10; 38]. P3P provides a protocol 
which allows the site administrators to publish the privacy 
policies followed by a site in a machine readable format. 
When the user visits the site for the first time the browser 
reads the privacy policies followed by the site and then com- 
pares that with that security setting configured by the user. 
If the policies are satisfactory the browser continues request- 
ing pages from the site, otherwise a negotiation protocol is 
used to arrive at a setting which is acceptable to the user. 
Another aim of P3P is to provide guidelines for independent 
organizations which can ensure that sites comply with the 
policy statement they are publishing [12]. 
The European Union has taken a lead in setting up a regu- 
latory framework for Internet Privacy and has issued a di- 
rective which sets guidelines for processing and transfer of 
personal data [15]. Unfortunately in U.S. there is no uni- 
fying framework in place, though U.S. Federal Trade Com- 
mission (FTC) after a study of commercial Web sites has 
recommended that Congress develop legislation to regulate 
the personal information being collected at Web sites[26]. 
7. C O N C L U S I O N S  
This paper has attempted to provide an up-to-date survey 
of the rapidly growing area of Web Usage mining. With 
the growth of Web-based applications, specifically electronic 
commerce, there is significant interest in analyzing Web us- 
age data to better understand Web usage, and apply the 
knowledge to better serve users. This has led to a number of 
commercial offerings for doing such analysis. However, Web 
Usage mining raises some hard scientific questions that must 
be answered before robust tools can be developed. This ar- 
ticle has aimed at describing such challenges, and the hope 
is that the research community will take up the challenge of 
addressing them. 
8. R E F E R E N C E S  
[1] Accrue. http://www.accrue.com. 
[2] Alladvantage. http://www.alladvantage.com. 
[3] Andromedia aria. http://www.andromedia.com. 
[4] Brogdvision. http://www.broadvision.com. 
[5] Hit list commerce, http://www.marketwave.com. 
[6] Likeminds. http://www.andromedia.com. 
[7] Netgenesis. http://www.netgenesis.com. 
[8] Netperceptions. http://www.netperceptions.com. 
[9] Netzero. http://www.netzero.com. 
[10] Platform for privacy project. 
http://www.w3.org/P3P/. 
[11] Surfaid analytics, http://surfald.dfw.ibm.com. 
[12] Truste: Building a web you can believe in. 
http://www.truste.org/. 
[13] Webtrends log analyzer, http://www.webtrends.com. 
[14] World wide web committee web usage characterization 
activity, http://www.w3.org/WCA. 
[15] European commission, the directive on the protection 
of individuals with regard ot the processing of per- 
sonal data and on the free movement of such data. 
http://www2.echo.lu/, 1998. 
SIGKDD Explorations. Jazl 2000. Volume l, Issue 2 - page 20 
# , 
I 
Registration or Z Site Files Access Log Referrer Log Agent Log Remote Agent 
~~_~ ~ _  ~ _ a t a _  . . . .  . . . . . .  
~ r=~===~ site Topology j /  s e r v e r , s e s s i o n  I-l ie 
i ~ S l i t e  '' ' ~ ~ C o n t e n t  J Epi~e File J J  / \ 
_ 
~ l ,U  ul> :o 
F, 
otl 
>- ,,,.I 
Z 
Z 
I,i,i 
I1. 
Pattern Clustering ,-,oov ........ Statistics 
, , , ° , ° o  ) t J t Ru,eMining) t <>oo~oo° 
Sequential Patterns 
Filter 
Page Clusters User Clusters 
"Interesting" Rules, Patterns, 
and Statistics 
g / 
Association Rules Usage Statistics 
Figure 5: Archi tec ture  for the  W eb SIFT  System 
SIGKDD Explorat ions.  .Jail 2000. Volume 1, Issue 2 - page 21 
[16] Data mining: Crossing the chasm, 1999. Invited talk at 
the 5th ACM SIGKDD Int'l Conference on Knowledge 
Discovery and Data Mining(KDD99). 
[17] Charu C Aggarwal and Philip S Yu. On disk caching 
of web objects in proxy servers. In CIKM 97, pages 
238-245, Las Vegas, Nevada, 1997. 
[18] R. Agrawal and R. Srikant. Fast algorithms for mining 
association rules. In Proc. of the 20th VLDB Confer- 
ence, pages 487-499, Santiago, Chile, 1994. 
[19] Virgilio Almeida, Azer Bestavros, Mark Crovella, and 
Adriana de Oliveira. Characterizing reference locality 
in the www. Technical Report TR-96-11, Boston Uni- 
versity, 1996. 
[20] Martin F Arlitt and Carey L Williamson. Internet web 
servers: Workload characterization and performance 
implications. 1EEE/A CM Transactions on Networking, 
5(5):631-645, 1997. 
[21] M. Balabanovie and Y. Shoham. Learning informa- 
tion retrieval agents: Experiments with automated 
web browsing. In On-line Working Notes of the AAAI 
Spring Symposium Series on Information Gathering 
from Distributed, Heterogeneous Environments, 1995. 
[22] Alex Buchner and Maurice D Mulvenna. Discovering 
internet marketing intelligence through online analyt- 
ical web usage mining. SIGMOD Record, 27(4):54-61, 
1998. 
[23] L. Catledge and J. Pitkow. Characterizing browsing be- 
haviors on the world wide web. Computer Networks and 
ISDN Systems, 27(6), 1995. 
[24] M.S. Chen, J. Hart, and P.S. Yu. Data mining: An 
overview from a database perspective. IEEE Transac- 
tions on Knowledge and Data Engineering, 8(6):866- 
883, 1996. 
[25] M.S. Chen, J.S. Park, and P.S. Yu. Data mining 
for path traversal patterns in a web environment. In 
16th International Conference on Distributed Comput- 
ing Systems, pages 385-392, 1996. 
[26] Roger Clarke. Internet privacy concerns conf the case 
for intervention. 42(2):60-67, 1999. 
[27] E. Cohen, B. Krishnamurthy, and J. Rexford. Improv- 
ing end-to-end performance of the web using server 
volumes and proxy filters. In Proe. ACM SIGCOMM, 
pages 241-253, 1998. 
[28] Robert Cooley, Bamshad Mobasher, and Jaideep Sri- 
vastava. Grouping web page references into transac- 
tions for mining world wide web browsing patterns. In 
Knowledge and Data Engineering Workshop, pages 2-9, 
Newport Beach, CA, 1997. IEEE. 
[29] Robert Codley, Bamshad Mobasher, and Jaideep Sri- 
vastava. Web mining: Information and pattern discov- 
ery on/th/e world wide web. In International Confer- 
ence on Tools with Artificial Intelligence, pages 558- 
567, Newport Beach, 1997. IEEE. 
[30] Robert Cooley, Bamshad Mobasher, and Jaideep Sri- 
vastava. Data preparation for mining world wide web 
browsing patterns. Knowledge and Information Sys- 
tems, 1(1), 1999. 
[31] Robert Cooley, Pang-Ning Tan, and Jaideep Srivastava. 
Discovery of interesting usage patterns from web data. 
Technical Report TR 99-022, University of Minnesota, 
1999. 
[32] T. Fawcett and F. Provost. Activity monitoring: Notic- 
ing interesting changes in behavior. In Fifth ACM 
SIGKDD International Conference on Knowledge Dis- 
covery and Data Mining, pages 53-62, San Diego, CA, 
1999. ACM. 
[33] U. Fayyad, G. Piatetsky-Shapiro, and P. Smyth. From 
data mining to knowledge discovery: An overview. In 
Proc. ACM KDD, 1994. 
[34] David Gibson, Jon Kleinberg, and Prabhakar Ragha- 
van. Inferring web communities from link topology. In 
Conference on Hypertext and Hypermedia. ACM, 1998. 
[35] Chi E. H., Pitkow J., Mackinlay J., Pirolli P., Goss- 
weiler, and Card S. K. Visualizing the evolution of web 
ecologies. In CHI '98, Los Angeles, California, 1998. 
[36] Bernardo Huberman, Peter Pirolli, James Pitkow, and 
Rajan Kukose. Strong regularities in world wide web 
surfing. Technical report, Xerox PARC, 1998. 
[37] T. Joachims, D. Freitag, and T. Mitchell. Webwatcher: 
A tour guide for the world wide web. In The 15th Inter- 
national Conference on Artificial Intelligence, Nagoya, 
Japan, 1997. 
[38] Reagle Joseph and Cranor Lorrie Faith. The platform 
for privacy preferences. 42(2):48-55, 1999. 
[39] H. Lieberman. Letizia: An agent that assists web 
browsing. In Proe. of the 1995 International Joint Con- 
ference on Artificial Intelligence, Montreal, Canada, 
1995. 
[40] Stephen Lee Manley. An Analysis of Issues Facing 
World Wide Web Servers. Undergraduate, Harvard, 
1997. 
[41] B. Masand and M. Spiliopoulou, editors. Workshop on 
Web Usage Analysis and User Profiling (WebKDD), 
1999. 
[42] B. Mobasher, N. Jaln, E. Hart, and J. Srivastava. Web 
mining: Pattern discovery from world wide web trans- 
actions. (TR 96-050), 1996. 
[43] Bamshad Mobasher, Robert Cooley, and Jaideep Sri- 
vastava. Creating adaptive web sites through usage- 
based clustering of urls. In Knowledge and Data En- 
gineering Workshop, 1999. 
[44] Olfa Nasraoui, Raghu Krishnapuram, and Anupam 
Joshi. Mining web access logs using a fuzzy rela- 
tional clustering algorithm based on a robust estimator. 
In Eighth International World Wide Web Conference, 
Toronto, Canada, 1999. 
SIGKDD Explorations. Jan 2000. Volume 1, Issue 2 - page 22 
[45] D.S.W. Ngu and X. Wu. Sitehelper: A localized agent 
tha t  helps incremental exploration of the world wide 
web. In 6th International World Wide Web Conference, 
Santa  Clara, CA, 1997. 
[46] Balaji  Padmanabhan and Alexander Tuzhilin. A belief- 
driven method  for discovering unexpected patterns.  In 
Fourth International Conference on Knowledge Discov- 
ery and Data Mining, pages 94-100, New York, New 
York, 1998. 
[47] M. Pazzani, L. Nguyen, and S. Mantik. Learning from 
hotlists and coldlists: Towards a www information fil- 
tering and seeking agent. In IEEE 1995 International 
Conference on Tools with Artificial Intelligence, 1995. 
[48] Mike Perkowitz and Oren Etzioni. Adapt ive  web sites: 
Automatical ly  synthesizing web pages. In Fifteenth Na- 
tional Conference on Artificial Intelligence, Madison, 
WI,  1998. 
[49] Mike Perkowitz and Oren Etzioni. Adapt ive web sites: 
Conceptual  cluster mining. In Sixteenth International 
Joint Conference on Artificial Intelligence, Stockholm, 
Sweden, 1999. 
[50] Peter  Pirolli, James Pitkow, and R a m a n a  Rao. Silk 
from a sow's ear: Extract ing usable structures from 
the  web. In CHI-96, Vancouver, 1996. 
[51] G. Salton and M.J. McGill. Introduction to Modern In- 
formation Retrieval. McGraw-Hill, New York, 1983. 
[52] S. Schechter, M. Krishnan, and M. D. Smith. Using 
path profiles to predict h t tp  requests. In 7th Interna- 
tional World Wide Web Conference, Brisbane, Aus- 
tralia, 1998. 
[53] Cyrus Shahabi, Amir  M Zarkesh, Jafar Adibi, and 
Vishal Shah. Knowledge discovery from users web-page 
navigation. In Workshop on Research Issues in Data 
Engineering, Birmingham, England, 1997. 
[54] E. Spertus. Parasite : Mining structural  information on 
the web. Computer Networks and ISDN Systems: The 
International Journal of Computer and Telecommuni- 
cation Networking, 29:1205-1215, 1997. 
[55] Myra Spiliopoulou and Lukas C Faulstich. Wum: A 
web utilization miner. In EDBT Workshop WebDB98, 
Valencia, Spain, 1998. Springer Verlag. 
[56] Kun-lung Wu, Philip S Yu, and Allen Ballman. Speed- 
tracer: A web usage mining and analysis tool. IBM 
Systems Journal, 37(1), 1998. 
[57] T. Yah, M. Jacobsen, H. Garcia-Molina, and U. Dayal. 
From user access pat terns  to dynamic hyper text  link- 
ing. In Fifth International World Wide Web Confer- 
ence, Paris, France, 1996. 
[58] O. R. Zaiane, M. Xin, and J. Han. Discovering web 
access pat terns and trends by applying olap and data  
mining technology on web logs. In Advances in Digital 
Libraries, pages 19-29, Santa Barbara, CA, 1998. 
[59] Amir  Zarkesh, Jafar Adibi, Cyrus Shahabi, Reza Sadri, and 
Vishal Shah. Analysis and design of server informative www- 
sites. In Sixth International Conference on Information and 
Knowledge Management, Las Vegas, Nevada, 1997. 
A b o u t  t h e  A u t h o r s  : 
J a i deep  Sr ivas tava  received the B.Tech. degree in computer 
science from the Indian Institute of Technology, Kanpur, India, 
in 1983, and the M.S. and Ph.D. degrees in computer science 
from the University of California, Berkeley, in 1985 and 1988, 
respectively. Since 1988 he has been on the faculty of the Com- 
puter Science Department, University of Minnesota, Minneapolis, 
where he is currently an Associate Professor. In 1983 he was a 
research engineer with Uptron Digital Systems, Lucknow, India. 
He has published over 110 papers in refereed journals and con- 
ferences in the areas of databases, parallel processing, artificial 
intelligence, and multi-media. His current research is in the areas 
of databases, distributed systems, and multi-media computing. 
He has given a number of invited talks and participated in panel 
discussions on these topics. Dr. Srivastava is a senior member of 
the IEEE Computer Society and the ACM. His professional ac- 
tivities have included being on various program committees, and 
refereeing for journals, conferences, and the NSF. 
R o b e r t  Cooley  is currently pursuing a Ph.D. in computer sci- 
ence at the University of Minnesota. He received an M.S. in 
computer science from Minnesota in 1998. His research interests 
include Data Mining and Information Retrieval. 
M u k u n d  Deshpande  is a Ph.D. student in the Department of 
Computer Science at the University of Minnesota. He received 
an M.E. in system science & automation from Indian Institute of 
Science, Bangalore, India in 1997. 
Pang-Ning  Tan is currently working towards his Ph.D. in Com- 
puter Science at University of Minnesota. His primary research 
interest is in Data Mining. He received an M.S. in Physics from 
University of Minnesota in 1996. 
S IGKDD Explorations. Jan  2000. Volume 1, Issue 2 - page 23 

