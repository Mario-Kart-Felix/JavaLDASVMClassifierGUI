1Pastry, 23
rd  March 2009
Pastry: Scalable, decentralized object 
location and routing for large-scale 
peer-to-peer systems
Antony Rowstron - Peter Druschel  
Microsoft Research Ltd - Rice University
(IFIP/ACM International Conference on Distributed Systems Platforms - 2001)
Amir H. Payberah (amir@sics.se)
Seif Haridi (haridi@kth.se)
2Pastry, 23
rd  March 2009
Review
3
Pastry, 23rd  March 2009
P2P Systems
•Distributed computer system with
 Symmetric components
 Decentralized control and state
 Self-organization
4
Pastry, 23rd  March 2009
Overlay Networks
•Overlay links rely on unicast service in the Internet.
Internet
5
Pastry, 23rd  March 2009
Key Problem: Object Location
•Objects partitioned among participating nodes.
•Mapping from objects to nodes is dynamic.
•Two solutions:
 Unstructured overlay
 Structured overlay
6
Pastry, 23rd  March 2009
Unstructured vs. Structured
•Unstructured
 No assumptions about overlay graph structure.
 Object placement: Inserting node, random walk target or ...
 Object lookup: Scoped flooding or random walk.
 Examples: Gnutella, Kazaa, ...
7
Pastry, 23rd  March 2009
Unstructured vs. Structured
•Unstructured
 No assumptions about overlay graph structure.
 Object placement: Inserting node, random walk target or ...
 Object lookup: Scoped flooding or random walk.
 Examples: Gnutella, Kazaa, ...
•Structured
 Overlay graph conforms to a specific graph structure.
 Key-based routing
 Examples: Chord, Pastry, Kademlia, SkipNet, ...
8Pastry, 23
rd  March 2009
Motivation
9
Pastry, 23rd  March 2009
Consistent Hashing
•Both keys and nodes are mapped to the same ID space.
 Example: Chord
214
7
5
10
8
15
11
3
12
6
0
13
9
4
1
ID Space: [0, 15]
Key
Node
10
Pastry, 23rd  March 2009
Consistent Hashing
•Both keys and nodes are mapped to the same ID space.
 Example: Chord
•Result:
 Uniformly distributed
214
7
5
10
8
15
11
3
12
6
0
13
9
4
1
ID Space: [0, 15]
Key
Node
11
Pastry, 23rd  March 2009
Challenge: Overlay Route Efficiency
•Nodes close in id space, but far away in Internet.
•Goal: choose routing table entries that yield few hops and low 
latency.
12Pastry, 23
rd  March 2009
Plaxton Mesh
13
Pastry, 23rd  March 2009
Goal
•A set of shared objects in a network.
•Goal: Designing an access scheme that is efficient w.r.t both 
time and space.
14
Pastry, 23rd  March 2009
Goal
•A set of shared objects in a network.
•Goal: Designing an access scheme that is efficient w.r.t both 
time and space.
•What is the challenge here (think about this: if every node 
stores the location of each object in the system)? [d]
15
Pastry, 23rd  March 2009
Goal
•A set of shared objects in a network.
•Goal: Designing an access scheme that is efficient w.r.t both 
time and space.
•What is the challenge here (think about this: if every node 
stores the location of each object in the system)? [d]
 Read is fast.
 Insert and delete are very expensive.
 Storage overhead grows.
16
Pastry, 23rd  March 2009
Main Idea
•Map the nodes and objects to b-ary numbers of m digits.
•Assign each object to the node with which it shares the largest 
prefix.
 e.g. b = 4 and m = 6:
                                                            321002
                               321302
                                                            321333
17
Pastry, 23rd  March 2009
Routing Table
•Level i matches i prefix entries.
•Number of rows = m.
•Number of entries per level = b.
•b = 4, m = 6
•nodeID = 110223
p = 4
p = 5
p = 2
p = 3
p = 0 0xxxxx
p = 1 10xxxx
d = 0 d = 1 d = 2 d = 3
11020x
1100xx
110200
111xxx
1101xx
11021x
110221
2xxxxx 3xxxxx
13xxxx12xxxx
112xxx 113xxx
1103xx
11023x
110222
110223
110223
110223
110223
110223
110223
18
Pastry, 23rd  March 2009
Routing Table
•b = 4, m = 6
•nodeID = 110223
p = 4
p = 5
p = 2
p = 3
p = 0 023120
p = 1 100233
d = 0 d = 1 d = 2 d = 3
110203
110021
110200
111023
110121
110213
110221
212320 300123
132121121100
112333 113222
110301
110233
110222
19
Pastry, 23rd  March 2009
Routing 
•At node A find object O:
 Let the shared prefix of A and O be of length n,
 Look at level n+1in routing table of A,
 Find the entry at level n+1 that matches digit n+1of O's id (call it the node B),
 Send the message to node B,
 Eventually the message gets relayed to the destination.
•Move closer to the target one digit at the time.
20
Pastry, 23rd  March 2009
Routing Sample (1/6)
• b = 4, m = 6, nodeID = 110223 → lookup(322010)
p = 4
p = 5
p = 2
p = 3
p = 0
p = 1
d = 0 d = 1 d = 2 d = 3
Node 110223 routing table
110223
300123
21
Pastry, 23rd  March 2009
Routing Sample (2/6)
• b = 4, m = 6, nodeID = 110223 → lookup(322010)
p = 4
p = 5
p = 2
p = 3
p = 0
p = 1
d = 0 d = 1 d = 2 d = 3
Node 300123 routing table
110223 300123
323130
22
Pastry, 23rd  March 2009
Routing Sample (3/6)
• b = 4, m = 6, nodeID = 110223 → lookup(322010)
p = 4
p = 5
p = 2
p = 3
p = 0
p = 1
d = 0 d = 1 d = 2 d = 3
322321
Node 323130 routing table
110223 300123 323130
23
Pastry, 23rd  March 2009
Routing Sample (4/6)
• b = 4, m = 6, nodeID = 110223 → lookup(322010)
p = 4
p = 5
p = 2
p = 3
p = 0
p = 1
d = 0 d = 1 d = 2 d = 3
Node 322321 routing table
110223 300123 323130 322321
322023
24
Pastry, 23rd  March 2009
Routing Sample (5/6)
• b = 4, m = 6, nodeID = 110223 → lookup(322010)
p = 4
p = 5
p = 2
p = 3
p = 0
p = 1
d = 0 d = 1 d = 2 d = 3
Node 322023 routing table
110223 300123 323130 322321 322023
322011
25
Pastry, 23rd  March 2009
Routing Sample (6/6)
• b = 4, m = 6, nodeID = 110223 → lookup(322010)
110223 300123 323130 322321 322023 322011
26
Pastry, 23rd  March 2009
Routing Sample (1/6)
• b = 4, m = 6, nodeID = 110223 → lookup(322010)
000000 100000 200000 300000 333333
110223 300123
27
Pastry, 23rd  March 2009
Routing Sample (2/6)
• b = 4, m = 6, nodeID = 110223 → lookup(322010)
000000 100000 200000 300000 333333
110223 300123
300000 310000 320000 330000 333333
300123 323130
28
Pastry, 23rd  March 2009
Routing Sample (3/6)
• b = 4, m = 6, nodeID = 110223 → lookup(322010)
000000 100000 200000 300000 333333
110223 300123
300000 310000 320000 330000 333333
300123 323130
320000 321000 322000 323000
323130322321
330000
29
Pastry, 23rd  March 2009
Routing Sample (4/6)
• b = 4, m = 6, nodeID = 110223 → lookup(322010)
000000 100000 200000 300000 333333
110223 300123
300000 310000 320000 330000 333333
300123 323130
320000 321000 322000 323000
323130322321
330000
322000 322100 322200 322300
322321322023
323000
30
Pastry, 23rd  March 2009
Routing Sample (5/6)
• b = 4, m = 6, nodeID = 110223 → lookup(322010)
000000 100000 200000 300000 333333
110223 300123
300000 310000 320000 330000 333333
300123 323130
320000 321000 322000 323000
323130322321
330000
322000 322100 322200 322300
322321322023
323000
322000 322010 322020 322030
322023322011
322100
31
Pastry, 23rd  March 2009
Routing Sample (6/6)
• b = 4, m = 6, nodeID = 110223 → lookup(322010)
000000 100000 200000 300000 333333
110223 300123
300000 310000 320000 330000 333333
300123 323130
320000 321000 322000 323000
323130322321
330000
322000 322100 322200 322300
322321322023
323000
322000 322010 322020 322030
322023322011
322100
322010 322011 322012 322013
322011322010
322020
32Pastry, 23
rd  March 2009
Pastry
33
Pastry, 23rd  March 2009
Pastry
•Pastry is an overlay and routing network for the implementation of 
a distributed hash table similar to Chord.
•Seeks to minimize the distance messages travel.
•Expected number of routing steps is O(log N).
 N = No. of Pastry nodes in the network.
34
Pastry, 23rd  March 2009
Routing Table
Leaf set: L/2 numerically closest 
nodes
Routing table: prefix-based
Neighbor set: M physically closest
nodes
35
Pastry, 23rd  March 2009
Routing
• If message with key D is within range of leaf set, forward to 
numerically closest leaf.
•Else forward to node that shares at least one more digit with D in 
its prefix than current nodeId.
• If no such node exists, forward to node that shares at least as 
many digits with D as current nodeId but numerically nearer than 
current nodeId.
36
Pastry, 23rd  March 2009
Routing Example
ID Space: [0, 2128-1]
d46a1c
d13da3
65a1fc
d4213f
d462ba
d467c4
route(d46a1c)
0 2128-1
d471f1
37
Pastry, 23rd  March 2009
Joining
•Assume the node ID is X, and initially it knows a physically nearby 
node A in the system.
•X sends A a join message with the key equal to X’s ID.
•Pastry routes the message to a node B whose ID is numerically 
closest to X’s ID.
•The message follows a paths through nodes A, B, etc., and 
eventually reaches node Z.
38
Pastry, 23rd  March 2009
Joining Example
ID Space: [0, 2128-1]
d46a1c
d13da3
65a1fc
d4213f
d462ba
d467c4
addnode(d46a1c)
0 2128-1
d471f1
39
Pastry, 23rd  March 2009
Joining: First Routing Table
•The neighborhood-set is set to that of the first node, A. 
•The leaf-set is set to that of the final node, Z.
•The routing table is collected from each node along the route.
 The ith node on the route should send its ith row of routing table to the new 
node.
40
Pastry, 23rd  March 2009
First Routing Table Example
ID Space: [0, 2128-1]
d46a1c
B
A
C
D
Z
addnode(d46a1c)
0 2128-1
X
Node X routing table
41
Pastry, 23rd  March 2009
Failure
•Failure in leaf set (LS):
 Detected by heartbeat
 Repair by inserting node from another leaf’s (LS).
42
Pastry, 23rd  March 2009
Failure
•Failure in leaf set (LS):
 Detected by heartbeat
 Repair by inserting node from another leaf’s (LS).
•Failure in neighborhood set (NS):
 Detected by heartbeat
 Query all NS members for their NS tables, choose replacement according to 
proximity metric.
43
Pastry, 23rd  March 2009
Failure
•Failure in leaf set (LS):
 Detected by heartbeat
 Repair by inserting node from another leaf’s (LS).
•Failure in neighborhood set (NS):
 Detected by heartbeat
 Query all NS members for their NS tables, choose replacement according to 
proximity metric.
•Failure int routing table (RT):
 Entries detected when attempting to route
 Query nodes in row for replacement entry, if failed
 Query successive rows until success.
44
Pastry, 23rd  March 2009
Failure Example
p = 4
p = 5
p = 2
p = 3
p = 0 023120
p = 1 100233
d = 0 d = 1 d = 2 d = 3
110203
110021
110200
111023
110121
110213
110221
212320 300123
132121121100
112333 113222
110301
110233
110222
1
1
0
2
2
3
Node in red fails.
1. Try asking some neighbors in 
the same row for its 111xxx entry.
2. If it doesn't have one, try asking
some neighbor in the row below, etc.
45Pastry, 23
rd  March 2009
So, what about
locality?
46
Pastry, 23rd  March 2009
Locality
•Pastry’s notion of network proximity is based on a scalar proximity 
metric.
 Number of IP routing hops
 Geographic distance
•We assume that the proximity space defined by the chosen 
proximity metric is Euclidean; that is, the triangulation inequality 
holds for distances among Pastry nodes.
47
Pastry, 23rd  March 2009
Locality in Routing Table
•The property we wish to maintain is that all routing table entries 
refer to a node that is near the present node.
ID Space: [0, 2128-1]
d46a1c
B
A
C
D
Z
addnode(d46a1c)
0 2128-1
X
Node X routing table
48
Pastry, 23rd  March 2009
Locality in Routing Table
•We assume that this property holds prior to node X’s joining the 
system, and show how we can maintains the property as node 
joins.
49
Pastry, 23rd  March 2009
Routing Table – Row 0
•First, we require that node A is near X, according to the proximity 
metric. 
•Since the entries in row zero of A’s routing table are close to A, 
and A is close to X, and we assume that the triangulation 
inequality holds in the proximity space, it follows that the entries 
are relatively near A. Therefore, the desired property is preserved.
50
Pastry, 23rd  March 2009
Routing Table – Row 1
•The entries in this row are near B, however, it is not clear how 
close B is to X.
•Take row one of X's routing table from node B does not preserve 
the desired property, since the entries are close to B, but not 
necessarily to X. [d]
51
Pastry, 23rd  March 2009
Routing Table – Row 1
•For larger row numbers the number of possible choices decreases 
exponentially.
•For larger row numbers the expected distance to the nearest 
neighbor increases exponentially.
•Therefore, the expected distance from B to its row one entries (B1) 
is much larger than the expected distance traveled from node A to 
B.
52
Pastry, 23rd  March 2009
Locality
X
A
B - (A0)
C - (B1)
53Pastry, 23
rd  March 2009
Pastry and other DHTs
54
Pastry, 23rd  March 2009
Pastry vs. Chord
•A Plaxton tree combined with a Chord-like ring
 Each node has Plaxton-style neighbors.
 Each node knows its predecessor and successor.
• Called its leaf set
• like Chord
 Only leaf set necessary for correctness.
 Plaxton-neighbors like finger table, only for performance.
•Unlike Chord
 Chord's metric is asymmetry, while Pastry's metric is symmetry.
55Pastry, 23
rd  March 2009
Done!
56
Pastry, 23rd  March 2009
A Page To Remember
Node X routing table
• At node A find object O:
 Let the shared prefix of A and O be of length n,
 Look at level n+1in routing table of A,
 Find the entry at level n+1 that matches digit n+1of O's id 
(call it the node B),
 Send the message to node B,
 Eventually the message gets relayed to the destination.
ID Space: [0, 2128-1]
d46a1c
d13da3
65a1fc
d4213f
d462ba
d467c4
addnode(d46a1c)
0 2128-1
d471f1
Node X
57
Pastry, 23rd  March 2009
References
• [1] C. G. Plaxton, R. Rajaraman, and A. W. Richa. "Accessing nearby copies of replicated objects in a 
distributed environment". In Proceedings of the 9th Annual ACM Symposium on Parallel Algorithms and 
Architectures, Newport, Rhode Island, pages 311-320, June 1997.
• [2] A. Rowstron and P. Druschel, "Pastry: Scalable, decentralized object location and routing for large-
scale peer-to-peer systems".  IFIP/ACM International Conference on Distributed Systems Platforms 
(Middleware), Heidelberg, Germany, pages 329-350, November, 2001.
58Pastry, 23
rd  March 2009
Question?

