Parareal Algorithm Implementation and Simulation in Julia
Tyler M. Masthay and Saverio Perugini
Department of Computer Science
University of Dayton
Dayton, Ohio 45469–2160 USA
{tmasthay1,saverio}@udayton.edu
ABSTRACT
We present a full implementation of the parareal algorithm—an
integration technique to solve dierential equations in parallel—
in the Julia programming language for a fully general, rst-order,
initial-value problem. Our implementation accepts both coarse and
ne integrators as functional arguments. We use Euler’s method
and another Runge-Kutta integration technique as the integrators
in our experiments. We also present a simulation of the algorithm
for purposes of pedagogy.
KEYWORDS
Concurrent programming, Euler’s method, Julia, Runge-Kutta meth-
ods, parareal algorithm, ordinary dierential equations.
Tyler M. Masthay and Saverio Perugini. 2017. Parareal Algorithm
Implementation and Simulation in Julia. , 4 pages.
1 INTRODUCTION
The parareal algorithm was rst proposed in 2001 by Lions, Ma-
day, and Turinici [3] as an integration technique to solve dier-
ential equations in parallel. We present a full implementation of
the parareal algorithm in the Julia programming language (https:
//julialang.org) [4] for a fully general, rst-order, initial-value prob-
lem. Furthermore, we present a simulation of the algorithm for
purposes of pedagogy. Our implementation accepts both coarse
and ne integrators as functional arguments. We use Euler’s method
and another Runge-Kutta integration technique as the integrators
in our experiments.
2 THE PARAREAL ALGORITHM
The parareal algorithm is designed to perform parallel-in-time in-
tegration for a rst-order initial-value problem. The algorithm in-
volves two integration techniques, often known as the ‘coarse’
integrator and the ‘ne’ integrator. For the algorithm to be eective,
the coarse integrator must be of substantially lower computational
cost than the ne integrator. The reason will become apparent later
in this section. Consider the dierential equation (1) given by
y′(t) = f (t ,y(t)) t ∈ [a,b] (1)
with its associated initial-value problem (2)
y(t∗) = y∗ t∗ ∈ [a,b]. (2)
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for prot or commercial advantage and that copies bear this notice and the full citation
on the rst page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
© 2017 Copyright held by the owner/author(s).
Figure 1: Right endpoint error.
For simplicity, let us assume t∗ = a, so that the solution only ex-
tends rightward. To obtain an approximate solution to equation (1)
satisfying the initial condition (2), we partition our domain into
[t0 = a, ..., tN = b] with uniform step size ∆. We now precisely
dene an ‘integrator’ as a function from (0,∞)×R2 ×R to R where
R is the set of all Riemann integrable functions. For example, the
integrator I given by
I (δ ,x0,y0,д) = y0 + д(x0,y0)δ
is the integrator corresponding to Euler’s method with step size δ .
Let C and F be the coarse and ne integrators, respectively. Dene
y0,1 = y(t0) = y∗
yn+1,1 = y(tn+1) = C(∆, tn ,yn,1, f ).
Sinceyn+1,1 depends onyn,1, this algorithm is inherently sequential.
Partition [tn , tn+1] into {t0n = tn , ..., tmn , ...tMn = tn+1}with uniform
step size δ < ∆. Dene
z0n,1 = y(t
0
n ) = yn,1
zm+1n,1 = y(t
m+1
n ) = F(δ , tmn , zmn,1, f ).
This yields an approximate solution {z0n,1, ..., z
M
n,1} to (1) over [tn , tn+1]
with initial conditions
y(tn ) = yn,1.
Since zm1n1,1 does not depend on z
m2
n2,1 for n1 , n2, we can compute
these approximations in parallel. After the last subproblem is solved,
we simply combine the solutions on each subdomain to obtain a so-
lution over the whole interval. However, our values {y1,1, ...,yn,1}
are relatively inaccurate. The vertical spikes in the orange graph
separating the coarse and ne predictions in Figure 1 illustrate this
ar
X
iv
:1
70
6.
08
56
9v
1 
 [
cs
.M
S]
  2
6 
Ju
n 
20
17
T.M. Masthay & S. Perugini
error. However, zMn−1,1 is a better approximation for ϕ(tn ) where
ϕ is the exact solution to the dierential equation. We use this to
obtain a better set of points {yn,2} for the coarse approximation.
We do this by rst dening wn,1 = yn,1 and then dening
w1,2 = y1,1 = y1,2 = y
∗
wn,2 = C(∆, tn−1,yn−1,2, f )
yn,2 = (wn,2 −wn,1) + zMn−1,1.
Thus, wn+1,2 serves as a new prediction given a more accurate
previous prediction from yn,2 since zMn−1,1 has now been taken into
account in calculating yn,2. In general, we continue evaluating so
that for k > 1, we have
w1,k = y1,k = y
∗
wn,k = C(∆, tn−1,yn−1,k−1, f )
yn,k = (wn,k −wn,k−1) + zMn−1,k−1.
Note that since yn,k is dependent on wn,k , this step must be done
sequentially. As k increases,wn,k −wn,k−1 → 0, which means that
yn,k converges to the value that the ne integrator would predict
if ne integration were simply done sequentially. Thus, each k de-
notes ne integration over the whole interval. This means that the
total computation performed is much greater than if ne integra-
tion were performed sequentially. However, the time eciency of
each iteration has the potential to be improved through concur-
rency. Since ne integration is more computationally intensive, this
improvement in the run-time eciency may compensate for the
cumulative computation performed.
Let K be the total number of iterations necessary to achieve a
desired accuracy of solution and P be the number of subintervals
into which we divide according to the coarse integrator. If K =
1, then we achieve perfect parallel eciency. If K = P , then we
likely slowed the computation down. The parareal algorithm is
guaranteed to converge to the solution given by the sequential
ne integrator within P iterations. For a more complete treatment
of this convergence analysis, we refer the reader to [2]. For fully
general pseudocode, we refer the reader to [1, 5].
3 IMPLEMENTATION IN JULIA
Listing 1 presents an implementation of the parareal algorithm
(from the prior section) in Julia. The @async macro within the loop
causes the program to evaluate the rst expression to its right as
a concurrent task (i.e., the for loop assigning values to sub). The
@sync macro causes the main program thread to wait until all tasks
(spawned in the the rst expression to its right with an @async or
@parallel macro) complete. Once all concurrent tasks are com-
plete, execution of the program proceeds sequentially. Given the
semantics of these macros, the program in Listing 1 correctly per-
form concurrent integration. The sequential and parallel versions
of this implementation have no signicant dierences in run-time
eciency. However, if a sleep statement is placed in the argument
of fineIntegrator, the parallel version runs much faster. This
demonstrates that use of those two macros does lead to concurrent
program execution.
4 GRAPHICAL ALGORITHM SIMULATION
The function simulate in Listing 2 creates a graphical simulator of
the parareal algorithm. This function can be used to introduce the
parareal algorithm to students in a numerical analysis course. The
rst line gets the sequential solution from the ne integrator (the
"ideal" solution) and the second line gets the history of the computa-
tions that took place during the parareal execution. The main loop
over the variable k then displays the inner workings of the algo-
rithm. The ideal solution is plotted, with a scatter plot of the points
obtained from the coarse integrator. To simulate the parallel nature
of the algorithm, random progress is made on randomly selected
subdomains. Thus the plot dynamically makes partial progress on
dierent subdomains until all subdomains are nished with the
ne integration. After this, the plots are connected into the current
iteration’s approximation. During the next iteration, the previous
guesses from the coarse integrator are displayed in red and the
new guesses from the coarse integrator are displayed in green. As
k increases, these guesses converge to the ideal solution.
In addition to the use of this function for pedagogical purposes, it
can be used to investigate the types of curves for which the parareal
algorithm might be practical. For instance, consider the dierential
equation
y′(x) = sin(xy), x ∈ [−20, 20]
with y(−20) = 10, ∆ = 4 (10 points), and δ = 0.008 (500 points).
Figure 2 shows the rst and ninth iterations respectively. The ninth
iteration’s large error on the right end of the interval shows that this
is an example where parareal convergence is slow. This is as ine-
cient as possible, needing as many iterations as subdomains in order
for the solution to converge. However, the simulation also shows
that if f (x ,y) = sin(x)ex , then the solution converges after just one
iteration. These two examples show that the algorithm’s eciency
can be highly dependent on the integrand. Below the simulation
function are Euler’s method and another Runge-Kutta integration
technique that can be used as examples to be passed as rst-class
functions as coarse or ne integration techniques to the ‘parareal’
or ‘simulate’ functions. A Git repository of both the implementa-
tion and graphical simulation is available at https://bitbucket.org/
sperugin/parareal-implementation-and-simulation-in-julia. Note
also that we use the Julia Plots package to generate the graphs,
available at https://juliaplots.github.io/.
REFERENCES
[1] E. Aubanel. 2011. Scheduling of tasks in the parareal algorithm. Parallel Comput.
37, 3 (2011), 172–182.
[2] M. J. Gander and S. Vandewalle. 2007. Analysis of the parareal time-parallel
time-integration method. SIAM Journal on Scientic Computing 29, 2 (2007),
556–578.
[3] J.-L. Lions, Y. Maday, and G. Turinici. 2001. A “parareal” in time discretization of
PDE’s. Comptes Rendus de l’Académie des Sciences - Series I - Mathematics 332
(2001), 661–668.
[4] J. Mot and B.A. Tate. 2014. Julia. In Seven more languages in seven weeks:
Languages that are shaping the future, B.A. Tate, F. Daoud, I. Dees, and J. Mot
(Eds.). Pragmatic Bookshelf, Dallas, TX, Chapter 5, 171–207.
[5] A.S. Nielsen. 2012. Feasibility study of the parareal algorithm. Master’s thesis.
Technical University of Denmark.
Parareal Algorithm Implementation and Simulation in Julia
Listing 1: Implementation of the parareal algorithm in Julia
@everywhere f u n c t i o n p a r a r e a l ( a , b , nC , nF , K , y0 , f , c o a r s e I n t e g r a t o r , f i n e I n t e g r a t o r )
# i n i t i a l i z e c o a r s e i n f o r m a t i o n
xC = l i n s p a c e ( a , b , nC + 1 ) ;
yC = z e r o s ( s i z e ( xC , 1 ) , K ) ;
d e l t a C = ( b−a ) / ( nC + 1 ) ;
yC [ 1 , : ] = y0 ;
# " c o a r s e i n t e g r a t o r p a r t i a l l y e v a l u a t e d "
c i P E v a l e d = ( ( x1 , y1 ) −> c o a r s e I n t e g r a t o r ( de l t aC , x1 , y1 , f ) ) ;
# g e t i n i t i a l c o a r s e i n t e g r a t i o n s o l u t i o n
f o r i = 2 : ( nC+1 )
yC [ i , 1 ] = c i P E v a l e d ( xC [ i −1] , yC [ i − 1 , 1 ] ) ;
end
c o r r e c t C = copy ( yC ) ;
# i n i t i a l i z e f i n e i n f o r m a t i o n
xF = z e r o s ( nC , nF + 1 ) ;
f o r i = 1 : nC
xF [ i , : ] = l i n s p a c e ( xC [ i ] , xC [ i + 1 ] , nF + 1 ) ;
end
sub = z e r o s ( nC , nF +1 ,K ) ;
d e l t a F = xF [ 1 , 2 ] − xF [ 1 , 1 ] ;
# " f i n e i n t e g r a t o r p a r t i a l l y e v a l u a t e d "
f i P E v a l e d = ( ( x1 , y1 ) −> f i n e I n t e g r a t o r ( d e l t a F , x1 , y1 , f ) ) ;
f o r k = 2 :K
# run f i n e i n t e g r a t i o n on each subdomain
t i c ( ) ;
@sync f o r i = 1 : nC
sub [ i , 1 , k ] = c o r r e c t C [ i , k−1 ] ;
@async f o r j = 2 : ( nF +1 )
sub [ i , j , k ] = f i P E v a l e d ( xF [ i , j −1] , sub [ i , j −1 , k ] ) ;
end
end
t o c ( ) ;
# p r e d i c t and c o r r e c t
f o r i = 1 : nC
yC [ i +1 , k ] = c i P E v a l e d ( xC [ i ] , c o r r e c t C [ i , k ] ) ;
c o r r e c t C [ i +1 , k ] = yC [ i +1 , k ] − yC [ i +1 , k−1] + sub [ i , nF +1 , k ] ;
end
end
yF = z e r o s ( nC ∗ ( nF + 1 ) , K− 1 ) ;
f o r k = 2 :K
yF [ : , k−1] = r e s h a p e ( sub [ : , : , k ] ' , nC ∗ ( nF + 1 ) ) ;
end
r e t u r n r e s h a p e ( xF ' , nC ∗ ( nF + 1 ) ) , r e s h a p e ( sub [ : , : , K ] ' , nC ∗ ( nF + 1 ) ) , yF , sub , xC , c o r r e c t C , yC ;
end
Figure 2: Slow parareal example. (left) Solution after rst iteration with Euler’s method. (right) Solution after ninth iteration
with Euler’s method.
T.M. Masthay & S. Perugini
Listing 2: Implementation of a graphical simulator of the parareal algorithm in Julia
@everywhere f u n c t i o n f u l l M e t h o d ( n , a , b , y0 , f , i n t e g r a t o r )
# s e t u p domain and range s p a c e
x = l i n s p a c e ( a , b , n + 1 ) ;
d e l t a X = x [ 2 ] − x [ 1 ] ;
y = ones ( n + 1 , 1 ) ;
# i n i t i a l i z e l e f t e n d p o i n t
y [ 1 ] = y0 ;
# i n t e g r a t e each p o i n t
f o r i = 1 : n
y [ i +1] = i n t e g r a t o r ( de l taX , x [ i ] , y [ i ] , f ) ;
end
r e t u r n x , y ;
end
f u n c t i o n s i m u l a t e ( a , b , N ,M, K , y0 , f , c o a r s e I n t , f i n e I n t , showPrev )
x1 , y1 = f u l l M e t h o d (N ∗ (M+ 1 ) , a , b , y0 , f , f i n e I n t ) ;
x , y , yF , sub , xC , yC , iC = p a r a r e a l ( a , b , N ,M, K , y0 , f , c o a r s e I n t , f i n e I n t ) ;
xF = ( r e s h a p e ( x ,M+1 ,N ) ) ' ;
f i n e = M+ 1 ;
f o r k = 2 :K
d i s p l a y ( p l o t ( x1 , y1 ) ) ;
i f ( showPrev && k > 2 )
d i s p l a y ( s c a t t e r ! ( xC , yC [ : , k−2] , c o l o r =" red " , l e g e n d = f a l s e ) ) ;
end
d i s p l a y ( s c a t t e r ! ( xC , yC [ : , k−1] , c o l o r =" green " , l e g e n d = f a l s e ) ) ;
done = z e r o s ( I n t 6 4 , N , 1 ) ;
workingSubdomains = 1 :N ;
whi l e ( done != (M+1) ∗ ones (N , 1 ) )
index = I n t 6 4 ( c e i l ( s i z e ( workingSubdomains , 1 ) ∗ rand ( ) ) ) ;
cu r r Th re ad = workingSubdomains [ index ] ;
wh i l e ( done [ c ur rT hr ead ] == M+1 )
cu r r Th re ad = I n t 6 4 ( c e i l (N ∗ rand ( ) ) ) ;
end
c u r r T h r e a d P l o t = I n t 6 4 ( c e i l ( f i n e ∗ rand ( ) ) ) ;
t o t a l A d v a n c e = done [ c ur rT hr ead ] + c u r r T h r e a d P l o t ;
i f ( t o t a l A d v a n c e > f i n e ) t o t a l A d v a n c e = f i n e ; end
newP = ( done [ cu r r Th re ad ] + 1 ) : t o t a l A d v a n c e ;
d i s p l a y ( p l o t ! ( xF [ currThread , newP ] , sub [ currThread , newP , k ] , c o l o r =" b l a c k " ) ) ;
done [ c ur rT hr ead ] = t o t a l A d v a n c e ;
workingSubdomains = f i n d ( ( ( x )−>x != M+ 1 ) , done ) ;
p r i n t ( j o i n ( [ " Working on subdomain # " , currThread , " . . . " ,
" Pending Subdomains : " , workingSubdomains ' , " \ n " ] ) ) ;
end
d i s p l a y ( p l o t ! ( x , yF [ : , k−1] , c o l o r =" orange " ) ) ;
s l e e p ( 5 ) ;
end
end
f u n c t i o n e u l e r ( d e l t a , x0 , y0 , f )
r e t u r n y0 + d e l t a ∗ f ( x0 , y0 ) ;
end
f u n c t i o n rungeKut ta ( d e l t a , x0 , y0 , f )
k1 = f ( x0 , y0 ) ;
k2 = f ( x0+ d e l t a / 2 , y0 + ( d e l t a / 2 ) ∗ k1 ) ;
k3 = f ( x0+ d e l t a / 2 , y0 + ( d e l t a / 2 ) ∗ k2 ) ;
k4 = f ( x0+ d e l t a , y0+ d e l t a ∗ k3 ) ;
r e t u r n y0 + ( d e l t a / 6 ) ∗ ( k1 +2 ∗ k2 +2 ∗ k3+k4 ) ;
end

