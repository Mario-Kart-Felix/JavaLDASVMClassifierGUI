Learning Knowledge Graph Embeddings with Type Regularizer
Bhushan Kotnis
Dept. of Computational Linguistics,
Heidelberg University
Heidelberg, Germany
kotnis@cl.uni-heidelberg.de
Vivi Nastase
Dept. of Computational Linguistics,
Heidelberg University
Heidelberg, Germany
Abstract
Learning relations based on evidence from
knowledge bases relies on processing
the available relation instances. Many
relations, however, have clear domain
and range, which we hypothesize could
help learn a better, more generalizing,
model. We include such information in
the RESCAL model in the form of a reg-
ularization factor added to the loss func-
tion that takes into account the types (cat-
egories) of the entities that appear as argu-
ments to relations in the knowledge base.
We note increased performance compared
to the baseline model in terms of mean
reciprocal rank and hits@N, N = 1, 3,
10. Furthermore, we discover scenarios
that significantly impact the effectiveness
of the type regularizer.
1 Introduction
Knowledge Graphs (KGs), like Freebase (Bol-
lacker et al., 2008) and NELL (Carlson et al.,
2010) capture structured information in the form
of entities linked through semantic relations, and
have been proven useful for tasks such as reason-
ing and question answering (Miller et al., 2016).
KGs are known to be incomplete (Min et al.,
2013), i.e., a significant number of relations be-
tween entities are missing. Embedding the knowl-
edge graph in a continuous vector space has been
successfully used to address this problem (Nickel
et al., 2011, 2012; Bordes et al., 2013; Socher
et al., 2013). Such models represent the com-
ponents of the graph, i.e., the entities and rela-
tions, using real valued latent factors that capture
the structure of the knowledge graph. Examples
include the RESCAL (Nickel et al., 2012) ten-
sor factorization model, the TransE model (Bor-
des et al., 2013) and their variations (Lin et al.,
2015; Dong et al., 2014; Nickel et al., 2016). We
focus on the RESCAL model, the most flexible
and best performing of these, which is a bilinear
model that represents triples as a pairwise interac-
tion of source and target entity latent factors (em-
beddings) through a matrix that represents the la-
tent factors of the connecting relation. The entity
and relation representations induced can be used
to predict additional relations – edges – between
the known entities.
Approaches such as RESCAL take an exten-
sional view of relations – they process the col-
lection of instances without knowledge of higher
level rules or information about these relations.
We hypothesize that providing such information
in the form of types or categories of their argu-
ments, can lead to improved results for the task
of link prediction. This may be true particularly
for knowledge graphs such as FreeBase that have
strongly typed relations. Table 1 lists a few exam-
ples of entity type information in FreeBase.
In this article we present experimental results
supporting the hypothesis that augmenting single-
relation models with entity type information, in
the form of a ‘Type’ regularizer, leads to improve-
ments in predicting missing links. We also analyze
the effects of training data size on the usefulness of
the type regularizer, and note that its impact grows
with the amount of training data.
2 Related Work
A variety of latent factor models (Nickel et al.,
2012; Bordes et al., 2013; Socher et al., 2013;
Riedel et al., 2013) have been developed to rep-
resent entities and relations in a knowledge graph,
and have been used to address the knowledge base
completion problem. Most latent factor models
ar
X
iv
:1
70
6.
09
27
8v
1 
 [
cs
.A
I]
  2
8 
Ju
n 
20
17
Source Type Source Path or Relation Target Target Type
film star wars episode IV produced by george lucas film producer
person alexandre dumas people profession writer profession
academic post professor profession people albert einstein award winner
Table 1: Entity Type Information: Examples of source and target entity types from Freebase used in
the type regularizer.
are trained on either knowledge graph triples, or
triples extracted from open domain knowledge ex-
traction tools (Riedel et al., 2013). A notable ex-
ception is the RNN model proposed by (Neelakan-
tan et al., 2015) that learns path embeddings for
knowledge base completion. (Guu et al., 2015)
propose a compositional objective function, for
composable latent factor models, which is trained
on paths as well as triples. For models that are
composable, (Toutanova et al., 2016) shows that
incorporating intermediate entity information, in
the form of latent factors, improves KBC perfor-
mance. However, unlike this article, they do not
explicitly model source and target entity types.
(Chang et al., 2014) incorporate type information
in the RESCAL model by limiting the entity ma-
trix to entities belonging to the domain and range
of the relation. A recent study by (Das et al.,
2016) which builds on (Neelakantan et al., 2015),
uses an RNN to model paths incorporating type
information of intermediate and terminal entities.
Their results suggest that explicitly modeling en-
tity types improves RNN performance.
3 Methods
3.1 Definitions
Let E ,R be the set of entities and relations in the
KG respectively. A knowledge graph G is a set of
triples (s, r, t) where s, t ∈ E , r ∈ R and relation
r connects s to t.
The knowledge base completion (KBC) task is
the task of classifying whether the triple (s, r, t) is
a part of the knowledge graph. This can be inter-
preted in various ways, depending on the task: (i)
as (s, ?, t) if the aim is to add edges between ex-
isting nodes in the KG, (ii) as (s, r, ?) where the
question mark represents the unknown correct tar-
get entity from a set of candidate entities, when the
starting point and relation type are known.
3.2 RESCAL Model
The RESCAL model (Nickel et al., 2011, 2012)
weights the interaction of all pairwise latent fac-
tor between the source and target entity for pre-
dicting a relation. It represents every entity as
a vector (x ∈ Rd), and every relation as a ma-
trix W ∈ Rd×d. This model represents the triple
(s, r, t) as a score given by
sc(s, r, t) = x
T
s Wr xt
This is equivalent to tensor factorization where
each relation matrix is a slice of the tensor. These
vectors and matrices are learned by constructing
a loss function that contrasts the score of a cor-
rect triple to incorrect ones. Here we use the max-
margin loss described in the following equation:
J(Θ) =
N∑
i
∑
t′∈N(t)
mm(σ(sci), σ(s
′
ci)) (1)
mm(σ(sci), σ(s
′
ci)) = max
[
0, 1− σ(sci) + σ(s′ci)
]
where sci = sc(si, ri, ti) and s
′
ci = sc(si, ri, t
′
i).
N(t) is the set of incorrect targets and σ is the
sigmoid function.
3.3 Type Regularizer
We introduce a regularizer term which incorpo-
rates type information of source and target entities.
Let scat be the type for entity s and rcat the rela-
tion between s and scat. Depending on the knowl-
edge resource, rcat could be is a (in an ontology,
for example), category (in a resource built based
on Wikipedia), or other such relations that capture
the entity type. A few examples of entity types can
be seen in Table 1. Note that entity type informa-
tion is not used during test time.
If s is the source entity and t the target entity
for query q, then we define the regularizer as in
equation 2, where N(scat) and N(tcat) are sets
of (negatives) for scat, tcat, while T (scat), T (tcat)
are sets of correct categories for source s and
target t respectively. mm is the max margin loss
described in equation (1).
R(Θ, q) :=
∑
s
′
cat∈N(scat)
scat∈T (scat)
mm
(
σsc(s, rcat, scat), σsc(s, rcat, s
′
cat)
)
+
∑
t
′
cat∈N(tcat)
tcat∈T (tcat)
mm
(
σsc(t, rcat, tcat), σsc(t, rcat, t
′
cat)
)
(2)
The complete objective function to be mini-
mized is
J(Θ) =
N∑
i=1
∑
t
′
i∈T (qi)
mm(qi, ti, t
′
i) + αR(Θ, qi)
where the hyper-parameter α, α ≥ 0, controls
the impact of the regularizer terms and T (qi) is
the set of negative targets for query qi, where qi
corresponds to query (si, ri, ?).
4 Experiments
4.1 Data
We carry out experiments on FB15K, a subset of
the Freebase knowledge graph provided by (Bor-
des et al., 2013). The FB15K dataset consists of
1345 relations and 14,951 entities. The training,
validation and test set consists of 483,142, 50,000
and 59,071 triples respectively. The Freebase re-
lations do not include the category relation, thus
there is no overlap between the category triples
and FB15K triples.
As entity type information we obtain Freebase
category data from (Gardner and Mitchell, 2015),
and then the entity type by mapping the Freebase
entity identifier to the Freebase category. This re-
sults in 101,353 instances of the category relation
which is used in the training stage to provide the
entity types for the regularization factor. It is not
used in the test stage.
4.2 Implementation
We implemented the bilinear model using Theano
(Bastien et al., 2012). We use the Adam (Kingma
and Ba, 2014) SGD optimizer for training because
it addresses the problem of decreasing learning
rate in AdaGrad. We use median gradient clipping
to prevent explosive gradients and we also ensure
that entity embeddings have unit norm. We per-
formed exhaustive grid search for the L2 regular-
izer as well as type regularizer coefficient alpha
on the validation set and we tuned the training du-
ration using early stopping. We use 100 dimen-
sional entity vector in all experiments. We plan to
make the code publicly available upon publication
of this manuscript.
4.3 Evaluation Procedure
For evaluating the models we follow the procedure
described in (Socher et al., 2013). For every test
triple we predict either the source or the target,
and negative instaces for training and testing are
produced by corrupting positive ones: we replace
s (or t) in a (s, r, t) triple with an sn (or tn) that
has the same type as s (or t) but does not appear
in a positive instance (sn, r, t) (or (s, r, tn)). For
meaningful comparison, the negative triples that
occur in training, validation or test datasets as pos-
itive triples are filtered out. This is done to ensure
that correct predictions are not marked as incor-
rect. For faster evaluation, instead of using all
entities as negatives, we randomly sampled 1000
entities from the entire set. We report results in
terms of hits at 1,3,10 (HITS@1,3,10) and mean
reciprocal rank (MRR) metrics. Hits at K is the
proportion of correct answers (hits) in the first K
ranked predictions, while MRR is the mean of the
reciprocal of the rank of the correct answers.
4.4 Results
Metrics Bilinear Bilinear + TR
MRR 0.343 0.3862
HITS@1 0.2451 0.304
HITS@3 0.3804 0.4161
HITS@10 0.5312 0.5408
Table 2: Evaluation: Performance Comparison be-
tween bilinear model with and without type regu-
larizer.
We use the bilinear (RESCAL) model as a base-
line. As evidenced by the results in Table 2, adding
the type regularizer improves performance. This
suggests that explicitly adding the type informa-
tion helps the model learn domain and range of
the relations which prove useful for the KBC task.
It may be tempting to think that the performance
improvement is natural since we are providing ad-
ditional information through the type regularizer.
We further test the impact of the type regularizer
by analyzing its performance on different sizes of
training data. We first generate multiple train-
ing datasets by randomly sampling 25%, 50% and
75% of the triples. As illustrated in Table 3, when
using only 25% to 50% of the training data, the
performance drops. Thus, simply augmenting the
Percentage of training data Model MRR Percentage Improvement
100
Bilinear 0.343
Bilinear + TR 0.3862 +12.59
75
Bilinear 0.3495
Bilinear+ TR 0.3552 +1.6
50
Bilinear 0.3457
Bilinear + TR 0.3409 -1.3
25
Bilinear 0.332
Bilinear + TR 0.3198 -3.67
Table 3: Effect of training data size on TR: Performance comparison between bilinear models with and
without type regularizer for different dataset sizes.
model with additional information may not always
improve performance.
The reason behind the performance drop with
less training data is not obvious, because adding
external information should help the model learn
better embeddings. We hypothesize that the drop
in performance is due to the fact that when fewer
number of training instances are available, the type
regularizer leads the system to learn relations that
over-generalize – the model will place equal or
more emphasis on learning categories for reduc-
ing training loss. This possibly results in embed-
dings that are biased towards predicting relations
at the level of categories and not individual rela-
tions resulting in performance drop for the relation
prediction task. We investigate this hypothesis by
varying the value of α that weighs the importance
of the type regularizer (cf. equation 1). We plot
the Mean Reciprocal Rank vs. the strength of the
type regularizer for model trained on only 25% of
the training data in Fig. 1. The higher the strength
of the type regularizer, the higher the cost incurred
for mis-predicting the category. As Fig. 1 shows,
MRR falls sharply with increase in α. This ef-
fect is not observed in the 100% training data sce-
nario. This suggests that adding category informa-
tion may lead to improved performance only under
certain conditions, namely when the added infor-
mation does not severely bias or overwhelm the
training data.
We note that equation (2) has the same max
margin structure as the loss function, equation (1).
Therefore using this particular formula for the type
regularizer is equivalent to adding the category re-
lation as an additional slice of the tensor factorized
by RESCAL, then the hyperparameter α is 1. Ex-
periments have shown though that fine tuning α –
and this fine-tuning the usage of type information
Figure 1: MRR vs. α: MRR drops with in-
creasing strength of the type regularizer for mod-
els trained on 25% (blue) and 100% (orange) of
FB15K dataset.
– can lead to better results.
5 Conclusion
We proposed a type regularizer that leverages en-
tity type information for state-of-the-art latent fac-
tor models like RESCAL. Experiments on Free-
base FB15K dataset suggest that adding the type
regularizer improves performance on the knowl-
edge base completion task. However adding cate-
gory information may not work on all datasets es-
pecially those where training triples are roughly
equivalent the number of category triples. In such
a scenario the category triples bias the learned em-
beddings to predict categories rather than relations
encountered in training data resulting in a perfor-
mance drop. We plan to study the impact of the
added type information for datasets where the re-
lations are not as strongly typed as FreeBase –
for grammatical collocation information for exam-
ple and inducing selectional preferences – and for
more complex, path prediction, tasks.
References
Frédéric Bastien, Pascal Lamblin, Razvan Pascanu,
James Bergstra, Ian Goodfellow, Arnaud Bergeron,
Nicolas Bouchard, David Warde-Farley, and Yoshua
Bengio. 2012. Theano: new features and speed im-
provements. arXiv preprint arXiv:1211.5590 .
Kurt Bollacker, Colin Evans, Praveen Paritosh,
Tim Sturge, and Jamie Taylor. 2008. Free-
base: A collaboratively created graph database
for structuring human knowledge. In Proceed-
ings of the 2008 ACM SIGMOD International
Conference on Management of Data. ACM, New
York, NY, USA, SIGMOD ’08, pages 1247–1250.
https://doi.org/10.1145/1376616.1376746.
Antoine Bordes, Nicolas Usunier, Alberto Garcia-
Duran, Jason Weston, and Oksana Yakhnenko.
2013. Translating embeddings for modeling multi-
relational data. In C. J. C. Burges, L. Bottou,
M. Welling, Z. Ghahramani, and K. Q. Weinberger,
editors, Advances in Neural Information Processing
Systems 26, Curran Associates, Inc., pages 2787–
2795. http://papers.nips.cc/paper/5071-translating-
embeddings-for-modeling-multi-relational-data.pdf.
Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr
Settles, Estevam R. Hruschka, and Tom M. Mitchell.
2010. Toward an architecture for never-ending lan-
guage learning. In AAAI.
Kai-Wei Chang, Wen-tau Yih, Bishan Yang, and
Christopher Meek. 2014. Typed tensor de-
composition of knowledge bases for relation
extraction. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP). Association for
Computational Linguistics, pages 1568–1579.
https://doi.org/10.3115/v1/D14-1165.
Rajarshi Das, Arvind Neelakantan, David Belanger,
and Andrew McCallum. 2016. Chains of reasoning
over entities, relations, and text using recurrent neu-
ral networks. arXiv preprint arXiv:1607.01426 .
Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko
Horn, Ni Lao, Kevin Murphy, Thomas Strohmann,
Shaohua Sun, and Wei Zhang. 2014. Knowledge
vault: a web-scale approach to probabilistic knowl-
edge fusion. In KDD.
Matt Gardner and Tom Mitchell. 2015. Efficient
and expressive knowledge base completion us-
ing subgraph feature extraction. In Proceed-
ings of the 2015 Conference on Empirical Meth-
ods in Natural Language Processing. Association
for Computational Linguistics, pages 1488–1498.
https://doi.org/10.18653/v1/D15-1173.
Kelvin Guu, John Miller, and Percy Liang. 2015.
Traversing knowledge graphs in vector space. In
Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing. Associa-
tion for Computational Linguistics, pages 318–327.
https://doi.org/10.18653/v1/D15-1038.
Diederik Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980 .
Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang
Liu, and Xuan Zhu. 2015. Learning entity
and relation embeddings for knowledge graph
completion. In Proceedings of the Twenty-
Ninth AAAI Conference on Artificial Intelli-
gence. AAAI Press, AAAI’15, pages 2181–2187.
http://dl.acm.org/citation.cfm?id=2886521.2886624.
Alexander Miller, Adam Fisch, Jesse Dodge, Amir-
Hossein Karimi, Antoine Bordes, and Jason We-
ston. 2016. Key-value memory networks for
directly reading documents. In Proceedings
of the 2016 Conference on Empirical Meth-
ods in Natural Language Processing. Association
for Computational Linguistics, pages 1400–1409.
http://aclweb.org/anthology/D16-1147.
Bonan Min, Ralph Grishman, Li Wan, Chang
Wang, and David Gondek. 2013. Distant su-
pervision for relation extraction with an incom-
plete knowledge base. In Proceedings of the
2013 Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics: Human Language Technologies. Associa-
tion for Computational Linguistics, pages 777–782.
http://aclweb.org/anthology/N13-1095.
Arvind Neelakantan, Benjamin Roth, and Andrew Mc-
Callum. 2015. Compositional vector space mod-
els for knowledge base completion. In Proceed-
ings of the 53rd Annual Meeting of the Associa-
tion for Computational Linguistics and the 7th In-
ternational Joint Conference on Natural Language
Processing (Volume 1: Long Papers). Associa-
tion for Computational Linguistics, pages 156–166.
https://doi.org/10.3115/v1/P15-1016.
Maximilian Nickel, Lorenzo Rosasco, and Tomaso
Poggio. 2016. Holographic embeddings of
knowledge graphs. In Proceedings of the
Thirtieth AAAI Conference on Artificial Intelli-
gence. AAAI Press, AAAI’16, pages 1955–1961.
http://dl.acm.org/citation.cfm?id=3016100.3016172.
Maximilian Nickel, Volker Tresp, and Hans-Peter
Kriegel. 2011. A three-way model for collective
learning on multi-relational data. In ICML.
Maximilian Nickel, Volker Tresp, and Hans-Peter
Kriegel. 2012. Factorizing yago: Scalable machine
learning for linked data. In Proceedings of the
21st International Conference on World Wide Web.
ACM, New York, NY, USA, WWW ’12, pages 271–
280. https://doi.org/10.1145/2187836.2187874.
Sebastian Riedel, Limin Yao, Andrew McCallum, and
M. Benjamin Marlin. 2013. Relation extraction with
matrix factorization and universal schemas. In Pro-
ceedings of the 2013 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies. Asso-
ciation for Computational Linguistics, pages 74–84.
http://aclweb.org/anthology/N13-1008.
Richard Socher, Danqi Chen, Christopher D Manning,
and Andrew Ng. 2013. Reasoning with neural
tensor networks for knowledge base comple-
tion. In C. J. C. Burges, L. Bottou, M. Welling,
Z. Ghahramani, and K. Q. Weinberger, editors,
Advances in Neural Information Processing Sys-
tems 26, Curran Associates, Inc., pages 926–934.
http://papers.nips.cc/paper/5028-reasoning-with-
neural-tensor-networks-for-knowledge-base-
completion.pdf.
Kristina Toutanova, Victoria Lin, Wen-tau Yih, Hoi-
fung Poon, and Chris Quirk. 2016. Compositional
learning of embeddings for relation paths in knowl-
edge base and text. In Proceedings of the 54th An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers). Association
for Computational Linguistics, pages 1434–1444.
https://doi.org/10.18653/v1/P16-1136.

