IEEE TRANSACTIONS ON SIGNAL PROCESSING. VOL. 41. NO. 12, DECEMBER 1993 3397
Matching Pursuits With Time-Frequency Dictionaries
Stephane G. Mallat, Member, IEEE, and Zhifeng Zhang
Abstract-We introduce an algorithm, called matching pur-
suit, that decomposes any signal into a linear expansion of
waveforms that are selected from a redundant dictionary of
functions. These waveforms are chosen in order to best match
the signal structures. Matching pursuits are general proce-
dures to compute adaptive signal representations. With a
dictionary of Gabor functions a matching pursuit defines an
adaptive time-frequency transform. We derive a signal energy
distribution in the time-frequency plane, which does not in-
clude interference terms, unlike Wigner and Cohen class dis-
tributions. A matching pursuit isolates the signal structures that
are coherent with respect to a given dictionary. An application
to pattern extraction from noisy signals is described. We com-
pare a matching pursuit decomposition with a signal expansion
over an optimized wavepacket orthonormal basis, selected with
the algorithm of Coifman and Wickerhauser.
I. INTRODUCTION
WE can express a wide range of ideas and at the sametime easily communicate subtle difference between
close concepts, because natural languages have large vo-
cabularies, that include words with close meanings. For
information processing, low level signal representations
must also provide explicit information on very different
properties, while giving simple cues to differentiate close
patterns. The numerical parameters should offer compact
characterizations of the elements we are looking for. The
wide scope of patterns embedded in complex signals and
the precision of their characterization, also motivate de-
compositions over large and redundant dictionaries of
waveforms. Linear expansions in a single basis, whether
it is a Fourier, wavelet, or any other basis, are not flexible
enough. A Fourier basis provided a poor representation
of functions well localized in time, and wavelet bases are
not well adapted to represent functions whose Fourier
transforms have a narrow high frequency support. In both
cases, it is difficult to detect and identify the signal pat-
terns from their expansion coefficients, because the infor-
mation is diluted across the whole basis. Similar examples
can be found for any type of basis. Such decompositions
are similar to a text written with a small vocabulary. Al-
though this vocabulary might be sufficient to express all
Manuscript received August 28, 1992; revised May 5, 1993. The Guest
Editor coordinating the review of this paper and approving it for publica-
tion was Dr. Ahmed Tewfik. This work was supported in part by the Air
Force Office of Scientific Research under Grant F49620-1-0102, in part by
the Office of Naval Research under Grant NOOOI4-91-J-1967, and in part
by the Alfred Sloan Foundation.
The authors are with Department of Computer Science, Courant Institute
of Mathematical Sciences, New York University. New York, NY 10012.
IEEE Log Number 9212192.
ideas, it requires to use circumvolutions that replace un-
available words by full sentences.
Flexible decompositions are particularly important for
representing signal components whose localizations in
time and frequency vary widely. The signal must be ex-
panded into waveforms whose time-frequency properties
are adapted to its local structures. Such waveforms are
called time-frequency atoms. For example, impulses need
to be decomposed over functions well concentrated in
time, while spectral lines are better represented by wave-
forms which have a narrow frequency support. When the
signal includes both of these elements, the time-frequency
atoms must be adapted accordingly. One must therefore
introduce a procedure that chooses the waveforms that are
best adapted to decompose the signal structures, among
all the time-frequency atoms of a large dictionary. Section
II briefly reviews the properties of time-frequency atoms
and their relations to window Fourier transforms and
wavelet transforms.
We introduce an algorithm called matching pursuit, that
decomposes any signal into a linear expansion of wave-
forms that belong to a redundant dictionary of functions.
These waveforms are selected in order to best match the
signal structures. Although a matching pursuit is nonlin-
ear, like an orthogonal expansion, it maintains an energy
conservation which guaranties its convergence. It is
closely related to projection pursuit strategies, developed
by Friedman and Stuetzle [7] for statistical parameter es-
timation. The general algorithm in the Hilbert space
framework is explained in Section III and the finite di-
mensional case is further studied in Section IV.
The application of matching pursuits to adaptive time-
frequency decomposition is described in Section V. The
signal is decomposed into waveforms selected among a
dictionary of time-frequency atoms, that are the dilations,
translations, and modulations of a single window func-
tion. We derive a time-frequency energy distribution, by
adding the Wigner distribution of the selected time-fre-
quency atoms. Contrarily to the Wigner distribution or
Cohen's class distributions, this energy distribution does
not include interference terms and thus provides a clear
picture in the time-frequency plane. Qian and Chen [14]
have developed independently a similar algorithm to ex-
pand signals over time-frequency atoms. A fast imple-
mentation of the matching pursuit for dictionary of Gabor
time-frequency atoms is described in Section VI, with nu-
merical examples.
A matching pursuit decomposition provides an inter-
pretation of the signal structures. If a structure does not
IOS3-S87X/93$03.00 © 1993 IEEE
3398 IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 41, NO, 12, DECEMBER 1993
where g (t) is the complex conjugate of g (t), The Fourier
transform off(t) E L 2 (R) is writtenJ(w) and defined by
Notations
The space L 2 (R) is the Hilbert space of complex valued
functions such that
correlate well with any particular dictionary element, it is
subdecomposed into several elements and its information
is diluted, Section VII formally defines coherent signal
structures with respect to a given dictionary, and explains
how to detect them, An application to the extraction of
patterns from noisy signals is described,
A matching pursuit is a greedy algorithm that chooses
at each iteration a waveform that is best adapted to ap-
proximate part of the signal. Section VIII compares this
locally adaptive method to the algorithm of Coifman and
Wickerhauser [4], which selects the basis that is best
adapted to the global signal properties, among all bases
of a wavepacket family, Numerical results show that the
global optimization does not perform well for highly non-
stationary signals, as opposed the greedy approach of a
matching pursuit. On the other hand, the best basis al-
gorithm is efficient to represent simpler signals that have
stationary properties,
II. TIME-FREQUENCY ATOMIC DECOMPOSITIONS
Decompositions of signals over family of functions that
are well localized both in time and frequency have found
many applications in signal processing and harmonic
analysis. Such functions are called time-frequency atoms.
Depending upon the choice of time-frequency atoms, the
decomposition might have very different properties. Win-
dow Fourier transforms and wavelet transforms are ex-
amples of time-frequency signal decomposition that have
been studied thoroughly [2], [5], [13], [15]. To extract
informations from complex signals, it is often necessary
to adapt the time-frequency decomposition to the partic-
ular signal structures. This section discusses the adaptiv-
ity requirements.
A general family of time-frequency atoms can be gen-
erated by scaling, translating and modulating a single
window function g(t) E L 2 (R). We suppose that get) is
real, continuously differentiable and 0(1 /(t2 + 1». We
also impose that II gil = I, that the integral of g (t) is non-
zero and that g (0) '* O. For any scale s > 0, frequency
modulating ~ and translation u, we denote 'Y = (s, u, 0
(6)
(4)
f(t) = ~ ang'Yu(t).
n = -00
+00
Depending upon the choice of the atoms g'YU (t), the ex-
pansion coefficients an give explicit information on cer-
tain types of properties of f(t). Window Fourier trans-
forms and wavelet transforms correspond to different
families of time-frequency atoms, that are frames or bases
ofL2(R).
In a window Fourier transform, all the atoms g'Yn have
a constant scale Sn = So and are thus mainly localized over
an interval whose size is proportional to so. If the main
signal structures are localized over a time-scale of the or-
der of so, the expansion coefficients an give important in-
sights on their localization and frequency content. How-
ever, a window Fourier transform is not well adapted to
describe structures that are much smaller or much larger
than so. To analyze components of varying sizes, it is nec-
essary to use time-frequency atoms of different scales.
In opposition to the window Fourier transform, the
wavelet transform decomposes signals over time-fre-
quency atoms of varying scales, called wavelets. A wave-
let family (g'Yn (t»nEN is built by relating the frequency pa-
rameter ~n to the scale Sn with ~n = ~o/Sn' where ~o is a
constant. The resulting family is composed of dilations
and translations of a single function, multiplied by com-
plex phase parameter. The expansion coefficients an of
functions over wavelet families characterize the scaling
behavior of signal structures. This is important for the
analysis of fractals and singular behaviors. However, ex-
pansion coefficients in a wavelet frame do not provide
precise estimates of the frequency content of waveforms
whose Fourier transforms is well localized, especially at
high frequencies. This is due to the restriction on the fre-
quency parameter ~n' that remains inversely proportional
to the scale Sn-
For signals f (t) that include scaling and highly oscil-
g'Y(t) = l g C~ u) ei~l.
The index 'Y is an element of the set r = R+ x R2 • The
factor I /.[; normalizes to 1 the norm of g'Y (t). If g (t) is
even, which is generally the case, g'Y (t) is centered at the
abscissa u. Its energy is mostly concentrated in a neigh-
borhood of u, whose size is proportional to s. Let g(w) be
the Fourier transform of g (t). Equation (4) yields
g'Y(w) = .[; g(s(w - ~»e-i(w-Ou. (5)
Since Ig (w) I is even, Ig'Y (w) I is centered at the frequency
w = ~. Its energy is concentrated in a neighborhood of ~,
whose size is proportional to 1/s.
The family 5) = (g'Y(t»'Y E[ is extremely redundant, and
its properties have been studied by Torresani [17]. To rep-
resent efficiently any function f (t), we must select an ap-
propriate countable subset of atoms (g'Yu(t»nEN, with 'Yn
= (SfP Un' ~n), so thatf(t) can be written
and define
(3)
(2)
(I)
\+00
J(w) = Loo f(t)e- iw1 dt,
\+00
(f, g) = Loo f(t)g(t) dt
Ilfll = i~: If(tW dt < +00,
The inner product of (j, g) E L2(R)2 is defined by
MALLAT AND ZHANG: MATCHING PURSUITS WITH TIME-FREQUENCY DICTIONARIES 3399
latory structures, one can not define a priori the appropri-
ate constraints on the scale and modulation parameters of
the time-frequency atoms gy" (t) used in the expansion (6).
We need to select adaptively the elements of the dictionary
~ = (gy(t))YEr, depending upon the local properties of
f(t).
III. MATCHING PURSUIT IN HILBERT SPACES
The general issue behind adaptive time-frequency de-
compositions is to find procedures to expand functions
over a set of waveforms, selected appropriately among a
large and redundant dictionary. We describe a general al-
gorithm, called matching pursuit, that performs such an
adaptive decomposition.
Let H be a Hilbert space. We define a dictionary as a
family ~ = (gy)yEf of vectors in H, such that II gyll = 1.
Let V be the closed linear span of the dictionary vectors.
Finite linear expansions of vectors in 1) are dense in the
space V. We say that the dictionary is complete if and
only if V = H. For the dictionary of time-frequency at-
oms described in Section II, H = L 2 (R), and each vector
gy is an atom defined by (4). Finite linear expansions of
time-frequency atoms are dense in L 2 (R) [17], hence this
dictionary is complete.
Letf E H. We want to compute a linear expansion off
over a set of vectors selected from 1), in order to best
match its inner structures. This is done by successive ap-
proximations offwith orthogonal projections on elements
of 1). Let gyO E 1). The vector f can be decomposed into
f = <f, g'Yo) g'Yo + Rf (7)
exists at least one choice function, but in practice there
are many ways to define it, and it depends upon the nu-
merical implementation.
Let us explain by induction, how the matching pursuit
is carried further. Let ROf = f. We suppose that we have
computed the nth order residue R n f, for n 2: O. We
choose, with the choice function C, an element gYn E 1)
which closely matches the residue R nf
I<Rnf, gyn) I 2: ex sup I<Rnf, gy) I· (11)
yEr
The residue R nf is subdecomposed into
Rnf = <Rnf, gyn) gYn + R n+ If (12)
which defines the residue at the order n + 1. Since R n + If
is orthogonal to g'Yn
IIR nfl1 2 = I<Rnf, gyn) 12 + IIR n+If11 2. (13)
Let us carry this decomposition up to the order m. We
decompose f into the concatenated sum
m-I
f= ~ (Rnf- R"+If) + Rmf. (14)
"=0
Equation (12) yields
m-I
f= n~o <R"f, gy,,)g'Y" + Rmf. (15)
Similarly, II f 11 2 decomposed in a concatenated sum
m-l
IIfl1 2 = ~ (11R nf11 2 - IIR n + 1fI1 2) + IIR mfI1 2. (16)
n=O
where Rf is the residual vector after approximating f in
the direction of gyo' Clearly g'Yo is orthogonal to Rf, hence
IIfl1 2 = I<f, gyo) 12 + IIRfI1 2. (8)
To minimize IIRf II, we must choose gyO E ~ such that
I<f, g'Yo ) I is maximum. In some cases, it is only possible
to find a vector g'Yo that is almost the best in the sense that
I <f, g'Yo) I 2: ex sup I <f, g'Y ) I (9)
yEr
where ex is an optimality factor that satisfies 0 < ex ::; 1.
A matching pursuit is an iterative algorithm that sub-
decomposes the residue Rf by projecting it on a vector of
~ that matches Rf almost at best, as it was done for f.
This procedure is repeated each time on the following res-
idue that is obtained. Before giving further details, let us
emphasize that the "choice" of a vector g'Yo that satisfies
(9) is not random. It is defined by a choice function C,
that associates to any subset A of r an index that belongs
to A. Let us define the set of vector indexes that satisfy
(9)
Ao = {(3 E r: ! <f, g(3) I 2: ex sup I<f, g'Y)!}' (10)
YEr
The choice of a vector gyO that satisfies (9) is equivalent
to the choice of the index 'Yo within Ao, formally defined
by 'Yo = C (Ao). The axiom of choice guaranties that there
Equation (13) yields an energy conservation equation
m-l
II fl1 2 = n~o I<Rnf, g'Y") 12 + IIR mfI1 2. (17)
The original vector f is decomposed into a sum of
dictionary elements, that are chosen to best match its res-
idues. Although this decomposition is nonlinear, we
maintain an energy conservation as if it was a linear or-
thogonal decomposition. A major issue is to understand
the behavior of the residue R mfwhen m increases. Let us
mention that the algorithm can be modified by selecting
several vectors from the dictionary at each iterations and
projecting the residue over the space generated by these
vectors [12], but we shall not further develop this ap-
proach here.
Functional approximations through such iterated or-
thogonal projections has previously been studied in statis-
tics by Friedman and Stuetzle [7], under the name of pro-
jection pursuit regressions. Our algorithm was developed
independently in a very different context, but the under-
lying mathematics are similar, so we adopted the same
vocabulary. The statistical problem is to estimate the con-
ditional expectation of a random variable Y with respect
to d random variables XI' X2 , ••• , Xd • To reduce the
dimensionality of the problem, a projection pursuit
regression decomposes the conditional expectation as a
3400 IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 41, NO. 12, DECEMBER 1993
(25)
(26)
m-I
Pv",Rmf = n~o x"g')'"
m-I
I; x" (g')'", g')'k)'
,,=0
m-I
(28)
Let us denote X = (xn)o";,, < m and Y = «R m f,
g')'k) )0,,; k < m' Let G = « g')'", g')'k ) )0,,; k < m,O,,; n< m be the
If the family of vectors (g')'")o,,;,, < m is not orthogonal,
which is generally the case, then Pv",Rmf '* O. The com-
putation of
m-I
is the orthogonal projection of f on the space Wm , which
is orthogonal complement of Vm in H. One can derive
from (23) that
II p wJI1 2 = II Pw",Rmfl12 = IIR mfl1 2 - II Pv",R mfI1 2.
(27)
is called a back-projection. Instead of storing the inner
products (Rnf, g')',,) in the structure book, we then store
(Rnf, g')',,) + Xn in order to recover Pv",f with (24). In
this case, the approximation error
verges in one iteration with g')'o = f / II f II and (f, g')'o) =
II f II. The index 'Yo characterizes f / II f II among all unit
vectors of H. If H has a finite dimension N, the unit sphere
is a surface of dimension N - 1, so 'Yo is characterized by
N - 1 scalars whereas (f, g')'o) is given by 1 scalar. In
this case, the index 'Yo carries much more information than
(f, g')'o ). In general, the balance of information between
indexes and inner products depends upon the size of the
dictionary .
After m iterations, a matching pursuit decomposes a
signal f into
The reduction of the approximation error thus depends
upon II pvmR mf II.
The calculation of the coefficients (xn)o,,; n < m requires
to solve the following linear system. For any gw 0 :s
k < m
If we stop the algorithm at this stage and only record the
partial structure book «R"f, g')',,), 'Yn)O,,;,,<m, the sum-
mation of (23) recovers an approximation of f, with an
error equal to Rnf. However, this sum is not a linear ex-
pansion of the vectors (g')',,)o,,; n < m that approximates fat
best. Let Vm be the space generated by (g')',,)o,,; n < m and
Pv", be the orthogonal projector on Vm . For any f E H,
Pv", f is the closest vector to f that can be written as linear
expansion of the m vectors (g')',,)o,,; n< m' We derive from
(23) that
(22)
(18)
(19)
(21 )
(20)
+00
+00
lim IIRmf - Pwfll = o.
m- +00
Hence,
and
The vector f is characterized by the double sequence
«Rnf, g')',,), 'Yn)nEN that we call structure book. Each 'Y"
indexes an element selected in the dictionary and
(R" f, g')',,) is the corresponding inner product. The order
of elements in a structure book is not important for the
reconstruction.
The smallest complete dictionaries are bases. If 1) is
an orthogonal basis, (R"f, g')',,) = (f, g')',,). The match-
ing pursuit decomposition is then equivalent to an orthog-
onal expansion in the basis 1). In this case, the indexes
'Y" carry no information. Indeed for almost all vectors f E
H, the inner product with elements of the basis are never
zero. Hence the sequence ('Y")"EN includes exactly once
each index of the basis vectors and is thus a permutation
of the index set r of 1). Since the order is unimportant
for the reconstruction, the sequence ('Y"),, EN carries no in-
formation. The largest possible dictionary ~ is the set of
all unit vectors in H. For this dictionary, we can set the
optimality factor ex to 1 and the matching pursuit con-
Theorem 1 proves that the matching pursuit recovers
the components offthat belongs to the space spanned by
the vectors of 1). The proof is in Appendix A. When the
dictionary is complete, which means that V = H, then
Pvf = fand Pwf = O. Hence,
+00
and
+00
sum of conditional expectations of successive residues of
Y, with respect to one-dimensional random variables that
are linear expansions of Xj, X2 , ••• , Xd • This decom-
position is obtained with a strategy similar to the match-
ing pursuit approach. Readers further interested by pro-
jections pursuits are referred to a tutorial review written
by Huber [10]. The mathematical similarities of the two
algorithms allow us to transpose a result of Jones [11] that
proves the convergence of projection pursuit algorithms.
Let us recall that V is the closed linear span of vectors in
~. We denote by W the orthogonal complement of V in
H. The orthogonal projectors over V and Ware respec-
tively written as Pv and Pw,
Theorem 1: LetfE H. The residue Rmfdefined by the
induction (12) satisfies
MALLAT AND ZHANG: MATCHING PURSUITS WITH TIME-FREQUENCY DICTIONARIES 3401
Gram matrix of the family of selected vectors. The linear
system of (28) can be written Y = GX. The matrix G is
nonnegative symmetric but might have some zero eigen-
values if the vectors (g-yJo,; n < m are linearly dependent.
It is often a sparse matrix without any particular structure.
Let p be the number of nonzero coefficient of G. The con-
jugate gradient algorithm, when initialized to Xo = 0, it-
eratively computes a sequence of vectors Xn that converge
to the vector X of minimum norm which satisfies Y = GX
[8]. Let K be the ratio between the largest eigenvalue of
G and the smallest nonzero eigenvalue. One can prove [8]
that
The main computational burden of each iteration is to ap-
ply G to some intermediate residual vector, which re-
quires O(p) operations. The conjugate gradient algorithm
thus requires O(np) operations to compute Xn- If no is the
rank of G, unless K - 1 is comparable to the computational
precision, this algorithm guaranties that X = Xno ' and
clearly no :;; m.
A matching pursuit is similar to a shape-gain vector
quantizer [16]. The codebook of a shape-gain quantizer is
composed of a family of K unit vectors which is equiva-
lent to a dictionary, and a sequence of scalars to quantize
inner product values. The quantization approximates any
vector jby projecting it on a vector g-yo' which correlates
best j among the K vectors of the codebook. The inner
product (j, g-yo> is quantized by approximating it to the
closest scalar stored in the codebook. Vector quantiza-
tions algorithms can be extended with a multistage strat-
egy [9]. After quantizing a given vector, the remaining
error is quantized once more, and the process continues
iteratively. A matching pursuit is similar to a multistage
shape-gain vector quantizer. However, a matching pursuit
does not quantize the inner products (Rnj, g-Yn >, as op-
posed to this vector quantizer. For information processing
applications, matching pursuits use very redundant dic-
tionaries of infinite size, whereas vector quantizers are
based on finite dictionaries that are best adapted to data
compression. Another major difference is that vector
quantizations are performed in spaces of low dimension,
generally smaller than 16. For example, image quantizers
are based on blocks of less than 4 by 4 pixels. On the
contrary, a matching pursuits is performed in a signal
space H whose dimension N is equal to the total number
of signal samples, which is typically several thousands.
The underlined mathematical and algorithmic issues are
thus quite different.
(
~ _ l)n
II X - Xn II :;; II X II ~ ~ + 1 (29)
suit algorithms and prove that the norm of the residues
decays exponentially.
When the dictionary is very redundant, the search for
the vectors that match best the signal residues can mostly
be limited to a subdictionary :Da = (g-Y)-YEr" C :D. We
suppose that r a is a finite index set included in r such
that for any j E H
sup I(j, g-y> I ~ ex sup I (j, g-y> I· (30)
-yEra -yEr
Depending upon ex and the dictionary redundancy, the set
r a can be much smaller than r. The matching pursuit
is initialized by computing the inner products
« j, g-y >)-YEf,,' and continues by induction as follows.
Suppose that we have already computed «R"j,
g-y >)-YEf,,' for n ~ 0. We search in :Da for an element
gYn such that
I (Rnj, g"in> I = sup I (Rnj, g-y> I. (31)
-yEra
To find a dictionary element that matches j even better
than g"in' we then search with a Newton method for an
index "in in a neighborhood of 'Yn in r where I (j, g-y> I
reaches a local maxima. Clearly
I (Rnj, g-yn> I ~ I (Rnj, g"in> I ~ ex sup I (Rnj, g-y> I·
-yEr
(32)
Let us observe that the choice function mentioned in Sec-
tion III is defined indirectly by this double search strat-
egy. Once the vector g-Y-n is selected, we compute the inner
product of the new residue Rn + Ijwith any g-y E :Da , with
an updating formula derived from (12)
(R n+ Ij, g-y> = (Rnj, g-y> - (Rnj, g-yn> (g-Yn' g-y >.
(33)
Since we previously stored (Rnj, g-y >and (Rnj, g-Yn >, this
update requires only to compute (g-Yn' g-y >. Dictionaries
are generally built so that this inner product is recovered
with a small number of operations. The number of times
we subdecompose the residues of a given signal j depends
upon the desired precision E. The number of iterations is
the minimum p such that
The energy conservation (17) proves that this equation is
equivalent to
p-I
II jll - I; I (Rnj, g-yn> 12 :;; E 2 11 jll. (35)
n=O
IV. MATCHING PURSUIT IN FINITE SPACES
When the signal space H has a finite dimension N, the
matching pursuit has specific properties that are studied
in this section. The dictionary :D may have an infinite
number of elements and we suppose that it is complete.
We describe an efficient implementation of matching pur-
Since we do not compute the residue R nj, at each iteration
we test the validity of (35) to stop the decomposition. The
number of iterations p depends upon the decay rate of
IIR n j II. It can vary widely depending upon the signals but
is much smaller than N is most applications. The energy
of the residual error can be decreased with the back-pro-
3402 IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 41, NO. 12, DECEMBER 1993
(36)
jection algorithm described in Section III. Many types of
dictionaries do not contain any subfamily of less than N
+ 1 vectors that are linearly dependent. In this case, once
the matching pursuit has selected N different vectors, these
vectors spans the whole signal space H. Hence, after back-
projection there is no more residual error and f is re-
covered as a linear expansion of the N selected vectors.
However, this basis of H might be badly conditioned
which slows down the convergence of the back-projection
algorithm.
The decay of IIR nf II depends upon the correlation be-
tween the residues and the dictionary elements. Let us
define the correlation ratio of a function f E H with respect
to :D as
"\ (f) = I(f, g1 ) I
1'\ ~~~ Ilfll
The following lemma guaranties that for any f E H, A(f)
is larger than a strictly positive constant.
Lemma 1: Let :D be a complete dictionary in a finite
dimensional space H,
order to well approximated. This means that the infor-
mation off is diluted across the dictionary. The extraction
of coherent signal structures is further studied in Section
VII.
V. MATCHING PURSUIT WITH TIME-FREQUENCY
DICTIONARIES
For dictionaries of time-frequency atoms, a matching
pursuit yields an adaptive time-frequency transform. It
decomposes any functionf(t) E L 2 (R) into a sum of com-
plex time-frequency atoms that best match its residues.
This section studies the properties of this particular
matching pursuit decomposition. We derive a new type of
time-frequency energy distribution by summing the Wig-
ner distribution of each time-frequency atom.
Since a time-frequency atom dictionary is complete,
Theorem 1 proves that a matching pursuit decomposes any
function f E L 2 (R) into
+00
(42)
I(A) = inf A(f) > O.
fEB
These atoms are chosen to best match the residues off.
The matching pursuit algorithm depends upon a choice
function that selects at each iteration a vector g-yn among
all vectors that satisfy (11). Appendix C proves that we
can define choice functions for which the matching pur-
suit is covariant by dilation, translation and modulation.
Let us denote (g-y::)nEN and (g-y})nEN' with 'Y~ = (s~, u~,
~~) and 'Y~ = (s~, u~, ~,~)' the family of time-frequency
atoms selected to decompose respectively fO (t) and f I (t).
Appendix C proves that there exists a class of choice
functions such that
if and only if for all n ~ 0
(43)
(45)
(44)
~~ = a(~~ - b)
o u~ - c
Un = ---
a
o s ~
Sn == -,
am-l
The proof of this lemma is in Appendix B. The value
of 1(A) is the cosine of the maximum possible angle be-
tween a direction of H and the closest direction of a
dictionary vector. If :D is an orthogonal basis, one can
prove that 1(A) = l/../N. The next lemma guaranties that
IIR nf II decays exponentially in a finite dimensional space,
with a rate proportional to a? 12 ( A).
Lemma 2: Letf E H. For any m > 0
IIRmfl1 $ Ilfllo - ciI2(A))m/2. (38)
Proof the matching pursuit chooses a vector g-Yn that
satisfies
I (Rnf, g-yn) I ~ a sup I (Rnf, g-y) 1= aA(Rnf)IIRnfll.
-yEf
(39)
Since IIR n + 1f11 2 = IIR nfl1 2 - I (Rnf, g-y,,> 12,
IIRn+1fll $ IIR nfll(1 - a 2A2(R nf))I/2 (40)
and hence, for any m > 0
IIRmfl1 $ Ilfll IT 0 - a 2A2(R nf))1/2
n=O and
o (41) (46)
The lower the correlation ratios of a particular signal f
and its residues, the slower the decay of their norm. If the
signal f is the sum of a few high energy components that
belong to the dictionary, the correlation ratios off and its
residues is high so their norm decrease quickly. These
high energy components can be viewed as "coherent
structures" with respect to the dictionary. If the residues
off have low-correlation ratios, their norm decay slowly
and f must be expanded over many dictionary vectors in
The translation, modulation, and dilation of a function
appears as simple modifications of the selected atom in-
dexes. The covariance through dilation, translation and
modulation is important to perform a signal analysis that
takes into account any of these transformations.
From the decomposition of any f(t) within a time-fre-
quency dictionary we derive a new time-frequency energy
distribution, by adding the Wigner distribution of each
selected atom. Let us recall that the cross Wigner distri-
MALLAT AND ZHANG: MATCHING PURSUITS WITH TIME-FREQUENCY DICTIONARIES 3403
(54)
bution of two functions f (t) and h (t) is defined by
W[j, h](t, w)
= ~ \+00 f(t + !.-) Ii (t _ !.-) e-iWT dT. (47)
27r J-oo 2 2
The Wigner distribution of f(t) is Wf(t, w) = W[j, f] (t,
w). Since the Wigner distribution is quadratic, we derive
from the atomic decomposition (42) off (t) that
butions rI ]. The importance of these marginal properties
for signal processing is however not clear.
When the signalf(t) is real, to get a decomposition with
real expansion coefficients, one must use dictionaries of
real time-frequency atoms. For any I' = (s, t u), with ~
*- 0, and any phase r/> E [0, 27f[, we define
K(-Y.1» (t - u)
g(-Y.1» = .[;; g -s- cos (~t + r/».
+00 +00
+00
(58)
£f(t, w) = ~ ~ I (R"f, g(-Y".1>n» 1 2
1l~0
( (
t - U ll )
. Wg -S-n-. Sn(W - ~n)
(
t - U ll ))+ Wg --, Sn(W - ~n) .
Sn
+00
This distribution also satisfies the energy density property
(53).
In signal processing applications of time-frequency
matching pursuits, we process directly the discrete param-
eters ("Yn, r/>n) = (Sn, ~n' U Il , r/>n) and (Rnf, g'¥n) of the
selected atoms, rather than the energy density £f (t, w).
Indeed, these parameters carry all the necessary infor-
mation and are much easier to manipulate than the two-
dimensional map £f (t, w). This energy distribution is
where 1'- = (s, -t u). However, one can show that the
real matching pursuit decomposition (55) is not equiva-
lent to the complex decomposition (42), because the two
vectors g'"r (t) and g'"r- (t) are not orthogonal.
The time-frequency energy distribution of a real func-
tion f (t) is derived from its matching pursuit decomposi-
tion, by summing the Wigner distribution of the under-
lined complex atoms
£f(t, w) = ~ I (R"f, g('"r".1>,,) 1 2
n=O
. ~ (Wg'"r,,(t, W) + Wg'"rn (t, w)). (57)
By inserting (50) in this expression, we obtain
+00
where the indexes ("Yn' r/>Il) = (SIl' U'" ~n, r/>n) are chosen
to best match the residues off. For any I' = (s, t u), real
atoms are related to complex atoms by
+00
The constant K('"r.1>J is adjusted so that II g(-Y.1» II = 1. The
phase r/> that was hidden in the complex numbers, now
appears explicitly as a parameter of the real atoms. The
dictionary of real time-frequency atoms is defined by
:D = (g(-Y.1»)Efx [0.27r[, with r = R+ x R2 . The matching
pursuit performed with this dictionary decomposes any
real signal f (t) into
(51)
(50)
(48)
c-U - 0)Wg'"r(t, w) = Wg -s-. sew
and hence,
+00
£f(t, w) ~ 1 (R"f, g'"r") 1
2
n=O
C- U - ~n)).. Wg __" ,Sn(W
Sn
£f(t, w) = ~ I (R"f, g'"rn) 12 Wg'"r,,(t, w). (49)
n=O
We can thus interpret £f (t, w) as an energy density of f
in the time-frequency plane (t, w). Unlike the Wigner and
the Cohen class distributions, it does not include cross
terms. It also remains positive if Wg(t, w) is positive,
which is the case when g (t) is Gaussian. On the other
hand, the energy density £f (t, w) does not satisfy mar-
ginal properties, as opposed to certain Cohen class distri-
The Wigner distribution also satisfies
r: r: Wg(t, w) dt dw = II g 11 2 (52)
The double sum corresponds to the cross terms of the
Wigner distribution. It regroups the terms that one usually
tries to remove in order to obtain a clear picture of the
energy distribution of f(t) in the time-frequency plane.
We thus only keep the first sum and define
+00
so the energy conservation (22) implies
r: r: £f(t, w) dt dw = II f11 2 • (53)
+ ~ ~ (R"f,g'"r")
n=O m=O.m*fl
A similar decomposition algorithm over time-frequency
atoms was derived independently by Qian and Chen [14],
in order to define this energy distribution in the time-fre-
quency plane. From the well known dilation and transla-
tion properties of the Wigner distribution and the expres-
sion (43) of a time-frequency atom, we derive that for I'
=(s,~,u)
3404 IEEE TRANSACTIONS ON SIGNAL PROCESSING. VOL 41. NO. 12. DECEMBER 1993
rather used for the visualization of the structure book in-
fonnation. If g (t) is the Gaussian window
get) = 21/4e-1Tt2 (59)
then
(60)
N. To this dictionary of atoms, we add the canonical basis
of discrete Diracs and the discrete Fourier basis of com-
plex exponentials. For l' = (1, p, 0), g-y(n) is a discrete
Dirac centered at p. For l' = (N, 0, k), g-y(n) =
1/JNei (21Tk/N)/I.
Similarly to (56), for any l' = (s, p, 271"k/N) and cf> E
[0, 271"[, real discrete time-frequency atoms are given by
Appendix D gives a proof of this theorem. The fast nu-
merical implementation of a matching pursuit in a Gabor
dictionary is based on this theorem.
The constant Ks nonnalizes the discrete nonn of gs. For
any integer °:s; p < Nand °:s; k < N, we denote l' =
(s, p, 27I"k / N) and define the discrete Gabor atom
g-y(n) = g,(n - p)ei(hk/Nln. (64)
The discrete complex Gabor dictionary is the set of all
such atoms for S E ] 1, N [ and p, k integers between °and
(65)
with K<-y.1>l such that II g-y.1> II = 1. Appendix E describes
an efficient implementation of a matching pursuit with this
real discrete Gabor dictionary and gives infonnation to
obtain a copy of a matching pursuit software. The imple-
mentation follows the general algorithm described in Sec-
tion IV. We compute the inner products of the signal res-
idues with the complex Gabor atoms (64) and recover the
phase from the complex coefficients. As suggested by
Theorem 2 and the implementation algorithm of Section
IV, we only compute the inner product of the signal res-
idues with a subset 5)a = (g-Y)-YET
Q
of the complex Gabor
dictionary. The index set r a is composed of all l' = (a),
pa)l1u, ka-)110, with a = 2, l1u = 1/2, 11~ = 71",°< j < log2 N, ° :s; p < Nr) + I and ° :s; k < 2) + 1 •
We also add the discrete Dirac and Fourier bases to 5)a'
The number of vectors in 5)a is O(N log2 N). The imple-
mentation of the matching pursuit iterations is further de-
scribed in Appendix E. The search over 5)a finds the ap-
proximate scale, time and frequency localization of the
main signal structures. These values are then refined with
a Newton search strategy to recover the time-frequency
parameters that best match the signal components. Each
iteration requires O(Nlog N) operations and as much CPU
time as a fast Fourier transfonn subroutine applied to a
signal of N samples.
Fig. l(a) is a signal f of 512 samples that is built by
adding chirps, truncated sinusoidal waves and wavefonns
of different time-frequency localizations. No Gabor func-
tion have been used to construct this signal. Fig. 1(b)
shows the time-frequency energy distribution Ef(t, w).
Since Ef(t, w) = Ef(t, -w), we only display its values
for w ~ 0. Each Gabor time-frequency atom selected by
the matching pursuit is an elongated Gaussian blob in the
time-frequency plane. We clearly see appearing two chirps
that cross each other, with a localized time-frequency
wavefonn at the top of their crossing point. We can also
detect closely spaced Diracs, and truncated sinusoidal
waves having close frequencies. Several isolated local-
ized time-frequency components also appear in this en-
ergy distribution. The curve (a) in Fig. 2 gives the decay
of 10glO IIRnf II / II f II as a function of the number of iter-
ations n. For n :s; 130, IIRnfl1 has a relatively faster de-
cay. These iterations correspond to the coherent signal
structures, as shown in Section VII. For n ~ 130, the
decay rate is almost constant. This confinns the exponen-
tial decay proved by Lemma 2. For any n ~ 0, the back-
projection algorithm described in Section III recovers a
(63)
(61)
Ks ~ (n - PN)gs(n) = I LJ g -- .
"\IS p~-oo S
The time-frequency atoms g-y (t) are then called Gabor
functions. The time-frequency energy distribution Ef(t,
w) is a sum of Gaussian blobs whose locations and vari-
ances along the time and frequency axes depend upon the
parameters (sn, Un' ~n)'
As explained in Section IV, to implement efficiently a
matching pursuit, we must avoid computing the inner
products of the signal residues with all the dictionary vec-
tors. The following theorem guaranties that, if we discre-
tize appropriately the Gabor dictionary, one can obtain a
subdictionary that satisfies the property (30).
Theorem 2: Let 11 U and 11 ~ be respectively a time and
a frequency discretization interval that satisfy
VI. DISCRETE MATCHING PURSUIT IN GABOR
DICTIONARIES
We explain the discrete implementation of a matching
pursuit for a dictionary of Gabor time-frequency atoms.
Numerical examples are shown at the end of this section.
We suppose that our signal is real and has N samples. The
space H is the set of infinite discrete signals of period N.
Due to the limitations of the sampling rate and the signal
size, the scale S can only vary between 1 and N. The win-
dow function g (t) is the nonnalized Gaussian given by
(59). To obtain a discrete and periodic signal, at any scale
s, the window function is unifonnly sampled and period-
ized over N points
11~
l1u = 271" < 1.
Let a > 1 be an elementary dilation factor. Let r a be the
discrete subset of r = R+ x R2 , of all indexes l' = (a),
pa }l1u, ka-) 11 0, for (j, p, k) E Z3. There exists a con-
stant ex > °such that for all f E L 2 (R)
sup I(f, g-y) I ~ ex sup I(f, g-y) I. (62)
-YETa -yET
MALLAT AND ZHANG: MATCHING PURSUITS WITH TIME-FREQUENCY DICTIONAR[ES 3405
2r------~------_,_------~------~-----__,,.....,
-2
100 200 300 400 500
(a)
(b)
Fig. I. (a) Signal of 512 samples built by adding chirps, truncated sinusoidal waves and wavefonns of different time-frequency
localizations. (b) Time-frequency energy distribution Ef(t, w) of the signal shown in (a). The horizontal axis is time. The vertical
axis is frequency. The highest frequencies are on the top. The darkness of this time-frequency image increases with the value
Ef(t, w).
o""-------,------..,.--------,--------r------r-----,
-[
-2
-3
-4
-5
-6
-7
500400300200[00
-8 '-- ---'-- '-- -'- ~ --'--...L___'
o
Fig. 2. The curve (a) gives the decay of log,o IIR"f 11/ II f II, as function of the number of iterations n, for the signal f of Fig.
I(a). The curve (b) gives the decay of logJ() II pw,J 11/ II f II.
3406 IEEE TRANSACTIONS ON SIGNAL PROCESSING. VOL. 41, NO. 12. DECEMBER 1993
2000r-----~----~----~-----~----~--____,
1500
1000
o 1/V\/W'\fVo__RI
(a)
(b)
Fig. 3. (a) speech recording of the word' 'greasy," sampled at 16 kHz. (b) Time-frequency energy distribution of the speech
recording shown in (a). We see the low-frequency component of the "g," the quick burst transition to the "ea" and the
harmonics of the "ea." The "s" has an energy spread over high frequencies.
better approximation off from the n atoms selected from
the dictionary, The reconstruction error is then the or-
thogonal projection offon the space Wnthat is orthogonal
to the n vectors selected by the matching pursuit. The
back-projection requires much less computation than the
matching pursuit. The curve (b) in Fig, 2 gives the decay
oflog IO II pwJ 11/ II f II, For n :'5 130, IIRnf II z II pwJ II,
It means that the matching pursuit computes a close ap-
proximation of the orthogonal projection offon the n vec-
tors selected from the dictionary, For n = 300, IIRnfl1 =
l.511 pwJ II, For n = N = 512, 10gl0 II pwJ 11/ II f II drops
to -00 because pwJ = 0, This indicates that the N vec-
tors selected by the matching pursuit are linearly inde-
pendent and thus define a basis of the signal space H. The
relative gain of the back-projection is important when the
number of iterations is of the order of the dimension of
the signal space. For almost all signals f, the decays of
IIRnfl1 and II Pwmfll have the same qualitative behavior
as in Fig. 2.
Fig, 3(a) is the graph of a speech recording correspond-
ing to the word "greasy," sampled at 16 kHz. From the
time-frequency energy displayed in Fig. 3(b), we can see
the low-frequency component of the "g" and the quick
burst transition to the "ea" has many harmonics that are
lined up but we can also see localized high-frequency im-
pulses that correspond to the pitch. The "s" component
has a time-frequency energy spread over a high-frequency
interval. Most of the signal energy is characterized by few
time-frequency atoms. For n = 250 atoms, IIRnf II / II f II
= 0,169, although the signal has 5782 samples, and
the sound recovered from these atoms is of excellent
quality.
Fig. 4(a) shows a signal obtained by adding a Gaussian
white noise to the speech recording given in Fig. 3(a),
with a signal to noise ratio of 1,5 db. Fig. 4(b) is the time-
frequency energy distribution of this noisy signal. The
white noise generates time-frequency atoms spread across
the whole time-frequency plane, but we can still distin-
MALLAT AND ZHANG: MATCHING PURSUITS WITH TIME-FREQUENCY DICTIONARIES
2500,-------,------~----~----~~----~---_,
2000
(a)
(b)
Fig. 4. (a) Signal obtained by adding a Gaussian white noise to the speech recording shown in Fig. 3(a). The signal to noise
ratio is 1.5 db. (b) Time-frequency energy distribution of the noisy speech signal. The energy distribution of the white noise is
spread across the whole time-frequency plane.
3407
(66)
guish the time-frequency structures of the original signal
because their energy is better concentrated in this plane.
VII. NOISE AND COHERENT STRUCTURES
Generally, the notion of noise versus signal information
is ill-defined. Even though a signal component might carry
a lot of information, it is often considered as noise if we
can not make sense out of it. In a crowd of people speak-
ing a language we do not understand, surrounding con-
versations are generally perceived as a noise background.
However, our attention will be attracted by an remote
conversation in a language we know. In this case, what is
important is not the information content but whether this
information is in a coherent format with respect to our
system of interpretation. A matching pursuit decomposi-
tion in a given dictionary defines a system of interpreta-
tion for signals. We study the notion of coherence and
describe an algorithm that isolates signal structures that
are coherent with respect to a given dictionary.
Coherent signal components have a strong correlation
with some dictionary vectors. The more coherent a signal,
the larger the correlation ratios of the signal residues
l\(Rnf) = sup I(Rnj, g'f> I
'fEr IIRnjl1
The matching pursuit selects vectors g'fn that almost best
correlate the signal residues. Let us denote
Equation (11) implies that
- I _
l\(Rnf) :5 l\(Rnf) :5 - l\(Rnf). (68)
IX
For any h E H, the choice procedure implies that}.. (h) =
}.. (h / II h II ). Hence, }.. (h) only depends upon the position
of h / II h lion the unit sphere of the signal space H. Let W
be a discrete Gaussian white noise. For any n ~ 0, the
average value of }"(Rnf) measured with a uniform prob-
ability distribution over the unit sphere, is equal to the
3408 IEEE TRANSACTIONS ON SIGNAL PROCESSING. VOL. 41. NO. 12. DECEMBER 1993
expected value E(i.. (R n W». Indeed, after normalization,
the realizations of a discrete Gaussian white noise have a
uniform probability distribution over the unit sphere of H.
We define the coherent structures of a signal f as the first
m vectors (gy)O:5 n < m that have a higher than average cor-
relation with Rnf. In other words, fhas m coherent struc-
tures if and only if for 0 :5 n < m
'A(Rnf) > E('A(R nW» (69)
and
0.2
400 800
(70)
Equation (13) proves that 'A (Rnf) is related to the de-
cay of IIRnf II by
Fig. 5. The curve (c) is a plot of E ( );. (R" W) as a function of 11. for a
discrete Gaussian white noise of 5762 samples. The curves (a) and (b) give
the values of);. (R"!) for the speech signal in Fig. 3(a) and the noisy speech
signal in Fig. 4(a).
VIII. WAVEPACKET DICTIONARY
A wavepacket dictionary is a family of orthonormal
bases composed of vectors that are well localized both in
time and frequency. It is computed with a quadrature mir-
One can verify that for a Gabor dictionary, the signal
shown in Fig. lea) has m = 130 coherent structures that
correspond to the iterations where the IIR nf II has a rela-
tively faster decay in Fig. 2.
For all the dictionaries that we studied numerically, we
have observed that when n increases, E('A(RnW» con-
verges quickly to a constant E ('A (R oo W». In fact, the
process R nW seems to converge to a process ROO W that
we call dictionary noise, whose properties are now being
studied. The realizations of a dictionary noise have an en-
ergy that is uniformly spread across the whole dictionary.
For a Gabor dictionary this process is a stationary white
noise, that is not Gaussian. The curve (c) in Fig. 5 gives
the value of E('A(R nW» as a function of n, for a discrete
Gaussian white noise of 5762 samples, decomposed in a
Gabor dictionary. The limit is E('A(ROO W» ~ 0.0506.
The curve (a) in Fig. 5 gives the value of ,,(Rnf) as a
function of n for the speech recording f shown in Fig.
3(a). The number of coherent structures is the abscissa of
the first intersection between curves (a) and (c), which is
located at n = 698. We have observed numerically that
after removing the coherent structures from a signal f, the
residue R mf behaves like a realization of the dictionary
noise R oo W. This property remains to be studied more
precisely. The curve (b) in Fig. 5 gives the value .of
'A (R nf) for the noisy speech signal in Fig. 4(a). The nOIse
has destroyed the low-energy coherent structures and only
76 coherent structures remains at an SNR of 1.5 db. Fig.
6(a) is the time-frequency energy distribution of these
m = 76 coherent structures. Fig. 6(b) is the signal recon-
structed from these time-frequency atoms. The SNR of
the reconstructed signal is 6.8 db. The white noise has
been removed and this signal has a good auditory quality
because the main time-frequency structures of the original
speech signal have been retained.
'A (Rnf) IIR" + If 11
2
1 - IIR nfl1 2 . (71) ror filter bank algorithm [15]. Through our numerical ex-
periments with wavepacket dictionaries, we intend to
compare matching pursuit decompositions with the best
basis algorithm of Coifman and Wikerhauser [4], that se-
lects an "optimal" orthonormal basis within the wave-
packet dictionary. This highlights the respective advan-
tages of procedures that globally adapt the sig?al
representation versus the greedy strategy o~ ~ matchmg
pursuit, that locally optimizes the decomposition.
For signals of N samples, each vector g_, of a wave-
packet dictionary is indexed by l' = (j, p, k), with 0 :5
j :5 log2 (N), 0 :5 P :5 Tj N, 0 :5 P :5 2 j. Such a vector
has a similar time-frequency localization properties as a
discrete window function, dilated by 2 j, centered at 2 j (p
+ 1/2), and modulated by sinusoidal wave of frequency
27f2-j (k + 1/2). The wavepacket dictionary:D = (g,,)yEl'
includes (N + 1) log2 (N) vectors. For any discrete signal
fen) of N samples, the inner products ( f, gy) )YE[ are
computed with a filter bank algorithm based on qu.adrature
mirror filters, that requires 0 (N log2 (N» operatIOns [4].
The implementation of the matching pursuit decomposi-
tion follows the general outline of the algorithm described
in Section IV. In this case, we set the optimality factor ex
to I and search over the whole dictionary :D because it is
not to large. To compute the inner product updating for-
mula (33), we calculate the inner product of wavepacket
vectors from the coefficients of the quadrature mirror fil-
ters [4]. Each matching pursuit iteration requires O(N log2
(N» operations.
Fig. 7(a) shows the structure book (R"f, gy,,), I'n)nEN
of the signal in Fig. l(a), with the display conventions of
Coifman and Wickerhauser [4]. The wavepacket
dictionary is built with the Daubechies 6 quadrature mir-
ror filters [5]. The horizontal and vertical axes of Fig. 10
are respectively the time and frequency axes. Each vector
g f'or 'V = (J' k p) is represented by a rectangle)'11' III n' 11' n'
which is centered at the time 2 jll (PII + 1/2) and at the
frequency 27f2-j"(kn + 1/2). This rectangle has a width
of 2 jll along time and 2 -j" 7f along frequencies. It gives an
approximate idea of the localization in time and frequen~y
of the atom gw but it reality gy" is much more spread m
time and frequency than the zone indicated by its rectan-
MALLAT AND ZHANG: MATCHING PURSUITS WITH TIME-FREQUENCY DICTIONARIES
(a)
2000r------~-----~------~-----~-----~----___,
1500
3409
-1500
o 1000
----~-------~-----
3000 soun
(bJ
Fig. 6. (a) Time-frequency energy distribution of the In 76 coherent structures of the noisy speech signal shown in hg. 4.
(b) Signal reconstructed from the 79 coherent structures shown in (a). The white noise has been removed.
(a) (b)
Fig. 7. (a) Time frequency display of the wavepaeket structure hook of thc signal shown in Fig. I(a). Each rectangle roughly
represents the location and time-frequency sprcad of a selected wavepaeket function (hi Time-frequency display of the signal
in Fig. I(a) deeomposcd in the hest wavepackct orthonormal basis.
3410 IEEE TRANSACTIONS ON SIGNAL PROCESSING. VOL. 41, NO. 12. DECEMBER 1993
gle. Wavepacket functions are not as well localized in time
and frequency as Gabor functions. When the scale 2 J in-
creases, these atoms have a complicated time-frequency
localization studied by Coifman, Meyer and Wickerhau-
ser [3]. The time-frequency image obtained with this
wavepacket dictionary is similar to the energy distribution
in Fig. l(b), obtained with Gabor dictionary. Some signal
features do not appear as clearly because wavepackets are
not as well localized in time and frequencies as Gabor
functions. Moreover, wavepacket functions do not in-
clude a phase parameter and thus can not match signal
components as well Gabor functions. We must also men-
tion that the Gabor dictionary includes Gabor functions
translated in time and frequency over a much finer grid
than wavepackets, so that the different time-frequency
signal features can be located more precisely. Although
the Gabor dictionary is much larger than the wavepacket
dictionary, the matching pursuit does not require much
more calculations because we limit most of the compu-
tations to a subdictionary ~" that is approximately of the
same size as the wavepacket dictionary.
By combining the vectors of a wavepacket dictionary,
Coifman and Wickerhauser [4] proved that we can build
2N different orthonormal bases. They have introduced an
algorithm that finds the orthonormal basis (gl',,)1 '" n '" Nof
:D which minimizes the entropy
N
L: I (j, gl'n>1 2 10g2 (I (j, gl'n> 12 ). (72)
n = I
The choice of this "optimal" orthonormal basis is thus
obtained through a global minimization over all the signal
components. Fig. 7(b) displays the structure book « j,
gl'n >, 'Yn)nEN that is obtained by decomposing the sig~al
of Fig. l(a) in the optimal wavepacket orthonormal basIs.
One can hardly distinguish many of the signal compo-
nents, including the two chirps. The entropy optimization
creates a competition between the signal components that
are in the same frequency range, but have different time-
frequency signatures. Since the signal is not stationary,
the global entropy minimization is driven by the transients
of highest energy. It leads to a choice of orthonormal ba-
sis that is well adapted to represent the corresponding
transients, but not to represent other signal structures that
have different time-frequency behaviors. For highly non-
stationary signals, the entropy minimization produces
mismatch between the "best" orthonormal basis and
many local signal components. On the contrary, a match-
ing pursuit is a greedy algorithm that locally optimizes the
choice of the wavepacket function, for each signal resi-
due. It can thus adapt itself to varying structures. On the
other hand, this greedy strategy requires more computa-
tions than the best basis decomposition algorithm, whose
total complexity is 0 (N log N). The best basis algorithm
is thus better suited to represent simpler signals that have
stationary properties. The global optimization is then valid
locally, and yields good results.
IX. CONCLUSION
Matching pursuits provide extremely flexible signal
representations since the choice of dictionaries is not lim-
ited. We showed that time-frequency dictionaries yield
adaptive decompositions where signal structures are rep-
resented by atoms that match their time-frequency signa-
ture. The properties of the signal components are explic-
itly given by the scale, frequency, time and phase indexes
of the selected atoms. This representation is therefore well
adapted to information processing.
Compact signal coding is another important domain of
application of matching pursuits. For a given class of sig-
nals, if we can adapt the dictionary to minimize the stor-
age for a given approximation precision, we are guaran-
teed to obtain better results than decompositions on
orthonormal bases. Indeed, an orthonormal decomposi-
tion is a particular case of matching pursuit where the
dictionary is the orthonormal basis. For dictionaries that
are not orthonormal bases, we must code the inner prod-
ucts of the structure book but also the indexes of the se-
lected vectors. This requires to quantize the inner product
values and use a dictionary of finite size. The matching
pursuit decomposition is then equivalent to a multistage
shape-gain vector quantization in a very high dimensional
space.
For information processing or compact signal coding,
it is important to have strategies to adapt the dictionary to
the class of signal that is decomposed. Time-frequency
dictionaries include vectors that are spread between the
Fourier and Dirac bases. They are regularly distributed of
the unit sphere of the signal space and are thus well
adapted to decompose signals over which we have little
prior information. When enough prior information is
available, one can adapt the dictionary to the probability
distribution of the signal class within the signal space H.
Learning a dictionary is equivalent to finding the impor-
tant inner structures of the signals that are decomposed.
Classical algorithms such as LBG to optimize codebooks
[9] do not converge to satisfying solutions in such high
dimensional vector spaces. Finding strategies to optimize
dictionaries in high dimensions is an open problem that
shares similar features with learning problems in neural
networks.
ApPENDIX A
PROOF OF THEOREM
This appendix is a translation in the matching pursuit
context of Jones's proof [11] for the convergence of pro-
jection pursuit regressions.
Lemma 3: Let hn = (Rnj, gl') gl'n' For any n ~ 0 and
m ~ 0
Proof Since hm = (Rmj, gl'm> gl'm
I(hm, Rnj>1 = I(Rmj, gl'm> (gl'm' Rnj>1
= Ilhmll 1(gl'm' Rnj>l· (74)
MALLAT AND ZHANG: MATCHING PURSUITS WITH TIME-FREQUENCY DICTIONARIES 3411
Equation (11) implies
o (75)
Similarly,
Hence,
(84)
Lemma 4: If (Sn)nEZ is a positive sequence such that
E::o s~ :5 +00, then which proves that (R"f)/lEN is a Cauchy sequence. Let
lim inf Sn 2.,; Sk = O.
n~ +00 k=O
(76)
1/- +00
Proof" For any E > 0, we choose n such that
Et:;, s; :5 E/2. Since limk~ +00 Sk = 0, we can choose k
large enough such that Sk E7=o Sj :5 E/2. Let Sj be the
minimum element for indexes between n + 1 and k
J j
Sj 2.,; Sk = Sj 2.,; Sk + Sj 2.,; Sk
k=O k=O k=n+\
We know that lim" ~ +00 I<R"f, g-y) I = O. Since,
I<Rnf, g-y)1 2: ex sup I<Rnf, g-y)1
-YEI"
for any 'Y E r, limn ~ +00 I<Rnf, g-y> I = 0, and thus I<Roof,
g'Y> I = O. This implies that Roof E W. Since,
+00
J
:5 E/2 + 2.,; S~:5 E.
k=n+\
o (77)
(86)
and E::o <Rnf, g'Y) g'Yn E V, we derive that
To prove Theorem 1, we prove that the sequence
(Rnf)nEN is a Cauchy sequence. Let N 2: 0 and M 2: 0
+00
(87)
and
ApPENDIX B
PROOF OF LEMMA
If this lemma was wrong, one could construct a se-
quence of unit vectors (!")"EN and the sequence O'n)nEN
of decreasing real numbers converging to zero such that
for all n 2: 0
IIRNf- R
M
fl12 = IIRMf- RMf+ ~~~h,,11 (78)
IIR Nfl1 2 + IIR Mfl1 2 - 211R Mfl12
M-]
-22.,; Real <RMf,h,,>. (79)
n=N
Lemma 3 implies that
IIRNf - R Mfl1 2
M-j
:5 IIRNfl12 - IIRMfl12+ ~ IlhM11 2.,; Ilhnll. (80)
ex n=N
sup 1<1;" g-y> I :5 A.n·
"IEI'
o (88)
(89)
The energy conservation equation (13) proves that the
sequence (1IRnfll)"EN is monotonically decreasing and
thus converges to some value Roo. Let E > 0, there exist
K> osuch that for all m > K, IIR mfI1 2 :5 R~ + E 2 • Let
p > O. We want to estimate IIRmf - Rm+Pfll, for m >
K. Equation (17) proves that E::o I<R"f, g-Yn>1
2 =
E::o IIhnl1 2 :5 Ilfl1 2 < +00, hence Lemma 4implies that
there exist q > m + p such that Since f has a norm 1, the inner product which each ele-
ment of :D can not be zero since ;D is complete and thus
includes at least a basis of H. This contradicts our as-
sumption, which finishes the proof. 0
Since the unit sphere of the finite dimensional space H is
compact, there exists a subsequence (fn)pEN that con-
verges to a unit vector f E H. Hence
lim 1< f, g-y> I = lim sup 1< fnp' g-y> I
"IEI' P -, +00 -yEI"
q
Ilhqll 2.,; Ilhnll :5 E 2 .
n=O
We can decompose
(81)
:5 lim A.nl> = O.
P -+ + 00
(90)
IIRmf - Rm+Pfll
:5IIRmf-Rqfll + IIRm+Pf-Rqfll. (82)
Equation (80) for N = m and M = q implies
IIRmf- R qf11 2 :5 E 2 + ~E2. (83)
ex
ApPENDIX C
DILATION, TRANSLATION, AND MODULATION
COVARIANCE
We say that a subset A of f is admissible and associated
to f E L 2 (R) if
A = {{3 E f: I<f, gl3>1 2: ex sup I<f, g'Y>I}· (91)
"lEI"
3412 IEEE TRANSACTIONS ON SIGNAL PROCESSING. VOL. 41. NO. 12. DECEMBER 1993
Let A be an admissible set and (a, b, c) E R + X R 2 . Let on covariant choice functions. Let us define
A choice function C is said to be covariant if and only if
for any admissible set A, C(A) = (so, Uo, ~o) implies that
(94)
A(a.b.c) = [iJ = (s, u, n E r:
(
s U - C ) J. ~'-a-,a(~ - b) EA .
(
So Uo - c )
C(A(a be)) = -, --, a(~O - b) .. . a a
(92)
(93)
d (t - c)fl (t) = -fo -- e ibr .
~ a
Let I' 1= (s, U, 0 and 1'0 = (s/a, (u - c)/a, a(~ - b)).
With a change of variable, we prove that
<fl, gy'> = deic(b-O <fo, gyo>. (95)
Hence SUPyd 1<fl, gy> I = d SUPyd 1<fO, gy> I· Let us
define
A = {iJ E r: I<f l , gjJ>1 ~ ex sup I<f l , gy>I}. (96)
yEr
(97)
Equation (95) proves that the set A(a.b.c) defined in (92),
also satisfies
A(a,b,c) = {iJ E r: I<fo, gjJ>1 ~ ex sup I<fo, g,>I}·
yEr
(98)
~o
(99)
c)/a,
<Rnfl, gy,~> = deiC(b-~,,) <RnfO, gyo>. (100)
Conversely, if the residues of fO (t) and f I (t) satisfies these
equalities, (42) proves that (94) is satisfied. Hence, a
matching pursuit based on covariant choice functions is
covariant by dilation, translation and modulation.
The covariance of the choice function implies that if C (A)
= 1'6 = (so, Uo, ~o), then C(A(a,b.c)) = 1'8 = (so/a, (uo
- c)/a, a(~o - b)). We can thus derive that
d (t - c)Rfl (t) = - Rfo -- e ibr .
~ a
Similarly, we can prove by induction that for any n
Rnfl (t) = ~ Rnfo (t - c) eibr
~ a
and ifl'~ = (sno Un' ~j) then I'~ = (Sn/a , (un
a(~n - b)), and
lim sup I<f, gy>1 = o.
s~ +00 (u.OER2
We can thus derive that there exist a finite Sl that is the
supremum of all s such that (s, u, 0 E A. Since A is
closed, there exists (Slo u, 0 E A. Since
lim 1 g(t)1 = 0
Irl~oo
and f(t) is absolutely integrable, we can prove that for
I' = (Slo U, 0,
Ifwe restrict our signal space to functions that are bounded
and absolutely integrable, the matching pursuit residues
are also bounded and absolutely integrable. An example
of covariant choice function can then be defined as fol-
lows. For any admissible set A, associated to a bounded
and absolutely integrable function, C(A) = (Slo Ulo ~I),
such that SI = sup{s: 3(u, ~) E R2 , (s, u, n E A}, UI =
sup{u: 3~ E R, (Slo U, 0 E A}, and ~I = sup{~: (s" Ulo
o E A}. The following lemma proves that the index (Slo
Ulo ~I) is well defined and belongs to A.
Lemma 5: For any admissible set A, associated to a
bounded and absolutely integrable function, (s 10 U" ~ I) E
A.
Proof let A be an admissible index set associated to
f. Since g (t) is bounded and f (t) is absolutely integrable,
one can prove that
lim sup I<f, gy>1 = o.
u~ +00 ~ER
We can then derive that there exists U'I that is the supre-
mum of all U such that (SI, U, 0 E A. Since A is closed,
there exists ~ such that (Slo UI, 0 E A. Since
lim Ig(w)1 = 0
Iwl ~oo
and l(w) is absolutely integrable, we can prove that for
I' = (Slo UI, 0,
lim I<f, gy>1 = o.
~ ~ +00
We can finally derive that ~ I that is the supremum of all
~ such that (Slo Ulo 0 EA. Since A is closed, (s" U" ~I)
EA. This finishes the proof of the lemma. D
Let us prove the covariance of a matching pursuit based
ApPENDIX D
PROOF OF THEOREM 2
We denote gj.p,k(t) = gy (t) for I' = (a j , pa j l1u,
ka-J110 E r". Since l1u = I1U27r and l1ul1~ < 27r,
Daubechies [6] proved that for the Gaussian window g (t)
specified by (59), (gO.p,k(t))(p.k)EZ1 is a frame of L 2(R).
The dual frame is given by (gO.p.k(t))(p.k)EZ2, where get)
E L 2 (R) and
_ 1 _ (t - pa j I1U) ika-j!J.~r
gj.p.k(t) = J;;J g a j e . (101)
The dual window g(t) has an exponential decay and its
Fourier transform g(w) also has an exponential decay [5].
For any fE L 2 (R),
+00 +00
MALLAT AND ZHANG: MATCHING PURSUITS WITH TIME-FREQUENCY DICTIONARIES 34\3
(113)
( 117)
(120)
K(,,,.¢,,,)
<g(y".¢,,,j' gy> = --2-
. (ei¢'<gYn' gy> + e-i¢'<gy,~, g).
R n+ If = Rnf - <Rnf, g(Yn. ¢,,,j> g(,,,.¢,,,), (118)
for the next iteration we must compute for any l' E r CI
<R n+ If, g,> = <Rnf, g,>
- <Rnf, g(,n.¢,,,j> <giy".¢,,,), gy>' (119)
We therefore estimate
Since,
.fi
Kry,¢) = 11 R 1 ( i2¢ , (114)
v + ea e <gy, gy_»
where Real (z) is the real part of the complex number z.
For any residue Rnf,
I<Rnf, g(y.¢j> I = K(y.¢) IReal (e- i¢ <Rnf, gy»l· (115)
By choosing ¢ equal to the complex phase ¢y of <Rnf,
gy>, we obtain
IReal (e-i¢'<Rnf, g,»1 = I<Rnf, gy>l· (116)
We search for an index 'Yn that maximizes I<Rnf, gy> I for
l' in the subset r CI of r. With a Newton algorithm, we
then look in the neighborhood of l'n in r for an index l'n
= (sn' Pn' 21rkn/N) E r, where I<Rnf, gy>1 reaches a
local maxima. One can verify that there exists ex > 0 such
that
ApPENDIX E
MATCHING PURSUIT IMPLEMENTATION WITH GABOR
DICTIONARIES
This appendix describes the numerical implementation
of a matching pursuit for a Gabor dictionary (Instructions
to obtain a free copy of the software implementing this
transform are available through anonymous ftp at the ad-
dress cs.nyu.edu, in the file README of the directory/
pub/wave/software).
For any l' = (s, P, 21rk/N) and ¢ E [0, 21r[, real dis-
crete time-frequency atoms are related to complex atoms
by
(106) is bounded by a finite constant K that is independent
of 1'0' From (105), we derive that any constant ex ~ 1/K
satisfies the condition (62) of Theorem 2.
(109)
(108)
_ K(y,¢) ( i¢ -i¢)
gry,¢J - -2- e gy + e gy_'
(106) One can derive that the normalization constant is
+00 +00
+00 +00
+00 +00
+00 +00
<f, gyo> = I; I; <f, gj.p.k> <gj.p.b gyo>' (104)
p= -00 k=-oo
I<f, gyo>1 ~ sup I<f, gy>1 I; I; I<gj.p.b gyo>l·
)'Era p= -00 k=-oo
(105)
I<gj," g,.>1 " [:~ H:w,) I
. li(w + aj~ - k.:lOI dw. (112)
Since both g(w) andJ(w) have an exponential decay and
1/ ~ ~ s / a j ~ ...;a, we can also derive that there exists
two constant C2 and D2 that satisfy (108). From the upper
bounds (107) and (108) we can show that the sum SyO of
From the expression of gj.p.k(W) in (5), with a change of
variable we derive that
With a change of variable, we derive that
. Ig(t + a-j u - p.:lu)1 dt. (110)
Since 1/ ~ ~ a j / s ~ ~, and since both g (t) and g(t)
have an exponential decay, one can derive that there ex-
ists two constant C] > 0 and D] > 0 that satisfy (107).
To prove (108), we observe that
1<gj.p.b gyo> I ~ r: Igj.p.k(W) II gyO (w)1 dw. (111)
I<gj.p.b gyo> I ~ D2 exp (-C2Ik.:l~ - aj~I)·
Clearly,
Let us now prove that there exists a finite constant K such
that for all 1'0
For this purpose, we shall prove that there exists D\ > 0,
C\ > 0 and D2 > 0, C2 > 0 such that
1< gj.p.b gyo> I ~ D] exp (-C] Ip.:lu - a-j ul) (107)
and
Since gj.p. k = gy with l' E r CI
f(t) = I; I; <f, gj.p.k> gj.p.k(t). (103)
p~-ook=-oo
Let 1'0 = (s, u, 0 E rand) E Z be such that a j - 1/ 2 <
s ~ a j + ] /2
With a change of variable, one can derive that for any
} E Z
3414 IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 41, NO, 12, DECEMBER 1993
To compute fast this inner product, we use an analytical
formula that gives the inner product of two discrete com-
plex Gabor signals. This formula is derived from the fol-
lowing lemma.
Lemma 6: Let f (t) and h (t) be two continuously dif-
ferentiable functions such thatf(t) = 0(1/(1 + t 2»and
h(t) = 0(1/(1 + t 2». Letfdand hdbe the discrete signals
of period N defined by
+00
2: fen + mN),
m=-oo
+00
2: hen + mN).
Then,
N
2: fd(n)hd(n)
n=1
(121)
(122)
When g"yl or g"y2 is a discrete Dirac or a discrete complex
exponential, different formula must be used. If we limit
the computation to a precision E, for any Gabor atom
g"yl' there are 0 (N~) other vectors g"y2 such that
(g"yI' g"y2> is not negligible. One can show that (127) re-
quires 0 (N flog E 1 3 / 2) operations to compute the inner
product of any atom g"yl with all other discrete atoms
(g)"yEra , The total numerical complexity for one match-
ing pursuit iteration is 0 (N log N). By tabulating the
Gaussian and complex exponential functions, each itera-
tion requires approximately as much CPU time as a Fast
Fourier Transform on a signal of N samples. In the ex-
periments shown in this paper, we restricted the scale Sn
of the selected atoms to powers of 2, to minimize the
memory required by the tabulation. However, choice of
Sn may have no such restriction, if we do not use any tab-
ulation.
Proof:
N
(fd' hd > = 2: fd(n)hd(n)
n~1
mN) ei2q1r1 dt,
(123)
ACKNOWLEDGMENTS
The authors thank Francois Bergeaud, Wen Liang
Hwang and Mike Orszag who helped us to develop the
software. They are also grateful to Dave Donoho and lain
Johnstone for showing them the relations between this
work and projection pursuit regressions.
2: 2: fen + qN) 2: hen + mN)
n=1 q=-oo
Inserting this in (125) yields (123). This finishes the proof
of the lemma, D
For 1'1 = (SJ, Ph 27rk l /N) and 1'2 = (S2' P2' 27rkdN)
and get) given by (59), one can derive from (123) of
Lemma 6 that the inner product of two discrete Gabor
signals is
2: oCt - p) = 2: e,2'lrql
[I] C. K, Chui, Wavelets: A Tutorial in Theory and Applications New
York: Academic Press, 1992,
[2] L Cohen, "Time-frequency distributions: A review," Proc. IEEE,
voL 77, pp. 941-979, July 1989.
[3] R. Coifman, Y. Meyer, and V. Wickerhauser, "Size properties of
wavelet-packets," M. B, Ruskai, Ed., Wavelets and Their Applica-
tions, Boston, MA: Jones and Bartlett, pp. 453-470, 1992.
[4] R. Coifman and V. Wickerhauser, " Entropy-based algorithms for best
basis selection," IEEE Trans. Informal. Theory, voL 38, Mar. 1992.
[5] Daubechies, "Ten lectures on wavelets," SIAM AppL Math., 1991.
[6] -, "The wavelet transform, time-frequency localization and signal
analysis," IEEE Trans. Informal. Theory, voL 36, pp. 961-1005,
Sept. 1990,
[7] 1. H. Friedman and W. Stuetzle, "Projection pursuit regression," J,
Amer, Statist, Asso., voL 76, pp. 817-823, 1981.
[8] G. Golub and C. Van Loan, Matrix Computations, Baltimore, MD:,
The Johns Hopkins Press.
[9] R. Gray, "Vector quantization," IEEE ASSP Mag" Apr. 1984,
[10] P. 1. Huber, "Projection pursuit," Ann. Stat., voL 13, no. 2, pp,
435-475, 1985.
[II] L K. Jones, "On a conjecture of Huber concerning the convergence
of projection pursuit regression," Ann, Statist" voL 15, no. 2, pp,
880-882, 1987,
[12] S. Mallat and Z. Zhang, "Local time-frequency multilayer ortho-
gonal transforms," Proc. Workshop on the Role of Wavelets in Signal
Processing Appl., Dayton, Ohio, Mar. 1992.
[13] Y. Meyer, Ondelettes et Operateurs. Paris: Hermann, 1990.
REFERENCES
(126)
(125)
(124)
+00
+00
q = -00
+00 +00
+00 +00
+00
[+00
. Loo f(t)h(t + mN)o(t - p) dt.
m= -00 p=-oo
2: f(p) 2: h(p + mN),
p=-oo m=-oo
p=-oo
N +00
Let us recall the Poisson formula
Hence,
+00 +00
m=-ooq=-oo
(127)
(
S~ 27r
X exp i -2--2 - (k2 - k, + qN)( P2
S, + S2 N
x
MALLAT AND ZHANG: MATCHING PURSUITS WITH TIME-FREQUENCY DICTIONARIES 3415
[14] S. Qian and D. Chen, "'Signal representation via adaptive normalized
Gaussian functions," IEEE Trans. Signal Processing, vol. 36, Jan.
1988.
[15] O. Rioul and M. Vetterli, "Wavelets and signal processing," IEEE
Signal Processing Magazine, Oct. 1991.
[161 M. Sabin and R. Gray, "Product code vector quantizer for waveform
and voice coding," IEEE Trans. Acoust., Speech, and Signal Pro-
cessing, vol. 32, June 1984.
[17] B. Torresani, "Wavelets associated with representations of the affine
Weyl-Heisenberg group," 1. Math. Physics, vol. 32, pp. 1273-1279,
May 1991.
the Alfred Sloan Fellowship in Mathematics, in 1993. His research inter-
ests include computer vision, signal processing and applied mathematics.
Stephane Mallat was born in Paris, France. He
graduated from Ecole Poly technique, Paris, in
1984 and from Ecole Nationale Superieure des
Telecommunications, Paris, in 1985. He received
a Ph.D. degree in electrical engineering from the
University of Pennsylvania, Philadelphia, in 1988.
In 1988, he joined the Courant Institute of
Mathematical Sciences at New York University,
New York, where he is currently Associate Pro-
fessor of Computer Science. He received the 1990
IEEE Signal Processing Society's paper award and
Zhifeng Zhang was born in Guangzhou, China.
He received his B.S. degree in chemical engi-
neering from South China Institute of Technol-
ogy, in 1982 and M.S. degree in Applied Mathe-
matics from New Jersey Institute of Technology,
Newark, in 1987.
Since September 1988, he has been in the Ph.D.
program in the Department of Mathematics of the
Courant Institute of Mathematical Sciences, New
York University, New York. His research interest
includes signal processing and applied mathemat-
ics.

