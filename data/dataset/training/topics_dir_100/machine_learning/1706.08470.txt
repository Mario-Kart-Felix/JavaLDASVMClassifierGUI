Efficiency of quantum versus classical annealing in non-convex learning
problems
Carlo Baldassi1,2 and Riccardo Zecchina1,3
1Bocconi Institute for Data Science and Analytics, Bocconi University, Milano, Italy
2Istituto Nazionale di Fisica Nucleare, Sezione di Torino, Italy
3International Centre for Theoretical Physics, Trieste, Italy
Quantum annealers aim at solving non-convex optimization problems by exploiting cooperative
tunneling effects to escape local minima. The underlying idea consists in designing a classical energy
function whose ground states are the sought optimal solutions of the original optimization problem
and add a controllable quantum transverse field to generate tunneling processes. A key challenge
is to identify classes of non-convex optimization problems for which quantum annealing remains
efficient while thermal annealing fails. We show that this happens for a wide class of problems
which are central to machine learning. Their energy landscapes is dominated by local minima
that cause exponential slow down of classical thermal annealers while quantum annealing converges
efficiently to rare dense regions of optimal solutions.
CONTENTS
I. Introduction 2
II. Energy functions 4
III. Connection with the local entropy measure 5
IV. Phase diagram: analytical and numerical results 5
V. Conclusions 6
Acknowledgments 8
A. Theoretical analysis by the replica method 9
a. Small Î“ limit 15
1. Energy function with stability 15
a. Small Î“ limit 16
B. Estimation of the local energy and entropy landscapes with the cavity method 17
C. Numerical simulations details 18
1. Quantum annealing protocol 18
2. Classical simulated annealing protocol 18
D. Additional numerical results 19
1. Quantum Hamiltonian expectation, comparisons between theory and simulations 19
2. Experiments with two-layer networks 20
References 20
ar
X
iv
:1
70
6.
08
47
0v
2 
 [
qu
an
t-
ph
] 
 2
7 
Ju
n 
20
17
2
I. INTRODUCTION
a
b
c
E({Ïƒj})
Ïƒj
Figure 1. Topology of the Suzuki-Trotter vs Robust
Ensemble representations. a: the classical objective
function we wish to optimize which depends on N
discrete variables {Ïƒj} (N = 5 in the picture). b:
Suzuki-Trotter interaction topology: y replicas of the
classical system (y = 7 in the picture) are coupled by
periodic 1 dimensional chains, one for each classical
spin. c: Robust Ensemble interaction topology: y
replicas are coupled through a centroid configuration.
In the limit of large N and large y (quantum limit)
and for strong interaction couplings all replicas are
forced to be close, and the behavior of the two effective
models is expected to be similar.
Quantum tunneling and quantum correla-
tions govern the behavior of very complex col-
lective phenomena in quantum physics at low
temperature. Since the discovery of the fac-
toring quantum algorithms in the 90s [1], a
lot of efforts have been devoted to the under-
standing of how quantum fluctuations could
be exploited to find low-energy configurations
of energy functions which encode the solu-
tions of non-convex optimization problems in
their ground states. This has led to the
notion of controlled quantum adiabatic evo-
lution, where a time dependent many-body
quantum system is evolved towards its ground
states so as to escape local minima through
multiple tunneling events [2â€“6]. When fi-
nite temperature effects have to be taken into
account, the computational process is called
Quantum Annealing (QA). Classical Simu-
lated Annealing (SA) uses thermal fluctua-
tions for the same computational purpose,
and Markov Chains based on this principle
are among the most widespread optimization
techniques across science [7]. Quantum fluc-
tuations are qualitatively different from ther-
mal fluctuations and in principle quantum an-
nealing algorithms could lead to extremely
powerful alternative computational devices.
In the quantum annealing approach, a time
dependent quantum transverse field is added
to the classical energy function leading to an
interpolating Hamiltonian that may take ad-
vantage of correlated fluctuations mediated
by tunneling. Starting with a high trans-
verse field, the quantum model system can be
initialized in its ground state, e.g. all spins
aligned in the direction of the field. The adi-
abatic theorem then ensures that by slowly
reducing the transverse field the system re-
mains in the ground state of the interpolating Hamiltonian. At the end of the process the transverse
field vanishes and the systems ends up in the sought ground state of the classical energy function.
The original optimization problem would then be solved if the overall process could take place in
a time bounded by some low degree polynomial in the size of the problem. Unfortunately, the
adiabatic process can become extremely slow. The adiabatic theorem requires the rate of change
of the Hamiltonian to be smaller than the square of the gap between the ground state and the
first excited state [8â€“10]. For small gaps the process can thus become inefficient. Exponentially
3
small gaps are not only possible in worst case scenarios but have also been found to exist in typical
random systems where comparative studies between quantum and classical annealing have so far
failed in displaying quantum exponential speed up, e.g. at first order phase transition in quantum
spin glasses [11] or 2D spin glass systems [12â€“14]. More positive results have been found for ad
hoc energy functions in which global minima are planted in such a way that tunneling cascades
can become more efficient than thermal fluctuations [5, 15]. As far as the physical implementations
of quantum annealers is concerned, studies have been focused on discriminating the presence of
quantum effects rather than on their computational effectiveness [16â€“18].
Consequently, a key open question is to identify classes of relevant optimization problems for
which quantum annealing can be shown to be exponentially faster than its classical thermal coun-
terpart.
Here we give an answer to this question by providing analytical and numerical evidence of expo-
nential quantum speed up for a representative class of random non-convex optimization problems
of basic interest in machine learning. The simplest example of this class is the problem of training
binary neural networks (described in detail below): very schematically, the variables of the prob-
lem are the (binary) connection weights, while the energy measures the training error over a given
dataset.
These problems have been very recently found to possess a rather distinctive geometrical structure
of ground states [19â€“22]: the free energy landscape has been shown to be characterized by the
existence of an exponentially large number metastable states and isolated ground states, and a few
regions where the ground states are dense. These dense regions, which had previously escaped the
equilibrium statistical physics analysis [23, 24], are exponentially rare, but still possess a very high
local entropy: they are composed of ground states that are surrounded, at extensive but relatively
small distances, by exponentially many other ground states. Under these circumstances, classical SA
(as any Markov Chain satisfying detailed balance) gets trapped in the metastable states, suffering
ergodicity breaking and exponential slowing down toward the low energy configurations. These
problems have been considered to be intractable for decades and display deep similarities with
disordered spin glass models which are known to never reach equilibrium.
The large deviation analysis that has unveiled the existence of the rare dense regions has led
to several novel algorithms, including a Monte Carlo scheme defined over an appropriate objective
function [20] that bears close similarities with a Quantum Monte Carlo (QMC) technique based on
the Suzuki-Trotter transformation [6]. Motivated by this analytical mapping and by the physical
structure of ground states, we have conducted a full analytic and numerical study of the quantum
annealing problem, reaching the conclusion that in the quantum limit the QMC process, i.e. QA,
can equilibrate efficiently while the classical SA gets stuck in high energy metastable states. These
results generalize to multi layered networks.
While it is known that other quasi-optimal classical algorithms for the same problems exist
[20, 25, 26], here we focus on the physical speed up that QA can provide in finding rare regions of
ground states.
As far as machine learning is concerned, dense regions of low energy configurations (i.e. quasi-
flat minima over macroscopic length scales) are of fundamental interest, as they are particularly
well-suited for making predictions given the learned data [27]: the centroid of a region acts as
a representative of the region as a whole, and thus would be a major contributor in an optimal
Bayesian estimate, compared to an isolated configuration at the bottom of a narrow minimum.
In this respect, it is worth mentioning that in deep learning all the algorithms which are effective
for predictions always include effects of systematic injected noise in the learning phase [28], a fact
that makes the equilibrium Gibbs measure not the stationary measure of the learning protocols.
We expect that these results can be generalized to many other classes of non convex optimization
4
problems where local entropy plays a role, ranging from robust optimization to physical disordered
systems.
Quantum gate based algorithms for machine learning exist, however the possibility of a physical
implementation remains a critical issue [29].
II. ENERGY FUNCTIONS
As a working example, we first consider the problem of learning random patterns in single layer
neural network with binary weights, the so called binary perceptron problem [23]. This network
maps vectors of N inputs Î¾ âˆˆ {âˆ’1,+1}N to binary outputs Ï„ = Â±1 through the non linear function
Ï„ = sgn (Ïƒ Â· Î¾), where Ïƒ âˆˆ {âˆ’1,+1}N is the vector of synaptic weights. Given Î±N input pat-
terns {Î¾Âµ}Î±NÂµ=1 with Âµ = 1, ..., Î±N and their corresponding desired outputs {Ï„Âµ}
Î±N
Âµ=1, the learning
problem consists in finding Ïƒ such that all input patterns are simultaneously classified correctly,
i.e. sgn (Ïƒ Â· Î¾Âµ) = Ï„Âµ for all Âµ. Both the components of the input vectors Î¾Âµi and the outputs Ï„Âµ are
independent identically distributed unbiased random variables (P (x) = 12Î´ (xâˆ’ 1)+
1
2Î´ (x+ 1)). In
the binary framework, the procedure for writing a spin Hamiltonian whose ground states are the
sought optimal solutions of the original optimization problem is well known [30].The energy E of
the binary perceptron is proportional to the number of classification errors and can be written as
E ({Ïƒj}) =
Î±Nâˆ‘
Âµ=1
âˆ†nÂµÎ˜ (âˆ’âˆ†Âµ) , âˆ†Âµ
.
=
Ï„Âµâˆš
N
Nâˆ‘
j=1
Î¾Âµj Ïƒj (1)
where Î˜ (x) is the Heaviside step function: Î˜ (x) = 1 if x > 0, Î˜ (x) = 0 otherwise. When the
argument of the Î˜ function is positive, the perceptron is implementing the wrong input-output
mapping. The exponent n âˆˆ {0, 1} defines two different forms of the energy functions which have
the same zero energy ground states and different structures of local minima. The equilibrium
analysis of the binary perceptron problem shows that in the large size limit and for Î± < Î±c ' 0.83
[23], the energy landscape is dominated by an exponential number of local minima and of zero
energy ground states that are typically geometrically isolated [31], i.e. they have extensive mutual
Hamming distances. For both choices of n the problem is computationally hard for SA processes
[32]: in the large N limit, a detailed balanced stochastic search process gets stuck in metastable
states at energy levels of order O(N) above the ground states.
Following the standard QA approach, we identify the binary variables Ïƒ with one of the compo-
nents of physical quantum spins, say Ïƒz, and we introduce the Hamiltonian operator of a model of
N quantum spins with the perceptron term of Eq. (1) acting in the longitudinal direction z and a
magnetic field Î“ acting in the transverse direction x. The interpolating Hamiltonian reads:
HÌ‚ = E
({
ÏƒÌ‚zj
})
âˆ’ Î“
Nâˆ‘
j=1
ÏƒÌ‚xj (2)
where ÏƒÌ‚zj and ÏƒÌ‚j
x are the spin operators (Pauli matrices) in the z and x directions. For Î“ = 0 one
recovers the classical optimization problem. The QA procedure consists in initializing the system
at large Î² and Î“, and slowly decreasing Î“ to 0. To analyze the low temperature phase diagram of
the model we need to study the average of the logarithm of the partition function Z = Tr
(
eâˆ’Î²HÌ‚
)
.
This can be done using the Suzuki-Trotter transformation which leads to the study of a classical
5
effective Hamiltonian acting on a system of y interacting Trotter replicas of the original classical
system coupled in an extra dimension:
Heff
({
Ïƒaj
}
j,a
)
=
1
y
yâˆ‘
a=1
E
({
Ïƒaj
}
j
)
âˆ’ Î³
Î²
yâˆ‘
a=1
Nâˆ‘
j=1
Ïƒaj Ïƒ
a+1
j âˆ’
NK
Î²
(3)
where the Ïƒaj = Â±1 are Ising spins, a âˆˆ {1, . . . , y} is a replica index with periodic boundary
conditions Ïƒy+1j â‰¡ Ïƒ1j , Î³ = 12 log coth
(
Î²Î“
y
)
and K = 12y log
(
1
2 sinh
(
2Î²Î“y
))
.
The replicated system needs to be studied in the limit y â†’âˆ to recover the so called path integral
continuous quantum limit and to make the connection with the behavior of quantum devices [14].
III. CONNECTION WITH THE LOCAL ENTROPY MEASURE
The effective Hamiltonian Eq. (3) can be interpreted as many replicas of the original systems
coupled through one dimensional periodic chains, one for each original spin, see Fig. 1b. Note that
the interaction term Î³ diverges as the transverse field Î“ goes to 0. This geometrical structure is
very similar to that of the Robust Ensemble (RE) formalism [20], where a probability measure
that gives higher weight to rare dense regions of low energy states is introduced. There, the main
idea is to maximize Î¦ (Ïƒ?) = log
âˆ‘
{Ïƒ} e
âˆ’Î²E(Ïƒ)âˆ’Î»
âˆ‘N
j=1 ÏƒjÏƒ
?
j , i.e. a â€œlocal free entropyâ€ where Î» is a
Lagrange parameter that controls the extensive size of the region around a reference configuration
Ïƒ?. One can then build a new Gibbs distribution P (Ïƒ?) âˆ eyÎ¦(Ïƒ?), where âˆ’Î¦ has the role of an
energy and y of an inverse temperature: in the limit of large y, this distribution concentrates on the
maxima of Î¦. Upon restricting the values of y to be integer (and large), P (Ïƒ?) takes a factorized
form yielding a replicated probability measure PRE
(
Ïƒ?, Ïƒ1, . . . , Ïƒy
)
âˆ eâˆ’Î²H
RE
eff (Ïƒ
?,{Ïƒaj }) where the
effective energy is given by
HREeff
(
Ïƒ?,
{
Ïƒaj
}
j,a
)
=
yâˆ‘
a=1
E
({
Ïƒaj
}
j
)
âˆ’ Î»
Î²
yâˆ‘
a=1
Nâˆ‘
j=1
Ïƒaj Ïƒ
?
j (4)
As in the Suzuki-Trotter formalism, HREeff
(
Ïƒ?,
{
Ïƒaj
}
j,a
)
corresponds to a system with an overall
energy given by the sum of y individual â€œreal replica energiesâ€ plus a geometric coupling term; in
this case however the replicas interact with the â€œreferenceâ€ configurations Ïƒ? rather than among
themselves, see Fig. 1c.
The Suzuki-Trotter representation and the RE formalism differ in the topology of the interactions
between replicas and in the scaling of the interactions, but for both cases there is a classical limit,
Î“ â†’ 0 and Î» â†’ âˆ respectively, in which the replicated systems are forced to correlate and
eventually coalesce in identical configurations. For non convex problems, these will not in general
correspond to configuration dominating the original classical Gibbs measure.
IV. PHASE DIAGRAM: ANALYTICAL AND NUMERICAL RESULTS
Thanks to the mean field nature of the energetic part of the system, Eq. (3), we can resort to
the replica method for calculating analytically the phase diagram. As discussed in the Appendix
6
Sec. A, this can be done under the so called static approximation, which consists in using a single
parameter q1 to represent the overlaps along the Trotter dimension, qab1 =
âŒ©
1
N
âˆ‘N
j=1 Ïƒ
a
j Ïƒ
b
j
âŒª
â‰ˆ q1.
Although this approximation neglects the dependency of qab1 from |aâˆ’ b|, the resulting predictions
show a remarkable agreement with numerical simulations.
In the main panel of Fig. 2, we report the analytical predictions for the average ground state
energy of the quantum model as a function of the transverse field Î“, and compare the results
with the outcome of extensive simulations performed with the reduced-rejection-rate Monte Carlo
method [33]. The details are reported in the Appendix Sec. C. The size of the systems, the number
of samples and the number of Trotter replicas are scaled up to large values so that both finite size
effects and the quantum limit are kept under control. A key point is to observe that the results do
not degrade with the number of Trotter replicas: the average ground state energy approaches the
predicted value in the large y quantum limit. In the same plot we display the behavior of classical
SA simulated with a standard Metropolis-Hastings scheme, under an annealing protocol in Î² that
would follow the same theoretical curve as QA if the system were able to equilibrate (see Appendix
Sec. C): as expected [32], SA gets trapped instead at very high energies (increasing with problem
size). Alternative annealing protocols yield analogous results.
In the inset of Fig. 2 we report the analytical prediction for the transverse overlap parameter q1,
which quite remarkably reproduces the average overlap as measured from simulations.
In Fig. 3 we provide the energetic profiles of the the minima found for different values of Î“ in
the case of QA and different temperatures for SA. These results are computed analytically by the
cavity method (see Appendix Sec. B) by evaluating which is the most probable energy found at
a normalized Hamming distance d from a given configuration. As it turns out, throughout the
annealing process, QA follows a path dominated by wide valleys while SA gets stuck in steep
metastable states. The cooperative tunneling effects drive the QA process to converge toward wide
flat regions, in spite of the fact that they are sub-dominant.
As concluding remarks we report that the models with n = 0 and n = 1 have phase diagrams
which are qualitatively very similar (for the sake of simplicity, here we reported the n = 0 case
only). The former presents at very small positive values of Î“ a collapse of the density matrix onto
the classical one whereas the latter ends up in the classical state only at Î“ = 0.
For the sake of completeness, we have checked that the performance of QA in the y â†’âˆ quantum
limit extends to more complex architectures which include hidden layers; the details are reported
in the Appendix Sec. D 2.
V. CONCLUSIONS
We conclude by noticing that, at variance with other studies on spin glass models in which the
evidence for QA outperforming classical annealing was limited to finite values of y, thereby just
defining a different type of classical SA algorithms, in our case the quantum limit coincides with
the optimal behavior of the algorithm itself. We believe that these results could play a role in
many optimization problems in which optimality of the cost function needs to also meet robustness
conditions (i.e. wide minima). As far as learning problems are concerned, it is worth mentioning
that for the best performing artificial neural networks, the so called deep networks [28], there is
numerical evidence for the existence of rare flat minima [34], and that all the effective algorithms
always include effects of systematic injected noise in the learning phase [35], which implies that
the equilibrium Gibbs measure is not the stationary measure of the learning protocols. For the
sake of clarity we should remark that our results are aimed to demonstrate that QA can equilibrate
7
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0 0.5 1 1.5 2 2.5
cl
as
si
ca
l e
ne
rg
y 
de
ns
ity
 ğ¸
/N
transverse field ğ›¤
QA N=4001
SA N=1001
SA N=2001
SA N=4001
theory
â–µ â‹†
0
0.2
0.4
0.6
0.8
1
0 0.5 1 1.5 2 2.5
re
pl
ic
a
ov
er
la
ps
ğ‘ 1
ğ›¤
increasing y=64,128,256
increasing
simulation
time
y=128
y=256 average y=256
average y=128
theory
Figure 2. Classical energy density (i.e. longitudinal component of the energy, divided by N) as a function
of the transverse field Î“ (single layer problems with Î± = 0.4 and n = 0, 15 independent samples per curve).
The QA simulations at Î² = 20 approach the theoretical prediction as y increases (cf. black arrow). The
results do not change significantly when varying N or the simulation time (the curves with N = 1001
or N = 2001 are indistinguishable from the ones displayed at this level of detail). All SA simulations
instead got stuck and failed to equilibrate at low enough temperatures (small equivalent Î“). The results
are noticeably worse for larger N , and doubling or quadrupling the simulation time doesnâ€™t help much
(cf. purple arrows). Inset: Trotter replicas overlaps qab1 (same data as for the main figure). The theoretical
prediction is in remarkably good agreement with the average value measured from the simulations (the
y = 128 curve is barely visible under the y = 256 one). The gray curves show the overlaps at varying
distances along the Trotter dimension: the topmost one is the overlap between neighboring replicas qa(a+1)1 ,
then there is the overlap between second-neighbors qa(a+2)1 and so on (cf. Fig. 1). The y = 128 curves
are essentially hidden under the y = 256 ones and can only be seen from their darker shade, following an
alternating pattern.
8
0
0.005
0.01
0.015
0.02
0.025
0 0.005 0.01 0.015 0.02
en
er
gy
 d
en
si
ty
 d
iff
. f
ro
m
 re
fe
re
nc
e 
Î”E
/N
distance ğ‘‘
â–µ
0
0.002
0.004
0.006
0.008
0.01
0.012
0.014
0 0.005 0.01 0.015 0.02
distance ğ‘‘
â‹†
0
0.02
0.04
0.06
0.08
0.1
0 0.01 0.02 0.03 0.04 0.05
lo
ca
l e
nt
ro
py
 fr
om
 re
fe
re
nc
e
distance ğ‘‘
â–µ
a b c
Figure 3. Panels a and b: energetic profiles (in terms of the classical energy E, Eq. (1)) around the
configurations reached during the annealing process, comparing QA (orange lower curves) with SA (gray
top curves). The profiles represent the most probable value of the energy density shift âˆ†E/N with respect
to the reference point when moving away from the reference at a given normalized Hamming distance d.
The curves refer to the data shown in Fig. 2, using two different times in the annealing process, marked
with the symbols M and ? in both figures. For QA, we show the results for 15 instances with N = 4001,
y = 256, Ï„ = 4, using the mode of the replicas Ïƒ?j = sgn
(âˆ‘y
a=1 Ïƒ
a
j
)
as the reference point; for SA, we show
15 samples for N = 4001 and Ï„ = 16. These results show a marked qualitative difference in the type of
landscape that is typically explored by the two algorithms: the local landscape of QA is generally much
wider, while SA is typically working inside narrow regions of the landscape which tend to trap the algorithm
eventually. Panel c: local entropy, i.e. the logarithm of the number of solutions surrounding the reference
point at a given distance d for the same configurations of panel a. The QA configurations (orange curves at
the top) are located in regions with exponentially many solutions surrounding them (although these regions
are not maximally dense, as can be seen from the comparison with the dashed curve representing the overall
number of surrounding configurations at that distance). The SA configurations (gray curves at the bottom)
are far away from these exponentially dense regions (the local entropy has a gap around d = 0).
efficiently whereas SA cannot, i.e. our notion of quantum speed up is relative to the same algorithmic
scheme that runs on classical hardware. Other classical algorithms for the same class of problems,
besides the above-mentioned ones based on the RE, have been discovered [25, 36â€“39]; however,
all of these algorithms are qualitatively different from QA, which can provide a huge speed up
by manipulating single physical bits. Our results provide further evidence that learning can be
achieved through different types of correlated fluctuations, among which quantum tunneling could
be a relevant example for physical devices.
ACKNOWLEDGMENTS
The authors thank G. Santoro and B. Kappen for discussions.
9
Appendix A: Theoretical analysis by the replica method
We present here the analytical calculations performed to derive all the theoretical results men-
tioned in the main text. For completeness, we report all the relevant formulas and definitions here,
even those that were already introduced in the main text.
The Hamiltonian operator of a model of N quantum spins with an energy term acting in the
longitudinal direction z and a magnetic field Î“ acting in the transverse direction x is written as:
HÌ‚ = E
({
ÏƒÌ‚zj
}
j
)
âˆ’ Î“
Nâˆ‘
j=1
ÏƒÌ‚xj (A1)
where ÏƒÌ‚zj and ÏƒÌ‚j
x are the spin operators (Pauli matrices) in the z and x directions. We want to
study the partition function:
Z = Tr
(
eâˆ’Î²HÌ‚
)
. (A2)
By using the Suzuki-Trotter transformation, we end up with a classical effective Hamiltonian
acting on a system of y interacting Trotter replicas, to be studied in the limit y â†’âˆ:
Heff
({
Ïƒaj
}
j,a
)
=
1
y
âˆ‘
a
E
({
Ïƒaj
}
j
)
âˆ’ Î³
Î²
âˆ‘
aj
Ïƒaj Ïƒ
a+1
j âˆ’
NK
Î²
(A3)
where the Ïƒaj = Â±1 are Ising spins, a âˆˆ {1, . . . , y} is a replica index with periodic boundary
conditions Ïƒy+1j â‰¡ Ïƒ1j , and we have defined:
Î³ =
1
2
log coth
(
Î²Î“
y
)
, (A4)
K =
1
2
y log
(
1
2
sinh
(
2
Î²Î“
y
))
. (A5)
In the following, we will just use Ïƒa to denote the configuration of one Trotter replica,
{
Ïƒaj
}
j
; we
will always use the indices a or b for the Trotter replicas and assume that they range in 1, . . . , y;
we will also use j for the site index and assume that it ranges in 1, . . . , N .
The effective partition function for a given y reads:
Zeff =
âˆ‘
{Ïƒa}
eâˆ’
Î²
y
âˆ‘
a E(Ïƒ
a)+Î³
âˆ‘
aj Ïƒ
a
j Ïƒ
a+1
j +NK . (A6)
Here, we first study the binary perceptron case in which the longitudinal energy E is defined in
terms of a set of Î±N patterns {Î¾Âµ}Âµ with Âµ âˆˆ {1, . . . , Î±N}, where each pattern is a binary vector
of length N , Î¾Âµj = Â±1:
E (Ïƒ) =
Î±Nâˆ‘
Âµ=1
Î˜
ï£«ï£­âˆ’ 1âˆš
N
âˆ‘
j
Î¾Âµj Ïƒj
ï£¶ï£¸ (A7)
where Î˜ (x) is the Heaviside step function: Î˜ (x) = 1 if x > 0, Î˜ (x) = 0 otherwise. The energy
thus simply counts the number of classification errors of the perceptron, assuming that the desired
output for each pattern in the set is 1. A different form for the energy function is treated in sec. A 1.
10
We consider the case in which the patterns entries are extracted randomly and independently
from an unbiased distribution, P
(
Î¾Âµj
)
= 12Î´
(
Î¾Âµj âˆ’ 1
)
+ 12Î´
(
Î¾Âµj + 1
)
, and we want to study the typical
properties of this system by averaging over the quenched disorder introduced by the patterns. We
use the replica method, which exploits the transformation:
ã€ˆlogZã€‰Î¾ = limnâ†’0
ã€ˆZnã€‰Î¾ âˆ’ 1
n
= lim
nâ†’0
ã€ˆ
âˆn
c=1 Zã€‰Î¾ âˆ’ 1
n
(A8)
where ã€ˆÂ·ã€‰Î¾ denotes the average over the disorder. We thus need to replicate the whole system n
times, and therefore we have two replica indices for each spin. We will use indices c, d = 1, . . . , n
for the â€œvirtualâ€ replicas introduced by the replica method,1 to distinguish them from the indices
a and b used for the Trotter replicas. The average replicated partition function of eq. (A6) is thus
written as:
ã€ˆZneffã€‰Î¾ = e
nNK
âŒ©âˆ« âˆ
caj
dÂµ
(
Ïƒcaj
)âˆ
caj
eÎ³Ïƒ
c
jÏƒ
c(a+1)
j
âˆ
Âµca
ï£«ï£­Î˜
ï£®ï£° 1âˆš
N
âˆ‘
j
Î¾Âµj Ïƒ
ca
j
ï£¹ï£»(1âˆ’ eâˆ’ Î²y )+ eâˆ’ Î²y
ï£¶ï£¸âŒª
Î¾
(A9)
where we changed the sum over all configurations into an (nÃ—yÃ—N -dimensional) integral, using the
customary notation dÂµ (Ïƒ) = Î´ (Ïƒ âˆ’ 1) + Î´ (Ïƒ + 1) with Î´ (Â·) denoting the Dirac-delta distribution.
Here and in the following, all integrals will be assumed to range over the whole R unless otherwise
specified.
We introduce new auxiliary variables Î»caÂµ =
1âˆš
N
âˆ‘
j Î¾
Âµ
j Ïƒ
ca
j via additional Dirac-deltas:
ã€ˆZneffã€‰Î¾ = e
nNK
âˆ« âˆ
caj
dÂµ
(
Ïƒcaj
)âˆ
caj
eÎ³Ïƒ
ca
j Ïƒ
c(a+1)
j
âˆ« âˆ
Âµca
dÎ»caÂµ
âˆ
Âµca
(
Î˜
[
Î»caÂµ
] (
1âˆ’ eâˆ’
Î²
y
)
+ eâˆ’
Î²
y
)
Ã—
Ã—
âŒ©âˆ
Âµca
Î´
ï£«ï£­Î»caÂµ âˆ’ 1âˆš
N
âˆ‘
j
Î¾Âµj Ïƒ
ca
j
ï£¶ï£¸âŒª
Î¾
(A10)
We then use the integral representation of the delta Î´ (x) =
âˆ«
dxÌ‚
2Ï€ e
ixxÌ‚, and perform the average
over the disorder, to the leading order in N :âŒ©âˆ
Âµca
Î´
ï£«ï£­Î»caÂµ âˆ’ 1âˆš
N
âˆ‘
j
Î¾Âµj Ïƒ
ca
j
ï£¶ï£¸âŒª
Î¾
=
âˆ« âˆ
Âµca
dÎ»Ì‚caÂµ
2Ï€
âˆ
Âµca
eiÎ»Ì‚
ca
Âµ Î»
ca
Âµ
âˆ
Âµ
exp
ï£«ï£­âˆ’1
2
âˆ‘
cdab
Î»Ì‚caÂµ Î»Ì‚
db
Âµ
ï£«ï£­ 1
N
âˆ‘
j
Ïƒcaj Ïƒ
db
j
ï£¶ï£¸ï£¶ï£¸ (A11)
Next, we introduce the overlaps qca,db = 1N
âˆ‘
j Ïƒ
ca
j Ïƒ
db
j via Dirac-deltas (note that due to sym-
metries and the fact that the self-overlaps are always 1 we have ny (ny âˆ’ 1) /2 overlaps overall),
1 Note that the parameter n has a different meaning in main text, cf. sec. A 1.
11
expand those deltas introducing conjugate parameters qÌ‚ca,db (as usual for these parameters in these
models, we absorb away a factor i and integrate them along the imaginary axis, without explicitly
noting this), and finally factorize over the site and pattern indices:
ã€ˆZneffã€‰Î¾ = e
nNK
âˆ« âˆ
c,a>b
dqca,cbdqÌ‚ca,cbN
2Ï€
âˆ
c>d,ab
dqca,dbdqÌ‚ca,dbN
2Ï€
Ã—
Ã—eâˆ’N
âˆ‘
c,a>b q
ca,cbqÌ‚ca,cbâˆ’N
âˆ‘
c>d,ab q
ca,dbqÌ‚ca,db Ã—GNS Ã—GÎ±NE (A12)
GS
.
=
âˆ« âˆ
ca
dÂµ (Ïƒca) e
âˆ‘
c,a>b qÌ‚
ca,cbÏƒcaÏƒcb+
âˆ‘
c>d,ab qÌ‚
ca,dbÏƒcaÏƒdb+Î³
âˆ‘
ca Ïƒ
caÏƒc(a+1) (A13)
GE
.
=
âˆ« âˆ
ca
dÎ»cadÎ»Ì‚ca
2Ï€
âˆ
ca
(
Î˜ [Î»ca]
(
1âˆ’ eâˆ’
Î²
y
)
+ eâˆ’
Î²
y
)
Ã— (A14)
Ã—eâˆ’
1
2
âˆ‘
ca(Î»Ì‚
ca)
2
+i
âˆ‘
ca Î»
caÎ»Ì‚caâˆ’
âˆ‘
c,a>b Î»Ì‚
caÎ»Ì‚cbqca,cbâˆ’
âˆ‘
c>d,ab Î»Ì‚
caÎ»Ì‚dbqca,db
We now introduce the replica-symmetric (RS) ansatz for the overlaps:
qca,db =
{
q1 if c = d
q0 if c 6= d
(A15)
and analogous for the conjugate parameters qÌ‚ca,db.
Note that this is the so-called â€œstatic approximationâ€ since we neglect the dependency of the
overlap from the distance along the Trotter dimension; however, we have kept the interaction
term Î³
âˆ‘
ca Ïƒ
caÏƒc(a+1) and inserted it in the GS term (rather than writing it in terms of the overlap
qca,c(a+1) and inserting it in theGE term where it would have been rewritten as Î³q1). This difference,
despite its inconsistency, is the standard procedure when performing the static approximation, and
is justified a posteriori from the comparison with the numerical simulation results. We obtain:
ã€ˆZneffã€‰Î¾ = e
nNK
âˆ« âˆ
c,a>b
dqca,cbdqÌ‚ca,cbN
2Ï€
âˆ
c>d,ab
dqca,dbdqÌ‚ca,dbN
2Ï€
Ã—
Ã—eâˆ’Nn
y(yâˆ’1)
2 q1qÌ‚1âˆ’N
n(nâˆ’1)
2 y
2q0qÌ‚0 Ã—GNS Ã—GÎ±NE (A16)
GS =
âˆ« âˆ
ca
dÂµ (Ïƒca) eqÌ‚1
âˆ‘
c,a>b Ïƒ
caÏƒcb+qÌ‚0
âˆ‘
c>d,ab Ïƒ
caÏƒdb+Î³
âˆ‘
ca Ïƒ
caÏƒc(a+1) (A17)
GE =
âˆ« âˆ
ca
dÎ»cadÎ»Ì‚ca
2Ï€
âˆ
ca
(
Î˜ [Î»ca]
(
1âˆ’ eâˆ’
Î²
y
)
+ eâˆ’
Î²
y
)
Ã— (A18)
Ã—eâˆ’
1
2
âˆ‘
ca(Î»Ì‚
ca)
2
+i
âˆ‘
ca Î»
caÎ»Ì‚caâˆ’q1
âˆ‘
c,a>b Î»Ì‚
caÎ»Ì‚cbâˆ’q0
âˆ‘
c>d,ab Î»Ì‚
caÎ»Ì‚db
12
The entropic term GS can be explicitly computed as
GS =
âˆ« âˆ
ca
dÂµ (Ïƒca) e
1
2 qÌ‚1
âˆ‘
c
(
(
âˆ‘
a Ïƒ
ca)
2âˆ’
âˆ‘
a(Ïƒ
ca)2
)
+ 12 qÌ‚0
(
(
âˆ‘
ca Ïƒ
ca)
2âˆ’
âˆ‘
c(
âˆ‘
a Ïƒ
ca)
2
)
Ã—eÎ³
âˆ‘
ca Ïƒ
caÏƒc(a+1)
= eâˆ’
1
2 qÌ‚1ny
âˆ« âˆ
ca
dÂµ (Ïƒca) e
1
2 (qÌ‚1âˆ’qÌ‚0)
âˆ‘
c(
âˆ‘
a Ïƒ
ca)
2
+ 12 qÌ‚0(
âˆ‘
ca Ïƒ
ca)
2
+Î³
âˆ‘
ca Ïƒ
caÏƒc(a+1)
=
âˆ«
Dz0 e
âˆ’ 12 qÌ‚1ny
[âˆ« âˆ
a
dÂµ (Ïƒa) e
1
2 (qÌ‚1âˆ’qÌ‚0)(
âˆ‘
a Ïƒ
a)
2
+z0
âˆš
qÌ‚0(
âˆ‘
a Ïƒ
a)+Î³
âˆ‘
a Ïƒ
aÏƒa+1
]n
=
âˆ«
Dz0 e
âˆ’ 12 qÌ‚1ny
[âˆ«
Dz1
âˆ« âˆ
a
dÂµ (Ïƒa) e(z1
âˆš
qÌ‚1âˆ’qÌ‚0+z0
âˆš
qÌ‚0)(
âˆ‘
a Ïƒ
a)+Î³
âˆ‘
a Ïƒ
aÏƒa+1
]n
(A19)
where the notation Dz = dz 1âˆš
2Ï€
eâˆ’
x2
2 is a shorthand for a Gaussian integral, and we used twice the
Hubbard-Stratonovich transformation e
1
2 b =
âˆ«
Dz ez
âˆš
b. The expression between square brackets
in the last line is the partition function of a 1-dimensional Ising model of size y with uniform
interactions J = Î³ and uniform fields h = z1
âˆš
qÌ‚1 âˆ’ qÌ‚0 + z0
âˆš
qÌ‚0 and can be computed by the well-
known transfer matrix method. Note however that while usually in the analysis of the 1D Ising spin
model it is sufficient to keep the largest eigenvalue of the transfer matrix in the thermodynamic
limit y â†’âˆ, in this case instead we need to keep both eigenvalues, since the interaction term scales
with the size of the system. The result is:
GS =
âˆ«
Dz0 e
âˆ’ 12 qÌ‚1ny
[âˆ«
Dz1e
Î³y
âˆ‘
w=Â±1
g (z0, z1, w)
y
]n
(A20)
g (z0,z1, w)
.
= cosh (h (z0, z1)) + w
âˆš
sinh (h (z0, z1))
2
+ eâˆ’4Î³ (A21)
h (z0, z1)
.
= z1
âˆš
qÌ‚1 âˆ’ qÌ‚0 + z0
âˆš
qÌ‚0 (A22)
In the limit of small n we obtain:
GS
.
=
1
n
logGS +
1
2
qÌ‚1y âˆ’ Î³y
=
âˆ«
Dz0 log
[âˆ«
Dz1
âˆ‘
w=Â±1
(
cosh (h (z0, z1)) + w
âˆš
sinh (h (z0, z1))
2
+ eâˆ’4Î³
)y]
(A23)
Note that in the limit of large y the term Î³y tends toâˆ’K up to terms of order yâˆ’1.
The energetic term GE is computed similarly, by first performing two Hubbard-Stratonovich
transformations which allow to factorize the indices c and a, and then explicitly performing the
13
inner integrals:
GE =
âˆ« âˆ
ca
dÎ»cadÎ»Ì‚ca
2Ï€
âˆ
ca
(
Î˜ [Î»ca]
(
1âˆ’ eâˆ’
Î²
y
)
+ eâˆ’
Î²
y
)
Ã—
Ã—eâˆ’
1
2
âˆ‘
ca(Î»Ì‚
ca)
2
+i
âˆ‘
ca Î»
caÎ»Ì‚caâˆ’ 12 q1
âˆ‘
c
(
(
âˆ‘
a Î»Ì‚
ca)
2âˆ’
âˆ‘
a(Î»Ì‚
ca)
2
)
âˆ’ 12 q0
(
(
âˆ‘
ca Î»Ì‚
ca)
2âˆ’
âˆ‘
c(
âˆ‘
a Î»Ì‚
ca)
2
)
=
âˆ«
Dz0
[âˆ«
Dz1
[âˆ«
dÎ»dÎ»Ì‚
2Ï€
(
Î˜ [Î»]
(
1âˆ’ eâˆ’
Î²
y
)
+ eâˆ’
Î²
y
)
eâˆ’
1âˆ’q1
2 (Î»Ì‚)
2
+iÎ»Ì‚(Î»âˆ’z1
âˆš
q1âˆ’q0âˆ’z0
âˆš
q0)
]y]n
=
âˆ«
Dz0
[âˆ«
Dz1
(
eâˆ’Î²
[
1 +
(
e
Î²
y âˆ’ 1
)
H
(
z1
âˆš
q1 âˆ’ q0 + z0
âˆš
q0âˆš
1âˆ’ q1
)]y)]n
(A24)
where H (x) = 12erfc
(
xâˆš
2
)
. In the limit of small n and of large y we finally obtain:
GE
.
=
1
n
logGE =
âˆ«
Dz0 log
âˆ«
Dz1 exp
(
âˆ’Î²H
(
z1
âˆš
q1 âˆ’ q0 + z0
âˆš
q0âˆš
1âˆ’ q1
))
(A25)
Using equations (A23) and (A25), we obtain the expression for the action:
Ï†
.
=
1
N
ã€ˆlogZeffã€‰ = extrq0,q1,qÌ‚0,qÌ‚1
{
1
2
y2q0qÌ‚0 âˆ’
1
2
y (y âˆ’ 1) q1qÌ‚1 âˆ’
1
2
qÌ‚1y + GS + Î±GE
}
(A26)
In order to obtain a finite result in the limit of y â†’âˆ, we assume the following scalings for the
conjugated order parameters:
qÌ‚0 =
pÌ‚0
y2
(A27)
qÌ‚1 =
pÌ‚1
y2
(A28)
With these, we find the following final expressions:
Ï† = extrq0,q1,pÌ‚0,pÌ‚1
{
1
2
q0pÌ‚0 âˆ’
1
2
q1pÌ‚1 + GS + Î±GE
}
(A29)
GS =
âˆ«
Dz0 log
[âˆ«
Dz1 2 cosh
(âˆš
kÌ‚ (z0, z1)
2
+ Î²2Î“2
)]
(A30)
kÌ‚ (z0, z1) = z1
âˆš
pÌ‚1 âˆ’ pÌ‚0 + z0
âˆš
pÌ‚0 (A31)
GE =
âˆ«
Dz0 log
âˆ«
Dz1 exp (âˆ’Î²H (k (z0, z1))) (A32)
k (z0, z1) =
z1
âˆš
q1 âˆ’ q0 + z0
âˆš
q0âˆš
1âˆ’ q1
(A33)
The parameters q0, q1, pÌ‚0 and pÌ‚1 are found by solving the system of equations obtained by setting
14
the partial derivatives of Ï† with respect to those parameters to 0:
pÌ‚0 =
Î±Î²âˆš
1âˆ’ q1
âˆ«
Dz0
âˆ«
Dz1e
âˆ’Î²H(k(z0,z1))G (k (z0, z1))
(
z1âˆš
q1âˆ’q0
âˆ’ z0âˆšq0
)
âˆ«
Dz1eâˆ’Î²H(k(z0,z1))
(A34)
pÌ‚1 =
Î±Î²âˆš
(1âˆ’ q1)3 (q1 âˆ’ q0)
Ã— (A35)
Ã—
âˆ«
Dz0
âˆ«
Dz1e
âˆ’Î²H(k(z0,z1))G (k (z0, z1))
(
z0
âˆš
q0 (q1 âˆ’ q0) + z1 (1âˆ’ q0)
)
âˆ«
Dz1eâˆ’Î²H(k(z0,z1))
q0 =
1âˆš
kÌ‚ (z0, z1)
2
+ Î²2Î“2
Ã— (A36)
Ã—
âˆ«
Dz0
âˆ«
Dz1 sinh
(âˆš
kÌ‚ (z0, z1)
2
+ Î²2Î“2
)
kÌ‚ (z0, z1)
(
z1âˆš
pÌ‚1âˆ’pÌ‚0
âˆ’ z0âˆš
pÌ‚0
)
âˆ«
Dz1 cosh
(âˆš
kÌ‚ (z0, z1)
2
+ Î²2Î“2
)
q1 =
1âˆš
kÌ‚ (z0, z1)
2
+ Î²2Î“2
Ã— (A37)
Ã—
âˆ«
Dz0
âˆ«
Dz1 sinh
(âˆš
kÌ‚ (z0, z1)
2
+ Î²2Î“2
)
kÌ‚ (z0, z1)
(
z1âˆš
pÌ‚1âˆ’pÌ‚0
)
âˆ«
Dz1 cosh
(âˆš
kÌ‚ (z0, z1)
2
+ Î²2Î“2
)
Once these are found, we can use them to compute the action Ï† and the average values of the
longitudinal energy and the transverse fields, and finally of the Hamiltonian:
âŒ©
HÌ‚
âŒª
Î¾
= N
(
EÌ„ âˆ’ Î“TÌ„
)
(A38)
EÌ„ =
1
N
ã€ˆE ({ÏƒÌ‚z})ã€‰Î¾ = âˆ’
âˆ‚Ï†
âˆ‚Î²
= Î±
âˆ«
Dz0
âˆ«
Dz1e
âˆ’Î²H(k(z0,z1))H (k (z0, z1))âˆ«
Dz1eâˆ’Î²H(k(z0,z1))
(A39)
TÌ„ =
1
N
âŒ©
ÏƒÌ‚xj
âŒª
=
âˆ‚Ï†
âˆ‚ (Î²Î“)
=
âˆ«
Dz0
âˆ«
Dz1
Î²Î“ sinh
(âˆš
kÌ‚(z0,z1)
2+Î²2Î“2
)
âˆš
kÌ‚(z0,z1)
2+Î²2Î“2âˆ«
Dz1 cosh
(âˆš
kÌ‚ (z0, z1)
2
+ Î²2Î“2
) (A40)
where the notation ã€ˆÂ·ã€‰Î¾ denotes the fact that we performed both the average over the quenched
disorder and the thermal average.
15
a. Small Î“ limit
It can be verified that in the limit Î“â†’ 0 the equations (A29)-(A33) reduce to the classical case,
in the RS description. In this limit, q1 â†’ 1 (i.e., the Trotter replicas collapse), which leads to:
GE =
âˆ«
Dz0 log
((
1âˆ’ eâˆ’Î²
)
H
(
z0
âˆš
q0
1âˆ’ q0
)
+ eâˆ’Î²
)
. (A41)
For Î“ = 0 and q1 = 1 we also have the identity:2
âˆ’ 1
2
pÌ‚1q1 + GS = âˆ’
1
2
pÌ‚0 +
âˆ«
Dz0 log 2 cosh
(
z0
âˆš
pÌ‚0
)
. (A42)
Putting these two expressions back in eq. (A29) we recover the classical expression where pÌ‚0
assumes the role of the usual conjugate parameter qÌ‚ in the RS analysis of ref. [23].
In order to study in detail how this classical limit is reached, however, we need to expand the
saddle point equations around this limit. To to this, we define  = 1âˆ’q1  1. From equation (A35),
expanding to the leading order, we obtain the scaling pÌ‚1 = cÌ‚1âˆš , with
cÌ‚1 =
ï£®ï£¯ï£° 1âˆš
1âˆ’ q0
âˆ«
Dz0
G
(
z0
âˆš
q0
1âˆ’q0
)
eâˆ’Î² + (1âˆ’ eâˆ’Î²)H
(
z0
âˆš
q0
1âˆ’q0
)
ï£¹ï£ºï£»[âˆ« Dz1 exp (âˆ’Î²H (z1)) z1] . (A43)
Then, we use this scaling in equation (A37) and we expand it, first using Î²Î“ 1 and then  1.
We obtain the approximate expression:
 =
Î²2Î“2
2
âˆ’
âˆš
cÌ‚1+
âˆš
2 (cÌ‚1 +
âˆš
) 1/4F
(
1âˆš
2
âˆš
cÌ‚1âˆš

)
cÌ‚
3/2
1
(A44)
where F (x) =
âˆš
Ï€
2 e
âˆ’x2erfi (x) is the Dawsonâ€™s function. For a given Î² (from which we obtain cÌ‚1 via
eq. (A43)), this equation can be solved numerically to obtain  (and thus q1 and pÌ‚1) as a function
of Î“. This expression has always the solution  = 0, which correspond to the purely classical case.
There is a critical Î“ below which  = 0 is also the only solution; above that, two additional solutions
appear at  > 0, of which the largest is the physical one. Therefore, the classical limit is not achieved
continuously, but rather with a first-order transition (although the step is tiny).
1. Energy function with stability
We can generalize the energy function eq. (A7) to take into account, for those patterns that are
misclassified, by how much the classification is wrong:
E (Ïƒ) =
Î±Nâˆ‘
Âµ=1
Î˜
ï£«ï£­âˆ’ 1âˆš
N
âˆ‘
j
Î¾Âµj Ïƒj
ï£¶ï£¸ï£«ï£­âˆ’ 1âˆš
N
âˆ‘
j
Î¾Âµj Ïƒj
ï£¶ï£¸r . (A45)
2 This follows from
âˆ«
Dz1 cosh (a z1 + b z0) = e
a2
2 cosh (b z0).
16
The previous case is recovered by setting r = 0. Here, we study the case r = 1. Note that this
parameter is called n in the main text: that notation was borrowed from ref. [32], but here we
change it in order to avoid confusion with the number of replicas. While the ground states in the
SAT phase of the classical model are unaffected, the system can have different properties for finite
Î².
This change only affects the GE term. Equation (A24) becomes (with the definition of eq. (A33)):
GE =
âˆ«
Dz0
[âˆ«
Dz1
[
e
Î²
y
âˆš
1âˆ’q1(k(z0,z1)+ 12
Î²
y
âˆš
1âˆ’q1)H
(
k (z0, z1) +
Î²
y
âˆš
1âˆ’ q1
)
+
+H (âˆ’k (z0, z1))
]y]n
. (A46)
In the limit of large y we have the modified version of eq. (A25):
GE =
1
n
logGE =
âˆ«
Dz0 log
âˆ«
Dz1 exp
(
âˆ’Î²
âˆš
1âˆ’ q1 [G (k (z0, z1))âˆ’ k (z0, z1)H (k (z0, z1))]
)
(A47)
The saddle point equations (A34) and (A35) become:
pÌ‚0 = âˆ’Î±Î²
âˆ«
Dz0
âˆ«
Dz1 exp
(
âˆ’Î²
âˆš
1âˆ’ q1A (z0, z1)
)
H (k (z0, z1))
(
z1âˆš
q1âˆ’q0
âˆ’ z0âˆšq0
)
âˆ«
Dz1 exp
(
Î²
âˆš
1âˆ’ q1A (z0, z1)
) (A48)
pÌ‚1 = Î±Î²
2
âˆ«
Dz0
âˆ«
Dz1 exp
(
âˆ’Î²
âˆš
1âˆ’ q1A (z0, z1)
)
H (k (z0, z1))
2âˆ«
Dz1 exp
(
Î²
âˆš
1âˆ’ q1A (z0, z1)
) (A49)
where
A (z0, z1) = G (k (z0, z1))âˆ’ k (z0, z1)H (k (z0, z1)) .
a. Small Î“ limit
As in the previous case, it can be checked that for Î“â†’ 0, we have q1 â†’ 1 and eq. (A47) becomes
the expression for the classical model under the RS ansatz:
GE =
âˆ«
Dz0 log
(
eÎ²
âˆš
1âˆ’q0(k0(z0)+ 12Î²
âˆš
1âˆ’q0)H
(
k0 (z0) + Î²
âˆš
1âˆ’ q0
)
+H (âˆ’k0 (z0))
)
(A50)
where k0 (z0) = z0
âˆš
q0
1âˆ’q0 . Also, eq. (A42) still holds, and pÌ‚0 takes the role of the usual parameter
qÌ‚ in the classical RS analysis. In this case, however, we no longer have pÌ‚1 â†’âˆ; rather, it tends to
a finite value:
pÌ‚1 = Î±Î²
2
âˆ«
Dz0
(
1âˆ’ H (âˆ’k0 (z0))
eÎ²
âˆš
1âˆ’q0(k0(z0)+ 12Î²
âˆš
1âˆ’q0)H
(
k0 (z0) + Î²
âˆš
1âˆ’ q0
)
+H (âˆ’k0 (z0))
)
(A51)
Therefore, the scaling of  = 1 âˆ’ q1 is different in this case. We find (using the definition of
eq. (A31)):
1âˆ’ q1 = Î²2Î“2
âˆ«
Dz0
eâˆ’
pÌ‚1âˆ’pÌ‚0
2
cosh
(
z0
âˆš
pÌ‚0
) âˆ« Dz1 1
kÌ‚ (z0, z1)
2
ï£«ï£­cosh(kÌ‚ (z0, z1))âˆ’ sinh
(
kÌ‚ (z0, z1)
)
kÌ‚ (z0, z1)
ï£¶ï£¸
(A52)
17
Therefore, the convergence to the classical case is smooth.
Appendix B: Estimation of the local energy and entropy landscapes with the cavity method
In order to compute the local landscapes of the energy and the entropy around a reference
configuration (Fig. 3), we used the Belief Propagation (BP) algorithm, a cavity method message-
passing algorithm that has been successfully employed numerous times for the study of disordered
systems [40]. In the case of single-layer binary perceptrons trained on random unbiased i.i.d.
patterns, it is believed that the results of this algorithm are exact in the limit of N â†’âˆ, at least
up to the critical value Î±c â‰ˆ 0.83 [41].
For a full explanation of the BP equations for binary perceptrons, we refer the interested reader
to the Appendix of ref. [21]. Here, we provide only a summary. The BP equations involve two
sets of quantities (called â€œmessagesâ€), representing cavity marginal probabilities associated with
each edge in a factor graph representation of the (classical) Boltzmann distribution induced by the
energy function (A7). To each edge in the graph linking the variable node i with the factor node
Âµ, are associated two messages, miâ†’Âµ and mÌ‚Âµâ†’i. These are determined by solving iteratively the
following system of equations:
miâ†’Âµ = tanh
ï£«ï£­âˆ‘
Î½ 6=Âµ
tanhâˆ’1 (mÌ‚Î½â†’i)
ï£¶ï£¸ (B1)
mÌ‚Âµâ†’i = Î¾i g (aÂµâ†’i, bÂµâ†’i) (B2)
where:
g (a, b) =
H
(
aâˆ’1
b
)
âˆ’H
(
a+1
b
)
H
(
aâˆ’1
b
)
+H
(
a+1
b
) (B3)
aÂµâ†’i =
âˆ‘
j 6=i
Î¾Âµjmjâ†’Âµ (B4)
bÂµâ†’i =
âˆšâˆ‘
j 6=i
(
1âˆ’m2jâ†’Âµ
)
(B5)
(as for the previous section, we used the definition H (x) = 12erfc
(
xâˆš
2
)
.)
Once a self-consistent solution is found, these quantities can be used to compute, using standard
formulas, all thermodynamic quantities of interest, in particular the typical (equilibrium) energy and
the entropy of the system. A numerically accurate implementation of these equations is available
at ref. [42].
It is also possible to compute those same thermodynamic quantities in a neighborhood of some
arbitrary reference configuration w = {wi}i. This is achieved by adding an external field in the
direction of that configuration, which amounts at this simple modification of eq. (B1):
miâ†’Âµ = tanh
ï£«ï£­âˆ‘
Î½ 6=Âµ
tanhâˆ’1 (mÌ‚Î½â†’i) + Î»wi
ï£¶ï£¸ (B6)
By varying the auxiliary parameter Î», we can control the size of the neighborhood under consider-
ation (the larger Î», the narrower the neighborhood); the typical normalized Hamming distance from
18
the reference of the configurations that are considered by this modified measure can be obtained
from the fixed-point BP messages for any given Î» by this formula:
d =
1
2
(
1âˆ’ 1
N
âˆ‘
i
miwi
)
(B7)
where the mi are the total magnetizations:
mi = tanh
(âˆ‘
Î½
tanhâˆ’1 (mÌ‚Î½â†’i) + Î»wi
)
(B8)
In order to produce the energy landscape plots of Figs. 3a and 3b, we simply ran this algorithm at
infinite temperature, varying Î» and plotting the energy density shift from the center as a function
of d. This gives us an estimate of the most probable energy density shift which would be obtained
by moving in a random point at distance d from the reference.
The plot in Fig. 3c was similarly obtained by setting the temperature to 0 and computing the
entropy density instead, which in this context is then simply the natural logarithm of the number
of solutions in the given neighborhood, divided by N .
Appendix C: Numerical simulations details
1. Quantum annealing protocol
In this section we provide the details of the QA results presented in Fig. 2. The simulations
were performed using the RRR Monte Carlo method [33]. We fixed the total number of spin flip
attempts at Ï„Ny Â· 104 and followed a linear protocol (divided in 30Ï„ steps) for the annealing of Î“.
In the figure, we have shown the results for N = 4001 and Ï„ = 4; the results for N = 1001, 2001
and for Ï„ = 1, 2 were essentially indistinguishable at that level of detail.
2. Classical simulated annealing protocol
The results for SA presented in Fig. 2 used an annealing protocol in Î² designed to make a direct
comparison to QA: we found analytically a curve Î²equiv (Î“) such that the classical equilibrium
energy would be equal to the longitudinal component of the quantum system energy, eq. (A39).
The classical equilibrium energy was computed from the equations in ref. [23]. The result is shown
in Fig. 4. The vertical jump to Î² = 20 is due to the transition mentioned in sec. A 0 a; as shown in
Fig. 2, the SA protocol in the regime we tested gets stuck well before this transition.
The SA annealing protocol thus consisted in setting Î² = Î²equiv (Î“) and decreasing linearly Î“ from
2.5 to 0, like for the QA case. We fixed the total number of spin flip attempts at Ï„N Â· 104 and used
Ï„ = 4, 8, 16; as for the QA case, the annealing process was divided in 30Ï„ steps.
Other more standard annealing protocols (e.g. linear or exponential or logarithmic) yielded very
similar qualitative results, as expected from the analysis of ref. [32].
19
0
2
4
6
8
10
12
14
16
18
20
0 0.5 1 1.5 2 2.5
eq
ui
va
le
nt
 in
ve
rs
e 
te
m
pe
ra
tu
re
 ğ›½
transverse field ğ›¤
Figure 4. The curve Î²equiv (Î“) for Î± = 0.4 corresponding to a quantum system at Î² = 20.
-2.5
-2
-1.5
-1
-0.5
0
0 0.5 1 1.5 2 2.5
av
er
ag
e 
ha
m
ilt
on
ia
n 
de
ns
ity
 âŸ¨ğ»
âŸ©/ğ‘
transverse field ğ›¤
ğ‘¦=64
ğ‘¦=128
ğ‘¦=256
theory
Figure 5. Comparison between theory and simulations for the average of the Hamiltonian density, eq. (A38)
divided by N . Same data as Fig. 2. The numerical curves are very close to the theoretical one at this level
of detail. A close inspection reveals that the agreement improves with increasing y.
Appendix D: Additional numerical results
1. Quantum Hamiltonian expectation, comparisons between theory and simulations
Fig. 2 compares the result of Monte Carlo simulations with the theoretical predictions for the
classical component of the energy, eq. (A39), and the transverse overlap, eq. (A37). Fig. 5 shows the
comparison for the expectation of the full quantum Hamiltonian, eq. (A38), using the same data.
The agreement is remarkable, and a close inspection reveals that the curves from the simulation
tend towards the theoretical one as y increases, i.e. in the quantum limit.
20
2. Experiments with two-layer networks
We performed additional experiments using two-layer fully-connected binary networks, the so-
called committee machines. Previous results obtained with the robust-ensemble measure [20] showed
that this case is quite similar to that of single layer networks. In particular, standard Simulated
Annealing suffers from an exponential slow-down as the system size increases even moderately, while
algorithms that are able to target the dense states do not suffer from the trapping in meta-stable
states. Indeed, we found the latter feature to be true in the quantum annealing scenario.
The model in this case is defined by a modified energy function (cf. eq. (A7)):
E (Ïƒ) =
Î±Nâˆ‘
Âµ=1
Î˜
ï£«ï£­âˆ’ Kâˆ‘
k=1
sgn
N/Kâˆ‘
j=1
Î¾Âµj Ïƒkj
ï£¶ï£¸ (D1)
where now the N spin variables are divided in groups of K hidden units, and consequently the spin
variables Ïƒkj have two indices, k = 1, . . . ,K for the hidden unit and j = 1, . . . , N/K for the input.
Notice that the input size is reduced N -fold with respect to the previous case. The output of these
machines is simply decided by the majority of the outputs of the individual units, and the energy
still counts the number of errors. The Suzuki-Trotter transformation proceeds in exactly the same
way as for the previous cases.
Like for the single-layer case, we tested the case of Î± = 0.4 at Î² = 20, and we used K = 5
units. We tested different values of N = 1005, 2005, 4005 with different values of the Trotter
replicas y = 32, 64, 128 (only y = 32 for N = 4005) at a fixed overall running time of yNÏ„ Â· 104
spin flip attempts, with Ï„ = 4 (cf. Fig. 2). The MC algorithm and the annealing protocols were
also unchanged. The results are shown in Fig. 6: all these tests produce curves which are almost
indistinguishable at this level of detail for different N , and that seemingly tend to converge to some
limit curve for increasing y (while being almost overlapping at small transverse field Î“), consistently
with the single-layer scenario.
[1] P. W. Shor, in Foundations of Computer Science, 1994 Proceedings., 35th Annual Symposium on (IEEE,
1994) pp. 124â€“134.
[2] P. Ray, B. K. Chakrabarti, and A. Chakrabarti, Physical Review B 39, 11828 (1989).
[3] A. Finnila, M. Gomez, C. Sebenik, C. Stenson, and J. Doll, Chemical physics letters 219, 343 (1994).
[4] T. Kadowaki and H. Nishimori, Physical Review E 58, 5355 (1998).
[5] E. Farhi, J. Goldstone, S. Gutmann, J. Lapan, A. Lundgren, and D. Preda, Science 292, 472 (2001).
[6] A. Das and B. K. Chakrabarti, Reviews of Modern Physics 80, 1061 (2008).
[7] C. Moore and S. Mertens, The nature of computation (Oxford University Press, 2011).
[8] M. Born and V. Fock, Zeitschrift fÃ¼r Physik A Hadrons and Nuclei 51, 165 (1928).
[9] L. Landau, Phys. Z. Sowjetunion 2, 1 (1932).
[10] C. Zener, in Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering
Sciences, Vol. 137 (The Royal Society, 1932) pp. 696â€“702.
[11] V. Bapst, L. Foini, F. Krzakala, G. Semerjian, and F. Zamponi, Physics Reports 523, 127 (2013).
[12] G. E. Santoro, R. MartoÅˆÃ¡k, E. Tosatti, and R. Car, Science 295, 2427 (2002).
[13] R. MartoÅˆÃ¡k, G. E. Santoro, and E. Tosatti, Physical Review B 66, 094203 (2002).
[14] B. Heim, T. F. RÃ¸nnow, S. V. Isakov, and M. Troyer, Science 348, 215 (2015).
[15] T. F. RÃ¸nnow, Z. Wang, J. Job, S. Boixo, S. V. Isakov, D. Wecker, J. M. Martinis, D. A. Lidar, and
M. Troyer, Science 345, 420 (2014).
21
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0 0.5 1 1.5 2 2.5
cl
as
si
ca
l e
ne
rg
y 
de
ns
ity
 ğ¸
/ğ‘
transverse field ğ›¤
ğ‘=1005 ğ‘¦=32
ğ‘=2005 ğ‘¦=32
ğ‘=4005 ğ‘¦=32
ğ‘=1005 ğ‘¦=64
ğ‘=2005 ğ‘¦=64
ğ‘=1005 ğ‘¦=128
ğ‘=2005 ğ‘¦=128
Figure 6. Energy density eq. (D1) as a function of the transverse field Î“ for the two-layer binary committee
machine model with K = 5 at Î± = 0.4 and Î² = 20, with different values of N and y, and using Ï„ = 4 in
the overall running time (number of spin flip attempts) set as yNÏ„ Â· 104. Each curve is averaged over 15
samples.
[16] M. W. Johnson, M. H. Amin, S. Gildert, T. Lanting, F. Hamze, N. Dickson, R. Harris, A. J. Berkley,
J. Johansson, P. Bunyk, et al., Nature 473, 194 (2011).
[17] S. Boixo, T. F. RÃ¸nnow, S. V. Isakov, Z. Wang, D. Wecker, D. A. Lidar, J. M. Martinis, and M. Troyer,
Nature Physics 10, 218 (2014).
[18] W. Langbein, P. Borri, U. Woggon, V. Stavarache, D. Reuter, and A. Wieck, Physical Review B 69,
161301 (2004).
[19] C. Baldassi, A. Ingrosso, C. Lucibello, L. Saglietti, and R. Zecchina, Physical Review Letters 115,
128101 (2015).
[20] C. Baldassi, C. Borgs, J. T. Chayes, A. Ingrosso, C. Lucibello, L. Saglietti, and R. Zecchina, Proceed-
ings of the National Academy of Sciences 113, E7655 (2016).
[21] C. Baldassi, A. Ingrosso, C. Lucibello, L. Saglietti, and R. Zecchina, Journal of Statistical Mechanics:
Theory and Experiment 2016, P023301 (2016).
[22] C. Baldassi, F. Gerace, C. Lucibello, L. Saglietti, and R. Zecchina, Physical Review E 93, 052313
(2016).
[23] W. Krauth and M. MÃ©zard, J. Phys. France 50, 3057 (1989).
[24] H. Sompolinsky, N. Tishby, and H. S. Seung, Physical Review Letters 65, 1683 (1990).
[25] I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and Y. Bengio, arXiv preprint arXiv:1609.07061
(2016).
[26] M. Courbariaux, Y. Bengio, and J.-P. David, in Advances in Neural Information Processing Systems
(2015) pp. 3105â€“3113.
[27] D. J. MacKay, Information theory, inference and learning algorithms (Cambridge university press,
2003).
[28] Y. LeCun, Y. Bengio, and G. Hinton, Nature 521, 436 (2015).
[29] S. Aaronson, Nature Physics 11, 291 (2015).
[30] F. Barahona, Journal of Physics A: Mathematical and General 15, 3241 (1982).
[31] H. Huang and Y. Kabashima, Physical Review E 90, 052813 (2014).
[32] H. Horner, Zeitschrift fÃ¼r Physik B Condensed Matter 86, 291 (1992).
[33] C. Baldassi, Journal of Statistical Mechanics: Theory and Experiment 2017, 033301 (2017).
[34] N. S. Keskar, D. Mudigere, J. Nocedal, M. Smelyanskiy, and P. T. P. Tang, arXiv preprint
22
arXiv:1609.04836 (2016).
[35] L. Bottou, F. E. Curtis, and J. Nocedal, arXiv preprint arXiv:1606.04838 (2016).
[36] A. Braunstein and R. Zecchina, Phys. Rev. Lett. 96, 030201 (2006).
[37] C. Baldassi, A. Braunstein, N. Brunel, and R. Zecchina, Proceedings of the National Academy of
Sciences 104, 11079 (2007).
[38] C. Baldassi, J. Stat. Phys. 136, 902 (2009).
[39] C. Baldassi and A. Braunstein, Journal of Statistical Mechanics: Theory and Experiment 2015, P08008
(2015).
[40] M. MÃ©zard and A. Montanari, Information, Physics, and Computation (Oxford University Press, 2009).
[41] M. MÃ©zard, Journal of Physics A: Mathematical and General 22, 2181 (1989).
[42] â€œBelief Propagation code,â€ https://github.com/carlobaldassi/BinaryCommitteeMachineFBP.jl.

