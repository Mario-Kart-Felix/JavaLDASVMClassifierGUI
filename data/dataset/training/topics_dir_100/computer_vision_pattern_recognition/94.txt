Multiresolution Gray-Scale and Rotation
Invariant Texture Classification
with Local Binary Patterns
Timo Ojala, Matti PietikaÃˆ inen, Senior Member, IEEE, and Topi MaÃˆenpaÃˆaÃˆ
AbstractÃThis paper presents a theoretically very simple, yet efficient, multiresolution approach to gray-scale and rotation invariant
texture classification based on local binary patterns and nonparametric discrimination of sample and prototype distributions. The
method is based on recognizing that certain local binary patterns, termed Âªuniform,Âº are fundamental properties of local image texture
and their occurrence histogram is proven to be a very powerful texture feature. We derive a generalized gray-scale and rotation
invariant operator presentation that allows for detecting the ÂªuniformÂº patterns for any quantization of the angular space and for any
spatial resolution and presents a method for combining multiple operators for multiresolution analysis. The proposed approach is very
robust in terms of gray-scale variations since the operator is, by definition, invariant against any monotonic transformation of the gray
scale. Another advantage is computational simplicity as the operator can be realized with a few operations in a small neighborhood and
a lookup table. Excellent experimental results obtained in true problems of rotation invariance, where the classifier is trained at one
particular rotation angle and tested with samples from other rotation angles, demonstrate that good discrimination can be achieved
with the occurrence statistics of simple rotation invariant local binary patterns. These operators characterize the spatial configuration of
local image texture and the performance can be further improved by combining them with rotation invariant variance measures that
characterize the contrast of local image texture. The joint distributions of these orthogonal measures are shown to be very powerful
tools for rotation invariant texture analysis.
Index TermsÃNonparametric, texture analysis, Outex, Brodatz, distribution, histogram, contrast.
Ã¦
1 INTRODUCTION
ANALYSIS of two-dimensional textures has many poten-tial applications, for example, in industrial surface
inspection, remote sensing, and biomedical image analy-
sis, but only a limited number of examples of successful
exploitation of texture exist. A major problem is that
textures in the real world are often not uniform due to
variations in orientation, scale, or other visual appearance.
The gray-scale invariance is often important due to
uneven illumination or great within-class variability. In
addition, the degree of computational complexity of most
proposed texture measures is too high, as Randen and
Husoy [32] concluded in their recent extensive compara-
tive study involving dozens of different spatial filtering
methods: ÂªA very useful direction for future research is
therefore the development of powerful texture measures
that can be extracted and classified with a low-computa-
tional complexity.Âº
Most approaches to texture classification assume, either
explicitly or implicitly, that the unknown samples to be
classified are identical to the training samples with respect
to spatial scale, orientation, and gray-scale properties.
However, real-world textures can occur at arbitrary spatial
resolutions and rotations and they may be subjected to
varying illumination conditions. This has inspired a
collection of studies which generally incorporate invariance
with respect to one or at most two of the properties spatial
scale, orientation, and gray scale.
The first few approaches on rotation invariant texture
description include generalized cooccurrence matrices [12],
polarograms [11], and texture anisotropy [7]. Quite often an
invariant approach has been developed by modifying a
successful noninvariant approach such as MRF (Markov
Random Field) model or Gabor filtering. Examples of MRF-
based rotation invariant techniques include the CSAR
(circular simultaneous autoregressive) model by Kashyap
and Khotanzad [16], the MRSAR (multiresolution simulta-
neous autoregressive) model by Mao and Jain [23], and the
works of Chen and Kundu [6], Cohen et al. [9], and Wu and
Wei [37]. In the case of feature-based approaches, such as
filtering with Gabor wavelets or other basis functions,
rotation invariance is realized by computing rotation
invariant features from the filtered images or by converting
rotation variant features to rotation invariant features [13],
[14], [15], [19], [20], [21], [22], [30], [39]. Using a circular
neighbor set, Porter and Canagarajah [31] presented
rotation invariant generalizations for all three mainstream
paradigms: wavelets, GMRF, and Gabor filtering. Utilizing
similar circular neighborhoods, Arof and Deravi obtained
rotation invariant features with 1D DFT transformation [2].
A number of techniques incorporating invariance with
respect to both spatial scale and rotation have been
presented [1], [9], [20], [22]. [38], [39]. The approach based
IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 24, NO. 7, JULY 2002 971
. The authors are with the Machine Vision and Media Processing Unit,
Infotech Oulu, University of Oulu, PO Box 4500, FIN-90014, Finland.
E-mail: {skidi, mkp, topiolli}@ee.oulu.fi.
Manuscript received 13 June 2000; revised 21 June 2001; accepted 16 Oct.
2001.
Recommended for acceptance by D. Jacobs.
For information on obtaining reprints of this article, please send e-mail to:
tpami@computer.org, and reference IEEECS Log Number 112278.
0162-8828/02/$17.00 ÃŸ 2002 IEEE
on Zernike moments by Wang and Healey [36] is one of the
first studies to include invariance with respect to all three
properties: spatial scale, rotation, and gray scale. In his mid-
1990s survey on scale and rotation invariant texture
classification, Tan [35] called for more work on perspective
projection invariant texture classification, which has re-
ceived a rather limited amount of attention [5], [8], [17].
This work focuses on gray-scale and rotation invariant
texture classification, which has been addressed by Chen
and Kundu [6] and Wu and Wei [37]. Both studies
approached gray-scale invariance by assuming that the
gray-scale transformation is a linear function. This is a
somewhat strong simplification, which may limit the
usefulness of the proposed methods. Chen and Kundu
realized gray-scale invariance by global normalization of
the input image using histogram equalization. This is not a
general solution, however, as global histogram equalization
cannot correct intraimage (local) gray-scale variations.
In this paper, we propose a theoretically and computa-
tionally simple approach which is robust in terms of gray-
scale variations and which is shown to discriminate a large
range of rotated textures efficiently. Extending our earlier
work [27], [28], [29], we present a gray-scale and rotation
invariant texture operator based on local binary patterns.
Starting from the joint distribution of gray values of a
circularly symmetric neighbor set of pixels in a local
neighborhood, we derive an operator that is, by definition,
invariant against any monotonic transformation of the gray
scale. Rotation invariance is achieved by recognizing that
this gray-scale invariant operator incorporates a fixed set of
rotation invariant patterns.
The main contribution of this work lies in recognizing
that certain local binary texture patterns termed ÂªuniformÂº
are fundamental properties of local image texture and in
developing a generalized gray-scale and rotation invariant
operator for detecting these ÂªuniformÂº patterns. The term
ÂªuniformÂº refers to the uniform appearance of the local
binary pattern, i.e., there are a limited number of transitions
or discontinuities in the circular presentation of the pattern.
These ÂªuniformÂº patterns provide a vast majority, some-
times over 90 percent, of the 3 3 texture patterns in
examined surface textures. The most frequent ÂªuniformÂº
binary patterns correspond to primitive microfeatures, such
as edges, corners, and spots; hence, they can be regarded as
feature detectors that are triggered by the best matching
pattern.
The proposed texture operator allows for detecting Âªuni-
formÂº local binary patterns at circular neighborhoods of any
quantization of the angular space and at any spatial resolu-
tion. We derive the operator for a general case based on a
circularly symmetric neighbor set ofP members on a circle of
radius R, denoting the operator as LBPriu2P;R . Parameter P
controls the quantization of the angular space, whereas R
determines the spatial resolution of the operator. In addition
to evaluating the performance of individual operators of a
particular (P;R), we also propose a straightforward approach
for multiresolution analysis, which combines the responses of
multiple operators realized with different (P;R).
The discrete occurrence histogram of the ÂªuniformÂº
patterns (i.e., the responses of the LBPriu2P;R operator)
computed over an image or a region of image is shown to
be a very powerful texture feature. By computing the
occurrence histogram, we effectively combine structural
and statistical approaches: The local binary pattern detects
microstructures (e.g., edges, lines, spots, flat areas) whose
underlying distribution is estimated by the histogram.
We regard image texture as a two-dimensional phenom-
enon characterized by two orthogonal properties: spatial
structure (pattern) and contrast (the ÂªamountÂº of local
image texture). In terms of gray-scale and rotation invariant
texture description, these two are an interesting pair: Where
spatial pattern is affected by rotation, contrast is not, and
vice versa, where contrast is affected by the gray scale,
spatial pattern is not. Consequently, as long as we want to
restrict ourselves to pure gray-scale invariant texture
analysis, contrast is of no interest as it depends on the gray
scale.
TheLBPriu2P;R operator is an excellent measure of the spatial
structure of local image texture, but it, by definition, discards
the other important property of local image texture, i.e.,
contrast, since it depends on the gray scale. If only rotation
invariant texture analysis is desired, i.e., gray-scale invar-
iance is not required, the performance of LBPriu2P;R can be
further enhanced by combining it with a rotation invariant
variance measure V ARP;R that characterizes the contrast of
local image texture. We present the joint distribution of these
two complementary operators,LBPriu2P;R =V ARP;R, as a power-
ful tool for rotation invariant texture classification.
As the classification rule, we employ nonparametric
discrimination of sample and prototype distributions based
on a log-likelihood measure of the dissimilarity of histo-
grams, which frees us from making any, possibly erro-
neous, assumptions about the feature distributions.
The performance of the proposed approach is demon-
strated with two experiments. Excellent results in both
experiments demonstrate that the proposed texture opera-
tor is able to produce, from just one reference rotation angle,
a representation that allows for discriminating a large
number of textures at other rotation angles. The operators
are also computationally attractive as they can be realized
with a few operations in a small neighborhood and a
lookup table.
The paper is organized as follows: The derivation of the
operators and the classification principle are described in
Section 2. Experimental results are presented in Section 3
and Section 4 concludes the paper.
2 GRAY SCALE AND ROTATION INVARIANT LOCAL
BINARY PATTERNS
We start the derivation of our gray scale and rotation
invariant texture operator by defining texture T in a local
neighborhood of a monochrome texture image as the joint
distribution of the gray levels of P Â…P > 1Â† image pixels:
T Âˆ tÂ…gc; g0; . . . ; gPÃ¿1Â†; Â…1Â†
where gray value gc corresponds to the gray value of the
center pixel of the local neighborhood and gpÂ…p Âˆ
0; . . . ; P Ã¿ 1Â† correspond to the gray values of P equally
972 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 24, NO. 7, JULY 2002
spaced pixels on a circle of radius R Â…R > 0Â† that form a
circularly symmetric neighbor set.
If the coordinates of gc are (0; 0), then the coordinates
of gp are given by Â…Ã¿R sinÂ…2p=P Â†; R cosÂ…2p=P Â†Â†. Fig. 1
illustrates circularly symmetric neighbor sets for various
(P;R). The gray values of neighbors which do not fall
exactly in the center of pixels are estimated by
interpolation.
2.1 Achieving Gray-Scale Invariance
As the first step toward gray-scale invariance, we subtract,
without losing information, the gray value of the center
pixel (gc) from the gray values of the circularly symmetric
neighborhood gp Â…p Âˆ 0; . . . ; P Ã¿ 1Â†, giving:
T Âˆ tÂ…gc; g0 Ã¿ gc; g1 Ã¿ gc; . . . ; gPÃ¿1 Ã¿ gcÂ†: Â…2Â†
Next, we assume that differences gp Ã¿ gc are independent
of gc, which allows us to factorize (2):
T  tÂ…gcÂ†tÂ…g0 Ã¿ gc; g1 Ã¿ gc; . . . ; gPÃ¿1 Ã¿ gcÂ†: Â…3Â†
In practice, an exact independence is not warranted;
hence, the factorized distribution is only an approximation
of the joint distribution. However, we are willing to accept
the possible small loss in information as it allows us to
achieve invariance with respect to shifts in gray scale.
Namely, the distribution tÂ…gcÂ† in (3) describes the overall
luminance of the image, which is unrelated to local image
texture and, consequently, does not provide useful in-
formation for texture analysis. Hence, much of the informa-
tion in the original joint gray level distribution (1) about the
textural characteristics is conveyed by the joint difference
distribution [28]:
T  tÂ…g0 Ã¿ gc; g1 Ã¿ gc; . . . ; gpÃ¿1 Ã¿ gcÂ†: Â…4Â†
This is a highly discriminative texture operator. It
records the occurrences of various patterns in the neighbor-
hood of each pixel in a P -dimensional histogram. For
constant regions, the differences are zero in all directions.
On a slowly sloped edge, the operator records the highest
difference in the gradient direction and zero values along
the edge and, for a spot, the differences are high in all
directions.
Signed differences gp Ã¿ gc are not affected by changes in
mean luminance; hence, the joint difference distribution is
invariant against gray-scale shifts. We achieve invariance
with respect to the scaling of the gray scale by considering
just the signs of the differences instead of their exact values:
T  tÂ…sÂ…g0 Ã¿ gcÂ†; sÂ…g1 Ã¿ gcÂ†; . . . ; sÂ…gPÃ¿1 Ã¿ gcÂ†Â†; Â…5Â†
where
sÂ…xÂ† Âˆ 1; x  0
0; x < 0:

Â…6Â†
By assigning a binomial factor 2p for each sign sÂ…gp Ã¿ gcÂ†,
we transform (5) into a unique LBPP;R number that
characterizes the spatial structure of the local image texture:
LBPP;R Âˆ
XPÃ¿1
pÂˆ0
sÂ…gp Ã¿ gcÂ†2p: Â…7Â†
The name ÂªLocal Binary PatternÂº reflects the function-
ality of the operator, i.e., a local neighborhood is
thresholded at the gray value of the center pixel into a
binary pattern. LBPP;R operator is by definition invariant
against any monotonic transformation of the gray scale,
i.e., as long as the order of the gray values in the image
stays the same, the output of the LBPP;R operator
remains constant.
If we set (P Âˆ 8; R Âˆ 1), we obtain LBP8;1, which is
similar to the LBP operator we proposed in [27]. The two
differences between LBP8;1 and LBP are: 1) The pixels in
the neighbor set are indexed so that they form a circular
chain and 2) the gray values of the diagonal pixels are
determined by interpolation. Both modifications are neces-
sary to obtain the circularly symmetric neighbor set, which
allows for deriving a rotation invariant version of LBPP;R.
2.2 Achieving Rotation Invariance
The LBPP;R operator produces 2
P different output values,
corresponding to the 2P different binary patterns that can be
formed by the P pixels in the neighbor set. When the image
is rotated, the gray values gp will correspondingly move
along the perimeter of the circle around g0. Since g0 is
always assigned to be the gray value of element (0; R) to the
right of gc rotating a particular binary pattern naturally
results in a different LBPP;R value. This does not apply to
patterns comprising of only 0s (or 1s) which remain
constant at all rotation angles. To remove the effect of
rotation, i.e., to assign a unique identifier to each rotation
invariant local binary pattern we define:
LBPriP;R Âˆ minfRORÂ…LBPP;R; iÂ† j i Âˆ 0; 1; . . . ;PÃ¿ 1g;
Â…8Â†
where RORÂ…x; iÂ† performs a circular bit-wise right shift on
the P -bit number x i times. In terms of image pixels, (8)
OJALA ET AL.: MULTIRESOLUTION GRAY-SCALE AND ROTATION INVARIANT TEXTURE CLASSIFICATION WITH LOCAL BINARY PATTERNS 973
Fig. 1. Circularly symmetric neighbor sets for different (P;R).
simply corresponds to rotating the neighbor set clockwise
so many times that a maximal number of the most
significant bits, starting from gPÃ¿1, is 0.
LBPriP;R quantifies the occurrence statistics of individual
rotation invariant patterns corresponding to certain micro-
features in the image; hence, the patterns can be considered
as feature detectors. Fig. 2 illustrates the 36 unique rotation
invariant local binary patterns that can occur in the case of
P Âˆ 8, i.e., LBPri8;R can have 36 different values. For
example, pattern #0 detects bright spots, #8 dark spots
and flat areas, and #4 edges. If we set R Âˆ 1, LBPri8;1
corresponds to the gray-scale and rotation invariant
operator that we designated as LBPROT in [29].
2.3 Improved Rotation Invariance with ÂªUniformÂº
Patterns and Finer Quantization of the Angular
Space
Our practical experience, however, has shown that
LBPROT as such does not provide very good discrimina-
tion, as we also concluded in [29]. There are two reasons:
The occurrence frequencies of the 36 individual patterns
incorporated in LBPROT vary greatly and the crude
quantization of the angular space at 45 intervals.
We have observed that certain local binary patterns are
fundamental properties of texture, providing the vast
majority, sometimes over 90 percent, of all 3 3 patterns
present in the observed textures. This is demonstrated in
more detail in Section 3 with statistics of the image data
used in the experiments. We call these fundamental
patterns ÂªuniformÂº as they have one thing in common,
namely, uniform circular structure that contains very few
spatial transitions. ÂªUniformÂº patterns are illustrated on the
first row of Fig. 2. They function as templates for
microstructures such as bright spot (0), flat area or dark
spot (8), and edges of varying positive and negative
curvature (1-7).
To formally define the ÂªuniformÂº patterns, we introduce
a uniformity measure U(ÂªpatternÂº), which corresponds to
the number of spatial transitions (bitwise 0/1 changes) in
the Âªpattern.Âº For example, patterns 000000002 and
111111112 have U value of 0, while the other seven patterns
in the first row of Fig. 2 have U value of 2 as there are
exactly two 0/1 transitions in the pattern. Similarly, the
other 27 patterns have U value of at least 4. We designate
patterns that have U value of at most 2 as ÂªuniformÂº and
propose the following operator for gray-scale and rotation
invariant texture description instead of LBPriP;R:
LBPriu2P;R Âˆ
PPÃ¿1
pÂˆ0 sÂ…gp Ã¿ gcÂ† if UÂ…LBPP;RÂ†  2
P Â‡ 1 otherwise;

Â…9Â†
where
UÂ…LBPP;RÂ† Âˆ j sÂ…gPÃ¿1 Ã¿ gcÂ† Ã¿ sÂ…g0 Ã¿ gcÂ† j
Â‡
XPÃ¿1
pÂˆ1
j sÂ…gp Ã¿ gcÂ† Ã¿ sÂ…gpÃ¿1 Ã¿ gcÂ† j :
Â…10Â†
Superscript riu2 reflects the use of rotation invariant
ÂªuniformÂº patterns that have U value of at most 2. By
definition, exactly P Â‡ 1 ÂªuniformÂº binary patterns can
occur in a circularly symmetric neighbor set of P pixels.
Equation (9) assigns a unique label to each of them
corresponding to the number of Âª1Âº bits in the pattern
(0!!P ), while the ÂªnonuniformÂº patterns are grouped under
the ÂªmiscellaneousÂº label (P Â‡ 1). In Fig. 2, the labels of the
ÂªuniformÂº patterns are denoted inside the patterns. In
practice, the mapping from LBPP;R to LBP
riu2
P;R , which has
P Â‡ 2 distinct output values, is best implemented with a
lookup table of 2P elements.
The final texture feature employed in texture analysis is
the histogram of the operator outputs (i.e., pattern labels)
accumulated over a texture sample. The reason why the
histogram of ÂªuniformÂº patterns provides better discrimi-
nation in comparison to the histogram of all individual
patterns comes down to differences in their statistical
properties. The relative proportion of ÂªnonuniformÂº pat-
terns of all patterns accumulated into a histogram is so
small that their probabilities cannot be estimated reliably.
974 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 24, NO. 7, JULY 2002
Fig. 2. The 36 unique rotation invariant binary patterns that can occur in the circularly symmetric neighbor set of LBPri8;R. Black and white circles
correspond to bit values of 0 and 1 in the 8-bit output of the operator. The first row contains the nine ÂªuniformÂº patterns and the numbers inside them
correspond to their unique LBPriu28;R codes.
Inclusion of their noisy estimates in the dissimilarity
analysis of sample and model histograms would deteriorate
performance.
We noted earlier that the rotation invariance of
LBPROT Â…LBPri8;1Â† is hampered by the crude 45 quantiza-
tion of the angular space provided by the neighbor set of
eight pixels. A straightforward fix is to use a larger P since
the quantization of the angular space is defined by (360=P ).
However, certain considerations have to be taken into
account in the selection of P . First, P and R are related in
the sense that the circular neighborhood corresponding to a
given R contains a limited number of pixels (e.g., nine for
R Âˆ 1), which introduces an upper limit to the number of
nonredundant sampling points in the neighborhood.
Second, an efficient implementation with a lookup table of
2P elements sets a practical upper limit for P . In this study,
we explore P values up to 24, which requires a lookup table
of 16 MB that can be easily managed by a modern
computer.
2.4 Rotation Invariant Variance Measures of the
Contrast of Local Image Texture
The LBPriu2P;R operator is a gray-scale invariant measure, i.e.,
its output is not affected by any monotonic transformation
of the gray scale. It is an excellent measure of the spatial
pattern, but it, by definition, discards contrast. If gray-scale
invariance is not required and we wanted to incorporate the
contrast of local image texture as well, we can measure it
with a rotation invariant measure of local variance:
V ARP;R Âˆ 1
P
XPÃ¿1
pÂˆ0
Â…gp Ã¿ Â†2; where  Âˆ 1
P
XPÃ¿1
pÂˆ0
gp: Â…11Â†
V ARP;R is by definition invariant against shifts in gray
scale. Since LBPriu2P;R and V ARP;R are complementary, their
joint distribution LBPriu2P;R =V ARP;R is expected to be a very
powerful rotation invariant measure of local image texture.
Note that, even though we in this study restrict ourselves to
using only joint distributions of LBPriu2P;R and V ARP;R
operators that have the same (P;R) values, nothing would
prevent us from using joint distributions of operators
computed at different neighborhoods.
2.5 Nonparametric Classification Principle
In the classification phase, we evaluate the dissimilarity of
sample and model histograms as a test of goodness-of-fit,
which is measured with a nonparametric statistical test. By
using a nonparametric test, we avoid making any, possibly
erroneous, assumptions about the feature distributions.
There are many well-known goodness-of-fit statistics such
as the chi-square statistic and the G (log-likelihood ratio)
statistic [33]. In this study, a test sample S was assigned to
the class of the model M that maximized the log-likelihood
statistic:
LÂ…S;MÂ† Âˆ
XB
bÂˆ1
Sb logMb; Â…12Â†
where B is the number of bins and Sb and Mb correspond to
the sample and model probabilities at bin b, respectively.
Equation (12) is a straightforward simplification of the G
(log-likelihood ratio) statistic:
GÂ…S;MÂ† Âˆ 2
XB
bÂˆ1
Sb log
Sb
Mb
Âˆ 2
XB
bÂˆ1
Â‰Sb logSb Ã¿ Sb logMbÂŠ;
Â…13Â†
where the first term of the righthand expression can be
ignored as a constant for a given S.
L is a nonparametric pseudometric that measures like-
lihoods that sample S is from alternative texture classes,
based on exact probabilities of feature values of preclassi-
fied texture models M. In the case of the joint distribution
LBPriu2P;R =V ARP;R, (12) was extended in a straightforward
manner to scan through the two-dimensional histograms.
Sample and model distributions were obtained by
scanning the texture samples and prototypes with the
chosen operator and dividing the distributions of operator
outputs into histograms having a fixed number of B bins.
Since LBPriu2P;R has a fixed set of discrete output values
(0! P Â‡ 1), no quantization is required, but the operator
outputs are directly accumulated into a histogram of
P Â‡ 2 bins. Each bin effectively provides an estimate of
the probability of encountering the corresponding pattern
in the texture sample or prototype. Spatial dependencies
between adjacent neighborhoods are inherently incorpo-
rated in the histogram because only a small subset of
patterns can reside next to a given pattern.
Variance measure VARP;R has a continuous-valued
output; hence, quantization of its feature space is needed.
This was done by adding together feature distributions for
every single model image in a total distribution, which was
divided into B bins having an equal number of entries.
Hence, the cut values of the bins of the histograms
corresponded to the (100=B) percentile of the combined
data. Deriving the cut values from the total distribution and
allocating every bin the same amount of the combined data
guarantees that the highest resolution of quantization is
used where the number of entries is largest and vice versa.
The number of bins used in the quantization of the feature
space is of some importance as histograms with a too small
number of bins fail to provide enough discriminative
information about the distributions. On the other hand,
since the distributions have a finite number of entries, a too
large number of bins may lead to sparse and unstable
histograms. As a rule of thumb, statistics literature often
proposes that an average number of 10 entries per bin
should be sufficient. In the experiments, we set the value of
B so that this condition is satisfied.
2.6 Multiresolution Analysis
We have presented general rotation-invariant operators for
characterizing the spatial pattern and the contrast of local
image texture using a circularly symmetric neighbor set of
P pixels placed on a circle of radius R. By altering P and R,
we can realize operators for any quantization of the angular
space and for any spatial resolution. Multiresolution
analysis can be accomplished by combining the information
provided by multiple operators of varying (P;R).
In this study, we perform straightforward multiresolu-
tion analysis by defining the aggregate dissimilarity as the
OJALA ET AL.: MULTIRESOLUTION GRAY-SCALE AND ROTATION INVARIANT TEXTURE CLASSIFICATION WITH LOCAL BINARY PATTERNS 975
sum of individual log-likelihoods computed from the
responses of individual operators
LN Âˆ
XN
nÂˆ1
LÂ…Sn;MnÂ†; Â…14Â†
where N is the number of operators and Sn and Mn
correspond to the sample and model histograms extracted
with operator n Â…n Âˆ 1; . . . ; NÂ†, respectively. This expres-
sion is based on the additivity property of the G statistic
(13), i.e., the results of several G tests can be summed to
yield a meaningful result. If X and Y are independent
random events and SX, SY , MX , and MY are the
respective marginal distributions for S and M, then
GÂ…SXY;MXYÂ† Âˆ GÂ…SX;MXÂ† Â‡GÂ…SY;MYÂ† [18].
Generally, the assumption of independence between
different texture features does not hold. However, estima-
tion of exact joint probabilities is not feasible due to
statistical unreliability and computational complexity of
large multidimensional histograms. For example, the joint
histogram of LBPriu28;R , LBP
riu2
16;R, and LBP
riu2
24;R would contain
4,680 (10 18 26) cells. To satisfy the rule of thumb for
statistical reliability, i.e., at least 10 entries per cell on
average, the image should be of roughly Â…216Â‡ 2RÂ†Â…216Â‡
2RÂ† pixels in size. Hence, high-dimensional histograms
would only be reliable with really large images, which
renders them impractical. Large multidimensional histo-
grams are also computationally expensive, both in terms of
computing speed and memory consumption.
We have recently successfully employed this approach
also in texture segmentation, where we quantitatively
compared different alternatives for combining individual
histograms for multiresolution analysis [25]. In this study,
we restrict ourselves to combinations of at most three
operators.
3 EXPERIMENTS
We demonstrate the performance of our approach with two
different problems of rotation invariant texture analysis.
Experiment #1 is replicated from a recent study on rotation
invariant texture classification by Porter and Canagarajah
[31] for the purpose of obtaining comparative results to
other methods. Image data includes 16 source textures
captured from the Brodatz album [4]. Considering this in
conjunction with the fact that rotated textures are generated
from the source textures digitally, this image data provides
a slightly simplified but highly controlled problem for
rotation invariant texture analysis. In addition to the
original experimental setup, where training was based on
multiple rotation angles, we also consider a more challen-
ging setup, where the texture classifier is trained at only one
particular rotation angle and then tested with samples from
other rotation angles.
Experiment #2 involves a new set of texture images
which have a natural tactile dimension and natural
appearance of local intensity distortions caused by the
tactile dimension. Some source textures have large intra-
class variation in terms of color content, which results in
highly different gray-scale properties in the intensity
images. Adding the fact that the textures were captured
using three different illuminants of different color spectra,
this image data presents a very realistic and challenging
problem for illumination and rotation invariant texture
analysis.
To incorporate three different spatial resolutions and
three different angular resolutions, we realized LBPriu2P;R and
VARP;R with Â…P;RÂ† values of (8, 1), (16, 2), and (24, 3) in the
experiments. Corresponding circularly symmetric neigh-
borhoods are illustrated in Fig. 1. In multiresolution
analysis, we use the three 2-resolution combinations and
the one 3-resolution combination these three alternatives
can form.
Before going into the experiments, we take a quick look
at the statistical foundation of LBPriu2P;R . In the case of
LBPriu28;R , we choose nine ÂªuniformÂº patterns out of the
36 possible patterns, merging the remaining 27 under the
ÂªmiscellaneousÂº label. Similarly, in the case of LBPriu216;R, we
consider only 7 percent (17 out of 243) of the possible
rotation invariant patterns. Taking into account a minority
of the possible patterns and merging a majority of them
could imply that we are throwing away most of the pattern
information. However, this is not the case, as the ÂªuniformÂº
patterns appear to be fundamental properties of local image
texture, as illustrated by the numbers in Table 1.
In the case of the image data of Experiment #1, the
nine ÂªuniformÂº patterns of LBPriu28;1 contribute from
76.6 percent up to 91.8 percent of the total pattern data,
averaging 87.2 percent. The most frequent individual
pattern is symmetric edge detector 000011112 with an
18.0 percent share, followed by 000111112 (12.8 percent)
and 000001112 (11.8 percent); hence, these three patterns
contribute 42.6 percent of the textures. As expected, in
the case of LBPriu216;1 , the 17 ÂªuniformÂº patterns contribute
a smaller proportion of the image data, from 50.9 percent
up to 76.4 percent of the total pattern data, averaging
66.9 percent. The most frequent pattern is the flat area/
dark spot detector 11111111111111112 with an 8.8 percent
share.
The numbers for the image data of Experiment #2 are
remarkably similar. The contribution of the nine ÂªuniformÂº
patterns of LBPriu28;1 totaled over the three illuminants (see
Section 3.2.1) ranges from 82.4 percent to 93.3 percent,
averaging 89.7 percent. The three most frequent patterns are
again 000011112 (18.9 percent), 000001112 (15.2 percent), and
000111112 (14.5 percent), totalling 48.6 percent of the
patterns. The contribution of the 17 ÂªuniformÂº patterns of
LBPriu216;2 ranges from 57.6 percent to 79.6 percent, averaging
70.7 percent. The most frequent patterns is again
11111111111111112 with an 8.7 percent share. In the case
of LBPriu224;3 , the 25 ÂªuniformÂº patterns contribute 54.0 per-
cent of the local texture. The two most frequent patterns are
the flat area/dark spot detector (all bits Âª1Âº) with an
8.6 percent share and the bright spot detector (all bits Âª0Âº)
with an 8.2 percent share.
3.1 Experiment #1
In their comprehensive study, Porter and Canagarajah [31]
presented three feature extraction schemes for rotation
invariant texture classification, employing the wavelet
transform, a circularly symmetric Gabor filter, and a
976 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 24, NO. 7, JULY 2002
Gaussian Markov Random Field with a circularly sym-
metric neighbor set. They concluded that the wavelet-based
approach was the most accurate and exhibited the best
noise performance also having the lowest computational
complexity.
3.1.1 Image Data and Experimental Setup
The image data included 16 texture classes from the Brodatz
album [4] is shown in Fig. 3. For each texture class, there
were eight 256 256 source images, of which the first was
used for training the classifier, while the other seven images
were used to test the classifier. Porter and Canagarajah
created 180 180 images of rotated textures from these
source images using bilinear interpolation. If the rotation
angle was a multiple of 90 degrees (0 or 90 in the case of
the present ten rotation angles), a small amount of artificial
blur was added to the images to simulate the effect of
blurring on rotation at other angles. It should be stressed
that the source textures were captured from sheets in the
Brodatz album and that the rotated textures were generated
digitally from the source images. Consequently, the rotated
textures do not have any local intensity distortions such as
shadows, which could be caused when a real texture with a
natural tactile dimension was rotated with respect to an
illuminant and a camera. Thus, this image data provides a
slightly simplified but highly controlled problem for
rotation invariant texture analysis.
In the original experimental setup, the texture classifier
was trained with several 16 16 subimages extracted from
the training image. This fairly small size of training samples
increases the difficulty of the problem nicely. The training
set comprised rotation angles 0, 30, 45, and 60, while the
textures for classification were presented at rotation angles
20, 70, 90, 120, 135, and 150. Consequently, the test
data included 672 samples, 42 Â…6 angles 7 imagesÂ† for each
of the 16 texture classes. Using a Mahalanobis distance
classifier, Porter and Canagarajah reported 95.8 percent
classification accuracy for the rotation invariant wavelet-
based features as the best result.
3.1.2 Experimental Results
We started replicating the original experimental setup by
dividing the 180 180 images of the four training angles
Â…0; 30; 45; and 60Â† into 121 disjoint 16 16 subimages. In
other words, we had 7,744 training samples, 484 Â…4 angles
121 samplesÂ† in each of the 16 texture classes. We first
computed the histogram of the chosen operator for each of
the 16 16 samples. Then, we added the histograms of all
samples belonging to a particular class into one big model
histogram for this class since the histograms of single
16 16 samples would have been too sparse to be reliable
models. Also, using 7,744 different models would have
resulted in computational overhead for, in the classification
phase, the sample histograms were compared to every model
histogram. Consequently, we obtained 16 reliable model
histograms containing 484Â…16Ã¿ 2RÂ†2 entries (the operators
have aR pixel border). The performance of the operators was
evaluated with the 672 testing images. Their sample histo-
grams contained Â…180Ã¿ 2RÂ†2 entries; hence, we did not have
to worry about their stability.
OJALA ET AL.: MULTIRESOLUTION GRAY-SCALE AND ROTATION INVARIANT TEXTURE CLASSIFICATION WITH LOCAL BINARY PATTERNS 977
TABLE 1
Proportions (%) of ÂªUniformÂº Patterns of All Patterns for Each Texture
Used in the Experiments and Their Average Over All Textures
Results in Table 2 correspond to the percentage of
correctly classified samples of all testing samples. As
expected, LBPriu216;2 and LBP
riu2
24;3 clearly outperformed their
simpler counterpart LBPriu28;1 , which had difficulties in
discriminating strongly oriented textures, as misclassifica-
tions of rattan, straw, and wood contributed 70 of the
79 misclassified samples. Interestingly, in all 79 cases, the
model of the true class ranked second, right after the most
similar model of a false class that led to misclassification.
LBPriu216;2 did much better, classifying all samples correctly
except 10 grass samples that were assigned to leather. Again,
in all 10 cases, the model of the true class ranked second.
LBPriu224;3 provided further improvement by missing just five
grass samples and a matting sample. In all six cases, the
model of the true class again ranked second.
Combining the LBPriu2P;R operator with the V ARP;R
operator, which did not do too badly by itself, generally
improved the performance. The lone exception was (24, 3),
where the addition of the poorly performing VAR24;3 only
hampered the excellent discrimination by LBPriu224;3 . We see
that LBPriu216;2 =V AR16;2 fell one sample short of a faultless
result as a straw sample at 90 angle was labeled as grass.
The results for single resolutions are so good that there is
not much room for improvement by the multiresolution
analysis, though two joint distributions provided a perfect
classification. The largest gain was achieved for the VARP;R
operator, especially when VAR24;3 was excluded.
Note that we voluntarily discarded the knowledge that
training samples come from four different rotation angles,
merging all sample histograms into a single model for each
texture class. Hence, the final texture model was an
ÂªaverageÂº of the models of the four training angles, which
actually decreased the performance to a certain extent. If we
had used four separate models, one for each training angle,
for example, LBPriu216;2 =V AR16;2 would have provided a
perfect classification and the classification error of LBPriu216;2
would have been halved.
978 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 24, NO. 7, JULY 2002
Fig. 3. 180 180 samples of the 16 textures used in Experiment #1 at particular angles.
Even though a direct comparison to the results of Porter
and Canagarajah may not be meaningful due to the
different classification principle, the excellent results for
our operators demonstrate their suitability for rotation
invariant texture classification.
Table 3 presents results for a more challenging
experimental setup where the classifier was trained with
samples of just one rotation angle and tested with
samples of other nine rotation angles. We trained the
classifier with the 16 16 samples extracted from the
designated training images, again merging the histograms
of the 121 16 16 samples of a particular texture class
into one model histogram. The classifier was tested with
the samples obtained from the other nine rotation angles
of the seven source images reserved for testing purposes,
totaling 1,008 samples, 63 in each of the 16 texture
classes. Note that the seven testing images in each texture
class are physically different from the one designated
training image; hence, this setup is a true test for the
texture operators' ability to produce a rotation invariant
representation of local image texture that also generalizes
to physically different samples.
Training with just one rotation angle allows a more
conclusive analysis of the rotation invariance of our
OJALA ET AL.: MULTIRESOLUTION GRAY-SCALE AND ROTATION INVARIANT TEXTURE CLASSIFICATION WITH LOCAL BINARY PATTERNS 979
TABLE 2
Classification Accuracies (%) for the Original Experimental Setup, where Training Is Done with Rotations 0, 30, 45, and 60
TABLE 3
Classification Accuracies (%) when Training Is Done at just One Rotation Angle and the Average Accuracy Over the 10 Angles
operators. For example, it is hardly surprising that LBPriu28;1
provides the worst performace when the training angle is a
multiple of 45. Due to the crude quantization of the
angular space the presentations learned at 0, 45, 90, or
135 do not generalize that well to other angles.
Again, the importance of the finer quantization of the
angular space shows as LBPriu216;2 and LBP
riu2
24;3 provide a
solid performance with average classification accuracy of
98.3 percent and 98.5 percent, respectively. In the case of the
173 misclassifications by LBPriu216;2 , the model of the true
class always ranked second. In the case of the 149 mis-
classifications by LBPriu224;3 , the model of the true class
ranked second 117 times and third 32 times.
There is a strong suspicion that the weaker results for
LBPriu216;2 at training angles 0
 and 90 were due to the
artificial blur added to the original images at angles 0 and
90. The effect of the blur can also be seen in the results of the
joint distributions LBPriu28;1 =V AR8;1 and LBP
riu2
16;2 =V AR16;2,
which achieved the best performance when the training
angle is either 0 or 90, the (16, 2) joint operator in fact
provides a perfect classification in these cases. Namely,
when training was done at some other rotation angle, test
angles 0 and 90 contributed most of the misclassified
samples, actually all of them in the case of LBPriu216;2 =V AR16;2.
Nevertheless, the result for LBPriu216;2 =V AR16;2 is quite
excellent, whereas LBPriu224;3 =V AR24;3 seems to suffer from
the poor discrimination of the variance measure.
Even though the results for multiresolution analysis
generally exhibit improved discrimination over single
resolutions, they also serve as a welcome reminder that
the addition of inferior operator does not necessarily
enhance the performance.
3.2 Experiment #2
3.2.1 Image Data and Experimental Setup
In this experiment, we used textures from Outex, which is a
publicly available framework for experimental evaluation
of texture analysis algorithms [26]. Outex provides a large
collection of textures and ready-made test suites for
different types of texture analysis problems, together with
baseline results for well-known published algorithms.
The surface textures available in the Outex image
database are captured using the setup shown in Fig. 4a. It
includes a Macbeth SpectraLight II Luminare light source
and a Sony DXC-755P three chip CCD camera attached to
a robot arm. A workstation controls the light source for
the purpose of switching on the desired illuminant, the
camera for the purpose of selecting desired zoom
dictating the spatial resolution, the robot arm for the
purpose of rotating the camera into the desired rotation
angle and the frame grabber for capturing 24-bit RGB
images of size 538 Â…heightÂ†  716 Â…widthÂ† pixels. The
relative positions of a texture sample, illuminant, and
camera are illustrated in Fig. 4b.
Each texture available at the site is captured using three
different simulated illuminants provided in the light source:
2300K horizon sunlight denoted as Âªhorizon,Âº 2856K
incandescent CIE A denoted as Âªinca,Âº and 4000K fluor-
escent tl84 denoted as Âªtl84.Âº The spectra of the illuminants
are shown in Fig. 4c. The camera is calibrated using the
ÂªincaÂº illuminant. It should be noted that, despite the
diffuse plate, the imaging geometry is different for each
illuminant due to their different physical location in the
light source. Each texture is captured using six spatial
resolutions (100, 120, 300, 360, 500, and 600 dpi) and nine
rotation angles (0, 5, 10, 15, 30, 45, 60, 75, and 90);
hence, 162 images are captured from each texture.
The frame grabber produces rectangular pixels whose
aspect ratio (height/width) is roughly 1.04. The aspect ratio
is corrected by stretching the images in horizontal direction
to size 538 746 using Matlab's imresize command with
bilinear interpolation. Bilinear interpolation is employed
instead of bicubic because the latter may introduce halos or
extra noise around edges or in areas of high contrast, which
would be harmful to texture analysis. Horizontal stretching
is used instead of vertical size reduction because sampling
images captured by an interline transfer camera along scan
lines produces less noise and digital artifacts than sampling
across the scan lines.
In this study, we used images captured at the 100 dpi
spatial resolution. 24-bit RGB images were transformed into
eight bit intensity images using the standard formula:
I Âˆ 0:299RÂ‡ 0:587GÂ‡ 0:114R: Â…15Â†
Twenty nonoverlapping 128 128 texture samples were
extracted from each intensity image by centering the 5 4
sampling grid so that equally many pixels were left over on
each side of the sampling grid (13 pixels above and below,
53 pixels left and right). To remove the effect of global first
and second order gray-scale properties, which are unrelated
980 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 24, NO. 7, JULY 2002
Fig. 4. (a) Imaging setup. (b) Relative positions of texture sample, illuminant, and camera. (c) Spectra of the illuminants.
to local image texture, each 128 128 texture sample was
individually normalized to have an average intensity of 128
and a standard deviation of 20. In every forthcoming
experiment, the classifier was trained with the samples
extracted from images captured using illuminant ÂªincaÂº
and angle 0 (henceforth termed the reference textures).
We selected the 24 textures shown in Fig. 5. While
selecting the textures, the underlying texture pattern was
required to be roughly uniform over the whole source
image, while local gray-scale variations due to varying color
properties of the source texture were allowed (e.g.,
canvas023 and canvas033, shown in Fig. 6). Most of the
texture samples are canvases with strong directional
structure. Some of them have a large tactile dimension
(e.g., canvas025, canvas033, and canvas038), which can
induce considerable local gray-scale distortions. Taking
variations caused by different spectra of the illuminants
into account, we can conclude that this collection of textures
presents a realistic and challenging problem for illumina-
tion and rotation invariant texture analysis.
The selection of textures was partly guided by the
requirement that the reference textures could be separated
from each other. This allowed quantifying our texture
operators' ability to discriminate rotated textures without
any bias introduced by the inherent difficulty of the
problem. When the 480 samples (24 classes a' 20) were
OJALA ET AL.: MULTIRESOLUTION GRAY-SCALE AND ROTATION INVARIANT TEXTURE CLASSIFICATION WITH LOCAL BINARY PATTERNS 981
Fig. 5. 128 128 samples of the 24 textures used in Experiment #2 at particular angles.
randomly halved 100 times so that half of the 20 samples in
each texture class served as models for training the classifier
and the other 10 samples were used for testing the classifier
with the 3-NN method (sample was assigned to the class of
the majority of the three most similar models), 99.4 percent
average classification accuracy was achieved with the
simple rotation variant LBP8;1 operator (7). The perfor-
mance loss incurred by considering just rotation invariant
ÂªuniformÂº patterns is demonstrated by the 93.2 percent
average accuracy obtained with the corresponding rotation
invariant operator LBPriu28;1 . LBP
riu2
16;2 and LBP
riu2
24;3 achieved
average classification accuracies of 94.6 percent and 96.3
percent, respectively, in classifying the reference textures.
3.2.2 Results for The Proposed Method
We considered two different setups:
1. Rotation invariant texture classification (test suite
Outex_TC_00010): The classifier is trained with the
reference textures (20 samples of illuminant ÂªincaÂº
and angle 0 in each texture class), while the
160 samples of the the same illuminant ÂªincaÂº but
the other eight other rotation angles in each texture
class, are used for testing the classifier. Hence, in this
suite, there are 480 (24 20) models and 3,840
(24 20 8) validation samples in total.
2. Rotation and illuminant invariant texture classi-
fication (test suite Outex_TC_00012): The classifier
is trained with the reference textures (20 samples
of illuminant ÂªincaÂº and angle 0 in each texture
class) and tested with all samples captured using
illuminant Âªtl84Âº (problem 000) and ÂªhorizonÂº
(problem 001). Hence, in both problems, there are
480 (24 20) models and 4,320 (24 20 9) vali-
dation samples in total.
In Outex, the performance of a texture classification
algorithm is characterized with score (S), which corre-
sponds to the percentage of correctly classified samples.
Scores for the proposed operators, obtained using the 3-NN
method, in rotation invariant texture classification are
shown in Table 4. Of individual operators, LBPriu224;3
produced the best score of 94.6 percent which, recalling
the 96.3 percent score in the classification of reference
textures, demonstrates the robustness of the operator with
respect to rotation. LBPriu224;3 =V AR24;3 achieved the best
result of joint operators (97.8 percent), which is a consider-
able improvement over either of the individual operators,
underlining their complementary nature. Multiresolution
analysis generally improved the performance and the
highest score (97.9 percent) was obtained with the combina-
tion of LBPriu28;1 =V AR8;1 and LBP
riu2
24;3 =V AR24;3.
We offer the three employed combinations of (P , R)
((8, 1), (16, 2), and (24, 3)) as a reasonable starting point
for realizing the operators, but there is no guarantee
that they produce the optimal operator for a given task.
For example, when test suite Outex_TC_00010 was
tackled with 189 LBPriu2P;R operators realized using
(P Âˆ 4; 5; . . . ; 24; R Âˆ 1:0; 1:5; . . . ; 5:0), the best score of
97.2 percent was obtained with LBPriu222;4 . Thirty-two of
the 189 operators beat the 94.6 percent score obtained
with LBPriu224;3 . Fourteen of those 32 operators were
realized with (P Âˆ 11 . . . 24; R Âˆ 4:0) and they produced
the eight highest scores (97.2-97.0 percent). Task or even
texture class driven selection of texture operators could
be conducted by optimizing cross validation classifica-
tion of the training data, for example.
Table 5 shows the numbers of misclassified samples for
each texture and rotation angle for LBPriu224;3 , V AR24;3, and
LBPriu224;3 =V AR24;3, allowing detailed analysis of the discri-
mination of individual textures and the effect of rotation.
LBPriu224;3 classified seven out of the 24 classes completely
982 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 24, NO. 7, JULY 2002
Fig. 6. Intraclass gray-scale variations caused by varying color content of source textures.
TABLE 4
Scores (%) for the Proposed Texture Operators in Rotation
Invariant Texture Classification (Test Suite Outex_TC_00010)
correctly, having most difficulties with canvas033 (48/160
misclassified, 19 assigned to canvas038, 16 to canvas031).
LBPriu224;3 =V AR24;3 got 16 of the 24 classes correct and well
over half of the 2.2 percent error was contributed by
50 misclassified canvas038 samples. In 20 of the 24 classes,
the joint operator did at least as well as either of the
individual operators, demonstrating the usefulness of
complementary analysis. However, the four exceptions
(canvas005, canvas023, canvas033, tile005) remind that joint
analysis is not guaranteed to provide the optimal perfor-
mance. By studying the column totals and the contributions
of individual rotation angles to misclassifications, we see
OJALA ET AL.: MULTIRESOLUTION GRAY-SCALE AND ROTATION INVARIANT TEXTURE CLASSIFICATION WITH LOCAL BINARY PATTERNS 983
TABLE 5
The Numbers of Misclassified Samples for Each Texture and Rotation Angle
for LBPriu224;3 (plain), VAR24;3 (italic), and LBP
riu2
24;3 =V AR24;3 (bold) in the Base Problem
Column total percentage corresponds to the percentage of the column total of all misclassified samples. Only textures with misclassified samples are
included.
TABLE 6
Scores (%) for the Proposed Operators in Rotation
and Illumination Invariant Texture Classification (Test Suite Outex_TC_00012)
The classifier is trained with reference textures (illuminant ÂªincaÂº) and tested with samples captured using illuminants Âªt184Âº (problem 000) and
ÂªhorizonÂº (problem 001).
that each operator had the most misclassifications at high
rotation angles. For example, angle 90 contributed almost
30 percent of the misclassified samples in the case of
LBPriu224;3 . This attributes to the different image acquisition
properties of the interline transfer camera in horizontal and
vertical directions.
Scores in Table 6 illustrate the performance in rotation
and illumination invariant texture classification. The classi-
fier was trained with the reference textures (Âªinca,Âº 0) and
tested with samples captured using a different illuminant.
The scores for ÂªhorizonÂº and Âªtl84Âº include samples from
all nine rotation angles, i.e., 180 samples of each texture
were used for testing the classifier.
We see that classification performance deteriorated
clearly when the classifier was evaluated with samples
captured under different illumination than the reference
textures used in training. It is difficult to quantify to which
extent this is due to the differences in the spectral properties
of the illuminants affecting the colors of textures and to
which extent due to the different imaging geometries of the
illuminants affecting the appearance of local distortions
caused by the tactile dimension of textures.
In terms of rotation and illumination invariant classifica-
tion, canvas038 was the most difficult texture for LBPriu224;3
(143/180 Âªtl84Âº and 178/180 ÂªhorizonÂº samples misclassi-
fied) and LBPriu224;3 =V AR24;3 (140/180 Âªtl84Âº and 102/180
ÂªhorizonÂº sample misclassified). This is easy to understand
when looking at three different samples of canvas038 in
Fig. 7, which illustrate the prominent tactile dimension of
canvas038 and the effect it has on local texture structure
under different illumination conditions.
3.2.3 Comparative Results for Wavelet-Based Rotation
Invariant Features
For comparison purposes, we implemented the wavelet-
based rotation invariant features proposed by Porter and
Canagarajah, which they concluded to be a favorable
approach over Gabor-based and GMRF-based rotation
invariant features [31]. We extracted the features using
two different image areas, the 16 16 suggested by Porter
and Canagarajah and 128 128. As a classifier, we used the
Mahalanobis distance classifier, just like Porter and Cana-
garajah.
Table 7 shows the scores for the wavelet-based features
extracted with image area 128 128 since they provided
slightly better performance than the features extracted with
image area 16 16. When these features were employed in
classifying the reference textures using 100 random halv-
ings of the samples into training and testing sets, an average
classification accuracy of 84.9 percent was obtained.
In the rotation invariant classification, the wavelet-based
based features achieved score of 80.4 percent, which is
clearly lower than the scores obtained with the proposed
operators. As demonstrated by the scores for rotation and
illumination invariant classification, wavelet-based features
appeared to tolerate illumination changes moderately well.
Since they are computed over a larger neighborhood, they
also characterize macrotextural properties, which are less
sensitive to the local changes caused by the different
imaging geometries of the illuminants.
Table 7 also shows the percentages of misclassifications
contributed by each rotation angle. We observe that 45
contributed the largest number of misclassified samples in
all three cases. This is expected for the rotation invariance of
wavelet-based features is achieved by averaging horizontal
and vertical information by grouping together LH and HL
channels in each level of decomposition [31], which results
in the weakest estimate in the 45 direction.
In rotation invariant classification, wavelet-based features
had the most difficulties in discriminating textures canvas035
(86/160 samples misclassified), canvas023 (78/160), canvas01
(76/160), and canvas033 (72/160). In rotation and illumina-
tion invariant classification, the highest classification errors
were obtained for canvas11 (158/180 Âªtl84Âº and 163/180
ÂªhorizonÂº samples misclassified).
984 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 24, NO. 7, JULY 2002
Fig. 7. Three samples of canvas038: (a) Âªinca,Âº 0, (b) Âªhorizon,Âº 45, and
(c) Âªt184,Âº 90.
TABLE 7
Scores (%) for the Wavelet-Based Rotation Invariant Features Proposed
by Porter and Canagarajah and the Percentages of Misclassifications Contributed by Each Rotation Angle
4 DISCUSSION
We presented a theoretically and computationally simple
yet efficient multiresolution approach to gray-scale and
rotation invariant texture classification based on ÂªuniformÂº
local binary patterns and nonparametric discrimination of
sample and prototype distributions. ÂªUniformÂº patterns
were recognized to be a fundamental property of texture as
they provide a vast majority of local texture patterns in
examined textures, corresponding to texture microstruc-
tures such as edges. By estimating the distributions of these
microstructures, we combined structural and statistical
texture analysis.
We developed a generalized gray-scale and rotation
invariant operator LBPriu2P;R , which allows for detecting
ÂªuniformÂº patterns in circular neighborhoods of any
quantization of the angular space and at any spatial
resolution. We also presented a simple method for combin-
ing responses of multiple operators for multiresolution
analysis by assuming that the operator responses are
independent.
Excellent experimental results obtained in two problems
of true rotation invariance where the classifier was trained
at one particular rotation angle and tested with samples
from other rotation angles demonstrate that good discrimi-
nation can be achieved with the occurrence statistics of
ÂªuniformÂº rotation invariant local binary patterns.
The proposed approach is very robust in terms of gray-
scale variations caused, e.g., by changes in illumination
intensity since the LBPriu2P;R operator is by definition
invariant against any monotonic transformation of the gray
scale. This should make it very attractive in situations
where nonuniform illumination conditions are a concern,
e.g., in visual inspection. Gray-scale invariance is also
necessary if the gray-scale properties of the training and
testing data are different. This was clearly demonstrated in
our recent study on supervised texture segmentation with
the same image set that was used by Randen and Husoy in
their recent extensive comparative study [32]. In our
experiments, the basic 3 3 LBP operator provided better
performance than any of the methods benchmarked by
Randen and Husoy for 10 of the 12 texture mosaics and, in
most cases, by a clear margin [28]. Results in Experiment #2,
involving three illuminants with different spectra and large
intraclass color variations in source textures demonstrate
that the proposed approach is also robust in terms of color
variations.
Computational simplicity is another advantage as the
operators can be realized with a few comparisons in a small
neighborhood and a lookup table. This facilitates a very
straightforward and efficient implementation, which may
be mandatory in time critical applications.
If gray-scale invariance is not required, performance can
be further improved by combining the LBPriu2P;R operator
with the rotation invariant variance measure VARP;R that
characterizes the contrast of local image texture. As we
observed in the experiments, the joint distributions of these
orthogonal operators are very powerful tools for rotation
invariant texture analysis.
The spatial size of the operators is of interest. Some may
find our experimental results surprisingly good considering
how small spatial support our operators have, for example,
in comparison to much larger Gabor filters that are often
used in texture analysis. However, the built-in spatial
support of our operators is inherently larger as only a
limited subset of patterns can reside adjacent to a particular
pattern. Still, our operators may not be suitable for
discriminating textures where the dominant features appear
at a very large scale. This can be addressed by increasing
the spatial predicate R, which allows generalizing the
operators to any neighborhood size.
The performance can be further enhanced by multi-
resolution analysis. We presented a straightforward method
for combining operators of different spatial resolutions for
this purpose. Experimental results involving three different
spatial resolutions showed that multiresolution analysis is
beneficial, except in those cases where a single resolution
was already sufficient for a very good discrimination.
Ultimately, we would want to incorporate scale invariance,
in addition to gray-scale and rotation invariance.
Regarding future work, one thing deserving a closer look
is the use of a task specific subset of rotation invariant
patterns, which may, in some cases, provide better
performance than ÂªuniformÂº patterns. Patterns or pattern
combinations are evaluated with some criterion, e.g.,
classification accuracy on a training data, and the combina-
tion providing the best accuracy is chosen. Since combina-
torial explosion may prevent an exhaustive search through
all possible subsets, suboptimal solutions such as stepwise
or beam search should be considered. We have explored
this approach in a classification problem involving 16
textures from the Curet database [10] with an 11:25 tilt
between training and testing images [24]. Thanks to its
invariance against monotonic gray-scale transformations,
the methodology is applicable to textures with minor 3D
transformations, corresponding to such textures which a
human can easily, without attention, classify to the same
categories as the original textures. Successful discrimination
of Curet textures captured from slightly different view-
points demonstrates the robustness of the approach with
respect to small distortions caused by height variations,
local shadowing, etc.
In a similar fashion to deriving a task-specific subset of
patterns, instead of using a general purpose set of
operators, the parameters P and R could be ÂªtunedÂº for
the task in hand or even for each texture class separately.
We also reported that when classification errors occur, the
model of the true class very often ranks second. This
suggests that classification could be carried out in stages
by selecting operators which best discriminate among
remaining alternatives.
Our findings suggest that complementary information of
local spatial patterns and contrast plays an important role in
texture discrimination. There are studies on human percep-
tion that support this conclusion. For example, Tamura et al.
[34] designated coarseness, edge orientation, and contrast as
perceptually important textural properties. The LBP histo-
grams provide information of texture orientation and
coarseness, while the local gray-scale variance characterizes
contrast. Similarly, Beck et al. [3] suggested that texture
segmentation of human perception might occur as a result of
OJALA ET AL.: MULTIRESOLUTION GRAY-SCALE AND ROTATION INVARIANT TEXTURE CLASSIFICATION WITH LOCAL BINARY PATTERNS 985
differences in the first-order statistics of textural elements and
their parts, i.e., in the LBP histogram.
APPENDIX
NOTE
Test suites (include images) used in this paper and a Matlab
implementation of the proposed method are available at the
Outex site (http://www.outex.oulu.fi). The original setup
of Experiment #1 is available as test suite Contrib_TC_00000
(single problem) and the revised setup is available as test
suite Contrib_TC_00001 (10 problems corresponding to
training with each of the 10 rotation angles in turn).
Experiment #2 is available as test suites Outex_TC_00010
(rotation invariant texture classification, single problem)
and Outex_TC_00012 (rotation and illumination invariant
texture classification, two problems).
ACKNOWLEDGMENTS
The authors wish to thank Dr. Nishan Canagarajah and
Mr. Paul Hill from the University of Bristol for providing
the texture images of Experiment #1. The authors also
would like to thank the anonymous referees for their
valuable comments. The financial support provided by the
Academy of Finland is gratefully acknowledged.
REFERENCES
[1] O. Alata, C. Cariou, C. Ramananjarasoa, and M. Najim,
ÂªClassification of Rotated and Scaled Textures Using HMHV
Spectrum Estimation and the Fourier-Mellin Transform,Âº Proc.
IEEE Int'l Conf. Image Processing, vol. 1, pp. 53-56, 1998.
[2] H. Arof and F. Deravi, ÂªCircular Neighbourhood and 1-D DFT
Features for Texture Classification and Segmentation,Âº IEE
Proc.ÃVision, Image, and Signal Processing, vol. 145, pp. 167-172,
1998.
[3] J. Beck, S. Prazdny, and A. Rosenfeld, ÂªA Theory of Textural
Segmentation,Âº Human and Machine Vision, J. Beck, B. Hope, and
A. Rosenfeld, eds., Academic, 1983.
[4] P. Brodatz, Textures: A Photographic Album for Artists and Designers.
Dover, 1966.
[5] S. Chang, L.S. Davis, S.M. Dunn, J.O. Eklundh, and A. Rosenfeld,
ÂªTexture Discrimination by Projective Invariants,Âº Pattern Recog-
nition Letters, vol. 5, pp. 337-342, 1987.
[6] J.-L. Chen and A. Kundu, ÂªRotation and Gray Scale Transform
Invariant Texture Identification Using Wavelet Decomposition
and Hidden Markov Model,Âº IEEE Trans. Pattern Analysis and
Machine Intelligence, vol. 16, pp. 208-214, 1994.
[7] D. Chetverikov, ÂªExperiments in the Rotation-Invariant Texture
Discrimination Using Anisotropy Features,Âº Proc. Sixth Int'l Conf.
Pattern Recognition, pp. 1071-1073, 1982.
[8] D. Chetverikov, ÂªPattern Regularity as a Visual Key,Âº Image and
Vision Computing, vol. 18, pp. 975-985, 2000.
[9] F.S. Cohen, Z. Fan, and M.A. Patel, ÂªClassification of Rotated and
Scaled Texture Images Using Gaussian Markov Random Field
Models,Âº IEEE Trans. Pattern Analysis and Machine Intelligence,
vol. 13, pp. 192-202, 1991.
[10] K. Dana, S. Nayar, B. van Ginneken, and J. Koenderink,
ÂªReflectance and Texture of Real-World Surfaces,Âº Proc. Int'l Conf.
Computer Vision and Pattern Recognition, pp. 151-157, 1997 http://
www.cs.columbia.edu/CAVE/curet/.
[11] L.S. Davis, ÂªPolarograms: A New Tool for Image Texture
Analysis,Âº Pattern Recognition, vol. 13, pp. 219-223, 1981.
[12] L.S. Davis, S.A. Johns, and J.K. Aggarwal, ÂªTexture Analysis
Using Generalized Cooccurrence Matrices,Âº IEEE Trans. Pattern
Analysis and Machine Intelligence, vol. 1, pp. 251-259, 1979.
[13] S.R. Fountain and T.N. Tan, ÂªEfficient Rotation Invariant Texture
Features for Content-Based Image Retrieval,Âº Pattern Recognition,
vol. 31, pp. 1725-1732, 1998.
[14] H. Greenspan, S. Belongie, R. Goodman, and P. Perona, ÂªRotation
Invariant Texture Recognition Using a Steerable Pyramid,Âº Proc.
12th Int'l Conf. Pattern Recognition, vol. 2, pp. 162-167, 1994.
[15] G.M. Haley and B.S. Manjunath, ÂªRotation-Invariant Texture
Classification Using a Complete Space-Frequency Model,Âº IEEE
Trans. Image Processing, vol. 8, pp. 255-269, 1999.
[16] R.L. Kashyap and A. Khotanzad, ÂªA Model-Based Method for
Rotation Invariant Texture Classification,Âº IEEE Trans. Pattern
Analysis and Machine Intelligence, vol. 8, pp. 472-481, 1986.
[17] R. Kondepudy and G. Healey, ÂªUsing Moment Invariants to
Analyze 3-D Color Textures,Âº Proc. IEEE Int'l Conf. Image
Processing, vol. 2, pp. 61-65, 1994.
[18] S. Kullback, Information Theory and Statistics. Dover, 1997.
[19] W.-K. Lam and C.-K. Li, ÂªRotated Texture Classification by
Improved Iterative Morphological Decomposition,Âº IEE Proc.
Vision, Image, and Signal Processing, vol. 144, pp. 171- 179, 1997.
[20] M.M. Leung and A.M. Peterson, ÂªScale and Rotation Invariant
Texture Classification,Âº Proc. 26th Asilomar Conf. Signals, Systems,
and Computers, vol. 1, pp. 461-465, 1992.
[21] S.V.R. Madiraju and C.C Liu, ÂªRotation Invariant Texture
Classification Using Covariance,Âº Proc. Int'l Conf. Image Processing,
vol. 2, pp. 655-659, 1994.
[22] V. Manian and R. Vasquez, ÂªScaled and Rotated Texture
Classification Using a Class of Basis Functions,Âº Pattern Recogni-
tion, vol. 31, pp. 1937-1948, 1998.
[23] J. Mao and A.K. Jain, ÂªTexture Classification and Segmentation
Using Multiresolution Simultaneous Autoregressive Models,Âº
Pattern Recognition, vol. 25, pp. 173-188, 1992.
[24] T. MaÃˆenpaÃˆaÃˆ, T. Ojala, M. PietikaÃˆinen, and M. Soriano, ÂªRobust
Texture Classification by Subsets of Local Binary Patterns,Âº Proc.
15th Int'l Conf. Pattern Recognition, vol. 3, pp. 947-950, 2000.
[25] T. MaÃˆenpaÃˆaÃˆ, M. PietikaÃˆinen, and T. Ojala, ÂªTexture Classification
by Multi-Predicate Local Binary Pattern Operators,Âº Proc. 15th
Int'l Conf. Pattern Recognition, vol. 3, pp. 951-954, 2000.
[26] T. Ojala, T. MaÃˆenpaÃˆaÃˆ, M. PietikaÃˆinen, J. Viertola, J. KylloÃˆnen, and
S. Huovinen, ÂªOutexÃA New Framework for Empirical Evalua-
tion of Texture Analysis Algorithms,Âº Proc. 16th Int'l Conf. Pattern
Recognition, 2002.
[27] T. Ojala, M. PietikaÃˆinen, and D. Harwood, ÂªA Comparative Study
of Texture Measures with Classification Based on Feature
Distributions,Âº Pattern Recognition, vol. 29, pp. 51-59, 1996.
[28] T. Ojala, K. Valkealahti, E. Oja, and M. PietikaÃˆinen, ÂªTexture
Discrimination with Multi-Dimensional Distributions of Signed
Gray Level Differences,Âº Pattern Recognition, vol. 34, pp. 727- 739,
2001.
[29] M. PietikaÃˆinen, T. Ojala, and Z. Xu, ÂªRotation-Invariant Texture
Classification Using Feature Distributions,Âº Pattern Recognition,
vol. 33, pp. 43-52, 2000.
[30] M. Porat and Y. Zeevi, ÂªLocalized Texture Processing in Vision:
Analysis and Synthesis in the Gaborian Space,Âº IEEE Trans.
Biomedical Eng., vol. 36, pp. 115-129, 1989.
[31] R. Porter and N. Canagarajah, ÂªRobust Rotation-Invariant Texture
Classification: Wavelet, Gabor Filter and GMRF Based Schemes,Âº
IEE Proc. Vision, Image, and Signal Processing, vol. 144, pp. 180-188,
1997.
[32] T. Randen and J.H. Husoy, ÂªFiltering for Texture Classification: A
Comparative Study,Âº IEEE Trans. Pattern Analysis and Machine
Intelligence, vol. 21, pp. 291-310, 1999.
[33] R.R. Sokal and F.J. Rohlf, Biometry. W.H. Freeman, 1969.
[34] H. Tamura, S. Mori, and T. Yamawaki, ÂªTextural Features
Corresponding to Visual Perception,Âº IEEE Trans. Systems, Man,
and Cybernetics, vol. 8, pp. 460-473, 1978.
[35] T.N. Tan, ÂªScale and Rotation Invariant Texture Classification,Âº
IEE Colloquium Texture Classification: Theory and Applications 1994.
[36] L. Wang and G. Healey, ÂªUsing Zernike Moments for the
Illumination and Geometry Invariant Classification of Multi-
Spectral Texture,Âº IEEE Trans. Image Processing, vol. 7, pp. 196-203,
1998.
[37] W.-R. Wu and S.-C. Wei, ÂªRotation and Gray-Scale Transform-
Invariant Texture Classification Using Spiral Resampling, Sub-
band Decomposition and Hidden Markov Model,Âº IEEE Trans.
Image Processing, vol. 5, pp. 1423-1434, 1996.
[38] Y. Wu and Y. Yoshida, ÂªAn Efficient Method for Rotation and
Scaling Invariant Texture Classification,Âº Proc. IEEE Int'l Conf.
Acoustics, Speech, and Signal Processing, vol. 4, pp. 2519-2522, 1995.
986 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 24, NO. 7, JULY 2002
[39] J. You and H.A. Cohen, ÂªClassification and Segmentation of
Rotated and Scaled Textured Images Using Texture `Tuned'
Masks,Âº Pattern Recognition, vol. 26, pp. 245-258, 1993.
Timo Ojala received the MSc (with honors) and
Dr.Tech. degrees in electrical engineering from
the University of Oulu, Finland, in 1992 and
1997, respectively. He is currently an Academy
Fellow of the Academy of Finland and the
associate director of the MediaTeam Oulu
research group at the University of Oulu. His
research interests include distributed multimedia
and pattern recognition.
Matti PietikaÃˆinen received the doctor of tech-
nology degree in electrical engineering from the
University of Oulu, Finland, in 1982. In 1981, he
established the Machine Vision Group at the
University of Oulu. The research results of his
group have been widely exploited in industry.
Currently, he is a professor of information
technology, the scientific director of Infotech
Oulu Research Center, and the director of the
Machine Vision and Media Processing Unit at
the University of Oulu. From 1980 to 1981 and from 1984 to 1985, he
visited the Computer Vision Laboratory at the University of Maryland.
His research interests are in machine vision and image analysis. His
current research focuses on texture analysis, color and face image
analysis, and document image analysis. He has authored more than
120 papers in international journals, books, and conference proceed-
ings, and about 85 other publications or reports. He is an associate
editor of the IEEE Transactions on Pattern Analysis and Machine
Intelligence and Pattern Recognition journals. He was the guest editor
(with L.F. Pau) of a two-part special issue on "Machine Vision for
Advanced Production" for the International Journal of Pattern Recogni-
tion and Artificial Intelligence (also reprinted as a book by World
Scientific in 1996). He was also the editor of the book Texture Analysis
in Machine Vision (World Scientific, 2000) and has served as a reviewer
for numerous journals and conferences. He was the president of the
Pattern Recognition Society of Finland from 1989 to 1992. Since 1989,
he has served as a member of the governing board of the International
Association for Pattern Recognition (IAPR) and became a fellow of the
IAPR in 1994. He is also a member of IAPR's education committee and
served as its chairman in 1997-98. He has also served on committees of
several international conferences. He is a senior member of the IEEE
and a member of the IEEE Computer Society.
Topi MaÃˆenpaÃˆaÃˆ received the MSc degree in
electrical engineering from the University of
Oulu, Finland, in 1999 (with honors). He is
currently working with the Machine Vision and
Media Processing Unit and the Department of
Electrical Engineering as a postgraduate student
of the national Graduate School in Electronics,
Telecommunications, and Automation. His re-
search interests include color and texture
analysis, visual inspection with efficient texture
methods, and robotics.
. For more information on this or any other computing topic,
please visit our Digital Library at http://computer.org/publications/dlib.
OJALA ET AL.: MULTIRESOLUTION GRAY-SCALE AND ROTATION INVARIANT TEXTURE CLASSIFICATION WITH LOCAL BINARY PATTERNS 987

