Generative Encoder-Decoder Models for Task-Oriented Spoken Dialog
Systems with Chatting Capability
Tiancheng Zhao, Allen Lu, Kyusong Lee and Maxine Eskenazi
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, Pennsylvania, USA
{tianchez,arlu,kyusongl,max+}@cs.cmu.edu
Abstract
Generative encoder-decoder models of-
fer great promise in developing domain-
general dialog systems. However, they
have mainly been applied to open-domain
conversations. This paper presents
a practical and novel framework for
building task-oriented dialog systems
based on encoder-decoder models. This
framework enables encoder-decoder mod-
els to accomplish slot-value independent
decision-making and interact with external
databases. Moreover, this paper shows the
flexibility of the proposed method by in-
terleaving chatting capability with a slot-
filling system for better out-of-domain re-
covery. The models were trained on both
real-user data from a bus information sys-
tem and human-human chat data. Re-
sults show that the proposed framework
achieves good performance in both offline
evaluation metrics and in task success rate
with human users.
1 Introduction
Task-oriented spoken dialog systems have trans-
formed human-computer interaction by enabling
people interact with computers via spoken lan-
guage (Raux et al., 2005; Young, 2006; Bohus
and Rudnicky, 2003). The task-oriented SDS is
usually domain-specific. The system creators first
map the user utterances into semantic frames that
contain domain-specific slots and intents using
spoken language understanding (SLU) (De Mori
et al., 2008). Then a set of domain-specific dialog
state variables is tracked to retain the context infor-
mation over turns (Williams et al., 2013). Lastly,
the dialog policy decides the next move from a
list of dialog acts that covers the expected com-
municative functions from the system.
Although the above approach has been success-
fully applied to many practical systems, it has lim-
ited ability to generalize to out-of-domain (OOD)
requests and to scale up to new domains. For ex-
ample, even within in a simple domain, real users
often make requests that are not included in the
semantic specifications. Due to this, proper er-
ror handling strategies that guide users back to the
in-domain conversation are crucial to dialog suc-
cess (Bohus and Rudnicky, 2005). Past error han-
dling strategies were limited to a set of predefined
dialog acts, e.g. request repeat, clarification etc.,
which constrained the system’s capability in keep-
ing users engaged. Moreover, there has been an
increased interest in extending task-oriented sys-
tems to multiple topics (Lee et al., 2009; Gašić
et al., 2015b) and multiple skills, e.g. grouping
heterogeneous types of dialogs into a single sys-
tem (Zhao et al., 2016). Both cases require the
system to be flexible enough to extend to new slots
and actions.
Our goal is to move towards a domain-general
task-oriented SDS framework that is flexible
enough to expand to new domains and skills by
removing domain-specific assumptions on the di-
alog state and dialog acts (Bordes and Weston,
2016). To achieve this goal, the neural encoder-
decoder model(Cho et al., 2014; Sutskever et al.,
2014) is a suitable choice, since it has achieved
promising results in modeling open-domain con-
versations (Vinyals and Le, 2015; Sordoni et al.,
2015). It encodes the dialog history using deep
neural networks and then generates the next sys-
tem utterance word-by-word via recurrent neural
networks (RNNs). Therefore, unlike the tradi-
tional SDS pipeline, the encoder-decoder model is
theoretically only limited by its input/output vo-
cabulary.
ar
X
iv
:1
70
6.
08
47
6v
1 
 [
cs
.C
L
] 
 2
6 
Ju
n 
20
17
A na‘̀ive implementation of an encoder-
decoder-based task-oriented system would use
RNNs to encode the raw dialog history and gen-
erate the next system utterance using a separate
RNN decoder. However, while this implementa-
tion might achieve good performance in an offline
evaluation of a closed dataset, it would certainly
fail when used by humans. There are several rea-
sons for this: 1) real users can mention new enti-
ties that do not appear in the training data, such as
a new restaurant name. These entities are, how-
ever, essential in delivering the information that
matches users’ needs in a task-oriented system.
2) a task-oriented SDS obtains information from
a knowledge base (KB) that is constantly updated
(“today’s” weather will be different every day), so
simply memorizing KB results that occurred in the
training data would produce false information. In-
stead, an effective model should learn to query the
KB constantly to get the most up-to-date informa-
tion. 3) users may give OOD requests (e.g. say,
“how is your day”, to a slot-filling system), which
must be handled gracefully in order to keep the
conversation moving in the intended direction.
This paper proposes an effective encoder-
decoder framework for building task-oriented
SDSs. We propose entity indexing to tackle the
challenges of out-of-vocabulary (OOV) entities
and to query the KB. Moreover, we show the ex-
tensibility of the proposed model by adding chat-
ting capability to a task-oriented encoder-decoder
SDS for better OOD recovery. This approach
was assessed on the Let’s Go Bus Information
data from the 1st Dialog State Tracking Chal-
lenge (Williams et al., 2013), and we report per-
formance on both offline metrics and real human
users. Results show that this model attains good
performance for both of these metrics.
2 Related Work
Past research in developing domain-general di-
alog systems can be broadly divided into three
branches. The first one focuses on learning
domain-independent dialog state representation
while still using hand-crafted dialog act system ac-
tions. Researchers proposed the idea of extract-
ing slot-value independent statistics as the dia-
log state (Wang et al., 2015; Gašić et al., 2015a),
so that the dialog state representation can be
shared across systems serving different knowledge
sources. Another approach uses RNNs to auto-
matically learn a distributed vector representation
of the dialog state by accumulating the observa-
tions at each turn (Williams and Zweig, 2016;
Zhao and Eskenazi, 2016; Dhingra et al., 2016;
Williams et al., 2017). The learned dialog state
is then used by the dialog policy to select the
next action. The second branch of research de-
velops a domain-general action space for dialog
policy. Prior work replaced the domain-specific
dialog acts with domain-independent natural lan-
guage semantic schema as the action space of dia-
log managers (Eshghi and Lemon, 2014), e.g. Dy-
namic Syntax (Kempson et al., 2000). More re-
cently, Wen, et al. (2016) have shown the feasibil-
ity of using an RNN as the decoder to generate the
system utterances word by word, and the dialog
policy of the proposed model can be fine tuned us-
ing reinforcement learning (Su et al., 2016). Fur-
thermore, to deal with the challenge of develop-
ing end-to-end task-oriented dialog models that
are able to interface with external KB, prior work
has unified the special KB query actions via deep
reinforcement learning (Zhao and Eskenazi, 2016)
and soft attention over the database (Dhingra et al.,
2016). The third branch strives to solve both prob-
lems at the same time by building an end-to-end
model that maps an observable dialog history di-
rectly to the word sequences of the system’s re-
sponse. By using an encoder-decoder model, it has
been successfully applied to open-domain conver-
sational models (Serban et al., 2015; Li et al.,
2015, 2016; Zhao et al., 2017), as well as to task
oriented systems (Bordes and Weston, 2016; Yang
et al., 2016; Eric and Manning, 2017). In order to
better predict the next correct system action, this
branch has focused on investigating various neu-
ral network architectures to improve the machine’s
ability to reason over user input and model long-
term dialog context.
This paper is closely related to the third branch,
but differs in the following ways: 1) these models
are slot-value independent by leveraging domain-
general entity recognizer, which is more extensi-
ble to OOV entities, 2) these models emphasize
the interactive nature of dialog and address out-of-
domain handling by interleaving chatting in task-
oriented conversations, 3) instead of testing on a
synthetic dataset, this approach focuses on real
world use by testing the system on human users
via spoken interface.
3 Proposed Method
Our proposed framework consists of three steps
as shown in Figure 2: a) entity indexing (EI), b)
slot-value independent encoder-decoder (SiED),
c) system utterance lexicalization (UL). The in-
tuition is to leverage domain-general named en-
tity recognition (NER) (Tjong Kim Sang and
De Meulder, 2003) techniques to extract salient
entities in the raw dialog history and convert the
lexical values of the entities into entity indexes.
The encoder-decoder model is then trained to fo-
cus solely on reasoning over the entity indexes in
a dialog history and to make decisions about the
next utterance to produce (including KB query). In
this way, the model can be unaffected by the inclu-
sion of new entities and new KB, while maintain-
ing its domain-general input/output interface for
easy extension to new types of conversation skills.
Lastly, the output from the decoder networks are
lexicalized by replacing the entity indexes and spe-
cial KB tokens with natural language. The follow-
ing sections explain each step in detail.
3.1 Entity Indexing and Utterance
Lexicalization
Entity Indexing EI has two parts. First, the EI
utilizes an existing domain-general NER to ex-
tract entities from both the user and system utter-
ances. Note that the entity here is assumed to be
a super-set of the slots in the domain. For exam-
ple, for a flight-booking system, the system may
contain two slots: [from-LOCATION] and [to-
LOCATION] for the departure and arrival city, re-
spectively. However, EI only extracts every men-
tion of [LOCATION] in the utterances and leaves
the task of distinguishing between departure and
arrival to the encoder-decoder model. Further-
more, this step replaces each KB search result with
its search query (e.g. the weather is cloudy→ [kb-
search]-[DATETIME-0]). The second step of EI
involves constructing a indexed entity table. Each
entity is indexed by its order of occurrence in the
conversation. Figure 1 shows an example in which
there are two [LOCATION] mentions.
Properties of Entity Indexing In this section,
several properties of EI and their assumptions are
addressed. First, each entity is indexed uniquely
by its entity type and index. Note that the in-
dex is not associated with the entity value, but
rather solely by the order of appearance in the
dialog. Despite the actual words being hidden,
Figure 1: An example of entity indexing and utter-
ance lexicalization.
a human can still easily predict which entity the
system should confirm or search for in the KB
based on logical reasoning. Therefore, that the EI
not only alleviates the OOV problem of deploying
the encoder-decoder model in the real world, but
also forces the encoder-decoder model’s focus on
learning the reasoning process of task-oriented di-
alogs instead of leveraging too much information
from the language modeling.
Moreover, most slot-filling SDSs, apart from in-
forming the concepts from KBs, usually do not in-
troduce novel entities to users. Instead, systems
mostly corroborate the entities introduced by the
users. With this assumption, every entity mention
in the system utterances can always be found in the
users’ utterances in the dialog history, and there-
fore can also be found in the indexed entity table.
This property reduces the grounding behavior of
the conventional task-oriented dialog manager into
selecting an entity from the indexed entity table
and confirming it with the user.
Utterance Lexicalization is the reverse of EI.
Since EI is a deterministic process, its effect can
always be reversed by finding the corresponding
entity in the indexed entity table and replacing the
index with its word. For KB search, a simple string
matching algorithm can search for the special [kb-
search] token and take the following generated en-
tities as the argument to the KB. Then the actual
KB results can replace the original KB query. Fig-
ure 1 shows an example of utterance lexicaliza-
tion.
3.2 Encoder-Decoder Models
The encoder-decoder model can then read in the
EI-processed dialog history and predict the sys-
tem’s next utterance in EI format. Specifically,
a dialog history of k turns is represented by
[(a0, u0, c0), ...(ak−1, uk−1, ck−1)], in which ai,
ui and ci are, respectively, the system, user utter-
ance and ASR confidence score at turn i. Each ut-
terance in the dialog history is encoded into fixed-
size vectors using Convolutional Neural Networks
Figure 2: The proposed pipeline for task-oriented dialog systems.
(CNNs) proposed in (Kim, 2014). Specifically,
each word in an utterance x is mapped to its word
embedding, so that an utterance is represented as a
matrix R ∈ R|x|×D, in which D is the size of the
word embedding. Then L filters of size 1,2,3 con-
duct convolutions on R to obtain a feature map, c,
of n-gram features in window size 1,2,3. Then c
is passed through a nonlinear ReLu (Glorot et al.,
2011) layer, followed by a max-pooling layer to
obtain a compact summary of salient n-gram fea-
tures, i.e. et(x) = maxpool(ReLu(c + b)). Us-
ing CNNs to capture word-order information is
crucial, because the encoder-decoder has to be
able to distinguish between fine-grained differ-
ences between entities. For example, a simple
bag-of-word embedding approach will fail to dis-
tinguish between the two location entities in “leave
from [LOCATION-0] and go to [LOCATION-1]”,
while a CNN encoder can capture the context in-
formation of these two entities.
After obtaining utterance embedding, a turn-
level dialog history encoder network similar to
the one proposed in (Zhao and Eskenazi, 2016)
is used. Turn embedding is a simple concatena-
tion of system, user utterance embedding and the
confidence score t = [eu(ai); eu(ui); ci]. Then
an Long Short-Term Memory (LSTM) (Hochre-
iter and Schmidhuber, 1997) network reads the se-
quence turn embeddings in the dialog history via
recursive state update si+1 = LSTM(ti+1, hi), in
which hi is the output of the LSTM hidden state.
Decoding with/without Attention A vanilla
decoder takes in the last hidden state of the
encoder as its initial state and decodes the
next system utterance word by word as shown
in (Sutskever et al., 2014). This assumes that
the fixed-size hidden state is expressive enough
to encode all important information about the
history of a dialog. However, this assump-
tion may often be violated for a task that has
long-dependency or complex reasoning of the en-
tire source sequence. An attention mechanism
proposed (Bahdanau et al., 2014) in the ma-
chine translation community has helped encoder-
decoder models improve state-of-art performance
in various tasks (Bahdanau et al., 2014; Xu et al.,
2015). Attention allows the decoder to look over
every hidden state in the encoder and dynamically
decide the importance of each hidden state at each
decoding step, which significantly improves the
model’s ability to handle long-term dependency.
We experiment decoders both with and without
attention. Attention is computed similarly mul-
tiplicative attention described in (Luong et al.,
2015). We denote the hidden state of the decoder
at time step j by sj , and the hidden state outputs
of the encoder at turn i by hi. We then predict the
next word by
aji = softmax(hTi Wasj + ba) (1)
cj =
∑
i
ajihi (2)
s̃j = tanh(Ws
[
sj
cj
]
) (3)
p(wj |sj , cj) = softmax(Wos̃j) (4)
The decoder next state is updated by sj+1 =
LSTM(sj , e(wj+1), s̃j).
3.3 Leveraging Chat Data to Improve OOD
Recovery
Past work has shown that simple supervised learn-
ing is usually inadequate for learning robust se-
quential decision-making policy (Williams and
Young, 2003; Ross et al., 2011). This is because
the model is only exposed to the expert demonstra-
tion, but not to examples of how to recover from its
own mistakes or users’ OOD requests. We present
a simple yet effective technique that leverages the
extensibility of the encoder-decoder model in or-
der to obtain a more robust policy in the setting
of supervised learning. Specifically, we artificially
augment a task-oriented dialog dataset with chat
data from an open-domain conversation corpus.
This has been shown to be effective in improv-
ing the performance of task-oriented systems (Yu
et al., 2017). Let the original dialog dataset with
N dialogs be D = [d0..., dn, ...dN ], where dn is a
multi-turn task-oriented dialog of |dn| turns. Fur-
thermore, we assume we have access to a chat
dataset Dc = [(q0, r0), ...(qm, rm), ...(qM , rM )],
where qm, rm are common adjacency pairs that
appear in chats, (e.g. q = hello, r = hi, how are
you). Then we can create a new dataset D∗ by re-
peating the following process a certain number of
times:
1. Randomly sample dialog dn from D
2. Randomly sample turn ti = [ai, ui] from dn
3. Randomly sample an adjacency pair
(qm, rm) from Dc
4. Replace the user utterance of ti by qm so that
ti = [ai, qm]
5. Insert a new turn after ti, i.e. ti+1 = [rm +
ei+1, ui]
Figure 3: Illustration of data augmentation. The
turn in the dashed line is inserted in the original
dialog.
In Step 5, ei is an error handling system utterance
after the system answers the user’s OOD request,
qm. In this study, we experimented with a simple
case where ei+1 = ai so that the system should re-
peat its previous prompt after responding to qm via
rm. Figure 3 shows an example of an augmented
turn. Eventually, we train the model on the union
of the two datasets D+ = D ∪D∗
Discussion: There are several reasons that the
above data augmentation process is appealing.
First, the model effectively learns an OOD recov-
ery strategy from D∗, i.e. it first gives chatting
answers to users’ OOD requests and then tries to
pull users back to the main-task conversation. Sec-
ond, chat data usually has a larger vocabulary and
more diverse natural language expressions, which
can reduce the chance of OOVs and enable the
model to learn more robust word embeddings and
language models.
4 Experiment Setup
4.1 Dataset and Domain
The CMU Let’s Go Bus Information Sys-
tem (Raux et al., 2005) is a task-oriented spoken
dialog system that contains bus information. We
combined the train1a and train1b datasets from
DSTC 1 (Williams et al., 2013), which contain
2608 total dialogs. The average dialog length
is 9.07 turns. The dialogs were randomly split-
ted into 85/5/10 proportions for train/dev/test data.
The data was noisy since the dialogs were col-
lected from real users via telephone lines. Fur-
thermore, this version of Let’s Go used an in-
house database containing the Port Authority bus
schedule. In the current version, that database was
replaced with the Google Directions API, which
both reduces the human burden of maintaining a
database and opens the possibility of extending
Let’s Go to cities other than Pittsburgh. Connect-
ing to Google Directions API involves a POST call
to their URL, with our given access key as well
as the parameters needed: departure place, arrival
place and departure time, and the travel mode,
which we always set as TRANSIT to obtain rel-
evant bus routes. There are 14 distinct dialog acts
available to the system, and each system utterance
contains one or more dialog acts. Lastly, the sys-
tem vocabulary size is 1311 and the user vocabu-
lary size is 1232. After the EI process, the sizes
become 214 and 936, respectively.
For chat data, we use a publicly available chat
corpus used in (Yu et al., 2015)1. In total, there
are 3793 chatting adjacency pairs. We control the
number of data injections to 30% of the number of
turns in the original DTSC dataset, which leads to
a user vocabulary size of 3537 and system vocab-
ulary size of 4047.
4.2 Training Details
For all experiments, the word embedding size was
100. The sizes of the LSTM hidden states for both
the encoder and decoder were 500 with 1 layer.
The attention context size was also 500. We tied
the CNN weights for the encoding system and user
utterances. Each CNN has 3 filter windows, 1, 2,
and 3, with 100 feature maps each. We trained
the model end-to-end using Adam (Kingma and
Ba, 2014), with a learning rate of 1e-3 and a
batch size of 40. To combat overfitting, we apply
dropout (Zaremba et al., 2014) to the LSTM layer
outputs and the CNN outputs after the maxpooling
layer, with a dropout rate of 40%.
5 Experiments Results
This approach was assessed both offline and on-
line evaluations. The offline evaluation contains
standard metrics to test open-domain encoder-
decoder dialog models (Li et al., 2015; Serban
et al., 2015). System performance was assessed
from three perspectives that are essential for task-
oriented systems: dialog acts, slot-values, and KB
query. The online evaluation is composed of ob-
jective task success rate, the number of turns, and
subjective satisfaction with human users.
5.1 Offline Evaluation
Dialog Acts (DA): Each system utterance is made
up of one or more dialog acts, e.g. “leaving
at [TIME-0], where do you want to go?” →
[implicit-confirm, request(arrival place)]. To eval-
uate whether a generated utterance has the same
dialog acts as the ground truth, we trained a multi-
label dialog tagger using one-vs-rest Support Vec-
tor Machines (SVM) (Tsoumakas and Katakis,
2006), with bag-of-bigram features for each dia-
log act label. Since the natural language genera-
tion module in Let’s Go is handcrafted, the dialog
act tagger achieved 99.4% average label accuracy
on a held-out dataset. We used this dialog act tag-
ger to tag both the ground truth and the generated
1github.com/echoyuzhou/ticktock text api
responses. Then we computed the micro-average
precision, recall, and the F-score.
Slots: This metric measures the model’s perfor-
mance in generating the correct slot-values. The
slot-values mostly occur in grounding utterances
(e.g. explicit/implicit confirm) and KB queries.
We compute precision, recall, and F-score.
KB Queries: Although the slots metric already
covers the KB queries, here the precision/recall/F-
score of system utterances that contain KB queries
are also explicitly measured, due to their impor-
tance. Specifically, this action measures whether
the system is able to generate the special [kb-
query] symbol to initiate a KB query, as well as
how accurate the corresponding KB query argu-
ments are.
BLEU (Papineni et al., 2002): compares the n-
gram precision with length penalty, and has been
a popular score used to evaluate the performance
of natural language generation (Wen et al., 2015)
and open-domain dialog models (Li et al., 2016).
Corpus-level BLEU-4 is reported.
Metrics Vanilla EI EI
+Attn
EI+Attn
+Chat
DA
(p/r/f1)
83.5
77.9
80.5
79.7
80.1
80.0
80.0
83.1
81.5
81.8
83.5
82.7
Slot
(p/r/f1)
42.0
30.3
35.2
60.6
63.6
62.1
63.7
64.7
64.2
64.6
69.1
66.8
KB
(p/r/f1)
N/A 48.9
55.3
51.9
55.4
70.8
62.2
58.2
71.9
64.4
BLEU 36.9 54.6 59.3 60.5
Table 1: Performance of each model on automatic
measures.
Four systems were compared: the basic
encoder-decoder models without EI (vanilla), the
basic model with EI pre-processing (EI), the
model with attentional decoder (EI+Attn) and the
model trained on the dataset augmented with chat-
ting data (EI+Attn+Chat). The comparison was
carried out on exactly the same held-out test
dataset that contains 261 dialogs. Table 1 shows
the results. It can be seen that all four mod-
els achieve similar performance on the dialog act
metrics, even the vanilla model. This confirms
the capacity of encoder-decoders models to learn
the “shape” of a conversation, since they have
achieved impressive results in more challenging
settings, e.g. modeling open-domain conversa-
tions. Furthermore, since the DSTC1 data was
collected over several months, there were minor
updates made to the dialog manager. Therefore,
there are inherent ambiguities in the data (the dia-
log manager may take different actions in the same
situation). We conjecture that ∼80% is near the
upper limit of our data in modeling the system’s
next dialog act given the dialog history.
On the other hand, these proposed methods sig-
nificantly improved the metrics related to slots
and KB queries. The inclusion of EI alone was
able to improve the F-score of slots by a relative
76%, which confirms that EI is crucial in develop-
ing slot-value independent encoder-decoder mod-
els for modeling task-oriented dialogs. Likewise,
the inclusion of attention further improved the pre-
diction of slots in system utterances. Adding at-
tention also improved the performance of predict-
ing KB queries, more so than the overall slot accu-
racy. This is expected, since KB queries are usu-
ally issued near the end of a conversation, which
requires global reasoning over the entire dialog
history. The use of attention allows the decoder
to look over the history and make better decisions
rather than simply depending on the context sum-
mary in the last hidden layer of the encoder. Be-
cause of the good performance achieved by the
models with the attentional decoder, the attention
weights in Equation 1 at every step of the decod-
ing process in two example dialogs from test data
are visualized. For both figures, the vertical axes
show the dialog history flowing from the top to the
bottom. Each row is a turn in the format of (sys-
tem utterance # user utterance). The top horizon-
tal axis shows the predicted next system utterance.
The darkness of a bar indicates the value of the
attention calculated in Equation 1.
The first example shows attention for ground-
ing the new entity [LOCATION-1] in the previ-
ous turn. The attention weights become focus on
the previous turn when predicting [LOCATION-
1] in the implicit confirm action. The second di-
alog example shows a more challenging situation,
in which the model is predicting a KB query. We
can see that the attention weights when generating
each input argument of the KB query clearly fo-
cus on the specific mention in the dialog history.
The visualization confirms the effectiveness of the
attention mechanism in dealing with long-term de-
pendency at discourse level.
Figure 4: Visualization of attention weights when
generating implicit confirm (top) and KB query
(bottom).
Surprisingly, the model trained on the data aug-
mented with chat achieved slightly better slot ac-
curacy performance, even though the augmented
data is not directly related to task-oriented di-
alogs. Furthermore, the model trained on chat-
augmented data achieved better scores for the
KB query metrics. Several reasons may explain
this improvement: 1) since chat data exposes the
model to a significantly larger vocabulary, the re-
sulting model is more robust to words that it had
not seen in the original task-oriented-only training
data, and 2) the augmented dialog turn can be seen
as noise in the dialog history, which adds extra
regularization to the model and enables the model
to learn more robust long-term reasoning mecha-
nisms.
5.2 Human Evaluation
Although the model achieves good performance
in offline evaluation, this may not carray over
to real user dialogs, where the system must si-
multaneously deal with several challenges, such
as automatic speech recognition (ASR) errors,
OOD requests, etc. Therefore, a real user study
was conducted to evaluate the performance of
the proposed systems in the real world. Due to
the limited number of real users, only two best
performing system were compared, EI+Attn and
EI+Attn+Chat. Users were able to talk to a web
interface to the dialog systems via speech. Google
Chrome Speech API 2 served as the ASR and text-
to-speech (TTS) modules. Turn-taking was done
via the built-in Chrome voice activity detection
(VAD) plus a finite state machine-based end-of-
turn detector (Zhao et al., 2015). Lastly, a hybrid
named entity recognizer (NER) was trained using
Conditional Random Field (CRF) (McCallum and
Li, 2003) and rules to extract 4 types of entities
(location, hour, minute, pm/am) for the EI process.
The experiment setup is as follows: when a user
logs into the website, the system prompts the user
with a goal, which is a randomly chosen combina-
tion of departure place, arrival place and time (e.g.
leave from CMU and go to the airport at 10:30
AM). The system also instructs the user to say
goodbye if the he/she thinks the goal is achieved
or wants to give up. The user begins a conversa-
tion with one of the two evaluated systems, with a
50/50 chance of choosing either system (not vis-
ible to the user). After the user’s session is fin-
ished, the system asks the him/her to give two
scores between 1 and 5 for correctness and nat-
uralness of the system respectively. The subjects
in this study consist of undergraduate and grad-
uate students. However, many subjects did not
follow the prompted goal, but rather asked about
bus routes of their own. Therefore, the dialog
was manually labeled for dialog success. A dia-
log is successful if and only if the systems give at
least one bus schedule that matches with all three
slots expressed by the users. Table 2 shows the
Metrics EI+Attn EI+Attn
+Chat
# of Dialog 75 74
Slot Precision 73.3% 71.8%
KB Precision 88.6% 93.7%
Success Rate 73.3% 77.0%
Avg Turns 4.88 4.91
Avg Correctness 3.45 (1.32) 3.22 (1.40)
Avg Naturalness 3.46 (1.41) 3.53 (1.34)
Table 2: Performance of each model on automatic
measures. The standard deviations of subjective
scores are in parentheses.
results. Overall, our systems achieved reasonable
performance in terms of dialog success rate. The
EI+Attn+Chat model achieves slightly higher suc-
cess and subjective naturalness metrics (although
the difference between EI+Attn+Chat and EI+Attn
2www.google.com/intl/en/chrome/demos/speech.html
was not statistically significant due to the limited
number of subjects). The precision of ground-
ing the correct slots and predicting the correct KB
query was also manually labelled. EI+Attn model
performs slightly better than the EI+Attn+Chat
model in slot precision, while the latter model per-
forms significantly better in KB query precision.
In addition, EI+Attn+Chat leads to slightly longer
dialogs because sometimes it generates chatting
utterances with users when it cannot understand
users’ utterances.
At last, we investigated the log files and iden-
tified the following major types of sources of dia-
log failure: RNN Decoder Invalid Output: Oc-
casionally, the RNN decoder outputs system ut-
terances as “Okay going to [LOCATION-2]. Did
I get that right?”, in which [LOCATION-2] can-
not be found in the indexed entity table. Such in-
valid output confuses users. This occurred in 149
of the dialogs, where 4.1% of system utterances
contain invalid symbols. Imitation of Subopti-
mal Dialog Policy: Since our models are only
trained to imitate the suboptimal hand-crafted di-
alog policy, their limitations show when the orig-
inal dialog manager cannot handle the situation,
such as failing to understand slots that appeared in
compound utterances. Future plans involves im-
proving the models to perform better than the sub-
optimal teacher policy.
6 Conclusions
In conclusion, this paper discusses constructing
task-oriented dialog systems using generative en-
coder decoder models. EI is effective in solving
both the OOV entity and KB query challenges for
encoder-decoder-based task-oriented SDSs. Addi-
tionally, the novel data augmentation technique of
interleaving task-oriented dialog corpus with chat
data led to better model performance in both on-
line and offline evaluation. Future work includes
developing more advanced encoder-decoder mod-
els that to better deal with long-term dialog his-
tory and complex reasoning challenges than cur-
rent models do. Furthermore, inspired by the suc-
cess of mixing chatting with slot-filling dialogs,
we will take full advantage of the extensibility of
encoder-decoder models by investigating how to
make systems that are able to interleave various
conversational tasks, e.g. different domains, chat-
ting or task-oriented, which in turn can create a
more versatile conversational agent.
References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-
gio. 2014. Neural machine translation by jointly
learning to align and translate. arXiv preprint
arXiv:1409.0473 .
Dan Bohus and Alexander I Rudnicky. 2003. Raven-
claw: Dialog management using hierarchical task
decomposition and an expectation agenda .
Dan Bohus and Alexander I Rudnicky. 2005. Er-
ror handling in the ravenclaw dialog management
framework. In Proceedings of the conference on
Human Language Technology and Empirical Meth-
ods in Natural Language Processing. Association
for Computational Linguistics, pages 225–232.
Antoine Bordes and Jason Weston. 2016. Learn-
ing end-to-end goal-oriented dialog. arXiv preprint
arXiv:1605.07683 .
Kyunghyun Cho, Bart Van Merriënboer, Caglar Gul-
cehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. 2014. Learning
phrase representations using rnn encoder-decoder
for statistical machine translation. arXiv preprint
arXiv:1406.1078 .
Renato De Mori, Frédéric Bechet, Dilek Hakkani-Tur,
Michael McTear, Giuseppe Riccardi, and Gokhan
Tur. 2008. Spoken language understanding. IEEE
Signal Processing Magazine 25(3).
Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng
Gao, Yun-Nung Chen, Faisal Ahmed, and Li Deng.
2016. End-to-end reinforcement learning of dia-
logue agents for information access. arXiv preprint
arXiv:1609.00777 .
Mihail Eric and Christopher D Manning. 2017. A
copy-augmented sequence-to-sequence architecture
gives good performance on task-oriented dialogue.
arXiv preprint arXiv:1701.04024 .
Arash Eshghi and Oliver Lemon. 2014. How domain-
general can we be? learning incremental dialogue
systems without dialogue acts. DialWattSemdial
2014 page 53.
M Gašić, N Mrkšić, Pei-hao Su, David Vandyke,
Tsung-Hsien Wen, and Steve Young. 2015a. Policy
committee for adaptation in multi-domain spoken
dialogue systems. In Automatic Speech Recognition
and Understanding (ASRU), 2015 IEEE Workshop
on. IEEE, pages 806–812.
Milica Gašić, Dongho Kim, Pirros Tsiakoulis, and
Steve Young. 2015b. Distributed dialogue poli-
cies for multi-domain statistical dialogue manage-
ment. In Acoustics, Speech and Signal Processing
(ICASSP), 2015 IEEE International Conference on.
IEEE, pages 5371–5375.
Xavier Glorot, Antoine Bordes, and Yoshua Bengio.
2011. Deep sparse rectifier neural networks. In Ais-
tats. volume 15, page 275.
Sepp Hochreiter and Jürgen Schmidhuber. 1997.
Long short-term memory. Neural computation
9(8):1735–1780.
Ruth Kempson, Wilfried Meyer-Viol, and Dov M Gab-
bay. 2000. Dynamic syntax: The flow of language
understanding. Wiley-Blackwell.
Yoon Kim. 2014. Convolutional neural net-
works for sentence classification. arXiv preprint
arXiv:1408.5882 .
Diederik Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980 .
Cheongjae Lee, Sangkeun Jung, Seokhwan Kim, and
Gary Geunbae Lee. 2009. Example-based dialog
modeling for practical multi-domain dialog system.
Speech Communication 51(5):466–484.
Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,
and Bill Dolan. 2015. A diversity-promoting objec-
tive function for neural conversation models. arXiv
preprint arXiv:1510.03055 .
Jiwei Li, Will Monroe, Alan Ritter, Michel Galley,
Jianfeng Gao, and Dan Jurafsky. 2016. Deep rein-
forcement learning for dialogue generation. arXiv
preprint arXiv:1606.01541 .
Minh-Thang Luong, Hieu Pham, and Christopher D
Manning. 2015. Effective approaches to attention-
based neural machine translation. arXiv preprint
arXiv:1508.04025 .
Andrew McCallum and Wei Li. 2003. Early results for
named entity recognition with conditional random
fields, feature induction and web-enhanced lexicons.
In Proceedings of the seventh conference on Natu-
ral language learning at HLT-NAACL 2003-Volume
4. Association for Computational Linguistics, pages
188–191.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of
the 40th annual meeting on association for compu-
tational linguistics. Association for Computational
Linguistics, pages 311–318.
Antoine Raux, Brian Langner, Dan Bohus, Alan W
Black, and Maxine Eskenazi. 2005. Lets go pub-
lic! taking a spoken dialog system to the real world.
In in Proc. of Interspeech 2005. Citeseer.
Stéphane Ross, Geoffrey J Gordon, and Drew Bagnell.
2011. A reduction of imitation learning and struc-
tured prediction to no-regret online learning. In AIS-
TATS. volume 1, page 6.
Iulian V Serban, Alessandro Sordoni, Yoshua Bengio,
Aaron Courville, and Joelle Pineau. 2015. Build-
ing end-to-end dialogue systems using generative hi-
erarchical neural network models. arXiv preprint
arXiv:1507.04808 .
Alessandro Sordoni, Michel Galley, Michael Auli,
Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015.
A neural network approach to context-sensitive gen-
eration of conversational responses. arXiv preprint
arXiv:1506.06714 .
Pei-Hao Su, Milica Gasic, Nikola Mrksic, Lina Rojas-
Barahona, Stefan Ultes, David Vandyke, Tsung-
Hsien Wen, and Steve Young. 2016. Continu-
ously learning neural dialogue management. arXiv
preprint arXiv:1606.02689 .
Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to sequence learning with neural net-
works. In Advances in neural information process-
ing systems. pages 3104–3112.
Erik F Tjong Kim Sang and Fien De Meulder.
2003. Introduction to the conll-2003 shared task:
Language-independent named entity recognition. In
Proceedings of the seventh conference on Natural
language learning at HLT-NAACL 2003-Volume 4.
Association for Computational Linguistics, pages
142–147.
Grigorios Tsoumakas and Ioannis Katakis. 2006.
Multi-label classification: An overview. Interna-
tional Journal of Data Warehousing and Mining
3(3).
Oriol Vinyals and Quoc Le. 2015. A neural conversa-
tional model. arXiv preprint arXiv:1506.05869 .
Zhuoran Wang, Tsung-Hsien Wen, Pei-Hao Su,
and Yannis Stylianou. 2015. Learning domain-
independent dialogue policies via ontology parame-
terisation. In 16th Annual Meeting of the Special In-
terest Group on Discourse and Dialogue. page 412.
Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic, Pei-
Hao Su, David Vandyke, and Steve Young. 2015.
Semantically conditioned lstm-based natural lan-
guage generation for spoken dialogue systems.
arXiv preprint arXiv:1508.01745 .
Tsung-Hsien Wen, David Vandyke, Nikola Mrksic,
Milica Gasic, Lina M Rojas-Barahona, Pei-Hao Su,
Stefan Ultes, and Steve Young. 2016. A network-
based end-to-end trainable task-oriented dialogue
system. arXiv preprint arXiv:1604.04562 .
Jason Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan Black. 2013. The dialog state track-
ing challenge. In Proceedings of the SIGDIAL 2013
Conference. pages 404–413.
Jason Williams and Steve Young. 2003. Using wizard-
of-oz simulations to bootstrap reinforcement-
learning-based dialog management systems. In
Proceedings of the 4th SIGDIAL Workshop on
Discourse and Dialogue.
Jason D Williams, Kavosh Asadi, and Geoffrey
Zweig. 2017. Hybrid code networks: practical
and efficient end-to-end dialog control with super-
vised and reinforcement learning. arXiv preprint
arXiv:1702.03274 .
Jason D Williams and Geoffrey Zweig. 2016. End-
to-end lstm-based dialog control optimized with su-
pervised and reinforcement learning. arXiv preprint
arXiv:1606.01269 .
Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho,
Aaron C Courville, Ruslan Salakhutdinov, Richard S
Zemel, and Yoshua Bengio. 2015. Show, attend and
tell: Neural image caption generation with visual at-
tention. In ICML. volume 14, pages 77–81.
Zichao Yang, Phil Blunsom, Chris Dyer, and Wang
Ling. 2016. Reference-aware language models.
arXiv preprint arXiv:1611.01628 .
Steve J Young. 2006. Using pomdps for dialog man-
agement. In SLT . pages 8–13.
Zhou Yu, Alan W Black, and Alexander I Rudnicky.
2017. Learning conversational systems that inter-
leave task and non-task content. arXiv preprint
arXiv:1703.00099 .
Zhou Yu, Alexandros Papangelis, and Alexander Rud-
nicky. 2015. Ticktock: A non-goal-oriented mul-
timodal dialog system with engagement awareness.
In Proceedings of the AAAI Spring Symposium.
Wojciech Zaremba, Ilya Sutskever, and Oriol Vinyals.
2014. Recurrent neural network regularization.
arXiv preprint arXiv:1409.2329 .
Tiancheng Zhao, Alan W Black, and Maxine Eskenazi.
2015. An incremental turn-taking model with ac-
tive system barge-in for spoken dialog systems. In
16th Annual Meeting of the Special Interest Group
on Discourse and Dialogue. page 42.
Tiancheng Zhao and Maxine Eskenazi. 2016. Towards
end-to-end learning for dialog state tracking and
management using deep reinforcement learning. In
17th Annual Meeting of the Special Interest Group
on Discourse and Dialogue.
Tiancheng Zhao, Maxine Eskenazi, and Kyusong Lee.
2016. Dialport: A general framework for aggregat-
ing dialog systems. EMNLP 2016 page 32.
Tiancheng Zhao, Ran Zhao, and Maxine Eskenazi.
2017. Learning discourse-level diversity for neural
dialog models using conditional variational autoen-
coders. arXiv preprint arXiv:1703.10960 .

