International Journal of Advances in Engineering & Technology, Sept 2011. 
©IJAET                                                                                                          ISSN: 2231-1963 
127 Vol. 1, Issue 4, pp. 127-137  
 
IMPLEMENTATION OF PATTERN RECOGNITION 
TECHNIQUES AND OVERVIEW OF ITS APPLICATIONS IN 
VARIOUS AREAS OF ARTIFICIAL INTELLIGENCE  
 
1
S. P. Shinde, 
2
V.P.Deshmukh 
1
Deptt. of Computer, Bharati Vidyapeeth Univ., Pune, Y.M.I.M.Karad, Maharashtra, India. 
2
Deptt. of Management, Bharati Vidyapeeth Univ., Pune, Y.M.I.M.Karad, Maharashtra, India 
 
 
ABSTRACT:  
A pattern is an entity, vaguely defined, that could be given a name, e.g. fingerprint image, handwritten word, 
human face, speech signal, DNA sequence. Pattern recognition is the study of how machines can observe the 
environment, learn to distinguish patterns of interest from their background, and make sound and reasonable 
decisions about the categories of the patterns. The goal of pattern recognition research is to clarify complicated 
mechanisms of decision making processes and automatic these function using computers. Pattern recognition 
systems can be designed using the following main approaches: template matching, statistical methods, syntactic 
methods and neural networks. This paper reviews Pattern Recognition, Process, Design Cycle, Application, 
Models etc. This paper focuses on Statistical method of pattern Recognition.  
KEYWORDS: Pattern, Artificial Intelligence, statistical pattern recognition, Biometric Recognition, 
Clustering of micro array data. 
I. INTRODUCTION 
Humans have developed highly sophisticated skills for sensing their environment and taking actions 
according to what they observe, e.g.,  recognizing a face, understanding spoken words, reading 
handwriting, distinguishing fresh food from its smell. [1]This capability is called Human Perception: 
We would like to give similar capabilities to machines. Pattern recognition as a field of study 
developed significantly in the 1960s. It was very much an interdisciplinary subject, covering 
developments in the areas of statistics, engineering, artificial intelligence, computer science, 
psychology and physiology, among others. Human being has natural intelligence and so can recognize 
patterns. [3]A pattern is an entity, vaguely defined, that could be given a name, e.g. fingerprint image, 
handwritten word, human face, speech signal, DNA sequence. [1]Most of the children can recognize 
digits and letters by the time they are five years old, whereas young people can easily recognize small 
characters, large characters, handwritten, machine printed. The characters may be written on a 
cluttered background, on crumpled paper or may even be partially occluded. Pattern recognition is the 
study of how machines can observe the environment, learn to distinguish patterns of interest from 
their background, and make sound and reasonable decisions about the categories of the patterns. 
[5]But in spite of almost 50 years of research, design of a general purpose machine pattern recognizer 
remains an elusive goal.  The best pattern recognizers in most instances are humans, yet we do not 
understand how humans recognize patterns. The more relevant patterns at your disposal, the better 
your decisions will be. This is hopeful news to proponents of artificial intelligence, since computers 
can surely be taught to recognize patterns. Indeed, successful computer programs that help banks 
score credit applicants, help doctors diagnose disease and help pilots land airplanes.[4] Some 
examples of Pattern Recognition Applications to state here are as follows: 
 
International Journal of Advances in Engineering & Technology, Sept 2011. 
©IJAET                                                                                                          ISSN: 2231-1963 
128 Vol. 1, Issue 4, pp. 127-137  
 
 
 
Figure1: Fingerprint recognition. 
 
 
 
Figure2 : Biometric recognition. 
 
 
 
Figure3 : Pattern Classifier 
 
II. PATTERN  
A pattern is an entity, vaguely defined, that could be given a name, e.g. fingerprint image, handwritten 
word, human face, speech signal, DNA sequence. Patterns can be represented as (i) Vectors of real-
numbers,(ii)Lists of attributes(iii)Descriptions of parts and their relationships. Similar patterns should 
have similar representations. Patterns from different classes should have dissimilar representations. 
Choose features that are robust to noise and favor features that lead to simpler decision regions[23]. 
 
III. PATTERN RECOGNITION 
Pattern recognition techniques are used to automatically classify physical objects (2D or 3D) or 
abstract multidimensional patterns (n points in d dimensions) into known or possibly unknown 
categories. A number of commercial pattern recognition systems exist for character recognition, 
handwriting recognition, document classification, fingerprint classification, speech and speaker 
recognition, white blood cell (leukocyte) classification, military target recognition among others. 
Most machine vision systems employ pattern recognition techniques to identify objects for sorting, 
inspection, and assembly. The design of a pattern recognition system requires the following modules: 
sensing, feature extraction and selection, decision making, and system performance evaluation. The 
availability of low cost and high resolution sensors (e.g., CCD cameras, microphones and scanners) 
and data sharing over the Internet have resulted in huge repositories of digitized documents (text, 
speech, image and video). Need for efficient archiving and retrieval of this data has fostered the 
development of pattern recognition algorithms in new application domains (e.g., text, image and video 
retrieval, bioinformatics, and face recognition). [38] 
International Journal of Advances in Engineering & Technology, Sept 2011. 
©IJAET                                                                                                          ISSN: 2231-1963 
129 Vol. 1, Issue 4, pp. 127-137  
 
IV. GOAL OF PATTERN RECOGNITION 
1)  Hypothesize the models that describe the two populations. 
2)  Process the sensed data to eliminate noise. 
3)  Given a sensed pattern, choose the model that best represents it. 
 
V. VARIOUS AREAS OF PATTERN RECOGNITION 
1) Template matching:- The pattern to be recognized is matched against a stored template while 
taking 
     Into account all allowable pose (translation and rotation) and scale changes. 
2) Statistical pattern recognition:- Focuses on the statistical properties of the patterns (i.e., 
probability   
     Densities) 
3)  Artificial Neural Networks:- Inspired by biological neural network models. 
4)  Syntactic pattern recognition: - Decisions consist of logical rules or grammars[13] 
 
Generally, Pattern Recognition Systems follow the phases stated below. 
1) Data acquisition and sensing: Measurements of physical variables, Important issues: 
bandwidth, resolution, sensitivity, distortion, SNR, latency, etc. 
2) Pre-processing: Removal of noise in data, Isolation of patterns of interest from the 
background. 
3)  Feature extraction:  Finding a new representation in terms of features. 
4) Model learning and estimation: Learning a mapping between features and pattern groups and 
categories. 
5)  Classification: Using features and learned models to assign a pattern to a category. 
6) Post-processing: Evaluation of confidence in decisions, Exploitation of context to improve 
performance, Combination of experts. 
5.1 Important issues in the design of a PR system 
- Definition of pattern classes. 
- Sensing environment. 
- Pattern representation. 
- Feature extraction and selection. 
- Cluster analysis. 
- Selection of training and test examples. 
- Performance evaluation. 
 
VI. DESIGN OF A PATTERN RECOGNITION SYSTEM: 
 
 
Figure 4: The Design Cycle 
 
Patterns have to be designed in various steps expressed below:  
 Step 1)  Data collection: During this step Collect training and testing data. Next the question arises  
How can we know when we have adequately large and representative set of samples? 
Step 2)  Feature selection: During this step various details have to be investigated such as Domain 
dependence and prior information ,Computational cost and feasibility, Discriminative features, 
International Journal of Advances in Engineering & Technology, Sept 2011. 
©IJAET                                                                                                          ISSN: 2231-1963 
130 Vol. 1, Issue 4, pp. 127-137  
 
Similar values for similar patterns, Different values for different patterns, Invariant features with 
respect to translation, rotation and Scale,  Robust features with respect to occlusion, distortion, 
deformation, and variations in environment. 
Step 3)   Model selection: During this phase select models based on following criteria: Domain 
dependence and prior information., Definition of design criteria, Parametric vs. non-parametric 
models, Handling of missing features, Computational complexity Various types of models are : 
templates, decision-theoretic or statistical, syntactic or structural, neural, and hybrid. Using these 
models we can investigate how can we know how close we are to the true model underlying the 
patterns? 
Step 4) Training: Training phase deals with How can we learn the rule from data? 
 Supervised learning: a teacher provides a category label or cost for each pattern in the training set. 
 Unsupervised learning: the system forms clusters or natural groupings of the input patterns. 
Reinforcement learning: no desired category is given but the teacher provides feedback to the system 
such as the decision is right or wrong. 
Step) 5 Evaluation: During this phase in the design cycle some questions have to be answered such as 
how can we estimate the performance with training samples? How can we predict the performance 
with future data? Problems of over fitting and generalization.[18]  
6.1 Models in Pattern Recognition 
Pattern recognition systems can be designed using the following main approaches: (i) Template 
Matching, (ii) Statistical methods, (iii) Syntactic methods and (iv) Neural networks. This paper will 
introduce the fundamentals of statistical pattern recognition with examples from several application 
areas. Techniques for analyzing multidimensional data of various types and scales along with 
algorithms for projection, dimensionality reduction, clustering and classification of data will be 
explained.[1,2] 
Table 1: Models in Pattern Recognition 
Approach Representation  Recognition Function Typical Criterion 
Template Matching Samples, pixels, curves Correlation, distance 
measure 
Classification error 
Statistical Features Discriminant function Classification error 
Syntactic or Structural Primitives  Rules , grammar  Acceptance error 
Neural Network  Samples ,pixels, 
features  
Network Function  Mean square error 
VII. PROCESS FOR PATTERN RECOGNITION SYSTEMS 
As the figure 5 shows pattern recognition process has following steps. 
1) Data acquisition and sensing: Measurements of physical variables like bandwidth, resolution, 
sensitivity, distortion, SNR, latency, etc. 
2) Pre-processing: Removal of noise in data, Isolation of patterns of interest from the 
background. 
3)  Feature extraction: Finding a new representation in terms of features 
4) Model learning and estimation: Learning a mapping between features and pattern groups and 
categories. 
5) Classification: Using features and learned models to assign a pattern to a category. 
6) Post-processing: Evaluation of confidence in decisions, Exploitation of context to improve 
performance Combination of experts. 
 
International Journal of Advances in Engineering & Technology, Sept 2011. 
©IJAET                                                                                                          ISSN: 2231-1963 
131 Vol. 1, Issue 4, pp. 127-137  
 
 
Figure5: Process Diagram for Pattern Recognition system 
VIII. PATTERN RECOGNITION APPLICATIONS 
Overall Pattern recognition techniques find applications in many areas: machine learning, statistics, 
mathematics, computer science, biology, etc. There are many sub-problems in the design process; 
many of these problems can indeed be solved. More complex learning, searching and optimization 
algorithms are developed with advances in computer technology. There remain many fascinating 
unsolved problems. Pattern Recognition Applications to state here are English handwriting 
Recognition ,any other foreign language e.g. Chinese handwriting recognition, Fingerprint 
recognition, Biometric Recognition , Cancer detection and grading using microscopic tissue data, 
Land cover classification using satellite data, Building and non-building group recognition using 
satellite data ,Clustering of micro array data.[16] 
 
Table 2: Some of the examples of Pattern Recognition Applications 
Problem Domain Applications Input Pattern Pattern Classes 
Bioinformatics Sequence Analysis DNA/Protein Sequence Known types of genes or 
pattern 
Data Mining Searching for meaningful 
patterns 
Points in 
multidimensional space 
Compact and well 
separated clusters  
Document Classification  Internet search  Text Document  Semantic Categories  
Document Image 
Analysis 
Optical character 
recognition 
Document image Alphanumeric characters, 
word 
Industrial Automation  Printed circuit board 
inspection 
Intensity or range image Defective/ non- defective 
nature of product  
Multimedia Database  
retrieval  
Internet search Video clip Video genres (e.g. Action 
,dialogue etc)  
Biometric recognition Personal identification Face, iris, fingerprint Authorized users for 
access control  
Remote sensing Forecasting crop yield Multi spectral image Land use categories 
,growth patterns of crop  
Speech recognition Telephone directory Speech waveform Spoken words 
Medical Computer aided 
diagnosis 
Microscopic image   
Military Automatic target 
recognition 
Optical or infrared image Target type 
Natural language 
processing 
Information extraction Sentences Parts of speech  
International Journal of Advances in Engineering & Technology, Sept 2011. 
©IJAET                                                                                                          ISSN: 2231-1963 
132 Vol. 1, Issue 4, pp. 127-137  
 
IX. STATISTICAL PATTERN RECOGNITION 
Statistical pattern recognition is a term used to cover all stages of an investigation from problem 
formulation and data collection through to discrimination and classification, assessment of results and 
interpretation. Some of the basic terminology is introduced and two complementary approaches to 
discrimination described.[24] 
9.1 Steps in Statistical pattern recognition 
1. Formulation of the problem: gaining a clear understanding of the aims of the investigation and 
planning the remaining stages. 
2. Data collection: making measurements on appropriate variables and recording details of the data 
collection procedure (ground truth). 
3. Initial examination of the data: checking the data, calculating summary statistics and producing 
plots in order to get a feel for the structure. 
4. Feature selection or feature extraction: selecting variables from the measured set that are 
appropriate for the task. These new variables may be obtained by a linear or nonlinear transformation 
of the original set (feature extraction). To some extent, the division of feature extraction and 
classification is artificial. 
5. Unsupervised pattern classification or clustering. This may be viewed as exploratory data analysis 
and it may provide a successful conclusion to a study. On the other hand, it may be a means of 
preprocessing the data for a supervised classification procedure. 
6. Apply discrimination or regression procedures as appropriate. The classifier is designed using a 
training set of exemplar patterns. 
7. Assessment of results. This may involve applying the trained classifier to an independent test set of 
labeled patterns. 
8. Interpretation. [57] 
The above is necessarily an iterative process: the analysis of the results may pose further hypotheses 
that require further data collection. Also, the cycle may be terminated at different stages: the questions 
posed may be answered by an initial examination of the data or it may be discovered that the data 
cannot answer the initial question and the problem must be reformulated. The emphasis of this book is 
on techniques for performing steps 4, 5 and 6. 
9.2 Statistical pattern recognition Approach 
 In the statistical approach, each pattern is represented in terms of d features or measurements and is 
viewed as a point in a d-dimensional space. The goal is to choose those features that allow pattern 
vectors belonging to different categories to occupy compact and disjoint regions in a d-dimensional 
feature space. The effectiveness of the representation space (feature set) is determined by how well 
patterns from different classes can be separated. Given a set of training patterns from each class, the 
objective is to establish decision boundaries in the feature space which separate patterns belonging to 
different classes. In the statistical decision theoretic approach, the decision boundaries re determined 
by the probability distributions of the patterns belonging to each class, which must either be specified 
or learned . One can also take a discriminate analysis-based approach to classification: First a 
parametric form of the decision boundary (e.g., linear or quadratic) is specified; then the ªbestº 
decision boundary of the specified form is found based on the classification of training patterns. Such 
boundaries can be constructed using, for example, a mean squared error criterion. The direct boundary 
construction approaches are supported by Vapnik's philosophy [162]: ªIf you possess a restricted 
amount of information for solving some problem, try to solve the problem directly and never solve a 
more general problem as an intermediate step. It is possible that the available information is sufficient 
for a direct solution but is insufficient for solving a more general intermediate problem.[57] 
International Journal of Advances in Engineering & Technology, Sept 2011. 
©IJAET                                                                                                          ISSN: 2231-1963 
133 Vol. 1, Issue 4, pp. 127-137  
 
 
Figure6 : Model for statistical pattern recognition 
 
X. RESULT & DISCUSSION. 
Pattern recognition is a field of study developing significantly from 1960s. It was very much an 
interdisciplinary subject, covering developments in the areas of statistics, engineering, artificial 
intelligence, computer science, psychology and physiology, among others. Pattern Recognition is such 
a field in Artificial Intelligence which has applications in varied domain such as Bioinformatics, Data 
Mining, Document Classification, Document Image Analysis, and Industrial Automation, Multimedia, 
Database retrieval, Biometric recognition, Remote sensing, Speech recognition, Medical, Military, 
Natural language processing. Statistical pattern recognition Approach, in the statistical approach, each 
pattern is represented in terms of d features or measurements and is viewed as a point in a d-
dimensional space. The goal is to choose those features that allow pattern vectors belonging to 
different categories to occupy compact and disjoint regions in a d-dimensional feature space 
XI. AWARENESS OF RELATED WORK 
There are various examples of Pattern Recognition Applications namely Bioinformatics, Data Mining 
Document  Classification, Document Image Analysis, Industrial Automation, Multimedia Database 
retrieval, Biometric recognition, Remote sensing, Speech recognition,, Medical,, Military, Natural 
language processing where various Input Pattern such as DNA/Protein Sequence ,Points in 
multidimensional space, Text Document, Document image, Intensity or range image, Video clip, 
Face, iris, fingerprint, Multi spectral image, Speech waveform, Microscopic image, Optical or 
infrared image, Sentences to match the pattern classes such as Known types of genes or pattern 
,Compact and well separated clusters ,Semantic Categories ,Alphanumeric characters, word, 
Defective/ non- defective nature of product ,Video genres (e.g. Action ,dialogue etc) ,Authorized 
users for access control Land use categories ,growth patterns of crop ,Spoken words, Target type, 
Parts of speech. The researcher has a wide interest in this field and is trying to do research in 
Biometric recognition and maintenance of attendance in some organizations in India  
XII. CONCLUSIONS 
Pattern Recognition plays a very vital role in Artificial intelligence. But now a day’s pattern 
recognition has become a day to day activity in everyday’s life. As human beings have limitations in 
recognizing various items, the field of pattern recognition is becoming very popular. The goal of 
pattern recognition research to clarify complicated mechanisms of decision making processes and 
automatic these function using computers is implemented in day to day life. Pattern recognition has 
various applications in numerous fields as data mining, biometrics, sensors, speech recognition, 
medical, military, natural language processing etc. Statistical pattern recognition is used to cover all 
stages of an investigation from problem formulation and data collection through to discrimination and 
classification, assessment of results and interpretation. Here each pattern is represented in terms of d 
International Journal of Advances in Engineering & Technology, Sept 2011. 
©IJAET                                                                                                          ISSN: 2231-1963 
134 Vol. 1, Issue 4, pp. 127-137  
 
features or measurements and is viewed as a point in a d-dimensional space. The authors have deep 
interest in the same field and my further research will explore the same area. Pattern recognition 
applications include Sequence Analysis, Searching for meaningful patterns, Internet search, Optical 
character recognition, Printed circuit board inspection, Internet search, Personal identification, 
Forecasting crop yield, Telephone directory, Computer aided diagnosis, Automatic target recognition, 
Information extraction. Various approaches in Pattern Recognition are Template Matching, Statistical, 
Syntactic or Structural and Neural Network. In Statistical pattern recognition the analysis of the 
results may pose further hypotheses that require further data collection. Also, the cycle may be 
terminated at different stages: the questions posed may be answered by an initial examination of the 
data or it may be discovered that the data cannot answer the initial question and the problem must be 
reformulated. Pattern recognition techniques find applications in many areas: machine learning, 
statistics, mathematics, computer science, biology, etc. There are many sub-problems in the design 
process. Many of these problems can indeed be solved. More complex learning, searching and 
optimization algorithms are developed with advances in computer technology. There remain many 
fascinating unsolved problems 
REFERENCES   
[1] H.M. Abbas and M.M. Fahmy, ªNeural Networks for Maximum Likelihood Clustering,º Signal Processing, 
vol. 36, no. 1, pp. 111-126, 1994. 
[2] H. Akaike, ªA New Look at Statistical Model Identification,º IEEE Trans. Automatic Control, vol. 19, pp. 
716-723, 1974. 
[3] S. Amari, T.P. Chen, and A. Cichocki, ªStability Analysis of Learning Algorithms for Blind Source 
Separation,º Neural Networks,vol. 10, no. 8, pp. 1,345-1,351, 1997. 
[4] J.A. Anderson, ªLogistic Discrimination,º Handbook of Statistics. P. R. Krishnaiah and L.N. Kanal, eds., vol. 
2, pp. 169-191, Amsterdam: North Holland, 1982. 
[5] J. Anderson, A. Pellionisz, and E. Rosenfeld, Neurocomputing 2: Directions for Research. Cambridge Mass.: 
MIT Press, 1990. 
[6] A. Antos, L. Devroye, and L. Gyorfi, ªLower Bounds for Bayes Error Estimation,º IEEE Trans. Pattern 
Analysis and MachineIntelligence, vol. 21, no. 7, pp. 643-645, July 1999. 
[7] H. Avi-Itzhak and T. Diep, ªArbitrarily Tight Upper and Lower Bounds on the Bayesian Probability of 
Error,º IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 18, no. 1, pp. 89-91, Jan. 1996.  
[8] E. Backer, Computer-Assisted Reasoning in Cluster Analysis. Prentice Hall, 1995. 
[9] R. Bajcsy and S. Kovacic, ªMultiresolution Elastic Matching,º Computer Vision Graphics Image Processing, 
vol. 46, pp. 1-21, 1989. 
[10] A. Barron, J. Rissanen, and B. Yu, ªThe Minimum Description Length Principle in Coding and Modeling,º 
IEEE Trans. Information Theory, vol. 44, no. 6, pp. 2,743-2,760, Oct. 1998. 
[11] A. Bell and T. Sejnowski, ªAn Information-Maximization Approach to Blind Separation,º Neural 
Computation, vol. 7, pp. 1,004-1,034, 1995. 
[12] Y. Bengio, ªMarkovian Models for Sequential Data,º Neural Computing Surveys, vol. 2, pp. 129-162, 1999. 
http://www.icsi.berkeley.edu/~jagota/NCS. 
[13] K.P. Bennett, ªSemi-Supervised Support Vector Machines,º Proc. Neural Information Processing Systems, 
Denver, 1998. 
[14] J. Bernardo and A. Smith, Bayesian Theory. John Wiley & Sons, 1994. 
[15] J.C. Bedeck, Pattern Recognition with Fuzzy Objective Function Algorithms. New York: Plenum Press, 
1981. 
[16] Fuzzy Models for Pattern Recognition: Methods that Search for Structures in Data. J.C. Bezdek and S.K. 
Pal, eds., IEEE CS Press,1992. 
[17] S.K. Bhatia and J.S. Deogun, ªConceptual Clustering in Information Retrieval,º IEEE Trans. Systems, Man, 
and Cybernetics, vol. 28,no. 3, pp. 427-436, 1998. 
[18] C.M. Bishop, Neural Networks for Pattern Recognition. Oxford: Clarendon Press, 1995. 
[19] A.L. Blum and P. Langley, ªSelection of Relevant Features and Examples in Machine Learning,º Artificial 
Intelligence, vol. 97,nos. 1-2, pp. 245-271, 1997. 
[20] I. Borg and P. Groenen, Modern Multidimensional Scaling, Berlin: Springer-Verlag, 1997. 
[21] L. Breiman, ªBagging Predictors,º Machine Learning, vol. 24, no. 2  ,pp. 123-140, 1996. 
[22] L. Breiman, J.H. Friedman, R.A. Olshen, and C.J. Stone, Classification and Regression Trees. Wadsworth, 
Calif., 1984. 
[23] C.J.C. Burges, ªA Tutorial on Support Vector Machines for Pattern Recognition,º Data Mining and 
Knowledge Discovery, vol. 2, no. 2,pp. 121-167, 1998. 
International Journal of Advances in Engineering & Technology, Sept 2011. 
©IJAET                                                                                                          ISSN: 2231-1963 
135 Vol. 1, Issue 4, pp. 127-137  
 
[24] J. Cardoso, ªBlind Signal Separation: Statistical Principles,º Proc. IEEE, vol. 86, pp. 2,009-2,025, 1998. 
[25] C. Carpineto and G. Romano, ªA Lattice Conceptual Clustering System and Its Application to Browsing 
Retrieval,º Machine Learning, vol. 24, no. 2, pp. 95-122, 1996. 
[26] G. Castellano, A.M. Fanelli, and M. Pelillo, ªAn Iterative Pruning Algorithm for Feedforward Neural 
Networks,º IEEE Trans. Neural Networks, vol. 8, no. 3, pp. 519-531, 1997. 
[27] C. Chatterjee and V.P. Roychowdhury, ªOn Self-Organizing Algorithms and Networks for Class-
Separability Features,º IEEE Trans. Neural Networks, vol. 8, no. 3, pp. 663-678, 1997. 
[28] B. Cheng and D.M. Titterington, ªNeural Networks: A Review from Statistical Perspective,º Statistical 
Science, vol. 9, no. 1, pp. 2-54, 1994. 
[29] H. Chernoff, ªThe Use of Faces to Represent Points ink-Dimensional Space Graphically,º J. Am. Statistical 
Assoc.,vol. 68, pp. 361-368, June 1973. 
[30] P.A. Chou, ªOptimal Partitioning for Classification and RegressionTrees,º IEEE Trans. Pattern Analysis 
and Machine Intelligence,vol. 13, no. 4, pp. 340-354, Apr. 1991. 
[31] P. Comon, ªIndependent Component Analysis, a New Concept?,ºSignal Processing, vol. 36, no. 3, pp. 287-
314, 1994. 
[32] P.C. Cosman, K.L. Oehler, E.A. Riskin, and R.M. Gray, ªUsing Vector Quantization for Image Processing,º 
Proc. IEEE, vol. 81, pp. 1,326-1,341, Sept. 1993. 
[33] T.M. Cover, ªGeometrical and Statistical Properties of Systems of Linear Inequalities with Applications in 
Pattern Recognition,ºIEEE Trans. Electronic Computers, vol. 14, pp. 326-334, June 1965. 
[34] T.M. Cover, ªThe Best Two Independent Measurements are not the Two Best,º IEEE Trans. Systems, Man, 
and Cybernetics, vol. 4,pp. 116-117, 1974. 
[35] T.M. Cover and J.M. Van Campenhout, ªOn the Possible Orderings in the Measurement Selection 
Problem,º IEEE Trans. Systems, Man, and Cybernetics, vol. 7, no. 9, pp. 657-661, Sept. 1977. 
[36] A. Dempster, N. Laird, and D. Rubin, ªMaximum Likelihood from Incomplete Data via the (EM) 
Algorithm,º J. Royal Statistical Soc.,vol. 39, pp. 1-38, 1977. 
[37] H. Demuth and H.M. Beale, Neural Network Toolbox for Use with Matlab. version 3, Mathworks, Natick, 
Mass., 1998. 
[38] D. De Ridder and R.P.W. Duin, ªSammon's Mapping Using Neural Networks: Comparison,º Pattern 
Recognition Letters, vol. 18,no. 11-13, pp. 1,307-1,316, 1997. 
[39] P.A. Devijver and J. Kittler, Pattern Recognition: A Statistical Approach. London: Prentice Hall, 1982. 
[40] L. Devroye, ªAutomatic Pattern Recognition: A Study of the Probability of Error,º IEEE Trans. Pattern 
Analysis and Machine Intelligence, vol. 10, no. 4, pp. 530-543, 1988. 
[41] L. Devroye, L. Gyorfi, and G. Lugosi, A Probabilistic Theory of Pattern Recognition. Berlin: Springer-
Verlag, 1996. 
[42] A. Djouadi and E. Bouktache, ªA Fast Algorithm for the Nearest-Neighbor Classifier,º IEEE Trans. Pattern 
Analysis and Machine Intelligence, vol. 19, no. 3, pp. 277-282, 1997. 
[43] H. Drucker, C. Cortes, L.D. Jackel, Y. Lecun, and V. Vapnik, ªBoosting and Other Ensemble Methods,º 
Neural Computation, vol. 6, no. 6, pp. 1,289-1,301, 1994. 
[44] R.O. Duda and P.E. Hart, Pattern Classification and Scene Analysis, New York: John Wiley & Sons, 1973. 
[45] R.O. Duda, P.E. Hart, and D.G. Stork, Pattern Classification and Scene Analysis. second ed., New York: 
John Wiley & Sons, 2000. 
[46] R.P.W. Duin, ªA Note on Comparing Classifiers,º Pattern Recognition Letters, vol. 17, no. 5, pp. 529-536, 
1996. 
[47] R.P.W. Duin, D. De Ridder, and D.M.J. Tax, ªExperiments with a Featureless Approach to Pattern 
Recognition,º Pattern Recognition Letters, vol. 18, nos. 11-13, pp. 1,159-1,166, 1997.  
[48] B. Efron, The Jackknife, the Bootstrap and Other Resampling Plans.Philadelphia: SIAM, 1982. 
[49] U. Fayyad, G. Piatetsky-Shapiro, and P. Smyth, ªKnowledge Discovery and Data Mining: Towards a 
Unifying Framework,ºProc. Second Int'l Conf. Knowledge Discovery and Data Mining, Aug. 1999. 
[50] F. Ferri, P. Pudil, M. Hatef, and J. Kittler, ªComparative Study of Techniques for Large Scale Feature 
Selection,º Pattern Recognition in Practice IV, E. Gelsema and L. Kanal, eds., pp. 403-413, 1994. 
[51] M. Figueiredo, J. Leitao, and A.K. Jain, ªOn Fitting Mixture Models,º Energy Minimization Methods in 
Computer Vision and Pattern Recognition. E. Hancock and M. Pellillo, eds., Springer-Verlag, 1999. 
34 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 22, NO. 1, 
JANUARY 2000  
[52] Y. Freund and R. Schapire, ªExperiments with a New Boosting Algorithm,º Proc. 13th Int'l Conf. Machine 
Learning, pp. 148-156,1996. 
[53] J.H. Friedman, ªExploratory Projection Pursuit,º J. Am. Statistical Assoc., vol. 82, pp. 249-266, 1987. 
[54] J.H. Friedman, ªRegularized Discriminant Analysis,º J. Am.Statistical Assoc., vol. 84, pp. 165-175, 1989. 
[55] H. Frigui and R. Krishnapuram, ªA Robust Competitive Clustering Algorithm with Applications in 
Computer Vision,º IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 21,no. 5, pp. 450-465, 1999. 
International Journal of Advances in Engineering & Technology, Sept 2011. 
©IJAET                                                                                                          ISSN: 2231-1963 
136 Vol. 1, Issue 4, pp. 127-137  
 
[56] K.S. Fu, Syntactic Pattern Recognition and Applications. Englewood Cliffs, N.J.: Prentice-Hall, 1982. 
[57] K.S. Fu, ªA Step Towards Unification of Syntactic and StatisticalPattern Recognition,º IEEE Trans. Pattern 
Analysis and Machine Intelligence, vol. 5, no. 2, pp. 200-205, Mar. 1983. 
[58] K. Fukunaga, Introduction to Statistical Pattern Recognition. Second ed., New York: Academic Press, 990. 
[59] K. Fukunaga and R.R. Hayes, ªEffects of Sample Size in Classifier Design,º IEEE Trans. Pattern Analysis 
and Machine Intelligence, vol. 11, no. 8, pp. 873-885, Aug. 1989. 
[60] K. Fukunaga and R.R. Hayes, ªThe Reduced Parzen Classifier,ºIEEE Trans. Pattern Analysis and Machine 
Intelligence, vol. 11, no. 4,pp. 423-425, Apr. 1989. 
[61] K. Fukunaga and D.M. Hummels, ªLeave-One-Out Procedures for Nonparametric Error Estimates,º IEEE 
Trans. Pattern Analysis and Machine Intelligence, vol. 11, no. 4, pp. 421-423, Apr. 1989. 
[62] K. Fukushima, S. Miyake, and T. Ito, ªNeocognitron: A Neural Network Model for a Mechanism of Visual 
Pattern Recognition,ºIEEE Trans. Systems, Man, and Cybernetics, vol. 13, pp. 826-834,1983. 
[63] S.B. Gelfand, C.S. Ravishankar, and E.J. Delp, ªAn Iterative Growing and Pruning Algorithm for 
Classification Tree Design,ºIEEE Trans. Pattern Analysis and Machine Intelligence, vol. 13, no. 2, 
pp. 163-174, Feb. 1991. 
[64] S. Geman, E. Bienenstock, and R. Doursat, ªNeural Networks and the Bias/Variance Dilemma,º Neural 
Computation, vol. 4, no. 1, pp.1-58, 1992. 
[65] C. Glymour, D. Madigan, D. Pregibon, and P. Smyth, ªStatistical Themes and Lessons for Data Mining,º 
Data Mining and Knowledge Discovery, vol. 1, no. 1, pp. 11-28, 1997. 
[66] M. Golfarelli, D. Maio, and D. Maltoni, ªOn the Error-Reject Trade-Off in Biometric Verification System,º 
IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 19, no. 7, pp. 786-796, July1997. 
[67] R.M. Gray, ªVector Quantization,º IEEE ASSP, vol. 1, pp. 4-29, Apr. 1984. 
[68] R.M. Gray and R.A. Olshen, ªVector Quantization and Density Estimation,º Proc. Int'l Conf. Compression 
and Complexity of Sequences, 1997. http://www-isl.stanford.edu/~gray/ compression.html. 
[69] U. Grenander, General Pattern Theory. Oxford Univ. Press, 1993.  
[70] D.J. Hand, ªRecent Advances in Error Rate Estimation,º Pattern Recognition Letters, vol. 4, no. 5, pp. 335-
346, 1986. 
[71] M.H. Hansen and B. Yu, ªModel Selection and the Principle of Minimum Description Length,º technical 
report, Lucent Bell Lab,Murray Hill, N.J., 1998. 
[72] M.A. Hearst, ªSupport Vector Machines,º IEEE Intelligent Systems,pp. 18-28, July/Aug. 1998. 
[73] S. Haykin, Neural Networks, A Comprehensive Foundation. Second ed., Englewood Cliffs, N.J.: Prentice 
Hall, 1999. 
[74] T. K. Ho, J.J. Hull, and S.N. Srihari, ªDecision Combination in Multiple Classifier Systems,º IEEE Trans. 
Pattern Analysis and Machine Intelligence, vol. 16, no. 1, pp. 66-75, 1994. 
[75] T.K. Ho, ªThe Random Subspace Method for Constructing Decision Forests,º IEEE Trans. Pattern Analysis 
and Machine Intelligence, vol. 20, no. 8, pp. 832-844, Aug. 1998. 
[76] J.P. Hoffbeck and D.A. Landgrebe, ªCovariance Matrix Estimation and Classification with Limited 
Training Data,º IEEE Trans.Pattern Analysis and Machine Intelligence, vol. 18, no. 7, pp. 763-767, 
July 1996. 
[77] A. Hyvarinen, ªSurvey on Independent Component Analysis,ºNeural Computing Surveys, vol. 2, pp. 94-
128, 1999. http://www.icsi.berkeley.edu/~jagota/NCS. 
[78] A. Hyvarinen and E. Oja, ªA Fast Fixed-Point Algorithm for Independent Component Analysis,º Neural 
Computation, vol. 9,no. 7, pp. 1,483-1,492, Oct. 1997. 
[79] R.A. Jacobs, M.I. Jordan, S.J. Nowlan, and G.E. Hinton, ªAdaptive Mixtures of Local Experts,º Neural 
Computation, vol. 3, pp. 79-87,1991. 
[80] A.K. Jain and B. Chandrasekaran, ªDimensionality and Sample Size Considerations in Pattern Recognition 
Practice,º Handbook of Statistics. P.R. Krishnaiah and L.N. Kanal, eds., vol. 2, pp. 835-855,Amsterdam: North-
Holland, 1982. 
[81] A.K. Jain and R.C. Dubes, Algorithms for Clustering Data. Englewood Cliffs, N.J.: Prentice Hall, 1988. 
[82] A.K. Jain, R.C. Dubes, and C.-C. Chen, ªBootstrap Techniques for Error Estimation,º IEEE Trans. Pattern 
Analysis and Machine Intelligence, vol. 9, no. 5, pp. 628-633, May 1987. 
[83] A.K. Jain, J. Mao, and K.M. Mohiuddin, ªArtificial Neural Networks: A Tutorial,º Computer, pp. 31-44, 
Mar. 1996. 
[84] A. Jain, Y. Zhong, and S. Lakshmanan, ªObject Matching Using Deformable Templates,º IEEE Trans. 
Pattern Analysis and Machine Intelligence, vol. 18, no. 3, Mar. 1996. 
[85] A.K. Jain and D. Zongker, ªFeature Selection: Evaluation,Application, and Small Sample Performance,º 
IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 19, no. 2, pp. 153-158, Feb. 1997. 
[86] F. Jelinek, Statistical Methods for Speech Recognition. MIT Press,1998. 
[87] M.I. Jordan and R.A. Jacobs, ªHierarchical Mixtures of Experts and the EM Algorithm,º Neural 
Computation, vol. 6, pp. 181-214,1994. 
International Journal of Advances in Engineering & Technology, Sept 2011. 
©IJAET                                                                                                          ISSN: 2231-1963 
137 Vol. 1, Issue 4, pp. 127-137  
 
[88] D. Judd, P. Mckinley, and A.K. Jain, ªLarge-Scale Parallel Data Clustering,º IEEE Trans. Pattern Analysis 
and Machine Intelligence,vol. 20, no. 8, pp. 871-876, Aug. 1998. 
[89] L.N. Kanal, ªPatterns in Pattern Recognition: 1968-1974,º IEEE Trans. Information Theory, vol. 20, no. 6, 
pp. 697-722, 1974. 
[90] J. Kittler, M. Hatef, R.P.W. Duin, and J. Matas, ªOn Combining Classifiers,º IEEE Trans. Pattern Analysis 
and Machine Intelligence,vol. 20, no. 3, pp. 226-239, 1998. 
[91] R.M. Kleinberg, ªStochastic Discrimination,º Annals of Math. And Artificial Intelligence, vol. 1, pp. 207-
239, 1990.  
[92] T. Kohonen, Self-Organizing Maps. Springer Series in Information  Sciences, vol. 30, Berlin, 1995. 
[93] A. Krogh and J. Vedelsby, ªNeural Network Ensembles, Cross Validation, and Active Learning,º Advances 
in Neural Information Processing Systems, G. Tesauro, D. Touretsky, and T. Leen, eds.,vol. 7, Cambridge, 
Mass.: MIT Press, 1995. 
[94] L. Lam and C.Y. Suen, ªOptimal Combinations of Pattern Classifiers,º Pattern Recognition Letters, vol. 16, 
no. 9, pp. 945-954, 1995. 
[95] Y. Le Cun, B. Boser, J.S. Denker, D. Henderson, R.E. Howard, W. Hubbard, and L.D. Jackel, ªBack 
propagation Applied to Handwritten Zip Code Recognition,º Neural Computation, vol. 1,pp. 541-551, 1989. 
[96] T.W. Lee, Independent Component Analysis. Dordrech: Kluwer Academic Publishers, 1998. 
[97] C. Lee and D.A. Landgrebe, ªFeature Extraction Based on Decision Boundaries,º IEEE Trans. Pattern 
Analysis and Machine Intelligence, vol. 15, no. 4, pp. 388-400, 1993. 
[98] B. Lerner, H. Guterman, M. Aladjem, and I. Dinstein, ªA Comparative Study of Neural Network Based 
Feature Extraction Paradigms,º Pattern Recognition Letters vol. 20, no. 1, pp. 7-14, 1999 
[99] D.R. Lovell, C.R. Dance, M. Niranjan, R.W. Prager, K.J. Dalton,and R. Derom, ªFeature Selection Using 
Expected Attainable Discrimination,º Pattern Recognition Letters, vol. 19, nos. 5-6,pp. 393-402, 1998. 
[100] D. Lowe and A.R. Webb, ªOptimized Feature Extraction and the Bayes Decision in Feed-Forward 
Classifier Networks,º IEEE Trans.Pattern Analysis and Machine Intelligence, vol. 13, no. 4, pp. 355-264, 
Apr. 1991. 
[101] D.J.C. MacKay, ªThe Evidence Framework Applied to Classification Networks,º Neural Computation, 
vol. 4, no. 5, pp. 720-736,1992. 
[102] J.C. Mao and A.K. Jain, ªArtificial Neural Networks for Feature Extraction and Multivariate Data 
Projection,º IEEE Trans. Neural Networks, vol. 6, no. 2, pp. 296-317, 1995. 
[103] J. Mao, K. Mohiuddin, and A.K. Jain, ªParsimonious Network Design and Feature Selection through Node 
Pruning,º Proc. 12thInt'l Conf. Pattern on Recognition, pp. 622-624, Oct. 1994. 
[104] J.C. Mao and K.M. Mohiuddin, ªImproving OCR Performance Using Character Degradation Models and 
Boosting Algorithm,ºPattern Recognition Letters, vol. 18, no. 11-13, pp. 1,415-1,419, 1997. 
 
AUTHORS BIOGRAPHY  
 
S. P. Shinde is an Assistant Professor in Department of computers, Bharati Vidyapeeth Deemed 
University, Pune, Yashwantrao Mohite Institute of Management Karad .She is a research student 
in Shivaji University, Kolhapur. She is a post graduate in computers having Degrees M.C.A And 
M.Phil.. Her area of interest is in various advancements in the field of Artificial Intelligence i.e. 
Pattern recognition, Speech Recognition , Various search Algorithms to find a solution to the 
problem ,Decision Support System and Expert System and so on . Her further research area is in 
the same field. 
 
    
V. P. Deshmukh is an Assistant Professor in Department of Management, Bharati Vidyapeeth 
Deemed University, Pune , Yashwantrao Mohite Institute of Management Karad .He is a post 
graduate in management having Degree M.B.A  and is a research student . His area of interest is 
in various advancements in the field of operations research. His further research area is in the 
same field where he want to study various models in operations research.  

