The Fusion of Biology, Computer Science, and Engineering: Towards
Efficient and Successful Synthetic Biology
Gregory Linshiz, Alex Goldberg, Tania Konry, Nathan J. Hillson
Perspectives in Biology and Medicine, Volume 55, Number 4, Autumn
2012, pp. 503-520 (Article)
Published by The Johns Hopkins University Press
DOI: 10.1353/pbm.2012.0044
For additional information about this article
                                                       Access provided by Harvard University (9 Jan 2014 09:51 GMT)
http://muse.jhu.edu/journals/pbm/summary/v055/55.4.linshiz.html
*Fuels Synthesis Division, Joint BioEnergy Institute, Emeryville, CA.
†Physical BioSciences Division, Lawrence Berkeley National Labs, Berkeley.
‡Center for Engineering in Medicine and Department of Surgery,Massachusetts General Hospital,
Harvard Medical School, Boston.
Corresponding authors:Gregory Linshiz or Nathan J.Hillson, Joint BioEnergy Institute (JBEI), 5885
Hollis Street, 4th Floor, Emeryville, CA 94608.
E-mail: glinshiz@lbl.gov; njhillson@lbl.gov.
Perspectives in Biology and Medicine, volume 55, number 4 (autumn 2012):503–20
© 2013 by The Johns Hopkins University Press
ABSTRACT Synthetic biology is a nascent field that emerged in earnest only
around the turn of the millennium. It aims to engineer new biological systems and im-
part new biological functionality, often through genetic modifications.The design and
construction of new biological systems is a complex, multistep process, requiring mul-
tidisciplinary collaborative efforts from “fusion” scientists who have formal training in
computer science or engineering, as well as hands-on biological expertise.The public
has high expectations for synthetic biology and eagerly anticipates the development of
solutions to the major challenges facing humanity. This article discusses laboratory
practices and the conduct of research in synthetic biology. It argues that the fusion sci-
ence approach, which integrates biology with computer science and engineering best
practices, including standardization, process optimization, computer-aided design and
laboratory automation, miniaturization, and systematic management, will increase the
predictability and reproducibility of experiments and lead to breakthroughs in the con-
struction of new biological systems.The article also discusses several successful fusion
503
The Fusion of Biology,
Computer Science, and
Engineering
towards efficient and successful
synthetic biology
Gregory Linshiz,*† Alex Goldberg,‡ Tania Konry,‡
and Nathan J. Hillson*†
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 503
projects, including the development of software tools for DNA construction design
automation, recursive DNA construction, and the development of integrated microflu-
idics systems.
THE INTEGRATION OF computer science, biology, and engineering has re-sulted in the emergence of rapidly growing interdisciplinary fields such as
bioinformatics, bioengineering, DNA computing, and systems and synthetic
biology. Ideas derived from computer science and engineering can provide inno-
vative solutions to biological problems and advance research in new directions.
Although interdisciplinary research has become increasingly prevalent in recent
years, the scientists contributing to these efforts largely remain specialists in their
original disciplines and are not fully capable of covering the many facets of mul-
tidisciplinary problems, which impedes the development of truly integrated
solutions. It would be beneficial for the scientists working in a multidisciplinary
life sciences environment to have hands-on biological experience as well as for-
mal training in computer science or engineering.These “fusion” scientists would
be capable of comprehensively analyzing biological systems and would have a
deep understanding of interdisciplinary approaches, their integration, and effi-
cient implementation. Fusion scientists would be able to bridge communication
gaps between the various research fields and lead interdisciplinary projects.
Modern physics, which has fully integrated physics, mathematics, and engineer-
ing, presents a successful historical example of fusion science.
A significant obstacle to putting the fusion science approach in to practice is
that it is currently difficult to implement a “fusion” scientist training program.
Today, few educational institutions offer what could be considered fusion biol-
ogy training programs. Given that educational institutions have limited amounts
of time to train students, the challenge is to develop curricula that provide con-
comitant depth and breadth.Without breadth, there is no fusion; without depth,
it is difficult for trainees to make important new contributions.While there may
not be a straightforward means to effectively execute a fusion science training
program at present, it will become easier to do so as fusion scientists themselves
begin to train students, and as training curricula are no longer forcibly split be-
tween different academic departments.
Synthetic Biology as Fusion Science
The development of synthetic biology is an attempt at fusion science. Synthetic
biology explores nature not only through observation and systematization, but
also through the construction and experimental assessment of new biological
systems, such as metabolic pathways, genetic control circuitry, and even entire or-
ganisms (Collins 2012; Khalil and Collins 2010).To pursue new complex bio-
logical systems in the most effective manner possible, thorough system analysis
Perspectives in Biology and Medicine
Gregory Linshiz et al.
504
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 504
505autumn 2012 • volume 55, number 4
The Fusion of Biology, Computer Science, and Engineering
should be conducted to present complex problems as hierarchies of abstract lay-
ers, and all system components and processes should be standardized, well
described, and readily available (Ho-Shing et al. 2012). The standardization of
biological processes and components itself enables multiple hierarchical levels of
system abstraction (Heinemann and Panke 2006; Müller and Arndt 2012). Such
abstraction enables the organization of biological systems in a manner similar to
the object-oriented approach taken in computer science.These structured rep-
resentations of biological systems facilitate the development of laboratory and
data management platforms for conducting biological research in a more effi-
cient, methodical, and organized way.
The construction of new biological systems often requires the reprogram-
ming of genetic information and thereby extensive de novo DNA synthesis
(Bashor et al. 2010).A deep understanding of a biological system’s environmen-
tal interactions (i.e., input and output), as well as its intracellular processes is
required to determine which genetic modifications are necessary to achieve a
given behavior (Gendrault et al. 2011). Computer science can assist in building
models to describe these interactions and processes, and the models can be uti-
lized to predict the sets of genetic modifications to be achieved by DNA con-
struction (Shuler, Foley, and Atlas 2012).
DNA Construction Methods
DNA construction technology is at the core of synthetic biology, and there
have been several significant breakthroughs over the past few years. Decreases in
DNA oligonucleotide synthesis prices along with the development of new DNA
assembly technologies, have led to trends in decreasing DNA construction costs
(Figure 1A) and increasing DNA molecule lengths (Figure 1B; Carlson 2009,
2011; Ellis,Adie, and Baldwin 2011; Hillson 2011;Mueller, Coleman, andWim-
mer 2009).The first synthetic DNA, constructed in 1979, consisted of 207 nu-
cleotides (Khorana 1979). In 2008, the first synthetic microbial genome was
reported, consisting of 1.08-Mbp (Gibson et al. 2010).
All modern DNA construction methods assemble small fragments into larger
DNA molecules. De novo DNA synthesis begins with a set of short single-
stranded DNA oligonucleotides, which are then assembled together into larger
double-stranded DNA fragments via ligase chain reaction (LCR) or assembly
PCR (Au et al. 1998;Ma,Tang, andTian 2012; Xiong et al. 2006). Synthetic and
natural DNA fragments can then be assembled together with a variety of meth-
ods to yield even longer DNA molecules. Several in vitro DNA assembly meth-
ods, including BioBricks, BglBricks, and type IIs endonuclease methods (e.g.,
Golden Gate, MoClo, and GoldenBraid), employ standardized restriction en-
zyme protocols (Anderson et al. 2010; Engler et al. 2009; Sarrion-Perdigones et
al. 2011; Shetty, Endy, and Knight 2008; Werner et al. 2012). A hierarchical
method for recursive DNA construction from oligonucleotides and natural frag-
ments that utilizes a divide-and-conquer (D&C) approach is capable of assem-
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 505
Perspectives in Biology and Medicine
Gregory Linshiz et al.
506
Trends in synthetic DNA price and length. (Top) Per base DNA oligonucleotide (lower line) and per
base-pair synthetic DNA (upper line) prices. (Bottom) Longest published synthetic DNA lengths.
SOURCE: BAKER 2011; CARLSON 2009, 2011.
Figure 1
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 506
507autumn 2012 • volume 55, number 4
The Fusion of Biology, Computer Science, and Engineering
bling long error-free DNA molecules from error-prone fragments (BenYehezkel
et al. 2008; Linshiz et al. 2008). Flanking homology sequence overlap DNA
assembly methods, such as the in vitro In-Fusion, SLIC, CPEC, SLiCE, and
Gibson methods, as well as the in vivo yeast and Bacillus DNA assembly meth-
ods, are fairly sequence-independent and capable of constructing DNA mole-
cules as long as an entire microbial genome (Ellis,Adie, and Baldwin, 2011; Gib-
son 2009; Hillson 2011; Irwin et al. 2012; Li and Elledge 2012; Ohtani et al.
2012; Quan and Tian 2011; Shao, Zhao, and Zhao 2009; Zhang,Werling, and
Edelmann 2012).
Continued innovation of DNA construction technology, both methodology
and software design automation tools, is required to increase the profitability of
the synthetic biology products.
Synthetic Biology: Hype and Expectations
The global synthetic biology market totaled over $1.6 billion in 2011 and is ex-
pected to reach $10.8 billion by 2016, increasing at a compound annual growth
rate (CAGR) of 45.8% (BCC Research 2011).The synthetic biology market can
be broken down into three segments: enabling technologies, core products, and
enabled products. Enabling technologies drive the development of the synthetic
biology industry, while core products, including standardized DNA parts, syn-
thetic genes, and chassis organisms, form the basis of the cellular factories and
systems that enable production. Enabled products, including pharmaceuticals,
diagnostic tools, chemicals, biofuels, and agricultural products, target large
downstream market opportunities. Since each of these downstream markets is
annually worth tens of billions of dollars, there are optimistic expectations for
the CAGR of synthetic biology.
The Gartner hype cycle characterizes the progressive developmental stages
that each nascent technology passes through, from emergence to adoption (Fig-
ure 2). Synthetic biology began to emerge in earnest around the turn of the mil-
lennium. Expectations for the success of the synthetic biology approach are cur-
rently very high, especially after the publication of the synthesis of first synthetic
cell genome and the construction of a synthetic pathway for the production of
a precursor to the anti-malarial drug artemisinin (Baker 2011; Gibson et al.
2010; Ro et al. 2006). Synthetic biology has recently achieved high visibility in
the popular media, and the development of successful synthetic biology applica-
tions capable of solving health-care problems and providing solutions for biofuel
production and other major challenges are eagerly anticipated (Weber and Fus-
senegger 2012). According to the Gartner hype cycle, successful synthetic biol-
ogy applications should appear in the coming years, but not before a period of
public disillusionment.To ensure that synthetic biology successfully matures to
its plateau of productivity, we suggest in the following sections a framework for
the development of synthetic biology based on the fusion science approach.
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 507
Laboratory and Project Management
Scientific Information Cloud
Modern research requires multi-level project management and the accurate
recording of protocols and results (Prilusky et al. 2005;Vu et al. 2012). Inaccurate
project management and imprecise protocol recording lead to experimental data
loss, irreproducible experiments, production of redundant data, and a lack of sci-
entific transparency. Pharmaceutical companies and scientists from academia
report that more than half of academic research is not reproducible (Begley and
Ellis 2012; Ioannidis et al. 2009; Mullard 2011).
As an overall solution, we envision the development of a “scientific informa-
tion cloud” for the management and documentation of research projects. This
system would allow scientists to define projects at a high level of abstraction and
would facilitate the division of projects into subtasks assigned to team members.
Group leaders and lab members would define which protocols would be used at
each step of the project according to project analysis, available technical re-
sources, and prior experience. All protocols would be stored in the system, and
each change in a protocol tracked by version control. Results from each exper-
iment would be stored in the database and linked to the exact protocol that has
produced the results. Security policies would govern which people have access
508
Gregory Linshiz et al.
Perspectives in Biology and Medicine
Figure 2
Gartner hype cycle for synthetic biology.
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 508
to which scientific data, allowing for quick online data access, efficient collabo-
ration, and research transparency. The system would produce reports linked to
primary data, enhancing manuscript preparation efficiency and scientific relia-
bility, while reducing occurrences of irreproducible experiments. Manuscripts
would provide links to the scientific information cloud for public access to pri-
mary data and protocols, contributing to the standardization of experimental
protocols, laboratory device input/output, and data representation.The scientific
information cloud would gradually emerge as a scientific social network and a
comprehensive solution for concentrating scientific knowledge.
Communication Tools
The success of fusion science depends on efficient interdisciplinary commu-
nication, which may require the development of new expressive languages. Ex-
amples of lingua franca that provide communication bridges between biology
and computer science include script-based and graphical design tools for com-
binatorial DNA libraries, such as the Eugene (any resemblance to eugenics is
purely coincidental) biological design specification language and the Device-
Editor visual biological CAD canvas ( Bilitchenko et al. 2011; Chen et al. 2012).
Both Eugene and DeviceEditor enable abstract, high-level definitions of DNA
constructs and provide easy, compact, and flexible means of representing combi-
natorial DNA libraries, making the logic and rationale behind the DNA library
easy to understand. Not only does a defining DNA library with Eugene or De-
viceEditor serve as a communication tool that helps computer scientists better
understand the biologists’ needs, it also provides a platform for more inspired and
creative biological thinking.
Laboratory Evolution:
Automation and Scaling Down
Robot Programming Language
The development of biology-friendly robotic platforms and software tools is a
crucial step towards laboratory process automation.The current lack of such tools
is a major obstacle for the modernization of the life sciences. Many well-funded
research laboratories are equipped with liquid-handling robots that aim to accel-
erate research, save time, and provide high-throughput solutions.While proudly
shown to visitors during laboratory tours, these robots frequently remain under-
utilized with very low duty cycles. A simple explanation for this is that it often
requires a researcher more effort and time to instruct a robot to perform a new
task than the robot saves the researcher in performing the task. In other words, it
is a net loss for the researcher to use the robot. Since liquid-handling robotic
companies have largely targeted the lucrative, highly repetitive industrial opera-
tions market, there has been little effort devoted to developing easy-to-use pro-
gramming tools targeted at dynamic (non-repetitive) research environments.
The Fusion of Biology, Computer Science, and Engineering
autumn 2012 • volume 55, number 4 509
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 509
To help close this gap, we are developing a new biology-friendly high-level
language in our laboratory.The syntax and compiler for the language are based
on computer science principles and a deep understanding of biological needs.
Our language allows researchers to use liquid-handling robots effectively, en-
abling a plethora of new experiments that would not have been considered pre-
viously. After minimal training, a biologist can independently write relatively
complicated protocols for a robot within a half an hour.This is a good example
of how biology-friendly programming languages can give a real boost to re-
search and open new horizons for innovative scientific directions.
From Macro to Micro
Liquid-handling robots, though a good step towards laboratory automation,
are expensive and have large footprints, and they are well outside of the bud-
getary reach of many laboratories. Furthermore, the minimum accurate pipet-
ting volumes for these robots (frequently 2–5 µL) result in the inefficient uti-
lization of costly reagents. Performing automated laboratory operations on small
scales and increasing experiments throughput, using miniaturized microfluidic
lab-on-a-chip (LOC) devices, is the next step forward in biotechnology (Mark
et al. 2010).
Microfluidic devices integrate and scale down laboratory processes to a micro-
chip format by allowing fluid manipulation in tiny channels and micro reactors
instead of traditional test tubes. Microfluidic devices are used in a wide array of
biological and analytical applications, including rapid pathogen detection, clinical
diagnostics, forensic science, electrophoresis, flow cytometry, blood chemistry
analysis, and protein and DNA analysis (Gulati et al. 2009;Haeberle and Zengerle
2007). Furthermore, LOC has the potential to offer point-of-care diagnostic abil-
ities that could revolutionize medicine (Chin, Linder, and Sia 2007).The fusion
of microfluidic technology, computer science, and synthetic biology should lead
to the development of new applications, such as DNA construction and high-
throughput screening within a single microfluidic device.The design and fabri-
cation of microfluidic systems is a complex task that requires a multidisciplinary
approach. Computer-aided design is critical in the development of successful
microfluidic devices, facilitating the design of optimal fluidic channel topology,
modeling fluid flow, controlling reagent and information flow, and supporting
data collection and processing (Amarasinghe,Amin, andThies 2009; Chakrabarty
and Zeng 2006; Mark et al. 2010;Vangelooven and Desmet 2010).
From Micro to Nano
Although microfluidics itself is a recent and advanced technology, the next
step would be to take biological research to the nano level (Jain 2003; Kumar
2010). Nanotechnology refers to understanding and control of matter at the
atomic, molecular or macromolecular levels, at the length scale of approximately
1–100 nanometers. Until recently, nanotechnology concentrated almost entirely
510
Gregory Linshiz et al.
Perspectives in Biology and Medicine
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 510
on electronics, computers, telecommunications, and materials manufacture.
Now, biomedical nanotechnology has emerged, in which bioengineers construct
tiny nano-scale bio-structures that combine inorganic and biological materials
(Hurst 2011). Recently very interesting and complex nano-scale structures have
been built from biopolymers, such as DNA molecules and proteins (Yeates 2011;
Zhang et al. 2011).The manipulation of biological materials on the nano-scale
level opens new perspectives for the creation of new biosensor applications,
measurements of single molecule–level biochemical reactions, high-throughput
DNA sequencing, and the construction of new nano biomaterials with unique
properties (Kumar et al. 2011).
Standardization
The standardization of components and processes has led to major advances in
mature engineering disciplines such as mechanical and electrical engineering.
The capacity to quickly and reliably engineer multi-component systems from
libraries of standardized interchangeable parts is a hallmark of modern tech-
nologies. However, to a great extent, the design and construction of engineered
biological systems remains an ad hoc process for which costs, completion times,
and probabilities of success are difficult to estimate accurately.The standardiza-
tion of protocols, tools, biological parts, and processes management is a basic
principle of synthetic biology (de Lorenzo 2010; Müller and Arndt 2012).
The standardization of biological protocols would help produce more reliable
and reproducible experiments. Ideally, experiments would be performed using
standardized labware, so that each experiment could be conducted with the
same (or at least comparable) devices across different laboratories.The protocols
would use standardized input (definition of experiments) and output (the results)
formats that reference standard lab devices.These protocols would evolve until
ultimately only the most successful protocols, validated across laboratories, are
accepted as community standards.
Another crucial step is the standardization of computational tools, as well as
data processing, storage, and representation.The Synthetic Biology Open Lan-
guage (SBOL) is a major community-based initiative in this direction that seeks
to standardize not only the data representation but also the visual depiction of
biological components (Galdzicki et al. 2011). For monitoring and managing
research projects, the development of a multi-level transparent system, such as
the scientific information cloud described above, is required.
Reuse of standardized biological parts, such as promoters, ribosome binding
sides, coding regions, and terminators, is another very important component of
standardization.These biological parts are informatically as well as physically de-
posited in, and accessible from, community repositories such as the Registry of
Standardized Parts, the JBEI-ICE repository platform, the DNASU plasmid re-
pository, and AddGene (Cormier et al. 2010; Ham et al. 2012; Herscovitch et al.
The Fusion of Biology, Computer Science, and Engineering
autumn 2012 • volume 55, number 4 511
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 511
2012; Müller and Arndt 2012). The standardization of biological parts enables
the rapid and inexpensive construction of sophisticated pathways and new bio-
logical systems.
Standardization facilitates the description and annotation of these new bio-
logical systems. Furthermore, since the behavior of each standardized system
component is known from previous experimental data, standardization also
enables the simulation of new biological systems and pathways. Reliable in sil-
ico simulation, a key portion of the engineering design-build-test cycle, prom-
ises to reduce the amount of requisite biological wet lab experiments, thereby
lowering the cost of new biological systems development, as experiments are
much more expensive than simulation.
System Optimization
One of the major goals of synthetic biology is to optimize biological application
development, reducing the time and cost to product. Even with standardized
tools for engineering new biological systems, the time to reaching functionality
(the time to product) is very long, since reprogramming and debugging biolog-
ical systems is a complicated and resource-intensive process (Figure 3A). Engi-
neering disciplines widely utilize iterative approaches for system optimization,
and there is a broad range of iterative algorithms that help solve challenging
optimization problems.The adoption of an iterative approach in synthetic biol-
ogy would help reduce the time to product and make the development of bio-
logical systems fast, inexpensive, and robust (FIRst; Figure 3B).
The iterative protein design cycle applies the iterative approach to the optimiza-
tion of biological systems.This method utilizes efficient automated DNA con-
struction and high-throughput screening and identifies promising bio-catalysts
through an iterative semi-rational design and directed evolution process (Figure
4). Each iteration includes four stages: the design of the DNA library, the con-
struction of the DNA molecules, the expression and screening of the proteins,
and the evaluation of the results.At the stage of DNA synthesis, the hierarchical
structure of synthesis methods enables the creation of granular combinatorial
libraries that contribute to efficient protein optimization.The main power of the
approach lies in the reuse of DNA sequence parts, created in previous rounds,
for the construction of the sequences required in the next iteration of the cycle.
This significantly reduces the cost and time of the DNA construction phase.
Screening rationally designed libraries can dramatically reduce the number of
selection rounds and the number of activity assays in each round, which are a
major cost in the development of new enzymatic properties.
In the iterative semi-rational approach, the identification of candidate proteins
is initially derived from multiple sequence alignments (producing a set of puta-
tive permissive mutations) and from protein structure insights.The results from
512
Gregory Linshiz et al.
Perspectives in Biology and Medicine
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 512
each round of experiments progressively lead to a better understanding of the
connection between sequence, protein structure, and function.These results feed
in to the design of the next round of candidates, according to a scoring function
that maps sequence to a protein function and optimization algorithms. After a
few rounds of rational design, random mutagenesis is performed on the most
promising candidates. This provides a sampling of the sequence landscape sur-
rounding the promising candidates, adding genetic diversity for next iteration.
The Fusion of Biology, Computer Science, and Engineering
autumn 2012 • volume 55, number 4 513
Figure 3
Time to product and the adoption of the fast, inexpensive, and robust (FIRst) iterative approach
in synthetic biology.
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 513
Examples of Fusion Science Projects
Recursive DNA Construction
Recursive DNA construction, integrating ideas from biology, computer sci-
ence, engineering, and robotics, is a striking example of a Fusion project.This
method utilizes a divide-and-conquer (D&C) approach, which is a widely used
algorithm design paradigm in computer science, often implemented using recur-
sions (BenYehezkel et al. 2008; Linshiz et al. 2008).We have proposed using the
D&C approach for construction of complex error-free objects from the error-
prone components in a biochemical system. This DNA synthesis technology
employs a biochemical protocol to enable in vitro synthesis and error correction
of long DNA molecules in an automated manner, and can accurately produce
large rationally designed combinatorial DNA libraries with pre-specified com-
binations of interest (Linshiz, BenYehezkel, and Shapiro 2012).The D&C DNA
construction technology is based on the computer-aided design (CAD) and
manufacturing (CAM) of DNA molecules, making new use of information
technologies to accelerate progress and bolster efficiency in key areas of research
and development.
In some respects, genetic programming is akin to computer programming.
However, unlike the straightforward composition of computer programs with
text editors, the design, construction, and editing of DNA in a programmatic
fashion remains a slow, expensive, and labor-intensive process (Shabi et al. 2010).
The vision of CAD/CAM, applied to DNA construction in particular and to
synthetic biology in general, is to replace labor-intensive manual laboratory
operations, which are today carried out by thousands of skilled lab workers
around the world, with efficient laboratory management, computational design,
high-throughput process automation, and optimization (Ben Yehezkel et al.
2011). In the semiconductor industry, the analogous approach has enabled a rev-
514
Gregory Linshiz et al.
Perspectives in Biology and Medicine
Figure 4
Iterative bio-research cycle.
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 514
olution in computers, internet, and telecommunication, and we anticipate a sim-
ilar effect on biology and biotechnology.
Software Tools for DNA Construction Design
In addition to experimental DNA construction methodology development,
there are active research efforts into the development of software tools that auto-
mate the design and robotic execution of optimal DNA construction protocols
for these newly emerging techniques.Algorithms that optimize the reuse of Bgl-
Brick assembly intermediates have been coupled with liquid-handling robotics
to execute the resulting protocols (Densmore et al. 2010; Leguia et al. 2011).
Complementary algorithms have been developed to design cost-optimal (lever-
aging DNA synthesis when cost-effective to do so) scar-less combinatorial type
IIs endonuclease and flanking homology sequence overlap DNA assembly meth-
ods, which can similarly be executed with robotics platforms (Hillson, Rosen-
garten, and Keasling 2012). Beyond saving researcher effort and DNA construc-
tion costs, the further development of these software design automation tools
will be crucial for scaling up DNA construction efforts beyond that possible
with manual protocol design alone. Genomic-scale DNA design and construc-
tion software tools have recently enabled the report of the first partially synthetic
eukaryotic (yeast) chromosome (Dymond et al. 2011; Richardson et al. 2012).
Microfluidics Implementation: An Integrated Microfluidics System
Microfluidic devices offer powerful techniques for cell interrogation with
rapid processing speeds and low cost.These techniques can be combined with
monoclonal antibodies (mAb) developed against cellular markers to identify and
capture cells with high specificity, and with a highly specific and sensitive screen-
ing method for the detection of protein markers based on rolling circle amplifi-
cation (RCA) to understand cellular heterogeneity (Konry et al. 2011a, 2011b).
The use of nano-liter reaction volumes and parallel sample processing offered
by droplet-based microfluidic devices make them ideally suited for total chem-
ical and bioassay analyses, ultra-high throughput screening applications, and
other cases where samples and reagents are available in limited quantities. Single-
cell droplet technology provides a cost-effective method to gain sequence infor-
mation and protein expression from individual cells that have been sorted for
phenotype. Thus, both phenotypic and genomic information can be obtained
from droplet-encapsulated individual cells. For cell encapsulation, droplet
microfluidics uses a two-phase system in which live cells and assay reagents can
be compartmentalized in an aqueous microdroplet (of 1 pL to 10 nL in size) sur-
rounded by immiscible oil.
The advantages of this droplets-based technique include the physical and
chemical isolation of droplets eliminating the risk of cross-contamination, the
fast and efficient mixing of the reagents within droplets, the ability to digitally
The Fusion of Biology, Computer Science, and Engineering
autumn 2012 • volume 55, number 4 515
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 515
manipulate droplets at a very high throughput, and the ability to incubate stable
droplets off-chip and reintroduce them into the microfluidic environment for
further processing and analysis. Using a custom-designed optical system for
interrogation of fluorescent signal within the droplets, one can then determine
the secretion pattern in the nanoliter droplets in a time-dependent fashion and
sort the cells that secrete specific molecules to establish the heterogeneity in the
population.Thus, live-cell secretion and surface monitoring can be carried out
in distinct microenvironments, utilizing a microfluidic approach merged with
microsphere sensors. Previously, this was only possible using complicated and
multi-step in vitro and in vivo live-cell microscopy, combined with immuno-
logical studies of the secretion outcomes of cellular interactions.This system can
also operate as a droplet-based fluorescence-activated cell sorting (FACS), inter-
rogating the entire reaction volume and sorting cells based on the results. How-
ever, unlike a traditional FACS, the cells remain encapsulated in droplets and
therefore can be identified individually post-sorting.
Conclusion
Over the course of human history, scientific progress has taken a path of increas-
ing specialization.To explore nature, scientists have frequently utilized a reduc-
tionist approach, breaking the world into smaller and smaller fragments. As a
result, distinct scientific disciplines, concentrated on specific aspects of nature,
have emerged. Recently, there has been a powerful resurgence of integrative
multidisciplinary research, in which experts from different fields work together
on common projects. However, if scientists remain within the boundaries of
their own disciplines, this greatly constrains progress.
The fusion science approach moves beyond simple collaboration and attempts
to integrate concepts from multiple disciplines. Fusion science research requires
that researchers gain a depth of understanding in multiple disciplines and be-
come fluent in their disparate languages and technologies. Fusion scientists break
down traditional disciplinary barriers and would be able to bridge communica-
tion gaps between the various research fields and lead interdisciplinary projects.
The development of synthetic biology is an attempt in fusion science, accom-
plished by blurring traditional lines between biology, computer science, and
engineering.The adoption of mature engineering discipline best practices, such
as laboratory management, automation, standardization, system analysis, and
optimization, has contributed to synthetic biology becoming an efficient and
successful fusion science, enabling scientists from different fields to join efforts
and collaborate fruitfully on the development of novel creative solutions for the
construction of new biological systems.
516
Gregory Linshiz et al.
Perspectives in Biology and Medicine
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 516
References
Amarasinghe, S., N. Amin, and W.Thies. 2009. Computer-aided design for microfluidic
chips based on multilayer soft lithography. In Proceedings of the 2009 IEEE International
Conference on Computer Design. Lake Tahoe: Institute of Electrical and Electronics
Engineers.
Anderson, J. C., et al. 2010. BglBricks: A flexible standard for biological part assembly. J
Biol Eng 4(1):1.
Au, L. C., et al. 1998. Gene synthesis by a LCR-based approach: High-level production
of leptin-L54 using synthetic gene in Escherichia coli. Biochem Biophys Res Commun
248(1):200–203.
Baker, M. 2011. Synthetic genomes: The next step for the synthetic genome. Nature
473(7347):403, 405–8.
Bashor, C. J., et al. 2010. Rewiring cells: Synthetic biology as a tool to interrogate the
organizational principles of living systems. Annu Rev Biophys 39:515–37.
BCC Research. 2011. Synthetic biology: Emerging global markets.BCC Research (report
code BIO066B).
Begley, C. G., and L. M. Ellis. 2012. Drug development: Raise standards for preclinical
cancer research.Nature 483(7391):531–33.
BenYehezkel,T., et al. 2008.De novo DNA synthesis using single molecule PCR.Nucleic
Acids Res 36(17):e107.
Ben Yehezkel, T., et al. 2011. Computer-aided high-throughput cloning of bacteria in
liquid medium. BioTechniques 50(2):124–7.
Bilitchenko, L., et al. 2011. Eugene:A domain specific language for specifying and con-
straining synthetic biological parts, devices, and systems. Ed. Diego Di Bernardo. PloS
One 6(4):e18882.
Carlson, R. 2009. The hanging economics of DNA synthesis. Nat Biotechnol 27(12):
1091–94.
Carlson, R. 2011. Cost per base of synthetic DNA2. http://www.synthesis.cc/assets_c/
2011/06/carlson_synthesis_cost_per_base_june_2011.html.
Chakrabarty, K., and J. Zeng. 2006. Design automation methods and tools for microflu-
idics-based biochips. ACM J Emerg Technol Comput Syst 1(3):403.
Chen, J., et al. 2012. DeviceEditor visual biological CAD canvas. J Biol Eng 6(1):1.
Chin, C. D.,V. Linder, and S. K. Sia. 2007. Lab-on-a-chip devices for global health: Past
studies and future opportunities. Lab Chip 7(1):41–57.
Collins, J. 2012. Synthetic biology: Bits and pieces come to life. Nature 483(7387):S8–
S10.
Cormier,C.Y., et al. 2010. Protein structure initiative material repository:An open shared
public resource of structural genomics plasmids for the biological community.Nucleic
Acids Res 38(database issue):D743–D749.
de Lorenzo,V. 2010. Synthetic biology: Something old, something new. BioEssays 32(4):
267–70.
Densmore, D., et al. 2010. Algorithms for automated DNA assembly. Nucleic Acids Res
38(8):2607–16.
Dymond, J. S., et al. 2011. Synthetic chromosome arms function in yeast and generate
phenotypic diversity by design.Nature 477(7365):471–76.
The Fusion of Biology, Computer Science, and Engineering
autumn 2012 • volume 55, number 4 517
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 517
Ellis,T.,T.Adie, and G. S. Baldwin. 2011.DNA assembly for synthetic biology: From parts
to pathways and beyond. Integr Biol 3(2):109–18.
Engler, C., et al. 2009. Golden Gate shuffling: A one-pot DNA shuffling method based
on type IIs restriction enzymes. PloS One 4(5):e5553.
Galdzicki, M., et al. 2011. Standard biological parts knowledgebase. PloS One 6(2):
e17005.
Gendrault,Y., et al. 2011. Computer-aided design in synthetic biology. In Proceedings of
the 4th International Symposium onApplied Sciences in Biomedical and CommunicationTech-
nologies—ISABEL ’11, 1–7. NewYork:ACM Press.
Gibson, D. G. 2009. Synthesis of DNA fragments in yeast by one-step assembly of over-
lapping oligonucleotides.Nucleic Acids Res 37(20):6984–90.
Gibson, D. G., et al. 2010. Creation of a bacterial cell controlled by a chemically synthe-
sized genome. Science 329(5987):52–56.
Gulati, S., et al. 2009. Opportunities for microfluidic technologies in synthetic biology. J
R Soc Interface 6(suppl. 4):S493–S506.
Haeberle, S., and R. Zengerle. 2007. Microfluidic platforms for lab-on-a-chip applica-
tions. Lab Chip 7(9):1094–110.
Ham, T. S., et al. 2012. Design, implementation and practice of JBEI-ICE: An open
source biological part registry platform and tools.Nucleic Acids Res 40(18):e141.
Heinemann,M., and S. Panke. 2006. Synthetic biology: Putting engineering into biology.
Bioinformatics 22(22):2790–99.
Herscovitch, M., et al. 2012.Addgene provides an open forum for plasmid sharing. Nat
Biotechnol 30(4):316–17.
Hillson, N. 2011. DNA assembly method standardization for synthetic biomolecular cir-
cuits and systems. In Design and analysis of biomolecular circuits: Engineering approaches to
systems and synthetic biology, 295–20. Dordrecht: Springer-Verlag.
Hillson, N. J., R. D. Rosengarten, and J. D. Keasling. 2012. J5 DNA assembly design
automation software. ACS Synth Biol 1(1):14–21.
Ho-Shing, O., et al. 2012. Assembly of standardized DNA parts using BioBrick ends in
E. coli.Methods Mol Biol 852:61–76.
Hurst, S. J. 2011. Biomedical nanotechnology.Methods Mol Biol 726:1–13.
Ioannidis, J. P.A., et al. 2009.Repeatability of published microarray gene expression anal-
yses.Nat Genet 41(2):149–55.
Irwin, C. R., et al. 2012. In-fusion® cloning with Vaccinia virus DNA polymerase.
Methods Mol Biol 890:23–35.
Jain, K. 2003. Nanodiagnostics:Application of nanotechnology in molecular diagnostics.
Expert Rev Mol Diagn 3(2):9.
Khalil,A. S., and J. J. Collins. 2010. Synthetic biology:Applications come of age.Nat Rev
Genet 11(5):367–79.
Khorana, H. 1979.Total synthesis of a gene. Science 203(4381):614–25.
Konry, T., et al. 2011a. Droplet-based microfluidic platforms for single T cell secretion
analysis of IL-10 cytokine. Biosens Bioelectron 26(5):2707–10.
Konry,T., et al. 2011b. Ultrasensitive detection of low-abundance surface-marker protein
using isothermal rolling circle amplification in a microfluidic nanoliter platform.Small
7(3):395–400.
Kumar, C. S. S. R. 2010.Microfluidic devices in nanotechnology: Fundamental concepts, vol. 1.
Hoboken: JohnWiley.
518
Gregory Linshiz et al.
Perspectives in Biology and Medicine
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 518
Kumar, H., et al. 2011. Biopolymers in nanopores: Challenges and opportunities. Soft
Matter 7(13):5898.
Leguia,M., et al. 2011.Automated assembly of standard biological parts.Methods Enzymol
498:363–97.
Li, M. Z., and S. J. Elledge. 2012. SLIC:A method for sequence- and ligation-independ-
ent cloning.Methods Mol Biol 852:51–59.
Linshiz, G., et al. 2008. Recursive construction of perfect DNA molecules from imper-
fect oligonucleotides.Mol Syst Biol 4:191.
Linshiz, G., T. Ben Yehezkel, and E. Shapiro. 2012. Recursive construction of perfect
DNA molecules and libraries from imperfect oligonucleotides.Methods Mol Biol 852:
151–63.
Ma, S., N.Tang, and J.Tian. 2012. DNA synthesis, assembly and applications in synthetic
biology.Curr Opin Chem Biol 16(3-4):260–67.
Mark, D., et al. 2010. Microfluidic lab-on-a-chip platforms: Requirements, characteris-
tics and applications.Chem Soc Rev 39(3):1153–82.
Mueller, S., J. R. Coleman, and E.Wimmer. 2009. Putting synthesis into biology: A viral
view of genetic engineering through de novo gene and genome synthesis.Chem Biol
16(3):337–47.
Mullard, A. 2011. Reliability of “new drug target” claims called into question. Nat Rev
Drug Discov 10(9):643–44.
Müller, K. M., and K.M.Arndt. 2012. Standardization in synthetic biology.Methods Mol
Biol 813:23–43.
Ohtani, N., et al. 2012. Serial Assembly of thermus megaplasmid DNA in the genome of
Bacillus subtilis 168:A BAC-based domino method applied to DNA with a high GC
content. Biotechnol J 7(7):867–76.
Prilusky, J., et al. 2005. HalX: An open-source LIMS (laboratory information manage-
ment system) for small- to large-scale laboratories. Acta Crystallogr D Biol Crystallogr
61(pt. 6):671–78.
Quan, J., and J.Tian. 2011. Circular polymerase extension cloning for high-throughput
cloning of complex and combinatorial DNA libraries.Nat Protoc 6(2):242–51.
Richardson, S. M., et al. 2012. Design-a-gene with GeneDesign.Methods Mol Biol 852:
235–47.
Ro, D.-K., et al. 2006. Production of the antimalarial drug precursor artemisinic acid in
engineered yeast.Nature 440(7086):940–43.
Sarrion-Perdigones, A., et al. 2011. GoldenBraid: An iterative cloning system for stan-
dardized assembly of reusable genetic modules. PloS One 6(7):e21622.
Shabi, U., et al. 2010. Processing DNA molecules as text. Syst Synth Biol 4(3):227–36.
Shao, Z., H. Zhao, and H. Zhao. 2009. DNA assembler, an in vivo genetic method for
rapid construction of biochemical pathways.Nucleic Acids Res 37(2):e16.
Shetty, R. P., D. Endy, and T. F. Knight. 2008. Engineering BioBrick vectors from Bio-
Brick parts. J Biol Eng 2:5.
Shuler, M. L., P. Foley, and J.Atlas. 2012. Modeling a minimal cell.Methods Mol Biol 881:
573–610.
Vangelooven, J., and G. Desmet. 2010. Computer Aided design optimisation of microflu-
idic flow distributors. J Chromatogr A 1217(43):6724–32.
Vu,T. D., et al. 2012.A laboratory information management system for DNA barcoding
workflows. Integr Biol (Camb) 4(7):744–55.
The Fusion of Biology, Computer Science, and Engineering
autumn 2012 • volume 55, number 4 519
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 519
Weber, W., and M. Fussenegger. 2012. Emerging biomedical applications of synthetic
biology.Nat Rev Genet 13(1):21–35.
Werner, S., et al 2012. Fast track assembly of multigene constructs using Golden Gate
cloning and the MoClo system. Bioeng Bugs 3(1):38–43.
Xiong,A.-S., et al. 2006. PCR-based accurate synthesis of long DNA sequences.Nat Pro-
toc 1(2):791–97.
Yeates, T. O. 2011. Nanobiotechnology: Protein arrays made to order. Nat Nanotechnol
6(9):541–42.
Zhang,Y.,U.Werling, andW.Edelmann. 2012. SLiCE:A novel bacterial cell extract-based
DNA cloning method.Nucleic Acids Res 40(8):e55.
Zhang, Z., et al. 2011. Self-assembly-based structural DNA nanotechnology. Curr Org
Chem 15(4):14.
520
Gregory Linshiz et al.
Perspectives in Biology and Medicine
09_linshiz 503–20:03_51.3thagard 335–  2/21/13  3:40 PM  Page 520

