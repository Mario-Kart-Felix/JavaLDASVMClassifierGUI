Bridging the Gap between Probabilistic and
Deterministic Models: A Simulation Study on a
Variational Bayes Predictive Coding Recurrent
Neural Network Model
Ahmadreza Ahmadi1 and Jun Tani1,2
1 Dept. of Electrical Engineering, KAIST, Daejeon, 305-701, Korea
2 Okinawa Institute of Science and Technology, Okinawa, Japan 904-0495
Abstract. The current paper proposes a novel variational Bayes pre-
dictive coding RNN model, which can learn to generate fluctuated tem-
poral patterns from exemplars. The model learns to maximize the lower
bound of the weighted sum of the regularization and reconstruction error
terms. We examined how this weighting can affect development of differ-
ent types of information processing while learning fluctuated temporal
patterns. Simulation results show that strong weighting of the recon-
struction term causes the development of deterministic chaos for imitat-
ing the randomness observed in target sequences, while strong weighting
of the regularization term causes the development of stochastic dynamics
imitating probabilistic processes observed in targets. Moreover, results
indicate that the most generalized learning emerges between these two
extremes. The paper concludes with implications in terms of the under-
lying neuronal mechanisms for autism spectrum disorder and for free
action.
Keywords: recurrent neural network, variational Bayes, predictive cod-
ing, generative model
1 Introduction
Cognitive agents dealing with a changing environment need to develop inter-
nal models accounting for such fluctuations by extracting underlying structures
through learning. Recently, many schemes have been proposed for learning fluc-
tuated temporal patterns by extracting latent probabilistic structures. Those
schemes include conventional dynamic Bayesian networks such as HMM and
Kalman filters, and the recently developed variational Bayes recurrent neural
network (RNN) models [2,5,8]. At the same time, there have been alternative
trials with a deterministic dynamics approach in which predictive models for
probabilistically generated target sequences are learned by embedding extracted
probabilistic structures into deterministic chaos self-organized in RNN mod-
els [14,15,18]. Because these two approaches - one probabilistic and the other
deterministic - have been developed relatively independently, research bridging
the gap between them seems worthwhile.
ar
X
iv
:1
70
6.
10
24
0v
1 
 [
cs
.A
I]
  3
0 
Ju
n 
20
17
In this direction, Murata et al [13] developed a predictive coding-type stochas-
tic RNN model inspired by the free energy minimization principle [7]. This model
learns to predict the mean and variance of sensory input for each next time step
of multiple perceptual sequences, mapping from its current latent state. The
learning optimizes not only connectivity weights but also the latent state at
the initial step for each training sequence by way of back-propagation through
time [16]. Murata and colleagues experimented with the degree of the initial
state dependency in learning to imitate probabilistic sequences, and examined
how the internal dynamic structure develops differently in different cases. It
turned out that initial state dependency arbitrated the development between
deterministic and probabilistic dynamic structure. In the case of strong initial
state dependency, deterministic chaos is dominantly developed, while stochastic
dynamics develops by estimating larger variance in the case of weak initial state
dependency.
However, this model [13] suffers a considerable drawback. It cannot estimate
variance for latent variables (the context units). This significantly constrains
the capability of the model in learning latent probabilistic structures in target
patterns. The current paper proposes a version of a variational Bayes RNN
(VBRNN) model, which can estimate variance for each context unit at each
time step (time varying variance). The proposed model is simpler than other
VBRNN models [2,5,8] because it employs a predictive coding scheme rather
than an autoencoder. Thus, the model is referred to as the variational Bayes
predictive coding RNN (VBP-RNN). It assumes that learning aims to maximize
the lower bound L [3], which is represented by the weighted sum of a negative
regularization term for the posterior distribution of the latent variable and the
likelihood term in the output generation.
The current study investigates how differently weighting these two terms in
the summation during learning influences the development of different types of
information processing in the model. To this end, we conducted a simulation
experiment in which the VBP-RNN learned to predict/generate fluctuated tem-
poral patterns containing probabilistic transitions between prototypical patterns.
Consistent with Murata et al. [13], results showed that the different weighting
arbitrates between two extremes at which the model develops either a deter-
ministic dynamic structure or a probabilistic one. Analysis on simulation results
clarifies how the degree of generalization in learning as well as the strength of
the top-down intentionality in generating patterns changes from one extreme to
another.
2 Model
This section introduces the lower bound equation. Then, the variational Bayes
predictive coding RNN (VBP-RNN) is described.
2
2.1 Generative model and the lower bound
A generative model can provide probabilistic prediction about fluctuating sen-
sation. The joint probability of sensation x and latent variable z in a generative
model can be written as a product of likelihood and a prior as:
Pθ(x, z) = Pθ(x|z)P (z) (1)
where the likelihood Pθ(x|z) is parameterized by learning parameter θ. On the
other hand, perception of x can be considered as a process of inferring posterior z
as P (z|x) which, however, becomes intractable when the likelihood is a nonlinear
function of θ. Then, the problem is to maximize the joint probability Pθ(x, z) for
a given sensory dataset X = {xt}Nt=1 by inferring both θ and the true posterior
which is approximated using a recognition model Qθ(z|x). In variational Bayes,
it has been well known that this approximation by means of minimization of the
KL-divergence between the model approximation Q and the true posterior P is
equivalent to maximizing a value referred to as the lower bound [3]. The lower
bound L to be maximized can be written as:
L = −KL(Qθ(Z|X)||P (Z)) + EQθ(Z|X)[log(Pθ(X|Z)] (2)
where the first term on the right hand side is the regularization term by which
the posterior distribution of the latent variable is constrained to be similar to
its prior, usually taken as a unit Gaussian distribution. The second term mini-
mizes the reconstruction error. This formula for maximizing the lower bound is
equivalent to the principle of free energy minimization provided by Friston [7].
2.2 Variational Bayes predictive coding RNN models
Here, we describe the implementation of the aforementioned formulation in a
continuous-time RNN (CTRNN) model as well as in a multiple timescale RNN
(MTRNN) model [1,19]. If we take X l =
{
xlt
}N
t=1
to be the lth teaching sensory
sequence pattern used for training the VBP-RNN model, the regularization term
in the lower bound for the all teaching sequences Lz can be written as:
Lz =
L∑
l=1
−KL(Qθ(zl1:T |xl1:T )||P (zl1:T )) (3)
where the posterior zlt is approximated by the recognition model Qθ as a con-
ditional probability with a given sensory sequence pattern. The prior P (zlt) can
be given, for example as a normal distribution. Next, the reconstruction error
term Lx can be described as:
Lx =
L∑
l=1
[EQθ(zl1:T |xl1:T )
T∑
t=1
[log(Pθ(x
l
t|zlt)]] (4)
3
The total lower bound is obtained as a weighted sum of the regularization term
and the reconstruction error term, with a weighting parameter W as shown in
Equation 5.
L = W.Lz + (1−W )Lx (5)
Finally, the objective of learning is to maximize the total lower bound by opti-
mizing both learning parameter θ and zl1 as the latent state at the initial step for
each latent state sequence, given a specific value for W. Following the Kingma
and Welling’s reparameterization trick [11], a random value is sampled from a
standard normal distribution at each time step, i.e. εlt ∼ N(0, 1) which is used
to sample zl1:T from Q. In the current RNN implementation, the latent state
is represented as the ensemble of the internal state values of all context units
at each step, as zlt,1:C . Then, the internal state of the ith context unit at time
step t in the lth sequence can be computed with the estimation of time varying
mean µlt,i and variance σ
l
t,i in the following way:
zlt,i = µ
l
t,i + σ
l
t,iε
l
t,i (6)
µlt,i = (1−
1
τi
)zlt−1,i +
1
τi
(
∑
j
wµcij c
l
t−1,j +
∑
k
wµxik x
l
t−1,k + b
µ
i ) (7)
σlt,i =
∑
j
(wσcij c
l
t−1,j + b
σ
i ) (8)
where τi is time constant of the ith context unit. Although the VBP-CTRNN
uses the same time constant value for all context units, the VBP-MTRNN
uses different time constant values for different units. Learning parameters w
µ|σ
ij
and b
µ|σ
i are connectivity weights and biases, respectively. c
l
t,i is the activation of
the ith context unit the value of which is computed as clt,i = tanh(z
l
t,i). Because
both P (zt1:T ) (the prior) and Qθ(z
l
1:T |xl1:T ) are Gaussian, the regularization term
in the lower bound for C numbers of context units can be rewritten as:
Lz =
1
2C
L∑
l=1
T∑
t=1
C∑
i=1
(1 + log((σlt,i)
2)− (µlt,i)2 − (σlt,i)2) (9)
The ith dimension of the prediction output is computed in the form of proba-
bilistic distribution by using the SoftMax function with M elements. Eventually,
the distribution is computed by mapping from the current context unit acti-
vation patterns at each time step. The probability of the ith dimension of the
prediction output is computed with wxcij learnable connectivity weights and b
x
i
biases as:
xlt,i =
exp(
∑
j(w
xc
ij c
l
t,j + b
x
i ))∑M
i=1 exp(
∑
j(w
xc
ij c
l
t,j + b
x
i ))
(10)
Figure 1 outlines the information flow in the VBP-MTRNN. The learning
process starts with random initialization for all learning parameters and the
initial latent state for each latent sequence. The lower bound L with a given W
4
Fig. 1. The scheme of variational Bayes predictive MTRNN (VBP-MTRNN). H and
L are abbreviation for Higher and Lower layers, respectively. The initial time step at
which optimal initial latent states are given to the network is shown by t=1. The word
“Sample” shows that for each context unit, a random value is sampled from a standard
normal distribution at each time step (ε
H|L
t ∼ N(0, 1)).
can be obtained for each epoch by computing the latent state sequences as well as
the output sequences using equations 6 to 10. L is maximized by optimizing the
learning parameters and the initial latent state for each latent sequence by using
the back-propagation through time (BPTT) algorithm [16]. With an optimal W
at the convergence of training, we expected the model’s posterior sequence to
approximate the true one . This model is simple compared to other variational
Bayes RNN models [2,5,8]. Those models are built from separate functions, of the
decoder RNN and the encoder RNN. By optimizing the connectivity weights and
the initial latent states, in the current model the same RNN computes both the
prediction output sequences by means of its forward dynamics and the posterior
of the latent state sequences by means of BPTT.
3 Simulation Experiments
We conducted simulation experiments to determine how learning in the proposed
model depends on meta-prior W as well as on the number of training patterns.
Figure 2 illustrates simulation and analysis performed in this study. First, a hu-
man generated patterns like ABB ABC ABC ABB ABC in which after AB, B is
30% probable C is 70%. These probability transitions are the same as those of a
probabilistic finite state machine (pFSM) as shown in the bottom left of Figure 2.
Then, we trained two types of MTRNNs, a target generator MTRNN (Tar-Gen-
5
Fig. 2. Illustration of the simulation and analysis procedure. Human Gen. Prob.
Patterns, Tar-Gen MTRNN, Class. MTRNN, Class. Labels, Label. Seq., and Prob.
Dist. are abbreviations for Human-Generated Probabilistic Patterns, Target Genera-
tor MTRNN, Classifier MTRNN, Classified Labels, Label Sequences, and Probabilistic
Distribution, respectively.
MTRNN) and an output classifier MTRNN (Class-MTRNN) with those proto-
typical patterns. The Tar-Gen-MTRNN was prepared for autonomous generation
of target temporal patterns (consisting of 100000 steps) which were then used for
training the VBP-MTRNN. The Class-MTRNN was prepared for autonomous
segmentation of temporal patterns into sequences of labels assigned to different
prototypical patterns, which were used for the N-GRAM analysis. The patterns
generated by the Tar-Gen-MTRNN were used as the target teaching patterns
for the main experiment, training the VBP-MTRNN under different conditions.
After training, the characteristics of output patterns generated by the VBP-
MTRNN were quantitatively compared with those of the Tar-Gen-MTRNN.
Using the trained Class-MTRNN, we computed the probabilistic distribution of
N consecutive labels corresponding to different prototypical patterns classified
from output patterns generated for 100000 steps by both the Tar-Gen-MTRNN
and the VBP-MTRNN. Finally, the N-GRAM KL-divergence between these two
probability distributions was computed in order to obtain a measure of similarity
in the output generation between the Tar-Gen-MTRNN and the VBP-MTRNN
trained in different conditions.
All network models consisted of 7 context layers with (from lowest to highest
layer) 121, 60, 30, 15, 10, 10, 10 context units, and all were trained for 100,000
epochs. The time constants of the 7 context layers were set to 2, 4, 8, 16, 32, 64,
and 128 from lowest to highest layer. There were 121 input and output units in
each network. In order to map the target patterns from 2-D to 121-D, the 2-D
SoftMax transform was used (11×11). All VBP-MTRNN models used a mini-
batch size equal to 8, and the ADAM optimizer [10] was used to maximize the
weighted lower bound.
6
3.1 Target Generator MTRNN and classifier MTRNN
The Tar-Gen-MTRNN was prepared for autonomous generation of fluctuating
target patterns of 100000 steps, which were used for the main experiment train-
ing the VBP-MTRNN. The 2-D temporal patterns for training the Tar-Gen-
MTRNN were provided by a human generate pattern compositions from a set of
different prototypical patterns using a tablet input device. The target sequence
pattern was generated by concatenating 30 prototypical patterns. Each prototyp-
ical pattern is a different periodic pattern with 3 cycles, fluctuating in amplitude
and periodicity at each appearance. The prototypical pattern “A” for example
is generated 10 times in training patterns by a human. Because it is generated
by a human on a tablet, each prototypical pattern is expressed with different
amplitudes and periodicity in each trial. After training with these human ex-
pressed patterns, the Tar-Gen-MTRNN generated an output sequence pattern
for 100,000 steps. This output sequence pattern was generated closed-loop (feed-
ing next step inputs with current step prediction outputs) while adding Gaussian
noise with zero mean and with constant σ of 0.1 into the internal state of each
context unit at each time step. This was done in order to make the network
output patterns stochastic while maintaining a certain probabilistic structure in
transitions between the prototypical patterns. We sampled the sequence pattern
generated from the 50,000th step to the 100,000th step. Then, two groups of tar-
get patterns were sampled, one consisting of 16 sequence patterns each with 400
step length and the other of 128 sequence patterns with the same step length.
These target sequence patterns were used in the main experiment, training the
VBP-MTRNN.
In order to prepare the Class-MTRNN, an MTRNN model was trained
to classify 3 different prototypical patterns (A, B, and C). The same human-
generated sequence pattern consisting of 30 consecutive prototypical patterns
was used as the teaching input pattern. The corresponding label sequence pat-
tern was used as the target of SoftMax output with 3 elements for A, B, and C
labels.
3.2 Simulation experiment of VBP-MTRNN and analysis
The VBP-MTRNN trained with meta-prior W set to 0.0, 0.01, 0.1, and 0.2 and
with both 16 and 128 teaching target sequences that had been generated by
the Tar-Gen-MTRNN. After training for 100,000 epochs under each condition,
closed-loop output patterns were generated starting from all different initial
latent states obtained for all target sequences after learning. Figure 3 compares
one target sequence pattern and its corresponding closed-loop regeneration by
the VBP-MTRNN trained with 16 target sequences. The first row shows the
target pattern and the second, the third and the fourth rows show regenerated
patterns with W set to 0.0, 0.1, and 0.2, respectively. Each pattern is associated
with a sequence of labels classified by the Class-MTRNN. When W = 0.0, the
target sequence pattern was completely regenerated for all steps. When W =
0.1, target and the regenerated patterns begin to significantly diverge at around
7
170 steps. Local deviation from each prototypical pattern arose soon after onset.
When W=0.2, the divergence starts earlier.
These observations suggest that the VBP-MTRNN trained with W=0.0 de-
velops deterministic dynamics. Additional analysis on the output sequence gen-
erated for 100,000 steps revealed that there was no periodicity, suggesting that
deterministic chaos or transient chaos developed in this learning condition. On
the other hand, when W was increased to larger values during training, the
model developed probabilistic processing in which more randomness was gener-
ated internally.
The sigma and context state values of two selected neural units inside the
second context layer for VBP-MTRNNs trained with 128 target sequences and
with W equal to 0.0 and 0.01 are given in Figure 4. From first to fourth rows are
one of the target sequence patterns, its corresponding closed-loop regeneration,
the context states, and the sigma values. With W set to 0.0, the sigma values
become close to zero accounting for the development of deterministic dynamics.
With W set to 0.01, the sigma values fluctuate from 0.0 and 0.1 accounting
for the development of stochastic dynamics. Summarily, changing the meta-
prior affects sigma values as the VBP-MTRNN alters between deterministic and
stochastic dynamics.
Table 1. Average divergence step (ADS) and Tri-gram KL-divergence of Tar-Gen-
MTRNN and VBP-MTRNN trained under various conditions.
Weighting Parameters
No. Seq. W=0.0 W=0.01 W=0.1 W=0.2
ADS
16 Seq. 370 182 77 50
128 Seq. 207 169 75 41
Tri-gram KL-Div.
16 Seq. 0.0699 0.01 0.016 0.0817
128 Seq. 0.015 0.0151 0.0033 0.0575
In order to quantify differences in network characteristics when trained un-
der different meta-prior W settings and different numbers of training sequence
patterns, the average divergence step (ADS) and the N-GRAM KL-divergence
between the Tar-Gen-MTRNN and the VBP-MTRNN were computed for each
condition. The ADS was computed for all target sequences by taking the aver-
age step at which the target sequence pattern and the regenerated one diverged.
Starting from the initial step for both 16 and 128 target sequences, divergence
was detected when the mean square error between the target and the gener-
ated pattern exceeded a threshold (0.025 in the current experiment). N-GRAM
KL-divergence can be obtained as described previously. Setting N=3, the Tri-
gram was computed for the Tar-Gen-MTRNN. For this purpose, a sample label
sequence was generated by feeding the Class-MTRNN with a sequence pattern
generated for 100,000 steps by the Tar-Gen-MTRNN. In the same way, a Tri-
gram for the VBP-MTRNN which had been trained with each different condi-
8
tion was computed by generating a sample sequence pattern with the same step
length. Table 1 shows the results of this analysis. As expected, for both 16 and
128 target sequences, ADS decreases as W increases.
The ADS obtained for the 128 target case decreases as the W value in-
creases, but not as much overall as does the 16 target case. This suggests that
the top-down intention for regenerating a learned sequence pattern decays as
W and number of training sequences increases. The Tri-gram KL-divergence
is minimized in between the two extreme W settings, 0.0 and 0.2. This value
is smaller for 128 targets than for 16 for each W value (except for W=0.01,
which is very close). The training condition with 128 training target sequences
and W set to 0.1 turned out to generate the minimum KL-divergence. Inter-
estingly, we found that the probability distribution of the Tri-grams generated
by the Tar-Gen-MTRNN and the VBP-MTRNN become quite similar in this
condition. Good generalization in learning can be achieved in such a condition
by extracting precise probabilistic structures.
It should be taken into account that the average divergence step (ADS)
was computed with a time step length of 400 for each target teaching sequence
pattern, and that generated patterns exhibited the same time step length, so a
higher ADS value does not signify better generalization capability. It is a proper
measure only of exact similarity between the target teaching patterns and the
generated output patterns. However, each Tri-gram KL-divergence value was
computed by comparing long sequence patterns (100,000 steps) test-generated by
the Tar-Gen-MTRNN and by the trained VBP-MTRNN. This value represents
the capability for generalization in learning, as it shows how much each VBP-
MTRNN model was able to extract of the probabilistic structure latent in the
teaching target patterns.
4 Discussion and summary
The current paper proposed a novel variational Bayes predictive coding RNN
model, which can learn to predict/generate fluctuated temporal patterns from
exemplars in order to shed new light on the gap between deterministic and proba-
bilistic modeling. The model network is characterized by a meta-prior W which
balances two cost functions, the regularization term and reconstruction error
term. We investigated how this meta-prior parameter along with the number of
taught sequence patterns affects model learning performance through simulation
experiments which involved learning sequence patterns which exhibit probabilis-
tic transitions between prototypical patterns. Results are summarized as follows.
When the meta-prior W was set to 0.0, the model learned to imitate the
probabilistic transitions observed in taught sequences through the development
of deterministic chaos. It was able to repeat taught sequences exactly for long
periods. However, with strong top-down intentionality developing in initial latent
states, generalization in learning turned out to be poor. When W was set with
larger values, the model exhibited stochastic dynamics as it adapted time vary-
ing sigma to noise sampling. With W set too high, reconstruction error increased
9
Fig. 3. A typical comparison between a teaching target sequence pattern and the
closed-loop output generated by the VBP-MTRNN model trained with 16 target se-
quences and set with different values for W. The capital letters segmenting the sequence
patterns indicate label sequences as classified by the Class-MTRNN.
with additional randomness in generated patterns as taught sequences could be
repeated only for shorter periods. For every value of W, when the number of
taught patterns increased, generalization in learning improved. And moreover,
the highest degree of generalization in learning is exhibited in the middle be-
tween extreme W values. Related to this, one may ask if there are any means to
optimize W values automatically. It is speculated that W values at each layer
could be optimized independently by feeding back the system performance in
terms of generalization such as by using reinforcement learning. This challenge
is left for future study. The current study did not involve with simulation ex-
periments on active inference [7] of the latent state. The active inference can
be done by back-propagating the error signal to the context units in the past
window [1,13] for real-time update of their activation values in the direction of
minimizing the error. It is expected that smaller value being set for W, more
effective the active inference becomes because of stronger causality between the
latent state and the perceived sensation. Otherwise, the active inference becomes
less effective because of less causality. This expectation is analogous to [13].
The current results bear on the task of learning to extract latent structures in
observed fluctuating temporal patterns, and as such may inform inquiry into the
10
Fig. 4. The target, generated output, context state, and sigma values of two VBP-
MTRNNs trained with 128 target sequences and meta-prior W set to (A) 0.0 and (B)
0.01.
mechanism underlying autism spectrum disorders (ASD). Van de Cruys et al [6]
have suggested that ASD might be caused by overly strong top-down prior poten-
tiation to minimize prediction error, which can enhance capacities for rote learn-
ing while losing the capacity to generalize what is learned, a pathology typical of
ASD. With the meta-prior W set below a threshold value, the proposed model
naturally reflects such pathology. This unbalance setting of W might be caused
by Dysfuction in GABA signaling as shown in mice experiments conducted by
Chao and colleagues [4]. Future study is expected to validate this hypothesis.
Another implication of the current study involves mechanisms underlying spon-
taneous or free generation of action [9,12,17]. Sequences of ”seemingly” freely
selecting each action can be accounted for by either deterministic chaos with
unconscious intentionality, or by stochastic dynamics driven by sampled noise
without strong intentionality, or it could be by an intermediate between these
two extremes as shown in the current paper.
Future studies should concern scaling of the proposed model in various real
world applications including robot learning, which will inevitably involve deal-
ing with fluctuating temporal patterns. This should include an investigation for
the optimization scheme for the meta-prior W at each level by feeding back
the system performance, as mentioned previously. At the same time, studies
11
should explore the organizing principles of cognitive brains both in normal and
abnormal conditions by selectively extending the model, and comparing model
with empirical data. Finally, study should aim at understanding how the quali-
tative meaning of free action differs when generated under differing conditions,
important when considering attribution of responsibility for human action for
example.
References
1. Ahmadi, A., Tani, J.: How can a recurrent neurodynamic predictive coding model
cope with fluctuation in temporal patterns? robotic experiments on imitative in-
teraction. Neural Networks 92, 3 – 16 (2017)
2. Bayer, J., Osendorfer, C.: Learning stochastic recurrent networks. arXiv preprint
arXiv:1411.7610 (2014)
3. Bishop, C.M.: Pattern Recognition and Machine Learning (Information Science
and Statistics). Springer-Verlag New York, Inc., Secaucus, NJ, USA (2006)
4. Chao, H.T., Chen, H., Samaco, R.C., Xue, M., Chahrour, M., Yoo, J., Neul, J.L.,
Gong, S., Lu, H.C., Heintz, N., et al.: Dysfunction in gaba signalling mediates
autism-like stereotypies and rett syndrome phenotypes. Nature 468(7321), 263–
269 (2010)
5. Chung, J., Kastner, K., Dinh, L., Goel, K., Courville, A.C., Bengio, Y.: A recur-
rent latent variable model for sequential data. In: Advances in neural information
processing systems. pp. 2980–2988 (2015)
6. Van de Cruys, S., Evers, K., Van der Hallen, R., Van Eylen, L., Boets, B., de Wit,
L., Wagemans, J.: Precise minds in uncertain worlds: predictive coding in autism.
Psychological review 121(4), 649 (2014)
7. Friston, K.: A theory of cortical responses. Philosophical Transactions of the Royal
Society of London B: Biological Sciences 360(1456), 815–836 (2005)
8. Gregor, K., Danihelka, I., Graves, A., Rezende, D., Wierstra, D.: Draw: A recur-
rent neural network for image generation. In: International Conference on Machine
Learning. pp. 1462–1471 (2015)
9. Haggard, P.: Human volition: towards a neuroscience of will. Nature Reviews Neu-
roscience 9(12), 934–946 (2008)
10. Kingma, D., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980 (2014)
11. Kingma, D.P., Welling, M.: Auto-encoding variational bayes. arXiv preprint
arXiv:1312.6114 (2013)
12. Libet, B.: Unconscious cerebral initiative and the role of conscious will in voluntary
action. Behavioral and brain sciences 8(4), 529–539 (1985)
13. Murata, S., Yamashita, Y., Arie, H., Ogata, T., Sugano, S., Tani, J.: Learning
to perceive the world as probabilistic or deterministic via interaction with others:
a neuro-robotics experiment. IEEE transactions on neural networks and learning
systems (2015)
14. Namikawa, J., Nishimoto, R., Tani, J.: A neurodynamic account of spontaneous
behaviour. PLoS Comput Biol 7(10), e1002221 (2011)
15. Nishimoto, R., Tani, J.: Learning to generate combinatorial action sequences uti-
lizing the initial sensitivity of deterministic dynamical systems. Neural Networks
17(7), 925–933 (2004)
12
16. Rumelhart, D.E., Hinton, G.E., Williams, R.J.: Learning internal representations
by error propagation. In: Rumelhart, D.E., McClelland, J.L., PDP Research Group,
C. (eds.) Parallel Distributed Processing: Explorations in the Microstructure of
Cognition, Vol. 1, pp. 318–362. MIT Press, Cambridge, MA, USA (1986)
17. Tani, J.: Exploring robotic minds: actions, symbols, and consciousness as self-
organizing dynamic phenomena. Oxford University Press (2016)
18. Tani, J., Fukumura, N.: Embedding a grammatical description in deterministic
chaos: an experiment in recurrent neural learning. Biological Cybernetics 72(4),
365–370 (1995)
19. Yamashita, Y., Tani, J.: Emergence of functional hierarchy in a multiple timescale
neural network model: a humanoid robot experiment. PLoS Comput Biol 4(11),
e1000220 (2008)
13

