 
 
Revolutionizing Engineering Science 
through Simulation 
May 2006 
 
 
 
Report of the National Science Foundation 
Blue Ribbon Panel on 
Simulation-Based Engineering Science 
 
 
 
 

 ii
 iii
 
A Report of the National Science Foundation 
Blue Ribbon Panel on 
Simulation-Based Engineering Science 
 
 
 
 
 
Revolutionizing Engineering Science 
through Simulation 
 
 
 
 
 
 
May 2006 
 iv
 v
 vi
 vii
THE NSF BLUE RIBBON PANEL ON  
SIMULATION-BASED ENGINEERING SCIENCE 
 
J. Tinsley Oden, Chair 
Associate Vice President for Research 
Director, Institute for Computational Engineering and Sciences 
Cockrell Family Regents Chair in Engineering 
The University of Texas at Austin 
Ted Belytschko 
Walter P. Murphy Professor and McCormick Professor 
Department of Mechanical Engineering 
Northwestern University 
Jacob Fish 
The Rosalind and John J. Redfern, Jr.’33 Chaired Professor in Engineering 
Department of Mechanical, Aerospace and Nuclear Engineering 
Rensselaer Polytechnic Institute 
Thomas J.R. Hughes 
Professor, Aerospace Engineering and Engineering Mechanics 
Computational and Applied Mathematics Chair III 
Institute for Computational Engineering and Sciences 
The University of Texas at Austin  
Chris Johnson 
Director, Scientific Computing and Imaging Institute 
Co-Director, Center for Integrated Biomedical Computing 
Distinguished Professor, Computer Science 
Research Professor, Bioengineering 
Adjunct Professor, Physics 
University of Utah 
David Keyes 
Fu Foundation Professor of Applied Mathematics 
Department of Applied Physics and Applied Mathematics 
Acting Director, Institute for Scientific Computing Research at LLNL 
Columbia University  
 viii
Alan Laub 
Director, Institute for Digital Research and Education 
Professor, Electrical Engineering / Mathematics 
University of California – Los Angeles  
Linda Petzold 
Chair, Department of Computer Science 
Professor, Department of Mechanical and Environmental Engineering 
Professor, Department of Computer Science 
Director, Computational Science and Engineering Program 
University of California, Santa Barbara 
David Srolovitz 
Department Chair, Mechanical and Aerospace Engineering 
Professor, Mechanical and Aerospace Engineering 
Professor, Princeton Institute for the Science and Technology of Materials 
Princeton University 
Sidney Yip 
Professor, Nuclear Engineering and Materials Science Engineering 
Computational and Systems Biology (CSBi) 
Massachusetts Institute of Technology 
 
 
 Panel Administrative Coordinator: 
  Jon Bass 
  Deputy Director, Institute for Computational Engineering and Sciences 
  The University of Texas at Austin 
 ix
PREFACE 
 
This document is the final report of the findings and recommendations of the 
Blue Ribbon Panel on Simulation-Based Engineering Science. The report 
contains recommendations critical to the acceleration of advances in Simulation-
Based Engineering Science (SBES), and it identifies several areas in which SBES 
can play a remarkable role in promoting developments vital to the health, 
security, and technological competitiveness of the nation. 
For over a decade, the nation's engineering and science communities have 
become increasingly aware that computer simulation is an indispensable tool for 
resolving a multitude of scientific and technological problems facing our country. 
To define the field of computer simulation more precisely and to assess its 
potential impact on important areas of engineering science, in April 2004 the 
NSF organized a workshop on SBES. Encouraged by the widespread interest in 
the results of the workshop, the Foundation appointed a Blue Ribbon Panel on 
Simulation-Based Engineering Science. The purpose of the Panel was to explore 
the challenges and potential benefits of SBES, as well as the barriers to its 
development. Furthermore, the Panel was tasked with making recommendations 
on how the discipline could be nurtured within academia, industry, national 
laboratories, and government agencies. A second workshop on SBES was held in 
September 2005, at which time the Panel received input on SBES from a broad 
constituency. 
Acknowledgements:  The Panel has benefited from the advice and council of 
many individuals. The enthusiastic support of Drs. Richard Buckius and Ken 
Chong of NSF and Dr. John Brighton, formerly of NSF, is gratefully 
acknowledged. Valuable advice from the over 100 workshop attendees has also 
been factored into the findings and recommendations. In addition, a large group 
of experts outside the workshops have provided valuable commentary on the 
early drafts of this report. 
The Panel gratefully acknowledges the following individuals and institutions 
for providing the graphics that appear in this report: NASA’s Earth Observatory 
(Cover Image); Charles Taylor, Stanford University (Figure 1); Y. Zhang and C. 
Bajaj, University of Texas and the New York University School of Medicine, 
respectively (Figure 2); SCI, University of Utah (Figure 3); SCI, University of 
Utah, and J. Bell and V. Beckner, Lawrence Berkeley National Laboratory 
(Figure 4); and the U.S. Department of Energy (Figure 5, a reproduction from the 
SCaLeS report). Particularly helpful in the preparation of this final report were 
the comments and advice of Drs. Chandrajit Bajaj, Larry Biegler, Mark 
 x
Carpenter, Alok Chaturvedi, Weng Cho Chew, Frederica Darema, Omar Ghattas, 
George Hazelrigg, Craig Henriquez, Anthony Ingraffea, Kirk Jordan, Chandrika 
Kamath, Dimitri Kusnezov, Wing Kam Liu, Robert Moser, Habib Najm, 
Anthony Patera, Mark Rashid, Mark Shephard, Charles Taylor, Elizabeth 
Tornquist, Mary Wheeler, Daniel White, Jacob White, and David Young,. 
Although this report was prepared by a Panel of the National Science 
Foundation, all opinions, findings, and recommendations expressed here are 
those of the Panel and do not necessarily reflect the views of the National 
Science Foundation. 
 xi
 CONTENTS 
 
PREFACE................................................................................................................ix 
CONTENTS ............................................................................................................xi 
EXECUTIVE SUMMARY.......................................................................................xiii 
1.0   SBES: A National Priority for Tomorrow’s Engineering and Science .............1 
2.0  THE PAYOFF: Driving Applications and Societal Benefits of SBES................9 
   2.1 SBES in Medicine.............................................................................................9 
   2.2 SBES in Predictive Homeland Security ........................................................13 
   2.3 SBES in Energy and the Environment ..........................................................17 
   2.4 SBES in Materials ..........................................................................................18 
   2.5 SBES in Industrial and Defense Applications ...............................................22 
3.0 CORE ISSUES: Challenges, Barriers, and Opportunities in SBES 
Research ..........................................................................................................29 
   3.1 The Tyranny of Scales: The Challenge of Multiscale Modeling and 
        Simulation........................................................................................................29 
   3.2 Verification, Validation, and Uncertainty Quantification..............................33 
   3.3 Dynamic Simulation Systems, Sensors, Measurements, and 
        Heterogeneous Simulations ...........................................................................37 
   3.4 New Vistas in Simulation Software...............................................................40 
   3.5 The Emergence of Big Data in Simulation and the Role of 
        Visualization in SBES .....................................................................................44 
   3.6 Next-Generation Algorithms and Computational Performance...................49 
4.0 THE CRISIS OF THE KNOWLEDGE EXPLOSION: SBES Education for 
 Tomorrow’s Engineers and Scientists ............................................................53 
5.0 CONCLUSIONS................................................................................................57 
 xii
Appendix A: SBES Workshop Attendees..............................................................61 
   April 2004 Workshop ...........................................................................................61 
   September 2005 Workshop..................................................................................62 
BIBLIOGRAPHY.....................................................................................................63 
 
 xiii
 EXECUTIVE SUMMARY 
 
Simulation refers to the application of computational models to the study and 
prediction of physical events or the behavior of engineered systems.  The 
development of computer simulation has drawn from a deep pool of scientific, 
mathematical, computational, and engineering knowledge and methodologies. 
With the depth of its intellectual development and its wide range of applications, 
computer simulation has emerged as a powerful tool, one that promises to 
revolutionize the way engineering and science are conducted in the twenty-first 
century. 
Computer simulation represents an extension of theoretical science in that it 
is based on mathematical models. Such models attempt to characterize the 
physical predictions or consequences of scientific theories. Simulation can be 
much more, however. For example, it can be used to explore new theories and to 
design new experiments to test these theories. Simulation also provides a 
powerful alternative to the techniques of experimental science and observation 
when phenomena are not observable or when measurements are impractical or 
too expensive. 
Simulation-Based Engineering Science (SBES) is defined as the discipline 
that provides the scientific and mathematical basis for the simulation of 
engineered systems. Such systems range from microelectronic devices to 
automobiles, aircraft, and even the infrastructures of oilfields and cities. In a 
word, SBES fuses the knowledge and techniques of the traditional engineering 
fields—electrical, mechanical, civil, chemical, aerospace, nuclear, biomedical, 
and materials science—with the knowledge and techniques of fields like 
computer science, mathematics, and the physical and social sciences. As a result, 
 xiv
engineers are better able to predict and optimize systems affecting almost all 
aspects of our lives and work, including our environment, our security and safety, 
and the products we use and export. 
Whereas the use of computer simulations in engineering science began over 
half a century ago, only in the past decade or so have simulation theory and 
technology made a dramatic impact across the engineering fields. That 
remarkable change has come about mainly because of developments in the 
computational and computer sciences and the rapid advances in computing 
equipment and systems. There are other reasons. For example, a host of 
technologies are on the horizon that we cannot hope to understand, develop, or 
utilize without simulation. Many of those technologies are critical to the nation’s 
continued leadership in science and engineering. Clearly, research in SBES is 
quickly becoming indispensable to our country’s security and well-being. 
This report was prepared by a Blue Ribbon Panel on Simulation-Based 
Engineering Sciences, which was convened by the Assistant Director of the 
Engineering Directorate of the National Science Foundation (NSF). The Panel 
was directed to explore opportunities for and potential advances in SBES and to 
make strategic recommendations as to how to structure programs to foster SBES. 
The Panel developed its findings and recommendations from several 
information sources. Among them, interactions with recognized leaders of the 
computational engineering and science communities played an essential role. 
Another important source of information was the work of previous panels and 
committees. The results of those earlier efforts, which have accumulated over the 
last decade, address major issues in the computational and computer sciences. 
The Panel also relied on input from leaders in the computer simulation 
community who participated in the NSF-supported workshops on SBES. Finally, 
the Panel developed its findings and recommendations after thorough discussions 
among its members. 
This report explores the potential impact of advances in SBES on science and 
 xv
technology and identifies the challenges and barriers to further advances in 
SBES. For instance, we must overcome difficulties inherent in multiscale 
modeling, the development of next-generation algorithms, and the design and 
implementation of dynamic data-driven application systems. We must improve 
methods to quantify uncertainty and to model validation and verification. We 
must determine better ways to integrate data-intensive computing, visualization, 
and simulation. Importantly, we must overhaul our educational system to foster 
the interdisciplinary study that SBES requires.  The payoffs for meeting these 
challenges are profound. We can expect dramatic advances on a broad front: 
medicine, materials science, homeland security, manufacturing, engineering 
design, and many others. 
For more than a decade, researchers and educators in engineering and science 
have agreed: the computational and simulation engineering sciences are 
fundamental to the security and welfare of the United States. The findings and 
recommendations of this report strongly reinforce that contention.  
 xvi
Major Findings 
1. SBES is a discipline indispensable to the nation’s continued leadership in 
science and engineering. It is central to advances in biomedicine, 
nanomanufacturing, homeland security, microelectronics, energy and 
environmental sciences, advanced materials, and product development. There 
is ample evidence that developments in these new disciplines could 
significantly impact virtually every aspect of human experience. 
2. Formidable challenges stand in the way of progress in SBES research. These 
challenges involve resolving open problems associated with multiscale and 
multi-physics modeling, real-time integration of simulation methods with 
measurement systems, model validation and verification, handling large data, 
and visualization. Significantly, one of those challenges is education of the 
next generation of engineers and scientists in the theory and practices of 
SBES. 
3. There is strong evidence that our nation’s leadership in computational 
engineering and science, particularly in areas key to Simulation-Based 
Engineering Science, is rapidly eroding. Because competing nations 
worldwide have increased their investments in research, the U.S. has seen a 
steady reduction in its proportion of scientific advances relative to that of 
Europe and Asia. Any reversal of those trends will require changes in our 
educational system as well as changes in how basic research is funded in the 
U.S. 
 xvii
Principal Recommendations 
 
1. The Panel recommends that the National Science Foundation and other Federal 
research agencies make changes in their organizational structures to facilitate long-
range core funding of SBES. The new Cyberinfrastructure at NSF is envisioned as a 
“portion of cyberspace” where scientists can “pursue research in new ways and with 
new efficiency” by utilizing: 1) high-performance, global-scale networking, 2) 
middleware, 3) high-performance computing services, 4) observation and 
measurement devices, and 5) improved interfaces and visualization services. Serious 
consideration should be given to the feasibility of developing a parallel program in 
SBES that interfaces to multiple divisions of NSF in concert with 
Cyberinfrastructure. Supporting SBES research should certainly be a goal of every 
division within the Directorate of Engineering at NSF, but the realization of the full 
potential of advances in SBES will require support across all directorates and from 
other federal agencies as well. 
2. To maintain our leadership in science and engineering, the Panel recommends a 
minimum increase in NSF funding of $300 million per year over 2005 levels of 
SBES-related disciplines.  We cannot maintain our leadership in engineering and the 
engineering sciences without substantial investments in SBES, because simulation is 
a key element in accelerating progress in engineering. Advances in computing speed 
alone or in measurement devices or in networking or interfaces cannot meet the great 
challenges before us without advances in the basic components of SBES. Similar 
observations have been made in the President’s Information Technology Advisory 
Committee (PITAC) report, as well as in the results of several other related studies. 
3. The Panel recommends a long-term program of high-risk research to exploit the 
considerable promise of SBES. The Panel strongly supports the observation made in 
the PITAC report and elsewhere that short-term investments and limited strategic 
planning will lead to excessive focus on incremental research rather than on long-
range sustained research with a lasting impact. Progress in SBES will require the 
creation of interdisciplinary teams that work together on leading-edge simulation 
problems. The work of these teams should be sustained for a decade or more to yield 
the full fruits of the investment. 
4. The Panel recommends that NSF underwrite the work of an NRC committee to 
explore the issue of interdisciplinary education in detail and to make 
recommendations for a sweeping overhaul of our educational system. The problem 
of education in SBES-component disciplines, and in multidisciplinary programs in 
general, is large, pervasive, and critically important. The initiative for change will 
not likely come from academia alone; it must be encouraged by the engineering and 
scientific leadership and throughout the organizational structure of our universities. 
 
Other important findings and recommendations of the Panel are given in the 
body of the report.  
 xviii
 
 
 1
1.0 SBES: A National Priority for 
Tomorrow’s Engineering and 
Science 
  
Today the field of computer simulation is on the threshold of a new era. 
Advances in mathematical modeling, computational algorithms, the speed of 
computers, and the science and technology of data-intensive computing have 
prepared the way for unprecedented improvements in the health, security, 
productivity, and competitiveness of our nation. To realize these advances, 
however, we must overcome major scientific, engineering, sociological, and 
educational obstacles. Progress will require significant breakthroughs in research, 
changes in the research and educational cultures of our academic institutions, and 
changes in the organizational structure of our educational system. For the 
engineering fields, advances in computer simulation offer rich possibilities.  Full 
exploitation of the new capabilities, however, must await basic research into the 
scientific components of modeling, simulation, and computing, among other 
areas. We refer to the combination of these basic research activities as 
Simulation-Based Engineering Science, or SBES. 
In this report we describe this new discipline. We first identify some of the 
remarkable benefits SBES brings to technologies that make our lives healthier, 
safer, and better. Next, we survey the core issues of SBES, that is, the major 
obstacles to and opportunities for its development. We then explore the impact of 
SBES on our national research and educational resources, goals, and 
organizations. Throughout the report, we highlight our findings and 
recommendations. In making those recommendations, we attempt to reflect the 
views prevailing within the nation’s scientific and engineering communities. 
 2
This much is certain: there is overwhelming concurrence that simulation is 
key to achieving progress in engineering and science in the foreseeable future. 
Indeed, seldom have so many independent 
studies by experts from diverse perspectives 
been in such agreement:  computer simulation 
has and will continue to have an enormous 
impact on all areas of engineering, scientific 
discovery, and endeavors to solve major 
societal problems. This message is woven into 
the principal findings of many key 
investigations.  For example, the PITAC report 
[4] emphasizes the need to develop 
computational science for national 
competitiveness, and the SciDAC [26] and SCaLeS [18, 19] reports identify 
opportunities for scientific discovery at the high end of today’s simulation 
capabilities and call for a new scientific culture of interdisciplinary teamwork to 
realize those capabilities. In addition, the Roadmap for the Revitalization of 
High-End Computing [24] and the Federal Plan for High-End Computing [13] 
both call for innovations in computer architecture to accommodate advanced 
simulation. The Future of Supercomputing report [12] examines the role of the 
Federal Government in sustaining the leading edge of supercomputing, and the 
Cyberinfrastructure report [1] outlines a diverse program of interrelated research 
imperatives stretching well beyond simulation into communication and data 
technologies. Beginning with the Lax report of 1982 [20] and continuing with a 
number of reports already appearing in this young century [3, 8, 9, 23], the 
studies share a similar vision regarding the importance of simulation. 
Consequently, the present report enters an arena already filled with voices 
calling for more vigorous research and training in computation-based simulation. 
The ideas in this report are in harmony with those voices, and in fact the report is 
as brief as it is because others have already eloquently articulated the case for 
Seldom have so many 
independent studies been 
in such agreement: 
simulation is a key 
element for achieving 
progress in engineering 
and science. 
 3
simulation. Even so, this report addresses important elements of simulation that 
have been overlooked. Moreover, it adds the voice of engineering to the 
discussion, one that has not yet been fully heard. 
Realizing the full potential of SBES will require a revolution in simulation 
technology. Simulation-Based Engineering Science is not “simulation as usual”; 
rather, it is research focused on the modeling 
and simulation of complex, interrelated 
engineered systems and on the acquisition of 
results meeting specified standards of precision 
and reliability. Indeed, the scope of SBES 
includes much more than the modeling of 
physical phenomena. It develops new methods, 
devices, procedures, processes, and planning 
strategies. Not only does it draw on and 
stimulate advances in our scientific 
understanding, it capitalizes on those advances by applying them to challenges in 
the engineering domain. For example, discoveries in SBES have direct 
applications to optimization, control, uncertainty quantification, verification and 
validation, decision-making, and real-time response. In short, SBES will lift 
simulation to a powerful new level, a level where we hope to solve the most 
stubborn problems of modeling, engineering design, manufacturing, and 
scientific inquiry. In fact, so profound are the implications of advanced 
simulation techniques that we can expect SBES to trigger the development of a 
host of aggressive new technologies and to foster significant new scientific 
discoveries. 
Consider, for example, a few of the breakthroughs that SBES offers: (1) the 
means to understand and control multiscale, multi-physics phenomena;  
(2) fundamental developments in nanotechnology, biomedicine, materials, energy 
and environment, and the earth and life sciences; and (3) dramatic enhancements 
to the fidelity and utility of computational predictions. Clearly, SBES ushers in a 
SBES constitutes a new 
paradigm that will be 
indispensable in meeting 
the scientific and 
engineering challenges of 
the twenty-first century. 
 4
technology that not only expands the reach and capability of every field of 
engineering but also promises significant improvements in the health, security, 
competitiveness, and wealth of our nation. 
If we are to reap the benefits of SBES, however, we must first overcome the 
obstacles. First, we must revolutionize the way we conceive and perform 
simulation. This revolution requires that we learn to incorporate new discoveries 
that simplify and enhance multiscale, multidisciplinary simulations. Second, we 
must make significant advances in the supporting technologies, including large-
scale computing, data management, and algorithms. Third, we must overhaul our 
educational institutions to accommodate the needs of SBES research and 
training. Fourth, we must change the manner in which research is funded and 
conducted in the U.S. 
So far, developments in simulation have ridden the wave of advances in 
hardware and software information technology. Because of these advances, 
simulation has become an increasingly effective tool in traditional science and 
engineering practices. Unlike most theory, which 
posits restricted, idealized systems, simulation 
deals with real systems. For that reason, 
simulation provides unprecedented access to 
real-world conditions. In addition, simulation has 
none of the limitations of experimental designs 
and tests, which are often hampered by cost 
constraints, unrealistic parameter ranges, and 
even restrictions imposed by treaties or health 
and environmental concerns. For these reasons, 
computer simulation is credited with numerous 
triumphs in the twentieth century. It has become 
indispensable, for example, in assessments of 
vehicle crashworthiness. It is fundamental to the generation of predictive models 
of the weather, climate change, and the behavior of the atmosphere. Its 
Simulation has become 
indispensable in 
predictive methods for 
weather, climate change, 
and behavior of the 
atmosphere; and in 
broad areas of 
engineering analysis and 
design. 
 5
importance in broad areas of engineering analysis and design are well known. It 
has become essential to product manufacturing. Its achievements in biomedical 
applications are widely discussed. Systems design in defense, communication, 
and transportation also rely on computer simulation. 
At the heart of these successes, however, are simulation methodologies that 
are decades old, too old to meet the challenges of new technology. In many ways, 
the past successes of computer simulation may be its worst enemies, because the 
knowledge base, methods, and practices that enabled its achievements now 
threaten to stifle its prospects for the future. 
Our nation prides itself in being the leader in computational science and 
simulation theory and technology. Unfortunately, many indicators suggest that 
the United States is quickly losing ground. Particularly in SBES, the country is 
no longer positioned to lead the world over the next few decades. Even today, the 
consequences of falling behind are penetrating deep into our technology and 
economy, as well as jeopardizing our position in the 
global community. 
Our global competitors are well aware of the great 
potential of computer simulation. Throughout Europe 
and Asia, governments are making major investments 
in computing, mathematical and computational 
modeling, algorithms, networking, and generally in 
computational engineering and science.  Indeed, these 
nations are building on the technologies that the U.S. 
pioneered in the twentieth century. We are in danger, 
once again, of producing world-leading science but leaving it to our competitors 
to harvest the technological and economic advantages. 
Yet, even our traditional lead in basic research is under threat. According to 
[4, p. 9]: “Since 1988, Western Europe has produced more science and 
engineering journal articles than the United States and the total growth in 
The importance and 
great potential of 
simulation have not 
gone unnoticed by 
our competitors 
around the world. 
 6
research papers is highest in East Asia (492 percent), followed by Japan (67 
percent), and Europe (59 percent), compared with 13 percent for the United 
States. Worldwide, the share of U.S. citations in scientific papers is shrinking, 
from 38 percent in 1988 to 31 percent in 2001.” In Germany, 36 percent of 
undergraduates receive degrees in science and engineering; in China, 59 percent, 
and in Japan, 66 percent. In contrast; only 32 percent of undergraduates receive 
such degrees in the United States [6, 25, 21]. 
The imbalance is beginning to reveal itself in international trade. “From 1980 
to 2001, the U.S. share of global high-technology exports dropped from 31 
percent to 18 percent, while the share for Asian countries rose from 7 to 25 
percent” [4, p. 8]. Since 2001, the U.S. trade balance in high-tech products has 
been negative. 
The chief global economic competitor of the United States is China. In 2004 
China graduated approximately 498,000 bachelor’s level engineers. By 
comparison, India graduated 350,000 engineers, and the U.S. graduated 70,000 
[6, 25]. The employment of an engineer in China costs roughly one-tenth to one-
sixth of what it costs in the United States. Some argue, however, that the U.S. 
production of engineers, computer scientists, and information technology 
specialists remains competitive in global markets when like-to-like data from the 
representative countries are compared [11]. Nevertheless, even our competitors 
in SBES believe that SBES research expenditures in Europe and Asia are rapidly 
expanding while they are stagnant or declining in the U.S. 
The key to offsetting those disadvantages is leadership in simulation. The 
U.S. must be in the forefront of efforts to make simulation easier and more 
reliable. We must extend the capabilities of simulation to the analysis of more 
complex systems and the real-time acquisition of real-time data. Simulation must 
no longer be relegated to the peripheries of an engineering student’s skill set; 
instead, it should be a core part of the engineering curriculum, where it plays a 
role in effective pedagogy. 
 7
Computer simulation has become indispensable to the development of all 
other technologies, including microelectronics, advanced materials, 
biotechnology, nanotechnology, pharmaceuticals, medicine, and defense and 
security. Many breakthroughs in these technologies derive from computer 
simulation and simulation-based scientific discovery. Clearly, we must integrate 
computer simulation into engineering education and practice. To do so, however, 
requires great intellectual resources and a national commitment to SBES. 
In Chapter 2, we describe some of the remarkable applications of SBES, all 
of which represent enormous benefits to our society. If we are to realize such 
great potential, however, we must overcome many technical, mathematical, 
scientific, and computational challenges. So great are these challenges that they 
will require a sea change in our approach to engineering and science education. 
Chapter 3 surveys the greatest of those obstacles. In addition, the chapter 
identifies opportunities for broadening the impact of SBES through 
developments in visualization, sensors and image processing, and uncertainty 
quantification. 
Finally, in Chapter 4 we describe the impact of SBES on our educational 
system. Our educational system must change if it is to equip future generations of 
engineering scientists with knowledge of SBES and its value in science and 
technology. 
 8
 9
2.0  THE PAYOFF: 
Driving Applications and 
Societal Benefits of SBES 
 
The applications and benefits of SBES are many. This chapter reviews 
some of the important applications of SBES and explores the challenges and 
benefits of each. 
 
2.1 SBES in Medicine 
  
Most diseases (such as heart disease, cancer, stroke, and respiratory 
diseases) and their treatments (whether surgical, transcatheter, or pharmacologic) 
involve complex physical responses and interactions between biological systems, 
from the molecular to organism scales.  Simulation methods can therefore 
dramatically increase our understanding of these diseases and treatments, and 
furthermore, improve treatment.  Computational science has already made 
significant inroads in many biomedical domains, most notably genomics and 
proteomics. A current challenge is the application of SBES to clinical medicine 
and to the study of biological systems at the cellular, tissue, and organ scales. 
Medical practice and engineering have many 
similarities. Both are problem-solving disciplines, and 
both require an understanding of complex systems. 
Engineering design processes, however, are based 
upon predicted outcomes. Often, engineering solutions 
Both medical practice 
and engineering are 
problem-solving 
disciplines. 
 10
require the satisfaction of numerous criteria simultaneously. Those solutions 
often require sophisticated computer and analysis technologies.  By contrast, 
medical practice uses a “build them and bust them” approach. Historically, the 
paradigm of medicine combines diagnosis and empiricism; that is, physicians use 
various tests to diagnose a medical condition and then plan a treatment or 
intervention based on empirical data and professional experience. Generally, 
medical practice precludes any formal process to predict the outcome of a 
treatment for an individual patient, although there may be some statistical data to 
indicate the success rate of the treatment. 
 
 
 
 
 
 
  
 
 
A program in SBES could lead to new 
approaches to medical practice, approaches that 
could be collectively called Simulation-Based 
Medicine. New SBES methodologies, already 
leveraging tremendous advances in medical imaging 
and high-performance computing, would give the 
practice of medicine the tools of modern 
engineering. For example, doctors would be able to 
use simulations—initialized with patient-specific 
Figure 1: Example of a simulation-based medical approach applied to the design of a bypass 
surgery procedure for a patient with occlusive cardiovascular disease in the aorta and iliac 
arteries. Shown from left to right are magnetic resonance image data, a preoperative geometric 
solid model, an operative plan, computed blood flow velocity in the aorta and proximal end of 
bypass, and post-operative image data used to validate predictions. Advances contemplated in 
SBES disciplines could greatly improve these approaches by allowing real-time adaptive 
control of surgical procedures through the combination of simulation tools and imaging 
technologies. 
 A program in SBES 
could also lead to 
new approaches to 
medical practice, 
collectively called 
Simulation-Based 
Medicine. 
 11
anatomic and physiologic data—to predict the outcomes of procedures and 
thereby design optimal treatments for individual patients. This ability to predict 
treatment outcomes and design procedures accordingly represents an exciting 
new possibility for medicine. 
Not only could physicians devise better treatments for individual patients, but 
also manufacturers could use SBES methods to predict the performance of their 
medical devices in virtual patients. The physical and animal testing procedures 
currently used prior to human trials have significant limitations in their ability to 
represent variations in human anatomy and physiology. With SBES methods, 
manufacturers could conduct virtual prototyping of medical devices by 
simulating the performances of alternate device designs for a range of virtual 
Figure 2: The modeling of biomedical systems is becoming increasingly 
sophisticated. Here is an example of a three-dimensional, tetrahedral-mesh, 
heart model [27] developed from surface data obtained from the New York 
University School of Medicine [22]. (a) Exterior view. (b) Boundary detection 
represented in wire frame. (c) Cross-sectional view of the mesh. Patient-
specific modeling technologies need to be advanced significantly to make the 
vision of Simulation-Based Medicine a reality. The benefits, however, are 
impressive: dynamic models of deformation, blood flow, and fine-scale 
capillary effects may greatly advance cardiovascular medicine. 
 12
patients. In this way, manufacturers would be able to refine their designs for 
different patient conditions. As a result, these virtual clinical trials prior to 
animal and human trials could lead to safer, more effective devices, reduce 
development costs, and shorten time-to-market. 
Manufacturers in pharmaceuticals and biotechnology could also benefit from 
SBES methods. For example, targeted drug-delivery techniques are being used 
increasingly to treat a range of diseases, including heart disease (for example, 
drug-eluting stents), cancer (for example, local chemotherapies), and chronic 
respiratory diseases (for example, therapeutic inhalants). In all those areas of 
innovation, simulation-based methods could be used to model the transport of 
drugs through the circulatory or respiratory systems and to determine the local 
concentrations to use in pharmacokinetic models of drug metabolism. 
Currently, important topics in cancer research are the mechanisms of cell 
adhesion and invasion and signaling pathways. A better understanding of those 
mechanisms is critical to advances in cancer research and neurobiology. The 
developments of multiscale SBES technologies for investigations into cellular 
structures and cell mechanics, as well as the development of novel cellular force-
measurement devices, will help explain dynamic cellular architectures and the 
mechanism of cell motility. 
Of particular significance is cell motility. To understand cell motility we 
must first understand: (1) the mechanics of the cell interior, and (2) the 
mechanics of the cell-substrate or cell-ECM (extra-cellular matrix) interaction 
force. These complex mechanisms determine cell shape and migration, which in 
turn allow the cell to perform its critical functions, such as wound healing and 
embryonic morphogenesis. SBES technologies hold promise that we can improve 
our understanding of those cellular functions and increase our ability to 
differentiate normal cells from cancer cells. The stakes are high, because the 
invasion of transformed cells into other tissues—the process called metastasis—
is believed to be the precursor of the development of cancer tissue. 
 13
2.2 SBES in Predictive Homeland Security 
  
In the broadest sense, engineering design for security involves the 
development of systems to protect human populations and the artificial and 
natural infrastructures that support them. The systems protect us from a range of 
threats, whether hostile (for example terrorists), environmental (for example, air 
and water pollution), or natural (for example, earthquake or hurricane). The 
protective systems must guard our entire support infrastructure: buildings; 
transportation systems; food, water, and power distribution; communications; and 
waste disposal. 
The methods of SBES can play an important role in the design and 
optimization of these protective systems. Most notably, SBES would allow our 
emergency planners to predict not only the 
consequences of threats (for example, the accidental 
or malicious release of a toxic chemical or 
biological agent), but also the effects of 
countermeasures. With the aid of predictive 
simulations, engineers would be able to design and 
optimize infrastructures that would be impervious to 
a wide range of threats. With the ability to conduct 
real-time simulations, moreover, an emergency team 
would be able to identify the most rational response to a crisis. The World Trade 
Center disaster of September 11, 2001 serves as a tragic example: if real-time 
simulation had been available, the emergency response team would have realized 
the importance of the immediate evacuation of the building complex. 
SBES can give engineers and planners a remarkably large operational view 
of the systems that make up our society. For example, SBES would give us the 
ability to simulate the operation of a whole city as a single system. It is able to do 
so because it integrates multiscale simulations of multiple subsystems and 
SBES will allow the 
prediction of the 
consequences of 
threats and 
countermeasure 
responses. 
 14
processes, such as structural responses, fluid transport of contaminants, power 
distribution, and transportation systems, as well as the response of the human 
population. 
This vision of a “Digital City” would require the acquisition of data of 
unprecedented detail. Not only would the system have to acquire static data, that 
is, data regarding the installed infrastructure, but it would also have to 
continuously acquire dynamic data, that is, data undergoing constant change. 
Dynamic data, for example, would include continuous measurements of air- and 
water-contaminant concentrations; the flow rates of air, water, and effluents; the 
locations and velocities of transportation and other movable assets (for example, 
trains and heavy machinery); and the densities and movements of people and 
automobiles. 
A logical extension of the Digital-City concept is that of the Digital 
Ecosystem, which may be artificial (such as a city) or natural (such as a forest, 
watershed, continent, or even the entire planet). Whatever the scale, the benefits 
are the same: we gain the ability to optimize human activity and infrastructures in 
respect to adverse events or trends, and, through real-time simulation, we are able 
to identify rational responses to crises. 
The concepts and methods of SBES promise to revolutionize the practice of 
urban planning, transportation, structural and environmental engineering, and 
municipal and environmental management. To realize the visions of the Digital 
City and the Digital Ecosystem, however, we must acknowledge that a great 
amount of research must pioneer the way. The following are a few of the areas 
requiring development: 
• Quantitative models of the processes to be simulated must be developed. For 
many of those processes, models of some level of fidelity already exist, or 
they are being developed for narrower engineering purposes. Obvious 
examples are structural models (of buildings and other structures), fluid-
dynamics models (air and water flows), combustion models (for example, for 
 15
predicting the spread of fires), and transportation models (for example, to 
analyze traffic flow). For other important processes, however, quantitative 
models are rudimentary or nonexistent. For example, we lack sociological 
models that can help us describe or predict the response of populations to 
crises. In addition, we need better models for the evolution of natural 
ecosystems such as forests or lakes. 
• A comprehensive simulation system is required that integrates detailed 
models of a wide range of scales. The comprehensiveness of the simulation 
system is a requirement if SBES applications are to simulate multiscale 
complex systems. Some of the issues are generic, but others are problem 
specific. 
• New models of exceptional fidelity are required. The development and 
validation of such models entail the acquisition of data of extraordinary 
detail. As a result, the development of the Digital City and Digital Ecosystem 
will inevitably put pressure on the experimental sciences and theoretical 
research to meet the demand for copious data. Furthermore, the real-time 
simulation of some applications will drive developments in sensors and the 
communication infrastructure, both of which must support streams of data. In 
addition, we need to develop the simulation techniques that can 
accommodate the data streams. 
• A better understanding of the role of uncertainty is required. Some degree of 
uncertainty is inevitable in the ability of a model to reflect reality and in the 
data the model uses. We need to find ways to interpret uncertainty and to 
characterize its effects on assessments of the probable outcomes. 
 
The rewards of meeting those challenges are great:  enhanced security, 
safety, and convenience of life in the Digital City and the Digital Ecosystem; a 
social infrastructure of unparalleled efficiency; rational responses to natural 
events; and optimal interactions with natural environments. The following 
 16
summarizes some of the major applications. 
 
• Protection Against Air Contaminants: SBES technologies will detect and 
measure the presence of biological or chemical contaminants in the air and, 
given detailed weather data, identify the likely release location and 
magnitude of the release. The system will then design an optimal response 
plan. 
• Optimization of Infrastructures: SBES technologies will optimize the 
designs of buildings and other infrastructural elements. Such designs would 
be site specific, interact well with natural and man-made surroundings, and 
blend with the urban system of which they are a part. In addition, the designs 
would take into account the effects of the structures both on normal 
operations and on operations during a wide range of large-scale emergencies.  
• Prediction of Long-Term Environmental Impacts: SBES technologies 
will predict the effects of effluents from existing and proposed facilities on 
urban and natural environments. Such predictions would greatly increase the 
reliability and usefulness of environmental impact studies. In addition, they 
would allow planners to minimize the probability of unforeseen deleterious 
events. 
• Optimization of Emergency Responses: SBES technologies would 
optimize emergency responses to fire and explosion (whether accidental or 
intentional). Planning for emergency responses would consider how the 
situation might evolve or escalate (for example, a fire might spread, building 
collapse, or the response intervention itself might adversely affect the 
situation). 
• Optimization of Security Infrastructures for Urban Environments: 
SBES technologies would assist in the design and placement of air- and 
water-contaminant sensors and would help in the planning of 
countermeasures, such as contaminant dispersal and flood abatement. 
 
 17
2.3 SBES in Energy and the Environment 
 
The energy-related industries rely on modern simulation methods to monitor 
the production of oil reservoirs, plan pollution remediation measures, and devise 
control strategies. Recent advances in simulation-related technologies may raise 
oil-reservoir management to a new level of sophistication. Those advances 
include distributed computing, multi-physics and 
chemistry modeling, parallel algorithms, and methods 
and devices for the dynamic use of well-bore and 
seismic data. In addition, the next generation of oilfield 
simulation tools could exploit developing technologies 
for data-driven, interactive, and dynamically adaptive 
strategies for subsurface characterization and reservoir 
management. Soon we could see multi-resolution 
reservoir models that can be executed on very large, 
distributed, heterogeneous, computational environments. 
Those models, moreover, could be fed data from sensors 
embedded in reservoir fields (for example, permanent 
downhole sensors and seismic sensors anchored on the 
seafloor). Such a model-and-sensors system could provide a symbiotic feedback 
loop between measurement data and computational models. This approach could 
lead to an instrumented oilfield, one that is more efficient, cost effective, and 
environmentally safe. The strategic and economic benefits are enormous: 
• An increase in the volume of oil and natural gas produced from existing 
reservoirs. With our better understanding of existing oil and gas reservoirs, 
we can expect to deplete existing reserves more efficiently and to locate and 
produce bypassed reserves. The additional production could help us reduce 
our dependence on foreign oil. 
• A better understanding of risks and uncertainties in exploration and lower 
An instrumented 
oilfield will result in 
more efficient, cost-
effective, and 
environmentally 
safer reservoirs, 
with enormous 
strategic and 
economic benefits. 
 18
finding costs. Better models of the subsurface would allow oil and gas 
companies to focus on prospects that offer the best return. As a result, they 
can allocate their capital much more efficiently. 
The new SBES-related technologies have immediate application to other 
areas as well, including environmental remediation and storage of hazardous 
wastes. Again, these new application areas require an integrated and interactive 
simulation framework with multiscale capabilities. The development and use of 
such frameworks require the support of cross-disciplinary teams of researchers, 
including geoscientists, engineers, applied mathematicians, and computer 
scientists. 
  
  
2.4 SBES in Materials 
  
SBES-related technology may have its greatest societal impact where 
innovations in modeling and simulation methodologies intersect with innovations 
in materials. Multiscale modeling and simulation are transforming the science 
and technology of new-material development and the improvement of existing 
materials. This transformation is tantamount to 
a shift to a powerful new paradigm of 
engineering science. The new methods enable 
the unprecedented ability to manipulate 
metallic, ceramic, semiconductor, 
supramolecular, and polymeric materials. The 
results are material structures and devices that 
have remarkable physical, chemical, 
electronic, optical, and magnetic properties. 
We can now anticipate the molecular design of 
With SBES, materials 
development becomes a 
unique opportunity for the 
integration of funda- 
mental, interdisciplinary 
knowledge, with techno- 
logical applications of 
obvious benefit to society.
 19
composite materials with undreamed-of functionalities. Moreover, to reap the 
advantages that SBES technology brings to materials development, researchers 
from many disciplines would have to integrate their knowledge in the materials 
sciences. Such collaboration maximizes the possibilities for developing materials 
of great technological value. 
The principle of materials design is rooted in the correlation of molecular 
structure with physical properties. From those correlations, models can be 
formulated that predict microstructural evolutions. Such models allow the 
researcher to investigate the mechanisms underlying the critical behaviors of 
materials and to systematically arrive at improved designs. 
The use of simulations to uncover structure-property correlations can be 
superior to relying only on experimental data. The reason is that simulation 
provides detailed information regarding the evolved microstructure, as well as 
complete control over the initial and boundary conditions. Another significant 
aspect of SBES, one that makes future materials development more robust, is that 
it links simulation methods across different length and time scales. A great deal 
of progress is being made in the first principles calculations of electronic 
structure and in atomistic simulations. Now progress is also being made in 
connecting these two powerful techniques of probing physical phenomena in 
materials. 
The benefits from new materials development are amply evident in the 
current progress in nanoscience and technology, a world-wide enterprise that can 
be compared to drug design. Because of the multiscale nature of materials 
modeling and simulation, SBES is destined to play a key role in nanoscience. 
SBES provides the capability of linking electronic-structure methods, which are 
necessary for dealing with novel nanostructures and functional properties, with 
atomistic and mesoscale techniques. That linkage ensures that the different 
phases of materials innovation—from design to testing to performance and 
lifetime evaluation—can all be simulated, examined, and optimized. 
 20
The power of multiscale computation can be seen in a number of high-profile 
applications involving the behavior of known materials in extreme environments. 
For example, a problem that has occupied the attention of a sizable community of 
researchers for several years is the characterization of the mechanical behavior of 
plastic deformation in metals at high pressure and high strain rate. The challenge, 
which is relevant to national security, is to conduct multiscale simulation that 
links all of the following: calculation of the core of a dislocation using electronic-
structure methods; the modeling of dislocation mobility using molecular 
dynamics simulation; and the determination of constitutive relations for 
continuum-level codes. Multiscale simulation can also help solve problems in the 
development of the structural components of nuclear power reactors. Such 
materials must not only be radiation resistant, but they must have lifetimes of 
over 40 years. 
Even for materials that do not have to stand up to the extreme conditions of 
high pressure and intense radiation, the field of materials innovation is rich with 
challenges to our understanding of the underlying microstructures of the 
materials. By meeting those challenges, we can reap enormous benefits. For 
example, we could generate a molecular model of 
cement, the most widely used substance made by 
humans. Such a model would help us develop a new 
cement with greater creep resistance and environmental 
durability. Similarly, models would help us improve the 
performance of catalysts for fuel-cell electric vehicles. 
We could also improve techniques in oilfield 
exploration, where instrumentation and digital 
management of hydrocarbon reservoirs are issues. In all 
these examples, improvements in materials performance 
would have great impact. 
Everywhere one looks there are problems important 
Everywhere one 
looks there are 
problems important 
to society that 
require optimizing 
the functional 
properties of 
materials through 
control of their 
microstructure. 
 21
to society that require optimizing the functional properties of materials through 
the control of their microstructures. Clearly, SBES will have a long-term impact 
on materials innovation. Three attributes of SBES in particular lead to this 
conclusion. 
• Exceptional Bandwidth: The conceptual basis of materials modeling and 
simulation encompasses all of the physical sciences. It makes no distinction 
between what belongs to physics versus chemistry versus engineering and so 
on. This universality of SBES technology represents a scientific bandwidth 
that is at least as broad as the entire range of multiscale applications in 
science and engineering. In materials modeling and simulation, as in SBES 
more generally, traditional disciplinary barriers vanish; all that matters is “the 
need to know.” 
• Elimination of Empiricism: A virtue of multiscale modeling is that the 
results from both modeling and simulation are conceptually and operationally 
quantifiable. Consequently, empirical assumptions can be systematically 
replaced by physically-based descriptions. Quantifiability allows researchers 
to scrutinize and upgrade any portion of a model and simulation in a 
controlled manner. They can thus probe a complex phenomenon detail by 
detail. 
• Visualization of Phenomena: The numerical outputs from a simulation are 
generally data on the degrees of freedom characterizing the model. The 
availability of this kind of data lends itself not only to direct animation, but 
also to the visualization of the properties under analysis, properties that 
would not be accessible to experimental observation. In microscopy, for 
example, researchers can obtain structural information but usually without 
the energetics. Through simulation, however, they can have both. The same 
may be said of data on deformation mechanisms and reaction pathways. 
These three attributes of SBES, of course, are not restricted to materials 
 22
development; they apply equally well to the other areas of SBES application. In 
this section, however, the focus has been on the application of SBES to materials 
development. The point that emerges is that, aided by SBES technology, 
materials modeling and simulation, or computational materials, is becoming the 
sister science of computational physics and computational chemistry. 
  
  
2.5 SBES in Industrial and Defense Applications 
 
Simulation is ubiquitous in industry. It plays an essential role in the design of 
materials, manufacturing processes, and products. Increasingly, simulation is 
replacing physical tests to ensure product 
reliability and quality. Fewer tests mean fewer 
prototypes, and the result is a shorter design 
cycle. Steady reductions in design cycles, in 
turn, are crucial to U.S. efforts to remain 
competitive in a world where the pace at which 
new consumer products are being developed is 
increasing every day. The need for shorter 
design cycles also applies to our national 
defense and security. World events are often 
unpredictable; our defense industry must be 
able to design, modify, and manufacture equipment in quick response to military 
and police exigencies. A case in point is the unanticipated need to reinforce 
armored vehicles in Iraq after several such vehicles were destroyed by 
improvised explosive devices. 
The use of simulation has proved effective in some industrial applications. 
For example, in crashworthiness studies the few instances that simulations 
To increase U.S. 
competitiveness, short 
design cycles are crucial if 
we are to keep up with the 
rapid pace of new-
products throughout the 
world. 
 23
replaced testing are frequently cited as success 
stories. Generally, however, simulation has yet to 
play a central role in important industrial and 
defense design applications. The reason is that 
large-scale simulation does not enter into the 
design cycle until its later stages. Model 
preparation, after all, requires a substantial amount 
of time and labor. Often it takes months to prepare 
a model, and even then the model needs to be 
calibrated with tests if the design is substantially 
different from previous designs. 
In addition, the preparation of a model usually 
requires considerable knowledge of and skill in 
finite-element analysis. For that reason, the 
challenge of generating models normally falls on 
engineers with advanced degrees, not designers. 
This separation between simulation and design 
activities results in delays and reduces the 
effectiveness of the simulation. 
The difficulties of simulation are compounded 
when new materials, such as composites and 
metallics, are used in product designs. Before 
simulation can even begin, the new materials must 
be tested extensively to determine their properties. 
Such tests are time consuming, and they lengthen 
the time necessary to prepare and conduct useful 
simulations. 
In addition, simulation capabilities are currently limited in their ability to 
model relevant phenomena. For example, in the simulation of a rear collision 
Figure 3: An example of 
contemporary visualization and 
simulation capabilities. Shown is a 
simulation of the explosion of a 
steel tank filled with explosive 
subjected to a jet of heated air. 
New methods are needed to 
capture multiscale effects and 
quantify uncertainties. 
 24
between two automobiles, it would be desirable to model the gasoline in the fuel 
tank and the effects of any fracture of the fuel tank. To date, such multi-physics 
simulations are not possible. Similarly, we are still unable to model the fracture 
of the interior panels and trim, which is important in determining occupant 
injury, or the fracture of sheet metal and structural members, which is common 
with aluminum.  
Thus, crashworthiness simulation technology 
is usually used to check designs near their final 
stages. Optimization of a design for 
crashworthiness in the early stages of the design 
process is simply not yet feasible. The complexity 
of model generation and the uncertainties are too 
great. Even if an industry were to replace testing 
almost completely with simulation, the changeover 
would still require robust verification and 
validation procedures to ensure the effectiveness of 
the simulation tools. 
Similar limitations are found in many other industrial applications where, at 
least superficially, simulation has appeared to be a success. For example, in the 
simulation of sheet-metal forming, important phenomena, such as the tribology 
of the metal-die interface, are not modeled. Those phenomena are characterized 
by much smaller scales than the overall process, and they are subject to great 
variability because they depend on factors such as temperature and the age of the 
lubricant. In the tire industry, simulation is usually limited to determining the tire 
footprint; important performance characteristics such as pothole impact, 
hydroplaning, and cornering performance cannot be simulated because they 
involve multi-physics and many disparate length and time scales. 
In the chemical processing industry, simulation would seem to have a 
significant role. In fact, most petrochemical plants use steady-state process 
If an industry is to 
replace testing with 
simulation, the 
simulation tools must 
undergo robust 
verification and 
validation procedures 
for effectiveness. 
 25
simulation models to perform detailed real-time optimization. As a result, 
chemical plants are more energy and environmentally efficient. Even in the 
chemical industries, however, the use of simulation is limited. Current planning 
models capture only nominal plant capacities; they do not address the real 
performance of the plants and the processes at various scales, nor are they 
sensitive to uncertainties. 
Over the past two decades the integrated circuit industry has been a major 
player in simulation-based engineering. Until now, the U.S. has been a leader in 
the development of highly integrated, easy-to-use software for circuit analysis, 
such as SPICE, and in the education of our engineering workforce in the 
application of that software. As a result, the U.S. was able to maintain its 
leadership in the high value-added segment of the market. As clock rates move 
into the gigahertz range, however, circuit theory is no longer applicable. Future -
generation transistors, such as single electron transistors, low-threshold 
transistors, and quantum computing devices, will be based on new physics that 
links quantum mechanics and electromagnetics. 
Overall, simulation in industry has yet to meet its full potential. The 
following list is a summary of its current limitations: 
1. The development of models is very time consuming, particularly for 
geometries of complex engineering systems such as ships, automobiles, and 
aircraft. Moreover, the determination of material properties often requires 
extensive small-scale testing before simulation can be started, especially if 
statistical properties are needed. This testing also lengthens the time to obtain 
a simulation and hence the design cycle. 
2.  Methods are needed for linking models at various scales and simulating 
multi-physics phenomena. 
3.  Simulation is often separate from the design optimization process and cannot 
simultaneously deal with factors such as manufacturability, cost, and 
environmental impact. 
 26
Overcoming these barriers will require progress in our basic understanding 
and in the development of powerful new methods. Among these challenges are 
the following:  
1.  Multiscale methods that can deal with large ranges of time and spatial scales 
and link various types of physics. 
2.  Methods for computing macroscopic phenomena, such as material properties 
and manufacturing processes, in terms of subscale behavior. 
3.  Effective optimization methods that can deal with complex integrated 
systems, account for uncertainties, and provide robust designs. 
4.  Frameworks for validation, verification, and uncertainty qualification. 
5.  Methods for rapidly generating models of complex geometries and material 
properties. 
Multiscale methods will provide extensive benefits. For instance, they will 
enable us to understand relationships and interactions of phenomena at different 
scales, which is crucial in the design of many products. In the design of products, 
it is often necessary to couple diverse physics, such as fluids with solids or 
electromagnetics with structures. Simulations of such couplings involve a large 
range of length and time scales. For example, to model live fire testing of defense 
products, it is necessary to incorporate phenomena of an immense range of scales 
associated with combustion and structures. Similarly, designs involving different 
components also have an enormous range of coupled time scales that determine 
overall system behavior. 
Multiscale methods may also make possible the prediction of material 
properties in terms of basic building blocks, ranging from matrix and fiber 
properties of composite materials to the properties of atoms in metals. Demand is 
increasing for materials that reduce weight and cost; consequently, the 
availability of tools that, through simulation, can predict the behavior of a 
material from its basic building blocks would open tremendous possibilities for 
 27
quickly developing better, less costly, and safer products. Such tools would 
eliminate the bottleneck of extensive materials testing, resulting in substantial 
reductions in design-cycle times. The methods we envision would be able to link 
models of different scales, such as models of micromechanics or even quantum 
mechanics linked to models of macroscale behavior. 
Of course, as design processes increasingly rely on computer simulation, 
validation and verification procedures will become increasingly important. 
Although some efforts have been made at providing validation benchmark 
problems for linear analysis, nonlinear simulation software has not been 
subjected to extensive validation procedures. In fact, we find considerable 
controversy as to what appropriate validation procedures are, how broadly they 
apply, and whether they are even feasible. Clearly, a basic understanding of 
verification and validation procedures is urgently needed. After all, to be useful, 
the simulation tools used by industry and defense agencies must provide reliable 
results. Furthermore, since many real-world phenomena 
are not deterministic, statistical methods that can 
quantify uncertainty will be needed. 
Design optimization is also in its infancy, and it too 
has many obstacles to overcome. The constraints on the 
optimization of a product design relate to 
manufacturability, robustness, and a variety of other 
factors. Optimality often needs to be defined in terms of 
complex criteria, and the frameworks currently in use 
are not readily amenable to that task. Moreover, to be 
effective for engineering design, optimization methods 
must be closely coupled with simulation techniques. 
Generally, however, we still lack a fundamental understanding of what 
constitutes an optimal design and how to find it in a complex multi-criteria 
design environment. Once optimization methods are developed that can deal with 
these complexities, we can expect to see chemical plants, automobiles, laptop 
SBES has the 
potential to deliver, 
within a short design 
period, designs that 
are optimized for 
cost performance 
and total impact on 
the environment. 
 28
computers, and a host of other industrial and consumer products that feature 
unprecedented efficiency at lower cost. 
In summary, SBES has the potential to deliver designs that are optimized for 
cost performance and their total impact on the environment (from production to 
disposal or recycling), all within a short design cycle. This achievement is not 
possible, however, simply by extending current research methods and taking 
small, incremental steps in SBES development. The barriers to the realization of 
SBES relate to our entire way of conducting research and development and 
educating engineers. The next chapter discusses some of these core issues.  
 
 
Finding 
Because of the interdisciplinary character and complexity of SBES 
challenges, incremental, short-term research efforts are inadequate to achieving 
SBES goals. Instead, a long-term program of high-risk research will be needed to 
resolve the numerous obstacles standing in the way of SBES developments. The 
Panel agrees with the observation made in the PITAC report and elsewhere that 
short-term investments and limited strategic planning will lead to an excessive 
focus on incremental research rather than on the long-range, sustained research 
necessary to have a lasting impact. Moreover, progress in such research will 
require the creation of interdisciplinary teams that work together on leading-edge 
simulation problems. The work of those teams should be sustained for a decade 
or more for the investment to yield its full fruits. 
 29
3.0 CORE ISSUES: Challenges, 
Barriers, and Opportunities in 
SBES Research 
 
All of the driving applications discussed in the preceding chapter share 
common challenges, barriers, and requirements for research breakthroughs. We 
elaborate on the major issues in this chapter. 
 
3.1  The Tyranny of Scales: The Challenge of  
        Multiscale Modeling and Simulation 
 
Researchers in the worldwide race toward miniaturization, nanoscience, 
molecular modeling of drugs and biological systems, advanced materials, and 
other applications, all of which involve events on atomistic and molecular levels, 
have run into a formidable roadblock: the tyranny of scales. Virtually all 
simulation methods known at the beginning of the twenty-first century were valid 
only for limited ranges of spatial and temporal scales. Those conventional 
methods, however, cannot cope  with physical phenomena operating across large 
ranges of scale—12 orders of magnitude in time scales, such as in the modeling 
of protein folding [4, p. 4], or 10 orders of magnitude in spatial scales, such as in 
the design of advanced materials. At those ranges, the power of the tyranny of 
scales renders useless virtually all conventional methods. Confounding matters 
further, the principal physics governing events often changes with scale, so that 
the models themselves must change in structure as the ramifications of events 
 30
pass from one scale to another. 
The tyranny of scales dominates simulation efforts not just at the atomistic or 
molecular levels, but wherever large disparities in spatial and temporal scales are 
encountered. Such disparities appear in virtually all areas of modern science and 
engineering, for example, in astrophysics, atmospheric science, geological 
sciences, and in the design of complex engineering systems such as submarines, 
commercial aircraft, and turbine engines. 
In many ways, all that we know about the physical universe and about the 
design and functioning of engineering systems has been partitioned according to 
categories of scale. The designer manipulating the 
electronic properties of materials sees the world as a 
myriad of infinitesimal atoms with clouds of orbiting 
electrons. The atmospheric scientist sees the world as 
the movement of great air masses that change 
climate conditions across thousands of miles of the 
earth’s surface. Today, we are attempting 
technological advances that cannot tolerate any view 
of nature that partitions phenomena into neat 
categories of scale. The modeling and simulation 
tools we are seeking now must be commensurate in 
their applications with the great breadth of the 
phenomena they must simulate. 
The tyranny of scales will not be defeated simply 
by building bigger and faster computers. Instead, we 
will have to revamp the fundamental ways we 
conceive of scientific and engineering methodologies, long the mainstays of 
human progress. Such a daunting challenge, historic in its significance, is beyond 
the capability of single individuals and disciplines. The necessary breakthroughs 
in computational mathematics and the development of new ways to model 
The development of 
effective multiscale 
modeling techniques 
will require major 
breakthroughs in 
computational 
mathematics and new 
thinking on how to 
model natural events 
occurring at multiple 
scales. 
 31
natural events at multiple scales will require the efforts of interdisciplinary teams 
of researchers and thinkers working in concert. 
We can see instances already where preliminary and often ad hoc 
methodologies have retarded technological progress. The design of nanodevices 
is one example. Nanodevices are systems with tiny masses and relatively large 
surface areas. The design of such devices is in urgent need of new simulation 
tools, because they are at a scale too small to be captured by continuum 
mechanics. Another example is any biological application that requires methods 
that link diverse time scales. For instance, the sequence of events following a 
medical implant is initiated by the interactions between individual water 
molecules and the surface of the implant. This first set of interactions occurs on a 
timescale of nanoseconds. The resulting water “shell,” in turn, has an influence 
on proteins and other types of molecules that arrive later. This second set of 
interactions has a timescale from microseconds to milliseconds. Thus, there is a 
significant time gap in the behavior that is difficult to model. Similarly, temporal 
gaps in the behavior of polymers cause problems for current simulation methods. 
Numerous important applications of nanotechnology are being driven by 
homeland security. As a result, the need and urgency for developing multiscale 
tools has increased significantly. For example, we know that small concentrations 
of chemical and biological agents can have lethal effects on large segments of the 
human population. The recognition of that threat has prompted development of 
new mitigation methods, such as miniaturized intelligent sensors, protective 
clothing, and masks. The need for engineered nanostructured materials for 
homeland-security applications, as well as for optical and structural applications, 
has spurred much interest in the development of multiscale methods that can 
accommodate diversity in spatial scales. 
Recent work in multiscale modeling has emphasized the synthesis of theories 
applicable to different scale ranges, such as quantum, molecular, and continuum 
descriptions [5, p. 1504]. Nevertheless, enormously important technological 
 32
problems, such as turbulence modeling, remain unsolved. These problems 
involve a very broad range of scales amenable to a single description, such as 
continuum theory in the case of turbulence. In fact, turbulent-flow problems in 
practical engineering involve such an enormous range of scales that they cannot 
be currently solved on the world’s largest and fastest computers. If we assume 
that progress continues at the rate of Moore’s Law, the turbulence-flow problems 
will not succumb to solutions for many generations to come. The implications of 
solving these problems are great; for example, they have to do with our 
leadership in designing future generations of commercial and military aircraft. 
Before we can lead, however, we must find the path to fundamental 
developments in multiscale modeling.  
The urgency of the development of multiscale simulation models has been 
felt worldwide. Over the past five years, virtually every conference, symposium, 
and international congress devoted to computational engineering and science has 
listed multiscale modeling as an important theme. Multiscale modeling has often 
been the subject of colloquia, study groups, or invited lectures. Three DOE 
workshops were recently held on multiscale mathematics [8, 23, 10], and 
programs at NSF and NIH are already in place for promoting the beginnings of 
new research in this area. In recent years, a large and growing body of literature 
in physics, chemistry, biology, and engineering has focused on various methods 
to fit together simulation models of two or more scales, and this has led to the 
development of various multi-level modeling approaches. To date, however, 
progress on multiscale modeling has been agonizingly slow. Only a series of 
major breakthroughs will help us establish a general mathematical and 
computational framework for handling multiscale events and reveal to us the 
commonalities and limitations of existing methods. 
 33
Finding 
Formidable obstacles remain in linking highly disparate length and time 
scales and in bringing together the disciplines involved in researching simulation 
methods. These issues are common to many SBES applications. Fundamental 
discoveries will be needed to surmount these obstacles. 
 
 
3.2 Verification, Validation, and  
Uncertainty Quantification 
 
The ultimate goal of simulation is to predict physical events or the behaviors 
of engineered systems. Predictions are the basis of engineering decisions, they 
are the determining factor in product or system design, they are a basis for 
scientific discovery, and they are the principal reason that computational science 
can project itself beyond the realm of physical experiments and observations. It is 
therefore natural to ask whether specific decisions can 
rely on the predicted outcomes of an event. How 
accurate are the predictions of a computer simulation? 
What level of confidence can one assign a predicted 
outcome in light of what may be known about the 
physical system and the model used to describe it? 
The science, technology, and, in many ways, the 
philosophy of determining and quantifying the 
reliability of computer simulations and their 
predictions has come to be known as V&V, or 
verification and validation. The methods of V&V are 
fundamental to the success and advancement of SBES.  
To appreciate the subtleties and goals of V&V, one must first dissect the 
What level of 
confidence can one 
assign a predicted 
outcome in light of 
what may be known 
about the physical 
system and the model 
used to describe it? 
 34
process of simulation.  Beginning with the conceptual understanding of certain 
physical events of interest and with scientific theories that explain them (the 
target physical phenomena or engineering system identified for study), the 
analyst (the modeler, scientist or engineer) constructs a mathematical model of 
the event.  The mathematical model is a collection of mathematical constructions, 
equations, inequalities, constraints, etc., that represent abstractions of the reality, 
and are dictated by the theory or theories characterizing the events. The analyst 
then develops a computational model of the event. The computational model is a 
discretized approximation of the mathematical model, and its purpose is to 
implement the analysis on a computer. Validation is the subjective process that 
determines the accuracy with which the mathematical model depicts the actual 
physical event. Verification is the process that determines the accuracy with 
which the computational model represents the mathematical model. In simple 
terms, validation asks, “Are the right equations solved?” while verification asks, 
“Are the equations solved correctly?” 
The entire field of V&V is in the early stage of development. Basic 
definitions and principles have been the subject of much debate in recent years, 
and many aspects of the V&V remain in the gray area between the philosophy of 
science, subjective decision theory, and hard mathematics and physics. The 
twentieth century philosopher of science Karl Popper asserted that a scientific 
theory could not be validated; it could only be 
invalidated. Inasmuch as the mathematical model of 
a physical event is an expression of a theory, such 
models can never actually be validated in the strictest 
sense; they can only be invalidated. To some degree, 
therefore, all validation processes rely on prescribed 
acceptance criteria and metrics. Accordingly, the 
analyst judges whether the model is invalid in light 
of physical observations, experiments, and criteria 
The most 
confounding aspect of 
V&V has to do with 
uncertainty in the data 
characterizing 
mathematical models 
of nature. 
 35
based on experience and judgment. 
Verification processes, on the other hand, are mathematical and 
computational enterprises. They involve software engineering protocols, bug 
detection and control, scientific programming methods, and, importantly, a 
posteriori error estimation. 
Ultimately, the most confounding aspect of V&V has to do with uncertainty 
in the data characterizing mathematical models of nature. In some cases, 
parameters defining models are determined through laboratory tests, field 
measurements, or observations, but the measured values of those parameters 
always vary from one sample to another or from one observation to the next. 
Moreover, the experimental devices used to obtain the data can introduce their 
own errors because of uncontrollable factors, so-called noise, or errors in 
calibration. For some phenomena, little quantitative information is known, or our 
knowledge of the governing physical processes is incomplete or inaccurate. In 
those cases; we simply do not have the necessary data needed to complete the 
definition of the model. 
Uncertainty may thus be due to variability in data due to immeasurable or 
unknown factors, such as our incomplete knowledge of the underlying physics or 
due to the inherent nature of all models as incomplete characterizations of nature. 
These are called subjective uncertainties. Some argue that since the data itself 
can never be quantified with absolute certainty, all 
uncertainties are subjective. Whatever the source of 
uncertainty, techniques must be developed to 
quantify it and to incorporate it into the methods and 
interpretation of simulation predictions. 
Although uncertainty-quantification methods 
have been studied to some degree for half a century, 
their use in large-scale simulations has barely 
begun. Because model parameters can often be 
The use of stochastic 
models can represent 
gigantic increases in 
complexity in data 
volume, storage, 
manipulation, and 
retrieval requirements.
 36
treated as random fields, probabilistic formulations provide one approach to 
quantifying uncertainty when ample statistical information is available. The use 
of stochastic models, on the other hand, can result in gigantic increases in the 
complexity of data volume, storage, manipulation, and retrieval requirements. 
Other approaches that have been proposed for uncertainty quantification include 
stochastic perturbation methods, fuzzy sets, Bayesian statistics, information-gap 
theory, and decision theory. The development of reliable methodologies—
algorithms, data acquisition and management procedures, software, and theory—
for quantifying uncertainty in computer predictions stands as one of the most 
important and daunting challenges in advancing SBES. 
 
Finding 
While verification and validation and uncertainty quantification have been 
subjects of concern for many years, their further development will have a 
profound impact on the reliability and utility of simulation methods in the future. 
New theory and methods are needed for handling stochastic models and for 
developing meaningful and efficient approaches to the quantification of 
uncertainties. As they stand now, verification, validation, and uncertainty 
quantification are challenging and necessary research areas that must be actively 
pursued. 
 
 
 37
3.3 Dynamic Simulation Systems, Sensors, 
Measurements, and Heterogeneous Simulations 
  
One of the most challenging applications of SBES, but one that may yield the 
greatest dividends, is the linkage of simulation tools directly to measurement 
devices for real-time control of simulations and computer predictions. Some 
preliminary investments in the research into this new idea have been made under 
NSF’s program in dynamic data-driven applications systems (DDDAS) [7, 9]. 
The full development of this revolutionary and fundamentally important 
discipline will take years of research and technological development. 
The concept of DDDAS is envisioned as a new paradigm in computer 
simulation, one involving a “symbiotic feedback control system” [7, 9] in which 
simulations and experiments (or field data) interact in real time to dramatically 
improve the fidelity of the simulation tool, its accuracy, and its reliability. 
The document that originally put forth the idea [7], now over five years old, 
described the goal of DDDAS as one of developing “application simulations that 
can dynamically accept and respond to ‘online’ field data and measurements 
and/or control such measurements. This 
synergistic and symbiotic feedback control loop 
among applications, simulations, and 
measurements is a novel technical direction that 
can open new domains in the capabilities of 
simulations with a high potential payoff, and 
create applications with new and enhanced 
capabilities. It has the potential to transform the 
way science and engineering are done, and 
induces a major beneficial impact in the way 
many functions in our society are conducted, such 
This synergistic and 
symbiotic feedback 
control loop among 
applications, simulations,
and measurements has 
the potential to transform 
the way science and 
engineering are done. 
 38
as manufacturing, commerce, transportation, hazard prediction/management, and 
medicine, to name a few.” 
A half-decade later, these words are still true, but we also better appreciate 
the size of the challenge. To develop DDDAS, we must resolve issues involving 
the complexity of the systems, the breadth of expertise and technologies required 
to implement the systems, the new software infrastructures, and the efficiency 
and capacity of the computational and data management systems required. 
Success on all those technological fronts will mandate a sustained and well-
funded program of basic and applied research over possibly a decade or more. 
The payoffs, however, are immense—so important, in fact, that the highest 
priority should be given to developing and exploiting this fundamental SBES 
discipline. DDDAS is a concept conceived, defined, and promoted in the United 
States. To capitalize on our own initiatives, however, we must become aggressive 
in our development of DDDAS. Our current complacency in this technology is 
allowing our competitors to gain on us, once again. 
The basic building blocks of DDDAS include the following: 1) a hierarchy of 
heterogeneous simulation models, 2) a system to gather data from archival and 
dynamic sources, 3) algorithms to analyze and predict system behavior by 
blending simulation models and data, 4) algorithms to steer and control the data 
gathering and model validation processes, and 5) the software infrastructure 
supporting model execution, data gathering, analysis prediction, and control 
algorithms.  
In many ways, DDDAS will rewrite the 
book on the validation and verification of 
computer predictions. No longer will 
validation be a one-shot operation to judge the 
acceptability of a simulation problem on the 
basis of a static data set. In DDDAS, validation 
becomes a part of the dynamic control process 
Dynamic data-driven 
application systems will 
rewrite the book on the 
validation and verification 
of computer predictions. 
 39
that identifies and assesses deficiencies of the computational model and upgrades 
and improves the model on the fly. This incorporation of validation into the 
dynamics of the model dramatically enriches the predictability of the model and 
increases confidence in the predicted results. 
DDDAS dynamically incorporates measurement data into a simulation as 
that simulation is executing. The simulation, in turn, dynamically steers the 
measurement process. To perform these operations, DDDAS integrates large-
scale numerical computing with data-intensive computing, sensors, imaging, grid 
computing, and other measurement devices. The development of this technology 
requires new concepts in software infrastructure, algorithms, control protocols, 
and solvers. Once in place, however, the technology offers an endless list of 
applications. Surgical procedures, homeland security, control of hazardous 
materials, environmental remediation, drug delivery, manufacturing processes, 
oil reservoir management, and vehicle flight control are just a few. 
  
  
Finding 
Research is needed to effectively use and integrate data-intensive computing 
systems, ubiquitous sensors and high-resolution detectors, imaging devices, and 
other data-gathering storage and distribution devices, and to develop 
methodologies and theoretical frameworks for their integration into simulation 
systems. Concomitant investments are also required in sensory-data computing, 
the collection and use of experimental data, and the facilitation of interactions 
between computational models and methods, all of which are necessary to 
achieve dynamic adaptive control of the computational process. 
 
 
 40
3.4 New Vistas in Simulation Software  
  
Many contemporary engineering communities regard simulation software as 
a commodity that vendors provide for well-defined, specific, and independent 
domains of application. Occasionally, these long-lived codes for engineering 
analysis receive incremental improvements, usually in the form of functional 
extensions. This leisurely approach to software development will not support the 
next generation of engineering problems—multiscaling with real-time data 
interaction and abundant uncertainties in the data. As the PITAC report states 
[14], “Today it is altogether too difficult to develop computational science 
software and applications. Environments and toolkits are inadequate to meet the 
needs of software developers in addressing increasingly complex 
interdisciplinary problems. Legacy software remains a persistent problem 
because the lifetime of a computational science application is significantly 
greater than the three- to five-year life cycle of a computing system. In addition, 
since there is no consistency in software engineering best practices, many of the 
new applications are not robust and cannot easily be ported to new hardware.” 
For those reasons, entirely new approaches are 
needed for the development of the software that will 
encapsulate the models and methods used in SBES. 
Researchers must identify the methodologies that support 
the interoperability of individual components of 
simulation software. Then they must develop those 
methodologies and integrate them into the next 
generation of engineering software. This search for new 
methods and tools to support simulation software 
development is fraught with difficulties. Not only do the 
new simulation components require complex algorithms, 
they must also function efficiently on an evolving range 
Entirely new 
approaches are 
needed for the 
development of the 
software that will 
encapsulate the 
models and 
methods used in 
SBES. 
 41
of architectures designed for large-scale parallel computations. 
Tomorrow’s SBES software requires extraordinary degrees of robustness, 
efficiency, and flexibility. The new software must not only execute simulation 
algorithms, but must also dynamically manage data throughput and model 
adaptivity and control. It must steer observational and measurement systems to 
optimize data collection and use. It must navigate efficiently across models of 
multiple scales and accommodate multiple physical theories, and it must have 
scalable methods that interact seamlessly with data-gathering devices. 
Much of our contemporary software development tools—libraries (for 
instance, linear equation solvers), language interoperability tools, component 
coupling and data transfer tools, and simulation development frameworks—do 
not meet the demands of SBES. To define the real requirements for the 
implementation of SBES technologies, we require a new paradigm of software 
development. Such a fundamental change calls for a great deal of “out-of-the-
box” thinking about the way we approach software 
development and practice engineering. The change 
will even affect the way scientific computing is 
taught and perceived in our universities. Not only 
will tomorrow’s software developers have to cope 
with more complex systems and heterogeneous 
hardware systems, but they will also have to 
understand the important details of the applications. 
Whereas the future of SBES software is largely 
uncharted, some path-finding work is under way. A 
Federal government group, for instance, has taken a 
similarly aggressive software philosophy and 
developed software with which to bootstrap. This effort is called the Scientific 
Discovery Through Advanced Computing (SciDAC) initiative [26] (see also 
Chapter 2 of [18]). Organized in 2001, SciDAC is a highly interdisciplinary 
Not only will tomorrow’s 
software developers 
have to cope with more 
complex algorithms, 
but they will also have 
to understand the 
important details of the 
applications. 
 42
program tasked with finding methods by which state-of-the-art mathematics and 
domain-specific application sciences can be embodied in robust codes that run 
efficiently on current terascale supercomputers. The initiative is driven by 
research into science applications relevant to the goals of DOE’s Office of 
Science. Those applications include fields such as global climate modeling, 
plasma fusion, quantum chromodynamics, accelerators, combustion, and 
supernovae, as well as the mathematics and computer science relevant to those 
disciplines. Most of this research portfolio involves the coordinated efforts of 
dedicated domain scientists in collaboration with mathematicians, computer 
scientists, and computational scientists throughout the nation. One of the 
principal products of SciDAC is sharable software, and development of such 
software takes the sustained effort of a permanent staff.  For this reason, the 
center of gravity for most of the work in this field is at national labs.  In addition, 
U.S. universities continue to play a key role in that research. At any rate, it is 
clear that the questions are too large and complex for any single institution to 
manage alone. Instead, we must encourage the formation of teams of researchers, 
working in a collaborative software environment, where they can profit from 
distributed resources and expertise. 
The DOE’s National Nuclear Security Agency is also heavily involved in 
computational science. In the mid-1990s, that agency embarked on an ambitious 
program of Stockpile Stewardship. Part of the 
program was the Accelerated Strategic Computing 
Initiative (ASCI, now ASC). With ten times the 
funding of SciDAC, the ASCI program, among other 
goals, seeks to use simulation to manage our nuclear 
stockpile. Simulation, in this case, would be a 
substitution for our actual testing of the devices, 
which is prohibited by international treaty. Five 
centers were established at U.S. universities to 
The new paradigm for 
SBES software 
research and 
development will 
allow for 
specialization with 
cross-accountability. 
 43
develop the computational science for ASCI. 
As both DOE programs exemplify, if the engineering sciences are to realize 
the full benefits of the rapid advances in computing technologies, we must 
somehow integrate the knowledge and discoveries of mathematics, computer 
science, engineering, and the domain sciences. We also need to recognize that 
SBES is located at the intersection of those disciplines. In that sense, we can 
think of SBES as a super-discipline. 
The new paradigm for SBES software research and development will allow 
for specialization with cross-accountability. As envisioned, mission-driven 
teams, primarily practicing engineers, will define and model the engineering 
systems that require breakthroughs in simulation methods (for example, artificial 
organs or distribution networks). In addition, the engineers will tentatively 
identify data interfaces and the computational tasks between those interfaces. 
From there, teams of “enabling technologists,” primarily mathematicians and 
computer scientists, will tackle the abstract requirements identified by the 
mission-driven teams and develop software components that port across the 
target architectures (for example, massively parallel distributed memory 
computers). The component development will track the research frontier for each 
algorithmic area of expertise (for example, error estimation or eigenanalysis) 
while also conforming to mission requirements. 
 
Finding 
Much of our current software in computational engineering science is inadequate for 
dealing with the multifaceted applications and challenges of SBES. New software tools, 
paradigms, and protocols will need to be developed so that software is more transferable 
between fields and not wastefully duplicated. In the multidisciplinary teams we establish 
for SBES research, we must incorporate experienced software developers who will work 
closely with engineering scientists to develop tomorrow’s SBES software. 
 44
3.5 The Emergence of Big Data in Simulation and 
       the Role of Visualization in SBES 
  
Since the advent of computing, the world has experienced an information 
“big bang,” an explosion of data. Information is being created at an exponential 
rate. Since 2003, digital information makes up 
90 percent of all information production, 
vastly exceeding the amount of paper and film. 
One of the greatest scientific and engineering 
challenges of the twenty-first century is to 
understand and make effective use of this 
growing body of information.  
In the computational engineering and 
science environment that existed near the end 
of the previous century, data-intensive computing and large-scale scientific 
computing were essentially disjoint camps. One transported, stored, and 
manipulated large data sets, and the other implemented scalable parallel 
computing strategies for resolving very large computational models of scientific 
and engineering problems. That era of separation has passed. In all the 
applications of SBES discussed in this chapter, the use and generation of 
immense data sets are integral components. For example, uncertainty 
quantification, a key component of SBES, will require data sets many orders of 
magnitude larger than those of traditional deterministic computing. DDDAS, by 
definition, will demand new methods that rapidly generate, store, access, and 
transfer large data sets over computational grids or high-bandwidth networks. 
Then there is the issue of interpreting the results of the simulation itself, a 
problem that can involve gigantic data sets.  
As we work to harness the accelerating information explosion, visualization 
will be among our most important tools. Indeed, visualization capabilities will 
The era in which data-
intensive computing and 
large-scale scientific 
computing were 
essentially disjoint camps 
is over. 
 45
have a dramatic impact on scientific, biomedical, and engineering research; 
defense and national security; and industrial innovations. 
The reason visualization is such a powerful tool is that it is fundamental to 
our ability to interpret models of complex phenomena, such as multilevel models 
of human physiology from DNA to whole organs, multi-century climate shifts, or 
multidimensional simulations of airflow past a 
jet wing. Visualization reduces and refines data 
streams rapidly and economically, thus enabling 
us to winnow huge volumes of data – an ability 
important in applications such as the 
surveillance of public health at a regional or 
national level in order to track the spread of 
infectious diseases. Visualization for solving 
problems in applications like hurricane 
dynamics and homeland security are generating 
new knowledge that crosses traditional 
disciplinary boundaries. Finally, the use of 
visualization is rapidly transforming business 
and engineering practices for the better [15], 
thereby increasing the competitive edge of our 
industry. 
Visualization allows people to comprehend visual representations of data 
much more rapidly than they can digest the raw numbers or text.  The designers 
of computer visualization tools exploit the high-bandwidth channel of human 
visual perception.   Software systems may provide either static or interactive 
visual representations of data, depending on user needs and on whether the final 
goal is the explanation or the exploration of the data.  
Visual representation of information has a rich historical tradition, primarily 
in manually created depictions such as anatomical drawings, spread sheets or 
Visualization is 
fundamental to our ability 
to interpret models of 
complex phenomena, 
such as multilevel models 
of human physiology from 
DNA to whole organs, 
multi-century climate 
shifts, or multidimensional 
simulations of airflow past 
a jet wing. 
 46
basic graphics.  Now, however, computer graphics has the scalability to handle 
datasets much larger than any that could be manually depicted. In addition, 
computer graphics offers new possibilities in animation and interactivity. 
Visualization is useful for detecting patterns, assessing situations, and prioritizing 
tasks. Computation alone does not lead to understanding. The end user also needs 
a comprehensible interface with the computational output. Visualization provides 
that interface, and in so doing becomes the key to the interpretation of the data. 
Engineers need assistance in making complex decisions and analyses, 
especially with tasks involving large amounts of data. Often, engineers have to 
deal with over-specified situations, and visualization of the situation helps them 
filter out the irrelevant data. Engineers can use visual analysis systems to explore 
“what if” scenarios and to examine data under multiple perspectives and 
assumptions. They can identify connections between any number of attributes, 
and they can assess the reliability of any conclusions [15]. 
Visualization research must continually respond to 
and address the needs of the scientific community.  For 
example, the ability to visualize measures of error and 
uncertainty will be fundamental to a better 
understanding of three-dimensional simulation data. 
This understanding will allow the validation of new 
theoretical models, improve the interpretation of data, 
and facilitate decision-making. With few exceptions, 
however, visualization research has ignored the need 
for visual representation of errors and uncertainty for 
three-dimensional visualizations [16]. We need to 
create an SBES visualization framework for 
uncertainty and to investigate new visual 
representations for characterizing error and uncertainty. 
Within DDDAS and SBES applications, visualization of time-dependent data 
We need to create 
an SBES 
visualization 
framework for 
uncertainty and to 
investigate and 
explore new visual 
representations for 
characterizing error 
 47
will be crucial. Currently, however, most interactive visualization techniques 
make use of static data only. The prevailing method for visualizing time-
dependent data is first to select a viewing angle and then to render time steps off- 
line and play the visualization back as a video. Whereas this approach is often 
adequate for presentational purposes, the inability to engage in interactive 
exploration undermines the effectiveness and relevancy of visualization for 
investigative purposes. Thus, new methods for interactively visualizing large-
scale, time-dependent data are needed. In addition, we need methods for 
visualizing vector and tensor fields, field data collected experimentally from 
multiple sources, and the ability to visualize data from both a global and local 
perspective. 
Figure 4:  State-of-the-art visualization of turbulence in combustible flow.  
Tomorrow’s capabilities may include parallel, interrogative visualization tools, 
integration of visualization with large-scale dynamics simulations of complex 
multi-physics events, and zooming techniques to visualize events at multiple scales. 
 48
      New approaches to algorithmic visualization will be needed that focus on the 
needs of SBES. One approach is interrogative visualization, which is another 
way of saying that quantitative querying through analysis must be supported 
hand-in-hand with fast rendering of domains and computed function fields. A 
second approach is interpretive visualization. Interpretive visualization focuses 
on informatics and techniques to interpret imaging data, as well as various 
quantitative-analysis data. For example, going from imaging data to the 
construction of a domain model is an arduous task. In particular, to capture 
spatial domain realism at each of the desired scales of simulation is daunting, and 
may in fact be impossible. 
A third approach is repetitive visualization. Humans have several 
biorhythms. We have the daily circadian rhythm of mental efficiency, and we 
alternate between periods of work and rest. We should accommodate biorhythms 
in our methodologies for quantitative or interpretive visualization. In other 
words, we should develop a mathematical framework for visualizations that 
allows our perceptions of information to change with repeated visualizations of 
that information. Additionally, if we are simulating the same function using 
models at varying scales, we would have a natural opportunity to revisit our 
earlier visualizations and make comparisons at multiple scales [2]. 
Because of the complexity and the massive amounts of data from 
simulations, researchers will turn to semi-automated techniques from the 
multidisciplinary field of scientific data mining to extract useful information 
from the data. To meet this purpose, data-mining techniques exploit ideas from 
image and video processing, statistics, pattern recognition, mathematical 
optimization, and other fields. Scientific data-mining techniques can be used to 
quantitatively compare simulations to each other and to experiments, to extract 
summary statistics from high-fidelity simulations for use in building models, and 
to analyze experimental data. 
Whereas data-mining techniques can be effective in the extraction of 
 49
information from simulation data, several open challenges remain. Those 
challenges include the extraction of features of interest from adaptive mesh 
refinements and unstructured grids, the processing and interpretation of 
experimental images that are often of low quality, the definition of metrics used 
in comparisons of simulations and experiments, and the analysis of distributed 
data sets resulting from simulations on parallel systems [17]. 
 
Finding 
Visualization and data management are key technologies for enabling future 
contributions in SBES. In addition, they hold great promise for scientific 
discovery, security, economic competitiveness, and other areas of national 
concern. Computer visualization will be integral to our ability to interpret and 
utilize the large data sets generated in SBES applications. 
 
 
3.6 Next-Generation Algorithms and 
              Computational Performance 
  
Algorithms, the recipes for turning mathematical into computational 
processes, provides the bridge between the models describing physical and 
engineered systems, on the one hand, and the computational devices that generate 
the digital representations of simulations, on the other. Too often, only the speed 
of a computational device is cited as the figure of merit for simulation 
performance, and the impact of algorithms on reducing the time complexity 
(number of operations) and space complexity (size of memory) is unappreciated.  
For more than three decades, progress in microprocessor capabilities has been 
described by Moore’s Law, the observation that the number of transistors per unit 
 50
area on a processor doubles every 18 months, with corresponding increases in 
practical performance for a fixed algorithm.  Faster and more cost-effective 
hardware is a strong driver for simulation-based engineering.  However, 
algorithmic improvements have been far more important.  
In tomorrow’s SBES environment, the computing performance of individual 
microprocessors will be just one of many important factors.  New metrics will be 
needed to judge the effectiveness of systems based on SBES principles. More 
fundamental metrics include: time to solution in a multiprocessor environment, 
the wall-clock time that elapses from the initiation of the simulation process to 
the predicted outcome, and a measure of the confidence level for the predicted 
result. If the time to solution is short, but the quality of and confidence in the 
solution are low, the prediction may be of little value. 
Improved algorithms have resulted in significant performance gains as 
measured by time to solution. Recent studies have noted remarkable progress in 
this area [3, 13, 18]. Figure 5 shows an example of that progress. The figure 
depicts improvements in performance for large-scale simulations of turbulent 
gas-phase combustion [19, p. 79]. As the example shows, advances in simulation 
algorithms have tripled the effective performance over that due to advances in 
processor speed alone over a period of a couple of decades.  Similar results have 
been documented in many other domains, such as magnetohydrodynamics and 
radiation transport, and should inspire efforts to obtain and document super- 
Moore’s Law gains in all areas of SBES 
Among the most challenging problems for new algorithms are optimization 
and inverse problems. Simulation-based decision-making gives rise to complex 
optimization problems, which are governed by large-scale simulations. These 
optimization problems appear in engineering design (in which the decision 
variables represent the configuration and constitution of the system) and in 
manufacturing and operations (in which the decision variables represent control 
parameters). Moreover, decision-making informed by predictive simulation 
 51
requires estimations of uncertain parameters that characterize the simulation. The 
response to the resulting inverse problems is to seek estimates for those 
parameters that minimize discrepancies with observations. 
 
 
Unfortunately, simulation-based optimization—whether in the form of 
optimal design, optimal control, or inverse problems—is notoriously more 
challenging than the corresponding simulation. First, the optimization problem is 
typically ill-posed, even though the simulation problems themselves are usually 
well-defined. Second, optimization usually results in a four-dimensional space-
time boundary-value problem, despite the evolutionary nature of the forward 
problem. Third, the optimization problem is often formulated in probabilistic 
terms. Fourth, the simulation is merely a subproblem associated with 
optimization, which can be orders of magnitude more computationally 
challenging. Indeed, when the simulation problem requires terascale resources, 
Figure 5.  Increases in time to solution due to new algorithms, given in
effective gigaflops over a period of years during which Moore’s Law, the
bottom line on this log-linear plot, remains valid (from [19, p. 79]). 
 52
the optimization problem will be in the petascale realm. 
Contemporary optimization methods are inadequate for those tasks. We need 
entirely new classes of scalable, efficient, and robust optimization algorithms that 
are tailored to the complex multiscale, multi-physics simulations engendered by 
SBES. The resulting challenges are of the highest order; yet, they must be 
overcome to fulfill the promise of SBES: to elevate decision-making from a 
practice relying on simple interpolative models to a more rigorous science based 
on high-fidelity predictive simulation. 
 
  
Finding 
Investment in research in the core disciplines of science and engineering at 
the heart of SBES applications should be balanced with investment in the 
development of algorithms and computational procedures for dynamic 
multiscale, multiphysical applications. 
 
 53
4.0 THE CRISIS OF THE KNOWLEDGE 
EXPLOSION: SBES Education for 
Tomorrow’s Engineers and 
Scientists 
  
In Volume Two of the SCaLeS Report [19], one finds mention of the “crisis 
of the knowledge explosion.”  This expression refers to the dramatic expansion 
of the knowledge base required to advance modern simulation. The expansion 
ignores the traditional boundaries between academic disciplines, which have long 
been compartmentalized in the rigid organizational structures of today’s 
universities. The old silo structure of educational institutions has become an 
antiquated liability. It discourages innovation, limits the critically important 
exchange of knowledge between core disciplines, and discourages the 
interdisciplinary research, study, and interaction critical to advances in SBES.  
The PITAC report [4] lists the following as one its principal 
recommendations [4, p. 9]: “Universities must significantly change their 
organizational structures to promote and reward collaborative research that 
invigorates and advances multidisciplinary science. Universities must implement 
new multidisciplinary programs and organizations that provide rigorous, 
multifaceted education for the growing ranks of computational scientists the 
nation will need to remain at the forefront of scientific discovery.” The report 
goes on to ask: Will research and educational study in the twenty-first century be 
“medieval or modern?”  
The Panel strongly supports the viewpoint of the PITAC Report. If 
simulation is to become a discipline, an engineering tool, and a life-long learning 
 54
opportunity, then the university-level engineering educational system in this 
country must be restructured. The current system does not provide the broad 
range of interdisciplinary knowledge that tomorrow’s engineers and scientists in 
SBES require. To succeed, they must acquire substantial depth in computational 
and applied mathematics, as well as in their specific engineering or scientific 
disciplines. Graduate students, moreover, must be able to build foundations that 
allow them to access quantum and molecular science; statistical and continuum 
mechanics; biological science and chemistry; applied and computational 
mathematics; computer science and scientific computing; and imaging, geometry, 
and visualization.  Participation in multidisciplinary research teams and industrial 
internships will give students the broad scientific and technical perspective, as 
well as the communication skills that are necessary for the effective development 
and deployment of SBES. 
The integration of SBES into the educational system will broaden the 
curriculum for undergraduate students. Undergraduates, moreover, will have 
access to educational materials that demonstrate theories and practices that 
complement the traditional experimental and theoretical approaches to 
knowledge acquisition. In addition, SBES will provide a rich new environment 
for undergraduate research, in which students from engineering and science can 
work together on interdisciplinary teams. 
As in any entrenched culture, change is hard to 
come by. To change the culture of separate 
disciplines in U.S. universities will require well-
directed, persistent, and innovative federal 
initiatives.  The NSF has already done much to 
encourage multidisciplinary research and education 
through initiatives like the ITR and IGERT and DOE 
has the highly successful SciDAC program. Serious 
consideration should be given to turning successful 
NSF will need to 
collaborate with other 
federal agencies to 
open the door for a 
new generation of 
multidisciplinary 
research. 
 55
cross-cutting programs into permanent (but still cross-cutting) administrative 
structures, just as the disciplinary divisions are permanent. 
It is unlikely that the necessary changes in educational structure will come 
without strong directives from leaders from academia, industry, and government 
laboratories.  Exactly what changes are needed and how they can best be 
implemented are issues well beyond the scope of this Panel.  A detailed study of 
these issues, perhaps undertaken by an NSF-funded committee of the National 
Research Council, could trace out the new educational framework needed for 
effective interdisciplinary study and research. 
The NSF needs to take the lead in “legitimizing” multidisciplinary research. 
One possibility might be the introduction of CAREER awards in 
multidisciplinary research areas. In some areas, NSF will need to collaborate 
with other federal agencies to open the door for a new generation of 
multidisciplinary researchers. A core base of funding should be provided that will 
allow multidisciplinary research and education to flourish. Best practices in 
multidisciplinary education should be identified and then encouraged.  NSF 
programs like IGERT or DOE’s Computational Science Graduate Fellowship 
Program provide much-needed funding and guidance for multidisciplinary 
graduate education, but they only have the resources to fund a very few such 
efforts in a given area. More funding is urgently needed for multidisciplinary 
graduate education programs that offer students an integrated approach of team 
research and career development. 
 56
Finding 
Meaningful advances in SBES will require dramatic changes in science and 
engineering education. Interdisciplinary education in computational science and 
computing technology must be greatly improved. Interdisciplinary programs in 
computational science must be encouraged, and the traditional boundaries 
between disciplines in higher education must be made pervious to the exchange 
of information between discipline scientists working within multidisciplinary 
research teams. 
 
 57
5.0 CONCLUSIONS  
  
This report has documented the findings and recommendations of the Blue 
Ribbon Panel on Simulation-Based Engineering Science, or SBES. As defined in 
this report, SBES is a discipline that focuses on the computer modeling and 
simulation of complex, interrelated engineered systems and on the acquisition of 
data meeting specified standards of precision and reliability. SBES draws on 
advances in scientific understanding and incorporates that understanding into 
new approaches to problems in the engineering domain through computer 
simulation.  
The need for SBES as a distinct field of research comes at a crossroads in our 
nation’s technological development. For almost half a century, developments in 
mathematical modeling, computational algorithms, and the technology of data-
intensive computing have led to remarkable improvements in the health, security, 
productivity, quality of life, and competitiveness of the United States. We have 
now arrived at an historic moment. As described in this report, we are on the 
verge of an enormous expansion in our ability to model and simulate an almost 
limitless variety of natural phenomena. That expansion has profound 
implications: 
First, computer modeling and simulation will allow us to explore natural 
events and engineered systems that have long defied analysis, measurement, and 
experimental methodologies. In effect, empirical assumptions will be replaced by 
science-based computational models. 
Second, modeling and simulation will have applications across 
technologies—from microprocessors to the infrastructure of cities. Not the least 
of these new technologies will be effective systems for national security. 
 58
Moreover, new simulation methods will lay the groundwork for entire 
technologies that are only now emerging as possibilities. 
Third, modeling and simulation will enable us to design and manufacture 
materials and products on a more scientific basis with less trial and error and 
shorter design cycles. 
Fourth, modeling and simulation will greatly improve our ability to predict 
outcomes and optimize solutions before committing resources to specific designs 
and decisions. 
Fifth, modeling and simulation will expand our ability to cope with problems 
that have been too complex for traditional methods. Such problems, for example, 
are those involving multiple scales of length and time, multiple physical 
processes, and unknown levels of uncertainties. 
Sixth, modeling and simulation will introduce tools and methods that apply 
across all engineering disciplines—electrical, computer, mechanical, civil, 
chemical, aerospace, nuclear, biomedical, and materials science. For instance, all 
engineering disciplines stand to benefit from advances in optimization, control, 
uncertainty quantification, verification and validation, design decision-making, 
and real-time response. 
There is little wonder that independent studies into the future of the nation’s 
technology are unanimous in their conclusions that computer modeling and 
simulation are the key elements for achieving progress in engineering and 
science. The challenges of making progress, however, are as substantial as the 
benefits. We must, for example, find methods for linking phenomena in systems 
that span large ranges of time and spatial scales. We must be able to describe 
macroscopic events in terms of subscale behaviors. We need better optimization 
procedures for simulating complex systems, procedures that can account for 
uncertainties. We need to build frameworks for validation, verification, and 
uncertainty quantification. Finally, we need methods for rapidly generating high-
fidelity models of complex geometries and material properties. 
 59
We are not alone in recognizing the urgency of our need to find solutions to 
these problems. Many of our international competitors are well ahead of us in 
committing the necessary funding and intellectual resources to overcome the 
technical problems described in this report. Indeed, the technological superiority 
Americans have so long taken for granted seems to be slipping away. 
To arrest that trend and to help restore the U.S. to its leadership role in this 
strategically critical technology, the Panel has made four recommendations (see 
page xiv of this report for details): 
(1) The Panel recommends that the NSF change its organizational structures 
to facilitate long-range core funding of SBES. 
(2) The Panel recommends a minimum sixfold increase in funding over 2005 
levels of SBES-related disciplines. 
(3) The Panel recommends a long-term program of high-risk research to 
exploit the considerable promise of SBES.  
(4) The Panel recommends that NSF underwrite an effort to explore the 
possibility of initiating a sweeping overhaul of our engineering 
educational system to reflect the multidisciplinary nature of modern 
engineering and to help students acquire the necessary modeling and 
simulation skills. 
These recommendations call for NSF to take decisive and aggressive action 
to support SBES. Unfortunately, over the past decade, NSF and other agencies 
have persistently funded far fewer simulation-related research projects than 
recommended.  The difference was sometimes a factor of three and occasionally 
a factor of ten. Moreover, even projects receiving support were frequently under-
funded and the grant periods were so short that researchers could only hope to 
achieve incremental advances in the development of key disciplines. By contrast, 
over the same period, funding for SBES research in Europe and Asia increased 
many fold.  To overcome these combined shortcomings in funding and duration, 
 60
the Panel recommends at NSF, an annual fund of $300 million be made available 
to advance the SBES components critical to the nation’s security, leadership, and 
competitiveness. 
The Panel recognizes that improvements in the speed and efficiency of 
computers remain important components of advances in SBES. Nevertheless, 
efforts in these improvements should not supersede efforts in other disciplines 
underlying simulation. Instead, NSF should focus on initiatives in SBES that 
promote interaction between multiple disciplines that fit naturally and 
strategically in parallel with or within the Cyberinfrastructure framework. Within 
NSF, SBES should represent a new and fundamental thread of the 
Cyberinfrastructure theme, one that could well call for a parallel program that 
interfaces every division within the Directorate of Engineering, if not across the 
entire Foundation. 
 
 61
Appendix A: SBES Workshop Attendees 
April 2004 Workshop 
 
Workshop Organizers  
 Ted Belytschko (Northwestern)     Thomas J. R. Hughes (U Texas-Austin) 
  Jacob Fish (Rensselaer)    J. Tinsley Oden (U Texas-Austin)  
 
Universities 
Narayan Aluru, (U Illinois-UC)  Donald Millard (Rensselaer) 
William Curtin (Brown U)      Robert Moser (U Illinois-UC) 
Leszek Demkowicz (U Texas-Austin)   Alan Needleman (Brown U) 
Charbel Farhat (U Colorado-Boulder)   N. Radhakrishnam (N Carolina A&T U)  
Omar Ghattas (Carnegie Mellon)    Mark Shephard (Rensselaer) 
Anthony Ingraffea (Cornell)    Charles Taylor (Stanford) 
Chris Johnson (U Utah)      Mary Wheeler (U Texas-Austin) 
David Keyes (Columbia)   
 
Government Laboratories 
Thomas Bickel (SNL)    Walter Jones (AFOSR)    
John Red-Horse (SNL)    Raju Namburu (ARL)    
Roshdy Barsoum (ONR)    Noam Bernstein (NRL)     
Luise Couchman (ONR)    Jonathan B. Ransom (NASA)  
Craig Hartley (AFOSR)   
      
NSF 
   Kamal Abdali (NSF)    George Lea (NSF) 
   John Brighton (ENG)  Priscilla Nelson (NSF) 
   Ken Chong (ENG/CMS)    Michael Plesniak (ENG/CTS) 
   Sangtae Kim (NSF)    Galip Ulsoy (ENG) 
 
 
 
 62
September 2005 Workshop 
 
Universities 
  Richard Alkire (U Illinois-UC)   Carl Timothy Kelley (NC State)  
  Narayana Aluru (U Illinois-UC)    Yannis Kevrekidis (Princeton)  
  Kyle Anderson (UTC SimCenter)   David Keyes (Columbia) 
  Chandrajit Bajaj (U Texas-Austin)   Alan Laub (UCLA) 
  Jon Bass (U Texas-Austin)   David Levermore (U Maryland-CP) 
  Ted Belytschko (Northwestern)   Michael Levine (Pittsburgh) 
  Larry Biegler (Carnegie Mellon)   David Littlefield (U Alabama) 
  Wei Cai (Stanford)    Wing Kam Liu (Northwestern) 
  Alok Chaturvedi (Purdue)   Raghu Marchiraju (Ohio State)  
  Leszek Demkowicz (U Texas-Austin)  J. Tinsley Oden (U Texas-Austin)  
  Abhi Deshmukh (U Mass)   Steven Parker (U Utah) 
  Craig Douglas (U Kentucky)   Linda Petzold (UC-Santa Barbara) 
  Charbel Farhat (Stanford)   Robert Pennington (U Illinois-UC) 
  Jacob Fish (Rensselaer)     N. Radhakrishnan (NC A&T U) 
  Roger Ghanem (USC)    Mark Rashid (UC-Davis)   
  Omar Ghattas (U Texas-Austin)    Tom Russell (U Mass) 
  Michael Heath (U Illinois-UC)   Mark Shephard (Rensselaer)  
  K. Jimmy Hsiah (U Illinois-UC)   David Srolovitz (Princeton) 
  Thomas J. R. Hughes (U Texas-Austin)  Fanis Strouboulis (Texas A&M) 
  Tony Ingraffea (Cornell)    Andrew Szeri (UC-Berkeley) 
  Chris Johnson (U Utah)    Brian Wirth (UC-Berkeley) 
  Ramdev Kanapady (U Minnesota)   Jacob White (MIT) 
      Sidney Yip (MIT) 
 
DOE, Government Laboratories, and NIH 
  Roshdy Barsoum (ONR)    Chandrika Kamath (LLNL)  
  Peter Castle (INL)    Dimitri Kusnezov (DOE)   
  Luise Couchman (ONR)    Habib Najm (SNL) 
  Stephen Davis (ARO)    Raju Namburu (ARL) 
  Evi Dube (LLNL)    Tomas Diaz de la Rubia (LLNL)  
  Francois Gygi (LLNL)    Daniel White (LLNL) 
      Terry Yoo (NLM) 
Industry 
  Joshua Fujiwara (Honda/OSU)   John Ullo (Schlumberger-Doll)   
  Kirk Jordan (IBM)     David Young (Boeing) 
 
NSF 
  Richard Buckius (ENG/OAD)   Wen Masters (MPS/DMS) 
  Ken Chong (ENG/CMS)    Michael Plesniak (ENG/CTS) 
  Frederica Darema (CISE/CNS)   M. C. Roco (ENG/OAD) 
  George Hazelrigg (ENG/DMI)   Celeste Rohlfing (MPS/CHE) 
  Deborah Lockhart (MPS/DMS)   HenryWarchall (MPS/DMS) 
 63
BIBLIOGRAPHY 
 
1. Atkins, D. (Chair); Revolutionizing Science and Engineering Through 
Cyberinfrastructure; National Science Foundation Blue Ribbon Panel Report, 
January 2003. 
http://www.communitytechnology.org/nsf_ci_report/ExecSum.pdf  
http://www.communitytechnology.org/nsf_ci_report/report.pdf  
http://www.communitytechnology.org/nsf_ci_report/appendices.pdf  
2. Bajaj, C., Input from the NSF Workshop on Simulation Based Engineering 
Science, Arlington, VA, September 2005. 
3. Belytschko, T., Fish, J., Hughes, T.J.R., and Oden, J.T., (Eds.); Simulation Based 
Engineering Science; National Science Foundation Workshop Report, May 2004. 
http://www.ices.utexas.edu/~bass/outgoing/sbes/SBES_Workshop_1_Report.pdf 
4. Benioff, M. and Lazowska, E. (Chairs), Computational Science: Ensuring 
America’s Competitiveness; President’s Information Technology Advisory 
Committee (PITAC) Report, June 2005. http://www.nitrd.gov 
5. Chong, K. P., ”Nanoscience and Engineering in Mechanics and Materials”, 
Journal of Physics & Chemistry of Solids, vol. 65 (2004), pp. 1501-1506. 
6. Colvin, G., “America Isn’t Ready”, Fortune Magazine, July 25, 2005. 
7. Darema, F., “Engineering/Scientific and Commercial applications: differences, 
similarities, and future evolution”; HERMIS, vol. 1 (1994), pp. 367-374, 
Proceedings of the Second Hellenic European Conference on Mathematics and 
Informatics. 
8. Dolbow, J., Khalell, M.A., and Mitchell, J., (Eds.); Multiscale Mathematics 
Initiative: A Roadmap; Department of Energy – Office of Science Roadmap, 
December 2004. http://www.sc.doe.gov/ascr/mics/amr/Multiscale Math 
Workshop 3 - Report latest edition. pdf 
9. Douglas, C. and Deshmukh, A., (Eds.); Dynamic Data Driven Application 
Systems; NSF Workshop Report, March 2000. http://www.cise.nsf.gov/dddas 
 64
10. Estep, D., Shadid, J., Simon, T., (Eds.); Final Report Second DOE Workshop on 
Multiscale Problems; Department of Energy – Office of Science Workshop 
Report, October 2004. http://www.sc.doe.gov/ascr/mics/amr/Multiscale Math 
Workshop 2 version - Report.pdf 
11. Gereffi, G., and Wadhwa, V., (Eds.); Framing the Engineering Outsourcing 
Debate: Placing the United States on a Level Playing Field with China and 
India; Master of Engineering Management Program, Duke University, December 
2005.  
12. Graham, S. and Snir, M., (Eds.); The Future of Supercomputing; National 
Research Council – Computer Science and Telecommunications Board Interim 
Report, May 2003.http://www7.nationalacademies.org/cstb/pub_supercomp.html 
13. Grosh, J. and Laub, A., (Eds.); Federal Plan for High-End Computing; High-End 
Computing Revitalization Task Force Report, Office of Science and Technology 
Policy, May 2004. http://www.sc.doe.gov/ascr/hecrtfrpt.pdf 
14. Joy, W. and Kennedy, K., (Chairs); Information Technology Research: Investing 
in Our Future; Presidents Information Technology Advisory Committee Report, 
February 1999. http://www.itrd.gov/pitac/report/pitac_report.pdf 
15. Johnson, C., Moorhead, R., Munzner, T., Pfister, H., Rheingans, P., and  
Yoo, T. S., (Eds.); NIH-NSF Visualization Research Challenges Report; IEEE 
Press, ISBN 0-7695-2733-7, 2006. http://tab.computer.org/vgtc/vrc/index.html 
16. Johnson, C.R., “Top Scientific Visualization Research Problems”, IEEE 
Computer Graphics and Applications, pp. 2-6, July/August 2004.  
17. Kamath. C., Input from the NSF Workshop on Simulation Based Engineering 
Science, Arlington, VA, September 2005. 
18. Keyes, D., Colella, P., Dunning Jr., T., and Gropp, W., (Eds.); A Science-Based 
Case for Large-Scale Simulation - Volume 1; Department of Energy – Office of 
Science Workshop Report, July 2003. http://www.pnl.gov/scales/  
19. Keyes, D., Colella, P., Dunning, Jr., T., and Gropp, W., (Eds.); A Science-Based 
Case for Large-Scale Simulation - Volume 2; Department of Energy – Office of 
Science Workshop Report, September 2004.  http://www.pnl.gov/scales/  
20. Lax, Peter D., (Chair); Report of the Panel on Large Scale Computing in Science 
and Engineering; Department of Defense and the National Science Foundation, 
December 1982. http://www.pnl.gov/scales/docs/lax_report_1982.pdf 
 65
21. National Science Foundation, Division of Science Resources Statistics, Science 
and Engineering Degrees: 1966-2001; NSF 04-31, Project Officers, Susan T. 
Hill and Jean M. Johnson. http://www.nsf.gov/statistics/nsf04311/htmstart.htm 
22. New York University School of Medicine, http://endeavor.med.nyu.edu/public/. 
23. Petzold, L., Colella, P., and Hou, T., (Eds.); Report of the First Multiscale 
Mathematics Workshop: First Steps toward a Roadmap; Department of Energy – 
Office of Science Workshop Report, July 2004.  
http://www.sc.doe.gov/ascr/mics/amr/Multiscale Math Workshop 1 - Report.pdf 
24. Reed, D., (Ed.); The Roadmap for the Revitalization of High-End Computing; 
National Coordination Office for Information Technology Research and 
Development Report, June 2003. http://www.cra.org/reports/supercomputing.pdf 
25. Rising Above the Gathering Storm: Energizing and Employing America for a 
Brighter Economic Future, Committee on Prospering in the Global Economy of 
the 21st Century, 2005. http://www.nap.edu/catalog/11463.html 
26. Scientific Discovery through Advanced Computing; Department of Energy - 
Office of Science Strategic report, March 2000. 
http://www.sc.doe.gov/ascr/mics/scidac/SciDAC_strategy.pdf 
27. Y. Zhang, and C. Bajaj, Finite Element Meshing for Cardiac Analysis, ICES 
Technical Report 04-26, University of Texas, Austin, 2004. 
 
 
 
 66
 
 
 

