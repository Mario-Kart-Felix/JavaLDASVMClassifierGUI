ar
X
iv
:1
70
6.
08
93
4v
1 
 [
cs
.L
G
] 
 2
7 
Ju
n 
20
17
Reexamining Low Rank Matrix Factorization
for Trace Norm Regularization
Carlo Ciliberto 1
c.ciliberto@ucl.ac.uk
Dimitrios Stamos 1
d.stamos@cs.ucl.ac.uk
Massimiliano Pontil 1,2
m.pontil@cs.ucl.ac.uk
June 28, 2017
Abstract
Trace norm regularization is a widely used approach for learning low rank matri-
ces. A standard optimization strategy is based on formulating the problem as one
of low rank matrix factorization which, however, leads to a non-convex problem. In
practice this approach works well, and it is often computationally faster than standard
convex solvers such as proximal gradient methods. Nevertheless, it is not guaranteed
to converge to a global optimum, and the optimization can be trapped at poor sta-
tionary points. In this paper we show that it is possible to characterize all critical
points of the non-convex problem. This allows us to provide an efficient criterion to
determine whether a critical point is also a global minimizer. Our analysis suggests
an iterative meta-algorithm that dynamically expands the parameter space and allows
the optimization to escape any non-global critical point, thereby converging to a global
minimizer. The algorithm can be applied to problems such as matrix completion or
multitask learning, and our analysis holds for any random initialization of the factor
matrices. Finally, we confirm the good performance of the algorithm on synthetic and
real datasets.
1 Introduction
Learning low rank matrices is a problem of broad interest in machine learning and statis-
tics, with applications ranging from collaborative filtering [1,2], to multitask learning [3],
to computer vision [4], and many more. A principled approach to tackle this problem is via
suitable convex relaxations. Perhaps the most successful strategy in this sense is provided
by trace (or nuclear) norm regularization [3, 5–7]. However, solving the corresponding
optimization problem is computationally expensive for two main reasons. First, many com-
monly used algorithms require the computation of the proximity operator (e.g. [8]) which
entails performing the singular value decomposition at each iteration. Second, and most
importantly, the space complexity of convex solvers grows with the matrix size, which
makes it prohibitive to employ them for large scale applications.
1University College London, London, UK
2Computational Statistics and Machine Learning - Istituto Italiano di Tecnologia, Genova, Italy
1
Due to the above shortcomings, practical algorithms for low rank matrix completion
often use an explicit low rank matrix factorization to reduce the number of variables (see
e.g. [2, 9] and references therein). In particular, a reduced variational form of the trace
norm is used [7]. The resulting problem is however non-convex, and popular methods
such as alternate minimization or alternate gradient descent may get struck at poor sta-
tionary points. Recent studies [10, 11] have shown that under certain conditions on the
data generation process (underling low rank model, RIP, etc.) a particular version of the
non-convex problem can be solved efficiently. However such conditions are not verifiable
in real applications, and the problem of finding a global solution remains open.
In this paper we characterize the critical points of the non-convex problem and provide
an efficient criterion to determine whether a critical point is also a global minimizer. Our
analysis is constructive and suggests an iterative meta-algorithm that dynamically expands
the parameter space to escape any non-global critical point, thereby converging to a global
minimizer. We highlight the potential of the proposed meta-algorithm, by comparing its
computational and statistical performance to two state of the art methods [9,12].
The paper is organized as follows. In Sec. 2 we introduce the trace norm regularization
problem and basic notions used throughout the paper. In Sec. 2.2 we present the low rank
matrix factorization approach and set the main questions addressed in the paper. In Sec. 3
we present our analysis of the critical points of the low rank matrix factorization problem
and the associated meta-algorithm. In Sec. 4 we report results from numerical experiments
using our method. The Appendix contains proofs of the results, only stated in the main
body of the paper, together with further auxiliary results and empirical observations.
2 Background and Problem Setting
In this work we study trace norm regularized problems of the form
minimize
W∈Rn×m
fλ(W), fλ(W) = ℓ(W) + λ ‖W‖∗ (1)
where ℓ : Rn×m → R is a twice differentiable function with Lipschitz continuous gradient,
‖W‖∗ denotes the trace norm of a matrix W ∈ R
n×m, namely the sum of the singular
values of W, and λ is a positive parameter. Examples of relevant learning problems that
can be formulated as Eq. (1) are:
Matrix Completion. In this setting we wish to recover a matrix Y ∈ Rn×m from a small
subset of its entries. A typical choice for ℓ is the square error, ℓ(W) = ‖M ⊙ (Y − W)‖2F,
where ‖ · ‖F is the Frobenius norm, ⊙ denotes the Hadamard product (i.e. the entry-wise
product) between two matrices and M ∈ Rn×m is a binary matrix used to “mask” the
entries of Y that are not available.
Multi-task Learning. Here, the columns w1, . . . ,wm of matrix W are interpreted as the
regression vectors of different learning tasks. Given m datasets (xij, y
i
j)
nj
i=1 with x
i
j ∈ R
n and
yij ∈ R, for j = 1, . . . ,m, we choose ℓ(W) =
∑m
j=1
1
nj
∑nj
i=1 ℓ̄(y
i
j,w
⊤
j x
i
j), where ℓ̄ : R×R → R
is a prescribed loss function (e.g. the square or the logistic loss).
Other examples which are captured by problem (1) include collaborative filtering with
attributes [13] and multiclass classification [5].
2
2.1 Proximal Gradient Methods
Problem (1) can be solved by first-order optimization methods such as the proximal
forward-backward (PFB) splitting [8]. Given a starting point W0 ∈ R
n×m, PFB produces a
sequence (Wk)k∈N with
Wk+1 = proxγλ‖·‖∗
(
Wk − γ∇ℓ(Wk)
)
(2)
where γ > 0 and for any convex function φ : Rn×m → R, the associated proximity
operator at W ∈ Rn×m is defined as proxφ(W) = argmin
{
φ(Z)+ 12‖W−Z‖
2
F : Z ∈ R
n×m
}
.
In particular, the proximity operator of the trace norm at W ∈ Rn×m corresponds to
performing a soft-thresholding on the singular values of W. That is, assuming a singular
value decomposition (SVD) W = UΣV⊤, where U ∈ Rn×r, V ∈ Rm×r have orthonormal
columns, Σ = diag(σ1, . . . , σr), with σ1 ≥ · · · ≥ σr > 0 and r = rank(W), we have
proxγλ‖·‖∗(W) = Udiag(hγλ(σ1), . . . , hγλ(σr))V
⊤ (3)
where hγλ is the soft-thresholding operator, defined for σ ≥ 0 as hγλ(σ) = max(0, σ − γλ).
PFB guarantees that for a suitable choice of the descent step γ (e.g. γ < 2/L with L
the Lipschitz constant of the gradient of ℓ), the sequence fλ(Wk) converges to the global
minimum of the problem with a rate of O(1/k) [8] (faster rates can be achieved using
accelerated versions of the algorithm [14]). However, at each iteration PFB performs
the SVD of an n × m matrix via Eqs. (2) and (3), which requires O(min(n,m) nm)
operations, a procedure that becomes prohibitively expensive for large values of n and
m. Other methods such as those based on Frank-Wolfe procedure (e.g. [15]) alleviate
this cost but require more iterations. More importantly, these methods need to store in
memory the iterates Wk imposing an O(nm) space complexity, a major bottleneck for large
scale applications. However, trace norm regularization is typically applied to problems
where the solution of problem (1) is assumed to be low-rank, namely of the form AB⊤ for
some A ∈ Rn×r, B ∈ Rm×r and r ≪ min(n,m). Therefore it would be ideal to have an
optimization method capable to capture this aspect and consequently reduce the memory
requirement to O(nmr) by keeping track of the two factor matrices A and B throughout
the optimization rather than their product. This is the idea behind factorization-based
methods, which have been observed to lead to remarkable performance in practice and
are the subject of our investigation in this work.
2.2 Matrix Factorization Approach
Factorization methods build on the so-called variational form of the trace norm. Specif-
ically, the trace norm of a matrix W ∈ Rn×m can be characterized as (see e.g. [16] or
Lemma 9 in the Appendix)
‖W‖∗ =
1
2
inf
{
‖A‖2F + ‖B‖
2
F, : r ∈ N, A ∈ R
n×r, B ∈ Rm×r, W = AB⊤
}
. (4)
with the infimum always attained for r = rank(W). The above formulation leads to the
following “factorized” version of the original optimization problem (1)
minimize
A∈Rn×r,B∈Rm×r
gλ,r(A,B), gλ,r(A,B) = ℓ(AB
⊤) +
λ
2
(
‖A‖2F + ‖B‖
2
F
)
(5)
3
where r ∈ N is now a further hyperparameter of the problem. Clearly, fλ and gλ,r are
tightly related and a natural question is whether minimizing the latter would allow to
recover a solution of the original problem. As it turns out, the two problems are indeed
equivalent (for sufficiently large r).
Proposition 1 (Equivalence between problems (1) and (5)). Let W∗ ∈ R
n×m be a global
minimizer of fλ in Eq. (1) with r∗ = rank(W∗). Then, for every r ≥ r∗, every global minimizer
(A∗, B∗) of gλ,r is such that
gλ,r(A∗, B∗) = fλ(A∗B
⊤
∗ ) = fλ(W∗). (6)
The above proposition implies that for sufficiently large values of r in Eq. (5), the
optimization of fλ and gλ,r are equivalent. Therefore, we can minimize fλ by finding a
global minimizer for gλ,r. This is a well-known approach to trace norm regularization (see
e.g. [1, 2]) and can be extremely advantageous in practice. Indeed, we can leverage on a
large body of smooth optimization literature to solve such a factorized problem [17]. As
an example, if we apply Gradient Descent (GD) from a starting point (A0, B0), we obtain
the sequence (Ak, Bk)k∈N with
Ak+1 = Ak − γ(∇ℓ(AkB
⊤
k )Bk + λA)
Bk+1 = Bk − γ(∇ℓ(AkB
⊤
k )
⊤Ak + λB).
(7)
This approach is much more appealing than PFB from a computational perspective be-
cause: 1) for small values of r, the iterations at Eq. (7) are extremely fast since they
mainly consists of matrix products and therefore require only O(nmr) operations; 2) the
space complexity of GD is O(r(n+m)), which may be remarkably smaller than the O(nm)
of PFB for small values of r; 3) Even if for large values of r, e.g. r = min(n,m), every
iteration has the same time complexity as PFB, we do not need to perform expensive op-
erations such as the SVD of an n×m matrix at every iteration. This dramatically reduces
computational times in practice.
The strategy of minimizing gλ,r instead of fλ was originally proposed in [7] and its
empirical advantages have been extensively documented in previous literature, e.g. [2].
However, this approach opens important theoretical and practical questions that have not
been addressed by previous work:
• How to choose r? By Prop. 1 we know that for suitably large values of r the mini-
mization of gλ,r and fλ are equivalent. However, a lower bound for such an r cannot
be recovered analytically from the functional itself and, so, it is not clear how to
choose r in practice.
• Global convergence. The function gλ,r is not jointly convex in the two variables
A and B. This opens the question of whether GD (or other optimization methods)
converge to a global minimizer for sufficiently large values of r.
Investigating such issues is the main focus of this work.
4
3 Analysis
In this section we study the questions outlined above and provide a meta-algorithm to
minimize the function gλ,r while incrementally searching for a rank r for which Prop. 1 is
verified. Our analysis builds upon the following keypoints:
• (Prop. 2) We characterize all critical points of gλ,r, namely those points to which iter-
ative optimization methods applied to Eq. (5) (e.g. GD) could in principle converge
to.
• (Thm. 3) We derive an efficient criterion to determine whether a critical point of gλ,r
is a global minimizer (typically an NP hard problem for non-convex functions).
• (Prop. 4) We show that for any critical point (A,B) of gλ,r which is not a global
minimizer, it is always possible to constructively find a descent direction for gλ,r+1
from the point ([A 0], [B 0]) ∈ Rn×(r+1) × Rm×(r+1).
• (Thm. 5) By combining the above results we show that for r ≥ min(n,m), every
critical point of gλ,r is either a global minimizer or a so-called strict saddle point,
namely a point where the Hessian of the target function has at least a negative
direction. We can then appeal to [18] to show that descent methods such as GD
avoid strict saddle points and hence convergence to a global minimizer.
The above discussion suggests a natural “meta-algorithm” (which is presented more for-
mally in Sec. 3.3) to address the minimization of fλ via gλ,r while increasing r incremen-
tally:
1. Initialize r = 1. Choose A ′0 ∈ R
n and B ′0 ∈ R
m.
2. Starting from (A ′r−1, B
′
r−1), converge to a critical point (Ar, Br) for gλ,r.
3. If (Ar, Br) satisfies our criterion for global optimality (see Thm. 3) stop, otherwise:
4. Perform a step in a descent direction for gλ,r+1 from ([Ar 0], [Br 0]) to a point (A
′
r, B
′
r),
A ′r ∈ R
n×r+1, B ′r ∈ R
m×r+1; Increase r to r + 1 and go back to Step 2.
From our analysis in the following, the procedure above is guaranteed to stop at most
after r = min(n,m) iterations. However, Prop. 1, together with our criterion for global op-
timality, suggests that this meta-algorithm could stop much earlier if fλ admits a low-rank
minimizer (which is indeed the case in our experiments). This has two main advantages:
1) by exploring candidate ranks incrementally, we can expect significantly faster computa-
tions and convergence if our optimality criterion activates for r ≪ min(n,m) and 2) we
automatically recover the rank of a minimizer for fλ without the need to perform expen-
sive operations such as SVD.
Remark 1. The meta-algorithm considered in this paper is related to the optimization strat-
egy recently proposed in [19], where the authors study convex problems for which a non-
convex “factorized” formulation exists, including the setting considered in this work as a
special case. However, by adopting such a general perspective, the resulting optimization
5
strategy is less effective when applied to the specific minimization of gλ,r. In particular: 1)
the optimality criterion derived in [19] is only a sufficient but not necessary condition; 2) the
upper bound on r is much larger than the one provided in this work, i.e. r = nm rather than
r = min(n,m); 3) convergence guarantees to a global optimum cannot be provided.
By focusing exclusively on the question of minimizing fλ via its factorized form gλ,r and,
by leveraging on the specific structure of the problem, it is instead possible to provide a further
analysis of the behavior of the proposed meta-algorithm.
3.1 Critical Points and a Criterion for Global Optimality
Since gλ,r is a non-convex smooth function, in principle we can expect optimization algo-
rithms based on first or second order methods to converge only to critical points, i.e. points
(A∗, B∗) for which ∇gλ,r(A∗, B∗) = 0. The following result provides a characterization of
such critical points and plays a key role in our analysis.
Proposition 2 (Characterization of Critical Points of gλ,r). Let (A∗, B∗) ∈ R
n×r × Rm×r
be a critical point of gλ,r. Let s ≤ min(n,m) and let U ∈ R
n×s and V ∈ Rm×s be two
matrices with orthonormal columns corresponding to the left and right singular vectors of
∇ℓ(A∗B
⊤
∗ ) ∈ R
n×m with singular value equal to λ. Then, there exists C ∈ Rs×r, such that
A∗ = UC and B∗ = −VC.
This result is instrumental in deriving a necessary and sufficient condition to determine
whether a stationary point for gλ,r is actually a global minimizer. Indeed, since fλ is convex,
we can leverage on the first order condition for global optimality, stating that the matrix
W∗ = A∗B
⊤
∗ is a global minimizer for fλ (and by Prop. 1 also (A∗, B∗) for gλ,r) if and only
if the zero matrix belongs to its subdifferential (see e.g. [8]). Studying this inclusion leads
to the following theorem.
Theorem 3 (A Criterion for Global Optimality). Let (A∗, B∗) be a critical point of gλ,r. Then
A∗B
⊤
∗ is a minimizer for fλ if and only if ‖∇ℓ(A∗B
⊤
∗ )‖ ≤ λ.
This result provides a natural strategy to determine whether a descent method mini-
mizing gλ,r has converged to a global minimizer, that is we evaluate the operator norm of
the gradient, denoted ‖∇ℓ(A∗B
⊤
∗ )‖, and then check whether it is larger than λ. For large
matrices this operation can be performed efficiently by using approximation methods, e.g.
power iteration [20]. Note that in general it is an NP-hard problem to determine whether
a critical point of a non-convex function is actually a global minimizer [21]; it is only be-
cause of the relation with the convex function fλ that in this case it is possible to perform
such check in polynomial time.
3.2 Escape Directions and Global Convergence
In this section, we observe that for any critical point of gλ,r which is not a global minimizer,
it is always possible to either find a direction to escape from it or alternatively to increase
r by one and to find a decreasing direction for gλ,r+1. This strategy is suggested by the
following result.
6
Proposition 4 (Escape Direction from Critical Points). With the same notation of Prop. 2,
assume rank(A∗) = rank(B∗) < r and ‖∇ℓ(A∗B
⊤
∗ )‖ = µ > λ. Then, (A∗, B∗) is a so-called
strict saddle point for gλ,r, namely the Hessian of gλ,r at (A∗, B∗) has at least one negative
eigenvalue. In particular, there exists q ∈ Rr such that A∗q = 0, B∗q = 0 and if u ∈ R
n and
v ∈ Rm are the left and right singular vectors of ∇ℓ(A∗B
⊤
∗ ) with singular value equal to µ,
then gλ,r decreases locally at (A∗, B∗) along the direction (uq
⊤,−vq⊤).
A direct consequence of the result above is that an optimization strategy can remain
trapped only at global minimizers of gλ,r or at critical points (A∗, B∗) for which A∗ and B∗
have full rank (since we can always escape from rank deficient ones). If the latter happens,
Prop. 4 suggests the strategy adopted in this work, namely to increase the problem dimen-
sion to r+ 1 and consider the “inflated” point ([A∗ 0], [B∗ 0]). Indeed, at such point, gλ,r+1
attains the same value as gλ,r(A∗B
⊤
∗ ) and it is straightforward to verify that ([A∗ 0], [B∗ 0])
is still a critical point for gλ,r+1. Since matrices [A∗ 0] and [B∗ 0] have now rank < r + 1,
we can apply Prop. 4 to find a direction along which gλ,r+1 decreases. This procedure
will stop for r > min(n,m) since rank(A∗) ≤ min(n,m) < r and we can therefore apply
Prop. 4 to always escape from critical points until we reach a global minimizer (this fact
can be actually improved to hold also for r = min(n,m) as we see in the following).
Note however that in general, if the number of non-global critical points is infinite, it
is not guaranteed that such strategy will converge to the global minimizer. However, since
by Prop. 4 every such critical point is a strict saddle point, we can leverage on previous
results from the non-convex optimization literature (see [18] and references therein) in
order to prove the following result.
Theorem 5 (Convergence to Global Minimizers of gλ,r). Let r ≥ min(n,m). Then the set
of starting points (A0, B0) for which GD does not converge to a global minimizer of gλ,r has
measure zero.
In particular, Thm. 5 suggests to initialize the optimization method used to minimize
gλ,r by applying a small perturbation to the initial point (A0, B0) via additive noise accord-
ing to a distribution that is absolutely continuous with respect to the Lebesgue measure
of Rn×r × Rm×r (e.g. a Gaussian). This perturbation guarantees such initial point to not
be in the set of points for which GD converges to strict saddle point and therefore that the
meta-algorithm considered in this work converges to a global minimizer. We make this
statement more precise in the next section.
3.3 A Meta-algorithm to Minimize fλ
We can now formally present the meta-algorithm outlined at the beginning of Sec. 3 to
find a solution of the trace norm regularization problem (1) by minimizing gλ,r in Eq. (5)
for increasing values of r. Algorithm 1 proceeds by iteratively applying the descent method
OPTIMIZATIONALGORITHM (e.g. GD) to minimize gλ,r while increasing the estimated rank
r one step at the time. Whenever the optimization algorithm converges to a critical point
(Ar, Br) of gλ,r (within a certain tolerance ǫconv), Algorithm 1 verifies whether the global
optimality criterion has been activated (again within a certain tolerance ǫcrit). If this is
the case, (Ar, Br) is a global minimizer and we stop the algorithm. Otherwise we “in-
flate” the two factor matrices by one column each and repeat the procedure. The new
7
Algorithm 1 META-ALGORITHM
Input: λ > 0, ǫconv > 0 convergence tolerance, ǫcrit > 0 global criterion tolerance.
Initialize: Set r = 1. Sample A ′0 ∈ R
n and B ′0 ∈ R
m randomly.
For r = 1 to min(n,m)
(Ar, Br) = OPTIMIZATIONALGORITHM(A
′
r−1 , B
′
r−1, gλ,r, ǫconv)
If ‖∇ℓ(ArB
⊤
r )‖ ≤ λ + ǫcrit
Break
(A ′r, B
′
r) = ([Ar u], [Br v]) with u ∈ R
n, v ∈ Rm sampled randomly.
r = r + 1
End
Return (Ar, Br)
column is initialized randomly, since by Prop. 4 we know that we will not converge again
to ([Ar 0], [Br 0]) because it is not full rank. A more refined approach would be to choose
u and −v to be the singular vectors of ∇ℓ(ArB
⊤
r ) associated to the highest singular value.
For the sake of brevity we provide an example of such strategy in the Appendix. However
note that we still need to apply a random perturbation to the step in the descent direction
in order to invoke Thm. 5 and be guaranteed to not converge to strict saddle points. As a
direct corollary to Thm. 5 we have
Corollary 6. Algorithm 1 with GD as OPTIMIZATIONALGORITHM converges to a point (A∗, B∗)
such that A∗B
⊤
∗ is a global minimizer for fλ with probability 1.
3.4 Convergence Rates
In this section, we touch upon the question of convergence rates for optimization schemes
applied to problem (5). For simplicity, we focus on GD, but our result generalizes to other
first order methods. We provide upper bounds to the number of iterations required to
guarantee that GD iterates are ǫ close to a critical point of the target function. By standard
convex analysis results (see [22]) it is known that GD applied to a differentiable convex
function is guaranteed to have sublinear convergence of O(1/ǫ) comparable to that of
PFB. However, since gλ,r is non-convex, here we need to rely on more recent results that
investigated the application of first order methods to functions satisfying the so-called
Kurdyka-Lojasiewicz (KL) inequality [23,24].
Definition 7 (Kurdyka-Lojasiewicz Inequality). A differentiable function g : Rd → R is
said to satisfy the Kurdyka-Lojasiewicz inequality at a critical point x∗ ∈ R
d if there exists a
neighborhood U ⊆ Rd and constants γ, ǫ > 0 and α ∈ [0, 1) such that, for all x ∈ U ∩ {x :
g(x∗) < g(x) < g(x∗) + ǫ},
γ|g(x) − g(x∗)|
α < ‖∇g(x)‖F. (8)
The KL inequality is a measure of how large is the gradient of the function in the neigh-
borhood of a critical point. This allows us to derive convergence rates for GD methods that
depend on the constant α. In particular, as a corollary to [18] (see also [23]) we obtain
the following result.
8
Corollary 8 (Convergence Rate of Gradient Descent). Let (Ak, Bk)k∈N a sequence produced
by GD method applied to gλ,r. If gλ,r satisfies the KL inequality for some α ∈ [0, 1), then there
exists a critical point (A∗, B∗) of gλ,r and constants C,b > 0 such that
‖(Ak, Bk) − (A∗, B∗)‖
2
F ≤
{
Cbk if α ∈ (0, 1/2],
Ck−
1−α
2α−1 if α ∈ (1/2, 1).
(9)
Furthermore, if α = 0 convergence is achieved in a finite number of steps.
This result shows that depending on the constant α ∈ [0, 1) appearing in the KL inequal-
ity, we can expect different convergence rates for GD applied to problem (5). Although, it
is a challenging task to identify such constant or even provide an upper bound in specific
instances, the class of functions satisfying the KL inequality is extremely large and includes
both analytic and semi-algebraic functions, see e.g. [25]. In the Appendix, we argue that
if a function ℓ : Rn×m → R is a semi-algebraic, then also ℓr : R
n×r × Rm×r → R such that
ℓr(A,B) = ℓ(AB
⊤) is semi-algebraic. Therefore, in order to apply Cor. 8 it is sufficient that
the error ℓ and the regularizer are semi-algebraic, a property which is verified by many
commonly used error functions (or the associated loss functions, e.g. square, logistic) and
regularizers (in particular the squared Frobenius norm).
4 Experiments
We report an empirical analysis of the meta-algorithm studied in this work. All experi-
ments were conducted on an Intel Xeon E5-2697 V3 2.60Ghz CPU with 32GB RAM. We
consider a matrix completion setting, with the loss ℓ(W) = ‖M ⊙ (Y −W)‖2F , where Y is
the matrix that we aim to recover and M a binary matrix masking entries not available at
training time. Below we briefly described the datasets used.
Synthetic. We generated a 100× 100 matrix Y = AB⊤ + E as a rank 10 matrix product
of two 100 × 10 matrices A,B plus additive noise E; the entries for A,B and E were
independently sampled from a standard normal distribution.
Movielens. This dataset [26] consists of different datasets for movie recommendation
of increasing size. They all comprise a number of ratings (from 1 to 5) given by n users on
a database of m movies, which are recorded as a Y ∈ Rn×m matrix with missing entries.
In this work we considered three such datasets of increasing size, namely Movielens 100k
(ml100k) with 100 thousand ratings from n = 943 users on m = 1682 movies, Movielens
1m (ml1m) with ∼ 1 million ratings, n = 6040 users and m = 3900 movies and Movielens
10m (ml10m), with ∼ 10 millions ratings, n = 71567 users and 10681 movies.
4.1 The Criterion for Global Optimality and the Estimated Rank
The result in Thm. 3 provides a necessary and sufficient criterion to determine whether
Algorithm 1 has achieved a global minimum for fλ. A natural question is to ask whether,
in practice, such criterion will be satisfied for a much smaller rank r than the one at
which we are guaranteed convergence, namely r = min(n,m). To address this question
we compared the solution achieved by our approach with the one obtained by iterative
9
-1 0 1 2
lambda (log10 scale)
0
5
10
15
20
25
30
re
c
o
v
e
re
d
 r
a
n
k
ISTA
ours
-1 0 1 2
lambda (log10 scale)
20
40
60
80
100
120
140
re
c
o
v
e
re
d
 r
a
n
k
ISTA
ours
Figure 1: Rank of the solution for iterative soft thresholding algorithm (ISTA) and our
method in Algorithm 1 varying lambda, on synthetic data (Left) and ml100k (Right).
soft thresholding (ISTA) (or proximal forward backward, see e.g. [8]) on both synthetic
and real datasets. Fig. 1 reports the value of r for which our meta-algorithm satisfied
the criterion for global optimality and compares it with the rank of the ISTA solution for
different values of λ. For the Synthetic dataset (Fig. 1 Left ) we considered only 20%
of the generated matrix Y entries for the optimization of fλ. For the real dataset (Fig. 1
Right ) we considered ml100k and sampled 50% of each user’s available ratings. For both
synthetic and real experiments our meta-algorithm recovers the same rank than as that
found by ISTA. However, our algorithm reaches such rank incrementally, exploiting the
low rank factorization. As we will see in the next section this results in a much faster
convergence speed in practice.
4.2 Large Scale Matrix Completion
We compared the performance of our meta-algorithm with two state of the art methods,
Active Newton (ALT) [12] and Alternating Least Squares Soft Impute (ASL-SI) [9] on the
three Movielens datasets. We used 50%, 25% and 25% of each user’s ratings for training,
validation and testing and repeated our experiments across 5 separate trials to account for
statistical variability in the sampling. Test error was measured in terms of the Normalized
Mean Absolute Error (NMAE), namely the mean (entry-wise) absolute error on the test
set, normalized by the maximum discrepancy max(Yij) − min(Yij) between entires in Y.
As a reference of the behavior of the different methods, Fig. 2, reports on a single trial
the decrease of fλ on training data and NMAE on the test set with respect to time for
the best λ chosen by validation. All methods where run until convergence and attained
the same value of the objective function and same test error in all our trials. However,
as it can be noticed, our meta-algorithm and ALS-SI seem to attain a much lower test
error during earlier iterations. To better investigate this aspect, Table. 1 reports results
in terms of time, test error and estimated rank attained on average across the 5 trials by
the different methods at the iteration with smallest validation error. As it can be noticed
our meta-algorithm is generally on par with its competitors in terms of test error while
being relatively faster and recovering low-rank solutions. This highlights an interesting
byproduct of the meta-algorithm considered in this work, namely that by exploring candi-
date ranks incrementally, the method allows to find potentially better factorizations than
trace norm regularization both in terms of test error and estimated rank. This fact can be
empirically observed also for different values of λ as we report in the Appendix.
10
50 100 150
time (sec)
0.75
0.8
0.85
o
b
je
c
ti
v
e
ml100k
active ALT
softImpute-ALS
ours
1000 2000 3000 4000 5000
time (sec)
0.54
0.56
0.58
0.6
0.62
0.64
0.66
o
b
je
c
ti
v
e
ml1m
active ALT
softImpute-ALS
ours
0.5 1 1.5 2
time (sec) ×10 5
0.6
0.65
0.7
0.75
0.8
o
b
je
c
ti
v
e
ml10m
active ALT
softImpute-ALS
ours
50 100 150
time (sec)
0.2
0.21
0.22
0.23
0.24
0.25
0.26
te
s
t 
e
rr
o
r
ml100k
active ALT
softImpute-ALS
ours
1000 2000 3000 4000 5000
time (sec)
0.18
0.2
0.22
0.24
0.26
te
s
t 
e
rr
o
r
ml1m
active ALT
softImpute-ALS
ours
0.5 1 1.5 2
time (sec) ×10 5
0.18
0.2
0.22
0.24
0.26
te
s
t 
e
rr
o
r
ml10m
active ALT
softImpute-ALS
ours
Figure 2: Convergence vs. time of the objective fλ (Top row) and test errors (Bottom row)
on three matrix completion large scale datasets for our meta-algorithm, ALT [12] and. The
purple circle indicates when the global optimality criterion from Thm. 3 is satisfied.
ml100k ml1m ml10m
NMAE time(s) rank NMAE time(s) rank NMAE time(s) rank
ALT 0.2165 97 93 0.1806 4133 179 0.1670 205023 225
ALS-SI 0.1956 40 16 0.1749 832 31 0.1648 51205 36
Ours 0.1959 2 11 0.1751 39 25 0.1659 3150 41
Table 1: Average Normalized Mean Absolute Error (NMAE), convergence time and es-
timated rank achieved for the best validation parameters by ALT [12], ALS-SI [9] and
Alg. 1, on the three Movielens datasets.
5 Conclusions
We studied the convergence properties of low rank factorization methods for trace norm
regularization. Key to our study is a necessary and sufficient condition for global optimal-
ity, which can be applied to any critical points of the non-convex problem. This condition
together with a detailed analysis of the critical points lead us to propose a meta-algorithm
for trace norm regularization, that incrementally expands the number of factors used by
the non-convex solver. Although algorithms of this kind have been studied empirically
for years, our analysis provides a fresh look and novel insights which can be used to con-
firm whether a global solution has been reached. Numerical experiments indicated that
our optimality condition is useful in practice and the meta-algorithm is competitive with
state-of-the art solvers. In the future it would be valuable to study improvements to our
analysis, which would allow from one hand to derive precise rate of convergence for spe-
cific solvers used within the meta-algorithm and from another hand to study additional
conditions under which our global optimality is guaranteed to activate immediately after
the number of factors exceed the rank of the trace norm regularization minimizer.
11
6 Acknowledgments
This work was supported in part by EPSRC grant EP/P009069/1.
References
[1] J. D. M. Rennie and N. Srebro. Fast maximum margin matrix factorization for collaborative
prediction. In Proceedings of the 22nd international conference on Machine learning, pages
713–719, 2005.
[2] Y. Koren, R. Bell, and C. Volinsky. Matrix factorization techniques for recommender systems.
Computer, 42(8), 2009.
[3] A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task feature learning. Machine Learn-
ing, 73(3):243–272, 2008.
[4] Z. Harchaoui, M. Douze, M. Paulin, M. Dudik, and J. Malick. Large-scale image classification
with trace-norm regularization. In Proc. 2012 IEEE Conf. on Computer Vision and Pattern
Recognition, pages 3386–3393, 2012.
[5] Y. Amit, M. Fink, N. Srebro, and S. Ullman. Uncovering shared structures in multiclass
classification. In Proceedings of the 24th International Conference on Machine Learning, 2007.
[6] F. Bach. Consistency of trace norm minimization. Journal of Machine Learning Research, Vol.
8:1019–1048, 2008.
[7] N. Srebro, J. D. M. Rennie, and T. S. Jaakkola. Maximum-margin matrix factorization. Ad-
vances in Neural Information Processing Systems 17, 2005.
[8] H. H. Bauschke and P. L. Combettes. Convex Analysis and Monotone Operator Theory in Hilbert
Spaces. Canadian Mathematical Society, 2010.
[9] T. Hastie, R. Mazumder, J. D. Lee, and R. Zadeh. Matrix completion and low-rank svd via
fast alternating least squares. J. Mach. Learn. Res, 16(1):3367–3402, 2015.
[10] R. Ge, J. D. Lee, and T. Ma. Matrix completion has no spurious local minimum. In Advances
in Neural Information Processing Systems 29, pages 2973–2981. 2016.
[11] S. Bhojanapalli, B. Neyshabur, and N. Srebro. Global optimality of local search for low rank
matrix recovery. In Advances in Neural Information Processing Systems, pages 3873–3881,
2016.
[12] C.-J. Hsieh and P. Olsen. Nuclear norm minimization via active subspace selection. In Inter-
national Conference on Machine Learning, pages 575–583, 2014.
[13] J. Abernethy, F. Bach, T. Evgeniou, and J.-P. Vert. A new approach to collaborative filtering.
Journal of Machine Learning Research, 10:803–826, 2009.
[14] A. Beck and M. Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse
problems. SIAM J. Imaging Sciences, 2(1):183–202, 2009.
[15] M. Dudik, Z. Harchaoui, and J. Malick. Lifted coordinate descent for learning with trace-
norm regularization. In Artificial Intelligence and Statistics, pages 327–336, 2012.
[16] G. J. O. Jameson. Summing and Nuclear Norms in Banach Space Theory. Cambridge University
Press, 1987.
[17] D. P. Bertsekas. Nonlinear programming. Athena scientific Belmont, 1999.
12
[18] J. D. Lee, M. Simchowitz, M. I. Jordan, and B. Recht. Gradient descent only converges to
minimizers. In 29th Annual Conference on Learning Theory, pages 1246–1257, 2016.
[19] B. D. Haeffele and R. Vidal. Global optimality in tensor factorization, deep learning, and
beyond. arXiv preprint arXiv:1506.07540, 2015.
[20] D. P Woodruff et al. Sketching as a tool for numerical linear algebra. Foundations and
Trends R© in Theoretical Computer Science, 10(1–2):1–157, 2014.
[21] K. G. Murty and S. N. Kabadi. Some np-complete problems in quadratic and nonlinear pro-
gramming. Mathematical programming, 39(2):117–129, 1987.
[22] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, 2004.
[23] H. Attouch, J. Bolte, P. Redont, and A. Soubeyran. Proximal alternating minimization and
projection methods for nonconvex problems: An approach based on the kurdyka-łojasiewicz
inequality. Mathematics of Operations Research, 35(2):438–457, 2010.
[24] J. Bolte, A. Daniilidis, O. Ley, and L. Mazet. Characterizations of łojasiewicz inequalities:
subgradient flows, talweg, convexity. Transactions of the American Mathematical Society,
362(6):3319–3363, 2010.
[25] H. Attouch and J. Bolte. On the convergence of the proximal algorithm for nonsmooth
functions involving analytic features. Mathematical Programming, 116(1):5–16, 2009.
[26] F. M. Harper and J. A. Konstan. The movielens datasets: History and context. ACM Transac-
tions on Interactive Intelligent Systems (TiiS), 5(4):19, 2016.
[27] A. S. Lewis. The convex analysis of unitarily invariant matrix functions. Journal of Convex
Analysis, 2:173–183, 1995.
13
Appendix
Here we collect some auxiliary results and we provide proofs of the results stated in the
main body of the paper.
A Auxiliary Results
The first lemma establishes the variational form for the trace norm; its proof can be found
in [16].
Lemma 9 (Variational Form of the Trace Norm). For every W ∈ Rn×m and r ∈ N let
Fr(W) = {(A,B) ∈ R
n×k × Rm×r : AB⊤ = W}. Let k = rank(W) and let σ1(W) ≥ · · · ≥
σk(W) > 0 be the k singular values of W. Then
‖W‖∗ =
k∑
i=1
σi(W) =
1
2
inf
{
‖A‖2F + ‖B‖
2
F
∣∣∣ (A,B) ∈ Fr(W), r ∈ N
}
.
Furthermore if W = UΣV⊤ is a singular value decomposition (SVD) for W, with Σ =
diag(σ1(W), . . . , σr(W)), the infimum is attained for r = rank(W), A = UΣ
1
2 , and B = VΣ
1
2 .
Recall that if φ : Rd → R ∪ {+∞} is proper convex function, its sub-differential at x is
the set
∂φ(x) = {u : φ(x) + 〈u, y − x〉 ≤ φ(y), for all y ∈ domain(φ)} .
The elements of ∂φ(x) are called the sub-gradients of φ at x.
Let On be the set of n × n orthogonal matrices. A norm ‖ · ‖ : R
m×n → [0,∞) is
called orthogonally invariant if, for every U ∈ On, V ∈ Om and W ∈ R
n×m we have that
‖UWV‖ = ‖W‖ or, equivalently ‖W‖ = g(σ(W)), where g is a symmetric gauge function
(SGF), that is g is a norm invariant to permutations and sign changes. An important
example of orthogonally invariant norms are the p-Schatten norms, ‖W‖ = ‖σ(W)‖p,
where ‖ · ‖ is the ℓp-norm of a vector. In particular, for p ∈ {1, 2,∞} we have the trace,
Frobenius, and spectral norms, respectively.
The following result is due to [27, Cor. 2.5].
Lemma 10. If ‖ · ‖ : Rm×n is an orthogonally invariant and g is the associated SGF, then for
every W ∈ Rn×m, it holds that
∂‖W‖ = {Udiag(µ)V⊤ : U ∈ On, V ∈ Om, µ ∈ ∂g(σ), W = Udiag(σ)V
⊤}.
B Proofs
For convenience of the reader, we restate the results presented in the main body of the
paper.
14
Proposition 1 (Equivalence between problems (1) and (5)). Let W∗ ∈ R
n×m be a global
minimizer of fλ in Eq. (1) with r∗ = rank(W∗). Then, for every r ≥ r∗, every global minimizer
(A∗, B∗) of gλ,r is such that
gλ,r(A∗, B∗) = fλ(A∗B
⊤
∗ ) = fλ(W∗). (6)
Proof. Let W∗ ∈ R
n×m be a minimizer for fλ of rank r∗ = rank(W∗) and let UΣV
⊤ be a
singular value decomposition of W∗ with U ∈ R
n×r∗ and V ∈ Rm×r∗ with orthonormal
columns and Σ ∈ Rr∗×r∗ diagonal with positive diagonal entires. Define A∗ = UΣ
1/2 ∈
R
n×r∗ and B = VΣ1/2 ∈ Rm×r∗. By construction ‖W∗‖∗ =
1
2 (‖A∗‖
2
F + ‖B∗‖
2
F) and therefore
fλ(W∗) = fλ(A∗B
⊤
∗ ) = gλ,r∗(A∗, B∗).
Now, we prove that (A∗, B∗) is a minimizer for gλ,r∗ . Suppose by contraddiction that there
exist a couple A1 ∈ R
n×r∗ , B1 ∈ R
m×r∗ such that gλ,r∗(A1, B1) < gλ,r∗(A∗, B∗). Define
(Ā1, B̄1) = argmin
AB⊤=A1B
⊤
1
‖A‖2F + ‖B‖
2
F.
Then by Lemma 9 we have
‖Ā1B̄
⊤
1 ‖∗ =
1
2
(‖Ā1‖
2
F + ‖B̄1‖
2
F) ≤
1
2
(‖A1‖
2
F + ‖B1‖
2
F)
and therefore
fλ(Ā1B̄
⊤
1 ) = gλ,r∗(Ā1, B̄1) ≤ gλ,r∗(A1, B1) < gλ,r∗(A∗, B∗) = fλ(W∗)
which is clearly not possible since W∗ was a global minimizer for W∗.
Proposition 2 (Characterization of Critical Points of gλ,r). Let (A∗, B∗) ∈ R
n×r × Rm×r
be a critical point of gλ,r. Let s ≤ min(n,m) and let U ∈ R
n×s and V ∈ Rm×s be two
matrices with orthonormal columns corresponding to the left and right singular vectors of
∇ℓ(A∗B
⊤
∗ ) ∈ R
n×m with singular value equal to λ. Then, there exists C ∈ Rs×r, such that
A∗ = UC and B∗ = −VC.
Proof. Let A∗ ∈ R
m×r, B∗ ∈ R
n×r be the matrices that correspond to a critical point of
gλ,r. We let
∇ℓ(A∗B∗
⊤) = λU1V
⊤
1 +U2Σ2V
⊤
2 +U3Σ3V
⊤
3 (10)
be the breakdown SVD of the gradient of ℓ at A∗B∗
⊤, where Σ2 is the diagonal matrix
formed by the singular values strictly larger than λ and Σ3 is the diagonal matrix formed
by the singular values strictly smaller than λ (including those which are zero). For each
i = 1, 2, 3 we denote with si the number of columns of Ui ∈ R
n×si and Vi ∈ R
m×si . Recall
that the matrices [U1 U2 U3] ∈ R
n×n and [V1 V2 V3] ∈ R
m×m are both orthogonal.
Taking the derivatives of Eq. (5) w.r.t. A and B and setting them to zero gives the
following optimality conditions for the critical points
∇ℓ(A∗B∗
⊤)B∗ + λA∗ = 0 (11)
∇ℓ(A∗B∗
⊤)⊤A∗ + λB∗ = 0. (12)
15
Solving Eq. (12) for B∗ and and replacing it in Eq. (11) yields that
(
−
1
λ2
∇ℓ(A∗B∗
⊤)∇ℓ(A∗B∗
⊤)⊤ + Im
)
A∗ = 0. (13)
By Eq. (10) ℓ(A∗B∗
⊤)∇ℓ(A∗B∗
⊤)⊤ = λ2U⊤1 + U2Σ
2
2U
⊤
2 + U3Σ
2
3U
⊤
3 . Using this in Eq. (13)
and rearranging gives
(
Im −U1U
⊤
1 −U2
Σ22
λ2
U⊤2 −U3
Σ23
λ2
U⊤3
)
A∗ = 0
which we rewrite as
(
U2(I −
Σ22
λ2
)U⊤2 +U3(I −
Σ23
λ2
)U⊤3
)
A∗ = 0.
Therefore, the columns of A∗ must be in the range of U1 (i.e. orthogonal to U2 and U3),
namely
A∗ = U1C (14)
for some C ∈ Rs1×r. Similarly we derive that
B∗ = V1D (15)
for some D ∈ Rs1×r. Combining Eq. (10) with Eq. (15) we obtain that
∇ℓ(A∗B∗
⊤)B∗ = −λU1C.
Using this equation, Eq. (14) and Eq. (15) we rewrite Eq. (11) as λU1D+ λU1C = 0. This
implies that D = −C and, so, B∗ = −V1C.
Theorem 3 (A Criterion for Global Optimality). Let (A∗, B∗) be a critical point of gλ,r. Then
A∗B
⊤
∗ is a minimizer for fλ if and only if ‖∇ℓ(A∗B
⊤
∗ )‖ ≤ λ.
Proof. Let W∗ = A∗B∗
⊤. We need to show that 0 ∈ ∂fλ(W∗) or, equivalently
−
1
λ
∇ℓ(W∗) ∈ ∂‖W∗‖∗. (16)
Let Z = − 1λ∇ℓ(W∗). As a special case of Lemma 10 we have that Z ∈ ∂‖W∗‖∗ holds
true if and only if there exists a simultaneous singular value decomposition of the form
W∗ = Udiag(σ)V
⊤, Z = Udiag(σ(Z))V⊤ and σ(Z) ∈ ∂‖σ(W∗)‖1, with σ(Z) denoting
the spectrum of Z (namely the vector of singular values of Z arranged in non-increasing
order). Recall that
∂‖σ‖1 = {z ∈ R
m : zi = 1 if σi 6= 0, and zi ∈ [−1, 1] otherwise}.
Using the same notation of Prop. 2, consider the SVD
Z = −U1V
⊤
1 −U2
Σ2
λ
V⊤2 −U3
Σ3
λ
V⊤3 .
16
By Prop. 2 we have that A∗ = U1C and B∗ = −V1C, with C ∈ R
s1×r. Now, let r̄ =
rank(C) ≤ r and let C = PΓQ⊤ be the SVD of C, with P ∈ Rs1×r̄ and Q ∈ Rr̄×r matrices
with orthonormal columns and Γ ∈ Rr̄×r̄ diagonal with positive diagonal elements. Denote
P̃ = [P P⊥] ∈ Rs1×s1 the orthonormal matrix obtained by completing P with a matrix P⊥ ∈
R
s1×(s1−r̄) with orthonormal columns such that P⊤P⊥ = 0. Moreover denote Γ̃ ∈ Rs1×s1 as
Γ̃ =
[
Γ 0r̄×s1−r̄
0s1−r̄×r̄ 0s1−r̄×s̄1−r̄
]
.
Then,
W∗ = −U1CC
⊤V1 = (−U1P)Γ
2(V1P)
⊤ = (−U1P̃)Γ̃
2(V1P̃)
⊤ = (−Ũ1)Γ̃
2(Ṽ1)
with Ũ1 = U1P̃ and Ṽ = V1P̃. Note that since P̃ is orthonormal, Ũ1Ṽ
⊤
1 = U1V
⊤
1 . More-
over U2, U3 have columns orthogonal to Ũ1 and V2, V3 have columns orthogonal to Ṽ1.
Consequently,
Z = −U1V
⊤
1 −U2
Σ2
λ
V⊤2 −U3
Σ3
λ
V⊤3 = −Ũ1Ṽ
⊤
1 −U2
Σ2
λ
V2 −U3
Σ3
λ
V⊤3
is an alternative singular value decomposition for Z. Therefore, W∗ and Z have a simulta-
neous singular value decomposition and we can conclude that σ(Z) ∈ ∂‖σ(W∗)‖1 if and
only if s2 = 0, namely ‖∇ℓ(W∗)‖ ≤ λ as desired.
Proposition 4 (Escape Direction from Critical Points). With the same notation of Prop. 2,
assume rank(A∗) = rank(B∗) < r and ‖∇ℓ(A∗B
⊤
∗ )‖ = µ > λ. Then, (A∗, B∗) is a so-called
strict saddle point for gλ,r, namely the Hessian of gλ,r at (A∗, B∗) has at least one negative
eigenvalue. In particular, there exists q ∈ Rr such that A∗q = 0, B∗q = 0 and if u ∈ R
n and
v ∈ Rm are the left and right singular vectors of ∇ℓ(A∗B
⊤
∗ ) with singular value equal to µ,
then gλ,r decreases locally at (A∗, B∗) along the direction (uq
⊤,−vq⊤).
Proof. By Theorem 2, A∗ = U1C and B∗ = −V1C, where U1 and V1 are the matrices of left
and right singular vectors of ∇ℓ(A∗B∗
⊤) and C ∈ Rs×r, for s = rank(A∗) = rank(B∗). Tak-
ing the SVD of C = PΓQ⊤, we rewrite
A∗ = U1PΓQ
⊤, B∗ = −V1PΓQ
⊤. (17)
Since A∗ and B∗ are rank deficient and they have the same null space, we can choose
q ∈ Rr such that A∗q = B∗q = 0. Let u2 and v2 the a left and right singular vector of
∇ℓ(A∗B∗
⊤) with singular value equal to µ.
We consider a perturbation of the objective function in the direction (−u2q
⊤, v1q
⊤).
We have that
L(γ) = ℓ
(
(A∗ − γu2q
⊤)(B∗ + γv1q
⊤)⊤
)
+
λ
2
(
‖A∗ − γu1q
⊤‖2F + ‖B∗ + γv1q
⊤‖2F
)
(18)
= ℓ(A∗B∗
⊤ − γ2u2v
⊤
2 ) +
λ
2
(‖A∗‖
2
F + ‖B∗‖
2
F) + λγ
2. (19)
(20)
17
Thus, we have that
L ′(γ) = 〈−2γ∇ℓ(A∗B∗
⊤ − γ2u2v
⊤
2 ), u2v
⊤
2 〉 + 2γλ (21)
= −2γu⊤2 ∇ℓ(A∗B∗
⊤ − γ2u2v
⊤
2 )v2 + 2γλ. (22)
Consequently
L ′′(0) = 2(λ − u⊤2∇ℓ(A∗B∗
⊤)v2) = 2(λ − µ) < 0
and the result follows.
Theorem 5 (Convergence to Global Minimizers of gλ,r). Let r ≥ min(n,m). Then the set
of starting points (A0, B0) for which GD does not converge to a global minimizer of gλ,r has
measure zero.
Proof. We have shown in Prop. 4 that every critical point (A,B) of gλ,r for r ≥ min(n,m)
is either a global minimizer or a strict saddle point, namely such that the Hessian ∇2gλ,r(A,B)
has at least a negative eigenvalue. Therefore, since the error function ℓ is twice differen-
tiable with gradient Lipschitz continuous also gλ,r is. Let Lr > 0 be the Lipschitz constant of
∇gλ,r. Then, we are in the hypotheses of Thm.4.1 in [18] which states that if (Ak, Bk)k∈N is
obtained with step 0 < α < 1/Lr with initial point (A0, B0) sampled uniformly at random,
then for any (A∗, B∗) strict saddle point of gλ,r,
Prob
(
lim
k→+∞
(Ak, Bk) = (A∗, B∗)
)
= 0
which implies the desired result and corresponds to Cor. 6.
At last we show that if the spectral norm of the gradient at a critical point is close to
one from above then value of the objective function is close to the global minimum.
Proposition 11. Let (A∗, B∗) be a critical point of gλ,r and let W∗ = A∗B
⊤
∗ . If ‖∇ℓ(W∗)‖ ≤
λ+ ǫ with ǫ ∈ [0, λ] then
fλ(W∗) ≤ min
W
fλ(W) + ǫ
(
‖W∗‖∗ +
ℓ(0)
λ
)
Proof. We write
∇ℓ(W∗) = λU1V
⊤
1 +U2Σ2V
⊤
2 + λU3V
⊤
3 +U3Σ3V
⊤
3 (23)
= λ(U1V
⊤
1 +U3V
⊤
3 ) +U2Σ2V
⊤
2 + λU3V
⊤
3 +U3(Σ3 − λU)V
⊤
3 .
Let Z = U3(Σ3 − λU)V
⊤
3 . By assumption ‖Σ3‖ ≤ 2λ, implying that −Z ∈ ∂fλ(W∗). That is,
for every W ∈ Mn,m,
fλ(W∗) + 〈Z,W −W∗〉 ≤ fλ(W). (24)
In turn this implies that
fλ(W∗) ≤ 〈Z,W −W∗〉+ fλ(W).
18
Since the minimizer can be constrainted to be in the set {W : ‖W‖tr ≤ ℓ(0)/λ} we conclude
from Eq. (24) that
fλ(W∗) ≤ fλ(W) − 〈Z,W −W∗〉
≤ min
W
fλ(W) + ‖Z‖
(
‖W∗‖∗ +
ℓ(0)
λ
)
≤ min
W
fλ(W) + ǫ
(
‖W∗‖tr +
ℓ(0)
λ
)
.
C Meta-algorithm with Explicit Escape from Stationary Points
We expand on the discussion in Sec. 3.3, where we formally introduced the meta-algorithm
considered in this work. Specifically we observe that in the formulation of Algorithm 1 we
did not exploit the result in Prop. 4, providing an explicit decreasing direction for gλ,r+1
from the inflated point ([A∗ 0], [B∗ 0]), where (A∗, B∗) is a stationary point for gλ,r. For
completeness in Algorithm 2 we report a variant of the meta-algorithm proposed in this
paper that makes use of such escape direction. We care to point out that in our experiments
we did not observe any statistically significant difference with the original version.
We discuss here the details of Algorithm 2. By Prop. 4 we know that there exists γ > 0
such that
gλ,r+1([A∗ 0] + γ[0n×r, u], [B∗ 0] + γ[0m×r, − v]) < gλ,r(A∗, B∗)
where u ∈ Rn, v ∈ Rm are respectively the left and right singular vectors associated to the
largest singular value µ of ∇ℓ(A∗B
⊤
∗ ). In Algorithm 2 these are provided by the routine
LARGESTSINGULARPAIR.
We can find a new point on the direction specified above by trying to approximate the
minimizer of
γ∗ = argmin
γ∈[0,1]
gλ,r+1([A∗ 0] + γ[0n×r u], [B∗ 0] + γ[0m×r − v])
for instance by considering a set of candidate γ1, . . . , γM ∈ (0, 1] (e.g. γi = γ
i
0 for
i = 1, . . . ,M) and choose the one leading to the lowest value for gλ,r+1. In Algorithm
2 we refer to this procedure as LINESEARCH given its analogy with standard line search
approaches often used in optimization. However notice that such methods can typically
leverage on a criterion depending on the norm of the gradient ‖∇gλ,r+1([A∗ 0], [B∗ 0])‖F
in order to guarantee that the function decreases significantly. We cannot replicate such
strategy since ∇gλ,r+1([A∗ 0], [B∗ 0]) = 0 in our case.
As a final observation, we care to point out (as we already done in Sec. 3.3) that it is
necessary to perturb the point ([A∗ γu], [B∗ − γv]), e.g. by adding some noise, in order to
guarantee that ([A∗ γu], [B∗ −γv]) does not belong to the set of measure zero, mentioned
in Thm. 5, of initial points that converge to strict saddle points of gλ,r.
19
Algorithm 2 META-ALGORITHM WITH EXPLICIT ESCAPE FROM STATIONARY POINTS
Input: λ > 0, ǫconv > 0 convergence tolerance, ǫcrit > 0 global criterion tolerance, σ > 0
noise parameter.
Initialize: Set r = 1. Sample A0 ∈ R
n and B0 ∈ R
n randomly.
For r = 1 to min(n,m)
(Ar, Br) = OPTIMIZATIONALGORITHM(Ar−1 , Br−1, gλ,r, ǫconv)
If ‖∇ℓ(ArB
⊤
r )‖ ≤ λ + ǫcrit
Break
[u, µ, v] =LARGESTSINGULARPAIR(∇ℓ(ArB
⊤
r ))
γ̂ = LINESEARCH([Ar 0], [Br 0], u, v)
Perturb u = u+ η with η ∼ N (0, σIn×n)
Perturb v = v+ η with η ∼ N (0, σIm×m)
(Ar+1, Br+1) = ([Ar γu], [Br − γv])
r = r + 1
End
Return (Ar, Br)
D On the Kurdyka-Lojasiewicz Inequality
We extend here the discussion on the KL inequality (Def. 7) and corresponding conver-
gence results reviewed in Sec. 3.4. As a special case to the problem of optimizing gλ,r
considered in this work, we have recalled in Cor. 8 that if gλ,r satisfies the KL inequality,
we can expect GD to exhibit polynomial rates of convergence. A natural question is when
gλ,r satisfies such inequality. To provide an insight on this issue, we consider the result
in [24] showing that the KL inequality is satisfied by semi-algebraic functions. We recall
that a set S ⊆ Rd is said semi-algebraic if there exists a finite number of polynomials
pkh, qkh : R
d → R such that
S =
K⋃
k=1
H⋂
h=1
{
x ∈ Rd | pkh(x) = 0, qkh(x) ≤ 0
}
.
A function f : Rd → R is said semi-algebraic if its graph
graph f =
{
(x, t) | x ∈ Rd, t ∈ R, f(x) = t
}
is semi-algebraic.
Note that a variety of error functions ℓ : Rn×m → R typically used in machine learning
and matrix factorization problems are semi-algebraic (e.g. the square loss). Interestingly,
we have that if ℓ is semi-algebraic, then ℓr : R
n×r×Rm×r → R such that ℓr(A,B) = ℓ(AB
⊤),
is semi-algebraic as well. Indeed, by definition of semi-algebraic function we have that
graph ℓ =
{
(X, t) | X ∈ Rn×m, t ∈ R, ℓ(X) = t
}
is semi algebraic, therefore there exist pkh, qkh : R
n×m × R → R such that
graph ℓ =
K⋃
k=1
H⋂
h=1
{(X, t) | pkh(X, t) = 0, qkh(X, t) ≤ 0} .
20
Now, denote Xij the (i, j)-th entry of X. For X = AB
⊤ with A ∈ Rn×r and B ∈ Rm×r
we have Xij =
∑r
s=1 AisBjs namely Xij = mij(A,B) with mij : R
n×r × Rm×r → R a real
polynomial. Let us denote m : Rn×r×Rm×r → Rn×m the matrix valued function with (i, j)-
th entry m(A,B)ij = mij(A,B). Since every pkh and qkh are polynomial in the variables
of X, we have that pkh ◦m and hkh ◦m are still polynomials and therefore the graph of ℓr
graph ℓr = {(A,B, t) | A ∈ R
n×r, B ∈ Rm×r, t ∈ R, ℓ(ABtop) = t}
=
K⋃
k=1
H⋂
h=1
{(A,B, t) | pkh(m(A,B)), t) = 0, qkh(m(A,B), t) ≤ 0}
is semi-algebraic, which implies that ℓr is a semi-algebraic function.
Going back to the question of whether gλ,r(A,B) = ℓ(AB
⊤) + λ
2
(‖A‖2F + ‖B‖
2
F) is semi-
algebraic, we now can conclude that it is sufficient to assume the error function ℓ to be
semi-algebric. Indeed, it is well-known (see e.g. [24]) that the squared Frobenius norm
of a matrix is semi-algebraic and that the finite sum of semi-algebraic functions is still
semi-algebraic. Therefore we can re-formulate Cor. 8 in terms only of the error ℓ, namely
Corollary 12 (Convergence Rate of Gradient Descent). Let (Ak, Bk)k∈N a sequence pro-
duced by GD method applied to gλ,r. If ℓ is semi-algebraic, then gλ,r satisfies the KL inequality
for some constant α ∈ [0, 1), and there exists a critical point (A∗, B∗) of gλ,r and constants
C,b > 0 such that
‖(Ak, Bk) − (A∗, B∗)‖
2
F ≤
{
Cbk if α ∈ (0, 1/2],
Ck−
1−α
2α−1 if α ∈ (1/2, 1).
(25)
Furthermore, if α = 0 convergence is achieved in a finite number of steps.
E Further Experiments
This last section provides more comparative experiments between the meta-algorithm and
the two state-of-the art solvers, as well as a comparison to the algorithm in [19]
E.1 Large Scale Matrix Completion
In Sec. 4 we reported on the performance of the three methods considered for λ chosen by
validation as the parameter leading to the lowest Normalized Mean Average Error (NMAE).
For completeness here we report the same experiments for a range of candidate values of
λ.
Figures 3 and 4 report respectively the value of the objective function fλ and the test
error (NMAE) for the three methods considered in our experiments. Interestingly we
observe a similar pattern to the one of the optimal λ, with our method exhibiting compa-
rable performance in terms of both time and test error to the state-of-the-art competitors
for most of the λ considered.
21
0 500 1000 1500
0.2
0.3
0.4
o
b
je
c
ti
v
e
lambda: 1
active ALT
softImpute-ALS
ours
0 200 400 600 800
0.3
0.4
0.5
lambda: 1.5849
0 100 200 300
0.4
0.5
0.6
lambda: 2.5119
0 50 100 150 200
0.5
0.55
0.6
0.65
0.7
o
b
je
c
ti
v
e
lambda: 3.9811
0 50 100 150 200
0.75
0.8
0.85
lambda: 6.3096
0 10 20 30 40
1.04
1.06
1.08
1.1
lambda: 10
0 5 10 15
time (sec)
1.43
1.44
o
b
je
c
ti
v
e
lambda: 15.8489
0 2 4 6 8
time (sec)
1.92
1.93
lambda: 25.1189
0 2 4 6
time (sec)
2
4
6
8
10
lambda: 39.8107
Figure 3: Convergence of the objective function on ml100k for various lambda values.
The center plot is for the optimal lambda value based on the validation errors. The circle
indicates that our proposed global optimality criterion has been satisfied.
0 500 1000 1500
0.2
0.25
0.3
0.35
te
s
t 
e
rr
o
r
lambda: 1
active ALT
softImpute-ALS
ours
0 200 400 600 800
0.2
0.25
0.3
0.35
lambda: 1.5849
0 100 200 300
0.2
0.25
0.3
0.35
lambda: 2.5119
0 50 100 150 200
0.2
0.25
0.3
0.35
te
s
t 
e
rr
o
r
lambda: 3.9811
0 50 100 150 200
0.2
0.25
0.3
0.35
lambda: 6.3096
0 10 20 30 40
0.25
0.3
0.35
lambda: 10
0 5 10 15
time (sec)
0.25
0.3
0.35
te
s
t 
e
rr
o
r
lambda: 15.8489
0 2 4 6 8
time (sec)
0.25
0.3
0.35
lambda: 25.1189
0 2 4 6
time (sec)
0.3
0.32
0.34
0.36
lambda: 39.8107
Figure 4: Test error on ml100k for various lambda values. The center plot is for the opti-
mal lambda value based on the validation errors. The circle indicates that our proposed
global optimality criterion has been satisfied on the original problem.
22

