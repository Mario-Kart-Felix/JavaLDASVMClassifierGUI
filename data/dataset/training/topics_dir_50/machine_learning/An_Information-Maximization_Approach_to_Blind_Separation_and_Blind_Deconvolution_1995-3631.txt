ARTICLE Coni~nunicated by John Platt and Simon Haykin 
An Information-Maximization Approach to 
Blind Separation and Blind Deconvolution 
Anthony J. Bell 
Terrence J. Sejnowski 
Ho~unrd H q h e s  Medical Itzstltutc, 
Cotnyutationnl Neirrobiology Laboratory, Tlw Salk Institute, 
10010 N. Torrry Pines Road, La lolla, CA 92037 U S A  atzd 
Departrize~~t of Biology, Ul~rz~ersity of Callfortlrn, San Diqo ,  Ln lolla, CA 92093 USA 
We derive a new self-organizing learning algorithm that maximizes 
the information transferred in a network of nonlinear units. The al- 
gorithm does not assume any knowledge of the input distributions, 
and is defined here for the zero-noise limit. Under these conditions, 
information maximization has extra properties not found in the linear 
case (Linsker 1989). The nonlinearities in the transfer function are able 
to pick up higher-order moments of the input distributions and per- 
form something akin to true redundancy reduction between units in 
the output representation. This enables the network to separate statis- 
tically independent components in the inputs: a higher-order general- 
ization of principal components analysis. We apply the network to the 
source separation (or cocktail party) problem, successfully separating 
unknown mixtures of up to 10 speakers. We also show that a variant 
on the network architecture is able to perform blind deconvolution 
(cancellation of unknown echoes and reverberation in a speech sig- 
nal). Finally, we derive dependencies of information transfer on time 
delays. We suggest that information maximization provides a unifying 
framework for problems in "blind" signal processing. 
1 Introduction 
This paper presents a convergence of two lines of research. The first, 
the development of information-theoretic unsupervised learning rules for 
neural networks, has been pioneered by Linsker (1992), Becker and Hin- 
ton (1992), Atick and Redlich (1993), Plumbley and Fallside (19881, and 
others. The second is the use, in signal processing, of higher-order statis- 
tics for separating out mixtures of independent sources (blind separation) 
or reversing the effect of an unknown filter (blind deconvolution). Meth- 
ods exist for solving these problems, but it is fair to say that many of them 
are ad hoc. The literature displays a diversity of approaches and justifi- 
cations-for historical reviews see Comon (1994) and I-Iaykin (1994a). 
Ncrrrnl Corllp~rtafiorl 7, 1129-1159 (1995) @ 1995 Massachusetts Institute of Technology 
Anthony J.  Bell and Terrence J .  Sejnowski 
In this paper, we supply a common theoretical framework for these 
problems through the use of information-theoretic objective functions 
applied to neural networks with nonlinear units. The resulting learn- 
ing rules have enabled a principled approach to the signal processing 
problems, and opened a new application area for information-theoretic 
unsupervised learning. 
Blind separation techniques can be used in any domain where an ar- 
ray of N receivers picks up linear mixtures of N source signals. Examples 
include speech separation (the "cocktail party problem"), processing of 
arrays of radar or sonar signals, and processing of multisensor biomed- 
ical recordings. A previous approach has been implemented in analog 
VLSI circuitry for real-time source separation (Vittoz and Arreguit 1989; 
Cohen and Andreou 1992). The application areas of blind deconvolu- 
tion techniques include the cancellation of acoustic reverberations (for 
example, the "barrel effect" observed when using speaker phones), the 
processing of geophysical data (seismic deconvolution), and the restora- 
tion of images. 
The approach we take to these problems is a generalization of Linsker's 
iizfomax principle to nonlinear units with arbitrarily distributed inputs un- 
corrupted by any knowiz noise sources. The principle is that described by 
Laughlin (1981) (see Figure la): when inputs are to be passed through 
a sigmoid function, maximum information transmission can be achieved 
when the sloping part of the sigmoid is optimally lined up with the high- 
density parts of the inputs. As we show, this can be achieved in an adap- 
tive manner, using a stochastic gradient ascent rule. The generalization 
of this rule to multiple units leads to a system that, in maximizing in- 
formation transfer, also reduces the redundancy between the units in the 
output layer. It is this latter process, also called independent component 
analysis (ICA), that enables the network to solve the blind separation task. 
The paper is organized as follows. Section 2 describes the new infor- 
mation maximization learning algorithm, applied, respectively to a single 
input, an N -+ N mapping, a causal filter, a system with time delays, and 
a "flexible" nonlinearity. Section 3 describes the blind separation and 
blind deconvolution problems. Section 4 discusses the conditions under 
which the information maximization process can find factorial codes (per- 
form ICA), and therefore solve the separation and deconvolution prob- 
lems. Section 5 presents results on the separation and deconvolution of 
speech signals. Section 6 attempts to place the theory and results in the 
context of previous work and mentions the limitations of the approach. 
A brief report of this research appears in Bell and Sejnowski (1995). 
2 Information Maximization 
The basic problem tackled here is how to maximize the mutual informa- 
tion that the output Y of a neural network processor contains about its 
Information-Maximization 
input X. This is defined as 
where H(Y)  is the entropy of the output, while H(Y I X) is whatever en- 
tropy the output has that did not come from the ~nput .  In the case that 
we have no noise (or rather, we do not know what 1s noise and what is 
signal in the input), the mapping between X and Y 1s deterministic, and 
H ( Y  I X) has its lowest possible value: it diverges to -x. This divergence 
is one of the consequences of the generalization of information theory 
to continuous variables. What we call H ( Y )  is really the "differential" 
entropy of Y with respect to some reference, such as the noise level or 
the accuracy of our discretization of the variables in X and Y.' To avoid 
such complexities, we consider here only the gradierzt of information- 
theoretic quantities with respect to some parameter, zu, in our network. 
Such gradients are as well behaved as discrete-variable entropies, because 
the reference terms involved in the definition of differential entropies 
disappear. The above equation can be differentiated as follows, with 
respect to a parameter, 70, involved in the mapping from X to Y: 
because H ( Y  I X) does not depend on z u .  This can be seen by considering 
a system that avoids infinities: Y = G(X) + N, where G is some invert- 
ible transformation and N is additive noise on the outputs. In this case, 
H ( Y  I X) = H(N) (Nadal and Parga 1995). Whatever the level of this addi- 
tive noise, maximization of the mutual information, I(Y. X), is equivalent 
to the maximization of the output entropy, H (Y), because (D/azu)H(N) = 
0. There is nothing mysterious about the deterministic case, despite the 
fact that H ( Y  I X) tends to minus infinity as the noise variance goes to 
zero. 
Thus for invertible continuous deterministic mappings, the mutual in- 
formation between inputs and outputs can be maximized by maximizing 
the entropy of the outputs alone. 
2.1 For One Input and One Output. When we pass a single input 
s through a transforming function ~ ( s )  to give an output variable y, 
both I (y .x)  and H ( y )  are maximized when we align high density parts 
of the probability derlsity fii~zcfion (pdf) of s with highly sloping parts of 
the function g(x) .  This is the idea of "matching a neuron's input-output 
function to the expected distribution of signals" that we find in (Laughlin 
1981). See Figure l a  for an illustration. 
When g (x )  is monotonically increasing or decreasing (i.e., has a unique 
inverse), the pdf of the output, f,,(y), can be wr~tten as a function of the 
'See the dlscusslon In H a y k ~ n  (1994b, chap l l ) ,  and In Cover and Thomas (1991, 
chap 9). 
1132 Anthony J .  Bell and Terrence J .  Sejnowski 
Figure 1: Optimal information flow in sigmoidal neurons. (a) Input x having 
density function fx(x), in this case a gaussian, is passed through a nonlinear 
function ~(x). The information in the resulting density, f,,(y) depends on match- 
ing the mean and variance of s to the threshold, wo, and slope, za, of ~ ( x )  (see 
Schraudolph ef al .  1991). (b) f,(y) is plotted for different values of the weight 
111. The optimal weight, zvOpt, transmits most information. 
pdf of the input, fv(x), (Papoulis 1984, equation 5-51: 
where the bars denote absolute value. The entropy of the output, H(y), 
is given by 
where E[.] denotes expected value. Substituting 2.3 into 2.4 gives 
The second term on the right (the entropy of x) may be considered to be 
unaffected by alterations in a parameter zu determining g ( x ) .  Therefore 
in order to maximize the entropy of y by changing zo, we need only 
concentrate on maximizing the first term, which is the average log of 
how the input affects the output. This can be done by considering the 
"training set" of x's to approximate the density f,(s), and deriving an 
"online," stochastic gradient ascent learning rule: 
Information-Maximization 
In the case of the logistic transfer function: 
in which the input is multiplied by a weight -iil and added to a bias-weight 
iclo, the terms above evaluate as 
Dividing 2.9 by 2.8 gives the learning rule for the logistic function, as 
calculated from the general rule of 2.6: 
Similar reasoning leads to the rule for the bias-weight: 
The effect of these two rules can be seen in Figure la.  For example, 
if the input pdf f ,(x) were gaussian, then the Azoo-rule would center 
the steepest part of the sigmoid curve on the peak of f , ( x ) ,  matching 
input density to output slope, in a manner suggested intuitively by 2.3. 
The Azo-rule would then scale the slope of the sigmoid curve to match 
the variance of f ,(x). For example, narrow pdf's would lead to sharply 
sloping sigmoids. The Aw-rule is anti-HebbiallI2 with an anti-decay term. 
The anti-Hebbian term keeps y away from one uninformative situation: 
that of y being saturated at 0 or 1. But an anti-Hebbian rule alone makes 
weights go to zero, so the anti-decay term (llw) keeps y away from the 
other uninformative situation: when zu is so small that y stays around 
0.5. 
The effect of these two balanced forces is to produce an output pdf, 
f,(y), that is close to the flat unit distribution; that is, the maximum 
entropy distribution for a variable bounded between 0 and 1. Figure l b  
shows a family of these distributions, with the most informative one 
occurring at w,,,. 
A rule that maximizes information for one input and one output may 
be suggestive for structures such as synapses and photoreceptors that 
must position the gain of their nonlinearity at a level appropriate to the 
average value and size of the input fluctuations (Laughlin 1981). How- 
ever, to see the advantages of this approach in artificial neural networks, 
we now analyze the case of multidimensiona1 inputs and outputs. 
1134 Antliony J .  Bell and Terrence J .  Sejnowski 
2.2 For an  N -- N Network. Consider a network with a n  input vector 
x, a welght matrix W, a bias vector wo, and a monotonically transformed 
output vector y = g(Wx + wo). Analogously to 2.3, the multivariate 
probability density function of y can be written (Papoulis 1984, equation 
6-63): 
where I J J  is the absolute value of the Jacobian of the transformation. The 
Jacobian is the determinant of the matrix of partial derivatives: 
The derivation proceeds as in the previous section except instead of maxi- 
mizing In 18y/8xll now we maximize In (/). This latter quantity represents 
the log of the volume of space in y into which points in x are mapped. By 
maximizing it, we attempt to spread our training set of x-points evenly 
in y. 
For sigmoidal units, y = g(u), u = Wx + wo, with g being the logistic 
function: g ( u )  = (I + e-")-I, the resulting learning rules are familiar in 
form (proof given in the Appendix): 
except that now x, y, wo, and 1 are vectors (I is a vector of ones), W is 
a matrix, and the anti-Hebbian term has become an outer product. The 
anti-decay term has generalized to an anti-redundancy term: the inverse 
of the transpose of the weight matrix. For an individual weight, 70,,, this 
rule amounts to 
cof wij 
nw,, m --- 
det W 
+ xi( l  - 2y;) 
where cof w,,, the cofactor of zu,,, is (-l) '+l times the determinant of the 
matrix obtained by removing the ith row and the jth column from W. 
This rule is the same as the one for the single unit mapping, except 
that instead of w = 0 being an unstable point of the dynamics, now any 
degenerate weight matrix is unstable, since det W = 0 if W is degenerate. 
This fact enables different output units y, to learn to represent different 
things in the input. When the weight vectors entering two output units 
become too similar, det W becomes small and the natural dynamic of 
learning causes these weight vectors to diverge from each other. This 
effect is mediated by the numerator, cof .roll. When this cofactor becomes 
small, it indicates that there is a degeneracy in the weight matrix of the 
resf of the layer (i.e., those weights not associated with input s, or output 
y,). In this case, any degeneracy in W has less to do  with the specific 
weight zu,, that we are adjusting. Further discussion of the convergence 
conditions of this rule (in terms of higher-order moments) is deferred to 
Section 6.2. 
The utility of this rule for performing blind separation is demonstrated 
in Section 5.1. 
2.3 For a Causal Filter. I t  is not necessary to restrict our architecture 
to weight matrices. Consider the top part of Figure 3b, in which a time 
series x ( f ) ,  of length M, is convolved with a causal filter zu l . .  . . . z u ~  of 
impulse response zu( t ) ,  to give an output time series u ( t ) ,  which is then 
passed through a nonlinear function, g, to give y ( t ) .  We can write this 
system either as a convolution or as a matrix equation: 
in which Y, X, and U are vectors of the whole time series, and W is an 
M x M matrix. When the filtering is causal, W will be lower triangular: 
At this point, we take the liberty of imagining there is an ensemble of 
such time series, so that we can write, 
where again, JJI is the Jacobian of the transformation. We can "create" 
this ensemble from a single time series by chopping it into bits (of length 
L for example, making W in 2.19 an L x L matrix). The Jacobian in 2.20 
is written as follows: 
M 
1 = det [w] = (det W, llyl(f) 
i)s(t,) ;, t = 1  
and may be decomposed into the determinant of the weight n~atrix 
2.19, and the product of the slopes of the squashing function, y ' ( t )  = 
a y ( t ) / a z l ( t ) ,  for all times t  (see Appendix A.6). Because W is lower- 
triangular, its determinant is simply the product of its diagonal values, 
that is 7ufJ'. As in the previous section, we maximize the joint entropy 
1136 Anthony J.  Bell and Terrence J. Sejnowski 
H ( Y )  by maximizing In 111, which can then be simply written as 
If we assume that our nonlinear function 8 is the hyperbolic tangent 
(tanh), then differentiation with respect to the weights in our filter zu(t), 
gives two simple3 rules: 
Here, W L  is the 'leading' weight, and the ZUL-,, where j > 0, are tapped 
delay lines linking xl-, to y,. The leading weight thus adjusts just as 
would a weight connected to a neuron with only that one input (see 
Section 2.1). The delay weights attempt to decorrelate the past input 
from the present output. Thus the filter is kept from "shrinking" by its 
leading weight. 
The utility of this rule for performing blind deconvolution is demon- 
strated in Section 5.2. 
2.4 For Weights with Time Delays. Consider a weight, zu, with a 
time delay, d, and a sigmoidal nonlinearity, g, so that 
y ( t )  = ~ [ z u x ( ~  - d ) ]  (2.25) 
We can maximize the entropy of y with respect to the time delay, again 
by maximizing the log slope of y (as in 2.6): 
a~ a 
Ad ix - = -- (ln ly l l )  
ad ad 
The crucial step in this derivation is to realize that 
Calling this quantity simply -x, we may then write 
Our general rule is therefore given as follows: 
a I 1 a y i a y  . dyi  
- (In I!/ I )  = - - - = - Z C ) S -  ad y' 8 y  ad a y 
3The corresponding rules for rlo~musa1 filters are substantially more complex 
When g is the tan11 function, for example, this yields the following rule 
for adapting the time delay: 
This rule holds regardless of the architecture 111 which the network is em- 
bedded, and i t  is local, unlike the Azo rule In 2.16. I t  bears a resemblance 
to the rule proposed by I1latt and Faggin (1992) for adjustable time delays 
in the network architecture of Jutten and Herault (1991 1. 
The rule has an Intuitive Interpretation. First, if  70 = 0, there IS no 
reason to adjust the delay. Second, the rule maximizes the delivered poriw 
of the inputs, stabilizing when (iy) = 0. As an example, if  y received 
several sinusoidal inputs of the same frequency, &I, and different phase, 
each with its own adjustable time delay, then the time delays would 
adjust until the phases of the time-delayed inputs were all the same. 
Then, for each input, (iy) would be proportional to (cos~?t  anh(sindf)), 
which would be zero. 
In adjusting delays, therefore, the rule will attempt to line up similar 
signals in time, and cancel time delays caused by the same signal taking 
alternate paths. 
We hope to explore, in future work, the usefulness of this rule for 
adjusting time delays and tap-spacing in blind separation and blind de- 
convolution tasks. 
2.5 For a Generalized Sigmoid Function. In Section 4, we will show 
how it is sometimes necessary not only to train the weights of the net- 
work, but also to select the form of the nonlinearity, so that it can "match" 
input pdf's. In other words, if the input to a neuron is u,  with a pdf of 
f,,(u), then our sigmoid should approximate, as closely as possible, the 
cumulative distribution of this input: 
One way to do this is to define a "flexible" sigmoid that can be altered 
to fit the data, in the sense of 2.31. An example of such a function is the 
asymmetric generalized logistic function (see also Baram and Roth 1994) 
described by the differential equation: 
where p and r are positive real numbers. Numerical integration of this 
equation produces sigmoids suitable for very peaked (as p. I. > 1, see 
Fig. 2b) and flat, unit-like (as p, r < 1, see Fig. 2c) input distributions. 
So by varying these coefficients, we can mold the sigmoid so that its 
slope fits unimodal distributions of varying kurtosis. By having p # I., 
Anthony J .  Bcll and Terrence J .  Sejn0wsk.i 
Figure 2: The generalized logistic sigmoid (top row) of 2.32, and its slope, y' 
(bottom row), for (a) p = r = 1, (b) p = r. = 5 and (c) p = 1. = 0.2. Compare 
the slope of (b) with the pdf in Figure 5a: it provides a good match for natural 
speech signals. 
we can also account for some skew in the distributions. When we have 
chosen values for p and 1', perhaps by some optimization process, the 
rules for changing a single input-output weight, zo, and a bias, zuo, are 
subtly altered from 2.14 and 2.11, but clearly the same when F )  = I' = 1: 
The importance of being able to train a general function of this type brill 
be explained in Section 4. 
3 Background to Blind Separation and Blind Deconvolution 
Blind separation and blind deconvolution are related problems in signal 
processing. In bliizdsepnmfion, as introduced by Herault and Jutten (1986), 
and illustrated in Figure 3a, a set of sources, s , ( t ) .  . . . shr(t) ,  (different 
people speaking, music, etc.) is mixed together linearly by a matrix A. 
We do not know anything about the sources, or the mixing process. All 
Information-Maximization 11 39 
unknown BLIND 
mixing SEPARATION ' 
process (learnt weights) 
At BLIND DECONVOLUTION 
Figure 3: Network architectures for (a) blind separation of tive mixed signals, 
and (b) blind deconvolution of a single signal. 
we receive are the N superpositions of them, XI ( t ) .  . . xN(f).  The task is 
to recover the original sources by finding a square matrix, W, which is a 
permutation and rescaling of the inverse of the unknown matrix, A. The 
problem has also been called the "cocktail-party" problem." 
In blind deconvolutio~z, described in Haykin (1991,1994a) and illustrated 
in Figure 3b, a single unknown signal s(f) is convolved with an unknown 
tapped delay-line filter a,. . . . . a ~ ,  giving a corrupted signal x(t) = a(t)*s(t) 
where a(t)  is the impulse response of the filter. The task is to recover s( t )  
by convolving x ( t )  with a learnt filter zu,. . . . . ZUL, which reverses the effect 
of the filter a([). 
There are many similarities between the two problems. In one, sources 
are corrupted by the superposition of other sources. In the other, a source 
is corrupted by time-delayed versions of itself. In both cases, unsuper- 
vised learning must be used because no error signals are available. In 
both cases, second-order statistics are inadequate to solve the problem. 
For example, for blind separation, a second-order decorrelation tech- 
nique such as that of Barlow and FijldiAk (1989) would find uncorrelated, 
or linearly independent, projections, y, of the input data, x. But it could 
only find a symmetric decorrelation matrix, that would not suffice if the 
mixing matrix, A, were asymmetric (Jutten and Herault 1991). Similarly, 
for blind deconvolution, second-order techniques based on the autocor- 
relation function, such as prediction-error filters, are phase-blind. They do  
not have sufficient information to estimate the phase of the corrupting 
filter, a(f), only its amplitude (Haykin 19944. 
4 T h o ~ ~ g h  for now, we ignore the problem of signal propagation delays 
1140 Anthony J .  Bell and Terrence J.  Sejnowski 
The reason why second-order techniques fail is that these two "blind" 
signal processing problems are information-theoretic problems We are 
assuming, in the case of blind separation, that the sources, s, are statis- 
tically independent and non-gaussian, and in the case of blind deconvo- 
lution, that the original signal, s ( t ) ,  consists of Independent symbols (a 
white process). Then blind separation becomes the problem of minimlz- 
ing the mutual information between outputs, I [ , ,  introduced by the mix- 
ing matrix A; and blind deconvolution becomes the problem of removing 
from the convolved signal, x ( t ) ,  any statistical dependencies across time, 
introduced by the corrupting filter a ( t ). The former process, the learning 
of W, is called the problem of independent component analysis, or ICA 
(Con-ton 1994). The latter process, the learning of zo(t), is sometimes called 
the 7id7itening of x ( t  ). Henceforth, we use the term reduizdancy r.t.duchorz 
when we mean either ICA or the whitening of a time series. 
In either case, it is clear in an informa tion-theoretic context that second- 
order statistics are inadequate for reducing redundancy, because the mu- 
tual information between two variables involves statistics of all orders, 
except in the special case that the variables are jointly gaussian. 
In the various approaches in the literature, the higher-order statistics 
required for redundancy reduction have been accessed in two main ways. 
The first way is the explicit estimation of cumulants and polyspectra. See 
Comon (1994) and Hatzinakos and Nikias (1994) for the application of 
this approach to separation and deconvolution, respectively. The draw- 
backs of such direct techniques are that they can sometimes be compu- 
tationally intensive, and may be inaccurate when cumulants higher than 
fourth order are ignored, as they usually are. It is currently not clear 
why direct approaches can be surprisingly successful despite errors in 
the estimation of the cumulants, and in the usage of these cumulants to 
estimate mutual information. 
The second main way of accessing higher-order statistics is through 
the use of static nonlinear functions. The Taylor series expansions of 
these nonlinearities yield higher-order terms. The hope, in general, is 
that learning rules containing such terms will be sensitive to the right 
higher-order statistics necessary to perform ICA or whitening. Such rea- 
soning has been used to justify both the Herault-Jutten (or H-J) approach 
to blind separation (Comon et 01. 1991) and the so-called "Bussgang" ap- 
proaches to blind deconvolution (Bellini 1994). The drawback here is 
that there is no guarantee that the higher-order statistics yielded by the 
nonlinearities are weighted in a way relating to the calculation of statis- 
tical dependency. For the H-J algorithm, the standard approach is to try 
different nonlinearities on different problems to see if they work. 
Clearly, it would be of benefit to have some method of rigorously 
linking our choice of a static nonlinearity to a learning rule perform- 
ing gradient ascent in some quantity relating to statistical dependency. 
Because of the infinite number of higher-order statistics involved in sta- 
tistical dependency, this has generally been thought to be impossible. As 
we now show, this belief is incorrect. 
4 When Does Information Maximization Reduce 
Statistical Dependence? 
In this section, we consider under what conditions the information mns-  
in~izntio~z algorithm presented in Section 2 minin~izes  the mutual informa- 
tion between outputs (or time points) and therefore performs redundancy 
reduction. 
Consider a system with two outputs, yl and y2 (two output channels 
in the case of separation, or two time points in the case of deconvolution). 
The joint entropy of these two variables may be written as (Papoulis 1984, 
equation 15-93): 
Maximizing this joint entropy consists of maximizing the individual en- 
tropies while minimizing the mutual information, l(yl. y2), shared be- 
tween the two. When this latter quantity is zero, the two variables 
are statistically independent, and the pdf can be factored: fvlvz(y1.y2) =
fyl (yl)fyz(y2). Both ICA and the "whitening" approach to deconvolution 
are examples of minimizing I(y,. y2) for all pairs yl and y2. This process is 
variously known as factorial code learning (Barlow 1989), predictability 
minimization (Schmidhuber 1992, as well as independent component 
analysis (Comon 1994) and redundancy reduction (Barlow 1961; Atick 
1992). 
The algorithm presented in Section 2 is a stochastic gradient ascent 
algorithm that maximizes the joint entropy in 4.1. In doing so, it will, in 
general, reduce 1(yl.y2), reducing the statistical dependence of the two 
outputs. 
However, it is not guaranteed to reach the absolute minimum of 
l(yl .y2), because of interference from the other terms, the H(y,). Fig- 
ure 4 shows one pathological situation where a "diagonal" projection 
(Fig. 4c) of two independent, uniformly distributed variables s l  and s z  
is preferred over an "independent" projection (Fig. 4b). This is because 
of a "mismatch" between the input pdf's and the slope of the sigmoid 
nonlinearity. The learning procedure is able to achieve higher values in 
Figure 4c for the individual output entropies, H(yl) and H(yz), because 
the pdf's of x, + x2 and s, - xz are triangular, more closely matching the 
slope of the sigmoid. This interferes with the minimization of l (yl .  y2). 
In many practical situations, however, such interference will have 
minimal effect. We conjecture that only when the pdf's of the ~nputs  are 
sub-gnussin~~ (meaning their kurtosis, or fourth-order standardized cumu- 
lant, is less than O), may unwanted lugher entropy solutions tor logistic 
11 42 Anthony J.  Bell and Terrence J. Sejnowski 
Figure 4: An example of when joint entropy maximization fails to yield statis- 
tically independent con~ponents. (a) Two independent input variables, x.1 and 
x2, having uniform (flat) pdf's, are input into an entropy maximization net- 
work with sigmoidal outputs. Because the input pdf's are not well matched 
to the nonlinearity, the "diagonal" solution (c) has higher joint entropy than 
the "independent-component" solution (b), despite its having nonzero mutual 
information between the outputs. The values given are for illustration purposes 
only. 
sigmoid networks be found by combining inputs in the way shown in 
Figure 4c (Kenji Doya, personal communication). Many real-world ana- 
log signals, including the speech signals we used, are super-gaussian. 
They have longer tails and are more sharply peaked than gaussians (see 
Fig. 5). For such signals, in our experience, maximizing the joint entropy 
in simple logistic sigmoidal networks always minimizes the mutual in- 
formation between the outputs (see the results in Section 5). 
We can tailor conditions so that the mutual information between out- 
puts is minimized, by constructing our nonlinear function, s ( ~ ) ,  so that 
it matches, in the sense of 2.31, the known pdf's of the independent 
variables. When this is the case, H(y) will be n~aximized [meaning f,,(y) 
will be the flat unit distribution] only when ~i carries one single hide- 
pendent variable. Any linear combination of the variables will produce 
a "more gaussian" f , ,(u) (due to central limit tendencies) and a resulting 
suboptimal (nonfla t) fy(y). 
We have presented, in Section 2.5, one possible "flexible" nonlinear- 
ity. This suggests a two-stage algorithm for performing independent 
component analysis. First, a nonlinearity such as that defined by 2.32 is 
optimized to approximate the cumulative distributions, 2.31, of known 
independent components (sources). Then networks using this nonlinear- 
Figure 5: Typical probability density functions for (a) speech, (b) rock music, 
and (c) gaussian white noise. The kurtosis of pdf's (a) and (b) was greater than 
0, and they would be classified as super-gaussian. 
ity are trained using the full weight matrix and bias vector generalization 
of 2.33 and 2.34: 
AWO p(l-y)-YY (4.3) 
This way, we can be sure that the problem of maximizing the mutual in- 
formation between the inputs and outputs, and the problem of minimiz- 
ing the mutual information between the outputs, have the same solution. 
This argument is well supported by the analysis of Nadal and Parga 
(1995), who independently reached the conclusion that in the low-noise 
limit, information maximization yields factorial codes when both the non- 
linear function, g(u) ,  and the weights, w, can be optimized. Here, we pro- 
vide a practical optimization method for the weights and a framework for 
optimizing the nonlinear function. Having discussed these caveats, we 
now present results for blind separation and blind deconvolution using 
the standard logistic function. 
5 Methods and Results 
The experiments presented here were obtained using 7 second segments 
of speech recorded from various speakers (only one speaker per record- 
ing). All signals were sampled at 8 kHz from the output of the auxiliary 
microphone of a Sparc-10 workstation. No special postprocessing was 
performed on the waveforms, other than that of normalizing their am- 
plitudes so they were appropriate for use with our networks (input values 
roughly between -3 and 3). The method of training was stochastic gra- 
dient ascent, but because of the costly matrix inversion in 2.14, weights 
were usually adjusted based on the summed AW's of small "batches" of 
length B, where 5 < B < 300. Batch training was made efficient using 
1144 Anthony J.  Bell and Terrence J.  Sejnowski 
vectorized code written in MATLAB. To ensure that the input ensemble 
was stationary in time, the time index of the signals was permuted. This 
means that at each iteration of the training, the network would receive 
input from a random time point. Various learning rates' were used (0.01 
was typical). I t  was helpful to reduce the learning rate during learning 
for convergence to good solutions. 
5.1 Blind Separation Results. The architecture in Figure 3a and the 
algorithm in 2.14 and 2.15 were sufficient to perform blind separation. A 
random mixing matrix, A, was generated with values usually uniformly 
distributed between -1 and 1. This was used to make the mixed time 
series, x, from the original sources, s. The matrices s and x, then, were 
both N x M matrices (N signals, M timepoints), and x was constructed 
from s by (1) permuting the time index of s to produce st, and (2) creating 
the mixtures, x, by multiplying by the mixing matrix: x = AS+. The 
unmixing matrix W and the bias vector wo were then trained. 
An example run with five sources is shown in Figure 6. The mix- 
tures, x, formed an incomprehensible babble. This unmixed solution 
was reached after around lo6 time points were presented, equivalent to 
about 20 passes through the complete time ~ e r i e s , ~  though much of the 
improvement occurred on the first few passes through the data. Any 
residual interference in u is inaudible. This is reflected in the permuta- 
tion structure of the matrix WA: 
As can be seen, only one substantial entry (boxed) exists in each row and 
column. The interference was attenuated by between 20 and 70 dB in all 
cases, and the system was continuing to improve slowly with a learning 
rate of 0.0001. 
In our most ambitious attempt, 10 sources (six speakers, rock music, 
raucous laughter, a gong, and the Hallelujah chorus) were successfully 
separated, though the fine tuning of the solution took many hours and 
required some annealing of the learning rate (lowering it with time). 
For two sources, convergence is normally achieved in less than one pass 
through the data (50,000 data points), and 011 a Sparc-10 on-line learning 
"The learning rate is defined as the proportio~~ality constant in 2.14-2.15 and 2.23- 
2.24. 
6This took on the order of 5 min on a Sparc-10. Two I~ii~iCIre~i data points were 
presented at a time in a "batch," then tlie weights were changed wit11 a learning rate 
of 0.01 based on the sum of tlie 200 accumulated Ai~ls. 
Information-Maximization 11 45 
Figure 6: A 5 x5  information maximization network performed blind separation, 
learning the unmixing matrix W. The outputs, u, are shown here unsquashed 
by the sigmoid. They can be visually matched to their corresponding sources, S ,  
even though their order was different and some (for example ~ 1 , )  were recovered 
as negative (upside down). 
can occur at twice the speed at which the sounds themselves are played. 
Real-time separation for more than, say, three sources, may require fur- 
ther work to speed convergence, or special-purpose hardware. 
In all our attempts at blind separation, the algorithm has failed under 
only two conditions: 
1. when more than one of the sources were gaussian white noise, and 
2. when the mixing matrix A was almost singular. 
Both are understandable. First, no procedure can separate out indepen- 
dent gaussian sources since the sum of two gaussian variables has itself 
a gaussian distribution. Second, if A is almost singular, then any unmix- 
ing W must also be almost singular, making the learning in 2.14 quite 
unstable in the vicinity of a solution. 
11 46 An thony  J .  Bcll 2 n d  Terrence 1. Sejnowsk~ 
In contrast with these results, our experience with tests on the H-J 
network of Jutten and lierault (1991) has been that i t  occasionally fails 
to converge for two sources and only rarely converges for three, on the 
same speech and music signals we used for separating 10 sources. Cohen 
and Andreou (1992) report separation of up to slx sinusoidal signals of 
different frequencies using analog VLSI H-J networks. In addition, In 
Cohen and Andreou (1995), they report results wlth mixed sine waves 
and noise in 5 x 5 networks, but no separation results for more than two 
speakers. 
IHow does convergence time scale with the number of sources, N? 
The difficulty in answering this question is that different learning rates 
are required for different N and for different stages of convergence. We 
expect to address this issue in future work, and employ useful heuristic 
or explicit second-order techniques (Battiti 1992) to speed convergence. 
For now, we present rough estimates for the number of epochs (each 
containing 50,000 data vectors) required to reach an average signal to 
noise ratio on the ouput channels of 20 dB. At such a level, approximately 
80% of each output channel amplitude is devoted to one signal. These 
results were collected for mixing matrices of unit determinant, so that 
convergence would not be hampered by having to find an unmixing 
matrix with especially large entries. Therefore these convergence times 
may be lower than for randomly generated matrices. The batch size, B, 
was in each case 20. 
The average numbers of epochs to convergence (over 10 trials) and 
the computer times consumed per epoch (on a Sparc-10) are given in the 
following table: 
No. of sources, 
N 2 3 4 5 6  7 8 9 10 
Learningrate 0.1 0.1 0.1 0.05 0.05 0.025 0.025 0.025 0.0125 
Epochs to 
convergence < 1 < 1 2.25 5.0 9.0 9.2 13.8 14.9 30.6 
Time in 
secs./epoch 12.1 13.3 14.6 15.6 16.9 18.4 19.9 21.7 23.6 
5.2 Blind Deconvolution Results. Speech signals were convolved 
with various filters and the learning rules in 2.23 and 2.24 were used to 
perform blind deconvolution. Some results are shown in Figure 7. The 
convolving filters generally contained some zero values. For example, 
Figure 7e is the filter [0.8,0,0,0,1]. In addition, the taps were sometimes 
adjacent to each other (Fig. 7a-d) and sometimes spaced out in time 
(Fig. 7i-1). The "leading weight" of each filter is the rightmost bar in 
each histogram. 
For each of the three experiments shown in Figure 7, we display the 
convolving filter, a ( t ) ,  the truncated inverting filter, 7uldeal(t), the filter 
produced by our algorithm, zu(t), and the convolution of z u ( t )  and n ( f ) .  
MANY ECHOES ! task I NTHITENZNG / BARREL EFFECT 
L - - -  I .. - -1 
no. of , I 
; taps 15 
. - - - 
, tap I ( = 0.125ms) 
, spacing , 
C - 
i filter 
I 
i ideal 
I deconvolv- 
I ingfilter 
1 'wide01 ' 
i 
I-- 
1 learnt 
I deconvolv- 
1 ingfiner 
I!?-- 
! 
'1 (b) 
i 
Figure 7: Blind deconvolution results. (a,e,i) Filters used to convolve speech 
signals, (b,f,j) their inverses, (c,g,k) deconvolving filters learned by the algo- 
rithm, and (d,h,l) convolution of the convolving and deconvolving filters. See 
text for further explanation. 
The latter should be a delta-function (i.e., consist of only a single high 
value, at the position of the leading weight) if zu( t )  correctly inverts a ( [ ) .  
The first example, Figure 7a-d, shows what happens when one tries 
to "deconvolve" a speech signal that has not actually been corrupted [fil- 
ter a ( t )  is a delta function]. If the tap spacing is close enough (in this 
case, as close as the samples), the algorithm learns a whitening filter 
(Fig. 7c), which flattens the amplitude spectrum of the speech right u p  to 
the Nyquist limit, the frequency corresponding to half the sampling rate. 
The spectra before and after such "deconvolution" are shown in Figure 8. 
Whitened speech sounds like a clear s l~arp  version of the original signal 
since the phase structure is preserved. Using all available frequency lev- 
1148 Anthony J.  Bell and Terrence J .  Sejnowski 
Figure 8: Amplitude spectra of a speech signal (a)  before and (b) after the 
"wliite~~ing" performed in Figure 7c. 
els equally is another example of maximizing the information throughput 
of a channel. 
This shows that when the original signal is not white, we may recover 
a whitened version of it, rather than the exact original. However, when 
the taps are spaced out further, as in Figure 7e-1, there is less opportunity 
for simple whitening. 
In the second example (Fig. 7e) a 6.25-msec echo is added to the signal. 
This creates a mild audible "barrel e f fe~ t . "~  Because the filter (Fig. 7e) 
is finite in length, its inverse (Fig. 7f) is infinite in length, shown here 
truncated. The inverting filter learned in Figure 7g resembles it, though 
the resemblance tails off toward the left since we are really learning an 
optimal filter of finite length, not a truncated infinite filter. The resulting 
deconvolution (Fig. 7h) is quite good. 
The cleanest results, though, come when the ideal deconvolving fil- 
ter is of finite length, as in our third example. A set of exponentially 
decaying echoes spread out over 275 msec (Fig. 7i) may be inverted by 
a two-point filter (Fig. 7j) with a small decaying correction on its left, 
an artifact of the truncation of the convolving filter (Fig. 7i). As seen in 
Figure 7k, the learned filter corresponds almost exactly to the ideal one, 
and the deconvolution in Figure 71 is almost perfect. This result shows 
the sensitivity of the learning algorithm in cases where the tap-spacing is 
great enough (12.5 msec) that simple whitening does not interfere notice- 
ably with the deconvolution process. The deconvolution result, in this 
case, represents an improvement of the signal-to-noise ratio from -23 to 
12 dB. In all cases, convergence was relatively rapid, with these solutions 
being produced after on the order of 70,000 data points were presented, 
7An example of the barrel effect is the acoustic echoes heard when someone talks 
into a "speaker-phone." 
which amounts to 2 sec training on 8 sec of speech, amounting to four 
times as fast as real-time on a Sparc-10. 
5.3 Combining Separation and Deconvolution. The blind separa- 
t~on  rules in 2.14 and 2.15 and the blind deconvolution rules in 2.23 and 
2.24 can be easily combined. The objective then becomes the n~aximiza- 
tion of the log of a Jacobian with local lower triangular structure. This 
yields exactly the learning rule one would expect: the leading weights 
in the filters follow the blind separation rules and all the others follow 
a decorrelation rule similar to 2.24 except that now there are tapped 
weights w,k, between an input x,(t - k) and an output y,(t). 
We have performed experiments with speech signals in which signals 
have been simultaneously separated and deconvolved using these rules. 
We used mixtures of two signals with convolution filters like those in 
Figure 7e and 7i, and convergence to separated, deconvolved speech 
was almost perfect. 
6 Discussion 
We will consider these techniques first in the context of previous informa- 
tion-theoretic approaches within neural networks, and then in the context 
of related approaches to "blind" signal processing problems. 
6.1 Comparison with Previous Work on Information Maximization. 
Many authors have formulated optimality criteria similar to ours, for 
both neural networks and sensory systems (Barlow 1989; Atick 1992; 
Bialek et al. 1991). However, our work is most similar to that of Linsker, 
who in 1989 proposed an "infomax" principle for linear mappings with 
various forms of noise. Linsker (1992) derived a learning algorithm for 
maximizing the mutual information between two layers of a network. 
This "infomax" criterion is the same as ours (see 2.1). However, the 
problem as formulated here is different in the following respects: 
1. There is no noise, or rather, there is no noise r d c l  in this system. 
2. There is no assumption that inputs or outputs have gaussian statis- 
tics. 
3. The transfer function is in general nonlinear. 
These differences lead to quite a different learning rule. Linsker's 1992 
rule uses (for input signal X and output Y) a Hebbian term to maximize 
H(Y) when the network receives both signal and noise, an anti-Hebbian 
term to minimize H(Y I X)  when the system receives only noise, and an 
anti-Hebbian lateral interaction to decorrelate the outputs Y. When the 
network is deterministic, however, the H(Y 1 X) term does not contribute. 
A deterministic linear network can increase ~ t s  inforn~ation throughput 
witl~out bound, as the [WJ]- '  term in 2.14 suggests. 
1150 Anthony J .  Bell and Terrence J .  Sejnowski 
However, the information capacity in the networks we have consld- 
ered is bounded, not by noise, but by the saturation of a squashing func- 
tjon. Our network shares with Linsker's the property that this bound 
gives rise to an anti-Hebbian term in the learning rule. This is true for 
various squashing functions (see Table I in the Append~x). 
This nonlinear, non-gaussian, deterministic formulation of the "in- 
fomax" problem leads to more powerful algorithms, since, as demon- 
strated, the nonlinear function enables the network to compute with 
non-gaussian statistics, and find higher-order forms of redundancy in- 
herent in the inputs. (As emphasized in Section 3, linear approaches are 
inadequate for solving the problems of blind separation and blind de- 
convolution.) These observations also apply to the approaches of Atick 
and Redlich (1993) and Bialek et al. 1991 1. 
The problem of information maximization through nonlinear sigmoi- 
dal neurons has been considered before without a learning rule actually 
being proposed. Schraudolph et al. (1991), in work that inspired this 
approach, considered it as a method for initializing weights in a neural 
network. Before this, Laughlin (1981) used it to characterize as optimal, 
the exact contrast sensitivity curves of interneurons in the insect's com- 
pound eye. Various other authors have considered unsupervised learning 
rules for nonlinear units, without justifying them in terms of information 
theory (see Karhunen and Joutsensalo 1994, and references therein). 
Several recent papers, however, have touched closely on the work 
presented in this paper. Deco and Brauer (1995) use cumulant expansions 
to approximate mutual information between outputs. Parra and Deco 
(1995) use symplectic transforms to train no~zlinear informa tion-preserving 
mappings. Most notably, Bararn and Rot11 (1994) perform substantially 
the same analysis as ours, but apply their networks to probability density 
estimation and time series forecasting. None of this work was known to 
us when we developed our approach. 
Finally, another group of information-theoretic algorithms has been 
proposed by Becker and Hinton (1992). These en~ploy nonlinear net- 
works to nzaxinzize mutual information between different sets of outputs. 
This increasing of redundancy enables the network to discover invariants 
in separate groups of inputs (see also Schraudolph and Sejnowski 1992). 
This is, in a sense, the opposite of our objective, though some way may 
be found to view the two in the same light. 
6.2 Comparison with Previous Work on Blind Separation. As in- 
dicated in Section 3, approaches to blind separation and blind decon- 
volution have divided into those using nonlinear functions (Jutten and 
Herault 1991; Bellini 1994) and those using explicit calculations of cumu- 
lants and polyspectra (Comon 1994; Hatzinakos and Nikias 1994). We 
have shown that an information maximization approach can provide a 
theoretical framework for approaches of the former type. 
Information-Maxiniization 1151 
In the case of blind separation, the architecture of our N + N network, 
although i t  is a fecdforward network, maps dlrectlp onto that of the 
recurrent Herault-Jutten network. The relationship between our weight 
matrix, W, and the H-J recurrent weight matrix, WIII ,  can be written as 
W = (1 t- W14,)- ' ,  where I is the identity matrix. From thls we may write 
so that our learning rule, 2.14 forms part of a rule for the recurrent H-J 
network. Unfortunately, this rule is complex and not obviously related 
to the nonlinear anti-Hebbian rule proposed for the H-J net: 
where g and 1.1 are odd nonlinear functions. I t  remains to conduct a de- 
tailed performance comparison between 6.2 and the algorithm presented 
here. We have performed many simulations in which the H-J net failed 
to converge, but because there is substantial freedom in the choice of 8 
and h in 6.2, we cannot be sure that our choices were good ones. 
We now compare the convergence criteria of the two algorithms to 
show how they are related. The explanation (Jutten and Herault 1991) 
for the success of the H-J network is that the Taylor series expansion of 
g ( u ) l ~ ( u ) ~  in 6.2 yields odd cross moments, such that the weights stop 
changing when 
for all output unit pairs i # j, for p. q = 0.1.2,3.  . ., and for the coefficients 
b,,,, coming from the Taylor series expansion of g and h. This, they argue, 
provides an "approximation of an independence test." 
This can be compared with the convergence criterion of our algorithm. 
For the tan11 nonlinearity, we derive 
This converges in the mean (ignoring bias weights and assuming x to be 
zero mean) when: 
This condition can be readily rewritten (multiplying it by WT and using 
u = Wx) as 
I = 2(tanh(u)uT) (6.6) 
Since tanh is an odd function, its series expansion is of the form tanh(l0 = 
C, b,u2pf1, the b, being coefficients, and thus the convergence criterion 6.6 
amounts to the condition 
Anthony J .  Bell and Terrence J .  Sejnowski 
for all output unit pairs I # 1, for p = 0.1.2.3.  ., and for the coefficients 
b,,,, coming from the Taylor series expansion of the tan11 function. 
The convergence criterion 6.7 lnvolves fewer cross-moments than that 
of 6.3 and in this sense may be viewed as a less restrictive condition. More 
relevant, however, is the fact that the weighting, or relative importance, 
b,,,, of the moments in 6.7 is determined by the lnformation-theoretic 
objective function in conjunction with the nonlinear function 8, while in 
6.3, the b,,,,, values are accidents of the particular nonlinear functions, 
g and 17, that we choose. These observations may help to explain the 
existence of spurious solutions for H-J, as revealed, for example, in the 
stability analysis of Sorouchyari (1991). 
Several other approaches to blind separation exist. Comon (1994) 
expands the mutual information in terms of cumulants up to order 4, 
amounting to a truncation of the constraints in 6.7. A similar proposal 
that combines separation with deconvolution is to be found in Yellin and 
Weinstein (1994). Such cumulant-based methods seem to work, though 
they are complex. It is not clear how the truncation of the expansion af- 
fects the solution. In addition, Molgedey and Schuster (1994) proposed a 
novel technique that uses time-delayed correlations to constrain the solu- 
tion. Finally, Hopfield (1991) has applied a variant of the H-J architecture 
to odor separation in a model of the olfactory bulb. 
6.3 Comparison with Previous Work on Blind Deconvolution. In 
the case of blind deconvolution, our approach most resembles the "Buss- 
gang" family of techniques (Bellini 1994; Haykin 1991). These algorithms 
assume some knowledge about the input distributions to sculpt a non- 
linearity that may be used in the creation of a memoryless conditional 
estimator for the input signal. In our notation, the nonlinearly trans- 
formed output, y, is exactly this conditional estimator: 
and the goal of the system is to change weights until u ,  the actual output, 
is the same as y, our estimate of s. An error is thus defined, c i m r  = 
y - 11, and a stochastic weight update rule follows directly from gradient 
descent in mean-squared error. This gives the blind deconvolution rule 
for a tapped delay weight at time t [compare with 2.241: 
If g ( u )  = tanh(u) then this rule is very similar to 2.24. The only difference 
is that 2.24 contains the term tanh(ti) where 6.9 has the term u - tanh(u), 
but as can be easily verified, these terms are of the same sign at all limes, 
so the algorithms should behave similarly. 
Information-Maximization 1153 
The theoretical justifications for the Bussgang approaches are, how- 
ever, a little obscure, and, as with the Herault-Jutten rules, part of their 
appeal derives from the'fact h i t  they have been'sl~own to work in many 
circumstances. The primary difficulty lies in the consideration, 6.8, of 
y as a conditional estimator for s. Why, a priori, should we consider 
a nonlinearly transformed output to be a conditional estimator for the 
unconvolved input? The answer comes from Bayesian considerations. 
The output, r r ,  is considered to be a noisy version of the original signal, 
5 .  Models of the pdf's of the original signal and this noise are then con- 
structed, and Bayesian reasoning yields a nonlinear conditional estimator 
of s from u, which can be quite complex (see 20.39 in Haykin 1991). I t  is 
not clear, however, that the "noise" introduced by the convolving filter, 
a, is well modeled as gaussian. Nor will we generally have justifiable es- 
timates of its mean and variance, and how they compare with the means 
and variances of the input, s. 
In short, the selection of a nonlinearity, 8, is a black art. Haykin 
does note, though, that in the limit of high convolutional noise, g can 
be well approximated by the tanh sigmoid nonlinearity (see 20.44 in 
Haykin 1991), exactly the nonlinearity we have been using. Could i t  be 
that the success of the Bussgang approaches using Bayesian conditional 
estimators is due less to the exact form of the conditional estimator than 
to the general goal of squeezing as much information as possible through 
a sigmoid function? As noted, a similarity exists between the information 
maximization rule 2.24, derived without any Bayesian modeling, and the 
Bussgang rule 6.9 when convolutional noise levels are high. This suggests 
that the higher-order moments and information maximization properties 
may be the important factors in blind deconvolution, rather than the 
minimization of a contrived error measure, and its justification in terms 
of estimation theory. 
! 
1 Finally, we note that the idea of using a variable-slope sigmoid func- 
i tion for blind deconvolution was first described in Haykin (1992). 
! 
6.4 Conclusion. In their current forms, the algorithms presented here 
are limited. First, since only single layer networks are used, the optimal 
mappings discovered are constrained to be linear, while some multilayer 
system could be more powerful. With layers of hidden units, the Jacobian 
in 2.13 becomes more complicated, as do the learning rules derived from 
it. Second, the networks require, for N inputs, that there be N outputs, 
which makes them unable to perform the computationally useful tasks 
of dimensionality reduction or optimal data compression. Third, real- 
istic acoustic environments are characterized by substantial propagation 
delays. As a result, blind separation techniques without adaptive time 
delays do not work for speech recorded in a natural environment. A11 
approach to this problem using "ber?mforming" may be found in Li and 
Sejnowskil(l994). Fourth, no account has yet been given for cases where 
there is known noise in the inputs. The beginning of such an analysis 
11 54 Aiitlioiiy J .  Bell and Terrence J .  Sejnowski 
may be found in Nadal and Parga (1995) and Schuster (19921, and i t  may 
be possible to define learning rules for such cases. 
Finally, and most seriously from a biological point of view, the lean- 
ing rule in equation 2.16 is decidedly nonlocal. Each "neuron" must 
know the cofactors either of all the weights entering it, or all those leav- 
ing it. Some architectural trick may be found that enables information 
maximization to take place using only local information. The existence 
of local learning rules such as the H-J network suggests that i t  may be 
possible to develop local learning rules approximating the nonlocal ones 
derived here. For now, however, the network learning rule in 2.14 re- 
mains unbiological. 
Despite these concerns, we believe that the information maximization 
approach presented here could serve as a unifying framework that brings 
together several lines of research, and as a guiding principle for further 
advances. The principles may also be applied to other sensory modal- 
ities such as vision, where Field (1994) has recently argued that phase- 
insensitive information maximization (using only second-order statistics) 
is unable to predict local (non-Fourier) receptive fields. 
Appendix: Proof of Learning Rule (2.14) 
Consider a network with an input vector x, a weight matrix W, a bias 
vector wo, and a nonlinearly transformed output vector y = g(u), u = 
Wx + wo. Providing W is a square matrix and g is an invertible function, 
the multivariate probability density function of y can be written (Papoulis 
1984, eq. 6-63): 
where I J I  is the absolute value of the Jacobian of the transformation. This 
simplifies to the product of the determinant of the weight matrix and the 
derivatives, yi, of the outputs, y,, with respect to their net inputs: 
N 
! = (det W) IT Y: (A.2) 
r=l 
For example, in the case where the nonlinearity is the logistic sigmoid, 
We can perform gradient ascent in the information that the outputs 
transmit about inputs by noting that the information gradient is the same 
as the entropy gradient 2.2 for invertible deterministic mappings. The 
joint entropy of the outputs is 
= E[ln I J I ]  - E[ln f,(x)] from A.l (A.5) 
Table 1:  Different Nonlinearities, g(ul), Give Different Slopes and Anti-Hebbinn 
Terms That Appear When Deriving I~iforniation Maximization Rules Using 
equation A.6. 
Function: Slope: Anti-Hebb term: 
Weights can be adjusted to maximize H ( y ) .  As before, they only affect 
the E[ln lJl] term above, and thus, substituting A.2 into A.5: 
dH B d 6' 
AW C( - = - In IJI = --- In I det WI + ---Inn 
BW aw aw DW I 
The first term is the same regardless of the transfer function, and since 
det W = El wll cof w,, for any row i (cof zlill being the cofactor of zo,,), we 
have, for a single weight: 
d cofwii 
-In IdetWI = --- 
dzoil det W 
For the full weight matrix, we use the definition of the inverse of a matrix, 
and the fact that the acljoint matrix, adj W, is the transpose of the matrix 
of cofactors. This gives 
d 
-1n I det WI = (adj W)' = [wT] -' 
DW det W 
For the second term in A.6, we note that the product, 111 n, y;, splits 
up into a sum of log-terms, only one of which depends on a particular 
zu,,. The calculation of this dependency proceeds as in the one-to-one 
mapping of 2.8 and 2.9. Different squasl~ing functions give different 
forms of anti-Hebbian terms. Some examples are given in Table 1. 
Thus, for units computing weighted sums, the il~formation-maximiza- 
tion rule consists of an a i l t i - r . c ~ i l l n d n ~ z c  term, which always has the form 
of A.8, and an mti-Hebb term, which keeps the unit from saturating. o 
11 56 Anthony J.  Bell and Terrence J .  Sejnowski 
Several points are wort11 noting in Table 1: 
1. The logistic (A) and tanh (B) functions produce anti-Hebb terms 
that use higher-order statistics. The other functions use the net 
input u, as their output variable, rather than the actual, nonlinearly 
transformed output y,. Tests have shown the erf function (D) to be 
unsuitable for blind separation problems. In fact, i t  can be shown to 
converge in the mean when (compare with 6.6) I = 2(uuT), showing 
clearly that i t  is just a decorrelator. 
2. The generalized cumulative gaussian function (E) has a variable ex- 
ponent, r. This can be varied between 0 and cm to produce squash- 
ing functions suitable for symmetrical input distributions with very 
high or low kurtosis. When r is very large, then g(u,) is suitable for 
unit input distributions such as those in Figure 4. When close to 
zero, it fits high kurtosis input distributions, that are peaked with 
long tails. 
3. Analogously, it is possible to define a generalized "tanh" sigmoid 
(F), of which the hyperbolic tangent (B) is a special case (I. = 2). The 
values of function F can in general only be attained by numerical 
integration (in both directions) of the differential equation, gl(u) = 
1 - Jg(u)lr, from a boundary condition of g(0) = 0. Once this is done, 
however, and the values are stored in a look-up table, the slope and 
anti-Hebb terms are easily evaluated at each presentation. Again, 
as in Section 2.5, it should be useful for data that may have flat 
( r  > 2 )  or peaky ( r  < 2) pdf's. 
4. The learning rule for a gaussian radial basis function node (G) 
shows the unsuitability of nonmonotonic functions for information 
maximization learning. The 11, term on the denominator would 
make such learning unstable when the net input to the unit was 
zero. 
Acknowledgments 
This research was supported by a grant from the Office of Naval Research. 
We are much indebted to Nicol Schraudolph, who not only supplied 
the original idea in Figure 1 and shared his unpublished calculations 
(Schraudolph et a/. 1991), but also provided detailed criticism at every 
stage of the work. Many helpful observations also came from Paul Viola, 
Barak Pearlmutter, Kenji Doya, Misha Tsodyks, Alexandre Pouget, Peter 
Dayan, Olivier Coenen, and Iris Ginzburg. 
References 
Atick, J. J .  1992. Could information theory provide an ecological theory of 
sensory processing? Netzuork 3, 213-251. 
Atick, J .  J . ,  and Redlicli, A. N. 1993. Convergent algorithm tor sensory receptive 
field development. Nilrrral Coitip. 5, 45-60. 
Baram, Y., and Roth, Z. 1994. Multi-dimensional density shaping by sigmoidal 
networks with application to classification, estimation and forecasting. CIS 
report No. 9420, October 1994, Centre for Intelligent systems, Dept. of Com- 
puter Science, Technion, Israel Institute of Technology, Haifa, submitted for 
publication. 
Barlow, H. B. 1961. Possible principles underlying the transformation of sensory 
messages. In SeilsoryCot1lii7ui1icafioil, W. A. Rosenblith, ed., pp. 217-234. MIT 
Press, Cambridge, MA.  
Barlow, H. B. 1989. Unsupervised learning. Neural Coinp. 1, 295-311. 
Barlow, H. B., and Foldisk, P. 1989. Adaptation and decorrelation in the cortex. 
In The Coinputiizg Neuron, R. Durbin et al., eds., pp. 54-72. Addison-Wesley, 
Reading, MA. 
Battiti, R. 1992. First- and second-order methods for learning: Between steepest 
descent and Newton's method. Neural Comp. 4(2), 141-166. 
Becker, S., and Hinton, G. E. 1992. A self-nrganising neural network that dis- 
covers surfaces in random-dot stereograms. Nnture (Loi~don) 355, 161-163. 
Bell, A. J., and Sejnowski, T. J. 1995. A nonlinear information maximization 
algorithm that performs blind separation. I11 Adzlances in Neurnl In~ormntion 
Processing S y s t e m  7, G. Tesauro et al., eds., pp. 467-474. MIT Press, Cam- 
bridge, MA. 
Bellini, S. 1994. Bussgang techniques for blind deconvolution and equalisation. 
In Blind Deconvolution, S. Haykin, ed. Prentice-Hall, Englewood Cliffs, NJ. 
Bialek, W., Ruderman, D. L., and Zee, A. 1991. Optimal sampling of natural 
images: A design principle for the visual system? In Advances in Nel~ral 
Ii~forn~ation Processing S!/stems 3. R. P. Lippmann et al., eds., pp. 363-369. 
Morgan Kaufmann, San Mateo, CA. 
Burel, G. 1992. Blind separation of sources: A nonlinear neural algorithm. 
Neuml Netzuorks 5, 937-947 
Cohen, M. H., and Andreou, A. G. 1992. Current-mode subthreshold MOS 
implementation of the Herault-Jutten autoadaptive network. IEEE 1. Solid- 
Stafe Circuits 27(5), 714-727. 
Cohen, M. H., and Andreou, A. G. 1995. Analog CMOS integration and exper- 
imentation with an autoadaptive independent component analyzer. l E E E  
Trans. Circuits System-11: Aimlog Digital Signal Process. 42(2), 65-77. 
Comon, P. 1994. Independent component analysis, a new concept? Sipml  Pro- 
CCSS. 36, 287-314. 
Comon, P., Jutten, C., and Herault, J. 1991. Blind separation of sources, part 11: 
Problems statement. S i p a l  Process. 24, 11-21. 
Cover, T. M., and Thomas, J. A. 1991. Elei?zents of lnforinntion Theor!/. John Wiley, 
New York. 
Deco, G., and Brauer, W. 1995. Non-linear higher-order statistical decorrelation 
by volunie-conserving neural architectures. Ncurul Nefr iwks ,  in press. 
Field, D. J.  1994. What is the goal of sensory coding? Nefrral Cotnp. 6, 559-601. 
Hatzinakos, D., and Nikias, C. L. 1994. Blind equalisation based 011 higher-order 
1158 Anthony J .  Bell and Terrence J .  Sejnowski 
statistics. In Biirrrl Dccclrrzlc~llrtiorr, S. [Haykin, ed., pp. 181-2%. Prentice-I-[all, 
Englewood Cliffs, NJ. 
Haykin, S. 1991. .Adnptiz~c Filter Tl~cory, 2nd ed. Prentice-Hall, Englewood Cliffs, 
NJ. 
iaykin, S. 1992. Blind equalisation forn~ulated as a. self-organized learning 
process. Procredirlgs ot thc 26/11 Asilorrlnr Confercvic~, or1 S i~rrr~ls ,  Systcrr~s nrlil 
Cor~rprrtc~r~. Pacific Grove, CA. 
iaykin, S. (ed.) 1994a. Bliri~f Dccorrz~olrrtioi~. Prentice-Hall, Englewoocl Cliffs, 
NJ. 
iaykin, S. (ed.) 1994b. Ncuri71 Netzcwks: A Corizprt.l~cr~.siz~c Forrrr~latior~. Macmillan, 
New York. 
Herault, J., and Jutten, C. 1986. Space or time adaptive signal processing by 
n,eural network models. In Neural Netzoorks for Conzplrtirrg: AIP Corzfercfzce 
~~roceedings 251, J.  S. Denker, ed. American Institute for Physics, New York. 
Hopfield, J. J. 1991. Olfactory computation and object perception. Proc. Natl. 
Acad. Sci. U.S .A.  88, 64624466. 
Jutten, C., and Herault, J. 1991. Blind separation of sources, part I: An adaptive 
algorithm based on neuromimetic architecture. Sigml  Process. 24, 1-10. 
Karhunen, J., and Joutsensalo, J. 1994. Representation and separation of signals 
using nonlinear PCA type learning. Neural Netzoorks 7(1), 113-127. 
Laughlin, S. 1981. A simple coding procedure enhances a neuron's information 
capacity. Z. Naturforsch. 36, 910-912. 
Li, S., and Sejnowski, T. J.  1994. Adaptive separation of mixed broadband 
sound sources with delays by a beamforming Herault-Jutten network. IEEE 
1. Ocearzic Erzg. 20(1), 73-79. 
Linsker, R. 1989. An application of the principle of maximum information 
preservation to linear systems. In Advances in Nelcrnl lfzforrnntioi? Processir~g 
Systenzs 2 ,  D. S. Touretzky, ed. Morgan Kaufmann, San Mateo, CA. 
Linsker, R. 1992. Local synaptic learning rules suffice to maximize mutual in- 
formation in a linear network. Neural Conzp. 4, 691-702. 
Molgedey, L., and Schuster, H. G. 1994. Separation of independent signals using 
time-delayed correlations. Plzys. Rev. Lett. 72(23), 3634-3637. 
Nadal, J-P., and Parga, N. 1994. Non-linear neurons in the low noise limit: A 
factorial code maximizes information transfer. Netzuork 5, 565-581. 
Papoulis, A. 1984. Probability, Rnrzdom Variables and Stoclzastic Processes, 2nd ed. 
McGraw-Hill, New York. 
Parra, L., Deco, G., and Miesbach, S. 1995. Redundancy reduction with infor- 
ma tion-preserving maps. Net work 6, 61 -72. 
Platt, J .  C., and Faggin', F. 1992. Networks for the separation of sources that 
are superimposed and delayed. In Advaizces iiz Ne~rral Infortnation Processiq 
Systetns 4. J. E.  Moody et al., eds., pp. 730-737. Morgan Kaufmann, San 
Mateo, CA. 
Plumbley, M. D., and Fallside, F. 1988. An information-theoretic approach to 
unsupervised connectionist models. In Proceediirgs of the 1988 Coriilectior-rist 
Models Strmmer School, 239-245. D. Touretzky, G. Hinton, and T. Sejnowski, 
eds. Morgan Kaufmann, San Mateo, CA. 
~c~lmid l iuber ,  J .  1992. Learning factorial coclcs by predictability rninimiz<?tion. 
Ncrirwl Corrrp. 4(6), 863-887. 
Schraudolph, N.  N., and Scjno~vski, T. J .  1992. Competitive anti-Hebbian learn- 
ing of invariants. In Riizlnrrccs irr Ncrrrnl III)OI-rrrrltior~ Proic~ssirr,y S!/slcrrrs 4 ,  
J. E. Moody et al., eds. Morgan Kaufmann, San Mateo, CA. 
Scliraudolph, N .  N., Hart, W. E., and Uelew, I?. K. 1991. Optimal intormition 
flow in sig~noidai neurons. Unpublished manuscript. 
Schuster, H.  C.  1992. Learning by maximizing the intormation transter through 
nonlinear noisy neurons and "noise breakdown", Plrys. Rc'i'. A 46(4), 2131- 
21 38. 
Sorouchyari, E. 1991. Blind separation of sources, part I I I :  Stability analysis. 
S igml  Process. 24(1), 11-20. 
Vittoz, E. A., and Arreguit, X. 1989. CMOS integration of Herault-lutten cells 
for separation of sources. In A r l n l o ~  VLSI fi~~plcrirciltntio~r I$ Nerrrnl S!/stcrrzs, 
57-84. C. Mead and M. Isrnail, eds.  Kluwer, Boston. 
Yellin, D., and Weinstein, E. 1994. Criteria for multichannel signal separation. 
l E E E  firms. S igml  Process. 42(8), 21 58-2168. 
Received October 10, 1994; accepted February 14, 1995 

