A new signature scheme based on (U |U + V ) codes
Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
Inria, EPI SECRET
2 rue Simone Iff, Paris 75012, France
{thomas.debris,nicolas.sendrier,jean-pierre.tillich}@inria.fr
Abstract. We present here a new code-based digital signature scheme. This scheme uses
(U |U + V ) codes, where both U and V are random. We prove that the scheme achieves
existential unforgeability under adaptive chosen message attacks under two assumptions from
coding theory, both strongly related to the hardness of decoding in a random linear code.
The proof imposes a uniform distribution on the produced signatures, we show that this
distribution is easily and efficiently achieved by rejection sampling. Our scheme is efficient
to produce and verify signatures. For a (classical) security of 128 bits, the signature size is
less than one kilobyte and the public key size a bit smaller than 2 megabytes. This gives the
first practical signature scheme based on binary codes which comes with a security proof and
which scales well with the security parameter: it can be shown that if one wants a security
level of 2λ, then signature size is of order O(λ), public key size is of size O(λ2), signature
generation cost is of order O(λ3), whereas signature verification cost is of order O(λ2).
Keywords: code-based cryptography, digital signature scheme, decoding algorithm.
1 Introduction
Code-based signature schemes. It is a long standing open problem to build an efficient and
secure signature scheme based on the hardness of decoding a linear code which could compete in
all respects with DSA or RSA. Such schemes could indeed give a quantum resistant signature for
replacing in practice the aforementioned signature schemes that are well known to be broken by
quantum computers. A first partial answer to this question was given in [CFS01]. It consisted in
adapting the Niederreiter scheme [Nie86] for this purpose. This requires a linear code for which
there exists an efficient decoding algorithm for a non-negligible set of inputs. This means that if
H is an r × n parity-check matrix of the code, there exists for a non-negligible set of elements
s in {0, 1}r an efficient way to find a word e in {0, 1}n of smallest Hamming weight such that
HeT = sT . In such a case, we say that s, which is generally called a syndrome in the literature,
can be decoded. To sign a message m, a hash function H is used to produce a sequence s0, . . . , s`
of elements of {0, 1}r. For instance s0 = H (m) and si = H (s0, i) for i > 0. The first si that can
be decoded defines the signature of m as the word e of smallest Hamming weight such that
HeT = sTi .
The CFS signature scheme. The authors of [CFS01] noticed that very high rate Goppa codes
are able to fulfill this task, and their scheme can indeed be considered as the first step towards
a solution of the aforementioned problem. Moreover they gave a security proof of their scheme
relying only on the assumption that two problems were hard, namely (i) decoding a generic linear
code and (ii) distinguishing a Goppa code from a random linear code with the same parameters.
However, afterwards it was realized that the parameters proposed in [CFS01] can be attacked by
an unpublished attack of Bleichenbacher. The significant increase of parameters needed to thwart
the Bleichenbacher attack was fixed by a slight variation [Fin10]. However, this modified scheme
is not able to fix two other worrying drawbacks of the CFS scheme, namely
ar
X
iv
:1
70
6.
08
06
5v
1 
 [
cs
.C
R
] 
 2
5 
Ju
n 
20
17
2 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
(i) a lack of security proof in light of the distinguisher of high rate Goppa codes found in [FGO+11]
(see also [FGO+13] for more details) which shows that the hypotheses used in [CFS01] to give
a security proof of the signature scheme were not met,
(ii) poor scaling of the parameters when security has to be increased. [CFS01] is namely based
on t-error correcting Goppa codes of length 2m. The complexity S = 2λ of the best attack
is S = 2tm/2, the public key is of size K = tm2m, obtaining a signature needs about t!t2m3
operations. Here the factorial t! term accounts for the number of syndromes si that have to be
computed before finding one of them that can be decoded. Keeping a reasonable signature cost
requires that we fix t to be small (say smaller than 12). In this case, the security parameter S
is only polynomial in the key size K : S ≈ Kt/2.
Other code-based signature schemes. Other signature schemes based on codes were also
given in the literature such as for instance the KKS scheme [KKS97, KKS05] or its variants
[BMS11, GS12]. But they can be considered at best to be one-time signature schemes in the light
of the attack given in [COV07] and great care has to be taken to choose the parameters of these
schemes as shown by [OT11] which broke all the parameters proposed in [KKS97, KKS05, BMS11].
There has been some revival of the CFS strategy [CFS01], by choosing other code families. The
new code families that were used are LDGM codes in [BBC+13], i.e. codes with a Low Density
Generator Matrix, or (essentially) convolutional codes [GSJB14]. There are still some doubts that
there is a way to choose the parameters of the scheme [GSJB14] in order to avoid the attack [LT13]
on the McEliece cryptosystem based on convolutional codes [LJ12] and the LDGM scheme was
broken in [PT16].
A last possibility is to use the Fiat-Shamir heuristic to turn a zero-knowledge authentication
scheme into a signature scheme. When based on the Stern authentication scheme [Ste93] this gives
a code-based signature scheme. However this approach leads to really large signature sizes (of the
order of thousand(s) of bits). This represents a complete picture of code-based signature schemes
based on the Hamming metric. There has been some recent progress in this area for another
metric, namely the rank metric [GRSZ14]. We provide a detailed discussion about this point in
the conclusion. It should be added that the Hamming metric is particularly attractive for designing
code-based schemes due to the fact that the difficulty of decoding for this metric is a topic that
has been thoroughly studied over the years (for more details see the discussion that appears later
in the introduction).
Moving from error-correcting codes to lossy source codes. It can be argued that the main
problem with the CFS approach is to find a family of linear codes that are at the same time (i)
indistinguishable from a random code and (ii) that have a non-negligible fraction of syndromes
that can be decoded. There are not so many codes for which (ii) can be achieved and this is
probably too much to ask for. However if we relax a little bit what we ask for the code, namely
just a code such that the equation (in e)
HeT = sT (1)
admits for most of the s’s a solution e of small enough weight, then there are many more codes
that are able to fulfill this task. This kind of codes are not used in error-correction but can be
found in lossy source coding or source distortion theory where the problem is to find codes with
an associated decoding algorithm which can approximate any word of the ambient space by a
close enough codeword. In the case of linear codes, this means a code and a associated decoding
algorithm that can find for any syndrome s a vector e of small enough weight satisfying (1) where
H is a parity-check matrix of the code.
Solving (1) is the basic problem upon which all code-based cryptography relies. This problem
has been studied for a long time and despite many efforts on this issue [Pra62, Ste88, Dum91,
Bar97, MMT11, BJMM12, MO15, DAT17] the best algorithms for solving this problem [BJMM12,
MO15] are exponential in the weight w of e as long as w = (1− )r/2 for any  > 0. Furthermore
A new signature scheme based on (U |U + V ) codes 3
when w is sublinear in n, the exponent of the best known algorithms has not changed [CTS16] since
the Prange algorithm [Pra62] dating back to the early sixties. Moreover, it seems very difficult to
lower this exponent by a multiplicative factor smaller than 12 in the quantum computation model
as illustrated by [Ber10, KT17].
The exponent c()r is maximal when w is required to be equal to the Gilbert-Varshamov bound,
namely w = nh−1(r/n) where h(x)
4
=−x log2(x) − (1 − x) log2(1 − x) and h−1(x) is the inverse
function defined for x in [0, 1] and ranging over [0, 12 ]. It represents the largest weight w for which
we can typically expect that Problem (1) has a unique solution. The amount c() goes slowly to
0 as  goes to zero. There is a very simple algorithm solving this problem, namely the Prange
algorithm [Pra62] which is of polynomial complexity when  = 0. In the context of this work, we
are precisely in a case where Equation (1) admits numerous solutions.
Our contribution: a new signature scheme based on (U |U + V ) codes. Convolutional
codes or LDGM codes are codes which come with a decoding algorithm which is polynomial for
weights below r/2. They could theoretically be used in this context, since they provide an advantage
over standard linear codes in this context. Permuting the coordinates and publishing a random
parity-check matrix of the resulting code might seem enough to yield a secure signature scheme.
However in the light of the attacks [LJ12, PT16], it seems very difficult to propose parameters
which avoid the attacks given in these papers. Polar codes are also codes which fulfill (ii) but the
attack [BCD+16] found on the McEliece scheme based on polar codes [SK14] would also apply in
this setting. We are instead introducing a new class of codes in this context namely (U |U + V )
codes. A (U |U + V ) code is just a way of building of code of length n when we have two codes U
and V of length n/2. It consists in
(U |U + V )4={(u|u + v) : u ∈ U,v ∈ V }.
Generalized (U |U+V ) codes have already been proposed in the cryptographic context for building
a McEliece encryption scheme [MCT16]. However, there it was suggested to take U and V to be
codes that have an efficient decoding algorithm (this is namely mandatory in the encryption
context). In the signature context, when we just need to find a small enough solution of (1) this
is not needed. In our case, we can afford to choose random codes for U and V . It turns out that
if we choose U and V random with the right choice of the dimension of U and V , then a suitable
use of the Prange algorithm on the code U and the code V provides an advantage in this setting.
It namely allows to solve (1) for weights w that are significantly below r/2, that is in the range of
weights for which the best decoding algorithms are exponential.
Moreover, by tweaking a little bit the output of the Prange algorithm in our case and performing
an appropriate rejection sampling, it turns out that the signatures are indistinguishable from a
random word of weight w. This allows to give a security proof of our signature scheme which relies
on two problems:
P1: Solving the decoding problem (1) when w is sufficiently below r/2
P2: Distinguishing a permuted (U |U + V ) code from a random code of the same length and
dimension and this even when U and V are themselves random codes.
Problem P1 is the problem upon which all code-based cryptography relies. Here we are in a case
where there are multiple solutions of (1) and the adversary may produce any number of instances
of (1) with the same matrix H and various syndromes s and is interested in solving only one of
them. This relates to the, so called, Decoding One Out of Many (DOOM) problem. This problem
was first considered in [JJ02]. It was shown there how to modify slightly the known algorithms
for decoding a linear code in order to solve this modified problem. This modification was later
analyzed in [Sen11]. The parameters of the known algorithms for solving (1) can be easily adapted
to this scenario where we have to decode simultaneously multiple instances which all have multiple
solutions.
Problem P2 might seem to be an ad-hoc problem. However we are really in a situation where
the resulting permuted (U |U +V ) code is actually very close to a random code. The only different
4 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
behavior that can be found seems to be in the weight distribution for small weights. In this case,
the permuted (U |U +V ) code has some codewords of a weight slightly smaller than the minimum
distance of a random code of the same length and dimension. It is very tempting to conjecture that
the best algorithms for solving Problem P2 come from detecting such codewords. This approach
can be easily thwarted by choosing the parameters of the scheme in such a way that the best
algorithms for solving this task are of prohibitive complexity. Notice that the best algorithms that
we have for detecting such codewords are in essence precisely the generic algorithms for solving
the first problem, namely Problem P1. In some sense, it seems that we might rely on the very
same problem, namely solving Problem P1, even if our proof technique does not show this.
All in all, this gives the first practical signature scheme based on binary codes which comes
with a security proof and which scales well with the parameters: it can be shown that if one
wants a security level of 2λ, then signature size is of order O(λ), public key size is of order O(λ2),
signature generation is of order O(λ3), whereas signature verification is of order O(λ2).
Organization of the paper. The paper is organized as follows, we present our scheme in §2, in
§3 we prove it is secure under existential unforgeability under an adaptive chosen message attack
(EUF-CMA), in relation with this proof we respectively examine in §4, §5, and §6, how to produce
uniformly distributed signatures as well as the best message and key attacks. Finally we give some
set of parameters on par with the security reduction and with the current state-of-the-art for
decoding techniques.
Notation. We provide here some notation that will be used throughout the paper. Vectors will
be written with bold letters (such as e) and uppercase bold letters are used to denote matrices
(such as H). Vectors are in row notation. Let x and y be two vectors, we will write (x|y) to denote
their concatenation. We also denote for a subset I of positions of the vector x = (xi)1≤i≤n by xI
the vector whose components are those of x which are indexed by I, i.e.
xI = (xi)i∈I .
We define the support of x as
Supp(x)
4
={i ∈ {1, · · · , n} such that xi 6= 0}
The Hamming weight of x is denoted by |x|. By some abuse of notation, we will use the same
notation to denote the size of a finite set: |S| stands for the size of the finite set S. It will be clear
from the context whether |x| means the Hamming weight or the size of a finite set. Note that
|x| = |Supp(x)|.
The notation x
4
= y means that x is defined to be equal to y. We denote by Fn2 the set of binary
vectors of length n and Sw is its subset of words of weight w. Let S be a finite set, then x←↩ S means
that x is assigned to be a random element chosen uniformly at random in S. For a distribution D
we write ξ ∼ D to indicate that the random variable ξ is chosen according to D . We denote the
uniform distribution on Sw by Uw.
A binary linear code C of length n and dimension k is a subspace of Fn2 of dimension k and is
usually defined by a parity-check matrix H of size r × n as
C =
{
x ∈ {0, 1}n : HxT = 0
}
.
When H is of full rank (which is usually the case) we have r = n− k. The rate of this code (that
we denote by R) is defined as R
4
= kn .
A new signature scheme based on (U |U + V ) codes 5
2 The (U,U + V )-signature Scheme
2.1 The general scheme Scode
Our scheme can be viewed as a probabilistic version of the full domain hash (FDH) signature
scheme as defined in [BR96] which is similar to the probabilistic signature scheme introduced in
[Cor02] except that we replace RSA with a trapdoor function based upon the hardness of Problem
P1. Let C be a binary linear code of length n defined by a parity-check matrix H. The one way
function fw we consider is given by
fw : C × Sw −→ Fn2
(c, e) 7−→ c + e
Inverting this function on an input y amounts to solve Problem P1 with sT
4
= HyT since we have
that sT = HyT = H(cT + eT ) = HeT . Solving Problem P1 yields in this case e and we recover c
with c = y − e.
We are ready now to give the general scheme we consider. We assume that we have a family F
of codes of length n for which we can invert for all codes C in the family the associated function
fw. Then we pick a code Csec uniformly at random in F . We then choose an n × n permutation
matrix P. This is the secret key (sk) of the signature scheme. The public code is defined as
Cpub = {cP : c ∈ Csec}.
We compute a parity-check matrix Hpub of Cpub. This is the public key (pk) of the signature
scheme. We also select a cryptographic hash function H : {0, 1}∗ → Fn2 and a parameter λ0 for
the random salt. The algorithms Sgnsk and Vrfypk are defined as follows
Sgnsk(m): Vrfypk(m, (e′, r)):
r←↩ {0, 1}λ0 y←H (m|r)
y←H (m|r) w0 ← |e′|
(c, e)← f−1w (yP−1)P if Hpub(yT + e′
T
) = 0 and w0 = w return 1
return(e, r) else return 0
The correction of the verification step (i.e. that the pair (eP, r) passes the verification step) follows
from the fact that by definition of f−1w we have c+e = yP
−1 with c ∈ Csec and |e| = w. This implies
that cP+eP = y and therefore y+eP is in Cpub which in turn implies that Hpub(yT +PTeT ) = 0.
We also have |eP| = |e| = w. Finding a valid signature pair clearly amounts to solve Problem P1
for the code Cpub and the syndrome sT = HpubyT as explained before.
2.2 Source-distortion codes and decoders
Source-distortion theory is a branch of information theory which deals with obtaining a family of
codes F of the smallest possible dimension which can be used in our setting (i.e. for which we can
invert fw). Recall that a linear code is a vector space and the dimension of the code is defined as
the dimension of this vector space. For a linear code specified by a full rank parity-check matrix
of size r × n, the dimension k of the code is equal to n − r. It is essential to have the smallest
possible dimension in our cryptographic application, since this makes the associated problem P1
harder: the smaller n− r is, the bigger r is and the further away w can be from r/2 (where solving
P1 becomes easy). This kind of codes is used for performing lossy coding of a source. Indeed
assume that we can perform this task, then this means that we can find for every binary word y
a codeword c which is at most at distance w from it. The word y is compressed with a compact
description of c. Since the code is dimension n− r we just need n− r bits to store a description of
c. We have replaced here y with a word which is not too far away from it. Of course, the smaller
n − r is, the smaller the compression rate n−rn is. There is some loss by replacing y by c since
we are in general close to y but not equal to it. Finding a close codeword c of a given word y
6 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
is equivalent to find a low weight “error” e such that y + e is in the code. For our purpose it
will be more convenient to adopt the error viewpoint than the codeword viewpoint. To stress the
similarity with error-correction we will call the function which associates to y such an e a source
distortion decoder.
Definition 1 (Source Distortion Decoder). Let n, k ≤ n be integers and let F be a family of
binary linear codes of length n and dimension k. A source distortion decoder for F is a probabilistic
algorithm ϕ:
ϕ : F × Fn2 −→ Fn2
(C ,y) 7−→ e
such that y + e ∈ C . When the weight of the error is fixed, we call it a decoder of fixed distortion
w and we denote it by ϕw. We say that the distortion w is achievable if there exists a family of
codes with a decoder of fixed distortion w.
This discussion raises a first question: for given n and k, what is the minimal distortion w which
is achievable? We know from Shannon’s rate-distortion theorem that the minimal w is given by
the Gilbert-Varshamov bound dGV(n, k) which follows:
Definition 2 (Gilbert-Varshamov’s bound). For given integers n and k such that k ≤ n, the
Gilbert-Varshamov bound dGV(n, k) is given by:
dGV(n, k)
4
=nh−1 (1− k/n)
where h denotes the binary entropy: h(x) = −x log2 x − (1 − x) log2(1 − x) and h−1 its inverse
defined on [0, 1] and whose range is [0, 12 ].
Achieving distortion w = (n − k)/2 with the Prange technique. The study of random
codes shows that they achieve this source-distortion bound in average. Nevertheless we do not know
for them an efficient source-distortion algorithm. However, as the following proposition shows, it
is not the case when the distortion w is higher. When w = (n − k)/2 there is a very efficient
decoder using the Prange technique [Pra62] for decoding. To explain it consider a linear code C
of dimension k, length n and a parity-check matrix H for it. We want to find for a given y ∈ Fn2
an error e of low weight such that y− e is in C . This means that we should have HyT = HeT . H
is a full-rank matrix and it therefore contains an invertible submatrix A of size (n− k)× (n− k).
We choose a set of positions I of size n− k for which H restricted to these positions is a full rank
matrix. For simplicity assume that this matrix is in the first n−k positions: H =
(
A|B
)
. We look
for an e of the form e = (e′|0k) where e′ ∈ Fn−k2 . We should therefore have HyT = HeT = Ae′
T
,
that is e′
T
= A−1HyT . The expected weight of e′ is n−k2 and it easy to check that by randomly
picking a random set I of size n− k we have to check a polynomial number of them until finding
an e′
T
of weight exactly (n− k)/2.
Notation. We denote by ϕPrange(n−k)/2 this fixed distortion decoder and by ϕ
Prange the decoder which
picks a random subset until finding one for which H restricted to the columns corresponding to I
is invertible and computes e′ as explained above. ϕPrange does not necessarily output an error of
weight (n− k)/2.
From the previous discussion we easily obtain
Proposition 1 (Generic Source Distortion Decoder). Let integers n, k ≤ n and F the
family of random codes of length n and dimension k. ϕPrange(n−k)/2 works on average polynomial time.
When we consider in general the family of linear codes we speak about generic source-distortion
decoders as there is no structure, except linearity of the code. In contrast to the distortion (n−k)/2,
the only algorithms we know for linear codes for smaller values of w are all exponential in the
distortion. This is illustrated by Figure 1 where we give the exponents (divided by the length n)
A new signature scheme based on (U |U + V ) codes 7
of the complexity in base 2 as a function of the distance, for the fixed rate R = k/n = 0.5, of
the best generic fixed-w source distortion decoders. As we see, the normalized exponent is 0 for
distortion (n − k)/2 and the difficulty increases as w approaches the Gilbert-Varshamov bound
(which is equal approximately to 0.11n in this case).
Fig. 1: Normalized exponents in base 2 of the best generic fixed-w source distortion decoders.
Source distortion theory has found over the years several families of codes with an efficient
source-distortion algorithm which achieves asymptotically the Gilbert-Varshamov source-distortion
bound, one of the most prominent ones being probably the Arikan polar codes [Arı09] (see [Kor09]).
The naive way would be to build our signature on such a code-family and hoping that permuting
the code positions and publishing a random parity-check matrix of the permuted code would de-
stroy all the structure used for decoding. All known families of codes used in this context have low
weight codewords and this can be used to mount an attack. We will proceed differently here and
introduce in this setting the (U |U + V ) codes mentioned in the introduction. The point is that
they (i) have very little structure, (ii) have a very simple source-distortion decoder which is more
performant than the generic source decoder, (iii) they do not suffer from low weight codewords as
was the case with the aforementioned families. It will be useful to recall here that
Definition 3 ((U |U + V )-Codes). Let U , V be linear binary codes of length n/2 and dimension
kU , kV . We define the subset of Fn2 :
(U |U + V )4={(u|u + v) such that u ∈ U and v ∈ V }
which is a linear code of length n and dimension k = kU + kV . The resulting code is of minimum
distance min(2dU , dV ) where dU is the minimum distance of U and dV is the minimum distance
of V .
We are now going to present a source-distortion for a (U |U + V ) code. The following definitions
will be useful here.
Definition 4 (Punctured code). Consider a code C of length n. The punctured code PuncI(C )
in a set of positions I ⊂ {1, . . . , n} is a code of length n− |I| defined as
Punc
I
(C )
4
={cĪ : c ∈ C }
where Ī = {1, . . . , n} \ I. If x = (xi)1≤i≤n is a binary vector, Puncx will denote PuncSupp(x).
8 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
We will also need the dual notion of extending a partial codeword. Assume that for a given
set of positions J and a linear code C of length n we have that dim C = dim (PuncJ C ), then if
for x ∈ Fn−|J|2 there exists a codeword c in C such that cJ = x, such a codeword is necessarily
unique and we say that c is the completion of x with respect to J and write c = CompCJ (x). For
a random code C , a set J has this property with probability 1−O(2−n+|J|+dim C ). Moreover, for
a vector x = (xi)1≤i≤n, Comp
C
x will denote Comp
C
Supp(x).
We can use the generic source distortion decoder of Proposition 1 for source distortion decoding
a (U |U + V ) code. Assume that we have a (U |U + V ) code of length n and a word y = (y1|y2)
that we want to decode where the yi’s belong to Fn/22 . We assume that the dimension of U is
kU and that the dimension of V is kV . Let us first try to recover a “good” v. Such a v should
clearly be a good approximation for y1 + y2. We use the (Prange) generic source decoder for
V to find such a v. That is eV = ϕ
Prange
(n/2−kV )/2(V,y1 + y2). Here v = eV + y1 + y2. We then
subtract v to y2 to get y
′
2 = y2 + v = y1 + eV . We are now left with the task of approximating
y′ = (y1|y1 + eV ) with a word of the form (u|u) where u ∈ U . We clearly have to get the best
approximation of y1 in the positions which do not correspond to the support of eV . In other
words we compute e′U = ϕ
Prange
(n/2−kU−|eV |)/2(PunceV (U),PunceV (y1)). This can be done as long as
(n/2 − kU − |eV |)/2 ≥ 0, that is n/2 ≥ kU + |eV | which amounts to n/2 ≥ kU + (n/2 − kV )/2,
that is n/2 ≥ 2kU − kV . The word u we are looking is such that PunceV (u) = PunceV (y1) + e′U .
We compute the righthand term and we perform its completion to recover u. This procedure is
given in Algorithm 1.
Algorithm 1 UV -sddV1 : (U |U + V )−Source Distortion Decoder
Parameter: a (U |U + V ) code of length n and dimension k = kU + kV
Input: (y1|y2) with yi ∈ Fn/22
Output: e ∈ Fn2
Assumes: 2kU − kV ≤ n/2.
1: eV ← ϕPrange(n/2−kV )/2(V,y1 + y2)
2: e′U ← ϕPrange(n/2−kU−|eV |)/2(PunceV (U),PunceV (y1))
3: u← CompUeV (PunceV (y1) + e
′
U )
4: eU ← y1 + u
5: return (eU |eU + eV )
Proposition 2. The algorithm UV -sddV1 is a fixed-(n/2− kU ) source distortion decoder which
works in polynomial average-time when 2kU − kV ≤ n/2.
Proof. Let e′′U be the element of F
n/2
2 which coincides with e
′
U on the positions outside the support
of eV and is zero elsewhere. We may write eU = e
′′
U + e
′′′
U where the support of e
′′′
U is included in
the support of eV .
|(eU |eU + eV )| = |eU |+ |eU + eV |
= |e′′U |+ |e′′′U |+ |e′′U + e′′′U + eV |
= |e′′U |+ |e′′′U |+ |e′′U |+ |e′′′U + eV |
= 2|e′′U |+ |e′′′U | − |e′′′U |+ |eV |
= 2|e′′U |+ |eV |
= n/2− kU − |eV |+ |eV |
= n/2− kU
We can now choose the parameters kU and kV in order to minimize the distortion n/2 − kU for
a fixed dimension k = kU + kV of the code. Figure 2 compares the distance that we obtain with
A new signature scheme based on (U |U + V ) codes 9
this algorithm to (n− k)/2 which corresponds to what is achieved by the generic decoder and to
the optimal distance (Gilbert-Varshamov bound) where R denotes the rate of the code. As we see
there is a non-negligible gain. Nevertheless, UV -sddV1 approximates to a fixed distance in each
step of its execution which leads to correlations between some bits that can be used to recover the
structure of the secret key. In order to fix this problem and as it is asked in our proof of security,
we will present a modified version of UV -sddV1 in §4 which uses a rejection sampling method
to simulate uniform outputs. This comes at the price of slightly increasing the weight of the error
output by the decoder.
Fig. 2: Comparison of the Optimal Signature Distance, the Gilbert-Varshamov Bound and Generic
Distance
3 Security Proof
We give in this section a security proof of the signature scheme Scode. This proof is in the spirit
of the security proof of the FDH signatures in the random oracle model (see [BR93]). However as
our scheme is probabilistic we were also inspired by the proof of [Cor02]. Our main result is to
reduce the security to two major problems in code-based cryptography.
3.1 Basic tools
Basic definitions.
Definition 5 (Negligible Function). A function f : N → R is negligible if for every positive
polynomial p:
∃N, ∀n > N, |f(n)| ≤ 1
p(n)
.
Definition 6 (Statistical Distance). Let D0 and D1 be two discrete probability distributions
over a same discrete space E . Their statistical distance is defined as:
ρ(D0,D1)
4
=
∑
x∈E
|D0(x)−D1(x)|.
We will need the following well known property for the statistical distance which can be easily
proved by induction
10 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
Proposition 3. Let (D01 , . . . ,D
0
n) and (D
1
1 , . . . ,D
1
n) be two n-tuples of discrete probability distri-
butions where D0i and D
1
i are distributed over a same space Ei. For a ∈ {0, 1}, let us denote by
Da1 ⊗· · ·⊗Dan the product probability distribution of Da1 , . . . ,Dan, that is Da1 ⊗· · ·⊗Dan(x1, . . . , xn) =
Da1 (x1) . . .D
a
n(xn) with xi ∈ Ei for i ∈ {1, . . . , n}. In such a case we have
ρ
(
D01 ⊗ · · · ⊗D0n,D11 ⊗ · · · ⊗D1n
)
≤
n∑
i=1
ρ(D0i ,D
1
i ).
We are now going to define the concept of distinguisher between two distributions and to relate it
with the statistical distance.
Definition 7 (Distinguisher). A distinguisher between two distributions D0 and D1 over the
same space E is a randomized algorithm which takes as input an element of E that follows the
distribution D0 or D1 and outputs b ∈ {0, 1}.
A distinguisher A between D0 and D1 is characterized by its advantage:
AdvD
0,D1(A )
4
=Pξ∼D0 (A (ξ) outputs 1)− Pξ∼D1 (A (ξ) outputs 1)
where Pξ∼Di (A (ξ) outputs 1) is the probability that A (ξ) outputs 1 when its inputs are picked
according to the distribution D i and for each executions its internal coins are picked uniformly at
random. We call this quantity the advantage of A against D0 and D1.
We are now able to define the computational distance between two distributions.
Definition 8 (Computational Distance and Indistinguishability). The computational dis-
tance between two distributions D0 and D1 in time t is:
ρc
(
D0,D1
)
(t)
4
= max
|A |≤t
{
AdvD
0,D1(A )
}
where |A | denotes the running time of A on its inputs.
The ensembles D0 = (D0n) and D
1 = (D1n) are computationally indistinguishable in time (tn)
if their computational distance in time (tn) is negligible in n.
In other words, the computational distance is the best advantage that any adversary could get in
bounded time. It is well known that statistical distance is greater than computational distance as
the following theorem claims.
Theorem 1. Let D0 and D1 be two distributions, then ρ
(
D0,D1
)
is the best advantage that any
adversary could get, even with unbounded time:
∀t, ρc
(
D0,D1
)
(t) ≤ ρ
(
D0,D1
)
.
Digital signature and games. Let us recall the concept of signature schemes, the security
model that will be considered in the following and to recall in this context the paradigm of games
in which we give a security proof of our scheme.
Definition 9 (Signature Scheme). A signature scheme S is a triple of algorithms Gen, Sgn,
and Vrfy which are defined as:
– The key generation algorithm Gen is a probabilistic algorithm which given 1λ, where λ is the
security parameter, outputs a pair of matching public and private keys (pk, sk);
– The signing algorithm is probabilistic and takes as input a message m ∈ {0, 1}∗ to be signed
and returns a signature s = Sgnsk(m);
– The verification algorithm takes as input a message m and a signature s. It returns Vrfypk(m, s)
which is 1 if the signature is accepted and 0 otherwise. It is required that Vrfypk(m, s) = 1 if
s = Sgnsk(m).
A new signature scheme based on (U |U + V ) codes 11
For this kind of scheme one of the strongest security notion is existential unforgeability under an
adaptive chosen message attack (EUF-CMA). In other words, the adversary has access to any sig-
natures of its choice and its goal is to produce a valid forgery. A valid forgery is a message/signature
pair (m, s) such that Vrfypk(m, s) = 1 whereas the signature of m has never been requested by
the forger. More precisely, the following definition gives the EUF-CMA security of a signature
scheme:
Definition 10 (EUF-CMA Security). Let S be a signature scheme.
A forger A is a (t, qhash, qsign, ε)-adversary in EUF-CMA against S if after at most qhash queries
to the hash oracle, qsign signatures queries and t working time, it outputs a valid forgery with
probability at least ε. We define the EUF-CMA success probability against S as:
SuccEUF-CMAS (t, qhash, qsign)
4
= max (ε|it exists a (t, qhash, qsign, ε)-adversary) .
The signature scheme S is said to be (t, qhash, qsign)-secure in EUF-CMA if the above success
probability is a negligible function of the security parameter λ.
The game associated to our code-based signature scheme. The modern approach to prove
the security of cryptographic schemes is to relate the security of its primitives to well-known
problems that are believed to be hard by proving that breaking the cryptographic primitives
provides a mean to break one of these hard problems. In our case, the security of the signature
scheme is defined as a game with an adversary that has access to hash and sign oracles. It will be
helpful here to be more formal and to define more precisely the games we will consider. They are
games between two players, an adversary and a challenger. In a game G, the challenger executes
three kind of procedures:
– an initialization procedure Initialize which is called once at the beginning the game.
– oracle procedures which can be requested at the will of the adversary. In our case, there will
be two, Hash and Sign. The adversary A which is an algorithm may call Hash at most qhash
times and Sign at most qsign times.
– a final procedure Finalize which is executed once A has terminated. The output of A is
given as input to this procedure.
The output of the game G, which is denoted G(A ), is the output of the finalization procedure
(which is a bit b ∈ {0, 1}). The game G with A is said to be successful if G(A ) = 1. The standard
approach for obtaining a security proof in a certain model is to construct a sequence of games such
that the success of the first game with an adversary A is exactly the success against the model of
security, the difference of the probability of success between two consecutive games is negligible
until the final game where the probability of success is the probability for A to break one of the
problems which is supposed to be hard. In this way, no adversary can break the claim of security
with non-negligible success unless it breaks one of the problems that are supposed to be hard.
Definition 11 (challenger procedures in the EUF-CMA Game). The challenger procedures
for the EUF-CMA Game corresponding to Scode are defined as:
proc Initialize(λ) proc Hash(m, r) proc Sign(m) proc Finalize(m, e, r)
(Hpub,P, λ0)← Gen(1λ) return H (m|r) r←↩ {0, 1}λ0 y← Hash(m, r)
return Hpub y← Hash(m, r) c← y + e
(c, e)← f−1w (yP−1)P return HpubcT = 0 ∧ |e| = w
return (e, r)
3.2 Code-Based Signatures
We introduce in this subsection the code-based problems that will be used in the security proof.
The first is Decoding One Out of Many (DOOM) which was first considered in [JJ02] and later
analyzed in [Sen11]. We will come back to the best known algorithms to solve this problem as a
function of the distance w in §5.
12 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
Problem 1 (DOOM – Decoding One Out of Many).
Instance: H ∈ F(n−k)×n2 ; y1, · · · ,yq ∈ Fn2 ; w ∈ {0, · · · , n}
Output: e ∈ Fn2 of Hamming weight w such that for some i ∈ {1, · · · , q}, HeT = HyTi
We will denote by (H,y1, · · · ,yq)←↩ DOOM(n, k, w) a randomly chosen instance of this problem.
Definition 12 (One-Wayness of DOOM). We define the success of an algorithm A against
DOOM with the parameters n, k, w as:
Succn,k,wDOOM (A ) = P
(
A (H,y1, · · · ,yq) solution
of DOOM | (H,y1, · · · ,yq)←↩ DOOM(n, k, w)
)
.
where the probability is taken over uniformly instances and internal coins of A .
The computational success in time t of breaking DOOM with the parameters n, k, w is then
defined as:
Succn,k,wDOOM(t) = max|A |≤t
{
Succn,k,wDOOM (A )
}
Another problem will appear in the security proof: distinguish random codes from a code drawn
uniformly at random in the family used in the signature scheme. Let F be the family of public
codes of length n and dimension k that we use in Scode. We define the uniform distribution over
F as DF . On the other hand DR will denote the uniform distribution over the family of all binary
linear codes of length n and dimension k.
Remark 1. In Scode, the family F is {Cpub} where:
Cpub = {cP : c ∈ Csec}
with P a permutation matrix and Csec a (U |U + V )-code of length n and dimension k.
Let us denote by Dw the distribution of the w-source distortion decoder outputs which is used to
sign and by Uw the uniform distribution over Sw (which is the set of words of weight w in Fn2 ).
3.3 EUF-CMA Security Proof
This Subsection is devoted to our main theorem and its proof
Theorem 2 (Security Reduction). Let qhash (resp. qsign) be the number of queries to the hash
(resp. signing) oracle. We assume that λ0 = λ+ 2 log2(qsign) where λ is the security parameter of
the signature scheme. We have for all w, time t :
SuccEUF−CMAScode (t, qhash, qsign) ≤ 4Succ
n,k,w
DOOM(tc) +
1
2
qhash
√
2n−k(
n
w
)
+ qsignρ (Dw,Uw) + 3ρc
(
DR,DF
)
(tc)
where tc = t+O
(
qhash · n2
)
Remark 2. In the paradigm of code-based signatures we have w greater than the Gilbert-Varshamov
bound, which gives 2n−k 
(
n
w
)
.
Proof. Let A be a (t, qsign, qhash, ε)-adversary in the EUF-CMA model against Scode. We will
write P (Si) to denote the probability of success for A of game Gi. Let q = qhash − qsign. If proc
Hash is called several times with the same arguments, it returns the same output, we do not handle
this in the games to keep the pseudo code simple.
Game 0 is the EUF-CMA game for Scode.
A new signature scheme based on (U |U + V ) codes 13
Game 1 is identical to Game 0 unless the following failure event F occurs: there is a collision
in a signature query (i.e. two signatures queries for a same message m lead to the same salt r).
By using the difference lemma (see for instance [Sho04, Lemma 1]) we get:
P (S0) ≤ P (S1) + P (F ) .
The following lemma (see A.2 for a proof) shows that in our case as λ0 = λ+ 2 log2(qsign), the
probability of the event F is negligible.
Lemma 1. For λ0 = λ+ 2 log2(qsign) we have:
P (F ) ≤ 1
2λ
.
Game 2 is modified from Game 1 as follows:
proc Initialize(λ) proc Hash(m, r) proc Sign(m)
(Hpub,P, λ0)← Gen(1λ) if Lm.contains(r) r← Lm.next()
H0 ←↩ F(n−k)×n2 (c, Em,r)←↩ Cpub × Sw y← Hash(m, r)
(y1, . . . ,yq)←↩ (Fn2 )
q
return c + Em,r (c, e)← f−1w (yP−1)P
j ← 0 else return (e, r)
return Hpub j ← j + 1
return yj
To each message m we associate a list Lm containing qsign random elements of Fλ02 . It is constructed
the first time it is needed. The call Lm.contains(r) returns true if and only if r ∈ Lm. The call
Lm.next() returns elements of Lm sequentially. The list is large enough to satisfy all queries. The
Hash procedure now creates the list Lm if needed, then, if r ∈ Lm it returns y = c + e with
e ←↩ Sw and c ←↩ Cpub. This leads to a valid signature (e, r) for m. The error value is stored in
Em,r. If r 6∈ Lm it outputs one of yj of the instance (H0,y1, . . . ,yq) of the DOOM problem. The
Sign procedure is unchanged, except for r which is now taken in Lm. The global index j is set to
0 in proc Initialize.
We can relate this game to the previous one through the following lemma.
Lemma 2.
P(S1) ≤ P(S2) +
1
2
qhash
√
2n−k(
n
w
) + 2ρc (DF ,DR) (t ·O(n2))
The proof of this lemma is given in Appendix A.3 and relies among other things on the leftover
hash lemma (see [BDK+11]). We show in appendix how to emulate the lists Lm in such a way
that list operations cost, including its construction, is at most linear in the security parameter λ.
Since λ ≤ n, it follows that the cost to a call to proc Hash cannot exceed O(n2) and the running
time of the challenger is tc = t+O
(
qhash · n2
)
.
Game 3 differs from Game 2 by changing in proc Sign the call “(c, e) ← f−1w (yP−1)P” by
“e← Em,r”. Any signature (e, r) produced by proc Sign is valid. The error e is drawn according
to the uniform distribution Uw while previously it was drawn according to the source distortion
decoder distribution, that is Dw. By using Proposition 3 it follows that
P (S2) ≤ P (S3) + qsignρ (Uw,Dw) .
The running time of the challenger cannot increase by more than O(qsign · λ) and thus we still
have tc = t+O
(
qhash · n2
)
.
Game 4 is the game where we replace the public matrix Hpub by H0. In other words the
Initialize procedure is now:
14 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
proc Initialize(λ)
(Hpub,P, λ0)← Gen(1λ)
(H0,y1, · · · ,yq)←↩ DOOM(n, k, w)
j ← 0
Hpub ← H0
return Hpub
In this way we will force the adversary to build a solution of the DOOM problem. Here if a
difference is detected between games it gives a distinguisher between the distribution DR and
DF :
P (S3) ≤ P (S4) + ρc
(
DF ,DR
)
(tc) .
Game 5 differs in the finalize procedure.
proc Finalize(m, e, r)
y← Hash(m, r)
b← Hpub (y + e)T = 0 ∧ |e| = w
return b ∧ ¬Lm.contains(r)
We assume the forger outputs a valid signature (e, r) for the
message m. The probability of success of Game 5 is the prob-
ability of the event “S4 ∧ (r 6∈ Lm)”.
If the forgery is valid, the message m has never been queried by Sign, and the adversary never
had access to any element of the list Lm. This way, the two events are independent and we get:
P (S5) = (1− 2−λ0)qsignP (S4) .
As we assumed λ0 = λ+ 2 log2(qsign) ≥ log2(qsign), we have:(
1− 2−λ0
)qsign ≥ (1− 1
qsign
)qsign
≥ 1
4
.
Therefore
P (S5) ≥
1
4
P (S4) . (2)
The probability P (S5) is then exactly the probability for A to output e ∈ Sw such that H0(yj +
e)T = 0 for some j which gives
P (S5) ≤ Succn,k,wDOOM(tc). (3)
(2) together with (3) imply that
P(S4) ≤ 4Succn,k,wDOOM(tc).
This concludes the proof of Theorem 2 by combining this together with all the bounds obtained
for each of the previous games.
4 Achieving the Uniform Distribution of the Outputs
4.1 Rejection Sampling Method
In our security proof, we use the fact that the distribution of the outputs of the (U |U+V ) decoder
is close to the uniform distribution on the words of weight w. We will show how to modify a little
bit the decoder by performing some moderate rejection sampling in order to meet this property.
Note that ensuring such a property is actually not only desirable for the security proof, it is
also more or less necessary since there is an easy way to attack the signature when it is based
on the decoder UV -sddV1. Indeed, it is readily verified that with this decoder the probability
P(ei = 1, ej = 1) we have on the output e of the decoder for certain i and j is larger than the same
probability for a random word e of weight w. The pairs (i, j) which have this property correspond
to the image by the permutation P of pairs of the form (x, x+n/2) or (x+n/2, x). In other words,
A new signature scheme based on (U |U + V ) codes 15
signatures leak information in this case and this can be used to recover completely the permuted
(U |U + V ) structure of the code.
It is insightful to consider more precisely the shape of the errors that are output by the
(U |U +V )-source distortion decoder. This is given by Figure 3 where w1 is the distortion achieved
in the first step of the algorithm and w2 is the second one. Algorithm UV -sddV1 has this behavior
with w1 = (n/2 − kV )/2 and w2 = (n/2 − kU − w1)/2 = (n/2 − kU − (n/2 − kV )/2)/2 =
n/8 − kU/2 + kV /4. However we would have the same shape by applying to V and to U any
source-distortion decoder. The weight w1 would be in this case the distortion achieved for the
decoder for V and w2 would be the distortion achieved by the decoder for the punctured version
of U with respect to the support of error output by the decoder for V . It turns out that by
allowing more freedom in the distortion achieved by the decoders of U and V we are able to
achieve a uniform distribution on the words of weight w. The corresponding procedure is given
in Algorithm 2. Roughly speaking the idea is to use the Prange decoder but without fixing the
weight for the V -decoder and performing some rejection sampling in order to achieve the uniform
distribution over the outputs.
Algorithm 2 UV -sddV2 : (U |U + V )−Source Distortion Decoder
Parameter: a (U |U + V ) code of length n
Inputs: · (y1|y2) with yi ∈ Fn/22
· no-rejection probability vector x = (xi)0≤i≤n−kV ∈ [0, 1]
n−kV
Output: e ∈ Fn2 with |e| = w.
Assumes: 2kU − kV ≤ n/2.
1: repeat
2: eV ← ϕ(V,y1 + y2)
3: p←↩ [0, 1]
4: until |eV | ≤ w, w − |eV | ≡ 0 (mod 2) and p ≤ x|eV |
5: e′U ← ϕ(w−|eV |)/2(PunceV (U),PunceV (y1))
6: u← CompUeV (PunceV (y1) + e
′
U )
7: eU ← y1 + u
8: return (eU |eU + eV )
Fig. 3: Shape of the outputs of UV -sddV1
n/2
n
0 1
w2
E
w1
0 1
w2
Ē
w1
To explain the rejection method let us introduce some notation.
Notation. Let e ∈ Fn2 and w ∈ {0, · · · , n},
w1(e)
4
= #
{
i ∈ {1, · · · , n/2} : ei 6= ei+n/2
}
,
w2(e)
4
= #
{
i ∈ {1, · · · , n/2} : ei = ei+n/2 = 1
}
.
The strategy for rejection sampling is that the distortion w1 should follow the same law as
w1(e) when e is drawn uniformly at random from the word of weight w. Note that we clearly have
16 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
for any word e ∈ Sw
w = w1(e) + 2w2(e).
It will be helpful to bring in now the following quantities. Let us first assume that e is chosen
uniformly at random in Sw. For i ∈ {1, 2} we define the quantities
pui (j)
4
=Pe←↩Sw (wi(e) = j) .
It is straightforward to check that
Proposition 4 (Distribution of w1 and w2). For all i in {0, . . . , w} such that w ≡ i (mod 2)
pu2
(
w − i
2
)
= pu1 (i) = 2
i
(
n/2
(w−i)/2
)(
n/2−(w−i)/2
i
)(
n
w
)
and for other choices of i, p1(i) and p2(i) are equal to 0.
Similarly to the case of the uniform distribution, we define the following probability distributions
for the outputs of the source-distortion decoder and for i in {1, 2}:
psddi (j)
4
=Pe (wi(e) = j)
where e is now the output of Algorithm 2. A simple formula for these probability distributions is
given in Proposition 5 (see in the appendix §B.1 for a proof). These distributions can be derived
from the rejection probabilities and the weight distribution of the source distortion decoder as
follows:
Proposition 5. Let p(i)
4
=Py,θ(|ϕ(V,y)| = i). If two executions of ϕ are independent, then for
all i in {0, . . . , w} such that w − i ≡ 0 (mod 2) we have
psdd2
(
w − i
2
)
= psdd1 (i) =
xi p(i)
p1w
(4)
where
p1w
4
=
∑
0≤j≤w
j≡w (mod 2)
xj p(j)
and psdd1 (i) = 0 for other choices of i.
Remark 3. We stress here that two executions of ϕ have to be independent. It is naturally the
case for the Prange algorithm if we choose independently the different information sets.
The following definition will turn out be be useful.
Definition 13. Let θ denote the internal coin used in the probabilistic algorithm ϕ. We say that
ϕ behaves uniformly for a code C if Py,θ (e = ϕ(C ,y)) only depends on the weight |e|.
In the case of a decoder ϕ that behaves uniformly, the no-rejection vector x can be chosen so that
the output of Algorithm 2 is uniformly distributed as shown by the following proposition.
Proposition 6. If the source decoder ϕ used in Algorithm 2 behaves uniformly for V and uni-
formly for PunceV (U) for all error patterns eV obtained as eV = ϕ(V,y1 + y2), we have:
ρ (Dw,Uw) = ρ
(
psdd1 , p
u
1
)
The output of Algorithm 2 is the uniform distribution over Sw if in addition two executions of ϕ
are independent and the no-rejection probability vector x is chosen for any i in {0, . . . , w} as
xi =
1
Mrs
pu1 (i)
p(i)
if w ≡ i (mod 2)
and 0 otherwise with Mrs
4
= sup
0≤i≤w
i≡w (mod 2)
pu1 (i)
p(i) .
A new signature scheme based on (U |U + V ) codes 17
4.2 Application to the Prange source distortion decoder.
The Prange source decoder (defined in §2.2) is extremely close to behave uniformly for almost all
linear codes. To keep this paper within a reasonable length we just provide here how the relevant
distribution p(i) is computed.
Proposition 7 (Weight Distribution of the Prange Algorithm).
Let p(i) =
∑
e:|e|=i Py,θ
(
e = ϕPrange(C ,y)
)
. For all w, k, n ∈ N with k ≤ n, w ≤ n− k, all codes
C of length n and dimension k, we have:
p(w) =
(
n−k
w
)
2n−k
By using Proposition 6 with this distribution p we can set up the no-rejection probability vector
x in Algorithm 2. To have an efficient algorithm it is essential that the parameter Mrs is as
small as possible (it is namely readily verified that the average number of calls in Algorithm 2
to ϕPrange(V,y1 + y2) is Mrs). Let e be an error of weight w chosen uniformly at random. This
average number of calls can be chosen to be small by imposing that the distributions of w1(e) and
|ϕ(V,y)| to have the same expectation. The expectation of w1(e) is approximately w
(
1− wn
)
and
the expectation of |ϕ(V,y)| is (n/2− kV )/2. We choose therefore kV such that
(n/2− kV )/2 ≈ w
(
1− w
n
)
.
Thanks to this property, kV is chosen to “align” both distributions and in this way Mrs is small.
We can find in Figure 4 an example of the distributions pu1 and p corresponding to the choice
n = 2000, kV = 383 , w = 381. In this case, Mrs = 2.54.
Fig. 4: Comparison of Prange algorithm’s output distribution with uniform outputs
This rejection sampling method comes at the price of slightly increasing the weight the decoder
can output. Indeed, given parameters n, k what set of parameters do we have to choose? First, in
order to avoid a prohibitive cost for the Prange algorithm we have to set kU and w such that w
corresponds to the expected weight of the Prange decoder. This implies:
n/2− kU = w (5)
Moreover as explained above, the rejection sampling comes with a minimal cost when the following
constraint is met:
kV = n/2− 2w
(
1− w
n
)
(6)
18 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
Finally we also have k = kU + kV . Combining this with (6) and (5) leads to the following system
of equations: {
n/2− kU = w
kV = n/2− 2w
(
1− wn
) ⇐⇒ {kV = w − n/2 + k
2w2/n− 3w + n− k = 0
Therefore ω
4
=w/n and R
4
= k/n have to verify
2ω2 − 3ω + 1−R = 0 (7)
Once k and n are fixed, ω is chosen and we deduce kU and kV thanks to (5) and (6). Figure 5
gives ω as a function of R. For instance for R = 0.5 we have ω = 0.1909.
Fig. 5: Comparison of the Optimal Signature Distortion with or without the Rejection Sampling
Method, the Gilbert-Varshamov Bound and the Generic Distortion
5 Best Known Algorithms for Solving the DOOM Decoding Problem
We consider here the best known techniques for solving Problem 1, namely decoding one out of
many, i.e. the so called DOOM problem. This problem is a variation of the classical decoding
problem where for a binary [n, k] code and a vector y of length n we have to find an error vector
e of Hamming weight w such that y + e is in the code. This problem is equivalent to syndrome
decoding
Problem 2 (SD – Syndrome Decoding).
Instance: H ∈ F(n−k)×n2 , s ∈ F
n−k
2 , w integer
Output: e ∈ Fn2 such that |e| = w and HeT = sT
Information set decoding is the best known technique to solve the syndrome decoding problem,
it can be traced back to Prange [Pra62]. It has been improved in [Ste88, Dum91] by introducing
a birthday paradox. The current state-of-the-art can be found in [MMT11, BJMM12, MO15].
Existing literature usually assumes that there is a unique solution to the problem. This is true
in particular when w is smaller than the Gilbert-Varshamov bound (see Definition 2). When w
is larger, as it is the case here, we speak of source distortion decoding even though the problem
statement is the same. The expected number of solutions grows as M =
(
n
w
)
/2n−k and the cost
analysis must be adapted to take that into account. There is a second specificity in the current
study which is the possibility for an attacker to consider several instances simultaneously. This is
precisely the DOOM problem we referred to above.
A new signature scheme based on (U |U + V ) codes 19
The DOOM problem was first considered in [JJ02] then analyzed in [Sen11] for Dumer’s variant
of ISD. From this point and till the end of this section, the parameters n, k, w are fixed.
5.1 An Attack Using Multiple Instances
An attacker may produce many, say q, favorable messages and hash them to obtain s1, . . . , sq
submitted to a solver of Problem 1 together with a parity check matrix of the public key. If it is
successful, it has forged a new signature.
Note that in the security reduction, the assumption related to DOOM is precisely the same,
that is assuming key indistinguishability and a proper distribution of the signatures, the adversary
has to solve a DOOM instance as described above and the reduction is tight in this respect.
5.2 ISD – Information Set Decoding
The skeleton of the ISD algorithm for solving DOOM is given by Algorithm 3.
Algorithm 3 (generalized) ISD
1: input: H ∈ F(n−k)×n2 , S = {s1, . . . , sq} ⊂ F
(n−k)
2 , w integer
2: loop
3: pick an n× n permutation matrix P
4: perform partial Gaussian elimination on HP
UHP =
0
In−k−`
H′
H′′
6
6
?
?
`
n− k − `
UsTi =
s′′i
T
s′i
T
i = 1, . . . , q
5: find E = all solutions of DOOM(H′, S′, p), H′ ∈ F`×(k+`)2 , S′ = {s′1, . . . , s′q}
6: for all (e′, i) ∈ E do
7: e′′ ← e′H′′T + si′′ ; e← (e′′ | e′)PT
8: if |e| = w then print (e, i)
In all variants of ISD, the set E computed at Instruction 5 contains (up to a small polynomial
factor) all the solutions of DOOM(H′, S′, p). The cost to produce E dominates the cost of one
loop of Algorithm 3, we denote it by Cq(p, `). As it is described, the loop is repeated forever and
just prints a stream of solutions. The standard version corresponds to a single instance, that is
q = 1. Below we explain how the cost estimate of the algorithm varies in various situations: when
we have a single instance and a single solution, when the number of solutions increases and when
the number of instances increases. For each value of n, k, w and q, the algorithm is optimized over
the parameters p and `. The optimal values of p and ` will change with the number of solutions
and the number of instances.
Single Instance and Single Solution. We consider a situation where we wish to estimate the
cost of the algorithm for producing one specific solution of Problem 2, that is q = 1. In that
case, even when w is large and there are multiple solutions, the solution we are looking for, say
e, is printed if and only if the permutation P is such that |e′| = p and |e′′| = w − p where
(e′′ | e′)← e
(
P−1
)T
. This will happen with probability P(p, `) leading to the workfactor WF(1)
P(p, `) =
(
n−k−`
w−p
)(
k+`
p
)(
n
w
) ,WF(1) = min
p,`
C1(p, `)
P(p, `)
,
which is obtained by solving an optimization problem over p and `. The exact expression of
C1(p, `) depends on the variant, for instance, for Dumer’s algorithm [Dum91] we have C1(p, `) =
20 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
max
(√(
k+`
p
)
,
(
k+`
p
)
2−`
)
up to a small polynomial factor. For more involved variants [BJMM12,
MO15], the value of C1(p, `) is, for each (p, `), the solution of another optimization problem.
Single Instance and Multiple Solutions. We now consider a situation where there are M
solutions to a syndrome decoding problem (q = 1). If w is larger than the Gilbert-Varshamov bound
we expect M =
(
n
w
)
/2n−k else M = 1. Assuming each of the M solutions can be independently
produced, the probability that one particular iteration produces (at least) one of the solutions
becomes PM (p, `) = 1− (1− P(p, `))M . The corresponding workfactor is
WF(M) = min
p,`
C1(p, `)
PM (p, `)
.
Let (p0, `0) be the optimal value of the pair (p, `) for a single instance.
Case 1: P(p0, `0) ≤ 1/M . Then, up to a small constant (at most exp(−1)) we have PM (p0, `0) =
1 − (1 − P(p0, `0))M ≈ MP(p0, `0). Also remark that PM (p, `) ≤ MP(p, `) and thus WF(M) ≥
WF(1)/M . We also have
WF(M) = min
p,`
C1(p, `)
PM (p, `)
≤ C1(p0, `0)
PM (p0, `0)
=
1
M
C1(p0, `0)
P(p0, `0)
=
1
M
WF(1)
up to a small constant factor. In other words, the optimal parameters remain the same and the
workfactor for multiple solutions is simply obtained by dividing the single solution workfactor by
the number of solutions.
Case 2: P(p0, `0) > 1/M . In this case the success probability PM (p0, `0) < MP(p0, `0) and the
pair (p, `) that minimizes the workfactor is going to be different. It gives a different optimization
problem and we observe that the gain is much less than the factor M of Case 1.
In practice, and for the parameters we consider in this work, we are always in Case 2. In fact,
for k/n = 0.5, with Dumer’s algorithm Case 1 only applies when w/n < 0.150, while the Gilbert-
Varshamov bound corresponds to w/n = 0.110. With BJMM’s algorithm, Case 1 only happens
when w/n ≤ 0.117. In our signature scheme we have w/n ≈ 0.19 and we always fall in Case 2,
even with a single instance.
Multiples Instances with Multiple Solutions. We now consider the case where the adversary
has access to q instances of Problem 2 for the same matrix H and various syndromes. This is Prob-
lem 1 that appears in the security reduction. For each instance, we expect M = max
(
1,
(
n
w
)
/2n−k
)
solutions.
As before, the cost is dominated by Instruction 5, which we denote by Cq(p, `), and the proba-
bility of success is PqM (p, `) = 1− (1−P(p, `))qM . Next this cost has to be minimized over p and
`
WF(M)q = min
p,`
Cq(p, `)
PqM (p, `)
.
Indeed, solving DOOM(H′, S′, p) is not specified here. This is in fact what [JJ02, Sen11] are about.
For instance with Dumer’s algorithm, we have [Sen11]
Cq(p, `) = max
(√
q
(
k+`
p
)
,
q
(
k+`
p
)
2`
)
, q ≤
(
k + `
p
)
up to a small polynomial factor. Introducing multiple instances in advanced variants of ISD has
not been done so far and is an open problem. We give in Table 1 the asymptotic exponent for
various decoding distances and for the code rate 0.5. The third column gives the largest useful
value of q. It is likely that BJMM’s algorithm will have a slightly lower exponent when addressing
multiple instances. Note that for Dumer’s algorithm in this range of parameters, the improvement
A new signature scheme based on (U |U + V ) codes 21
Dumer BJMM
w/n 1
n
log2M
1
n
log2 q
1
n
log2 WF
(M)
q
1
n
log2 WF
(M) 1
n
log2 WF
(M)
0.11 0.0000 0.0872 0.0872 0.1152 0.1000
0.15 0.1098 0.0448 0.0448 0.0535 0.0486
0.19 0.2015 0.0171 0.0171 0.0184 0.0175
Table 1: Asymptotic Exponent for Algorithm 3 for k/n = 0.5
from WF(M) (single instance) to WF(M)q (multiple instances) is relatively small, there is no reason
to expect a much different behavior for BJMM.
Finally, let us mention that the best asymptotic exponent among all known decoding techniques
was proposed in 2015 by May and Ozerov [MO15]. However it is penalized by a big polynomial
overhead which makes it unpractical at this point for the problems considered here.
5.3 Other Decoding Techniques.
As mentioned in [CJ04, FS09], the Generalized Birthday Algorithm (GBA) [Wag02] is a relevant
technique to solve decoding problems, in particular when there are multiple solutions. However, it
is competitive only when the ratio k/n tends to 1, and does not apply here. We refer the reader
to [MS09] for more details on GBA and its usage.
6 Key Attack
6.1 The Idea of the Attack
A (U |U + V ) code where U and V are random seems very close to a random linear code. There is
for instance only a very slight difference between the weight distribution of a random linear code
and the weight distribution of a random (U |U + V )-code of the same length and dimension. This
slight difference happens for small and large weights and is due to codewords of the form (u|u)
where u belongs to U or codewords of the form (0|v) where v belongs to V . More precisely, we
have the following proposition
Proposition 8. Assume that we choose a (U |U+V ) code by picking the parity-check matrices of U
and V uniformly at random among the binary matrices of size (n/2−kU )×n/2 and (n/2−kV )×n/2
respectively. Let a(U |U+V )(w), a(U |U)(w) and a(0|V )(w) be the expected number of codewords of
weight w that are respectively in the (U |U + V ) code, of the form (u|u) where u belongs to U and
of the form (0|v) where v belongs to V . These numbers are given for even w in {0, . . . , n} by
a(U |U+V )(w) =
(
n/2
w/2
)
2n/2−kU
+
(
n/2
w
)
2n/2−kV
+
1
2n−kU−kV
((
n
w
)
−
(
n/2
w
)
−
(
n/2
w/2
))
a(U |U)(w) =
(
n/2
w/2
)
2n/2−kU
; a(0|V )(w) =
(
n/2
w
)
2n/2−kV
and for odd w in {0, . . . , n} by
a(U |U+V )(w) =
(
n/2
w
)
2n/2−kV
+
1
2n−kU−kV
((
n
w
)
−
(
n/2
w
))
a(U |U)(w) = 0 ; a(0|V )(w) =
(
n/2
w
)
2n/2−kV
On the other hand, when we choose a code of length n with a random parity-check matrix of size
(n − kU − kV ) × n chosen uniformly at random, then the expected number a(w) of codewords of
weight w > 0 is given by
a(w) =
(
n
w
)
2n−kU−kV
.
22 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
Remark 4. When the (U |U+V ) code is chosen in this way, its dimension is kU+kV with probability
1−O
(
max(2kU−n/2, 2kV −n/2)
)
. This also holds for the random codes of length n.
We have plotted in Figure 6 the normalized logarithm of the density of codewords of the form
(u|u) and (0|v) of relative even weight x4= wn against x in the case U is of rate
kU
n/2 = 0.6 and V
is of rate kVn/2 = 0.4. These two relative densities are defined respectively by
α(U |U)(w/n) =
log2(a(U |U)(w)/a(w))
n
; α(0|V )(w/n) =
log2(a(0|V )(w)/a(w))
n
We see that for a relative weight w/n below approximately 0.18 almost all the codewords are of
the form (0|v) in this case.
Fig. 6: α(U |U)(w/n) and α(0|V )(w/n) against x
4
= wn .
Since the weight distribution is invariant by permuting the positions, this slight difference also
survives in the permuted version of (U |U + V ). These considerations lead to the best attack we
have found for recovering the structure of a permuted (U |U + V ) code. It consists in applying
known algorithms aiming at recovering low weight codewords in a linear code. We run such an
algorithm until getting at some point either a permuted (u|u) codeword where u is in U or a
permuted (0|v) codeword where v belongs to V . The rationale behind this algorithm is that the
density of codewords of the form (u,u) or (0,v) is bigger when the weight of the codeword gets
smaller.
Once we have such a codeword we can bootstrap from there very similarly to what has been
done in [OT11, Subs. 4.4]. Note that this attack is actually very close in spirit to the attack that
was devised on the KKS signature scheme [OT11]. In essence, the attack against the KKS scheme
really amounts to recover the support of the V code. The difference with the KKS scheme is that
the support of V is much bigger in our case. As explained in the conclusion of [OT11] the attack
against the KKS scheme has in essence an exponential complexity. This exponent becomes really
prohibitive in our case when the parameters of U and V are chosen appropriately as we will now
explain.
6.2 Recovering the V code up to a permutation
The aforementioned attack recovers V up to some permutation of the positions. In a first step it
recovers a basis of
V ′
4
=(0|V )P = {(0,v)P : v ∈ V }.
A new signature scheme based on (U |U + V ) codes 23
Once this is achieved, the support Supp(V ′) of V ′ can be obtained. Recall that this is the set
of positions for which there exists at least one codeword of V ′ that is non-zero in this position.
This allows to recover the code V up to some permutation. The basic algorithm for recovering the
support of V ′ and a basis of V ′ is given in Algorithm 4.
Algorithm 4 ComputeV: algorithm that computes a set of independent elements in V ′.
Parameters: (i) ` : small integer (` 6 40),
(ii) p : very small integer (typically 1 6 p 6 10).
Input: (i) Cpub the public code used for verifying signatures.
(ii) N a certain number of iterations
Output: an independent set of elements in V ′
1: function ComputeV(Cpub,N)
2: for i = 1, . . . , N do
3: B ← ∅
4: Choose a set I ⊂ {1, . . . , n} of size n− k − ` uniformly at random
5: L ← Codewords(PuncI(Cpub), p)
6: for all x ∈ L do
7: x← Complete(x, I,Cpub)
8: if CheckV(x) then
9: add x to B if x /∈< B >
10: return B
It uses other auxiliary functions
– Codewords(PuncI(Cpub), p) which computes all (or a big fraction of) codewords of weight p of
the punctured public code PuncI(Cpub). All modern [Dum91, FS09, MMT11, BJMM12, MO15]
algorithms for decoding linear codes perform such a task in their inner loop.
– Complete(x, I,Cpub) which computes the codeword c in Cpub such that its restriction outside
I is equal to x.
– CheckV(x) which checks whether x belongs to V ′.
Choosing N appropriately. Let us first analyze how we have to choose N such that ComputeV
returns Ω(1) elements. This is essentially the analysis which can be found in [OT11, Subsec 5.2].
This analysis leads to
Proposition 9. The probability Psucc that one iteration of the for loop (Instruction 2) in Algo-
rithm 4 adds elements to the list B is lower-bounded by
Psucc ≥
n/2∑
w=0
(
n/2
w
)(
n/2
n−k−`−w
)(
n
n−k−`)
) f ((n/2− w
p
)
2kV +w−n/2
)
(8)
where f is the function defined by f(x)
4
= max
(
x(1− x/2), 1− 1x
)
. Algorithm 4 returns a non zero
list with probability Ω(1) when N is chosen as N = Ω
(
1
Psucc
)
.
Proof. It will be helpful to recall [OT11, Lemma 3]
Lemma 3. Choose a random code Crand of length n from a parity-check matrix of size r × n
chosen uniformly at random in Fr×n2 . Let X be some subset of Fn2 of size m. We have
P(X ∩ Crand 6= ∅) ≥ f
(m
2r
)
.
24 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
To lower-bound the probability Psucc that an iteration is successful, we bring in the following
random variables
I ′
4
= I ∩ Supp(I ′′) and W 4= |I ′|
where I ′′ is the set of positions that are of the images of the permutation P of the n/2 last positions.
ComputeV outputs at least one element of V ′ if there is an element of weight p in PuncI′(V
′).
Therefore the probability of success Psucc is given by
Psucc =
n/2∑
w=0
P(W = w)P (∃x ∈ V ′ : |xĪ′ | = p | W = w) (9)
where Ī ′
4
= Supp(V ′) \ I ′. On the other hand, by using Lemma 3 with the set
X
4
=
{
x = (xj)j∈Supp(V ′) : |xĪ′ | = p
}
which is of size
(
n/2−w
p
)
2w, we obtain
P (∃x ∈ V ′ : |xĪ′ | = p|W = w) ≥ f(x). (10)
with
x
4
=
(
n/2−w
p
)
2w
2n/2−kV
=
(
n/2− w
p
)
2kV +w−n/2
The first quantity is clearly equal to
P(W = w) =
(
n/2
w
)(
n/2
n−k−`−w
)(
n
n−k−`
) . (11)
Plugging in the expressions obtained in (10) and (11) in (9) we have an explicit expression of a
lower bound on Psucc
Psucc ≥
n/2∑
w=0
(
n/2
w
)(
n/2
n−k−`−w
)(
n
n−k−`)
) f ((n/2− w
p
)
2kV +w−n/2
)
(12)
The claim on the number N of iterations follows directly from this. ut
Complexity of recovering a permuted version of V . The complexity of a call to ComputeV
can be estimated as follows. The complexity of computing the list of codewords of weight p in a
code of length k + ` and dimension k is equal to C1(p, `) (this quantity is introduced in §5). It
depends on the particular algorithm used here [Dum91, FS09, MMT11, BJMM12, MO15]. This
is the complexity of the call Codewords(PuncI(Cpub), p) in Step 5 in Algorithm 4. The complexity
of ComputeV and hence the complexity of recovering a permuted version of V is clearly lower
bounded by Ω
(
C1(p,`)
Psucc
)
. It turns out that the whole complexity of recovering a permuted version
of V is actually of this order, namely Θ
(
C1(p,`)
Psucc
)
. This can be done by a combination of two
techniques
– Once a non-zero element of V ′ has been identified, it is much easier to find other ones. This
uses one of the tricks for breaking the KKS scheme (see [OT11, Subs. 4.4]). The point is the
following: if we start again the procedure ComputeV, but this time by choosing a set I on which
we puncture the code which contains the support of the codeword that we already found, then
the number N of iterations that we have to perform until finding a new element is negligible
when compared to the original value of N .
A new signature scheme based on (U |U + V ) codes 25
– The call to CheckV can be implemented in such a way that the additional complexity coming
from all the calls to this function is of the same order as the N calls to Codewords. The strategy
to adopt depends on the values of the dimensions k and kV . In certain cases, it is easy to detect
such codewords since they have a typical weight that is significantly smaller than the other
codewords. In more complicated cases, we might have to combine a technique checking first
the weight of x, if it is above some prescribed threshold, we decide that it is not in V ′, if it is
below the threshold, we decide that it is a suspicious candidate and use then the previous trick.
We namely check whether the support of the codeword x can be used to find other suspicious
candidates much more quickly than performing N calls to CheckV.
To keep the length of this paper within some reasonable limit we avoid here giving the analysis of
those steps and we will just use the aforementioned lower bound on the complexity of recovering
a permuted version of V .
6.3 Recovering the U code up to permutation
We consider here the permuted code
U ′
4
=(U |U)P = {(u,u)P : u ∈ U}.
The attack in this case consists in recovering a basis of U ′. Once this is done, it is easy to recover
the U code up to permutation by matching the pairs of coordinates which are equal in U ′. The
algorithm for recovering U ′ is the same as the algorithm for recovering V ′. We call the associated
function ComputeU though since they differ in the choice for N . The analysis is slightly different
indeed.
Choosing N appropriately. As in the previous subsection let us analyze how we have to choose
N in order that ComputeU returns Ω(1) elements of U ′. We have in this case the following result.
Proposition 10. The probability Psucc that one iteration of the for loop (Instruction 2) in Com-
puteU adds elements to the list B is lower-bounded by
Psucc ≥
n/2∑
w=0
(
n/2
w
)(
n/2−w
k+`−2w
)
2k+`−2w(
n
k+`
) bp/2cmax
i=0
f
( (
k+`−2w
p−2i
)(
w
i
)
2max(0,k+`−w−kU )
)
(13)
where f is the function defined by f(x)
4
= max
(
x(1− x/2), 1− 1x
)
. ComputeU returns a non zero
list with probability Ω(1) when N is chosen as N = Ω
(
1
Psucc
)
.
Proof. Here the crucial notion is the concept of matched positions. We say that two positions i
and j are matched if and only if ci = cj for every c ∈ U ′. There are clearly n/2 pairs of matched
positions. W will now be defined by the number of matched pairs that are included in {1, . . . , n}\I.
We compute the probability of success as before by conditioning on the values taken by W :
Psucc =
n/2∑
w=0
P(W = w)P (∃x ∈ U ′ : |xĪ | = p |W = w) (14)
where Ī
4
={1, . . . , n}\I. Notice that we can partition Ī as Ī = J1∪J2 where J2 consists in the union
of the matched pairs in Ī. Note that |J2| = 2w. We may further partition J2 as J2 = J21 ∪ J22
where the elements of a matched pair are divided into the two sets. In other words, neither J21
nor J22 contains a matched pair. We are going to consider the codes
U”
4
= Punc
I
(U ′)
U ′′′
4
= Punc
I∪J22
(U ′)
26 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
The last code is of length k + `− w. The point of defining the first code is that
P (∃x ∈ U ′ : |xĪ | = p | W = w)
is equal to the probability that U” contains a codeword of weight p. The problem is that we can
not apply Lemma 3 to it due to the matched positions it contains. This is precisely the point of
defining U ′′′. In this case, we can consider that it is a random code whose parity-check matrix is
chosen uniformly at random among the set of matrices of size max(0, k+ `−w−kU )× (k+ `−w).
We can therefore apply Lemma 3 to it. We have to be careful about the words of weight p in
U” though, since they do not have the same probability of occurring in U” due to the possible
presence of matched pairs in the support. This is why we introduce for i in {0, . . . , bp/2c} the sets
Xi defined as follows
Xi
4
={x = (xi)i∈Ī\J22F
k+`−w
2 : |xJ1 | = p− 2i, |xJ21 | = i}
A codeword of weight p in U” corresponds to some word in one of the Xi’s by puncturing it in
J22. We obviously have the lower bound
P {∃x ∈ U ′ : |xĪ | = p | W = w} ≥
bp/2c
max
i=0
{P(Xi ∩ U ′′′ 6= ∅)} (15)
By using Lemma 3 we have
P(Xi ∩ U ′′′ 6= ∅) ≥ f
( (
k+`−2w
p−2i
)(
w
i
)
2max(0,k+`−w−kU )
)
. (16)
On the other hand, we may notice that P(W = w) = P(w2(e) = w) when e is drawn uniformly at
random among the binary words of weight k + ` and length n. By using Proposition 4 we deduce
P(W = w) =
(
n/2
w
)(
n/2−w
k+`−2w
)
2k+`−2w(
n
k+`
) .
These considerations lead to the following lower bound on Psucc
Psucc ≥
n/2∑
w=0
(
n/2
w
)(
n/2−w
k+`−2w
)
2k+`−2w(
n
k+`
) bp/2cmax
i=0
f
( (
k+`−2w
p−2i
)(
w
i
)
2max(0,k+`−w−kU )
)
(17)
ut
Complexity of recovering a permuted version of U . As for recovering the permuted V
code, the complexity for recovering the permuted U is of order Ω
(
C1(p,`)
Psucc
)
.
6.4 Distinguishing a (U |U + V ) code
It is not clear in the first case that from the single knowledge of V ′ and a permuted version of V
we are able to find a permutation of the positions which gives to the whole code the structure of
a (U |U + V )-code. However in both cases as single successful call to ComputeV (resp. ComputeU)
is really distinguishing the code from a random code of the same length and dimension. In other
words, we have a distinguishing attack whose complexity is given by min(O(CU ), O(CV )) where
CU
4
=
C1(p, `)∑n/2
w=0
(n/2w )(
n/2−w
k+`−2w)2k+`−2w
( nk+`)
max
bp/2c
i=0 f
(
(k+`−2wp−2i )(
w
i )
2max(0,k+`−w−kU )
)
CV
4
=
C1(p, `)∑n/2
w=0
(n/2w )(
n/2
n−k−`−w)
( nn−k−`)
f
((
n/2−w
p
)
2kV +w−n/2
)
A new signature scheme based on (U |U + V ) codes 27
and f(x)
4
= max (x(1− x/2), 1− 1/x). As for the decoders of §5 the above numbers are minimized
(independently) over p and `.
We end this section by remarking that the dual of a code (U |U +V ) is (U⊥+V ⊥|V ⊥) thus we
have the same attack with the dual. With k/n = 0.5, these two attacks have the same complexity
as CU = CV ⊥ and CV = CU⊥ .
7 Parameter Selection
In the light of the security proof in §3 and the rejection sampling method in §4, we need to derive
parameters which lead to negligible success for the two following problems:
1. Solve a syndrome decoding problem with multiple instances (DOOM) for parameters n, k, w
and an arbitrarily large number of instances.
2. Distinguish public matrices of the code family (U |U + V ) from random matrices of same size.
In the security proof we required a salt size λ0 = λ + 2 log2(qsig) where qsig is the number
of signature queries allowed to the adversary. Since qsig ≤ 2λ (λ the security parameter) we
choose a conservative λ0 = 3λ. We gave in §5 and §6 state-of-the-art algorithms for the two
problems mentioned above. This served as a basis for the parameters proposed in Table 2. For
the key security, the estimates CU and CV are derived from the formulas at the end of §6. In
those formulas the C1(p, `) term derives from Dumer’s algorithm. Using more involved techniques
[MMT11, BJMM12, MO15] will reduce the key security but will leave it above the security claims.
For the message security (log2 WF), it is based on the DOOM variant of Dumer’s algorithm, which
is the current state-of-the-art. Algorithmic improvements, like adapting DOOM to BJMM, may
lower the message security and require an adjustment of the sizes.
λ (security) 80 128 256
n 4678 7486 14970
k 2339 3743 7485
kV 899 1439 2878
w 889 1422 2844
Signature length (bits) 4918 7870 15738
Public key size (MBytes) 0.683 1.75 7.00
log2 CV (§6) 163 260 521
log2 CU (§6) 250 400 800
log2 WF (§5) 80 128 256
Table 2: Proposed Parameters for the (U | U + V ) Signature Scheme
Note also that there is an additive term qhash/2
√
2n−k/
(
n
w
)
in the adversary’s advantage
(see Theorem 2 in the security proof §3). With the current parameters, we have k = n/2 and(
n
w
)
≈ 20.70n, and the above term is of order qhash2−n/10 which is always negligible.
Implementation. In Table 2 the ratio w/n is chosen close to 0.19 to minimize the rejection
probability (see §4). For the three security levels we need to perform on average 27, 37, or 75
Gaussian eliminations to produce a signature. Most of those Gaussian elimination are performed
on parity check matrices of shortened codes. Finally, let us mention that the signature length
(n+ 3λ in the table) can be reduced (by about 30%) by choosing a compact representation of the
sparse error vector.
8 Concluding remarks
We have presented a new code-based signature scheme which is EUF-CMA secure under two
assumptions from coding theory. Both of those assumptions relate closely to hard decoding prob-
lems. Two nice features of this scheme are its simplicity and the fact that it is very close to rely
28 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
on random linear codes: it is based on (U |U + V ) codes where U and V are random linear codes
of appropriate dimensions. Using rejection sampling, we have shown how to efficiently avoid key
leakage from any number of signatures. The main purpose of our work was to propose this new
scheme, give a proof security and assess its security against current knowledge. It scales well with
respect to the security parameter λ expressed in bits (S = 2λ measures the complexity of the best
known attack), since the key size, signature size, signature generation time and signature verifi-
cation time are respectively of order O(λ2), O(λ), O(λ3) and O(λ2). This is the first code-based
signature scheme with a security parameter which scales polynomially in key size. By code-based
scheme, we mean here the restricted case where we are interested in binary linear codes and we
use the Hamming metric for expressing the decoding problem. This setting presents the advantage
that we are in the case where the decoding problem has been thoroughly studied for many decades
and where it can be considered that the complexity of the best known attacks has not dramatically
changed since the early sixties.
Comparison with RankSign. Recently another code-based signature scheme whose security
relies on decoding codes with respect to the rank metric has been proposed in [GRSZ14]. It is
called RankSign. Strictly speaking, the rank metric consists in viewing an element in FNq (when
N is a product N = m × n) as an m × n matrix over Fq and the rank distance between two
elements x and y is defined as the rank of the matrix x − y. This depends of course on how
N is viewed as a product of two elements. Decoding in this metric is known to be an NP hard
problem [BFS99, Cou01]. In the particular case of [GRSZ14], the codes which are considered are
not Fq-linear but, as is customary in the setting of rank metric based cryptography, Fqm -linear.
This allows to reduce the keysize by a factor of m when compared to the Fq-linear setting (for
more details see for instance §2, just below Def. 2.3 in [HT15]).
This is generally the key explanation why rank cryptographic systems (when the codes are
actually linear on an extension field Fqm of Fq) have generally shorter keysizes than Hamming
metric schemes. This is also the key reason why compared to the scheme proposed here, RankSign
enjoys much shorter key sizes: it is of order tens of thousands bits for 128 bits of security. In some
sense, the codes used in [GRSZ14] are more structured than just Fq linear codes. Decoding such
codes for the rank metric is not known to be NP-hard anymore. There is however a randomized
reduction of this problem to decoding an Fq-linear code for the Hamming metric [GZ16] when the
degree m of the extension field is sufficiently big. This situation is in some sense reminiscent to the
current thread in cryptography based on codes or on lattices where structured codes (for instance
quasi-cyclic codes) or structured lattices (corresponding to an additional ring structure) are taken.
In the case at hand, there is however a randomized reduction to an NP complete problem (even if
this reduction seems really loose and is not used to devise secure parameters for those schemes).
Note however that contrarily to the quasi-cyclic case where it is not known whether decoding a
quasi-cyclic code can be done faster than with a polynomial speedup when compared to a generic
linear code, it is known how to use the Fqm-linearity of the code to decrease the exponent of
the rank metric analogue of the Prange algorithm for decoding [GRS16]. There are also other
algorithms for decoding in the rank metric that really use the Fqm-linearity (see [GRS16] again).
Our signature scheme offers however a significant advantage over RankSign when it comes to
the security proof. First even if RankSign has a partial security proof showing that when the
number of signatures is smaller than q/2 it does not leak information, there is no overall reduction
of the security scheme to well identified problems in (rank metric) coding theory. Second, the fact
that the number of signatures has to be smaller than q/2 to avoid information leakage represents a
strong constraint on the parameters of the RankSign scheme. The problem of information leakage
coming from signatures originating from a same public key is in general the main threat on
signature schemes and it is handled in our case in a very satisfying fashion by a rejection sampling
method which ensures statistical indistinguishability of the signatures when compared to random
words of the same weight. It should also be added that our signature relies on the Hamming metric
and that irrespective of the merits of a signature scheme based on the rank metric it is probably
A new signature scheme based on (U |U + V ) codes 29
desirable to have also a signature scheme working for the Hamming metric due to the general faith
in the hardness of decoding with this metric.
Reducing the keysize. The previous comparison with RankSign raises the issue whether it would
be possible to reduce the keysize of the signature scheme proposed here. One obvious approach
which comes to mind is to use more structured codes such as quasi-cyclic codes. There are two
issues with this research thread. The first is that this degrades key security and this has to be
taken into account into the distinguisher of Section 6. This certainly requires to use only quasi-
cyclic codes with small circulant blocks and will allow only for some moderate gains in the keysize.
Second, this also changes somehow the security proof and in particular the arguments used for
instance in Game 2. Another related way to reduce the keysize would be to take advantage of the
gap of the best attack against the key and the best attack for forging a signature to change a little
bit the scheme to degrade a little bit key security but by improving the security against forgeries.
This suggests that there might exist other choices of code parameters with different and possibly
better features.
Implementation issues. Though rejection sampling in our algorithm is relatively unobtrusive
(a few samples per signature) we did not examine how much impact a loss of accuracy in the
calculations could have on the amount of key leakage. Also, we need to implement generic decoding
for producing signatures and we use a plain Prange algorithm for that. Efficiency could be improved
by using Dumer [Dum91] or MMT [MMT11] algorithm, but they must first be adapted to produce
provably independent outputs.
References
Arı09. Erdal Arıkan. Channel polarization: a method for constructing capacity-achieving codes for
symmetric binary-input memoryless channels. IEEE Trans. Inform. Theory, 55(7):3051–3073,
2009.
Bar97. Alexander Barg. Complexity issues in coding theory. Electronic Colloquium on Computational
Complexity, October 1997.
BBC+13. Marco Baldi, Marco Bianchi, Franco Chiaraluce, Joachim Rosenthal, and Davide Schipani.
Using LDGM codes and sparse syndromes to achieve digital signatures. In Post-Quantum
Cryptography 2013, volume 7932 of LNCS, pages 1–15. Springer, 2013.
BCD+16. Magali Bardet, Julia Chaulet, Vlad Dragoi, Ayoub Otmani, and Jean-Pierre Tillich. Crypt-
analysis of the McEliece public key cryptosystem based on polar codes. In Post-Quantum
Cryptography2016, LNCS, pages 118–143, Fukuoka, Japan, February 2016.
BDK+11. Boaz Barak, Yevgeniy Dodis, Hugo Krawczyk, Olivier Pereira, Krzysztof Pietrzak, François-
Xavier Standaert, and Yu Yu. Leftover hash lemma, revisited. In Advances in Cryptology -
CRYPTO 2011 - 31st Annual Cryptology Conference, Santa Barbara, CA, USA, August 14-18,
2011. Proceedings, pages 1–20, 2011.
Ber10. Daniel J. Bernstein. Grover vs. McEliece. In Nicolas Sendrier, editor, Post-Quantum Cryptog-
raphy 2010, volume 6061 of LNCS, pages 73–80. Springer, 2010.
BFS99. Jonathan F. Buss, Gudmund S. Frandsen, and Jeffrey O. Shallit. The computational complexity
of some problems of linear algebra. J. Comput. System Sci., 58(3):572–596, June 1999.
BJMM12. Anja Becker, Antoine Joux, Alexander May, and Alexander Meurer. Decoding random binary
linear codes in 2n/20: How 1 + 1 = 0 improves information set decoding. In Advances in
Cryptology - EUROCRYPT 2012, LNCS. Springer, 2012.
BMS11. Paulo S.L.M Barreto, Rafael Misoczki, and Marcos A. Jr. Simplicio. One-time signature scheme
from syndrome decoding over generic error-correcting codes. Journal of Systems and Software,
84(2):198–204, 2011.
BR93. Mihir Bellare and Phillip Rogaway. Random oracles are practical: A paradigm for designing
efficient protocols. In CCS ’93, Proceedings of the 1st ACM Conference on Computer and
Communications Security, Fairfax, Virginia, USA, November 3-5, 1993., pages 62–73, 1993.
BR96. Mihir Bellare and Phillip Rogaway. The exact security of digital signatures-how to sign with
rsa and rabin. In Advances in Cryptology - EUROCRYPT ’96, volume 1070 of LNCS, pages
399–416. Springer, 1996.
30 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
CFS01. Nicolas Courtois, Matthieu Finiasz, and Nicolas Sendrier. How to achieve a McEliece-based
digital signature scheme. In Advances in Cryptology - ASIACRYPT 2001, volume 2248 of
LNCS, pages 157–174, Gold Coast, Australia, 2001. Springer.
CJ04. Jean-Sebastien Coron and Antoine Joux. Cryptanalysis of a provably secure cryptographic
hash function. IACR Cryptology ePrint Archive, Report 2004/013, 2004. http://eprint.
iacr.org/.
Cor02. Jean-Sébastien Coron. Optimal security proofs for PSS and other signature schemes. In
Advances in Cryptology - EUROCRYPT 2002, International Conference on the Theory and
Applications of Cryptographic Techniques, Amsterdam, The Netherlands, April 28 - May 2,
2002, Proceedings, pages 272–287, 2002.
Cou01. Nicolas Courtois. Efficient zero-knowledge authentication based on a linear algebra problem
MinRank. In Advances in Cryptology - ASIACRYPT 2001, volume 2248 of LNCS, pages 402–
421, Gold Coast, Australia, 2001. Springer.
COV07. Pierre-Louis Cayrel, Ayoub Otmani, and Damien Vergnaud. On Kabatianskii-Krouk-Smeets
signatures. In Arithmetic of Finite Fields - WAIFI 2007, volume 4547 of LNCS, pages 237–251,
Madrid, Spain, June 21–22 2007.
CTS16. Rodolfo Canto-Torres and Nicolas Sendrier. Analysis of information set decoding for a sub-
linear error weight. In Post-Quantum Cryptography 2016, LNCS, pages 144–161, Fukuoka,
Japan, February 2016.
DAT17. Thomas Debris-Alazard and Jean-Pierre Tillich. Statistical decoding. preprint, January 2017.
arXiv:1701.07416.
Dum91. Ilya Dumer. On minimum distance decoding of linear codes. In Proc. 5th Joint Soviet-Swedish
Int. Workshop Inform. Theory, pages 50–52, Moscow, 1991.
FGO+11. Jean-Charles Faugère, Valérie Gauthier, Ayoub Otmani, Ludovic Perret, and Jean-Pierre
Tillich. A distinguisher for high rate McEliece cryptosystems. In Proc. IEEE Inf. Theory
Workshop- ITW 2011, pages 282–286, Paraty, Brasil, October 2011.
FGO+13. Jean-Charles Faugère, Valérie Gauthier, Ayoub Otmani, Ludovic Perret, and Jean-Pierre
Tillich. A distinguisher for high rate McEliece cryptosystems. IEEE Trans. Inform. Theory,
59(10):6830–6844, October 2013.
Fin10. Matthieu Finiasz. Parallel-CFS - strengthening the CFS McEliece-based signature scheme.
In Selected Areas in Cryptography 17th International Workshop, 2010, Waterloo, Ontario,
Canada, August 12-13, 2010, revised selected papers, volume 6544 of LNCS, pages 159–170.
Springer, 2010.
FS09. Matthieu Finiasz and Nicolas Sendrier. Security bounds for the design of code-based cryp-
tosystems. In M. Matsui, editor, Advances in Cryptology - ASIACRYPT 2009, volume 5912 of
LNCS, pages 88–105. Springer, 2009.
GRS16. Philippe Gaborit, Olivier Ruatta, and Julien Schrek. On the complexity of the rank syndrome
decoding problem. IEEE Trans. Information Theory, 62(2):1006–1019, 2016.
GRSZ14. Philippe Gaborit, Olivier Ruatta, Julien Schrek, and Gilles Zémor. New results for rank-based
cryptography. In Progress in Cryptology - AFRICACRYPT 2014, volume 8469 of LNCS, pages
1–12, 2014.
GS12. Philippe Gaborit and Julien Schrek. Efficient code-based one-time signature from automor-
phism groups with syndrome compatibility. In Proc. IEEE Int. Symposium Inf. Theory -
ISIT 2012, pages 1982–1986, Cambridge, MA, USA, July 2012.
GSJB14. Danilo Gligoroski, Simona Samardjiska, H̊akon Jacobsen, and Sergey Bezzateev. McEliece in
the world of Escher. IACR Cryptology ePrint Archive, Report2014/360, 2014. http://eprint.
iacr.org/.
GZ16. Philippe Gaborit and Gilles Zémor. On the hardness of the decoding and the minimum distance
problems for rank codes. IEEE Trans. Information Theory, 62(12):7245–7252, 2016.
HT15. Adrien Hauteville and Jean-Pierre Tillich. New algorithms for decoding in the rank metric and
an attack on the LRPC cryptosystem, 2015. abs/1504.05431.
JJ02. Thomas Johansson and Fredrik Jönsson. On the complexity of some cryptographic problems
based on the general decoding problem. IEEE Trans. Inform. Theory, 48(10):2669–2678, Oc-
tober 2002.
KKS97. Gregory Kabatianskii, Ernst Krouk, and Ben. J. M. Smeets. A digital signature scheme based
on random error-correcting codes. In IMA Int. Conf., volume 1355 of LNCS, pages 161–167.
Springer, 1997.
KKS05. Gregory Kabatianskii, Ernst Krouk, and Ben. J. M. Smeets. Error Correcting Coding and
Security for Data Networks: Analysis of the Superchannel Concept. John Wiley & Sons, 2005.
A new signature scheme based on (U |U + V ) codes 31
Kor09. Satish Babu Korada. Polar Codes for Channel and Source Coding. PhD thesis, ’Ecole Poly-
technique Fédérale de Lausanne (EPFL), July 2009.
KT17. Ghazal Kachigar and Jean-Pierre Tillich. Quantum information set decoding algorithms.
preprint, arXiv:1703.00263 [cs.CR], February 2017.
LJ12. Carl Löndahl and Thomas Johansson. A new version of McEliece PKC based on convolutional
codes. In Information and Communications Security, ICICS, volume 7168 of LNCS, pages
461–470. Springer, 2012.
LT13. Grégory Landais and Jean-Pierre Tillich. An efficient attack of a McEliece cryptosystem variant
based on convolutional codes. In P. Gaborit, editor, Post-Quantum Cryptography’13, volume
7932 of LNCS, pages 102–117. Springer, June 2013.
MCT16. Irene Márquez-Corbella and Jean-Pierre Tillich. Using Reed-Solomon codes in the (u|u + v)
construction and an application to cryptography. preprint, 2016. arXiv:1601:08227.
MMT11. Alexander May, Alexander Meurer, and Enrico Thomae. Decoding random linear codes in
O(20.054n). In Dong Hoon Lee and Xiaoyun Wang, editors, Advances in Cryptology - ASI-
ACRYPT 2011, volume 7073 of LNCS, pages 107–124. Springer, 2011.
MO15. Alexander May and Ilya Ozerov. On computing nearest neighbors with applications to decod-
ing of binary linear codes. In E. Oswald and M. Fischlin, editors, Advances in Cryptology -
EUROCRYPT 2015, volume 9056 of LNCS, pages 203–228. Springer, 2015.
MS09. L. Minder and A. Sinclair. The extended k-tree algorithm. In C. Mathieu, editor, Proceedings
of SODA 2009, pages 586–595. SIAM, 2009.
Nie86. Harald Niederreiter. Knapsack-type cryptosystems and algebraic coding theory. Problems of
Control and Information Theory, 15(2):159–166, 1986.
OT11. Ayoub Otmani and Jean-Pierre Tillich. An efficient attack on all concrete KKS proposals. In
Post-Quantum Cryptography 2011, volume 7071 of LNCS, pages 98–116, 2011.
Pra62. Eugene Prange. The use of information sets in decoding cyclic codes. IRE Transactions on
Information Theory, 8(5):5–9, 1962.
PT16. Aurélie Phesso and Jean-Pierre Tillich. An efficient attack on a code-based signature scheme.
In Post-Quantum Cryptography 2016, volume 9606 of LNCS, pages 86–103, Fukuoka, Japan,
February 2016. Springer.
Sen11. Nicolas Sendrier. Decoding one out of many. In Post-Quantum Cryptography 2011, volume
7071 of LNCS, pages 51–67, 2011.
Sho04. Victor Shoup. Sequences of games: a tool for taming complexity in security proofs. IACR
Cryptology ePrint Archive, 2004:332, 2004.
SK14. Sujan Raj Shrestha and Young-Sik Kim. New McEliece cryptosystem based on polar codes
as a candidate for post-quantum cryptography. In 2014 14th International Symposium on
Communications and Information Technologies (ISCIT), pages 368–372. IEEE, 2014.
Ste88. Jacques Stern. A method for finding codewords of small weight. In G. D. Cohen and J. Wolf-
mann, editors, Coding Theory and Applications, volume 388 of LNCS, pages 106–113. Springer,
1988.
Ste93. Jacques Stern. A new identification scheme based on syndrome decoding. In D.R. Stinson,
editor, Advances in Cryptology - CRYPTO’93, volume 773 of LNCS, pages 13–21. Springer,
1993.
Wag02. David Wagner. A generalized birthday problem. In Moti Yung, editor, Advances in Cryptology
- CRYPTO 2002, volume 2442 of LNCS, pages 288–303. Springer, 2002.
32 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
A Proofs for §3
A.1 List Emulation
In the security proof, we need to build lists of indices (salts) in Fλ02 . Those lists have size qsign, the
maximum number of signature queries allowed to the adversary, a number which is possibly very
large. For each message m which is either hashed or signed in the game we need to be able to
– create a list Lm of qsign random elements of Fλ02 , using the constructor new list,
– pick an element in Lm, using the method Lm.next, this element can be picked only once,
– decide whether or not a given salt r is in Lm, using the method Lm.contains.
The straightforward manner to achieve this is to draw qsign random numbers when the list is
constructed, this has to be done once for each different message m used in the game. This may
result in a quadratic cost qhashqsign just to build the lists. Once the lists are constructed, and
assuming they are stored in a proper data structure (a heap for instance) picking an element or
testing membership has a cost at most O(log qsign), that is at most linear in the security parameter
λ.
class list method list.contains(r)
elt, index return r ∈ {elt[i], 1 ≤ i ≤ qsign}
list()
index← 0 method list.next()
for i = 1, . . . , qsign index← index + 1
elt[i]← randint(2λ0) return elt[index]
Instead we may emulate the lists and never construct them explicitly as above. At any point
in the game, we will denote by Sm the list of values of r such that Sign(m) was queried and
returned r and we will denote by Hm the list of values of r such that Hash(m, r) was queried,
partitioned in Htruem and H
false
m depending on the return value. The three attributes of the class
list, namely in, out and used, will contain the elements of Htruem , H
false
m and Sm respectively.
In all those lists elements may appear several times, however in the current setting, the game is
aborted earlier (Game 1) whenever a salt is used more than once in a signature of m, it follows
that in the above lists no element can appear more than once.
class list method list.contains(r) method list.next()
in, out, used if r 6∈ in ∪ out ∪ used if rand() ≤ γ
list() if rand() ≤ β r← in.pop()
in← ∅ in.push(r) else
out← ∅ else r←↩ Fλ02 \ (in ∪ out ∪ used)
used← ∅ out.push(r) used.push(r)
return r ∈ in ∪ used return r
All push, pop, membership testing above can be implemented in time proportional to λ0. The
method pop removes randomly an element from the list and returns it. The method push adds
an element in a list. The procedure rand() picks uniformly a real number between 0 and 1. We
denote
β = 1−
(
1− 1
2λ0 − |Hm| − |Sm|
)qsign−|Htruem |−|Sm|
and γ =
|Htruem |
qsign − |Sm|
.
For the emulation to be correct we need the following to hold
Proposition 11. At any point of the game, for any message m, and for all r ∈ Fλ02 , we have
(i) P[Lm.contains(r)] = P[r ∈ Lm]
(ii) P[r← Lm.next()] = P[r←↩ Lm \ Sm]
A new signature scheme based on (U |U + V ) codes 33
Proof. First recall that the game will abort if at some point the same r is returned for signing m.
It follows that Htruem , H
false
m and Sm are disjoint and never contain duplicate elements.
(i) If r ∈ Htruem ∪ Sm both probabilities equal 1 and if r ∈ Hfalsem both probabilities equal 0.
If r 6∈ Sm∪Hm. There are qsign−|Htruem |−|Sm| slots are available in Lm and 2λ0−|Hm|−|Sm|
possible values remaining. Thus
P[r ∈ Lm] = 1−
(
1− 1
2λ0 − |Hm| − |Sm|
)qsign−|Htruem |−|Sm|
= β = P[Lm.contains(r)]
(ii) If r ∈ Hfalsem ∪ Sm both probabilities equal 0.
If r ∈ Htruem , then r ∈ Lm \ Sm and
P[r←↩ Lm \ Sm] =
1
qsign − |Sm|
In the emulated call Lm.next(), if r ∈ Htruem it is returned with probability γ/|Htruem |, which
is the same.
Finally, if r 6∈ Hm ∪ Sm, the value r is among the 2λ0 − |Hm| − |Sm| values that have not
been seen yet by the algorithm and all those values are equally likely to be drawn in both
cases.
A.2 Proof of Lemma 1
The goal of this subsection is to estimate the probability of a collision in a signature query for a
message m when we allow at most qsign queries (the event F in the security proof) and to deduce
Lemma 1 of §3.3. We recall that in Scode for each signature query, we pick r uniformly at random
in {0, 1}λ0 . Then the probability we are looking for is bounded by the probability to pick the same
r at least twice after qsign draws. The following lemma will be useful.
Lemma 4. The probability to have at least one collision after drawing uniformly and indepen-
dently t elements in a set of size n is upper bounded by t2/n for sufficiently large n and t2 < n.
Proof. The probability of no collisions after drawing independently t elements among n is:
pn,t
4
=
t−1∏
i=0
(
1− i
n
)
≥ 1−
t−1∑
i=0
i
n
= 1− t(t− 1)
2n
from which we easily get 1− pn,t ≤ t2/n, concluding the proof.
In our case, the probability of the event F is bounded by the previous probability for t = qsign
and n = 2λ0 , so, with λ0 = λ+ 2 log2 qsign, we can conclude that
P (F ) ≤
q2sign
2λ0
=
1
2λ0−2 log2(qsign)
=
1
2λ
which concludes the proof of Lemma 1.
A.3 Proof of Lemma 2
Our goal in this subsection is to prove Lemma 2 of §3.3 which asserts that syndromes by Hpub of
errors of weight w are indistinguishable from random elements in Fn−k2 :
Lemma 2.
P(S1) ≤ P(S2) +
1
2
qhash
√
2n−k(
n
w
) + 2ρc (DF ,DR) (t ·O(n2))
34 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
Let us first introduce two distributions:
– F0 is defined as the distribution of {(H,HeTj ), 1 ≤ j ≤ q} where the ej ’s are drawn uniformly
at random in Sw and H is drawn uniformly at random in F .
– The distribution F1 is defined as the distribution of {(H, sTj ), 1 ≤ j ≤ q} where the sj ’s are
drawn uniformly at random in Fn−k2 and H is drawn uniformly at random in F .
– Similarly, we define the distributions R0 and R1 for H←↩ F(n−k)×n2 .
We now observe that (we use here notations of the security proof in §3.3)
|P(S1)− P(S2)| ≤ ρc (F0,F1) (t). (18)
Moreover, from the metric-like properties of the computational distance we have:
ρc (F0,F1) (t) ≤ ρc (F0,R0) (t) + ρc (R0,R1) (t) + ρc (R1,F1) (t). (19)
We upper-bound the first term and the last term of the sum through the following lemma.
Lemma 5.
ρc (F0,R0) (t) ≤ ρc
(
DF ,DR
) (
t+O(qn2)
)
(20)
ρc (F1,R1) (t) ≤ ρc
(
DF ,DR
)
(t+O(qn)) . (21)
Proof. We construct an algorithm A ′ with advantage ρc (F0,R0) (t) distinguishing between DF
and DR from an algorithm A of complexity ≤ t distinguishing with advantage ρc (F0,R0) (t) be-
tween F0 and R0 as follows. From the sample H that we have, we construct q syndromes HeTj ’s by
drawing uniformly at random q samples e1, . . . , eq from Sw. This takes time O(qn
2). Then we apply
A on the sample {(H, sTj ), 1 ≤ j ≤ q}. This is our algorithm A ′ for distinguishing between DF
and DR. The advantage of this algorithm is by definition smaller than ρc
(
DF ,DR
) (
t+O(qn2)
)
.
This shows (20). (21) is proved in a similar fashion. ut
We are now going to bound ρc (R0,R1). We start by using Theorem 1
ρc (R0,R1) (t) ≤ ρ (R0,R1) .
Let us bring in for this purpose two auxiliary distributions. Let us first define R′0 as the distribution
of (
H,HeT
)
where H←↩ Fn−k2 and e←↩ Sw
whereas R′1 is the distribution of
(H, s) where H←↩ Fn−k2 and s←↩ F
n−k
2 .
These distributions are very similar to R0 and R1. The distribution Ri is in the proof of security
a sample of qhash independent syndromes obtianed from the same matrix H. We can use here
Proposition 3 and obtain
ρ (R0,R1) ≤ qhash ρ (R′0,R′1) . (22)
We are now going to bound ρ (R′0,R
′
1) with the leftover hash lemma. For this purpose, let us recall
the following definition.
Definition 14 (Universal Hashing). A family H of deterministic functions h : X → {0, 1}v
is a called a universal hash family if for any x1 6= x2 ∈X we have Ph←↩H (h(x1) = h(x2)) ≤ 12v .
In our case, we define the family H as the set
{
H : H ∈ F(n−k)×n2
}
acting on Sv:
H : Sw −→ Fn−k2 .
e 7→ HeT
A new signature scheme based on (U |U + V ) codes 35
Lemma 7 in §C shows that
PH←↩Fn−k2
(
HeT1 = He
T
2
)
=
1
2n−k
.
It follows that H is a universal hash family. We recall now the following lemma which is known
as the leftover hash Lemma (see for instance [BDK+11]).
Lemma 6. Let H be a universal hash family of functions h : X → {0, 1}v. Let D be the distri-
bution of h(X) where h is drawn uniformly at random in H and X is a random variable taking
its values in X . Let m
4
=− log2
(
max
x∈X
P (X = x)
)
be the min entropy of X. Then
ρ(D ,Uv) ≤
1
2
√
2v
2m
.
Let X be a random variable whose distribution is Uw and let D be the distribution of HXT where
H←↩ F(n−k)×n2 . We observe that
ρ (R′0,R
′
1) = ρ (D ,Un−k) .
We can therefore apply the leftover hash lemma. For this, let us compute the min entropy of X.
It is readily verified that it is equal to
− log2
(
1(
n
w
)) = log2(nw
)
.
which leads to the conclusion:
ρ (R′0,R
′
1) ≤
1
2
√
2n−k(
n
w
) (23)
By plugging results of Lemma 5, (19), (22) and (23) in (18) we get:
P (S1) ≤ P (S2) +
1
2
qhash
√
2n−k(
n
w
) + 2ρc (DF ,DR) (t+O(qn2))
which concludes the proof.
B Proofs for §4
B.1 Proof of Propositions 5 and 6
Let us recall Proposition 5
Proposition 5. Let p(i)
4
=Py,θ(|ϕ(V,y)| = i). If two executions of ϕ are independent, then for
all i in {0, . . . , w} such that w − i ≡ 0 (mod 2) we have
psdd2
(
w − i
2
)
= psdd1 (i) =
xi p(i)
p1w
(4)
where
p1w
4
=
∑
0≤j≤w
j≡w (mod 2)
xj p(j)
and psdd1 (i) = 0 for other choices of i.
36 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
Proof. Let e be the output of Algorithm 2. Recall that
psdd1 (j)
4
=P (w1(e) = j) .
As two executions of ϕ are independent, by a disjunction of independent events the probability to
get an error e such that w1(e) = i is given by:
+∞∑
l=0
αlβi =
βi
1− α
(24)
where α denotes the probability that the output of ϕ at Instruction 2 of Algorithm 2 is rejected
and βi the probability to have an error of weight i which is accepted. These probabilities are
readily seen to be equal to:
βi = p(i)xi ; α = 1−
∑
0≤j≤w
j≡w (mod 2)
xjp(j).
Plugging this expression in (24) finishes the proof. ut
Let us recall now Proposition 6
Proposition 6. If the source decoder ϕ used in Algorithm 2 behaves uniformly for V and uni-
formly for PunceV (U) for all error patterns eV obtained as eV = ϕ(V,y1 + y2), we have:
ρ (Dw,Uw) = ρ
(
psdd1 , p
u
1
)
The output of Algorithm 2 is the uniform distribution over Sw if in addition two executions of ϕ
are independent and the no-rejection probability vector x is chosen for any i in {0, . . . , w} as
xi =
1
Mrs
pu1 (i)
p(i)
if w ≡ i (mod 2)
and 0 otherwise with Mrs
4
= sup
0≤i≤w
i≡w (mod 2)
pu1 (i)
p(i) .
Proof. Let us first introduce some notation. Let e be a random variable whose distribution is Uw,
i.e. the uniform distribution over Sw, and let ẽ be a random variable whose distribution is Dw.
The last random variable can be viewed in a natural way as the ouput of Algorithm 2 and is of
the form ẽ = (eU |eU + eV ). We view eU and eV as random variables. We have
ρ (Dw,Uw) =
∑
e1,e2∈Fn/22 :|(e1|e2)|=w
|P(ẽ = (e1|e2))− P(e = (e1|e2))| . (25)
We notice now that
P(ẽ = (e1|e2)) = P(eU = e1|eV = e1 + e2)P(eV = e1 + e2)
= P(eU = e1|eV = e1 + e2)P(y1,y2),θ(ϕ(V,y1 + y2) = e1 + e2) (26)
From the assumption on the uniform behavior of ϕ we deduce that P(y1,y2),θ(ϕ(V,y1 + y2) =
e1 +e2) only depends on the Hamming weight |e1 +e2| of e1 +e2. We recall now that in Algorithm
2 we have
eU = y1 + u where
u =
U
Comp
eV
(Punc
eV
(y1) + e
′
U ) with
e′U = ϕ(w−|eV |)/2(PunceV
(U),Punc
eV
(y1)).
A new signature scheme based on (U |U + V ) codes 37
Let
n′ = n/2− |e|
w′
4
=
w − |e|
2
U ′
4
= Punc
eV
(U).
It will also be convenient to split y1, eU and e1 into two parts: the first one, denoted respectively
by y′1, e
′
U , and e
′
1 is the restriction of these vectors to the complement of the support of eV ,
whereas the second one, denoted respectively by y′′1 , e
′′
U and e
′′
1 is the restriction of these vectors
to the support of eV . With this notation, we now notice that
P(eU = e1|eV = e1 + e2) = Py1,y2,θ(e′U = e′1, e′′U = e′′1 |eV = e1 + e2)
= Py′1,θ(e
′
U = e
′
1)Py′′1 (e
′′
U = e
′′
1)
= Py′1,θ(ϕw′(U
′,y′1) = e
′
1)Py′′1 (e
′′
U = e
′′
1)
=
1(
n′
w′
) 1
2n/2−n′
. (27)
The last equality follows from the fact that ϕ behaves uniformly on U ′ and therefore the output
of ϕw′(U
′,y′1) is the uniform distribution over the set of words of weight w
′ in Fn′2 . (27) implies
that P(eU = e1|eV = e1 + e2) only depends on the weight of w′ which itself only depends on the
weight of e1 + e2. Since P(y1,y2),θ(ϕ(V,y1 + y2) = e1 + e2) has the same property, we deduce from
(26), that P(ẽ = (e1|e2)) only depends on the weight of e1 + e2. Obviously P(e = (e1|e2)) also
has this property. We may therefore write
P(ẽ = (e1|e2)) = f(|e1 + e2)|)
P(e = (e1|e2)) = g(|e1 + e2)|)
for some functions f and g. Plugging these expressions in (25) yields by bringing in the quantity
mi which is the number of e in Sw such that w1(e) = i:
ρ (Dw,Uw) =
∑
0≤i≤w
i≡w (mod 2)
∑
m∈Sw|w1(m)=i
|P(ẽ = m)− P(e = m)|
=
∑
0≤i≤w
i≡w (mod 2)
mi |f(i)− g(i)|
=
∑
0≤i≤w
i≡w (mod 2)
|mi(f(i)− g(i))|
=
∑
0≤i≤w
i≡w (mod 2)
|P(w1(ẽ) = i)− P(w1(e) = i)|
= ρ(psdd1 − pu1 ).
The last part of the proposition follows from the fact that the psdd1 (i)’s are functions of the non-
rejection probability vector x = (xi). Thanks to what we just proved, we can compute the xi’s to
have ρ
(
D1w,U
1
w
)
= 0. This will imply that the output of Algorithm 2 is the uniform distribution.
Indeed, we first notice that for all i:
0 ≤ xi =
1
Mrs
pu1 (i)
p(i)
=
 inf
0≤j≤w
w≡j (mod 2)
p(j)
pu1 (j)
 pu1 (i)
p(i)
≤ p(i)
p1u(i)
pu1 (i)
p(i)
= 1
38 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
which allows to assert that x is a probability vector. We now use the following equalities for all i:
psdd1 (i) =
xi p(i)
p1w
=
pu1 (i)
Mrs
∑
0≤j≤w
w≡j (mod 2)
1
Mrs
pu1 (j)
= pu1 (i).
where the last line relies on the equality
∑
0≤j≤w
w≡j (mod 2)
pu1 (j) = 1. ut
B.2 Proof of Proposition 7
Here the internal coins are over the choices of the n − k positions (columns of the parity-check
matrix H of C ) I we choose to invert in the Prange algorithm the square submatrix of H. We
have here
p(w) =
∑
e:|e|=w
Py,I
(
e = ϕPrange(C ,y)
)
=
∑
I⊂{1,...,n}:|I|=n−k
P(I)
∑
e:|e|=w
Py(e = ϕPrange(C ,y)|I)
=
∑
I⊂{1,...,n}:|I|=n−k
P(I)
∑
e:|e|=w,Supp(e)⊂I
1
2n−k
=
(
n−k
w
)
2n−k
.
C Proof of Proposition 8 in §6
Let us recall Proposition 8
Proposition 8. Assume that we choose a (U |U+V ) code by picking the parity-check matrices of U
and V uniformly at random among the binary matrices of size (n/2−kU )×n/2 and (n/2−kV )×n/2
respectively. Let a(U |U+V )(w), a(U |U)(w) and a(0|V )(w) be the expected number of codewords of
weight w that are respectively in the (U |U + V ) code, of the form (u|u) where u belongs to U and
of the form (0|v) where v belongs to V . These numbers are given for even w in {0, . . . , n} by
a(U |U+V )(w) =
(
n/2
w/2
)
2n/2−kU
+
(
n/2
w
)
2n/2−kV
+
1
2n−kU−kV
((
n
w
)
−
(
n/2
w
)
−
(
n/2
w/2
))
a(U |U)(w) =
(
n/2
w/2
)
2n/2−kU
; a(0|V )(w) =
(
n/2
w
)
2n/2−kV
and for odd w in {0, . . . , n} by
a(U |U+V )(w) =
(
n/2
w
)
2n/2−kV
+
1
2n−kU−kV
((
n
w
)
−
(
n/2
w
))
a(U |U)(w) = 0 ; a(0|V )(w) =
(
n/2
w
)
2n/2−kV
A new signature scheme based on (U |U + V ) codes 39
On the other hand, when we choose a code of length n with a random parity-check matrix of size
(n − kU − kV ) × n chosen uniformly at random, then the expected number a(w) of codewords of
weight w > 0 is given by
a(w) =
(
n
w
)
2n−kU−kV
.
We will need the following lemma.
Lemma 7. Let y be a non-zero vector of Fn2 and s an arbitrary element in Fr2. We choose a matrix
H of size r × n uniformly at random among the set of r × n binary matrices. In this case
P
(
HyT = sT
)
=
1
2r
Proof. The coefficient of H at row i and column j is denoted by hij , whereas the coefficients of y
and s are denoted by yi and si respectively. The probability we are looking for is the probability
to have ∑
j
hijyj = si (28)
for all i in {1, . . . , r}. Since y is non zero, it has at least one non-zero coordinate. Without loss
of generality, we may assume that y1 = 1. We may rewrite (28) as hi1 =
∑
j>1 hijyj . This event
happens with probability 12 for a given i and with probability
1
2r on all r events simultaneously
due to the independence of the hij ’s.
The last part of Proposition 8 is a direct application of this lemma. We namely have
Proposition 12. Let a(w) be the expected number of codewords in a binary linear code C of
length n whose parity-check matrix is chosen H uniformly at random among all binary matrices
of size r × n. We have
a(w) =
(
n
w
)
2n−r
.
Proof. Let Z
4
=
∑
x∈Fn2 :|x|=w
Zx where Zx is the indicator function of the event “x is in C ”. We
have
a(w) = E(Z)
=
∑
x∈Fn2 :|x|=w
E(Zx)
=
∑
x∈Fn2 :|x|=w
P(x ∈ C )
=
∑
x∈Fn2 :|x|=w
P(HxT = 0)
=
∑
x∈Fn2 :|x|=w
1
2r
=
(
n
w
)
2n−r
.
This proves the part of Proposition 8 dealing with the expected weight distribution of a random
linear code. We are ready now to prove Proposition 8 concerning the expected weight distribution
of a random (U |U + V ) code.
Weight distributions of (U |U)4={(u|u) : u ∈ U} and (0|V )4={(0|v) : v ∈ V }. This follows
directly from Proposition 12 since a(U,U)(w) = 0 for odd and a(U,U)(w) is equal to the expected
number of codewords of weight w/2 in a random linear code of length n/2 with a parity-check
40 Thomas Debris-Alazard, Nicolas Sendrier, and Jean-Pierre Tillich
matrix of size (n/2− kU )×n/2 when w is even. On the other hand a(0|V ) is equal to the expected
number of weight w in a random linear code of length n/2 and with a parity-check matrix of size
(n/2− kV )× n/2. In other words
a(U |U)(w) = 0 if w is odd
a(U |U)(w) =
(
n/2
w/2
)
2n/2−kU
if w is even
a(0|V )(w) =
(
n/2
w
)
2n/2−kV
Weight distributions of (U |U + V ). (U |U + V ) is chosen randomly by picking up a parity-
check matrix HU of U uniformly at random among the set of (n/2 − kU ) × n/2 binary matrices
and a parity-check matrix HV of V uniformly at random among the set of (n/2 − kV ) × n/2
binary matrices. Let Z
4
=
∑
x∈Fn2 :|x|=w
Zx where Zx is the indicator function of the event “x is in
(U |U + V )”.
We have
a(U |U+V )(w) = E(Z)
=
∑
x∈Fn2 :|x|=w
E(Zx)
=
∑
x∈Fn2 :|x|=w
P(Zx = 1)
=
∑
x∈Fn2 :|x|=w
P(x ∈ (U |U + V )) (29)
By writing x = (x1|x2) where xi is in Fn/22 we know that x is in (U |U + V ) if and only if at the
same time x1 is in U and x2 + x1 is in V , that is
HUx
T
1 = 0, HV x
T
1 = HV x
T
2 .
There are three cases to consider
Case 1: x1 = 0 and x2 6= 0. In this case
P(x ∈ (U |U + V )) = P(HV xT2 = 0) =
1
2n/2−kV
(30)
Case 2: x1 = x2. In this case
P(x ∈ (U |U + V )) = P(HUxT1 = 0) =
1
2n/2−kU
(31)
Case 3: x1 6= x2 and x1 6= 0. In this case
P(x ∈ (U |U + V )) = P(HUxT1 = 0 and HV (xT1 + xT2 ) = 0) =
1
2n/2−kU
1
2n/2−kV
(32)
Note that we used in each case Lemma 7.
By substituting P(x ∈ (U |U + V )) in (29) we obtain for even 0 < w ≤ n
a(U |U+V )(w) =
(
n/2
w/2
)
2n/2−kU
+
(
n/2
w
)
2n/2−kV
+
1
2n−kU−kV
((
n
w
)
−
(
n/2
w
)
−
(
n/2
w/2
))
and for odd w ≤ n
a(w) =
(
n/2
w
)
2n/2−kV
+
1
2n−kU−kV
((
n
w
)
−
(
n/2
w
))

